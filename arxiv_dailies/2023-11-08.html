<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.04287", "Date": "Tue, 07 Nov 2023 19:00:56 ", "Title": "Holistic Evaluation of Text-To-Image Models", "Authors": ["Tony Lee", "Michihiro Yasunaga", "Chenlin Meng", "Yifan Mai", "Joon Sung Park", "Agrim Gupta", "Yunzhi Zhang", "Deepak Narayanan", "Hannah Benita Teufel", "Marco Bellagente", "Minguk Kang", "Taesung Park", "Jure Leskovec", "Jun-Yan Zhu", "Li Fei-Fei", "Jiajun Wu", "Stefano Ermon", "Percy Liang"], "Categories": "cs.CV cs.LG", "Comments": ["NeurIPS 2023. First three authors contributed equally"]}, "abstract": "The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on text-image alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at https://crfm.stanford.edu/heim/v1.1.0 and the code at https://github.com/stanford-crfm/helm, which is integrated with the HELM codebase.", "url": "https://arxiv.org/abs/2311.04287"}, {"metadata": {"arXiv": "2311.04346", "Date": "Tue, 07 Nov 2023 21:06:06 ", "Title": "SaFL: Sybil-aware Federated Learning with Application to Face Recognition", "Authors": ["Mahdi Ghafourian", "Julian Fierrez", "Ruben Vera-Rodriguez", "Ruben Tolosana", "Aythami Morales"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Federated Learning (FL) is a machine learning paradigm to conduct collaborative learning among clients on a joint model. The primary goal is to share clients' local training parameters with an integrating server while preserving their privacy. This method permits to exploit the potential of massive mobile users' data for the benefit of machine learning models' performance while keeping sensitive data on local devices. On the downside, FL raises security and privacy concerns that have just started to be studied. To address some of the key threats in FL, researchers have proposed to use secure aggregation methods (e.g. homomorphic encryption, secure multiparty computation, etc.). These solutions improve some security and privacy metrics, but at the same time bring about other serious threats such as poisoning attacks, backdoor attacks, and free running attacks. This paper proposes a new defense method against poisoning attacks in FL called SaFL (Sybil-aware Federated Learning) that minimizes the effect of sybils with a novel time-variant aggregation scheme.", "url": "https://arxiv.org/abs/2311.04346"}, {"metadata": {"arXiv": "2311.04480", "Date": "Wed, 08 Nov 2023 06:20:32 ", "Title": "CLearViD: Curriculum Learning for Video Description", "Authors": ["Cheng-Yu Chuang", "Pooyan Fazli"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["15 pages", "4 figures"]}, "abstract": "Video description entails automatically generating coherent natural language sentences that narrate the content of a given video. We introduce CLearViD, a transformer-based model for video description generation that leverages curriculum learning to accomplish this task. In particular, we investigate two curriculum strategies: (1) progressively exposing the model to more challenging samples by gradually applying a Gaussian noise to the video data, and (2) gradually reducing the capacity of the network through dropout during the training process. These methods enable the model to learn more robust and generalizable features. Moreover, CLearViD leverages the Mish activation function, which provides non-linearity and non-monotonicity and helps alleviate the issue of vanishing gradients. Our extensive experiments and ablation studies demonstrate the effectiveness of the proposed model. The results on two datasets, namely ActivityNet Captions and YouCook2, show that CLearViD significantly outperforms existing state-of-the-art models in terms of both accuracy and diversity metrics.", "url": "https://arxiv.org/abs/2311.04480"}, {"metadata": {"arXiv": "2311.04711", "Date": "Wed, 08 Nov 2023 14:38:10 ", "Title": "Training CLIP models on Data from Scientific Papers", "Authors": ["Calvin Metzger"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023 Workshop"]}, "abstract": "Contrastive Language-Image Pretraining (CLIP) models are able to capture the semantic relationship of images and texts and have enabled a wide range of applications, from image retrieval to classification. These models are trained with datasets extracted from web crawls, which are of large quantity but limited quality. This paper explores whether limited amounts higher quality data in a specific domain improve the general performance of CLIP models. To this purpose, we extract text-image data from scientific papers hosted in the arXiv and PubMed Central repositories. Experiments on small-scale CLIP models (ViT B/32) show that model performance increases on average, but only moderately. This result indicates that using the data sources considered in the paper to train large-scale CLIP models is a worthwile research direction.", "url": "https://arxiv.org/abs/2311.04711"}, {"metadata": {"arXiv": "2311.04777", "Date": "Wed, 08 Nov 2023 15:55:18 ", "Title": "Lidar Annotation Is All You Need", "Authors": ["Dinar Sharafutdinov", "Stanislav Kuskov", "Saian Protasov", "Alexey Voropaev"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["Preprint", "11 pages"], "ACM-class": "I.4.6; I.2.10; I.2.9"}, "abstract": "In recent years, computer vision has transformed fields such as medical imaging, object recognition, and geospatial analytics. One of the fundamental tasks in computer vision is semantic image segmentation, which is vital for precise object delineation. Autonomous driving represents one of the key areas where computer vision algorithms are applied. The task of road surface segmentation is crucial in self-driving systems, but it requires a labor-intensive annotation process in several data domains. The work described in this paper aims to improve the efficiency of image segmentation using a convolutional neural network in a multi-sensor setup. This approach leverages lidar (Light Detection and Ranging) annotations to directly train image segmentation models on RGB images. Lidar supplements the images by emitting laser pulses and measuring reflections to provide depth information. However, lidar's sparse point clouds often create difficulties for accurate object segmentation. Segmentation of point clouds requires time-consuming preliminary data preparation and a large amount of computational resources. The key innovation of our approach is the masked loss, addressing sparse ground-truth masks from point clouds. By calculating loss exclusively where lidar points exist, the model learns road segmentation on images by using lidar points as ground truth. This approach allows for blending of different ground-truth data types during model training. Experimental validation of the approach on benchmark datasets shows comparable performance to a high-quality image segmentation model. Incorporating lidar reduces the load on annotations and enables training of image-segmentation models without loss of segmentation quality. The methodology is tested on diverse datasets, both publicly available and proprietary. The strengths and weaknesses of the proposed method are also discussed in the paper.", "url": "https://arxiv.org/abs/2311.04777"}, {"metadata": {"arXiv": "2311.04813", "Date": "Wed, 08 Nov 2023 16:39:13 ", "Title": "Be Careful When Evaluating Explanations Regarding Ground Truth", "Authors": ["Hubert Baniecki", "Maciej Chrabaszcz", "Andreas Holzinger", "Bastian Pfeifer", "Anna Saranti", "Przemyslaw Biecek"], "Categories": "cs.CV cs.LG"}, "abstract": "Evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves. Driven by this observation, we propose a framework for $\\textit{jointly}$ evaluating the robustness of safety-critical systems that $\\textit{combine}$ a deep neural network with an explanation method. These are increasingly used in real-world applications like medical image analysis or robotics. We introduce a fine-tuning procedure to (mis)align model$\\unicode{x2013}$explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment. Experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks.", "url": "https://arxiv.org/abs/2311.04813"}, {"metadata": {"arXiv": "2311.04252", "Date": "Tue, 07 Nov 2023 11:57:33 ", "Title": "CNN-Based Structural Damage Detection using Time-Series Sensor Data", "Authors": ["Ishan Pathak", "Ishan Jha", "Aditya Sadana", "and Basuraj Bhowmik"], "Categories": "cs.LG eess.SP", "Comments": ["13 pages", "5 figures"]}, "abstract": "Structural Health Monitoring (SHM) is vital for evaluating structural condition, aiming to detect damage through sensor data analysis. It aligns with predictive maintenance in modern industry, minimizing downtime and costs by addressing potential structural issues. Various machine learning techniques have been used to extract valuable information from vibration data, often relying on prior structural knowledge. This research introduces an innovative approach to structural damage detection, utilizing a new Convolutional Neural Network (CNN) algorithm. In order to extract deep spatial features from time series data, CNNs are taught to recognize long-term temporal connections. This methodology combines spatial and temporal features, enhancing discrimination capabilities when compared to methods solely reliant on deep spatial features. Time series data are divided into two categories using the proposed neural network: undamaged and damaged. To validate its efficacy, the method's accuracy was tested using a benchmark dataset derived from a three-floor structure at Los Alamos National Laboratory (LANL). The outcomes show that the new CNN algorithm is very accurate in spotting structural degradation in the examined structure.", "url": "https://arxiv.org/abs/2311.04252"}, {"metadata": {"arXiv": "2311.04293", "Date": "Tue, 07 Nov 2023 19:07:16 ", "Title": "Lie Point Symmetry and Physics Informed Networks", "Authors": ["Tara Akhound-Sadegh", "Laurence Perreault-Levasseur", "Johannes Brandstetter", "Max Welling", "Siamak Ravanbakhsh"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "Symmetries have been leveraged to improve the generalization of neural networks through different mechanisms from data augmentation to equivariant architectures. However, despite their potential, their integration into neural solvers for partial differential equations (PDEs) remains largely unexplored. We explore the integration of PDE symmetries, known as Lie point symmetries, in a major family of neural solvers known as physics-informed neural networks (PINNs). We propose a loss function that informs the network about Lie point symmetries in the same way that PINN models try to enforce the underlying PDE through a loss function. Intuitively, our symmetry loss ensures that the infinitesimal generators of the Lie group conserve the PDE solutions. Effectively, this means that once the network learns a solution, it also learns the neighbouring solutions generated by Lie point symmetries. Empirical evaluations indicate that the inductive bias introduced by the Lie point symmetries of the PDEs greatly boosts the sample efficiency of PINNs.", "url": "https://arxiv.org/abs/2311.04293"}, {"metadata": {"arXiv": "2311.04338", "Date": "Tue, 07 Nov 2023 20:45:46 ", "Title": "Convex Methods for Constrained Linear Bandits", "Authors": ["Amirhossein Afsharrad", "Ahmadreza Moradipari", "Sanjay Lall"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Recently, bandit optimization has received significant attention in real-world safety-critical systems that involve repeated interactions with humans. While there exist various algorithms with performance guarantees in the literature, practical implementation of the algorithms has not received as much attention. This work presents a comprehensive study on the computational aspects of safe bandit algorithms, specifically safe linear bandits, by introducing a framework that leverages convex programming tools to create computationally efficient policies. In particular, we first characterize the properties of the optimal policy for safe linear bandit problem and then propose an end-to-end pipeline of safe linear bandit algorithms that only involves solving convex problems. We also numerically evaluate the performance of our proposed methods.", "url": "https://arxiv.org/abs/2311.04338"}, {"metadata": {"arXiv": "2311.04378", "Date": "Tue, 07 Nov 2023 22:52:54 ", "Title": "Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models", "Authors": ["Hanlin Zhang", "Benjamin L. Edelman", "Danilo Francati", "Daniele Venturi", "Giuseppe Ateniese", "Boaz Barak"], "Categories": "cs.LG cs.CL cs.CR"}, "abstract": "Watermarking generative models consists of planting a statistical signal (watermark) in a model's output so that it can be later verified that the output was generated by the given model. A strong watermarking scheme satisfies the property that a computationally bounded attacker cannot erase the watermark without causing significant quality degradation. In this paper, we study the (im)possibility of strong watermarking schemes. We prove that, under well-specified and natural assumptions, strong watermarking is impossible to achieve. This holds even in the private detection algorithm setting, where the watermark insertion and detection algorithms share a secret key, unknown to the attacker. To prove this result, we introduce a generic efficient watermark attack; the attacker is not required to know the private key of the scheme or even which scheme is used. Our attack is based on two assumptions: (1) The attacker has access to a \"quality oracle\" that can evaluate whether a candidate output is a high-quality response to a prompt, and (2) The attacker has access to a \"perturbation oracle\" which can modify an output with a nontrivial probability of maintaining quality, and which induces an efficiently mixing random walk on high-quality outputs. We argue that both assumptions can be satisfied in practice by an attacker with weaker computational capabilities than the watermarked model itself, to which the attacker has only black-box access. Furthermore, our assumptions will likely only be easier to satisfy over time as models grow in capabilities and modalities. We demonstrate the feasibility of our attack by instantiating it to attack three existing watermarking schemes for large language models: Kirchenbauer et al. (2023), Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully removes the watermarks planted by all three schemes, with only minor quality degradation.", "url": "https://arxiv.org/abs/2311.04378"}, {"metadata": {"arXiv": "2311.04402", "Date": "Wed, 08 Nov 2023 00:10:21 ", "Title": "Likelihood Ratio Confidence Sets for Sequential Decision Making", "Authors": ["Nicolas Emmenegger", "Mojm\\'ir Mutn\\'y", "Andreas Krause"], "Categories": "cs.LG stat.ML"}, "abstract": "Certifiable, adaptive uncertainty estimates for unknown quantities are an essential ingredient of sequential decision-making algorithms. Standard approaches rely on problem-dependent concentration results and are limited to a specific combination of parameterization, noise family, and estimator. In this paper, we revisit the likelihood-based inference principle and propose to use likelihood ratios to construct any-time valid confidence sequences without requiring specialized treatment in each application scenario. Our method is especially suitable for problems with well-specified likelihoods, and the resulting sets always maintain the prescribed coverage in a model-agnostic manner. The size of the sets depends on a choice of estimator sequence in the likelihood ratio. We discuss how to provably choose the best sequence of estimators and shed light on connections to online convex optimization with algorithms such as Follow-the-Regularized-Leader. To counteract the initially large bias of the estimators, we propose a reweighting scheme that also opens up deployment in non-parametric settings such as RKHS function classes. We provide a non-asymptotic analysis of the likelihood ratio confidence sets size for generalized linear models, using insights from convex duality and online learning. We showcase the practical strength of our method on generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions.", "url": "https://arxiv.org/abs/2311.04402"}, {"metadata": {"arXiv": "2311.04434", "Date": "Wed, 08 Nov 2023 02:54:19 ", "Title": "A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space", "Authors": ["Wenchong He", "Zhe Jiang", "Tingsong Xiao", "Zelin Xu", "Shigang Chen", "Ronald Fick", "Miles Medina", "Christine Angelini"], "Categories": "cs.LG", "Comments": ["Accepted in NeurIPS 2023"]}, "abstract": "Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at \\url{https://github.com/spatialdatasciencegroup/HST}.", "url": "https://arxiv.org/abs/2311.04434"}, {"metadata": {"arXiv": "2311.04449", "Date": "Wed, 08 Nov 2023 04:20:56 ", "Title": "Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability", "Authors": ["Jishnu Ray Chowdhury", "Cornelia Caragea"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth is just $\\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive than even RNNs. In this paper, we introduce a novel framework -- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \\log_k n$. Our best RIR-based model is the first model that demonstrates high ($\\geq 90\\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: \\url{https://github.com/JRC1995/BeamRecursionFamily/}.", "url": "https://arxiv.org/abs/2311.04449"}, {"metadata": {"arXiv": "2311.04465", "Date": "Wed, 08 Nov 2023 05:26:58 ", "Title": "Solving High Frequency and Multi-Scale PDEs with Gaussian Processes", "Authors": ["Shikai Fang", "Madison Cooley", "Da Long", "Shibo Li", "Robert Kirby", "Shandian Zhe"], "Categories": "cs.LG cs.CE"}, "abstract": "Machine learning based solvers have garnered much attention in physical simulation and scientific computing, with a prominent example, physics-informed neural networks (PINNs). However, PINNs often struggle to solve high-frequency and multi-scale PDEs, which can be due to spectral bias during neural network training. To address this problem, we resort to the Gaussian process (GP) framework. To flexibly capture the dominant frequencies, we model the power spectrum of the PDE solution with a student t mixture or Gaussian mixture. We then apply the inverse Fourier transform to obtain the covariance function (according to the Wiener-Khinchin theorem). The covariance derived from the Gaussian mixture spectrum corresponds to the known spectral mixture kernel. We are the first to discover its rationale and effectiveness for PDE solving. Next,we estimate the mixture weights in the log domain, which we show is equivalent to placing a Jeffreys prior. It automatically induces sparsity, prunes excessive frequencies, and adjusts the remaining toward the ground truth. Third, to enable efficient and scalable computation on massive collocation points, which are critical to capture high frequencies, we place the collocation points on a grid, and multiply our covariance function at each input dimension. We use the GP conditional mean to predict the solution and its derivatives so as to fit the boundary condition and the equation itself. As a result, we can derive a Kronecker product structure in the covariance matrix. We use Kronecker product properties and multilinear algebra to greatly promote computational efficiency and scalability, without any low-rank approximations. We show the advantage of our method in systematic experiments.", "url": "https://arxiv.org/abs/2311.04465"}, {"metadata": {"arXiv": "2311.04503", "Date": "Wed, 08 Nov 2023 07:35:28 ", "Title": "Constrained Adaptive Attacks: Realistic Evaluation of Adversarial Examples and Robust Training of Deep Neural Networks for Tabular Data", "Authors": ["Thibault Simonetto", "Salah Ghamizi", "Antoine Desjardins", "Maxime Cordy", "Yves Le Traon"], "Categories": "cs.LG"}, "abstract": "State-of-the-art deep learning models for tabular data have recently achieved acceptable performance to be deployed in industrial settings. However, the robustness of these models remains scarcely explored. Contrary to computer vision, there is to date no realistic protocol to properly evaluate the adversarial robustness of deep tabular models due to intrinsic properties of tabular data such as categorical features, immutability, and feature relationship constraints. To fill this gap, we propose CAA, the first efficient evasion attack for constrained tabular deep learning models. CAA is an iterative parameter-free attack that combines gradient and search attacks to generate adversarial examples under constraints. We leverage CAA to build a benchmark of deep tabular models across three popular use cases: credit scoring, phishing and botnet attacks detection. Our benchmark supports ten threat models with increasing capabilities of the attacker, and reflects real-world attack scenarios for each use case. Overall, our results demonstrate how domain knowledge, adversarial training, and attack budgets impact the robustness assessment of deep tabular models and provide security practitioners with a set of recommendations to improve the robustness of deep tabular models against various evasion attack scenarios.", "url": "https://arxiv.org/abs/2311.04503"}, {"metadata": {"arXiv": "2311.04511", "Date": "Wed, 08 Nov 2023 07:57:21 ", "Title": "Solution of FPK Equation for Stochastic Dynamics Subjected to Additive Gaussian Noise via Deep Learning Approach", "Authors": ["Amir H. Khodabakhsh", "Seid H. Pourtakdoust"], "Categories": "cs.LG math.DS math.PR stat.AP", "Comments": ["43 pages", "21 figures"], "MSC-class": "60G65", "ACM-class": "G.3; I.2.6", "Journal-ref": "Struct Saf, 106 (2024) 102399", "DOI": "10.1016/j.strusafe.2023.102399"}, "abstract": "The Fokker-Plank-Kolmogorov (FPK) equation is an idealized model representing many stochastic systems commonly encountered in the analysis of stochastic structures as well as many other applications. Its solution thus provides an invaluable insight into the performance of many engineering systems. Despite its great importance, the solution of the FPK equation is still extremely challenging. For systems of practical significance, the FPK equation is usually high dimensional, rendering most of the numerical methods ineffective. In this respect, the present work introduces the FPK-DP Net as a physics-informed network that encodes the physical insights, i.e. the governing constrained differential equations emanated out of physical laws, into a deep neural network. FPK-DP Net is a mesh-free learning method that can solve the density evolution of stochastic dynamics subjected to additive white Gaussian noise without any prior simulation data and can be used as an efficient surrogate model afterward. FPK-DP Net uses the dimension-reduced FPK equation. Therefore, it can be used to address high-dimensional practical problems as well. To demonstrate the potential applicability of the proposed framework, and to study its accuracy and efficacy, numerical implementations on five different benchmark problems are investigated.", "url": "https://arxiv.org/abs/2311.04511"}, {"metadata": {"arXiv": "2311.04518", "Date": "Wed, 08 Nov 2023 08:02:59 ", "Title": "Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach", "Authors": ["Dennis Rall", "Bernhard Bauer", "Thomas Fraunholz"], "Categories": "cs.LG", "ACM-class": "I.2.1", "Journal-ref": "Proceedings of the 2023 7th International Conference on Cloud and Big Data Computing 34-39", "DOI": "10.1145/3616131.3616136"}, "abstract": "Recent AI research has significantly reduced the barriers to apply AI, but the process of setting up the necessary tools and frameworks can still be a challenge. While AI-as-a-Service platforms have emerged to simplify the training and deployment of AI models, they still fall short of achieving true democratization of AI. In this paper, we aim to address this gap by comparing several popular AI-as-a-Service platforms and identifying the key requirements for a platform that can achieve true democratization of AI. Our analysis highlights the need for self-hosting options, high scalability, and openness. To address these requirements, we propose our approach: the \"Open Space for Machine Learning\" platform. Our platform is built on cutting-edge technologies such as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the challenges of democratizing AI. We argue that our approach is more comprehensive and effective in meeting the requirements of democratizing AI than existing AI-as-a-Service platforms.", "url": "https://arxiv.org/abs/2311.04518"}, {"metadata": {"arXiv": "2311.04522", "Date": "Wed, 08 Nov 2023 08:22:38 ", "Title": "Long-term Time Series Forecasting based on Decomposition and Neural Ordinary Differential Equations", "Authors": ["Seonkyu Lim", "Jaehyeon Park", "Seojin Kim", "Hyowon Wi", "Haksoo Lim", "Jinsung Jeon", "Jeongwhan Choi", "Noseong Park"], "Categories": "cs.LG"}, "abstract": "Long-term time series forecasting (LTSF) is a challenging task that has been investigated in various domains such as finance investment, health care, traffic, and weather forecasting. In recent years, Linear-based LTSF models showed better performance, pointing out the problem of Transformer-based approaches causing temporal information loss. However, Linear-based approach has also limitations that the model is too simple to comprehensively exploit the characteristics of the dataset. To solve these limitations, we propose LTSF-DNODE, which applies a model based on linear ordinary differential equations (ODEs) and a time series decomposition method according to data statistical characteristics. We show that LTSF-DNODE outperforms the baselines on various real-world datasets. In addition, for each dataset, we explore the impacts of regularization in the neural ordinary differential equation (NODE) framework.", "url": "https://arxiv.org/abs/2311.04522"}, {"metadata": {"arXiv": "2311.04528", "Date": "Wed, 08 Nov 2023 08:33:03 ", "Title": "Bandit Learning to Rank with Position-Based Click Models: Personalized and Equal Treatments", "Authors": ["Tianchen Zhou", "Jia Liu", "Yang Jiao", "Chaosheng Dong", "Yetian Chen", "Yan Gao", "Yi Sun"], "Categories": "cs.LG cs.IR"}, "abstract": "Online learning to rank (ONL2R) is a foundational problem for recommender systems and has received increasing attention in recent years. Among the existing approaches for ONL2R, a natural modeling architecture is the multi-armed bandit framework coupled with the position-based click model. However, developing efficient online learning policies for MAB-based ONL2R with position-based click models is highly challenging due to the combinatorial nature of the problem, and partial observability in the position-based click model. To date, results in MAB-based ONL2R with position-based click models remain rather limited, which motivates us to fill this gap in this work. Our main contributions in this work are threefold: i) We propose the first general MAB framework that captures all key ingredients of ONL2R with position-based click models. Our model considers personalized and equal treatments in ONL2R ranking recommendations, both of which are widely used in practice; ii) Based on the above analytical framework, we develop two unified greed- and UCB-based policies called GreedyRank and UCBRank, each of which can be applied to personalized and equal ranking treatments; and iii) We show that both GreedyRank and UCBRank enjoy $O(\\sqrt{t}\\ln t)$ and $O(\\sqrt{t\\ln t})$ anytime sublinear regret for personalized and equal treatment, respectively. For the fundamentally hard equal ranking treatment, we identify classes of collective utility functions and their associated sufficient conditions under which $O(\\sqrt{t}\\ln t)$ and $O(\\sqrt{t\\ln t})$ anytime sublinear regrets are still achievable for GreedyRank and UCBRank, respectively. Our numerical experiments also verify our theoretical results and demonstrate the efficiency of GreedyRank and UCBRank in seeking the optimal action under various problem settings.", "url": "https://arxiv.org/abs/2311.04528"}, {"metadata": {"arXiv": "2311.04550", "Date": "Wed, 08 Nov 2023 09:33:21 ", "Title": "Regression with Cost-based Rejection", "Authors": ["Xin Cheng and Yuzhou Cao and Haobo Wang and Hongxin Wei and Bo An and Lei Feng"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2311.04550"}, {"metadata": {"arXiv": "2311.04561", "Date": "Wed, 08 Nov 2023 09:48:42 ", "Title": "Information-Theoretic Generalization Bounds for Transductive Learning and its Applications", "Authors": ["Huayi Tang and Yong Liu"], "Categories": "cs.LG stat.ML"}, "abstract": "In this paper, we develop data-dependent and algorithm-dependent generalization bounds for transductive learning algorithms in the context of information theory for the first time. We show that the generalization gap of transductive learning algorithms can be bounded by the mutual information between training labels and hypothesis. By innovatively proposing the concept of transductive supersamples, we go beyond the inductive learning setting and establish upper bounds in terms of various information measures. Furthermore, we derive novel PAC-Bayesian bounds and build the connection between generalization and loss landscape flatness under the transductive learning setting. Finally, we present the upper bounds for adaptive optimization algorithms and demonstrate the applications of results on semi-supervised learning and graph learning scenarios. Our theoretic results are validated on both synthetic and real-world datasets.", "url": "https://arxiv.org/abs/2311.04561"}, {"metadata": {"arXiv": "2311.04592", "Date": "Wed, 08 Nov 2023 10:45:12 ", "Title": "On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology", "Authors": ["Suryaka Suresh", "Bishshoy Das", "Vinayak Abrol", "Sumantra Dutta Roy"], "Categories": "cs.LG cs.CV"}, "abstract": "We study how the topology of feature embedding space changes as it passes through the layers of a well-trained deep neural network (DNN) through Betti numbers. Motivated by existing studies using simplicial complexes on shallow fully connected networks (FCN), we present an extended analysis using Cubical homology instead, with a variety of popular deep architectures and real image datasets. We demonstrate that as depth increases, a topologically complicated dataset is transformed into a simple one, resulting in Betti numbers attaining their lowest possible value. The rate of decay in topological complexity (as a metric) helps quantify the impact of architectural choices on the generalization ability. Interestingly from a representation learning perspective, we highlight several invariances such as topological invariance of (1) an architecture on similar datasets; (2) embedding space of a dataset for architectures of variable depth; (3) embedding space to input resolution/size, and (4) data sub-sampling. In order to further demonstrate the link between expressivity \\& the generalization capability of a network, we consider the task of ranking pre-trained models for downstream classification task (transfer learning). Compared to existing approaches, the proposed metric has a better correlation to the actually achievable accuracy via fine-tuning the pre-trained model.", "url": "https://arxiv.org/abs/2311.04592"}, {"metadata": {"arXiv": "2311.04599", "Date": "Wed, 08 Nov 2023 11:01:32 ", "Title": "Predicting Market Value in Professional Soccer: Insights from Explainable Machine Learning Models", "Authors": ["Chunyang Huang", "Shaoliang Zhang"], "Categories": "cs.LG cs.CY q-fin.CP", "Comments": ["9pages", "5figures"]}, "abstract": "This study presents an innovative method for predicting the market value of professional soccer players using explainable machine learning models. Using a dataset curated from the FIFA website, we employ an ensemble machine learning approach coupled with Shapley Additive exPlanations (SHAP) to provide detailed explanations of the models' predictions. The GBDT model achieves the highest mean R-Squared (0.8780) and the lowest mean Root Mean Squared Error (3,221,632.175), indicating its superior performance among the evaluated models. Our analysis reveals that specific skills such as ball control, short passing, finishing, interceptions, dribbling, and tackling are paramount within the skill dimension, whereas sprint speed and acceleration are critical in the fitness dimension, and reactions are preeminent in the cognitive dimension. Our results offer a more accurate, objective, and consistent framework for market value estimation, presenting useful insights for managerial decisions in player transfers.", "url": "https://arxiv.org/abs/2311.04599"}, {"metadata": {"arXiv": "2311.04606", "Date": "Wed, 08 Nov 2023 11:14:29 ", "Title": "Accurate Autism Spectrum Disorder prediction using Support Vector Classifier based on Federated Learning (SVCFL)", "Authors": ["Ali Mohammadifar", "Hasan Samadbin", "Arman Daliri"], "Categories": "cs.LG"}, "abstract": "The path to an autism diagnosis can be long and difficult, and delays can have serious consequences. Artificial intelligence can completely change the way autism is diagnosed, especially when it comes to situations where it is difficult to see the first signs of the disease. AI-based diagnostic tools may help confirm a diagnosis or highlight the need for further testing by analyzing large volumes of data and uncovering patterns that may not be immediately apparent to human evaluators. After a successful and timely diagnosis, autism can be treated through artificial intelligence using various methods. In this article, by using four datasets and gathering them with the federated learning method and diagnosing them with the support vector classifier method, the early diagnosis of this disorder has been discussed. In this method, we have achieved 99% accuracy for predicting autism spectrum disorder and we have achieved 13% improvement in the results.", "url": "https://arxiv.org/abs/2311.04606"}, {"metadata": {"arXiv": "2311.04611", "Date": "Wed, 08 Nov 2023 11:18:17 ", "Title": "Byzantine-Tolerant Methods for Distributed Variational Inequalities", "Authors": ["Nazarii Tupitsa", "Abdulla Jasem Almansoori", "Yanlin Wu", "Martin Tak\\'a\\v{c}", "Karthik Nandakumar", "Samuel Horv\\'ath", "Eduard Gorbunov"], "Categories": "cs.LG math.OC", "Comments": ["NeurIPS 2023; 69 pages", "12 figures"]}, "abstract": "Robustness to Byzantine attacks is a necessity for various distributed training scenarios. When the training reduces to the process of solving a minimization problem, Byzantine robustness is relatively well-understood. However, other problem formulations, such as min-max problems or, more generally, variational inequalities, arise in many modern machine learning and, in particular, distributed learning tasks. These problems significantly differ from the standard minimization ones and, therefore, require separate consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this important question in the context of Byzantine robustness. Our work makes a further step in this direction by providing several (provably) Byzantine-robust methods for distributed variational inequality, thoroughly studying their theoretical convergence, removing the limitations of the previous work, and providing numerical comparisons supporting the theoretical findings.", "url": "https://arxiv.org/abs/2311.04611"}, {"metadata": {"arXiv": "2311.04686", "Date": "Wed, 08 Nov 2023 13:46:58 ", "Title": "Robust and Communication-Efficient Federated Domain Adaptation via Random Features", "Authors": ["Zhanbo Feng", "Yuanjie Wang", "Jie Li", "Fan Yang", "Jiong Lou", "Tiebin Mi", "Robert. C. Qiu", "Zhenyu Liao"], "Categories": "cs.LG cs.DC stat.ML", "Comments": ["21 pages"]}, "abstract": "Modern machine learning (ML) models have grown to a scale where training them on a single machine becomes impractical. As a result, there is a growing trend to leverage federated learning (FL) techniques to train large ML models in a distributed and collaborative manner. These models, however, when deployed on new devices, might struggle to generalize well due to domain shifts. In this context, federated domain adaptation (FDA) emerges as a powerful approach to address this challenge. Most existing FDA approaches typically focus on aligning the distributions between source and target domains by minimizing their (e.g., MMD) distance. Such strategies, however, inevitably introduce high communication overheads and can be highly sensitive to network reliability. In this paper, we introduce RF-TCA, an enhancement to the standard Transfer Component Analysis approach that significantly accelerates computation without compromising theoretical and empirical performance. Leveraging the computational advantage of RF-TCA, we further extend it to FDA setting with FedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that is \\emph{independent} of the sample size, while maintaining performance that is either comparable to or even surpasses state-of-the-art FDA methods. We present extensive experiments to showcase the superior performance and robustness (to network condition) of FedRF-TCA.", "url": "https://arxiv.org/abs/2311.04686"}, {"metadata": {"arXiv": "2311.04731", "Date": "Wed, 08 Nov 2023 14:58:11 ", "Title": "Robust Best-arm Identification in Linear Bandits", "Authors": ["Wei Wang", "Sattar Vakili", "Ilija Bogunovic"], "Categories": "cs.LG stat.ML"}, "abstract": "We study the robust best-arm identification problem (RBAI) in the case of linear rewards. The primary objective is to identify a near-optimal robust arm, which involves selecting arms at every round and assessing their robustness by exploring potential adversarial actions. This approach is particularly relevant when utilizing a simulator and seeking to identify a robust solution for real-world transfer. To this end, we present an instance-dependent lower bound for the robust best-arm identification problem with linear rewards. Furthermore, we propose both static and adaptive bandit algorithms that achieve sample complexity that matches the lower bound. In synthetic experiments, our algorithms effectively identify the best robust arm and perform similarly to the oracle strategy. As an application, we examine diabetes care and the process of learning insulin dose recommendations that are robust with respect to inaccuracies in standard calculators. Our algorithms prove to be effective in identifying robust dosage values across various age ranges of patients.", "url": "https://arxiv.org/abs/2311.04731"}, {"metadata": {"arXiv": "2311.04774", "Date": "Wed, 08 Nov 2023 15:52:32 ", "Title": "Towards a Unified Framework of Contrastive Learning for Disentangled Representations", "Authors": ["Stefan Matthes", "Zhiwei Han", "Hao Shen"], "Categories": "cs.LG stat.ML"}, "abstract": "Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data. Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process. This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution. Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions. The theoretical findings are validated on several benchmark datasets. Finally, practical limitations of these methods are also investigated.", "url": "https://arxiv.org/abs/2311.04774"}, {"metadata": {"arXiv": "2311.04787", "Date": "Wed, 08 Nov 2023 16:09:25 ", "Title": "Why Do Clinical Probabilistic Models Fail To Transport Between Sites?", "Authors": ["Thomas A. Lasko", "Eric V. Strobl", "William W. Stead"], "Categories": "cs.LG cs.PF stat.ML", "Comments": ["18 pages", "3 figures"]}, "abstract": "The rising popularity of artificial intelligence in healthcare is highlighting the problem that a computational model achieving super-human clinical performance at its training sites may perform substantially worse at new sites. In this perspective, we present common sources for this failure to transport, which we divide into sources under the control of the experimenter and sources inherent to the clinical data-generating process. Of the inherent sources we look a little deeper into site-specific clinical practices that can affect the data distribution, and propose a potential solution intended to isolate the imprint of those practices on the data from the patterns of disease cause and effect that are the usual target of clinical models.", "url": "https://arxiv.org/abs/2311.04787"}, {"metadata": {"arXiv": "2311.04789", "Date": "Wed, 08 Nov 2023 16:10:28 ", "Title": "Determination of toxic comments and unintended model bias minimization using Deep learning approach", "Authors": ["Md Azim Khan"], "Categories": "cs.LG cs.CL cs.CY"}, "abstract": "Online conversations can be toxic and subjected to threats, abuse, or harassment. To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years. However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias. In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers). We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization. The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git", "url": "https://arxiv.org/abs/2311.04789"}, {"metadata": {"arXiv": "2311.04818", "Date": "Wed, 08 Nov 2023 16:42:14 ", "Title": "Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment", "Authors": ["Matt Gorbett", "Hossein Shirazi", "Indrakshi Ray"], "Categories": "cs.LG cs.CV cs.DC", "Comments": ["Published at IEEE Big Data 2023"]}, "abstract": "Learning from the collective knowledge of data dispersed across private sources can provide neural networks with enhanced generalization capabilities. Federated learning, a method for collaboratively training a machine learning model across remote clients, achieves this by combining client models via the orchestration of a central server. However, current approaches face two critical limitations: i) they struggle to converge when client domains are sufficiently different, and ii) current aggregation techniques produce an identical global model for each client. In this work, we address these issues by reformulating the typical federated learning setup: rather than learning a single global model, we learn N models each optimized for a common objective. To achieve this, we apply a weighted distance minimization to model parameters shared in a peer-to-peer topology. The resulting framework, Iterative Parameter Alignment, applies naturally to the cross-silo setting, and has the following properties: (i) a unique solution for each participant, with the option to globally converge each model in the federation, and (ii) an optional early-stopping mechanism to elicit fairness among peers in collaborative learning settings. These characteristics jointly provide a flexible new framework for iteratively learning from peer models trained on disparate datasets. We find that the technique achieves competitive results on a variety of data partitions compared to state-of-the-art approaches. Further, we show that the method is robust to divergent domains (i.e. disjoint classes across peers) where existing approaches struggle.", "url": "https://arxiv.org/abs/2311.04818"}, {"metadata": {"arXiv": "2311.04829", "Date": "Wed, 08 Nov 2023 16:54:23 ", "Title": "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data", "Authors": ["Shikai Fang", "Xin Yu", "Zheng Wang", "Shibo Li", "Mike Kirby", "Shandian Zhe"], "Categories": "cs.LG stat.ML"}, "abstract": "Tucker decomposition is a powerful tensor model to handle multi-aspect data. It demonstrates the low-rank property by decomposing the grid-structured data as interactions between a core tensor and a set of object representations (factors). A fundamental assumption of such decomposition is that there were finite objects in each aspect or mode, corresponding to discrete indexes of data entries. However, many real-world data are not naturally posed in the setting. For example, geographic data is represented as continuous indexes of latitude and longitude coordinates, and cannot fit tensor models directly. To generalize Tucker decomposition to such scenarios, we propose Functional Bayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as the interaction between the Tucker core and a group of latent functions. We use Gaussian processes (GP) as functional priors to model the latent functions, and then convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE) to reduce computational cost. An efficient inference algorithm is further developed for scalable posterior approximation based on advanced message-passing techniques. The advantage of our method is shown in both synthetic data and several real-world applications.", "url": "https://arxiv.org/abs/2311.04829"}, {"metadata": {"arXiv": "2311.04830", "Date": "Wed, 08 Nov 2023 16:56:16 ", "Title": "Real-Time Recurrent Reinforcement Learning", "Authors": ["Julian Lemmel", "Radu Grosu"], "Categories": "cs.LG cs.NE cs.SY eess.SY", "Comments": ["12 pages", "8 figures", "includes Appendix"]}, "abstract": "Recent advances in reinforcement learning, for partially-observable Markov decision processes (POMDPs), rely on the biologically implausible backpropagation through time algorithm (BPTT) to perform gradient-descent optimisation. In this paper we propose a novel reinforcement learning algorithm that makes use of random feedback local online learning (RFLO), a biologically plausible approximation of realtime recurrent learning (RTRL) to compute the gradients of the parameters of a recurrent neural network in an online manner. By combining it with TD($\\lambda$), a variant of temporaldifference reinforcement learning with eligibility traces, we create a biologically plausible, recurrent actor-critic algorithm, capable of solving discrete and continuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as different network architectures, and find that RFLO can perform just as well as RTRL while exceeding even BPTT in terms of complexity. The proposed method, called real-time recurrent reinforcement learning (RTRRL), serves as a model of learning in biological neural networks mimicking reward pathways in the mammalian brain.", "url": "https://arxiv.org/abs/2311.04830"}, {"metadata": {"arXiv": "2311.04843", "Date": "Wed, 08 Nov 2023 17:26:38 ", "Title": "Bridging Dimensions: Confident Reachability for High-Dimensional Controllers", "Authors": ["Yuang Geng", "Souradeep Dutta", "Ivan Ruchkin"], "Categories": "cs.LG"}, "abstract": "Autonomous systems are increasingly implemented using end-end-end trained controllers. Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions. Especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation. Then, if low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller. We investigate two inflation techniques -- based on trajectories and actions -- both of which show convincing performance in two OpenAI gym benchmarks.", "url": "https://arxiv.org/abs/2311.04843"}, {"metadata": {"arXiv": "2311.04846", "Date": "Wed, 08 Nov 2023 17:29:41 ", "Title": "Incorporating temporal dynamics of mutations to enhance the prediction capability of antiretroviral therapy's outcome for HIV-1", "Authors": ["Giulia Di Teodoro", "Martin Pirkl", "Francesca Incardona", "Ilaria Vicenti", "Anders S\\\"onnerborg", "Rolf Kaiser", "Laura Palagi", "Maurizio Zazzi", "Thomas Lengauer"], "Categories": "cs.LG q-bio.QM", "Comments": ["14 pages", "5 figures"]}, "abstract": "Motivation: In predicting HIV therapy outcomes, a critical clinical question is whether using historical information can enhance predictive capabilities compared with current or latest available data analysis. This study analyses whether historical knowledge, which includes viral mutations detected in all genotypic tests before therapy, their temporal occurrence, and concomitant viral load measurements, can bring improvements. We introduce a method to weigh mutations, considering the previously enumerated factors and the reference mutation-drug Stanford resistance tables. We compare a model encompassing history (H) with one not using it (NH). Results: The H-model demonstrates superior discriminative ability, with a higher ROC-AUC score (76.34%) than the NH-model (74.98%). Significant Wilcoxon test results confirm that incorporating historical information improves consistently predictive accuracy for treatment outcomes. The better performance of the H-model might be attributed to its consideration of latent HIV reservoirs, probably obtained when leveraging historical information. The findings emphasize the importance of temporal dynamics in mutations, offering insights into HIV infection complexities. However, our result also shows that prediction accuracy remains relatively high even when no historical information is available. Supplementary information: Supplementary material is available.", "url": "https://arxiv.org/abs/2311.04846"}, {"metadata": {"arXiv": "2311.04896", "Date": "Wed, 08 Nov 2023 18:56:29 ", "Title": "Optimized measurements of chaotic dynamical systems via the information bottleneck", "Authors": ["Kieran A. Murphy and Dani S. Bassett"], "Categories": "cs.LG cs.IT math.IT nlin.CD", "Comments": ["Project page: https://distributed-information-bottleneck.github.io"]}, "abstract": "Deterministic chaos permits a precise notion of a \"perfect measurement\" as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy. Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done. We establish an equivalence between a perfect measurement and a variant of the information bottleneck. As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data. We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series.", "url": "https://arxiv.org/abs/2311.04896"}, {"metadata": {"arXiv": "2311.04740", "Date": "Wed, 08 Nov 2023 15:08:55 ", "Title": "Enhancing Multi-Agent Coordination through Common Operating Picture Integration", "Authors": ["Peihong Yu", "Bhoram Lee", "Aswin Raghavan", "Supun Samarasekara", "Pratap Tokekar", "James Zachary Hare"], "Categories": "cs.MA cs.LG cs.RO", "Comments": ["accepted to OODWorkshop@CoRL23; please see https://openreview.net/forum?id=fADcJl0B0P for the paper"]}, "abstract": "In multi-agent systems, agents possess only local observations of the environment. Communication between teammates becomes crucial for enhancing coordination. Past research has primarily focused on encoding local information into embedding messages which are unintelligible to humans. We find that using these messages in agent's policy learning leads to brittle policies when tested on out-of-distribution initial states. We present an approach to multi-agent coordination, where each agent is equipped with the capability to integrate its (history of) observations, actions and messages received into a Common Operating Picture (COP) and disseminate the COP. This process takes into account the dynamic nature of the environment and the shared mission. We conducted experiments in the StarCraft2 environment to validate our approach. Our results demonstrate the efficacy of COP integration, and show that COP-based training leads to robust policies compared to state-of-the-art Multi-Agent Reinforcement Learning (MARL) methods when faced with out-of-distribution initial states.", "url": "https://arxiv.org/abs/2311.04740"}, {"metadata": {"arXiv": "2311.04472", "Date": "Wed, 08 Nov 2023 05:54:22 ", "Title": "Autonomous Advanced Aerial Mobility -- An End-to-end Autonomy Framework for UAVs and Beyond", "Authors": ["Sakshi Mishra and Praveen Palanisamy"], "Categories": "cs.RO cs.LG cs.MA cs.SY eess.SY", "Comments": ["32 pages", "12 figures"]}, "abstract": "Developing aerial robots that can both safely navigate and execute assigned mission without any human intervention - i.e., fully autonomous aerial mobility of passengers and goods - is the larger vision that guides the research, design, and development efforts in the aerial autonomy space. However, it is highly challenging to concurrently operationalize all types of aerial vehicles that are operating fully autonomously sharing the airspace. Full autonomy of the aerial transportation sector includes several aspects, such as design of the technology that powers the vehicles, operations of multi-agent fleets, and process of certification that meets stringent safety requirements of aviation sector. Thereby, Autonomous Advanced Aerial Mobility is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we present a comprehensive perspective on the emerging field of autonomous advanced aerial mobility, which involves the use of unmanned aerial vehicles (UAVs) and electric vertical takeoff and landing (eVTOL) aircraft for various applications, such as urban air mobility, package delivery, and surveillance. The article proposes a scalable and extensible autonomy framework consisting of four main blocks: sensing, perception, planning, and controls. Furthermore, the article discusses the challenges and opportunities in multi-agent fleet operations and management, as well as the testing, validation, and certification aspects of autonomous aerial systems. Finally, the article explores the potential of monolithic models for aerial autonomy and analyzes their advantages and limitations. The perspective aims to provide a holistic picture of the autonomous advanced aerial mobility field and its future directions.", "url": "https://arxiv.org/abs/2311.04472"}, {"metadata": {"arXiv": "2311.04838", "Date": "Wed, 08 Nov 2023 17:02:53 ", "Title": "Toward Rapid, Optimal, and Feasible Power Dispatch through Generalized Neural Mapping", "Authors": ["Meiyi Li", "Javad Mohammadi"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "The evolution towards a more distributed and interconnected grid necessitates large-scale decision-making within strict temporal constraints. Machine learning (ML) paradigms have demonstrated significant potential in improving the efficacy of optimization processes. However, the feasibility of solutions derived from ML models continues to pose challenges. It's imperative that ML models produce solutions that are attainable and realistic within the given system constraints of power systems. To address the feasibility issue and expedite the solution search process, we proposed LOOP-LC 2.0(Learning to Optimize the Optimization Process with Linear Constraints version 2.0) as a learning-based approach for solving the power dispatch problem. A notable advantage of the LOOP-LC 2.0 framework is its ability to ensure near-optimality and strict feasibility of solutions without depending on computationally intensive post-processing procedures, thus eliminating the need for iterative processes. At the heart of the LOOP-LC 2.0 model lies the newly proposed generalized gauge map method, capable of mapping any infeasible solution to a feasible point within the linearly-constrained domain. The proposed generalized gauge map method improves the traditional gauge map by exhibiting reduced sensitivity to input variances while increasing search speeds significantly. Utilizing the IEEE-200 test case as a benchmark, we demonstrate the effectiveness of the LOOP-LC 2.0 methodology, confirming its superior performance in terms of training speed, computational time, optimality, and solution feasibility compared to existing methodologies.", "url": "https://arxiv.org/abs/2311.04838"}, {"metadata": {"arXiv": "2311.04403", "Date": "Wed, 08 Nov 2023 00:14:05 ", "Title": "Human-Centered Planning", "Authors": ["Yuliang Li and Nitin Kamra and Ruta Desai and Alon Halevy"], "Categories": "cs.AI"}, "abstract": "LLMs have recently made impressive inroads on tasks whose output is structured, such as coding, robotic planning and querying databases. The vision of creating AI-powered personal assistants also involves creating structured outputs, such as a plan for one's day, or for an overseas trip. Here, since the plan is executed by a human, the output doesn't have to satisfy strict syntactic constraints. A useful assistant should also be able to incorporate vague constraints specified by the user in natural language. This makes LLMs an attractive option for planning. We consider the problem of planning one's day. We develop an LLM-based planner (LLMPlan) extended with the ability to self-reflect on its output and a symbolic planner (SymPlan) with the ability to translate text constraints into a symbolic representation. Despite no formal specification of constraints, we find that LLMPlan performs explicit constraint satisfaction akin to the traditional symbolic planners on average (2% performance difference), while retaining the reasoning of implicit requirements. Consequently, LLM-based planners outperform their symbolic counterparts in user satisfaction (70.5% vs. 40.4%) during interactive evaluation with 40 users.", "url": "https://arxiv.org/abs/2311.04403"}, {"metadata": {"arXiv": "2311.04412", "Date": "Wed, 08 Nov 2023 00:54:06 ", "Title": "Human Conditional Reasoning in Answer Set Programming", "Authors": ["Chiaki Sakama"], "Categories": "cs.AI cs.LO", "Comments": ["Under consideration in Theory and Practice of Logic Programming (TPLP)"]}, "abstract": "Given a conditional sentence P=>Q (if P then Q) and respective facts, four different types of inferences are observed in human reasoning. Affirming the antecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent (AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and denying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them, AA and DC are logically valid, while AC and DA are logically invalid and often called logical fallacies. Nevertheless, humans often perform AC or DA as pragmatic inference in daily life. In this paper, we realize AC, DA and DC inferences in answer set programming. Eight different types of completion are introduced and their semantics are given by answer sets. We investigate formal properties and characterize human reasoning tasks in cognitive psychology. Those completions are also applied to commonsense reasoning in AI.", "url": "https://arxiv.org/abs/2311.04412"}, {"metadata": {"arXiv": "2311.04474", "Date": "Wed, 08 Nov 2023 05:57:39 ", "Title": "Emergent Communication for Rules Reasoning", "Authors": ["Yuxuan Guo", "Yifan Hao", "Rui Zhang", "Enshuai Zhou", "Zidong Du", "Xishan Zhang", "Xinkai Song", "Yuanbo Wen", "Yongwei Zhao", "Xuehai Zhou", "Jiaming Guo", "Qi Yi", "Shaohui Peng", "Di Huang", "Ruizhi Chen", "Qi Guo", "Yunji Chen"], "Categories": "cs.AI"}, "abstract": "Research on emergent communication between deep-learning-based agents has received extensive attention due to its inspiration for linguistics and artificial intelligence. However, previous attempts have hovered around emerging communication under perception-oriented environmental settings, that forces agents to describe low-level perceptual features intra image or symbol contexts. In this work, inspired by the classic human reasoning test (namely Raven's Progressive Matrix), we propose the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules, rather than perceived low-level contexts. Moreover, we propose 1) an unbiased dataset (namely rule-RAVEN) as a benchmark to avoid overfitting, 2) and a two-stage curriculum agent training method as a baseline for more stable convergence in the Reasoning Game, where contexts and semantics are bilaterally drifting. Experimental results show that, in the Reasoning Game, a semantically stable and compositional language emerges to solve reasoning problems. The emerged language helps agents apply the extracted rules to the generalization of unseen context attributes, and to the transfer between different context attributes or even tasks.", "url": "https://arxiv.org/abs/2311.04474"}, {"metadata": {"arXiv": "2311.04659", "Date": "Wed, 08 Nov 2023 13:00:06 ", "Title": "Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models", "Authors": ["Yiyuan Li", "Rakesh R. Menon", "Sayan Ghosh", "Shashank Srivastava"], "Categories": "cs.AI", "Comments": ["EMNLP 2023"]}, "abstract": "Generalized quantifiers (e.g., few, most) are used to indicate the proportions predicates are satisfied (for example, some apples are red). One way to interpret quantifier semantics is to explicitly bind these satisfactions with percentage scopes (e.g., 30%-40% of apples are red). This approach can be helpful for tasks like logic formalization and surface-form quantitative reasoning (Gordon and Schubert, 2010; Roy et al., 2015). However, it remains unclear if recent foundation models possess this ability, as they lack direct training signals. To explore this, we introduce QuRe, a crowd-sourced dataset of human-annotated generalized quantifiers in Wikipedia sentences featuring percentage-equipped predicates. We explore quantifier comprehension in language models using PRESQUE, a framework that combines natural language inference and the Rational Speech Acts framework. Experimental results on the HVD dataset and QuRe illustrate that PRESQUE, employing pragmatic reasoning, performs 20% better than a literal reasoning baseline when predicting quantifier percentage scopes, with no additional training required.", "url": "https://arxiv.org/abs/2311.04659"}, {"metadata": {"arXiv": "2311.04778", "Date": "Wed, 08 Nov 2023 15:57:26 ", "Title": "On the Multiple Roles of Ontologies in Explainable AI", "Authors": ["Roberto Confalonieri and Giancarlo Guizzardi"], "Categories": "cs.AI", "Comments": ["Submitted to the Neurosymbolic AI journal: https://www.neurosymbolic-ai-journal.com/system/files/nai-paper-683.pdf"], "ACM-class": "I.2.6"}, "abstract": "This paper discusses the different roles that explicit knowledge, in particular ontologies, can play in Explainable AI and in the development of human-centric explainable systems and intelligible explanations. We consider three main perspectives in which ontologies can contribute significantly, namely reference modelling, common-sense reasoning, and knowledge refinement and complexity management. We overview some of the existing approaches in the literature, and we position them according to these three proposed perspectives. The paper concludes by discussing what challenges still need to be addressed to enable ontology-based approaches to explanation and to evaluate their human-understandability and effectiveness.", "url": "https://arxiv.org/abs/2311.04778"}, {"metadata": {"arXiv": "2311.04498", "Date": "Wed, 08 Nov 2023 07:15:05 ", "Title": "NExT-Chat: An LMM for Chat, Detection and Segmentation", "Authors": ["Ao Zhang", "Liming Zhao", "Chen-Wei Xie", "Yun Zheng", "Wei Ji", "Tat-Seng Chua"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Project: https://next-chatv.github.io/"]}, "abstract": "The development of large language models (LLMs) has greatly advanced the field of multimodal understanding, leading to the emergence of large multimodal models (LMMs). In order to enhance the level of visual comprehension, recent studies have equipped LMMs with region-level understanding capabilities by representing object bounding box coordinates as a series of text sequences (pixel2seq). In this paper, we introduce a novel paradigm for object location modeling called pixel2emb method, where we ask the LMM to output the location embeddings and then decoded by different decoders. This paradigm allows for different location formats (such as bounding boxes and masks) to be used in multimodal conversations Furthermore, this kind of embedding based location modeling enables the utilization of existing practices in localization tasks, such as detection and segmentation. In scenarios with limited resources, our pixel2emb demonstrates superior performance compared to existing state-of-the-art (SOTA) approaches in both the location input and output tasks under fair comparison. Leveraging the proposed pixel2emb method, we train an LMM named NExT-Chat and demonstrate its capability of handling multiple tasks like visual grounding, region caption, and grounded reasoning.", "url": "https://arxiv.org/abs/2311.04498"}, {"metadata": {"arXiv": "2311.04512", "Date": "Wed, 08 Nov 2023 07:57:29 ", "Title": "FFINet: Future Feedback Interaction Network for Motion Forecasting", "Authors": ["Miao Kang", "Shengqi Wang", "Sanping Zhou", "Ke Ye", "Jingjing Jiang", "Nanning Zheng"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "8 figures", "12 tables"]}, "abstract": "Motion forecasting plays a crucial role in autonomous driving, with the aim of predicting the future reasonable motions of traffic agents. Most existing methods mainly model the historical interactions between agents and the environment, and predict multi-modal trajectories in a feedforward process, ignoring potential trajectory changes caused by future interactions between agents. In this paper, we propose a novel Future Feedback Interaction Network (FFINet) to aggregate features the current observations and potential future interactions for trajectory prediction. Firstly, we employ different spatial-temporal encoders to embed the decomposed position vectors and the current position of each scene, providing rich features for the subsequent cross-temporal aggregation. Secondly, the relative interaction and cross-temporal aggregation strategies are sequentially adopted to integrate features in the current fusion module, observation interaction module, future feedback module and global fusion module, in which the future feedback module can enable the understanding of pre-action by feeding the influence of preview information to feedforward prediction. Thirdly, the comprehensive interaction features are further fed into final predictor to generate the joint predicted trajectories of multiple agents. Extensive experimental results show that our FFINet achieves the state-of-the-art performance on Argoverse 1 and Argoverse 2 motion forecasting benchmarks.", "url": "https://arxiv.org/abs/2311.04512"}, {"metadata": {"arXiv": "2311.04645", "Date": "Wed, 08 Nov 2023 12:44:38 ", "Title": "SKU-Patch: Towards Efficient Instance Segmentation for Unseen Objects in Auto-Store", "Authors": ["Biqi Yang", "Weiliang Tang", "Xiaojie Gao", "Xianzhi Li", "Yun-Hui Liu", "Chi-Wing Fu", "Pheng-Ann Heng"], "Categories": "cs.CV cs.AI"}, "abstract": "In large-scale storehouses, precise instance masks are crucial for robotic bin picking but are challenging to obtain. Existing instance segmentation methods typically rely on a tedious process of scene collection, mask annotation, and network fine-tuning for every single Stock Keeping Unit (SKU). This paper presents SKU-Patch, a new patch-guided instance segmentation solution, leveraging only a few image patches for each incoming new SKU to predict accurate and robust masks, without tedious manual effort and model re-training. Technical-wise, we design a novel transformer-based network with (i) a patch-image correlation encoder to capture multi-level image features calibrated by patch information and (ii) a patch-aware transformer decoder with parallel task heads to generate instance masks. Extensive experiments on four storehouse benchmarks manifest that SKU-Patch is able to achieve the best performance over the state-of-the-art methods. Also, SKU-Patch yields an average of nearly 100% grasping success rate on more than 50 unseen SKUs in a robot-aided auto-store logistic pipeline, showing its effectiveness and practicality.", "url": "https://arxiv.org/abs/2311.04645"}, {"metadata": {"arXiv": "2311.04397", "Date": "Tue, 07 Nov 2023 23:55:56 ", "Title": "ToP-ToM: Trust-aware Robot Policy with Theory of Mind", "Authors": ["Chuang Yu", "Baris Serhan and Angelo Cangelosi"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages"]}, "abstract": "Theory of Mind (ToM) is a fundamental cognitive architecture that endows humans with the ability to attribute mental states to others. Humans infer the desires, beliefs, and intentions of others by observing their behavior and, in turn, adjust their actions to facilitate better interpersonal communication and team collaboration. In this paper, we investigated trust-aware robot policy with the theory of mind in a multiagent setting where a human collaborates with a robot against another human opponent. We show that by only focusing on team performance, the robot may resort to the reverse psychology trick, which poses a significant threat to trust maintenance. The human's trust in the robot will collapse when they discover deceptive behavior by the robot. To mitigate this problem, we adopt the robot theory of mind model to infer the human's trust beliefs, including true belief and false belief (an essential element of ToM). We designed a dynamic trust-aware reward function based on different trust beliefs to guide the robot policy learning, which aims to balance between avoiding human trust collapse due to robot reverse psychology. The experimental results demonstrate the importance of the ToM-based robot policy for human-robot trust and the effectiveness of our robot ToM-based robot policy in multiagent interaction settings.", "url": "https://arxiv.org/abs/2311.04397"}, {"metadata": {"arXiv": "2311.04235", "Date": "Mon, 06 Nov 2023 08:50:29 ", "Title": "Can LLMs Follow Simple Rules?", "Authors": ["Norman Mu", "Sarah Chen", "Zifan Wang", "Sizhe Chen", "David Karamardian", "Lulwa Aljeraisy", "Dan Hendrycks", "David Wagner"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Project website: https://eecs.berkeley.edu/~normanmu/llm_rules"]}, "abstract": "As Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and constrain the behavior of these systems in a reliable manner. Model developers may wish to set explicit rules for the model, such as \"do not generate abusive content\", but these may be circumvented by jailbreaking techniques. Evaluating how well LLMs follow developer-provided rules in the face of adversarial inputs typically requires manual review, which slows down monitoring and methods development. To address this issue, we propose Rule-following Language Evaluation Scenarios (RuLES), a programmatic framework for measuring rule-following ability in LLMs. RuLES consists of 15 simple text scenarios in which the model is instructed to obey a set of rules in natural language while interacting with the human user. Each scenario has a concise evaluation program to determine whether the model has broken any rules in a conversation. Through manual exploration of model behavior in our scenarios, we identify 6 categories of attack strategies and collect two suites of test cases: one consisting of unique conversations from manual testing and one that systematically implements strategies from the 6 categories. Across various popular proprietary and open models such as GPT-4 and Llama 2, we find that all models are susceptible to a wide variety of adversarial hand-crafted user inputs, though GPT-4 is the best-performing model. Additionally, we evaluate open models under gradient-based attacks and find significant vulnerabilities. We propose RuLES as a challenging new setting for research into exploring and defending against both manual and automatic attacks on LLMs.", "url": "https://arxiv.org/abs/2311.04235"}, {"metadata": {"arXiv": "2311.04239", "Date": "Mon, 06 Nov 2023 19:53:26 ", "Title": "Kindness in Multi-Agent Reinforcement Learning", "Authors": ["Farinaz Alamiyan-Harandi", "Mersad Hassanjani", "Pouria Ramazi"], "Categories": "cs.AI cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2302.12053"]}, "abstract": "In human societies, people often incorporate fairness in their decisions and treat reciprocally by being kind to those who act kindly. They evaluate the kindness of others' actions not only by monitoring the outcomes but also by considering the intentions. This behavioral concept can be adapted to train cooperative agents in Multi-Agent Reinforcement Learning (MARL). We propose the KindMARL method, where agents' intentions are measured by counterfactual reasoning over the environmental impact of the actions that were available to the agents. More specifically, the current environment state is compared with the estimation of the current environment state provided that the agent had chosen another action. The difference between each agent's reward, as the outcome of its action, with that of its fellow, multiplied by the intention of the fellow is then taken as the fellow's \"kindness\". If the result of each reward-comparison confirms the agent's superiority, it perceives the fellow's kindness and reduces its own reward. Experimental results in the Cleanup and Harvest environments show that training based on the KindMARL method enabled the agents to earn 89\\% (resp. 37\\%) and 44% (resp. 43\\%) more total rewards than training based on the Inequity Aversion and Social Influence methods. The effectiveness of KindMARL is further supported by experiments in a traffic light control problem.", "url": "https://arxiv.org/abs/2311.04239"}, {"metadata": {"arXiv": "2311.04240", "Date": "Mon, 06 Nov 2023 20:30:11 ", "Title": "Environmental-Impact Based Multi-Agent Reinforcement Learning", "Authors": ["Farinaz Alamiyan-Harandi", "Pouria Ramazi"], "Categories": "cs.AI cs.LG"}, "abstract": "To promote cooperation and strengthen the individual impact on the collective outcome in social dilemmas, we propose the Environmental-impact Multi-Agent Reinforcement Learning (EMuReL) method where each agent estimates the \"environmental impact\" of every other agent, that is, the difference in the current environment state compared to the hypothetical environment in the absence of that other agent. Inspired by the Inequity Aversion model, the agent then compares its own reward with those of its fellows multiplied by their environmental impacts. If its reward exceeds the scaled reward of one of its fellows, the agent takes \"social responsibility\" toward that fellow by reducing its own reward. Therefore, the less influential an agent is in reaching the current state, the more social responsibility is taken by other agents. Experiments in the Cleanup (resp. Harvest) test environment demonstrate that agents trained based on EMuReL learn to cooperate more effectively and obtain $54\\%$ ($39\\%$) and $20\\%$ ($44\\%$) more total rewards while preserving the same cooperation levels compared to when they are trained based on the two state-of-the-art reward reshaping methods inequity aversion and social influence.", "url": "https://arxiv.org/abs/2311.04240"}, {"metadata": {"arXiv": "2311.04250", "Date": "Tue, 07 Nov 2023 11:17:55 ", "Title": "Unifying Structure and Language Semantic for Efficient Contrastive Knowledge Graph Completion with Structured Entity Anchors", "Authors": ["Sang-Hyun Je", "Wontae Choi", "Kwangjin Oh"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "The goal of knowledge graph completion (KGC) is to predict missing links in a KG using trained facts that are already known. In recent, pre-trained language model (PLM) based methods that utilize both textual and structural information are emerging, but their performances lag behind state-of-the-art (SOTA) structure-based methods or some methods lose their inductive inference capabilities in the process of fusing structure embedding to text encoder. In this paper, we propose a novel method to effectively unify structure information and language semantics without losing the power of inductive reasoning. We adopt entity anchors and these anchors and textual description of KG elements are fed together into the PLM-based encoder to learn unified representations. In addition, the proposed method utilizes additional random negative samples which can be reused in the each mini-batch during contrastive learning to learn a generalized entity representations. We verify the effectiveness of the our proposed method through various experiments and analysis. The experimental results on standard benchmark widely used in link prediction task show that the proposed model outperforms existing the SOTA KGC models. Especially, our method show the largest performance improvement on FB15K-237, which is competitive to the SOTA of structure-based KGC methods.", "url": "https://arxiv.org/abs/2311.04250"}, {"metadata": {"arXiv": "2311.04254", "Date": "Tue, 07 Nov 2023 12:30:36 ", "Title": "Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation", "Authors": ["Ruomeng Ding", "Chaoyun Zhang", "Lu Wang", "Yong Xu", "Minghua Ma", "Wei Zhang", "Si Qin", "Saravan Rajmohan", "Qingwei Lin and Dongmei Zhang"], "Categories": "cs.AI cs.LG", "Comments": ["17 pages", "5 figures"]}, "abstract": "Recent advancements in Large Language Models (LLMs) have revolutionized decision-making by breaking down complex problems into more manageable language sequences referred to as ``thoughts''. An effective thought design should consider three key perspectives: performance, efficiency, and flexibility. However, existing thought can at most exhibit two of these attributes. To address these limitations, we introduce a novel thought prompting approach called ``Everything of Thoughts'' (XoT) to defy the law of ``Penrose triangle of existing thought paradigms. XoT leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge into thoughts, thereby enhancing LLMs' capabilities and enabling them to generalize to unseen problems efficiently. Through the utilization of the MCTS-LLM collaborative thought revision framework, this approach autonomously produces high-quality comprehensive cognitive mappings with minimal LLM interactions. Additionally, XoT empowers LLMs to engage in unconstrained thinking, allowing for flexible cognitive mappings for problems with multiple solutions.", "url": "https://arxiv.org/abs/2311.04254"}, {"metadata": {"arXiv": "2311.04256", "Date": "Tue, 07 Nov 2023 14:03:28 ", "Title": "Foundational propositions of hesitant fuzzy sets and parameter reductions of hesitant fuzzy information systems", "Authors": ["Shizhan Lu"], "Categories": "cs.AI cs.IT cs.LG math.IT", "Comments": ["22 pages"]}, "abstract": "Hesitant fuzzy sets are widely used in the instances of uncertainty and hesitation. The inclusion relationship is an important and foundational definition for sets. Hesitant fuzzy set, as a kind of set, needs explicit definition of inclusion relationship. Base on the hesitant fuzzy membership degree of discrete form, several kinds of inclusion relationships for hesitant fuzzy sets are proposed. And then some foundational propositions of hesitant fuzzy sets and the families of hesitant fuzzy sets are presented. Finally, some foundational propositions of hesitant fuzzy information systems with respect to parameter reductions are put forward, and an example and an algorithm are given to illustrate the processes of parameter reductions.", "url": "https://arxiv.org/abs/2311.04256"}, {"metadata": {"arXiv": "2311.04491", "Date": "Wed, 08 Nov 2023 06:48:13 ", "Title": "Explainable AI for Earth Observation: Current Methods, Open Challenges, and Opportunities", "Authors": ["Gulsen Taskin", "Erchan Aptoula", "Alp Ert\\\"urk"], "Categories": "cs.AI cs.LG"}, "abstract": "Deep learning has taken by storm all fields involved in data analysis, including remote sensing for Earth observation. However, despite significant advances in terms of performance, its lack of explainability and interpretability, inherent to neural networks in general since their inception, remains a major source of criticism. Hence it comes as no surprise that the expansion of deep learning methods in remote sensing is being accompanied by increasingly intensive efforts oriented towards addressing this drawback through the exploration of a wide spectrum of Explainable Artificial Intelligence techniques. This chapter, organized according to prominent Earth observation application fields, presents a panorama of the state-of-the-art in explainable remote sensing image analysis.", "url": "https://arxiv.org/abs/2311.04491"}, {"metadata": {"arXiv": "2311.04262", "Date": "Tue, 07 Nov 2023 16:27:37 ", "Title": "ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses and Dissertations", "Authors": ["Muntabir Hasan Choudhury", "Lamia Salsabil", "William A. Ingram", "Edward A. Fox", "Jian Wu"], "Categories": "cs.CV cs.AI cs.DL cs.LG", "Comments": ["10 pages", "3 figures", "accepted to Innovative Applications of Artificial Intelligence (IAAI-24)"]}, "abstract": "Electronic theses and dissertations (ETDs) have been proposed, advocated, and generated for more than 25 years. Although ETDs are hosted by commercial or institutional digital library repositories, they are still an understudied type of scholarly big data, partially because they are usually longer than conference proceedings and journals. Segmenting ETDs will allow researchers to study sectional content. Readers can navigate to particular pages of interest, discover, and explore the content buried in these long documents. Most existing frameworks on document page classification are designed for classifying general documents and perform poorly on ETDs. In this paper, we propose ETDPC. Its backbone is a two-stream multimodal model with a cross-attention network to classify ETD pages into 13 categories. To overcome the challenge of imbalanced labeled samples, we augmented data for minority categories and employed a hierarchical classifier. ETDPC outperforms the state-of-the-art models in all categories, achieving an F1 of 0.84 -- 0.96 for 9 out of 13 categories. We also demonstrated its data efficiency. The code and data can be found on GitHub (https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation).", "url": "https://arxiv.org/abs/2311.04262"}, {"metadata": {"arXiv": "2311.04400", "Date": "Wed, 08 Nov 2023 00:03:52 ", "Title": "LRM: Large Reconstruction Model for Single Image to 3D", "Authors": ["Yicong Hong and Kai Zhang and Jiuxiang Gu and Sai Bi and Yang Zhou and Difan Liu and Feng Liu and Kalyan Sunkavalli and Trung Bui and Hao Tan"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["23 pages"]}, "abstract": "We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs including real-world in-the-wild captures and images from generative models. Video demos and interactable 3D meshes can be found on this website: https://yiconghong.me/LRM/.", "url": "https://arxiv.org/abs/2311.04400"}, {"metadata": {"arXiv": "2311.04614", "Date": "Wed, 08 Nov 2023 11:30:05 ", "Title": "LuminanceL1Loss: A loss function which measures percieved brightness and colour differences", "Authors": ["Dominic De Jonge"], "Categories": "cs.CV cs.AI cs.LG eess.IV"}, "abstract": "We introduce LuminanceL1Loss, a novel loss function designed to enhance the performance of image restoration tasks. We demonstrate its superiority over MSE when applied to the Retinexformer, BUIFD and DnCNN architectures. Our proposed LuminanceL1Loss leverages a unique approach by transforming images into grayscale and subsequently computing the MSE loss for both grayscale and color channels. Experimental results demonstrate that this innovative loss function consistently outperforms traditional methods, showcasing its potential in image denoising and other related tasks in image reconstruction. It demonstrates gains up to 4.7dB. The results presented in this study highlight the efficacy of LuminanceL1Loss for various image restoration tasks.", "url": "https://arxiv.org/abs/2311.04614"}, {"metadata": {"arXiv": "2311.04888", "Date": "Wed, 08 Nov 2023 18:50:04 ", "Title": "Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks", "Authors": ["Quentin Bouniot"], "Categories": "cs.CV cs.AI cs.LG stat.ML", "Comments": ["PhD Thesis"]}, "abstract": "In this thesis, we develop theoretical, algorithmic and experimental contributions for Machine Learning with limited labels, and more specifically for the tasks of Image Classification and Object Detection in Computer Vision. In a first contribution, we are interested in bridging the gap between theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification. We make connections to Multi-Task Representation Learning, which benefits from solid theoretical foundations, to verify the best conditions for a more efficient meta-learning. Then, to leverage unlabeled data when training object detectors based on the Transformer architecture, we propose both an unsupervised pretraining and a semi-supervised learning method in two other separate contributions. For pretraining, we improve Contrastive Learning for object detectors by introducing the localization information. Finally, our semi-supervised method is the first tailored to transformer-based detectors.", "url": "https://arxiv.org/abs/2311.04888"}, {"metadata": {"arXiv": "2311.04894", "Date": "Wed, 08 Nov 2023 18:55:24 ", "Title": "DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets", "Authors": ["Yash Jain", "Harkirat Behl", "Zsolt Kira", "Vibhav Vineet"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["https://github.com/jinga-lala/DAMEX"]}, "abstract": "Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets? The answer lies in learning dataset-specific features and ensembling their knowledge but do all this in a single model. Previous methods achieve this by having separate detection heads on a common backbone but that results in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an `expert' of a dataset by learning to route each dataset tokens to its mapped expert. Experiments on Universal Object-Detection Benchmark show that we outperform the existing state-of-the-art by average +10.2 AP score and improve over our non-MoE baseline by average +2.0 AP score. We also observe consistent gains while mixing datasets with (1) limited availability, (2) disparate domains and (3) divergent label sets. Further, we qualitatively show that DAMEX is robust against expert representation collapse.", "url": "https://arxiv.org/abs/2311.04894"}, {"metadata": {"arXiv": "2311.04226", "Date": "Wed, 01 Nov 2023 18:43:20 ", "Title": "Assessing Upper Limb Motor Function in the Immediate Post-Stroke Perioud Using Accelerometry", "Authors": ["Mackenzie Wallich", "Kenneth Lai", "and Svetlana Yanushkevich"], "Categories": "cs.LG cs.AI eess.SP", "Journal-ref": "2023 IEEE Conference on Artificial Intelligence (CAI), Santa Clara, 2023, pp. 132-33", "DOI": "10.1109/CAI54212.2023.00064"}, "abstract": "Accelerometry has been extensively studied as an objective means of measuring upper limb function in patients post-stroke. The objective of this paper is to determine whether the accelerometry-derived measurements frequently used in more long-term rehabilitation studies can also be used to monitor and rapidly detect sudden changes in upper limb motor function in more recently hospitalized stroke patients. Six binary classification models were created by training on variable data window times of paretic upper limb accelerometer feature data. The models were assessed on their effectiveness for differentiating new input data into two classes: severe or moderately severe motor function. The classification models yielded Area Under the Curve (AUC) scores that ranged from 0.72 to 0.82 for 15-minute data windows to 0.77 to 0.94 for 120-minute data windows. These results served as a preliminary assessment and a basis on which to further investigate the efficacy of using accelerometry and machine learning to alert healthcare professionals to rapid changes in motor function in the days immediately following a stroke.", "url": "https://arxiv.org/abs/2311.04226"}, {"metadata": {"arXiv": "2311.04244", "Date": "Tue, 07 Nov 2023 00:54:04 ", "Title": "HKTGNN: Hierarchical Knowledge Transferable Graph Neural Network-based Supply Chain Risk Assessment", "Authors": ["Zhanting Zhou", "Kejun Bi", "Yuyanzhen Zhong", "Chao Tang", "Dongfen Li", "Shi Ying", "Ruijin Wang"], "Categories": "cs.LG cs.AI", "Comments": ["11pages", "3 figures", "accepted and submitted by IEEE ISPA 2023(The 21st IEEE International Symposium on Parallel and Distributed Processing with Applications)"], "ACM-class": "I.2.4"}, "abstract": "The strength of a supply chain is an important measure of a country's or region's technical advancement and overall competitiveness. Establishing supply chain risk assessment models for effective management and mitigation of potential risks has become increasingly crucial. As the number of businesses grows, the important relationships become more complicated and difficult to measure. This emphasizes the need of extracting relevant information from graph data. Previously, academics mostly employed knowledge inference to increase the visibility of links between nodes in the supply chain. However, they have not solved the data hunger problem of single node feature characteristics. We propose a hierarchical knowledge transferable graph neural network-based (HKTGNN) supply chain risk assessment model to address these issues. Our approach is based on current graph embedding methods for assessing corporate investment risk assessment. We embed the supply chain network corresponding to individual goods in the supply chain using the graph embedding module, resulting in a directed homogeneous graph with just product nodes. This reduces the complicated supply chain network into a basic product network. It addresses difficulties using the domain difference knowledge transferable module based on centrality, which is presented by the premise that supply chain feature characteristics may be biased in the actual world. Meanwhile, the feature complement and message passing will alleviate the data hunger problem, which is driven by domain differences. Our model outperforms in experiments on a real-world supply chain dataset. We will give an equation to prove that our comparative experiment is both effective and fair.", "url": "https://arxiv.org/abs/2311.04244"}, {"metadata": {"arXiv": "2311.04245", "Date": "Tue, 07 Nov 2023 02:36:24 ", "Title": "GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks", "Authors": ["Zhonghang Li", "Lianghao Xia", "Yong Xu", "Chao Huang"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["This paper has been accepted by NeurIPS 2023"], "Journal-ref": "Thirty-seventh Conference on Neural Information Processing Systems(NeurIPS 2023)"}, "abstract": "In recent years, there has been a rapid development of spatio-temporal prediction techniques in response to the increasing demands of traffic management and travel planning. While advanced end-to-end models have achieved notable success in improving predictive performance, their integration and expansion pose significant challenges. This work aims to address these challenges by introducing a spatio-temporal pre-training framework that seamlessly integrates with downstream baselines and enhances their performance. The framework is built upon two key designs: (i) We propose a spatio-temporal mask autoencoder as a pre-training model for learning spatio-temporal dependencies. The model incorporates customized parameter learners and hierarchical spatial pattern encoding networks. These modules are specifically designed to capture spatio-temporal customized representations and intra- and inter-cluster region semantic relationships, which have often been neglected in existing approaches. (ii) We introduce an adaptive mask strategy as part of the pre-training mechanism. This strategy guides the mask autoencoder in learning robust spatio-temporal representations and facilitates the modeling of different relationships, ranging from intra-cluster to inter-cluster, in an easy-to-hard training manner. Extensive experiments conducted on representative benchmarks demonstrate the effectiveness of our proposed method. We have made our model implementation publicly available at https://github.com/HKUDS/GPT-ST.", "url": "https://arxiv.org/abs/2311.04245"}, {"metadata": {"arXiv": "2311.04247", "Date": "Tue, 07 Nov 2023 06:17:57 ", "Title": "Analysis and Applications of Deep Learning with Finite Samples in Full Life-Cycle Intelligence of Nuclear Power Generation", "Authors": ["Chenwei Tang and Wenqiang Zhou and Dong Wang and Caiyang Yu and Zhenan He and Jizhe Zhou and Shudong Huang and Yi Gao and Jianming Chen and Wentao Feng and Jiancheng Lv"], "Categories": "cs.LG cs.AI"}, "abstract": "The advent of Industry 4.0 has precipitated the incorporation of Artificial Intelligence (AI) methods within industrial contexts, aiming to realize intelligent manufacturing, operation as well as maintenance, also known as industrial intelligence. However, intricate industrial milieus, particularly those relating to energy exploration and production, frequently encompass data characterized by long-tailed class distribution, sample imbalance, and domain shift. These attributes pose noteworthy challenges to data-centric Deep Learning (DL) techniques, crucial for the realization of industrial intelligence. The present study centers on the intricate and distinctive industrial scenarios of Nuclear Power Generation (NPG), meticulously scrutinizing the application of DL techniques under the constraints of finite data samples. Initially, the paper expounds on potential employment scenarios for AI across the full life-cycle of NPG. Subsequently, we delve into an evaluative exposition of DL's advancement, grounded in the finite sample perspective. This encompasses aspects such as small-sample learning, few-shot learning, zero-shot learning, and open-set recognition, also referring to the unique data characteristics of NPG. The paper then proceeds to present two specific case studies. The first revolves around the automatic recognition of zirconium alloy metallography, while the second pertains to open-set recognition for signal diagnosis of machinery sensors. These cases, spanning the entirety of NPG's life-cycle, are accompanied by constructive outcomes and insightful deliberations. By exploring and applying DL methodologies within the constraints of finite sample availability, this paper not only furnishes a robust technical foundation but also introduces a fresh perspective toward the secure and efficient advancement and exploitation of this advanced energy source.", "url": "https://arxiv.org/abs/2311.04247"}, {"metadata": {"arXiv": "2311.04251", "Date": "Tue, 07 Nov 2023 11:37:08 ", "Title": "MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters", "Authors": ["Chau Pham", "Piotr Teterwak", "Soren Nelson", "Bryan A. Plummer"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV) 2024"]}, "abstract": "Most deep neural networks are trained under fixed network architectures and require retraining when the architecture changes. If expanding the network's size is needed, it is necessary to retrain from scratch, which is expensive. To avoid this, one can grow from a small network by adding random weights over time to gradually achieve the target network size. However, this naive approach falls short in practice as it brings too much noise to the growing process. Prior work tackled this issue by leveraging the already learned weights and training data for generating new weights through conducting a computationally expensive analysis step. In this paper, we introduce MixtureGrowth, a new approach to growing networks that circumvents the initialization overhead in prior work. Before growing, each layer in our model is generated with a linear combination of parameter templates. Newly grown layer weights are generated by using a new linear combination of existing templates for a layer. On one hand, these templates are already trained for the task, providing a strong initialization. On the other, the new coefficients provide flexibility for the added layer weights to learn something new. We show that our approach boosts top-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet datasets, while achieving comparable performance with fewer FLOPs to a larger network trained from scratch. Code is available at https://github.com/chaudatascience/mixturegrowth.", "url": "https://arxiv.org/abs/2311.04251"}, {"metadata": {"arXiv": "2311.04301", "Date": "Tue, 07 Nov 2023 19:17:59 ", "Title": "Class-Incremental Continual Learning for General Purpose Healthcare Models", "Authors": ["Amritpal Singh", "Mustafa Burak Gurbuz", "Shiva Souhith Gantha", "Prahlad Jasti"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["4 pages", "1 Figure. Accepted in NeurIPS 2023 (Medical Imaging meets NeurIPS Workshop)"]}, "abstract": "Healthcare clinics regularly encounter dynamic data that changes due to variations in patient populations, treatment policies, medical devices, and emerging disease patterns. Deep learning models can suffer from catastrophic forgetting when fine-tuned in such scenarios, causing poor performance on previously learned tasks. Continual learning allows learning on new tasks without performance drop on previous tasks. In this work, we investigate the performance of continual learning models on four different medical imaging scenarios involving ten classification datasets from diverse modalities, clinical specialties, and hospitals. We implement various continual learning approaches and evaluate their performance in these scenarios. Our results demonstrate that a single model can sequentially learn new tasks from different specialties and achieve comparable performance to naive methods. These findings indicate the feasibility of recycling or sharing models across the same or different medical specialties, offering another step towards the development of general-purpose medical imaging AI that can be shared across institutions.", "url": "https://arxiv.org/abs/2311.04301"}, {"metadata": {"arXiv": "2311.04325", "Date": "Tue, 07 Nov 2023 20:02:52 ", "Title": "Extending Machine Learning-Based Early Sepsis Detection to Different Demographics", "Authors": ["Surajsinh Parmar and Tao Shan and San Lee and Yonghwan Kim and Jang Yong Kim"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Sepsis requires urgent diagnosis, but research is predominantly focused on Western datasets. In this study, we perform a comparative analysis of two ensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD dataset and a private South Korean St. Mary's Hospital's dataset. Our analysis reveals the effectiveness of these methods in addressing healthcare data imbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight edge in computational efficiency and scalability. The study paves the way for the broader application of machine learning in critical care, thereby expanding the reach of predictive analytics in healthcare globally.", "url": "https://arxiv.org/abs/2311.04325"}, {"metadata": {"arXiv": "2311.04441", "Date": "Wed, 08 Nov 2023 03:49:23 ", "Title": "MixTEA: Semi-supervised Entity Alignment with Mixture Teaching", "Authors": ["Feng Xie", "Xin Song", "Xiang Zeng", "Xuechen Zhao", "Lei Tian", "Bin Zhou", "Yusong Tan"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["Findings of EMNLP 2023; 11 pages", "4 figures; code see https://github.com/Xiefeng69/MixTEA"]}, "abstract": "Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2311.04441"}, {"metadata": {"arXiv": "2311.04457", "Date": "Wed, 08 Nov 2023 04:52:20 ", "Title": "Evaluating Uncertainty Quantification approaches for Neural PDEs in scientific applications", "Authors": ["Vardhan Dongre", "Gurpreet Singh Hora"], "Categories": "cs.LG cs.AI physics.comp-ph physics.flu-dyn", "Comments": ["8 pages", "4 figures", "1 table", "AI for Science Workshop Attention Track", "neurips 2023"]}, "abstract": "The accessibility of spatially distributed data, enabled by affordable sensors, field, and numerical experiments, has facilitated the development of data-driven solutions for scientific problems, including climate change, weather prediction, and urban planning. Neural Partial Differential Equations (Neural PDEs), which combine deep learning (DL) techniques with domain expertise (e.g., governing equations) for parameterization, have proven to be effective in capturing valuable correlations within spatiotemporal datasets. However, sparse and noisy measurements coupled with modeling approximation introduce aleatoric and epistemic uncertainties. Therefore, quantifying uncertainties propagated from model inputs to outputs remains a challenge and an essential goal for establishing the trustworthiness of Neural PDEs. This work evaluates various Uncertainty Quantification (UQ) approaches for both Forward and Inverse Problems in scientific applications. Specifically, we investigate the effectiveness of Bayesian methods, such as Hamiltonian Monte Carlo (HMC) and Monte-Carlo Dropout (MCD), and a more conventional approach, Deep Ensembles (DE). To illustrate their performance, we take two canonical PDEs: Burger's equation and the Navier-Stokes equation. Our results indicate that Neural PDEs can effectively reconstruct flow systems and predict the associated unknown parameters. However, it is noteworthy that the results derived from Bayesian methods, based on our observations, tend to display a higher degree of certainty in their predictions as compared to those obtained using the DE. This elevated certainty in predictions suggests that Bayesian techniques might underestimate the true underlying uncertainty, thereby appearing more confident in their predictions than the DE approach.", "url": "https://arxiv.org/abs/2311.04457"}, {"metadata": {"arXiv": "2311.04588", "Date": "Wed, 08 Nov 2023 10:31:29 ", "Title": "Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection", "Authors": ["Akshit Jindal", "Vikram Goyal", "Saket Anand", "Chetan Arora"], "Categories": "cs.LG cs.AI cs.CR cs.CV", "Comments": ["10 pages", "5 figures", "paper accepted to WACV 2024"]}, "abstract": "Machine Learning (ML) models become vulnerable to Model Stealing Attacks (MSA) when they are deployed as a service. In such attacks, the deployed model is queried repeatedly to build a labelled dataset. This dataset allows the attacker to train a thief model that mimics the original model. To maximize query efficiency, the attacker has to select the most informative subset of data points from the pool of available data. Existing attack strategies utilize approaches like Active Learning and Semi-Supervised learning to minimize costs. However, in the black-box setting, these approaches may select sub-optimal samples as they train only one thief model. Depending on the thief model's capacity and the data it was pretrained on, the model might even select noisy samples that harm the learning process. In this work, we explore the usage of an ensemble of deep learning models as our thief model. We call our attack Army of Thieves(AOT) as we train multiple models with varying complexities to leverage the crowd's wisdom. Based on the ensemble's collective decision, uncertain samples are selected for querying, while the most confident samples are directly included in the training data. Our approach is the first one to utilize an ensemble of thief models to perform model extraction. We outperform the base approaches of existing state-of-the-art methods by at least 3% and achieve a 21% higher adversarial sample transferability than previous work for models trained on the CIFAR-10 dataset.", "url": "https://arxiv.org/abs/2311.04588"}, {"metadata": {"arXiv": "2311.04640", "Date": "Wed, 08 Nov 2023 12:34:36 ", "Title": "Object-Centric Learning with Slot Mixture Module", "Authors": ["Daniil Kirilenko", "Vitaliy Vorobyov", "Alexey K. Kovalev", "Aleksandr I. Panov"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["17 pages", "6 figures"]}, "abstract": "Object-centric architectures usually apply a differentiable module to the entire feature map to decompose it into sets of entity representations called slots. Some of these methods structurally resemble clustering algorithms, where the cluster's center in latent space serves as a slot representation. Slot Attention is an example of such a method, acting as a learnable analog of the soft k-means algorithm. Our work employs a learnable clustering method based on the Gaussian Mixture Model. Unlike other approaches, we represent slots not only as centers of clusters but also incorporate information about the distance between clusters and assigned vectors, leading to more expressive slot representations. Our experiments demonstrate that using this approach instead of Slot Attention improves performance in object-centric scenarios, achieving state-of-the-art results in the set property prediction task.", "url": "https://arxiv.org/abs/2311.04640"}, {"metadata": {"arXiv": "2311.04653", "Date": "Wed, 08 Nov 2023 12:53:07 ", "Title": "Hybrid Focal and Full-Range Attention Based Graph Transformers", "Authors": ["Minhong Zhu", "Zhenhao Zhao", "Weiran Cai"], "Categories": "cs.LG cs.AI"}, "abstract": "The paradigm of Transformers using the self-attention mechanism has manifested its advantage in learning graph-structured data. Yet, Graph Transformers are capable of modeling full range dependencies but are often deficient in extracting information from locality. A common practice is to utilize Message Passing Neural Networks (MPNNs) as an auxiliary to capture local information, which however are still inadequate for comprehending substructures. In this paper, we present a purely attention-based architecture, namely Focal and Full-Range Graph Transformer (FFGT), which can mitigate the loss of local information in learning global correlations. The core component of FFGT is a new mechanism of compound attention, which combines the conventional full-range attention with K-hop focal attention on ego-nets to aggregate both global and local information. Beyond the scope of canonical Transformers, the FFGT has the merit of being more substructure-aware. Our approach enhances the performance of existing Graph Transformers on various open datasets, while achieves compatible SOTA performance on several Long-Range Graph Benchmark (LRGB) datasets even with a vanilla transformer. We further examine influential factors on the optimal focal length of attention via introducing a novel synthetic dataset based on SBM-PATTERN.", "url": "https://arxiv.org/abs/2311.04653"}, {"metadata": {"arXiv": "2311.04698", "Date": "Wed, 08 Nov 2023 14:10:19 ", "Title": "Challenging Common Assumptions in Multi-task Learning", "Authors": ["Cathrin Elich", "Lukas Kirchdorfer", "Jan M. K\\\"ohler", "Lukas Schott"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["-"]}, "abstract": "While multi-task learning (MTL) has gained significant attention in recent years, its underlying mechanisms remain poorly understood. Recent methods did not yield consistent performance improvements over single task learning (STL) baselines, underscoring the importance of gaining more profound insights about challenges specific to MTL. In our study, we challenge common assumptions in MTL in the context of STL: First, the choice of optimizer has only been mildly investigated in MTL. We show the pivotal role of common STL tools such as the Adam optimizer in MTL. We deduce the effectiveness of Adam to its partial loss-scale invariance. Second, the notion of gradient conflicts has often been phrased as a specific problem in MTL. We delve into the role of gradient conflicts in MTL and compare it to STL. For angular gradient alignment we find no evidence that this is a unique problem in MTL. We emphasize differences in gradient magnitude as the main distinguishing factor. Lastly, we compare the transferability of features learned through MTL and STL on common image corruptions, and find no conclusive evidence that MTL leads to superior transferability. Overall, we find surprising similarities between STL and MTL suggesting to consider methods from both fields in a broader context.", "url": "https://arxiv.org/abs/2311.04698"}, {"metadata": {"arXiv": "2311.04744", "Date": "Wed, 08 Nov 2023 15:12:31 ", "Title": "Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers", "Authors": ["Pim de Haan", "Taco Cohen and Johann Brehmer"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted as an extended abstract to the workshop Symmetry and Geometry in Neural Representations (NeurReps) 2023"]}, "abstract": "The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.", "url": "https://arxiv.org/abs/2311.04744"}, {"metadata": {"arXiv": "2311.04770", "Date": "Wed, 08 Nov 2023 15:47:58 ", "Title": "Vital Sign Forecasting for Sepsis Patients in ICUs", "Authors": ["Anubhav Bhatti", "Yuwei Liu", "Chen Dan", "Bingjie Shen", "San Lee", "Yonghwan Kim", "Jang Yong Kim"], "Categories": "cs.LG cs.AI", "Comments": ["4 pages", "3 Figures"]}, "abstract": "Sepsis and septic shock are a critical medical condition affecting millions globally, with a substantial mortality rate. This paper uses state-of-the-art deep learning (DL) architectures to introduce a multi-step forecasting system to predict vital signs indicative of septic shock progression in Intensive Care Units (ICUs). Our approach utilizes a short window of historical vital sign data to forecast future physiological conditions. We introduce a DL-based vital sign forecasting system that predicts up to 3 hours of future vital signs from 6 hours of past data. We further adopt the DILATE loss function to capture better the shape and temporal dynamics of vital signs, which are critical for clinical decision-making. We compare three DL models, N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), using the publicly available eICU Collaborative Research Database (eICU-CRD), highlighting their forecasting capabilities in a critical care setting. We evaluate the performance of our models using mean squared error (MSE) and dynamic time warping (DTW) metrics. Our findings show that while TFT excels in capturing overall trends, N-HiTS is superior in retaining short-term fluctuations within a predefined range. This paper demonstrates the potential of deep learning in transforming the monitoring systems in ICUs, potentially leading to significant improvements in patient care and outcomes by accurately forecasting vital signs to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock.", "url": "https://arxiv.org/abs/2311.04770"}, {"metadata": {"arXiv": "2311.04817", "Date": "Wed, 08 Nov 2023 16:42:10 ", "Title": "Decentralized Personalized Online Federated Learning", "Authors": ["Renzhi Wu and Saayan Mitra and Xiang Chen and Anup Rao"], "Categories": "cs.LG cs.AI", "Journal-ref": "IEEE BigData 2023"}, "abstract": "Vanilla federated learning does not support learning in an online environment, learning a personalized model on each client, and learning in a decentralized setting. There are existing methods extending federated learning in each of the three aspects. However, some important applications on enterprise edge servers (e.g. online item recommendation at global scale) involve the three aspects at the same time. Therefore, we propose a new learning setting \\textit{Decentralized Personalized Online Federated Learning} that considers all the three aspects at the same time. In this new setting for learning, the first technical challenge is how to aggregate the shared model parameters from neighboring clients to obtain a personalized local model with good performance on each client. We propose to directly learn an aggregation by optimizing the performance of the local model with respect to the aggregation weights. This not only improves personalization of each local model but also helps the local model adapting to potential data shift by intelligently incorporating the right amount of information from its neighbors. The second challenge is how to select the neighbors for each client. We propose a peer selection method based on the learned aggregation weights enabling each client to select the most helpful neighbors and reduce communication cost at the same time. We verify the effectiveness and robustness of our proposed method on three real-world item recommendation datasets and one air quality prediction dataset.", "url": "https://arxiv.org/abs/2311.04817"}, {"metadata": {"arXiv": "2311.04837", "Date": "Wed, 08 Nov 2023 17:01:35 ", "Title": "Identifying Semantic Component for Robust Molecular Property Prediction", "Authors": ["Zijian Li", "Zunhong Xu", "Ruichu Cai", "Zhenhui Yang", "Yuguang Yan", "Zhifeng Hao", "Guangyi Chen", "Kun Zhang"], "Categories": "cs.LG cs.AI q-bio.QM"}, "abstract": "Although graph neural networks have achieved great success in the task of molecular property prediction in recent years, their generalization ability under out-of-distribution (OOD) settings is still under-explored. Different from existing methods that learn discriminative representations for prediction, we propose a generative model with semantic-components identifiability, named SCI. We demonstrate that the latent variables in this generative model can be explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI) components, which contributes to better OOD generalization by involving minimal change properties of causal mechanisms. Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables. Sequentially, to reduce misidentification, we restrict the minimal changes of the SR atom variables and add a semantic latent substructure regularization to mitigate the variance of the SR substructure under augmented domain changes. Under mild assumptions, we prove the block-wise identifiability of the SR substructure and the comment-wise identifiability of SR atom variables. Experimental studies achieve state-of-the-art performance and show general improvement on 21 datasets in 3 mainstream benchmarks. Moreover, the visualization results of the proposed SCI method provide insightful case studies and explanations for the prediction results. The code is available at: https://github.com/DMIRLAB-Group/SCI.", "url": "https://arxiv.org/abs/2311.04837"}, {"metadata": {"arXiv": "2311.04898", "Date": "Wed, 08 Nov 2023 18:57:19 ", "Title": "Two Complementary Perspectives to Continual Learning: Ask Not Only What to Optimize, But Also How", "Authors": ["Timm Hess", "Tinne Tuytelaars", "Gido M. van de Ven"], "Categories": "cs.LG cs.AI cs.CV stat.ML", "Comments": ["Pre-registered report", "accepted at the 1st ContinualAI Unconference. Full paper with the results of the proposed experiment is expected to follow by June 2024"]}, "abstract": "Recent years have seen considerable progress in the continual training of deep neural networks, predominantly thanks to approaches that add replay or regularization terms to the loss function to approximate the joint loss over all tasks so far. However, we show that even with a perfect approximation to the joint loss, these approaches still suffer from temporary but substantial forgetting when starting to train on a new task. Motivated by this 'stability gap', we propose that continual learning strategies should focus not only on the optimization objective, but also on the way this objective is optimized. While there is some continual learning work that alters the optimization trajectory (e.g., using gradient projection techniques), this line of research is positioned as alternative to improving the optimization objective, while we argue it should be complementary. To evaluate the merits of our proposition, we plan to combine replay-approximated joint objectives with gradient projection-based optimization routines to test whether the addition of the latter provides benefits in terms of (1) alleviating the stability gap, (2) increasing the learning efficiency and (3) improving the final learning outcome.", "url": "https://arxiv.org/abs/2311.04898"}, {"metadata": {"arXiv": "2311.04765", "Date": "Wed, 08 Nov 2023 15:39:27 ", "Title": "The voraus-AD Dataset for Anomaly Detection in Robot Applications", "Authors": ["Jan Thie{\\ss} Brockmann", "Marco Rudolph", "Bodo Rosenhahn", "Bastian Wandt"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["14 pages", "14 figures", "accepted to Transactions on Robotics"]}, "abstract": "During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC.", "url": "https://arxiv.org/abs/2311.04765"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

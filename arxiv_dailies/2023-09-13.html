<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.05809", "Date": "Mon, 11 Sep 2023 20:26:40 ", "Title": "Divergences in Color Perception between Deep Neural Networks and Humans", "Authors": ["Ethan O. Nadler", "Elise Darragh-Ford", "Bhargav Srinivasa Desikan", "Christian Conaway", "Mark Chu", "Tasker Hull", "Douglas Guilbeault"], "Categories": "cs.CV cs.LG", "Comments": ["22 pages", "8 figures + SI Appendix; to appear in Cognition"]}, "abstract": "Deep neural networks (DNNs) are increasingly proposed as models of human vision, bolstered by their impressive performance on image classification and object recognition tasks. Yet, the extent to which DNNs capture fundamental aspects of human vision such as color perception remains unclear. Here, we develop novel experiments for evaluating the perceptual coherence of color embeddings in DNNs, and we assess how well these algorithms predict human color similarity judgments collected via an online survey. We find that state-of-the-art DNN architectures $-$ including convolutional neural networks and vision transformers $-$ provide color similarity judgments that strikingly diverge from human color judgments of (i) images with controlled color properties, (ii) images generated from online searches, and (iii) real-world images from the canonical CIFAR-10 dataset. We compare DNN performance against an interpretable and cognitively plausible model of color perception based on wavelet decomposition, inspired by foundational theories in computational neuroscience. While one deep learning model $-$ a convolutional DNN trained on a style transfer task $-$ captures some aspects of human color perception, our wavelet algorithm provides more coherent color embeddings that better predict human color judgments compared to all DNNs we examine. These results hold when altering the high-level visual task used to train similar DNN architectures (e.g., image classification versus image segmentation), as well as when examining the color embeddings of different layers in a given DNN architecture. These findings break new ground in the effort to analyze the perceptual representations of machine learning algorithms and to improve their ability to serve as cognitively plausible models of human vision. Implications for machine learning, human perception, and embodied cognition are discussed.", "url": "https://arxiv.org/abs/2309.05809"}, {"metadata": {"arXiv": "2309.05810", "Date": "Mon, 11 Sep 2023 20:28:18 ", "Title": "SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors", "Authors": ["Hongge Chen", "Zhao Chen", "Gregory P. Meyer", "Dennis Park", "Carl Vondrick", "Ashish Shrivastava", "Yuning Chai"], "Categories": "cs.CV cs.CR cs.LG cs.RO", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "We present SHIFT3D, a differentiable pipeline for generating 3D shapes that are structurally plausible yet challenging to 3D object detectors. In safety-critical applications like autonomous driving, discovering such novel challenging objects can offer insight into unknown vulnerabilities of 3D detectors. By representing objects with a signed distanced function (SDF), we show that gradient error signals allow us to smoothly deform the shape or pose of a 3D object in order to confuse a downstream 3D detector. Importantly, the objects generated by SHIFT3D physically differ from the baseline object yet retain a semantically recognizable shape. Our approach provides interpretable failure modes for modern 3D object detectors, and can aid in preemptive discovery of potential safety risks within 3D perception systems before these risks become critical failures.", "url": "https://arxiv.org/abs/2309.05810"}, {"metadata": {"arXiv": "2309.05832", "Date": "Mon, 11 Sep 2023 21:18:15 ", "Title": "Instance-Agnostic Geometry and Contact Dynamics Learning", "Authors": ["Mengti Sun", "Bowen Jiang", "Bibit Bianchini", "Camillo Jose Taylor", "Michael Posa"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "This work presents an instance-agnostic learning framework that fuses vision with dynamics to simultaneously learn shape, pose trajectories and physical properties via the use of geometry as a shared representation. Unlike many contact learning approaches that assume motion capture input and a known shape prior for the collision model, our proposed framework learns an object's geometric and dynamic properties from RGBD video, without requiring either category-level or instance-level shape priors. We integrate a vision system, BundleSDF, with a dynamics system, ContactNets and propose a cyclic training pipeline to use the output from the dynamics module to refine the poses and the geometry from the vision module, using perspective reprojection. Experiments demonstrate our framework's ability to learn the geometry and dynamics of rigid and convex objects and improve upon the current tracking framework.", "url": "https://arxiv.org/abs/2309.05832"}, {"metadata": {"arXiv": "2309.05883", "Date": "Tue, 12 Sep 2023 00:07:08 ", "Title": "Hierarchical Conditional Semi-Paired Image-to-Image Translation For Multi-Task Image Defect Correction On Shopping Websites", "Authors": ["Moyan Li", "Jinmiao Fu", "Shaoyuan Xu", "Huidong Liu", "Jia Liu", "Bryan Wang"], "Categories": "cs.CV cs.LG", "Comments": ["6 pages", "6 figures", "3 tables. To be published in ICIP 2023"]}, "abstract": "On shopping websites, product images of low quality negatively affect customer experience. Although there are plenty of work in detecting images with different defects, few efforts have been dedicated to correct those defects at scale. A major challenge is that there are thousands of product types and each has specific defects, therefore building defect specific models is unscalable. In this paper, we propose a unified Image-to-Image (I2I) translation model to correct multiple defects across different product types. Our model leverages an attention mechanism to hierarchically incorporate high-level defect groups and specific defect types to guide the network to focus on defect-related image regions. Evaluated on eight public datasets, our model reduces the Frechet Inception Distance (FID) by 24.6% in average compared with MoNCE, the state-of-the-art I2I method. Unlike public data, another practical challenge on shopping websites is that some paired images are of low quality. Therefore we design our model to be semi-paired by combining the L1 loss of paired data with the cycle loss of unpaired data. Tested on a shopping website dataset to correct three image defects, our model reduces (FID) by 63.2% in average compared with WS-I2I, the state-of-the art semi-paired I2I method.", "url": "https://arxiv.org/abs/2309.05883"}, {"metadata": {"arXiv": "2309.05900", "Date": "Tue, 12 Sep 2023 01:03:43 ", "Title": "Adversarial Attacks Assessment of Salient Object Detection via Symbolic Learning", "Authors": ["Gustavo Olague", "Roberto Pineda", "Gerardo Ibarra-Vazquez", "Matthieu Olague", "Axel Martinez", "Sambit Bakshi", "Jonathan Vargas and Isnardo Reducindo"], "Categories": "cs.CV cs.CR cs.LG cs.NE", "Comments": ["14 pages", "8 figures", "6 tables", "IEEE Transactions on Emerging Topics in Computing", "Accepted for publication"], "MSC-class": "68T45, 68T05, 68T07", "ACM-class": "I.4.6; I.1.2"}, "abstract": "Machine learning is at the center of mainstream technology and outperforms classical approaches to handcrafted feature design. Aside from its learning process for artificial feature extraction, it has an end-to-end paradigm from input to output, reaching outstandingly accurate results. However, security concerns about its robustness to malicious and imperceptible perturbations have drawn attention since its prediction can be changed entirely. Salient object detection is a research area where deep convolutional neural networks have proven effective but whose trustworthiness represents a significant issue requiring analysis and solutions to hackers' attacks. Brain programming is a kind of symbolic learning in the vein of good old-fashioned artificial intelligence. This work provides evidence that symbolic learning robustness is crucial in designing reliable visual attention systems since it can withstand even the most intense perturbations. We test this evolutionary computation methodology against several adversarial attacks and noise perturbations using standard databases and a real-world problem of a shorebird called the Snowy Plover portraying a visual attention task. We compare our methodology with five different deep learning approaches, proving that they do not match the symbolic paradigm regarding robustness. All neural networks suffer significant performance losses, while brain programming stands its ground and remains unaffected. Also, by studying the Snowy Plover, we remark on the importance of security in surveillance activities regarding wildlife protection and conservation.", "url": "https://arxiv.org/abs/2309.05900"}, {"metadata": {"arXiv": "2309.05994", "Date": "Tue, 12 Sep 2023 06:49:56 ", "Title": "ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation", "Authors": ["Zhitong Gao", "Shipeng Yan", "Xuming He"], "Categories": "cs.CV cs.LG", "Comments": ["In submission"]}, "abstract": "Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models.", "url": "https://arxiv.org/abs/2309.05994"}, {"metadata": {"arXiv": "2309.06142", "Date": "Tue, 12 Sep 2023 11:29:12 ", "Title": "Towards Reliable Domain Generalization: A New Dataset and Evaluations", "Authors": ["Jiao Zhang", "Xu-Yao Zhang", "Cheng-Lin Liu"], "Categories": "cs.CV cs.LG"}, "abstract": "There are ubiquitous distribution shifts in the real world. However, deep neural networks (DNNs) are easily biased towards the training set, which causes severe performance degradation when they receive out-of-distribution data. Many methods are studied to train models that generalize under various distribution shifts in the literature of domain generalization (DG). However, the recent DomainBed and WILDS benchmarks challenged the effectiveness of these methods. Aiming at the problems in the existing research, we propose a new domain generalization task for handwritten Chinese character recognition (HCCR) to enrich the application scenarios of DG method research. We evaluate eighteen DG methods on the proposed PaHCC (Printed and Handwritten Chinese Characters) dataset and show that the performance of existing methods on this dataset is still unsatisfactory. Besides, under a designed dynamic DG setting, we reveal more properties of DG methods and argue that only the leave-one-domain-out protocol is unreliable. We advocate that researchers in the DG community refer to dynamic performance of methods for more comprehensive and reliable evaluation. Our dataset and evaluations bring new perspectives to the community for more substantial progress. We will make our dataset public with the article published to facilitate the study of domain generalization.", "url": "https://arxiv.org/abs/2309.06142"}, {"metadata": {"arXiv": "2309.06313", "Date": "Tue, 12 Sep 2023 15:24:26 ", "Title": "Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle", "Authors": ["Maria Priisalu"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle. Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often. This has led to the popularisation of traffic data-specific benchmarks. Recently Light Detection And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions. However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods. We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians.", "url": "https://arxiv.org/abs/2309.06313"}, {"metadata": {"arXiv": "2309.05678", "Date": "Sat, 09 Sep 2023 11:17:06 ", "Title": "Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces", "Authors": ["Haitz Saez de Ocariz Borde", "Alvaro Arroyo", "Ismael Morales", "Ingmar Posner", "Xiaowen Dong"], "Categories": "cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2309.04810"]}, "abstract": "Recent studies propose enhancing machine learning models by aligning the geometric characteristics of the latent space with the underlying data structure. Instead of relying solely on Euclidean space, researchers have suggested using hyperbolic and spherical spaces with constant curvature, or their combinations (known as product manifolds), to improve model performance. However, there exists no principled technique to determine the best latent product manifold signature, which refers to the choice and dimensionality of manifold components. To address this, we introduce a novel notion of distance between candidate latent geometries using the Gromov-Hausdorff distance from metric geometry. We propose using a graph search space that uses the estimated Gromov-Hausdorff distances to search for the optimal latent geometry. In this work we focus on providing a description of an algorithm to compute the Gromov-Hausdorff distance between model spaces and its computational implementation.", "url": "https://arxiv.org/abs/2309.05678"}, {"metadata": {"arXiv": "2309.05686", "Date": "Mon, 11 Sep 2023 12:38:01 ", "Title": "Temporal Patience: Efficient Adaptive Deep Learning for Embedded Radar Data Processing", "Authors": ["Max Sponner and Julius Ott and Lorenzo Servadei and Bernd Waschneck and Robert Wille and Akash Kumar"], "Categories": "cs.LG cs.NI eess.SP", "Comments": ["CODAI 2023 Workshop Submission"]}, "abstract": "Radar sensors offer power-efficient solutions for always-on smart devices, but processing the data streams on resource-constrained embedded platforms remains challenging. This paper presents novel techniques that leverage the temporal correlation present in streaming radar data to enhance the efficiency of Early Exit Neural Networks for Deep Learning inference on embedded devices. These networks add additional classifier branches between the architecture's hidden layers that allow for an early termination of the inference if their result is deemed sufficient enough by an at-runtime decision mechanism. Our methods enable more informed decisions on when to terminate the inference, reducing computational costs while maintaining a minimal loss of accuracy. Our results demonstrate that our techniques save up to 26% of operations per inference over a Single Exit Network and 12% over a confidence-based Early Exit version. Our proposed techniques work on commodity hardware and can be combined with traditional optimizations, making them accessible for resource-constrained embedded platforms commonly used in smart devices. Such efficiency gains enable real-time radar data processing on resource-constrained platforms, allowing for new applications in the context of smart homes, Internet-of-Things, and human-computer interaction.", "url": "https://arxiv.org/abs/2309.05686"}, {"metadata": {"arXiv": "2309.05751", "Date": "Mon, 11 Sep 2023 18:15:51 ", "Title": "The Effect of Intrinsic Dimension on Metric Learning under Compression", "Authors": ["Efstratios Palias", "Ata Kab\\'an"], "Categories": "cs.LG stat.ML", "Comments": ["18 pages", "2 figures"]}, "abstract": "Metric learning aims at finding a suitable distance metric over the input space, to improve the performance of distance-based learning algorithms. In high-dimensional settings, metric learning can also play the role of dimensionality reduction, by imposing a low-rank restriction to the learnt metric. In this paper, instead of training a low-rank metric on high-dimensional data, we consider a randomly compressed version of the data, and train a full-rank metric there. We give theoretical guarantees on the error of distance-based metric learning, with respect to the random compression, which do not depend on the ambient dimension. Our bounds do not make any explicit assumptions, aside from i.i.d. data from a bounded support, and automatically tighten when benign geometrical structures are present. Experimental results on both synthetic and real data sets support our theoretical findings in high-dimensional settings.", "url": "https://arxiv.org/abs/2309.05751"}, {"metadata": {"arXiv": "2309.05798", "Date": "Mon, 11 Sep 2023 20:06:00 ", "Title": "Enhancing Hyperedge Prediction with Context-Aware Self-Supervised Learning", "Authors": ["Yunyong Ko", "Hanghang Tong", "Sang-Wook Kim"], "Categories": "cs.LG cs.SI", "Comments": ["12 pages", "11 figures"]}, "abstract": "Hypergraphs can naturally model group-wise relations (e.g., a group of users who co-purchase an item) as hyperedges. Hyperedge prediction is to predict future or unobserved hyperedges, which is a fundamental task in many real-world applications (e.g., group recommendation). Despite the recent breakthrough of hyperedge prediction methods, the following challenges have been rarely studied: (C1) How to aggregate the nodes in each hyperedge candidate for accurate hyperedge prediction? and (C2) How to mitigate the inherent data sparsity problem in hyperedge prediction? To tackle both challenges together, in this paper, we propose a novel hyperedge prediction framework (CASH) that employs (1) context-aware node aggregation to precisely capture complex relations among nodes in each hyperedge for (C1) and (2) self-supervised contrastive learning in the context of hyperedge prediction to enhance hypergraph representations for (C2). Furthermore, as for (C2), we propose a hyperedge-aware augmentation method to fully exploit the latent semantics behind the original hypergraph and consider both node-level and group-level contrasts (i.e., dual contrasts) for better node and hyperedge representations. Extensive experiments on six real-world hypergraphs reveal that CASH consistently outperforms all competing methods in terms of the accuracy in hyperedge prediction and each of the proposed strategies is effective in improving the model accuracy of CASH. For the detailed information of CASH, we provide the code and datasets at: https://github.com/yy-ko/cash.", "url": "https://arxiv.org/abs/2309.05798"}, {"metadata": {"arXiv": "2309.05805", "Date": "Mon, 11 Sep 2023 20:17:11 ", "Title": "Online ML Self-adaptation in Face of Traps", "Authors": ["Michal T\\\"opfer", "Franti\\v{s}ek Pl\\'a\\v{s}il", "Tom\\'a\\v{s} Bure\\v{s}", "Petr Hn\\v{e}tynka", "Martin Kruli\\v{s}", "Danny Weyns"], "Categories": "cs.LG cs.NE", "Comments": ["This is the authors' version of the paper M. T\\\"opfer", "F. Pl\\'a\\v{s}il", "T. Bure\\v{s}", "P. Hn\\v{e}tynka", "M. Kruli\\v{s}", "D. Weyns: Online ML Self-adaptation in Face of Traps", "accepted for publication in Proceedings of ACSOS 2023", "Toronto", "Canada"]}, "abstract": "Online machine learning (ML) is often used in self-adaptive systems to strengthen the adaptation mechanism and improve the system utility. Despite such benefits, applying online ML for self-adaptation can be challenging, and not many papers report its limitations. Recently, we experimented with applying online ML for self-adaptation of a smart farming scenario and we had faced several unexpected difficulties -- traps -- that, to our knowledge, are not discussed enough in the community. In this paper, we report our experience with these traps. Specifically, we discuss several traps that relate to the specification and online training of the ML-based estimators, their impact on self-adaptation, and the approach used to evaluate the estimators. Our overview of these traps provides a list of lessons learned, which can serve as guidance for other researchers and practitioners when applying online ML for self-adaptation.", "url": "https://arxiv.org/abs/2309.05805"}, {"metadata": {"arXiv": "2309.05823", "Date": "Mon, 11 Sep 2023 21:01:11 ", "Title": "Ensemble-based modeling abstractions for modern self-optimizing systems", "Authors": ["Michal T\\\"opfer", "Milad Abdullah", "Tom\\'a\\v{s} Bure\\v{s}", "Petr Hn\\v{e}tynka", "Martin Kruli\\v{s}"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["This is the authors' version of the paper - M. T\\\"opfer", "M. Abdullah", "T. Bure\\v{s}", "P. Hn\\v{e}tynka", "M. Kruli\\v{s}: Ensemble-Based Modeling Abstractions for Modern Self-optimizing Systems", "in Proceedings of ISOLA 2022", "Rhodes", "Greece", "pp. 318-334", "2022. The final authenticated publication is available online at https://doi.org/10.1007/978-3-031-19759-8_20"], "DOI": "10.1007/978-3-031-19759-8_20"}, "abstract": "In this paper, we extend our ensemble-based component model DEECo with the capability to use machine-learning and optimization heuristics in establishing and reconfiguration of autonomic component ensembles. We show how to capture these concepts on the model level and give an example of how such a model can be beneficially used for modeling access-control related problem in the Industry 4.0 settings. We argue that incorporating machine-learning and optimization heuristics is a key feature for modern smart systems which are to learn over the time and optimize their behavior at runtime to deal with uncertainty in their environment.", "url": "https://arxiv.org/abs/2309.05823"}, {"metadata": {"arXiv": "2309.05826", "Date": "Mon, 11 Sep 2023 21:11:48 ", "Title": "KD-FixMatch: Knowledge Distillation Siamese Neural Networks", "Authors": ["Chien-Chih Wang", "Shaoyuan Xu", "Jinmiao Fu", "Yang Liu", "Bryan Wang"], "Categories": "cs.LG cs.CV", "Comments": ["5 pages", "1 figure", "5 tables. To be published in ICIP 2023"]}, "abstract": "Semi-supervised learning (SSL) has become a crucial approach in deep learning as a way to address the challenge of limited labeled data. The success of deep neural networks heavily relies on the availability of large-scale high-quality labeled data. However, the process of data labeling is time-consuming and unscalable, leading to shortages in labeled data. SSL aims to tackle this problem by leveraging additional unlabeled data in the training process. One of the popular SSL algorithms, FixMatch, trains identical weight-sharing teacher and student networks simultaneously using a siamese neural network (SNN). However, it is prone to performance degradation when the pseudo labels are heavily noisy in the early training stage. We present KD-FixMatch, a novel SSL algorithm that addresses the limitations of FixMatch by incorporating knowledge distillation. The algorithm utilizes a combination of sequential and simultaneous training of SNNs to enhance performance and reduce performance degradation. Firstly, an outer SNN is trained using labeled and unlabeled data. After that, the network of the well-trained outer SNN generates pseudo labels for the unlabeled data, from which a subset of unlabeled data with trusted pseudo labels is then carefully created through high-confidence sampling and deep embedding clustering. Finally, an inner SNN is trained with the labeled data, the unlabeled data, and the subset of unlabeled data with trusted pseudo labels. Experiments on four public data sets demonstrate that KD-FixMatch outperforms FixMatch in all cases. Our results indicate that KD-FixMatch has a better training starting point that leads to improved model performance compared to FixMatch.", "url": "https://arxiv.org/abs/2309.05826"}, {"metadata": {"arXiv": "2309.05843", "Date": "Mon, 11 Sep 2023 22:03:34 ", "Title": "Optimizing Audio Augmentations for Contrastive Learning of Health-Related Acoustic Signals", "Authors": ["Louis Blankemeier", "Sebastien Baur", "Wei-Hung Weng", "Jake Garrison", "Yossi Matias", "Shruthi Prabhakara", "Diego Ardila", "Zaid Nabulsi"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["7 pages", "2 pages appendix", "2 figures", "5 appendix tables"]}, "abstract": "Health-related acoustic signals, such as cough and breathing sounds, are relevant for medical diagnosis and continuous health monitoring. Most existing machine learning approaches for health acoustics are trained and evaluated on specific tasks, limiting their generalizability across various healthcare applications. In this paper, we leverage a self-supervised learning framework, SimCLR with a Slowfast NFNet backbone, for contrastive learning of health acoustics. A crucial aspect of optimizing Slowfast NFNet for this application lies in identifying effective audio augmentations. We conduct an in-depth analysis of various audio augmentation strategies and demonstrate that an appropriate augmentation strategy enhances the performance of the Slowfast NFNet audio encoder across a diverse set of health acoustic tasks. Our findings reveal that when augmentations are combined, they can produce synergistic effects that exceed the benefits seen when each is applied individually.", "url": "https://arxiv.org/abs/2309.05843"}, {"metadata": {"arXiv": "2309.05853", "Date": "Mon, 11 Sep 2023 22:28:36 ", "Title": "ChemSpaceAL: An Efficient Active Learning Methodology Applied to Protein-Specific Molecular Generation", "Authors": ["Gregory W. Kyro", "Anton Morgunov", "Rafael I. Brent", "Victor S. Batista"], "Categories": "cs.LG q-bio.BM"}, "abstract": "The incredible capabilities of generative artificial intelligence models have inevitably led to their application in the domain of drug discovery. It is therefore of tremendous interest to develop methodologies that enhance the abilities and applicability of these powerful tools. In this work, we present a novel and efficient semi-supervised active learning methodology that allows for the fine-tuning of a generative model with respect to an objective function by strategically operating within a constructed representation of the sample space. In the context of targeted molecular generation, we demonstrate the ability to fine-tune a GPT-based molecular generator with respect to an attractive interaction-based scoring function by strategically operating within a chemical space proxy, thereby maximizing attractive interactions between the generated molecules and a protein target. Importantly, our approach does not require the individual evaluation of all data points that are used for fine-tuning, enabling the incorporation of computationally expensive metrics. We are hopeful that the inherent generality of this methodology ensures that it will remain applicable as this exciting field evolves. To facilitate implementation and reproducibility, we have made all of our software available through the open-source ChemSpaceAL Python package.", "url": "https://arxiv.org/abs/2309.05853"}, {"metadata": {"arXiv": "2309.05855", "Date": "Mon, 11 Sep 2023 22:34:06 ", "Title": "Energy Preservation and Stability of Random Filterbanks", "Authors": ["Daniel Haider", "Vincent Lostanlen", "Martin Ehler", "Peter Balazs"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["4 pages", "5 figures", "1 page appendix"]}, "abstract": "What makes waveform-based deep learning so hard? Despite numerous attempts at training convolutional neural networks (convnets) for filterbank design, they often fail to outperform hand-crafted baselines. This is all the more surprising because these baselines are linear time-invariant systems: as such, their transfer functions could be accurately represented by a convnet with a large receptive field. In this article, we elaborate on the statistical properties of simple convnets from the mathematical perspective of random convolutional operators. We find that FIR filterbanks with random Gaussian weights are ill-conditioned for large filters and locally periodic input signals, which both are typical in audio signal processing applications. Furthermore, we observe that expected energy preservation of a random filterbank is not sufficient for numerical stability and derive theoretical bounds for its expected frame bounds.", "url": "https://arxiv.org/abs/2309.05855"}, {"metadata": {"arXiv": "2309.05865", "Date": "Mon, 11 Sep 2023 23:08:03 ", "Title": "Force-directed graph embedding with hops distance", "Authors": ["Hamidreza Lotfalizadeh", "Mohammad Al Hasan"], "Categories": "cs.LG"}, "abstract": "Graph embedding has become an increasingly important technique for analyzing graph-structured data. By representing nodes in a graph as vectors in a low-dimensional space, graph embedding enables efficient graph processing and analysis tasks like node classification, link prediction, and visualization. In this paper, we propose a novel force-directed graph embedding method that utilizes the steady acceleration kinetic formula to embed nodes in a way that preserves graph topology and structural features. Our method simulates a set of customized attractive and repulsive forces between all node pairs with respect to their hop distance. These forces are then used in Newton's second law to obtain the acceleration of each node. The method is intuitive, parallelizable, and highly scalable. We evaluate our method on several graph analysis tasks and show that it achieves competitive performance compared to state-of-the-art unsupervised embedding techniques.", "url": "https://arxiv.org/abs/2309.05865"}, {"metadata": {"arXiv": "2309.05878", "Date": "Mon, 11 Sep 2023 23:59:18 ", "Title": "Reaction coordinate flows for model reduction of molecular kinetics", "Authors": ["Hao Wu and Frank No\\'e"], "Categories": "cs.LG math.DS physics.chem-ph physics.data-an stat.ML"}, "abstract": "In this work, we introduce a flow based machine learning approach, called reaction coordinate (RC) flow, for discovery of low-dimensional kinetic models of molecular systems. The RC flow utilizes a normalizing flow to design the coordinate transformation and a Brownian dynamics model to approximate the kinetics of RC, where all model parameters can be estimated in a data-driven manner. In contrast to existing model reduction methods for molecular kinetics, RC flow offers a trainable and tractable model of reduced kinetics in continuous time and space due to the invertibility of the normalizing flow. Furthermore, the Brownian dynamics-based reduced kinetic model investigated in this work yields a readily discernible representation of metastable states within the phase space of the molecular system. Numerical experiments demonstrate how effectively the proposed method discovers interpretable and accurate low-dimensional representations of given full-state kinetics from simulations.", "url": "https://arxiv.org/abs/2309.05878"}, {"metadata": {"arXiv": "2309.05953", "Date": "Tue, 12 Sep 2023 04:21:30 ", "Title": "GLAD: Content-aware Dynamic Graphs For Log Anomaly Detection", "Authors": ["Yufei Li", "Yanchi Liu", "Haoyu Wang", "Zhengzhang Chen", "Wei Cheng", "Yuncong Chen", "Wenchao Yu", "Haifeng Chen", "Cong Liu"], "Categories": "cs.LG cs.IR", "Comments": ["Accepted by ICKG 2023"]}, "abstract": "Logs play a crucial role in system monitoring and debugging by recording valuable system information, including events and states. Although various methods have been proposed to detect anomalies in log sequences, they often overlook the significance of considering relations among system components, such as services and users, which can be identified from log contents. Understanding these relations is vital for detecting anomalies and their underlying causes. To address this issue, we introduce GLAD, a Graph-based Log Anomaly Detection framework designed to detect relational anomalies in system logs. GLAD incorporates log semantics, relational patterns, and sequential patterns into a unified framework for anomaly detection. Specifically, GLAD first introduces a field extraction module that utilizes prompt-based few-shot learning to identify essential fields from log contents. Then GLAD constructs dynamic log graphs for sliding windows by interconnecting extracted fields and log events parsed from the log parser. These graphs represent events and fields as nodes and their relations as edges. Subsequently, GLAD utilizes a temporal-attentive graph edge anomaly detection model for identifying anomalous relations in these dynamic log graphs. This model employs a Graph Neural Network (GNN)-based encoder enhanced with transformers to capture content, structural and temporal features. We evaluate our proposed method on three datasets, and the results demonstrate the effectiveness of GLAD in detecting anomalies indicated by varying relational patterns.", "url": "https://arxiv.org/abs/2309.05953"}, {"metadata": {"arXiv": "2309.05968", "Date": "Tue, 12 Sep 2023 05:36:08 ", "Title": "Neural Network Layer Matrix Decomposition reveals Latent Manifold Encoding and Memory Capacity", "Authors": ["Ng Shyh-Chang", "A-Li Luo", "Bo Qiu"], "Categories": "cs.LG cs.NE physics.bio-ph"}, "abstract": "We prove the converse of the universal approximation theorem, i.e. a neural network (NN) encoding theorem which shows that for every stably converged NN of continuous activation functions, its weight matrix actually encodes a continuous function that approximates its training dataset to within a finite margin of error over a bounded domain. We further show that using the Eckart-Young theorem for truncated singular value decomposition of the weight matrix for every NN layer, we can illuminate the nature of the latent space manifold of the training dataset encoded and represented by every NN layer, and the geometric nature of the mathematical operations performed by each NN layer. Our results have implications for understanding how NNs break the curse of dimensionality by harnessing memory capacity for expressivity, and that the two are complementary. This Layer Matrix Decomposition (LMD) further suggests a close relationship between eigen-decomposition of NN layers and the latest advances in conceptualizations of Hopfield networks and Transformer NN models.", "url": "https://arxiv.org/abs/2309.05968"}, {"metadata": {"arXiv": "2309.05975", "Date": "Tue, 12 Sep 2023 05:55:41 ", "Title": "CleanUNet 2: A Hybrid Speech Denoising Model on Waveform and Spectrogram", "Authors": ["Zhifeng Kong", "Wei Ping", "Ambrish Dantrey", "Bryan Catanzaro"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["INTERSPEECH 2023"], "Journal-ref": "Proc. INTERSPEECH 2023, pages 790--794", "DOI": "10.21437/Interspeech.2023-1287"}, "abstract": "In this work, we present CleanUNet 2, a speech denoising model that combines the advantages of waveform denoiser and spectrogram denoiser and achieves the best of both worlds. CleanUNet 2 uses a two-stage framework inspired by popular speech synthesis methods that consist of a waveform model and a spectrogram model. Specifically, CleanUNet 2 builds upon CleanUNet, the state-of-the-art waveform denoiser, and further boosts its performance by taking predicted spectrograms from a spectrogram denoiser as the input. We demonstrate that CleanUNet 2 outperforms previous methods in terms of various objective and subjective evaluations.", "url": "https://arxiv.org/abs/2309.05975"}, {"metadata": {"arXiv": "2309.05981", "Date": "Tue, 12 Sep 2023 06:20:34 ", "Title": "Learning Unbiased News Article Representations: A Knowledge-Infused Approach", "Authors": ["Sadia Kamal", "Jimmy Hartford", "Jeremy Willis", "Arunkumar Bagavathi"], "Categories": "cs.LG"}, "abstract": "Quantification of the political leaning of online news articles can aid in understanding the dynamics of political ideology in social groups and measures to mitigating them. However, predicting the accurate political leaning of a news article with machine learning models is a challenging task. This is due to (i) the political ideology of a news article is defined by several factors, and (ii) the innate nature of existing learning models to be biased with the political bias of the news publisher during the model training. There is only a limited number of methods to study the political leaning of news articles which also do not consider the algorithmic political bias which lowers the generalization of machine learning models to predict the political leaning of news articles published by any new news publishers. In this work, we propose a knowledge-infused deep learning model that utilizes relatively reliable external data resources to learn unbiased representations of news articles using their global and local contexts. We evaluate the proposed model by setting the data in such a way that news domains or news publishers in the test set are completely unseen during the training phase. With this setup we show that the proposed model mitigates algorithmic political bias and outperforms baseline methods to predict the political leaning of news articles with up to 73% accuracy.", "url": "https://arxiv.org/abs/2309.05981"}, {"metadata": {"arXiv": "2309.06015", "Date": "Tue, 12 Sep 2023 07:29:47 ", "Title": "Interpolation, Approximation and Controllability of Deep Neural Networks", "Authors": ["Jingpu Cheng", "Qianxiao Li", "Ting Lin", "Zuowei Shen"], "Categories": "cs.LG math.DS math.OC", "MSC-class": "93B05, 41A05, 68T07"}, "abstract": "We investigate the expressive power of deep residual neural networks idealized as continuous dynamical systems through control theory. Specifically, we consider two properties that arise from supervised learning, namely universal interpolation - the ability to match arbitrary input and target training samples - and the closely related notion of universal approximation - the ability to approximate input-target functional relationships via flow maps. Under the assumption of affine invariance of the control family, we give a characterisation of universal interpolation, showing that it holds for essentially any architecture with non-linearity. Furthermore, we elucidate the relationship between universal interpolation and universal approximation in the context of general control systems, showing that the two properties cannot be deduced from each other. At the same time, we identify conditions on the control family and the target function that ensures the equivalence of the two notions.", "url": "https://arxiv.org/abs/2309.06015"}, {"metadata": {"arXiv": "2309.06021", "Date": "Tue, 12 Sep 2023 07:40:53 ", "Title": "Emergent Communication in Multi-Agent Reinforcement Learning for Future Wireless Networks", "Authors": ["Marwa Chafii", "Salmane Naoumi", "Reda Alami", "Ebtesam Almazrouei", "Mehdi Bennis", "Merouane Debbah"], "Categories": "cs.LG cs.MA eess.SP"}, "abstract": "In different wireless network scenarios, multiple network entities need to cooperate in order to achieve a common task with minimum delay and energy consumption. Future wireless networks mandate exchanging high dimensional data in dynamic and uncertain environments, therefore implementing communication control tasks becomes challenging and highly complex. Multi-agent reinforcement learning with emergent communication (EC-MARL) is a promising solution to address high dimensional continuous control problems with partially observable states in a cooperative fashion where agents build an emergent communication protocol to solve complex tasks. This paper articulates the importance of EC-MARL within the context of future 6G wireless networks, which imbues autonomous decision-making capabilities into network entities to solve complex tasks such as autonomous driving, robot navigation, flying base stations network planning, and smart city applications. An overview of EC-MARL algorithms and their design criteria are provided while presenting use cases and research opportunities on this emerging topic.", "url": "https://arxiv.org/abs/2309.06021"}, {"metadata": {"arXiv": "2309.06034", "Date": "Tue, 12 Sep 2023 08:06:04 ", "Title": "Normality Learning-based Graph Anomaly Detection via Multi-Scale Contrastive Learning", "Authors": ["Jingcan Duan", "Pei Zhang", "Siwei Wang", "Jingtao Hu", "Hu Jin", "Jiaxin Zhang", "Haifang Zhou", "Haifang Zhou"], "Categories": "cs.LG", "Comments": ["10 pages", "7 figures", "accepted by ACM MM 2023"]}, "abstract": "Graph anomaly detection (GAD) has attracted increasing attention in machine learning and data mining. Recent works have mainly focused on how to capture richer information to improve the quality of node embeddings for GAD. Despite their significant advances in detection performance, there is still a relative dearth of research on the properties of the task. GAD aims to discern the anomalies that deviate from most nodes. However, the model is prone to learn the pattern of normal samples which make up the majority of samples. Meanwhile, anomalies can be easily detected when their behaviors differ from normality. Therefore, the performance can be further improved by enhancing the ability to learn the normal pattern. To this end, we propose a normality learning-based GAD framework via multi-scale contrastive learning networks (NLGAD for abbreviation). Specifically, we first initialize the model with the contrastive networks on different scales. To provide sufficient and reliable normal nodes for normality learning, we design an effective hybrid strategy for normality selection. Finally, the model is refined with the only input of reliable normal nodes and learns a more accurate estimate of normality so that anomalous nodes can be more easily distinguished. Eventually, extensive experiments on six benchmark graph datasets demonstrate the effectiveness of our normality learning-based scheme on GAD. Notably, the proposed algorithm improves the detection performance (up to 5.89% AUC gain) compared with the state-of-the-art methods. The source code is released at https://github.com/FelixDJC/NLGAD.", "url": "https://arxiv.org/abs/2309.06034"}, {"metadata": {"arXiv": "2309.06049", "Date": "Tue, 12 Sep 2023 08:35:24 ", "Title": "A Perceptron-based Fine Approximation Technique for Linear Separation", "Authors": ["\\'Akos Hajnal"], "Categories": "cs.LG", "Comments": ["12 pages", "5 figures"]}, "abstract": "This paper presents a novel online learning method that aims at finding a separator hyperplane between data points labelled as either positive or negative. Since weights and biases of artificial neurons can directly be related to hyperplanes in high-dimensional spaces, the technique is applicable to train perceptron-based binary classifiers in machine learning. In case of large or imbalanced data sets, use of analytical or gradient-based solutions can become prohibitive and impractical, where heuristics and approximation techniques are still applicable. The proposed method is based on the Perceptron algorithm, however, it tunes neuron weights in just the necessary extent during searching the separator hyperplane. Due to an appropriate transformation of the initial data set we need not to consider data labels, neither the bias term. respectively, reducing separability to a one-class classification problem. The presented method has proven converge; empirical results show that it can be more efficient than the Perceptron algorithm, especially, when the size of the data set exceeds data dimensionality.", "url": "https://arxiv.org/abs/2309.06049"}, {"metadata": {"arXiv": "2309.06054", "Date": "Tue, 12 Sep 2023 08:45:25 ", "Title": "How does representation impact in-context learning: A exploration on a synthetic task", "Authors": ["Jingwen Fu", "Tao Yang", "Yuwang Wang", "Yan Lu", "Nanning Zheng"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "In-context learning, i.e., learning from in-context samples, is an impressive ability of Transformer. However, the mechanism driving the in-context learning is not yet fully understood. In this study, we aim to investigate from an underexplored perspective of representation learning. The representation is more complex for in-context learning senario, where the representation can be impacted by both model weights and in-context samples. We refer the above two conceptually aspects of representation as in-weight component and in-context component, respectively. To study how the two components affect in-context learning capabilities, we construct a novel synthetic task, making it possible to device two probes, in-weights probe and in-context probe, to evaluate the two components, respectively. We demonstrate that the goodness of in-context component is highly related to the in-context learning performance, which indicates the entanglement between in-context learning and representation learning. Furthermore, we find that a good in-weights component can actually benefit the learning of the in-context component, indicating that in-weights learning should be the foundation of in-context learning. To further understand the the in-context learning mechanism and importance of the in-weights component, we proof by construction that a simple Transformer, which uses pattern matching and copy-past mechanism to perform in-context learning, can match the in-context learning performance with more complex, best tuned Transformer under the perfect in-weights component assumption. In short, those discoveries from representation learning perspective shed light on new approaches to improve the in-context capacity.", "url": "https://arxiv.org/abs/2309.06054"}, {"metadata": {"arXiv": "2309.06062", "Date": "Tue, 12 Sep 2023 09:00:17 ", "Title": "Selection of contributing factors for predicting landslide susceptibility using machine learning and deep learning models", "Authors": ["Cheng Chen and Lei Fan"], "Categories": "cs.LG cs.CV physics.geo-ph", "Comments": ["Stochastic Environmental Research and Risk Assessment"]}, "abstract": "Landslides are a common natural disaster that can cause casualties, property safety threats and economic losses. Therefore, it is important to understand or predict the probability of landslide occurrence at potentially risky sites. A commonly used means is to carry out a landslide susceptibility assessment based on a landslide inventory and a set of landslide contributing factors. This can be readily achieved using machine learning (ML) models such as logistic regression (LR), support vector machine (SVM), random forest (RF), extreme gradient boosting (Xgboost), or deep learning (DL) models such as convolutional neural network (CNN) and long short time memory (LSTM). As the input data for these models, landslide contributing factors have varying influences on landslide occurrence. Therefore, it is logically feasible to select more important contributing factors and eliminate less relevant ones, with the aim of increasing the prediction accuracy of these models. However, selecting more important factors is still a challenging task and there is no generally accepted method. Furthermore, the effects of factor selection using various methods on the prediction accuracy of ML and DL models are unclear. In this study, the impact of the selection of contributing factors on the accuracy of landslide susceptibility predictions using ML and DL models was investigated. Four methods for selecting contributing factors were considered for all the aforementioned ML and DL models, which included Information Gain Ratio (IGR), Recursive Feature Elimination (RFE), Particle Swarm Optimization (PSO), Least Absolute Shrinkage and Selection Operators (LASSO) and Harris Hawk Optimization (HHO). In addition, autoencoder-based factor selection methods for DL models were also investigated. To assess their performances, an exhaustive approach was adopted,...", "url": "https://arxiv.org/abs/2309.06062"}, {"metadata": {"arXiv": "2309.06081", "Date": "Tue, 12 Sep 2023 09:18:12 ", "Title": "Information Flow in Graph Neural Networks: A Clinical Triage Use Case", "Authors": ["V\\'ictor Valls", "Mykhaylo Zayats", "Alessandra Pascale"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) have gained popularity in healthcare and other domains due to their ability to process multi-modal and multi-relational graphs. However, efficient training of GNNs remains challenging, with several open research questions. In this paper, we investigate how the flow of embedding information within GNNs affects the prediction of links in Knowledge Graphs (KGs). Specifically, we propose a mathematical model that decouples the GNN connectivity from the connectivity of the graph data and evaluate the performance of GNNs in a clinical triage use case. Our results demonstrate that incorporating domain knowledge into the GNN connectivity leads to better performance than using the same connectivity as the KG or allowing unconstrained embedding propagation. Moreover, we show that negative edges play a crucial role in achieving good predictions, and that using too many GNN layers can degrade performance.", "url": "https://arxiv.org/abs/2309.06081"}, {"metadata": {"arXiv": "2309.06086", "Date": "Tue, 12 Sep 2023 09:31:34 ", "Title": "Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning", "Authors": ["Alex Gomez-Villa", "Bartlomiej Twardowski", "Kai Wang", "Joost van de Weijer"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at WACV2024"]}, "abstract": "Continuous unsupervised representation learning (CURL) research has greatly benefited from improvements in self-supervised learning (SSL) techniques. As a result, existing CURL methods using SSL can learn high-quality representations without any labels, but with a notable performance drop when learning on a many-tasks data stream. We hypothesize that this is caused by the regularization losses that are imposed to prevent forgetting, leading to a suboptimal plasticity-stability trade-off: they either do not adapt fully to the incoming data (low plasticity), or incur significant forgetting when allowed to fully adapt to a new SSL pretext-task (low stability). In this work, we propose to train an expert network that is relieved of the duty of keeping the previous knowledge and can focus on performing optimally on the new tasks (optimizing plasticity). In the second phase, we combine this new knowledge with the previous network in an adaptation-retrospection phase to avoid forgetting and initialize a new expert with the knowledge of the old network. We perform several experiments showing that our proposed approach outperforms other CURL exemplar-free methods in few- and many-task split settings. Furthermore, we show how to adapt our approach to semi-supervised continual learning (Semi-SCL) and show that we surpass the accuracy of other exemplar-free Semi-SCL methods and reach the results of some others that use exemplars.", "url": "https://arxiv.org/abs/2309.06086"}, {"metadata": {"arXiv": "2309.06166", "Date": "Tue, 12 Sep 2023 12:23:49 ", "Title": "Certified Robust Models with Slack Control and Large Lipschitz Constants", "Authors": ["Max Losch", "David Stutz", "Bernt Schiele", "Mario Fritz"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["To be published at GCPR 2023"]}, "abstract": "Despite recent success, state-of-the-art learning-based models remain highly vulnerable to input changes such as adversarial examples. In order to obtain certifiable robustness against such perturbations, recent work considers Lipschitz-based regularizers or constraints while at the same time increasing prediction margin. Unfortunately, this comes at the cost of significantly decreased accuracy. In this paper, we propose a Calibrated Lipschitz-Margin Loss (CLL) that addresses this issue and improves certified robustness by tackling two problems: Firstly, commonly used margin losses do not adjust the penalties to the shrinking output distribution; caused by minimizing the Lipschitz constant $K$. Secondly, and most importantly, we observe that minimization of $K$ can lead to overly smooth decision functions. This limits the model's complexity and thus reduces accuracy. Our CLL addresses these issues by explicitly calibrating the loss w.r.t. margin and Lipschitz constant, thereby establishing full control over slack and improving robustness certificates even with larger Lipschitz constants. On CIFAR-10, CIFAR-100 and Tiny-ImageNet, our models consistently outperform losses that leave the constant unattended. On CIFAR-100 and Tiny-ImageNet, CLL improves upon state-of-the-art deterministic $L_2$ robust accuracies. In contrast to current trends, we unlock potential of much smaller models without $K=1$ constraints.", "url": "https://arxiv.org/abs/2309.06166"}, {"metadata": {"arXiv": "2309.06169", "Date": "Tue, 12 Sep 2023 12:27:17 ", "Title": "Elucidating the solution space of extended reverse-time SDE for diffusion models", "Authors": ["Qinpeng Cui", "Xinyi Zhang", "Zongqing Lu and Qingmin Liao"], "Categories": "cs.LG cs.CV"}, "abstract": "Diffusion models (DMs) demonstrate potent image generation capabilities in various generative modeling tasks. Nevertheless, their primary limitation lies in slow sampling speed, requiring hundreds or thousands of sequential function evaluations through large neural networks to generate high-quality images. Sampling from DMs can be seen as solving corresponding stochastic differential equations (SDEs) or ordinary differential equations (ODEs). In this work, we formulate the sampling process as an extended reverse-time SDE (ER SDE), unifying prior explorations into ODEs and SDEs. Leveraging the semi-linear structure of ER SDE solutions, we offer exact solutions and arbitrarily high-order approximate solutions for VP SDE and VE SDE, respectively. Based on the solution space of the ER SDE, we yield mathematical insights elucidating the superior performance of ODE solvers over SDE solvers in terms of fast sampling. Additionally, we unveil that VP SDE solvers stand on par with their VE SDE counterparts. Finally, we devise fast and training-free samplers, ER-SDE Solvers, elevating the efficiency of stochastic samplers to unprecedented levels. Experimental results demonstrate achieving 3.45 FID in 20 function evaluations and 2.24 FID in 50 function evaluations on the ImageNet 64$\\times$64 dataset.", "url": "https://arxiv.org/abs/2309.06169"}, {"metadata": {"arXiv": "2309.06180", "Date": "Tue, 12 Sep 2023 12:50:04 ", "Title": "Efficient Memory Management for Large Language Model Serving with PagedAttention", "Authors": ["Woosuk Kwon", "Zhuohan Li", "Siyuan Zhuang", "Ying Sheng", "Lianmin Zheng", "Cody Hao Yu", "Joseph E. Gonzalez", "Hao Zhang", "Ion Stoica"], "Categories": "cs.LG cs.DC", "Comments": ["SOSP 2023"]}, "abstract": "High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2-4$\\times$ with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. vLLM's source code is publicly available at https://github.com/vllm-project/vllm", "url": "https://arxiv.org/abs/2309.06180"}, {"metadata": {"arXiv": "2309.06195", "Date": "Tue, 12 Sep 2023 13:03:47 ", "Title": "Optimization Guarantees of Unfolded ISTA and ADMM Networks With Smooth Soft-Thresholding", "Authors": ["Shaik Basheeruddin Shah", "Pradyumna Pradhan", "Wei Pu", "Ramunaidu Randhi", "Miguel R. D. Rodrigues", "Yonina C. Eldar"], "Categories": "cs.LG eess.SP"}, "abstract": "Solving linear inverse problems plays a crucial role in numerous applications. Algorithm unfolding based, model-aware data-driven approaches have gained significant attention for effectively addressing these problems. Learned iterative soft-thresholding algorithm (LISTA) and alternating direction method of multipliers compressive sensing network (ADMM-CSNet) are two widely used such approaches, based on ISTA and ADMM algorithms, respectively. In this work, we study optimization guarantees, i.e., achieving near-zero training loss with the increase in the number of learning epochs, for finite-layer unfolded networks such as LISTA and ADMM-CSNet with smooth soft-thresholding in an over-parameterized (OP) regime. We achieve this by leveraging a modified version of the Polyak-Lojasiewicz, denoted PL$^*$, condition. Satisfying the PL$^*$ condition within a specific region of the loss landscape ensures the existence of a global minimum and exponential convergence from initialization using gradient descent based methods. Hence, we provide conditions, in terms of the network width and the number of training samples, on these unfolded networks for the PL$^*$ condition to hold. We achieve this by deriving the Hessian spectral norm of these networks. Additionally, we show that the threshold on the number of training samples increases with the increase in the network width. Furthermore, we compare the threshold on training samples of unfolded networks with that of a standard fully-connected feed-forward network (FFNN) with smooth soft-thresholding non-linearity. We prove that unfolded networks have a higher threshold value than FFNN. Consequently, one can expect a better expected error for unfolded networks than FFNN.", "url": "https://arxiv.org/abs/2309.06195"}, {"metadata": {"arXiv": "2309.06212", "Date": "Tue, 12 Sep 2023 13:28:06 ", "Title": "Long-term drought prediction using deep neural networks based on geospatial weather data", "Authors": ["Vsevolod Grabar", "Alexander Marusov", "Alexey Zaytsev", "Yury Maximov", "Nazar Sotiriadi", "Alexander Bulkin"], "Categories": "cs.LG"}, "abstract": "The accurate prediction of drought probability in specific regions is crucial for informed decision-making in agricultural practices. It is important to make predictions one year in advance, particularly for long-term decisions. However, forecasting this probability presents challenges due to the complex interplay of various factors within the region of interest and neighboring areas. In this study, we propose an end-to-end solution to address this issue based on various spatiotemporal neural networks. The models considered focus on predicting the drought intensity based on the Palmer Drought Severity Index (PDSI) for subregions of interest, leveraging intrinsic factors and insights from climate models to enhance drought predictions. Comparative evaluations demonstrate the superior accuracy of Convolutional LSTM (ConvLSTM) and transformer models compared to baseline gradient boosting and logistic regression solutions. The two former models achieved impressive ROC AUC scores from 0.90 to 0.70 for forecast horizons from one to six months, outperforming baseline models. The transformer showed superiority for shorter horizons, while ConvLSTM did so for longer horizons. Thus, we recommend selecting the models accordingly for long-term drought forecasting. To ensure the broad applicability of the considered models, we conduct extensive validation across regions worldwide, considering different environmental conditions. We also run several ablation and sensitivity studies to challenge our findings and provide additional information on how to solve the problem.", "url": "https://arxiv.org/abs/2309.06212"}, {"metadata": {"arXiv": "2309.06236", "Date": "Tue, 12 Sep 2023 13:51:29 ", "Title": "The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models", "Authors": ["Dimitris Spathis", "Fahim Kawsar"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted at the Generative AI for Pervasive Computing Symposium (GenAI4PC) at UbiComp 2023"]}, "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this \"modality gap\". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.", "url": "https://arxiv.org/abs/2309.06236"}, {"metadata": {"arXiv": "2309.06239", "Date": "Tue, 12 Sep 2023 13:55:01 ", "Title": "Risk-Aware Reinforcement Learning through Optimal Transport Theory", "Authors": ["Ali Baheri"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making. Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks. In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework. Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles. By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives. Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors. Through the lens of OT, this work illuminates a promising direction for RL, ensuring a balanced fusion of reward pursuit and risk awareness.", "url": "https://arxiv.org/abs/2309.06239"}, {"metadata": {"arXiv": "2309.06248", "Date": "Tue, 12 Sep 2023 14:04:12 ", "Title": "Rethinking Evaluation Metric for Probability Estimation Models Using Esports Data", "Authors": ["Euihyeon Choi", "Jooyoung Kim", "Wonkyung Lee"], "Categories": "cs.LG", "Comments": ["7 pages"]}, "abstract": "Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis. Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available. The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation. However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination. In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field. Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good properties that probability estimation metric should have. Under the general condition, we also found that the Balance score can be an effective approximation of the true expected calibration error which has been imperfectly approximated by ECE using the binning technique. Extensive evaluations using simulation studies and real game snapshot data demonstrate the promising potential to adopt the proposed metric not only for the win probability estimation model for esports but also for evaluating general probability estimation models.", "url": "https://arxiv.org/abs/2309.06248"}, {"metadata": {"arXiv": "2309.06256", "Date": "Tue, 12 Sep 2023 14:16:54 ", "Title": "Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models", "Authors": ["Yong Lin", "Lu Tan", "Hangyu Lin", "Zeming Zheng", "Renjie Pi", "Jipeng Zhang", "Shizhe Diao", "Haoxiang Wang", "Han Zhao", "Yuan Yao", "and Tong Zhang"], "Categories": "cs.LG", "Comments": ["30 Pages"]}, "abstract": "Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets. The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training. Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning. In this study, we demonstrate this phenomenon in both VLMs and LLMs. For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions and common sense. To address the trade-off between the speciality and generality, we investigate multiple regularization methods from continual learning, the weight averaging method (Wise-FT) from out-of-distributional (OOD) generalization, which interpolates parameters between pre-trained and fine-tuned models, and parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA). Our findings show that both continual learning and Wise-ft methods effectively mitigate the loss of generality, with Wise-FT exhibiting the strongest performance in balancing speciality and generality.", "url": "https://arxiv.org/abs/2309.06256"}, {"metadata": {"arXiv": "2309.06274", "Date": "Tue, 12 Sep 2023 14:36:13 ", "Title": "ELRA: Exponential learning rate adaption gradient descent optimization method", "Authors": ["Alexander Kleinsorge", "Stefan Kupper", "Alexander Fauck", "Felix Rothe"], "Categories": "cs.LG math.OC", "Comments": ["9 pages", "11 figures"], "ACM-class": "G.1.6; I.2.6"}, "abstract": "We present a novel, fast (exponential rate adaption), ab initio (hyper-parameter-free) gradient based optimizer algorithm. The main idea of the method is to adapt the learning rate $\\alpha$ by situational awareness, mainly striving for orthogonal neighboring gradients. The method has a high success and fast convergence rate and does not rely on hand-tuned parameters giving it greater universality. It can be applied to problems of any dimensions n and scales only linearly (of order O(n)) with the dimension of the problem. It optimizes convex and non-convex continuous landscapes providing some kind of gradient. In contrast to the Ada-family (AdaGrad, AdaMax, AdaDelta, Adam, etc.) the method is rotation invariant: optimization path and performance are independent of coordinate choices. The impressive performance is demonstrated by extensive experiments on the MNIST benchmark data-set against state-of-the-art optimizers. We name this new class of optimizers after its core idea Exponential Learning Rate Adaption - ELRA. We present it in two variants c2min and p2min with slightly different control. The authors strongly believe that ELRA will open a completely new research direction for gradient descent optimize.", "url": "https://arxiv.org/abs/2309.06274"}, {"metadata": {"arXiv": "2309.06299", "Date": "Tue, 12 Sep 2023 15:05:11 ", "Title": "Modeling Supply and Demand in Public Transportation Systems", "Authors": ["Miranda Bihler", "Hala Nelson", "Erin Okey", "Noe Reyes Rivas", "John Webb", "Anna White"], "Categories": "cs.LG stat.AP stat.ML", "Comments": ["28 pages", "2022 REU project at James Madison University"], "MSC-class": "00A69, 62-07, 62P30"}, "abstract": "The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.", "url": "https://arxiv.org/abs/2309.06299"}, {"metadata": {"arXiv": "2309.06359", "Date": "Tue, 12 Sep 2023 16:20:20 ", "Title": "Using Reed-Muller Codes for Classification with Rejection and Recovery", "Authors": ["Daniel Fentham (1)", "David Parker (2)", "Mark Ryan (1) ((1) University of Birmingham", "(2) University of Oxford)"], "Categories": "cs.LG", "Comments": ["38 pages", "7 figures"]}, "abstract": "When deploying classifiers in the real world, users expect them to respond to inputs appropriately. However, traditional classifiers are not equipped to handle inputs which lie far from the distribution they were trained on. Malicious actors can exploit this defect by making adversarial perturbations designed to cause the classifier to give an incorrect output. Classification-with-rejection methods attempt to solve this problem by allowing networks to refuse to classify an input in which they have low confidence. This works well for strongly adversarial examples, but also leads to the rejection of weakly perturbed images, which intuitively could be correctly classified. To address these issues, we propose Reed-Muller Aggregation Networks (RMAggNet), a classifier inspired by Reed-Muller error-correction codes which can correct and reject inputs. This paper shows that RMAggNet can minimise incorrectness while maintaining good correctness over multiple adversarial attacks at different perturbation budgets by leveraging the ability to correct errors in the classification process. This provides an alternative classification-with-rejection method which can reduce the amount of additional processing in situations where a small number of incorrect classifications are permissible.", "url": "https://arxiv.org/abs/2309.06359"}, {"metadata": {"arXiv": "2309.06380", "Date": "Tue, 12 Sep 2023 16:42:09 ", "Title": "InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation", "Authors": ["Xingchao Liu", "Xiwen Zhang", "Jianzhu Ma", "Jian Peng", "Qiang Liu"], "Categories": "cs.LG cs.CV"}, "abstract": "Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity. However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results. Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model. In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets. The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models. We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images. Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37.2$ $\\rightarrow$ $23.3$ in FID). By utilizing an expanded network with 1.7B parameters, we further improve the FID to $22.4$. We call our one-step models \\emph{InstaFlow}. On MS COCO 2014-30k, InstaFlow yields an FID of $13.1$ in just $0.09$ second, the best in $\\leq 0.1$ second regime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second). Notably, the training of InstaFlow only costs 199 A100 GPU days. Project page:~\\url{https://github.com/gnobitab/InstaFlow}.", "url": "https://arxiv.org/abs/2309.06380"}, {"metadata": {"arXiv": "2309.06413", "Date": "Tue, 12 Sep 2023 17:25:32 ", "Title": "On Computationally Efficient Learning of Exponential Family Distributions", "Authors": ["Abhin Shah", "Devavrat Shah", "Gregory W. Wornell"], "Categories": "cs.LG stat.ML", "Comments": ["An earlier version of this work arXiv:2110.15397 was presented at the Neural Information Processing Systems Conference in December 2021 titled \"A Computationally Efficient Method for Learning Exponential Family Distributions\""]}, "abstract": "We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as well as an instance of minimizing the \\textit{surrogate} likelihood. We also provide finite sample guarantees to achieve an error (in $\\ell_2$-norm) of $\\alpha$ in the parameter estimation with sample complexity $O({\\sf poly}(k)/\\alpha^2)$. Our method achives the order-optimal sample complexity of $O({\\sf log}(k)/\\alpha^2)$ when tailored for node-wise-sparse Markov random fields. Finally, we demonstrate the performance of our estimator via numerical experiments.", "url": "https://arxiv.org/abs/2309.06413"}, {"metadata": {"arXiv": "2309.05803", "Date": "Mon, 11 Sep 2023 20:13:47 ", "Title": "Revisiting Energy Based Models as Policies: Ranking Noise Contrastive Estimation and Interpolating Energy Models", "Authors": ["Sumeet Singh", "Stephen Tu", "Vikas Sindhwani"], "Categories": "cs.RO cs.LG"}, "abstract": "A crucial design decision for any robot learning pipeline is the choice of policy representation: what type of model should be used to generate the next set of robot actions? Owing to the inherent multi-modal nature of many robotic tasks, combined with the recent successes in generative modeling, researchers have turned to state-of-the-art probabilistic models such as diffusion models for policy representation. In this work, we revisit the choice of energy-based models (EBM) as a policy class. We show that the prevailing folklore -- that energy models in high dimensional continuous spaces are impractical to train -- is false. We develop a practical training objective and algorithm for energy models which combines several key ingredients: (i) ranking noise contrastive estimation (R-NCE), (ii) learnable negative samplers, and (iii) non-adversarial joint training. We prove that our proposed objective function is asymptotically consistent and quantify its limiting variance. On the other hand, we show that the Implicit Behavior Cloning (IBC) objective is actually biased even at the population level, providing a mathematical explanation for the poor performance of IBC trained energy policies in several independent follow-up works. We further extend our algorithm to learn a continuous stochastic process that bridges noise and data, modeling this process with a family of EBMs indexed by scale variable. In doing so, we demonstrate that the core idea behind recent progress in generative modeling is actually compatible with EBMs. Altogether, our proposed training algorithms enable us to train energy-based models as policies which compete with -- and even outperform -- diffusion models and other state-of-the-art approaches in several challenging multi-modal benchmarks: obstacle avoidance path planning and contact-rich block pushing.", "url": "https://arxiv.org/abs/2309.05803"}, {"metadata": {"arXiv": "2309.05837", "Date": "Mon, 11 Sep 2023 21:34:16 ", "Title": "The Safety Filter: A Unified View of Safety-Critical Control in Autonomous Systems", "Authors": ["Kai-Chieh Hsu", "Haimin Hu", "Jaime Fern\\'andez Fisac"], "Categories": "eess.SY cs.LG cs.RO cs.SY", "Comments": ["Accepted for publication in Annual Review of Control", "Robotics", "and Autonomous Systems"]}, "abstract": "Recent years have seen significant progress in the realm of robot autonomy, accompanied by the expanding reach of robotic technologies. However, the emergence of new deployment domains brings unprecedented challenges in ensuring safe operation of these systems, which remains as crucial as ever. While traditional model-based safe control methods struggle with generalizability and scalability, emerging data-driven approaches tend to lack well-understood guarantees, which can result in unpredictable catastrophic failures. Successful deployment of the next generation of autonomous robots will require integrating the strengths of both paradigms. This article provides a review of safety filter approaches, highlighting important connections between existing techniques and proposing a unified technical framework to understand, compare, and combine them. The new unified view exposes a shared modular structure across a range of seemingly disparate safety filter classes and naturally suggests directions for future progress towards more scalable synthesis, robust monitoring, and efficient intervention.", "url": "https://arxiv.org/abs/2309.05837"}, {"metadata": {"arXiv": "2309.06090", "Date": "Tue, 12 Sep 2023 09:37:26 ", "Title": "A General Verification Framework for Dynamical and Control Models via Certificate Synthesis", "Authors": ["Alec Edwards", "Andrea Peruffo", "Alessandro Abate"], "Categories": "eess.SY cs.LG cs.LO cs.SY"}, "abstract": "An emerging branch of control theory specialises in certificate learning, concerning the specification of a desired (possibly complex) system behaviour for an autonomous or control model, which is then analytically verified by means of a function-based proof. However, the synthesis of controllers abiding by these complex requirements is in general a non-trivial task and may elude the most expert control engineers. This results in a need for automatic techniques that are able to design controllers and to analyse a wide range of elaborate specifications. In this paper, we provide a general framework to encode system specifications and define corresponding certificates, and we present an automated approach to formally synthesise controllers and certificates. Our approach contributes to the broad field of safe learning for control, exploiting the flexibility of neural networks to provide candidate control and certificate functions, whilst using SMT-solvers to offer a formal guarantee of correctness. We test our framework by developing a prototype software tool, and assess its efficacy at verification via control and certificate synthesis over a large and varied suite of benchmarks.", "url": "https://arxiv.org/abs/2309.06090"}, {"metadata": {"arXiv": "2309.05922", "Date": "Tue, 12 Sep 2023 02:34:06 ", "Title": "A Survey of Hallucination in Large Foundation Models", "Authors": ["Vipula Rawte", "Amit Sheth", "Amitava Das"], "Categories": "cs.AI cs.CL cs.IR"}, "abstract": "Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.", "url": "https://arxiv.org/abs/2309.05922"}, {"metadata": {"arXiv": "2309.05999", "Date": "Tue, 12 Sep 2023 06:56:46 ", "Title": "Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents", "Authors": ["Sungwoo Lee", "Younghyun Oh", "Hyunhoe An", "Hyebhin Yoon", "Karl J. Friston", "Seok Jun Hong", "Choong-Wan Woo"], "Categories": "cs.AI cs.NE", "Comments": ["28 pages", "4 figures", "3 boxes"], "ACM-class": "I.2.0"}, "abstract": "Building autonomous --- i.e., choosing goals based on one's needs -- and adaptive -- i.e., surviving in ever-changing environments -- agents has been a holy grail of artificial intelligence (AI). A living organism is a prime example of such an agent, offering important lessons about adaptive autonomy. Here, we focus on interoception, a process of monitoring one's internal environment to keep it within certain bounds, which underwrites the survival of an organism. To develop AI with interoception, we need to factorize the state variables representing internal environments from external environments and adopt life-inspired mathematical properties of internal environment states. This paper offers a new perspective on how interoception can help build autonomous and adaptive agents by integrating the legacy of cybernetics with recent advances in theories of life, reinforcement learning, and neuroscience.", "url": "https://arxiv.org/abs/2309.05999"}, {"metadata": {"arXiv": "2309.06045", "Date": "Tue, 12 Sep 2023 08:29:53 ", "Title": "Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures", "Authors": ["Fu-Yao Ko", "Katsuyuki Suzuki", "Kazuo Yonekura"], "Categories": "cs.AI cs.NA math.NA", "Comments": ["25 pages", "15 figures", "13 tables"], "Report-no": "SAMO-D-23-00757"}, "abstract": "Sizing optimization of truss structures is a complex computational problem, and the reinforcement learning (RL) is suitable for dealing with multimodal problems without gradient computations. In this paper, a new efficient optimization algorithm called update Monte Carlo tree search (UMCTS) is developed to obtain the appropriate design for truss structures. UMCTS is an RL-based method that combines the novel update process and Monte Carlo tree search (MCTS) with the upper confidence bound (UCB). Update process means that in each round, the optimal cross-sectional area of each member is determined by search tree, and its initial state is the final state in the previous round. In the UMCTS algorithm, an accelerator for the number of selections for member area and iteration number is introduced to reduce the computation time. Moreover, for each state, the average reward is replaced by the best reward collected on the simulation process to determine the optimal solution. The proposed optimization method is examined on some benchmark problems of planar and spatial trusses with discrete sizing variables to demonstrate the efficiency and validity. It is shown that the computation time for the proposed approach is at least ten times faster than the branch and bound (BB) method. The numerical results indicate that the proposed method stably achieves better solution than other conventional methods.", "url": "https://arxiv.org/abs/2309.06045"}, {"metadata": {"arXiv": "2309.06373", "Date": "Sun, 10 Sep 2023 16:40:30 ", "Title": "Chebyshev Particles", "Authors": ["Xiongming Dai and Gerald Baumgartner"], "Categories": "cs.AI cs.IT math.IT", "Comments": ["19 pages", "3 figures"], "MSC-class": "53-04", "ACM-class": "F.2"}, "abstract": "Markov chain Monte Carlo (MCMC) provides a feasible method for inferring Hidden Markov models, however, it is often computationally prohibitive, especially constrained by the curse of dimensionality, as the Monte Carlo sampler traverses randomly taking small steps within uncertain regions in the parameter space. We are the first to consider the posterior distribution of the objective as a mapping of samples in an infinite-dimensional Euclidean space where deterministic submanifolds are embedded and propose a new criterion by maximizing the weighted Riesz polarization quantity, to discretize rectifiable submanifolds via pairwise interaction. We study the characteristics of Chebyshev particles and embed them into sequential MCMC, a novel sampler with a high acceptance ratio that proposes only a few evaluations. We have achieved high performance from the experiments for parameter inference in a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility model with real-world data.", "url": "https://arxiv.org/abs/2309.06373"}, {"metadata": {"arXiv": "2309.05793", "Date": "Mon, 11 Sep 2023 19:59:43 ", "Title": "PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models", "Authors": ["Li Chen", "Mengyi Zhao", "Yiheng Liu", "Mingxu Ding", "Yangyang Song", "Shizun Wang", "Xu Wang", "Hao Yang", "Jing Liu", "Kang Du", "Min Zheng"], "Categories": "cs.CV cs.AI"}, "abstract": "Personalized text-to-image generation has emerged as a powerful and sought-after tool, empowering users to create customized images based on their specific concepts and prompts. However, existing approaches to personalization encounter multiple challenges, including long tuning times, large storage requirements, the necessity for multiple input images per identity, and limitations in preserving identity and editability. To address these obstacles, we present PhotoVerse, an innovative methodology that incorporates a dual-branch conditioning mechanism in both text and image domains, providing effective control over the image generation process. Furthermore, we introduce facial identity loss as a novel component to enhance the preservation of identity during training. Remarkably, our proposed PhotoVerse eliminates the need for test time tuning and relies solely on a single facial photo of the target identity, significantly reducing the resource cost associated with image generation. After a single training phase, our approach enables generating high-quality images within only a few seconds. Moreover, our method can produce diverse images that encompass various scenes and styles. The extensive evaluation demonstrates the superior performance of our approach, which achieves the dual objectives of preserving identity and facilitating editability. Project page: https://photoverse2d.github.io/", "url": "https://arxiv.org/abs/2309.05793"}, {"metadata": {"arXiv": "2309.05911", "Date": "Tue, 12 Sep 2023 02:01:31 ", "Title": "Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning", "Authors": ["Binh M. Le and Simon S. Woo"], "Categories": "cs.CV cs.AI", "Journal-ref": "International Conference on Computer Vision 2023"}, "abstract": "Deepfake has recently raised a plethora of societal concerns over its possible security threats and dissemination of fake information. Much research on deepfake detection has been undertaken. However, detecting low quality as well as simultaneously detecting different qualities of deepfakes still remains a grave challenge. Most SOTA approaches are limited by using a single specific model for detecting certain deepfake video quality type. When constructing multiple models with prior information about video quality, this kind of strategy incurs significant computational cost, as well as model and training data overhead. Further, it cannot be scalable and practical to deploy in real-world settings. In this work, we propose a universal intra-model collaborative learning framework to enable the effective and simultaneous detection of different quality of deepfakes. That is, our approach is the quality-agnostic deepfake detection method, dubbed QAD . In particular, by observing the upper bound of general error expectation, we maximize the dependency between intermediate representations of images from different quality levels via Hilbert-Schmidt Independence Criterion. In addition, an Adversarial Weight Perturbation module is carefully devised to enable the model to be more robust against image corruption while boosting the overall model's performance. Extensive experiments over seven popular deepfake datasets demonstrate the superiority of our QAD model over prior SOTA benchmarks.", "url": "https://arxiv.org/abs/2309.05911"}, {"metadata": {"arXiv": "2309.05930", "Date": "Tue, 12 Sep 2023 03:05:06 ", "Title": "Combining deep learning and street view imagery to map smallholder crop types", "Authors": ["Jordi Laguarta", "Thomas Friedel", "Sherrie Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Submitted to AAAI-24: Special Track on AI for Social Impact"]}, "abstract": "Accurate crop type maps are an essential source of information for monitoring yield progress at scale, projecting global crop production, and planning effective policies. To date, however, crop type maps remain challenging to create in low and middle-income countries due to a lack of ground truth labels for training machine learning models. Field surveys are the gold standard in terms of accuracy but require an often-prohibitively large amount of time, money, and statistical capacity. In recent years, street-level imagery, such as Google Street View, KartaView, and Mapillary, has become available around the world. Such imagery contains rich information about crop types grown at particular locations and times. In this work, we develop an automated system to generate crop type ground references using deep learning and Google Street View imagery. The method efficiently curates a set of street view images containing crop fields, trains a model to predict crop type by utilizing weakly-labelled images from disparate out-of-domain sources, and combines predicted labels with remote sensing time series to create a wall-to-wall crop type map. We show that, in Thailand, the resulting country-wide map of rice, cassava, maize, and sugarcane achieves an accuracy of 93%. As the availability of roadside imagery expands, our pipeline provides a way to map crop types at scale around the globe, especially in underserved smallholder regions.", "url": "https://arxiv.org/abs/2309.05930"}, {"metadata": {"arXiv": "2309.05943", "Date": "Tue, 12 Sep 2023 03:48:29 ", "Title": "Knowledge-Guided Short-Context Action Anticipation in Human-Centric Videos", "Authors": ["Sarthak Bhagat", "Simon Stepputtis", "Joseph Campbell", "Katia Sycara"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023 Workshop on AI for Creative Video Editing and Understanding"]}, "abstract": "This work focuses on anticipating long-term human actions, particularly using short video segments, which can speed up editing workflows through improved suggestions while fostering creativity by suggesting narratives. To this end, we imbue a transformer network with a symbolic knowledge graph for action anticipation in video segments by boosting certain aspects of the transformer's attention mechanism at run-time. Demonstrated on two benchmark datasets, Breakfast and 50Salads, our approach outperforms current state-of-the-art methods for long-term action anticipation using short video context by up to 9%.", "url": "https://arxiv.org/abs/2309.05943"}, {"metadata": {"arXiv": "2309.06006", "Date": "Tue, 12 Sep 2023 07:03:30 ", "Title": "SoccerNet 2023 Challenges Results", "Authors": ["Anthony Cioppa", "Silvio Giancola", "Vladimir Somers", "Floriane Magera", "Xin Zhou", "Hassan Mkhallati", "Adrien Deli\\`ege", "Jan Held", "Carlos Hinojosa", "Amir M. Mansourian", "Pierre Miralles", "Olivier Barnich", "Christophe De Vleeschouwer", "Alexandre Alahi", "Bernard Ghanem", "Marc Van Droogenbroeck", "Abdullah Kamal", "Adrien Maglo", "Albert Clap\\'es", "Amr Abdelaziz", "Artur Xarles", "Astrid Orcesi", "Atom Scott", "Bin Liu", "Byoungkwon Lim", "Chen Chen", "Fabian Deuser", "Feng Yan", "Fufu Yu", "Gal Shitrit", "Guanshuo Wang", "Gyusik Choi", "Hankyul Kim", "Hao Guo", "Hasby Fahrudin", "Hidenari Koguchi", "H{\\aa}kan Ard\\\"o", "Ibrahim Salah", "Ido Yerushalmy", "Iftikar Muhammad", "Ikuma Uchida", "Ishay Be'ery", "Jaonary Rabarisoa", "Jeongae Lee", "Jiajun Fu", "Jianqin Yin", "Jinghang Xu", "Jongho Nang", "Julien Denize", "Junjie Li", "Junpei Zhang", "Juntae Kim", "Kamil Synowiec", "Kenji Kobayashi", "et al. (48 additional authors not shown)"], "Categories": "cs.CV cs.AI"}, "abstract": "The SoccerNet 2023 challenges were the third annual video understanding challenges organized by the SoccerNet team. For this third edition, the challenges were composed of seven vision-based tasks split into three main themes. The first theme, broadcast video understanding, is composed of three high-level tasks related to describing events occurring in the video broadcasts: (1) action spotting, focusing on retrieving all timestamps related to global actions in soccer, (2) ball action spotting, focusing on retrieving all timestamps related to the soccer ball change of state, and (3) dense video captioning, focusing on describing the broadcast with natural language and anchored timestamps. The second theme, field understanding, relates to the single task of (4) camera calibration, focusing on retrieving the intrinsic and extrinsic camera parameters from images. The third and last theme, player understanding, is composed of three low-level tasks related to extracting information about the players: (5) re-identification, focusing on retrieving the same players across multiple views, (6) multiple object tracking, focusing on tracking players and the ball through unedited video streams, and (7) jersey number recognition, focusing on recognizing the jersey number of players from tracklets. Compared to the previous editions of the SoccerNet challenges, tasks (2-3-7) are novel, including new annotations and data, task (4) was enhanced with more data and annotations, and task (6) now focuses on end-to-end approaches. More information on the tasks, challenges, and leaderboards are available on https://www.soccer-net.org. Baselines and development kits can be found on https://github.com/SoccerNet.", "url": "https://arxiv.org/abs/2309.06006"}, {"metadata": {"arXiv": "2309.06129", "Date": "Tue, 12 Sep 2023 11:08:14 ", "Title": "LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images", "Authors": ["sean anthony byrne", "virmarie maquiling", "marcus nystr\\\"om", "enkelejda kasneci", "diederick c. niehorster"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["31 pages", "8 figures"]}, "abstract": "Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or \"LEyes\" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addition, a LEyes trained model outperforms the industry standard eye tracker using significantly more cost-effective hardware. Going forward, we are confident that LEyes will revolutionize synthetic data generation for gaze estimation models, and lead to significant improvements of the next generation video-based eye trackers.", "url": "https://arxiv.org/abs/2309.06129"}, {"metadata": {"arXiv": "2309.06130", "Date": "Tue, 12 Sep 2023 11:17:25 ", "Title": "JOADAA: joint online action detection and action anticipation", "Authors": ["Mohammed Guermal", "Francois Bremond", "Rui Dai", "Abid Ali"], "Categories": "cs.CV cs.AI"}, "abstract": "Action anticipation involves forecasting future actions by connecting past events to future ones. However, this reasoning ignores the real-life hierarchy of events which is considered to be composed of three main parts: past, present, and future. We argue that considering these three main parts and their dependencies could improve performance. On the other hand, online action detection is the task of predicting actions in a streaming manner. In this case, one has access only to the past and present information. Therefore, in online action detection (OAD) the existing approaches miss semantics or future information which limits their performance. To sum up, for both of these tasks, the complete set of knowledge (past-present-future) is missing, which makes it challenging to infer action dependencies, therefore having low performances. To address this limitation, we propose to fuse both tasks into a single uniform architecture. By combining action anticipation and online action detection, our approach can cover the missing dependencies of future information in online action detection. This method referred to as JOADAA, presents a uniform model that jointly performs action anticipation and online action detection. We validate our proposed model on three challenging datasets: THUMOS'14, which is a sparsely annotated dataset with one action per time step, CHARADES, and Multi-THUMOS, two densely annotated datasets with more complex scenarios. JOADAA achieves SOTA results on these benchmarks for both tasks.", "url": "https://arxiv.org/abs/2309.06130"}, {"metadata": {"arXiv": "2309.06194", "Date": "Tue, 12 Sep 2023 13:03:32 ", "Title": "A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace", "Authors": ["Jing Yang", "Nur Intan Raihana Ruhaiyem", "Chichun Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "The Yongle Palace murals, as valuable cultural heritage, have suffered varying degrees of damage, making their restoration of significant importance. However, the giant size and unique data of Yongle Palace murals present challenges for existing deep-learning based restoration methods: 1) The distinctive style introduces domain bias in traditional transfer learning-based restoration methods, while the scarcity of mural data further limits the applicability of these methods. 2) Additionally, the giant size of these murals results in a wider range of defect types and sizes, necessitating models with greater adaptability. Consequently, there is a lack of focus on deep learning-based restoration methods for the unique giant murals of Yongle Palace. Here, a 3M-Hybrid model is proposed to address these challenges. Firstly, based on the characteristic that the mural data frequency is prominent in the distribution of low and high frequency features, high and low frequency features are separately abstracted for complementary learning. Furthermore, we integrate a pre-trained Vision Transformer model (VIT) into the CNN module, allowing us to leverage the benefits of a large model while mitigating domain bias. Secondly, we mitigate seam and structural distortion issues resulting from the restoration of large defects by employing a multi-scale and multi-perspective strategy, including data segmentation and fusion. Experimental results demonstrate the efficacy of our proposed model. In regular-sized mural restoration, it improves SSIM and PSNR by 14.61% and 4.73%, respectively, compared to the best model among four representative CNN models. Additionally, it achieves favorable results in the final restoration of giant murals.", "url": "https://arxiv.org/abs/2309.06194"}, {"metadata": {"arXiv": "2309.06197", "Date": "Tue, 12 Sep 2023 13:04:41 ", "Title": "360$^\\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation", "Authors": ["Laurenz Reichardt", "Nikolas Ebert", "Oliver Wasenm\\\"uller"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV Workshop 2023"]}, "abstract": "Deep learning applications on LiDAR data suffer from a strong domain gap when applied to different sensors or tasks. In order for these methods to obtain similar accuracy on different data in comparison to values reported on public benchmarks, a large scale annotated dataset is necessary. However, in practical applications labeled data is costly and time consuming to obtain. Such factors have triggered various research in label-efficient methods, but a large gap remains to their fully-supervised counterparts. Thus, we propose ImageTo360, an effective and streamlined few-shot approach to label-efficient LiDAR segmentation. Our method utilizes an image teacher network to generate semantic predictions for LiDAR data within a single camera view. The teacher is used to pretrain the LiDAR segmentation student network, prior to optional fine-tuning on 360$^\\circ$ data. Our method is implemented in a modular manner on the point level and as such is generalizable to different architectures. We improve over the current state-of-the-art results for label-efficient methods and even surpass some traditional fully-supervised segmentation networks.", "url": "https://arxiv.org/abs/2309.06197"}, {"metadata": {"arXiv": "2309.06199", "Date": "Tue, 12 Sep 2023 13:08:46 ", "Title": "SCP: Scene Completion Pre-training for 3D Object Detection", "Authors": ["Yiming Shan", "Yan Xia", "Yuhong Chen", "Daniel Cremers"], "Categories": "cs.CV cs.AI", "Comments": ["Wins the best paper award at ISPRS Geospatial Week 2023"]}, "abstract": "3D object detection using LiDAR point clouds is a fundamental task in the fields of computer vision, robotics, and autonomous driving. However, existing 3D detectors heavily rely on annotated datasets, which are both time-consuming and prone to errors during the process of labeling 3D bounding boxes. In this paper, we propose a Scene Completion Pre-training (SCP) method to enhance the performance of 3D object detectors with less labeled data. SCP offers three key advantages: (1) Improved initialization of the point cloud model. By completing the scene point clouds, SCP effectively captures the spatial and semantic relationships among objects within urban environments. (2) Elimination of the need for additional datasets. SCP serves as a valuable auxiliary network that does not impose any additional efforts or data requirements on the 3D detectors. (3) Reduction of the amount of labeled data for detection. With the help of SCP, the existing state-of-the-art 3D detectors can achieve comparable performance while only relying on 20% labeled data.", "url": "https://arxiv.org/abs/2309.06199"}, {"metadata": {"arXiv": "2309.06285", "Date": "Tue, 12 Sep 2023 14:43:50 ", "Title": "Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos", "Authors": ["Bavesh Balaji", "Jerrin Bright", "Harish Prakash", "Yuhao Chen", "David A Clausi and John Zelek"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in the 6th International Workshop on Multimedia Content Analysis in Sports (MMSports'23) @ ACM Multimedia"]}, "abstract": "Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production. However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions. Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames. Hence, identifying frames that contain the jersey number is a key sub-problem to tackle. To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number. A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video. Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately. Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps. These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.", "url": "https://arxiv.org/abs/2309.06285"}, {"metadata": {"arXiv": "2309.06308", "Date": "Tue, 12 Sep 2023 15:19:36 ", "Title": "AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours", "Authors": ["Sergio Romero-Tapiador", "Ruben Tolosana", "Aythami Morales", "Isabel Espinosa-Salinas", "Gala Freixer", "Julian Fierrez", "Ruben Vera-Rodriguez", "Enrique Carrillo de Santa Pau", "Ana Ram\\'irez de Molina and Javier Ortega-Garcia"], "Categories": "cs.CV cs.AI cs.DB", "Comments": ["10 pages", "5 figures", "4 tables"]}, "abstract": "Nowadays millions of images are shared on social media and web platforms. In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet. On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world. Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID). Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed. This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours. AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images are taken using a smartphone. In addition to the framework, we also provide and describe a unique food image dataset that includes 4,800 different weekly eating behaviours from 15 different profiles and 1,200 subjects. Specifically, we consider profiles that comply with actual lifestyles from healthy eating behaviours (according to established knowledge), variable profiles (e.g., eating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets). Finally, we automatically evaluate a healthy index of the subject's eating behaviours using multidimensional metrics based on guidelines for healthy diets proposed by international organisations, achieving promising results (99.53% and 99.60% accuracy and sensitivity, respectively). We also release to the research community a software implementation of our proposed AI4Food-NutritionFW and the mentioned food image dataset created with it.", "url": "https://arxiv.org/abs/2309.06308"}, {"metadata": {"arXiv": "2309.06335", "Date": "Tue, 12 Sep 2023 15:52:08 ", "Title": "Grounded Language Acquisition From Object and Action Imagery", "Authors": ["James Robert Kubricht and Zhaoyuan Yang and Jianwei Qiu and Peter Henry Tu"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "7 figures", "conference"]}, "abstract": "Deep learning approaches to natural language processing have made great strides in recent years. While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world. In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm. An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels. These methods were applied in two experiments focusing on object recognition and action recognition. For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D trajectories were generated from 3D motion capture systems (MOVI dataset). In order to interpret the symbols produced for data in each experiment, gradient-weighted class activation mapping (Grad-CAM) methods were used to identify pixel regions indicating semantic features which contribute evidence towards symbols in learned languages. Additionally, a t-distributed stochastic neighbor embedding (t-SNE) method was used to investigate embeddings learned by CNN feature extractors.", "url": "https://arxiv.org/abs/2309.06335"}, {"metadata": {"arXiv": "2309.06441", "Date": "Tue, 12 Sep 2023 17:59:36 ", "Title": "Learning Disentangled Avatars with Hybrid 3D Representations", "Authors": ["Yao Feng", "Weiyang Liu", "Timo Bolkart", "Jinlong Yang", "Marc Pollefeys", "Michael J. Black"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["home page: https://yfeng95.github.io/delta. arXiv admin note: text overlap with arXiv:2210.01868"]}, "abstract": "Tremendous efforts have been made to learn animatable and photorealistic human avatars. Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata. For example, meshes are generally not suitable for modeling clothing and hair. Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations. DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers. Specifically, we demonstrate two important applications for DELTA. For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair. To do so, DELTA represents the body or face with an explicit mesh-based parametric 3D model and the clothing or hair with an implicit neural radiance field. To make this possible, we design an end-to-end differentiable renderer that integrates meshes into volumetric rendering, enabling DELTA to learn directly from monocular videos without any 3D supervision. Finally, we show that how these two applications can be easily combined to model full-body avatars, such that the hair, face, body and clothing can be fully disentangled yet jointly rendered. Such a disentanglement enables hair and clothing transfer to arbitrary body shapes. We empirically validate the effectiveness of DELTA's disentanglement by demonstrating its promising performance on disentangled reconstruction, virtual clothing try-on and hairstyle transfer. To facilitate future research, we also release an open-sourced pipeline for the study of hybrid human avatar modeling.", "url": "https://arxiv.org/abs/2309.06441"}, {"metadata": {"arXiv": "2309.05898", "Date": "Tue, 12 Sep 2023 00:54:15 ", "Title": "Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing", "Authors": ["Nunzio Lor\\`e", "Babak Heydari"], "Categories": "cs.GT cs.AI cs.CY cs.HC econ.TH", "Comments": ["25 pages", "12 figures"], "MSC-class": "91C99 (Primary), 91A05, 91A10, 91F99 (Secondary)", "ACM-class": "I.2.8; J.4; K.4.m"}, "abstract": "This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied proficiencies of LLMs in strategic decision-making, cautioning against their unqualified use in tasks requiring complex strategic reasoning.", "url": "https://arxiv.org/abs/2309.05898"}, {"metadata": {"arXiv": "2309.06038", "Date": "Tue, 12 Sep 2023 08:12:32 ", "Title": "Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping", "Authors": ["Tianhao Wu", "Mingdong Wu", "Jiyao Zhang", "Yunchong Gan", "Hao Dong"], "Categories": "cs.RO cs.AI"}, "abstract": "The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demonstrate the superiority of our proposed method compared to baselines, highlighting the user-awareness and practicality in real-world applications. The codes and demonstrations can be viewed at \"https://sites.google.com/view/graspgf\".", "url": "https://arxiv.org/abs/2309.06038"}, {"metadata": {"arXiv": "2309.05787", "Date": "Mon, 11 Sep 2023 19:35:12 ", "Title": "Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems", "Authors": ["Amr Gomaa", "Michael Feld"], "Categories": "cs.AI cs.HC cs.LG", "Comments": ["AI&HCI Workshop accepted paper at ICML2023 and accepted at ICMI2023 Blue Sky Papers. arXiv admin note: text overlap with arXiv:2211.03539"]}, "abstract": "Recent advances in machine learning, particularly deep learning, have enabled autonomous systems to perceive and comprehend objects and their environments in a perceptual subsymbolic manner. These systems can now perform object detection, sensor data fusion, and language understanding tasks. However, there is a growing need to enhance these systems to understand objects and their environments more conceptually and symbolically. It is essential to consider both the explicit teaching provided by humans (e.g., describing a situation or explaining how to act) and the implicit teaching obtained by observing human behavior (e.g., through the system's sensors) to achieve this level of powerful artificial intelligence. Thus, the system must be designed with multimodal input and output capabilities to support implicit and explicit interaction models. In this position paper, we argue for considering both types of inputs, as well as human-in-the-loop and incremental learning techniques, for advancing the field of artificial intelligence and enabling autonomous systems to learn like humans. We propose several hypotheses and design guidelines and highlight a use case from related work to achieve this goal.", "url": "https://arxiv.org/abs/2309.05787"}, {"metadata": {"arXiv": "2309.06097", "Date": "Tue, 12 Sep 2023 10:03:32 ", "Title": "Fidelity-Induced Interpretable Policy Extraction for Reinforcement Learning", "Authors": ["Xiao Liu", "Wubing Chen", "Mao Tan"], "Categories": "cs.AI cs.LG", "Comments": ["10 pages", "3 figures", "2 tables"]}, "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success in sequential decision-making problems. However, existing DRL agents make decisions in an opaque fashion, hindering the user from establishing trust and scrutinizing weaknesses of the agents. While recent research has developed Interpretable Policy Extraction (IPE) methods for explaining how an agent takes actions, their explanations are often inconsistent with the agent's behavior and thus, frequently fail to explain. To tackle this issue, we propose a novel method, Fidelity-Induced Policy Extraction (FIPE). Specifically, we start by analyzing the optimization mechanism of existing IPE methods, elaborating on the issue of ignoring consistency while increasing cumulative rewards. We then design a fidelity-induced mechanism by integrate a fidelity measurement into the reinforcement learning feedback. We conduct experiments in the complex control environment of StarCraft II, an arena typically avoided by current IPE methods. The experiment results demonstrate that FIPE outperforms the baselines in terms of interaction performance and consistency, meanwhile easy to understand.", "url": "https://arxiv.org/abs/2309.06097"}, {"metadata": {"arXiv": "2309.06286", "Date": "Tue, 12 Sep 2023 14:46:56 ", "Title": "Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition", "Authors": ["Mutahar Safdar", "Jiarui Xie", "Hyunwoong Ko", "Yan Lu", "Guy Lamouche", "Yaoyao Fiona Zhao"], "Categories": "cs.AI cs.CV cs.LG", "Comments": ["11 pages", "7 figures. This paper has been accepted to be published in the proceedings of IDETC-CIE 2023"]}, "abstract": "Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years. This has led to a plethora of scientific literature to emerge. The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way. Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another. As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies. There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning. We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer. As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components. The framework consists of pre-transfer, transfer, and post-transfer steps to accomplish knowledge transfer. A case study is conducted between flagship metal AM processes. Laser Powder Bed Fusion (LPBF) is the source of knowledge motivated by its relative matureness in applying AI over Directed Energy Deposition (DED), which drives the need for knowledge transfer as the less explored target process. We show successful transfer at different levels of the data-driven solution, including data representation, model architecture, and model parameters. The pipeline of AM knowledge transfer can be automated in the future to allow efficient cross-context or cross-process knowledge exchange.", "url": "https://arxiv.org/abs/2309.06286"}, {"metadata": {"arXiv": "2309.06375", "Date": "Fri, 08 Sep 2023 03:20:58 ", "Title": "Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models", "Authors": ["Craig Boutilier", "Martin Mladenov", "Guy Tennenholtz"], "Categories": "cs.AI cs.GT cs.HC cs.IR cs.LG cs.MA"}, "abstract": "Modern recommender systems lie at the heart of complex ecosystems that couple the behavior of users, content providers, advertisers, and other actors. Despite this, the focus of the majority of recommender research -- and most practical recommenders of any import -- is on the local, myopic optimization of the recommendations made to individual users. This comes at a significant cost to the long-term utility that recommenders could generate for its users. We argue that explicitly modeling the incentives and behaviors of all actors in the system -- and the interactions among them induced by the recommender's policy -- is strictly necessary if one is to maximize the value the system brings to these actors and improve overall ecosystem \"health\". Doing so requires: optimization over long horizons using techniques such as reinforcement learning; making inevitable tradeoffs in the utility that can be generated for different actors using the methods of social choice; reducing information asymmetry, while accounting for incentives and strategic behavior, using the tools of mechanism design; better modeling of both user and item-provider behaviors by incorporating notions from behavioral economics and psychology; and exploiting recent advances in generative and foundation models to make these mechanisms interpretable and actionable. We propose a conceptual framework that encompasses these elements, and articulate a number of research challenges that emerge at the intersection of these different disciplines.", "url": "https://arxiv.org/abs/2309.06375"}, {"metadata": {"arXiv": "2309.06255", "Date": "Tue, 12 Sep 2023 14:16:34 ", "Title": "Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation", "Authors": ["Yake Wei", "Ruoxuan Feng", "Zihe Wang", "Di Hu"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "Comments": ["7 pages"]}, "abstract": "One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this issue and improve cooperation between modalities by enhancing the discriminative ability of low-contributing modalities in a targeted manner. Overall, our methods reasonably observe the fine-grained uni-modal contribution at sample-level and achieve considerable improvement on different multi-modal models.", "url": "https://arxiv.org/abs/2309.06255"}, {"metadata": {"arXiv": "2309.05671", "Date": "Fri, 08 Sep 2023 17:47:31 ", "Title": "tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data", "Authors": ["Jonas H\\\"ugel and Ulrich Sax and Shawn N. Murphy and Hossein Estiri"], "Categories": "cs.LG cs.AI cs.IR", "Comments": ["Supplementary data: https://doi.org/10.5281/zenodo.8329519"]}, "abstract": "The increasing availability of large clinical datasets collected from patients can enable new avenues for computational characterization of complex diseases using different analytic algorithms. One of the promising new methods for extracting knowledge from large clinical datasets involves temporal pattern mining integrated with machine learning workflows. However, mining these temporal patterns is a computational intensive task and has memory repercussions. Current algorithms, such as the temporal sequence pattern mining (tSPM) algorithm, are already providing promising outcomes, but still leave room for optimization. In this paper, we present the tSPM+ algorithm, a high-performance implementation of the tSPM algorithm, which adds a new dimension by adding the duration to the temporal patterns. We show that the tSPM+ algorithm provides a speed up to factor 980 and a up to 48 fold improvement in memory consumption. Moreover, we present a docker container with an R-package, We also provide vignettes for an easy integration into already existing machine learning workflows and use the mined temporal sequences to identify Post COVID-19 patients and their symptoms according to the WHO definition.", "url": "https://arxiv.org/abs/2309.05671"}, {"metadata": {"arXiv": "2309.05675", "Date": "Sat, 09 Sep 2023 08:28:04 ", "Title": "SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation", "Authors": ["Sicen Liu", "Xiaolong Wang", "JIngcheng Du", "Yongshuai Hou", "Xianbing Zhao", "Hui Xu", "Hui Wang", "Yang Xiang", "Buzhou Tang"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "6 figures"]}, "abstract": "Effectively medication recommendation with complex multimorbidity conditions is a critical task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the information transmitted patterns of learning longitudinal sequence data are stable and intra-visit medical events are serialized. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this paper, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-level longitudinal representation efficiently. To endow the model with the capability of modeling the variable visit length, we introduce a soft curriculum learning method to assign the difficulty of each sample automatically by the visit length. Extensive experiments on a benchmark dataset verify the superiority of our model compared with several state-of-the-art baselines.", "url": "https://arxiv.org/abs/2309.05675"}, {"metadata": {"arXiv": "2309.05679", "Date": "Sat, 09 Sep 2023 14:44:39 ", "Title": "Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing", "Authors": ["Jinwen He", "Kai Chen", "Guozhu Meng", "Jiangshan Zhang", "Congyi Li"], "Categories": "cs.LG cs.AI cs.CR", "DOI": "10.1145/3576915.3616605"}, "abstract": "While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \\ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.", "url": "https://arxiv.org/abs/2309.05679"}, {"metadata": {"arXiv": "2309.05681", "Date": "Sun, 10 Sep 2023 02:06:49 ", "Title": "Knowledge-based Refinement of Scientific Publication Knowledge Graphs", "Authors": ["Siwen Yan (1)", "Phillip Odom (2)", "Sriraam Natarajan (1) ((1) The University of Texas at Dallas", "USA", "(2) Georgia Institute of Technology", "USA)"], "Categories": "cs.LG cs.AI cs.DL", "Comments": ["10 pages", "14 figures", "2 tables"]}, "abstract": "We consider the problem of identifying authorship by posing it as a knowledge graph construction and refinement. To this effect, we model this problem as learning a probabilistic logic model in the presence of human guidance (knowledge-based learning). Specifically, we learn relational regression trees using functional gradient boosting that outputs explainable rules. To incorporate human knowledge, advice in the form of first-order clauses is injected to refine the trees. We demonstrate the usefulness of human knowledge both quantitatively and qualitatively in seven authorship domains.", "url": "https://arxiv.org/abs/2309.05681"}, {"metadata": {"arXiv": "2309.05682", "Date": "Sun, 10 Sep 2023 19:15:22 ", "Title": "A compendium of data sources for data science, machine learning, and artificial intelligence", "Authors": ["Paul Bilokon and Oleksandr Bilokon and Saeed Amen"], "Categories": "cs.LG cs.AI cs.DB q-bio.QM q-fin.CP"}, "abstract": "Recent advances in data science, machine learning, and artificial intelligence, such as the emergence of large language models, are leading to an increasing demand for data that can be processed by such models. While data sources are application-specific, and it is impossible to produce an exhaustive list of such data sources, it seems that a comprehensive, rather than complete, list would still benefit data scientists and machine learning experts of all levels of seniority. The goal of this publication is to provide just such an (inevitably incomplete) list -- or compendium -- of data sources across multiple areas of applications, including finance and economics, legal (laws and regulations), life sciences (medicine and drug discovery), news sentiment and social media, retail and ecommerce, satellite imagery, and shipping and logistics, and sports.", "url": "https://arxiv.org/abs/2309.05682"}, {"metadata": {"arXiv": "2309.05683", "Date": "Mon, 11 Sep 2023 07:09:40 ", "Title": "EANet: Expert Attention Network for Online Trajectory Prediction", "Authors": ["Pengfei Yao", "Tianlu Mao", "Min Shi", "Jingkai Sun", "Zhaoqi Wang"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Trajectory prediction plays a crucial role in autonomous driving. Existing mainstream research and continuoual learning-based methods all require training on complete datasets, leading to poor prediction accuracy when sudden changes in scenarios occur and failing to promptly respond and update the model. Whether these methods can make a prediction in real-time and use data instances to update the model immediately(i.e., online learning settings) remains a question. The problem of gradient explosion or vanishing caused by data instance streams also needs to be addressed. Inspired by Hedge Propagation algorithm, we propose Expert Attention Network, a complete online learning framework for trajectory prediction. We introduce expert attention, which adjusts the weights of different depths of network layers, avoiding the model updated slowly due to gradient problem and enabling fast learning of new scenario's knowledge to restore prediction accuracy. Furthermore, we propose a short-term motion trend kernel function which is sensitive to scenario change, allowing the model to respond quickly. To the best of our knowledge, this work is the first attempt to address the online learning problem in trajectory prediction. The experimental results indicate that traditional methods suffer from gradient problems and that our method can quickly reduce prediction errors and reach the state-of-the-art prediction accuracy.", "url": "https://arxiv.org/abs/2309.05683"}, {"metadata": {"arXiv": "2309.05784", "Date": "Mon, 11 Sep 2023 19:31:14 ", "Title": "Grey-box Bayesian Optimization for Sensor Placement in Assisted Living Environments", "Authors": ["Shadan Golestan", "Omid Ardakanian", "Pierre Boulanger"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "Optimizing the configuration and placement of sensors is crucial for reliable fall detection, indoor localization, and activity recognition in assisted living spaces. We propose a novel, sample-efficient approach to find a high-quality sensor placement in an arbitrary indoor space based on grey-box Bayesian optimization and simulation-based evaluation. Our key technical contribution lies in capturing domain-specific knowledge about the spatial distribution of activities and incorporating it into the iterative selection of query points in Bayesian optimization. Considering two simulated indoor environments and a real-world dataset containing human activities and sensor triggers, we show that our proposed method performs better compared to state-of-the-art black-box optimization techniques in identifying high-quality sensor placements, leading to accurate activity recognition in terms of F1-score, while also requiring a significantly lower (51.3% on average) number of expensive function queries.", "url": "https://arxiv.org/abs/2309.05784"}, {"metadata": {"arXiv": "2309.05828", "Date": "Mon, 11 Sep 2023 21:14:55 ", "Title": "Exploring Geometric Deep Learning For Precipitation Nowcasting", "Authors": ["Shan Zhao", "Sudipan Saha", "Zhitong Xiong", "Niklas Boers", "Xiao Xiang Zhu"], "Categories": "cs.LG cs.AI physics.ao-ph", "Comments": ["submitted and accepted in IGARSS2023"]}, "abstract": "Precipitation nowcasting (up to a few hours) remains a challenge due to the highly complex local interactions that need to be captured accurately. Convolutional Neural Networks rely on convolutional kernels convolving with grid data and the extracted features are trapped by limited receptive field, typically expressed in excessively smooth output compared to ground truth. Thus they lack the capacity to model complex spatial relationships among the grids. Geometric deep learning aims to generalize neural network models to non-Euclidean domains. Such models are more flexible in defining nodes and edges and can effectively capture dynamic spatial relationship among geographical grids. Motivated by this, we explore a geometric deep learning-based temporal Graph Convolutional Network (GCN) for precipitation nowcasting. The adjacency matrix that simulates the interactions among grid cells is learned automatically by minimizing the L1 loss between prediction and ground truth pixel value during the training procedure. Then, the spatial relationship is refined by GCN layers while the temporal information is extracted by 1D convolution with various kernel lengths. The neighboring information is fed as auxiliary input layers to improve the final result. We test the model on sequences of radar reflectivity maps over the Trento/Italy area. The results show that GCNs improves the effectiveness of modeling the local details of the cloud profile as well as the prediction accuracy by achieving decreased error measures.", "url": "https://arxiv.org/abs/2309.05828"}, {"metadata": {"arXiv": "2309.05831", "Date": "Mon, 11 Sep 2023 21:17:10 ", "Title": "Studying Accuracy of Machine Learning Models Trained on Lab Lifting Data in Solving Real-World Problems Using Wearable Sensors for Workplace Safety", "Authors": ["Joseph Bertrand", "Nick Griffey", "Ming-Lun Lu", "Rashmi Jha"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "7 figures"], "MSC-class": "68T20", "ACM-class": "I.2.4"}, "abstract": "Porting ML models trained on lab data to real-world situations has long been a challenge. This paper discusses porting a lab-trained lifting identification model to the real-world. With performance much lower than on training data, we explored causes of the failure and proposed four potential solutions to increase model performance", "url": "https://arxiv.org/abs/2309.05831"}, {"metadata": {"arXiv": "2309.05845", "Date": "Mon, 11 Sep 2023 22:08:09 ", "Title": "Effective Abnormal Activity Detection on Multivariate Time Series Healthcare Data", "Authors": ["Mengjia Niu", "Yuchen Zhao", "Hamed Haddadi"], "Categories": "cs.LG cs.AI", "Comments": ["Poster accepted by the 29th Annual International Conference On Mobile Computing And Networking (ACM MobiCom 2023)"], "ACM-class": "J.3; I.2.6"}, "abstract": "Multivariate time series (MTS) data collected from multiple sensors provide the potential for accurate abnormal activity detection in smart healthcare scenarios. However, anomalies exhibit diverse patterns and become unnoticeable in MTS data. Consequently, achieving accurate anomaly detection is challenging since we have to capture both temporal dependencies of time series and inter-relationships among variables. To address this problem, we propose a Residual-based Anomaly Detection approach, Rs-AD, for effective representation learning and abnormal activity detection. We evaluate our scheme on a real-world gait dataset and the experimental results demonstrate an F1 score of 0.839.", "url": "https://arxiv.org/abs/2309.05845"}, {"metadata": {"arXiv": "2309.05858", "Date": "Mon, 11 Sep 2023 22:42:50 ", "Title": "Uncovering mesa-optimization algorithms in Transformers", "Authors": ["Johannes von Oswald", "Eyvind Niklasson", "Maximilian Schlegel", "Seijin Kobayashi", "Nicolas Zucchet", "Nino Scherrer", "Nolan Miller", "Mark Sandler", "Blaise Ag\\\"uera y Arcas", "Max Vladymyrov", "Razvan Pascanu", "Jo\\~ao Sacramento"], "Categories": "cs.LG cs.AI"}, "abstract": "Transformers have become the dominant model in deep learning, but the reason for their superior performance is poorly understood. Here, we hypothesize that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. To test this hypothesis, we reverse-engineer a series of autoregressive Transformers trained on simple sequence modeling tasks, uncovering underlying gradient-based mesa-optimization algorithms driving the generation of predictions. Moreover, we show that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, we propose a novel self-attention layer, the mesa-layer, that explicitly and efficiently solves optimization problems specified in context. We find that this layer can lead to improved performance in synthetic and preliminary language modeling experiments, adding weight to our hypothesis that mesa-optimization is an important operation hidden within the weights of trained Transformers.", "url": "https://arxiv.org/abs/2309.05858"}, {"metadata": {"arXiv": "2309.05863", "Date": "Mon, 11 Sep 2023 23:02:56 ", "Title": "The bionic neural network for external simulation of human locomotor system", "Authors": ["Yue Shi", "Shuhao Ma", "Yihui Zhao"], "Categories": "cs.LG cs.AI cs.RO q-bio.NC", "Comments": ["10"]}, "abstract": "Muscle forces and joint kinematics estimated with musculoskeletal (MSK) modeling techniques offer useful metrics describing movement quality. Model-based computational MSK models can interpret the dynamic interaction between the neural drive to muscles, muscle dynamics, body and joint kinematics, and kinetics. Still, such a set of solutions suffers from high computational time and muscle recruitment problems, especially in complex modeling. In recent years, data-driven methods have emerged as a promising alternative due to the benefits of flexibility and adaptability. However, a large amount of labeled training data is not easy to be acquired. This paper proposes a physics-informed deep learning method based on MSK modeling to predict joint motion and muscle forces. The MSK model is embedded into the neural network as an ordinary differential equation (ODE) loss function with physiological parameters of muscle activation dynamics and muscle contraction dynamics to be identified. These parameters are automatically estimated during the training process which guides the prediction of muscle forces combined with the MSK forward dynamics model. Experimental validations on two groups of data, including one benchmark dataset and one self-collected dataset from six healthy subjects, are performed. The results demonstrate that the proposed deep learning method can effectively identify subject-specific MSK physiological parameters and the trained physics-informed forward-dynamics surrogate yields accurate motion and muscle forces predictions.", "url": "https://arxiv.org/abs/2309.05863"}, {"metadata": {"arXiv": "2309.05915", "Date": "Tue, 12 Sep 2023 02:05:43 ", "Title": "ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning", "Authors": ["Chenxiao Gao", "Chenyang Wu", "Mingjun Cao", "Rui Kong", "Zongzhang Zhang", "Yang Yu"], "Categories": "cs.LG cs.AI"}, "abstract": "Decision Transformer (DT), which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DT's weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer (ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation results validate that, by leveraging the power of dynamic programming, ACT demonstrates effective trajectory stitching and robust action generation in spite of the environmental stochasticity, outperforming baseline methods across various benchmarks. Additionally, we conduct an in-depth analysis of ACT's various design choices through ablation studies.", "url": "https://arxiv.org/abs/2309.05915"}, {"metadata": {"arXiv": "2309.05925", "Date": "Tue, 12 Sep 2023 02:52:40 ", "Title": "On Regularized Sparse Logistic Regression", "Authors": ["Mengyuan Zhang and Kai Liu"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted to ICDM2023"]}, "abstract": "Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.", "url": "https://arxiv.org/abs/2309.05925"}, {"metadata": {"arXiv": "2309.05927", "Date": "Tue, 12 Sep 2023 02:59:26 ", "Title": "Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals", "Authors": ["Ran Liu", "Ellen L. Zippi", "Hadi Pouransari", "Chris Sandino", "Jingping Nie", "Hanlin Goh", "Erdrin Azemi", "Ali Moin"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "Leveraging multimodal information from biosignals is vital for building a comprehensive representation of people's physical and mental states. However, multimodal biosignals often exhibit substantial distributional shifts between pretraining and inference datasets, stemming from changes in task specification or variations in modality compositions. To achieve effective pretraining in the presence of potential distributional shifts, we propose a frequency-aware masked autoencoder ($\\texttt{bio}$FAME) that learns to parameterize the representation of biosignals in the frequency space. $\\texttt{bio}$FAME incorporates a frequency-aware transformer, which leverages a fixed-size Fourier-based operator for global token mixing, independent of the length and sampling rate of inputs. To maintain the frequency components within each input channel, we further employ a frequency-maintain pretraining strategy that performs masked autoencoding in the latent space. The resulting architecture effectively utilizes multimodal information during pretraining, and can be seamlessly adapted to diverse tasks and modalities at test time, regardless of input size and order. We evaluated our approach on a diverse set of transfer experiments on unimodal time series, achieving an average of $\\uparrow$5.5% improvement in classification accuracy over the previous state-of-the-art. Furthermore, we demonstrated that our architecture is robust in modality mismatch scenarios, including unpredicted modality dropout or substitution, proving its practical utility in real-world applications. Code will be available soon.", "url": "https://arxiv.org/abs/2309.05927"}, {"metadata": {"arXiv": "2309.06046", "Date": "Tue, 12 Sep 2023 08:30:35 ", "Title": "BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise", "Authors": ["Jeroen M. Galjaard", "Robert Birke", "Juan Perez", "Lydia Y. Chen"], "Categories": "cs.LG cs.AI cs.CV cs.NE", "Comments": ["10 pages,3 figures"]}, "abstract": "The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastive-shot tasks through augmentation, learning the embedding via a contrastive loss in meta-training, and then perform classification through zeroing on the embedding in meta-testing. We show that our approach can effectively mitigate the impact of meta-training label noise. Even with 60% wrong labels \\batman and \\man can limit the meta-testing accuracy drop to ${2.5}$, ${9.4}$, ${1.1}$ percent points, respectively, with existing meta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.", "url": "https://arxiv.org/abs/2309.06046"}, {"metadata": {"arXiv": "2309.06082", "Date": "Tue, 12 Sep 2023 09:24:21 ", "Title": "A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events", "Authors": ["Milan Jain", "Xueqing Sun", "Sohom Datta and Abhishek Somani"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["Published in IEEE PES GM 2023"]}, "abstract": "Power grids are moving towards 100% renewable energy source bulk power grids, and the overall dynamics of power system operations and electricity markets are changing. The electricity markets are not only dispatching resources economically but also taking into account various controllable actions like renewable curtailment, transmission congestion mitigation, and energy storage optimization to ensure grid reliability. As a result, price formations in electricity markets have become quite complex. Traditional root cause analysis and statistical approaches are rendered inapplicable to analyze and infer the main drivers behind price formation in the modern grid and markets with variable renewable energy (VRE). In this paper, we propose a machine learning-based analysis framework to deconstruct the primary drivers for price spike events in modern electricity markets with high renewable energy. The outcomes can be utilized for various critical aspects of market design, renewable dispatch and curtailment, operations, and cyber-security applications. The framework can be applied to any ISO or market data; however, in this paper, it is applied to open-source publicly available datasets from California Independent System Operator (CAISO) and ISO New England (ISO-NE).", "url": "https://arxiv.org/abs/2309.06082"}, {"metadata": {"arXiv": "2309.06157", "Date": "Tue, 12 Sep 2023 11:58:53 ", "Title": "Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines", "Authors": ["Khoa Tran", "Hai-Canh Vu", "Lam Pham", "Nassim Boudaoud"], "Categories": "cs.LG cs.AI"}, "abstract": "In this paper, a Robust Multi-branch Deep learning-based system for remaining useful life (RUL) prediction and condition operations (CO) identification of rotating machines is proposed. In particular, the proposed system comprises main components: (1) an LSTM-Autoencoder to denoise the vibration data; (2) a feature extraction to generate time-domain, frequency-domain, and time-frequency based features from the denoised data; (3) a novel and robust multi-branch deep learning network architecture to exploit the multiple features. The performance of our proposed system was evaluated and compared to the state-of-the-art systems on two benchmark datasets of XJTU-SY and PRONOSTIA. The experimental results prove that our proposed system outperforms the state-of-the-art systems and presents potential for real-life applications on bearing machines.", "url": "https://arxiv.org/abs/2309.06157"}, {"metadata": {"arXiv": "2309.06315", "Date": "Tue, 12 Sep 2023 15:27:00 ", "Title": "Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning", "Authors": ["Ole-Christoffer Granmo and Per-Arne Andersen and Lei Jiao and Xuan Zhang and Christian Blakely and Tor Tveit"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to ISTM2023", "8 pages", "6 figures"]}, "abstract": "A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable. If the blanket cannot be reduced without losing useful information, it is called a Markov boundary. Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous. Hence, the Markov boundary provides an optimal feature set. However, learning the Markov boundary from data is challenging for two reasons. If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information. Conversely, variables within the boundary may stop providing information. The true role of each candidate variable is only manifesting when the Markov boundary has been identified. In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II feedback. The scheme introduces a novel Finite State Automaton - a Context-Specific Independence Automaton. The automaton learns which features are outside the Markov boundary of the target, allowing them to be pruned from the TM during learning. We investigate the new scheme empirically, showing how it is capable of exploiting context-specific independence to find Markov boundaries. Further, we provide a theoretical analysis of convergence. Our approach thus connects the field of Bayesian networks (BN) with TMs, potentially opening up for synergies when it comes to inference and learning, including TM-produced Bayesian knowledge bases and TM-based Bayesian inference.", "url": "https://arxiv.org/abs/2309.06315"}, {"metadata": {"arXiv": "2309.06382", "Date": "Tue, 12 Sep 2023 16:48:00 ", "Title": "Ensemble Mask Networks", "Authors": ["Jonny Luntzel"], "Categories": "cs.LG cs.AI"}, "abstract": "Can an $\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$ feedforward network learn matrix-vector multiplication? This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure. Networks can approximate fixed operations such as matrix-vector multiplication $\\phi(A,x) \\rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models.", "url": "https://arxiv.org/abs/2309.06382"}, {"metadata": {"arXiv": "2309.06440", "Date": "Tue, 12 Sep 2023 17:59:20 ", "Title": "LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning", "Authors": ["Kenneth Shaw", "Ananye Agarwal", "Deepak Pathak"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "Comments": ["Website at https://leap-hand.github.io/"]}, "abstract": "Dexterous manipulation has been a long-standing challenge in robotics. While machine learning techniques have shown some promise, results have largely been currently limited to simulation. This can be mostly attributed to the lack of suitable hardware. In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research. In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose. LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts. It is capable of consistently exerting large torques over long durations of time. We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real. LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost. We release detailed assembly instructions, the Sim2Real pipeline and a development platform with useful APIs on our website at https://leap-hand.github.io/", "url": "https://arxiv.org/abs/2309.06440"}, {"metadata": {"arXiv": "2309.06420", "Date": "Sat, 09 Sep 2023 17:11:44 ", "Title": "Verifiable Reinforcement Learning Systems via Compositionality", "Authors": ["Cyrus Neary", "Aryaman Singh Samyal", "Christos Verginis", "Murat Cubuktepe", "Ufuk Topcu"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2106.05864"]}, "abstract": "We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaranteeing that if each subsystem learns a policy satisfying its subtask specification, then their composition is guaranteed to satisfy the overall task specification. Conversely, if the subtask specifications cannot all be satisfied by the learned policies, we present a method, formulated as the problem of finding an optimal set of parameters in the high-level model, to automatically update the subtask specifications to account for the observed shortcomings. The result is an iterative procedure for defining subtask specifications, and for training the subsystems to meet them. Experimental results demonstrate the presented framework's novel capabilities in environments with both full and partial observability, discrete and continuous state and action spaces, as well as deterministic and stochastic dynamics.", "url": "https://arxiv.org/abs/2309.06420"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

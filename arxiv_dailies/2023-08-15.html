<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.07445", "Date": "Mon, 14 Aug 2023 20:34:54 ", "Title": "Open-set Face Recognition using Ensembles trained on Clustered Data", "Authors": ["Rafael Henrique Vareto and William Robson Schwartz"], "Categories": "cs.CV cs.LG", "Comments": ["[Original paper title: Unconstrained Face Identification using Ensembles trained on Clustered Data] [2020 IEEE International Joint Conference on Biometrics (IJCB)] [https://ieeexplore.ieee.org/document/9304882]"], "DOI": "10.1109/IJCB48548.2020.9304882"}, "abstract": "Open-set face recognition describes a scenario where unknown subjects, unseen during the training stage, appear on test time. Not only it requires methods that accurately identify individuals of interest, but also demands approaches that effectively deal with unfamiliar faces. This work details a scalable open-set face identification approach to galleries composed of hundreds and thousands of subjects. It is composed of clustering and an ensemble of binary learning algorithms that estimates when query face samples belong to the face gallery and then retrieves their correct identity. The approach selects the most suitable gallery subjects and uses the ensemble to improve prediction performance. We carry out experiments on well-known LFW and YTF benchmarks. Results show that competitive performance can be achieved even when targeting scalability.", "url": "https://arxiv.org/abs/2308.07445"}, {"metadata": {"arXiv": "2308.07464", "Date": "Mon, 14 Aug 2023 21:21:03 ", "Title": "There Is a Digital Art History", "Authors": ["Leonardo Impett and Fabian Offert"], "Categories": "cs.CV cs.CY cs.LG"}, "abstract": "In this paper, we revisit Johanna Drucker's question, \"Is there a digital art history?\" -- posed exactly a decade ago -- in the light of the emergence of large-scale, transformer-based vision models. While more traditional types of neural networks have long been part of digital art history, and digital humanities projects have recently begun to use transformer models, their epistemic implications and methodological affordances have not yet been systematically analyzed. We focus our analysis on two main aspects that, together, seem to suggest a coming paradigm shift towards a \"digital\" art history in Drucker's sense. On the one hand, the visual-cultural repertoire newly encoded in large-scale vision models has an outsized effect on digital art history. The inclusion of significant numbers of non-photographic images allows for the extraction and automation of different forms of visual logics. Large-scale vision models have \"seen\" large parts of the Western visual canon mediated by Net visual culture, and they continuously solidify and concretize this canon through their already widespread application in all aspects of digital life. On the other hand, based on two technical case studies of utilizing a contemporary large-scale visual model to investigate basic questions from the fields of art history and urbanism, we suggest that such systems require a new critical methodology that takes into account the epistemic entanglement of a model and its applications. This new methodology reads its corpora through a neural model's training data, and vice versa: the visual ideologies of research datasets and training datasets become entangled.", "url": "https://arxiv.org/abs/2308.07464"}, {"metadata": {"arXiv": "2308.07571", "Date": "Tue, 15 Aug 2023 04:49:11 ", "Title": "Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition", "Authors": ["Dongqi Cai", "Yangyuxuan Kang", "Anbang Yao", "Yurong Chen"], "Categories": "cs.CV cs.LG", "Comments": ["The paper of Ske2Grid is published at ICML 2023. Code and models are available at https://github.com/OSVAI/Ske2Grid"]}, "abstract": "This paper presents Ske2Grid, a new representation learning framework for improved skeleton-based action recognition. In Ske2Grid, we define a regular convolution operation upon a novel grid representation of human skeleton, which is a compact image-like grid patch constructed and learned through three novel designs. Specifically, we propose a graph-node index transform (GIT) to construct a regular grid patch through assigning the nodes in the skeleton graph one by one to the desired grid cells. To ensure that GIT is a bijection and enrich the expressiveness of the grid representation, an up-sampling transform (UPT) is learned to interpolate the skeleton graph nodes for filling the grid patch to the full. To resolve the problem when the one-step UPT is aggressive and further exploit the representation capability of the grid patch with increasing spatial size, a progressive learning strategy (PLS) is proposed which decouples the UPT into multiple steps and aligns them to multiple paired GITs through a compact cascaded design learned progressively. We construct networks upon prevailing graph convolution networks and conduct experiments on six mainstream skeleton-based action recognition datasets. Experiments show that our Ske2Grid significantly outperforms existing GCN-based solutions under different benchmark settings, without bells and whistles. Code and models are available at https://github.com/OSVAI/Ske2Grid", "url": "https://arxiv.org/abs/2308.07571"}, {"metadata": {"arXiv": "2308.07625", "Date": "Tue, 15 Aug 2023 08:21:20 ", "Title": "Backpropagation Path Search On Adversarial Transferability", "Authors": ["Zhuoer Xu", "Zhangxuan Gu", "Jianping Zhang", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Deep neural networks are vulnerable to adversarial examples, dictating the imperativeness to test the model's robustness before deployment. Transfer-based attackers craft adversarial examples against surrogate models and transfer them to victim models deployed in the black-box situation. To enhance the adversarial transferability, structure-based attackers adjust the backpropagation path to avoid the attack from overfitting the surrogate model. However, existing structure-based attackers fail to explore the convolution module in CNNs and modify the backpropagation graph heuristically, leading to limited effectiveness. In this paper, we propose backPropagation pAth Search (PAS), solving the aforementioned two problems. We first propose SkipConv to adjust the backpropagation path of convolution by structural reparameterization. To overcome the drawback of heuristically designed backpropagation paths, we further construct a DAG-based search space, utilize one-step approximation for path evaluation and employ Bayesian Optimization to search for the optimal path. We conduct comprehensive experiments in a wide range of transfer settings, showing that PAS improves the attack success rate by a huge margin for both normally trained and defense models.", "url": "https://arxiv.org/abs/2308.07625"}, {"metadata": {"arXiv": "2308.07470", "Date": "Mon, 14 Aug 2023 21:46:37 ", "Title": "Symphony: Optimized Model Serving using Centralized Orchestration", "Authors": ["Lequn Chen", "Weixin Deng", "Anirudh Canumalla", "Yu Xin", "Matthai Philipose", "Arvind Krishnamurthy"], "Categories": "cs.DC cs.LG"}, "abstract": "The orchestration of deep neural network (DNN) model inference on GPU clusters presents two significant challenges: achieving high accelerator efficiency given the batching properties of model inference while meeting latency service level objectives (SLOs), and adapting to workload changes both in terms of short-term fluctuations and long-term resource allocation. To address these challenges, we propose Symphony, a centralized scheduling system that can scale to millions of requests per second and coordinate tens of thousands of GPUs. Our system utilizes a non-work-conserving scheduling algorithm capable of achieving high batch efficiency while also enabling robust autoscaling. Additionally, we developed an epoch-scale algorithm that allocates models to sub-clusters based on the compute and memory needs of the models. Through extensive experiments, we demonstrate that Symphony outperforms prior systems by up to 4.7x higher goodput.", "url": "https://arxiv.org/abs/2308.07470"}, {"metadata": {"arXiv": "2308.07359", "Date": "Mon, 14 Aug 2023 14:56:07 ", "Title": "Improving ICD-based semantic similarity by accounting for varying degrees of comorbidity", "Authors": ["Jan Janosch Schneider and Marius Adler and Christoph Ammer-Herrmenau and Alexander Otto K\\\"onig and Ulrich Sax and Jonas H\\\"ugel"], "Categories": "cs.LG cs.IR", "Comments": ["11 pages", "6 figures", "1 table"]}, "abstract": "Finding similar patients is a common objective in precision medicine, facilitating treatment outcome assessment and clinical decision support. Choosing widely-available patient features and appropriate mathematical methods for similarity calculations is crucial. International Statistical Classification of Diseases and Related Health Problems (ICD) codes are used worldwide to encode diseases and are available for nearly all patients. Aggregated as sets consisting of primary and secondary diagnoses they can display a degree of comorbidity and reveal comorbidity patterns. It is possible to compute the similarity of patients based on their ICD codes by using semantic similarity algorithms. These algorithms have been traditionally evaluated using a single-term expert rated data set. However, real-word patient data often display varying degrees of documented comorbidities that might impair algorithm performance. To account for this, we present a scale term that considers documented comorbidity-variance. In this work, we compared the performance of 80 combinations of established algorithms in terms of semantic similarity based on ICD-code sets. The sets have been extracted from patients with a C25.X (pancreatic cancer) primary diagnosis and provide a variety of different combinations of ICD-codes. Using our scale term we yielded the best results with a combination of level-based information content, Leacock & Chodorow concept similarity and bipartite graph matching for the set similarities reaching a correlation of 0.75 with our expert's ground truth. Our results highlight the importance of accounting for comorbidity variance while demonstrating how well current semantic similarity algorithms perform.", "url": "https://arxiv.org/abs/2308.07359"}, {"metadata": {"arXiv": "2308.07387", "Date": "Mon, 14 Aug 2023 18:09:58 ", "Title": "DISBELIEVE: Distance Between Client Models is Very Essential for Effective Local Model Poisoning Attacks", "Authors": ["Indu Joshi", "Priyank Upadhya", "Gaurav Kumar Nayak", "Peter Sch\\\"uffler and Nassir Navab"], "Categories": "cs.LG cs.CR cs.CV cs.DC", "Comments": ["Accepted by MICCAI 2023 - DeCaF"]}, "abstract": "Federated learning is a promising direction to tackle the privacy issues related to sharing patients' sensitive data. Often, federated systems in the medical image analysis domain assume that the participating local clients are \\textit{honest}. Several studies report mechanisms through which a set of malicious clients can be introduced that can poison the federated setup, hampering the performance of the global model. To overcome this, robust aggregation methods have been proposed that defend against those attacks. We observe that most of the state-of-the-art robust aggregation methods are heavily dependent on the distance between the parameters or gradients of malicious clients and benign clients, which makes them prone to local model poisoning attacks when the parameters or gradients of malicious and benign clients are close. Leveraging this, we introduce DISBELIEVE, a local model poisoning attack that creates malicious parameters or gradients such that their distance to benign clients' parameters or gradients is low respectively but at the same time their adverse effect on the global model's performance is high. Experiments on three publicly available medical image datasets demonstrate the efficacy of the proposed DISBELIEVE attack as it significantly lowers the performance of the state-of-the-art \\textit{robust aggregation} methods for medical image analysis. Furthermore, compared to state-of-the-art local model poisoning attacks, DISBELIEVE attack is also effective on natural images where we observe a severe drop in classification performance of the global model for multi-class classification on benchmark dataset CIFAR-10.", "url": "https://arxiv.org/abs/2308.07387"}, {"metadata": {"arXiv": "2308.07418", "Date": "Mon, 14 Aug 2023 19:12:40 ", "Title": "Locally Adaptive and Differentiable Regression", "Authors": ["Mingxuan Han", "Varun Shankar", "Jeff M Phillips", "Chenglong Ye"], "Categories": "cs.LG stat.ML"}, "abstract": "Over-parameterized models like deep nets and random forests have become very popular in machine learning. However, the natural goals of continuity and differentiability, common in regression models, are now often ignored in modern overparametrized, locally-adaptive models. We propose a general framework to construct a global continuous and differentiable model based on a weighted average of locally learned models in corresponding local regions. This model is competitive in dealing with data with different densities or scales of function values in different local regions. We demonstrate that when we mix kernel ridge and polynomial regression terms in the local models, and stitch them together continuously, we achieve faster statistical convergence in theory and improved performance in various practical settings.", "url": "https://arxiv.org/abs/2308.07418"}, {"metadata": {"arXiv": "2308.07421", "Date": "Mon, 14 Aug 2023 19:21:28 ", "Title": "U-Turn Diffusion", "Authors": ["Hamidreza Behjoo", "Michael Chertkov"], "Categories": "cs.LG cs.CV"}, "abstract": "We present a comprehensive examination of score-based diffusion models of AI for generating synthetic images. These models hinge upon a dynamic auxiliary time mechanism driven by stochastic differential equations, wherein the score function is acquired from input images. Our investigation unveils a criterion for evaluating efficiency of the score-based diffusion models: the power of the generative process depends on the ability to de-construct fast correlations during the reverse/de-noising phase. To improve the quality of the produced synthetic images, we introduce an approach coined \"U-Turn Diffusion\". The U-Turn Diffusion technique starts with the standard forward diffusion process, albeit with a condensed duration compared to conventional settings. Subsequently, we execute the standard reverse dynamics, initialized with the concluding configuration from the forward process. This U-Turn Diffusion procedure, combining forward, U-turn, and reverse processes, creates a synthetic image approximating an independent and identically distributed (i.i.d.) sample from the probability distribution implicitly described via input samples. To analyze relevant time scales we employ various analytical tools, including auto-correlation analysis, weighted norm of the score-function analysis, and Kolmogorov-Smirnov Gaussianity test. The tools guide us to establishing that the Kernel Intersection Distance, a metric comparing the quality of synthetic samples with real data samples, is minimized at the optimal U-turn time.", "url": "https://arxiv.org/abs/2308.07421"}, {"metadata": {"arXiv": "2308.07480", "Date": "Mon, 14 Aug 2023 22:17:33 ", "Title": "OCDaf: Ordered Causal Discovery with Autoregressive Flows", "Authors": ["Hamidreza Kamkari", "Vahid Zehtab", "Vahid Balazadeh", "Rahul G. Krishnan"], "Categories": "cs.LG stat.ME"}, "abstract": "We propose OCDaf, a novel order-based method for learning causal graphs from observational data. We establish the identifiability of causal graphs within multivariate heteroscedastic noise models, a generalization of additive noise models that allow for non-constant noise variances. Drawing upon the structural similarities between these models and affine autoregressive normalizing flows, we introduce a continuous search algorithm to find causal structures. Our experiments demonstrate state-of-the-art performance across the Sachs and SynTReN benchmarks in Structural Hamming Distance (SHD) and Structural Intervention Distance (SID). Furthermore, we validate our identifiability theory across various parametric and nonparametric synthetic datasets and showcase superior performance compared to existing baselines.", "url": "https://arxiv.org/abs/2308.07480"}, {"metadata": {"arXiv": "2308.07486", "Date": "Mon, 14 Aug 2023 22:36:27 ", "Title": "O-1: Self-training with Oracle and 1-best Hypothesis", "Authors": ["Murali Karthick Baskar", "Andrew Rosenberg", "Bhuvana Ramabhadran", "Kartik Audhkhasi"], "Categories": "cs.LG cs.CL cs.SD eess.AS"}, "abstract": "We introduce O-1, a new self-training objective to reduce training bias and unify training and evaluation metrics for speech recognition. O-1 is a faster variant of Expected Minimum Bayes Risk (EMBR), that boosts the oracle hypothesis and can accommodate both supervised and unsupervised data. We demonstrate the effectiveness of our approach in terms of recognition on publicly available SpeechStew datasets and a large-scale, in-house data set. On Speechstew, the O-1 objective closes the gap between the actual and oracle performance by 80\\% relative compared to EMBR which bridges the gap by 43\\% relative. O-1 achieves 13\\% to 25\\% relative improvement over EMBR on the various datasets that SpeechStew comprises of, and a 12\\% relative gap reduction with respect to the oracle WER over EMBR training on the in-house dataset. Overall, O-1 results in a 9\\% relative improvement in WER over EMBR, thereby speaking to the scalability of the proposed objective for large-scale datasets.", "url": "https://arxiv.org/abs/2308.07486"}, {"metadata": {"arXiv": "2308.07505", "Date": "Tue, 15 Aug 2023 00:08:43 ", "Title": "Data Race Detection Using Large Language Models", "Authors": ["Le Chen", "Xianzhong Ding", "Murali Emani", "Tristan Vanderbruggen", "Pei-hung Lin", "Chuanhua Liao"], "Categories": "cs.LG cs.CL"}, "abstract": "Large language models (LLMs) are demonstrating significant promise as an alternate strategy to facilitate analyses and optimizations of high-performance computing programs, circumventing the need for resource-intensive manual tool creation. In this paper, we explore a novel LLM-based data race detection approach combining prompting engineering and fine-tuning techniques. We create a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with fine-grain labels showing the presence of data race pairs and their associated variables, line numbers, and read/write information. DRB-ML is then used to evaluate representative LLMs and fine-tune open-source ones. Our experiment shows that LLMs can be a viable approach to data race detection. However, they still cannot compete with traditional data race detection tools when we need detailed information about variable pairs causing data races.", "url": "https://arxiv.org/abs/2308.07505"}, {"metadata": {"arXiv": "2308.07511", "Date": "Tue, 15 Aug 2023 00:30:58 ", "Title": "Distilling Knowledge from Resource Management Algorithms to Neural Networks: A Unified Training Assistance Approach", "Authors": ["Longfei Ma", "Nan Cheng", "Xiucheng Wang", "Zhisheng Yin", "Haibo Zhou", "Wei Quan"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "As a fundamental problem, numerous methods are dedicated to the optimization of signal-to-interference-plus-noise ratio (SINR), in a multi-user setting. Although traditional model-based optimization methods achieve strong performance, the high complexity raises the research of neural network (NN) based approaches to trade-off the performance and complexity. To fully leverage the high performance of traditional model-based methods and the low complexity of the NN-based method, a knowledge distillation (KD) based algorithm distillation (AD) method is proposed in this paper to improve the performance and convergence speed of the NN-based method, where traditional SINR optimization methods are employed as ``teachers\" to assist the training of NNs, which are ``students\", thus enhancing the performance of unsupervised and reinforcement learning techniques. This approach aims to alleviate common issues encountered in each of these training paradigms, including the infeasibility of obtaining optimal solutions as labels and overfitting in supervised learning, ensuring higher convergence performance in unsupervised learning, and improving training efficiency in reinforcement learning. Simulation results demonstrate the enhanced performance of the proposed AD-based methods compared to traditional learning methods. Remarkably, this research paves the way for the integration of traditional optimization insights and emerging NN techniques in wireless communication system optimization.", "url": "https://arxiv.org/abs/2308.07511"}, {"metadata": {"arXiv": "2308.07527", "Date": "Tue, 15 Aug 2023 01:48:11 ", "Title": "FeatGeNN: Improving Model Performance for Tabular Data with Correlation-based Feature Extraction", "Authors": ["Sammuel Ramos Silva and Rodrigo Silva"], "Categories": "cs.LG cs.NE"}, "abstract": "Automated Feature Engineering (AutoFE) has become an important task for any machine learning project, as it can help improve model performance and gain more information for statistical analysis. However, most current approaches for AutoFE rely on manual feature creation or use methods that can generate a large number of features, which can be computationally intensive and lead to overfitting. To address these challenges, we propose a novel convolutional method called FeatGeNN that extracts and creates new features using correlation as a pooling function. Unlike traditional pooling functions like max-pooling, correlation-based pooling considers the linear relationship between the features in the data matrix, making it more suitable for tabular data. We evaluate our method on various benchmark datasets and demonstrate that FeatGeNN outperforms existing AutoFE approaches regarding model performance. Our results suggest that correlation-based pooling can be a promising alternative to max-pooling for AutoFE in tabular data applications.", "url": "https://arxiv.org/abs/2308.07527"}, {"metadata": {"arXiv": "2308.07553", "Date": "Tue, 15 Aug 2023 03:46:41 ", "Title": "Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks", "Authors": ["Shijie Liu", "Andrew C. Cullen", "Paul Montague", "Sarah M. Erfani", "Benjamin I. P. Rubinstein"], "Categories": "cs.LG cs.CR", "Journal-ref": "Proceedings of the 2023 AAAI Conference on Artificial Intelligence, 37(7), 8861-8869", "DOI": "10.1609/aaai.v37i7.26065"}, "abstract": "Poisoning attacks can disproportionately influence model behaviour by making small changes to the training corpus. While defences against specific poisoning attacks do exist, they in general do not provide any guarantees, leaving them potentially countered by novel attacks. In contrast, by examining worst-case behaviours Certified Defences make it possible to provide guarantees of the robustness of a sample against adversarial attacks modifying a finite number of training samples, known as pointwise certification. We achieve this by exploiting both Differential Privacy and the Sampled Gaussian Mechanism to ensure the invariance of prediction for each testing instance against finite numbers of poisoned examples. In doing so, our model provides guarantees of adversarial robustness that are more than twice as large as those provided by prior certifications.", "url": "https://arxiv.org/abs/2308.07553"}, {"metadata": {"arXiv": "2308.07562", "Date": "Tue, 15 Aug 2023 04:09:53 ", "Title": "Semi-Supervised Learning with Multiple Imputations on Non-Random Missing Labels", "Authors": ["Jason Lu", "Michael Ma", "Huaze Xu", "Zixi Xu"], "Categories": "cs.LG", "Comments": ["8 pages"]}, "abstract": "Semi-Supervised Learning (SSL) is implemented when algorithms are trained on both labeled and unlabeled data. This is a very common application of ML as it is unrealistic to obtain a fully labeled dataset. Researchers have tackled three main issues: missing at random (MAR), missing completely at random (MCAR), and missing not at random (MNAR). The MNAR problem is the most challenging of the three as one cannot safely assume that all class distributions are equal. Existing methods, including Class-Aware Imputation (CAI) and Class-Aware Propensity (CAP), mostly overlook the non-randomness in the unlabeled data. This paper proposes two new methods of combining multiple imputation models to achieve higher accuracy and less bias. 1) We use multiple imputation models, create confidence intervals, and apply a threshold to ignore pseudo-labels with low confidence. 2) Our new method, SSL with De-biased Imputations (SSL-DI), aims to reduce bias by filtering out inaccurate data and finding a subset that is accurate and reliable. This subset of the larger dataset could be imputed into another SSL model, which will be less biased. The proposed models have been shown to be effective in both MCAR and MNAR situations, and experimental results show that our methodology outperforms existing methods in terms of classification accuracy and reducing bias.", "url": "https://arxiv.org/abs/2308.07562"}, {"metadata": {"arXiv": "2308.07588", "Date": "Tue, 15 Aug 2023 06:19:31 ", "Title": "High-Probability Risk Bounds via Sequential Predictors", "Authors": ["Dirk van der Hoeven", "Nikita Zhivotovskiy", "Nicol\\`o Cesa-Bianchi"], "Categories": "cs.LG cs.IT math.IT math.ST stat.TH", "Comments": ["24 pages"]}, "abstract": "Online learning methods yield sequential regret bounds under minimal assumptions and provide in-expectation risk bounds for statistical learning. However, despite the apparent advantage of online guarantees over their statistical counterparts, recent findings indicate that in many important cases, regret bounds may not guarantee tight high-probability risk bounds in the statistical setting. In this work we show that online to batch conversions applied to general online learning algorithms can bypass this limitation. Via a general second-order correction to the loss function defining the regret, we obtain nearly optimal high-probability risk bounds for several classical statistical estimation problems, such as discrete distribution estimation, linear regression, logistic regression, and conditional density estimation. Our analysis relies on the fact that many online learning algorithms are improper, as they are not restricted to use predictors from a given reference class. The improper nature of our estimators enables significant improvements in the dependencies on various problem parameters. Finally, we discuss some computational advantages of our sequential algorithms over their existing batch counterparts.", "url": "https://arxiv.org/abs/2308.07588"}, {"metadata": {"arXiv": "2308.07616", "Date": "Tue, 15 Aug 2023 07:53:18 ", "Title": "A Multilayer Perceptron-based Fast Sunlight Assessment for the Conceptual Design of Residential Neighborhoods under Chinese Policy", "Authors": ["Can Jiang", "Xiong Liang", "Yu-Cheng Zhou", "Yong Tian", "Shengli Xu", "Jia-Rui Lin", "Zhiliang Ma", "Shiji Yang", "Hao Zhou"], "Categories": "cs.LG cs.CY"}, "abstract": "In Chinese building codes, it is required that residential buildings receive a minimum number of hours of natural, direct sunlight on a specified winter day, which represents the worst sunlight condition in a year. This requirement is a prerequisite for obtaining a building permit during the conceptual design of a residential project. Thus, officially sanctioned software is usually used to assess the sunlight performance of buildings. These software programs predict sunlight hours based on repeated shading calculations, which is time-consuming. This paper proposed a multilayer perceptron-based method, a one-stage prediction approach, which outputs a shading time interval caused by the inputted cuboid-form building. The sunlight hours of a site can be obtained by calculating the union of the sunlight time intervals (complement of shading time interval) of all the buildings. Three numerical experiments, i.e., horizontal level and slope analysis, and simulation-based optimization are carried out; the results show that the method reduces the computation time to 1/84~1/50 with 96.5%~98% accuracies. A residential neighborhood layout planning plug-in for Rhino 7/Grasshopper is also developed based on the proposed model. This paper indicates that deep learning techniques can be adopted to accelerate sunlight hour simulations at the conceptual design phase.", "url": "https://arxiv.org/abs/2308.07616"}, {"metadata": {"arXiv": "2308.07661", "Date": "Tue, 15 Aug 2023 09:24:38 ", "Title": "Attention Is Not All You Need Anymore", "Authors": ["Zhe Chen"], "Categories": "cs.LG cs.CL cs.NE"}, "abstract": "In recent years, the popular Transformer architecture has achieved great success in many application areas, including natural language processing and computer vision. Many existing works aim to reduce the computational and memory complexity of the self-attention mechanism in the Transformer by trading off performance. However, performance is key for the continuing success of the Transformer. In this paper, a drop-in replacement for the self-attention mechanism in the Transformer, called the Extractor, is proposed. Experimental results show that replacing the self-attention mechanism with the Extractor improves the performance of the Transformer. Furthermore, the proposed Extractor has the potential to run faster than the self-attention since it has a much shorter critical path of computation. Additionally, the sequence prediction problem in the context of text generation is formulated using variable-length discrete-time Markov chains, and the Transformer is reviewed based on our understanding.", "url": "https://arxiv.org/abs/2308.07661"}, {"metadata": {"arXiv": "2308.07662", "Date": "Tue, 15 Aug 2023 09:25:11 ", "Title": "Gradient-Based Post-Training Quantization: Challenging the Status Quo", "Authors": ["Edouard Yvinec", "Arnaud Dapogny and Kevin Bailly"], "Categories": "cs.LG cs.CV"}, "abstract": "Quantization has become a crucial step for the efficient deployment of deep neural networks, where floating point operations are converted to simpler fixed point operations. In its most naive form, it simply consists in a combination of scaling and rounding transformations, leading to either a limited compression rate or a significant accuracy drop. Recently, Gradient-based post-training quantization (GPTQ) methods appears to be constitute a suitable trade-off between such simple methods and more powerful, yet expensive Quantization-Aware Training (QAT) approaches, particularly when attempting to quantize LLMs, where scalability of the quantization process is of paramount importance. GPTQ essentially consists in learning the rounding operation using a small calibration set. In this work, we challenge common choices in GPTQ methods. In particular, we show that the process is, to a certain extent, robust to a number of variables (weight selection, feature augmentation, choice of calibration set). More importantly, we derive a number of best practices for designing more efficient and scalable GPTQ methods, regarding the problem formulation (loss, degrees of freedom, use of non-uniform quantization schemes) or optimization process (choice of variable and optimizer). Lastly, we propose a novel importance-based mixed-precision technique. Those guidelines lead to significant performance improvements on all the tested state-of-the-art GPTQ methods and networks (e.g. +6.819 points on ViT for 4-bit quantization), paving the way for the design of scalable, yet effective quantization methods.", "url": "https://arxiv.org/abs/2308.07662"}, {"metadata": {"arXiv": "2308.07707", "Date": "Tue, 15 Aug 2023 11:30:45 ", "Title": "Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening", "Authors": ["Jack Foster", "Stefan Schoepf", "Alexandra Brintrup"], "Categories": "cs.LG"}, "abstract": "Machine unlearning, the ability for a machine learning model to forget, is becoming increasingly important to comply with data privacy regulations, as well as to remove harmful, manipulated, or outdated information. The key challenge lies in forgetting specific information while protecting model performance on the remaining data. While current state-of-the-art methods perform well, they typically require some level of retraining over the retained data, in order to protect or restore model performance. This adds computational overhead and mandates that the training data remain available and accessible, which may not be feasible. In contrast, other methods employ a retrain-free paradigm, however, these approaches are prohibitively computationally expensive and do not perform on par with their retrain-based counterparts. We present Selective Synaptic Dampening (SSD), a novel two-step, post hoc, retrain-free approach to machine unlearning which is fast, performant, and does not require long-term storage of the training data. First, SSD uses the Fisher information matrix of the training and forgetting data to select parameters that are disproportionately important to the forget set. Second, SSD induces forgetting by dampening these parameters proportional to their relative importance to the forget set with respect to the wider training data. We evaluate our method against several existing unlearning methods in a range of experiments using ResNet18 and Vision Transformer. Results show that the performance of SSD is competitive with retrain-based post hoc methods, demonstrating the viability of retrain-free post hoc unlearning approaches.", "url": "https://arxiv.org/abs/2308.07707"}, {"metadata": {"arXiv": "2308.07728", "Date": "Tue, 15 Aug 2023 12:08:43 ", "Title": "Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability", "Authors": ["Seokhyeon Ha", "Sunbeom Jung", "Jungwoo Lee"], "Categories": "cs.LG"}, "abstract": "Fine-tuning pre-trained neural network models has become a widely adopted approach across various domains. However, it can lead to the distortion of pre-trained feature extractors that already possess strong generalization capabilities. Mitigating feature distortion during adaptation to new target domains is crucial. Recent studies have shown promising results in handling feature distortion by aligning the head layer on in-distribution datasets before performing fine-tuning. Nonetheless, a significant limitation arises from the treatment of batch normalization layers during fine-tuning, leading to suboptimal performance. In this paper, we propose Domain-Aware Fine-Tuning (DAFT), a novel approach that incorporates batch normalization conversion and the integration of linear probing and fine-tuning. Our batch normalization conversion method effectively mitigates feature distortion by reducing modifications to the neural network during fine-tuning. Additionally, we introduce the integration of linear probing and fine-tuning to optimize the head layer with gradual adaptation of the feature extractor. By leveraging batch normalization layers and integrating linear probing and fine-tuning, our DAFT significantly mitigates feature distortion and achieves improved model performance on both in-distribution and out-of-distribution datasets. Extensive experiments demonstrate that our method outperforms other baseline methods, demonstrating its effectiveness in not only improving performance but also mitigating feature distortion.", "url": "https://arxiv.org/abs/2308.07728"}, {"metadata": {"arXiv": "2308.07817", "Date": "Tue, 15 Aug 2023 14:50:12 ", "Title": "Quantifying the Cost of Learning in Queueing Systems", "Authors": ["Daniel Freund", "Thodoris Lykouris", "Wentao Weng"], "Categories": "cs.LG cs.DS cs.PF math.PR"}, "abstract": "Queueing systems are widely applicable stochastic models with use cases in communication networks, healthcare, service systems, etc. Although their optimal control has been extensively studied, most existing approaches assume perfect knowledge of system parameters. Of course, this assumption rarely holds in practice where there is parameter uncertainty, thus motivating a recent line of work on bandit learning for queueing systems. This nascent stream of research focuses on the asymptotic performance of the proposed algorithms. In this paper, we argue that an asymptotic metric, which focuses on late-stage performance, is insufficient to capture the intrinsic statistical complexity of learning in queueing systems which typically occurs in the early stage. Instead, we propose the Cost of Learning in Queueing (CLQ), a new metric that quantifies the maximum increase in time-averaged queue length caused by parameter uncertainty. We characterize the CLQ of a single-queue multi-server system, and then extend these results to multi-queue multi-server systems and networks of queues. In establishing our results, we propose a unified analysis framework for CLQ that bridges Lyapunov and bandit analysis, which could be of independent interest.", "url": "https://arxiv.org/abs/2308.07817"}, {"metadata": {"arXiv": "2308.07822", "Date": "Tue, 15 Aug 2023 14:56:37 ", "Title": "Deep reinforcement learning for process design: Review and perspective", "Authors": ["Qinghe Gao and Artur M. Schweidtmann"], "Categories": "cs.LG"}, "abstract": "The transformation towards renewable energy and feedstock supply in the chemical industry requires new conceptual process design approaches. Recently, breakthroughs in artificial intelligence offer opportunities to accelerate this transition. Specifically, deep reinforcement learning, a subclass of machine learning, has shown the potential to solve complex decision-making problems and aid sustainable process design. We survey state-of-the-art research in reinforcement learning for process design through three major elements: (i) information representation, (ii) agent architecture, and (iii) environment and reward. Moreover, we discuss perspectives on underlying challenges and promising future works to unfold the full potential of reinforcement learning for process design in chemical engineering.", "url": "https://arxiv.org/abs/2308.07822"}, {"metadata": {"arXiv": "2308.07824", "Date": "Tue, 15 Aug 2023 15:07:32 ", "Title": "Cerberus: A Deep Learning Hybrid Model for Lithium-Ion Battery Aging Estimation and Prediction Based on Relaxation Voltage Curves", "Authors": ["Yue Xiang", "Bo Jiang", "Haifeng Dai"], "Categories": "cs.LG", "Comments": ["3 figures", "1 table", "9 pages"]}, "abstract": "The degradation process of lithium-ion batteries is intricately linked to their entire lifecycle as power sources and energy storage devices, encompassing aspects such as performance delivery and cycling utilization. Consequently, the accurate and expedient estimation or prediction of the aging state of lithium-ion batteries has garnered extensive attention. Nonetheless, prevailing research predominantly concentrates on either aging estimation or prediction, neglecting the dynamic fusion of both facets. This paper proposes a hybrid model for capacity aging estimation and prediction based on deep learning, wherein salient features highly pertinent to aging are extracted from charge and discharge relaxation processes. By amalgamating historical capacity decay data, the model dynamically furnishes estimations of the present capacity and forecasts of future capacity for lithium-ion batteries. Our approach is validated against a novel dataset involving charge and discharge cycles at varying rates. Specifically, under a charging condition of 0.25C, a mean absolute percentage error (MAPE) of 0.29% is achieved. This outcome underscores the model's adeptness in harnessing relaxation processes commonly encountered in the real world and synergizing with historical capacity records within battery management systems (BMS), thereby affording estimations and prognostications of capacity decline with heightened precision.", "url": "https://arxiv.org/abs/2308.07824"}, {"metadata": {"arXiv": "2308.07834", "Date": "Tue, 15 Aug 2023 15:23:36 ", "Title": "Simple and Efficient Partial Graph Adversarial Attack: A New Perspective", "Authors": ["Guanghui Zhu", "Mengyu Chen", "Chunfeng Yuan", "and Yihua Huang"], "Categories": "cs.LG cs.CR"}, "abstract": "As the study of graph neural networks becomes more intensive and comprehensive, their robustness and security have received great research interest. The existing global attack methods treat all nodes in the graph as their attack targets. Although existing methods have achieved excellent results, there is still considerable space for improvement. The key problem is that the current approaches rigidly follow the definition of global attacks. They ignore an important issue, i.e., different nodes have different robustness and are not equally resilient to attacks. From a global attacker's view, we should arrange the attack budget wisely, rather than wasting them on highly robust nodes. To this end, we propose a totally new method named partial graph attack (PGA), which selects the vulnerable nodes as attack targets. First, to select the vulnerable items, we propose a hierarchical target selection policy, which allows attackers to only focus on easy-to-attack nodes. Then, we propose a cost-effective anchor-picking policy to pick the most promising anchors for adding or removing edges, and a more aggressive iterative greedy-based attack method to perform more efficient attacks. Extensive experimental results demonstrate that PGA can achieve significant improvements in both attack effect and attack efficiency compared to other existing graph global attack methods.", "url": "https://arxiv.org/abs/2308.07834"}, {"metadata": {"arXiv": "2308.07843", "Date": "Tue, 15 Aug 2023 15:43:12 ", "Title": "Dyadic Reinforcement Learning", "Authors": ["Shuangning Li", "Lluis Salvat Niell", "Sung Won Choi", "Inbal Nahum-Shani", "Guy Shani", "Susan Murphy"], "Categories": "cs.LG stat.AP stat.ML"}, "abstract": "Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation studies on both toy scenarios and on a realistic test bed constructed from data collected in a mobile health study.", "url": "https://arxiv.org/abs/2308.07843"}, {"metadata": {"arXiv": "2308.07886", "Date": "Tue, 15 Aug 2023 17:23:18 ", "Title": "Back to Basics: A Sanity Check on Modern Time Series Classification Algorithms", "Authors": ["Bhaskar Dhariyal", "Thach Le Nguyen", "Georgiana Ifrim"], "Categories": "cs.LG"}, "abstract": "The state-of-the-art in time series classification has come a long way, from the 1NN-DTW algorithm to the ROCKET family of classifiers. However, in the current fast-paced development of new classifiers, taking a step back and performing simple baseline checks is essential. These checks are often overlooked, as researchers are focused on establishing new state-of-the-art results, developing scalable algorithms, and making models explainable. Nevertheless, there are many datasets that look like time series at first glance, but classic algorithms such as tabular methods with no time ordering may perform better on such problems. For example, for spectroscopy datasets, tabular methods tend to significantly outperform recent time series methods. In this study, we compare the performance of tabular models using classic machine learning approaches (e.g., Ridge, LDA, RandomForest) with the ROCKET family of classifiers (e.g., Rocket, MiniRocket, MultiRocket). Tabular models are simple and very efficient, while the ROCKET family of classifiers are more complex and have state-of-the-art accuracy and efficiency among recent time series classifiers. We find that tabular models outperform the ROCKET family of classifiers on approximately 19% of univariate and 28% of multivariate datasets in the UCR/UEA benchmark and achieve accuracy within 10 percentage points on about 50% of datasets. Our results suggest that it is important to consider simple tabular models as baselines when developing time series classifiers. These models are very fast, can be as effective as more complex methods and may be easier to understand and deploy.", "url": "https://arxiv.org/abs/2308.07886"}, {"metadata": {"arXiv": "2308.07899", "Date": "Tue, 15 Aug 2023 17:40:10 ", "Title": "The Regular Expression Inference Challenge", "Authors": ["Mojtaba Valizadeh", "Philip John Gorinski", "Ignacio Iacobacci", "Martin Berger"], "Categories": "cs.LG cs.CL cs.FL", "Comments": ["7 pages", "3 pages appendix", "6 tables"]}, "abstract": "We propose \\emph{regular expression inference (REI)} as a challenge for code/language modelling, and the wider machine learning community. REI is a supervised machine learning (ML) and program synthesis task, and poses the problem of finding minimal regular expressions from examples: Given two finite sets of strings $P$ and $N$ and a cost function $\\text{cost}(\\cdot)$, the task is to generate an expression $r$ that accepts all strings in $P$ and rejects all strings in $N$, while no other such expression $r'$ exists with $\\text{cost}(r')<\\text{cost}(r)$. REI has advantages as a challenge problem: (i) regular expressions are well-known, widely used, and a natural idealisation of code; (ii) REI's asymptotic worst-case complexity is well understood; (iii) REI has a small number of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string lengths of examples, or the cost function); this lets us easily finetune REI-hardness; (iv) REI is an unsolved problem for deep learning based ML. Recently, an REI solver was implemented on GPUs, using program synthesis techniques. This enabled, for the first time, fast generation of minimal expressions for complex REI instances. Building on this advance, we generate and publish the first large-scale datasets for REI, and devise and evaluate several initial heuristic and machine learning baselines. We invite the community to participate and explore ML methods that learn to solve REI problems. We believe that progress in REI directly translates to code/language modelling.", "url": "https://arxiv.org/abs/2308.07899"}, {"metadata": {"arXiv": "2308.07491", "Date": "Mon, 14 Aug 2023 22:58:54 ", "Title": "Adaptive Tracking of a Single-Rigid-Body Character in Various Environments", "Authors": ["Taesoo Kwon", "Taehong Gu", "Jaewon Ahn", "Yoonsang Lee"], "Categories": "cs.RO cs.GR cs.LG"}, "abstract": "Since the introduction of DeepMimic [Peng et al. 2018], subsequent research has focused on expanding the repertoire of simulated motions across various scenarios. In this study, we propose an alternative approach for this goal, a deep reinforcement learning method based on the simulation of a single-rigid-body character. Using the centroidal dynamics model (CDM) to express the full-body character as a single rigid body (SRB) and training a policy to track a reference motion, we can obtain a policy that is capable of adapting to various unobserved environmental changes and controller transitions without requiring any additional learning. Due to the reduced dimension of state and action space, the learning process is sample-efficient. The final full-body motion is kinematically generated in a physically plausible way, based on the state of the simulated SRB character. The SRB simulation is formulated as a quadratic programming (QP) problem, and the policy outputs an action that allows the SRB character to follow the reference motion. We demonstrate that our policy, efficiently trained within 30 minutes on an ultraportable laptop, has the ability to cope with environments that have not been experienced during learning, such as running on uneven terrain or pushing a box, and transitions between learned policies, without any additional learning.", "url": "https://arxiv.org/abs/2308.07491"}, {"metadata": {"arXiv": "2308.07741", "Date": "Tue, 15 Aug 2023 12:40:56 ", "Title": "Real Robot Challenge 2022: Learning Dexterous Manipulation from Offline Data in the Real World", "Authors": ["Nico G\\\"urtler", "Felix Widmaier", "Cansu Sancaktar", "Sebastian Blaes", "Pavel Kolev", "Stefan Bauer", "Manuel W\\\"uthrich", "Markus Wulfmeier", "Martin Riedmiller", "Arthur Allshire", "Qiang Wang", "Robert McCarthy", "Hangyeol Kim", "Jongchan Baek Pohang", "Wookyong Kwon", "Shanliang Qian", "Yasunori Toshimitsu", "Mike Yan Michelis", "Amirhossein Kazemipour", "Arman Raayatsanati", "Hehui Zheng", "Barnabasa Gavin Cangan", "Bernhard Sch\\\"olkopf", "Georg Martius"], "Categories": "cs.RO cs.LG"}, "abstract": "Experimentation on real robots is demanding in terms of time and costs. For this reason, a large part of the reinforcement learning (RL) community uses simulators to develop and benchmark algorithms. However, insights gained in simulation do not necessarily translate to real robots, in particular for tasks involving complex interactions with the environment. The Real Robot Challenge 2022 therefore served as a bridge between the RL and robotics communities by allowing participants to experiment remotely with a real robot - as easily as in simulation. In the last years, offline reinforcement learning has matured into a promising paradigm for learning from pre-collected datasets, alleviating the reliance on expensive online interactions. We therefore asked the participants to learn two dexterous manipulation tasks involving pushing, grasping, and in-hand orientation from provided real-robot datasets. An extensive software documentation and an initial stage based on a simulation of the real set-up made the competition particularly accessible. By giving each team plenty of access budget to evaluate their offline-learned policies on a cluster of seven identical real TriFinger platforms, we organized an exciting competition for machine learners and roboticists alike. In this work we state the rules of the competition, present the methods used by the winning teams and compare their results with a benchmark of state-of-the-art offline RL algorithms on the challenge datasets.", "url": "https://arxiv.org/abs/2308.07741"}, {"metadata": {"arXiv": "2308.07797", "Date": "Tue, 15 Aug 2023 14:21:53 ", "Title": "Adaptive Noise Covariance Estimation under Colored Noise using Dynamic Expectation Maximization", "Authors": ["Ajith Anil Meera and Pablo Lanillos"], "Categories": "eess.SY cs.LG cs.RO cs.SY", "Comments": ["62nd IEEE Conference on Decision and Control"]}, "abstract": "The accurate estimation of the noise covariance matrix (NCM) in a dynamic system is critical for state estimation and control, as it has a major influence in their optimality. Although a large number of NCM estimation methods have been developed, most of them assume the noises to be white. However, in many real-world applications, the noises are colored (e.g., they exhibit temporal autocorrelations), resulting in suboptimal solutions. Here, we introduce a novel brain-inspired algorithm that accurately and adaptively estimates the NCM for dynamic systems subjected to colored noise. Particularly, we extend the Dynamic Expectation Maximization algorithm to perform both online noise covariance and state estimation by optimizing the free energy objective. We mathematically prove that our NCM estimator converges to the global optimum of this free energy objective. Using randomized numerical simulations, we show that our estimator outperforms nine baseline methods with minimal noise covariance estimation error under colored noise conditions. Notably, we show that our method outperforms the best baseline (Variational Bayes) in joint noise and state estimation for high colored noise. We foresee that the accuracy and the adaptive nature of our estimator make it suitable for online estimation in real-world applications.", "url": "https://arxiv.org/abs/2308.07797"}, {"metadata": {"arXiv": "2308.07867", "Date": "Tue, 15 Aug 2023 16:34:37 ", "Title": "Graph-Structured Kernel Design for Power Flow Learning using Gaussian Processes", "Authors": ["Parikshit Pareek", "Deepjyoti Deka", "and Sidhant Misra"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["10 pages"]}, "abstract": "This paper presents a physics-inspired graph-structured kernel designed for power flow learning using Gaussian Process (GP). The kernel, named the vertex-degree kernel (VDK), relies on latent decomposition of voltage-injection relationship based on the network graph or topology. Notably, VDK design avoids the need to solve optimization problems for kernel search. To enhance efficiency, we also explore a graph-reduction approach to obtain a VDK representation with lesser terms. Additionally, we propose a novel network-swipe active learning scheme, which intelligently selects sequential training inputs to accelerate the learning of VDK. Leveraging the additive structure of VDK, the active learning algorithm performs a block-descent type procedure on GP's predictive variance, serving as a proxy for information gain. Simulations demonstrate that the proposed VDK-GP achieves more than two fold sample complexity reduction, compared to full GP on medium scale 500-Bus and large scale 1354-Bus power systems. The network-swipe algorithm outperforms mean performance of 500 random trials on test predictions by two fold for medium-sized 500-Bus systems and best performance of 25 random trials for large-scale 1354-Bus systems by 10%. Moreover, we demonstrate that the proposed method's performance for uncertainty quantification applications with distributionally shifted testing data sets.", "url": "https://arxiv.org/abs/2308.07867"}, {"metadata": {"arXiv": "2308.07321", "Date": "Mon, 31 Jul 2023 22:45:38 ", "Title": "The Efficacy of Utility Functions for Multicriteria Hospital Case-Mix Planning", "Authors": ["Robert L Burdett", "Paul Corry", "Prasad Yarlagadda", "David Cook", "Sean Birgan"], "Categories": "cs.AI cs.CY", "Comments": ["35 pages", "6 tables", "29 figures"]}, "abstract": "A new approach to perform hospital case-mix planning (CMP) is introduced in this article. Our multi-criteria approach utilises utility functions (UF) to articulate the preferences and standpoint of independent decision makers regarding outputs. The primary aim of this article is to test whether a utility functions method (UFM) based upon the scalarization of aforesaid UF is an appropriate quantitative technique to, i) distribute hospital resources to different operating units, and ii) provide a better capacity allocation and case mix. Our approach is motivated by the need to provide a method able to evaluate the trade-off between different stakeholders and objectives of hospitals. To the best of our knowledge, no such approach has been considered before in the literature. As we will later show, this idea addresses various technical limitations, weaknesses, and flaws in current CMP. The efficacy of the aforesaid approach is tested on a case study of a large tertiary hospital. Currently UF are not used by hospital managers, and real functions are unavailable, hence, 14 rational options are tested. Our exploratory analysis has provided important guidelines for the application of these UF. It indicates that these UF provide a valuable starting point for planners, managers, and executives of hospitals to impose their goals and aspirations. In conclusion, our approach may be better at identifying case mix that users want to treat and seems more capable of modelling the varying importance of different levels of output. Apart from finding desirable case mixes to consider, the approach can provide important insights via a sensitivity analysis of the parameters of each UF.", "url": "https://arxiv.org/abs/2308.07321"}, {"metadata": {"arXiv": "2308.07322", "Date": "Mon, 31 Jul 2023 22:55:48 ", "Title": "Multicriteria Optimization Techniques for Understanding the Case Mix Landscape of a Hospital", "Authors": ["Robert L Burdett", "Paul Corry", "Prasad Yarlagadda", "David Cook", "Sean Birgan"], "Categories": "cs.AI", "Comments": ["38 pages", "17 figures", "11 tables"]}, "abstract": "Various medical and surgical units operate in a typical hospital and to treat their patients these units compete for infrastructure like operating rooms (OR) and ward beds. How that competition is regulated affects the capacity and output of a hospital. This article considers the impact of treating different patient case mix (PCM) in a hospital. As each case mix has an economic consequence and a unique profile of hospital resource usage, this consideration is important. To better understand the case mix landscape and to identify those which are optimal from a capacity utilisation perspective, an improved multicriteria optimization (MCO) approach is proposed. As there are many patient types in a typical hospital, the task of generating an archive of non-dominated (i.e., Pareto optimal) case mix is computationally challenging. To generate a better archive, an improved parallelised epsilon constraint method (ECM) is introduced. Our parallel random corrective approach is significantly faster than prior methods and is not restricted to evaluating points on a structured uniform mesh. As such we can generate more solutions. The application of KD-Trees is another new contribution. We use them to perform proximity testing and to store the high dimensional Pareto frontier (PF). For generating, viewing, navigating, and querying an archive, the development of a suitable decision support tool (DST) is proposed and demonstrated.", "url": "https://arxiv.org/abs/2308.07322"}, {"metadata": {"arXiv": "2308.07323", "Date": "Mon, 31 Jul 2023 22:59:34 ", "Title": "Analytical Techniques to Support Hospital Case Mix Planning", "Authors": ["Robert L Burdett", "Paul corry", "David Cook", "Prasad Yarlagadda"], "Categories": "cs.AI cs.CY", "Comments": ["20 pages", "11 tables", "6 figures"]}, "abstract": "This article introduces analytical techniques and a decision support tool to support capacity assessment and case mix planning (CMP) approaches previously created for hospitals. First, an optimization model is proposed to analyse the impact of making a change to an existing case mix. This model identifies how other patient types should be altered proportionately to the changing levels of hospital resource availability. Then we propose multi-objective decision-making techniques to compare and critique competing case mix solutions obtained. The proposed techniques are embedded seamlessly within an Excel Visual Basic for Applications (VBA) personal decision support tool (PDST), for performing informative quantitative assessments of hospital capacity. The PDST reports informative metrics of difference and reports the impact of case mix modifications on the other types of patient present. The techniques developed in this article provide a bridge between theory and practice that is currently missing and provides further situational awareness around hospital capacity.", "url": "https://arxiv.org/abs/2308.07323"}, {"metadata": {"arXiv": "2308.07325", "Date": "Mon, 07 Aug 2023 12:39:42 ", "Title": "MSLE: An ontology for Materials Science Laboratory Equipment. Large-Scale Devices for Materials Characterization", "Authors": ["Mehrdad Jalali", "Matthias Mail", "Rossella Aversa", "and Christian K\\\"ubel"], "Categories": "cs.AI cond-mat.mtrl-sci", "Comments": ["Submitted to Materials Today Communication"]}, "abstract": "This paper introduces a new ontology for Materials Science Laboratory Equipment, termed MSLE. A fundamental issue with materials science laboratory (hereafter lab) equipment in the real world is that scientists work with various types of equipment with multiple specifications. For example, there are many electron microscopes with different parameters in chemical and physical labs. A critical development to unify the description is to build an equipment domain ontology as basic semantic knowledge and to guide the user to work with the equipment appropriately. Here, we propose to develop a consistent ontology for equipment, the MSLE ontology. In the MSLE, two main existing ontologies, the Semantic Sensor Network (SSN) and the Material Vocabulary (MatVoc), have been integrated into the MSLE core to build a coherent ontology. Since various acronyms and terms have been used for equipment, this paper proposes an approach to use a Simple Knowledge Organization System (SKOS) to represent the hierarchical structure of equipment terms. Equipment terms were collected in various languages and abbreviations and coded into the MSLE using the SKOS model. The ontology development was conducted in close collaboration with domain experts and focused on the large-scale devices for materials characterization available in our research group. Competency questions are expected to be addressed through the MSLE ontology. Constraints are modeled in the Shapes Query Language (SHACL); a prototype is shown and validated to show the value of the modeling constraints.", "url": "https://arxiv.org/abs/2308.07325"}, {"metadata": {"arXiv": "2308.07327", "Date": "Tue, 08 Aug 2023 13:54:48 ", "Title": "PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations", "Authors": ["Juho Kim"], "Categories": "cs.AI", "Comments": ["6 pages", "1 figure", "submission to IEEE Transactions on Games"]}, "abstract": "PokerKit is an open-source Python library designed to overcome the restrictions of existing poker game simulation and hand evaluation tools, which typically support only a handful of poker variants and lack flexibility in game state control. In contrast, PokerKit significantly expands this scope by supporting an extensive array of poker variants and it provides a flexible architecture for users to define their custom games. This paper details the design and implementation of PokerKit, including its intuitive programmatic API, multi-variant game support, and a unified hand evaluation suite across different hand types. The flexibility of PokerKit allows for applications in diverse areas, such as poker AI development, tool creation, and online poker casino implementation. PokerKit's reliability has been established through static type checking, extensive doctests, and unit tests, achieving 97\\% code coverage. The introduction of PokerKit represents a significant contribution to the field of computer poker, fostering future research and advanced AI development for a wide variety of poker games.", "url": "https://arxiv.org/abs/2308.07327"}, {"metadata": {"arXiv": "2308.07332", "Date": "Thu, 10 Aug 2023 07:41:01 ", "Title": "Notation3 as an Existential Rule Language", "Authors": ["D\\\"orthe Arndt and Stephan Mennicke"], "Categories": "cs.AI cs.LO"}, "abstract": "Notation3 Logic (\\nthree) is an extension of RDF that allows the user to write rules introducing new blank nodes to RDF graphs. Many applications (e.g., ontology mapping) rely on this feature as blank nodes -- used directly or in auxiliary constructs -- are omnipresent on the Web. However, the number of fast \\nthree reasoners covering this very important feature of the logic is rather limited. On the other hand, there are engines like VLog or Nemo which do not directly support Semantic Web rule formats but which are developed and optimized for very similar constructs: existential rules. In this paper, we investigate the relation between \\nthree rules with blank nodes in their heads and existential rules. We identify a subset of \\nthree which can be mapped directly to existential rules and define such a mapping preserving the equivalence of \\nthree formulae. In order to also illustrate that in some cases \\nthree reasoning could benefit from our translation, we then employ this mapping in an implementation to compare the performance of the \\nthree reasoners EYE and cwm to VLog and Nemo on \\nthree rules and their mapped counterparts. Our tests show that the existential rule reasoners perform particularly well for use cases containing many facts while especially the EYE reasoner is very fast when dealing with a high number of dependent rules. We thus provide a tool enabling the Semantic Web community to directly use existing and future existential rule reasoners and benefit from the findings of this active community.", "url": "https://arxiv.org/abs/2308.07332"}, {"metadata": {"arXiv": "2308.07347", "Date": "Sun, 13 Aug 2023 21:12:56 ", "Title": "A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman Problem", "Authors": ["Swetha Varadarajan and Darrell Whitley"], "Categories": "cs.AI cs.NE", "Comments": ["First submission was made to Europar", "2021. Paper Rejected"]}, "abstract": "The travelling salesman problem (TSP) is one of the well-studied NP-hard problems in the literature. The state-of-the art inexact TSP solvers are the Lin-Kernighan-Helsgaun (LKH) heuristic and Edge Assembly crossover (EAX). A recent study suggests that EAX with restart mechanisms perform well on a wide range of TSP instances. However, this study is limited to 2,000 city problems. We study for problems ranging from 2,000 to 85,900. We see that the performance of the solver varies with the type of the problem. However, combining these solvers in an ensemble setup, we are able to outperform the individual solver's performance. We see the ensemble setup as an efficient way to make use of the abundance of compute resources. In addition to EAX and LKH, we use several versions of the hybrid of EAX and Mixing Genetic Algorithm (MGA). A hybrid of MGA and EAX is known to solve some hard problems. We see that the ensemble of the hybrid version outperforms the state-of-the-art solvers on problems larger than 10,000 cities.", "url": "https://arxiv.org/abs/2308.07347"}, {"metadata": {"arXiv": "2308.07411", "Date": "Mon, 14 Aug 2023 18:58:00 ", "Title": "Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering", "Authors": ["Edward Junprung"], "Categories": "cs.AI cs.MA"}, "abstract": "The final frontier for simulation is the accurate representation of complex, real-world social systems. While agent-based modeling (ABM) seeks to study the behavior and interactions of agents within a larger system, it is unable to faithfully capture the full complexity of human-driven behavior. Large language models (LLMs), like ChatGPT, have emerged as a potential solution to this bottleneck by enabling researchers to explore human-driven interactions in previously unimaginable ways. Our research investigates simulations of human interactions using LLMs. Through prompt engineering, inspired by Park et al. (2023), we present two simulations of believable proxies of human behavior: a two-agent negotiation and a six-agent murder mystery game.", "url": "https://arxiv.org/abs/2308.07411"}, {"metadata": {"arXiv": "2308.07457", "Date": "Mon, 14 Aug 2023 21:01:00 ", "Title": "Artificial Intelligence for Smart Transportation", "Authors": ["Michael Wilbur", "Amutheezan Sivagnanam", "Afiya Ayman", "Samitha Samaranayeke", "Abhishek Dubey", "Aron Laszka"], "Categories": "cs.AI", "Comments": ["This is a pre-print for a book chapter to appear in Vorobeychik", "Yevgeniy.", "and Mukhopadhyay", "Ayan.", "(Eds.). (2023). Artificial Intelligence and Society. ACM Press"]}, "abstract": "There are more than 7,000 public transit agencies in the U.S. (and many more private agencies), and together, they are responsible for serving 60 billion passenger miles each year. A well-functioning transit system fosters the growth and expansion of businesses, distributes social and economic benefits, and links the capabilities of community members, thereby enhancing what they can accomplish as a society. Since affordable public transit services are the backbones of many communities, this work investigates ways in which Artificial Intelligence (AI) can improve efficiency and increase utilization from the perspective of transit agencies. This book chapter discusses the primary requirements, objectives, and challenges related to the design of AI-driven smart transportation systems. We focus on three major topics. First, we discuss data sources and data. Second, we provide an overview of how AI can aid decision-making with a focus on transportation. Lastly, we discuss computational problems in the transportation domain and AI approaches to these problems.", "url": "https://arxiv.org/abs/2308.07457"}, {"metadata": {"arXiv": "2308.07714", "Date": "Tue, 15 Aug 2023 11:47:16 ", "Title": "Flashpoints Signal Hidden Inherent Instabilities in Land-Use Planning", "Authors": ["Hazhir Aliahmadi", "Maeve Beckett", "Sam Connolly", "Dongmei Chen", "Greg van Anders"], "Categories": "cs.AI cond-mat.stat-mech physics.soc-ph", "Comments": ["9 pages", "5 figures"]}, "abstract": "Land-use decision-making processes have a long history of producing globally pervasive systemic equity and sustainability concerns. Quantitative, optimization-based planning approaches, e.g. Multi-Objective Land Allocation (MOLA), seemingly open the possibility to improve objectivity and transparency by explicitly evaluating planning priorities by the type, amount, and location of land uses. Here, we show that optimization-based planning approaches with generic planning criteria generate a series of unstable \"flashpoints\" whereby tiny changes in planning priorities produce large-scale changes in the amount of land use by type. We give quantitative arguments that the flashpoints we uncover in MOLA models are examples of a more general family of instabilities that occur whenever planning accounts for factors that coordinate use on- and between-sites, regardless of whether these planning factors are formulated explicitly or implicitly. We show that instabilities lead to regions of ambiguity in land-use type that we term \"gray areas\". By directly mapping gray areas between flashpoints, we show that quantitative methods retain utility by reducing combinatorially large spaces of possible land-use patterns to a small, characteristic set that can engage stakeholders to arrive at more efficient and just outcomes.", "url": "https://arxiv.org/abs/2308.07714"}, {"metadata": {"arXiv": "2308.07738", "Date": "Tue, 15 Aug 2023 12:33:58 ", "Title": "Formally-Sharp DAgger for MCTS: Lower-Latency Monte Carlo Tree Search using Data Aggregation with Formal Methods", "Authors": ["Debraj Chakraborty", "Damien Busatto-Gaston", "Jean-Fran\\c{c}ois Raskin and Guillermo A. P\\'erez"], "Categories": "cs.AI"}, "abstract": "We study how to efficiently combine formal methods, Monte Carlo Tree Search (MCTS), and deep learning in order to produce high-quality receding horizon policies in large Markov Decision processes (MDPs). In particular, we use model-checking techniques to guide the MCTS algorithm in order to generate offline samples of high-quality decisions on a representative set of states of the MDP. Those samples can then be used to train a neural network that imitates the policy used to generate them. This neural network can either be used as a guide on a lower-latency MCTS online search, or alternatively be used as a full-fledged policy when minimal latency is required. We use statistical model checking to detect when additional samples are needed and to focus those additional samples on configurations where the learnt neural network policy differs from the (computationally-expensive) offline policy. We illustrate the use of our method on MDPs that model the Frozen Lake and Pac-Man environments -- two popular benchmarks to evaluate reinforcement-learning algorithms.", "url": "https://arxiv.org/abs/2308.07738"}, {"metadata": {"arXiv": "2308.07779", "Date": "Tue, 15 Aug 2023 13:56:29 ", "Title": "Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing", "Authors": ["Chaoran Cui", "Hebo Ma", "Chen Zhang", "Chunyun Zhang", "Yumo Yao", "Meng Chen", "Yuling Ma"], "Categories": "cs.AI cs.CY", "Comments": ["13 pages"]}, "abstract": "Knowledge tracing (KT) aims to monitor students' evolving knowledge states through their learning interactions with concept-related questions, and can be indirectly evaluated by predicting how students will perform on future questions. In this paper, we observe that there is a common phenomenon of answer bias, i.e., a highly unbalanced distribution of correct and incorrect answers for each question. Existing models tend to memorize the answer bias as a shortcut for achieving high prediction performance in KT, thereby failing to fully understand students' knowledge states. To address this issue, we approach the KT task from a causality perspective. A causal graph of KT is first established, from which we identify that the impact of answer bias lies in the direct causal effect of questions on students' responses. A novel COunterfactual REasoning (CORE) framework for KT is further proposed, which separately captures the total causal effect and direct causal effect during training, and mitigates answer bias by subtracting the latter from the former in testing. The CORE framework is applicable to various existing KT models, and we implement it based on the prevailing DKT, DKVMN, and AKT models, respectively. Extensive experiments on three benchmark datasets demonstrate the effectiveness of CORE in making the debiased inference for KT.", "url": "https://arxiv.org/abs/2308.07779"}, {"metadata": {"arXiv": "2308.07889", "Date": "Tue, 15 Aug 2023 17:30:57 ", "Title": "A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning", "Authors": ["Long Jin", "Zhen Yao", "Mingyang Chen", "Huajun Chen", "Wen Zhang"], "Categories": "cs.AI cs.CL", "Comments": ["This paper is accepted by ISWC 2023"]}, "abstract": "Knowledge Graph Embedding (KGE) has proven to be an effective approach to solving the Knowledge Graph Completion (KGC) task. Relational patterns which refer to relations with specific semantics exhibiting graph patterns are an important factor in the performance of KGE models. Though KGE models' capabilities are analyzed over different relational patterns in theory and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency, and part-to-whole three aspects and get some counterintuitive conclusions. Finally, we introduce a training-free method Score-based Patterns Adaptation (SPA) to enhance KGE models' performance over various relational patterns. This approach is simple yet effective and can be applied to KGE models without additional training. Our experimental results demonstrate that our method generally enhances performance over specific relational patterns. Our source code is available from GitHub at https://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.", "url": "https://arxiv.org/abs/2308.07889"}, {"metadata": {"arXiv": "2308.07890", "Date": "Tue, 15 Aug 2023 17:31:35 ", "Title": "EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability", "Authors": ["Yiqi Zhao", "Ziyan An", "Meiyi Ma", "Taylor Johnson"], "Categories": "cs.AI cs.FL cs.LO"}, "abstract": "Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) are widely used in automated verification, but there is a lack of interactive tools designed for educational purposes in this field. To address this gap, we present EduSAT, a pedagogical tool specifically developed to support learning and understanding of SAT and SMT solving. EduSAT offers implementations of key algorithms such as the Davis-Putnam-Logemann-Loveland (DPLL) algorithm and the Reduced Order Binary Decision Diagram (ROBDD) for SAT solving. Additionally, EduSAT provides solver abstractions for five NP-complete problems beyond SAT and SMT. Users can benefit from EduSAT by experimenting, analyzing, and validating their understanding of SAT and SMT solving techniques. Our tool is accompanied by comprehensive documentation and tutorials, extensive testing, and practical features such as a natural language interface and SAT and SMT formula generators, which also serve as a valuable opportunity for learners to deepen their understanding. Our evaluation of EduSAT demonstrates its high accuracy, achieving 100% correctness across all the implemented SAT and SMT solvers. We release EduSAT as a python package in .whl file, and the source can be identified at https://github.com/zhaoy37/SAT_Solver.", "url": "https://arxiv.org/abs/2308.07890"}, {"metadata": {"arXiv": "2308.07391", "Date": "Mon, 14 Aug 2023 18:18:00 ", "Title": "PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects", "Authors": ["Jiayi Liu", "Ali Mahdavi-Amiri", "Manolis Savva"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Presented at ICCV 2023. Project website: https://3dlg-hcvc.github.io/paris/"]}, "abstract": "We address the task of simultaneous part-level reconstruction and motion parameter estimation for articulated objects. Given two sets of multi-view images of an object in two static articulation states, we decouple the movable part from the static part and reconstruct shape and appearance while predicting the motion parameters. To tackle this problem, we present PARIS: a self-supervised, end-to-end architecture that learns part-level implicit shape and appearance models and optimizes motion parameters jointly without any 3D supervision, motion, or semantic annotation. Our experiments show that our method generalizes better across object categories, and outperforms baselines and prior work that are given 3D point clouds as input. Our approach improves reconstruction relative to state-of-the-art baselines with a Chamfer-L1 distance reduction of 3.94 (45.2%) for objects and 26.79 (84.5%) for parts, and achieves 5% error rate for motion estimation across 10 object categories. Video summary at: https://youtu.be/tDSrROPCgUc", "url": "https://arxiv.org/abs/2308.07391"}, {"metadata": {"arXiv": "2308.07428", "Date": "Mon, 14 Aug 2023 19:49:29 ", "Title": "UniBrain: Unify Image Reconstruction and Captioning All in One Diffusion Model from Human Brain Activity", "Authors": ["Weijian Mai", "Zhijun Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Image reconstruction and captioning from brain activity evoked by visual stimuli allow researchers to further understand the connection between the human brain and the visual perception system. While deep generative models have recently been employed in this field, reconstructing realistic captions and images with both low-level details and high semantic fidelity is still a challenging problem. In this work, we propose UniBrain: Unify Image Reconstruction and Captioning All in One Diffusion Model from Human Brain Activity. For the first time, we unify image reconstruction and captioning from visual-evoked functional magnetic resonance imaging (fMRI) through a latent diffusion model termed Versatile Diffusion. Specifically, we transform fMRI voxels into text and image latent for low-level information and guide the backward diffusion process through fMRI-based image and text conditions derived from CLIP to generate realistic captions and images. UniBrain outperforms current methods both qualitatively and quantitatively in terms of image reconstruction and reports image captioning results for the first time on the Natural Scenes Dataset (NSD) dataset. Moreover, the ablation experiments and functional region-of-interest (ROI) analysis further exhibit the superiority of UniBrain and provide comprehensive insight for visual-evoked brain decoding.", "url": "https://arxiv.org/abs/2308.07428"}, {"metadata": {"arXiv": "2308.07444", "Date": "Mon, 14 Aug 2023 20:34:52 ", "Title": "The Performance of Transferability Metrics does not Translate to Medical Tasks", "Authors": ["Levy Chaves", "Alceu Bissoto", "Eduardo Valle", "Sandra Avila"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "3 figures. Accepted at the DART workshop @ MICCAI 2023"]}, "abstract": "Transfer learning boosts the performance of medical image analysis by enabling deep learning (DL) on small datasets through the knowledge acquired from large ones. As the number of DL architectures explodes, exhaustively attempting all candidates becomes unfeasible, motivating cheaper alternatives for choosing them. Transferability scoring methods emerge as an enticing solution, allowing to efficiently calculate a score that correlates with the architecture accuracy on any target dataset. However, since transferability scores have not been evaluated on medical datasets, their use in this context remains uncertain, preventing them from benefiting practitioners. We fill that gap in this work, thoroughly evaluating seven transferability scores in three medical applications, including out-of-distribution scenarios. Despite promising results in general-purpose datasets, our results show that no transferability score can reliably and consistently estimate target performance in medical contexts, inviting further work in that direction.", "url": "https://arxiv.org/abs/2308.07444"}, {"metadata": {"arXiv": "2308.07498", "Date": "Mon, 14 Aug 2023 23:45:01 ", "Title": "DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation", "Authors": ["Hanqing Wang", "Wei Liang", "Luc Van Gool", "Wenguan Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ICCV 2023; Project page: https://github.com/hanqingwangai/Dreamwalker"]}, "abstract": "VLN-CE is a recently released embodied task, where AI agents need to navigate a freely traversable environment to reach a distant target location, given language instructions. It poses great challenges due to the huge space of possible strategies. Driven by the belief that the ability to anticipate the consequences of future actions is crucial for the emergence of intelligent and interpretable planning behavior, we propose DREAMWALKER -- a world model based VLN-CE agent. The world model is built to summarize the visual, topological, and dynamic properties of the complicated continuous environment into a discrete, structured, and compact representation. DREAMWALKER can simulate and evaluate possible plans entirely in such internal abstract world, before executing costly actions. As opposed to existing model-free VLN-CE agents simply making greedy decisions in the real world, which easily results in shortsighted behaviors, DREAMWALKER is able to make strategic planning through large amounts of ``mental experiments.'' Moreover, the imagined future scenarios reflect our agent's intention, making its decision-making process more transparent. Extensive experiments and ablation studies on VLN-CE dataset confirm the effectiveness of the proposed approach and outline fruitful directions for future work.", "url": "https://arxiv.org/abs/2308.07498"}, {"metadata": {"arXiv": "2308.07509", "Date": "Tue, 15 Aug 2023 00:27:18 ", "Title": "Boosting Semi-Supervised Learning by bridging high and low-confidence predictions", "Authors": ["Khanh-Binh Nguyen", "Joon-Sung Yang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCVW2023 (Workshop on representation learning with very limited images: the potential of self-", "synthetic- and formula-supervision)"]}, "abstract": "Pseudo-labeling is a crucial technique in semi-supervised learning (SSL), where artificial labels are generated for unlabeled data by a trained model, allowing for the simultaneous training of labeled and unlabeled data in a supervised setting. However, several studies have identified three main issues with pseudo-labeling-based approaches. Firstly, these methods heavily rely on predictions from the trained model, which may not always be accurate, leading to a confirmation bias problem. Secondly, the trained model may be overfitted to easy-to-learn examples, ignoring hard-to-learn ones, resulting in the \\textit{\"Matthew effect\"} where the already strong become stronger and the weak weaker. Thirdly, most of the low-confidence predictions of unlabeled data are discarded due to the use of a high threshold, leading to an underutilization of unlabeled data during training. To address these issues, we propose a new method called ReFixMatch, which aims to utilize all of the unlabeled data during training, thus improving the generalizability of the model and performance on SSL benchmarks. Notably, ReFixMatch achieves 41.05\\% top-1 accuracy with 100k labeled examples on ImageNet, outperforming the baseline FixMatch and current state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.07509"}, {"metadata": {"arXiv": "2308.07558", "Date": "Tue, 15 Aug 2023 03:56:46 ", "Title": "Action Class Relation Detection and Classification Across Multiple Video Datasets", "Authors": ["Yuya Yoshikawa", "Yutaro Shigeto", "Masashi Shimbo", "Akikazu Takeuchi"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to Pattern Recognition Letters. 12 pages", "4 figures"]}, "abstract": "The Meta Video Dataset (MetaVD) provides annotated relations between action classes in major datasets for human action recognition in videos. Although these annotated relations enable dataset augmentation, it is only applicable to those covered by MetaVD. For an external dataset to enjoy the same benefit, the relations between its action classes and those in MetaVD need to be determined. To address this issue, we consider two new machine learning tasks: action class relation detection and classification. We propose a unified model to predict relations between action classes, using language and visual information associated with classes. Experimental results show that (i) pre-trained recent neural network models for texts and videos contribute to high predictive performance, (ii) the relation prediction based on action label texts is more accurate than based on videos, and (iii) a blending approach that combines predictions by both modalities can further improve the predictive performance in some cases.", "url": "https://arxiv.org/abs/2308.07558"}, {"metadata": {"arXiv": "2308.07580", "Date": "Tue, 15 Aug 2023 05:51:25 ", "Title": "AutoLTS: Automating Cycling Stress Assessment via Contrastive Learning and Spatial Post-processing", "Authors": ["Bo Lin", "Shoshanna Saxe", "Timothy C. Y. Chan"], "Categories": "cs.CV cs.AI"}, "abstract": "Cycling stress assessment, which quantifies cyclists' perceived stress imposed by the built environment and motor traffics, increasingly informs cycling infrastructure planning and cycling route recommendation. However, currently calculating cycling stress is slow and data-intensive, which hinders its broader application. In this paper, We propose a deep learning framework to support accurate, fast, and large-scale cycling stress assessments for urban road networks based on street-view images. Our framework features i) a contrastive learning approach that leverages the ordinal relationship among cycling stress labels, and ii) a post-processing technique that enforces spatial smoothness into our predictions. On a dataset of 39,153 road segments collected in Toronto, Canada, our results demonstrate the effectiveness of our deep learning framework and the value of using image data for cycling stress assessment in the absence of high-quality road geometry and motor traffic data.", "url": "https://arxiv.org/abs/2308.07580"}, {"metadata": {"arXiv": "2308.07605", "Date": "Tue, 15 Aug 2023 07:20:22 ", "Title": "SGDiff: A Style Guided Diffusion Model for Fashion Synthesis", "Authors": ["Zhengwentai Sun", "Yanghong Zhou", "Honghong He", "P. Y. Mok"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["Accepted by ACM MM'23"], "DOI": "10.1145/3581783.3613806"}, "abstract": "This paper reports on the development of \\textbf{a novel style guided diffusion model (SGDiff)} which overcomes certain weaknesses inherent in existing models for image synthesis. The proposed SGDiff combines image modality with a pretrained text-to-image diffusion model to facilitate creative fashion image synthesis. It addresses the limitations of text-to-image diffusion models by incorporating supplementary style guidance, substantially reducing training costs, and overcoming the difficulties of controlling synthesized styles with text-only inputs. This paper also introduces a new dataset -- SG-Fashion, specifically designed for fashion image synthesis applications, offering high-resolution images and an extensive range of garment categories. By means of comprehensive ablation study, we examine the application of classifier-free guidance to a variety of conditions and validate the effectiveness of the proposed model for generating fashion images of the desired categories, product attributes, and styles. The contributions of this paper include a novel classifier-free guidance method for multi-modal feature fusion, a comprehensive dataset for fashion image synthesis application, a thorough investigation on conditioned text-to-image synthesis, and valuable insights for future research in the text-to-image synthesis domain. The code and dataset are available at: \\url{https://github.com/taited/SGDiff}.", "url": "https://arxiv.org/abs/2308.07605"}, {"metadata": {"arXiv": "2308.07650", "Date": "Tue, 15 Aug 2023 08:57:03 ", "Title": "EQ-Net: Elastic Quantization Neural Networks", "Authors": ["Ke Xu and Lei Han and Ye Tian and Shangshang Yang and Xingyi Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Current model quantization methods have shown their promising capability in reducing storage space and computation complexity. However, due to the diversity of quantization forms supported by different hardware, one limitation of existing solutions is that usually require repeated optimization for different scenarios. How to construct a model with flexible quantization forms has been less studied. In this paper, we explore a one-shot network quantization regime, named Elastic Quantization Neural Networks (EQ-Net), which aims to train a robust weight-sharing quantization supernet. First of all, we propose an elastic quantization space (including elastic bit-width, granularity, and symmetry) to adapt to various mainstream quantitative forms. Secondly, we propose the Weight Distribution Regularization Loss (WDR-Loss) and Group Progressive Guidance Loss (GPG-Loss) to bridge the inconsistency of the distribution for weights and output logits in the elastic quantization space gap. Lastly, we incorporate genetic algorithms and the proposed Conditional Quantization-Aware Accuracy Predictor (CQAP) as an estimator to quickly search mixed-precision quantized neural networks in supernet. Extensive experiments demonstrate that our EQ-Net is close to or even better than its static counterparts as well as state-of-the-art robust bit-width methods. Code can be available at \\href{https://github.com/xuke225/EQ-Net.git}{https://github.com/xuke225/EQ-Net}.", "url": "https://arxiv.org/abs/2308.07650"}, {"metadata": {"arXiv": "2308.07686", "Date": "Tue, 15 Aug 2023 10:37:03 ", "Title": "Boosting Multi-modal Model Performance with Adaptive Gradient Modulation", "Authors": ["Hong Li", "Xingyu Li", "Pengbo Hu", "Yinuo Lei", "Chunxiao Li", "Yi Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "While the field of multi-modal learning keeps growing fast, the deficiency of the standard joint training paradigm has become clear through recent studies. They attribute the sub-optimal performance of the jointly trained model to the modality competition phenomenon. Existing works attempt to improve the jointly trained model by modulating the training process. Despite their effectiveness, those methods can only apply to late fusion models. More importantly, the mechanism of the modality competition remains unexplored. In this paper, we first propose an adaptive gradient modulation method that can boost the performance of multi-modal models with various fusion strategies. Extensive experiments show that our method surpasses all existing modulation methods. Furthermore, to have a quantitative understanding of the modality competition and the mechanism behind the effectiveness of our modulation method, we introduce a novel metric to measure the competition strength. This metric is built on the mono-modal concept, a function that is designed to represent the competition-less state of a modality. Through systematic investigation, our results confirm the intuition that the modulation encourages the model to rely on the more informative modality. In addition, we find that the jointly trained model typically has a preferred modality on which the competition is weaker than other modalities. However, this preferred modality need not dominate others. Our code will be available at https://github.com/lihong2303/AGM_ICCV2023.", "url": "https://arxiv.org/abs/2308.07686"}, {"metadata": {"arXiv": "2308.07749", "Date": "Tue, 15 Aug 2023 13:00:42 ", "Title": "Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with Image Diffusion Model", "Authors": ["Bosheng Qin", "Wentao Ye", "Qifan Yu", "Siliang Tang", "Yueting Zhuang"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "3 figures"]}, "abstract": "The rising demand for creating lifelike avatars in the digital realm has led to an increased need for generating high-quality human videos guided by textual descriptions and poses. We propose Dancing Avatar, designed to fabricate human motion videos driven by poses and textual cues. Our approach employs a pretrained T2I diffusion model to generate each video frame in an autoregressive fashion. The crux of innovation lies in our adept utilization of the T2I diffusion model for producing video frames successively while preserving contextual relevance. We surmount the hurdles posed by maintaining human character and clothing consistency across varying poses, along with upholding the background's continuity amidst diverse human movements. To ensure consistent human appearances across the entire video, we devise an intra-frame alignment module. This module assimilates text-guided synthesized human character knowledge into the pretrained T2I diffusion model, synergizing insights from ChatGPT. For preserving background continuity, we put forth a background alignment pipeline, amalgamating insights from segment anything and image inpainting techniques. Furthermore, we propose an inter-frame alignment module that draws inspiration from an auto-regressive pipeline to augment temporal consistency between adjacent frames, where the preceding frame guides the synthesis process of the current frame. Comparisons with state-of-the-art methods demonstrate that Dancing Avatar exhibits the capacity to generate human videos with markedly superior quality, both in terms of human and background fidelity, as well as temporal coherence compared to existing state-of-the-art approaches.", "url": "https://arxiv.org/abs/2308.07749"}, {"metadata": {"arXiv": "2308.07795", "Date": "Tue, 15 Aug 2023 14:21:24 ", "Title": "Learning to Identify Critical States for Reinforcement Learning from Videos", "Authors": ["Haozhe Liu", "Mingchen Zhuge", "Bing Li", "Yuhui Wang", "Francesco Faccio", "Bernard Ghanem", "J\\\"urgen Schmidhuber"], "Categories": "cs.CV cs.AI", "Comments": ["This paper was accepted to ICCV23"]}, "abstract": "Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good policies can be extracted from offline data which lack explicit information about executed actions. For example, videos of humans or robots may convey a lot of implicit information about rewarding action sequences, but a DRL machine that wants to profit from watching such videos must first learn by itself to identify and recognize relevant states/actions/rewards. Without relying on ground-truth annotations, our new method called Deep State Identifier learns to predict returns from episodes encoded as videos. Then it uses a kind of mask-based sensitivity analysis to extract/identify important critical states. Extensive experiments showcase our method's potential for understanding and improving agent behavior. The source code and the generated datasets are available at https://github.com/AI-Initiative-KAUST/VideoRLCS.", "url": "https://arxiv.org/abs/2308.07795"}, {"metadata": {"arXiv": "2308.07903", "Date": "Tue, 15 Aug 2023 17:42:39 ", "Title": "Relightable and Animatable Neural Avatar from Sparse-View Video", "Authors": ["Zhen Xu", "Sida Peng", "Chen Geng", "Linzhan Mou", "Zihan Yan", "Jiaming Sun", "Hujun Bao", "Xiaowei Zhou"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Project page: https://zju3dv.github.io/relightable_avatar"]}, "abstract": "This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse distances based on a parametric human model and compute fine distances by exploiting the local deformation invariance of SDF. Based on the HDQ algorithm, we leverage sphere tracing to efficiently estimate the surface intersection and light visibility. This allows us to develop the first system to recover animatable and relightable neural avatars from sparse view (or monocular) inputs. Experiments demonstrate that our approach is able to produce superior results compared to state-of-the-art methods. Our code will be released for reproducibility.", "url": "https://arxiv.org/abs/2308.07903"}, {"metadata": {"arXiv": "2308.07541", "Date": "Tue, 15 Aug 2023 03:01:41 ", "Title": "Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing", "Authors": ["Siddharth Agarwal", "Maria A. Rodriguez", "Rajkumar Buyya"], "Categories": "cs.DC cs.AI cs.SY eess.SY", "Comments": ["13 figures", "10 pages", "3 tables"]}, "abstract": "Function-as-a-Service is a cloud computing paradigm offering an event-driven execution model to applications. It features serverless attributes by eliminating resource management responsibilities from developers and offers transparent and on-demand scalability of applications. Typical serverless applications have stringent response time and scalability requirements and therefore rely on deployed services to provide quick and fault-tolerant feedback to clients. However, the FaaS paradigm suffers from cold starts as there is a non-negligible delay associated with on-demand function initialization. This work focuses on reducing the frequency of cold starts on the platform by using Reinforcement Learning. Our approach uses Q-learning and considers metrics such as function CPU utilization, existing function instances, and response failure rate to proactively initialize functions in advance based on the expected demand. The proposed solution was implemented on Kubeless and was evaluated using a normalised real-world function demand trace with matrix multiplication as the workload. The results demonstrate a favourable performance of the RL-based agent when compared to Kubeless' default policy and function keep-alive policy by improving throughput by up to 8.81% and reducing computation load and resource wastage by up to 55% and 37%, respectively, which is a direct outcome of reduced cold starts.", "url": "https://arxiv.org/abs/2308.07541"}, {"metadata": {"arXiv": "2308.07618", "Date": "Tue, 15 Aug 2023 07:56:33 ", "Title": "Vision-based Semantic Communications for Metaverse Services: A Contest Theoretic Approach", "Authors": ["Guangyuan Liu", "Hongyang Du", "Dusit Niyato", "Jiawen Kang", "Zehui Xiong", "and Boon Hee Soong"], "Categories": "cs.GT cs.AI cs.NI eess.SP", "Comments": ["6 pages,7figures"]}, "abstract": "The popularity of Metaverse as an entertainment, social, and work platform has led to a great need for seamless avatar integration in the virtual world. In Metaverse, avatars must be updated and rendered to reflect users' behaviour. Achieving real-time synchronization between the virtual bilocation and the user is complex, placing high demands on the Metaverse Service Provider (MSP)'s rendering resource allocation scheme. To tackle this issue, we propose a semantic communication framework that leverages contest theory to model the interactions between users and MSPs and determine optimal resource allocation for each user. To reduce the consumption of network resources in wireless transmission, we use the semantic communication technique to reduce the amount of data to be transmitted. Under our simulation settings, the encoded semantic data only contains 51 bytes of skeleton coordinates instead of the image size of 8.243 megabytes. Moreover, we implement Deep Q-Network to optimize reward settings for maximum performance and efficient resource allocation. With the optimal reward setting, users are incentivized to select their respective suitable uploading frequency, reducing down-sampling loss due to rendering resource constraints by 66.076\\% compared with the traditional average distribution method. The framework provides a novel solution to resource allocation for avatar association in VR environments, ensuring a smooth and immersive experience for all users.", "url": "https://arxiv.org/abs/2308.07618"}, {"metadata": {"arXiv": "2308.07878", "Date": "Tue, 15 Aug 2023 16:57:09 ", "Title": "The $10 Million ANA Avatar XPRIZE Competition Advanced Immersive Telepresence Systems", "Authors": ["Sven Behnke", "Julie A. Adams and David Locke"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["Extended version of article accepted for competitions column"], "Journal-ref": "IEEE Robotics and Automation Magazine, 2023"}, "abstract": "The $10M ANA Avatar XPRIZE aimed to create avatar systems that can transport human presence to remote locations in real time. The participants of this multi-year competition developed robotic systems that allow operators to see, hear, and interact with a remote environment in a way that feels as if they are truly there. On the other hand, people in the remote environment were given the impression that the operator was present inside the avatar robot. At the competition finals, held in November 2022 in Long Beach, CA, USA, the avatar systems were evaluated on their support for remotely interacting with humans, exploring new environments, and employing specialized skills. This article describes the competition stages with tasks and evaluation procedures, reports the results, presents the winning teams' approaches, and discusses lessons learned.", "url": "https://arxiv.org/abs/2308.07878"}, {"metadata": {"arXiv": "2308.07326", "Date": "Mon, 07 Aug 2023 18:14:24 ", "Title": "AI Text-to-Behavior: A Study In Steerability", "Authors": ["David Noever and Sam Hyams"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while \"openness\" presented linguistic ambiguity, \"conscientiousness\" and \"neuroticism\" were distinctly evoked in the OCEAN framework, with \"extroversion\" and \"agreeableness\" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. However, the rapid advancements in LLM capabilities and the opaque nature of some training techniques make metric proposals degrade rapidly. Our research emphasizes a quantitative role to describe steerability in LLMs, presenting both its promise and areas for further refinement in aligning its progress to human intentions.", "url": "https://arxiv.org/abs/2308.07326"}, {"metadata": {"arXiv": "2308.07329", "Date": "Wed, 09 Aug 2023 13:38:00 ", "Title": "Variations on the Reinforcement Learning performance of Blackjack", "Authors": ["Avish Buramdoyal", "Tim Gebbie"], "Categories": "cs.AI cs.LG q-fin.TR", "Comments": ["12 pages", "15 figures", "7 tables"]}, "abstract": "Blackjack or \"21\" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.", "url": "https://arxiv.org/abs/2308.07329"}, {"metadata": {"arXiv": "2308.07335", "Date": "Fri, 11 Aug 2023 07:14:37 ", "Title": "An Encoder-Decoder Approach for Packing Circles", "Authors": ["Akshay Kiran Jose", "Gangadhar Karevvanavar", "Rajshekhar V Bhat"], "Categories": "cs.AI cs.LG cs.NE math.OC"}, "abstract": "The problem of packing smaller objects within a larger object has been of interest since decades. In these problems, in addition to the requirement that the smaller objects must lie completely inside the larger objects, they are expected to not overlap or have minimum overlap with each other. Due to this, the problem of packing turns out to be a non-convex problem, obtaining whose optimal solution is challenging. As such, several heuristic approaches have been used for obtaining sub-optimal solutions in general, and provably optimal solutions for some special instances. In this paper, we propose a novel encoder-decoder architecture consisting of an encoder block, a perturbation block and a decoder block, for packing identical circles within a larger circle. In our approach, the encoder takes the index of a circle to be packed as an input and outputs its center through a normalization layer, the perturbation layer adds controlled perturbations to the center, ensuring that it does not deviate beyond the radius of the smaller circle to be packed, and the decoder takes the perturbed center as input and estimates the index of the intended circle for packing. We parameterize the encoder and decoder by a neural network and optimize it to reduce an error between the decoder's estimated index and the actual index of the circle provided as input to the encoder. The proposed approach can be generalized to pack objects of higher dimensions and different shapes by carefully choosing normalization and perturbation layers. The approach gives a sub-optimal solution and is able to pack smaller objects within a larger object with competitive performance with respect to classical methods.", "url": "https://arxiv.org/abs/2308.07335"}, {"metadata": {"arXiv": "2308.07336", "Date": "Fri, 11 Aug 2023 13:15:35 ", "Title": "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic", "Authors": ["Terufumi Morishita", "Gaku Morio", "Atsuki Yamaguchi", "Yasuhiro Sogawa"], "Categories": "cs.AI cs.CL cs.LG", "Journal-ref": "Proceedings of the 40th International Conference on Machine Learning, PMLR 202:25254-25274, 2023"}, "abstract": "We study a synthetic corpus-based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\\textbf{FLD}$ ($\\textbf{F}$ormal $\\textbf{L}$ogic $\\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.", "url": "https://arxiv.org/abs/2308.07336"}, {"metadata": {"arXiv": "2308.07870", "Date": "Tue, 15 Aug 2023 16:37:16 ", "Title": "Brain-Inspired Computational Intelligence via Predictive Coding", "Authors": ["Tommaso Salvatori", "Ankur Mali", "Christopher L. Buckley", "Thomas Lukasiewicz", "Rajesh P. N. Rao", "Karl Friston", "Alexander Ororbia"], "Categories": "cs.AI cs.LG cs.NE", "Comments": ["37 Pages", "9 Figures"]}, "abstract": "Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a powerful inversion scheme for a specific class of continuous-state generative models. With the hope of foregrounding research in this direction, we survey the literature that has contributed to this perspective, highlighting the many ways that PC might play a role in the future of machine learning and computational intelligence at large.", "url": "https://arxiv.org/abs/2308.07870"}, {"metadata": {"arXiv": "2308.07575", "Date": "Tue, 15 Aug 2023 05:08:12 ", "Title": "Story Visualization by Online Text Augmentation with Context Memory", "Authors": ["Daechul Ahn", "Daneul Kim", "Gwangmo Song", "Seung Hwan Kim", "Honglak Lee", "Dongyeop Kang", "Jonghyun Choi"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Story visualization (SV) is a challenging text-to-image generation task for the difficulty of not only rendering visual details from the text descriptions but also encoding a long-term context across multiple sentences. While prior efforts mostly focus on generating a semantically relevant image for each sentence, encoding a context spread across the given paragraph to generate contextually convincing images (e.g., with a correct character or with a proper background of the scene) remains a challenge. To this end, we propose a novel memory architecture for the Bi-directional Transformers with an online text augmentation that generates multiple pseudo-descriptions as supplementary supervision during training, for better generalization to the language variation at inference. In extensive experiments on the two popular SV benchmarks, i.e., the Pororo-SV and Flintstones-SV, the proposed method significantly outperforms the state of the arts in various evaluation metrics including FID, character F1, frame accuracy, BLEU-2/3, and R-precision with similar or less computational complexity.", "url": "https://arxiv.org/abs/2308.07575"}, {"metadata": {"arXiv": "2308.07687", "Date": "Tue, 15 Aug 2023 10:37:04 ", "Title": "DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models", "Authors": ["Ruiyuan Gao", "Chenchen Zhao", "Lanqing Hong", "Qiang Xu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV2023", "with supplementary materials"]}, "abstract": "Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions. As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input image. We also present several test-time techniques to further strengthen such differences. Experimental results show that DiffGuard is effective on both Cifar-10 and hard cases of the large-scale ImageNet, and it can be easily combined with existing OOD detection techniques to achieve state-of-the-art OOD detection results.", "url": "https://arxiv.org/abs/2308.07687"}, {"metadata": {"arXiv": "2308.07706", "Date": "Tue, 15 Aug 2023 11:28:21 ", "Title": "Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models", "Authors": ["Kanchan Poudel", "Manish Dhakal", "Prasiddha Bhandari", "Rabin Adhikari", "Safal Thapaliya", "Bishesh Khanal"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["25 pages", "9 figures"]}, "abstract": "Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning. To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations in model performance based on the generated prompts. Our findings highlight the distribution shift between the open-domain images and the medical domain and show that the segmentation models trained on open-domain images are not directly transferrable to the medical field. But their performance can be increased by finetuning them in the medical datasets. We report the zero-shot and finetuned segmentation performance of 4 Vision Language Models (VLMs) on 11 medical datasets using 9 types of prompts derived from 14 attributes.", "url": "https://arxiv.org/abs/2308.07706"}, {"metadata": {"arXiv": "2308.07748", "Date": "Tue, 15 Aug 2023 12:58:06 ", "Title": "Exploiting Sparsity in Automotive Radar Object Detection Networks", "Authors": ["Marius Lippke", "Maurice Quach", "Sascha Braun", "Daniel K\\\"ohler", "Michael Ulrich", "Bastian Bischoff and Wei Yap Tan"], "Categories": "cs.CV cs.AI cs.LG cs.RO"}, "abstract": "Having precise perception of the environment is crucial for ensuring the secure and reliable functioning of autonomous driving systems. Radar object detection networks are one fundamental part of such systems. CNN-based object detectors showed good performance in this context, but they require large compute resources. This paper investigates sparse convolutional object detection networks, which combine powerful grid-based detection with low compute resources. We investigate radar specific challenges and propose sparse kernel point pillars (SKPP) and dual voxel point convolutions (DVPC) as remedies for the grid rendering and sparse backbone architectures. We evaluate our SKPP-DPVCN architecture on nuScenes, which outperforms the baseline by 5.89% and the previous state of the art by 4.19% in Car AP4.0. Moreover, SKPP-DPVCN reduces the average scale error (ASE) by 21.41% over the baseline.", "url": "https://arxiv.org/abs/2308.07748"}, {"metadata": {"arXiv": "2308.07350", "Date": "Mon, 14 Aug 2023 09:21:19 ", "Title": "Efficient Neural PDE-Solvers using Quantization Aware Training", "Authors": ["Winfried van den Dool", "Tijmen Blankevoort", "Max Welling", "Yuki M. Asano"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at the ICCV 2023 Workshop on Resource Efficient Deep Learning for Computer Vision"]}, "abstract": "In the past years, the application of neural networks as an alternative to classical numerical methods to solve Partial Differential Equations has emerged as a potential paradigm shift in this century-old mathematical field. However, in terms of practical applicability, computational cost remains a substantial bottleneck. Classical approaches try to mitigate this challenge by limiting the spatial resolution on which the PDEs are defined. For neural PDE solvers, we can do better: Here, we investigate the potential of state-of-the-art quantization methods on reducing computational costs. We show that quantizing the network weights and activations can successfully lower the computational cost of inference while maintaining performance. Our results on four standard PDE datasets and three network architectures show that quantization-aware training works across settings and three orders of FLOPs magnitudes. Finally, we empirically demonstrate that Pareto-optimality of computational cost vs performance is almost always achieved only by incorporating quantization.", "url": "https://arxiv.org/abs/2308.07350"}, {"metadata": {"arXiv": "2308.07351", "Date": "Mon, 14 Aug 2023 09:22:35 ", "Title": "IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse", "Authors": ["Siyuan Li", "Hao Li", "Jin Zhang", "Zhen Wang", "Peng Liu", "Chongjie Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["26 pages", "9 figures"]}, "abstract": "Humans have the ability to reuse previously learned policies to solve new tasks quickly, and reinforcement learning (RL) agents can do the same by transferring knowledge from source policies to a related target task. Transfer RL methods can reshape the policy optimization objective (optimization transfer) or influence the behavior policy (behavior transfer) using source policies. However, selecting the appropriate source policy with limited samples to guide target policy learning has been a challenge. Previous methods introduce additional components, such as hierarchical policies or estimations of source policies' value functions, which can lead to non-stationary policy optimization or heavy sampling costs, diminishing transfer effectiveness. To address this challenge, we propose a novel transfer RL method that selects the source policy without training extra components. Our method utilizes the Q function in the actor-critic framework to guide policy selection, choosing the source policy with the largest one-step improvement over the current target policy. We integrate optimization transfer and behavior transfer (IOB) by regularizing the learned policy to mimic the guidance policy and combining them as the behavior policy. This integration significantly enhances transfer effectiveness, surpasses state-of-the-art transfer RL baselines in benchmark tasks, and improves final performance and knowledge transferability in continual learning scenarios. Additionally, we show that our optimization transfer technique is guaranteed to improve target policy learning.", "url": "https://arxiv.org/abs/2308.07351"}, {"metadata": {"arXiv": "2308.07352", "Date": "Mon, 14 Aug 2023 09:32:21 ", "Title": "Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer", "Authors": ["Shikhar Nilabh and Fidel Grandia"], "Categories": "cs.LG cs.AI physics.comp-ph physics.flu-dyn", "Comments": ["To be submitted to a NeurIPS 2023 workshop. arXiv admin note: substantial text overlap with arXiv:2211.03525"]}, "abstract": "Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility and quantifying the uncertainty. The inverse model output is then used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy.", "url": "https://arxiv.org/abs/2308.07352"}, {"metadata": {"arXiv": "2308.07439", "Date": "Mon, 14 Aug 2023 20:20:26 ", "Title": "Interaction-Aware Personalized Vehicle Trajectory Prediction Using Temporal Graph Neural Networks", "Authors": ["Amr Abdelraouf", "Rohit Gupta", "Kyungtae Han"], "Categories": "cs.LG cs.AI cs.CV cs.RO"}, "abstract": "Accurate prediction of vehicle trajectories is vital for advanced driver assistance systems and autonomous vehicles. Existing methods mainly rely on generic trajectory predictions derived from large datasets, overlooking the personalized driving patterns of individual drivers. To address this gap, we propose an approach for interaction-aware personalized vehicle trajectory prediction that incorporates temporal graph neural networks. Our method utilizes Graph Convolution Networks (GCN) and Long Short-Term Memory (LSTM) to model the spatio-temporal interactions between target vehicles and their surrounding traffic. To personalize the predictions, we establish a pipeline that leverages transfer learning: the model is initially pre-trained on a large-scale trajectory dataset and then fine-tuned for each driver using their specific driving data. We employ human-in-the-loop simulation to collect personalized naturalistic driving trajectories and corresponding surrounding vehicle trajectories. Experimental results demonstrate the superior performance of our personalized GCN-LSTM model, particularly for longer prediction horizons, compared to its generic counterpart. Moreover, the personalized model outperforms individual models created without pre-training, emphasizing the significance of pre-training on a large dataset to avoid overfitting. By incorporating personalization, our approach enhances trajectory prediction accuracy.", "url": "https://arxiv.org/abs/2308.07439"}, {"metadata": {"arXiv": "2308.07441", "Date": "Mon, 14 Aug 2023 20:26:23 ", "Title": "Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of Nitrogen Oxides", "Authors": ["Lianfa Li", "Roxana Khalili", "Frederick Lurmann", "Nathan Pavlovic", "Jun Wu", "Yan Xu", "Yisi Liu", "Karl O'Sharkey", "Beate Ritz", "Luke Oman", "Meredith Franklin", "Theresa Bastain", "Shohreh F. Farzan", "Carrie Breton", "Rima Habre"], "Categories": "cs.LG cs.AI"}, "abstract": "Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have recognized acute and chronic health and environmental effects. Machine learning (ML) methods have significantly enhanced our capacity to predict NOx concentrations at ground-level with high spatiotemporal resolution but may suffer from high estimation bias since they lack physical and chemical knowledge about air pollution dynamics. Chemical transport models (CTMs) leverage this knowledge; however, accurate predictions of ground-level concentrations typically necessitate extensive post-calibration. Here, we present a physics-informed deep learning framework that encodes advection-diffusion mechanisms and fluid dynamics constraints to jointly predict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures fine-scale transport of NO2 and NOx, generates robust spatial extrapolation, and provides explicit uncertainty estimation. The framework fuses knowledge-driven physicochemical principles of CTMs with the predictive power of ML for air quality exposure, health, and policy applications. Our approach offers significant improvements over purely data-driven ML methods and has unprecedented bias reduction in joint NO2 and NOx prediction.", "url": "https://arxiv.org/abs/2308.07441"}, {"metadata": {"arXiv": "2308.07452", "Date": "Mon, 14 Aug 2023 20:46:16 ", "Title": "GRU-D-Weibull: A Novel Real-Time Individualized Endpoint Prediction", "Authors": ["Xiaoyang Ruan", "Liwei Wang", "Charat Thongprayoon", "Wisit Cheungpasitporn", "Hongfang Liu"], "Categories": "cs.LG cs.AI", "Comments": ["30 pages", "7 figures", "4 supplementary figures"]}, "abstract": "Accurate prediction models for individual-level endpoints and time-to-endpoints are crucial in clinical practice. In this study, we propose a novel approach, GRU-D-Weibull, which combines gated recurrent units with decay (GRU-D) to model the Weibull distribution. Our method enables real-time individualized endpoint prediction and population-level risk management. Using a cohort of 6,879 patients with stage 4 chronic kidney disease (CKD4), we evaluated the performance of GRU-D-Weibull in endpoint prediction. The C-index of GRU-D-Weibull was ~0.7 at the index date and increased to ~0.77 after 4.3 years of follow-up, similar to random survival forest. Our approach achieved an absolute L1-loss of ~1.1 years (SD 0.95) at the CKD4 index date and a minimum of ~0.45 years (SD0.3) at 4 years of follow-up, outperforming competing methods significantly. GRU-D-Weibull consistently constrained the predicted survival probability at the time of an event within a smaller and more fixed range compared to other models throughout the follow-up period. We observed significant correlations between the error in point estimates and missing proportions of input features at the index date (correlations from ~0.1 to ~0.3), which diminished within 1 year as more data became available. By post-training recalibration, we successfully aligned the predicted and observed survival probabilities across multiple prediction horizons at different time points during follow-up. Our findings demonstrate the considerable potential of GRU-D-Weibull as the next-generation architecture for endpoint risk management, capable of generating various endpoint estimates for real-time monitoring using clinical data.", "url": "https://arxiv.org/abs/2308.07452"}, {"metadata": {"arXiv": "2308.07469", "Date": "Mon, 14 Aug 2023 21:40:23 ", "Title": "Omega-Regular Reward Machines", "Authors": ["Ernst Moritz Hahn", "Mateo Perez", "Sven Schewe", "Fabio Somenzi", "Ashutosh Trivedi", "Dominik Wojtczak"], "Categories": "cs.LG cs.AI cs.FL", "Comments": ["To appear in ECAI-2023"]}, "abstract": "Reinforcement learning (RL) is a powerful approach for training agents to perform tasks, but designing an appropriate reward mechanism is critical to its success. However, in many cases, the complexity of the learning objectives goes beyond the capabilities of the Markovian assumption, necessitating a more sophisticated reward mechanism. Reward machines and omega-regular languages are two formalisms used to express non-Markovian rewards for quantitative and qualitative objectives, respectively. This paper introduces omega-regular reward machines, which integrate reward machines with omega-regular languages to enable an expressive and effective reward mechanism for RL. We present a model-free RL algorithm to compute epsilon-optimal strategies against omega-egular reward machines and evaluate the effectiveness of the proposed algorithm through experiments.", "url": "https://arxiv.org/abs/2308.07469"}, {"metadata": {"arXiv": "2308.07496", "Date": "Mon, 14 Aug 2023 23:34:59 ", "Title": "ST-MLP: A Cascaded Spatio-Temporal Linear Framework with Channel-Independence Strategy for Traffic Forecasting", "Authors": ["Zepu Wang", "Yuqi Nie", "Peng Sun", "Nam H. Nguyen", "John Mulvey", "H. Vincent Poor"], "Categories": "cs.LG cs.AI"}, "abstract": "The criticality of prompt and precise traffic forecasting in optimizing traffic flow management in Intelligent Transportation Systems (ITS) has drawn substantial scholarly focus. Spatio-Temporal Graph Neural Networks (STGNNs) have been lauded for their adaptability to road graph structures. Yet, current research on STGNNs architectures often prioritizes complex designs, leading to elevated computational burdens with only minor enhancements in accuracy. To address this issue, we propose ST-MLP, a concise spatio-temporal model solely based on cascaded Multi-Layer Perceptron (MLP) modules and linear layers. Specifically, we incorporate temporal information, spatial information and predefined graph structure with a successful implementation of the channel-independence strategy - an effective technique in time series forecasting. Empirical results demonstrate that ST-MLP outperforms state-of-the-art STGNNs and other models in terms of accuracy and computational efficiency. Our finding encourages further exploration of more concise and effective neural network architectures in the field of traffic forecasting.", "url": "https://arxiv.org/abs/2308.07496"}, {"metadata": {"arXiv": "2308.07598", "Date": "Tue, 15 Aug 2023 06:58:19 ", "Title": "Generating Personas for Games with Multimodal Adversarial Imitation Learning", "Authors": ["William Ahlberg", "Alessandro Sestini", "Konrad Tollmar", "Linus Gissl\\'en"], "Categories": "cs.LG cs.AI", "Comments": ["Published in CoG 2023"]}, "abstract": "Reinforcement learning has been widely successful in producing agents capable of playing games at a human level. However, this requires complex reward engineering, and the agent's resulting policy is often unpredictable. Going beyond reinforcement learning is necessary to model a wide range of human playstyles, which can be difficult to represent with a reward function. This paper presents a novel imitation learning approach to generate multiple persona policies for playtesting. Multimodal Generative Adversarial Imitation Learning (MultiGAIL) uses an auxiliary input parameter to learn distinct personas using a single-agent model. MultiGAIL is based on generative adversarial imitation learning and uses multiple discriminators as reward models, inferring the environment reward by comparing the agent and distinct expert policies. The reward from each discriminator is weighted according to the auxiliary input. Our experimental analysis demonstrates the effectiveness of our technique in two environments with continuous and discrete action spaces.", "url": "https://arxiv.org/abs/2308.07598"}, {"metadata": {"arXiv": "2308.07641", "Date": "Tue, 15 Aug 2023 08:46:17 ", "Title": "Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping", "Authors": ["Boyu Chen", "Hanxuan Chen", "Jiao He", "Fengyu Sun", "Shangling Jui"], "Categories": "cs.LG cs.AI"}, "abstract": "We present a simple yet novel parameterized form of linear mapping to achieves remarkable network compression performance: a pseudo SVD called Ternary SVD (TSVD). Unlike vanilla SVD, TSVD limits the $U$ and $V$ matrices in SVD to ternary matrices form in $\\{\\pm 1, 0\\}$. This means that instead of using the expensive multiplication instructions, TSVD only requires addition instructions when computing $U(\\cdot)$ and $V(\\cdot)$. We provide direct and training transition algorithms for TSVD like Post Training Quantization and Quantization Aware Training respectively. Additionally, we analyze the convergence of the direct transition algorithms in theory. In experiments, we demonstrate that TSVD can achieve state-of-the-art network compression performance in various types of networks and tasks, including current baseline models such as ConvNext, Swim, BERT, and large language model like OPT.", "url": "https://arxiv.org/abs/2308.07641"}, {"metadata": {"arXiv": "2308.07761", "Date": "Tue, 15 Aug 2023 13:29:14 ", "Title": "NeFL: Nested Federated Learning for Heterogeneous Clients", "Authors": ["Honggu Kang", "Seohyeon Cha", "Jinwoo Shin", "Jongmyeong Lee", "Joonhyuk Kang"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages"]}, "abstract": "Federated learning (FL) is a promising approach in distributed learning keeping privacy. However, during the training pipeline of FL, slow or incapable clients (i.e., stragglers) slow down the total training time and degrade performance. System heterogeneity, including heterogeneous computing and network bandwidth, has been addressed to mitigate the impact of stragglers. Previous studies split models to tackle the issue, but with less degree-of-freedom in terms of model architecture. We propose nested federated learning (NeFL), a generalized framework that efficiently divides a model into submodels using both depthwise and widthwise scaling. NeFL is implemented by interpreting models as solving ordinary differential equations (ODEs) with adaptive step sizes. To address the inconsistency that arises when training multiple submodels with different architecture, we decouple a few parameters. NeFL enables resource-constrained clients to effectively join the FL pipeline and the model to be trained with a larger amount of data. Through a series of experiments, we demonstrate that NeFL leads to significant gains, especially for the worst-case submodel (e.g., 8.33 improvement on CIFAR-10). Furthermore, we demonstrate NeFL aligns with recent studies in FL.", "url": "https://arxiv.org/abs/2308.07761"}, {"metadata": {"arXiv": "2308.07772", "Date": "Tue, 15 Aug 2023 13:48:16 ", "Title": "MOLE: MOdular Learning FramEwork via Mutual Information Maximization", "Authors": ["Tianchao Li and Yulong Pei"], "Categories": "cs.LG cs.AI", "Comments": ["accepted by icml llw"]}, "abstract": "This paper is to introduce an asynchronous and local learning framework for neural networks, named Modular Learning Framework (MOLE). This framework modularizes neural networks by layers, defines the training objective via mutual information for each module, and sequentially trains each module by mutual information maximization. MOLE makes the training become local optimization with gradient-isolated across modules, and this scheme is more biologically plausible than BP. We run experiments on vector-, grid- and graph-type data. In particular, this framework is capable of solving both graph- and node-level tasks for graph-type data. Therefore, MOLE has been experimentally proven to be universally applicable to different types of data.", "url": "https://arxiv.org/abs/2308.07772"}, {"metadata": {"arXiv": "2308.07774", "Date": "Tue, 15 Aug 2023 13:49:12 ", "Title": "A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection", "Authors": ["Mahsa Mesgaran and A. Ben Hamza"], "Categories": "cs.LG cs.AI", "Journal-ref": "Neural Computing and Applications, 2023"}, "abstract": "A key component of many graph neural networks (GNNs) is the pooling operation, which seeks to reduce the size of a graph while preserving important structural information. However, most existing graph pooling strategies rely on an assignment matrix obtained by employing a GNN layer, which is characterized by trainable parameters, often leading to significant computational complexity and a lack of interpretability in the pooling process. In this paper, we propose an unsupervised graph encoder-decoder model to detect abnormal nodes from graphs by learning an anomaly scoring function to rank nodes based on their degree of abnormality. In the encoding stage, we design a novel pooling mechanism, named LCPool, which leverages locality-constrained linear coding for feature encoding to find a cluster assignment matrix by solving a least-squares optimization problem with a locality regularization term. By enforcing locality constraints during the coding process, LCPool is designed to be free from learnable parameters, capable of efficiently handling large graphs, and can effectively generate a coarser graph representation while retaining the most significant structural characteristics of the graph. In the decoding stage, we propose an unpooling operation, called LCUnpool, to reconstruct both the structure and nodal features of the original graph. We conduct empirical evaluations of our method on six benchmark datasets using several evaluation metrics, and the results demonstrate its superiority over state-of-the-art anomaly detection approaches.", "url": "https://arxiv.org/abs/2308.07774"}, {"metadata": {"arXiv": "2308.07832", "Date": "Tue, 15 Aug 2023 15:21:36 ", "Title": "REFORMS: Reporting Standards for Machine Learning Based Science", "Authors": ["Sayash Kapoor", "Emily Cantrell", "Kenny Peng", "Thanh Hien Pham", "Christopher A. Bail", "Odd Erik Gundersen", "Jake M. Hofman", "Jessica Hullman", "Michael A. Lones", "Momin M. Malik", "Priyanka Nanayakkara", "Russell A. Poldrack", "Inioluwa Deborah Raji", "Michael Roberts", "Matthew J. Salganik", "Marta Serra-Garcia", "Brandon M. Stewart", "Gilles Vandewiele", "Arvind Narayanan"], "Categories": "cs.LG cs.AI"}, "abstract": "Machine learning (ML) methods are proliferating in scientific research. However, the adoption of these methods has been accompanied by failures of validity, reproducibility, and generalizability. These failures can hinder scientific progress, lead to false consensus around invalid claims, and undermine the credibility of ML-based science. ML methods are often applied and fail in similar ways across disciplines. Motivated by this observation, our goal is to provide clear reporting standards for ML-based science. Drawing from an extensive review of past literature, we present the REFORMS checklist ($\\textbf{Re}$porting Standards $\\textbf{For}$ $\\textbf{M}$achine Learning Based $\\textbf{S}$cience). It consists of 32 questions and a paired set of guidelines. REFORMS was developed based on a consensus of 19 researchers across computer science, data science, mathematics, social sciences, and biomedical sciences. REFORMS can serve as a resource for researchers when designing and implementing a study, for referees when reviewing papers, and for journals when enforcing standards for transparency and reproducibility.", "url": "https://arxiv.org/abs/2308.07832"}, {"metadata": {"arXiv": "2308.07871", "Date": "Tue, 15 Aug 2023 16:39:10 ", "Title": "Emotion Embeddings $\\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets", "Authors": ["Sven Buechel and Udo Hahn"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["18 pages", "6 figures"]}, "abstract": "Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label formats, and even disparate model architectures. Experiments on a wide range of heterogeneous affective datasets indicate that this approach yields the desired interoperability for the sake of reusability, interpretability and flexibility, without penalizing prediction quality. Code and data are archived under https://doi.org/10.5281/zenodo.7405327 .", "url": "https://arxiv.org/abs/2308.07871"}, {"metadata": {"arXiv": "2308.07883", "Date": "Tue, 15 Aug 2023 17:13:16 ", "Title": "Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations", "Authors": ["Lekang Jiang", "Caiqi Zhang", "Farimah Poursafaei", "Shenyang Huang"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "4 figures", "4 tables"]}, "abstract": "Recently, Graph Neural Networks (GNNs) have shown promising performance in tasks on dynamic graphs such as node classification, link prediction and graph regression. However, few work has studied the temporal edge regression task which has important real-world applications. In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations. We introduce three simple yet strong baselines and comprehensively evaluate one static and three dynamic GNN models using the UN Trade dataset. Our experimental results reveal that the baselines exhibit remarkably strong performance across various settings, highlighting the inadequacy of existing GNNs. We also find that TGN outperforms other GNN models, suggesting TGN is a more appropriate choice for edge regression tasks. Moreover, we note that the proportion of negative edges in the training samples significantly affects the test performance. The companion source code can be found at: https://github.com/scylj1/GNN_Edge_Regression.", "url": "https://arxiv.org/abs/2308.07883"}, {"metadata": {"arXiv": "2308.07775", "Date": "Tue, 15 Aug 2023 13:51:03 ", "Title": "Hierarchical generative modelling for autonomous robots", "Authors": ["Kai Yuan", "Noor Sajid", "Karl Friston", "Zhibin Li"], "Categories": "cs.RO cs.AI cs.LG cs.SY eess.SY"}, "abstract": "Humans can produce complex whole-body motions when interacting with their surroundings, by planning, executing and combining individual limb movements. We investigated this fundamental aspect of motor control in the setting of autonomous robotic operations. We approach this problem by hierarchical generative modelling equipped with multi-level planning-for autonomous task completion-that mimics the deep temporal architecture of human motor control. Here, temporal depth refers to the nested time scales at which successive levels of a forward or generative model unfold, for example, delivering an object requires a global plan to contextualise the fast coordination of multiple local movements of limbs. This separation of temporal scales also motivates robotics and control. Specifically, to achieve versatile sensorimotor control, it is advantageous to hierarchically structure the planning and low-level motor control of individual limbs. We use numerical and physical simulation to conduct experiments and to establish the efficacy of this formulation. Using a hierarchical generative model, we show how a humanoid robot can autonomously complete a complex task that necessitates a holistic use of locomotion, manipulation, and grasping. Specifically, we demonstrate the ability of a humanoid robot that can retrieve and transport a box, open and walk through a door to reach the destination, approach and kick a football, while showing robust performance in presence of body damage and ground irregularities. Our findings demonstrated the effectiveness of using human-inspired motor control algorithms, and our method provides a viable hierarchical architecture for the autonomous completion of challenging goal-directed tasks.", "url": "https://arxiv.org/abs/2308.07775"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

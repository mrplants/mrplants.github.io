<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.14354", "Date": "Sat, 22 Jul 2023 19:40:00 ", "Title": "Learned Gridification for Efficient Point Cloud Processing", "Authors": ["Putri A. van der Linden", "David W. Romero", "Erik J. Bekkers"], "Categories": "cs.CV cs.LG"}, "abstract": "Neural operations that rely on neighborhood information are much more expensive when deployed on point clouds than on grid data due to the irregular distances between points in a point cloud. In a grid, on the other hand, we can compute the kernel only once and reuse it for all query positions. As a result, operations that rely on neighborhood information scale much worse for point clouds than for grid data, specially for large inputs and large neighborhoods. In this work, we address the scalability issue of point cloud methods by tackling its root cause: the irregularity of the data. We propose learnable gridification as the first step in a point cloud processing pipeline to transform the point cloud into a compact, regular grid. Thanks to gridification, subsequent layers can use operations defined on regular grids, e.g., Conv3D, which scale much better than native point cloud methods. We then extend gridification to point cloud to point cloud tasks, e.g., segmentation, by adding a learnable de-gridification step at the end of the point cloud processing pipeline to map the compact, regular grid back to its original point cloud form. Through theoretical and empirical analysis, we show that gridified networks scale better in terms of memory and time than networks directly applied on raw point cloud data, while being able to achieve competitive results. Our code is publicly available at https://github.com/computri/gridifier.", "url": "https://arxiv.org/abs/2307.14354"}, {"metadata": {"arXiv": "2307.14397", "Date": "Wed, 26 Jul 2023 12:05:08 ", "Title": "A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot", "Authors": ["Milad Abdollahzadeh", "Touba Malekzadeh", "Christopher T. H. Teo", "Keshigeyan Chandrasegaran", "Guimeng Liu", "Ngai-Man Cheung"], "Categories": "cs.CV cs.LG", "Comments": ["Technical Survey. Touba Malekzadeh", "Christopher T.H. Teo", "Keshigeyan Chandrasegaran contribute equally"]}, "abstract": "In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.", "url": "https://arxiv.org/abs/2307.14397"}, {"metadata": {"arXiv": "2307.14648", "Date": "Thu, 27 Jul 2023 06:53:16 ", "Title": "Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models", "Authors": ["Xin Yuan", "Linjie Li", "Jianfeng Wang", "Zhengyuan Yang", "Kevin Lin", "Zicheng Liu and Lijuan Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "In this paper, we study the denoising diffusion probabilistic model (DDPM) in wavelet space, instead of pixel space, for visual synthesis. Considering the wavelet transform represents the image in spatial and frequency domains, we carefully design a novel architecture SFUNet to effectively capture the correlation for both domains. Specifically, in the standard denoising U-Net for pixel data, we supplement the 2D convolutions and spatial-only attention layers with our spatial frequency-aware convolution and attention modules to jointly model the complementary information from spatial and frequency domains in wavelet data. Our new architecture can be used as a drop-in replacement to the pixel-based network and is compatible with the vanilla DDPM training process. By explicitly modeling the wavelet signals, we find our model is able to generate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and LSUN-Church datasets, than the pixel-based counterpart.", "url": "https://arxiv.org/abs/2307.14648"}, {"metadata": {"arXiv": "2307.14748", "Date": "Thu, 27 Jul 2023 10:12:17 ", "Title": "Semantic Image Completion and Enhancement using GANs", "Authors": ["Priyansh Saxena", "Raahat Gupta", "Akshat Maheshwari", "and Saumil Maheshwari"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["This work is part of 'High-Performance Vision Intelligence'; Part of the Studies in Computational Intelligence book series (SCI", "volume 913) and can be accessed at: https://link.springer.com/chapter/10.1007/978-981-15-6844-2_11. arXiv admin note: substantial text overlap with arXiv:1911.02222"]}, "abstract": "Semantic inpainting or image completion alludes to the task of inferring arbitrary large missing regions in images based on image semantics. Since the prediction of image pixels requires an indication of high-level context, this makes it significantly tougher than image completion, which is often more concerned with correcting data corruption and removing entire objects from the input image. On the other hand, image enhancement attempts to eliminate unwanted noise and blur from the image, along with sustaining most of the image details. Efficient image completion and enhancement model should be able to recover the corrupted and masked regions in images and then refine the image further to increase the quality of the output image. Generative Adversarial Networks (GAN), have turned out to be helpful in picture completion tasks. In this chapter, we will discuss the underlying GAN architecture and how they can be used used for image completion tasks.", "url": "https://arxiv.org/abs/2307.14748"}, {"metadata": {"arXiv": "2307.14917", "Date": "Thu, 27 Jul 2023 15:00:31 ", "Title": "NSA: Naturalistic Support Artifact to Boost Network Confidence", "Authors": ["Abhijith Sharma", "Phil Munz", "Apurva Narayan"], "Categories": "cs.CV cs.LG"}, "abstract": "Visual AI systems are vulnerable to natural and synthetic physical corruption in the real-world. Such corruption often arises unexpectedly and alters the model's performance. In recent years, the primary focus has been on adversarial attacks. However, natural corruptions (e.g., snow, fog, dust) are an omnipresent threat to visual AI systems and should be considered equally important. Many existing works propose interesting solutions to train robust models against natural corruption. These works either leverage image augmentations, which come with the additional cost of model training, or place suspicious patches in the scene to design unadversarial examples. In this work, we propose the idea of naturalistic support artifacts (NSA) for robust prediction. The NSAs are shown to be beneficial in scenarios where model parameters are inaccessible and adding artifacts in the scene is feasible. The NSAs are natural looking objects generated through artifact training using DC-GAN to have high visual fidelity in the scene. We test against natural corruptions on the Imagenette dataset and observe the improvement in prediction confidence score by four times. We also demonstrate NSA's capability to increase adversarial accuracy by 8\\% on average. Lastly, we qualitatively analyze NSAs using saliency maps to understand how they help improve prediction confidence.", "url": "https://arxiv.org/abs/2307.14917"}, {"metadata": {"arXiv": "2307.14959", "Date": "Thu, 27 Jul 2023 15:52:18 ", "Title": "Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification", "Authors": ["Marawan Elbatel", "Hualiang Wang", "Robert Mart\\'i", "Huazhu Fu", "Xiaomeng Li"], "Categories": "cs.CV cs.LG"}, "abstract": "In the medical field, federated learning commonly deals with highly imbalanced datasets, including skin lesions and gastrointestinal images. Existing federated methods under highly imbalanced datasets primarily focus on optimizing a global model without incorporating the intra-class variations that can arise in medical imaging due to different populations, findings, and scanners. In this paper, we study the inter-client intra-class variations with publicly available self-supervised auxiliary networks. Specifically, we find that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on every client yields consistent divergence measurements. Based on these findings, we derive a dynamic balanced model aggregation via self-supervised priors (MAS) to guide the global model optimization. Fed-MAS can be utilized with different local learning methods for effective model aggregation toward a highly robust and unbiased global model. Our code is available at \\url{https://github.com/xmed-lab/Fed-MAS}.", "url": "https://arxiv.org/abs/2307.14959"}, {"metadata": {"arXiv": "2307.15019", "Date": "Thu, 27 Jul 2023 17:22:41 ", "Title": "Self-Supervised Graph Transformer for Deepfake Detection", "Authors": ["Aminollah Khormali", "and Jiann-Shiun Yuan"], "Categories": "cs.CV cs.LG"}, "abstract": "Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision. To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations. The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches.", "url": "https://arxiv.org/abs/2307.15019"}, {"metadata": {"arXiv": "2307.15045", "Date": "Thu, 27 Jul 2023 17:51:52 ", "Title": "A Transformer-based Approach for Arabic Offline Handwritten Text Recognition", "Authors": ["Saleh Momeni and Bagher BabaAli"], "Categories": "cs.CV cs.LG"}, "abstract": "Handwriting recognition is a challenging and critical problem in the fields of pattern recognition and machine learning, with applications spanning a wide range of domains. In this paper, we focus on the specific issue of recognizing offline Arabic handwritten text. Existing approaches typically utilize a combination of convolutional neural networks for image feature extraction and recurrent neural networks for temporal modeling, with connectionist temporal classification used for text generation. However, these methods suffer from a lack of parallelization due to the sequential nature of recurrent neural networks. Furthermore, these models cannot account for linguistic rules, necessitating the use of an external language model in the post-processing stage to boost accuracy. To overcome these issues, we introduce two alternative architectures, namely the Transformer Transducer and the standard sequence-to-sequence Transformer, and compare their performance in terms of accuracy and speed. Our approach can model language dependencies and relies only on the attention mechanism, thereby making it more parallelizable and less complex. We employ pre-trained Transformers for both image understanding and language modeling. Our evaluation on the Arabic KHATT dataset demonstrates that our proposed method outperforms the current state-of-the-art approaches for recognizing offline Arabic handwritten text.", "url": "https://arxiv.org/abs/2307.15045"}, {"metadata": {"arXiv": "2307.14366", "Date": "Tue, 25 Jul 2023 09:12:50 ", "Title": "Explainable Disparity Compensation for Efficient Fair Ranking", "Authors": ["Abraham Gale", "Am\\'Elie Marian"], "Categories": "cs.LG cs.DB", "Comments": ["22 pages", "5 figures"]}, "abstract": "Ranking functions that are used in decision systems often produce disparate results for different populations because of bias in the underlying data. Addressing, and compensating for, these disparate outcomes is a critical problem for fair decision-making. Recent compensatory measures have mostly focused on opaque transformations of the ranking functions to satisfy fairness guarantees or on the use of quotas or set-asides to guarantee a minimum number of positive outcomes to members of underrepresented groups. In this paper we propose easily explainable data-driven compensatory measures for ranking functions. Our measures rely on the generation of bonus points given to members of underrepresented groups to address disparity in the ranking function. The bonus points can be set in advance, and can be combined, allowing for considering the intersections of representations and giving better transparency to stakeholders. We propose efficient sampling-based algorithms to calculate the number of bonus points to minimize disparity. We validate our algorithms using real-world school admissions and recidivism datasets, and compare our results with that of existing fair ranking algorithms.", "url": "https://arxiv.org/abs/2307.14366"}, {"metadata": {"arXiv": "2307.14371", "Date": "Tue, 25 Jul 2023 13:53:47 ", "Title": "Prediction of depression status in college students using a Naive Bayes classifier based machine learning model", "Authors": ["Fred Torres Cruz", "Evelyn Eliana Coaquira Flores", "Sebastian Jarom Condori Quispe"], "Categories": "cs.LG stat.AP"}, "abstract": "This study presents a machine learning model based on the Naive Bayes classifier for predicting the level of depression in university students, the objective was to improve prediction accuracy using a machine learning model involving 70% training data and 30% validation data based on the Naive Bayes classifier, the collected data includes factors associated with depression from 519 university students, the results showed an accuracy of 78.03%, high sensitivity in detecting positive cases of depression, especially at moderate and severe levels, and significant specificity in correctly classifying negative cases, these findings highlight the effectiveness of the model in early detection and treatment of depression, benefiting vulnerable sectors and contributing to the improvement of mental health in the student population.", "url": "https://arxiv.org/abs/2307.14371"}, {"metadata": {"arXiv": "2307.14373", "Date": "Tue, 25 Jul 2023 15:38:18 ", "Title": "Piecewise Linear Functions Representable with Infinite Width Shallow ReLU Neural Networks", "Authors": ["Sarah McCarty"], "Categories": "cs.LG math.FA"}, "abstract": "This paper analyzes representations of continuous piecewise linear functions with infinite width, finite cost shallow neural networks using the rectified linear unit (ReLU) as an activation function. Through its integral representation, a shallow neural network can be identified by the corresponding signed, finite measure on an appropriate parameter space. We map these measures on the parameter space to measures on the projective $n$-sphere cross $\\mathbb{R}$, allowing points in the parameter space to be bijectively mapped to hyperplanes in the domain of the function. We prove a conjecture of Ongie et al. that every continuous piecewise linear function expressible with this kind of infinite width neural network is expressible as a finite width shallow ReLU neural network.", "url": "https://arxiv.org/abs/2307.14373"}, {"metadata": {"arXiv": "2307.14374", "Date": "Tue, 25 Jul 2023 16:03:44 ", "Title": "Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design", "Authors": ["Suchetana Sadhukhan and Vivek Kumar Yadav"], "Categories": "cs.LG", "Comments": ["38 pages", "16 figures"]}, "abstract": "This study provides a comprehensive time series analysis of daily industry-specific, country-wise CO$_2$ emissions from January 2019 to February 2023. The research focuses on the Power, Industry, Ground Transport, Domestic Aviation, and International Aviation sectors in European countries (EU27 & UK, Italy, Germany, Spain) and India, utilizing near-real-time activity data from the Carbon Monitor research initiative. To identify regular emission patterns, the data from the year 2020 is excluded due to the disruptive effects caused by the COVID-19 pandemic. The study then performs a principal component analysis (PCA) to determine the key contributors to CO$_2$ emissions. The analysis reveals that the Power, Industry, and Ground Transport sectors account for a significant portion of the variance in the dataset. A 7-day moving averaged dataset is employed for further analysis to facilitate robust predictions. This dataset captures both short-term and long-term trends and enhances the quality of the data for prediction purposes. The study utilizes Long Short-Term Memory (LSTM) models on the 7-day moving averaged dataset to effectively predict emissions and provide insights for policy decisions, mitigation strategies, and climate change efforts. During the training phase, the stability and convergence of the LSTM models are ensured, which guarantees their reliability in the testing phase. The evaluation of the loss function indicates this reliability. The model achieves high efficiency, as demonstrated by $R^2$ values ranging from 0.8242 to 0.995 for various countries and sectors. Furthermore, there is a proposal for utilizing scandium and boron/aluminium-based thin films as exceptionally efficient materials for capturing CO$_2$ (with a binding energy range from -3.0 to -3.5 eV). These materials are shown to surpass the affinity of graphene and boron nitride sheets in this regard.", "url": "https://arxiv.org/abs/2307.14374"}, {"metadata": {"arXiv": "2307.14375", "Date": "Tue, 25 Jul 2023 16:37:09 ", "Title": "DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm", "Authors": ["Ying Xiao", "Hou-biao Li", "Yu-pu Zhang"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["21 pages", "10 figures"], "MSC-class": "62H30", "ACM-class": "I.5.3"}, "abstract": "With the development of Big data technology, data analysis has become increasingly important. Traditional clustering algorithms such as K-means are highly sensitive to the initial centroid selection and perform poorly on non-convex datasets. In this paper, we address these problems by proposing a data-driven Bregman divergence parameter optimization clustering algorithm (DBGSA), which combines the Universal Gravitational Algorithm to bring similar points closer in the dataset. We construct a gravitational coefficient equation with a special property that gradually reduces the influence factor as the iteration progresses. Furthermore, we introduce the Bregman divergence generalized power mean information loss minimization to identify cluster centers and build a hyperparameter identification optimization model, which effectively solves the problems of manual adjustment and uncertainty in the improved dataset. Extensive experiments are conducted on four simulated datasets and six real datasets. The results demonstrate that DBGSA significantly improves the accuracy of various clustering algorithms by an average of 63.8\\% compared to other similar approaches like enhanced clustering algorithms and improved datasets. Additionally, a three-dimensional grid search was established to compare the effects of different parameter values within threshold conditions, and it was discovered the parameter set provided by our model is optimal. This finding provides strong evidence of the high accuracy and robustness of the algorithm.", "url": "https://arxiv.org/abs/2307.14375"}, {"metadata": {"arXiv": "2307.14380", "Date": "Tue, 25 Jul 2023 19:40:41 ", "Title": "Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations", "Authors": ["Daniel Ka{\\l}u\\.za and Andrzej Janusz and Dominik \\'Sl\\k{e}zak"], "Categories": "cs.LG cs.HC", "Comments": ["9 pages", "2 figures", "4 tables Extended version of paper accepted for 26th European Conference on Artificial Intelligence ECAI 2023 with appendices"], "ACM-class": "I.2.6"}, "abstract": "Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. The proposed methods require little to no intersection between samples annotated by different experts. Our experiments on four public datasets indicate the robustness and superiority of the proposed methods in both, the estimation of the annotator's reliability, and the assignment of actual labels, against the state-of-the-art algorithms and the simple majority voting.", "url": "https://arxiv.org/abs/2307.14380"}, {"metadata": {"arXiv": "2307.14439", "Date": "Wed, 26 Jul 2023 18:16:43 ", "Title": "Fixed Integral Neural Networks", "Authors": ["Ryan Kortvelesy"], "Categories": "cs.LG"}, "abstract": "It is often useful to perform integration over learned functions represented by neural networks. However, this integration is usually performed numerically, as analytical integration over learned functions (especially neural networks) is generally viewed as intractable. In this work, we present a method for representing the analytical integral of a learned function $f$. This allows the exact integral of a neural network to be computed, and enables constrained neural networks to be parametrised by applying constraints directly to the integral. Crucially, we also introduce a method to constrain $f$ to be positive, a necessary condition for many applications (e.g. probability distributions, distance metrics, etc). Finally, we introduce several applications where our fixed-integral neural network (FINN) can be utilised.", "url": "https://arxiv.org/abs/2307.14439"}, {"metadata": {"arXiv": "2307.14453", "Date": "Wed, 26 Jul 2023 18:50:32 ", "Title": "Predictive Maintenance of Armoured Vehicles using Machine Learning Approaches", "Authors": ["Prajit Sengupta", "Anant Mehta", "Prashant Singh Rana"], "Categories": "cs.LG", "Comments": ["In Conference Proceedings of INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE", "MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE (pg:25-31) - (New Delhi", "2023)"]}, "abstract": "Armoured vehicles are specialized and complex pieces of machinery designed to operate in high-stress environments, often in combat or tactical situations. This study proposes a predictive maintenance-based ensemble system that aids in predicting potential maintenance needs based on sensor data collected from these vehicles. The proposed model's architecture involves various models such as Light Gradient Boosting, Random Forest, Decision Tree, Extra Tree Classifier and Gradient Boosting to predict the maintenance requirements of the vehicles accurately. In addition, K-fold cross validation, along with TOPSIS analysis, is employed to evaluate the proposed ensemble model's stability. The results indicate that the proposed system achieves an accuracy of 98.93%, precision of 99.80% and recall of 99.03%. The algorithm can effectively predict maintenance needs, thereby reducing vehicle downtime and improving operational efficiency. Through comparisons between various algorithms and the suggested ensemble, this study highlights the potential of machine learning-based predictive maintenance solutions.", "url": "https://arxiv.org/abs/2307.14453"}, {"metadata": {"arXiv": "2307.14474", "Date": "Wed, 26 Jul 2023 19:41:05 ", "Title": "Limits to Reservoir Learning", "Authors": ["Anthony M. Polloreno"], "Categories": "cs.LG cs.IT math.IT", "Comments": ["13 pages", "2 figures"]}, "abstract": "In this work, we bound a machine's ability to learn based on computational limitations implied by physicality. We start by considering the information processing capacity (IPC), a normalized measure of the expected squared error of a collection of signals to a complete basis of functions. We use the IPC to measure the degradation under noise of the performance of reservoir computers, a particular kind of recurrent network, when constrained by physical considerations. First, we show that the IPC is at most a polynomial in the system size $n$, even when considering the collection of $2^n$ possible pointwise products of the $n$ output signals. Next, we argue that this degradation implies that the family of functions represented by the reservoir requires an exponential number of samples to learn in the presence of the reservoir's noise. Finally, we conclude with a discussion of the performance of the same collection of $2^n$ functions without noise when being used for binary classification.", "url": "https://arxiv.org/abs/2307.14474"}, {"metadata": {"arXiv": "2307.14490", "Date": "Wed, 26 Jul 2023 20:29:15 ", "Title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs", "Authors": ["Brandon Mayer", "Anton Tsitsulin", "Hendrik Fichtenberger", "Jonathan Halcrow", "Bryan Perozzi"], "Categories": "cs.LG cs.DC cs.SI", "Comments": ["As appeared at KDD 2023"], "DOI": "10.1145/3580305.3599840"}, "abstract": "Graphs are a representation of structured data that captures the relationships between sets of objects. With the ubiquity of available network data, there is increasing industrial and academic need to quickly analyze graphs with billions of nodes and trillions of edges. A common first step for network understanding is Graph Embedding, the process of creating a continuous representation of nodes in a graph. A continuous representation is often more amenable, especially at scale, for solving downstream machine learning tasks such as classification, link prediction, and clustering. A high-performance graph embedding architecture leveraging Tensor Processing Units (TPUs) with configurable amounts of high-bandwidth memory is presented that simplifies the graph embedding problem and can scale to graphs with billions of nodes and trillions of edges. We verify the embedding space quality on real and synthetic large-scale datasets.", "url": "https://arxiv.org/abs/2307.14490"}, {"metadata": {"arXiv": "2307.14528", "Date": "Wed, 26 Jul 2023 22:12:31 ", "Title": "Function Value Learning: Adaptive Learning Rates Based on the Polyak Stepsize and Function Splitting in ERM", "Authors": ["Guillaume Garrigos", "Robert M. Gower", "Fabian Schaipp"], "Categories": "cs.LG math.OC", "Comments": ["38 pages", "2 figures"], "MSC-class": "90C53, 74S60, 90C06, 62L20, 68W20, 15B52, 65Y20, 68W40", "ACM-class": "G.1.6"}, "abstract": "Here we develop variants of SGD (stochastic gradient descent) with an adaptive step size that make use of the sampled loss values. In particular, we focus on solving a finite sum-of-terms problem, also known as empirical risk minimization. We first detail an idealized adaptive method called $\\texttt{SPS}_+$ that makes use of the sampled loss values and assumes knowledge of the sampled loss at optimality. This $\\texttt{SPS}_+$ is a minor modification of the SPS (Stochastic Polyak Stepsize) method, where the step size is enforced to be positive. We then show that $\\texttt{SPS}_+$ achieves the best known rates of convergence for SGD in the Lipschitz non-smooth. We then move onto to develop $\\texttt{FUVAL}$, a variant of $\\texttt{SPS}_+$ where the loss values at optimality are gradually learned, as opposed to being given. We give three viewpoints of $\\texttt{FUVAL}$, as a projection based method, as a variant of the prox-linear method, and then as a particular online SGD method. We then present a convergence analysis of $\\texttt{FUVAL}$ and experimental results. The shortcomings of our work is that the convergence analysis of $\\texttt{FUVAL}$ shows no advantage over SGD. Another shortcomming is that currently only the full batch version of $\\texttt{FUVAL}$ shows a minor advantages of GD (Gradient Descent) in terms of sensitivity to the step size. The stochastic version shows no clear advantage over SGD. We conjecture that large mini-batches are required to make $\\texttt{FUVAL}$ competitive. Currently the new $\\texttt{FUVAL}$ method studied in this paper does not offer any clear theoretical or practical advantage. We have chosen to make this draft available online nonetheless because of some of the analysis techniques we use, such as the non-smooth analysis of $\\texttt{SPS}_+$, and also to show an apparently interesting approach that currently does not work.", "url": "https://arxiv.org/abs/2307.14528"}, {"metadata": {"arXiv": "2307.14531", "Date": "Wed, 26 Jul 2023 22:39:47 ", "Title": "Controlling the Inductive Bias of Wide Neural Networks by Modifying the Kernel's Spectrum", "Authors": ["Amnon Geifman", "Daniel Barzilai", "Ronen Basri and Meirav Galun"], "Categories": "cs.LG"}, "abstract": "Wide neural networks are biased towards learning certain functions, influencing both the rate of convergence of gradient descent (GD) and the functions that are reachable with GD in finite training time. As such, there is a great need for methods that can modify this bias according to the task at hand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel family of constructed kernels that can be used to approximate kernels with desired eigenvalues for which no closed form is known. We leverage the duality between wide neural networks and Neural Tangent Kernels and propose a preconditioned gradient descent method, which alters the trajectory of GD. As a result, this allows for a polynomial and, in some cases, exponential training speedup without changing the final solution. Our method is both computationally efficient and simple to implement.", "url": "https://arxiv.org/abs/2307.14531"}, {"metadata": {"arXiv": "2307.14596", "Date": "Thu, 27 Jul 2023 02:43:21 ", "Title": "HUTFormer: Hierarchical U-Net Transformer for Long-Term Traffic Forecasting", "Authors": ["Zezhi Shao", "Fei Wang", "Zhao Zhang", "Yuchen Fang", "Guangyin Jin", "Yongjun Xu"], "Categories": "cs.LG", "Comments": ["TKDE Under Review"]}, "abstract": "Traffic forecasting, which aims to predict traffic conditions based on historical observations, has been an enduring research topic and is widely recognized as an essential component of intelligent transportation. Recent proposals on Spatial-Temporal Graph Neural Networks (STGNNs) have made significant progress by combining sequential models with graph convolution networks. However, due to high complexity issues, STGNNs only focus on short-term traffic forecasting, e.g., 1-hour forecasting, while ignoring more practical long-term forecasting. In this paper, we make the first attempt to explore long-term traffic forecasting, e.g., 1-day forecasting. To this end, we first reveal its unique challenges in exploiting multi-scale representations. Then, we propose a novel Hierarchical U-net TransFormer (HUTFormer) to address the issues of long-term traffic forecasting. HUTFormer consists of a hierarchical encoder and decoder to jointly generate and utilize multi-scale representations of traffic data. Specifically, for the encoder, we propose window self-attention and segment merging to extract multi-scale representations from long-term traffic data. For the decoder, we design a cross-scale attention mechanism to effectively incorporate multi-scale representations. In addition, HUTFormer employs an efficient input embedding strategy to address the complexity issues. Extensive experiments on four traffic datasets show that the proposed HUTFormer significantly outperforms state-of-the-art traffic forecasting and long time series forecasting baselines.", "url": "https://arxiv.org/abs/2307.14596"}, {"metadata": {"arXiv": "2307.14619", "Date": "Thu, 27 Jul 2023 04:27:26 ", "Title": "Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior", "Authors": ["Adam Block", "Daniel Pfrommer", "Max Simchowitz"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["107 pages", "6 figures"]}, "abstract": "We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers - either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call \"total variation continuity\" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accurately estimates the score of the (noise-augmented) expert policy, then the distribution of imitator trajectories is close to the demonstrator distribution in a natural optimal transport distance. Our analysis constructs intricate couplings between noise-augmented trajectories, a technique that may be of independent interest. We conclude by empirically validating our algorithmic recommendations.", "url": "https://arxiv.org/abs/2307.14619"}, {"metadata": {"arXiv": "2307.14628", "Date": "Thu, 27 Jul 2023 05:08:49 ", "Title": "Rapid and Scalable Bayesian AB Testing", "Authors": ["Srivas Chennu", "Andrew Maher", "Christian Pangerl", "Subash Prabanantham", "Jae Hyeon Bae", "Jamie Martin and Bud Goswami"], "Categories": "cs.LG stat.ME", "Comments": ["The 10th IEEE International Conference On Data Science And Advanced Analytics"]}, "abstract": "AB testing aids business operators with their decision making, and is considered the gold standard method for learning from data to improve digital user experiences. However, there is usually a gap between the requirements of practitioners, and the constraints imposed by the statistical hypothesis testing methodologies commonly used for analysis of AB tests. These include the lack of statistical power in multivariate designs with many factors, correlations between these factors, the need of sequential testing for early stopping, and the inability to pool knowledge from past tests. Here, we propose a solution that applies hierarchical Bayesian estimation to address the above limitations. In comparison to current sequential AB testing methodology, we increase statistical power by exploiting correlations between factors, enabling sequential testing and progressive early stopping, without incurring excessive false positive risk. We also demonstrate how this methodology can be extended to enable the extraction of composite global learnings from past AB tests, to accelerate future tests. We underpin our work with a solid theoretical framework that articulates the value of hierarchical estimation. We demonstrate its utility using both numerical simulations and a large set of real-world AB tests. Together, these results highlight the practical value of our approach for statistical inference in the technology industry.", "url": "https://arxiv.org/abs/2307.14628"}, {"metadata": {"arXiv": "2307.14643", "Date": "Thu, 27 Jul 2023 06:33:17 ", "Title": "MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy", "Authors": ["Haitao Nie", "Shengbo Zhang", "Bin Xie"], "Categories": "cs.LG"}, "abstract": "How to accurately measure the relevance and redundancy of features is an age-old challenge in the field of feature selection. However, existing filter-based feature selection methods cannot directly measure redundancy for continuous data. In addition, most methods rely on manually specifying the number of features, which may introduce errors in the absence of expert knowledge. In this paper, we propose a non-parametric feature selection algorithm based on maximum inter-class variation and minimum redundancy, abbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel density estimation on the features to capture their similarities and differences in inter-class and overall distributions. Subsequently, we present the criteria for maximum inter-class variation and minimum redundancy (MVMR), wherein the inter-class probability distributions are employed to reflect feature relevance and the distances between overall probability distributions are used to quantify redundancy. Finally, we employ an AGA to search for the feature subset that minimizes the MVMR. Compared with ten state-of-the-art methods, MVMR-FS achieves the highest average accuracy and improves the accuracy by 5% to 11%.", "url": "https://arxiv.org/abs/2307.14643"}, {"metadata": {"arXiv": "2307.14668", "Date": "Thu, 27 Jul 2023 07:42:44 ", "Title": "Bipartite Ranking Fairness through a Model Agnostic Ordering Adjustment", "Authors": ["Sen Cui", "Weishen Pan", "Changshui Zhang", "Fei Wang"], "Categories": "cs.LG cs.CY", "Comments": ["This paper is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: substantial text overlap with arXiv:2006.08267"]}, "abstract": "Algorithmic fairness has been a serious concern and received lots of interest in machine learning community. In this paper, we focus on the bipartite ranking scenario, where the instances come from either the positive or negative class and the goal is to learn a ranking function that ranks positive instances higher than negative ones. While there could be a trade-off between fairness and performance, we propose a model agnostic post-processing framework xOrder for achieving fairness in bipartite ranking and maintaining the algorithm classification performance. In particular, we optimize a weighted sum of the utility as identifying an optimal warping path across different protected groups and solve it through a dynamic programming process. xOrder is compatible with various classification models and ranking fairness metrics, including supervised and unsupervised fairness metrics. In addition to binary groups, xOrder can be applied to multiple protected groups. We evaluate our proposed algorithm on four benchmark data sets and two real-world patient electronic health record repositories. xOrder consistently achieves a better balance between the algorithm utility and ranking fairness on a variety of datasets with different metrics. From the visualization of the calibrated ranking scores, xOrder mitigates the score distribution shifts of different groups compared with baselines. Moreover, additional analytical results verify that xOrder achieves a robust performance when faced with fewer samples and a bigger difference between training and testing ranking score distributions.", "url": "https://arxiv.org/abs/2307.14668"}, {"metadata": {"arXiv": "2307.14680", "Date": "Thu, 27 Jul 2023 08:10:19 ", "Title": "TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting", "Authors": ["Nancy Xu", "Chrysoula Kosma", "Michalis Vazirgiannis"], "Categories": "cs.LG"}, "abstract": "Time series forecasting lies at the core of important real-world applications in many fields of science and engineering. The abundance of large time series datasets that consist of complex patterns and long-term dependencies has led to the development of various neural network architectures. Graph neural network approaches, which jointly learn a graph structure based on the correlation of raw values of multivariate time series while forecasting, have recently seen great success. However, such solutions are often costly to train and difficult to scale. In this paper, we propose TimeGNN, a method that learns dynamic temporal graph representations that can capture the evolution of inter-series patterns along with the correlations of multiple series. TimeGNN achieves inference times 4 to 80 times faster than other state-of-the-art graph-based methods while achieving comparable forecasting performance", "url": "https://arxiv.org/abs/2307.14680"}, {"metadata": {"arXiv": "2307.14732", "Date": "Thu, 27 Jul 2023 09:42:25 ", "Title": "A Strategic Framework for Optimal Decisions in Football 1-vs-1 Shot-Taking Situations: An Integrated Approach of Machine Learning, Theory-Based Modeling, and Game Theory", "Authors": ["Calvin C. K. Yeung and Keisuke Fujii"], "Categories": "cs.LG cs.GT"}, "abstract": "Complex interactions between two opposing agents frequently occur in domains of machine learning, game theory, and other application domains. Quantitatively analyzing the strategies involved can provide an objective basis for decision-making. One such critical scenario is shot-taking in football, where decisions, such as whether the attacker should shoot or pass the ball and whether the defender should attempt to block the shot, play a crucial role in the outcome of the game. However, there are currently no effective data-driven and/or theory-based approaches to analyzing such situations. To address this issue, we proposed a novel framework to analyze such scenarios based on game theory, where we estimate the expected payoff with machine learning (ML) models, and additional features for ML models were extracted with a theory-based shot block model. Conventionally, successes or failures (1 or 0) are used as payoffs, while a success shot (goal) is extremely rare in football. Therefore, we proposed the Expected Probability of Shot On Target (xSOT) metric to evaluate players' actions even if the shot results in no goal; this allows for effective differentiation and comparison between different shots and even enables counterfactual shot situation analysis. In our experiments, we have validated the framework by comparing it with baseline and ablated models. Furthermore, we have observed a high correlation between the xSOT and existing metrics. This alignment of information suggests that xSOT provides valuable insights. Lastly, as an illustration, we studied optimal strategies in the World Cup 2022 and analyzed a shot situation in EURO 2020.", "url": "https://arxiv.org/abs/2307.14732"}, {"metadata": {"arXiv": "2307.14751", "Date": "Thu, 27 Jul 2023 10:19:10 ", "Title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal Adversarial Masks", "Authors": ["Buse G. A. Tekgul", "N. Asokan"], "Categories": "cs.LG cs.CR", "Comments": ["13 pages", "5 figures", "7 tables"]}, "abstract": "We propose FLARE, the first fingerprinting mechanism to verify whether a suspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of another (victim) policy. We first show that it is possible to find non-transferable, universal adversarial masks, i.e., perturbations, to generate adversarial examples that can successfully transfer from a victim policy to its modified versions but not to independently trained policies. FLARE employs these masks as fingerprints to verify the true ownership of stolen DRL policies by measuring an action agreement value over states perturbed via such masks. Our empirical evaluations show that FLARE is effective (100% action agreement on stolen copies) and does not falsely accuse independent policies (no false positives). FLARE is also robust to model modification attacks and cannot be easily evaded by more informed adversaries without negatively impacting agent performance. We also show that not all universal adversarial masks are suitable candidates for fingerprints due to the inherent characteristics of DRL policies. The spatio-temporal dynamics of DRL problems and sequential decision-making process make characterizing the decision boundary of DRL policies more difficult, as well as searching for universal masks that capture the geometry of it.", "url": "https://arxiv.org/abs/2307.14751"}, {"metadata": {"arXiv": "2307.14758", "Date": "Thu, 27 Jul 2023 10:33:54 ", "Title": "Towards Practicable Sequential Shift Detectors", "Authors": ["Oliver Cobb and Arnaud Van Looveren"], "Categories": "cs.LG", "Comments": ["ICML 2022 Workshop on Principles of Distribution Shift (PODS)"]}, "abstract": "There is a growing awareness of the harmful effects of distribution shift on the performance of deployed machine learning models. Consequently, there is a growing interest in detecting these shifts before associated costs have time to accumulate. However, desiderata of crucial importance to the practicable deployment of sequential shift detectors are typically overlooked by existing works, precluding their widespread adoption. We identify three such desiderata, highlight existing works relevant to their satisfaction, and recommend impactful directions for future research.", "url": "https://arxiv.org/abs/2307.14758"}, {"metadata": {"arXiv": "2307.14778", "Date": "Thu, 27 Jul 2023 11:14:11 ", "Title": "MATNilm: Multi-appliance-task Non-intrusive Load Monitoring with Limited Labeled Data", "Authors": ["Jing Xiong", "Tianqi Hong", "Dongbo Zhao", "and Yu Zhang"], "Categories": "cs.LG eess.SP"}, "abstract": "Non-intrusive load monitoring (NILM) identifies the status and power consumption of various household appliances by disaggregating the total power usage signal of an entire house. Efficient and accurate load monitoring facilitates user profile establishment, intelligent household energy management, and peak load shifting. This is beneficial for both the end-users and utilities by improving the overall efficiency of a power distribution network. Existing approaches mainly focus on developing an individual model for each appliance. Those approaches typically rely on a large amount of household-labeled data which is hard to collect. In this paper, we propose a multi-appliance-task framework with a training-efficient sample augmentation (SA) scheme that boosts the disaggregation performance with limited labeled data. For each appliance, we develop a shared-hierarchical split structure for its regression and classification tasks. In addition, we also propose a two-dimensional attention mechanism in order to capture spatio-temporal correlations among all appliances. With only one-day training data and limited appliance operation profiles, the proposed SA algorithm can achieve comparable test performance to the case of training with the full dataset. Finally, simulation results show that our proposed approach features a significantly improved performance over many baseline models. The relative errors can be reduced by more than 50\\% on average. The codes of this work are available at https://github.com/jxiong22/MATNilm", "url": "https://arxiv.org/abs/2307.14778"}, {"metadata": {"arXiv": "2307.14788", "Date": "Thu, 27 Jul 2023 11:29:57 ", "Title": "Likely, Light, and Accurate Context-Free Clusters-based Trajectory Prediction", "Authors": ["Tiago Rodrigues de Almeida and Oscar Martinez Mozos"], "Categories": "cs.LG", "Comments": ["This paper has been accepted to the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)", "which will be held in Bilbao", "Spain on September 24-28", "2023"]}, "abstract": "Autonomous systems in the road transportation network require intelligent mechanisms that cope with uncertainty to foresee the future. In this paper, we propose a multi-stage probabilistic approach for trajectory forecasting: trajectory transformation to displacement space, clustering of displacement time series, trajectory proposals, and ranking proposals. We introduce a new deep feature clustering method, underlying self-conditioned GAN, which copes better with distribution shifts than traditional methods. Additionally, we propose novel distance-based ranking proposals to assign probabilities to the generated trajectories that are more efficient yet accurate than an auxiliary neural network. The overall system surpasses context-free deep generative models in human and road agents trajectory data while performing similarly to point estimators when comparing the most probable trajectory.", "url": "https://arxiv.org/abs/2307.14788"}, {"metadata": {"arXiv": "2307.14823", "Date": "Thu, 27 Jul 2023 13:00:21 ", "Title": "Fading memory as inductive bias in residual recurrent networks", "Authors": ["Igor Dubinin", "Felix Effenberger"], "Categories": "cs.LG cs.CV"}, "abstract": "Residual connections have been proposed as architecture-based inductive bias to mitigate the problem of exploding and vanishing gradients and increase task performance in both feed-forward and recurrent networks (RNNs) when trained with the backpropagation algorithm. Yet, little is known about how residual connections in RNNs influence their dynamics and fading memory properties. Here, we introduce weakly coupled residual recurrent networks (WCRNNs) in which residual connections result in well-defined Lyapunov exponents and allow for studying properties of fading memory. We investigate how the residual connections of WCRNNs influence their performance, network dynamics, and memory properties on a set of benchmark tasks. We show that several distinct forms of residual connections yield effective inductive biases that result in increased network expressivity. In particular, residual connections that (i) result in network dynamics at the proximity of the edge of chaos, (ii) allow networks to capitalize on characteristic spectral properties of the data, and (iii) result in heterogeneous memory properties are shown to increase practical expressivity. In addition, we demonstrate how our results can be extended to non-linear residuals and introduce a weakly coupled residual initialization scheme that can be used for Elman RNNs", "url": "https://arxiv.org/abs/2307.14823"}, {"metadata": {"arXiv": "2307.14940", "Date": "Thu, 27 Jul 2023 15:32:02 ", "Title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs", "Authors": ["C. Coelho", "M. Fernanda P. Costa", "L. L. Ferr\\'as"], "Categories": "cs.LG math.OC", "ACM-class": "I.5.1; G.1.6"}, "abstract": "The continuous dynamics of natural systems has been effectively modelled using Neural Ordinary Differential Equations (Neural ODEs). However, for accurate and meaningful predictions, it is crucial that the models follow the underlying rules or laws that govern these systems. In this work, we propose a self-adaptive penalty algorithm for Neural ODEs to enable modelling of constrained natural systems. The proposed self-adaptive penalty function can dynamically adjust the penalty parameters. The explicit introduction of prior knowledge helps to increase the interpretability of Neural ODE -based models. We validate the proposed approach by modelling three natural systems with prior knowledge constraints: population growth, chemical reaction evolution, and damped harmonic oscillator motion. The numerical experiments and a comparison with other penalty Neural ODE approaches and \\emph{vanilla} Neural ODE, demonstrate the effectiveness of the proposed self-adaptive penalty algorithm for Neural ODEs in modelling constrained natural systems. Moreover, the self-adaptive penalty approach provides more accurate and robust models with reliable and meaningful predictions.", "url": "https://arxiv.org/abs/2307.14940"}, {"metadata": {"arXiv": "2307.14952", "Date": "Thu, 27 Jul 2023 15:46:46 ", "Title": "Network Fault-tolerant and Byzantine-resilient Social Learning via Collaborative Hierarchical Non-Bayesian Learning", "Authors": ["Connor Mclaughlin", "Matthew Ding", "Denis Edogmus", "Lili Su"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["11 pages", "1 figure"]}, "abstract": "As the network scale increases, existing fully distributed solutions start to lag behind the real-world challenges such as (1) slow information propagation, (2) network communication failures, and (3) external adversarial attacks. In this paper, we focus on hierarchical system architecture and address the problem of non-Bayesian learning over networks that are vulnerable to communication failures and adversarial attacks. On network communication, we consider packet-dropping link failures. We first propose a hierarchical robust push-sum algorithm that can achieve average consensus despite frequent packet-dropping link failures. We provide a sparse information fusion rule between the parameter server and arbitrarily selected network representatives. Then, interleaving the consensus update step with a dual averaging update with Kullback-Leibler (KL) divergence as the proximal function, we obtain a packet-dropping fault-tolerant non-Bayesian learning algorithm with provable convergence guarantees. On external adversarial attacks, we consider Byzantine attacks in which the compromised agents can send maliciously calibrated messages to others (including both the agents and the parameter server). To avoid the curse of dimensionality of Byzantine consensus, we solve the non-Bayesian learning problem via running multiple dynamics, each of which only involves Byzantine consensus with scalar inputs. To facilitate resilient information propagation across sub-networks, we use a novel Byzantine-resilient gossiping-type rule at the parameter server.", "url": "https://arxiv.org/abs/2307.14952"}, {"metadata": {"arXiv": "2307.14988", "Date": "Thu, 27 Jul 2023 16:30:27 ", "Title": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs", "Authors": ["Or Sharir and Anima Anandkumar"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs. For example, an AI writing assistant is required to update its suggestions in real time as a document is edited. Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization. Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change. However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse. To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values. We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexity proportional to the fraction of the modified inputs. Our experiments with adapting the OPT-125M pre-trained language model demonstrate comparable accuracy on document classification while requiring 12.1X (median) fewer operations for processing sequences of atomic edits.", "url": "https://arxiv.org/abs/2307.14988"}, {"metadata": {"arXiv": "2307.15007", "Date": "Thu, 27 Jul 2023 17:06:02 ", "Title": "Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability", "Authors": ["Usha Bhalla", "Suraj Srinivas", "Himabindu Lakkaraju"], "Categories": "cs.LG cs.CV"}, "abstract": "With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by highlighting features that are critical to model predictions; however, prior work has shown that these explanations may not be faithful, and even more concerning is our inability to verify them. Specifically, it is nontrivial to evaluate if a given attribution is correct with respect to the underlying model. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful and verifiable, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we aim to bridge the gap between the aforementioned strategies by proposing Verifiability Tuning (VerT), a method that transforms black-box models into models that naturally yield faithful and verifiable feature attributions. We begin by introducing a formal theoretical framework to understand verifiability and show that attributions produced by standard models cannot be verified. We then leverage this framework to propose a method to build verifiable models and feature attributions out of fully trained black-box models. Finally, we perform extensive experiments on semi-synthetic and real-world datasets, and show that VerT produces models that (1) yield explanations that are correct and verifiable and (2) are faithful to the original black-box models they are meant to explain.", "url": "https://arxiv.org/abs/2307.15007"}, {"metadata": {"arXiv": "2307.15034", "Date": "Thu, 27 Jul 2023 17:42:06 ", "Title": "Speeding up Fourier Neural Operators via Mixed Precision", "Authors": ["Colin White", "Renbo Tu", "Jean Kossaifi", "Gennady Pekhimenko", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "The Fourier neural operator (FNO) is a powerful technique for learning surrogate maps for partial differential equation (PDE) solution operators. For many real-world applications, which often require high-resolution data points, training time and memory usage are significant bottlenecks. While there are mixed-precision training techniques for standard neural networks, those work for real-valued datatypes on finite dimensions and therefore cannot be directly applied to FNO, which crucially operates in the (complex-valued) Fourier domain and in function spaces. On the other hand, since the Fourier transform is already an approximation (due to discretization error), we do not need to perform the operation at full precision. In this work, we (i) profile memory and runtime for FNO with full and mixed-precision training, (ii) conduct a study on the numerical stability of mixed-precision training of FNO, and (iii) devise a training routine which substantially decreases training time and memory usage (up to 34%), with little or no reduction in accuracy, on the Navier-Stokes and Darcy flow equations. Combined with the recently proposed tensorized FNO (Kossaifi et al., 2023), the resulting model has far better performance while also being significantly faster than the original FNO.", "url": "https://arxiv.org/abs/2307.15034"}, {"metadata": {"arXiv": "2307.14938", "Date": "Thu, 27 Jul 2023 15:30:22 ", "Title": "Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops", "Authors": ["Saber Jafarpour and Akash Harapanahalli and Samuel Coogan"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "In this paper, we propose a computationally efficient framework for interval reachability of neural network controlled systems. Our approach builds upon inclusion functions for the neural network controller and the open-loop system. We observe that many state-of-the-art neural network verifiers can produce inclusion functions for neural networks. We introduce and analyze a new class of inclusion functions for the open-loop dynamics based on bounds of the function Jacobian that is particularly suitable for capturing the interactions between systems and neural network controllers. Next, for any dynamical system, we use inclusion functions to construct an embedding system with twice the number of states as the original system. We show that a single trajectory of this embedding system provides hyper-rectangular over-approximations of reachable sets. We then propose two approaches for constructing a closed-loop embedding system for a neural network controlled dynamical system that accounts for the interaction between the system and the controller in different ways. The interconnection-based approach accounts for the worst-case evolution of each coordinate separately by substituting the neural network inclusion function into the open-loop embedding system. The interaction-based approach uses the newly introduced class of Jacobian-based inclusion functions to fully capture first-order interactions between the system and the controller. Finally, we implement our approach in a Python framework called \\texttt{ReachMM} and show that on several existing benchmarks, our methods outperform the existing approaches in the literature. We also demonstrate the scalability of our method on a vehicle platooning example with up to $200$ states.", "url": "https://arxiv.org/abs/2307.14938"}, {"metadata": {"arXiv": "2307.14355", "Date": "Sun, 23 Jul 2023 18:41:11 ", "Title": "Framing Relevance for Safety-Critical Autonomous Systems", "Authors": ["Astrid Rakow"], "Categories": "cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2209.14038"]}, "abstract": "We are in the process of building complex highly autonomous systems that have build-in beliefs, perceive their environment and exchange information. These systems construct their respective world view and based on it they plan their future manoeuvres, i.e., they choose their actions in order to establish their goals based on their prediction of the possible futures. Usually these systems face an overwhelming flood of information provided by a variety of sources where by far not everything is relevant. The goal of our work is to develop a formal approach to determine what is relevant for a safety critical autonomous system at its current mission, i.e., what information suffices to build an appropriate world view to accomplish its mission goals.", "url": "https://arxiv.org/abs/2307.14355"}, {"metadata": {"arXiv": "2307.14556", "Date": "Thu, 27 Jul 2023 00:31:02 ", "Title": "Reinforcement learning guided fuzz testing for a browser's HTML rendering engine", "Authors": ["Martin Sablotny", "Bj{\\o}rn Sand Jensen", "Jeremy Singer"], "Categories": "cs.AI cs.SE"}, "abstract": "Generation-based fuzz testing can uncover various bugs and security vulnerabilities. However, compared to mutation-based fuzz testing, it takes much longer to develop a well-balanced generator that produces good test cases and decides where to break the underlying structure to exercise new code paths. We propose a novel approach to combine a trained test case generator deep learning model with a double deep Q-network (DDQN) for the first time. The DDQN guides test case creation based on a code coverage signal. Our approach improves the code coverage performance of the underlying generator model by up to 18.5\\% for the Firefox HTML rendering engine compared to the baseline grammar based fuzzer.", "url": "https://arxiv.org/abs/2307.14556"}, {"metadata": {"arXiv": "2307.14660", "Date": "Thu, 27 Jul 2023 07:24:30 ", "Title": "Multi-Valued Partial Order Plans in Numeric Planning", "Authors": ["Hayyan Helal", "Gerhard Lakemeyer"], "Categories": "cs.AI", "Comments": ["10 pages", "3 figures"]}, "abstract": "Many planning formalisms allow for mixing numeric with Boolean effects. However, most of these formalisms are undecidable. In this paper, we will analyze possible causes for this undecidability by studying the number of different occurrences of actions, an approach that proved useful for metric fluents before. We will start by reformulating a numeric planning problem known as restricted tasks as a search problem. We will then show how an NP-complete fragment of numeric planning can be found by using heuristics. To achieve this, we will develop the idea of multi-valued partial order plans, a least committing compact representation for (sequential and parallel) plans. Finally, we will study optimization techniques for this representation to incorporate soft preconditions.", "url": "https://arxiv.org/abs/2307.14660"}, {"metadata": {"arXiv": "2307.14669", "Date": "Thu, 27 Jul 2023 07:47:54 ", "Title": "Fuzzy order-sorted feature logic", "Authors": ["Gian Carlo Milanese", "Gabriella Pasi"], "Categories": "cs.AI", "Comments": ["Submitted to Fuzzy Sets and Systems"]}, "abstract": "Order-Sorted Feature (OSF) logic is a knowledge representation and reasoning language based on function-denoting feature symbols and set-denoting sort symbols ordered in a subsumption lattice. OSF logic allows the construction of record-like terms that represent classes of entities and that are themselves ordered in a subsumption relation. The unification algorithm for such structures provides an efficient calculus of type subsumption, which has been applied in computational linguistics and implemented in constraint logic programming languages such as LOGIN and LIFE and automated reasoners such as CEDAR. This work generalizes OSF logic to a fuzzy setting. We give a flexible definition of a fuzzy subsumption relation which generalizes Zadeh's inclusion between fuzzy sets. Based on this definition we define a fuzzy semantics of OSF logic where sort symbols and OSF terms denote fuzzy sets. We extend the subsumption relation to OSF terms and prove that it constitutes a fuzzy partial order with the property that two OSF terms are subsumed by one another in the crisp sense if and only if their subsumption degree is greater than 0. We show how to find the greatest lower bound of two OSF terms by unifying them and how to compute the subsumption degree between two OSF terms, and we provide the complexity of these operations.", "url": "https://arxiv.org/abs/2307.14669"}, {"metadata": {"arXiv": "2307.14799", "Date": "Thu, 27 Jul 2023 12:08:46 ", "Title": "Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version)", "Authors": ["Mohammed M. S. El-Kholany", "Ramsha Ali", "Martin Gebser"], "Categories": "cs.AI cs.LO", "Comments": ["17 pages", "1 figure", "4 listings", "1 table; a short version of this paper is presented at the 18th European Conference on Logics in Artificial Intelligence (JELIA 2023)"]}, "abstract": "Modern semiconductor manufacturing involves intricate production processes consisting of hundreds of operations, which can take several months from lot release to completion. The high-tech machines used in these processes are diverse, operate on individual wafers, lots, or batches in multiple stages, and necessitate product-specific setups and specialized maintenance procedures. This situation is different from traditional job-shop scheduling scenarios, which have less complex production processes and machines, and mainly focus on solving highly combinatorial but abstract scheduling problems. In this work, we address the scheduling of realistic semiconductor manufacturing processes by modeling their specific requirements using hybrid Answer Set Programming with difference logic, incorporating flexible machine processing, setup, batching and maintenance operations. Unlike existing methods that schedule semiconductor manufacturing processes locally with greedy heuristics or by independently optimizing specific machine group allocations, we examine the potentials of large-scale scheduling subject to multiple optimization objectives.", "url": "https://arxiv.org/abs/2307.14799"}, {"metadata": {"arXiv": "2307.14893", "Date": "Thu, 27 Jul 2023 14:35:42 ", "Title": "Base-based Model Checking for Multi-Agent Only Believing (long version)", "Authors": ["Tiago de Lima", "Emiliano Lorini and Fran\\c{c}ois Schwarzentruber"], "Categories": "cs.AI"}, "abstract": "We present a novel semantics for the language of multi-agent only believing exploiting belief bases, and show how to use it for automatically checking formulas of this language and of its dynamic extension with private belief expansion operators. We provide a PSPACE algorithm for model checking relying on a reduction to QBF and alternative dedicated algorithm relying on the exploration of the state space. We present an implementation of the QBF-based algorithm and some experimental results on computation time in a concrete example.", "url": "https://arxiv.org/abs/2307.14893"}, {"metadata": {"arXiv": "2307.14487", "Date": "Wed, 26 Jul 2023 20:25:29 ", "Title": "Technical note: ShinyAnimalCV: open-source cloud-based web application for object detection, segmentation, and three-dimensional visualization of animals using computer vision", "Authors": ["Jin Wang", "Yu Hu", "Lirong Xiang", "Gota Morota", "Samantha A. Brooks", "Carissa L. Wickens", "Emily K. Miller-Cushon", "and Haipeng Yu"], "Categories": "cs.CV cs.AI"}, "abstract": "Computer vision (CV), a non-intrusive and cost-effective technology, has furthered the development of precision livestock farming by enabling optimized decision-making through timely and individualized animal care. The availability of affordable two- and three-dimensional camera sensors, combined with various machine learning and deep learning algorithms, has provided a valuable opportunity to improve livestock production systems. However, despite the availability of various CV tools in the public domain, applying these tools to animal data can be challenging, often requiring users to have programming and data analysis skills, as well as access to computing resources. Moreover, the rapid expansion of precision livestock farming is creating a growing need to educate and train animal science students in CV. This presents educators with the challenge of efficiently demonstrating the complex algorithms involved in CV. Thus, the objective of this study was to develop ShinyAnimalCV, an open-source cloud-based web application. This application provides a user-friendly interface for performing CV tasks, including object segmentation, detection, three-dimensional surface visualization, and extraction of two- and three-dimensional morphological features. Nine pre-trained CV models using top-view animal data are included in the application. ShinyAnimalCV has been deployed online using cloud computing platforms. The source code of ShinyAnimalCV is available on GitHub, along with detailed documentation on training CV models using custom data and deploying ShinyAnimalCV locally to allow users to fully leverage the capabilities of the application. ShinyAnimalCV can contribute to CV research and teaching in the animal science community.", "url": "https://arxiv.org/abs/2307.14487"}, {"metadata": {"arXiv": "2307.14517", "Date": "Wed, 26 Jul 2023 21:33:35 ", "Title": "The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image Classifiers", "Authors": ["Meike Nauta and Christin Seifert"], "Categories": "cs.CV cs.AI", "Comments": ["24 pages", "1 image", "accepted at the 1st World Conference on eXplainable Artificial Intelligence (xAI 2023)"]}, "abstract": "Interpretable part-prototype models are computer vision models that are explainable by design. The models learn prototypical parts and recognise these components in an image, thereby combining classification and explanation. Despite the recent attention for intrinsically interpretable models, there is no comprehensive overview on evaluating the explanation quality of interpretable part-prototype models. Based on the Co-12 properties for explanation quality as introduced in arXiv:2201.08164 (e.g., correctness, completeness, compactness), we review existing work that evaluates part-prototype models, reveal research gaps and outline future approaches for evaluation of the explanation quality of part-prototype models. This paper, therefore, contributes to the progression and maturity of this relatively new research field on interpretable part-prototype models. We additionally provide a ``Co-12 cheat sheet'' that acts as a concise summary of our findings on evaluating part-prototype models.", "url": "https://arxiv.org/abs/2307.14517"}, {"metadata": {"arXiv": "2307.14521", "Date": "Wed, 26 Jul 2023 21:48:14 ", "Title": "Patterns of Vehicle Lights: Addressing Complexities in Curation and Annotation of Camera-Based Vehicle Light Datasets and Metrics", "Authors": ["Ross Greer", "Akshay Gopalkrishnan", "Maitrayee Keskar", "Mohan Trivedi"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper explores the representation of vehicle lights in computer vision and its implications for various tasks in the field of autonomous driving. Different specifications for representing vehicle lights, including bounding boxes, center points, corner points, and segmentation masks, are discussed in terms of their strengths and weaknesses. Three important tasks in autonomous driving that can benefit from vehicle light detection are identified: nighttime vehicle detection, 3D vehicle orientation estimation, and dynamic trajectory cues. Each task may require a different representation of the light. The challenges of collecting and annotating large datasets for training data-driven models are also addressed, leading to introduction of the LISA Vehicle Lights Dataset and associated Light Visibility Model, which provides light annotations specifically designed for downstream applications in vehicle detection, intent and trajectory prediction, and safe path planning. A comparison of existing vehicle light datasets is provided, highlighting the unique features and limitations of each dataset. Overall, this paper provides insights into the representation of vehicle lights and the importance of accurate annotations for training effective detection models in autonomous driving applications. Our dataset and model are made available at https://cvrr.ucsd.edu/vehicle-lights-dataset", "url": "https://arxiv.org/abs/2307.14521"}, {"metadata": {"arXiv": "2307.14575", "Date": "Thu, 27 Jul 2023 01:45:13 ", "Title": "A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos", "Authors": ["Rongqin Liang", "Yuanman Li", "Yingxin Yi", "Jiantao Zhou", "Xia Li"], "Categories": "cs.CV cs.AI", "Comments": ["12pages,5 figures"]}, "abstract": "Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a novel memory-augmented multi-task collaborative framework (MAMTCF) for unsupervised traffic accident detection in driving videos. Different from previous approaches, our method can more accurately detect both ego-involved and non-ego accidents by simultaneously modeling appearance changes and object motions in video frames through the collaboration of optical flow reconstruction and future object localization tasks. Further, we introduce a memory-augmented motion representation mechanism to fully explore the interrelation between different types of motion representations and exploit the high-level features of normal traffic patterns stored in memory to augment motion representations, thus enlarging the difference from anomalies. Experimental results on recently published large-scale dataset demonstrate that our method achieves better performance compared to previous state-of-the-art approaches.", "url": "https://arxiv.org/abs/2307.14575"}, {"metadata": {"arXiv": "2307.14591", "Date": "Thu, 27 Jul 2023 02:30:12 ", "Title": "The detection and rectification for identity-switch based on unfalsified control", "Authors": ["Junchao Huang", "Xiaoqi He and Sheng Zhao"], "Categories": "cs.CV cs.AI"}, "abstract": "The purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements.", "url": "https://arxiv.org/abs/2307.14591"}, {"metadata": {"arXiv": "2307.14605", "Date": "Thu, 27 Jul 2023 03:42:12 ", "Title": "Clustering based Point Cloud Representation Learning for 3D Analysis", "Authors": ["Tuo Feng", "Wenguan Wang", "Xiaohan Wang", "Yi Yang", "Qinghua Zheng"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ICCV 2023; Project page: https://github.com/FengZicai/Cluster3Dseg/"]}, "abstract": "Point cloud analysis (such as 3D segmentation and detection) is a challenging task, because of not only the irregular geometries of many millions of unordered points, but also the great variations caused by depth, viewpoint, occlusion, etc. Current studies put much focus on the adaption of neural networks to the complex geometries of point clouds, but are blind to a fundamental question: how to learn an appropriate point embedding space that is aware of both discriminative semantics and challenging variations? As a response, we propose a clustering based supervised learning scheme for point cloud analysis. Unlike current de-facto, scene-wise training paradigm, our algorithm conducts within-class clustering on the point embedding space for automatically discovering subclass patterns which are latent yet representative across scenes. The mined patterns are, in turn, used to repaint the embedding space, so as to respect the underlying distribution of the entire training dataset and improve the robustness to the variations. Our algorithm is principled and readily pluggable to modern point cloud segmentation networks during training, without extra overhead during testing. With various 3D network architectures (i.e., voxel-based, point-based, Transformer-based, automatically searched), our algorithm shows notable improvements on famous point cloud segmentation datasets (i.e.,2.0-2.6% on single-scan and 2.0-2.2% multi-scan of SemanticKITTI, 1.8-1.9% on S3DIS, in terms of mIoU). Our algorithm also demonstrates utility in 3D detection, showing 2.0-3.4% mAP gains on KITTI.", "url": "https://arxiv.org/abs/2307.14605"}, {"metadata": {"arXiv": "2307.14750", "Date": "Thu, 27 Jul 2023 10:16:13 ", "Title": "Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation", "Authors": ["Zhiyuan Li and Dongnan Liu and Heng Wang and Chaoyi Zhang and Weidong Cai"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages 5 figures"]}, "abstract": "Training an image captioner without annotated image-sentence pairs has gained traction in recent years. Previous approaches can be categorized into two strategies: crawling sentences from mismatching corpora and aligning them with the given images as pseudo annotations, or pre-training the captioner using external image-text pairs. However, the aligning setting seems to reach its performance limit due to the quality problem of pairs, and pre-training requires significant computational resources. To address these challenges, we propose a new strategy ``LPM + retrieval-augmented learning\" where the prior knowledge from large pre-trained models (LPMs) is leveraged as supervision, and a retrieval process is integrated to further reinforce its effectiveness. Specifically, we introduce Retrieval-augmented Pseudo Sentence Generation (RaPSG), which adopts an efficient approach to retrieve highly relevant short region descriptions from the mismatching corpora and use them to generate a variety of pseudo sentences with distinct representations as well as high quality via LPMs. In addition, a fluency filter and a CLIP-guided training objective are further introduced to facilitate model optimization. Experimental results demonstrate that our method surpasses the SOTA pre-training model (Flamingo3B) by achieving a CIDEr score of 78.1 (+5.1) while utilizing only 0.3% of its trainable parameters (1.3B VS 33M). Importantly, our approach eliminates the need of computationally expensive pre-training processes on external datasets (e.g., the requirement of 312M image-text pairs for Flamingo3B). We further show that with a simple extension, the generated pseudo sentences can be deployed as weak supervision to boost the 1% semi-supervised image caption benchmark up to 93.4 CIDEr score (+8.9) which showcases the versatility and effectiveness of our approach.", "url": "https://arxiv.org/abs/2307.14750"}, {"metadata": {"arXiv": "2307.14889", "Date": "Thu, 27 Jul 2023 14:28:50 ", "Title": "Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving", "Authors": ["Peter Bauer", "Arij Bouazizi", "Ulrich Kressel", "Fabian B. Flohr"], "Categories": "cs.CV cs.AI", "Comments": ["7 pages", "Accepted at IEEE-IV 2023"]}, "abstract": "Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios. Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments. Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains. We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data. The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections. Our approach outperforms state-of-the-art results by up to $\\sim$ 13% on the Waymo Open Dataset in the weakly supervised setting and achieves state-of-the-art results in the supervised setting.", "url": "https://arxiv.org/abs/2307.14889"}, {"metadata": {"arXiv": "2307.14901", "Date": "Thu, 27 Jul 2023 14:44:56 ", "Title": "Text-guided Foundation Model Adaptation for Pathological Image Classification", "Authors": ["Yunkun Zhang", "Jin Gao", "Mu Zhou", "Xiaosong Wang", "Yu Qiao", "Shaoting Zhang", "Dequan Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to MICCAI2023"]}, "abstract": "The recent surge of foundation models in computer vision and natural language processing opens up perspectives in utilizing multi-modal clinical data to train large models with strong generalizability. Yet pathological image datasets often lack biomedical text annotation and enrichment. Guiding data-efficient image diagnosis from the use of biomedical text knowledge becomes a substantial interest. In this paper, we propose to Connect Image and Text Embeddings (CITE) to enhance pathological image classification. CITE injects text insights gained from language models pre-trained with a broad range of biomedical texts, leading to adapt foundation models towards pathological image understanding. Through extensive experiments on the PatchGastric stomach tumor pathological image dataset, we demonstrate that CITE achieves leading performance compared with various baselines especially when training data is scarce. CITE offers insights into leveraging in-domain text knowledge to reinforce data-efficient pathological image classification. Code is available at https://github.com/Yunkun-Zhang/CITE.", "url": "https://arxiv.org/abs/2307.14901"}, {"metadata": {"arXiv": "2307.15016", "Date": "Thu, 27 Jul 2023 17:19:32 ", "Title": "How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges", "Authors": ["Haotong Qin", "Ge-Peng Ji", "Salman Khan", "Deng-Ping Fan", "Fahad Shahbaz Khan", "Luc Van Gool"], "Categories": "cs.CV cs.AI"}, "abstract": "Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, leading to enhanced capabilities in comprehending and interpreting fine-grained visual data. Our project is released on https://github.com/htqin/GoogleBard-VisUnderstand", "url": "https://arxiv.org/abs/2307.15016"}, {"metadata": {"arXiv": "2307.14501", "Date": "Wed, 26 Jul 2023 21:01:14 ", "Title": "Improving Reliable Navigation under Uncertainty via Predictions Informed by Non-Local Information", "Authors": ["Raihan Islam Arnob and Gregory J. Stein"], "Categories": "cs.RO cs.AI", "Comments": ["IROS 2023"]}, "abstract": "We improve reliable, long-horizon, goal-directed navigation in partially-mapped environments by using non-locally available information to predict the goodness of temporally-extended actions that enter unseen space. Making predictions about where to navigate in general requires non-local information: any observations the robot has seen so far may provide information about the goodness of a particular direction of travel. Building on recent work in learning-augmented model-based planning under uncertainty, we present an approach that can both rely on non-local information to make predictions (via a graph neural network) and is reliable by design: it will always reach its goal, even when learning does not provide accurate predictions. We conduct experiments in three simulated environments in which non-local information is needed to perform well. In our large scale university building environment, generated from real-world floorplans to the scale, we demonstrate a 9.3\\% reduction in cost-to-go compared to a non-learned baseline and a 14.9\\% reduction compared to a learning-informed planner that can only use local information to inform its predictions.", "url": "https://arxiv.org/abs/2307.14501"}, {"metadata": {"arXiv": "2307.14510", "Date": "Wed, 26 Jul 2023 21:19:45 ", "Title": "Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control", "Authors": ["Yijiong Lin", "Mauro Comi", "Alex Church", "Dandan Zhang", "Nathan F. Lepora"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted by IROS 2023"]}, "abstract": "High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \\textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile image that contains target and noise features; 2) a Tactile Saliency Network (TacSalNet), which predicts a tactile saliency map to describe the target areas for an input contact depth map; 3) and a Tactile Noise Generator (TacNGen), which generates noise features to train the TacSalNet. Experimental results in contact pose estimation and edge-following in the presence of distractors showcase the accurate prediction of target features from real tactile images. Overall, our tactile saliency prediction approach gives robust sim-to-real tactile control in environments with unknown distractors. Project page: https://sites.google.com/view/tactile-saliency/.", "url": "https://arxiv.org/abs/2307.14510"}, {"metadata": {"arXiv": "2307.14634", "Date": "Thu, 27 Jul 2023 05:49:24 ", "Title": "Fact-Checking of AI-Generated Reports", "Authors": ["Razi Mahmood", "Ge Wang", "Mannudeep Kalra", "and Pingkun Yan"], "Categories": "cs.AI cs.CR cs.CV cs.LG eess.IV", "Comments": ["10 pages", "3 figures", "3 tables"]}, "abstract": "With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility of such an examiner is demonstrated for verifying automatically generated reports by detecting and removing fake sentences. Future generative AI approaches can use the resulting tool to validate their reports leading to a more responsible use of AI in expediting clinical workflows.", "url": "https://arxiv.org/abs/2307.14634"}, {"metadata": {"arXiv": "2307.14993", "Date": "Thu, 27 Jul 2023 16:40:14 ", "Title": "Thinker: Learning to Plan and Act", "Authors": ["Stephen Chung", "Ivan Anokhin", "David Krueger"], "Categories": "cs.AI cs.LG", "Comments": ["37 pages"], "ACM-class": "I.2.6; I.2.8; I.5.1"}, "abstract": "We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model. The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model. These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment. This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization. We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively. Visualizations of agents trained with the Thinker algorithm demonstrate that they have learned to plan effectively with the world model to select better actions. The algorithm's generality opens a new research direction on how a world model can be used in reinforcement learning and how planning can be seamlessly integrated into an agent's decision-making process.", "url": "https://arxiv.org/abs/2307.14993"}, {"metadata": {"arXiv": "2307.14343", "Date": "Fri, 26 May 2023 11:44:35 ", "Title": "Pruning Distorted Images in MNIST Handwritten Digits", "Authors": ["Amarnath R", "Vinay Kumar V"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["26 pages", "10 figures", "14 tables", "54 references"]}, "abstract": "Recognizing handwritten digits is a challenging task primarily due to the diversity of writing styles and the presence of noisy images. The widely used MNIST dataset, which is commonly employed as a benchmark for this task, includes distorted digits with irregular shapes, incomplete strokes, and varying skew in both the training and testing datasets. Consequently, these factors contribute to reduced accuracy in digit recognition. To overcome this challenge, we propose a two-stage deep learning approach. In the first stage, we create a simple neural network to identify distorted digits within the training set. This model serves to detect and filter out such distorted and ambiguous images. In the second stage, we exclude these identified images from the training dataset and proceed to retrain the model using the filtered dataset. This process aims to improve the classification accuracy and confidence levels while mitigating issues of underfitting and overfitting. Our experimental results demonstrate the effectiveness of the proposed approach, achieving an accuracy rate of over 99.5% on the testing dataset. This significant improvement showcases the potential of our method in enhancing digit classification accuracy. In our future work, we intend to explore the scalability of this approach and investigate techniques to further enhance accuracy by reducing the size of the training data.", "url": "https://arxiv.org/abs/2307.14343"}, {"metadata": {"arXiv": "2307.14527", "Date": "Wed, 26 Jul 2023 22:09:29 ", "Title": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad", "Authors": ["Thomas Manzini", "Robin Murphy"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["10 pages", "10 figures"]}, "abstract": "This paper details the challenges in applying two computer vision systems, an EfficientDET supervised learning model and the unsupervised RX spectral classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and rescue (WSAR) effort in Japan and identifies 3 directions for future research. There have been at least 19 proposed approaches and 3 datasets aimed at locating missing persons in drone imagery, but only 3 approaches (2 unsupervised and 1 of an unknown structure) are referenced in the literature as having been used in an actual WSAR operation. Of these proposed approaches, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. The EfficientDET model was applied to the HERIDAL dataset and despite achieving performance that is statistically equivalent to the state-of-the-art, the model fails to translate to the real world in terms of false positives (e.g., identifying tree limbs and rocks as people), and false negatives (e.g., failing to identify members of the search team). The poor results in practice for algorithms that showed good results on datasets suggest 3 areas of future research: more realistic datasets for wilderness SAR, computer vision models that are capable of seamlessly handling the variety of imagery that can be collected during actual WSAR operations, and better alignment on performance measures.", "url": "https://arxiv.org/abs/2307.14527"}, {"metadata": {"arXiv": "2307.14971", "Date": "Thu, 27 Jul 2023 16:07:03 ", "Title": "Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models", "Authors": ["Ziyi Wang", "Xumin Yu", "Yongming Rao", "Jie Zhou", "Jiwen Lu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted to ICCV 2023", "project page: https://tap.ivg-research.xyz"]}, "abstract": "With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision. However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training. In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model. We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme. Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud. Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods. Our method is also effective in boosting the performance of architecture-oriented approaches, achieving state-of-the-art performance when fine-tuning on ScanObjectNN classification and ShapeNetPart segmentation tasks. Code is available at https://github.com/wangzy22/TAP.", "url": "https://arxiv.org/abs/2307.14971"}, {"metadata": {"arXiv": "2307.14381", "Date": "Tue, 25 Jul 2023 20:07:32 ", "Title": "EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence", "Authors": ["Ilkay Sikdokur", "\\.Inci M. Bayta\\c{s}", "Arda Yurdakul"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Deep edge intelligence aims to deploy deep learning models that demand computationally expensive training in the edge network with limited computational power. Moreover, many deep edge intelligence applications require handling distributed data that cannot be transferred to a central server due to privacy concerns. Decentralized learning methods, such as federated learning, offer solutions where models are learned collectively by exchanging learned weights. However, they often require complex models that edge devices may not handle and multiple rounds of network communication to achieve state-of-the-art performances. This study proposes a convolutional ensemble learning approach, coined EdgeConvEns, that facilitates training heterogeneous weak models on edge and learning to ensemble them where data on edge are heterogeneously distributed. Edge models are implemented and trained independently on Field-Programmable Gate Array (FPGA) devices with various computational capacities. Learned data representations are transferred to a central server where the ensemble model is trained with the learned features received from the edge devices to boost the overall prediction performance. Extensive experiments demonstrate that the EdgeConvEns can outperform the state-of-the-art performance with fewer communications and less data in various training scenarios.", "url": "https://arxiv.org/abs/2307.14381"}, {"metadata": {"arXiv": "2307.14382", "Date": "Tue, 25 Jul 2023 20:08:41 ", "Title": "When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review", "Authors": ["Maxime Fontana", "Michael Spratling", "Miaojing Shi"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["25 pages", "4 figures", "4 tables"]}, "abstract": "Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while exploiting their mutual relationships. By using shared resources to simultaneously calculate multiple outputs, this learning paradigm has the potential to have lower memory requirements and inference times compared to the traditional approach of using separate methods for each task. Previous work in MTL has mainly focused on fully-supervised methods, as task relationships can not only be leveraged to lower the level of data-dependency of those methods but they can also improve performance. However, MTL introduces a set of challenges due to a complex optimisation scheme and a higher labeling requirement. This review focuses on how MTL could be utilised under different partial supervision settings to address these challenges. First, this review analyses how MTL traditionally uses different parameter sharing techniques to transfer knowledge in between tasks. Second, it presents the different challenges arising from such a multi-objective optimisation scheme. Third, it introduces how task groupings can be achieved by analysing task relationships. Fourth, it focuses on how partially supervised methods applied to MTL can tackle the aforementioned challenges. Lastly, this review presents the available datasets, tools and benchmarking results of such methods.", "url": "https://arxiv.org/abs/2307.14382"}, {"metadata": {"arXiv": "2307.14384", "Date": "Wed, 26 Jul 2023 02:43:38 ", "Title": "HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning", "Authors": ["Xinting Liao", "Weiming Liu", "Chaochao Chen", "Pengyang Zhou", "Huabin Zhu", "Yanchao Tan", "Jun Wang and Yue Qi"], "Categories": "cs.LG cs.AI", "Comments": ["IJCAI 2023"]}, "abstract": "Federated learning (FL) collaboratively models user data in a decentralized way. However, in the real world, non-identical and independent data distributions (non-IID) among clients hinder the performance of FL due to three issues, i.e., (1) the class statistics shifting, (2) the insufficient hierarchical information utilization, and (3) the inconsistency in aggregating clients. To address the above issues, we propose HyperFed which contains three main modules, i.e., hyperbolic prototype Tammes initialization (HPTI), hyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly, HPTI in the server constructs uniformly distributed and fixed class prototypes, and shares them with clients to match class statistics, further guiding consistent feature representation for local clients. Secondly, HPL in each client captures the hierarchical information in local data with the supervision of shared class prototypes in the hyperbolic model space. Additionally, CA in the server mitigates the impact of the inconsistent deviations from clients to server. Extensive studies of four datasets prove that HyperFed is effective in enhancing the performance of FL under the non-IID set.", "url": "https://arxiv.org/abs/2307.14384"}, {"metadata": {"arXiv": "2307.14395", "Date": "Wed, 26 Jul 2023 10:05:18 ", "Title": "Learning to simulate partially known spatio-temporal dynamics with trainable difference operators", "Authors": ["Xiang Huang", "Zhuoyuan Li", "Hongsheng Liu", "Zidong Wang", "Hongye Zhou", "Bin Dong", "Bei Hua"], "Categories": "cs.LG cs.AI"}, "abstract": "Recently, using neural networks to simulate spatio-temporal dynamics has received a lot of attention. However, most existing methods adopt pure data-driven black-box models, which have limited accuracy and interpretability. By combining trainable difference operators with black-box models, we propose a new hybrid architecture explicitly embedded with partial prior knowledge of the underlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options called the trainable flipping difference layer (TFDL) and the trainable dynamic difference layer (TDDL) for the difference operators. Numerous numerical experiments have demonstrated that PDE-Net++ has superior prediction accuracy and better extrapolation performance than black-box models.", "url": "https://arxiv.org/abs/2307.14395"}, {"metadata": {"arXiv": "2307.14549", "Date": "Thu, 27 Jul 2023 00:11:59 ", "Title": "Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application", "Authors": ["Jianjun Yuan and Wei Lee Woon and Ludovik Coba"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by RecSys 2023 conference"]}, "abstract": "This paper presents an efficient algorithm to solve the sleeping bandit with multiple plays problem in the context of an online recommendation system. The problem involves bounded, adversarial loss and unknown i.i.d. distributions for arm availability. The proposed algorithm extends the sleeping bandit algorithm for single arm selection and is guaranteed to achieve theoretical performance with regret upper bounded by $\\bigO(kN^2\\sqrt{T\\log T})$, where $k$ is the number of arms selected per time step, $N$ is the total number of arms, and $T$ is the time horizon.", "url": "https://arxiv.org/abs/2307.14549"}, {"metadata": {"arXiv": "2307.14613", "Date": "Thu, 27 Jul 2023 04:00:23 ", "Title": "Self-Contrastive Graph Diffusion Network", "Authors": ["Yixian Ma", "Kun Zhan"], "Categories": "cs.LG cs.AI", "Comments": ["ACM Multimedia 2013 Accpeted"], "Journal-ref": "ACM MM 2013"}, "abstract": "Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic drift, without the need for pre-training. We conduct a high-quality sampling of samples based on structure and feature information. If two nodes are neighbors, they are considered positive samples of each other. If two disconnected nodes are also unrelated on $k$NN graph, they are considered negative samples for each other. The contrastive objective reasonably uses our proposed sampling strategies, and the redundancy reduction term minimizes redundant information in the embedding and can well retain more discriminative information. In this novel framework, the graph self-contrastive learning paradigm gives expression to a powerful force. SCGDN effectively balances between preserving high-order structure information and avoiding overfitting. The results manifest that SCGDN can consistently generate outperformance over both the contrastive methods and the classical methods.", "url": "https://arxiv.org/abs/2307.14613"}, {"metadata": {"arXiv": "2307.14623", "Date": "Thu, 27 Jul 2023 04:47:05 ", "Title": "BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning", "Authors": ["Sheikh Md Shakeel Hassan", "Arthur Feeney", "Akash Dhruv", "Jihoon Kim", "Youngjoon Suh", "Jaiyoung Ryu", "Yoonjin Won", "Aparna Chandramowlishwaran"], "Categories": "cs.LG cs.AI cs.CE cs.DC", "Comments": ["Submitted to Neurips Datasets and Benchmarks Track 2023"]}, "abstract": "In the field of phase change phenomena, the lack of accessible and diverse datasets suitable for machine learning (ML) training poses a significant challenge. Existing experimental datasets are often restricted, with limited availability and sparse ground truth data, impeding our understanding of this complex multi-physics phenomena. To bridge this gap, we present the BubbleML Dataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven simulations to provide accurate ground truth information for various boiling scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled boiling. This extensive dataset covers a wide range of parameters, including varying gravity conditions, flow rates, sub-cooling levels, and wall superheat, comprising 51 simulations. BubbleML is validated against experimental observations and trends, establishing it as an invaluable resource for ML research. Furthermore, we showcase its potential to facilitate exploration of diverse downstream tasks by introducing two benchmarks: (a) optical flow analysis to capture bubble dynamics, and (b) operator networks for learning temperature dynamics. The BubbleML dataset and its benchmarks serve as a catalyst for advancements in ML-driven research on multi-physics phase change phenomena, enabling the development and comparison of state-of-the-art techniques and models.", "url": "https://arxiv.org/abs/2307.14623"}, {"metadata": {"arXiv": "2307.14675", "Date": "Thu, 27 Jul 2023 07:58:38 ", "Title": "Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification", "Authors": ["Alfonso Gij\\'on", "Ainhoa Pujana-Goitia", "Eugenio Perea", "Miguel Molina-Solana and Juan G\\'omez-Romero"], "Categories": "cs.LG cs.AI"}, "abstract": "The ever-growing use of wind energy makes necessary the optimization of turbine operations through pitch angle controllers and their maintenance with early fault detection. It is crucial to have accurate and robust models imitating the behavior of wind turbines, especially to predict the generated power as a function of the wind speed. Existing empirical and physics-based models have limitations in capturing the complex relations between the input variables and the power, aggravated by wind variability. Data-driven methods offer new opportunities to enhance wind turbine modeling of large datasets by improving accuracy and efficiency. In this study, we used physics-informed neural networks to reproduce historical data coming from 4 turbines in a wind farm, while imposing certain physical constraints to the model. The developed models for regression of the power, torque, and power coefficient as output variables showed great accuracy for both real data and physical equations governing the system. Lastly, introducing an efficient evidential layer provided uncertainty estimations of the predictions, proved to be consistent with the absolute error, and made possible the definition of a confidence interval in the power curve.", "url": "https://arxiv.org/abs/2307.14675"}, {"metadata": {"arXiv": "2307.14754", "Date": "Thu, 27 Jul 2023 10:26:46 ", "Title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities", "Authors": ["Alex Oesterling", "Jiaqi Ma", "Flavio P. Calmon", "Hima Lakkaraju"], "Categories": "cs.LG cs.AI", "Comments": ["27 pages", "3 figures", "accepted to ICML 2023 DMLR Workshop"]}, "abstract": "As public consciousness regarding the collection and use of personal information by corporations grows, it is of increasing importance that consumers be active participants in the curation of corporate datasets. In light of this, data governance frameworks such as the General Data Protection Regulation (GDPR) have outlined the right to be forgotten as a key principle allowing individuals to request that their personal data be deleted from the databases and models used by organizations. To achieve forgetting in practice, several machine unlearning methods have been proposed to address the computational inefficiencies of retraining a model from scratch with each unlearning request. While efficient online alternatives to retraining, it is unclear how these methods impact other properties critical to real-world applications, such as fairness. In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fairness. We derive theoretical results which demonstrate that our method can provably unlearn data instances while maintaining fairness objectives. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness.", "url": "https://arxiv.org/abs/2307.14754"}, {"metadata": {"arXiv": "2307.14849", "Date": "Thu, 27 Jul 2023 13:28:18 ", "Title": "Counterfactual Explanations for Graph Classification Through the Lenses of Density", "Authors": ["Carlo Abrate", "Giulia Preti", "Francesco Bonchi"], "Categories": "cs.LG cs.AI"}, "abstract": "Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification, previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general density-based counterfactual search framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by opening or closing triangles, and a method driven by maximal cliques. We also discuss how the general method can be instantiated to exploit any other notion of dense substructures, including, for instance, a given taxonomy of nodes. We evaluate the effectiveness of our approaches in 7 brain network datasets and compare the counterfactual statements generated according to several widely-used metrics. Results confirm that adopting a semantic-relevant unit of change like density is essential to define versatile and interpretable counterfactual explanation methods.", "url": "https://arxiv.org/abs/2307.14849"}, {"metadata": {"arXiv": "2307.14953", "Date": "Thu, 27 Jul 2023 15:46:59 ", "Title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space", "Authors": ["Eduardo Fernandes Montesuma", "Fred Ngol\\`e Mboula", "Antoine Souloumiac"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["13 pages,9 figures,Accepted as a conference paper at the 26th European Conference on Artificial Intelligence"]}, "abstract": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification performance. Finally, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to the target domain.", "url": "https://arxiv.org/abs/2307.14953"}, {"metadata": {"arXiv": "2307.14568", "Date": "Thu, 27 Jul 2023 01:04:57 ", "Title": "Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning", "Authors": ["Brian Angulo", "Gregory Gorbov", "Aleksandr Panov", "Konstantin Yakovlev"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["4 pages", "5 figures"]}, "abstract": "While reinforcement learning algorithms have had great success in the field of autonomous navigation, they cannot be straightforwardly applied to the real autonomous systems without considering the safety constraints. The later are crucial to avoid unsafe behaviors of the autonomous vehicle on the road. To highlight the importance of these constraints, in this study, we compare two learnable navigation policies: safe and unsafe. The safe policy takes the constraints into account, while the other does not. We show that the safe policy is able to generate trajectories with more clearance (distance to the obstacles) and makes less collisions while training without sacrificing the overall performance.", "url": "https://arxiv.org/abs/2307.14568"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

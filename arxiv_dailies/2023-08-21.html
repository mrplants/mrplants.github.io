<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.08638", "Date": "Wed, 16 Aug 2023 19:20:06 ", "Title": "Fair GANs through model rebalancing with synthetic data", "Authors": ["Anubhav Jain", "Nasir Memon", "Julian Togelius"], "Categories": "cs.CV cs.CY cs.LG"}, "abstract": "Deep generative models require large amounts of training data. This often poses a problem as the collection of datasets can be expensive and difficult, in particular datasets that are representative of the appropriate underlying distribution (e.g. demographic). This introduces biases in datasets which are further propagated in the models. We present an approach to mitigate biases in an existing generative adversarial network by rebalancing the model distribution. We do so by generating balanced data from an existing unbalanced deep generative model using latent space exploration and using this data to train a balanced generative model. Further, we propose a bias mitigation loss function that shows improvements in the fairness metric even when trained with unbalanced datasets. We show results for the Stylegan2 models while training on the FFHQ dataset for racial fairness and see that the proposed approach improves on the fairness metric by almost 5 times, whilst maintaining image quality. We further validate our approach by applying it to an imbalanced Cifar-10 dataset. Lastly, we argue that the traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.", "url": "https://arxiv.org/abs/2308.08638"}, {"metadata": {"arXiv": "2308.08656", "Date": "Wed, 16 Aug 2023 20:12:01 ", "Title": "Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data", "Authors": ["Keziah Naggita", "Julienne LaChance", "Alice Xiang"], "Categories": "cs.CV cs.LG", "Comments": ["35 pages", "AI", "Ethics", "and Society Conference (AIES'23)"], "DOI": "10.1145/3600211.3604659"}, "abstract": "Biases in large-scale image datasets are known to influence the performance of computer vision models as a function of geographic context. To investigate the limitations of standard Internet data collection methods in low- and middle-income countries, we analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa. We report the quantity and content of available data with comparisons to population-matched nations in Europe as well as the distribution of data according to fine-grained intra-national wealth estimates. Temporal analyses are performed at two-year intervals to expose emerging data trends. Furthermore, we present findings for an ``othering'' phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers. The results of our study suggest that further work is required to capture image data representative of African people and their environments and, ultimately, to improve the applicability of computer vision models in a global context.", "url": "https://arxiv.org/abs/2308.08656"}, {"metadata": {"arXiv": "2308.08669", "Date": "Wed, 16 Aug 2023 20:39:06 ", "Title": "SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification", "Authors": ["Vlad-Constantin Lungu-Stan", "Dumitru-Clementin Cercel", "Florin Pop"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICANN 2023"]}, "abstract": "Skin cancer is a treatable disease if discovered early. We provide a production-specific solution to the skin cancer classification problem that matches human performance in melanoma identification by training a vision transformer on melanoma medical images annotated by experts. Since inference cost, both time and memory wise is important in practice, we employ knowledge distillation to obtain a model that retains 98.33% of the teacher's balanced multi-class accuracy, at a fraction of the cost. Memory-wise, our model is 49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on GPU and 97.96% faster on CPU. By adding classification heads at each level of the transformer and employing a cascading distillation process, we improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance. We provide the code at https://github.com/Longman-Stan/SkinDistilVit.", "url": "https://arxiv.org/abs/2308.08669"}, {"metadata": {"arXiv": "2308.08810", "Date": "Thu, 17 Aug 2023 06:37:37 ", "Title": "Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts", "Authors": ["Sunghyun Park", "Seunghan Yang", "Jaegul Choo", "Sungrack Yun"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.", "url": "https://arxiv.org/abs/2308.08810"}, {"metadata": {"arXiv": "2308.08812", "Date": "Thu, 17 Aug 2023 06:48:55 ", "Title": "A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction", "Authors": ["Sanchar Palit and Sandika Biswas"], "Categories": "cs.CV cs.LG", "Comments": ["15 pages"]}, "abstract": "Single-image 3D reconstruction is a research challenge focused on predicting 3D object shapes from single-view images. This task requires significant data acquisition to predict both visible and occluded portions of the shape. Furthermore, learning-based methods face the difficulty of creating a comprehensive training dataset for all possible classes. To this end, we propose a continual learning-based 3D reconstruction method where our goal is to design a model using Variational Priors that can still reconstruct the previously seen classes reasonably even after training on new classes. Variational Priors represent abstract shapes and combat forgetting, whereas saliency maps preserve object attributes with less memory usage. This is vital due to resource constraints in storing extensive training data. Additionally, we introduce saliency map-based experience replay to capture global and distinct object features. Thorough experiments show competitive results compared to established methods, both quantitatively and qualitatively.", "url": "https://arxiv.org/abs/2308.08812"}, {"metadata": {"arXiv": "2308.08853", "Date": "Thu, 17 Aug 2023 08:25:55 ", "Title": "Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays", "Authors": ["Feng Hong", "Tianjie Dai", "Jiangchao Yao", "Ya Zhang", "Yanfeng Wang"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted for the ICCV 2023 Workshop on Computer Vision for Automated Medical Diagnosis (CVAMD)"]}, "abstract": "Clinical classification of chest radiography is particularly challenging for standard machine learning algorithms due to its inherent long-tailed and multi-label nature. However, few attempts take into account the coupled challenges posed by both the class imbalance and label co-occurrence, which hinders their value to boost the diagnosis on chest X-rays (CXRs) in the real-world scenarios. Besides, with the prevalence of pretraining techniques, how to incorporate these new paradigms into the current framework lacks of the systematical study. This technical report presents a brief description of our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness for CXR diagnosis with the integration of several advanced designs about data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.", "url": "https://arxiv.org/abs/2308.08853"}, {"metadata": {"arXiv": "2308.09000", "Date": "Thu, 17 Aug 2023 14:14:28 ", "Title": "DealMVC: Dual Contrastive Calibration for Multi-view Clustering", "Authors": ["Xihong Yang", "Jiaqi Jin", "Siwei Wang", "Ke Liang", "Yue Liu", "Yi Wen", "Suyuan Liu", "Sihang Zhou", "Xinwang Liu", "En Zhu"], "Categories": "cs.CV cs.LG"}, "abstract": "Benefiting from the strong view-consistent information mining capacity, multi-view contrastive clustering has attracted plenty of attention in recent years. However, we observe the following drawback, which limits the clustering performance from further improvement. The existing multi-view models mainly focus on the consistency of the same samples in different views while ignoring the circumstance of similar but different samples in cross-view scenarios. To solve this problem, we propose a novel Dual contrastive calibration network for Multi-View Clustering (DealMVC). Specifically, we first design a fusion mechanism to obtain a global cross-view feature. Then, a global contrastive calibration loss is proposed by aligning the view feature similarity graph and the high-confidence pseudo-label graph. Moreover, to utilize the diversity of multi-view information, we propose a local contrastive calibration loss to constrain the consistency of pair-wise view features. The feature structure is regularized by reliable class information, thus guaranteeing similar samples have similar features in different views. During the training procedure, the interacted cross-view feature is jointly optimized at both local and global levels. In comparison with other state-of-the-art approaches, the comprehensive experimental results obtained from eight benchmark datasets provide substantial validation of the effectiveness and superiority of our algorithm. We release the code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.", "url": "https://arxiv.org/abs/2308.09000"}, {"metadata": {"arXiv": "2308.09065", "Date": "Thu, 17 Aug 2023 15:54:11 ", "Title": "Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression", "Authors": ["Xuanlong Yu", "Gianni Franchi", "Jindong Gu", "Emanuel Aldea"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["22 pages"]}, "abstract": "Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks.", "url": "https://arxiv.org/abs/2308.09065"}, {"metadata": {"arXiv": "2308.09084", "Date": "Thu, 17 Aug 2023 16:23:52 ", "Title": "MovePose: A High-performance Human Pose Estimation Algorithm on Mobile and Edge Devices", "Authors": ["Dongyang Yu and Haoyue Zhang and Zhirui Zhou and Wangpeng An and Yanhong Yang"], "Categories": "cs.CV cs.LG"}, "abstract": "We present MovePose, an optimized lightweight convolutional neural network designed specifically for real-time body pose estimation on CPU-based mobile devices. The current solutions do not provide satisfactory accuracy and speed for human posture estimation, and MovePose addresses this gap. It aims to maintain real-time performance while improving the accuracy of human posture estimation for mobile devices. The network produces 17 keypoints for each individual at a rate exceeding 11 frames per second, making it suitable for real-time applications such as fitness tracking, sign language interpretation, and advanced mobile human posture estimation. Our MovePose algorithm has attained an Mean Average Precision (mAP) score of 67.7 on the COCO \\cite{cocodata} validation dataset. The MovePose algorithm displayed efficiency with a performance of 69+ frames per second (fps) when run on an Intel i9-10920x CPU. Additionally, it showcased an increased performance of 452+ fps on an NVIDIA RTX3090 GPU. On an Android phone equipped with a Snapdragon 8 + 4G processor, the fps reached above 11. To enhance accuracy, we incorporated three techniques: deconvolution, large kernel convolution, and coordinate classification methods. Compared to basic upsampling, deconvolution is trainable, improves model capacity, and enhances the receptive field. Large kernel convolution strengthens these properties at a decreased computational cost. In summary, MovePose provides high accuracy and real-time performance, marking it a potential tool for a variety of applications, including those focused on mobile-side human posture estimation. The code and models for this algorithm will be made publicly accessible.", "url": "https://arxiv.org/abs/2308.09084"}, {"metadata": {"arXiv": "2308.09105", "Date": "Thu, 17 Aug 2023 17:17:08 ", "Title": "Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation", "Authors": ["Shengcao Cao", "Mengtian Li", "James Hays", "Deva Ramanan", "Yi-Xiong Wang", "Liang-Yan Gui"], "Categories": "cs.CV cs.LG", "Comments": ["ICML 2023"]}, "abstract": "Resource-constrained perception systems such as edge computing and vision-for-robotics require vision models to be both accurate and lightweight in computation and memory usage. While knowledge distillation is a proven strategy to enhance the performance of lightweight classification models, its application to structured outputs like object detection and instance segmentation remains a complicated task, due to the variability in outputs and complex internal network modules involved in the distillation process. In this paper, we propose a simple yet surprisingly effective sequential approach to knowledge distillation that progressively transfers the knowledge of a set of teacher detectors to a given lightweight student. To distill knowledge from a highly accurate but complex teacher model, we construct a sequence of teachers to help the student gradually adapt. Our progressive strategy can be easily combined with existing detection distillation mechanisms to consistently maximize student performance in various settings. To the best of our knowledge, we are the first to successfully distill knowledge from Transformer-based teacher detectors to convolution-based students, and unprecedentedly boost the performance of ResNet-50 based RetinaNet from 36.5% to 42.0% AP and Mask R-CNN from 38.2% to 42.5% AP on the MS COCO benchmark.", "url": "https://arxiv.org/abs/2308.09105"}, {"metadata": {"arXiv": "2308.09160", "Date": "Thu, 17 Aug 2023 19:22:30 ", "Title": "FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning", "Authors": ["Guangyu Sun", "Matias Mendieta", "Jun Luo", "Shandong Wu", "Chen Chen"], "Categories": "cs.CV cs.LG", "Comments": ["2023 IEEE/CVF International Conference on Computer Vision (ICCV)"]}, "abstract": "Personalized Federated Learning (PFL) represents a promising solution for decentralized learning in heterogeneous data environments. Partial model personalization has been proposed to improve the efficiency of PFL by selectively updating local model parameters instead of aggregating all of them. However, previous work on partial model personalization has mainly focused on Convolutional Neural Networks (CNNs), leaving a gap in understanding how it can be applied to other popular models such as Vision Transformers (ViTs). In this work, we investigate where and how to partially personalize a ViT model. Specifically, we empirically evaluate the sensitivity to data distribution of each type of layer. Based on the insights that the self-attention layer and the classification head are the most sensitive parts of a ViT, we propose a novel approach called FedPerfix, which leverages plugins to transfer information from the aggregated model to the local client as a personalization. Finally, we evaluate the proposed approach on CIFAR-100, OrganAMNIST, and Office-Home datasets and demonstrate its effectiveness in improving the model's performance compared to several advanced PFL methods.", "url": "https://arxiv.org/abs/2308.09160"}, {"metadata": {"arXiv": "2308.09228", "Date": "Fri, 18 Aug 2023 01:20:25 ", "Title": "Generalized Sum Pooling for Metric Learning", "Authors": ["Yeti Z. Gurbuz", "Ozan Sener and A. Ayd{\\i}n Alatan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted as a conference paper at International Conference on Computer Vision (ICCV) 2023"]}, "abstract": "A common architectural choice for deep metric learning is a convolutional neural network followed by global average pooling (GAP). Albeit simple, GAP is a highly effective way to aggregate information. One possible explanation for the effectiveness of GAP is considering each feature vector as representing a different semantic entity and GAP as a convex combination of them. Following this perspective, we generalize GAP and propose a learnable generalized sum pooling method (GSP). GSP improves GAP with two distinct abilities: i) the ability to choose a subset of semantic entities, effectively learning to ignore nuisance information, and ii) learning the weights corresponding to the importance of each entity. Formally, we propose an entropy-smoothed optimal transport problem and show that it is a strict generalization of GAP, i.e., a specific realization of the problem gives back GAP. We show that this optimization problem enjoys analytical gradients enabling us to use it as a direct learnable replacement for GAP. We further propose a zero-shot loss to ease the learning of GSP. We show the effectiveness of our method with extensive evaluations on 4 popular metric learning benchmarks. Code is available at: GSP-DML Framework", "url": "https://arxiv.org/abs/2308.09228"}, {"metadata": {"arXiv": "2308.09303", "Date": "Fri, 18 Aug 2023 04:52:56 ", "Title": "Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning", "Authors": ["Jun-Yeong Moon", "Keon-Hee Park", "Jung Uk Kim and Gyeong-Moon Park"], "Categories": "cs.CV cs.LG"}, "abstract": "Continual learning aims to learn a model from a continuous stream of data, but it mainly assumes a fixed number of data and tasks with clear task boundaries. However, in real-world scenarios, the number of input data and tasks is constantly changing in a statistical way, not a static way. Although recently introduced incremental learning scenarios having blurry task boundaries somewhat address the above issues, they still do not fully reflect the statistical properties of real-world situations because of the fixed ratio of disjoint and blurry samples. In this paper, we propose a new Stochastic incremental Blurry task boundary scenario, called Si-Blurry, which reflects the stochastic properties of the real-world. We find that there are two major challenges in the Si-Blurry scenario: (1) inter- and intra-task forgettings and (2) class imbalance problem. To alleviate them, we introduce Mask and Visual Prompt tuning (MVP). In MVP, to address the inter- and intra-task forgetting issues, we propose a novel instance-wise logit masking and contrastive visual prompt tuning loss. Both of them help our model discern the classes to be learned in the current batch. It results in consolidating the previous knowledge. In addition, to alleviate the class imbalance problem, we introduce a new gradient similarity-based focal loss and adaptive feature scaling to ease overfitting to the major classes and underfitting to the minor classes. Extensive experiments show that our proposed MVP significantly outperforms the existing state-of-the-art methods in our challenging Si-Blurry scenario.", "url": "https://arxiv.org/abs/2308.09303"}, {"metadata": {"arXiv": "2308.09368", "Date": "Fri, 18 Aug 2023 08:02:52 ", "Title": "A tailored Handwritten-Text-Recognition System for Medieval Latin", "Authors": ["Philipp Koch and Gilary Vera Nu\\~nez and Esteban Garces Arias and Christian Heumann and Matthias Sch\\\"offel and Alexander H\\\"aberlin and Matthias A{\\ss}enmacher"], "Categories": "cs.CV cs.CL cs.CY cs.LG stat.ML", "Comments": ["This paper has been accepted at the First Workshop on Ancient Language Processing", "co-located with RANLP 2023. This is the author's version of the work. The definite version of record will be published in the proceedings"]}, "abstract": "The Bavarian Academy of Sciences and Humanities aims to digitize its Medieval Latin Dictionary. This dictionary entails record cards referring to lemmas in medieval Latin, a low-resource language. A crucial step of the digitization process is the Handwritten Text Recognition (HTR) of the handwritten lemmas found on these record cards. In our work, we introduce an end-to-end pipeline, tailored to the medieval Latin dictionary, for locating, extracting, and transcribing the lemmas. We employ two state-of-the-art (SOTA) image segmentation models to prepare the initial data set for the HTR task. Furthermore, we experiment with different transformer-based models and conduct a set of experiments to explore the capabilities of different combinations of vision encoders with a GPT-2 decoder. Additionally, we also apply extensive data augmentation resulting in a highly competitive model. The best-performing setup achieved a Character Error Rate (CER) of 0.015, which is even superior to the commercial Google Cloud Vision model, and shows more stable performance.", "url": "https://arxiv.org/abs/2308.09368"}, {"metadata": {"arXiv": "2308.09426", "Date": "Fri, 18 Aug 2023 09:51:11 ", "Title": "Self-Supervised Single-Image Deconvolution with Siamese Neural Networks", "Authors": ["Mikhail Papkov", "Kaupo Palo", "Leopold Parts"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Accepted for DALI @ MICCAI 2023"]}, "abstract": "Inverse problems in image reconstruction are fundamentally complicated by unknown noise properties. Classical iterative deconvolution approaches amplify noise and require careful parameter selection for an optimal trade-off between sharpness and grain. Deep learning methods allow for flexible parametrization of the noise and learning its properties directly from the data. Recently, self-supervised blind-spot neural networks were successfully adopted for image deconvolution by including a known point-spread function in the end-to-end training. However, their practical application has been limited to 2D images in the biomedical domain because it implies large kernels that are poorly optimized. We tackle this problem with Fast Fourier Transform convolutions that provide training speed-up in 3D microscopy deconvolution tasks. Further, we propose to adopt a Siamese invariance loss for deconvolution and empirically identify its optimal position in the neural network between blind-spot and full image branches. The experimental results show that our improved framework outperforms the previous state-of-the-art deconvolution methods with a known point spread function.", "url": "https://arxiv.org/abs/2308.09426"}, {"metadata": {"arXiv": "2308.09542", "Date": "Fri, 18 Aug 2023 13:19:26 ", "Title": "Decoupled conditional contrastive learning with variable metadata for prostate lesion detection", "Authors": ["Camille Ruppli", "Pietro Gori", "Roberto Ardon", "Isabelle Bloch"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at MILLanD workshop (MICCAI)"]}, "abstract": "Early diagnosis of prostate cancer is crucial for efficient treatment. Multi-parametric Magnetic Resonance Images (mp-MRI) are widely used for lesion detection. The Prostate Imaging Reporting and Data System (PI-RADS) has standardized interpretation of prostate MRI by defining a score for lesion malignancy. PI-RADS data is readily available from radiology reports but is subject to high inter-reports variability. We propose a new contrastive loss function that leverages weak metadata with multiple annotators per sample and takes advantage of inter-reports variability by defining metadata confidence. By combining metadata of varying confidence with unannotated data into a single conditional contrastive loss function, we report a 3% AUC increase on lesion detection on the public PI-CAI challenge dataset. Code is available at: https://github.com/camilleruppli/decoupled_ccl", "url": "https://arxiv.org/abs/2308.09542"}, {"metadata": {"arXiv": "2308.09693", "Date": "Fri, 18 Aug 2023 17:41:39 ", "Title": "A Lightweight Transformer for Faster and Robust EBSD Data Collection", "Authors": ["Harry Dong", "Sean Donegan", "Megna Shah", "Yuejie Chi"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Three dimensional electron back-scattered diffraction (EBSD) microscopy is a critical tool in many applications in materials science, yet its data quality can fluctuate greatly during the arduous collection process, particularly via serial-sectioning. Fortunately, 3D EBSD data is inherently sequential, opening up the opportunity to use transformers, state-of-the-art deep learning architectures that have made breakthroughs in a plethora of domains, for data processing and recovery. To be more robust to errors and accelerate this 3D EBSD data collection, we introduce a two step method that recovers missing slices in an 3D EBSD volume, using an efficient transformer model and a projection algorithm to process the transformer's outputs. Overcoming the computational and practical hurdles of deep learning with scarce high dimensional data, we train this model using only synthetic 3D EBSD data with self-supervision and obtain superior recovery accuracy on real 3D EBSD data, compared to existing methods.", "url": "https://arxiv.org/abs/2308.09693"}, {"metadata": {"arXiv": "2308.09711", "Date": "Fri, 18 Aug 2023 17:59:01 ", "Title": "Robust Monocular Depth Estimation under Challenging Conditions", "Authors": ["Stefano Gasperini", "Nils Morbitzer", "HyunJun Jung", "Nassir Navab", "Federico Tombari"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["ICCV 2023. Source code and data: https://md4all.github.io"]}, "abstract": "While state-of-the-art monocular depth estimation approaches achieve impressive results in ideal settings, they are highly unreliable under challenging illumination and weather conditions, such as at nighttime or in the presence of rain. In this paper, we uncover these safety-critical issues and tackle them with md4all: a simple and effective solution that works reliably under both adverse and ideal conditions, as well as for different types of learning supervision. We achieve this by exploiting the efficacy of existing methods under perfect settings. Therefore, we provide valid training signals independently of what is in the input. First, we generate a set of complex samples corresponding to the normal training ones. Then, we train the model by guiding its self- or full-supervision by feeding the generated samples and computing the standard losses on the corresponding original images. Doing so enables a single model to recover information across diverse conditions without modifications at inference time. Extensive experiments on two challenging public datasets, namely nuScenes and Oxford RobotCar, demonstrate the effectiveness of our techniques, outperforming prior works by a large margin in both standard and challenging conditions. Source code and data are available at: https://md4all.github.io.", "url": "https://arxiv.org/abs/2308.09711"}, {"metadata": {"arXiv": "2308.08571", "Date": "Tue, 15 Aug 2023 18:33:58 ", "Title": "A physics-informed machine learning model for reconstruction of dynamic loads", "Authors": ["Gledson Rodrigo Tondo and Igor Kavrakov and Guido Morgenthal"], "Categories": "cs.LG cs.CE", "Comments": ["8 pages", "7 figures and 10 references"], "Journal-ref": "IABSE Symposium: Long Span Bridges, Istanbul, Turkey, 26-28 April 2023", "DOI": "10.2749/istanbul.2023.0315"}, "abstract": "Long-span bridges are subjected to a multitude of dynamic excitations during their lifespan. To account for their effects on the structural system, several load models are used during design to simulate the conditions the structure is likely to experience. These models are based on different simplifying assumptions and are generally guided by parameters that are stochastically identified from measurement data, making their outputs inherently uncertain. This paper presents a probabilistic physics-informed machine-learning framework based on Gaussian process regression for reconstructing dynamic forces based on measured deflections, velocities, or accelerations. The model can work with incomplete and contaminated data and offers a natural regularization approach to account for noise in the measurement system. An application of the developed framework is given by an aerodynamic analysis of the Great Belt East Bridge. The aerodynamic response is calculated numerically based on the quasi-steady model, and the underlying forces are reconstructed using sparse and noisy measurements. Results indicate a good agreement between the applied and the predicted dynamic load and can be extended to calculate global responses and the resulting internal forces. Uses of the developed framework include validation of design models and assumptions, as well as prognosis of responses to assist in damage detection and structural health monitoring.", "url": "https://arxiv.org/abs/2308.08571"}, {"metadata": {"arXiv": "2308.08641", "Date": "Wed, 16 Aug 2023 19:32:29 ", "Title": "Non-monotone Sequential Submodular Maximization", "Authors": ["Shaojie Tang and Jing Yuan"], "Categories": "cs.LG cs.DS"}, "abstract": "In this paper, we study a fundamental problem in submodular optimization, which is called sequential submodular maximization. Specifically, we aim to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \\cdots ,f_k: 2^V \\rightarrow \\mathbb{R}^+$ is maximized, here each function $f_j$ takes the first $j$ items from this sequence as input. The existing research on sequential submodular maximization has predominantly concentrated on the monotone setting, assuming that the submodular functions are non-decreasing. However, in various real-world scenarios, like diversity-aware recommendation systems, adding items to an existing set might negatively impact the overall utility. In response, this paper pioneers the examination of the aforementioned problem with non-monotone submodular functions and offers effective solutions for both flexible and fixed length constraints, as well as a special case with identical utility functions. The empirical evaluations further validate the effectiveness of our proposed algorithms in the domain of video recommendations. The results of this research have implications in various fields, including recommendation systems and assortment optimization, where the ordering of items significantly impacts the overall value obtained.", "url": "https://arxiv.org/abs/2308.08641"}, {"metadata": {"arXiv": "2308.08643", "Date": "Wed, 16 Aug 2023 19:36:01 ", "Title": "Towards Personalized Federated Learning via Heterogeneous Model Reassembly", "Authors": ["Jiaqi Wang", "Xingyi Yang", "Suhan Cui", "Liwei Che", "Lingjuan Lyu", "Dongkuan Xu", "Fenglong Ma"], "Categories": "cs.LG cs.DC"}, "abstract": "This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner.", "url": "https://arxiv.org/abs/2308.08643"}, {"metadata": {"arXiv": "2308.08653", "Date": "Wed, 16 Aug 2023 19:59:25 ", "Title": "Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction", "Authors": ["Michael G. Rawson", "Timothy Doster", "Tegan Emerson"], "Categories": "cs.LG eess.SP"}, "abstract": "Hyperspectral measurements from long range sensors can give a detailed picture of the items, materials, and chemicals in a scene but analysis can be difficult, slow, and expensive due to high spatial and spectral resolutions of state-of-the-art sensors. As such, sparsity is important to enable the future of spectral compression and analytics. It has been observed that environmental and atmospheric effects, including scattering, can produce nonlinear effects posing challenges for existing source separation and compression methods. We present a novel transformation into Hilbert spaces for pruning and constructing sparse representations via non-negative least squares minimization. Then we introduce max likelihood compression vectors to decrease information loss. Our approach is benchmarked against standard pruning and least squares as well as deep learning methods. Our methods are evaluated in terms of overall spectral reconstruction error and compression rate using real and synthetic data. We find that pruning least squares methods converge quickly unlike matching pursuit methods. We find that Hilbert space pruning can reduce error by as much as 40% of the error of standard pruning and also outperform neural network autoencoders.", "url": "https://arxiv.org/abs/2308.08653"}, {"metadata": {"arXiv": "2308.08655", "Date": "Wed, 16 Aug 2023 20:06:41 ", "Title": "Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems", "Authors": ["Faisal Nissar Malik", "James Ricles", "Masoud Yari", "Malik Arsala Nissar"], "Categories": "cs.LG"}, "abstract": "Dynamic response evaluation in structural engineering is the process of determining the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventional methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.", "url": "https://arxiv.org/abs/2308.08655"}, {"metadata": {"arXiv": "2308.08666", "Date": "Wed, 16 Aug 2023 20:33:57 ", "Title": "BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration", "Authors": ["Shikhar Tuli and Niraj K. Jha"], "Categories": "cs.LG"}, "abstract": "Researchers constantly strive to explore larger and more complex search spaces in various scientific studies and physical experiments. However, such investigations often involve sophisticated simulators or time-consuming experiments that make exploring and observing new design samples challenging. Previous works that target such applications are typically sample-inefficient and restricted to vector search spaces. To address these limitations, this work proposes a constrained multi-objective optimization (MOO) framework, called BREATHE, that searches not only traditional vector-based design spaces but also graph-based design spaces to obtain best-performing graphs. It leverages second-order gradients and actively trains a heteroscedastic surrogate model for sample-efficient optimization. In a single-objective vector optimization application, it leads to 64.1% higher performance than the next-best baseline, random forest regression. In graph-based search, BREATHE outperforms the next-best baseline, i.e., a graphical version of Gaussian-process-based Bayesian optimization, with up to 64.9% higher performance. In a MOO task, it achieves up to 21.9$\\times$ higher hypervolume than the state-of-the-art method, multi-objective Bayesian optimization (MOBOpt). BREATHE also outperforms the baseline methods on most standard MOO benchmark applications.", "url": "https://arxiv.org/abs/2308.08666"}, {"metadata": {"arXiv": "2308.08705", "Date": "Wed, 16 Aug 2023 23:42:03 ", "Title": "Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing", "Authors": ["Xiangyu Liu", "Kaiqing Zhang"], "Categories": "cs.LG cs.GT cs.MA", "Comments": ["International Conference on Machine Learning (ICML) 2023"]}, "abstract": "We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \\emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \\emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \\emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.", "url": "https://arxiv.org/abs/2308.08705"}, {"metadata": {"arXiv": "2308.08709", "Date": "Thu, 17 Aug 2023 00:15:11 ", "Title": "Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks", "Authors": ["Mirazul Haque and Wei Yang"], "Categories": "cs.LG"}, "abstract": "Deep Neural Networks (DNNs) have been used to solve different day-to-day problems. Recently, DNNs have been deployed in real-time systems, and lowering the energy consumption and response time has become the need of the hour. To address this scenario, researchers have proposed incorporating dynamic mechanism to static DNNs (SDNN) to create Dynamic Neural Networks (DyNNs) performing dynamic amounts of computation based on the input complexity. Although incorporating dynamic mechanism into SDNNs would be preferable in real-time systems, it also becomes important to evaluate how the introduction of dynamic mechanism impacts the robustness of the models. However, there has not been a significant number of works focusing on the robustness trade-off between SDNNs and DyNNs. To address this issue, we propose to investigate the robustness of dynamic mechanism in DyNNs and how dynamic mechanism design impacts the robustness of DyNNs. For that purpose, we evaluate three research questions. These evaluations are performed on three models and two datasets. Through the studies, we find that attack transferability from DyNNs to SDNNs is higher than attack transferability from SDNNs to DyNNs. Also, we find that DyNNs can be used to generate adversarial samples more efficiently than SDNNs. Then, through research studies, we provide insight into the design choices that can increase robustness of DyNNs against the attack generated using static model. Finally, we propose a novel attack to understand the additional attack surface introduced by the dynamic mechanism and provide design choices to improve robustness against the attack.", "url": "https://arxiv.org/abs/2308.08709"}, {"metadata": {"arXiv": "2308.08762", "Date": "Thu, 17 Aug 2023 03:32:38 ", "Title": "Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering", "Authors": ["Yanjie Sun", "Zhike Gong", "Quan Shi", "Lin Chen"], "Categories": "cs.LG"}, "abstract": "Effective control of credit risk is a key link in the steady operation of commercial banks. This paper is mainly based on the customer information dataset of a foreign commercial bank in Kaggle, and we use LightGBM algorithm to build a classifier to classify customers, to help the bank judge the possibility of customer credit default. This paper mainly deals with characteristic engineering, such as missing value processing, coding, imbalanced samples, etc., which greatly improves the machine learning effect. The main innovation of this paper is to construct new feature attributes on the basis of the original dataset so that the accuracy of the classifier reaches 0.734, and the AUC reaches 0.772, which is more than many classifiers based on the same dataset. The model can provide some reference for commercial banks' credit granting, and also provide some feature processing ideas for other similar studies.", "url": "https://arxiv.org/abs/2308.08762"}, {"metadata": {"arXiv": "2308.08765", "Date": "Thu, 17 Aug 2023 03:36:13 ", "Title": "Explainable AI for tool wear prediction in turning", "Authors": ["Saleh Valizadeh Sotubadi and Rui Liu and Vinh Neguyen"], "Categories": "cs.LG"}, "abstract": "This research aims develop an Explainable Artificial Intelligence (XAI) framework to facilitate human-understandable solutions for tool wear prediction during turning. A random forest algorithm was used as the supervised Machine Learning (ML) classifier for training and binary classification using acceleration, acoustics, temperature, and spindle speed during the orthogonal tube turning process as input features. The ML classifier was used to predict the condition of the tool after the cutting process, which was determined in a binary class form indicating if the cutting tool was available or failed. After the training process, the Shapley criterion was used to explain the predictions of the trained ML classifier. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning of the ML classifier predictions. After implementing the Shapley criterion on all testing datasets, the tool temperature was identified as the most significant feature in determining the classification of available versus failed cutting tools. Hence, this research demonstrates capability of XAI to provide machining operators the ability to diagnose and understand complex ML classifiers in prediction of tool wear.", "url": "https://arxiv.org/abs/2308.08765"}, {"metadata": {"arXiv": "2308.08778", "Date": "Thu, 17 Aug 2023 04:33:38 ", "Title": "Environment Diversification with Multi-head Neural Network for Invariant Learning", "Authors": ["Bo-Wei Huang", "Keng-Te Liao", "Chang-Sheng Kao", "Shou-De Lin"], "Categories": "cs.LG cs.CV", "Comments": ["In Proceedings of 36th Conference on Neural Information Processing Systems (NeurIPS 2022)"]}, "abstract": "Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.", "url": "https://arxiv.org/abs/2308.08778"}, {"metadata": {"arXiv": "2308.08786", "Date": "Thu, 17 Aug 2023 05:15:47 ", "Title": "APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service", "Authors": ["Zilinghan Li", "Shilan He", "Pranshu Chaturvedi", "Trung-Hieu Hoang", "Minseok Ryu", "E. A. Huerta", "Volodymyr Kindratenko", "Jordan Fuhrman", "Maryellen Giger", "Ryan Chard", "Kibaek Kim", "Ravi Madduri"], "Categories": "cs.LG"}, "abstract": "Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models without sharing sensitive (e.g., healthcare of financial) local data. To ease and accelerate the adoption of PPFL, we introduce APPFLx, a ready-to-use platform that provides privacy-preserving cross-silo federated learning as a service. APPFLx employs Globus authentication to allow users to easily and securely invite trustworthy collaborators for PPFL, implements several synchronous and asynchronous FL algorithms, streamlines the FL experiment launch process, and enables tracking and visualizing the life cycle of FL experiments, allowing domain experts and ML practitioners to easily orchestrate and evaluate cross-silo FL under one platform. APPFLx is available online at https://appflx.link", "url": "https://arxiv.org/abs/2308.08786"}, {"metadata": {"arXiv": "2308.08794", "Date": "Thu, 17 Aug 2023 05:42:27 ", "Title": "Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces", "Authors": ["Miguel Liu-Schiaffini", "Clare E. Singer", "Nikola Kovachki", "Tapio Schneider", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "Categories": "cs.LG math.DS", "Comments": ["29 pages", "15 figures"]}, "abstract": "Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.", "url": "https://arxiv.org/abs/2308.08794"}, {"metadata": {"arXiv": "2308.08823", "Date": "Thu, 17 Aug 2023 07:06:54 ", "Title": "Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning", "Authors": ["Tianmeng Yang", "Min Zhou", "Yujing Wang", "Zhengjie Lin", "Lujia Pan", "Bin Cui", "Yunhai Tong"], "Categories": "cs.LG", "Comments": ["Accepted by CIKM 2023"]}, "abstract": "Graph Active Learning (GAL), which aims to find the most informative nodes in graphs for annotation to maximize the Graph Neural Networks (GNNs) performance, has attracted many research efforts but remains non-trivial challenges. One major challenge is that existing GAL strategies may introduce semantic confusion to the selected training set, particularly when graphs are noisy. Specifically, most existing methods assume all aggregating features to be helpful, ignoring the semantically negative effect between inter-class edges under the message-passing mechanism. In this work, we present Semantic-aware Active learning framework for Graphs (SAG) to mitigate the semantic confusion problem. Pairwise similarities and dissimilarities of nodes with semantic features are introduced to jointly evaluate the node influence. A new prototype-based criterion and query policy are also designed to maintain diversity and class balance of the selected nodes, respectively. Extensive experiments on the public benchmark graphs and a real-world financial dataset demonstrate that SAG significantly improves node classification performances and consistently outperforms previous methods. Moreover, comprehensive analysis and ablation study also verify the effectiveness of the proposed framework.", "url": "https://arxiv.org/abs/2308.08823"}, {"metadata": {"arXiv": "2308.08825", "Date": "Thu, 17 Aug 2023 07:16:41 ", "Title": "Controlling Federated Learning for Covertness", "Authors": ["Adit Jain and Vikram Krishnamurthy"], "Categories": "cs.LG eess.SP"}, "abstract": "A learner aims to minimize a function $f$ by repeatedly querying a distributed oracle that provides noisy gradient evaluations. At the same time, the learner seeks to hide $\\arg\\min f$ from a malicious eavesdropper that observes the learner's queries. This paper considers the problem of \\textit{covert} or \\textit{learner-private} optimization, where the learner has to dynamically choose between learning and obfuscation by exploiting the stochasticity. The problem of controlling the stochastic gradient algorithm for covert optimization is modeled as a Markov decision process, and we show that the dynamic programming operator has a supermodular structure implying that the optimal policy has a monotone threshold structure. A computationally efficient policy gradient algorithm is proposed to search for the optimal querying policy without knowledge of the transition probabilities. As a practical application, our methods are demonstrated on a hate speech classification task in a federated setting where an eavesdropper can use the optimal weights to generate toxic content, which is more easily misclassified. Numerical results show that when the learner uses the optimal policy, an eavesdropper can only achieve a validation accuracy of $52\\%$ with no information and $69\\%$ when it has a public dataset with 10\\% positive samples compared to $83\\%$ when the learner employs a greedy policy.", "url": "https://arxiv.org/abs/2308.08825"}, {"metadata": {"arXiv": "2308.08872", "Date": "Thu, 17 Aug 2023 09:09:36 ", "Title": "Towards Semi-supervised Learning with Non-random Missing Labels", "Authors": ["Yue Duan", "Zhen Zhao", "Lei Qi", "Luping Zhou", "Lei Wang", "Yinghuan Shi"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data. While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distributions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.", "url": "https://arxiv.org/abs/2308.08872"}, {"metadata": {"arXiv": "2308.08873", "Date": "Thu, 17 Aug 2023 09:10:07 ", "Title": "Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task", "Authors": ["Mahyar Jahaninasab", "Mohamad Ali Bijarchi"], "Categories": "cs.LG", "Comments": ["23 pages", "8 figures", "3 tables"]}, "abstract": "In this work, a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN) is introduced. This framework is capable of learning the underlying pattern of any problem with low computational cost before the main training loop. The loss function of vanilla PINN due to the existence of two terms of partial differential residuals and boundary condition mean squared error is imbalanced. FE-PINN solves this challenge with just one minute of training instead of time-consuming hyperparameter tuning for loss function that can take hours. The FE-PINN accomplishes this process by performing a sequence of sub-tasks. The first sub-task learns useful features about the underlying physics. Then, the model trains on the target task to refine the calculations. FE-PINN is applied to three benchmarks, flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity. FE-PINN can solve each case with, 15x, 2x, and 5x speed up accordingly. Another advantage of FE-PINN is that reaching lower order of value for loss function is systematically possible. In this study, it was possible to reach a loss value near 1e-5 which is challenging for vanilla PINN. FE-PINN also has a smooth convergence process which allows for utilizing higher learning rates in comparison to vanilla PINN. This framework can be used as a fast, accurate tool for solving a wide range of Partial Differential Equations (PDEs) across various fields.", "url": "https://arxiv.org/abs/2308.08873"}, {"metadata": {"arXiv": "2308.08886", "Date": "Thu, 17 Aug 2023 09:44:05 ", "Title": "Dual Gauss-Newton Directions for Deep Learning", "Authors": ["Vincent Roulet", "Mathieu Blondel"], "Categories": "cs.LG math.OC", "Comments": ["Presented at the Duality Principles for Modern Machine Learning Workshop at ICML 2023"]}, "abstract": "Inspired by Gauss-Newton-like methods, we study the benefit of leveraging the structure of deep learning objectives, namely, the composition of a convex loss function and of a nonlinear network, in order to derive better direction oracles than stochastic gradients, based on the idea of partial linearization. In a departure from previous works, we propose to compute such direction oracles via their dual formulation, leading to both computational benefits and new insights. We demonstrate that the resulting oracles define descent directions that can be used as a drop-in replacement for stochastic gradients, in existing optimization algorithms. We empirically study the advantage of using the dual formulation as well as the computational trade-offs involved in the computation of such oracles.", "url": "https://arxiv.org/abs/2308.08886"}, {"metadata": {"arXiv": "2308.08896", "Date": "Thu, 17 Aug 2023 10:07:45 ", "Title": "Optimal Resource Allocation for U-Shaped Parallel Split Learning", "Authors": ["Song Lyu", "Zheng Lin", "Guanqiao Qu", "Xianhao Chen", "Xiaoxia Huang", "and Pan Li"], "Categories": "cs.LG", "Comments": ["6 pages", "6 figures"]}, "abstract": "Split learning (SL) has emerged as a promising approach for model training without revealing the raw data samples from the data owners. However, traditional SL inevitably leaks label privacy as the tail model (with the last layers) should be placed on the server. To overcome this limitation, one promising solution is to utilize U-shaped architecture to leave both early layers and last layers on the user side. In this paper, we develop a novel parallel U-shaped split learning and devise the optimal resource optimization scheme to improve the performance of edge networks. In the proposed framework, multiple users communicate with an edge server for SL. We analyze the end-to-end delay of each client during the training process and design an efficient resource allocation algorithm, called LSCRA, which finds the optimal computing resource allocation and split layers. Our experimental results show the effectiveness of LSCRA and that U-shaped PSL can achieve a similar performance with other SL baselines while preserving label privacy. Index Terms: U-shaped network, split learning, label privacy, resource allocation, 5G/6G edge networks.", "url": "https://arxiv.org/abs/2308.08896"}, {"metadata": {"arXiv": "2308.08934", "Date": "Thu, 17 Aug 2023 12:04:14 ", "Title": "On Data Imbalance in Molecular Property Prediction with Pre-training", "Authors": ["Limin Wang", "Masatoshi Hanai", "Toyotaro Suzumura", "Shun Takashige", "Kenjiro Taura"], "Categories": "cs.LG cond-mat.mtrl-sci"}, "abstract": "Revealing and analyzing the various properties of materials is an essential and critical issue in the development of materials, including batteries, semiconductors, catalysts, and pharmaceuticals. Traditionally, these properties have been determined through theoretical calculations and simulations. However, it is not practical to perform such calculations on every single candidate material. Recently, a combination method of the theoretical calculation and machine learning has emerged, that involves training machine learning models on a subset of theoretical calculation results to construct a surrogate model that can be applied to the remaining materials. On the other hand, a technique called pre-training is used to improve the accuracy of machine learning models. Pre-training involves training the model on pretext task, which is different from the target task, before training the model on the target task. This process aims to extract the input data features, stabilizing the learning process and improving its accuracy. However, in the case of molecular property prediction, there is a strong imbalance in the distribution of input data and features, which may lead to biased learning towards frequently occurring data during pre-training. In this study, we propose an effective pre-training method that addresses the imbalance in input data. We aim to improve the final accuracy by modifying the loss function of the existing representative pre-training method, node masking, to compensate the imbalance. We have investigated and assessed the impact of our proposed imbalance compensation on pre-training and the final prediction accuracy through experiments and evaluations using benchmark of molecular property prediction models.", "url": "https://arxiv.org/abs/2308.08934"}, {"metadata": {"arXiv": "2308.08936", "Date": "Thu, 17 Aug 2023 12:11:27 ", "Title": "Estimating fire Duration using regression methods", "Authors": ["Hansong Xiao"], "Categories": "cs.LG", "Comments": ["15pages", "5 figures"], "MSC-class": "F.2.2, I.2.7"}, "abstract": "Wildfire forecasting problems usually rely on complex grid-based mathematical models, mostly involving Computational fluid dynamics(CFD) and Celluar Automata, but these methods have always been computationally expensive and difficult to deliver a fast decision pattern. In this paper, we provide machine learning based approaches that solve the problem of high computational effort and time consumption. This paper predicts the burning duration of a known wildfire by RF(random forest), KNN, and XGBoost regression models and also image-based, like CNN and Encoder. Model inputs are based on the map of landscape features provided by satellites and the corresponding historical fire data in this area. This model is trained by happened fire data and landform feature maps and tested with the most recent real value in the same area. By processing the input differently to obtain the optimal outcome, the system is able to make fast and relatively accurate future predictions based on landscape images of known fires.", "url": "https://arxiv.org/abs/2308.08936"}, {"metadata": {"arXiv": "2308.08938", "Date": "Thu, 17 Aug 2023 12:16:48 ", "Title": "Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces", "Authors": ["Ahmad-Reza Ehyaei", "Kiarash Mohammadi", "Amir-Hossein Karimi", "Samira Samadi", "Golnoosh Farnadi"], "Categories": "cs.LG cs.CY"}, "abstract": "As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.", "url": "https://arxiv.org/abs/2308.08938"}, {"metadata": {"arXiv": "2308.08963", "Date": "Thu, 17 Aug 2023 13:07:09 ", "Title": "CONVERT:Contrastive Graph Clustering with Reliable Augmentation", "Authors": ["Xihong Yang", "Cheng Tan", "Yue Liu", "Ke Liang", "Siwei Wang", "Sihang Zhou", "Jun Xia", "Stan Z. Li", "Xinwang Liu", "En Zhu"], "Categories": "cs.LG"}, "abstract": "Contrastive graph node clustering via learnable data augmentation is a hot research spot in the field of unsupervised graph learning. The existing methods learn the sampling distribution of a pre-defined augmentation to generate data-driven augmentations automatically. Although promising clustering performance has been achieved, we observe that these strategies still rely on pre-defined augmentations, the semantics of the augmented graph can easily drift. The reliability of the augmented view semantics for contrastive learning can not be guaranteed, thus limiting the model performance. To address these problems, we propose a novel CONtrastiVe Graph ClustEring network with Reliable AugmenTation (COVERT). Specifically, in our method, the data augmentations are processed by the proposed reversible perturb-recover network. It distills reliable semantic information by recovering the perturbed latent embeddings. Moreover, to further guarantee the reliability of semantics, a novel semantic loss is presented to constrain the network via quantifying the perturbation and recovery. Lastly, a label-matching mechanism is designed to guide the model by clustering information through aligning the semantic labels and the selected high-confidence clustering pseudo labels. Extensive experimental results on seven datasets demonstrate the effectiveness of the proposed method. We release the code and appendix of CONVERT at https://github.com/xihongyang1999/CONVERT on GitHub.", "url": "https://arxiv.org/abs/2308.08963"}, {"metadata": {"arXiv": "2308.08989", "Date": "Thu, 17 Aug 2023 13:50:03 ", "Title": "Neural oscillators for generalization of physics-informed machine learning", "Authors": ["Taniya Kapoor", "Abhishek Chandra", "Daniel M. Tartakovsky", "Hongrui Wang", "Alfredo Nunez", "Rolf Dollevoet"], "Categories": "cs.LG cs.NE"}, "abstract": "A primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.", "url": "https://arxiv.org/abs/2308.08989"}, {"metadata": {"arXiv": "2308.09013", "Date": "Thu, 17 Aug 2023 14:37:35 ", "Title": "Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals", "Authors": ["Antoine Dubois", "Carlos Lima Azevedo", "Sonja Haustein and Bruno Miranda"], "Categories": "cs.LG eess.SP", "Comments": ["7 pages", "1 figure", "2 tables"]}, "abstract": "Emotions play a significant role in the cognitive processes of the human brain, such as decision making, learning and perception. The use of physiological signals has shown to lead to more objective, reliable and accurate emotion recognition combined with raising machine learning methods. Supervised learning methods have dominated the attention of the research community, but the challenge in collecting needed labels makes emotion recognition difficult in large-scale semi- or uncontrolled experiments. Unsupervised methods are increasingly being explored, however sub-optimal signal feature selection and label identification challenges unsupervised methods' accuracy and applicability. This article proposes an unsupervised deep cluster framework for emotion recognition from physiological and psychological data. Tests on the open benchmark data set WESAD show that deep k-means and deep c-means distinguish the four quadrants of Russell's circumplex model of affect with an overall accuracy of 87%. Seeding the clusters with the subject's subjective assessments helps to circumvent the need for labels.", "url": "https://arxiv.org/abs/2308.09013"}, {"metadata": {"arXiv": "2308.09015", "Date": "Thu, 17 Aug 2023 14:40:48 ", "Title": "Multi-field Visualisation via Trait-induced Merge Trees", "Authors": ["Jochen Jankowai", "Talha Bin Masood", "and Ingrid Hotz"], "Categories": "cs.LG cs.HC"}, "abstract": "In this work, we propose trait-based merge trees a generalization of merge trees to feature level sets, targeting the analysis of tensor field or general multi-variate data. For this, we employ the notion of traits defined in attribute space as introduced in the feature level sets framework. The resulting distance field in attribute space induces a scalar field in the spatial domain that serves as input for topological data analysis. The leaves in the merge tree represent those areas in the input data that are closest to the defined trait and thus most closely resemble the defined feature. Hence, the merge tree yields a hierarchy of features that allows for querying the most relevant and persistent features. The presented method includes different query methods for the tree which enable the highlighting of different aspects. We demonstrate the cross-application capabilities of this approach with three case studies from different domains.", "url": "https://arxiv.org/abs/2308.09015"}, {"metadata": {"arXiv": "2308.09066", "Date": "Thu, 17 Aug 2023 15:54:21 ", "Title": "Uplift Modeling: from Causal Inference to Personalization", "Authors": ["Felipe Moraes", "Hugo Manuel Proen\\c{c}a", "Anastasiia Kornilova", "Javier Albert", "Dmitri Goldenberg"], "Categories": "cs.LG cs.IR"}, "abstract": "Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.", "url": "https://arxiv.org/abs/2308.09066"}, {"metadata": {"arXiv": "2308.09072", "Date": "Thu, 17 Aug 2023 16:01:02 ", "Title": "Joint Power Control and Data Size Selection for Over-the-Air Computation Aided Federated Learning", "Authors": ["Xuming An", "Rongfei Fan", "Shiyuan Zuo", "Han Hu", "Hai Jiang", "and Ning Zhang"], "Categories": "cs.LG"}, "abstract": "Federated learning (FL) has emerged as an appealing machine learning approach to deal with massive raw data generated at multiple mobile devices, {which needs to aggregate the training model parameter of every mobile device at one base station (BS) iteratively}. For parameter aggregating in FL, over-the-air computation is a spectrum-efficient solution, which allows all mobile devices to transmit their parameter-mapped signals concurrently to a BS. Due to heterogeneous channel fading and noise, there exists difference between the BS's received signal and its desired signal, measured as the mean-squared error (MSE). To minimize the MSE, we propose to jointly optimize the signal amplification factors at the BS and the mobile devices as well as the data size (the number of data samples involved in local training) at every mobile device. The formulated problem is challenging to solve due to its non-convexity. To find the optimal solution, with some simplification on cost function and variable replacement, which still preserves equivalence, we transform the changed problem to be a bi-level problem equivalently. For the lower-level problem, optimal solution is found by enumerating every candidate solution from the Karush-Kuhn-Tucker (KKT) condition. For the upper-level problem, the optimal solution is found by exploring its piecewise convexity. Numerical results show that our proposed method can greatly reduce the MSE and can help to improve the training performance of FL compared with benchmark methods.", "url": "https://arxiv.org/abs/2308.09072"}, {"metadata": {"arXiv": "2308.09078", "Date": "Thu, 17 Aug 2023 16:08:18 ", "Title": "Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling", "Authors": ["Vaidotas Simkus and Michael U. Gutmann"], "Categories": "cs.LG stat.ML", "MSC-class": "62D10", "ACM-class": "G.3"}, "abstract": "Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get \"stuck\" far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks.", "url": "https://arxiv.org/abs/2308.09078"}, {"metadata": {"arXiv": "2308.09082", "Date": "Thu, 17 Aug 2023 16:15:47 ", "Title": "Over-the-Air Computation Aided Federated Learning with the Aggregation of Normalized Gradient", "Authors": ["Rongfei Fan", "Xuming An", "Shiyuan Zuo", "and Han Hu"], "Categories": "cs.LG"}, "abstract": "Over-the-air computation is a communication-efficient solution for federated learning (FL). In such a system, iterative procedure is performed: Local gradient of private loss function is updated, amplified and then transmitted by every mobile device; the server receives the aggregated gradient all-at-once, generates and then broadcasts updated model parameters to every mobile device. In terms of amplification factor selection, most related works suppose the local gradient's maximal norm always happens although it actually fluctuates over iterations, which may degrade convergence performance. To circumvent this problem, we propose to turn local gradient to be normalized one before amplifying it. Under our proposed method, when the loss function is smooth, we prove our proposed method can converge to stationary point at sub-linear rate. In case of smooth and strongly convex loss function, we prove our proposed method can achieve minimal training loss at linear rate with any small positive tolerance. Moreover, a tradeoff between convergence rate and the tolerance is discovered. To speedup convergence, problems optimizing system parameters are also formulated for above two cases. Although being non-convex, optimal solution with polynomial complexity of the formulated problems are derived. Experimental results show our proposed method can outperform benchmark methods on convergence performance.", "url": "https://arxiv.org/abs/2308.09082"}, {"metadata": {"arXiv": "2308.09087", "Date": "Thu, 17 Aug 2023 16:29:17 ", "Title": "Modeling Edge Features with Deep Bayesian Graph Networks", "Authors": ["Daniele Atzeni", "Federico Errica", "Davide Bacciu", "Alessio Micheli"], "Categories": "cs.LG", "Comments": ["Releasing pre-print version to comply with TAILOR project requirements"], "DOI": "10.1109/IJCNN52387.2021.9533430"}, "abstract": "We propose an extension of the Contextual Graph Markov Model, a deep and probabilistic machine learning model for graphs, to model the distribution of edge features. Our approach is architectural, as we introduce an additional Bayesian network mapping edge features into discrete states to be used by the original model. In doing so, we are also able to build richer graph representations even in the absence of edge features, which is confirmed by the performance improvements on standard graph classification benchmarks. Moreover, we successfully test our proposal in a graph regression scenario where edge features are of fundamental importance, and we show that the learned edge representation provides substantial performance improvements against the original model on three link prediction tasks. By keeping the computational complexity linear in the number of edges, the proposed model is amenable to large-scale graph processing.", "url": "https://arxiv.org/abs/2308.09087"}, {"metadata": {"arXiv": "2308.09158", "Date": "Thu, 17 Aug 2023 19:12:13 ", "Title": "ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse", "Authors": ["Yi-Kai Zhang", "Lu Ren", "Chao Yi", "Qi-Wei Wang", "De-Chuan Zhan", "Han-Jia Ye"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "The rapid expansion of foundation pre-trained models and their fine-tuned counterparts has significantly contributed to the advancement of machine learning. Leveraging pre-trained models to extract knowledge and expedite learning in real-world tasks, known as \"Model Reuse\", has become crucial in various applications. Previous research focuses on reusing models within a certain aspect, including reusing model weights, structures, and hypothesis spaces. This paper introduces ZhiJian, a comprehensive and user-friendly toolbox for model reuse, utilizing the PyTorch backend. ZhiJian presents a novel paradigm that unifies diverse perspectives on model reuse, encompassing target architecture construction with PTM, tuning target model with PTM, and PTM-based inference. This empowers deep learning practitioners to explore downstream tasks and identify the complementary advantages among different methods. ZhiJian is readily accessible at https://github.com/zhangyikaii/lamda-zhijian facilitating seamless utilization of pre-trained models and streamlining the model reuse process for researchers and developers.", "url": "https://arxiv.org/abs/2308.09158"}, {"metadata": {"arXiv": "2308.09187", "Date": "Thu, 17 Aug 2023 21:15:04 ", "Title": "Distributed Extra-gradient with Optimal Complexity and Communication Guarantees", "Authors": ["Ali Ramezani-Kebrya and Kimon Antonakopoulos and Igor Krawczuk and Justin Deschenaux and Volkan Cevher"], "Categories": "cs.LG cs.DC math.OC", "Comments": ["International Conference on Learning Representations (ICLR 2023)"]}, "abstract": "We consider monotone variational inequality (VI) problems in multi-GPU settings where multiple processors/workers/clients have access to local stochastic dual vectors. This setting includes a broad range of important problems from distributed convex minimization to min-max and games. Extra-gradient, which is a de facto algorithm for monotone VI problems, has not been designed to be communication-efficient. To this end, we propose a quantized generalized extra-gradient (Q-GenX), which is an unbiased and adaptive compression method tailored to solve VIs. We provide an adaptive step-size rule, which adapts to the respective noise profiles at hand and achieve a fast rate of ${\\mathcal O}(1/T)$ under relative noise, and an order-optimal ${\\mathcal O}(1/\\sqrt{T})$ under absolute noise and show distributed training accelerates convergence. Finally, we validate our theoretical results by providing real-world experiments and training generative adversarial networks on multiple GPUs.", "url": "https://arxiv.org/abs/2308.09187"}, {"metadata": {"arXiv": "2308.09198", "Date": "Thu, 17 Aug 2023 22:24:15 ", "Title": "Half-Hop: A graph upsampling approach for slowing down message passing", "Authors": ["Mehdi Azabou", "Venkataramana Ganesh", "Shantanu Thakoor", "Chi-Heng Lin", "Lakshmi Sathidevi", "Ran Liu", "Michal Valko", "Petar Veli\\v{c}kovi\\'c", "Eva L. Dyer"], "Categories": "cs.LG cs.SI", "Comments": ["Published as a conference paper at ICML 2023"]}, "abstract": "Message passing neural networks have shown a lot of success on graph-structured data. However, there are many instances where message passing can lead to over-smoothing or fail when neighboring nodes belong to different classes. In this work, we introduce a simple yet general framework for improving learning in message passing neural networks. Our approach essentially upsamples edges in the original graph by adding \"slow nodes\" at each edge that can mediate communication between a source and a target node. Our method only modifies the input graph, making it plug-and-play and easy to use with existing models. To understand the benefits of slowing down message passing, we provide theoretical and empirical analyses. We report results on several supervised and self-supervised benchmarks, and show improvements across the board, notably in heterophilic conditions where adjacent nodes are more likely to have different labels. Finally, we show how our approach can be used to generate augmentations for self-supervised learning, where slow nodes are randomly introduced into different edges in the graph to generate multi-scale views with variable path lengths.", "url": "https://arxiv.org/abs/2308.09198"}, {"metadata": {"arXiv": "2308.09199", "Date": "Thu, 17 Aug 2023 22:26:48 ", "Title": "Polynomial Bounds for Learning Noisy Optical Physical Unclonable Functions and Connections to Learning With Errors", "Authors": ["Apollo Albright", "Boris Gelfand", "Michael Dixon"], "Categories": "cs.LG cs.CR physics.optics", "Comments": ["10 pages", "2 figures", "submitted to IEEE Transactions on Information Forensics and Security"], "Report-no": "LA-UR-23-29328"}, "abstract": "It is shown that a class of optical physical unclonable functions (PUFs) can be learned to arbitrary precision with arbitrarily high probability, even in the presence of noise, given access to polynomially many challenge-response pairs and polynomially bounded computational power, under mild assumptions about the distributions of the noise and challenge vectors. This extends the results of Rh\\\"uramir et al. (2013), who showed a subset of this class of PUFs to be learnable in polynomial time in the absence of noise, under the assumption that the optics of the PUF were either linear or had negligible nonlinear effects. We derive polynomial bounds for the required number of samples and the computational complexity of a linear regression algorithm, based on size parameters of the PUF, the distributions of the challenge and noise vectors, and the probability and accuracy of the regression algorithm, with a similar analysis to one done by Bootle et al. (2018), who demonstrated a learning attack on a poorly implemented version of the Learning With Errors problem.", "url": "https://arxiv.org/abs/2308.09199"}, {"metadata": {"arXiv": "2308.09201", "Date": "Thu, 17 Aug 2023 22:32:32 ", "Title": "TinyProp -- Adaptive Sparse Backpropagation for Efficient TinyML On-device Learning", "Authors": ["Marcus R\\\"ub", "Daniel Maier", "Daniel Mueller-Gritschneder", "Axel Sikora"], "Categories": "cs.LG cs.CV", "Comments": ["7 Pages", "AIPE Conference 2023"]}, "abstract": "Training deep neural networks using backpropagation is very memory and computationally intensive. This makes it difficult to run on-device learning or fine-tune neural networks on tiny, embedded devices such as low-power micro-controller units (MCUs). Sparse backpropagation algorithms try to reduce the computational load of on-device learning by training only a subset of the weights and biases. Existing approaches use a static number of weights to train. A poor choice of this so-called backpropagation ratio limits either the computational gain or can lead to severe accuracy losses. In this paper we present TinyProp, the first sparse backpropagation method that dynamically adapts the back-propagation ratio during on-device training for each training step. TinyProp induces a small calculation overhead to sort the elements of the gradient, which does not significantly impact the computational gains. TinyProp works particularly well on fine-tuning trained networks on MCUs, which is a typical use case for embedded applications. For typical datasets from three datasets MNIST, DCASE2020 and CIFAR10, we are 5 times faster compared to non-sparse training with an accuracy loss of on average 1%. On average, TinyProp is 2.9 times faster than existing, static sparse backpropagation algorithms and the accuracy loss is reduced on average by 6 % compared to a typical static setting of the back-propagation ratio.", "url": "https://arxiv.org/abs/2308.09201"}, {"metadata": {"arXiv": "2308.09248", "Date": "Fri, 18 Aug 2023 02:23:48 ", "Title": "Active and Passive Causal Inference Learning", "Authors": ["Daniel Jiwoong Im", "Kyunghyun Cho"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper serves as a starting point for machine learning researchers, engineers and students who are interested in but not yet familiar with causal inference. We start by laying out an important set of assumptions that are collectively needed for causal identification, such as exchangeability, positivity, consistency and the absence of interference. From these assumptions, we build out a set of important causal inference techniques, which we do so by categorizing them into two buckets; active and passive approaches. We describe and discuss randomized controlled trials and bandit-based approaches from the active category. We then describe classical approaches, such as matching and inverse probability weighting, in the passive category, followed by more recent deep learning based algorithms. By finishing the paper with some of the missing aspects of causal inference from this paper, such as collider biases, we expect this paper to provide readers with a diverse set of starting points for further reading and research in causal inference and discovery.", "url": "https://arxiv.org/abs/2308.09248"}, {"metadata": {"arXiv": "2308.09250", "Date": "Fri, 18 Aug 2023 02:24:32 ", "Title": "Capacity Bounds for Hyperbolic Neural Network Representations of Latent Tree Structures", "Authors": ["Anastasis Kratsios", "Ruiyang Hong", "Haitz S\\'aez de Oc\\'ariz Borde"], "Categories": "cs.LG cs.DM cs.NA cs.NE math.MG math.NA", "Comments": ["22 Pages + References", "1 Table", "4 Figures"], "MSC-class": "68T07, 30L05, 68R12, 05C05"}, "abstract": "We study the representation capacity of deep hyperbolic neural networks (HNNs) with a ReLU activation function. We establish the first proof that HNNs can $\\varepsilon$-isometrically embed any finite weighted tree into a hyperbolic space of dimension $d$ at least equal to $2$ with prescribed sectional curvature $\\kappa<0$, for any $\\varepsilon> 1$ (where $\\varepsilon=1$ being optimal). We establish rigorous upper bounds for the network complexity on an HNN implementing the embedding. We find that the network complexity of HNN implementing the graph representation is independent of the representation fidelity/distortion. We contrast this result against our lower bounds on distortion which any ReLU multi-layer perceptron (MLP) must exert when embedding a tree with $L>2^d$ leaves into a $d$-dimensional Euclidean space, which we show at least $\\Omega(L^{1/d})$; independently of the depth, width, and (possibly discontinuous) activation function defining the MLP.", "url": "https://arxiv.org/abs/2308.09250"}, {"metadata": {"arXiv": "2308.09259", "Date": "Fri, 18 Aug 2023 02:34:37 ", "Title": "Distribution shift mitigation at test time with performance guarantees", "Authors": ["Rui Ding", "Jielong Yang", "Feng Ji", "Xionghu Zhong", "Linbo Xie"], "Categories": "cs.LG"}, "abstract": "Due to inappropriate sample selection and limited training data, a distribution shift often exists between the training and test sets. This shift can adversely affect the test performance of Graph Neural Networks (GNNs). Existing approaches mitigate this issue by either enhancing the robustness of GNNs to distribution shift or reducing the shift itself. However, both approaches necessitate retraining the model, which becomes unfeasible when the model structure and parameters are inaccessible. To address this challenge, we propose FR-GNN, a general framework for GNNs to conduct feature reconstruction. FRGNN constructs a mapping relationship between the output and input of a well-trained GNN to obtain class representative embeddings and then uses these embeddings to reconstruct the features of labeled nodes. These reconstructed features are then incorporated into the message passing mechanism of GNNs to influence the predictions of unlabeled nodes at test time. Notably, the reconstructed node features can be directly utilized for testing the well-trained model, effectively reducing the distribution shift and leading to improved test performance. This remarkable achievement is attained without any modifications to the model structure or parameters. We provide theoretical guarantees for the effectiveness of our framework. Furthermore, we conduct comprehensive experiments on various public datasets. The experimental results demonstrate the superior performance of FRGNN in comparison to mainstream methods.", "url": "https://arxiv.org/abs/2308.09259"}, {"metadata": {"arXiv": "2308.09274", "Date": "Fri, 18 Aug 2023 03:32:55 ", "Title": "A hybrid Decoder-DeepONet operator regression framework for unaligned observation data", "Authors": ["Bo Chen", "Chenyu Wang", "Weipeng Li", "Haiyang Fu"], "Categories": "cs.LG", "Comments": ["35 pages", "10 figures", "11 tables"], "MSC-class": "76-10", "ACM-class": "J.2.1"}, "abstract": "Deep neural operators (DNOs) have been utilized to approximate nonlinear mappings between function spaces. However, DNOs face the challenge of increased dimensionality and computational cost associated with unaligned observation data. In this study, we propose a hybrid Decoder-DeepONet operator regression framework to handle unaligned data effectively. Additionally, we introduce a Multi-Decoder-DeepONet, which utilizes an average field of training data as input augmentation. The consistencies of the frameworks with the operator approximation theory are provided, on the basis of the universal approximation theorem. Two numerical experiments, Darcy problem and flow-field around an airfoil, are conducted to validate the efficiency and accuracy of the proposed methods. Results illustrate the advantages of Decoder-DeepONet and Multi-Decoder-DeepONet in handling unaligned observation data and showcase their potentials in improving prediction accuracy.", "url": "https://arxiv.org/abs/2308.09274"}, {"metadata": {"arXiv": "2308.09296", "Date": "Fri, 18 Aug 2023 04:45:56 ", "Title": "CARLA: A Self-supervised Contrastive Representation Learning Approach for Time Series Anomaly Detection", "Authors": ["Zahra Zamanzadeh Darban", "Geoffrey I. Webb", "Shirui Pan", "Mahsa Salehi"], "Categories": "cs.LG cs.NE", "Comments": ["33 pages", "9 figures", "10 tables"]}, "abstract": "We introduce a Self-supervised Contrastive Representation Learning Approach for Time Series Anomaly Detection (CARLA), an innovative end-to-end self-supervised framework carefully developed to identify anomalous patterns in both univariate and multivariate time series data. By taking advantage of contrastive representation learning, We introduce an innovative end-to-end self-supervised deep learning framework carefully developed to identify anomalous patterns in both univariate and multivariate time series data. By taking advantage of contrastive representation learning, CARLA effectively generates robust representations for time series windows. It achieves this by 1) learning similar representations for temporally close windows and dissimilar representations for windows and their equivalent anomalous windows and 2) employing a self-supervised approach to classify normal/anomalous representations of windows based on their nearest/furthest neighbours in the representation space. Most of the existing models focus on learning normal behaviour. The normal boundary is often tightly defined, which can result in slight deviations being classified as anomalies, resulting in a high false positive rate and limited ability to generalise normal patterns. CARLA's contrastive learning methodology promotes the production of highly consistent and discriminative predictions, thereby empowering us to adeptly address the inherent challenges associated with anomaly detection in time series data. Through extensive experimentation on 7 standard real-world time series anomaly detection benchmark datasets, CARLA demonstrates F1 and AU-PR superior to existing state-of-the-art results. Our research highlights the immense potential of contrastive representation learning in advancing the field of time series anomaly detection, thus paving the way for novel applications and in-depth exploration in this domain.", "url": "https://arxiv.org/abs/2308.09296"}, {"metadata": {"arXiv": "2308.09301", "Date": "Fri, 18 Aug 2023 04:49:45 ", "Title": "Learning Reward Machines through Preference Queries over Sequences", "Authors": ["Eric Hsiung", "Joydeep Biswas", "Swarat Chaudhuri"], "Categories": "cs.LG", "Comments": ["24 pages", "10 figures"]}, "abstract": "Reward machines have shown great promise at capturing non-Markovian reward functions for learning tasks that involve complex action sequencing. However, no algorithm currently exists for learning reward machines with realistic weak feedback in the form of preferences. We contribute REMAP, a novel algorithm for learning reward machines from preferences, with correctness and termination guarantees. REMAP introduces preference queries in place of membership queries in the L* algorithm, and leverages a symbolic observation table along with unification and constraint solving to narrow the hypothesis reward machine search space. In addition to the proofs of correctness and termination for REMAP, we present empirical evidence measuring correctness: how frequently the resulting reward machine is isomorphic under a consistent yet inexact teacher, and the regret between the ground truth and learned reward machines.", "url": "https://arxiv.org/abs/2308.09301"}, {"metadata": {"arXiv": "2308.09360", "Date": "Fri, 18 Aug 2023 07:40:56 ", "Title": "Multi-feature concatenation and multi-classifier stacking: an interpretable and generalizable machine learning method for MDD discrimination with rsfMRI", "Authors": ["Yunsong Luo", "Wenyu Chen", "Ling Zhan", "Jiang Qiu", "Tao Jia"], "Categories": "cs.LG eess.SP"}, "abstract": "Major depressive disorder is a serious and heterogeneous psychiatric disorder that needs accurate diagnosis. Resting-state functional MRI (rsfMRI), which captures multiple perspectives on brain structure, function, and connectivity, is increasingly applied in the diagnosis and pathological research of mental diseases. Different machine learning algorithms are then developed to exploit the rich information in rsfMRI and discriminate MDD patients from normal controls. Despite recent advances reported, the discrimination accuracy has room for further improvement. The generalizability and interpretability of the method are not sufficiently addressed either. Here, we propose a machine learning method (MFMC) for MDD discrimination by concatenating multiple features and stacking multiple classifiers. MFMC is tested on the REST-meta-MDD data set that contains 2428 subjects collected from 25 different sites. MFMC yields 96.9% MDD discrimination accuracy, demonstrating a significant improvement over existing methods. In addition, the generalizability of MFMC is validated by the good performance when the training and testing subjects are from independent sites. The use of XGBoost as the meta classifier allows us to probe the decision process of MFMC. We identify 13 feature values related to 9 brain regions including the posterior cingulate gyrus, superior frontal gyrus orbital part, and angular gyrus, which contribute most to the classification and also demonstrate significant differences at the group level. The use of these 13 feature values alone can reach 87% of MFMC's full performance when taking all feature values. These features may serve as clinically useful diagnostic and prognostic biomarkers for mental disorders in the future.", "url": "https://arxiv.org/abs/2308.09360"}, {"metadata": {"arXiv": "2308.09381", "Date": "Fri, 18 Aug 2023 08:24:57 ", "Title": "On Gradient-like Explanation under a Black-box Setting: When Black-box Explanations Become as Good as White-box", "Authors": ["Yi Cai", "Gerhard Wunder"], "Categories": "cs.LG"}, "abstract": "Attribution methods shed light on the explainability of data-driven approaches such as deep learning models by revealing the most contributing features to decisions that have been made. A widely accepted way of deriving feature attributions is to analyze the gradients of the target function with respect to input features. Analysis of gradients requires full access to the target system, meaning that solutions of this kind treat the target system as a white-box. However, the white-box assumption may be untenable due to security and safety concerns, thus limiting their practical applications. As an answer to the limited flexibility, this paper presents GEEX (gradient-estimation-based explanation), an explanation method that delivers gradient-like explanations under a black-box setting. Furthermore, we integrate the proposed method with a path method. The resulting approach iGEEX (integrated GEEX) satisfies the four fundamental axioms of attribution methods: sensitivity, insensitivity, implementation invariance, and linearity. With a focus on image data, the exhaustive experiments empirically show that the proposed methods outperform state-of-the-art black-box methods and achieve competitive performance compared to the ones with full access.", "url": "https://arxiv.org/abs/2308.09381"}, {"metadata": {"arXiv": "2308.09393", "Date": "Fri, 18 Aug 2023 08:49:30 ", "Title": "Learning MDL logic programs from noisy data", "Authors": ["C\\'eline Hocquette", "Andreas Niskanen", "Matti J\\\"arvisalo", "Andrew Cropper"], "Categories": "cs.LG cs.LO", "Comments": ["arXiv admin note: text overlap with arXiv:2206.01614"]}, "abstract": "Many inductive logic programming approaches struggle to learn programs from noisy data. To overcome this limitation, we introduce an approach that learns minimal description length programs from noisy data, including recursive programs. Our experiments on several domains, including drug design, game playing, and program synthesis, show that our approach can outperform existing approaches in terms of predictive accuracies and scale to moderate amounts of noise.", "url": "https://arxiv.org/abs/2308.09393"}, {"metadata": {"arXiv": "2308.09430", "Date": "Fri, 18 Aug 2023 10:00:27 ", "Title": "Towards Understanding the Generalizability of Delayed Stochastic Gradient Descent", "Authors": ["Xiaoge Deng", "Li Shen", "Shengwei Li", "Tao Sun", "Dongsheng Li", "and Dacheng Tao"], "Categories": "cs.LG"}, "abstract": "Stochastic gradient descent (SGD) performed in an asynchronous manner plays a crucial role in training large-scale machine learning models. However, the generalization performance of asynchronous delayed SGD, which is an essential metric for assessing machine learning algorithms, has rarely been explored. Existing generalization error bounds are rather pessimistic and cannot reveal the correlation between asynchronous delays and generalization. In this paper, we investigate sharper generalization error bound for SGD with asynchronous delay $\\tau$. Leveraging the generating function analysis tool, we first establish the average stability of the delayed gradient algorithm. Based on this algorithmic stability, we provide upper bounds on the generalization error of $\\tilde{\\mathcal{O}}(\\frac{T-\\tau}{n\\tau})$ and $\\tilde{\\mathcal{O}}(\\frac{1}{n})$ for quadratic convex and strongly convex problems, respectively, where $T$ refers to the iteration number and $n$ is the amount of training data. Our theoretical results indicate that asynchronous delays reduce the generalization error of the delayed SGD algorithm. Analogous analysis can be generalized to the random delay setting, and the experimental results validate our theoretical findings.", "url": "https://arxiv.org/abs/2308.09430"}, {"metadata": {"arXiv": "2308.09444", "Date": "Fri, 18 Aug 2023 10:17:59 ", "Title": "An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network", "Authors": ["Weiguo Lu", "Xuan Wu", "Deng Ding", "Gangnan Yuan"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose an Gaussian Mixture Model (GMM) learning algorithm, based on our previous work of GMM expansion idea. The new algorithm brings more robustness and simplicity than classic Expectation Maximization (EM) algorithm. It also improves the accuracy and only take 1 iteration for learning. We theoretically proof that this new algorithm is guarantee to converge regardless the parameters initialisation. We compare our GMM expansion method with classic probability layers in neural network leads to demonstrably better capability to overcome data uncertainty and inverse problem. Finally, we test GMM based generator which shows a potential to build further application that able to utilized distribution random sampling for stochastic variation as well as variation control.", "url": "https://arxiv.org/abs/2308.09444"}, {"metadata": {"arXiv": "2308.09448", "Date": "Fri, 18 Aug 2023 10:22:31 ", "Title": "Defending Label Inference Attacks in Split Learning under Regression Setting", "Authors": ["Haoze Qiu", "Fei Zheng", "Chaochao Chen", "Xiaolin Zheng"], "Categories": "cs.LG cs.CR"}, "abstract": "As a privacy-preserving method for implementing Vertical Federated Learning, Split Learning has been extensively researched. However, numerous studies have indicated that the privacy-preserving capability of Split Learning is insufficient. In this paper, we primarily focus on label inference attacks in Split Learning under regression setting, which are mainly implemented through the gradient inversion method. To defend against label inference attacks, we propose Random Label Extension (RLE), where labels are extended to obfuscate the label information contained in the gradients, thereby preventing the attacker from utilizing gradients to train an attack model that can infer the original labels. To further minimize the impact on the original task, we propose Model-based adaptive Label Extension (MLE), where original labels are preserved in the extended labels and dominate the training process. The experimental results show that compared to the basic defense methods, our proposed defense methods can significantly reduce the attack model's performance while preserving the original task's performance.", "url": "https://arxiv.org/abs/2308.09448"}, {"metadata": {"arXiv": "2308.09464", "Date": "Fri, 18 Aug 2023 11:02:27 ", "Title": "Data augmentation and explainability for bias discovery and mitigation in deep learning", "Authors": ["Agnieszka Miko{\\l}ajczyk-Bare{\\l}a"], "Categories": "cs.LG cs.CV", "Comments": ["A PhD Thesis"]}, "abstract": "This dissertation explores the impact of bias in deep neural networks and presents methods for reducing its influence on model performance. The first part begins by categorizing and describing potential sources of bias and errors in data and models, with a particular focus on bias in machine learning pipelines. The next chapter outlines a taxonomy and methods of Explainable AI as a way to justify predictions and control and improve the model. Then, as an example of a laborious manual data inspection and bias discovery process, a skin lesion dataset is manually examined. A Global Explanation for the Bias Identification method is proposed as an alternative semi-automatic approach to manual data exploration for discovering potential biases in data. Relevant numerical methods and metrics are discussed for assessing the effects of the identified biases on the model. Whereas identifying errors and bias is critical, improving the model and reducing the number of flaws in the future is an absolute priority. Hence, the second part of the thesis focuses on mitigating the influence of bias on ML models. Three approaches are proposed and discussed: Style Transfer Data Augmentation, Targeted Data Augmentations, and Attribution Feedback. Style Transfer Data Augmentation aims to address shape and texture bias by merging a style of a malignant lesion with a conflicting shape of a benign one. Targeted Data Augmentations randomly insert possible biases into all images in the dataset during the training, as a way to make the process random and, thus, destroy spurious correlations. Lastly, Attribution Feedback is used to fine-tune the model to improve its accuracy by eliminating obvious mistakes and teaching it to ignore insignificant input parts via an attribution loss. The goal of these approaches is to reduce the influence of bias on machine learning models, rather than eliminate it entirely.", "url": "https://arxiv.org/abs/2308.09464"}, {"metadata": {"arXiv": "2308.09499", "Date": "Fri, 18 Aug 2023 12:14:51 ", "Title": "Bridged-GNN: Knowledge Bridge Learning for Effective Knowledge Transfer", "Authors": ["Wendong Bi", "Xueqi Cheng", "Bingbing Xu", "Xiaoqian Sun", "Li Xu", "Huawei Shen"], "Categories": "cs.LG", "Comments": ["Accepted by CIKM2023"], "DOI": "10.1145/3583780.3614796"}, "abstract": "The data-hungry problem, characterized by insufficiency and low-quality of data, poses obstacles for deep learning models. Transfer learning has been a feasible way to transfer knowledge from high-quality external data of source domains to limited data of target domains, which follows a domain-level knowledge transfer to learn a shared posterior distribution. However, they are usually built on strong assumptions, e.g., the domain invariant posterior distribution, which is usually unsatisfied and may introduce noises, resulting in poor generalization ability on target domains. Inspired by Graph Neural Networks (GNNs) that aggregate information from neighboring nodes, we redefine the paradigm as learning a knowledge-enhanced posterior distribution for target domains, namely Knowledge Bridge Learning (KBL). KBL first learns the scope of knowledge transfer by constructing a Bridged-Graph that connects knowledgeable samples to each target sample and then performs sample-wise knowledge transfer via GNNs.KBL is free from strong assumptions and is robust to noises in the source data. Guided by KBL, we propose the Bridged-GNN} including an Adaptive Knowledge Retrieval module to build Bridged-Graph and a Graph Knowledge Transfer module. Comprehensive experiments on both un-relational and relational data-hungry scenarios demonstrate the significant improvements of Bridged-GNN compared with SOTA methods", "url": "https://arxiv.org/abs/2308.09499"}, {"metadata": {"arXiv": "2308.09517", "Date": "Fri, 18 Aug 2023 12:49:57 ", "Title": "Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-based Similarity", "Authors": ["Van Thuy Hoang and O-Joun Lee"], "Categories": "cs.LG cs.SI", "Comments": ["13 pages"]}, "abstract": "Graph representation learning (GRL) methods, such as graph neural networks and graph transformer models, have been successfully used to analyze graph-structured data, mainly focusing on node classification and link prediction tasks. However, the existing studies mostly only consider local connectivity while ignoring long-range connectivity and the roles of nodes. In this paper, we propose Unified Graph Transformer Networks (UGT) that effectively integrate local and global structural information into fixed-length vector representations. First, UGT learns local structure by identifying the local substructures and aggregating features of the $k$-hop neighborhoods of each node. Second, we construct virtual edges, bridging distant nodes with structural similarity to capture the long-range dependencies. Third, UGT learns unified representations through self-attention, encoding structural distance and $p$-step transition probability between node pairs. Furthermore, we propose a self-supervised learning task that effectively learns transition probability to fuse local and global structural features, which could then be transferred to other downstream tasks. Experimental results on real-world benchmark datasets over various downstream tasks showed that UGT significantly outperformed baselines that consist of state-of-the-art models. In addition, UGT reaches the expressive power of the third-order Weisfeiler-Lehman isomorphism test (3d-WL) in distinguishing non-isomorphic graph pairs. The source code is available at https://github.com/NSLab-CUK/Unified-Graph-Transformer.", "url": "https://arxiv.org/abs/2308.09517"}, {"metadata": {"arXiv": "2308.09543", "Date": "Fri, 18 Aug 2023 13:20:08 ", "Title": "Latent State Models of Training Dynamics", "Authors": ["Michael Y. Hu", "Angelica Chen", "Naomi Saphra", "Kyunghyun Cho"], "Categories": "cs.LG"}, "abstract": "The impact of randomness on model training is poorly understood. How do differences in data order and initialization actually manifest in the model, such that some training runs outperform others or converge faster? Furthermore, how can we interpret the resulting training dynamics and the phase transitions that characterize different trajectories? To understand the effect of randomness on the dynamics and outcomes of neural network training, we train models multiple times with different random seeds and compute a variety of metrics throughout training, such as the $L_2$ norm, mean, and variance of the neural network's weights. We then fit a hidden Markov model (HMM) over the resulting sequences of metrics. The HMM represents training as a stochastic process of transitions between latent states, providing an intuitive overview of significant changes during training. Using our method, we produce a low-dimensional, discrete representation of training dynamics on grokking tasks, image classification, and masked language modeling. We use the HMM representation to study phase transitions and identify latent \"detour\" states that slow down convergence.", "url": "https://arxiv.org/abs/2308.09543"}, {"metadata": {"arXiv": "2308.09565", "Date": "Fri, 18 Aug 2023 13:57:04 ", "Title": "Normalization Is All You Need: Understanding Layer-Normalized Federated Learning under Extreme Label Shift", "Authors": ["Guojun Zhang", "Mahdi Beitollahi", "Alex Bie", "Xi Chen"], "Categories": "cs.LG stat.ML", "Comments": ["23 pages", "9 figures"]}, "abstract": "Layer normalization (LN) is a widely adopted deep learning technique especially in the era of foundation models. Recently, LN has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. In this work, we reveal the profound connection between layer normalization and the label shift problem in federated learning. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. Empirically, we show that normalization leads to drastic improvements on standard benchmarks under extreme label shift. Moreover, we conduct extensive ablation studies to understand the critical factors of layer normalization in FL. Our results verify that FN is an essential ingredient inside LN to significantly improve the convergence of FL while remaining robust to learning rate choices, especially under extreme label shift where each client has access to few classes.", "url": "https://arxiv.org/abs/2308.09565"}, {"metadata": {"arXiv": "2308.09571", "Date": "Fri, 18 Aug 2023 14:03:34 ", "Title": "Physics-Informed Boundary Integral Networks (PIBI-Nets): A Data-Driven Approach for Solving Partial Differential Equations", "Authors": ["Monika Nagy-Huber", "Volker Roth"], "Categories": "cs.LG cs.NA math.DS math.NA physics.comp-ph", "Comments": ["Preprint. Submitted to Journal of Computational Science", "Elsevier", "for special issue \"Machine Learning and Data Assimilation for Dynamical Systems\""]}, "abstract": "Partial differential equations (PDEs) can describe many relevant phenomena in dynamical systems. In real-world applications, we commonly need to combine formal PDE models with (potentially noisy) observations. This is especially relevant in settings where we lack information about boundary or initial conditions, or where we need to identify unknown model parameters. In recent years, Physics-informed neural networks (PINNs) have become a popular tool for problems of this kind. In high-dimensional settings, however, PINNs often suffer from computational problems because they usually require dense collocation points over the entire computational domain. To address this problem, we present Physics-Informed Boundary Integral Networks (PIBI-Nets) as a data-driven approach for solving PDEs in one dimension less than the original problem space. PIBI-Nets only need collocation points at the computational domain boundary, while still achieving highly accurate results, and in several practical settings, they clearly outperform PINNs. Exploiting elementary properties of fundamental solutions of linear differential operators, we present a principled and simple way to handle point sources in inverse problems. We demonstrate the excellent performance of PIBI-Nets for the Laplace and Poisson equations, both on artificial data sets and within a real-world application concerning the reconstruction of groundwater flows.", "url": "https://arxiv.org/abs/2308.09571"}, {"metadata": {"arXiv": "2308.09596", "Date": "Fri, 18 Aug 2023 14:45:28 ", "Title": "Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification", "Authors": ["Arpit Merchant", "Carlos Castillo"], "Categories": "cs.LG cs.CY cs.SI", "Comments": ["Accepted to CIKM 2023"]}, "abstract": "Graph neural networks (GNNs) are increasingly used in critical human applications for predicting node labels in attributed graphs. Their ability to aggregate features from nodes' neighbors for accurate classification also has the capacity to exacerbate existing biases in data or to introduce new ones towards members from protected demographic groups. Thus, it is imperative to quantify how GNNs may be biased and to what extent their harmful effects may be mitigated. To this end, we propose two new GNN-agnostic interventions namely, (i) PFR-AX which decreases the separability between nodes in protected and non-protected groups, and (ii) PostProcess which updates model predictions based on a blackbox policy to minimize differences between error rates across demographic groups. Through a large set of experiments on four datasets, we frame the efficacies of our approaches (and three variants) in terms of their algorithmic fairness-accuracy tradeoff and benchmark our results against three strong baseline interventions on three state-of-the-art GNN models. Our results show that no single intervention offers a universally optimal tradeoff, but PFR-AX and PostProcess provide granular control and improve model confidence when correctly predicting positive outcomes for nodes in protected groups.", "url": "https://arxiv.org/abs/2308.09596"}, {"metadata": {"arXiv": "2308.09604", "Date": "Fri, 18 Aug 2023 14:57:21 ", "Title": "Breaking the Complexity Barrier in Compositional Minimax Optimization", "Authors": ["Jin Liu", "Xiaokang Pan", "Junwen Duan", "Hongdong Li", "Youqi Li", "Zhe Qu"], "Categories": "cs.LG math.OC"}, "abstract": "Compositional minimax optimization is a pivotal yet under-explored challenge across machine learning, including distributionally robust training and policy evaluation for reinforcement learning. Current techniques exhibit suboptimal complexity or rely heavily on large batch sizes. This paper proposes Nested STOchastic Recursive Momentum (NSTORM), attaining the optimal sample complexity of $O(\\kappa^3/\\epsilon^3)$ for finding an $\\epsilon$-accurate solution. However, NSTORM requires low learning rates, potentially limiting applicability. Thus we introduce ADAptive NSTORM (ADA-NSTORM) with adaptive learning rates, proving it achieves the same sample complexity while experiments demonstrate greater effectiveness. Our methods match lower bounds for minimax optimization without large batch requirements, validated through extensive experiments. This work significantly advances compositional minimax optimization, a crucial capability for distributional robustness and policy evaluation", "url": "https://arxiv.org/abs/2308.09604"}, {"metadata": {"arXiv": "2308.09612", "Date": "Fri, 18 Aug 2023 15:14:31 ", "Title": "Constrained Bayesian Optimization Using a Lagrange Multiplier Applied to Power Transistor Design", "Authors": ["Ping-Ju Chuang", "Ali Saadat", "Sara Ghazvini", "Hal Edwards", "William G. Vandenberghe"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["7 pages", "5 figures"]}, "abstract": "We propose a novel constrained Bayesian Optimization (BO) algorithm optimizing the design process of Laterally-Diffused Metal-Oxide-Semiconductor (LDMOS) transistors while realizing a target Breakdown Voltage (BV). We convert the constrained BO problem into a conventional BO problem using a Lagrange multiplier. Instead of directly optimizing the traditional Figure-of-Merit (FOM), we set the Lagrangian as the objective function of BO. This adaptive objective function with a changeable Lagrange multiplier can address constrained BO problems which have constraints that require costly evaluations, without the need for additional surrogate models to approximate constraints. Our algorithm enables a device designer to set the target BV in the design space, and obtain a device that satisfies the optimized FOM and the target BV constraint automatically. Utilizing this algorithm, we have also explored the physical limits of the FOM for our devices in 30 - 50 V range within the defined design space.", "url": "https://arxiv.org/abs/2308.09612"}, {"metadata": {"arXiv": "2308.09629", "Date": "Fri, 18 Aug 2023 15:43:31 ", "Title": "Learning Computational Efficient Bots with Costly Features", "Authors": ["Anthony Kobanda", "Valliappan C.A.", "Joshua Romoff", "Ludovic Denoyer"], "Categories": "cs.LG"}, "abstract": "Deep reinforcement learning (DRL) techniques have become increasingly used in various fields for decision-making processes. However, a challenge that often arises is the trade-off between both the computational efficiency of the decision-making process and the ability of the learned agent to solve a particular task. This is particularly critical in real-time settings such as video games where the agent needs to take relevant decisions at a very high frequency, with a very limited inference time. In this work, we propose a generic offline learning approach where the computation cost of the input features is taken into account. We derive the Budgeted Decision Transformer as an extension of the Decision Transformer that incorporates cost constraints to limit its cost at inference. As a result, the model can dynamically choose the best input features at each timestep. We demonstrate the effectiveness of our method on several tasks, including D4RL benchmarks and complex 3D environments similar to those found in video games, and show that it can achieve similar performance while using significantly fewer computational resources compared to classical approaches.", "url": "https://arxiv.org/abs/2308.09629"}, {"metadata": {"arXiv": "2308.09635", "Date": "Fri, 18 Aug 2023 15:53:40 ", "Title": "Development of a Neural Network-based Method for Improved Imputation of Missing Values in Time Series Data by Repurposing DataWig", "Authors": ["Daniel Zhang"], "Categories": "cs.LG", "Comments": ["16 pages", "3 figures", "2 tables"]}, "abstract": "Time series data are observations collected over time intervals. Successful analysis of time series data captures patterns such as trends, cyclicity and irregularity, which are crucial for decision making in research, business, and governance. However, missing values in time series data occur often and present obstacles to successful analysis, thus they need to be filled with alternative values, a process called imputation. Although various approaches have been attempted for robust imputation of time series data, even the most advanced methods still face challenges including limited scalability, poor capacity to handle heterogeneous data types and inflexibility due to requiring strong assumptions of data missing mechanisms. Moreover, the imputation accuracy of these methods still has room for improvement. In this study, I developed tsDataWig (time-series DataWig) by modifying DataWig, a neural network-based method that possesses the capacity to process large datasets and heterogeneous data types but was designed for non-time series data imputation. Unlike the original DataWig, tsDataWig can directly handle values of time variables and impute missing values in complex time series datasets. Using one simulated and three different complex real-world time series datasets, I demonstrated that tsDataWig outperforms the original DataWig and the current state-of-the-art methods for time series data imputation and potentially has broad application due to not requiring strong assumptions of data missing mechanisms. This study provides a valuable solution for robustly imputing missing values in challenging time series datasets, which often contain millions of samples, high dimensional variables, and heterogeneous data types.", "url": "https://arxiv.org/abs/2308.09635"}, {"metadata": {"arXiv": "2308.09643", "Date": "Fri, 18 Aug 2023 16:01:18 ", "Title": "biquality-learn: a Python library for Biquality Learning", "Authors": ["Pierre Nodet and Vincent Lemaire and Alexis Bondu and Antoine Cornu\\'ejols"], "Categories": "cs.LG"}, "abstract": "The democratization of Data Mining has been widely successful thanks in part to powerful and easy-to-use Machine Learning libraries. These libraries have been particularly tailored to tackle Supervised Learning. However, strong supervision signals are scarce in practice, and practitioners must resort to weak supervision. In addition to weaknesses of supervision, dataset shifts are another kind of phenomenon that occurs when deploying machine learning models in the real world. That is why Biquality Learning has been proposed as a machine learning framework to design algorithms capable of handling multiple weaknesses of supervision and dataset shifts without assumptions on their nature and level by relying on the availability of a small trusted dataset composed of cleanly labeled and representative samples. Thus we propose biquality-learn: a Python library for Biquality Learning with an intuitive and consistent API to learn machine learning models from biquality data, with well-proven algorithms, accessible and easy to use for everyone, and enabling researchers to experiment in a reproducible way on biquality data.", "url": "https://arxiv.org/abs/2308.09643"}, {"metadata": {"arXiv": "2308.09685", "Date": "Fri, 18 Aug 2023 17:13:45 ", "Title": "Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions", "Authors": ["Michael Joannou", "Pia Rotshtein", "Uta Noppeney"], "Categories": "cs.LG cs.CV cs.MM cs.SD eess.AS"}, "abstract": "We present Audiovisual Moments in Time (AVMIT), a large-scale dataset of audiovisual action events. In an extensive annotation task 11 participants labelled a subset of 3-second audiovisual videos from the Moments in Time dataset (MIT). For each trial, participants assessed whether the labelled audiovisual action event was present and whether it was the most prominent feature of the video. The dataset includes the annotation of 57,177 audiovisual videos, each independently evaluated by 3 of 11 trained participants. From this initial collection, we created a curated test set of 16 distinct action classes, with 60 videos each (960 videos). We also offer 2 sets of pre-computed audiovisual feature embeddings, using VGGish/YamNet for audio data and VGG16/EfficientNetB0 for visual data, thereby lowering the barrier to entry for audiovisual DNN research. We explored the advantages of AVMIT annotations and feature embeddings to improve performance on audiovisual event recognition. A series of 6 Recurrent Neural Networks (RNNs) were trained on either AVMIT-filtered audiovisual events or modality-agnostic events from MIT, and then tested on our audiovisual test set. In all RNNs, top 1 accuracy was increased by 2.71-5.94\\% by training exclusively on audiovisual events, even outweighing a three-fold increase in training data. We anticipate that the newly annotated AVMIT dataset will serve as a valuable resource for research and comparative experiments involving computational models and human participants, specifically when addressing research questions where audiovisual correspondence is of critical importance.", "url": "https://arxiv.org/abs/2308.09685"}, {"metadata": {"arXiv": "2308.08978", "Date": "Thu, 17 Aug 2023 13:33:15 ", "Title": "Quantifying the biomimicry gap in biohybrid systems", "Authors": ["Vaios Papaspyros", "Guy Theraulaz", "Cl\\'ement Sire", "Francesco Mondada"], "Categories": "cs.RO cs.LG q-bio.QM"}, "abstract": "Biohybrid systems in which robotic lures interact with animals have become compelling tools for probing and identifying the mechanisms underlying collective animal behavior. One key challenge lies in the transfer of social interaction models from simulations to reality, using robotics to validate the modeling hypotheses. This challenge arises in bridging what we term the \"biomimicry gap\", which is caused by imperfect robotic replicas, communication cues and physics constrains not incorporated in the simulations that may elicit unrealistic behavioral responses in animals. In this work, we used a biomimetic lure of a rummy-nose tetra fish (Hemigrammus rhodostomus) and a neural network (NN) model for generating biomimetic social interactions. Through experiments with a biohybrid pair comprising a fish and the robotic lure, a pair of real fish, and simulations of pairs of fish, we demonstrate that our biohybrid system generates high-fidelity social interactions mirroring those of genuine fish pairs. Our analyses highlight that: 1) the lure and NN maintain minimal deviation in real-world interactions compared to simulations and fish-only experiments, 2) our NN controls the robot efficiently in real-time, and 3) a comprehensive validation is crucial to bridge the biomimicry gap, ensuring realistic biohybrid systems.", "url": "https://arxiv.org/abs/2308.08978"}, {"metadata": {"arXiv": "2308.08792", "Date": "Thu, 17 Aug 2023 05:34:46 ", "Title": "Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks", "Authors": ["Junkai Qian and Yuning Jiang and Xin Liu and Qing Wang and Ting Wang and Yuanming Shi and Wei Chen"], "Categories": "eess.SY cs.LG cs.MA cs.SY"}, "abstract": "With the growing popularity of electric vehicles (EVs), maintaining power grid stability has become a significant challenge. To address this issue, EV charging control strategies have been developed to manage the switch between vehicle-to-grid (V2G) and grid-to-vehicle (G2V) modes for EVs. In this context, multi-agent deep reinforcement learning (MADRL) has proven its effectiveness in EV charging control. However, existing MADRL-based approaches fail to consider the natural power flow of EV charging/discharging in the distribution network and ignore driver privacy. To deal with these problems, this paper proposes a novel approach that combines multi-EV charging/discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A mathematical model is developed to describe the RDN load. The EV charging control problem is formulated as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. To effectively learn the optimal EV charging control strategy, a federated deep reinforcement learning algorithm named FedSAC is further proposed. Comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.", "url": "https://arxiv.org/abs/2308.08792"}, {"metadata": {"arXiv": "2308.08714", "Date": "Thu, 17 Aug 2023 00:35:11 ", "Title": "Probabilistic Results on the Architecture of Mathematical Reasoning Aligned by Cognitive Alternation", "Authors": ["Minzheng Li", "Xiangzhong Fang", "Haixin Yang"], "Categories": "cs.AI math.PR"}, "abstract": "We envision a machine capable of solving mathematical problems. Dividing the quantitative reasoning system into two parts: thought processes and cognitive processes, we provide probabilistic descriptions of the architecture.", "url": "https://arxiv.org/abs/2308.08714"}, {"metadata": {"arXiv": "2308.08728", "Date": "Thu, 17 Aug 2023 01:58:04 ", "Title": "LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM", "Authors": ["Zhe Zheng", "Ke-Yin Chen", "Xin-Yu Cao", "Xin-Zheng Lu", "Jia-Rui Lin"], "Categories": "cs.AI cs.CL"}, "abstract": "As a vital stage of automated rule checking (ARC), rule interpretation of regulatory texts requires considerable effort. However, interpreting regulatory clauses with implicit properties or complex computational logic is still challenging due to the lack of domain knowledge and limited expressibility of conventional logic representations. Thus, LLM-FuncMapper, an approach to identifying predefined functions needed to interpret various regulatory clauses based on the large language model (LLM), is proposed. First, by systematically analysis of building codes, a series of atomic functions are defined to capture shared computational logics of implicit properties and complex constraints, creating a database of common blocks for interpreting regulatory clauses. Then, a prompt template with the chain of thought is developed and further enhanced with a classification-based tuning strategy, to enable common LLMs for effective function identification. Finally, the proposed approach is validated with statistical analysis, experiments, and proof of concept. Statistical analysis reveals a long-tail distribution and high expressibility of the developed function database, with which almost 100% of computer-processible clauses can be interpreted and represented as computer-executable codes. Experiments show that LLM-FuncMapper achieve promising results in identifying relevant predefined functions for rule interpretation. Further proof of concept in automated rule interpretation also demonstrates the possibility of LLM-FuncMapper in interpreting complex regulatory clauses. To the best of our knowledge, this study is the first attempt to introduce LLM for understanding and interpreting complex regulatory clauses, which may shed light on further adoption of LLM in the construction domain.", "url": "https://arxiv.org/abs/2308.08728"}, {"metadata": {"arXiv": "2308.08828", "Date": "Thu, 17 Aug 2023 07:40:47 ", "Title": "Lifted Algorithms for Symmetric Weighted First-Order Model Sampling", "Authors": ["Yuanhong Wang", "Juhua Pu", "Yuyi Wang and Ond\\v{r}ej Ku\\v{z}elka"], "Categories": "cs.AI cs.LO", "Comments": ["47 pages", "6 figures. An expanded version of \"On exact sampling in the two-variable fragment of first-order logic\" in LICS23", "submitted to AIJ. arXiv admin note: substantial text overlap with arXiv:2302.02730"], "MSC-class": "68T27", "ACM-class": "I.2.4"}, "abstract": "Weighted model counting (WMC) is the task of computing the weighted sum of all satisfying assignments (i.e., models) of a propositional formula. Similarly, weighted model sampling (WMS) aims to randomly generate models with probability proportional to their respective weights. Both WMC and WMS are hard to solve exactly, falling under the \\#P-hard complexity class. However, it is known that the counting problem may sometimes be tractable, if the propositional formula can be compactly represented and expressed in first-order logic. In such cases, model counting problems can be solved in time polynomial in the domain size, and are known as \\textit{domain-liftable}. The following question then arises: Is it also the case for weighted model sampling? This paper addresses this question and answers it affirmatively. Specifically, we prove the \\textit{domain-liftability under sampling} for the two-variables fragment of first-order logic with counting quantifiers in this paper, by devising an efficient sampling algorithm for this fragment that runs in time polynomial in the domain size. We then further show that this result continues to hold even in the presence of cardinality constraints. To empirically verify our approach, we conduct experiments over various first-order formulas designed for the uniform generation of combinatorial structures and sampling in statistical-relational models. The results demonstrate that our algorithm outperforms a start-of-the-art WMS sampler by a substantial margin, confirming the theoretical results.", "url": "https://arxiv.org/abs/2308.08828"}, {"metadata": {"arXiv": "2308.09219", "Date": "Fri, 18 Aug 2023 00:39:06 ", "Title": "Learning in Cooperative Multiagent Systems Using Cognitive and Machine Models", "Authors": ["Thuy Ngoc Nguyen and Duy Nhat Phan and Cleotilde Gonzalez"], "Categories": "cs.AI cs.MA", "Comments": ["22 pages", "5 figures", "2 tables"]}, "abstract": "Developing effective Multi-Agent Systems (MAS) is critical for many applications requiring collaboration and coordination with humans. Despite the rapid advance of Multi-Agent Deep Reinforcement Learning (MADRL) in cooperative MAS, one major challenge is the simultaneous learning and interaction of independent agents in dynamic environments in the presence of stochastic rewards. State-of-the-art MADRL models struggle to perform well in Coordinated Multi-agent Object Transportation Problems (CMOTPs), wherein agents must coordinate with each other and learn from stochastic rewards. In contrast, humans often learn rapidly to adapt to nonstationary environments that require coordination among people. In this paper, motivated by the demonstrated ability of cognitive models based on Instance-Based Learning Theory (IBLT) to capture human decisions in many dynamic decision making tasks, we propose three variants of Multi-Agent IBL models (MAIBL). The idea of these MAIBL algorithms is to combine the cognitive mechanisms of IBLT and the techniques of MADRL models to deal with coordination MAS in stochastic environments from the perspective of independent learners. We demonstrate that the MAIBL models exhibit faster learning and achieve better coordination in a dynamic CMOTP task with various settings of stochastic rewards compared to current MADRL models. We discuss the benefits of integrating cognitive insights into MADRL models.", "url": "https://arxiv.org/abs/2308.09219"}, {"metadata": {"arXiv": "2308.09267", "Date": "Fri, 18 Aug 2023 03:12:59 ", "Title": "Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach", "Authors": ["Lang Cao"], "Categories": "cs.AI"}, "abstract": "Large Language Models (LLMs) have showcased impressive reasoning capabilities, particularly when guided by specifically designed prompts in complex reasoning tasks such as math word problems. These models typically solve tasks using a chain-of-thought approach, which not only bolsters their reasoning abilities but also provides valuable insights into their problem-solving process. However, there is still significant room for enhancing the reasoning abilities of LLMs. Some studies suggest that the integration of an LLM output verifier can boost reasoning accuracy without necessitating additional model training. In this paper, we follow these studies and introduce a novel graph-based method to further augment the reasoning capabilities of LLMs. We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths. Therefore, we propose the Reasoning Graph Verifier (RGV) to analyze and verify the solutions generated by LLMs. By evaluating these graphs, models can yield more accurate and reliable results.Our experimental results show that our graph-based verification method not only significantly enhances the reasoning abilities of LLMs but also outperforms existing verifier methods in terms of improving these models' reasoning performance.", "url": "https://arxiv.org/abs/2308.09267"}, {"metadata": {"arXiv": "2308.09289", "Date": "Fri, 18 Aug 2023 04:19:36 ", "Title": "Preference-conditioned Pixel-based AI Agent For Game Testing", "Authors": ["Sherif Abdelfattah", "Adrian Brown", "Pushi Zhang"], "Categories": "cs.AI cs.MM"}, "abstract": "The game industry is challenged to cope with increasing growth in demand and game complexity while maintaining acceptable quality standards for released games. Classic approaches solely depending on human efforts for quality assurance and game testing do not scale effectively in terms of time and cost. Game-testing AI agents that learn by interaction with the environment have the potential to mitigate these challenges with good scalability properties on time and costs. However, most recent work in this direction depends on game state information for the agent's state representation, which limits generalization across different game scenarios. Moreover, game test engineers usually prefer exploring a game in a specific style, such as exploring the golden path. However, current game testing AI agents do not provide an explicit way to satisfy such a preference. This paper addresses these limitations by proposing an agent design that mainly depends on pixel-based state observations while exploring the environment conditioned on a user's preference specified by demonstration trajectories. In addition, we propose an imitation learning method that couples self-supervised and supervised learning objectives to enhance the quality of imitation behaviors. Our agent significantly outperforms state-of-the-art pixel-based game testing agents over exploration coverage and test execution quality when evaluated on a complex open-world environment resembling many aspects of real AAA games.", "url": "https://arxiv.org/abs/2308.09289"}, {"metadata": {"arXiv": "2308.09474", "Date": "Fri, 18 Aug 2023 11:19:41 ", "Title": "AI Hilbert: From Data and Background Knowledge to Automated Scientific Discovery", "Authors": ["Ryan Cory-Wright", "Bachir El Khadir", "Cristina Cornelio", "Sanjeeb Dash", "Lior Horesh"], "Categories": "cs.AI cs.SC math.OC"}, "abstract": "The discovery of scientific formulae that parsimoniously explain natural phenomena and align with existing background theory is a key goal in science. Historically, scientists have derived natural laws by manipulating equations based on existing knowledge, forming new equations, and verifying them experimentally. In recent years, data-driven scientific discovery has emerged as a viable competitor in settings with large amounts of experimental data. Unfortunately, data-driven methods often fail to discover valid laws when data is noisy or scarce. Accordingly, recent works combine regression and reasoning to eliminate formulae inconsistent with background theory. However, the problem of searching over the space of formulae consistent with background theory to find one that fits the data best is not well solved. We propose a solution to this problem when all axioms and scientific laws are expressible via polynomial equalities and inequalities and argue that our approach is widely applicable. We further model notions of minimal complexity using binary variables and logical constraints, solve polynomial optimization problems via mixed-integer linear or semidefinite optimization, and automatically prove the validity of our scientific discoveries via Positivestellensatz certificates. Remarkably, the optimization techniques leveraged in this paper allow our approach to run in polynomial time with fully correct background theory, or non-deterministic polynomial (NP) time with partially correct background theory. We experimentally demonstrate that some famous scientific laws, including Kepler's Third Law of Planetary Motion, the Hagen-Poiseuille Equation, and the Radiated Gravitational Wave Power equation, can be automatically derived from sets of partially correct background axioms.", "url": "https://arxiv.org/abs/2308.09474"}, {"metadata": {"arXiv": "2308.09488", "Date": "Fri, 18 Aug 2023 11:54:38 ", "Title": "Modelling Electricity Consumption in Irish Dairy Farms Using Agent-Based Modelling", "Authors": ["Hossein Khaleghy", "Abdul Wahid", "Eoghan Clifford", "Karl Mason"], "Categories": "cs.AI cs.MA", "Comments": ["This paper has been accepted at the 2023 Artificial Intelligence for Sustainability (AI4S) Workshop", "at 26th European Conference on Artificial Intelligence ECAI 2023"]}, "abstract": "Dairy farming can be an energy intensive form of farming. Understanding the factors affecting electricity consumption on dairy farms is crucial for farm owners and energy providers. In order to accurately estimate electricity demands in dairy farms, it is necessary to develop a model. In this research paper, an agent-based model is proposed to model the electricity consumption of Irish dairy farms. The model takes into account various factors that affect the energy consumption of dairy farms, including herd size, number of milking machines, and time of year. The outputs are validated using existing state-of-the-art dairy farm modelling frameworks. The proposed agent-based model is fully explainable, which is an advantage over other Artificial Intelligence techniques, e.g. deep learning.", "url": "https://arxiv.org/abs/2308.09488"}, {"metadata": {"arXiv": "2308.09502", "Date": "Fri, 18 Aug 2023 12:26:10 ", "Title": "Semantic relatedness in DBpedia: A comparative and experimental assessment", "Authors": ["Anna Formica and Francesco Taglino"], "Categories": "cs.AI cs.CL cs.LO", "Comments": ["37 pages", "16 figures"], "Journal-ref": "Information Sciences (ISSN 0020-0255), Volume 621, 2023, 474-505", "DOI": "10.1016/j.ins.2022.11.025"}, "abstract": "Evaluating semantic relatedness of Web resources is still an open challenge. This paper focuses on knowledge-based methods, which represent an alternative to corpus-based approaches, and rely in general on the availability of knowledge graphs. In particular, we have selected 10 methods from the existing literature, that have been organized according to it adjacent resources, triple patterns, and triple weights-based methods. They have been implemented and evaluated by using DBpedia as reference RDF knowledge graph. Since DBpedia is continuously evolving, the experimental results provided by these methods in the literature are not comparable. For this reason, in this work, such methods have been experimented by running them all at once on the same DBpedia release and against 14 well-known golden datasets. On the basis of the correlation values with human judgment obtained according to the experimental results, weighting the RDF triples in combination with evaluating all the directed paths linking the compared resources is the best strategy in order to compute semantic relatedness in DBpedia.", "url": "https://arxiv.org/abs/2308.09502"}, {"metadata": {"arXiv": "2308.09595", "Date": "Fri, 18 Aug 2023 14:45:22 ", "Title": "Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents", "Authors": ["Arrasy Rahman", "Jiaxun Cui", "Peter Stone"], "Categories": "cs.AI"}, "abstract": "Robustly cooperating with unseen agents and human partners presents significant challenges due to the diverse cooperative conventions these partners may adopt. Existing Ad Hoc Teamwork (AHT) methods address this challenge by training an agent with a population of diverse teammate policies obtained through maximizing specific diversity metrics. However, these heuristic diversity metrics do not always maximize the agent's robustness in all cooperative problems. In this work, we first propose that maximizing an AHT agent's robustness requires it to emulate policies in the minimum coverage set (MCS), the set of best-response policies to any partner policies in the environment. We then introduce the L-BRDiv algorithm that generates a set of teammate policies that, when used for AHT training, encourage agents to emulate policies from the MCS. L-BRDiv works by solving a constrained optimization problem to jointly train teammate policies for AHT training and approximating AHT agent policies that are members of the MCS. We empirically demonstrate that L-BRDiv produces more robust AHT agents than state-of-the-art methods in a broader range of two-player cooperative problems without the need for extensive hyperparameter tuning for its objectives. Our study shows that L-BRDiv outperforms the baseline methods by prioritizing discovering distinct members of the MCS instead of repeatedly finding redundant policies.", "url": "https://arxiv.org/abs/2308.09595"}, {"metadata": {"arXiv": "2308.08696", "Date": "Wed, 16 Aug 2023 22:54:49 ", "Title": "Improving Anomaly Segmentation with Multi-Granularity Cross-Domain Alignment", "Authors": ["Ji Zhang", "Xiao Wu", "Zhi-Qi Cheng", "Qi He", "Wei Li"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["Accepted to ACM Multimedia 2023"]}, "abstract": "Anomaly segmentation plays a crucial role in identifying anomalous objects within images, which facilitates the detection of road anomalies for autonomous driving. Although existing methods have shown impressive results in anomaly segmentation using synthetic training data, the domain discrepancies between synthetic training data and real test data are often neglected. To address this issue, the Multi-Granularity Cross-Domain Alignment (MGCDA) framework is proposed for anomaly segmentation in complex driving environments. It uniquely combines a new Multi-source Domain Adversarial Training (MDAT) module and a novel Cross-domain Anomaly-aware Contrastive Learning (CACL) method to boost the generality of the model, seamlessly integrating multi-domain data at both scene and sample levels. Multi-source domain adversarial loss and a dynamic label smoothing strategy are integrated into the MDAT module to facilitate the acquisition of domain-invariant features at the scene level, through adversarial training across multiple stages. CACL aligns sample-level representations with contrastive loss on cross-domain data, which utilizes an anomaly-aware sampling strategy to efficiently sample hard samples and anchors. The proposed framework has decent properties of parameter-free during the inference stage and is compatible with other anomaly segmentation networks. Experimental conducted on Fishyscapes and RoadAnomaly datasets demonstrate that the proposed framework achieves state-of-the-art performance.", "url": "https://arxiv.org/abs/2308.08696"}, {"metadata": {"arXiv": "2308.08717", "Date": "Thu, 17 Aug 2023 00:49:44 ", "Title": "EdgeMA: Model Adaptation System for Real-Time Video Analytics on Edge Devices", "Authors": ["Liang Wang", "Nan Zhang", "Xiaoyang Qu", "Jianzong Wang", "Jiguang Wan", "Guokuan Li", "Kaiyu Hu", "Guilin Jiang", "Jing Xiao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by 30th International Conference on Neural Information Processing (ICONIP 2023)"]}, "abstract": "Real-time video analytics on edge devices for changing scenes remains a difficult task. As edge devices are usually resource-constrained, edge deep neural networks (DNNs) have fewer weights and shallower architectures than general DNNs. As a result, they only perform well in limited scenarios and are sensitive to data drift. In this paper, we introduce EdgeMA, a practical and efficient video analytics system designed to adapt models to shifts in real-world video streams over time, addressing the data drift problem. EdgeMA extracts the gray level co-occurrence matrix based statistical texture feature and uses the Random Forest classifier to detect the domain shift. Moreover, we have incorporated a method of model adaptation based on importance weighting, specifically designed to update models to cope with the label distribution shift. Through rigorous evaluation of EdgeMA on a real-world dataset, our results illustrate that EdgeMA significantly improves inference accuracy.", "url": "https://arxiv.org/abs/2308.08717"}, {"metadata": {"arXiv": "2308.08746", "Date": "Thu, 17 Aug 2023 02:51:01 ", "Title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation", "Authors": ["Wenxi Yue", "Jing Zhang", "Kun Hu", "Yong Xia", "Jiebo Luo", "Zhiyong Wang"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["Technical Report. The source code will be released at https://github.com/wenxi-yue/SurgicalSAM"]}, "abstract": "The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to poor generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM's pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, which directly generates prompt embeddings from class prototypes and eliminates the use of explicit prompts for improved robustness and a simpler pipeline. In addition, to address the low inter-class variance among surgical instrument categories, we propose contrastive prototype learning, further enhancing the discrimination of the class prototypes for more accurate class prompting. The results of extensive experiments on both EndoVis2018 and EndoVis2017 datasets demonstrate that SurgicalSAM achieves state-of-the-art performance while only requiring a small number of tunable parameters. The source code will be released at https://github.com/wenxi-yue/SurgicalSAM.", "url": "https://arxiv.org/abs/2308.08746"}, {"metadata": {"arXiv": "2308.08857", "Date": "Thu, 17 Aug 2023 08:31:11 ", "Title": "D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field", "Authors": ["Xueting Yang", "Yihao Luo", "Yuliang Xiu", "Wei Wang", "Hao Xu", "Zhaoxin Fan"], "Categories": "cs.CV cs.AI"}, "abstract": "Realistic virtual humans play a crucial role in numerous industries, such as metaverse, intelligent healthcare, and self-driving simulation. But creating them on a large scale with high levels of realism remains a challenge. The utilization of deep implicit function sparks a new era of image-based 3D clothed human reconstruction, enabling pixel-aligned shape recovery with fine details. Subsequently, the vast majority of works locate the surface by regressing the deterministic implicit value for each point. However, should all points be treated equally regardless of their proximity to the surface? In this paper, we propose replacing the implicit value with an adaptive uncertainty distribution, to differentiate between points based on their distance to the surface. This simple ``value to distribution'' transition yields significant improvements on nearly all the baselines. Furthermore, qualitative results demonstrate that the models trained using our uncertainty distribution loss, can capture more intricate wrinkles, and realistic limbs. Code and models are available for research purposes at https://github.com/psyai-net/D-IF_release.", "url": "https://arxiv.org/abs/2308.08857"}, {"metadata": {"arXiv": "2308.08925", "Date": "Thu, 17 Aug 2023 11:30:49 ", "Title": "A White-Box False Positive Adversarial Attack Method on Contrastive Loss-Based Offline Handwritten Signature Verification Models", "Authors": ["Zhongliang Guo", "Yifei Qian", "Ognjen Arandjelovi\\'c", "Lei Fang"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "3 figures"]}, "abstract": "In this paper, we tackle the challenge of white-box false positive adversarial attacks on contrastive loss-based offline handwritten signature verification models. We propose a novel attack method that treats the attack as a style transfer between closely related but distinct writing styles. To guide the generation of deceptive images, we introduce two new loss functions that enhance the attack success rate by perturbing the Euclidean distance between the embedding vectors of the original and synthesized samples, while ensuring minimal perturbations by reducing the difference between the generated image and the original image. Our method demonstrates state-of-the-art performance in white-box attacks on contrastive loss-based offline handwritten signature verification models, as evidenced by our experiments. The key contributions of this paper include a novel false positive attack method, two new loss functions, effective style transfer in handwriting styles, and superior performance in white-box false positive attacks compared to other white-box attack methods.", "url": "https://arxiv.org/abs/2308.08925"}, {"metadata": {"arXiv": "2308.09036", "Date": "Thu, 17 Aug 2023 15:17:49 ", "Title": "Synthesizing Physically Plausible Human Motions in 3D Scenes", "Authors": ["Liang Pan", "Jingbo Wang", "Buzhen Huang", "Junyu Zhang", "Haofan Wang", "Xu Tang", "Yangang Wang"], "Categories": "cs.CV cs.AI cs.GR"}, "abstract": "Synthesizing physically plausible human motions in 3D scenes is a challenging problem. Kinematics-based methods cannot avoid inherent artifacts (e.g., penetration and foot skating) due to the lack of physical constraints. Meanwhile, existing physics-based methods cannot generalize to multi-object scenarios since the policy trained with reinforcement learning has limited modeling capacity. In this work, we present a framework that enables physically simulated characters to perform long-term interaction tasks in diverse, cluttered, and unseen scenes. The key idea is to decompose human-scene interactions into two fundamental processes, Interacting and Navigating, which motivates us to construct two reusable Controller, i.e., InterCon and NavCon. Specifically, InterCon contains two complementary policies that enable characters to enter and leave the interacting state (e.g., sitting on a chair and getting up). To generate interaction with objects at different places, we further design NavCon, a trajectory following policy, to keep characters' locomotion in the free space of 3D scenes. Benefiting from the divide and conquer strategy, we can train the policies in simple environments and generalize to complex multi-object scenes. Experimental results demonstrate that our framework can synthesize physically plausible long-term human motions in complex 3D scenes. Code will be publicly released at https://github.com/liangpan99/InterScene.", "url": "https://arxiv.org/abs/2308.09036"}, {"metadata": {"arXiv": "2308.09096", "Date": "Thu, 17 Aug 2023 16:48:41 ", "Title": "Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification", "Authors": ["G\\\"urkan Soykan", "Deniz Yuret", "Tevfik Metin Sezgin"], "Categories": "cs.CV cs.AI cs.IR", "Comments": ["18 pages", "9 Figures"]}, "abstract": "Character re-identification, recognizing characters consistently across different panels in comics, presents significant challenges due to limited annotated data and complex variations in character appearances. To tackle this issue, we introduce a robust semi-supervised framework that combines metric learning with a novel 'Identity-Aware' self-supervision method by contrastive learning of face and body pairs of characters. Our approach involves processing both facial and bodily features within a unified network architecture, facilitating the extraction of identity-aligned character embeddings that capture individual identities while preserving the effectiveness of face and body features. This integrated character representation enhances feature extraction and improves character re-identification compared to re-identification by face or body independently, offering a parameter-efficient solution. By extensively validating our method using in-series and inter-series evaluation metrics, we demonstrate its effectiveness in consistently re-identifying comic characters. Compared to existing methods, our approach not only addresses the challenge of character re-identification but also serves as a foundation for downstream tasks since it can produce character embeddings without restrictions of face and body availability, enriching the comprehension of comic books. In our experiments, we leverage two newly curated datasets: the 'Comic Character Instances Dataset', comprising over a million character instances and the 'Comic Sequence Identity Dataset', containing annotations of identities within more than 3000 sets of four consecutive comic panels that we collected.", "url": "https://arxiv.org/abs/2308.09096"}, {"metadata": {"arXiv": "2308.09126", "Date": "Thu, 17 Aug 2023 17:59:59 ", "Title": "EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding", "Authors": ["Karttikeya Mangalam", "Raiymbek Akshulakov", "Jitendra Malik"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["https://egoschema.github.io/"]}, "abstract": "We introduce EgoSchema, a very long-form video question-answering dataset, and benchmark to evaluate long video understanding capabilities of modern vision and language systems. Derived from Ego4D, EgoSchema consists of over 5000 human curated multiple choice question answer pairs, spanning over 250 hours of real video data, covering a very broad range of natural human activity and behavior. For each question, EgoSchema requires the correct answer to be selected between five given options based on a three-minute-long video clip. While some prior works have proposed video datasets with long clip lengths, we posit that merely the length of the video clip does not truly capture the temporal difficulty of the video task that is being considered. To remedy this, we introduce temporal certificate sets, a general notion for capturing the intrinsic temporal understanding length associated with a broad range of video understanding tasks & datasets. Based on this metric, we find EgoSchema to have intrinsic temporal lengths over 5.7x longer than the second closest dataset and 10x to 100x longer than any other video understanding dataset. Further, our evaluation of several current state-of-the-art video and language models shows them to be severely lacking in long-term video understanding capabilities. Even models with several billions of parameters achieve QA accuracy less than 33% (random is 20%) on the EgoSchema multi-choice question answering task, while humans achieve about 76% accuracy. We posit that \\name{}{}, with its long intrinsic temporal structures and diverse complexity, would serve as a valuable evaluation probe for developing effective long-term video understanding systems in the future. Data and Zero-shot model evaluation code are open-sourced for both public and commercial use under the Ego4D license at http://egoschema.github.io", "url": "https://arxiv.org/abs/2308.09126"}, {"metadata": {"arXiv": "2308.09180", "Date": "Thu, 17 Aug 2023 20:40:30 ", "Title": "How Does Pruning Impact Long-Tailed Multi-Label Medical Image Classifiers?", "Authors": ["Gregory Holste", "Ziyu Jiang", "Ajay Jaiswal", "Maria Hanna", "Shlomo Minkowitz", "Alan C. Legasto", "Joanna G. Escalon", "Sharon Steinberger", "Mark Bittman", "Thomas C. Shen", "Ying Ding", "Ronald M. Summers", "George Shih", "Yifan Peng", "and Zhangyang Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Early accepted to MICCAI 2023"]}, "abstract": "Pruning has emerged as a powerful technique for compressing deep neural networks, reducing memory usage and inference time without significantly affecting overall performance. However, the nuanced ways in which pruning impacts model behavior are not well understood, particularly for long-tailed, multi-label datasets commonly found in clinical settings. This knowledge gap could have dangerous implications when deploying a pruned model for diagnosis, where unexpected model behavior could impact patient well-being. To fill this gap, we perform the first analysis of pruning's effect on neural networks trained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR datasets, we examine which diseases are most affected by pruning and characterize class \"forgettability\" based on disease frequency and co-occurrence behavior. Further, we identify individual CXRs where uncompressed and heavily pruned models disagree, known as pruning-identified exemplars (PIEs), and conduct a human reader study to evaluate their unifying qualities. We find that radiologists perceive PIEs as having more label noise, lower image quality, and higher diagnosis difficulty. This work represents a first step toward understanding the impact of pruning on model behavior in deep long-tailed, multi-label medical image classification. All code, model weights, and data access instructions can be found at https://github.com/VITA-Group/PruneCXR.", "url": "https://arxiv.org/abs/2308.09180"}, {"metadata": {"arXiv": "2308.09209", "Date": "Thu, 17 Aug 2023 23:28:39 ", "Title": "GPU Accelerated Color Correction and Frame Warping for Real-time Video Stitching", "Authors": ["Lu Yang", "Zhenglun Kong", "Ting Li", "Xinyi Bai", "Zhiye Lin", "Hong Cheng"], "Categories": "cs.CV cs.AI cs.GR", "ACM-class": "I.4.5; I.4.0; I.4.1"}, "abstract": "Traditional image stitching focuses on a single panorama frame without considering the spatial-temporal consistency in videos. The straightforward image stitching approach will cause temporal flicking and color inconstancy when it is applied to the video stitching task. Besides, inaccurate camera parameters will cause artifacts in the image warping. In this paper, we propose a real-time system to stitch multiple video sequences into a panoramic video, which is based on GPU accelerated color correction and frame warping without accurate camera parameters. We extend the traditional 2D-Matrix (2D-M) color correction approach and a present spatio-temporal 3D-Matrix (3D-M) color correction method for the overlap local regions with online color balancing using a piecewise function on global frames. Furthermore, we use pairwise homography matrices given by coarse camera calibration for global warping followed by accurate local warping based on the optical flow. Experimental results show that our system can generate highquality panorama videos in real time.", "url": "https://arxiv.org/abs/2308.09209"}, {"metadata": {"arXiv": "2308.09238", "Date": "Fri, 18 Aug 2023 01:53:47 ", "Title": "Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation", "Authors": ["Carl McMillan", "Junhong Zhao", "Bing Xue", "Ross Vennell", "Mengjie Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["7 pages", "5 figures", "submitted to ICVNZ 2023 conference https://ivcnz2023.massey.ac.nz/"]}, "abstract": "The aquaculture sector in New Zealand is experiencing rapid expansion, with a particular emphasis on mussel exports. As the demands of mussel farming operations continue to evolve, the integration of artificial intelligence and computer vision techniques, such as intelligent object detection, is emerging as an effective approach to enhance operational efficiency. This study delves into advancing buoy detection by leveraging deep learning methodologies for intelligent mussel farm monitoring and management. The primary objective centers on improving accuracy and robustness in detecting buoys across a spectrum of real-world scenarios. A diverse dataset sourced from mussel farms is captured and labeled for training, encompassing imagery taken from cameras mounted on both floating platforms and traversing vessels, capturing various lighting and weather conditions. To establish an effective deep learning model for buoy detection with a limited number of labeled data, we employ transfer learning techniques. This involves adapting a pre-trained object detection model to create a specialized deep learning buoy detection model. We explore different pre-trained models, including YOLO and its variants, alongside data diversity to investigate their effects on model performance. Our investigation demonstrates a significant enhancement in buoy detection performance through deep learning, accompanied by improved generalization across diverse weather conditions, highlighting the practical effectiveness of our approach.", "url": "https://arxiv.org/abs/2308.09238"}, {"metadata": {"arXiv": "2308.09245", "Date": "Fri, 18 Aug 2023 02:12:54 ", "Title": "Masked Spatio-Temporal Structure Prediction for Self-supervised Learning on Point Cloud Videos", "Authors": ["Zhiqiang Shen and Xiaoxiao Sheng and Hehe Fan and Longguang Wang and Yulan Guo and Qiong Liu and Hao Wen and Xi Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Recently, the community has made tremendous progress in developing effective methods for point cloud video understanding that learn from massive amounts of labeled data. However, annotating point cloud videos is usually notoriously expensive. Moreover, training via one or only a few traditional tasks (e.g., classification) may be insufficient to learn subtle details of the spatio-temporal structure existing in point cloud videos. In this paper, we propose a Masked Spatio-Temporal Structure Prediction (MaST-Pre) method to capture the structure of point cloud videos without human annotations. MaST-Pre is based on spatio-temporal point-tube masking and consists of two self-supervised learning tasks. First, by reconstructing masked point tubes, our method is able to capture the appearance information of point cloud videos. Second, to learn motion, we propose a temporal cardinality difference prediction task that estimates the change in the number of points within a point tube. In this way, MaST-Pre is forced to model the spatial and temporal structure in point cloud videos. Extensive experiments on MSRAction-3D, NTU-RGBD, NvGesture, and SHREC'17 demonstrate the effectiveness of the proposed method.", "url": "https://arxiv.org/abs/2308.09245"}, {"metadata": {"arXiv": "2308.09247", "Date": "Fri, 18 Aug 2023 02:17:47 ", "Title": "Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos", "Authors": ["Xiaoxiao Sheng and Zhiqiang Shen and Gang Xiao and Longguang Wang and Yulan Guo and Hehe Fan"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "We propose a unified point cloud video self-supervised learning framework for object-centric and scene-centric data. Previous methods commonly conduct representation learning at the clip or frame level and cannot well capture fine-grained semantics. Instead of contrasting the representations of clips or frames, in this paper, we propose a unified self-supervised framework by conducting contrastive learning at the point level. Moreover, we introduce a new pretext task by achieving semantic alignment of superpoints, which further facilitates the representations to capture semantic cues at multiple scales. In addition, due to the high redundancy in the temporal dimension of dynamic point clouds, directly conducting contrastive learning at the point level usually leads to massive undesired negatives and insufficient modeling of positive representations. To remedy this, we propose a selection strategy to retain proper negatives and make use of high-similarity samples from other instances as positive supplements. Extensive experiments show that our method outperforms supervised counterparts on a wide range of downstream tasks and demonstrates the superior transferability of the learned representations.", "url": "https://arxiv.org/abs/2308.09247"}, {"metadata": {"arXiv": "2308.09300", "Date": "Fri, 18 Aug 2023 04:49:38 ", "Title": "V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models", "Authors": ["Heng Wang", "Jianbo Ma", "Santiago Pascual", "Richard Cartwright", "Weidong Cai"], "Categories": "cs.CV cs.AI cs.MM cs.SD eess.AS", "Comments": ["13 pages", "10 figures. Code", "demo", "and samples: https://v2a-mapper.github.io/"]}, "abstract": "Building artificial intelligence (AI) systems on top of a set of foundation models (FMs) is becoming a new paradigm in AI research. Their representative and generative abilities learnt from vast amounts of data can be easily adapted and transferred to a wide range of downstream tasks without extra training from scratch. However, leveraging FMs in cross-modal generation remains under-researched when audio modality is involved. On the other hand, automatically generating semantically-relevant sound from visual input is an important problem in cross-modal generation studies. To solve this vision-to-audio (V2A) generation problem, existing methods tend to design and build complex systems from scratch using modestly sized datasets. In this paper, we propose a lightweight solution to this problem by leveraging foundation models, specifically CLIP, CLAP, and AudioLDM. We first investigate the domain gap between the latent space of the visual CLIP and the auditory CLAP models. Then we propose a simple yet effective mapper mechanism (V2A-Mapper) to bridge the domain gap by translating the visual input between CLIP and CLAP spaces. Conditioned on the translated CLAP embedding, pretrained audio generative FM AudioLDM is adopted to produce high-fidelity and visually-aligned sound. Compared to previous approaches, our method only requires a quick training of the V2A-Mapper. We further analyze and conduct extensive experiments on the choice of the V2A-Mapper and show that a generative mapper is better at fidelity and variability (FD) while a regression mapper is slightly better at relevance (CS). Both objective and subjective evaluation on two V2A datasets demonstrate the superiority of our proposed method compared to current state-of-the-art approaches - trained with 86% fewer parameters but achieving 53% and 19% improvement in FD and CS, respectively.", "url": "https://arxiv.org/abs/2308.09300"}, {"metadata": {"arXiv": "2308.09322", "Date": "Fri, 18 Aug 2023 05:46:20 ", "Title": "Audio-Visual Glance Network for Efficient Video Recognition", "Authors": ["Muhammad Adi Nugroho", "Sangmin Woo", "Sumin Lee", "Changick Kim"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["ICCV 2023"]}, "abstract": "Deep learning has made significant strides in video understanding tasks, but the computation required to classify lengthy and massive videos using clip-level video classifiers remains impractical and prohibitively expensive. To address this issue, we propose Audio-Visual Glance Network (AVGN), which leverages the commonly available audio and visual modalities to efficiently process the spatio-temporally important parts of a video. AVGN firstly divides the video into snippets of image-audio clip pair and employs lightweight unimodal encoders to extract global visual features and audio features. To identify the important temporal segments, we use an Audio-Visual Temporal Saliency Transformer (AV-TeST) that estimates the saliency scores of each frame. To further increase efficiency in the spatial dimension, AVGN processes only the important patches instead of the whole images. We use an Audio-Enhanced Spatial Patch Attention (AESPA) module to produce a set of enhanced coarse visual features, which are fed to a policy network that produces the coordinates of the important patches. This approach enables us to focus only on the most important spatio-temporally parts of the video, leading to more efficient video recognition. Moreover, we incorporate various training techniques and multi-modal feature fusion to enhance the robustness and effectiveness of our AVGN. By combining these strategies, our AVGN sets new state-of-the-art performance in multiple video recognition benchmarks while achieving faster processing speed.", "url": "https://arxiv.org/abs/2308.09322"}, {"metadata": {"arXiv": "2308.09455", "Date": "Fri, 18 Aug 2023 10:40:25 ", "Title": "Artificial-Spiking Hierarchical Networks for Vision-Language Representation Learning", "Authors": ["Yeming Chen", "Siyu Zhang", "Yaoru Sun", "Weijian Liang", "Haoran Wang"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "With the success of self-supervised learning, multimodal foundation models have rapidly adapted a wide range of downstream tasks driven by vision and language (VL) pretraining. State-of-the-art methods achieve impressive performance by pre-training on large-scale datasets. However, bridging the semantic gap between the two modalities remains a nonnegligible challenge for VL tasks. In this work, we propose an efficient computation framework for multimodal alignment by introducing a novel visual semantic module to further improve the performance of the VL tasks. Specifically, we propose a flexible model, namely Artificial-Spiking Hierarchical Networks (ASH-Nets), which combines the complementary advantages of Artificial neural networks (ANNs) and Spiking neural networks (SNNs) to enrich visual semantic representations. In particular, a visual concrete encoder and a semantic abstract encoder are constructed to learn continuous and discrete latent variables to enhance the flexibility of semantic encoding. Considering the spatio-temporal properties of SNNs modeling, we introduce a contrastive learning method to optimize the inputs of similar samples. This can improve the computational efficiency of the hierarchical network, while the augmentation of hard samples is beneficial to the learning of visual representations. Furthermore, the Spiking to Text Uni-Alignment Learning (STUA) pre-training method is proposed, which only relies on text features to enhance the encoding ability of abstract semantics. We validate the performance on multiple well-established downstream VL tasks. Experiments show that the proposed ASH-Nets achieve competitive results.", "url": "https://arxiv.org/abs/2308.09455"}, {"metadata": {"arXiv": "2308.09472", "Date": "Fri, 18 Aug 2023 11:15:31 ", "Title": "Vision Relation Transformer for Unbiased Scene Graph Generation", "Authors": ["Gopika Sudhakaran", "Devendra Singh Dhami", "Kristian Kersting", "Stefan Roth"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted for publication in ICCV 2023"]}, "abstract": "Recent years have seen a growing interest in Scene Graph Generation (SGG), a comprehensive visual scene understanding task that aims to predict entity relationships using a relation encoder-decoder pipeline stacked on top of an object encoder-decoder backbone. Unfortunately, current SGG methods suffer from an information loss regarding the entities local-level cues during the relation encoding process. To mitigate this, we introduce the Vision rElation TransfOrmer (VETO), consisting of a novel local-level entity relation encoder. We further observe that many existing SGG methods claim to be unbiased, but are still biased towards either head or tail classes. To overcome this bias, we introduce a Mutually Exclusive ExperT (MEET) learning strategy that captures important relation features without bias towards head or tail classes. Experimental results on the VG and GQA datasets demonstrate that VETO + MEET boosts the predictive performance by up to 47 percentage over the state of the art while being 10 times smaller.", "url": "https://arxiv.org/abs/2308.09472"}, {"metadata": {"arXiv": "2308.09540", "Date": "Fri, 18 Aug 2023 13:17:07 ", "Title": "Meta-ZSDETR: Zero-shot DETR with Meta-learning", "Authors": ["Lu Zhang", "Chenbo Zhang", "Jiajia Zhao", "Jihong Guan", "Shuigeng Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in ICCV 2023"]}, "abstract": "Zero-shot object detection aims to localize and recognize objects of unseen classes. Most of existing works face two problems: the low recall of RPN in unseen classes and the confusion of unseen classes with background. In this paper, we present the first method that combines DETR and meta-learning to perform zero-shot object detection, named Meta-ZSDETR, where model training is formalized as an individual episode based meta-learning task. Different from Faster R-CNN based methods that firstly generate class-agnostic proposals, and then classify them with visual-semantic alignment module, Meta-ZSDETR directly predict class-specific boxes with class-specific queries and further filter them with the predicted accuracy from classification head. The model is optimized with meta-contrastive learning, which contains a regression head to generate the coordinates of class-specific boxes, a classification head to predict the accuracy of generated boxes, and a contrastive head that utilizes the proposed contrastive-reconstruction loss to further separate different classes in visual space. We conduct extensive experiments on two benchmark datasets MS COCO and PASCAL VOC. Experimental results show that our method outperforms the existing ZSD methods by a large margin.", "url": "https://arxiv.org/abs/2308.09540"}, {"metadata": {"arXiv": "2308.09678", "Date": "Fri, 18 Aug 2023 16:57:25 ", "Title": "PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Robust 3D Human Pose Estimation", "Authors": ["Hanbing Liu", "Jun-Yan He", "Zhi-Qi Cheng", "Wangmeng Xiang", "Qize Yang", "Wenhao Chai", "Gaoang Wang", "Xu Bao", "Bin Luo", "Yifeng Geng", "Xuansong Xie"], "Categories": "cs.CV cs.AI cs.MM cs.RO", "Comments": ["Accepted to ACM Multimedia 2023; 10 pages", "4 figures", "8 tables; the code is at https://github.com/hbing-l/PoSynDA"]}, "abstract": "The current 3D human pose estimators face challenges in adapting to new datasets due to the scarcity of 2D-3D pose pairs in target domain training sets. We present the \\textit{Multi-Hypothesis \\textbf{P}ose \\textbf{Syn}thesis \\textbf{D}omain \\textbf{A}daptation} (\\textbf{PoSynDA}) framework to overcome this issue without extensive target domain annotation. Utilizing a diffusion-centric structure, PoSynDA simulates the 3D pose distribution in the target domain, filling the data diversity gap. By incorporating a multi-hypothesis network, it creates diverse pose hypotheses and aligns them with the target domain. Target-specific source augmentation obtains the target domain distribution data from the source domain by decoupling the scale and position parameters. The teacher-student paradigm and low-rank adaptation further refine the process. PoSynDA demonstrates competitive performance on benchmarks, such as Human3.6M, MPI-INF-3DHP, and 3DPW, even comparable with the target-trained MixSTE model~\\cite{zhang2022mixste}. This work paves the way for the practical application of 3D human pose estimation. The code is available at https://github.com/hbing-l/PoSynDA.", "url": "https://arxiv.org/abs/2308.09678"}, {"metadata": {"arXiv": "2308.09710", "Date": "Fri, 18 Aug 2023 17:58:44 ", "Title": "SimDA: Simple Diffusion Adapter for Efficient Video Generation", "Authors": ["Zhen Xing", "Qi Dai", "Han Hu", "Zuxuan Wu", "Yu-Gang Jiang"], "Categories": "cs.CV cs.AI"}, "abstract": "The recent wave of AI-generated content has witnessed the great development and success of Text-to-Image (T2I) technologies. By contrast, Text-to-Video (T2V) still falls short of expectations though attracting increasing interests. Existing works either train from scratch or adapt large T2I model to videos, both of which are computation and resource expensive. In this work, we propose a Simple Diffusion Adapter (SimDA) that fine-tunes only 24M out of 1.1B parameters of a strong T2I model, adapting it to video generation in a parameter-efficient way. In particular, we turn the T2I model for T2V by designing light-weight spatial and temporal adapters for transfer learning. Besides, we change the original spatial attention to the proposed Latent-Shift Attention (LSA) for temporal consistency. With similar model architecture, we further train a video super-resolution model to generate high-definition (1024x1024) videos. In addition to T2V generation in the wild, SimDA could also be utilized in one-shot video editing with only 2 minutes tuning. Doing so, our method could minimize the training effort with extremely few tunable parameters for model adaptation.", "url": "https://arxiv.org/abs/2308.09710"}, {"metadata": {"arXiv": "2308.09716", "Date": "Fri, 18 Aug 2023 17:59:40 ", "Title": "Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization", "Authors": ["Soumik Mukhopadhyay", "Saksham Suri", "Ravi Teja Gadde", "Abhinav Shrivastava"], "Categories": "cs.CV cs.AI", "Comments": ["Website: see https://soumik-kanad.github.io/diff2lip . Submission under review"]}, "abstract": "The task of lip synchronization (lip-sync) seeks to match the lips of human faces with different audio. It has various applications in the film industry as well as for creating virtual avatars and for video conferencing. This is a challenging problem as one needs to simultaneously introduce detailed, realistic lip movements while preserving the identity, pose, emotions, and image quality. Many of the previous methods trying to solve this problem suffer from image quality degradation due to a lack of complete contextual information. In this paper, we present Diff2Lip, an audio-conditioned diffusion-based model which is able to do lip synchronization in-the-wild while preserving these qualities. We train our model on Voxceleb2, a video dataset containing in-the-wild talking face videos. Extensive studies show that our method outperforms popular methods like Wav2Lip and PC-AVS in Fr\\'echet inception distance (FID) metric and Mean Opinion Scores (MOS) of the users. We show results on both reconstruction (same audio-video inputs) as well as cross (different audio-video inputs) settings on Voxceleb2 and LRW datasets. Video results and code can be accessed from our project page ( https://soumik-kanad.github.io/diff2lip ).", "url": "https://arxiv.org/abs/2308.09716"}, {"metadata": {"arXiv": "2308.09041", "Date": "Thu, 17 Aug 2023 15:22:06 ", "Title": "A Mathematical Characterization of Minimally Sufficient Robot Brains", "Authors": ["Basak Sakcak", "Kalle G. Timperi", "Vadim Weinstein", "and Steven M. LaValle"], "Categories": "cs.RO cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2212.00523"]}, "abstract": "This paper addresses the lower limits of encoding and processing the information acquired through interactions between an internal system (robot algorithms or software) and an external system (robot body and its environment) in terms of action and observation histories. Both are modeled as transition systems. We want to know the weakest internal system that is sufficient for achieving passive (filtering) and active (planning) tasks. We introduce the notion of an information transition system for the internal system which is a transition system over a space of information states that reflect a robot's or other observer's perspective based on limited sensing, memory, computation, and actuation. An information transition system is viewed as a filter and a policy or plan is viewed as a function that labels the states of this information transition system. Regardless of whether internal systems are obtained by learning algorithms, planning algorithms, or human insight, we want to know the limits of feasibility for given robot hardware and tasks. We establish, in a general setting, that minimal information transition systems exist up to reasonable equivalence assumptions, and are unique under some general conditions. We then apply the theory to generate new insights into several problems, including optimal sensor fusion/filtering, solving basic planning tasks, and finding minimal representations for modeling a system given input-output relations.", "url": "https://arxiv.org/abs/2308.09041"}, {"metadata": {"arXiv": "2308.09320", "Date": "Fri, 18 Aug 2023 05:45:13 ", "Title": "Distributed Robust Learning-Based Backstepping Control Aided with Neurodynamics for Consensus Formation Tracking of Underwater Vessels", "Authors": ["Tao Yan", "Zhe Xu", "Simon X. Yang"], "Categories": "cs.RO cs.AI cs.SY eess.SY", "DOI": "10.1109/TCYB.2023.3299222"}, "abstract": "This paper addresses distributed robust learning-based control for consensus formation tracking of multiple underwater vessels, in which the system parameters of the marine vessels are assumed to be entirely unknown and subject to the modeling mismatch, oceanic disturbances, and noises. Towards this end, graph theory is used to allow us to synthesize the distributed controller with a stability guarantee. Due to the fact that the parameter uncertainties only arise in the vessels' dynamic model, the backstepping control technique is then employed. Subsequently, to overcome the difficulties in handling time-varying and unknown systems, an online learning procedure is developed in the proposed distributed formation control protocol. Moreover, modeling errors, environmental disturbances, and measurement noises are considered and tackled by introducing a neurodynamics model in the controller design to obtain a robust solution. Then, the stability analysis of the overall closed-loop system under the proposed scheme is provided to ensure the robust adaptive performance at the theoretical level. Finally, extensive simulation experiments are conducted to further verify the efficacy of the presented distributed control protocol.", "url": "https://arxiv.org/abs/2308.09320"}, {"metadata": {"arXiv": "2308.09387", "Date": "Fri, 18 Aug 2023 08:38:28 ", "Title": "Multi-Level Compositional Reasoning for Interactive Instruction Following", "Authors": ["Suvaansh Bhambri", "Byeonghwi Kim", "Jonghyun Choi"], "Categories": "cs.RO cs.AI", "Comments": ["AAAI 2023"]}, "abstract": "Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent's navigation by a master policy by alternating between a navigation policy and various independent interaction policies. Finally, at the lowest level, we infer manipulation actions with the corresponding object masks using the appropriate interaction policy. Our approach not only generates human interpretable subgoals but also achieves 2.03% absolute gain to comparable state of the arts in the efficiency metric (PLWSR in unseen set) without using rule-based planning or a semantic spatial memory.", "url": "https://arxiv.org/abs/2308.09387"}, {"metadata": {"arXiv": "2308.08994", "Date": "Thu, 17 Aug 2023 14:05:45 ", "Title": "An Extended Convergence Result for Behaviour Tree Controllers", "Authors": ["Christopher Iliffe Sprague", "Petter \\\"Ogren"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["Submitted to the IEEE Transactions on Robotics (T-RO)"]}, "abstract": "Behavior trees (BTs) are an optimally modular framework to assemble hierarchical hybrid control policies from a set of low-level control policies using a tree structure. Many robotic tasks are naturally decomposed into a hierarchy of control tasks, and modularity is a well-known tool for handling complexity, therefor behavior trees have garnered widespread usage in the robotics community. In this paper, we study the convergence of BTs, in the sense of reaching a desired part of the state space. Earlier results on BT convergence were often tailored to specific families of BTs, created using different design principles. The results of this paper generalize the earlier results and also include new cases of cyclic switching not covered in the literature.", "url": "https://arxiv.org/abs/2308.08994"}, {"metadata": {"arXiv": "2308.09326", "Date": "Fri, 18 Aug 2023 06:04:12 ", "Title": "Distributed Neurodynamics-Based Backstepping Optimal Control for Robust Constrained Consensus of Underactuated Underwater Vehicles Fleet", "Authors": ["Tao Yan", "Zhe Xu", "Simon X. Yang", "S. Andrew Gadsden"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["This paper is accepted by IEEE Transactions on Cybernetics"], "DOI": "10.1109/TCYB.2023.3301737"}, "abstract": "Robust constrained formation tracking control of underactuated underwater vehicles (UUVs) fleet in three-dimensional space is a challenging but practical problem. To address this problem, this paper develops a novel consensus based optimal coordination protocol and a robust controller, which adopts a hierarchical architecture. On the top layer, the spherical coordinate transform is introduced to tackle the nonholonomic constraint, and then a distributed optimal motion coordination strategy is developed. As a result, the optimal formation tracking of UUVs fleet can be achieved, and the constraints are fulfilled. To realize the generated optimal commands better and, meanwhile, deal with the underactuation, at the lower-level control loop a neurodynamics based robust backstepping controller is designed, and in particular, the issue of \"explosion of terms\" appearing in conventional backstepping based controllers is avoided and control activities are improved. The stability of the overall UUVs formation system is established to ensure that all the states of the UUVs are uniformly ultimately bounded in the presence of unknown disturbances. Finally, extensive simulation comparisons are made to illustrate the superiority and effectiveness of the derived optimal formation tracking protocol.", "url": "https://arxiv.org/abs/2308.09326"}, {"metadata": {"arXiv": "2308.08611", "Date": "Wed, 16 Aug 2023 18:03:33 ", "Title": "Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach", "Authors": ["A. Wahid", "I faiud", "K. Mason"], "Categories": "cs.AI cs.LG", "Comments": ["This paper has been accepted at the 2023 Deep Learning for Precision Agriculture (DLSPA) Workshop", "at The 2023 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)"]}, "abstract": "This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.", "url": "https://arxiv.org/abs/2308.08611"}, {"metadata": {"arXiv": "2308.08693", "Date": "Wed, 16 Aug 2023 22:47:16 ", "Title": "Planning in the imagination: High-level planning on learned abstract search spaces", "Authors": ["Carlos Martin", "Tuomas Sandholm"], "Categories": "cs.AI cs.LG"}, "abstract": "We propose a new method, called PiZero, that gives an agent the ability to plan in an abstract search space of its own creation that is completely decoupled from the real environment. Unlike prior approaches, this enables the agent to perform high-level planning at arbitrary timescales and reason in terms of compound or temporally-extended actions, which can be useful in environments where large numbers of base-level micro-actions are needed to perform relevant macro-actions. In addition, our method is more general than comparable prior methods because it handles settings with continuous action spaces and partial observability. We evaluate our method on multiple domains, including navigation tasks and Sokoban. Experimentally, it outperforms comparable prior methods without assuming access to an environment simulator.", "url": "https://arxiv.org/abs/2308.08693"}, {"metadata": {"arXiv": "2308.08708", "Date": "Thu, 17 Aug 2023 00:10:16 ", "Title": "Consciousness in Artificial Intelligence: Insights from the Science of Consciousness", "Authors": ["Patrick Butlin", "Robert Long", "Eric Elmoznino", "Yoshua Bengio", "Jonathan Birch", "Axel Constant", "George Deane", "Stephen M. Fleming", "Chris Frith", "Xu Ji", "Ryota Kanai", "Colin Klein", "Grace Lindsay", "Matthias Michel", "Liad Mudrik", "Megan A. K. Peters", "Eric Schwitzgebel", "Jonathan Simon", "Rufin VanRullen"], "Categories": "cs.AI cs.CY cs.LG q-bio.NC"}, "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive \"indicator properties\" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also shows that there are no obvious barriers to building conscious AI systems.", "url": "https://arxiv.org/abs/2308.08708"}, {"metadata": {"arXiv": "2308.09175", "Date": "Thu, 17 Aug 2023 20:27:33 ", "Title": "Diversifying AI: Towards Creative Chess with AlphaZero", "Authors": ["Tom Zahavy", "Vivek Veeriah", "Shaobo Hou", "Kevin Waugh", "Matthew Lai", "Edouard Leurent", "Nenad Tomasev", "Lisa Schut", "Demis Hassabis", "and Satinder Singh"], "Categories": "cs.AI cs.LG"}, "abstract": "In recent years, Artificial Intelligence (AI) systems have surpassed human intelligence in a variety of computational tasks. However, AI systems, like humans, make mistakes, have blind spots, hallucinate, and struggle to generalize to new situations. This work explores whether AI can benefit from creative decision-making mechanisms when pushed to the limits of its computational rationality. In particular, we investigate whether a team of diverse AI systems can outperform a single AI in challenging tasks by generating more ideas as a group and then selecting the best ones. We study this question in the game of chess, the so-called drosophila of AI. We build on AlphaZero (AZ) and extend it to represent a league of agents via a latent-conditioned architecture, which we call AZ_db. We train AZ_db to generate a wider range of ideas using behavioral diversity techniques and select the most promising ones with sub-additive planning. Our experiments suggest that AZ_db plays chess in diverse ways, solves more puzzles as a group and outperforms a more homogeneous team. Notably, AZ_db solves twice as many challenging puzzles as AZ, including the challenging Penrose positions. When playing chess from different openings, we notice that players in AZ_db specialize in different openings, and that selecting a player for each opening using sub-additive planning results in a 50 Elo improvement over AZ. Our findings suggest that diversity bonuses emerge in teams of AI agents, just as they do in teams of humans and that diversity is a valuable asset in solving computationally hard problems.", "url": "https://arxiv.org/abs/2308.09175"}, {"metadata": {"arXiv": "2308.08948", "Date": "Thu, 17 Aug 2023 12:40:38 ", "Title": "Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level", "Authors": ["Deepak Pathak", "Miro Miranda", "Francisco Mena", "Cristhian Sanchez", "Patrick Helber", "Benjamin Bischke", "Peter Habelitz", "Hiba Najjar", "Jayanth Siddamsetty", "Diego Arenas", "Michaela Vollmer", "Marcela Charfuelan", "Marlon Nuske", "Andreas Dengel"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["4 pages", "1 figure", "3 tables", "IEEE IGARSS 2023"], "MSC-class": "ACM-class: J.2"}, "abstract": "We introduce a simple yet effective early fusion method for crop yield prediction that handles multiple input modalities with different temporal and spatial resolutions. We use high-resolution crop yield maps as ground truth data to train crop and machine learning model agnostic methods at the sub-field level. We use Sentinel-2 satellite imagery as the primary modality for input data with other complementary modalities, including weather, soil, and DEM data. The proposed method uses input modalities available with global coverage, making the framework globally scalable. We explicitly highlight the importance of input modalities for crop yield prediction and emphasize that the best-performing combination of input modalities depends on region, crop, and chosen model.", "url": "https://arxiv.org/abs/2308.08948"}, {"metadata": {"arXiv": "2308.09351", "Date": "Fri, 18 Aug 2023 07:17:09 ", "Title": "RLIPv2: Fast Scaling of Relational Language-Image Pre-training", "Authors": ["Hangjie Yuan", "Shiwei Zhang", "Xiang Wang", "Samuel Albanie", "Yining Pan", "Tao Feng", "Jianwen Jiang", "Dong Ni", "Yingya Zhang", "Deli Zhao"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "Comments": ["Accepted to ICCV 2023. Code and models: https://github.com/JacobYuan7/RLIPv2"]}, "abstract": "Relational Language-Image Pre-training (RLIP) aims to align vision representations with relational texts, thereby advancing the capability of relational reasoning in computer vision tasks. However, hindered by the slow convergence of RLIPv1 architecture and the limited availability of existing scene graph data, scaling RLIPv1 is challenging. In this paper, we propose RLIPv2, a fast converging model that enables the scaling of relational pre-training to large-scale pseudo-labelled scene graph data. To enable fast scaling, RLIPv2 introduces Asymmetric Language-Image Fusion (ALIF), a mechanism that facilitates earlier and deeper gated cross-modal fusion with sparsified language encoding layers. ALIF leads to comparable or better performance than RLIPv1 in a fraction of the time for pre-training and fine-tuning. To obtain scene graph data at scale, we extend object detection datasets with free-form relation labels by introducing a captioner (e.g., BLIP) and a designed Relation Tagger. The Relation Tagger assigns BLIP-generated relation texts to region pairs, thus enabling larger-scale relational pre-training. Through extensive experiments conducted on Human-Object Interaction Detection and Scene Graph Generation, RLIPv2 shows state-of-the-art performance on three benchmarks under fully-finetuning, few-shot and zero-shot settings. Notably, the largest RLIPv2 achieves 23.29mAP on HICO-DET without any fine-tuning, yields 32.22mAP with just 1% data and yields 45.09mAP with 100% data. Code and models are publicly available at https://github.com/JacobYuan7/RLIPv2.", "url": "https://arxiv.org/abs/2308.09351"}, {"metadata": {"arXiv": "2308.09372", "Date": "Fri, 18 Aug 2023 08:06:49 ", "Title": "Which Transformer to Favor: A Comparative Analysis of Efficiency in Vision Transformers", "Authors": ["Tobias Christian Nauen", "Sebastian Palacio", "Andreas Dengel"], "Categories": "cs.CV cs.AI cs.LG", "MSC-class": "68T07", "ACM-class": "I.4.0; I.2.10; I.5.1"}, "abstract": "The growing popularity of Vision Transformers as the go-to models for image classification has led to an explosion of architectural modifications claiming to be more efficient than the original ViT. However, a wide diversity of experimental conditions prevents a fair comparison between all of them, based solely on their reported results. To address this gap in comparability, we conduct a comprehensive analysis of more than 30 models to evaluate the efficiency of vision transformers and related architectures, considering various performance metrics. Our benchmark provides a comparable baseline across the landscape of efficiency-oriented transformers, unveiling a plethora of surprising insights. For example, we discover that ViT is still Pareto optimal across multiple efficiency metrics, despite the existence of several alternative approaches claiming to be more efficient. Results also indicate that hybrid attention-CNN models fare particularly well when it comes to low inference memory and number of parameters, and also that it is better to scale the model size, than the image size. Furthermore, we uncover a strong positive correlation between the number of FLOPS and the training memory, which enables the estimation of required VRAM from theoretical measurements alone. Thanks to our holistic evaluation, this study offers valuable insights for practitioners and researchers, facilitating informed decisions when selecting models for specific applications. We publicly release our code and data at https://github.com/tobna/WhatTransformerToFavor", "url": "https://arxiv.org/abs/2308.09372"}, {"metadata": {"arXiv": "2308.09632", "Date": "Fri, 18 Aug 2023 15:44:45 ", "Title": "VALERIE22 -- A photorealistic, richly metadata annotated dataset of urban environments", "Authors": ["Oliver Grau and Korbinian Hagn"], "Categories": "cs.CV cs.AI cs.GR cs.LG"}, "abstract": "The VALERIE tool pipeline is a synthetic data generator developed with the goal to contribute to the understanding of domain-specific factors that influence perception performance of DNNs (deep neural networks). This work was carried out under the German research project KI Absicherung in order to develop a methodology for the validation of DNNs in the context of pedestrian detection in urban environments for automated driving. The VALERIE22 dataset was generated with the VALERIE procedural tools pipeline providing a photorealistic sensor simulation rendered from automatically synthesized scenes. The dataset provides a uniquely rich set of metadata, allowing extraction of specific scene and semantic features (like pixel-accurate occlusion rates, positions in the scene and distance + angle to the camera). This enables a multitude of possible tests on the data and we hope to stimulate research on understanding performance of DNNs. Based on performance metric a comparison with several other publicly available datasets is provided, demonstrating that VALERIE22 is one of best performing synthetic datasets currently available in the open domain.", "url": "https://arxiv.org/abs/2308.09632"}, {"metadata": {"arXiv": "2308.09004", "Date": "Thu, 17 Aug 2023 14:20:29 ", "Title": "Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability", "Authors": ["Renan Souza", "Tyler J. Skluzacek", "Sean R. Wilkinson", "Maxim Ziatdinov", "Rafael Ferreira da Silva"], "Categories": "cs.DC cs.AI cs.DB cs.LG", "Comments": ["10 pages", "5 figures", "2 Listings", "42 references", "Paper accepted at IEEE eScience'23"], "MSC-class": "65Y05, 68P15", "ACM-class": "I.2; H.2; C.4; J.2", "Journal-ref": "19th IEEE International Conference on e-Science (eScience) 2023 - Limassol, Cyprus"}, "abstract": "Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.", "url": "https://arxiv.org/abs/2308.09004"}, {"metadata": {"arXiv": "2308.08563", "Date": "Tue, 15 Aug 2023 02:38:08 ", "Title": "KMF: Knowledge-Aware Multi-Faceted Representation Learning for Zero-Shot Node Classification", "Authors": ["Likang Wu", "Junji Jiang", "Hongke Zhao", "Hao Wang", "Defu Lian", "Mengdi Zhang and Enhong Chen"], "Categories": "cs.LG cs.AI cs.IR"}, "abstract": "Recently, Zero-Shot Node Classification (ZNC) has been an emerging and crucial task in graph data analysis. This task aims to predict nodes from unseen classes which are unobserved in the training process. Existing work mainly utilizes Graph Neural Networks (GNNs) to associate features' prototypes and labels' semantics thus enabling knowledge transfer from seen to unseen classes. However, the multi-faceted semantic orientation in the feature-semantic alignment has been neglected by previous work, i.e. the content of a node usually covers diverse topics that are relevant to the semantics of multiple labels. It's necessary to separate and judge the semantic factors that tremendously affect the cognitive ability to improve the generality of models. To this end, we propose a Knowledge-Aware Multi-Faceted framework (KMF) that enhances the richness of label semantics via the extracted KG (Knowledge Graph)-based topics. And then the content of each node is reconstructed to a topic-level representation that offers multi-faceted and fine-grained semantic relevancy to different labels. Due to the particularity of the graph's instance (i.e., node) representation, a novel geometric constraint is developed to alleviate the problem of prototype drift caused by node information aggregation. Finally, we conduct extensive experiments on several public graph datasets and design an application of zero-shot cross-domain recommendation. The quantitative results demonstrate both the effectiveness and generalization of KMF with the comparison of state-of-the-art baselines.", "url": "https://arxiv.org/abs/2308.08563"}, {"metadata": {"arXiv": "2308.08574", "Date": "Tue, 15 Aug 2023 21:18:52 ", "Title": "A Comparative Analysis of the Capabilities of Nature-inspired Feature Selection Algorithms in Predicting Student Performance", "Authors": ["Thomas Trask"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["Draft"]}, "abstract": "Predicting student performance is key in leveraging effective pre-failure interventions for at-risk students. In this paper, I have analyzed the relative performance of a suite of 12 nature-inspired algorithms when used to predict student performance across 3 datasets consisting of instance-based clickstream data, intra-course single-course performance, and performance when taking multiple courses simultaneously. I found that, for all datasets, leveraging an ensemble approach using NIAs for feature selection and traditional ML algorithms for classification increased predictive accuracy while also reducing feature set size by 2/3.", "url": "https://arxiv.org/abs/2308.08574"}, {"metadata": {"arXiv": "2308.08614", "Date": "Wed, 16 Aug 2023 18:13:27 ", "Title": "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought", "Authors": ["Bin Lei", "pei-Hung Lin", "Chunhua Liao", "Caiwen Ding"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \\textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \\textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\\%$, $86\\%$, and $56\\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \\textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\\%$, $24\\%$, and $15\\%$.", "url": "https://arxiv.org/abs/2308.08614"}, {"metadata": {"arXiv": "2308.08621", "Date": "Wed, 16 Aug 2023 18:39:29 ", "Title": "LSTM-Based Forecasting Model for GRACE Accelerometer Data", "Authors": ["Neda Darbeheshti and Elahe Moradi"], "Categories": "cs.LG cs.AI physics.space-ph"}, "abstract": "The Gravity Recovery and Climate Experiment (GRACE) satellite mission, spanning from 2002 to 2017, has provided a valuable dataset for monitoring variations in Earth's gravity field, enabling diverse applications in geophysics and hydrology. The mission was followed by GRACE Follow-On in 2018, continuing data collection efforts. The monthly Earth gravity field, derived from the integration different instruments onboard satellites, has shown inconsistencies due to various factors, including gaps in observations for certain instruments since the beginning of the GRACE mission. With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes. In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.", "url": "https://arxiv.org/abs/2308.08621"}, {"metadata": {"arXiv": "2308.08634", "Date": "Wed, 16 Aug 2023 19:14:52 ", "Title": "FedPop: Federated Population-based Hyperparameter Tuning", "Authors": ["Haokun Chen", "Denis Krompass", "Jindong Gu", "Volker Tresp"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Federated Learning (FL) is a distributed machine learning (ML) paradigm, in which multiple clients collaboratively train ML models without centralizing their local data. Similar to conventional ML pipelines, the client local optimization and server aggregation procedure in FL are sensitive to the hyperparameter (HP) selection. Despite extensive research on tuning HPs for centralized ML, these methods yield suboptimal results when employed in FL. This is mainly because their \"training-after-tuning\" framework is unsuitable for FL with limited client computation power. While some approaches have been proposed for HP-Tuning in FL, they are limited to the HPs for client local updates. In this work, we propose a novel HP-tuning algorithm, called Federated Population-based Hyperparameter Tuning (FedPop), to address this vital yet challenging problem. FedPop employs population-based evolutionary algorithms to optimize the HPs, which accommodates various HP types at both client and server sides. Compared with prior tuning methods, FedPop employs an online \"tuning-while-training\" framework, offering computational efficiency and enabling the exploration of a broader HP search space. Our empirical validation on the common FL benchmarks and complex real-world FL datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the concurrent state-of-the-art HP tuning methods for FL.", "url": "https://arxiv.org/abs/2308.08634"}, {"metadata": {"arXiv": "2308.08682", "Date": "Wed, 16 Aug 2023 21:32:57 ", "Title": "Quantifying Overfitting: Introducing the Overfitting Index", "Authors": ["Sanad Aburass"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising avenue to advance model optimization and ensure real-world efficacy.", "url": "https://arxiv.org/abs/2308.08682"}, {"metadata": {"arXiv": "2308.08858", "Date": "Thu, 17 Aug 2023 08:34:58 ", "Title": "Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games", "Authors": ["Songtao Feng", "Ming Yin", "Yu-Xiang Wang", "Jing Yang", "Yingbin Liang"], "Categories": "cs.LG cs.AI cs.GT stat.ML"}, "abstract": "The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by leveraging the popular variance reduction technique based on the reference-advantage decomposition previously used only for single-agent RL. However, such a technique relies on a critical monotonicity property of the value function, which does not hold in Markov games due to the update of the policy via the coarse correlated equilibrium (CCE) oracle. Thus, to extend such a technique to Markov games, our algorithm features a key novel design of updating the reference value functions as the pair of optimistic and pessimistic value functions whose value difference is the smallest in the history in order to achieve the desired improvement in the sample efficiency.", "url": "https://arxiv.org/abs/2308.08858"}, {"metadata": {"arXiv": "2308.08904", "Date": "Thu, 17 Aug 2023 10:27:43 ", "Title": "Development of a Knowledge Graph Embeddings Model for Pain", "Authors": ["Jaya Chaturvedi", "Tao Wang", "Sumithra Velupillai", "Robert Stewart", "Angus Roberts"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at AMIA 2023", "New Orleans"]}, "abstract": "Pain is a complex concept that can interconnect with other concepts such as a disorder that might cause pain, a medication that might relieve pain, and so on. To fully understand the context of pain experienced by either an individual or across a population, we may need to examine all concepts related to pain and the relationships between them. This is especially useful when modeling pain that has been recorded in electronic health records. Knowledge graphs represent concepts and their relations by an interlinked network, enabling semantic and context-based reasoning in a computationally tractable form. These graphs can, however, be too large for efficient computation. Knowledge graph embeddings help to resolve this by representing the graphs in a low-dimensional vector space. These embeddings can then be used in various downstream tasks such as classification and link prediction. The various relations associated with pain which are required to construct such a knowledge graph can be obtained from external medical knowledge bases such as SNOMED CT, a hierarchical systematic nomenclature of medical terms. A knowledge graph built in this way could be further enriched with real-world examples of pain and its relations extracted from electronic health records. This paper describes the construction of such knowledge graph embedding models of pain concepts, extracted from the unstructured text of mental health electronic health records, combined with external knowledge created from relations described in SNOMED CT, and their evaluation on a subject-object link prediction task. The performance of the models was compared with other baseline models.", "url": "https://arxiv.org/abs/2308.08904"}, {"metadata": {"arXiv": "2308.08915", "Date": "Thu, 17 Aug 2023 11:00:01 ", "Title": "Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection", "Authors": ["Haotian Si", "Changhua Pei", "Zhihan Li", "Yadong Zhao", "Jingjing Li", "Haiming Zhang", "Zulong Diao", "Jianhui Li", "Gaogang Xie", "Dan Pei"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "ESEC/FSE industry track 2023"]}, "abstract": "Massive key performance indicators (KPIs) are monitored as multivariate time series data (MTS) to ensure the reliability of the software applications and service system. Accurately detecting the abnormality of MTS is very critical for subsequent fault elimination. The scarcity of anomalies and manual labeling has led to the development of various self-supervised MTS anomaly detection (AD) methods, which optimize an overall objective/loss encompassing all metrics' regression objectives/losses. However, our empirical study uncovers the prevalence of conflicts among metrics' regression objectives, causing MTS models to grapple with different losses. This critical aspect significantly impacts detection performance but has been overlooked in existing approaches. To address this problem, by mimicking the design of multi-gate mixture-of-experts (MMoE), we introduce CAD, a Conflict-aware multivariate KPI Anomaly Detection algorithm. CAD offers an exclusive structure for each metric to mitigate potential conflicts while fostering inter-metric promotions. Upon thorough investigation, we find that the poor performance of vanilla MMoE mainly comes from the input-output misalignment settings of MTS formulation and convergence issues arising from expansive tasks. To address these challenges, we propose a straightforward yet effective task-oriented metric selection and p&s (personalized and shared) gating mechanism, which establishes CAD as the first practicable multi-task learning (MTL) based MTS AD model. Evaluations on multiple public datasets reveal that CAD obtains an average F1-score of 0.943 across three public datasets, notably outperforming state-of-the-art methods. Our code is accessible at https://github.com/dawnvince/MTS_CAD.", "url": "https://arxiv.org/abs/2308.08915"}, {"metadata": {"arXiv": "2308.08918", "Date": "Thu, 17 Aug 2023 11:04:09 ", "Title": "IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making", "Authors": ["Hui Niu", "Siyuan Li", "Jiahao Zheng", "Zhouchi Lin", "Jian Li", "Jian Guo", "Bo An"], "Categories": "cs.LG cs.AI q-fin.TR"}, "abstract": "Market making (MM) has attracted significant attention in financial trading owing to its essential function in ensuring market liquidity. With strong capabilities in sequential decision-making, Reinforcement Learning (RL) technology has achieved remarkable success in quantitative trading. Nonetheless, most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. Strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level strategies involves a comprehensive trading action space, the challenge of effectively training profitable RL agents for MM persists. Inspired by the efficient workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework start with introducing effective state and action representations adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.", "url": "https://arxiv.org/abs/2308.08918"}, {"metadata": {"arXiv": "2308.08945", "Date": "Thu, 17 Aug 2023 12:35:02 ", "Title": "Interpretable Graph Neural Networks for Tabular Data", "Authors": ["Amr Alkhatib", "Sofiane Ennadir", "Henrik Bostr\\\"om", "Michalis Vazirgiannis"], "Categories": "cs.LG cs.AI", "Comments": ["18 pages", "12 figures"]}, "abstract": "Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true Shapley values of the features without incurring any additional computational overhead.", "url": "https://arxiv.org/abs/2308.08945"}, {"metadata": {"arXiv": "2308.08949", "Date": "Thu, 17 Aug 2023 12:41:04 ", "Title": "A Dual-Perspective Approach to Evaluating Feature Attribution Methods", "Authors": ["Yawei Li", "Yang Zhang", "Kenji Kawaguchi", "Ashkan Khakzar", "Bernd Bischl", "Mina Rezaei"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "14 figures"]}, "abstract": "Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.", "url": "https://arxiv.org/abs/2308.08949"}, {"metadata": {"arXiv": "2308.09023", "Date": "Thu, 17 Aug 2023 14:52:15 ", "Title": "Reinforcement Learning for Battery Management in Dairy Farming", "Authors": ["Nawazish Ali", "Abdul Wahid", "Rachael shaw", "Karl Mason"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["This paper has been accepted at the 2023 Artificial Intelligence for Sustainability (AI4S) Workshop", "at 26th European Conference on Artificial Intelligence ECAI 2023"]}, "abstract": "Dairy farming is a particularly energy-intensive part of the agriculture sector. Effective battery management is essential for renewable integration within the agriculture sector. However, controlling battery charging/discharging is a difficult task due to electricity demand variability, stochasticity of renewable generation, and energy price fluctuations. Despite the potential benefits of applying Artificial Intelligence (AI) to renewable energy in the context of dairy farming, there has been limited research in this area. This research is a priority for Ireland as it strives to meet its governmental goals in energy and sustainability. This research paper utilizes Q-learning to learn an effective policy for charging and discharging a battery within a dairy farm setting. The results demonstrate that the developed policy significantly reduces electricity costs compared to the established baseline algorithm. These findings highlight the effectiveness of reinforcement learning for battery management within the dairy farming sector.", "url": "https://arxiv.org/abs/2308.09023"}, {"metadata": {"arXiv": "2308.09189", "Date": "Thu, 17 Aug 2023 21:24:34 ", "Title": "Regularizing Adversarial Imitation Learning Using Causal Invariance", "Authors": ["Ivan Ovinnikov", "Joachim M. Buhmann"], "Categories": "cs.LG cs.AI", "Comments": ["Published at the ICML 2023 Workshop on Spurious Correlations", "Invariance", "and Stability"]}, "abstract": "Imitation learning methods are used to infer a policy in a Markov decision process from a dataset of expert demonstrations by minimizing a divergence measure between the empirical state occupancy measures of the expert and the policy. The guiding signal to the policy is provided by the discriminator used as part of an versarial optimization procedure. We observe that this model is prone to absorbing spurious correlations present in the expert data. To alleviate this issue, we propose to use causal invariance as a regularization principle for adversarial training of these models. The regularization objective is applicable in a straightforward manner to existing adversarial imitation frameworks. We demonstrate the efficacy of the regularized formulation in an illustrative two-dimensional setting as well as a number of high-dimensional robot locomotion benchmark tasks.", "url": "https://arxiv.org/abs/2308.09189"}, {"metadata": {"arXiv": "2308.09290", "Date": "Fri, 18 Aug 2023 04:29:48 ", "Title": "HyperLoRA for PDEs", "Authors": ["Ritam Majumdar", "Vishal Jadhav", "Anirudh Deodhar", "Shirish Karande", "Lovekesh Vig", "Venkataramana Runkana"], "Categories": "cs.LG cs.AI cs.CE math.AP", "Comments": ["8 pages", "4 figures", "3 Tables"]}, "abstract": "Physics-informed neural networks (PINNs) have been widely used to develop neural surrogates for solutions of Partial Differential Equations. A drawback of PINNs is that they have to be retrained with every change in initial-boundary conditions and PDE coefficients. The Hypernetwork, a model-based meta learning technique, takes in a parameterized task embedding as input and predicts the weights of PINN as output. Predicting weights of a neural network however, is a high-dimensional regression problem, and hypernetworks perform sub-optimally while predicting parameters for large base networks. To circumvent this issue, we use a low ranked adaptation (LoRA) formulation to decompose every layer of the base network into low-ranked tensors and use hypernetworks to predict the low-ranked tensors. Despite the reduced dimensionality of the resulting weight-regression problem, LoRA-based Hypernetworks violate the underlying physics of the given task. We demonstrate that the generalization capabilities of LoRA-based hypernetworks drastically improve when trained with an additional physics-informed loss component (HyperPINN) to satisfy the governing differential equations. We observe that LoRA-based HyperPINN training allows us to learn fast solutions for parameterized PDEs like Burger's equation and Navier Stokes: Kovasznay flow, while having an 8x reduction in prediction parameters on average without compromising on accuracy when compared to all other baselines.", "url": "https://arxiv.org/abs/2308.09290"}, {"metadata": {"arXiv": "2308.09293", "Date": "Fri, 18 Aug 2023 04:35:13 ", "Title": "How important are specialized transforms in Neural Operators?", "Authors": ["Ritam Majumdar", "Shirish Karande", "Lovekesh Vig"], "Categories": "cs.LG cs.AI cs.CE math.AP", "Comments": ["8 pages", "3 figures", "4 tables"]}, "abstract": "Simulating physical systems using Partial Differential Equations (PDEs) has become an indispensible part of modern industrial process optimization. Traditionally, numerical solvers have been used to solve the associated PDEs, however recently Transform-based Neural Operators such as the Fourier Neural Operator and Wavelet Neural Operator have received a lot of attention for their potential to provide fast solutions for systems of PDEs. In this work, we investigate the importance of the transform layers to the reported success of transform based neural operators. In particular, we record the cost in terms of performance, if all the transform layers are replaced by learnable linear layers. Surprisingly, we observe that linear layers suffice to provide performance comparable to the best-known transform-based layers and seem to do so with a compute time advantage as well. We believe that this observation can have significant implications for future work on Neural Operators, and might point to other sources of efficiencies for these architectures.", "url": "https://arxiv.org/abs/2308.09293"}, {"metadata": {"arXiv": "2308.09318", "Date": "Fri, 18 Aug 2023 05:37:55 ", "Title": "Towards Attack-tolerant Federated Learning via Critical Parameter Analysis", "Authors": ["Sungwon Han", "Sungwon Park", "Fangzhao Wu", "Sundong Kim", "Bin Zhu", "Xing Xie and Meeyoung Cha"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["ICCV'23 Accepted"]}, "abstract": "Federated learning is used to train a shared model in a decentralized way without clients sharing private data with each other. Federated learning systems are susceptible to poisoning attacks when malicious clients send false updates to the central server. Existing defense strategies are ineffective under non-IID data settings. This paper proposes a new defense strategy, FedCPA (Federated learning with Critical Parameter Analysis). Our attack-tolerant aggregation method is based on the observation that benign local models have similar sets of top-k and bottom-k critical parameters, whereas poisoned local models do not. Experiments with different attack scenarios on multiple datasets demonstrate that our model outperforms existing defense strategies in defending against poisoning attacks.", "url": "https://arxiv.org/abs/2308.09318"}, {"metadata": {"arXiv": "2308.09380", "Date": "Fri, 18 Aug 2023 08:23:47 ", "Title": "Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review", "Authors": ["Yun Xin Teoh", "Alice Othmani", "Siew Li Goh", "Juliana Usman", "Khin Wee Lai"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Existing artificial intelligence (AI) models for diagnosing knee osteoarthritis (OA) have faced criticism for their lack of transparency and interpretability, despite achieving medical-expert-like performance. This opacity makes them challenging to trust in clinical practice. Recently, explainable artificial intelligence (XAI) has emerged as a specialized technique that can provide confidence in the model's prediction by revealing how the prediction is derived, thus promoting the use of AI systems in healthcare. This paper presents the first survey of XAI techniques used for knee OA diagnosis. The XAI techniques are discussed from two perspectives: data interpretability and model interpretability. The aim of this paper is to provide valuable insights into XAI's potential towards a more reliable knee OA diagnosis approach and encourage its adoption in clinical practice.", "url": "https://arxiv.org/abs/2308.09380"}, {"metadata": {"arXiv": "2308.09437", "Date": "Fri, 18 Aug 2023 10:07:46 ", "Title": "From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space", "Authors": ["Maximilian Dreyer", "Frederik Pahde", "Christopher J. Anders", "Wojciech Samek", "Sebastian Lapuschkin"], "Categories": "cs.LG cs.AI cs.CV cs.CY"}, "abstract": "Deep Neural Networks are prone to learning spurious correlations embedded in the training data, leading to potentially biased predictions. This poses risks when deploying these models for high-stake decision-making, such as in medical applications. Current methods for post-hoc model correction either require input-level annotations, which are only possible for spatially localized biases, or augment the latent feature space, thereby hoping to enforce the right reasons. We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient. When modeling biases via Concept Activation Vectors, we highlight the importance of choosing robust directions, as traditional regression-based approaches such as Support Vector Machines tend to result in diverging directions. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientNet architectures.", "url": "https://arxiv.org/abs/2308.09437"}, {"metadata": {"arXiv": "2308.09490", "Date": "Fri, 18 Aug 2023 11:59:15 ", "Title": "Balancing Transparency and Risk: The Security and Privacy Risks of Open-Source Machine Learning Models", "Authors": ["Dominik Hintersdorf", "Lukas Struppek", "Kristian Kersting"], "Categories": "cs.LG cs.AI cs.CR cs.CY"}, "abstract": "The field of artificial intelligence (AI) has experienced remarkable progress in recent years, driven by the widespread adoption of open-source machine learning models in both research and industry. Considering the resource-intensive nature of training on vast datasets, many applications opt for models that have already been trained. Hence, a small number of key players undertake the responsibility of training and publicly releasing large pre-trained models, providing a crucial foundation for a wide range of applications. However, the adoption of these open-source models carries inherent privacy and security risks that are often overlooked. To provide a concrete example, an inconspicuous model may conceal hidden functionalities that, when triggered by specific input patterns, can manipulate the behavior of the system, such as instructing self-driving cars to ignore the presence of other vehicles. The implications of successful privacy and security attacks encompass a broad spectrum, ranging from relatively minor damage like service interruptions to highly alarming scenarios, including physical harm or the exposure of sensitive user data. In this work, we present a comprehensive overview of common privacy and security threats associated with the use of open-source models. By raising awareness of these dangers, we strive to promote the responsible and secure use of AI systems.", "url": "https://arxiv.org/abs/2308.09490"}, {"metadata": {"arXiv": "2308.09544", "Date": "Fri, 18 Aug 2023 13:22:59 ", "Title": "Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning", "Authors": ["Filip Szatkowski", "Mateusz Pyla", "Marcin Przewi\\k{e}\\'zlikowski", "Sebastian Cygert", "Bart{\\l}omiej Twardowski", "Tomasz Trzci\\'nski"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["VCL workshop at ICCV 2023"]}, "abstract": "In this work, we investigate exemplar-free class incremental learning (CIL) with knowledge distillation (KD) as a regularization strategy, aiming to prevent forgetting. KD-based methods are successfully used in CIL, but they often struggle to regularize the model without access to exemplars of the training data from previous tasks. Our analysis reveals that this issue originates from substantial representation shifts in the teacher network when dealing with out-of-distribution data. This causes large errors in the KD loss component, leading to performance degradation in CIL. Inspired by recent test-time adaptation methods, we introduce Teacher Adaptation (TA), a method that concurrently updates the teacher and the main model during incremental training. Our method seamlessly integrates with KD-based CIL approaches and allows for consistent enhancement of their performance across multiple exemplar-free CIL benchmarks.", "url": "https://arxiv.org/abs/2308.09544"}, {"metadata": {"arXiv": "2308.09570", "Date": "Fri, 18 Aug 2023 14:02:56 ", "Title": "Investigating the Interplay between Features and Structures in Graph Learning", "Authors": ["Daniele Castellana", "Federico Errica"], "Categories": "cs.LG cs.AI", "Journal-ref": "MLG Workshop at ECMLPKDD 2023"}, "abstract": "In the past, the dichotomy between homophily and heterophily has inspired research contributions toward a better understanding of Deep Graph Networks' inductive bias. In particular, it was believed that homophily strongly correlates with better node classification predictions of message-passing methods. More recently, however, researchers pointed out that such dichotomy is too simplistic as we can construct node classification tasks where graphs are completely heterophilic but the performances remain high. Most of these works have also proposed new quantitative metrics to understand when a graph structure is useful, which implicitly or explicitly assume the correlation between node features and target labels. Our work empirically investigates what happens when this strong assumption does not hold, by formalising two generative processes for node classification tasks that allow us to build and study ad-hoc problems. To quantitatively measure the influence of the node features on the target labels, we also use a metric we call Feature Informativeness. We construct six synthetic tasks and evaluate the performance of six models, including structure-agnostic ones. Our findings reveal that previously defined metrics are not adequate when we relax the above assumption. Our contribution to the workshop aims at presenting novel research findings that could help advance our understanding of the field.", "url": "https://arxiv.org/abs/2308.09570"}, {"metadata": {"arXiv": "2308.09647", "Date": "Fri, 18 Aug 2023 16:07:01 ", "Title": "Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction", "Authors": ["Daniel Bethell", "Simos Gerasimou", "Radu Calinescu"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classification and regression benchmarks. MC-CP can be easily added to existing models, making its deployment simple.", "url": "https://arxiv.org/abs/2308.09647"}, {"metadata": {"arXiv": "2308.09663", "Date": "Fri, 18 Aug 2023 16:30:51 ", "Title": "GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction", "Authors": ["Yucheng Shi", "Yushun Dong", "Qiaoyu Tan", "Jundong Li", "Ninghao Liu"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by CIKM 2023"]}, "abstract": "Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.", "url": "https://arxiv.org/abs/2308.09663"}, {"metadata": {"arXiv": "2308.09075", "Date": "Thu, 17 Aug 2023 16:05:44 ", "Title": "Fast Decision Support for Air Traffic Management at Urban Air Mobility Vertiports using Graph Learning", "Authors": ["Prajit KrisshnaKumar", "Jhoel Witter", "Steve Paul", "Hanvit Cho", "Karthik Dantu", "and Souma Chowdhury"], "Categories": "cs.MA cs.AI cs.LG cs.RO", "Comments": ["Accepted for presentation in proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems 2023"]}, "abstract": "Urban Air Mobility (UAM) promises a new dimension to decongested, safe, and fast travel in urban and suburban hubs. These UAM aircraft are conceived to operate from small airports called vertiports each comprising multiple take-off/landing and battery-recharging spots. Since they might be situated in dense urban areas and need to handle many aircraft landings and take-offs each hour, managing this schedule in real-time becomes challenging for a traditional air-traffic controller but instead calls for an automated solution. This paper provides a novel approach to this problem of Urban Air Mobility - Vertiport Schedule Management (UAM-VSM), which leverages graph reinforcement learning to generate decision-support policies. Here the designated physical spots within the vertiport's airspace and the vehicles being managed are represented as two separate graphs, with feature extraction performed through a graph convolutional network (GCN). Extracted features are passed onto perceptron layers to decide actions such as continue to hover or cruise, continue idling or take-off, or land on an allocated vertiport spot. Performance is measured based on delays, safety (no. of collisions) and battery consumption. Through realistic simulations in AirSim applied to scaled down multi-rotor vehicles, our results demonstrate the suitability of using graph reinforcement learning to solve the UAM-VSM problem and its superiority to basic reinforcement learning (with graph embeddings) or random choice baselines.", "url": "https://arxiv.org/abs/2308.09075"}, {"metadata": {"arXiv": "2308.08737", "Date": "Thu, 17 Aug 2023 02:23:59 ", "Title": "ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents", "Authors": ["Tejaswini Manjunath", "Mozhgan Navardi", "Prakhar Dixit", "Bharat Prakash", "Tinoosh Mohsenin"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["AAAI 2023 RL Ready for Production Workshop"]}, "abstract": "Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.", "url": "https://arxiv.org/abs/2308.08737"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

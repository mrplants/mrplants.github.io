<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.10305", "Date": "Thu, 13 Jul 2023 19:17:54 ", "Title": "Tapestry of Time and Actions: Modeling Human Activity Sequences using Temporal Point Process Flows", "Authors": ["Vinayak Gupta and Srikanta Bedathur"], "Categories": "cs.CV cs.LG", "Comments": ["Extended version of Gupta and Bedathur [arXiv:2206.05291] (SIGKDD 2022). Under review in a journal"]}, "abstract": "Human beings always engage in a vast range of activities and tasks that demonstrate their ability to adapt to different scenarios. Any human activity can be represented as a temporal sequence of actions performed to achieve a certain goal. Unlike the time series datasets extracted from electronics or machines, these action sequences are highly disparate in their nature -- the time to finish a sequence of actions can vary between different persons. Therefore, understanding the dynamics of these sequences is essential for many downstream tasks such as activity length prediction, goal prediction, next action recommendation, etc. Existing neural network-based approaches that learn a continuous-time activity sequence (or CTAS) are limited to the presence of only visual data or are designed specifically for a particular task, i.e., limited to next action or goal prediction. In this paper, we present ProActive, a neural marked temporal point process (MTPP) framework for modeling the continuous-time distribution of actions in an activity sequence while simultaneously addressing three high-impact problems -- next action prediction, sequence-goal prediction, and end-to-end sequence generation. Specifically, we utilize a self-attention module with temporal normalizing flows to model the influence and the inter-arrival times between actions in a sequence. In addition, we propose a novel addition over the ProActive model that can handle variations in the order of actions, i.e., different methods of achieving a given goal. We demonstrate that this variant can learn the order in which the person or actor prefers to do their actions. Extensive experiments on sequences derived from three activity recognition datasets show the significant accuracy boost of ProActive over the state-of-the-art in terms of action and goal prediction, and the first-ever application of end-to-end action sequence generation.", "url": "https://arxiv.org/abs/2307.10305"}, {"metadata": {"arXiv": "2307.10504", "Date": "Thu, 20 Jul 2023 00:02:24 ", "Title": "Identifying Interpretable Subspaces in Image Representations", "Authors": ["Neha Kalibhat", "Shweta Bhardwaj", "Bayan Bruss", "Hamed Firooz", "Maziar Sanjabi", "Soheil Feizi"], "Categories": "cs.CV cs.LG", "Comments": ["Published at ICML 2023"]}, "abstract": "We propose Automatic Feature Explanation using Contrasting Concepts (FALCON), an interpretability framework to explain features of image representations. For a target feature, FALCON captions its highly activating cropped images using a large captioning dataset (like LAION-400m) and a pre-trained vision-language model like CLIP. Each word among the captions is scored and ranked leading to a small number of shared, human-understandable concepts that closely describe the target feature. FALCON also applies contrastive interpretation using lowly activating (counterfactual) images, to eliminate spurious concepts. Although many existing approaches interpret features independently, we observe in state-of-the-art self-supervised and supervised models, that less than 20% of the representation space can be explained by individual features. We show that features in larger spaces become more interpretable when studied in groups and can be explained with high-order scoring concepts through FALCON. We discuss how extracted concepts can be used to explain and debug failures in downstream tasks. Finally, we present a technique to transfer concepts from one (explainable) representation space to another unseen representation space by learning a simple linear transformation.", "url": "https://arxiv.org/abs/2307.10504"}, {"metadata": {"arXiv": "2307.10695", "Date": "Thu, 20 Jul 2023 08:38:01 ", "Title": "Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss", "Authors": ["Jaekyun Ko and Sanghwan Lee"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Technical report and supplemantry materials are combined into one paper. - Technical report: Page 1~7 - Supplemantry materials : Page 8~18"]}, "abstract": "Recently, denoising methods based on supervised learning have exhibited promising performance. However, their reliance on external datasets containing noisy-clean image pairs restricts their applicability. To address this limitation, researchers have focused on training denoising networks using solely a set of noisy inputs. To improve the feasibility of denoising procedures, in this study, we proposed a single-image self-supervised learning method in which only the noisy input image is used for network training. Gated convolution was used for feature extraction and no-reference image quality assessment was used for guiding the training process. Moreover, the proposed method sampled instances from the input image dataset using Bernoulli sampling with a certain dropout rate for training. The corresponding result was produced by averaging the generated predictions from various instances of the trained network with dropouts. The experimental results indicated that the proposed method achieved state-of-the-art denoising performance on both synthetic and real-world datasets. This highlights the effectiveness and practicality of our method as a potential solution for various noise removal tasks.", "url": "https://arxiv.org/abs/2307.10695"}, {"metadata": {"arXiv": "2307.10705", "Date": "Thu, 20 Jul 2023 08:53:47 ", "Title": "TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars", "Authors": ["Quang Huy Che and Dinh Phuc Nguyen and Minh Quan Pham and Duc Khai Lam"], "Categories": "cs.CV cs.LG"}, "abstract": "Semantic segmentation is a common task in autonomous driving to understand the surrounding environment. Driveable Area Segmentation and Lane Detection are particularly important for safe and efficient navigation on the road. However, original semantic segmentation models are computationally expensive and require high-end hardware, which is not feasible for embedded systems in autonomous vehicles. This paper proposes a lightweight model for the driveable area and lane line segmentation. TwinLiteNet is designed cheaply but achieves accurate and efficient segmentation results. We evaluate TwinLiteNet on the BDD100K dataset and compare it with modern models. Experimental results show that our TwinLiteNet performs similarly to existing approaches, requiring significantly fewer computational resources. Specifically, TwinLiteNet achieves a mIoU score of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task with only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000. Furthermore, TwinLiteNet can run in real-time on embedded devices with limited computing power, especially since it achieves 60FPS on Jetson Xavier NX, making it an ideal solution for self-driving vehicles. Code is available: url{https://github.com/chequanghuy/TwinLiteNet}.", "url": "https://arxiv.org/abs/2307.10705"}, {"metadata": {"arXiv": "2307.10787", "Date": "Thu, 20 Jul 2023 11:36:45 ", "Title": "Feed-Forward Source-Free Domain Adaptation via Class Prototypes", "Authors": ["Ondrej Bohdal", "Da Li", "Timothy Hospedales"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["ECCV 2022 Workshop on Out of Distribution Generalization in Computer Vision (OOD-CV)"]}, "abstract": "Source-free domain adaptation has become popular because of its practical usefulness and no need to access source data. However, the adaptation process still takes a considerable amount of time and is predominantly based on optimization that relies on back-propagation. In this work we present a simple feed-forward approach that challenges the need for back-propagation based adaptation. Our approach is based on computing prototypes of classes under the domain shift using a pre-trained model. It achieves strong improvements in accuracy compared to the pre-trained model and requires only a small fraction of time of existing domain adaptation methods.", "url": "https://arxiv.org/abs/2307.10787"}, {"metadata": {"arXiv": "2307.10842", "Date": "Thu, 20 Jul 2023 13:02:45 ", "Title": "Label Calibration for Semantic Segmentation Under Domain Shift", "Authors": ["Ondrej Bohdal", "Da Li", "Timothy Hospedales"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["ICLR 2023 Workshop on Pitfalls of Limited Data and Computation for Trustworthy ML"]}, "abstract": "Performance of a pre-trained semantic segmentation model is likely to substantially decrease on data from a new domain. We show a pre-trained model can be adapted to unlabelled target domain data by calculating soft-label prototypes under the domain shift and making predictions according to the prototype closest to the vector with predicted class probabilities. The proposed adaptation procedure is fast, comes almost for free in terms of computational resources and leads to considerable performance improvements. We demonstrate the benefits of such label calibration on the highly-practical synthetic-to-real semantic segmentation problem.", "url": "https://arxiv.org/abs/2307.10842"}, {"metadata": {"arXiv": "2307.10875", "Date": "Thu, 20 Jul 2023 13:47:30 ", "Title": "Risk-optimized Outlier Removal for Robust Point Cloud Classification", "Authors": ["Xinke Li", "Junchi Lu"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "The popularity of point cloud deep models for safety-critical purposes has increased, but the reliability and security of these models can be compromised by intentional or naturally occurring point cloud noise. To combat this issue, we present a novel point cloud outlier removal method called PointCVaR, which empowers standard-trained models to eliminate additional outliers and restore the data. Our approach begins by conducting attribution analysis to determine the influence of each point on the model output, which we refer to as point risk. We then optimize the process of filtering high-risk points using Conditional Value at Risk (CVaR) as the objective. The rationale for this approach is based on the observation that noise points in point clouds tend to cluster in the tail of the risk distribution, with a low frequency but a high level of risk, resulting in significant interference with classification results. Despite requiring no additional training effort, our method produces exceptional results in various removal-and-classification experiments for noisy point clouds, which are corrupted by random noise, adversarial noise, and backdoor trigger noise. Impressively, it achieves 87% accuracy in defense against the backdoor attack by removing triggers. Overall, the proposed PointCVaR effectively eliminates noise points and enhances point cloud classification, making it a promising plug-in module for various models in different scenarios.", "url": "https://arxiv.org/abs/2307.10875"}, {"metadata": {"arXiv": "2307.10895", "Date": "Thu, 20 Jul 2023 14:18:44 ", "Title": "Variational Point Encoding Deformation for Dental Modeling", "Authors": ["Johan Ziruo Ye", "Thomas {\\O}rkild", "Peter Lempel S{\\o}ndergaard", "S{\\o}ren Hauberg"], "Categories": "cs.CV cs.LG"}, "abstract": "Digital dentistry has made significant advancements in recent years, yet numerous challenges remain to be addressed. In this study, we release a new extensive dataset of tooth meshes to encourage further research. Additionally, we propose Variational FoldingNet (VF-Net), which extends FoldingNet to enable probabilistic learning of point cloud representations. A key challenge in existing latent variable models for point clouds is the lack of a 1-to-1 mapping between input points and output points. Instead, they must rely on optimizing Chamfer distances, a metric that does not have a normalized distributional counterpart, preventing its usage in probabilistic models. We demonstrate that explicit minimization of Chamfer distances can be replaced by a suitable encoder, which allows us to increase computational efficiency while simplifying the probabilistic extension. Our experimental findings present empirical evidence demonstrating the superior performance of VF-Net over existing models in terms of dental scan reconstruction and extrapolation. Additionally, our investigation highlights the robustness of VF-Net's latent representations. These results underscore the promising prospects of VF-Net as an effective and reliable method for point cloud reconstruction and analysis.", "url": "https://arxiv.org/abs/2307.10895"}, {"metadata": {"arXiv": "2307.10922", "Date": "Thu, 20 Jul 2023 14:47:50 ", "Title": "Language-based Action Concept Spaces Improve Video Self-Supervised Learning", "Authors": ["Kanchana Ranasinghe and Michael Ryoo"], "Categories": "cs.CV cs.LG"}, "abstract": "Recent contrastive language image pre-training has led to learning highly transferable and robust image representations. However, adapting these models to video domains with minimal supervision remains an open problem. We explore a simple step in that direction, using language tied self-supervised learning to adapt an image CLIP model to the video domain. A backbone modified for temporal modeling is trained under self-distillation settings with train objectives operating in an action concept space. Feature vectors of various action concepts extracted from a language encoder using relevant textual prompts construct this space. We introduce two train objectives, concept distillation and concept alignment, that retain generality of original representations while enforcing relations between actions and their attributes. Our approach improves zero-shot and linear probing performance on three action recognition benchmarks.", "url": "https://arxiv.org/abs/2307.10922"}, {"metadata": {"arXiv": "2307.11017", "Date": "Thu, 20 Jul 2023 16:45:16 ", "Title": "Multi-objective point cloud autoencoders for explainable myocardial infarction prediction", "Authors": ["Marcel Beetz", "Abhirup Banerjee", "Vicente Grau"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Myocardial infarction (MI) is one of the most common causes of death in the world. Image-based biomarkers commonly used in the clinic, such as ejection fraction, fail to capture more complex patterns in the heart's 3D anatomy and thus limit diagnostic accuracy. In this work, we present the multi-objective point cloud autoencoder as a novel geometric deep learning approach for explainable infarction prediction, based on multi-class 3D point cloud representations of cardiac anatomy and function. Its architecture consists of multiple task-specific branches connected by a low-dimensional latent space to allow for effective multi-objective learning of both reconstruction and MI prediction, while capturing pathology-specific 3D shape information in an interpretable latent space. Furthermore, its hierarchical branch design with point cloud-based deep learning operations enables efficient multi-scale feature learning directly on high-resolution anatomy point clouds. In our experiments on a large UK Biobank dataset, the multi-objective point cloud autoencoder is able to accurately reconstruct multi-temporal 3D shapes with Chamfer distances between predicted and input anatomies below the underlying images' pixel resolution. Our method outperforms multiple machine learning and deep learning benchmarks for the task of incident MI prediction by 19% in terms of Area Under the Receiver Operating Characteristic curve. In addition, its task-specific compact latent space exhibits easily separable control and MI clusters with clinically plausible associations between subject encodings and corresponding 3D shapes, thus demonstrating the explainability of the prediction.", "url": "https://arxiv.org/abs/2307.11017"}, {"metadata": {"arXiv": "2307.11081", "Date": "Thu, 20 Jul 2023 17:57:04 ", "Title": "GLSFormer : Gated - Long, Short Sequence Transformer for Step Recognition in Surgical Videos", "Authors": ["Nisarg A. Shah", "Shameema Sikder", "S. Swaroop Vedula", "Vishal M. Patel"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to MICCAI 2023 (Early Accept)"]}, "abstract": "Automated surgical step recognition is an important task that can significantly improve patient safety and decision-making during surgeries. Existing state-of-the-art methods for surgical step recognition either rely on separate, multi-stage modeling of spatial and temporal information or operate on short-range temporal resolution when learned jointly. However, the benefits of joint modeling of spatio-temporal features and long-range information are not taken in account. In this paper, we propose a vision transformer-based approach to jointly learn spatio-temporal features directly from sequence of frame-level patches. Our method incorporates a gated-temporal attention mechanism that intelligently combines short-term and long-term spatio-temporal feature representations. We extensively evaluate our approach on two cataract surgery video datasets, namely Cataract-101 and D99, and demonstrate superior performance compared to various state-of-the-art methods. These results validate the suitability of our proposed approach for automated surgical step recognition. Our code is released at: https://github.com/nisargshah1999/GLSFormer", "url": "https://arxiv.org/abs/2307.11081"}, {"metadata": {"arXiv": "2307.10205", "Date": "Fri, 14 Jul 2023 07:01:48 ", "Title": "Adversarial Training Over Long-Tailed Distribution", "Authors": ["Guanlin Li", "Guowen Xu", "Tianwei Zhang"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "In this paper, we study adversarial training on datasets that obey the long-tailed distribution, which is practical but rarely explored in previous works. Compared with conventional adversarial training on balanced datasets, this process falls into the dilemma of generating uneven adversarial examples (AEs) and an unbalanced feature embedding space, causing the resulting model to exhibit low robustness and accuracy on tail data. To combat that, we propose a new adversarial training framework -- Re-balancing Adversarial Training (REAT). This framework consists of two components: (1) a new training strategy inspired by the term effective number to guide the model to generate more balanced and informative AEs; (2) a carefully constructed penalty function to force a satisfactory feature space. Evaluation results on different datasets and model structures prove that REAT can effectively enhance the model's robustness and preserve the model's clean accuracy. The code can be found in https://github.com/GuanlinLee/REAT.", "url": "https://arxiv.org/abs/2307.10205"}, {"metadata": {"arXiv": "2307.10253", "Date": "Mon, 17 Jul 2023 09:35:18 ", "Title": "Efficient selective attention LSTM for well log curve synthesis", "Authors": ["Yuankai Zhou", "Huanyu Li"], "Categories": "cs.LG"}, "abstract": "Non-core drilling has gradually become the primary exploration method in geological engineering, and well logging curves have increasingly gained importance as the main carriers of geological information. However, factors such as geological environment, logging equipment, borehole quality, and unexpected events can all impact the quality of well logging curves. Previous methods of re-logging or manual corrections have been associated with high costs and low efficiency. This paper proposes a machine learning method that utilizes existing data to predict missing well logging curves, and its effectiveness and feasibility have been validated through experiments. The proposed method builds upon the traditional Long Short-Term Memory (LSTM) neural network by incorporating a self-attention mechanism to analyze the spatial dependencies of the data. It selectively includes the dominant computational results in the LSTM, reducing the computational complexity from O(n^2) to O(nlogn) and improving model efficiency. Experimental results demonstrate that the proposed method achieves higher accuracy compared to traditional curve synthesis methods based on Fully Connected Neural Networks (FCNN) and LSTM. This accurate, efficient, and cost-effective prediction method holds practical value in engineering applications.", "url": "https://arxiv.org/abs/2307.10253"}, {"metadata": {"arXiv": "2307.10266", "Date": "Mon, 17 Jul 2023 18:49:46 ", "Title": "A DPLL(T) Framework for Verifying Deep Neural Networks", "Authors": ["Hai Duong", "Linhan Li", "ThanhVu Nguyen", "Matthew Dwyer"], "Categories": "cs.LG cs.LO cs.SE", "Comments": ["27 pages", "8 figures. NeuralSAT is avaliable from: https://github.com/dynaroars/neuralsat-solver"]}, "abstract": "Deep Neural Networks (DNNs) have emerged as an effective approach to tackling real-world problems. However, like human-written software, automatically-generated DNNs can have bugs and be attacked. This thus attracts many recent interests in developing effective and scalable DNN verification techniques and tools. In this work, we introduce a NeuralSAT, a new constraint solving approach to DNN verification. The design of NeuralSAT follows the DPLL(T) algorithm used modern SMT solving, which includes (conflict) clause learning, abstraction, and theory solving, and thus NeuralSAT can be considered as an SMT framework for DNNs. Preliminary results show that the NeuralSAT prototype is competitive to the state-of-the-art. We hope, with proper optimization and engineering, NeuralSAT will carry the power and success of modern SAT/SMT solvers to DNN verification. NeuralSAT is avaliable from: https://github.com/dynaroars/neuralsat-solver", "url": "https://arxiv.org/abs/2307.10266"}, {"metadata": {"arXiv": "2307.10320", "Date": "Wed, 19 Jul 2023 07:00:22 ", "Title": "Reproducibility in Machine Learning-Driven Research", "Authors": ["Harald Semmelrock and Simone Kopeinik and Dieter Theiler and Tony Ross-Hellauer and Dominik Kowald"], "Categories": "cs.LG cs.CY stat.ME", "Comments": ["This research is supported by the Horizon Europe project TIER2 under grant agreement No 101094817"]}, "abstract": "Research is facing a reproducibility crisis, in which the results and findings of many studies are difficult or even impossible to reproduce. This is also the case in machine learning (ML) and artificial intelligence (AI) research. Often, this is the case due to unpublished data and/or source-code, and due to sensitivity to ML training conditions. Although different solutions to address this issue are discussed in the research community such as using ML platforms, the level of reproducibility in ML-driven research is not increasing substantially. Therefore, in this mini survey, we review the literature on reproducibility in ML-driven research with three main aims: (i) reflect on the current situation of ML reproducibility in various research fields, (ii) identify reproducibility issues and barriers that exist in these research fields applying ML, and (iii) identify potential drivers such as tools, practices, and interventions that support ML reproducibility. With this, we hope to contribute to decisions on the viability of different solutions for supporting ML reproducibility.", "url": "https://arxiv.org/abs/2307.10320"}, {"metadata": {"arXiv": "2307.10350", "Date": "Wed, 19 Jul 2023 17:47:12 ", "Title": "Improving Multimodal Datasets with Image Captioning", "Authors": ["Thao Nguyen", "Samir Yitzhak Gadre", "Gabriel Ilharco", "Sewoong Oh", "Ludwig Schmidt"], "Categories": "cs.LG cs.CV"}, "abstract": "Massive web datasets play a key role in the success of large vision-language models like CLIP and Flamingo. However, the raw web data is noisy, and existing filtering methods to reduce noise often come at the expense of data diversity. Our work focuses on caption quality as one major source of noise, and studies how generated captions can increase the utility of web-scraped datapoints with nondescript text. Through exploring different mixing strategies for raw and generated captions, we outperform the best filtering method proposed by the DataComp benchmark by 2% on ImageNet and 4% on average across 38 tasks, given a candidate pool of 128M image-text pairs. Our best approach is also 2x better at Flickr and MS-COCO retrieval. We then analyze what makes synthetic captions an effective source of text supervision. In experimenting with different image captioning models, we also demonstrate that the performance of a model on standard image captioning benchmarks (e.g., NoCaps CIDEr) is not a reliable indicator of the utility of the captions it generates for multimodal training. Finally, our experiments with using generated captions at DataComp's large scale (1.28B image-text pairs) offer insights into the limitations of synthetic text, as well as the importance of image curation with increasing training data quantity.", "url": "https://arxiv.org/abs/2307.10350"}, {"metadata": {"arXiv": "2307.10430", "Date": "Wed, 19 Jul 2023 19:40:21 ", "Title": "DP-TBART: A Transformer-based Autoregressive Model for Differentially Private Tabular Data Generation", "Authors": ["Rodrigo Castellon", "Achintya Gopal", "Brian Bloniarz", "David Rosenberg"], "Categories": "cs.LG cs.CR"}, "abstract": "The generation of synthetic tabular data that preserves differential privacy is a problem of growing importance. While traditional marginal-based methods have achieved impressive results, recent work has shown that deep learning-based approaches tend to lag behind. In this work, we present Differentially-Private TaBular AutoRegressive Transformer (DP-TBART), a transformer-based autoregressive model that maintains differential privacy and achieves performance competitive with marginal-based methods on a wide variety of datasets, capable of even outperforming state-of-the-art methods in certain settings. We also provide a theoretical framework for understanding the limitations of marginal-based approaches and where deep learning-based approaches stand to contribute most. These results suggest that deep learning-based techniques should be considered as a viable alternative to marginal-based methods in the generation of differentially private synthetic tabular data.", "url": "https://arxiv.org/abs/2307.10430"}, {"metadata": {"arXiv": "2307.10437", "Date": "Wed, 19 Jul 2023 20:01:38 ", "Title": "A Bayesian Programming Approach to Car-following Model Calibration and Validation using Limited Data", "Authors": ["Franklin Abodo"], "Categories": "cs.LG stat.ME stat.ML", "Comments": ["Master's thesis", "64 pages", "10 tables", "9 figures"]}, "abstract": "Traffic simulation software is used by transportation researchers and engineers to design and evaluate changes to roadways. These simulators are driven by models of microscopic driver behavior from which macroscopic measures like flow and congestion can be derived. Many models are designed for a subset of possible traffic scenarios and roadway configurations, while others have no explicit constraints on their application. Work zones (WZs) are one scenario for which no model to date has reproduced realistic driving behavior. This makes it difficult to optimize for safety and other metrics when designing a WZ. The Federal Highway Administration commissioned the USDOT Volpe Center to develop a car-following (CF) model for use in microscopic simulators that can capture and reproduce driver behavior accurately within and outside of WZs. Volpe also performed a naturalistic driving study to collect telematics data from vehicles driven on roads with WZs for use in model calibration. During model development, Volpe researchers observed difficulties in calibrating their model, leaving them to question whether there existed flaws in their model, in the data, or in the procedure used to calibrate the model using the data. In this thesis, I use Bayesian methods for data analysis and parameter estimation to explore and, where possible, address these questions. First, I use Bayesian inference to measure the sufficiency of the size of the data set. Second, I compare the procedure and results of the genetic algorithm based calibration performed by the Volpe researchers with those of Bayesian calibration. Third, I explore the benefits of modeling CF hierarchically. Finally, I apply what was learned in the first three phases using an established CF model, Wiedemann 99, to the probabilistic modeling of the Volpe model. Validation is performed using information criteria as an estimate of predictive accuracy.", "url": "https://arxiv.org/abs/2307.10437"}, {"metadata": {"arXiv": "2307.10438", "Date": "Wed, 19 Jul 2023 20:03:42 ", "Title": "Uncertainty Quantification for Molecular Property Predictions with Graph Neural Architecture Search", "Authors": ["Shengli Jiang", "Shiyi Qin", "Reid C. Van Lehn", "Prasanna Balaprakash", "Victor M. Zavala"], "Categories": "cs.LG physics.chem-ph q-bio.BM"}, "abstract": "Graph Neural Networks (GNNs) have emerged as a prominent class of data-driven methods for molecular property prediction. However, a key limitation of typical GNN models is their inability to quantify uncertainties in the predictions. This capability is crucial for ensuring the trustworthy use and deployment of models in downstream tasks. To that end, we introduce AutoGNNUQ, an automated uncertainty quantification (UQ) approach for molecular property prediction. AutoGNNUQ leverages architecture search to generate an ensemble of high-performing GNNs, enabling the estimation of predictive uncertainties. Our approach employs variance decomposition to separate data (aleatoric) and model (epistemic) uncertainties, providing valuable insights for reducing them. In our computational experiments, we demonstrate that AutoGNNUQ outperforms existing UQ methods in terms of both prediction accuracy and UQ performance on multiple benchmark datasets. Additionally, we utilize t-SNE visualization to explore correlations between molecular features and uncertainty, offering insight for dataset improvement. AutoGNNUQ has broad applicability in domains such as drug discovery and materials science, where accurate uncertainty quantification is crucial for decision-making.", "url": "https://arxiv.org/abs/2307.10438"}, {"metadata": {"arXiv": "2307.10440", "Date": "Wed, 19 Jul 2023 20:11:30 ", "Title": "Confidence Estimation Using Unlabeled Data", "Authors": ["Chen Li", "Xiaoling Hu", "Chao Chen"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by ICLR'23"]}, "abstract": "Overconfidence is a common issue for deep neural networks, limiting their deployment in real-world applications. To better estimate confidence, existing methods mostly focus on fully-supervised scenarios and rely on training labels. In this paper, we propose the first confidence estimation method for a semi-supervised setting, when most training labels are unavailable. We stipulate that even with limited training labels, we can still reasonably approximate the confidence of model on unlabeled samples by inspecting the prediction consistency through the training process. We use training consistency as a surrogate function and propose a consistency ranking loss for confidence estimation. On both image classification and segmentation tasks, our method achieves state-of-the-art performances in confidence estimation. Furthermore, we show the benefit of the proposed method through a downstream active learning task. The code is available at https://github.com/TopoXLab/consistency-ranking-loss", "url": "https://arxiv.org/abs/2307.10440"}, {"metadata": {"arXiv": "2307.10492", "Date": "Wed, 19 Jul 2023 23:05:49 ", "Title": "Blockchain-Based Federated Learning: Incentivizing Data Sharing and Penalizing Dishonest Behavior", "Authors": ["Amir Jaberzadeh", "Ajay Kumar Shrestha", "Faijan Ahamad Khan", "Mohammed Afaan Shaikh", "Bhargav Dave and Jason Geng"], "Categories": "cs.LG", "Comments": ["To appear in the 5th International Congress on Blockchain and Applications (BLOCKCHAIN'23). Publish by the Lecture Notes in Networks and Systems series of Springer Verlag"]}, "abstract": "With the increasing importance of data sharing for collaboration and innovation, it is becoming more important to ensure that data is managed and shared in a secure and trustworthy manner. Data governance is a common approach to managing data, but it faces many challenges such as data silos, data consistency, privacy, security, and access control. To address these challenges, this paper proposes a comprehensive framework that integrates data trust in federated learning with InterPlanetary File System, blockchain, and smart contracts to facilitate secure and mutually beneficial data sharing while providing incentives, access control mechanisms, and penalizing any dishonest behavior. The experimental results demonstrate that the proposed model is effective in improving the accuracy of federated learning models while ensuring the security and fairness of the data-sharing process. The research paper also presents a decentralized federated learning platform that successfully trained a CNN model on the MNIST dataset using blockchain technology. The platform enables multiple workers to train the model simultaneously while maintaining data privacy and security. The decentralized architecture and use of blockchain technology allow for efficient communication and coordination between workers. This platform has the potential to facilitate decentralized machine learning and support privacy-preserving collaboration in various domains.", "url": "https://arxiv.org/abs/2307.10492"}, {"metadata": {"arXiv": "2307.10495", "Date": "Wed, 19 Jul 2023 23:25:21 ", "Title": "Novel Batch Active Learning Approach and Its Application to Synthetic Aperture Radar Datasets", "Authors": ["James Chapman", "Bohan Chen", "Zheng Tan", "Jeff Calder", "Kevin Miller", "Andrea L. Bertozzi"], "Categories": "cs.LG cs.CV eess.SP", "Comments": ["16 pages", "7 figures", "Preprint"], "ACM-class": "I.2.6; I.2.10; I.4.0; I.4.9", "Journal-ref": "Proc. SPIE. Algorithms for Synthetic Aperture Radar Imagery XXX (Vol. 12520, pp. 96-111). 13 June 2023", "DOI": "10.1117/12.2662393"}, "abstract": "Active learning improves the performance of machine learning methods by judiciously selecting a limited number of unlabeled data points to query for labels, with the aim of maximally improving the underlying classifier's performance. Recent gains have been made using sequential active learning for synthetic aperture radar (SAR) data arXiv:2204.00005. In each iteration, sequential active learning selects a query set of size one while batch active learning selects a query set of multiple datapoints. While batch active learning methods exhibit greater efficiency, the challenge lies in maintaining model accuracy relative to sequential active learning methods. We developed a novel, two-part approach for batch active learning: Dijkstra's Annulus Core-Set (DAC) for core-set generation and LocalMax for batch sampling. The batch active learning process that combines DAC and LocalMax achieves nearly identical accuracy as sequential active learning but is more efficient, proportional to the batch size. As an application, a pipeline is built based on transfer learning feature embedding, graph learning, DAC, and LocalMax to classify the FUSAR-Ship and OpenSARShip datasets. Our pipeline outperforms the state-of-the-art CNN-based methods.", "url": "https://arxiv.org/abs/2307.10495"}, {"metadata": {"arXiv": "2307.10496", "Date": "Wed, 19 Jul 2023 23:29:40 ", "Title": "A Competitive Learning Approach for Specialized Models: A Solution for Complex Physical Systems with Distinct Functional Regimes", "Authors": ["Okezzi F. Ukorigho and Opeoluwa Owoyele"], "Categories": "cs.LG math.DS"}, "abstract": "Complex systems in science and engineering sometimes exhibit behavior that changes across different regimes. Traditional global models struggle to capture the full range of this complex behavior, limiting their ability to accurately represent the system. In response to this challenge, we propose a novel competitive learning approach for obtaining data-driven models of physical systems. The primary idea behind the proposed approach is to employ dynamic loss functions for a set of models that are trained concurrently on the data. Each model competes for each observation during training, allowing for the identification of distinct functional regimes within the dataset. To demonstrate the effectiveness of the learning approach, we coupled it with various regression methods that employ gradient-based optimizers for training. The proposed approach was tested on various problems involving model discovery and function approximation, demonstrating its ability to successfully identify functional regimes, discover true governing equations, and reduce test errors.", "url": "https://arxiv.org/abs/2307.10496"}, {"metadata": {"arXiv": "2307.10507", "Date": "Thu, 20 Jul 2023 00:07:29 ", "Title": "FedSoup: Improving Generalization and Personalization in Federated Learning via Selective Model Interpolation", "Authors": ["Minghui Chen", "Meirui Jiang", "Qi Dou", "Zehua Wang", "Xiaoxiao Li"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by MICCAI2023"]}, "abstract": "Cross-silo federated learning (FL) enables the development of machine learning models on datasets distributed across data centers such as hospitals and clinical research laboratories. However, recent research has found that current FL algorithms face a trade-off between local and global performance when confronted with distribution shifts. Specifically, personalized FL methods have a tendency to overfit to local data, leading to a sharp valley in the local model and inhibiting its ability to generalize to out-of-distribution data. In this paper, we propose a novel federated model soup method (i.e., selective interpolation of model parameters) to optimize the trade-off between local and global performance. Specifically, during the federated training phase, each client maintains its own global model pool by monitoring the performance of the interpolated model between the local and global models. This allows us to alleviate overfitting and seek flat minima, which can significantly improve the model's generalization performance. We evaluate our method on retinal and pathological image classification tasks, and our proposed method achieves significant improvements for out-of-distribution generalization. Our code is available at https://github.com/ubc-tea/FedSoup.", "url": "https://arxiv.org/abs/2307.10507"}, {"metadata": {"arXiv": "2307.10524", "Date": "Thu, 20 Jul 2023 01:56:10 ", "Title": "Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions", "Authors": ["Tongxin Li", "Yiheng Lin", "Shaolei Ren and Adam Wierman"], "Categories": "cs.LG cs.PF", "Comments": ["27 pages"]}, "abstract": "We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice.", "url": "https://arxiv.org/abs/2307.10524"}, {"metadata": {"arXiv": "2307.10562", "Date": "Thu, 20 Jul 2023 03:56:04 ", "Title": "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples", "Authors": ["Shaokui Wei", "Mingda Zhang", "Hongyuan Zha", "Baoyuan Wu"], "Categories": "cs.LG cs.CR"}, "abstract": "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense.", "url": "https://arxiv.org/abs/2307.10562"}, {"metadata": {"arXiv": "2307.10579", "Date": "Thu, 20 Jul 2023 04:45:59 ", "Title": "SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning", "Authors": ["Ziyao Ren", "Yan Kang", "Lixin Fan", "Linghua Yang", "Tao Fan", "Yongxin Tong and Qiang Yang"], "Categories": "cs.LG cs.CR"}, "abstract": "SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting. It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability. However, SecureBoost suffers from high computational complexity and risk of label leakage. To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy. Existing methods either set hyperparameters empirically or heuristically, which are far from optimal. To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage. We design measurements of the three objectives. In particular, the privacy leakage is measured using our proposed instance clustering attack. Experimental results demonstrate that the CMOSB yields not only hyperparameters superior to the baseline but also optimal sets of hyperparameters that can support the flexible requirements of FL participants.", "url": "https://arxiv.org/abs/2307.10579"}, {"metadata": {"arXiv": "2307.10580", "Date": "Thu, 20 Jul 2023 04:46:34 ", "Title": "Intelligent model for offshore China sea fog forecasting", "Authors": ["Yanfei Xiang", "Qinghong Zhang", "Mingqing Wang", "Ruixue Xia", "Yang Kong", "Xiaomeng Huang"], "Categories": "cs.LG physics.ao-ph", "Comments": ["19 pages", "9 figures"]}, "abstract": "Accurate and timely prediction of sea fog is very important for effectively managing maritime and coastal economic activities. Given the intricate nature and inherent variability of sea fog, traditional numerical and statistical forecasting methods are often proven inadequate. This study aims to develop an advanced sea fog forecasting method embedded in a numerical weather prediction model using the Yangtze River Estuary (YRE) coastal area as a case study. Prior to training our machine learning model, we employ a time-lagged correlation analysis technique to identify key predictors and decipher the underlying mechanisms driving sea fog occurrence. In addition, we implement ensemble learning and a focal loss function to address the issue of imbalanced data, thereby enhancing the predictive ability of our model. To verify the accuracy of our method, we evaluate its performance using a comprehensive dataset spanning one year, which encompasses both weather station observations and historical forecasts. Remarkably, our machine learning-based approach surpasses the predictive performance of two conventional methods, the weather research and forecasting nonhydrostatic mesoscale model (WRF-NMM) and the algorithm developed by the National Oceanic and Atmospheric Administration (NOAA) Forecast Systems Laboratory (FSL). Specifically, in regard to predicting sea fog with a visibility of less than or equal to 1 km with a lead time of 60 hours, our methodology achieves superior results by increasing the probability of detection (POD) while simultaneously reducing the false alarm ratio (FAR).", "url": "https://arxiv.org/abs/2307.10580"}, {"metadata": {"arXiv": "2307.10586", "Date": "Thu, 20 Jul 2023 05:00:13 ", "Title": "A Holistic Assessment of the Reliability of Machine Learning Systems", "Authors": ["Anthony Corso", "David Karamadian", "Romeo Valentin", "Mary Cooper", "Mykel J. Kochenderfer"], "Categories": "cs.LG"}, "abstract": "As machine learning (ML) systems increasingly permeate high-stakes settings such as healthcare, transportation, military, and national security, concerns regarding their reliability have emerged. Despite notable progress, the performance of these systems can significantly diminish due to adversarial attacks or environmental changes, leading to overconfident predictions, failures to detect input faults, and an inability to generalize in unexpected scenarios. This paper proposes a holistic assessment methodology for the reliability of ML systems. Our framework evaluates five key properties: in-distribution accuracy, distribution-shift robustness, adversarial robustness, calibration, and out-of-distribution detection. A reliability score is also introduced and used to assess the overall system reliability. To provide insights into the performance of different algorithmic approaches, we identify and categorize state-of-the-art techniques, then evaluate a selection on real-world tasks using our proposed reliability metrics and reliability score. Our analysis of over 500 models reveals that designing for one metric does not necessarily constrain others but certain algorithmic techniques can improve reliability across multiple metrics simultaneously. This study contributes to a more comprehensive understanding of ML reliability and provides a roadmap for future research and development.", "url": "https://arxiv.org/abs/2307.10586"}, {"metadata": {"arXiv": "2307.10596", "Date": "Thu, 20 Jul 2023 05:23:49 ", "Title": "Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis", "Authors": ["Tin Lai", "Farnaz Farid", "Abubakar Bello", "Fariza Sabrina"], "Categories": "cs.LG cs.SI stat.ML"}, "abstract": "The Internet of Things (IoT) integrates more than billions of intelligent devices over the globe with the capability of communicating with other connected devices with little to no human intervention. IoT enables data aggregation and analysis on a large scale to improve life quality in many domains. In particular, data collected by IoT contain a tremendous amount of information for anomaly detection. The heterogeneous nature of IoT is both a challenge and an opportunity for cybersecurity. Traditional approaches in cybersecurity monitoring often require different kinds of data pre-processing and handling for various data types, which might be problematic for datasets that contain heterogeneous features. However, heterogeneous types of network devices can often capture a more diverse set of signals than a single type of device readings, which is particularly useful for anomaly detection. In this paper, we present a comprehensive study on using ensemble machine learning methods for enhancing IoT cybersecurity via anomaly detection. Rather than using one single machine learning model, ensemble learning combines the predictive power from multiple models, enhancing their predictive accuracy in heterogeneous datasets rather than using one single machine learning model. We propose a unified framework with ensemble learning that utilises Bayesian hyperparameter optimisation to adapt to a network environment that contains multiple IoT sensor readings. Experimentally, we illustrate their high predictive power when compared to traditional methods.", "url": "https://arxiv.org/abs/2307.10596"}, {"metadata": {"arXiv": "2307.10644", "Date": "Thu, 20 Jul 2023 07:14:58 ", "Title": "Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions", "Authors": ["Frank Nielsen"], "Categories": "cs.LG stat.ML", "Comments": ["25 pages"], "Journal-ref": "2nd Annual Topology, Algebra, and Geometry in Machine Learning Workshop, ICML TAG-ML, 2023"}, "abstract": "Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few. In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them. The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases. In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions. Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of centered normal distributions. We show that the projective Hilbert distance on the cone yields a metric on the embedded normal submanifold and we pullback that cone distance with its associated straight line Hilbert cone geodesics to obtain a distance and smooth paths between normal distributions. Compared to the Fisher-Rao distance approximation, the pullback Hilbert cone distance is computationally light since it requires to compute only the extreme minimal and maximal eigenvalues of matrices. Finally, we show how to use those distances in clustering tasks.", "url": "https://arxiv.org/abs/2307.10644"}, {"metadata": {"arXiv": "2307.10653", "Date": "Thu, 20 Jul 2023 07:33:36 ", "Title": "Refining the Optimization Target for Automatic Univariate Time Series Anomaly Detection in Monitoring Services", "Authors": ["Manqing Dong and Zhanxiang Zhao and Yitong Geng and Wentao Li and Wei Wang and Huai Jiang"], "Categories": "cs.LG", "Comments": ["Accepted by 2023 IJCAI Workshop"]}, "abstract": "Time series anomaly detection is crucial for industrial monitoring services that handle a large volume of data, aiming to ensure reliability and optimize system performance. Existing methods often require extensive labeled resources and manual parameter selection, highlighting the need for automation. This paper proposes a comprehensive framework for automatic parameter optimization in time series anomaly detection models. The framework introduces three optimization targets: prediction score, shape score, and sensitivity score, which can be easily adapted to different model backbones without prior knowledge or manual labeling efforts. The proposed framework has been successfully applied online for over six months, serving more than 50,000 time series every minute. It simplifies the user's experience by requiring only an expected sensitive value, offering a user-friendly interface, and achieving desired detection results. Extensive evaluations conducted on public datasets and comparison with other methods further confirm the effectiveness of the proposed framework.", "url": "https://arxiv.org/abs/2307.10653"}, {"metadata": {"arXiv": "2307.10654", "Date": "Thu, 20 Jul 2023 07:35:15 ", "Title": "Conditional expectation network for SHAP", "Authors": ["Ronald Richman and Mario V. W\\\"uthrich"], "Categories": "cs.LG cs.CE stat.AP stat.ML", "Comments": ["24 pages", "9 figures"], "MSC-class": "62J10, 62J12", "ACM-class": "I.6.4; I.2.6; G.3"}, "abstract": "A very popular model-agnostic technique for explaining predictive models is the SHapley Additive exPlanation (SHAP). The two most popular versions of SHAP are a conditional expectation version and an unconditional expectation version (the latter is also known as interventional SHAP). Except for tree-based methods, usually the unconditional version is used (for computational reasons). We provide a (surrogate) neural network approach which allows us to efficiently calculate the conditional version for both neural networks and other regression models, and which properly considers the dependence structure in the feature components. This proposal is also useful to provide drop1 and anova analyses in complex regression models which are similar to their generalized linear model (GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart that considers the right dependence structure in the feature components.", "url": "https://arxiv.org/abs/2307.10654"}, {"metadata": {"arXiv": "2307.10655", "Date": "Thu, 20 Jul 2023 07:35:42 ", "Title": "A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency", "Authors": ["Jiawei Shao", "Zijian Li", "Wenqiang Sun", "Tailin Zhou", "Yuchang Sun", "Lumin Liu", "Zehong Lin", "Jun Zhang"], "Categories": "cs.LG cs.CR"}, "abstract": "Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties. Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share privacy-preserving information without exposing private datasets. This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants. Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works. However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information. In this paper, we present a systematic survey from a new perspective, i.e., what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency. This survey differs from previous ones due to four distinct contributions. First, we present a new taxonomy of FL methods in terms of the sharing methods, which includes three categories of shared information: model sharing, synthetic data sharing, and knowledge sharing. Second, we analyze the vulnerability of different sharing methods to privacy attacks and review the defense mechanisms that provide certain privacy guarantees. Third, we conduct extensive experiments to compare the performance and communication overhead of various sharing methods in FL. Besides, we assess the potential privacy leakage through model inversion and membership inference attacks, while comparing the effectiveness of various defense approaches. Finally, we discuss potential deficiencies in current methods and outline future directions for improvement.", "url": "https://arxiv.org/abs/2307.10655"}, {"metadata": {"arXiv": "2307.10677", "Date": "Thu, 20 Jul 2023 07:57:14 ", "Title": "Deep learning for classification of noisy QR codes", "Authors": ["Rebecca Leygonie (LIPADE)", "Sylvain Lobry (LIPADE))", "Laurent Wendling (LIPADE)"], "Categories": "cs.LG cs.CV", "Comments": ["in French language. RFIAP 2022 - Reconnaissance des Formes", "Image", "Apprentissage et Perception", "Jul 2022", "Vannes (Bretagne)", "France"]}, "abstract": "We wish to define the limits of a classical classification model based on deep learning when applied to abstract images, which do not represent visually identifiable objects.QR codes (Quick Response codes) fall into this category of abstract images: one bit corresponding to one encoded character, QR codes were not designed to be decoded manually. To understand the limitations of a deep learning-based model for abstract image classification, we train an image classification model on QR codes generated from information obtained when reading a health pass. We compare a classification model with a classical (deterministic) decoding method in the presence of noise. This study allows us to conclude that a model based on deep learning can be relevant for the understanding of abstract images.", "url": "https://arxiv.org/abs/2307.10677"}, {"metadata": {"arXiv": "2307.10703", "Date": "Thu, 20 Jul 2023 08:50:16 ", "Title": "Graphs in State-Space Models for Granger Causality in Climate Science", "Authors": ["V\\'ictor Elvira", "\\'Emilie Chouzenoux", "Jordi Cerd\\`a", "Gustau Camps-Valls"], "Categories": "cs.LG", "Comments": ["4 pages", "2 figures", "3 tables", "CausalStats23: When Causal Inference meets Statistical Analysis", "April 17-21", "2023", "Paris", "France"]}, "abstract": "Granger causality (GC) is often considered not an actual form of causality. Still, it is arguably the most widely used method to assess the predictability of a time series from another one. Granger causality has been widely used in many applied disciplines, from neuroscience and econometrics to Earth sciences. We revisit GC under a graphical perspective of state-space models. For that, we use GraphEM, a recently presented expectation-maximisation algorithm for estimating the linear matrix operator in the state equation of a linear-Gaussian state-space model. Lasso regularisation is included in the M-step, which is solved using a proximal splitting Douglas-Rachford algorithm. Experiments in toy examples and challenging climate problems illustrate the benefits of the proposed model and inference technique over standard Granger causality methods.", "url": "https://arxiv.org/abs/2307.10703"}, {"metadata": {"arXiv": "2307.10704", "Date": "Thu, 20 Jul 2023 08:53:16 ", "Title": "Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits", "Authors": ["Sharyal Zafar (ENS Rennes", "SATIE)", "Rapha\\\"el Feraud", "Anne Blavette (ENS Rennes", "SATIE)", "Guy Camilleri (UT3", "IRIT)", "Hamid Ben (SATIE", "ENS Rennes)"], "Categories": "cs.LG", "Journal-ref": "CIRED 2023 International Conference \\& Exhibition on Electricity Distribution, Jun 2023, Rome, Italy"}, "abstract": "The drastic growth of electric vehicles and photovoltaics can introduce new challenges, such as electrical current congestion and voltage limit violations due to peak load demands. These issues can be mitigated by controlling the operation of electric vehicles i.e., smart charging. Centralized smart charging solutions have already been proposed in the literature. But such solutions may lack scalability and suffer from inherent drawbacks of centralization, such as a single point of failure, and data privacy concerns. Decentralization can help tackle these challenges. In this paper, a fully decentralized smart charging system is proposed using the philosophy of adaptive multi-agent systems. The proposed system utilizes multi-armed bandit learning to handle uncertainties in the system. The presented system is decentralized, scalable, real-time, model-free, and takes fairness among different players into account. A detailed case study is also presented for performance evaluation.", "url": "https://arxiv.org/abs/2307.10704"}, {"metadata": {"arXiv": "2307.10710", "Date": "Thu, 20 Jul 2023 09:05:46 ", "Title": "Reparameterized Policy Learning for Multimodal Trajectory Optimization", "Authors": ["Zhiao Huang", "Litian Liang", "Zhan Ling", "Xuanlin Li", "Chuang Gan", "Hao Su"], "Categories": "cs.LG"}, "abstract": "We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces. Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization. To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories. By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment. We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency. Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward. Our method consistently outperforms previous approaches across a range of tasks. Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/", "url": "https://arxiv.org/abs/2307.10710"}, {"metadata": {"arXiv": "2307.10718", "Date": "Thu, 20 Jul 2023 09:24:23 ", "Title": "Differences Between Hard and Noisy-labeled Samples: An Empirical Study", "Authors": ["Mahsa Forouzesh and Patrick Thiran"], "Categories": "cs.LG"}, "abstract": "Extracting noisy or incorrectly labeled samples from a labeled dataset with hard/difficult samples is an important yet under-explored topic. Two general and often independent lines of work exist, one focuses on addressing noisy labels, and another deals with hard samples. However, when both types of data are present, most existing methods treat them equally, which results in a decline in the overall performance of the model. In this paper, we first design various synthetic datasets with custom hardness and noisiness levels for different samples. Our proposed systematic empirical study enables us to better understand the similarities and more importantly the differences between hard-to-learn samples and incorrectly-labeled samples. These controlled experiments pave the way for the development of methods that distinguish between hard and noisy samples. Through our study, we introduce a simple yet effective metric that filters out noisy-labeled samples while keeping the hard samples. We study various data partitioning methods in the presence of label noise and observe that filtering out noisy samples from hard samples with this proposed metric results in the best datasets as evidenced by the high test accuracy achieved after models are trained on the filtered datasets. We demonstrate this for both our created synthetic datasets and for datasets with real-world label noise. Furthermore, our proposed data partitioning method significantly outperforms other methods when employed within a semi-supervised learning framework.", "url": "https://arxiv.org/abs/2307.10718"}, {"metadata": {"arXiv": "2307.10736", "Date": "Thu, 20 Jul 2023 10:03:50 ", "Title": "Long-Tail Theory under Gaussian Mixtures", "Authors": ["Arman Bolatov", "Maxat Tezekbayev", "Igor Melnykov", "Artur Pak", "Vassilina Nikoulina and Zhenisbek Assylbekov"], "Categories": "cs.LG stat.ML", "Comments": ["accepted to ECAI 2023"]}, "abstract": "We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory (2020). We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can. This confirms that for long-tailed distributions, rare training examples must be considered for optimal generalization to new data. Finally, we show that the performance gap between linear and nonlinear models can be lessened as the tail becomes shorter in the subpopulation frequency distribution, as confirmed by experiments on synthetic and real data.", "url": "https://arxiv.org/abs/2307.10736"}, {"metadata": {"arXiv": "2307.10779", "Date": "Thu, 20 Jul 2023 11:29:17 ", "Title": "Efficient Beam Tree Recursion", "Authors": ["Jishnu Ray Chowdhury", "Cornelia Caragea"], "Categories": "cs.LG"}, "abstract": "Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{d}$ into a sequence contextualizer of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{n \\times d}$. Thus, our proposals not only open up a path for further scalability of RvNNs but also standardize a way to use BT-RvNNs as another building block in the deep learning toolkit that can be easily stacked or interfaced with other popular models such as Transformers and Structured State Space models.", "url": "https://arxiv.org/abs/2307.10779"}, {"metadata": {"arXiv": "2307.10788", "Date": "Thu, 20 Jul 2023 11:38:55 ", "Title": "Adversarial attacks for mixtures of classifiers", "Authors": ["Lucas Gnecco Heredia", "Benjamin Negrevergne", "Yann Chevaleyre"], "Categories": "cs.LG", "Comments": ["7 pages + 4 pages of appendix. 5 figures in main text"]}, "abstract": "Mixtures of classifiers (a.k.a. randomized ensembles) have been proposed as a way to improve robustness against adversarial attacks. However, it has been shown that existing attacks are not well suited for this kind of classifiers. In this paper, we discuss the problem of attacking a mixture in a principled way and introduce two desirable properties of attacks based on a geometrical analysis of the problem (effectiveness and maximality). We then show that existing attacks do not meet both of these properties. Finally, we introduce a new attack called lattice climber attack with theoretical guarantees on the binary linear setting, and we demonstrate its performance by conducting experiments on synthetic and real datasets.", "url": "https://arxiv.org/abs/2307.10788"}, {"metadata": {"arXiv": "2307.10803", "Date": "Thu, 20 Jul 2023 12:12:05 ", "Title": "Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and Opportunities", "Authors": ["Hanchen Yang and Wengen Li and Shuyu Wang and Hui Li and Jihong Guan and Shuigeng Zhou and Jiannong Cao"], "Categories": "cs.LG physics.ao-ph"}, "abstract": "With the increasing amount of spatial-temporal~(ST) ocean data, numerous spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, e.g., climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data is more complicated with some unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models. Unfortunately, an overview of these studies is still missing, hindering computer scientists to identify the research issues in ocean while discouraging researchers in ocean science from applying advanced STDM techniques. To remedy this situation, we provide a comprehensive survey to summarize existing STDM studies in ocean. Concretely, we first summarize the widely-used ST ocean datasets and identify their unique characteristics. Then, typical ST ocean data quality enhancement techniques are discussed. Next, we classify existing STDM studies for ocean into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks. Finally, promising research opportunities are highlighted. This survey will help scientists from the fields of both computer science and ocean science have a better understanding of the fundamental concepts, key techniques, and open challenges of STDM in ocean.", "url": "https://arxiv.org/abs/2307.10803"}, {"metadata": {"arXiv": "2307.10843", "Date": "Thu, 20 Jul 2023 13:04:26 ", "Title": "Global Precipitation Nowcasting of Integrated Multi-satellitE Retrievals for GPM: A U-Net Convolutional LSTM Architecture", "Authors": ["Reyhaneh Rahimi", "Ardeshir Ebtehaj", "Ali Behrangi", "Jackson Tan"], "Categories": "cs.LG cs.CV physics.ao-ph"}, "abstract": "This paper presents a deep learning architecture for nowcasting of precipitation almost globally every 30 min with a 4-hour lead time. The architecture fuses a U-Net and a convolutional long short-term memory (LSTM) neural network and is trained using data from the Integrated MultisatellitE Retrievals for GPM (IMERG) and a few key precipitation drivers from the Global Forecast System (GFS). The impacts of different training loss functions, including the mean-squared error (regression) and the focal-loss (classification), on the quality of precipitation nowcasts are studied. The results indicate that the regression network performs well in capturing light precipitation (below 1.6 mm/hr), but the classification network can outperform the regression network for nowcasting of precipitation extremes (>8 mm/hr), in terms of the critical success index (CSI).. Using the Wasserstein distance, it is shown that the predicted precipitation by the classification network has a closer class probability distribution to the IMERG than the regression network. It is uncovered that the inclusion of the physical variables can improve precipitation nowcasting, especially at longer lead times in both networks. Taking IMERG as a relative reference, a multi-scale analysis in terms of fractions skill score (FSS), shows that the nowcasting machine remains skillful (FSS > 0.5) at the resolution of 10 km compared to 50 km for GFS. For precipitation rates greater than 4~mm/hr, only the classification network remains FSS-skillful on scales greater than 50 km within a 2-hour lead time.", "url": "https://arxiv.org/abs/2307.10843"}, {"metadata": {"arXiv": "2307.10845", "Date": "Thu, 20 Jul 2023 13:07:41 ", "Title": "Self-paced Weight Consolidation for Continual Learning", "Authors": ["Wei Cong", "Yang Cong", "Gan Sun", "Yuyang Liu", "Jiahua Dong"], "Categories": "cs.LG cs.CV"}, "abstract": "Continual learning algorithms which keep the parameters of new tasks close to that of previous tasks, are popular in preventing catastrophic forgetting in sequential task learning settings. However, 1) the performance for the new continual learner will be degraded without distinguishing the contributions of previously learned tasks; 2) the computational cost will be greatly increased with the number of tasks, since most existing algorithms need to regularize all previous tasks when learning new tasks. To address the above challenges, we propose a self-paced Weight Consolidation (spWC) framework to attain robust continual learning via evaluating the discriminative contributions of previous tasks. To be specific, we develop a self-paced regularization to reflect the priorities of past tasks via measuring difficulty based on key performance indicator (i.e., accuracy). When encountering a new task, all previous tasks are sorted from \"difficult\" to \"easy\" based on the priorities. Then the parameters of the new continual learner will be learned via selectively maintaining the knowledge amongst more difficult past tasks, which could well overcome catastrophic forgetting with less computational cost. We adopt an alternative convex search to iteratively update the model parameters and priority weights in the bi-convex formulation. The proposed spWC framework is plug-and-play, which is applicable to most continual learning algorithms (e.g., EWC, MAS and RCIL) in different directions (e.g., classification and segmentation). Experimental results on several public benchmark datasets demonstrate that our proposed framework can effectively improve performance when compared with other popular continual learning algorithms.", "url": "https://arxiv.org/abs/2307.10845"}, {"metadata": {"arXiv": "2307.10865", "Date": "Thu, 20 Jul 2023 13:34:11 ", "Title": "Addressing caveats of neural persistence with deep graph persistence", "Authors": ["Leander Girrbach", "Anders Christensen", "Ole Winther", "Zeynep Akata", "A. Sophia Koepke"], "Categories": "cs.LG stat.ML"}, "abstract": "Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at https://github.com/ExplainableML/Deep-Graph-Persistence .", "url": "https://arxiv.org/abs/2307.10865"}, {"metadata": {"arXiv": "2307.10869", "Date": "Thu, 20 Jul 2023 13:41:26 ", "Title": "Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection", "Authors": ["Wenwei Gu", "Jinyang Liu", "Zhuangbin Chen", "Jianping Zhang", "Yuxin Su", "Jiazhen Gu", "Cong Feng", "Zengyin Yang and Michael Lyu"], "Categories": "cs.LG cs.SE"}, "abstract": "Performance issues permeate large-scale cloud service systems, which can lead to huge revenue losses. To ensure reliable performance, it's essential to accurately identify and localize these issues using service monitoring metrics. Given the complexity and scale of modern cloud systems, this task can be challenging and may require extensive expertise and resources beyond the capacity of individual humans. Some existing methods tackle this problem by analyzing each metric independently to detect anomalies. However, this could incur overwhelming alert storms that are difficult for engineers to diagnose manually. To pursue better performance, not only the temporal patterns of metrics but also the correlation between metrics (i.e., relational patterns) should be considered, which can be formulated as a multivariate metrics anomaly detection problem. However, most of the studies fall short of extracting these two types of features explicitly. Moreover, there exist some unlabeled anomalies mixed in the training data, which may hinder the detection performance. To address these limitations, we propose the Relational- Temporal Anomaly Detection Model (RTAnomaly) that combines the relational and temporal information of metrics. RTAnomaly employs a graph attention layer to learn the dependencies among metrics, which will further help pinpoint the anomalous metrics that may cause the anomaly effectively. In addition, we exploit the concept of positive unlabeled learning to address the issue of potential anomalies in the training data. To evaluate our method, we conduct experiments on a public dataset and two industrial datasets. RTAnomaly outperforms all the baseline models by achieving an average F1 score of 0.929 and Hit@3 of 0.920, demonstrating its superiority.", "url": "https://arxiv.org/abs/2307.10869"}, {"metadata": {"arXiv": "2307.10890", "Date": "Thu, 20 Jul 2023 14:10:33 ", "Title": "Player-optimal Stable Regret for Bandit Learning in Matching Markets", "Authors": ["Fang Kong", "Shuai Li"], "Categories": "cs.LG", "Comments": ["SODA 2023"]}, "abstract": "The problem of matching markets has been studied for a long time in the literature due to its wide range of applications. Finding a stable matching is a common equilibrium objective in this problem. Since market participants are usually uncertain of their preferences, a rich line of recent works study the online setting where one-side participants (players) learn their unknown preferences from iterative interactions with the other side (arms). Most previous works in this line are only able to derive theoretical guarantees for player-pessimal stable regret, which is defined compared with the players' least-preferred stable matching. However, under the pessimal stable matching, players only obtain the least reward among all stable matchings. To maximize players' profits, player-optimal stable matching would be the most desirable. Though \\citet{basu21beyond} successfully bring an upper bound for player-optimal stable regret, their result can be exponentially large if players' preference gap is small. Whether a polynomial guarantee for this regret exists is a significant but still open problem. In this work, we provide a new algorithm named explore-then-Gale-Shapley (ETGS) and show that the optimal stable regret of each player can be upper bounded by $O(K\\log T/\\Delta^2)$ where $K$ is the number of arms, $T$ is the horizon and $\\Delta$ is the players' minimum preference gap among the first $N+1$-ranked arms. This result significantly improves previous works which either have a weaker player-pessimal stable matching objective or apply only to markets with special assumptions. When the preferences of participants satisfy some special conditions, our regret upper bound also matches the previously derived lower bound.", "url": "https://arxiv.org/abs/2307.10890"}, {"metadata": {"arXiv": "2307.10892", "Date": "Thu, 20 Jul 2023 14:11:29 ", "Title": "Learning and Generalizing Polynomials in Simulation Metamodeling", "Authors": ["Jesper Hauch", "Christoffer Riis", "Francisco C. Pereira"], "Categories": "cs.LG"}, "abstract": "The ability to learn polynomials and generalize out-of-distribution is essential for simulation metamodels in many disciplines of engineering, where the time step updates are described by polynomials. While feed forward neural networks can fit any function, they cannot generalize out-of-distribution for higher-order polynomials. Therefore, this paper collects and proposes multiplicative neural network (MNN) architectures that are used as recursive building blocks for approximating higher-order polynomials. Our experiments show that MNNs are better than baseline models at generalizing, and their performance in validation is true to their performance in out-of-distribution tests. In addition to MNN architectures, a simulation metamodeling approach is proposed for simulations with polynomial time step updates. For these simulations, simulating a time interval can be performed in fewer steps by increasing the step size, which entails approximating higher-order polynomials. While our approach is compatible with any simulation with polynomial time step updates, a demonstration is shown for an epidemiology simulation model, which also shows the inductive bias in MNNs for learning and generalizing higher-order polynomials.", "url": "https://arxiv.org/abs/2307.10892"}, {"metadata": {"arXiv": "2307.10907", "Date": "Thu, 20 Jul 2023 14:29:51 ", "Title": "The Role of Entropy and Reconstruction in Multi-View Self-Supervised Learning", "Authors": ["Borja Rodr\\'iguez-G\\'alvez", "Arno Blaas", "Pau Rodr\\'iguez", "Adam Goli\\'nski", "Xavier Suau", "Jason Ramapuram", "Dan Busbridge", "Luca Zappella"], "Categories": "cs.LG", "Comments": ["18 pages: 9 of main text", "2 of references", "and 7 of supplementary material. Appears in the proceedings of ICML 2023"]}, "abstract": "The mechanisms behind the success of multi-view self-supervised learning (MVSSL) are not yet fully understood. Contrastive MVSSL methods have been studied through the lens of InfoNCE, a lower bound of the Mutual Information (MI). However, the relation between other MVSSL methods and MI remains unclear. We consider a different lower bound on the MI consisting of an entropy and a reconstruction term (ER), and analyze the main MVSSL families through its lens. Through this ER bound, we show that clustering-based methods such as DeepCluster and SwAV maximize the MI. We also re-interpret the mechanisms of distillation-based approaches such as BYOL and DINO, showing that they explicitly maximize the reconstruction term and implicitly encourage a stable entropy, and we confirm this empirically. We show that replacing the objectives of common MVSSL methods with this ER bound achieves competitive performance, while making them stable when training with smaller batch sizes or smaller exponential moving average (EMA) coefficients. Github repo: https://github.com/apple/ml-entropy-reconstruction.", "url": "https://arxiv.org/abs/2307.10907"}, {"metadata": {"arXiv": "2307.10923", "Date": "Thu, 20 Jul 2023 14:49:58 ", "Title": "Sequential Multi-Dimensional Self-Supervised Learning for Clinical Time Series", "Authors": ["Aniruddh Raghu", "Payal Chandak", "Ridwan Alam", "John Guttag", "Collin M. Stultz"], "Categories": "cs.LG", "Comments": ["ICML 2023"]}, "abstract": "Self-supervised learning (SSL) for clinical time series data has received significant attention in recent literature, since these data are highly rich and provide important information about a patient's physiological state. However, most existing SSL methods for clinical time series are limited in that they are designed for unimodal time series, such as a sequence of structured features (e.g., lab values and vitals signs) or an individual high-dimensional physiological signal (e.g., an electrocardiogram). These existing methods cannot be readily extended to model time series that exhibit multimodality, with structured features and high-dimensional data being recorded at each timestep in the sequence. In this work, we address this gap and propose a new SSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is applied both at the level of the entire sequence and at the level of the individual high-dimensional data points in the sequence in order to better capture information at both scales. Our strategy is agnostic to the specific form of loss function used at each level -- it can be contrastive, as in SimCLR, or non-contrastive, as in VICReg. We evaluate our method on two real-world clinical datasets, where the time series contains sequences of (1) high-frequency electrocardiograms and (2) structured data from lab values and vitals signs. Our experimental results indicate that pre-training with our method and then fine-tuning on downstream tasks improves performance over baselines on both datasets, and in several settings, can lead to improvements across different self-supervised loss functions.", "url": "https://arxiv.org/abs/2307.10923"}, {"metadata": {"arXiv": "2307.10981", "Date": "Thu, 20 Jul 2023 16:09:07 ", "Title": "PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks", "Authors": ["Shiwei Ding", "Lan Zhang", "Miao Pan", "Xiaoyong Yuan"], "Categories": "cs.LG cs.CR"}, "abstract": "Collaborative inference has been a promising solution to enable resource-constrained edge devices to perform inference using state-of-the-art deep neural networks (DNNs). In collaborative inference, the edge device first feeds the input to a partial DNN locally and then uploads the intermediate result to the cloud to complete the inference. However, recent research indicates model inversion attacks (MIAs) can reconstruct input data from intermediate results, posing serious privacy concerns for collaborative inference. Existing perturbation and cryptography techniques are inefficient and unreliable in defending against MIAs while performing accurate inference. This paper provides a viable solution, named PATROL, which develops privacy-oriented pruning to balance privacy, efficiency, and utility of collaborative inference. PATROL takes advantage of the fact that later layers in a DNN can extract more task-specific features. Given limited local resources for collaborative inference, PATROL intends to deploy more layers at the edge based on pruning techniques to enforce task-specific features for inference and reduce task-irrelevant but sensitive features for privacy preservation. To achieve privacy-oriented pruning, PATROL introduces two key components: Lipschitz regularization and adversarial reconstruction training, which increase the reconstruction errors by reducing the stability of MIAs and enhance the target inference model by adversarial training, respectively.", "url": "https://arxiv.org/abs/2307.10981"}, {"metadata": {"arXiv": "2307.10988", "Date": "Thu, 20 Jul 2023 16:18:33 ", "Title": "Investigating minimizing the training set fill distance in machine learning regression", "Authors": ["Paolo Climaco and Jochen Garcke"], "Categories": "cs.LG"}, "abstract": "Many machine learning regression methods leverage large datasets for training predictive models. However, using large datasets may not be feasible due to computational limitations or high labelling costs. Therefore, sampling small training sets from large pools of unlabelled data points is essential to maximize model performance while maintaining computational efficiency. In this work, we study a sampling approach aimed to minimize the fill distance of the selected set. We derive an upper bound for the maximum expected prediction error that linearly depends on the training set fill distance, conditional to the knowledge of data features. For empirical validation, we perform experiments using two regression models on two datasets. We empirically show that selecting a training set by aiming to minimize the fill distance, thereby minimizing the bound, significantly reduces the maximum prediction error of various regression models, outperforming existing sampling approaches by a large margin.", "url": "https://arxiv.org/abs/2307.10988"}, {"metadata": {"arXiv": "2307.10997", "Date": "Thu, 20 Jul 2023 16:25:58 ", "Title": "DREAM: Domain-free Reverse Engineering Attributes of Black-box Model", "Authors": ["Rongqing Li", "Jiaqi Yu", "Changsheng Li", "Wenhan Luo", "Ye Yuan", "Guoren Wang"], "Categories": "cs.LG cs.CR"}, "abstract": "Deep learning models are usually black boxes when deployed on machine learning platforms. Prior works have shown that the attributes ($e.g.$, the number of convolutional layers) of a target black-box neural network can be exposed through a sequence of queries. There is a crucial limitation: these works assume the dataset used for training the target model to be known beforehand and leverage this dataset for model attribute attack. However, it is difficult to access the training dataset of the target black-box model in reality. Therefore, whether the attributes of a target black-box model could be still revealed in this case is doubtful. In this paper, we investigate a new problem of Domain-agnostic Reverse Engineering the Attributes of a black-box target Model, called DREAM, without requiring the availability of the target model's training dataset, and put forward a general and principled framework by casting this problem as an out of distribution (OOD) generalization problem. In this way, we can learn a domain-agnostic model to inversely infer the attributes of a target black-box model with unknown training data. This makes our method one of the kinds that can gracefully apply to an arbitrary domain for model attribute reverse engineering with strong generalization ability. Extensive experimental studies are conducted and the results validate the superiority of our proposed method over the baselines.", "url": "https://arxiv.org/abs/2307.10997"}, {"metadata": {"arXiv": "2307.10999", "Date": "Thu, 20 Jul 2023 16:27:51 ", "Title": "Private Federated Learning with Autotuned Compression", "Authors": ["Enayat Ullah", "Christopher A. Choquette-Choo", "Peter Kairouz", "Sewoong Oh"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted to ICML 2023"]}, "abstract": "We propose new techniques for reducing communication in private federated learning without the need for setting or tuning compression rates. Our on-the-fly methods automatically adjust the compression rate based on the error induced during training, while maintaining provable privacy guarantees through the use of secure aggregation and differential privacy. Our techniques are provably instance-optimal for mean estimation, meaning that they can adapt to the ``hardness of the problem\" with minimal interactivity. We demonstrate the effectiveness of our approach on real-world datasets by achieving favorable compression rates without the need for tuning.", "url": "https://arxiv.org/abs/2307.10999"}, {"metadata": {"arXiv": "2307.11007", "Date": "Thu, 20 Jul 2023 16:34:58 ", "Title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization", "Authors": ["Kaiyue Wen", "Tengyu Ma", "Zhiyuan Li"], "Categories": "cs.LG math.OC stat.ML", "Comments": ["34 pages,11 figures"]}, "abstract": "Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve better generalization. This calls for the search for other explanations for the generalization of over-parameterized neural networks.", "url": "https://arxiv.org/abs/2307.11007"}, {"metadata": {"arXiv": "2307.11011", "Date": "Thu, 20 Jul 2023 16:36:04 ", "Title": "Neuron Sensitivity Guided Test Case Selection for Deep Learning Testing", "Authors": ["Dong Huang", "Qingwen Bu", "Yichao Fu", "Yuhao Qing", "Bocheng Xiao", "Heming Cui"], "Categories": "cs.LG cs.SE"}, "abstract": "Deep Neural Networks~(DNNs) have been widely deployed in software to address various tasks~(e.g., autonomous driving, medical diagnosis). However, they could also produce incorrect behaviors that result in financial losses and even threaten human safety. To reveal the incorrect behaviors in DNN and repair them, DNN developers often collect rich unlabeled datasets from the natural world and label them to test the DNN models. However, properly labeling a large number of unlabeled datasets is a highly expensive and time-consuming task. To address the above-mentioned problem, we propose NSS, Neuron Sensitivity guided test case Selection, which can reduce the labeling time by selecting valuable test cases from unlabeled datasets. NSS leverages the internal neuron's information induced by test cases to select valuable test cases, which have high confidence in causing the model to behave incorrectly. We evaluate NSS with four widely used datasets and four well-designed DNN models compared to SOTA baseline methods. The results show that NSS performs well in assessing the test cases' probability of fault triggering and model improvement capabilities. Specifically, compared with baseline approaches, NSS obtains a higher fault detection rate~(e.g., when selecting 5\\% test case from the unlabeled dataset in MNIST \\& LeNet1 experiment, NSS can obtain 81.8\\% fault detection rate, 20\\% higher than baselines).", "url": "https://arxiv.org/abs/2307.11011"}, {"metadata": {"arXiv": "2307.11013", "Date": "Thu, 20 Jul 2023 16:38:18 ", "Title": "Flow Map Learning for Unknown Dynamical Systems: Overview, Implementation, and Benchmarks", "Authors": ["Victor Churchill", "Dongbin Xiu"], "Categories": "cs.LG math.DS stat.ML"}, "abstract": "Flow map learning (FML), in conjunction with deep neural networks (DNNs), has shown promises for data driven modeling of unknown dynamical systems. A remarkable feature of FML is that it is capable of producing accurate predictive models for partially observed systems, even when their exact mathematical models do not exist. In this paper, we present an overview of the FML framework, along with the important computational details for its successful implementation. We also present a set of well defined benchmark problems for learning unknown dynamical systems. All the numerical details of these problems are presented, along with their FML results, to ensure that the problems are accessible for cross-examination and the results are reproducible.", "url": "https://arxiv.org/abs/2307.11013"}, {"metadata": {"arXiv": "2307.11031", "Date": "Thu, 20 Jul 2023 17:07:28 ", "Title": "Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification", "Authors": ["Neel Guha", "Mayee F. Chen", "Kush Bhatia", "Azalia Mirhoseini", "Frederic Sala", "Christopher R\\'e"], "Categories": "cs.LG cs.CL", "Comments": ["38 pages", "22 figures", "8 tables"]}, "abstract": "Recent work has shown that language models' (LMs) prompt-based learning capabilities make them well suited for automating data labeling in domains where manual annotation is expensive. The challenge is that while writing an initial prompt is cheap, improving a prompt is costly -- practitioners often require significant labeled data in order to evaluate the impact of prompt modifications. Our work asks whether it is possible to improve prompt-based learning without additional labeled data. We approach this problem by attempting to modify the predictions of a prompt, rather than the prompt itself. Our intuition is that accurate predictions should also be consistent: samples which are similar under some feature representation should receive the same prompt prediction. We propose Embroid, a method which computes multiple representations of a dataset under different embedding functions, and uses the consistency between the LM predictions for neighboring samples to identify mispredictions. Embroid then uses these neighborhoods to create additional predictions for each sample, and combines these predictions with a simple latent variable graphical model in order to generate a final corrected prediction. In addition to providing a theoretical analysis of Embroid, we conduct a rigorous empirical evaluation across six different LMs and up to 95 different tasks. We find that (1) Embroid substantially improves performance over original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) also realizes improvements for more sophisticated prompting strategies (e.g., chain-of-thought), and (3) can be specialized to domains like law through the embedding functions.", "url": "https://arxiv.org/abs/2307.11031"}, {"metadata": {"arXiv": "2307.11085", "Date": "Thu, 20 Jul 2023 17:59:11 ", "Title": "Representation Learning in Anomaly Detection: Successes, Limits and a Grand Challenge", "Authors": ["Yedid Hoshen"], "Categories": "cs.LG cs.CV", "Comments": ["Keynote talk at the Visual Anomaly and Novelty Detection Workshop", "CVPR'23"]}, "abstract": "In this perspective paper, we argue that the dominant paradigm in anomaly detection cannot scale indefinitely and will eventually hit fundamental limits. This is due to the a no free lunch principle for anomaly detection. These limitations can be overcome when there are strong tasks priors, as is the case for many industrial tasks. When such priors do not exists, the task is much harder for anomaly detection. We pose two such tasks as grand challenges for anomaly detection: i) scientific discovery by anomaly detection ii) a \"mini-grand\" challenge of detecting the most anomalous image in the ImageNet dataset. We believe new anomaly detection tools and ideas would need to be developed to overcome these challenges.", "url": "https://arxiv.org/abs/2307.11085"}, {"metadata": {"arXiv": "2307.10541", "Date": "Thu, 20 Jul 2023 02:42:23 ", "Title": "Differentially Flat Learning-based Model Predictive Control Using a Stability, State, and Input Constraining Safety Filter", "Authors": ["Adam W. Hall and Melissa Greeff and Angela P. Schoellig"], "Categories": "eess.SY cs.LG cs.RO cs.SY", "Comments": ["6 pages", "5 figures", "Published in IEEE Control Systems Letters"], "Journal-ref": "in IEEE Control Systems Letters, vol. 7, pp. 2191-2196, 2023", "DOI": "10.1109/LCSYS.2023.3285616"}, "abstract": "Learning-based optimal control algorithms control unknown systems using past trajectory data and a learned model of the system dynamics. These controllers use either a linear approximation of the learned dynamics, trading performance for faster computation, or nonlinear optimization methods, which typically perform better but can limit real-time applicability. In this work, we present a novel nonlinear controller that exploits differential flatness to achieve similar performance to state-of-the-art learning-based controllers but with significantly less computational effort. Differential flatness is a property of dynamical systems whereby nonlinear systems can be exactly linearized through a nonlinear input mapping. Here, the nonlinear transformation is learned as a Gaussian process and is used in a safety filter that guarantees, with high probability, stability as well as input and flat state constraint satisfaction. This safety filter is then used to refine inputs from a flat model predictive controller to perform constrained nonlinear learning-based optimal control through two successive convex optimizations. We compare our method to state-of-the-art learning-based control strategies and achieve similar performance, but with significantly better computational efficiency, while also respecting flat state and input constraints, and guaranteeing stability.", "url": "https://arxiv.org/abs/2307.10541"}, {"metadata": {"arXiv": "2307.10198", "Date": "Tue, 11 Jul 2023 19:59:54 ", "Title": "Has China caught up to the US in AI research? An exploration of mimetic isomorphism as a model for late industrializers", "Authors": ["Chao Min", "Yi Zhao", "Yi Bu", "Ying Ding", "Caroline S. Wagner"], "Categories": "cs.AI"}, "abstract": "Artificial Intelligence (AI), a cornerstone of 21st-century technology, has seen remarkable growth in China. In this paper, we examine China's AI development process, demonstrating that it is characterized by rapid learning and differentiation, surpassing the export-oriented growth propelled by Foreign Direct Investment seen in earlier Asian industrializers. Our data indicates that China currently leads the USA in the volume of AI-related research papers. However, when we delve into the quality of these papers based on specific metrics, the USA retains a slight edge. Nevertheless, the pace and scale of China's AI development remain noteworthy. We attribute China's accelerated AI progress to several factors, including global trends favoring open access to algorithms and research papers, contributions from China's broad diaspora and returnees, and relatively lax data protection policies. In the vein of our research, we have developed a novel measure for gauging China's imitation of US research. Our analysis shows that by 2018, the time lag between China and the USA in addressing AI research topics had evaporated. This finding suggests that China has effectively bridged a significant knowledge gap and could potentially be setting out on an independent research trajectory. While this study compares China and the USA exclusively, it's important to note that research collaborations between these two nations have resulted in more highly cited work than those produced by either country independently. This underscores the power of international cooperation in driving scientific progress in AI.", "url": "https://arxiv.org/abs/2307.10198"}, {"metadata": {"arXiv": "2307.10221", "Date": "Fri, 14 Jul 2023 21:57:46 ", "Title": "`It is currently hodgepodge'': Examining AI/ML Practitioners' Challenges during Co-production of Responsible AI Values", "Authors": ["Rama Adithya Varanasi", "Nitesh Goyal"], "Categories": "cs.AI cs.HC", "ACM-class": "I.2; K.4", "DOI": "10.1145/3544548.3580903"}, "abstract": "Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures and opportunities to further aid practitioners.", "url": "https://arxiv.org/abs/2307.10221"}, {"metadata": {"arXiv": "2307.10224", "Date": "Sat, 15 Jul 2023 05:45:37 ", "Title": "RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization", "Authors": ["Zhecheng Yuan", "Sizhe Yang", "Pu Hua", "Can Chang", "Kaizhe Hu", "Xiaolong Wang", "Huazhe Xu"], "Categories": "cs.AI"}, "abstract": "Visual Reinforcement Learning (Visual RL), coupled with high-dimensional observations, has consistently confronted the long-standing challenge of generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this area, and lay a foundation for the future creation of universal visual generalization RL agents suitable for real-world scenarios. Access to our code and implemented algorithms is provided at https://gemcollector.github.io/RL-ViGen/.", "url": "https://arxiv.org/abs/2307.10224"}, {"metadata": {"arXiv": "2307.10225", "Date": "Sat, 15 Jul 2023 06:03:35 ", "Title": "First-Order Stable Model Semantics with Intensional Functions", "Authors": ["Michael Bartholomew", "Joohyung Lee"], "Categories": "cs.AI cs.SC", "Comments": ["69 pages"], "Journal-ref": "Artificial Intelligence 273, 56-93, 2019"}, "abstract": "In classical logic, nonBoolean fluents, such as the location of an object, can be naturally described by functions. However, this is not the case in answer set programs, where the values of functions are pre-defined, and nonmonotonicity of the semantics is related to minimizing the extents of predicates but has nothing to do with functions. We extend the first-order stable model semantics by Ferraris, Lee, and Lifschitz to allow intensional functions -- functions that are specified by a logic program just like predicates are specified. We show that many known properties of the stable model semantics are naturally extended to this formalism and compare it with other related approaches to incorporating intensional functions. Furthermore, we use this extension as a basis for defining Answer Set Programming Modulo Theories (ASPMT), analogous to the way that Satisfiability Modulo Theories (SMT) is defined, allowing for SMT-like effective first-order reasoning in the context of ASP. Using SMT solving techniques involving functions, ASPMT can be applied to domains containing real numbers and alleviates the grounding problem. We show that other approaches to integrating ASP and CSP/SMT can be related to special cases of ASPMT in which functions are limited to non-intensional ones.", "url": "https://arxiv.org/abs/2307.10225"}, {"metadata": {"arXiv": "2307.10226", "Date": "Sat, 15 Jul 2023 06:20:43 ", "Title": "On Loop Formulas with Variables", "Authors": ["Joohyung Lee", "Yunsong Meng"], "Categories": "cs.AI", "Comments": ["10 pages. In Proc. Eleventh International Conference on Principles of Knowledge Representation and Reasoning (KR 2008)", "pages 444-453. arXiv admin note: text overlap with arXiv:1401.3898"]}, "abstract": "Recently Ferraris, Lee and Lifschitz proposed a new definition of stable models that does not refer to grounding, which applies to the syntax of arbitrary first-order sentences. We show its relation to the idea of loop formulas with variables by Chen, Lin, Wang and Zhang, and generalize their loop formulas to disjunctive programs and to arbitrary first-order sentences. We also extend the syntax of logic programs to allow explicit quantifiers, and define its semantics as a subclass of the new language of stable models by Ferraris et al. Such programs inherit from the general language the ability to handle nonmonotonic reasoning under the stable model semantics even in the absence of the unique name and the domain closure assumptions, while yielding more succinct loop formulas than the general language due to the restricted syntax. We also show certain syntactic conditions under which query answering for an extended program can be reduced to entailment checking in first-order logic, providing a way to apply first-order theorem provers to reasoning about non-Herbrand stable models.", "url": "https://arxiv.org/abs/2307.10226"}, {"metadata": {"arXiv": "2307.10227", "Date": "Sat, 15 Jul 2023 06:41:08 ", "Title": "Causal Laws and Multi-Valued Fluents", "Authors": ["Enrico Giunchiglia", "Joohyung Lee", "Vladimir Lifschitz", "Hudson Turner"], "Categories": "cs.AI", "Comments": ["7 pages", "In Proceedings of Workshop on Nonmonotonic Reasoning", "Action and Change (NRAC 2001)"]}, "abstract": "This paper continues the line of work on representing properties of actions in nonmonotonic formalisms that stresses the distinction between being \"true\" and being \"caused\", as in the system of causal logic introduced by McCain and Turner and in the action language C proposed by Giunchiglia and Lifschitz. The only fluents directly representable in language C+ are truth-valued fluents, which is often inconvenient. We show that both causal logic and language C can be extended to allow values from arbitrary nonempty sets. Our extension of language C, called C+, also makes it possible to describe actions in terms of their attributes, which is important from the perspective of elaboration tolerance. We describe an embedding of C+ in causal theories with multi-valued constants, relate C+ to Pednault's action language ADL, and show how multi-valued constants can be eliminated in favor of Boolean constants.", "url": "https://arxiv.org/abs/2307.10227"}, {"metadata": {"arXiv": "2307.10250", "Date": "Mon, 17 Jul 2023 07:48:31 ", "Title": "Abductive Reasoning with the GPT-4 Language Model: Case studies from criminal investigation, medical practice, scientific research", "Authors": ["Remo Pareschi"], "Categories": "cs.AI", "Comments": ["The article is 12 pages long and has one figure. It also includes a link to some ChatGPT dialogues that show the experiments that support the article's findings. The article will be published in V. Bambini and C. Barattieri di San Pietro (eds.)", "Sistemi Intelligenti", "Special Section \"Multidisciplinary perspectives on ChatGPT and the family of Large Language Models\""]}, "abstract": "This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology. Using an interactive interview format, the AI assistant demonstrated reliability in generating and selecting hypotheses. It inferred plausible medical diagnoses based on patient data and provided potential causes and explanations in criminology and cosmology. The results highlight the potential of LLMs in complex problem-solving and the need for further research to maximize their practical applications.", "url": "https://arxiv.org/abs/2307.10250"}, {"metadata": {"arXiv": "2307.10315", "Date": "Wed, 19 Jul 2023 03:40:37 ", "Title": "Absolutist AI", "Authors": ["Mitchell Barrington"], "Categories": "cs.AI"}, "abstract": "This paper argues that training AI systems with absolute constraints -- which forbid certain acts irrespective of the amount of value they might produce -- may make considerable progress on many AI safety problems in principle. First, it provides a guardrail for avoiding the very worst outcomes of misalignment. Second, it could prevent AIs from causing catastrophes for the sake of very valuable consequences, such as replacing humans with a much larger number of beings living at a higher welfare level. Third, it makes systems more corrigible, allowing creators to make corrective interventions in them, such as altering their objective functions or shutting them down. And fourth, it helps systems explore their environment more safely by prohibiting them from exploring especially dangerous acts. I offer a decision-theoretic formalization of an absolute constraints, improving on existing models in the literature, and use this model to prove some results about the training and behavior of absolutist AIs. I conclude by showing that, although absolutist AIs will not maximize expected value, they will not be susceptible to behave irrationally, and they will not (contra coherence arguments) face environmental pressure to become expected-value maximizers.", "url": "https://arxiv.org/abs/2307.10315"}, {"metadata": {"arXiv": "2307.10420", "Date": "Wed, 19 Jul 2023 19:14:25 ", "Title": "GOOSE Algorithm: A Powerful Optimization Tool for Real-World Engineering Challenges and Beyond", "Authors": ["Rebwar Khalid Hamad", "Tarik A. Rashid"], "Categories": "cs.AI"}, "abstract": "This study proposes the GOOSE algorithm as a novel metaheuristic algorithm based on the goose's behavior during rest and foraging. The goose stands on one leg and keeps his balance to guard and protect other individuals in the flock. The GOOSE algorithm is benchmarked on 19 well-known benchmark test functions, and the results are verified by a comparative study with genetic algorithm (GA), particle swarm optimization (PSO), dragonfly algorithm (DA), and fitness dependent optimizer (FDO). In addition, the proposed algorithm is tested on 10 modern benchmark functions, and the gained results are compared with three recent algorithms, such as the dragonfly algorithm, whale optimization algorithm (WOA), and salp swarm algorithm (SSA). Moreover, the GOOSE algorithm is tested on 5 classical benchmark functions, and the obtained results are evaluated with six algorithms, such as fitness dependent optimizer (FDO), FOX optimizer, butterfly optimization algorithm (BOA), whale optimization algorithm, dragonfly algorithm, and chimp optimization algorithm (ChOA). The achieved findings attest to the proposed algorithm's superior performance compared to the other algorithms that were utilized in the current study. The technique is then used to optimize Welded beam design and Economic Load Dispatch Problem, three renowned real-world engineering challenges, and the Pathological IgG Fraction in the Nervous System. The outcomes of the engineering case studies illustrate how well the suggested approach can optimize issues that arise in the real-world.", "url": "https://arxiv.org/abs/2307.10420"}, {"metadata": {"arXiv": "2307.10458", "Date": "Wed, 19 Jul 2023 21:04:46 ", "Title": "Complying with the EU AI Act", "Authors": ["Jacintha Walters", "Diptish Dey", "Debarati Bhaumik", "Sophie Horsman"], "Categories": "cs.AI", "ACM-class": "I.2"}, "abstract": "The EU AI Act is the proposed EU legislation concerning AI systems. This paper identifies several categories of the AI Act. Based on this categorization, a questionnaire is developed that serves as a tool to offer insights by creating quantitative data. Analysis of the data shows various challenges for organizations in different compliance categories. The influence of organization characteristics, such as size and sector, is examined to determine the impact on compliance. The paper will also share qualitative data on which questions were prevalent among respondents, both on the content of the AI Act as the application. The paper concludes by stating that there is still room for improvement in terms of compliance with the AIA and refers to a related project that examines a solution to help these organizations.", "url": "https://arxiv.org/abs/2307.10458"}, {"metadata": {"arXiv": "2307.10491", "Date": "Wed, 19 Jul 2023 23:03:50 ", "Title": "Markov Decision Processes with Time-Varying Geometric Discounting", "Authors": ["Jiarui Gan", "Annika Hennes", "Rupak Majumdar", "Debmalya Mandal", "Goran Radanovic"], "Categories": "cs.AI cs.GT", "Comments": ["24 pages", "3 figures"], "Journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence 37(10) (2023) 11980-11988", "DOI": "10.1609/aaai.v37i10.26413"}, "abstract": "Canonical models of Markov decision processes (MDPs) usually consider geometric discounting based on a constant discount factor. While this standard modeling approach has led to many elegant results, some recent studies indicate the necessity of modeling time-varying discounting in certain applications. This paper studies a model of infinite-horizon MDPs with time-varying discount factors. We take a game-theoretic perspective -- whereby each time step is treated as an independent decision maker with their own (fixed) discount factor -- and we study the subgame perfect equilibrium (SPE) of the resulting game as well as the related algorithmic problems. We present a constructive proof of the existence of an SPE and demonstrate the EXPTIME-hardness of computing an SPE. We also turn to the approximate notion of $\\epsilon$-SPE and show that an $\\epsilon$-SPE exists under milder assumptions. An algorithm is presented to compute an $\\epsilon$-SPE, of which an upper bound of the time complexity, as a function of the convergence property of the time-varying discount factor, is provided.", "url": "https://arxiv.org/abs/2307.10491"}, {"metadata": {"arXiv": "2307.10543", "Date": "Thu, 20 Jul 2023 02:48:04 ", "Title": "TREA: Tree-Structure Reasoning Schema for Conversational Recommendation", "Authors": ["Wendi Li", "Wei Wei", "Xiaoye Qu", "Xian-Ling Mao", "Ye Yuan", "Wenfeng Xie", "Dangyang Chen"], "Categories": "cs.AI", "Comments": ["Accepted by ACL2023 main conference"]}, "abstract": "Conversational recommender systems (CRS) aim to timely trace the dynamic interests of users through dialogues and generate relevant responses for item recommendations. Recently, various external knowledge bases (especially knowledge graphs) are incorporated into CRS to enhance the understanding of conversation contexts. However, recent reasoning-based models heavily rely on simplified structures such as linear structures or fixed-hierarchical structures for causality reasoning, hence they cannot fully figure out sophisticated relationships among utterances with external knowledge. To address this, we propose a novel Tree structure Reasoning schEmA named TREA. TREA constructs a multi-hierarchical scalable tree as the reasoning structure to clarify the causal relationships between mentioned entities, and fully utilizes historical conversations to generate more reasonable and suitable responses for recommended results. Extensive experiments on two public CRS datasets have demonstrated the effectiveness of our approach.", "url": "https://arxiv.org/abs/2307.10543"}, {"metadata": {"arXiv": "2307.10551", "Date": "Thu, 20 Jul 2023 03:29:09 ", "Title": "PPN: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts", "Authors": ["Kaiwen Wei", "Jie Yao", "Jingyuan Zhang", "Yangyang Kang", "Fubang Zhao", "Yating Zhang", "Changlong Sun", "Xin Jin", "Xin Zhang"], "Categories": "cs.AI"}, "abstract": "Key Information Extraction (KIE) is a challenging multimodal task that aims to extract structured value semantic entities from visually rich documents. Although significant progress has been made, there are still two major challenges that need to be addressed. Firstly, the layout of existing datasets is relatively fixed and limited in the number of semantic entity categories, creating a significant gap between these datasets and the complex real-world scenarios. Secondly, existing methods follow a two-stage pipeline strategy, which may lead to the error propagation problem. Additionally, they are difficult to apply in situations where unseen semantic entity categories emerge. To address the first challenge, we propose a new large-scale human-annotated dataset named Complex Layout form for key information EXtraction (CLEX), which consists of 5,860 images with 1,162 semantic entity categories. To solve the second challenge, we introduce Parallel Pointer-based Network (PPN), an end-to-end model that can be applied in zero-shot and few-shot scenarios. PPN leverages the implicit clues between semantic entities to assist extracting, and its parallel extraction mechanism allows it to extract multiple results simultaneously and efficiently. Experiments on the CLEX dataset demonstrate that PPN outperforms existing state-of-the-art methods while also offering a much faster inference speed.", "url": "https://arxiv.org/abs/2307.10551"}, {"metadata": {"arXiv": "2307.10573", "Date": "Thu, 20 Jul 2023 04:28:53 ", "Title": "Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting", "Authors": ["Rylan Schaeffer", "Kateryna Pistunova", "Samar Khanna", "Sarthak Consul", "Sanmi Koyejo"], "Categories": "cs.AI", "Comments": ["ICML 2023 Workshop: Knowledge and Logical Reasoning in the Era of Data-driven Learning"]}, "abstract": "Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \\textit{why} such prompting improves performance is unclear. Recent work showed that using logically \\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \\textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \\textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning prompts. We also discover that some CoT prompts used by previous works contain logical errors. This suggests that covariates beyond logically valid reasoning are responsible for performance improvements.", "url": "https://arxiv.org/abs/2307.10573"}, {"metadata": {"arXiv": "2307.10574", "Date": "Thu, 20 Jul 2023 04:31:39 ", "Title": "Adaptive Control of Resource Flow to Optimize Construction Work and Cash Flow via Online Deep Reinforcement Learning", "Authors": ["Can Jiang", "Xin Li", "Jia-Rui Lin", "Ming Liu", "Zhiliang Ma"], "Categories": "cs.AI"}, "abstract": "Due to complexity and dynamics of construction work, resource, and cash flows, poor management of them usually leads to time and cost overruns, bankruptcy, even project failure. Existing approaches in construction failed to achieve optimal control of resource flow in a dynamic environment with uncertainty. Therefore, this paper introducess a model and method to adaptive control the resource flows to optimize the work and cash flows of construction projects. First, a mathematical model based on a partially observable Markov decision process is established to formulate the complex interactions of construction work, resource, and cash flows as well as uncertainty and variability of diverse influence factors. Meanwhile, to efficiently find the optimal solutions, a deep reinforcement learning (DRL) based method is introduced to realize the continuous adaptive optimal control of labor and material flows, thereby optimizing the work and cash flows. To assist the training process of DRL, a simulator based on discrete event simulation is also developed to mimic the dynamic features and external environments of a project. Experiments in simulated scenarios illustrate that our method outperforms the vanilla empirical method and genetic algorithm, possesses remarkable capability in diverse projects and external environments, and a hybrid agent of DRL and empirical method leads to the best result. This paper contributes to adaptive control and optimization of coupled work, resource, and cash flows, and may serve as a step stone for adopting DRL technology in construction project management.", "url": "https://arxiv.org/abs/2307.10574"}, {"metadata": {"arXiv": "2307.10600", "Date": "Thu, 20 Jul 2023 05:43:39 ", "Title": "Challenges and Solutions in AI for All", "Authors": ["Rifat Ara Shams", "Didar Zowghi", "Muneera Bano"], "Categories": "cs.AI", "Comments": ["39 pages", "10 figures", "10 tables"], "MSC-class": "I, I.2"}, "abstract": "Artificial Intelligence (AI)'s pervasive presence and variety necessitate diversity and inclusivity (D&I) principles in its design for fairness, trust, and transparency. Yet, these considerations are often overlooked, leading to issues of bias, discrimination, and perceived untrustworthiness. In response, we conducted a Systematic Review to unearth challenges and solutions relating to D&I in AI. Our rigorous search yielded 48 research articles published between 2017 and 2022. Open coding of these papers revealed 55 unique challenges and 33 solutions for D&I in AI, as well as 24 unique challenges and 23 solutions for enhancing such practices using AI. This study, by offering a deeper understanding of these issues, will enlighten researchers and practitioners seeking to integrate these principles into future AI systems.", "url": "https://arxiv.org/abs/2307.10600"}, {"metadata": {"arXiv": "2307.10680", "Date": "Thu, 20 Jul 2023 08:14:06 ", "Title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings", "Authors": ["Ngoc Luyen Le (Heudiasyc)", "Marie-H\\'el\\`ene Abel (Heudiasyc)", "Philippe Gouspillou"], "Categories": "cs.AI cs.IR", "Journal-ref": "The International Conference on Artificial Intelligence and Computer Vision (AICV2023), Mar 2023, Marrakesh, Morocco. pp.368-378", "DOI": "10.1007/978-3-031-27762-7_35"}, "abstract": "Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies. The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems. By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations. In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain. The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users.", "url": "https://arxiv.org/abs/2307.10680"}, {"metadata": {"arXiv": "2307.10688", "Date": "Thu, 20 Jul 2023 08:30:56 ", "Title": "Bounded Combinatorial Reconfiguration with Answer Set Programming", "Authors": ["Yuya Yamada", "Mutsunori Banbara", "Katsumi Inoue", "Torsten Schaub"], "Categories": "cs.AI", "Comments": ["15 pages"]}, "abstract": "We develop an approach called bounded combinatorial reconfiguration for solving combinatorial reconfiguration problems based on Answer Set Programming (ASP). The general task is to study the solution spaces of source combinatorial problems and to decide whether or not there are sequences of feasible solutions that have special properties. The resulting recongo solver covers all metrics of the solver track in the most recent international competition on combinatorial reconfiguration (CoRe Challenge 2022). recongo ranked first in the shortest metric of the single-engine solvers track. In this paper, we present the design and implementation of bounded combinatorial reconfiguration, and present an ASP encoding of the independent set reconfiguration problem that is one of the most studied combinatorial reconfiguration problems. Finally, we present empirical analysis considering all instances of CoRe Challenge 2022.", "url": "https://arxiv.org/abs/2307.10688"}, {"metadata": {"arXiv": "2307.10693", "Date": "Thu, 20 Jul 2023 08:37:14 ", "Title": "Towards an architectural framework for intelligent virtual agents using probabilistic programming", "Authors": ["Anton Andreev (GIPSA-Services)", "Gr\\'egoire Cattan"], "Categories": "cs.AI cs.HC cs.PL math.PR"}, "abstract": "We present a new framework called KorraAI for conceiving and building embodied conversational agents (ECAs). Our framework models ECAs' behavior considering contextual information, for example, about environment and interaction time, and uncertain information provided by the human interaction partner. Moreover, agents built with KorraAI can show proactive behavior, as they can initiate interactions with human partners. For these purposes, KorraAI exploits probabilistic programming. Probabilistic models in KorraAI are used to model its behavior and interactions with the user. They enable adaptation to the user's preferences and a certain degree of indeterminism in the ECAs to achieve more natural behavior. Human-like internal states, such as moods, preferences, and emotions (e.g., surprise), can be modeled in KorraAI with distributions and Bayesian networks. These models can evolve over time, even without interaction with the user. ECA models are implemented as plugins and share a common interface. This enables ECA designers to focus more on the character they are modeling and less on the technical details, as well as to store and exchange ECA models. Several applications of KorraAI ECAs are possible, such as virtual sales agents, customer service agents, virtual companions, entertainers, or tutors.", "url": "https://arxiv.org/abs/2307.10693"}, {"metadata": {"arXiv": "2307.10719", "Date": "Thu, 20 Jul 2023 09:25:02 ", "Title": "LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?", "Authors": ["David Glukhov", "Ilia Shumailov", "Yarin Gal", "Nicolas Papernot", "Vardan Papyan"], "Categories": "cs.AI cs.CR"}, "abstract": "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated; it should be treated as a security problem which warrants the adaptation of security-based approaches to mitigate potential risks.", "url": "https://arxiv.org/abs/2307.10719"}, {"metadata": {"arXiv": "2307.10832", "Date": "Thu, 20 Jul 2023 12:52:30 ", "Title": "Modifications of the Miller definition of contrastive (counterfactual) explanations", "Authors": ["Kevin McAreavey", "Weiru Liu"], "Categories": "cs.AI", "Comments": ["Accepted by ECSQARU'23"]}, "abstract": "Miller recently proposed a definition of contrastive (counterfactual) explanations based on the well-known Halpern-Pearl (HP) definitions of causes and (non-contrastive) explanations. Crucially, the Miller definition was based on the original HP definition of explanations, but this has since been modified by Halpern; presumably because the original yields counterintuitive results in many standard examples. More recently Borner has proposed a third definition, observing that this modified HP definition may also yield counterintuitive results. In this paper we show that the Miller definition inherits issues found in the original HP definition. We address these issues by proposing two improved variants based on the more robust modified HP and Borner definitions. We analyse our new definitions and show that they retain the spirit of the Miller definition where all three variants satisfy an alternative unified definition that is modular with respect to an underlying definition of non-contrastive explanations. To the best of our knowledge this paper also provides the first explicit comparison between the original and modified HP definitions.", "url": "https://arxiv.org/abs/2307.10832"}, {"metadata": {"arXiv": "2307.10987", "Date": "Thu, 20 Jul 2023 16:18:22 ", "Title": "Characterising Decision Theories with Mechanised Causal Graphs", "Authors": ["Matt MacDermott", "Tom Everitt", "and Francesco Belardinelli"], "Categories": "cs.AI cs.GT"}, "abstract": "How should my own decisions affect my beliefs about the outcomes I expect to achieve? If taking a certain action makes me view myself as a certain type of person, it might affect how I think others view me, and how I view others who are similar to me. This can influence my expected utility calculations and change which action I perceive to be best. Whether and how it should is subject to debate, with contenders for how to think about it including evidential decision theory, causal decision theory, and functional decision theory. In this paper, we show that mechanised causal models can be used to characterise and differentiate the most important decision theories, and generate a taxonomy of different decision theories.", "url": "https://arxiv.org/abs/2307.10987"}, {"metadata": {"arXiv": "2307.10991", "Date": "Thu, 20 Jul 2023 16:21:14 ", "Title": "Dense Sample Deep Learning", "Authors": ["Stephen Jos\\`e Hanson", "Vivek Yadev", "Catherine Hanson"], "Categories": "cs.AI q-bio.NC stat.ML"}, "abstract": "Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this paper, we explore these questions with a large (1.24M weights; VGG) DL in a novel high density sample task (5 unique tokens with at minimum 500 exemplars per token) which allows us to more carefully follow the emergence of category structure and feature construction. We use various visualization methods for following the emergence of the classification and the development of the coupling of feature detectors and structures that provide a type of graphical bootstrapping, From these results we harvest some basic observations of the learning dynamics of DL and propose a new theory of complex feature construction based on our results.", "url": "https://arxiv.org/abs/2307.10991"}, {"metadata": {"arXiv": "2307.10267", "Date": "Mon, 17 Jul 2023 19:04:39 ", "Title": "On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild", "Authors": ["Raiyan Rahman", "Christopher Indris", "Tianxiao Zhang", "Kaidong Li", "Brian McCornack", "Daniel Flippo", "Ajay Sharda", "Guanghui Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Aphid infestations can cause extensive damage to wheat and sorghum fields and spread plant viruses, resulting in significant yield losses in agriculture. To address this issue, farmers often rely on chemical pesticides, which are inefficiently applied over large areas of fields. As a result, a considerable amount of pesticide is wasted on areas without pests, while inadequate amounts are applied to areas with severe infestations. The paper focuses on the urgent need for an intelligent autonomous system that can locate and spray infestations within complex crop canopies, reducing pesticide use and environmental impact. We have collected and labeled a large aphid image dataset in the field, and propose the use of real-time semantic segmentation models to segment clusters of aphids. A multiscale dataset is generated to allow for learning the clusters at different scales. We compare the segmentation speeds and accuracy of four state-of-the-art real-time semantic segmentation models on the aphid cluster dataset, benchmarking them against nonreal-time models. The study results show the effectiveness of a real-time solution, which can reduce inefficient pesticide use and increase crop yields, paving the way towards an autonomous pest detection system.", "url": "https://arxiv.org/abs/2307.10267"}, {"metadata": {"arXiv": "2307.10405", "Date": "Tue, 18 Jul 2023 05:30:23 ", "Title": "Generative Visual Question Answering", "Authors": ["Ethan Shen", "Scotty Singh", "Bhavesh Kumar"], "Categories": "cs.CV cs.AI"}, "abstract": "Multi-modal tasks involving vision and language in deep learning continue to rise in popularity and are leading to the development of newer models that can generalize beyond the extent of their training data. The current models lack temporal generalization which enables models to adapt to changes in future data. This paper discusses a viable approach to creating an advanced Visual Question Answering (VQA) model which can produce successful results on temporal generalization. We propose a new data set, GenVQA, utilizing images and captions from the VQAv2 and MS-COCO dataset to generate new images through stable diffusion. This augmented dataset is then used to test a combination of seven baseline and cutting edge VQA models. Performance evaluation focuses on questions mirroring the original VQAv2 dataset, with the answers having been adjusted to the new images. This paper's purpose is to investigate the robustness of several successful VQA models to assess their performance on future data distributions. Model architectures are analyzed to identify common stylistic choices that improve generalization under temporal distribution shifts. This research highlights the importance of creating a large-scale future shifted dataset. This data can enhance the robustness of VQA models, allowing their future peers to have improved ability to adapt to temporal distribution shifts.", "url": "https://arxiv.org/abs/2307.10405"}, {"metadata": {"arXiv": "2307.10408", "Date": "Wed, 19 Jul 2023 18:37:57 ", "Title": "Explaining Autonomous Driving Actions with Visual Question Answering", "Authors": ["Shahin Atakishiyev", "Mohammad Salameh", "Housam Babiker", "Randy Goebel"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to the 2023 IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC-2023)"]}, "abstract": "The end-to-end learning ability of self-driving vehicles has achieved significant milestones over the last decade owing to rapid advances in deep learning and computer vision algorithms. However, as autonomous driving technology is a safety-critical application of artificial intelligence (AI), road accidents and established regulatory principles necessitate the need for the explainability of intelligent action choices for self-driving vehicles. To facilitate interpretability of decision-making in autonomous driving, we present a Visual Question Answering (VQA) framework, which explains driving actions with question-answering-based causal reasoning. To do so, we first collect driving videos in a simulation environment using reinforcement learning (RL) and extract consecutive frames from this log data uniformly for five selected action categories. Further, we manually annotate the extracted frames using question-answer pairs as justifications for the actions chosen in each scenario. Finally, we evaluate the correctness of the VQA-predicted answers for actions on unseen driving scenes. The empirical results suggest that the VQA mechanism can provide support to interpret real-time decisions of autonomous vehicles and help enhance overall driving safety.", "url": "https://arxiv.org/abs/2307.10408"}, {"metadata": {"arXiv": "2307.10487", "Date": "Wed, 19 Jul 2023 22:46:35 ", "Title": "Backdoor Attack against Object Detection with Clean Annotation", "Authors": ["Yize Cheng", "Wenbin Hu", "Minhao Cheng"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep neural networks (DNNs) have shown unprecedented success in object detection tasks. However, it was also discovered that DNNs are vulnerable to multiple kinds of attacks, including Backdoor Attacks. Through the attack, the attacker manages to embed a hidden backdoor into the DNN such that the model behaves normally on benign data samples, but makes attacker-specified judgments given the occurrence of a predefined trigger. Although numerous backdoor attacks have been experimented on image classification, backdoor attacks on object detection tasks have not been properly investigated and explored. As object detection has been adopted as an important module in multiple security-sensitive applications such as autonomous driving, backdoor attacks on object detection could pose even more severe threats. Inspired by the inherent property of deep learning-based object detectors, we propose a simple yet effective backdoor attack method against object detection without modifying the ground truth annotations, specifically focusing on the object disappearance attack and object generation attack. Extensive experiments and ablation studies prove the effectiveness of our attack on two benchmark object detection datasets, PASCAL VOC07+12 and MSCOCO, on which we achieve an attack success rate of more than 92% with a poison rate of only 5%.", "url": "https://arxiv.org/abs/2307.10487"}, {"metadata": {"arXiv": "2307.10549", "Date": "Thu, 20 Jul 2023 03:26:57 ", "Title": "Dynamic Large Language Models on Blockchains", "Authors": ["Yuanhao Gong"], "Categories": "cs.CV cs.AI cs.CL econ.GN q-fin.EC"}, "abstract": "Training and deploying the large language models requires a large mount of computational resource because the language models contain billions of parameters and the text has thousands of tokens. Another problem is that the large language models are static. They are fixed after the training process. To tackle these issues, in this paper, we propose to train and deploy the dynamic large language model on blockchains, which have high computation performance and are distributed across a network of computers. A blockchain is a secure, decentralized, and transparent system that allows for the creation of a tamper-proof ledger for transactions without the need for intermediaries. The dynamic large language models can continuously learn from the user input after the training process. Our method provides a new way to develop the large language models and also sheds a light on the next generation artificial intelligence systems.", "url": "https://arxiv.org/abs/2307.10549"}, {"metadata": {"arXiv": "2307.10554", "Date": "Thu, 20 Jul 2023 03:36:13 ", "Title": "EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization", "Authors": ["Peijie Dong and Lujun Li and Zimian Wei and Xin Niu and Zhiliang Tian and Hengyue Pan"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Mixed-Precision Quantization~(MQ) can achieve a competitive accuracy-complexity trade-off for models. Conventional training-based search methods require time-consuming candidate training to search optimized per-layer bit-width configurations in MQ. Recently, some training-free approaches have presented various MQ proxies and significantly improve search efficiency. However, the correlation between these proxies and quantization accuracy is poorly understood. To address the gap, we first build the MQ-Bench-101, which involves different bit configurations and quantization results. Then, we observe that the existing training-free proxies perform weak correlations on the MQ-Bench-101. To efficiently seek superior proxies, we develop an automatic search of proxies framework for MQ via evolving algorithms. In particular, we devise an elaborate search space involving the existing proxies and perform an evolution search to discover the best correlated MQ proxy. We proposed a diversity-prompting selection strategy and compatibility screening protocol to avoid premature convergence and improve search efficiency. In this way, our Evolving proxies for Mixed-precision Quantization~(EMQ) framework allows the auto-generation of proxies without heavy tuning and expert knowledge. Extensive experiments on ImageNet with various ResNet and MobileNet families demonstrate that our EMQ obtains superior performance than state-of-the-art mixed-precision methods at a significantly reduced cost. The code will be released.", "url": "https://arxiv.org/abs/2307.10554"}, {"metadata": {"arXiv": "2307.10577", "Date": "Thu, 20 Jul 2023 04:41:39 ", "Title": "Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning", "Authors": ["Hugo Latapie", "Kristinn R. Thorisson", "Shan Yu", "Vahagn Petrosyan", "Patrick Hammer", "Pei Wang", "Brandon Kynoch", "Hanning Chen", "Tangrui Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events. The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process. We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest. Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set. Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems. Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating accurate semantic knowledge of images within a few cycles. It successfully captures both explicit and nuanced elements efficiently. We also introduce the implementation of Korzybski's \"time-binding\" concept in machines, which allows for generational learning and knowledge sharing across deployments. Our evaluations demonstrate Ethosight's efficacy across 40 complex use cases. It has exhibited an exceptional ability to discern new areas of interest, consistently generating high-affinity scores within the top five labels from a set of a thousand. Tests conducted across diverse environments attest to Ethosight's robust performance. Detailed results and case studies within the main body of this paper and an appendix underscore a promising trajectory towards enhancing the adaptability and resilience of computer vision models in detecting and extracting subtle and nuanced behaviors.", "url": "https://arxiv.org/abs/2307.10577"}, {"metadata": {"arXiv": "2307.10711", "Date": "Thu, 20 Jul 2023 09:06:21 ", "Title": "AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models", "Authors": ["Jiachun Pan", "Hanshu Yan", "Jun Hao Liew", "Vincent Y. F. Tan", "Jiashi Feng"], "Categories": "cs.CV cs.AI"}, "abstract": "Existing customization methods require access to multiple reference examples to align pre-trained diffusion probabilistic models (DPMs) with user-provided concepts. This paper aims to address the challenge of DPM customization when the only available supervision is a differentiable metric defined on the generated contents. Since the sampling procedure of DPMs involves recursive calls to the denoising UNet, na\\\"ive gradient backpropagation requires storing the intermediate states of all iterations, resulting in extremely high memory consumption. To overcome this issue, we propose a novel method AdjointDPM, which first generates new samples from diffusion models by solving the corresponding probability-flow ODEs. It then uses the adjoint sensitivity method to backpropagate the gradients of the loss to the models' parameters (including conditioning signals, network weights, and initial noises) by solving another augmented ODE. To reduce numerical errors in both the forward generation and gradient backpropagation processes, we further reparameterize the probability-flow ODE and augmented ODE as simple non-stiff ODEs using exponential integration. Finally, we demonstrate the effectiveness of AdjointDPM on three interesting tasks: converting visual effects into identification text embeddings, finetuning DPMs for specific types of stylization, and optimizing initial noise to generate adversarial samples for security auditing.", "url": "https://arxiv.org/abs/2307.10711"}, {"metadata": {"arXiv": "2307.10713", "Date": "Thu, 20 Jul 2023 09:13:32 ", "Title": "Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV", "Authors": ["Jaime Spencer", "Chris Russell", "Simon Hadfield", "Richard Bowden"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["Accepted to ICCV2023"]}, "abstract": "Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings. To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture. We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) aspect ratio augmentation, 2) camera intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation. Code is available at https://github.com/jspenmar/slowtv_monodepth.", "url": "https://arxiv.org/abs/2307.10713"}, {"metadata": {"arXiv": "2307.10943", "Date": "Thu, 20 Jul 2023 15:13:29 ", "Title": "Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery", "Authors": ["Hyungmin Kim", "Sungho Suh", "Daehwan Kim", "Daun Jeong", "Hansang Cho", "Junmo Kim"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Recent advances in deep learning have significantly improved the performance of various computer vision applications. However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories. Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch. To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge. The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset. Furthermore, the proxy anchors-based exemplar generates representative category vectors to mitigate catastrophic forgetting. Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios.", "url": "https://arxiv.org/abs/2307.10943"}, {"metadata": {"arXiv": "2307.10953", "Date": "Thu, 20 Jul 2023 15:25:55 ", "Title": "PE-YOLO: Pyramid Enhancement Network for Dark Object Detection", "Authors": ["Xiangchen Yin", "Zhenda Yu", "Zetao Fei", "Wenjun Lv", "Xin Gao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ICANN 2023"]}, "abstract": "Current object detection models have achieved good results on many benchmark datasets, detecting objects in dark conditions remains a large challenge. To address this issue, we propose a pyramid enhanced network (PENet) and joint it with YOLOv3 to build a dark object detection framework named PE-YOLO. Firstly, PENet decomposes the image into four components of different resolutions using the Laplacian pyramid. Specifically we propose a detail processing module (DPM) to enhance the detail of images, which consists of context branch and edge branch. In addition, we propose a low-frequency enhancement filter (LEF) to capture low-frequency semantics and prevent high-frequency noise. PE-YOLO adopts an end-to-end joint training approach and only uses normal detection loss to simplify the training process. We conduct experiments on the low-light object detection dataset ExDark to demonstrate the effectiveness of ours. The results indicate that compared with other dark detectors and low-light enhancement models, PE-YOLO achieves the advanced results, achieving 78.0% in mAP and 53.6 in FPS, respectively, which can adapt to object detection under different low-light conditions. The code is available at https://github.com/XiangchenYin/PE-YOLO.", "url": "https://arxiv.org/abs/2307.10953"}, {"metadata": {"arXiv": "2307.10984", "Date": "Thu, 20 Jul 2023 16:14:23 ", "Title": "Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image", "Authors": ["Wei Yin", "Chi Zhang", "Hao Chen", "Zhipeng Cai", "Gang Yu", "Kaixuan Wang", "Xiaozhi Chen", "Chunhua Shen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023. Won the championship in the 2nd Monocular Depth Estimation Challenge. The code is available at https://github.com/YvanYin/Metric3D"]}, "abstract": "Reconstructing accurate 3D scenes from images is a long-standing vision task. Due to the ill-posedness of the single-image reconstruction problem, most well-established methods are built upon multi-view geometry. State-of-the-art (SOTA) monocular metric depth estimation methods can only handle a single camera model and are unable to perform mixed-data training due to the metric ambiguity. Meanwhile, SOTA monocular methods trained on large mixed datasets achieve zero-shot generalization by learning affine-invariant depths, which cannot recover real-world metrics. In this work, we show that the key to a zero-shot single-view metric depth model lies in the combination of large-scale data training and resolving the metric ambiguity from various camera models. We propose a canonical camera space transformation module, which explicitly addresses the ambiguity problems and can be effortlessly plugged into existing monocular models. Equipped with our module, monocular models can be stably trained with over 8 million images with thousands of camera models, resulting in zero-shot generalization to in-the-wild images with unseen camera settings. Experiments demonstrate SOTA performance of our method on 7 zero-shot benchmarks. Notably, our method won the championship in the 2nd Monocular Depth Estimation Challenge. Our method enables the accurate recovery of metric 3D structures on randomly collected internet images, paving the way for plausible single-image metrology. The potential benefits extend to downstream tasks, which can be significantly improved by simply plugging in our model. For example, our model relieves the scale drift issues of monocular-SLAM (Fig. 1), leading to high-quality metric scale dense mapping. The code is available at https://github.com/YvanYin/Metric3D.", "url": "https://arxiv.org/abs/2307.10984"}, {"metadata": {"arXiv": "2307.11035", "Date": "Thu, 20 Jul 2023 17:11:20 ", "Title": "Cascade-DETR: Delving into High-Quality Universal Object Detection", "Authors": ["Mingqiao Ye", "Lei Ke", "Siyuan Li", "Yu-Wing Tai", "Chi-Keung Tang", "Martin Danelljan and Fisher Yu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in ICCV 2023. Our code and models will be released at https://github.com/SysCV/cascade-detr"]}, "abstract": "Object localization in general environments is a fundamental part of vision systems. While dominating on the COCO benchmark, recent Transformer-based detection methods are not competitive in diverse domains. Moreover, these methods still struggle to very accurately estimate the object bounding boxes in complex environments. We introduce Cascade-DETR for high-quality universal object detection. We jointly tackle the generalization to diverse domains and localization accuracy by proposing the Cascade Attention layer, which explicitly integrates object-centric information into the detection decoder by limiting the attention to the previous box prediction. To further enhance accuracy, we also revisit the scoring of queries. Instead of relying on classification scores, we predict the expected IoU of the query, leading to substantially more well-calibrated confidences. Lastly, we introduce a universal object detection benchmark, UDB10, that contains 10 datasets from diverse domains. While also advancing the state-of-the-art on COCO, Cascade-DETR substantially improves DETR-based detectors on all datasets in UDB10, even by over 10 mAP in some cases. The improvements under stringent quality requirements are even more pronounced. Our code and models will be released at https://github.com/SysCV/cascade-detr.", "url": "https://arxiv.org/abs/2307.11035"}, {"metadata": {"arXiv": "2307.11058", "Date": "Thu, 20 Jul 2023 17:38:55 ", "Title": "Driving Policy Prediction based on Deep Learning Models", "Authors": ["Fuxiao Liu"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages", "9 figures"]}, "abstract": "In this project, we implemented an end-to-end system that takes in combined visual features of video frames from a normal camera and depth information from a cloud points scanner, and predicts driving policies (vehicle speed and steering angle). We verified the safety of our system by comparing the predicted results with standard behaviors by real-world experienced drivers. Our test results show that the predictions can be considered as accurate in at lease half of the testing cases (50% 80%, depending on the model), and using combined features improved the performance in most cases than using video frames only.", "url": "https://arxiv.org/abs/2307.11058"}, {"metadata": {"arXiv": "2307.11073", "Date": "Thu, 20 Jul 2023 17:53:46 ", "Title": "OBJECT 3DIT: Language-guided 3D-aware Image Editing", "Authors": ["Oscar Michel", "Anand Bhattad", "Eli VanderBilt", "Ranjay Krishna", "Aniruddha Kembhavi", "Tanmay Gupta"], "Categories": "cs.CV cs.AI cs.GR"}, "abstract": "Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected. As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process. In this work, we formulate the newt ask of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction in context of the underlying 3D scene. To promote progress towards this goal, we release OBJECT: a dataset consisting of 400K editing examples created from procedurally generated 3D scenes. Each example consists of an input image, editing instruction in language, and the edited image. We also introduce 3DIT : single and multi-task models for four editing tasks. Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations. Surprisingly, training on only synthetic scenes from OBJECT, editing capabilities of 3DIT generalize to real-world images.", "url": "https://arxiv.org/abs/2307.11073"}, {"metadata": {"arXiv": "2307.10594", "Date": "Thu, 20 Jul 2023 05:16:33 ", "Title": "Exploiting Structure for Optimal Multi-Agent Bayesian Decentralized Estimation", "Authors": ["Christopher Funk", "Ofer Dagan", "Benjamin Noack and Nisar R. Ahmed"], "Categories": "cs.RO cs.AI", "Comments": ["4 pages", "4 figures. presented at the Inference and Decision Making for Autonomous Vehicles (IDMAV) RSS 2023 workshop"]}, "abstract": "A key challenge in Bayesian decentralized data fusion is the `rumor propagation' or `double counting' phenomenon, where previously sent data circulates back to its sender. It is often addressed by approximate methods like covariance intersection (CI) which takes a weighted average of the estimates to compute the bound. The problem is that this bound is not tight, i.e. the estimate is often over-conservative. In this paper, we show that by exploiting the probabilistic independence structure in multi-agent decentralized fusion problems a tighter bound can be found using (i) an expansion to the CI algorithm that uses multiple (non-monolithic) weighting factors instead of one (monolithic) factor in the original CI and (ii) a general optimization scheme that is able to compute optimal bounds and fully exploit an arbitrary dependency structure. We compare our methods and show that on a simple problem, they converge to the same solution. We then test our new non-monolithic CI algorithm on a large-scale target tracking simulation and show that it achieves a tighter bound and a more accurate estimate compared to the original monolithic CI.", "url": "https://arxiv.org/abs/2307.10594"}, {"metadata": {"arXiv": "2307.10846", "Date": "Thu, 20 Jul 2023 13:08:14 ", "Title": "Goal-Conditioned Reinforcement Learning with Disentanglement-based Reachability Planning", "Authors": ["Zhifeng Qian and Mingyu You and Hongjun Zhou and Xuanhui Xu and Bin He"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted by 2023 RAL with ICRA"]}, "abstract": "Goal-Conditioned Reinforcement Learning (GCRL) can enable agents to spontaneously set diverse goals to learn a set of skills. Despite the excellent works proposed in various fields, reaching distant goals in temporally extended tasks remains a challenge for GCRL. Current works tackled this problem by leveraging planning algorithms to plan intermediate subgoals to augment GCRL. Their methods need two crucial requirements: (i) a state representation space to search valid subgoals, and (ii) a distance function to measure the reachability of subgoals. However, they struggle to scale to high-dimensional state space due to their non-compact representations. Moreover, they cannot collect high-quality training data through standard GC policies, which results in an inaccurate distance function. Both affect the efficiency and performance of planning and policy learning. In the paper, we propose a goal-conditioned RL algorithm combined with Disentanglement-based Reachability Planning (REPlan) to solve temporally extended tasks. In REPlan, a Disentangled Representation Module (DRM) is proposed to learn compact representations which disentangle robot poses and object positions from high-dimensional observations in a self-supervised manner. A simple REachability discrimination Module (REM) is also designed to determine the temporal distance of subgoals. Moreover, REM computes intrinsic bonuses to encourage the collection of novel states for training. We evaluate our REPlan in three vision-based simulation tasks and one real-world task. The experiments demonstrate that our REPlan significantly outperforms the prior state-of-the-art methods in solving temporally extended tasks.", "url": "https://arxiv.org/abs/2307.10846"}, {"metadata": {"arXiv": "2307.10714", "Date": "Thu, 20 Jul 2023 09:16:01 ", "Title": "Introducing Risk Shadowing For Decisive and Comfortable Behavior Planning", "Authors": ["Tim Puphal and Julian Eggert"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["Accepted at IEEE ITSC 2023"]}, "abstract": "We consider the problem of group interactions in urban driving. State-of-the-art behavior planners for self-driving cars mostly consider each single agent-to-agent interaction separately in a cost function in order to find an optimal behavior for the ego agent, such as not colliding with any of the other agents. In this paper, we develop risk shadowing, a situation understanding method that allows us to go beyond single interactions by analyzing group interactions between three agents. Concretely, the presented method can find out which first other agent does not need to be considered in the behavior planner of an ego agent, because this first other agent cannot reach the ego agent due to a second other agent obstructing its way. In experiments, we show that using risk shadowing as an upstream filter module for a behavior planner allows to plan more decisive and comfortable driving strategies than state of the art, given that safety is ensured in these cases. The usability of the approach is demonstrated for different intersection scenarios and longitudinal driving.", "url": "https://arxiv.org/abs/2307.10714"}, {"metadata": {"arXiv": "2307.10219", "Date": "Fri, 14 Jul 2023 21:29:16 ", "Title": "Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge", "Authors": ["Zifeng Ding", "Jingcheng Wu", "Jingpei Wu", "Yan Xia", "Volker Tresp"], "Categories": "cs.AI cs.LG"}, "abstract": "Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. In the meantime, due to the ever-evolving nature of world knowledge, extensive parallel works have been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be viewed as a KG fact coupled with a timestamp (or time period) specifying its time validity. The existing HKG reasoning approaches do not consider temporal information because it is not explicitly specified in previous benchmark datasets. Besides, all the previous TKG reasoning methods only lay emphasis on temporal reasoning and have no way to learn from qualifiers. To this end, we aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and propose a HTKG reasoning model that efficiently models both temporal facts and qualifiers. We further exploit additional time-invariant relational knowledge from the Wikidata knowledge base and study its effectiveness in HTKG reasoning. Time-invariant relational knowledge serves as the knowledge that remains unchanged in time (e.g., Sasha Obama is the child of Barack Obama), and it has never been fully explored in previous TKG reasoning benchmarks and approaches. Experimental results show that our model substantially outperforms previous related methods on HTKG link prediction and can be enhanced by jointly leveraging both temporal and time-invariant relational knowledge.", "url": "https://arxiv.org/abs/2307.10219"}, {"metadata": {"arXiv": "2307.10231", "Date": "Sat, 15 Jul 2023 18:07:08 ", "Title": "Automated Knowledge Modeling for Cancer Clinical Practice Guidelines", "Authors": ["Pralaypati Ta", "Bhumika Gupta", "Arihant Jain", "Sneha Sree C", "Arunima Sarkar", "Keerthi Ram", "Mohanasankar Sivaprakasam"], "Categories": "cs.AI cs.LG"}, "abstract": "Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to new evidence generated by active research. Currently, CPGs are primarily published in a document format that is ill-suited for managing this developing knowledge. A knowledge model of the guidelines document suitable for programmatic interaction is required. This work proposes an automated method for extraction of knowledge from National Comprehensive Cancer Network (NCCN) CPGs in Oncology and generating a structured model containing the retrieved knowledge. The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful extraction and modeling of knowledge. Three enrichment strategies using Cancer staging information, Unified Medical Language System (UMLS) Metathesaurus & National Cancer Institute thesaurus (NCIt) concepts, and Node classification are also presented to enhance the model towards enabling programmatic traversal and querying of cancer care guidelines. The Node classification was performed using a Support Vector Machine (SVM) model, achieving a classification accuracy of 0.81 with 10-fold cross-validation.", "url": "https://arxiv.org/abs/2307.10231"}, {"metadata": {"arXiv": "2307.10460", "Date": "Wed, 19 Jul 2023 21:12:04 ", "Title": "A data science axiology: the nature, value, and risks of data science", "Authors": ["Michael L. Brodie"], "Categories": "cs.AI cs.DB cs.LG", "ACM-class": "I.2; I.2.4; I.2.7; K.2"}, "abstract": "Data science is not a science. It is a research paradigm with an unfathomed scope, scale, complexity, and power for knowledge discovery that is not otherwise possible and can be beyond human reasoning. It is changing our world practically and profoundly already widely deployed in tens of thousands of applications in every discipline in an AI Arms Race that, due to its inscrutability, can lead to unfathomed risks. This paper presents an axiology of data science, its purpose, nature, importance, risks, and value for problem solving, by exploring and evaluating its remarkable, definitive features. As data science is in its infancy, this initial, speculative axiology is intended to aid in understanding and defining data science to recognize its potential benefits, risks, and open research challenges. AI based data science is inherently about uncertainty that may be more realistic than our preference for the certainty of science. Data science will have impacts far beyond knowledge discovery and will take us into new ways of understanding the world.", "url": "https://arxiv.org/abs/2307.10460"}, {"metadata": {"arXiv": "2307.10936", "Date": "Thu, 20 Jul 2023 15:09:06 ", "Title": "PASTA: Pretrained Action-State Transformer Agents", "Authors": ["Raphael Boige and Yannis Flet-Berliac and Arthur Flajolet and Guillaume Richard and Thomas Pierrot"], "Categories": "cs.AI cs.LG"}, "abstract": "Self-supervised learning has brought about a revolutionary paradigm shift in various computing domains, including NLP, vision, and biology. Recent approaches involve pre-training transformer models on vast amounts of unlabeled data, serving as a starting point for efficiently solving downstream tasks. In the realm of reinforcement learning, researchers have recently adapted these approaches by developing models pre-trained on expert trajectories, enabling them to address a wide range of tasks, from robotics to recommendation systems. However, existing methods mostly rely on intricate pre-training objectives tailored to specific downstream applications. This paper presents a comprehensive investigation of models we refer to as Pretrained Action-State Transformer Agents (PASTA). Our study uses a unified methodology and covers an extensive set of general downstream tasks including behavioral cloning, offline RL, sensor failure robustness, and dynamics change adaptation. Our goal is to systematically compare various design choices and provide valuable insights to practitioners for building robust models. Key highlights of our study include tokenization at the action and state component level, using fundamental pre-training objectives like next token prediction, training models across diverse domains simultaneously, and using parameter efficient fine-tuning (PEFT). The developed models in our study contain fewer than 10 million parameters and the application of PEFT enables fine-tuning of fewer than 10,000 parameters during downstream adaptation, allowing a broad community to use these models and reproduce our experiments. We hope that this study will encourage further research into the use of transformers with first-principles design choices to represent RL trajectories and contribute to robust policy learning.", "url": "https://arxiv.org/abs/2307.10936"}, {"metadata": {"arXiv": "2307.10237", "Date": "Sun, 16 Jul 2023 09:47:21 ", "Title": "CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion", "Authors": ["Bhavin Jawade", "Deen Dayal Mohan", "Dennis Fedorishin", "Srirangaraj Setlur", "Venu Govindaraju"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Paper accepted at IJCB 2023"]}, "abstract": "Face recognition from image sets acquired under unregulated and uncontrolled settings, such as at large distances, low resolutions, varying viewpoints, illumination, pose, and atmospheric conditions, is challenging. Face feature aggregation, which involves aggregating a set of N feature representations present in a template into a single global representation, plays a pivotal role in such recognition systems. Existing works in traditional face feature aggregation either utilize metadata or high-dimensional intermediate feature representations to estimate feature quality for aggregation. However, generating high-quality metadata or style information is not feasible for extremely low-resolution faces captured in long-range and high altitude settings. To overcome these limitations, we propose a feature distribution conditioning approach called CoNAN for template aggregation. Specifically, our method aims to learn a context vector conditioned over the distribution information of the incoming feature set, which is utilized to weigh the features based on their estimated informativeness. The proposed method produces state-of-the-art results on long-range unconstrained face recognition datasets such as BTS, and DroneSURF, validating the advantages of such an aggregation strategy.", "url": "https://arxiv.org/abs/2307.10237"}, {"metadata": {"arXiv": "2307.10404", "Date": "Wed, 19 Jul 2023 18:19:18 ", "Title": "Interpreting and Correcting Medical Image Classification with PIP-Net", "Authors": ["Meike Nauta", "Johannes H. Hegeman", "Jeroen Geerdink", "J\\\"org Schl\\\"otterer", "Maurice van Keulen", "Christin Seifert"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Part-prototype models are explainable-by-design image classifiers, and a promising alternative to black box AI. This paper explores the applicability and potential of interpretable machine learning, in particular PIP-Net, for automated diagnosis support on real-world medical imaging data. PIP-Net learns human-understandable prototypical image parts and we evaluate its accuracy and interpretability for fracture detection and skin cancer diagnosis. We find that PIP-Net's decision making process is in line with medical classification standards, while only provided with image-level class labels. Because of PIP-Net's unsupervised pretraining of prototypes, data quality problems such as undesired text in an X-ray or labelling errors can be easily identified. Additionally, we are the first to show that humans can manually correct the reasoning of PIP-Net by directly disabling undesired prototypes. We conclude that part-prototype models are promising for medical applications due to their interpretability and potential for advanced model debugging.", "url": "https://arxiv.org/abs/2307.10404"}, {"metadata": {"arXiv": "2307.10455", "Date": "Wed, 19 Jul 2023 20:54:08 ", "Title": "A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset", "Authors": ["Zahra Gharaee", "ZeMing Gong", "Nicholas Pellegrino", "Iuliia Zarubiieva", "Joakim Bruslund Haurum", "Scott C. Lowe", "Jaclyn T.A. McKeown", "Chris C.Y. Ho", "Joschka McLeod", "Yi-Yun C Wei", "Jireh Agda", "Sujeevan Ratnasingham", "Dirk Steinke", "Angel X. Chang", "Graham W. Taylor", "Paul Fieguth"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "In an effort to catalog insect biodiversity, we propose a new large dataset of hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is taxonomically classified by an expert, and also has associated genetic information including raw nucleotide barcode sequences and assigned barcode index numbers, which are genetically-based proxies for species classification. This paper presents a curated million-image dataset, primarily to train computer-vision models capable of providing image-based taxonomic assessment, however, the dataset also presents compelling characteristics, the study of which would be of interest to the broader machine learning community. Driven by the biological nature inherent to the dataset, a characteristic long-tailed class-imbalance distribution is exhibited. Furthermore, taxonomic labelling is a hierarchical classification scheme, presenting a highly fine-grained classification problem at lower levels. Beyond spurring interest in biodiversity research within the machine learning community, progress on creating an image-based taxonomic classifier will also further the ultimate goal of all BIOSCAN research: to lay the foundation for a comprehensive survey of global biodiversity. This paper introduces the dataset and explores the classification task through the implementation and analysis of a baseline classifier.", "url": "https://arxiv.org/abs/2307.10455"}, {"metadata": {"arXiv": "2307.10471", "Date": "Wed, 19 Jul 2023 21:45:07 ", "Title": "Classification of Visualization Types and Perspectives in Patents", "Authors": ["Junaid Ahmed Ghauri", "Eric M\\\"uller-Budack", "Ralph Ewerth"], "Categories": "cs.CV cs.AI cs.DL cs.IR cs.LG", "Comments": ["Accepted in International Conference on Theory and Practice of Digital Libraries (TPDL) 2023 (They have the copyright to publish camera-ready version of this work)"]}, "abstract": "Due to the swift growth of patent applications each year, information and multimedia retrieval approaches that facilitate patent exploration and retrieval are of utmost importance. Different types of visualizations (e.g., graphs, technical drawings) and perspectives (e.g., side view, perspective) are used to visualize details of innovations in patents. The classification of these images enables a more efficient search and allows for further analysis. So far, datasets for image type classification miss some important visualization types for patents. Furthermore, related work does not make use of recent deep learning approaches including transformers. In this paper, we adopt state-of-the-art deep learning methods for the classification of visualization types and perspectives in patent images. We extend the CLEF-IP dataset for image type classification in patents to ten classes and provide manual ground truth annotations. In addition, we derive a set of hierarchical classes from a dataset that provides weakly-labeled data for image perspectives. Experimental results have demonstrated the feasibility of the proposed approaches. Source code, models, and dataset will be made publicly available.", "url": "https://arxiv.org/abs/2307.10471"}, {"metadata": {"arXiv": "2307.10763", "Date": "Thu, 20 Jul 2023 10:53:12 ", "Title": "MSQNet: Actor-agnostic Action Recognition with Multi-modal Query", "Authors": ["Anindya Mondal", "Sauradip Nag", "Joaquin M Prada", "Xiatian Zhu", "Anjan Dutta"], "Categories": "cs.CV cs.AI cs.LG eess.IV"}, "abstract": "Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors. This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs. Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions. To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals. We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better. The elimination of actor-specific model designs is a key advantage, as it removes the need for actor pose estimation altogether. Extensive experiments on five publicly available benchmarks show that our MSQNet consistently outperforms the prior arts of actor-specific alternatives on human and animal single- and multi-label action recognition tasks by up to 50%. Code will be released at https://github.com/mondalanindya/MSQNet.", "url": "https://arxiv.org/abs/2307.10763"}, {"metadata": {"arXiv": "2307.10792", "Date": "Thu, 20 Jul 2023 11:45:38 ", "Title": "Optimizing PatchCore for Few/many-shot Anomaly Detection", "Authors": ["Jo\\~ao Santos", "Triet Tran", "Oliver Rippel"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and tries to distinguish between normal and anomalous data using only few selected samples. While newly proposed few-shot AD methods do compare against pre-existing algorithms developed for the full-shot domain as baselines, they do not dedicatedly optimize them for the few-shot setting. It thus remains unclear if the performance of such pre-existing algorithms can be further improved. We address said question in this work. Specifically, we present a study on the AD/anomaly segmentation (AS) performance of PatchCore, the current state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the many-shot settings. We hypothesize that further performance improvements can be realized by (I) optimizing its various hyperparameters, and by (II) transferring techniques known to improve few-shot supervised learning to the AD domain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal that (I) significant performance improvements can be realized by optimizing hyperparameters such as the underlying feature extractor, and that (II) image-level augmentations can, but are not guaranteed, to improve performance. Based on these findings, we achieve a new state of the art in few-shot AD on VisA, further demonstrating the merit of adapting pre-existing AD/AS methods to the few-shot setting. Last, we identify the investigation of feature extractors with a strong inductive bias as a potential future research direction for (few-shot) AD/AS.", "url": "https://arxiv.org/abs/2307.10792"}, {"metadata": {"arXiv": "2307.10802", "Date": "Thu, 20 Jul 2023 12:10:29 ", "Title": "Meta-Transformer: A Unified Framework for Multimodal Learning", "Authors": ["Yiyuan Zhang", "Kaixiong Gong", "Kaipeng Zhang", "Hongsheng Li", "Yu Qiao", "Wanli Ouyang", "Xiangyu Yue"], "Categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "Comments": ["Project website: https://kxgong.github.io/meta_transformer/"]}, "abstract": "Multimodal learning aims to build models that can process and relate information from multiple modalities. Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities ($\\textit{e.g.}$ natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them. In this work, we propose a framework, named Meta-Transformer, that leverages a $\\textbf{frozen}$ encoder to perform multimodal perception without any paired multimodal training data. In Meta-Transformer, the raw input data from various modalities are mapped into a shared token space, allowing a subsequent encoder with frozen parameters to extract high-level semantic features of the input data. Composed of three main components: a unified data tokenizer, a modality-shared encoder, and task-specific heads for downstream tasks, Meta-Transformer is the first framework to perform unified learning across 12 modalities with unpaired data. Experiments on different benchmarks reveal that Meta-Transformer can handle a wide range of tasks including fundamental perception (text, image, point cloud, audio, video), practical application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph, tabular, and time-series). Meta-Transformer indicates a promising future for developing unified multimodal intelligence with transformers. Code will be available at https://github.com/invictus717/MetaTransformer", "url": "https://arxiv.org/abs/2307.10802"}, {"metadata": {"arXiv": "2307.10864", "Date": "Thu, 20 Jul 2023 13:33:28 ", "Title": "Divide & Bind Your Attention for Improved Generative Semantic Nursing", "Authors": ["Yumeng Li", "Margret Keuper", "Dan Zhang", "Anna Khoreva"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Project page: \\url{https://sites.google.com/view/divide-and-bind}"]}, "abstract": "Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity. Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt. Prior work, Attend & Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics. It demonstrates promising results in generating simple prompts, e.g., ``a cat and a dog''. However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding. To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide & Bind. We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss. Our approach stands out in its ability to faithfully synthesize desired objects with improved attribute alignment from complex prompts and exhibits superior performance across multiple evaluation benchmarks. More videos and updates can be found on the project page \\url{https://sites.google.com/view/divide-and-bind}.", "url": "https://arxiv.org/abs/2307.10864"}, {"metadata": {"arXiv": "2307.11077", "Date": "Thu, 20 Jul 2023 17:55:14 ", "Title": "AlignDet: Aligning Pre-training and Fine-tuning in Object Detection", "Authors": ["Ming Li", "Jie Wu", "Xionghui Wang", "Chen Chen", "Jie Qin", "Xuefeng Xiao", "Rui Wang", "Min Zheng", "Xin Pan"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV 2023. Code and Models are publicly available. Project Page: https://liming-ai.github.io/AlignDet"]}, "abstract": "The paradigm of large-scale pre-training followed by downstream fine-tuning has been widely employed in various object detection algorithms. In this paper, we reveal discrepancies in data, model, and task between the pre-training and fine-tuning procedure in existing practices, which implicitly limit the detector's performance, generalization ability, and convergence speed. To this end, we propose AlignDet, a unified pre-training framework that can be adapted to various existing detectors to alleviate the discrepancies. AlignDet decouples the pre-training process into two stages, i.e., image-domain and box-domain pre-training. The image-domain pre-training optimizes the detection backbone to capture holistic visual abstraction, and box-domain pre-training learns instance-level semantics and task-aware concepts to initialize the parts out of the backbone. By incorporating the self-supervised pre-trained backbones, we can pre-train all modules for various detectors in an unsupervised paradigm. As depicted in Figure 1, extensive experiments demonstrate that AlignDet can achieve significant improvements across diverse protocols, such as detection algorithm, model backbone, data setting, and training schedule. For example, AlignDet improves FCOS by 5.3 mAP, RetinaNet by 2.1 mAP, Faster R-CNN by 3.3 mAP, and DETR by 2.3 mAP under fewer epochs.", "url": "https://arxiv.org/abs/2307.11077"}, {"metadata": {"arXiv": "2307.11086", "Date": "Thu, 20 Jul 2023 17:59:33 ", "Title": "PAPR: Proximity Attention Point Rendering", "Authors": ["Yanshu Zhang", "Shichong Peng", "Alireza Moazeni", "Ke Li"], "Categories": "cs.CV cs.AI cs.GR cs.LG cs.NE"}, "abstract": "Learning accurate and parsimonious point cloud representations of scene surfaces from scratch remains a challenge in 3D representation learning. Existing point-based methods often suffer from the vanishing gradient problem or require a large number of points to accurately model scene geometry and texture. To address these limitations, we propose Proximity Attention Point Rendering (PAPR), a novel method that consists of a point-based scene representation and a differentiable renderer. Our scene representation uses a point cloud where each point is characterized by its spatial position, foreground score, and view-independent feature vector. The renderer selects the relevant points for each ray and produces accurate colours using their associated features. PAPR effectively learns point cloud positions to represent the correct scene geometry, even when the initialization drastically differs from the target geometry. Notably, our method captures fine texture details while using only a parsimonious set of points. We also demonstrate four practical applications of our method: geometry editing, object manipulation, texture transfer, and exposure control. More results and code are available on our project website at https://zvict.github.io/papr/.", "url": "https://arxiv.org/abs/2307.11086"}, {"metadata": {"arXiv": "2307.10805", "Date": "Thu, 20 Jul 2023 12:16:26 ", "Title": "Communication-Efficient Split Learning via Adaptive Feature-Wise Compression", "Authors": ["Yongjeong Oh", "Jaeho Lee", "Christopher G. Brinton", "and Yo-Seb Jeon"], "Categories": "cs.DC cs.AI cs.LG"}, "abstract": "This paper proposes a novel communication-efficient split learning (SL) framework, named SplitFC, which reduces the communication overhead required for transmitting intermediate feature and gradient vectors during the SL training process. The key idea of SplitFC is to leverage different dispersion degrees exhibited in the columns of the matrices. SplitFC incorporates two compression strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise quantization. In the first strategy, the intermediate feature vectors are dropped with adaptive dropout probabilities determined based on the standard deviation of these vectors. Then, by the chain rule, the intermediate gradient vectors associated with the dropped feature vectors are also dropped. In the second strategy, the non-dropped intermediate feature and gradient vectors are quantized using adaptive quantization levels determined based on the ranges of the vectors. To minimize the quantization error, the optimal quantization levels of this strategy are derived in a closed-form expression. Simulation results on the MNIST, CIFAR-10, and CelebA datasets demonstrate that SplitFC provides more than a 5.6% increase in classification accuracy compared to state-of-the-art SL frameworks, while they require 320 times less communication overhead compared to the vanilla SL framework without compression.", "url": "https://arxiv.org/abs/2307.10805"}, {"metadata": {"arXiv": "2307.10262", "Date": "Mon, 17 Jul 2023 16:20:27 ", "Title": "Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotPython", "Authors": ["Thomas Bartz-Beielstein"], "Categories": "cs.LG cs.AI", "MSC-class": "90C26", "ACM-class": "I.2.6; G.1.6"}, "abstract": "This document provides a comprehensive guide to hyperparameter tuning using spotPython for scikit-learn, PyTorch, and river. The first part introduces spotPython's surrogate model-based optimization process, while the second part focuses on hyperparameter tuning. Several case studies are presented, including hyperparameter tuning for sklearn models such as Support Vector Classification, Random Forests, Gradient Boosting (XGB), and K-nearest neighbors (KNN), as well as a Hoeffding Adaptive Tree Regressor from river. The integration of spotPython into the PyTorch and PyTorch Lightning training workflow is also discussed. With a hands-on approach and step-by-step explanations, this cookbook serves as a practical starting point for anyone interested in hyperparameter tuning with Python. Highlights include the interplay between Tensorboard, PyTorch Lightning, spotPython, and river. This publication is under development, with updates available on the corresponding webpage.", "url": "https://arxiv.org/abs/2307.10262"}, {"metadata": {"arXiv": "2307.10317", "Date": "Wed, 19 Jul 2023 05:44:35 ", "Title": "FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning", "Authors": ["Chia-Hsiang Kao", "Yu-Chiang Frank Wang"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to NeurIPS'23"]}, "abstract": "Federated Learning (FL) offers a collaborative training framework, allowing multiple clients to contribute to a shared model without compromising data privacy. Due to the heterogeneous nature of local datasets, updated client models may overfit and diverge from one another, commonly known as the problem of client drift. In this paper, we propose FedBug (Federated Learning with Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively mitigate client drift. FedBug adaptively leverages the client model parameters, distributed by the server at each global round, as the reference points for cross-client alignment. Specifically, on the client side, FedBug begins by freezing the entire model, then gradually unfreezes the layers, from the input layer to the output layer. This bottom-up approach allows models to train the newly thawed layers to project data into a latent space, wherein the separating hyperplanes remain consistent across all clients. We theoretically analyze FedBug in a novel over-parameterization FL setup, revealing its superior convergence rate compared to FedAvg. Through comprehensive experiments, spanning various datasets, training conditions, and network architectures, we validate the efficacy of FedBug. Our contributions encompass a novel FL framework, theoretical analysis, and empirical validation, demonstrating the wide potential and applicability of FedBug.", "url": "https://arxiv.org/abs/2307.10317"}, {"metadata": {"arXiv": "2307.10318", "Date": "Wed, 19 Jul 2023 06:28:12 ", "Title": "Eliminating Label Leakage in Tree-Based Vertical Federated Learning", "Authors": ["Hideaki Takahashi", "Jingjing Liu", "Yang Liu"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Vertical federated learning (VFL) enables multiple parties with disjoint features of a common user set to train a machine learning model without sharing their private data. Tree-based models have become prevalent in VFL due to their interpretability and efficiency. However, the vulnerability of tree-based VFL has not been sufficiently investigated. In this study, we first introduce a novel label inference attack, ID2Graph, which utilizes the sets of record-IDs assigned to each node (i.e., instance space) to deduce private training labels. The ID2Graph attack generates a graph structure from training samples, extracts communities from the graph, and clusters the local dataset using community information. To counteract label leakage from the instance space, we propose an effective defense mechanism, ID-LMID, which prevents label leakage by focusing on mutual information regularization. Comprehensive experiments conducted on various datasets reveal that the ID2Graph attack presents significant risks to tree-based models such as Random Forest and XGBoost. Further evaluations on these benchmarks demonstrate that ID-LMID effectively mitigates label leakage in such instances.", "url": "https://arxiv.org/abs/2307.10318"}, {"metadata": {"arXiv": "2307.10422", "Date": "Wed, 19 Jul 2023 19:19:13 ", "Title": "PreDiff: Precipitation Nowcasting with Latent Diffusion Models", "Authors": ["Zhihan Gao", "Xingjian Shi", "Boran Han", "Hao Wang", "Xiaoyong Jin", "Danielle Maddix", "Yi Zhu", "Mu Li", "Yuyang Wang"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Technical report"]}, "abstract": "Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise. In the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques. These models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions. To address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop PreDiff, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge control mechanism to align forecasts with domain-specific physical constraints. This is achieved by estimating the deviation from imposed constraints at each denoising step and adjusting the transition distribution accordingly. We conduct empirical studies on two datasets: N-body MNIST, a synthetic dataset with chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset. Specifically, we impose the law of conservation of energy in N-body MNIST and anticipated precipitation intensity in SEVIR. Experiments demonstrate the effectiveness of PreDiff in handling uncertainty, incorporating domain-specific prior knowledge, and generating forecasts that exhibit high operational utility.", "url": "https://arxiv.org/abs/2307.10422"}, {"metadata": {"arXiv": "2307.10459", "Date": "Wed, 19 Jul 2023 21:06:43 ", "Title": "A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints", "Authors": ["Andrei V. Konstantinov and Lev V. Utkin"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "A new computationally simple method of imposing hard convex constraints on the neural network output values is proposed. The key idea behind the method is to map a vector of hidden parameters of the network to a point that is guaranteed to be inside the feasible set defined by a set of constraints. The mapping is implemented by the additional neural network layer with constraints for output. The proposed method is simply extended to the case when constraints are imposed not only on the output vectors, but also on joint constraints depending on inputs. The projection approach to imposing constraints on outputs can simply be implemented in the framework of the proposed method. It is shown how to incorporate different types of constraints into the proposed method, including linear and quadratic constraints, equality constraints, and dynamic constraints, constraints in the form of boundaries. An important feature of the method is its computational simplicity. Complexities of the forward pass of the proposed neural network layer by linear and quadratic constraints are O(n*m) and O(n^2*m), respectively, where n is the number of variables, m is the number of constraints. Numerical experiments illustrate the method by solving optimization and classification problems. The code implementing the method is publicly available.", "url": "https://arxiv.org/abs/2307.10459"}, {"metadata": {"arXiv": "2307.10529", "Date": "Thu, 20 Jul 2023 02:07:20 ", "Title": "Fast Unsupervised Deep Outlier Model Selection with Hypernetworks", "Authors": ["Xueying Ding", "Yue Zhao", "Leman Akoglu"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages", "6 figures"]}, "abstract": "Outlier detection (OD) finds many applications with a rich literature of numerous techniques. Deep neural network based OD (DOD) has seen a recent surge of attention thanks to the many advances in deep learning. In this paper, we consider a critical-yet-understudied challenge with unsupervised DOD, that is, effective hyperparameter (HP) tuning/model selection. While several prior work report the sensitivity of OD models to HPs, it becomes ever so critical for the modern DOD models that exhibit a long list of HPs. We introduce HYPER for tuning DOD models, tackling two fundamental challenges: (1) validation without supervision (due to lack of labeled anomalies), and (2) efficient search of the HP/model space (due to exponential growth in the number of HPs). A key idea is to design and train a novel hypernetwork (HN) that maps HPs onto optimal weights of the main DOD model. In turn, HYPER capitalizes on a single HN that can dynamically generate weights for many DOD models (corresponding to varying HPs), which offers significant speed-up. In addition, it employs meta-learning on historical OD tasks with labels to train a proxy validation function, likewise trained with our proposed HN efficiently. Extensive experiments on 35 OD tasks show that HYPER achieves high performance against 8 baselines with significant efficiency gains.", "url": "https://arxiv.org/abs/2307.10529"}, {"metadata": {"arXiv": "2307.10559", "Date": "Thu, 20 Jul 2023 03:54:47 ", "Title": "Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning", "Authors": ["Yutian Pang", "Jueming Hu", "Christopher S. Lieber", "Nancy J. Cooke", "Yongming Liu"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "Air traffic control (ATC) is a safety-critical service system that demands constant attention from ground air traffic controllers (ATCos) to maintain daily aviation operations. The workload of the ATCos can have negative effects on operational safety and airspace usage. To avoid overloading and ensure an acceptable workload level for the ATCos, it is important to predict the ATCos' workload accurately for mitigation actions. In this paper, we first perform a review of research on ATCo workload, mostly from the air traffic perspective. Then, we briefly introduce the setup of the human-in-the-loop (HITL) simulations with retired ATCos, where the air traffic data and workload labels are obtained. The simulations are conducted under three Phoenix approach scenarios while the human ATCos are requested to self-evaluate their workload ratings (i.e., low-1 to high-7). Preliminary data analysis is conducted. Next, we propose a graph-based deep-learning framework with conformal prediction to identify the ATCo workload levels. The number of aircraft under the controller's control varies both spatially and temporally, resulting in dynamically evolving graphs. The experiment results suggest that (a) besides the traffic density feature, the traffic conflict feature contributes to the workload prediction capabilities (i.e., minimum horizontal/vertical separation distance); (b) directly learning from the spatiotemporal graph layout of airspace with graph neural network can achieve higher prediction accuracy, compare to hand-crafted traffic complexity features; (c) conformal prediction is a valuable tool to further boost model prediction accuracy, resulting a range of predicted workload labels. The code used is available at \\href{https://github.com/ymlasu/para-atm-collection/blob/master/air-traffic-prediction/ATC-Workload-Prediction/}{$\\mathsf{Link}$}.", "url": "https://arxiv.org/abs/2307.10559"}, {"metadata": {"arXiv": "2307.10563", "Date": "Thu, 20 Jul 2023 04:00:37 ", "Title": "FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation", "Authors": ["Dhruv Pai", "Andres Carranza", "Rylan Schaeffer", "Arnuv Tandon", "Sanmi Koyejo"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted as BlueSky Poster at 2023 ICML AdvML Workshop"]}, "abstract": "We present FACADE, a novel probabilistic and geometric framework designed for unsupervised mechanistic anomaly detection in deep neural networks. Its primary goal is advancing the understanding and mitigation of adversarial attacks. FACADE aims to generate probabilistic distributions over circuits, which provide critical insights to their contribution to changes in the manifold properties of pseudo-classes, or high-dimensional modes in activation space, yielding a powerful tool for uncovering and combating adversarial attacks. Our approach seeks to improve model robustness, enhance scalable model oversight, and demonstrates promising applications in real-world deployment settings.", "url": "https://arxiv.org/abs/2307.10563"}, {"metadata": {"arXiv": "2307.10569", "Date": "Thu, 20 Jul 2023 04:14:09 ", "Title": "Deceptive Alignment Monitoring", "Authors": ["Andres Carranza", "Dhruv Pai", "Rylan Schaeffer", "Arnuv Tandon", "Sanmi Koyejo"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted as BlueSky Oral to 2023 ICML AdvML Workshop"]}, "abstract": "As the capabilities of large machine learning models continue to grow, and as the autonomy afforded to such models continues to expand, the spectre of a new adversary looms: the models themselves. The threat that a model might behave in a seemingly reasonable manner, while secretly and subtly modifying its behavior for ulterior reasons is often referred to as deceptive alignment in the AI Safety & Alignment communities. Consequently, we call this new direction Deceptive Alignment Monitoring. In this work, we identify emerging directions in diverse machine learning subfields that we believe will become increasingly important and intertwined in the near future for deceptive alignment monitoring, and we argue that advances in these fields present both long-term challenges and new research opportunities. We conclude by advocating for greater involvement by the adversarial machine learning community in these emerging directions.", "url": "https://arxiv.org/abs/2307.10569"}, {"metadata": {"arXiv": "2307.10575", "Date": "Thu, 20 Jul 2023 04:35:50 ", "Title": "Boosting Federated Learning Convergence with Prototype Regularization", "Authors": ["Yu Qiao", "Huy Q. Le", "Choong Seon Hong"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "As a distributed machine learning technique, federated learning (FL) requires clients to collaboratively train a shared model with an edge server without leaking their local data. However, the heterogeneous data distribution among clients often leads to a decrease in model performance. To tackle this issue, this paper introduces a prototype-based regularization strategy to address the heterogeneity in the data distribution. Specifically, the regularization process involves the server aggregating local prototypes from distributed clients to generate a global prototype, which is then sent back to the individual clients to guide their local training. The experimental results on MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3% and 8.9% in average test accuracy, respectively, compared to the most popular baseline FedAvg. Furthermore, our approach has a fast convergence rate in heterogeneous settings.", "url": "https://arxiv.org/abs/2307.10575"}, {"metadata": {"arXiv": "2307.10588", "Date": "Thu, 20 Jul 2023 05:03:25 ", "Title": "Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques", "Authors": ["Hanif Tayarani", "Trisha V. Ramadoss", "Vaishnavi Karanam", "Gil Tal", "Christopher Nitta"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["18 pages,8 figures", "4 tables"]}, "abstract": "Energy systems, climate change, and public health are among the primary reasons for moving toward electrification in transportation. Transportation electrification is being promoted worldwide to reduce emissions. As a result, many automakers will soon start making only battery electric vehicles (BEVs). BEV adoption rates are rising in California, mainly due to climate change and air pollution concerns. While great for climate and pollution goals, improperly managed BEV charging can lead to insufficient charging infrastructure and power outages. This study develops a novel Micro Clustering Deep Neural Network (MCDNN), an artificial neural network algorithm that is highly effective at learning BEVs trip and charging data to forecast BEV charging events, information that is essential for electricity load aggregators and utility managers to provide charging stations and electricity capacity effectively. The MCDNN is configured using a robust dataset of trips and charges that occurred in California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a total of 1570167 vehicle miles traveled. The numerical findings revealed that the proposed MCDNN is more effective than benchmark approaches in this field, such as support vector machine, k nearest neighbors, decision tree, and other neural network-based models in predicting the charging events.", "url": "https://arxiv.org/abs/2307.10588"}, {"metadata": {"arXiv": "2307.10616", "Date": "Thu, 20 Jul 2023 06:32:14 ", "Title": "Heterogeneous Federated Learning: State-of-the-art and Research Challenges", "Authors": ["Mang Ye", "Xiuwen Fang", "Bo Du", "Pong C. Yuen", "Dacheng Tao"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["42 pages", "11 figures", "and 4 tables"]}, "abstract": "Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level. Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field. A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey.", "url": "https://arxiv.org/abs/2307.10616"}, {"metadata": {"arXiv": "2307.10738", "Date": "Thu, 20 Jul 2023 10:04:55 ", "Title": "Fairness-Aware Client Selection for Federated Learning", "Authors": ["Yuxin Shi", "Zelei Liu", "Zhuan Shi", "Han Yu"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["Accepted by ICME 2023"]}, "abstract": "Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients) to train machine learning models collaboratively without revealing private data. Since the FL server can only engage a limited number of clients in each training round, FL client selection has become an important research problem. Existing approaches generally focus on either enhancing FL model performance or enhancing the fair treatment of FL clients. The problem of balancing performance and fairness considerations when selecting FL clients remains open. To address this problem, we propose the Fairness-aware Federated Client Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically adjusts FL clients' selection probabilities by jointly considering their reputations, times of participation in FL tasks and contributions to the resulting model performance. By not using threshold-based reputation filtering, it provides FL clients with opportunities to redeem their reputations after a perceived poor performance, thereby further enhancing fair client treatment. Extensive experiments based on real-world multimedia datasets show that FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on average than the best-performing state-of-the-art approach.", "url": "https://arxiv.org/abs/2307.10738"}, {"metadata": {"arXiv": "2307.10810", "Date": "Thu, 20 Jul 2023 12:20:18 ", "Title": "On Combining Expert Demonstrations in Imitation Learning via Optimal Transport", "Authors": ["Ilana Sebag", "Samuel Cohen", "Marc Peter Deisenroth"], "Categories": "cs.LG cs.AI", "Journal-ref": "NeurIPS Workshop on Optimal Transport and Machine Learning, 2021"}, "abstract": "Imitation learning (IL) seeks to teach agents specific tasks through expert demonstrations. One of the key approaches to IL is to define a distance between agent and expert and to find an agent policy that minimizes that distance. Optimal transport methods have been widely used in imitation learning as they provide ways to measure meaningful distances between agent and expert trajectories. However, the problem of how to optimally combine multiple expert demonstrations has not been widely studied. The standard method is to simply concatenate state (-action) trajectories, which is problematic when trajectories are multi-modal. We propose an alternative method that uses a multi-marginal optimal transport distance and enables the combination of multiple and diverse state-trajectories in the OT sense, providing a more sensible geometric average of the demonstrations. Our approach enables an agent to learn from several experts, and its efficiency is analyzed on OpenAI Gym control environments and demonstrates that the standard method is not always optimal.", "url": "https://arxiv.org/abs/2307.10810"}, {"metadata": {"arXiv": "2307.11044", "Date": "Thu, 20 Jul 2023 17:27:29 ", "Title": "On the Convergence of Bounded Agents", "Authors": ["David Abel", "Andr\\'e Barreto", "Hado van Hasselt", "Benjamin Van Roy", "Doina Precup", "Satinder Singh"], "Categories": "cs.LG cs.AI"}, "abstract": "When has an agent converged? Standard models of the reinforcement learning problem give rise to a straightforward definition of convergence: An agent converges when its behavior or performance in each environment state stops changing. However, as we shift the focus of our learning problem from the environment's state to the agent's state, the concept of an agent's convergence becomes significantly less clear. In this paper, we propose two complementary accounts of agent convergence in a framing of the reinforcement learning problem that centers around bounded agents. The first view says that a bounded agent has converged when the minimal number of states needed to describe the agent's future behavior cannot decrease. The second view says that a bounded agent has converged just when the agent's performance only changes if the agent's internal state changes. We establish basic properties of these two definitions, show that they accommodate typical views of convergence in standard settings, and prove several facts about their nature and relationship. We take these perspectives, definitions, and analysis to bring clarity to a central idea of the field.", "url": "https://arxiv.org/abs/2307.11044"}, {"metadata": {"arXiv": "2307.11046", "Date": "Thu, 20 Jul 2023 17:28:01 ", "Title": "A Definition of Continual Reinforcement Learning", "Authors": ["David Abel", "Andr\\'e Barreto", "Benjamin Van Roy", "Doina Precup", "Hado van Hasselt", "Satinder Singh"], "Categories": "cs.LG cs.AI"}, "abstract": "In this paper we develop a foundation for continual reinforcement learning.", "url": "https://arxiv.org/abs/2307.11046"}, {"metadata": {"arXiv": "2307.11049", "Date": "Thu, 20 Jul 2023 17:30:37 ", "Title": "Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-Loop Feedback", "Authors": ["Marcel Torne", "Max Balsells", "Zihan Wang", "Samedh Desai", "Tao Chen", "Pulkit Agrawal", "Abhishek Gupta"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Exploration and reward specification are fundamental and intertwined challenges for reinforcement learning. Solving sequential decision-making tasks requiring expansive exploration requires either careful design of reward functions or the use of novelty-seeking exploration bonuses. Human supervisors can provide effective guidance in the loop to direct the exploration process, but prior methods to leverage this guidance require constant synchronous high-quality human feedback, which is expensive and impractical to obtain. In this work, we present a technique called Human Guided Exploration (HuGE), which uses low-quality feedback from non-expert users that may be sporadic, asynchronous, and noisy. HuGE guides exploration for reinforcement learning not only in simulation but also in the real world, all without meticulous reward specification. The key concept involves bifurcating human feedback and policy learning: human feedback steers exploration, while self-supervised learning from the exploration data yields unbiased policies. This procedure can leverage noisy, asynchronous human feedback to learn policies with no hand-crafted reward design or exploration bonuses. HuGE is able to learn a variety of challenging multi-stage robotic navigation and manipulation tasks in simulation using crowdsourced feedback from non-expert users. Moreover, this paradigm can be scaled to learning directly on real-world robots, using occasional, asynchronous feedback from human supervisors.", "url": "https://arxiv.org/abs/2307.11049"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

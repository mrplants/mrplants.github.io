<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.09449", "Date": "Fri, 13 Oct 2023 23:56:47 ", "Title": "Pairwise Similarity Learning is SimPLE", "Authors": ["Yandong Wen", "Weiyang Liu", "Yao Feng", "Bhiksha Raj", "Rita Singh", "Adrian Weller", "Michael J. Black", "Bernhard Sch\\\"olkopf"], "Categories": "cs.CV cs.LG", "Comments": ["Published in ICCV 2023 (Project page: https://simple.is.tue.mpg.de/)"]}, "abstract": "In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.09449"}, {"metadata": {"arXiv": "2310.09484", "Date": "Sat, 14 Oct 2023 04:11:01 ", "Title": "Exploring the Design Space of Diffusion Autoencoders for Face Morphing", "Authors": ["Zander Blasingame", "Chen Liu"], "Categories": "cs.CV cs.LG", "Comments": ["Initial pre-print. arXiv admin note: text overlap with arXiv:2301.04218"]}, "abstract": "Face morphs created by Diffusion Autoencoders are a recent innovation and the design space of such an approach has not been well explored. We explore three axes of the design space, i.e., 1) sampling algorithms, 2) the reverse DDIM solver, and 3) partial sampling through small amounts of added noise.", "url": "https://arxiv.org/abs/2310.09484"}, {"metadata": {"arXiv": "2310.09630", "Date": "Sat, 14 Oct 2023 17:52:28 ", "Title": "Real-Time Traffic Sign Detection: A Case Study in a Santa Clara Suburban Neighborhood", "Authors": ["Harish Loghashankar", "Hieu Nguyen"], "Categories": "cs.CV cs.LG"}, "abstract": "This research project aims to develop a real-time traffic sign detection system using the YOLOv5 architecture and deploy it for efficient traffic sign recognition during a drive in a suburban neighborhood. The project's primary objectives are to train the YOLOv5 model on a diverse dataset of traffic sign images and deploy the model on a suitable hardware platform capable of real-time inference. The project will involve collecting a comprehensive dataset of traffic sign images. By leveraging the trained YOLOv5 model, the system will detect and classify traffic signs from a real-time camera on a dashboard inside a vehicle. The performance of the deployed system will be evaluated based on its accuracy in detecting traffic signs, real-time processing speed, and overall reliability. During a case study in a suburban neighborhood, the system demonstrated a notable 96% accuracy in detecting traffic signs. This research's findings have the potential to improve road safety and traffic management by providing timely and accurate real-time information about traffic signs and can pave the way for further research into autonomous driving.", "url": "https://arxiv.org/abs/2310.09630"}, {"metadata": {"arXiv": "2310.09718", "Date": "Sun, 15 Oct 2023 03:08:25 ", "Title": "Efficient and Effective Multi-View Subspace Clustering for Large-scale Data", "Authors": ["Yuxiu Lin", "Hui Liu", "Ren Wang", "Gongguan Chen", "and Caiming Zhang"], "Categories": "cs.CV cs.LG"}, "abstract": "Recent multi-view subspace clustering achieves impressive results utilizing deep networks, where the self-expressive correlation is typically modeled by a fully connected (FC) layer. However, they still suffer from two limitations: i) it is under-explored to extract a unified representation from multiple views that simultaneously satisfy minimal sufficiency and discriminability. ii) the parameter scale of the FC layer is quadratic to the number of samples, resulting in high time and memory costs that significantly degrade their feasibility in large-scale datasets. In light of this, we propose a novel deep framework termed Efficient and Effective Large-scale Multi-View Subspace Clustering (E$^2$LMVSC). Specifically, to enhance the quality of the unified representation, a soft clustering assignment similarity constraint is devised for explicitly decoupling consistent, complementary, and superfluous information across multi-view data. Then, following information bottleneck theory, a sufficient yet minimal unified feature representation is obtained. Moreover, E$^2$LMVSC employs the maximal coding rate reduction principle to promote intra-cluster aggregation and inter-cluster separability within the unified representation. Finally, the self-expressive coefficients are learned by a Relation-Metric Net instead of a parameterized FC layer for greater efficiency. Extensive experiments show that E$^2$LMVSC yields comparable results to existing methods and achieves state-of-the-art clustering performance in large-scale multi-view datasets.", "url": "https://arxiv.org/abs/2310.09718"}, {"metadata": {"arXiv": "2310.09912", "Date": "Sun, 15 Oct 2023 18:44:30 ", "Title": "Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained Diffusion Models", "Authors": ["Zijian Zhang", "Luping Liu. Zhijie Lin", "Yichen Zhu", "Zhou Zhao"], "Categories": "cs.CV cs.LG"}, "abstract": "We propose the first unsupervised and learning-based method to identify interpretable directions in the h-space of pre-trained diffusion models. Our method is derived from an existing technique that operates on the GAN latent space. In a nutshell, we employ a shift control module for pre-trained diffusion models to manipulate a sample into a shifted version of itself, followed by a reconstructor to reproduce both the type and the strength of the manipulation. By jointly optimizing them, the model will spontaneously discover disentangled and interpretable directions. To prevent the discovery of meaningless and destructive directions, we employ a discriminator to maintain the fidelity of shifted sample. Due to the iterative generative process of diffusion models, our training requires a substantial amount of GPU VRAM to store numerous intermediate tensors for back-propagating gradient. To address this issue, we first propose a general VRAM-efficient training algorithm based on gradient checkpointing technique to back-propagate any gradient through the whole generative process, with acceptable occupancy of VRAM and sacrifice of training efficiency. Compared with existing related works on diffusion models, our method inherently identifies global and scalable directions, without necessitating any other complicated procedures. Extensive experiments on various datasets demonstrate the effectiveness of our method.", "url": "https://arxiv.org/abs/2310.09912"}, {"metadata": {"arXiv": "2310.10166", "Date": "Mon, 16 Oct 2023 08:11:41 ", "Title": "The Road to On-board Change Detection: A Lightweight Patch-Level Change Detection Network via Exploring the Potential of Pruning and Pooling", "Authors": ["Lihui Xue", "Zhihao Wang", "Xueqian Wang", "Gang Li"], "Categories": "cs.CV cs.LG"}, "abstract": "Existing satellite remote sensing change detection (CD) methods often crop original large-scale bi-temporal image pairs into small patch pairs and then use pixel-level CD methods to fairly process all the patch pairs. However, due to the sparsity of change in large-scale satellite remote sensing images, existing pixel-level CD methods suffer from a waste of computational cost and memory resources on lots of unchanged areas, which reduces the processing efficiency of on-board platform with extremely limited computation and memory resources. To address this issue, we propose a lightweight patch-level CD network (LPCDNet) to rapidly remove lots of unchanged patch pairs in large-scale bi-temporal image pairs. This is helpful to accelerate the subsequent pixel-level CD processing stage and reduce its memory costs. In our LPCDNet, a sensitivity-guided channel pruning method is proposed to remove unimportant channels and construct the lightweight backbone network on basis of ResNet18 network. Then, the multi-layer feature compression (MLFC) module is designed to compress and fuse the multi-level feature information of bi-temporal image patch. The output of MLFC module is fed into the fully-connected decision network to generate the predicted binary label. Finally, a weighted cross-entropy loss is utilized in the training process of network to tackle the change/unchange class imbalance problem. Experiments on two CD datasets demonstrate that our LPCDNet achieves more than 1000 frames per second on an edge computation platform, i.e., NVIDIA Jetson AGX Orin, which is more than 3 times that of the existing methods without noticeable CD performance loss. In addition, our method reduces more than 60% memory costs of the subsequent pixel-level CD processing stage.", "url": "https://arxiv.org/abs/2310.10166"}, {"metadata": {"arXiv": "2310.10353", "Date": "Mon, 16 Oct 2023 12:42:44 ", "Title": "Multimodal Object Query Initialization for 3D Object Detection", "Authors": ["Mathijs R. van Geerenstein", "Felicia Ruppel", "Klaus Dietmayer", "Dariu M. Gavrila"], "Categories": "cs.CV cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "3D object detection models that exploit both LiDAR and camera sensor features are top performers in large-scale autonomous driving benchmarks. A transformer is a popular network architecture used for this task, in which so-called object queries act as candidate objects. Initializing these object queries based on current sensor inputs is a common practice. For this, existing methods strongly rely on LiDAR data however, and do not fully exploit image features. Besides, they introduce significant latency. To overcome these limitations we propose EfficientQ3M, an efficient, modular, and multimodal solution for object query initialization for transformer-based 3D object detection models. The proposed initialization method is combined with a \"modality-balanced\" transformer decoder where the queries can access all sensor modalities throughout the decoder. In experiments, we outperform the state of the art in transformer-based LiDAR object detection on the competitive nuScenes benchmark and showcase the benefits of input-dependent multimodal query initialization, while being more efficient than the available alternatives for LiDAR-camera initialization. The proposed method can be applied with any combination of sensor modalities as input, demonstrating its modularity.", "url": "https://arxiv.org/abs/2310.10353"}, {"metadata": {"arXiv": "2310.10417", "Date": "Mon, 16 Oct 2023 13:59:56 ", "Title": "Prior-Free Continual Learning with Unlabeled Data in the Wild", "Authors": ["Tao Zhuo", "Zhiyong Cheng", "Hehe Fan", "and Mohan Kankanhalli"], "Categories": "cs.CV cs.LG"}, "abstract": "Continual Learning (CL) aims to incrementally update a trained model on new tasks without forgetting the acquired knowledge of old ones. Existing CL methods usually reduce forgetting with task priors, \\ie using task identity or a subset of previously seen samples for model training. However, these methods would be infeasible when such priors are unknown in real-world applications. To address this fundamental but seldom-studied problem, we propose a Prior-Free Continual Learning (PFCL) method, which learns new tasks without knowing the task identity or any previous data. First, based on a fixed single-head architecture, we eliminate the need for task identity to select the task-specific output head. Second, we employ a regularization-based strategy for consistent predictions between the new and old models, avoiding revisiting previous samples. However, using this strategy alone often performs poorly in class-incremental scenarios, particularly for a long sequence of tasks. By analyzing the effectiveness and limitations of conventional regularization-based methods, we propose enhancing model consistency with an auxiliary unlabeled dataset additionally. Moreover, since some auxiliary data may degrade the performance, we further develop a reliable sample selection strategy to obtain consistent performance improvement. Extensive experiments on multiple image classification benchmark datasets show that our PFCL method significantly mitigates forgetting in all three learning scenarios. Furthermore, when compared to the most recent rehearsal-based methods that replay a limited number of previous samples, PFCL achieves competitive accuracy. Our code is available at: https://github.com/visiontao/pfcl", "url": "https://arxiv.org/abs/2310.10417"}, {"metadata": {"arXiv": "2310.10433", "Date": "Mon, 16 Oct 2023 14:16:47 ", "Title": "Object Detection in Aerial Images in Scarce Data Regimes", "Authors": ["Pierre Le Jeune"], "Categories": "cs.CV cs.LG", "Comments": ["PhD Thesis. Work conducted at L2TI (USPN) and COSE"]}, "abstract": "Most contributions on Few-Shot Object Detection (FSOD) evaluate their methods on natural images only, yet the transferability of the announced performance is not guaranteed for applications on other kinds of images. We demonstrate this with an in-depth analysis of existing FSOD methods on aerial images and observed a large performance gap compared to natural images. Small objects, more numerous in aerial images, are the cause for the apparent performance gap between natural and aerial images. As a consequence, we improve FSOD performance on small objects with a carefully designed attention mechanism. In addition, we also propose a scale-adaptive box similarity criterion, that improves the training and evaluation of FSOD methods, particularly for small objects. We also contribute to generic FSOD with two distinct approaches based on metric learning and fine-tuning. Impressive results are achieved with the fine-tuning method, which encourages tackling more complex scenarios such as Cross-Domain FSOD. We conduct preliminary experiments in this direction and obtain promising results. Finally, we address the deployment of the detection models inside COSE's systems. Detection must be done in real-time in extremely large images (more than 100 megapixels), with limited computation power. Leveraging existing optimization tools such as TensorRT, we successfully tackle this engineering challenge.", "url": "https://arxiv.org/abs/2310.10433"}, {"metadata": {"arXiv": "2310.10563", "Date": "Mon, 16 Oct 2023 16:36:54 ", "Title": "RefConv: Re-parameterized Refocusing Convolution for Powerful ConvNets", "Authors": ["Zhicheng Cai", "Xiaohan Ding", "Qiu Shen", "Xun Cao"], "Categories": "cs.CV cs.LG"}, "abstract": "We propose Re-parameterized Refocusing Convolution (RefConv) as a replacement for regular convolutional layers, which is a plug-and-play module to improve the performance without any inference costs. Specifically, given a pre-trained model, RefConv applies a trainable Refocusing Transformation to the basis kernels inherited from the pre-trained model to establish connections among the parameters. For example, a depth-wise RefConv can relate the parameters of a specific channel of convolution kernel to the parameters of the other kernel, i.e., make them refocus on the other parts of the model they have never attended to, rather than focus on the input features only. From another perspective, RefConv augments the priors of existing model structures by utilizing the representations encoded in the pre-trained parameters as the priors and refocusing on them to learn novel representations, thus further enhancing the representational capacity of the pre-trained model. Experimental results validated that RefConv can improve multiple CNN-based models by a clear margin on image classification (up to 1.47% higher top-1 accuracy on ImageNet), object detection and semantic segmentation without introducing any extra inference costs or altering the original model structure. Further studies demonstrated that RefConv can reduce the redundancy of channels and smooth the loss landscape, which explains its effectiveness.", "url": "https://arxiv.org/abs/2310.10563"}, {"metadata": {"arXiv": "2310.09511", "Date": "Sat, 14 Oct 2023 06:43:58 ", "Title": "Online Parameter Identification of Generalized Non-cooperative Game", "Authors": ["Jianguo Chen and Jinlong Lei and Hongsheng Qi and Yiguang Hong"], "Categories": "cs.GT cs.LG cs.SY eess.SY", "Comments": ["10 pages", "5 figures"]}, "abstract": "This work studies the parameter identification problem of a generalized non-cooperative game, where each player's cost function is influenced by an observable signal and some unknown parameters. We consider the scenario where equilibrium of the game at some observable signals can be observed with noises, whereas our goal is to identify the unknown parameters with the observed data. Assuming that the observable signals and the corresponding noise-corrupted equilibriums are acquired sequentially, we construct this parameter identification problem as online optimization and introduce a novel online parameter identification algorithm. To be specific, we construct a regularized loss function that balances conservativeness and correctiveness, where the conservativeness term ensures that the new estimates do not deviate significantly from the current estimates, while the correctiveness term is captured by the Karush-Kuhn-Tucker conditions. We then prove that when the players' cost functions are linear with respect to the unknown parameters and the learning rate of the online parameter identification algorithm satisfies \\mu_k \\propto 1/\\sqrt{k}, along with other assumptions, the regret bound of the proposed algorithm is O(\\sqrt{K}). Finally, we conduct numerical simulations on a Nash-Cournot problem to demonstrate that the performance of the online identification algorithm is comparable to that of the offline setting.", "url": "https://arxiv.org/abs/2310.09511"}, {"metadata": {"arXiv": "2310.09299", "Date": "Sat, 07 Oct 2023 09:09:19 ", "Title": "Digital Twin Assisted Deep Reinforcement Learning for Online Optimization of Network Slicing Admission Control", "Authors": ["Zhenyu Tao", "Wei Xu", "Xiaohu You"], "Categories": "cs.LG cs.SY eess.SP eess.SY", "Comments": ["13 pages", "11 figures"]}, "abstract": "The proliferation of diverse network services in 5G and beyond networks has led to the emergence of network slicing technologies. Among these, admission control plays a crucial role in achieving specific optimization goals through the selective acceptance of service requests. Although Deep Reinforcement Learning (DRL) forms the foundation in many admission control approaches for its effectiveness and flexibility, the initial instability of DRL models hinders their practical deployment in real-world networks. In this work, we propose a digital twin (DT) assisted DRL solution to address this issue. Specifically, we first formulate the admission decision-making process as a semi-Markov decision process, which is subsequently simplified into an equivalent discrete-time Markov decision process to facilitate the implementation of DRL methods. The DT is established through supervised learning and employed to assist the training phase of the DRL model. Extensive simulations show that the DT-assisted DRL model increased resource utilization by over 40\\% compared to the directly trained state-of-the-art Dueling-DQN and over 20\\% compared to our directly trained DRL model during initial training. This improvement is achieved while preserving the model's capacity to optimize the long-term rewards.", "url": "https://arxiv.org/abs/2310.09299"}, {"metadata": {"arXiv": "2310.09319", "Date": "Fri, 13 Oct 2023 13:03:25 ", "Title": "Topological Data Analysis in smart manufacturing processes -- A survey on the state of the art", "Authors": ["Martin Uray", "Barbara Giunti", "Michael Kerber", "Stefan Huber"], "Categories": "cs.LG math.AT stat.AP", "Comments": ["Preprint still under review"]}, "abstract": "Topological Data Analysis (TDA) is a mathematical method using techniques from topology for the analysis of complex, multi-dimensional data that has been widely and successfully applied in several fields such as medicine, material science, biology, and others. This survey summarizes the state of the art of TDA in yet another application area: industrial manufacturing and production in the context of Industry 4.0. We perform a rigorous and reproducible literature search of applications of TDA on the setting of industrial production and manufacturing. The resulting works are clustered and analyzed based on their application area within the manufacturing process and their input data type. We highlight the key benefits of TDA and their tools in this area and describe its challenges, as well as future potential. Finally, we discuss which TDA methods are underutilized in (the specific area of) industry and the identified types of application, with the goal of prompting more research in this profitable area of application.", "url": "https://arxiv.org/abs/2310.09319"}, {"metadata": {"arXiv": "2310.09336", "Date": "Fri, 13 Oct 2023 18:00:59 ", "Title": "Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task", "Authors": ["Maya Okawa", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka"], "Categories": "cs.LG", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS)"]}, "abstract": "Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of the real world, reliable use of these models in practical applications requires that they exhibit the capability to compose a novel set of concepts to generate outputs not seen in the training data set. Prior work demonstrates that recent diffusion models do exhibit intriguing compositional generalization abilities, but also fail unpredictably. Motivated by this, we perform a controlled study for understanding compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model's ability to generate samples out-of-distribution. Our results show: (i) the order in which the ability to generate samples from a concept and compose them emerges is governed by the structure of the underlying data-generating process; (ii) performance on compositional tasks exhibits a sudden ``emergence'' due to multiplicative reliance on the performance of constituent tasks, partially explaining emergent phenomena seen in generative models; and (iii) composing concepts with lower frequency in the training data to generate out-of-distribution samples requires considerably more optimization steps compared to generating in-distribution samples. Overall, our study lays a foundation for understanding capabilities and compositionality in generative models from a data-centric perspective.", "url": "https://arxiv.org/abs/2310.09336"}, {"metadata": {"arXiv": "2310.09360", "Date": "Fri, 13 Oct 2023 18:59:04 ", "Title": "Exact Verification of ReLU Neural Control Barrier Functions", "Authors": ["Hongchao Zhang", "Junlin Wu", "Yevgeniy Vorobeychik", "Andrew Clark"], "Categories": "cs.LG"}, "abstract": "Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. Based on this condition, we propose an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigate the complexity by only considering the boundary of the safe region and by pruning the segments with Interval Bound Propagation (IBP) and linear relaxation. We evaluate our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Our code is available at https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23.", "url": "https://arxiv.org/abs/2310.09360"}, {"metadata": {"arXiv": "2310.09361", "Date": "Fri, 13 Oct 2023 19:08:21 ", "Title": "Is Certifying $\\ell_p$ Robustness Still Worthwhile?", "Authors": ["Ravi Mangal", "Klas Leino", "Zifan Wang", "Kai Hu", "Weicheng Yu", "Corina Pasareanu", "Anupam Datta", "Matt Fredrikson"], "Categories": "cs.LG"}, "abstract": "Over the years, researchers have developed myriad attacks that exploit the ubiquity of adversarial examples, as well as defenses that aim to guard against the security vulnerabilities posed by such attacks. Of particular interest to this paper are defenses that provide provable guarantees against the class of $\\ell_p$-bounded attacks. Certified defenses have made significant progress, taking robustness certification from toy models and datasets to large-scale problems like ImageNet classification. While this is undoubtedly an interesting academic problem, as the field has matured, its impact in practice remains unclear, thus we find it useful to revisit the motivation for continuing this line of research. There are three layers to this inquiry, which we address in this paper: (1) why do we care about robustness research? (2) why do we care about the $\\ell_p$-bounded threat model? And (3) why do we care about certification as opposed to empirical defenses? In brief, we take the position that local robustness certification indeed confers practical value to the field of machine learning. We focus especially on the latter two questions from above. With respect to the first of the two, we argue that the $\\ell_p$-bounded threat model acts as a minimal requirement for safe application of models in security-critical domains, while at the same time, evidence has mounted suggesting that local robustness may lead to downstream external benefits not immediately related to robustness. As for the second, we argue that (i) certification provides a resolution to the cat-and-mouse game of adversarial attacks; and furthermore, that (ii) perhaps contrary to popular belief, there may not exist a fundamental trade-off between accuracy, robustness, and certifiability, while moreover, certified training techniques constitute a particularly promising way for learning robust models.", "url": "https://arxiv.org/abs/2310.09361"}, {"metadata": {"arXiv": "2310.09382", "Date": "Fri, 13 Oct 2023 20:03:18 ", "Title": "LL-VQ-VAE: Learnable Lattice Vector-Quantization For Efficient Representations", "Authors": ["Ahmed Khalil", "Robert Piechocki", "Raul Santos-Rodriguez"], "Categories": "cs.LG cs.CV"}, "abstract": "In this paper we introduce learnable lattice vector quantization and demonstrate its effectiveness for learning discrete representations. Our method, termed LL-VQ-VAE, replaces the vector quantization layer in VQ-VAE with lattice-based discretization. The learnable lattice imposes a structure over all discrete embeddings, acting as a deterrent against codebook collapse, leading to high codebook utilization. Compared to VQ-VAE, our method obtains lower reconstruction errors under the same training conditions, trains in a fraction of the time, and with a constant number of parameters (equal to the embedding dimension $D$), making it a very scalable approach. We demonstrate these results on the FFHQ-1024 dataset and include FashionMNIST and Celeb-A.", "url": "https://arxiv.org/abs/2310.09382"}, {"metadata": {"arXiv": "2310.09392", "Date": "Fri, 13 Oct 2023 20:26:55 ", "Title": "Machine Learning Estimation of Maximum Vertical Velocity from Radar", "Authors": ["Randy J. Chase", "Amy McGovern", "Cameron Homeyer", "Peter Marinescu", "Corey Potvin"], "Categories": "cs.LG"}, "abstract": "Despite being the source region of severe weather hazards, the quantification of the fast current of upward moving air (i.e., updraft) remains unavailable for operational forecasting. Updraft proxies, like overshooting top area from satellite images, have been linked to severe weather hazards but only relate to a limited portion of the total storm updraft. This study investigates if a machine learning model, namely U-Nets, can skillfully retrieve maximum vertical velocity and its areal extent from 3-dimensional (3D) gridded radar reflectivity alone. The machine learning model is trained using simulated radar reflectivity and vertical velocity from the National Severe Storm Laboratory's convection permitting Warn on Forecast System (WoFS). A parametric regression technique using the Sinh-arcsinh-normal (SHASH) distribution is adapted to run with UNets, allowing for both deterministic and probabilistic predictions of maximum vertical velocity. The best models after hyperparameter search provided less than 50% root mean squared error, a coefficient of determination greater than 0.65 and an intersection over union (IoU) of more than 0.45 on the independent test set composed of WoFS data. Beyond the WoFS analysis, a case study was conducted using real radar data and corresponding dual-Doppler analyses of vertical velocity within a supercell. The U-Net consistently underestimates the dual-Doppler updraft speed estimates by 50%. Meanwhile, the area of the 5 and 10 m s-1 updraft cores show an IoU of 0.25. While the above statistics are not exceptional, the machine learning model enables quick distillation of 3D radar data that is related to the maximum vertical velocity which could be useful in assessing a storm's severe potential.", "url": "https://arxiv.org/abs/2310.09392"}, {"metadata": {"arXiv": "2310.09397", "Date": "Fri, 13 Oct 2023 20:33:33 ", "Title": "Identifiability of Product of Experts Models", "Authors": ["Spencer L. Gordon", "Manav Kant", "Eric Ma", "Leonard J. Schulman", "Andrei Staicu"], "Categories": "cs.LG math.AG math.ST stat.TH", "Comments": ["24 pages", "2 figures"], "MSC-class": "62E10, 62F99, 68T05", "ACM-class": "I.2.6"}, "abstract": "Product of experts (PoE) are layered networks in which the value at each node is an AND (or product) of the values (possibly negated) at its inputs. These were introduced as a neural network architecture that can efficiently learn to generate high-dimensional data which satisfy many low-dimensional constraints -- thereby allowing each individual expert to perform a simple task. PoEs have found a variety of applications in learning. We study the problem of identifiability of a product of experts model having a layer of binary latent variables, and a layer of binary observables that are iid conditional on the latents. The previous best upper bound on the number of observables needed to identify the model was exponential in the number of parameters. We show: (a) When the latents are uniformly distributed, the model is identifiable with a number of observables equal to the number of parameters (and hence best possible). (b) In the more general case of arbitrarily distributed latents, the model is identifiable for a number of observables that is still linear in the number of parameters (and within a factor of two of best-possible). The proofs rely on root interlacing phenomena for some special three-term recurrences.", "url": "https://arxiv.org/abs/2310.09397"}, {"metadata": {"arXiv": "2310.09413", "Date": "Fri, 13 Oct 2023 21:28:19 ", "Title": "ZeroSwap: Data-driven Optimal Market Making in DeFi", "Authors": ["Viraj Nadkarni", "Jiachen Hu", "Ranvir Rana", "Chi Jin", "Sanjeev Kulkarni", "Pramod Viswanath"], "Categories": "cs.LG cs.GT"}, "abstract": "Automated Market Makers (AMMs) are major centers of matching liquidity supply and demand in Decentralized Finance. Their functioning relies primarily on the presence of liquidity providers (LPs) incentivized to invest their assets into a liquidity pool. However, the prices at which a pooled asset is traded is often more stale than the prices on centralized and more liquid exchanges. This leads to the LPs suffering losses to arbitrage. This problem is addressed by adapting market prices to trader behavior, captured via the classical market microstructure model of Glosten and Milgrom. In this paper, we propose the first optimal Bayesian and the first model-free data-driven algorithm to optimally track the external price of the asset. The notion of optimality that we use enforces a zero-profit condition on the prices of the market maker, hence the name ZeroSwap. This ensures that the market maker balances losses to informed traders with profits from noise traders. The key property of our approach is the ability to estimate the external market price without the need for price oracles or loss oracles. Our theoretical guarantees on the performance of both these algorithms, ensuring the stability and convergence of their price recommendations, are of independent interest in the theory of reinforcement learning. We empirically demonstrate the robustness of our algorithms to changing market conditions.", "url": "https://arxiv.org/abs/2310.09413"}, {"metadata": {"arXiv": "2310.09426", "Date": "Fri, 13 Oct 2023 22:14:51 ", "Title": "Offline Reinforcement Learning for Optimizing Production Bidding Policies", "Authors": ["Dmytro Korenkevych", "Frank Cheng", "Artsiom Balakir", "Alex Nikulkov", "Lingnan Gao", "Zhihao Cen", "Zuobing Xu", "Zheqing Zhu"], "Categories": "cs.LG stat.ML"}, "abstract": "The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary base policies with deep neural networks, where only the optimized base policy parameters are eventually deployed, and the neural network part is discarded after training. We demonstrate that such an architecture achieves statistically significant performance gains in both simulated and at-scale production bidding environments. Our approach does not incur additional infrastructure, safety, or explainability costs, as it directly optimizes parameters of existing production routines without replacing them with black box-style models like neural networks.", "url": "https://arxiv.org/abs/2310.09426"}, {"metadata": {"arXiv": "2310.09434", "Date": "Fri, 13 Oct 2023 22:57:46 ", "Title": "Learning nonlinear integral operators via Recurrent Neural Networks and its application in solving Integro-Differential Equations", "Authors": ["Hardeep Bassi", "Yuanran Zhu", "Senwei Liang", "Jia Yin", "Cian C. Reeves", "Vojtech Vlcek", "and Chao Yang"], "Categories": "cs.LG math.DS physics.comp-ph"}, "abstract": "In this paper, we propose using LSTM-RNNs (Long Short-Term Memory-Recurrent Neural Networks) to learn and represent nonlinear integral operators that appear in nonlinear integro-differential equations (IDEs). The LSTM-RNN representation of the nonlinear integral operator allows us to turn a system of nonlinear integro-differential equations into a system of ordinary differential equations for which many efficient solvers are available. Furthermore, because the use of LSTM-RNN representation of the nonlinear integral operator in an IDE eliminates the need to perform a numerical integration in each numerical time evolution step, the overall temporal cost of the LSTM-RNN-based IDE solver can be reduced to $O(n_T)$ from $O(n_T^2)$ if a $n_T$-step trajectory is to be computed. We illustrate the efficiency and robustness of this LSTM-RNN-based numerical IDE solver with a model problem. Additionally, we highlight the generalizability of the learned integral operator by applying it to IDEs driven by different external forces. As a practical application, we show how this methodology can effectively solve the Dyson's equation for quantum many-body systems.", "url": "https://arxiv.org/abs/2310.09434"}, {"metadata": {"arXiv": "2310.09440", "Date": "Fri, 13 Oct 2023 23:12:21 ", "Title": "Target Variable Engineering", "Authors": ["Jessica Clark"], "Categories": "cs.LG"}, "abstract": "How does the formulation of a target variable affect performance within the ML pipeline? The experiments in this study examine numeric targets that have been binarized by comparing against a threshold. We compare the predictive performance of regression models trained to predict the numeric targets vs. classifiers trained to predict their binarized counterparts. Specifically, we make this comparison at every point of a randomized hyperparameter optimization search to understand the effect of computational resource budget on the tradeoff between the two. We find that regression requires significantly more computational effort to converge upon the optimal performance, and is more sensitive to both randomness and heuristic choices in the training process. Although classification can and does benefit from systematic hyperparameter tuning and model selection, the improvements are much less than for regression. This work comprises the first systematic comparison of regression and classification within the framework of computational resource requirements. Our findings contribute to calls for greater replicability and efficiency within the ML pipeline for the sake of building more sustainable and robust AI systems.", "url": "https://arxiv.org/abs/2310.09440"}, {"metadata": {"arXiv": "2310.09473", "Date": "Sat, 14 Oct 2023 02:44:44 ", "Title": "Can CNNs Accurately Classify Human Emotions? A Deep-Learning Facial Expression Recognition Study", "Authors": ["Ashley Jisue Hong", "David DiStefano", "Sejal Dua"], "Categories": "cs.LG cs.NE", "ACM-class": "I.2.6; I.4.m"}, "abstract": "Emotional Artificial Intelligences are currently one of the most anticipated developments of AI. If successful, these AIs will be classified as one of the most complex, intelligent nonhuman entities as they will possess sentience, the primary factor that distinguishes living humans and mechanical machines. For AIs to be classified as \"emotional,\" they should be able to empathize with others and classify their emotions because without such abilities they cannot normally interact with humans. This study investigates the CNN model's ability to recognize and classify human facial expressions (positive, neutral, negative). The CNN model made for this study is programmed in Python and trained with preprocessed data from the Chicago Face Database. The model is intentionally designed with less complexity to further investigate its ability. We hypothesized that the model will perform better than chance (33.3%) in classifying each emotion class of input data. The model accuracy was tested with novel images. Accuracy was summarized in a percentage report, comparative plot, and confusion matrix. Results of this study supported the hypothesis as the model had 75% accuracy over 10,000 images (data), highlighting the possibility of AIs that accurately analyze human emotions and the prospect of viable Emotional AIs.", "url": "https://arxiv.org/abs/2310.09473"}, {"metadata": {"arXiv": "2310.09485", "Date": "Sat, 14 Oct 2023 04:17:00 ", "Title": "Applying Bayesian Ridge Regression AI Modeling in Virus Severity Prediction", "Authors": ["Jai Pal", "Bryan Hong"], "Categories": "cs.LG", "Comments": ["19 Pages", "7 Figures"]}, "abstract": "Artificial intelligence (AI) is a powerful tool for reshaping healthcare systems. In healthcare, AI is invaluable for its capacity to manage vast amounts of data, which can lead to more accurate and speedy diagnoses, ultimately easing the workload on healthcare professionals. As a result, AI has proven itself to be a power tool across various industries, simplifying complex tasks and pattern recognition that would otherwise be overwhelming for humans or traditional computer algorithms. In this paper, we review the strengths and weaknesses of Bayesian Ridge Regression, an AI model that can be used to bring cutting edge virus analysis to healthcare professionals around the world. The model's accuracy assessment revealed promising results, with room for improvement primarily related to data organization. In addition, the severity index serves as a valuable tool to gain a broad overview of patient care needs, aligning with healthcare professionals' preference for broader categorizations.", "url": "https://arxiv.org/abs/2310.09485"}, {"metadata": {"arXiv": "2310.09495", "Date": "Sat, 14 Oct 2023 05:14:51 ", "Title": "Learning In-between Imagery Dynamics via Physical Latent Spaces", "Authors": ["Jihun Han", "Yoonsang Lee", "Anne Gelb"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["26 pages", "13 figures"], "MSC-class": "37M05, 62F99, 68T45"}, "abstract": "We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations (PDEs), our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.", "url": "https://arxiv.org/abs/2310.09495"}, {"metadata": {"arXiv": "2310.09516", "Date": "Sat, 14 Oct 2023 07:02:54 ", "Title": "Efficient Link Prediction via GNN Layers Induced by Negative Sampling", "Authors": ["Yuxin Wang", "Xiannian Hu", "Quan Gan", "Xuanjing Huang", "Xipeng Qiu", "David Wipf"], "Categories": "cs.LG stat.ML", "Comments": ["19 pages", "5 figures"]}, "abstract": "Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, \\emph{node-wise} architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time (since node embeddings are only computed once and repeatedly reused), model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, \\emph{edge-wise} methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with the cost of increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the \\emph{forward pass} explicitly depends on \\emph{both} positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet still cheap node-wise embeddings. This is achieved by recasting the embeddings themselves as minimizers of a forward-pass-specific energy function (distinct from the actual training loss) that favors separation of positive and negative samples. As demonstrated by extensive empirical evaluations, the resulting architecture retains the inference speed of node-wise models, while producing competitive accuracy with edge-wise alternatives.", "url": "https://arxiv.org/abs/2310.09516"}, {"metadata": {"arXiv": "2310.09528", "Date": "Sat, 14 Oct 2023 08:13:43 ", "Title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural Networks", "Authors": ["Woojin Cho", "Kookjin Lee", "Donsub Rim", "Noseong Park"], "Categories": "cs.LG cs.NA math.NA physics.comp-ph"}, "abstract": "In various engineering and applied science applications, repetitive numerical simulations of partial differential equations (PDEs) for varying input parameters are often required (e.g., aircraft shape optimization over many design parameters) and solvers are required to perform rapid execution. In this study, we suggest a path that potentially opens up a possibility for physics-informed neural networks (PINNs), emerging deep-learning-based solvers, to be considered as one such solver. Although PINNs have pioneered a proper integration of deep-learning and scientific computing, they require repetitive time-consuming training of neural networks, which is not suitable for many-query scenarios. To address this issue, we propose a lightweight low-rank PINNs containing only hundreds of model parameters and an associated hypernetwork-based meta-learning algorithm, which allows efficient approximation of solutions of PDEs for varying ranges of PDE input parameters. Moreover, we show that the proposed method is effective in overcoming a challenging issue, known as \"failure modes\" of PINNs.", "url": "https://arxiv.org/abs/2310.09528"}, {"metadata": {"arXiv": "2310.09554", "Date": "Sat, 14 Oct 2023 10:29:52 ", "Title": "Neural network scoring for efficient computing", "Authors": ["Hugo Waltsburger", "Erwan Libessart", "Chengfang Ren", "Anthony Kolar", "Regis Guinvarc'h"], "Categories": "cs.LG", "Comments": ["5 pages", "5 figures"], "ACM-class": "I.2; I.4; C.4", "Journal-ref": "Proceedings of the 2023 IEEE International Symposium on Circuits and Systems (ISCAS)", "DOI": "10.1109/ISCAS46773.2023.10181766"}, "abstract": "Much work has been dedicated to estimating and optimizing workloads in high-performance computing (HPC) and deep learning. However, researchers have typically relied on few metrics to assess the efficiency of those techniques. Most notably, the accuracy, the loss of the prediction, and the computational time with regard to GPUs or/and CPUs characteristics. It is rare to see figures for power consumption, partly due to the difficulty of obtaining accurate power readings. In this paper, we introduce a composite score that aims to characterize the trade-off between accuracy and power consumption measured during the inference of neural networks. For this purpose, we present a new open-source tool allowing researchers to consider more metrics: granular power consumption, but also RAM/CPU/GPU utilization, as well as storage, and network input/output (I/O). To our best knowledge, it is the first fit test for neural architectures on hardware architectures. This is made possible thanks to reproducible power efficiency measurements. We applied this procedure to state-of-the-art neural network architectures on miscellaneous hardware. One of the main applications and novelties is the measurement of algorithmic power efficiency. The objective is to allow researchers to grasp their algorithms' efficiencies better. This methodology was developed to explore trade-offs between energy usage and accuracy in neural networks. It is also useful when fitting hardware for a specific task or to compare two architectures more accurately, with architecture exploration in mind.", "url": "https://arxiv.org/abs/2310.09554"}, {"metadata": {"arXiv": "2310.09574", "Date": "Sat, 14 Oct 2023 12:55:43 ", "Title": "Reduced Policy Optimization for Continuous Control with Hard Constraints", "Authors": ["Shutong Ding", "Jingya Wang", "Yali Du", "Ye Shi"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS2023"]}, "abstract": "Recent advances in constrained reinforcement learning (RL) have endowed reinforcement learning with certain safety guarantees. However, deploying existing constrained RL algorithms in continuous control tasks with general hard constraints remains challenging, particularly in those situations with non-convex hard constraints. Inspired by the generalized reduced gradient (GRG) algorithm, a classical constrained optimization technique, we propose a reduced policy optimization (RPO) algorithm that combines RL with GRG to address general hard constraints. RPO partitions actions into basic actions and nonbasic actions following the GRG method and outputs the basic actions via a policy network. Subsequently, RPO calculates the nonbasic actions by solving equations based on equality constraints using the obtained basic actions. The policy network is then updated by implicitly differentiating nonbasic actions with respect to basic actions. Additionally, we introduce an action projection procedure based on the reduced gradient and apply a modified Lagrangian relaxation technique to ensure inequality constraints are satisfied. To the best of our knowledge, RPO is the first attempt that introduces GRG to RL as a way of efficiently handling both equality and inequality hard constraints. It is worth noting that there is currently a lack of RL environments with complex hard constraints, which motivates us to develop three new benchmarks: two robotics manipulation tasks and a smart grid operation control task. With these benchmarks, RPO achieves better performance than previous constrained RL algorithms in terms of both cumulative reward and constraint violation. We believe RPO, along with the new benchmarks, will open up new opportunities for applying RL to real-world problems with complex constraints.", "url": "https://arxiv.org/abs/2310.09574"}, {"metadata": {"arXiv": "2310.09583", "Date": "Sat, 14 Oct 2023 13:28:36 ", "Title": "Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation", "Authors": ["Shutong Ding", "Tianyu Cui", "Jingya Wang", "Ye Shi"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by NeurIPS2023"]}, "abstract": "Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which explicitly solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem implicitly using a modified Neural ODE via homotopy continuation. Further, we developed an acceleration method for HomoODE with a shared learnable initial point. It is worth noting that our model also provides a better understanding of why Augmented Neural ODEs work as long as the augmented part is regarded as the equilibrium point to find. Comprehensive experiments with several image classification tasks demonstrate that HomoODE surpasses existing implicit models in terms of both accuracy and memory consumption.", "url": "https://arxiv.org/abs/2310.09583"}, {"metadata": {"arXiv": "2310.09586", "Date": "Sat, 14 Oct 2023 13:56:24 ", "Title": "Causality and Independence Enhancement for Biased Node Classification", "Authors": ["Guoxin Chen", "Yongqing Wang", "Fangda Guo", "Qinglang Guo", "Jiangli Shao", "Huawei Shen and Xueqi Cheng"], "Categories": "cs.LG", "Comments": ["10 pages", "5 figures"]}, "abstract": "Most existing methods that address out-of-distribution (OOD) generalization for node classification on graphs primarily focus on a specific type of data biases, such as label selection bias or structural bias. However, anticipating the type of bias in advance is extremely challenging, and designing models solely for one specific type may not necessarily improve overall generalization performance. Moreover, limited research has focused on the impact of mixed biases, which are more prevalent and demanding in real-world scenarios. To address these limitations, we propose a novel Causality and Independence Enhancement (CIE) framework, applicable to various graph neural networks (GNNs). Our approach estimates causal and spurious features at the node representation level and mitigates the influence of spurious correlations through the backdoor adjustment. Meanwhile, independence constraint is introduced to improve the discriminability and stability of causal and spurious features in complex biased environments. Essentially, CIE eliminates different types of data biases from a unified perspective, without the need to design separate methods for each bias as before. To evaluate the performance under specific types of data biases, mixed biases, and low-resource scenarios, we conducted comprehensive experiments on five publicly available datasets. Experimental results demonstrate that our approach CIE not only significantly enhances the performance of GNNs but outperforms state-of-the-art debiased node classification methods.", "url": "https://arxiv.org/abs/2310.09586"}, {"metadata": {"arXiv": "2310.09604", "Date": "Sat, 14 Oct 2023 15:44:14 ", "Title": "Learning Hierarchical Features with Joint Latent Space Energy-Based Prior", "Authors": ["Jiali Cui", "Ying Nian Wu", "Tian Han"], "Categories": "cs.LG cs.CV"}, "abstract": "This paper studies the fundamental problem of multi-layer generator models in learning hierarchical representations. The multi-layer generator model that consists of multiple layers of latent variables organized in a top-down architecture tends to learn multiple levels of data abstraction. However, such multi-layer latent variables are typically parameterized to be Gaussian, which can be less informative in capturing complex abstractions, resulting in limited success in hierarchical representation learning. On the other hand, the energy-based (EBM) prior is known to be expressive in capturing the data regularities, but it often lacks the hierarchical structure to capture different levels of hierarchical representations. In this paper, we propose a joint latent space EBM prior model with multi-layer latent variables for effective hierarchical representation learning. We develop a variational joint learning scheme that seamlessly integrates an inference model for efficient inference. Our experiments demonstrate that the proposed joint EBM prior is effective and expressive in capturing hierarchical representations and modelling data distribution.", "url": "https://arxiv.org/abs/2310.09604"}, {"metadata": {"arXiv": "2310.09615", "Date": "Sat, 14 Oct 2023 16:42:02 ", "Title": "STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning", "Authors": ["Weipu Zhang", "Gang Wang", "Jian Sun", "Yetian Yuan", "Gao Huang"], "Categories": "cs.LG"}, "abstract": "Recently, model-based reinforcement learning algorithms have demonstrated remarkable efficacy in visual input environments. These approaches begin by constructing a parameterized simulation world model of the real environment through self-supervised learning. By leveraging the imagination of the world model, the agent's policy is enhanced without the constraints of sampling from the real environment. The performance of these algorithms heavily relies on the sequence modeling and generation capabilities of the world model. However, constructing a perfectly accurate model of a complex unknown environment is nearly impossible. Discrepancies between the model and reality may cause the agent to pursue virtual goals, resulting in subpar performance in the real environment. Introducing random noise into model-based reinforcement learning has been proven beneficial. In this work, we introduce Stochastic Transformer-based wORld Model (STORM), an efficient world model architecture that combines the strong sequence modeling and generation capabilities of Transformers with the stochastic nature of variational autoencoders. STORM achieves a mean human performance of $126.7\\%$ on the Atari $100$k benchmark, setting a new record among state-of-the-art methods that do not employ lookahead search techniques. Moreover, training an agent with $1.85$ hours of real-time interaction experience on a single NVIDIA GeForce RTX 3090 graphics card requires only $4.3$ hours, showcasing improved efficiency compared to previous methodologies.", "url": "https://arxiv.org/abs/2310.09615"}, {"metadata": {"arXiv": "2310.09620", "Date": "Sat, 14 Oct 2023 17:03:29 ", "Title": "Machine Learning for Urban Air Quality Analytics: A Survey", "Authors": ["Jindong Han", "Weijia Zhang", "Hao Liu", "Hui Xiong"], "Categories": "cs.LG"}, "abstract": "The increasing air pollution poses an urgent global concern with far-reaching consequences, such as premature mortality and reduced crop yield, which significantly impact various aspects of our daily lives. Accurate and timely analysis of air pollution is crucial for understanding its underlying mechanisms and implementing necessary precautions to mitigate potential socio-economic losses. Traditional analytical methodologies, such as atmospheric modeling, heavily rely on domain expertise and often make simplified assumptions that may not be applicable to complex air pollution problems. In contrast, Machine Learning (ML) models are able to capture the intrinsic physical and chemical rules by automatically learning from a large amount of historical observational data, showing great promise in various air quality analytical tasks. In this article, we present a comprehensive survey of ML-based air quality analytics, following a roadmap spanning from data acquisition to pre-processing, and encompassing various analytical tasks such as pollution pattern mining, air quality inference, and forecasting. Moreover, we offer a systematic categorization and summary of existing methodologies and applications, while also providing a list of publicly available air quality datasets to ease the research in this direction. Finally, we identify several promising future research directions. This survey can serve as a valuable resource for professionals seeking suitable solutions for their specific challenges and advancing their research at the cutting edge.", "url": "https://arxiv.org/abs/2310.09620"}, {"metadata": {"arXiv": "2310.09628", "Date": "Sat, 14 Oct 2023 17:46:50 ", "Title": "Federated Battery Diagnosis and Prognosis", "Authors": ["Nur Banu Altinpulluk", "Deniz Altinpulluk", "Paritosh Ramanan", "Noah Paulson", "Feng Qiu", "Susan Babinec", "and Murat Yildirim"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Battery diagnosis, prognosis and health management models play a critical role in the integration of battery systems in energy and mobility fields. However, large-scale deployment of these models is hindered by a myriad of challenges centered around data ownership, privacy, communication, and processing. State-of-the-art battery diagnosis and prognosis methods require centralized collection of data, which further aggravates these challenges. Here we propose a federated battery prognosis model, which distributes the processing of battery standard current-voltage-time-usage data in a privacy-preserving manner. Instead of exchanging raw standard current-voltage-time-usage data, our model communicates only the model parameters, thus reducing communication load and preserving data confidentiality. The proposed model offers a paradigm shift in battery health management through privacy-preserving distributed methods for battery data processing and remaining lifetime prediction.", "url": "https://arxiv.org/abs/2310.09628"}, {"metadata": {"arXiv": "2310.09631", "Date": "Sat, 14 Oct 2023 17:53:55 ", "Title": "Landslide Topology Uncovers Failure Movements", "Authors": ["Kamal Rana", "Kushanav Bhuyan", "Joaquin Vicente Ferrer", "Fabrice Cotton", "Ugur Ozturk", "Filippo Catani", "and Nishant Malik"], "Categories": "cs.LG", "Comments": ["23 pages", "11 figures"]}, "abstract": "The death toll and monetary damages from landslides continue to rise despite advancements in predictive modeling. The predictive capability of these models is limited as landslide databases used in training and assessing the models often have crucial information missing, such as underlying failure types. Here, we present an approach for identifying failure types based on their movements, e.g., slides and flows by leveraging 3D landslide topology. We observe topological proxies reveal prevalent signatures of mass movement mechanics embedded in the landslide's morphology or shape, such as detecting coupled movement styles within complex landslides. We find identical failure types exhibit similar topological properties, and by using them as predictors, we can identify failure types in historic and event-specific landslide databases (including multi-temporal) from various geomorphological and climatic contexts such as Italy, the US Pacific Northwest region, Denmark, Turkey, and China with 80 to 94 % accuracy. To demonstrate the real-world application of the method, we implement it in two undocumented datasets from China and publicly release the datasets. These new insights can considerably improve the performance of landslide predictive models and impact assessments. Moreover, our work introduces a new paradigm for studying landslide shapes to understand underlying processes through the lens of landslide topology.", "url": "https://arxiv.org/abs/2310.09631"}, {"metadata": {"arXiv": "2310.09636", "Date": "Sat, 14 Oct 2023 18:15:51 ", "Title": "Generative Adversarial Training for Text-to-Speech Synthesis Based on Raw Phonetic Input and Explicit Prosody Modelling", "Authors": ["Tiberiu Boros and Stefan Daniel Dumitrescu and Ionut Mironica and Radu Chivereanu"], "Categories": "cs.LG"}, "abstract": "We describe an end-to-end speech synthesis system that uses generative adversarial training. We train our Vocoder for raw phoneme-to-audio conversion, using explicit phonetic, pitch and duration modeling. We experiment with several pre-trained models for contextualized and decontextualized word embeddings and we introduce a new method for highly expressive character voice matching, based on discreet style tokens.", "url": "https://arxiv.org/abs/2310.09636"}, {"metadata": {"arXiv": "2310.09639", "Date": "Sat, 14 Oct 2023 18:42:56 ", "Title": "DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization", "Authors": ["Liang Zhang", "Kiran Koshy Thekumparampil", "Sewoong Oh", "Niao He"], "Categories": "cs.LG cs.CR math.OC stat.ML"}, "abstract": "The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that its complexity hinges primarily on the problem's intrinsic dimension and exhibits only a logarithmic dependence on the ambient dimension. This renders DPZero a highly practical option for real-world LLMs deployments.", "url": "https://arxiv.org/abs/2310.09639"}, {"metadata": {"arXiv": "2310.09656", "Date": "Sat, 14 Oct 2023 19:59:03 ", "Title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space", "Authors": ["Hengrui Zhang", "Jiani Zhang", "Balasubramaniam Srinivasan", "Zhengyuan Shen", "Xiao Qin", "Christos Faloutsos", "Huzefa Rangwala and George Karypis"], "Categories": "cs.LG"}, "abstract": "Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces TABSYN, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed TABSYN include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capture inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data, (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that TABSYN outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines.", "url": "https://arxiv.org/abs/2310.09656"}, {"metadata": {"arXiv": "2310.09657", "Date": "Sat, 14 Oct 2023 20:08:54 ", "Title": "Topology-guided Hypergraph Transformer Network: Unveiling Structural Insights for Improved Representation", "Authors": ["Khaled Mohammed Saifuddin", "Mehmet Emin Aktas", "Esra Akbas"], "Categories": "cs.LG", "Comments": ["9 pages", "3 figures"]}, "abstract": "Hypergraphs, with their capacity to depict high-order relationships, have emerged as a significant extension of traditional graphs. Although Graph Neural Networks (GNNs) have remarkable performance in graph representation learning, their extension to hypergraphs encounters challenges due to their intricate structures. Furthermore, current hypergraph transformers, a special variant of GNN, utilize semantic feature-based self-attention, ignoring topological attributes of nodes and hyperedges. To address these challenges, we propose a Topology-guided Hypergraph Transformer Network (THTN). In this model, we first formulate a hypergraph from a graph while retaining its structural essence to learn higher-order relations within the graph. Then, we design a simple yet effective structural and spatial encoding module to incorporate the topological and spatial information of the nodes into their representation. Further, we present a structure-aware self-attention mechanism that discovers the important nodes and hyperedges from both semantic and structural viewpoints. By leveraging these two modules, THTN crafts an improved node representation, capturing both local and global topological expressions. Extensive experiments conducted on node classification tasks demonstrate that the performance of the proposed model consistently exceeds that of the existing approaches.", "url": "https://arxiv.org/abs/2310.09657"}, {"metadata": {"arXiv": "2310.09672", "Date": "Sat, 14 Oct 2023 22:07:13 ", "Title": "Towards Semi-Structured Automatic ICD Coding via Tree-based Contrastive Learning", "Authors": ["Chang Lu", "Chandan K. Reddy", "Ping Wang", "Yue Ning"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Automatic coding of International Classification of Diseases (ICD) is a multi-label text categorization task that involves extracting disease or procedure codes from clinical notes. Despite the application of state-of-the-art natural language processing (NLP) techniques, there are still challenges including limited availability of data due to privacy constraints and the high variability of clinical notes caused by different writing habits of medical professionals and various pathological features of patients. In this work, we investigate the semi-structured nature of clinical notes and propose an automatic algorithm to segment them into sections. To address the variability issues in existing ICD coding models with limited data, we introduce a contrastive pre-training approach on sections using a soft multi-label similarity metric based on tree edit distance. Additionally, we design a masked section training strategy to enable ICD coding models to locate sections related to ICD codes. Extensive experimental results demonstrate that our proposed training strategies effectively enhance the performance of existing ICD coding methods.", "url": "https://arxiv.org/abs/2310.09672"}, {"metadata": {"arXiv": "2310.09686", "Date": "Sun, 15 Oct 2023 00:05:50 ", "Title": "Enhancing Column Generation by Reinforcement Learning-Based Hyper-Heuristic for Vehicle Routing and Scheduling Problems", "Authors": ["Kuan Xu and Li Shen and Lindong Liu"], "Categories": "cs.LG"}, "abstract": "Column generation (CG) is a vital method to solve large-scale problems by dynamically generating variables. It has extensive applications in common combinatorial optimization, such as vehicle routing and scheduling problems, where each iteration step requires solving an NP-hard constrained shortest path problem. Although some heuristic methods for acceleration already exist, they are not versatile enough to solve different problems. In this work, we propose a reinforcement learning-based hyper-heuristic framework, dubbed RLHH, to enhance the performance of CG. RLHH is a selection module embedded in CG to accelerate convergence and get better integer solutions. In each CG iteration, the RL agent selects a low-level heuristic to construct a reduced network only containing the edges with a greater chance of being part of the optimal solution. In addition, we specify RLHH to solve two typical combinatorial optimization problems: Vehicle Routing Problem with Time Windows (VRPTW) and Bus Driver Scheduling Problem (BDSP). The total cost can be reduced by up to 27.9\\% in VRPTW and 15.4\\% in BDSP compared to the best lower-level heuristic in our tested scenarios, within equivalent or even less computational time. The proposed RLHH is the first RL-based CG method that outperforms traditional approaches in terms of solution quality, which can promote the application of CG in combinatorial optimization.", "url": "https://arxiv.org/abs/2310.09686"}, {"metadata": {"arXiv": "2310.09687", "Date": "Sun, 15 Oct 2023 00:22:12 ", "Title": "When Collaborative Filtering is not Collaborative: Unfairness of PCA for Recommendations", "Authors": ["David Liu", "Jackie Baek", "Tina Eliassi-Rad"], "Categories": "cs.LG cs.CY"}, "abstract": "We study the fairness of dimensionality reduction methods for recommendations. We focus on the established method of principal component analysis (PCA), which identifies latent components and produces a low-rank approximation via the leading components while discarding the trailing components. Prior works have defined notions of \"fair PCA\"; however, these definitions do not answer the following question: what makes PCA unfair? We identify two underlying mechanisms of PCA that induce unfairness at the item level. The first negatively impacts less popular items, due to the fact that less popular items rely on trailing latent components to recover their values. The second negatively impacts the highly popular items, since the leading PCA components specialize in individual popular items instead of capturing similarities between items. To address these issues, we develop a polynomial-time algorithm, Item-Weighted PCA, a modification of PCA that uses item-specific weights in the objective. On a stylized class of matrices, we prove that Item-Weighted PCA using a specific set of weights minimizes a popularity-normalized error metric. Our evaluations on real-world datasets show that Item-Weighted PCA not only improves overall recommendation quality by up to $0.1$ item-level AUC-ROC but also improves on both popular and less popular items.", "url": "https://arxiv.org/abs/2310.09687"}, {"metadata": {"arXiv": "2310.09705", "Date": "Sun, 15 Oct 2023 02:19:07 ", "Title": "SGA: A Graph Augmentation Method for Signed Graph Neural Networks", "Authors": ["Zeyu Zhang", "Shuyan Wan", "Sijie Wang", "Xianda Zheng", "Xinrui Zhang", "Kaiqi Zhao", "Jiamou Liu", "Dong Hao"], "Categories": "cs.LG cs.SI"}, "abstract": "Signed Graph Neural Networks (SGNNs) are vital for analyzing complex patterns in real-world signed graphs containing positive and negative links. However, three key challenges hinder current SGNN-based signed graph representation learning: sparsity in signed graphs leaves latent structures undiscovered, unbalanced triangles pose representation difficulties for SGNN models, and real-world signed graph datasets often lack supplementary information like node labels and features. These constraints limit the potential of SGNN-based representation learning. We address these issues with data augmentation techniques. Despite many graph data augmentation methods existing for unsigned graphs, none are tailored for signed graphs. Our paper introduces the novel Signed Graph Augmentation framework (SGA), comprising three main components. First, we employ the SGNN model to encode the signed graph, extracting latent structural information for candidate augmentation structures. Second, we evaluate these candidate samples (edges) and select the most beneficial ones for modifying the original training set. Third, we propose a novel augmentation perspective that assigns varying training difficulty to training samples, enabling the design of a new training strategy. Extensive experiments on six real-world datasets (Bitcoin-alpha, Bitcoin-otc, Epinions, Slashdot, Wiki-elec, and Wiki-RfA) demonstrate that SGA significantly improves performance across multiple benchmarks. Our method outperforms baselines by up to 22.2% in AUC for SGCN on Wiki-RfA, 33.3% in F1-binary, 48.8% in F1-micro, and 36.3% in F1-macro for GAT on Bitcoin-alpha in link sign prediction.", "url": "https://arxiv.org/abs/2310.09705"}, {"metadata": {"arXiv": "2310.09727", "Date": "Sun, 15 Oct 2023 04:10:44 ", "Title": "Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games", "Authors": ["Youbang Sun", "Tao Liu", "Ruida Zhou", "P. R. Kumar", "Shahin Shahrampour"], "Categories": "cs.LG math.OC", "Comments": ["Will appear in NeurIPS 2023"]}, "abstract": "This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the suboptimality gap, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.", "url": "https://arxiv.org/abs/2310.09727"}, {"metadata": {"arXiv": "2310.09728", "Date": "Sun, 15 Oct 2023 04:23:08 ", "Title": "SVM based Multiclass Classifier for Gait phase Classification using Shank IMU Sensor", "Authors": ["Aswadh Khumar G S and Barath Kumar JK"], "Categories": "cs.LG cs.RO", "Comments": ["6 pages", "6 figures"]}, "abstract": "In this study, a gait phase classification method based on SVM multiclass classification is introduced, with a focus on the precise identification of the stance and swing phases, which are further subdivided into seven phases. Data from individual IMU sensors, such as Shank Acceleration X, Y, Z, Shank Gyro X, and Knee Angles, are used as features in this classification model. The suggested technique successfully classifies the various gait phases with a significant accuracy of about 90.3%. Gait phase classification is crucial, especially in the domains of exoskeletons and prosthetics, where accurate identification of gait phases enables seamless integration with assistive equipment, improving mobility, stability, and energy economy. This study extends the study of gait and offers an effective method for correctly identifying gait phases from Shank IMU sensor data, with potential applications in biomechanical research, exoskeletons, rehabilitation, and prosthetics.", "url": "https://arxiv.org/abs/2310.09728"}, {"metadata": {"arXiv": "2310.09751", "Date": "Sun, 15 Oct 2023 06:30:22 ", "Title": "UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting", "Authors": ["Xu Liu", "Junfeng Hu", "Yuan Li", "Shizhe Diao", "Yuxuan Liang", "Bryan Hooi", "Roger Zimmermann"], "Categories": "cs.LG"}, "abstract": "Multivariate time series forecasting plays a pivotal role in contemporary web technologies. In contrast to conventional methods that involve creating dedicated models for specific time series application domains, this research advocates for a unified model paradigm that transcends domain boundaries. However, learning an effective cross-domain model presents the following challenges. First, various domains exhibit disparities in data characteristics, e.g., the number of variables, posing hurdles for existing models that impose inflexible constraints on these factors. Second, the model may encounter difficulties in distinguishing data from various domains, leading to suboptimal performance in our assessments. Third, the diverse convergence rates of time series domains can also result in compromised empirical performance. To address these issues, we propose UniTime for effective cross-domain time series learning. Concretely, UniTime can flexibly adapt to data with varying characteristics. It also uses domain instructions and a Language-TS Transformer to offer identification information and align two modalities. In addition, UniTime employs masking to alleviate domain convergence speed imbalance issues. Our extensive experiments demonstrate the effectiveness of UniTime in advancing state-of-the-art forecasting performance and zero-shot transferability.", "url": "https://arxiv.org/abs/2310.09751"}, {"metadata": {"arXiv": "2310.09787", "Date": "Sun, 15 Oct 2023 09:54:18 ", "Title": "Dynamic Link Prediction for New Nodes in Temporal Graph Networks", "Authors": ["Xiaobo Zhu", "Yan Wu", "Qinhu Zhang", "Zhanheng Chen", "Ying He"], "Categories": "cs.LG"}, "abstract": "Modelling temporal networks for dynamic link prediction of new nodes has many real-world applications, such as providing relevant item recommendations to new customers in recommender systems and suggesting appropriate posts to new users on social platforms. Unlike old nodes, new nodes have few historical links, which poses a challenge for the dynamic link prediction task. Most existing dynamic models treat all nodes equally and are not specialized for new nodes, resulting in suboptimal performances. In this paper, we consider dynamic link prediction of new nodes as a few-shot problem and propose a novel model based on the meta-learning principle to effectively mitigate this problem. Specifically, we develop a temporal encoder with a node-level span memory to obtain a new node embedding, and then we use a predictor to determine whether the new node generates a link. To overcome the few-shot challenge, we incorporate the encoder-predictor into the meta-learning paradigm, which can learn two types of implicit information during the formation of the temporal network through span adaptation and node adaptation. The acquired implicit information can serve as model initialisation and facilitate rapid adaptation to new nodes through a fine-tuning process on just a few links. Experiments on three publicly available datasets demonstrate the superior performance of our model compared to existing state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.09787"}, {"metadata": {"arXiv": "2310.09789", "Date": "Sun, 15 Oct 2023 10:13:44 ", "Title": "FLrce: Efficient Federated Learning with Relationship-based Client Selection and Early-Stopping Strategy", "Authors": ["Ziru Niu", "Hai Dong", "A. Kai Qin", "Tao Gu"], "Categories": "cs.LG", "Comments": ["arxiv preprint"], "ACM-class": "I.2.6"}, "abstract": "Federated learning (FL) achieves great popularity in broad areas as a powerful interface to offer intelligent services to customers while maintaining data privacy. Nevertheless, FL faces communication and computation bottlenecks due to limited bandwidth and resource constraints of edge devices. To comprehensively address the bottlenecks, the technique of dropout is introduced, where resource-constrained edge devices are allowed to collaboratively train a subset of the global model parameters. However, dropout impedes the learning efficiency of FL under unbalanced local data distributions. As a result, FL requires more rounds to achieve appropriate accuracy, consuming more communication and computation resources. In this paper, we present FLrce, an efficient FL framework with a relationship-based client selection and early-stopping strategy. FLrce accelerates the FL process by selecting clients with more significant effects, enabling the global model to converge to a high accuracy in fewer rounds. FLrce also leverages an early stopping mechanism to terminate FL in advance to save communication and computation resources. Experiment results show that FLrce increases the communication and computation efficiency by 6% to 73.9% and 20% to 79.5%, respectively, while maintaining competitive accuracy.", "url": "https://arxiv.org/abs/2310.09789"}, {"metadata": {"arXiv": "2310.09800", "Date": "Sun, 15 Oct 2023 11:16:14 ", "Title": "Model Inversion Attacks on Homogeneous and Heterogeneous Graph Neural Networks", "Authors": ["Renyang Liu", "Wei Zhou", "Jinhong Zhang", "Xiaoyuan Liu", "Peiyuan Si", "Haoran Li"], "Categories": "cs.LG cs.CV"}, "abstract": "Recently, Graph Neural Networks (GNNs), including Homogeneous Graph Neural Networks (HomoGNNs) and Heterogeneous Graph Neural Networks (HeteGNNs), have made remarkable progress in many physical scenarios, especially in communication applications. Despite achieving great success, the privacy issue of such models has also received considerable attention. Previous studies have shown that given a well-fitted target GNN, the attacker can reconstruct the sensitive training graph of this model via model inversion attacks, leading to significant privacy worries for the AI service provider. We advocate that the vulnerability comes from the target GNN itself and the prior knowledge about the shared properties in real-world graphs. Inspired by this, we propose a novel model inversion attack method on HomoGNNs and HeteGNNs, namely HomoGMI and HeteGMI. Specifically, HomoGMI and HeteGMI are gradient-descent-based optimization methods that aim to maximize the cross-entropy loss on the target GNN and the $1^{st}$ and $2^{nd}$-order proximities on the reconstructed graph. Notably, to the best of our knowledge, HeteGMI is the first attempt to perform model inversion attacks on HeteGNNs. Extensive experiments on multiple benchmarks demonstrate that the proposed method can achieve better performance than the competitors.", "url": "https://arxiv.org/abs/2310.09800"}, {"metadata": {"arXiv": "2310.09827", "Date": "Sun, 15 Oct 2023 13:18:31 ", "Title": "VFLAIR: A Research Library and Benchmark for Vertical Federated Learning", "Authors": ["Tianyuan Zou", "Zixuan Gu", "Yu He", "Hideaki Takahashi", "Yang Liu", "Guangnan Ye", "Ya-Qin Zhang"], "Categories": "cs.LG", "Comments": ["28 pages", "12 figures", "12 tabels"]}, "abstract": "Vertical Federated Learning (VFL) has emerged as a collaborative training paradigm that allows participants with different features of the same group of users to accomplish cooperative training without exposing their raw data or model parameters. VFL has gained significant attention for its research potential and real-world applications in recent years, but still faces substantial challenges, such as in defending various kinds of data inference and backdoor attacks. Moreover, most of existing VFL projects are industry-facing and not easily used for keeping track of the current research progress. To address this need, we present an extensible and lightweight VFL framework VFLAIR (available at https://github.com/FLAIR-THU/VFLAIR), which supports VFL training with a variety of models, datasets and protocols, along with standardized modules for comprehensive evaluations of attacks and defense strategies. We also benchmark 11 attacks and 8 defenses performance under different communication and model partition settings and draw concrete insights and recommendations on the choice of defense strategies for different practical VFL deployment scenario.", "url": "https://arxiv.org/abs/2310.09827"}, {"metadata": {"arXiv": "2310.09847", "Date": "Sun, 15 Oct 2023 14:18:42 ", "Title": "XRMDN: A Recurrent Mixture Density Networks-based Architecture for Short-Term Probabilistic Demand Forecasting in Mobility-on-Demand Systems with High Volatility", "Authors": ["Xiaoming Li", "Hubert Normandin-Taillon", "Chun Wang", "Xiao Huang"], "Categories": "cs.LG", "Comments": ["11 pages", "14 figures", "5 tables"]}, "abstract": "In real Mobility-on-Demand (MoD) systems, demand is subject to high and dynamic volatility, which is difficult to predict by conventional time-series forecasting approaches. Most existing forecasting approaches yield the point value as the prediction result, which ignores the uncertainty that exists in the forecasting result. This will lead to the forecasting result severely deviating from the true demand value due to the high volatility existing in demand. To fill the gap, we propose an extended recurrent mixture density network (XRMDN), which extends the weight and mean neural networks to recurrent neural networks. The recurrent neurons for mean and variance can capture the trend of the historical data-series data, which enables a better forecasting result in dynamic and high volatility. We conduct comprehensive experiments on one taxi trip record and one bike-sharing real MoD data set to validate the performance of XRMDN. Specifically, we compare our model to three types of benchmark models, including statistical, machine learning, and deep learning models on three evaluation metrics. The validation results show that XRMDN outperforms the three groups of benchmark models in terms of the evaluation metrics. Most importantly, XRMDN substantially improves the forecasting accuracy with the demands in strong volatility. Last but not least, this probabilistic demand forecasting model contributes not only to the demand prediction in MoD systems but also to other optimization application problems, especially optimization under uncertainty, in MoD applications.", "url": "https://arxiv.org/abs/2310.09847"}, {"metadata": {"arXiv": "2310.09852", "Date": "Sun, 15 Oct 2023 14:51:22 ", "Title": "Alpha Elimination: Using Deep Reinforcement Learning to Reduce Fill-In during Sparse Matrix Decomposition", "Authors": ["Arpan Dasgupta", "Pawan Kumar"], "Categories": "cs.LG", "Comments": ["accepted to ECML 2023", "Research Track"]}, "abstract": "A large number of computational and scientific methods commonly require decomposing a sparse matrix into triangular factors as LU decomposition. A common problem faced during this decomposition is that even though the given matrix may be very sparse, the decomposition may lead to a denser triangular factors due to fill-in. A significant fill-in may lead to prohibitively larger computational costs and memory requirement during decomposition as well as during the solve phase. To this end, several heuristic sparse matrix reordering methods have been proposed to reduce fill-in before the decomposition. However, finding an optimal reordering algorithm that leads to minimal fill-in during such decomposition is known to be a NP-hard problem. A reinforcement learning based approach is proposed for this problem. The sparse matrix reordering problem is formulated as a single player game. More specifically, Monte-Carlo tree search in combination with neural network is used as a decision making algorithm to search for the best move in our game. The proposed method, alphaElimination is found to produce significantly lesser non-zeros in the LU decomposition as compared to existing state-of-the-art heuristic algorithms with little to no increase in overall running time of the algorithm. The code for the project will be publicly available here\\footnote{\\url{https://github.com/misterpawan/alphaEliminationPaper}}.", "url": "https://arxiv.org/abs/2310.09852"}, {"metadata": {"arXiv": "2310.09872", "Date": "Sun, 15 Oct 2023 16:04:28 ", "Title": "Empower Text-Attributed Graphs Learning with Large Language Models (LLMs)", "Authors": ["Jianxiang Yu", "Yuxiang Ren", "Chenghua Gong", "Jiaqi Tan", "Xiang Li", "Xuecang Zhang"], "Categories": "cs.LG"}, "abstract": "Text-attributed graphs have recently garnered significant attention due to their wide range of applications in web domains. Existing methodologies employ word embedding models for acquiring text representations as node features, which are subsequently fed into Graph Neural Networks (GNNs) for training. Recently, the advent of Large Language Models (LLMs) has introduced their powerful capabilities in information retrieval and text generation, which can greatly enhance the text attributes of graph data. Furthermore, the acquisition and labeling of extensive datasets are both costly and time-consuming endeavors. Consequently, few-shot learning has emerged as a crucial problem in the context of graph learning tasks. In order to tackle this challenge, we propose a lightweight paradigm called ENG, which adopts a plug-and-play approach to empower text-attributed graphs through node generation using LLMs. Specifically, we utilize LLMs to extract semantic information from the labels and generate samples that belong to these categories as exemplars. Subsequently, we employ an edge predictor to capture the structural information inherent in the raw dataset and integrate the newly generated samples into the original graph. This approach harnesses LLMs for enhancing class-level information and seamlessly introduces labeled nodes and edges without modifying the raw dataset, thereby facilitating the node classification task in few-shot scenarios. Extensive experiments demonstrate the outstanding performance of our proposed paradigm, particularly in low-shot scenarios. For instance, in the 1-shot setting of the ogbn-arxiv dataset, ENG achieves a 76% improvement over the baseline model.", "url": "https://arxiv.org/abs/2310.09872"}, {"metadata": {"arXiv": "2310.09890", "Date": "Sun, 15 Oct 2023 17:14:17 ", "Title": "Score-Based Methods for Discrete Optimization in Deep Learning", "Authors": ["Eric Lei", "Arman Adibi", "Hamed Hassani"], "Categories": "cs.LG"}, "abstract": "Discrete optimization problems often arise in deep learning tasks, despite the fact that neural networks typically operate on continuous data. One class of these problems involve objective functions which depend on neural networks, but optimization variables which are discrete. Although the discrete optimization literature provides efficient algorithms, they are still impractical in these settings due to the high cost of an objective function evaluation, which involves a neural network forward-pass. In particular, they require $O(n)$ complexity per iteration, but real data such as point clouds have values of $n$ in thousands or more. In this paper, we investigate a score-based approximation framework to solve such problems. This framework uses a score function as a proxy for the marginal gain of the objective, leveraging embeddings of the discrete variables and speed of auto-differentiation frameworks to compute backward-passes in parallel. We experimentally demonstrate, in adversarial set classification tasks, that our method achieves a superior trade-off in terms of speed and solution quality compared to heuristic methods.", "url": "https://arxiv.org/abs/2310.09890"}, {"metadata": {"arXiv": "2310.09924", "Date": "Sun, 15 Oct 2023 19:23:05 ", "Title": "Deep Reinforcement Learning with Explicit Context Representation", "Authors": ["Francisco Munguia-Galeano", "Ah-Hwee Tan", "Ze Ji"], "Categories": "cs.LG", "Comments": ["Manuscript accepted for publication as regular paper in IEEE Transactions on Neural Networks and Learning Systems"]}, "abstract": "Reinforcement learning (RL) has shown an outstanding capability for solving complex computational problems. However, most RL algorithms lack an explicit method that would allow learning from contextual information. Humans use context to identify patterns and relations among elements in the environment, along with how to avoid making wrong actions. On the other hand, what may seem like an obviously wrong decision from a human perspective could take hundreds of steps for an RL agent to learn to avoid. This paper proposes a framework for discrete environments called Iota explicit context representation (IECR). The framework involves representing each state using contextual key frames (CKFs), which can then be used to extract a function that represents the affordances of the state; in addition, two loss functions are introduced with respect to the affordances of the state. The novelty of the IECR framework lies in its capacity to extract contextual information from the environment and learn from the CKFs' representation. We validate the framework by developing four new algorithms that learn using context: Iota deep Q-network (IDQN), Iota double deep Q-network (IDDQN), Iota dueling deep Q-network (IDuDQN), and Iota dueling double deep Q-network (IDDDQN). Furthermore, we evaluate the framework and the new algorithms in five discrete environments. We show that all the algorithms, which use contextual information, converge in around 40,000 training steps of the neural networks, significantly outperforming their state-of-the-art equivalents.", "url": "https://arxiv.org/abs/2310.09924"}, {"metadata": {"arXiv": "2310.09961", "Date": "Sun, 15 Oct 2023 21:40:16 ", "Title": "Theoretical Evaluation of Asymmetric Shapley Values for Root-Cause Analysis", "Authors": ["Domokos M. Kelen", "Mih\\'aly Petreczky", "P\\'eter Kersch", "Andr\\'as A. Bencz\\'ur"], "Categories": "cs.LG stat.ME", "Comments": ["10 pages", "6 figures", "to be published in IEEE ICDM 2023"]}, "abstract": "In this work, we examine Asymmetric Shapley Values (ASV), a variant of the popular SHAP additive local explanation method. ASV proposes a way to improve model explanations incorporating known causal relations between variables, and is also considered as a way to test for unfair discrimination in model predictions. Unexplored in previous literature, relaxing symmetry in Shapley values can have counter-intuitive consequences for model explanation. To better understand the method, we first show how local contributions correspond to global contributions of variance reduction. Using variance, we demonstrate multiple cases where ASV yields counter-intuitive attributions, arguably producing incorrect results for root-cause analysis. Second, we identify generalized additive models (GAM) as a restricted class for which ASV exhibits desirable properties. We support our arguments by proving multiple theoretical results about the method. Finally, we demonstrate the use of asymmetric attributions on multiple real-world datasets, comparing the results with and without restricted model families using gradient boosting and deep learning models.", "url": "https://arxiv.org/abs/2310.09961"}, {"metadata": {"arXiv": "2310.09971", "Date": "Sun, 15 Oct 2023 22:20:39 ", "Title": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents", "Authors": ["Jake Grigsby", "Linxi Fan", "Yuke Zhu"], "Categories": "cs.LG"}, "abstract": "We introduce AMAGO, an in-context Reinforcement Learning (RL) agent that uses sequence models to tackle the challenges of generalization, long-term memory, and meta-learning. Recent works have shown that off-policy learning can make in-context RL with recurrent policies viable. Nonetheless, these approaches require extensive tuning and limit scalability by creating key bottlenecks in agents' memory capacity, planning horizon, and model size. AMAGO revisits and redesigns the off-policy in-context approach to successfully train long-sequence Transformers over entire rollouts in parallel with end-to-end RL. Our agent is uniquely scalable and applicable to a wide range of problems. We demonstrate its strong performance empirically in meta-RL and long-term memory domains. AMAGO's focus on sparse rewards and off-policy data also allows in-context learning to extend to goal-conditioned problems with challenging exploration. When combined with a novel hindsight relabeling scheme, AMAGO can solve a previously difficult category of open-world domains, where agents complete many possible instructions in procedurally generated environments. We evaluate our agent on three goal-conditioned domains and study how its individual improvements connect to create a generalist policy.", "url": "https://arxiv.org/abs/2310.09971"}, {"metadata": {"arXiv": "2310.09988", "Date": "Mon, 16 Oct 2023 00:06:32 ", "Title": "Personalization of CTC-based End-to-End Speech Recognition Using Pronunciation-Driven Subword Tokenization", "Authors": ["Zhihong Lei", "Ernest Pusateri", "Shiyi Han", "Leo Liu", "Mingbin Xu", "Tim Ng", "Ruchir Travadi", "Youyuan Zhang", "Mirko Hannemann", "Man-Hung Siu", "Zhen Huang"], "Categories": "cs.LG"}, "abstract": "Recent advances in deep learning and automatic speech recognition have improved the accuracy of end-to-end speech recognition systems, but recognition of personal content such as contact names remains a challenge. In this work, we describe our personalization solution for an end-to-end speech recognition system based on connectionist temporal classification. Building on previous work, we present a novel method for generating additional subword tokenizations for personal entities from their pronunciations. We show that using this technique in combination with two established techniques, contextual biasing and wordpiece prior normalization, we are able to achieve personal named entity accuracy on par with a competitive hybrid system.", "url": "https://arxiv.org/abs/2310.09988"}, {"metadata": {"arXiv": "2310.09991", "Date": "Mon, 16 Oct 2023 00:35:24 ", "Title": "Applications of Machine Learning in Biopharmaceutical Process Development and Manufacturing: Current Trends, Challenges, and Opportunities", "Authors": ["Thanh Tung Khuat", "Robert Bassett", "Ellen Otte", "Alistair Grevis-James", "Bogdan Gabrys"], "Categories": "cs.LG", "Comments": ["155 pages"], "ACM-class": "A.1; J.3; I.2.0; I.2.6; I.2.m; I.5.4"}, "abstract": "While machine learning (ML) has made significant contributions to the biopharmaceutical field, its applications are still in the early stages in terms of providing direct support for quality-by-design based development and manufacturing of biopharmaceuticals, hindering the enormous potential for bioprocesses automation from their development to manufacturing. However, the adoption of ML-based models instead of conventional multivariate data analysis methods is significantly increasing due to the accumulation of large-scale production data. This trend is primarily driven by the real-time monitoring of process variables and quality attributes of biopharmaceutical products through the implementation of advanced process analytical technologies. Given the complexity and multidimensionality of a bioproduct design, bioprocess development, and product manufacturing data, ML-based approaches are increasingly being employed to achieve accurate, flexible, and high-performing predictive models to address the problems of analytics, monitoring, and control within the biopharma field. This paper aims to provide a comprehensive review of the current applications of ML solutions in a bioproduct design, monitoring, control, and optimisation of upstream, downstream, and product formulation processes. Finally, this paper thoroughly discusses the main challenges related to the bioprocesses themselves, process data, and the use of machine learning models in biopharmaceutical process development and manufacturing. Moreover, it offers further insights into the adoption of innovative machine learning methods and novel trends in the development of new digital biopharma solutions.", "url": "https://arxiv.org/abs/2310.09991"}, {"metadata": {"arXiv": "2310.10012", "Date": "Mon, 16 Oct 2023 02:11:20 ", "Title": "Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?", "Authors": ["Yu-Lin Tsai", "Chia-Yi Hsu", "Chulin Xie", "Chih-Hsun Lin", "Jia-You Chen", "Bo Li", "Pin-Yu Chen", "Chia-Mu Yu", "Chun-Ying Huang"], "Categories": "cs.LG"}, "abstract": "Diffusion models for text-to-image (T2I) synthesis, such as Stable Diffusion (SD), have recently demonstrated exceptional capabilities for generating high-quality content. However, this progress has raised several concerns of potential misuse, particularly in creating copyrighted, prohibited, and restricted content, or NSFW (not safe for work) images. While efforts have been made to mitigate such problems, either by implementing a safety filter at the evaluation stage or by fine-tuning models to eliminate undesirable concepts or styles, the effectiveness of these safety measures in dealing with a wide range of prompts remains largely unexplored. In this work, we aim to investigate these safety mechanisms by proposing one novel concept retrieval algorithm for evaluation. We introduce Ring-A-Bell, a model-agnostic red-teaming tool for T2I diffusion models, where the whole evaluation can be prepared in advance without prior knowledge of the target model. Specifically, Ring-A-Bell first performs concept extraction to obtain holistic representations for sensitive and inappropriate concepts. Subsequently, by leveraging the extracted concept, Ring-A-Bell automatically identifies problematic prompts for diffusion models with the corresponding generation of inappropriate content, allowing the user to assess the reliability of deployed safety mechanisms. Finally, we empirically validate our method by testing online services such as Midjourney and various methods of concept removal. Our results show that Ring-A-Bell, by manipulating safe prompting benchmarks, can transform prompts that were originally regarded as safe to evade existing safety mechanisms, thus revealing the defects of the so-called safety mechanisms which could practically lead to the generation of harmful contents.", "url": "https://arxiv.org/abs/2310.10012"}, {"metadata": {"arXiv": "2310.10030", "Date": "Mon, 16 Oct 2023 03:16:21 ", "Title": "Unraveling Fundamental Properties of Power System Resilience Curves using Unsupervised Machine Learning", "Authors": ["Bo Li", "Ali Mostafavi"], "Categories": "cs.LG"}, "abstract": "The standard model of infrastructure resilience, the resilience triangle, has been the primary way of characterizing and quantifying infrastructure resilience. However, the theoretical model merely provides a one-size-fits-all framework for all infrastructure systems. Most of the existing studies examine the characteristics of infrastructure resilience curves based on analytical models constructed upon simulated system performance. Limited empirical studies hindered our ability to fully understand and predict resilience characteristics in infrastructure systems. To address this gap, this study examined over 200 resilience curves related to power outages in three major extreme weather events. Using unsupervised machine learning, we examined different curve archetypes, as well as the fundamental properties of each resilience curve archetype. The results show two primary archetypes for power system resilience curves, triangular, and trapezoidal curves. Triangular curves characterize resilience behavior based on 1. critical functionality threshold, 2. critical functionality recovery rate, and 3. recovery pivot point. Trapezoidal archetypes explain resilience curves based on 1. duration of sustained function loss and 2. constant recovery rate. The longer the duration of sustained function loss, the slower the constant rate of recovery. The findings of this study provide novel perspectives enabling better understanding and prediction of resilience performance of power system infrastructures.", "url": "https://arxiv.org/abs/2310.10030"}, {"metadata": {"arXiv": "2310.10039", "Date": "Mon, 16 Oct 2023 03:51:13 ", "Title": "TpopT: Efficient Trainable Template Optimization on Low-Dimensional Manifolds", "Authors": ["Jingkai Yan", "Shiyu Wang", "Xinyu Rain Wei", "Jimmy Wang", "Zsuzsanna M\\'arka", "Szabolcs M\\'arka", "John Wright"], "Categories": "cs.LG eess.SP"}, "abstract": "In scientific and engineering scenarios, a recurring task is the detection of low-dimensional families of signals or patterns. A classic family of approaches, exemplified by template matching, aims to cover the search space with a dense template bank. While simple and highly interpretable, it suffers from poor computational efficiency due to unfavorable scaling in the signal space dimensionality. In this work, we study TpopT (TemPlate OPTimization) as an alternative scalable framework for detecting low-dimensional families of signals which maintains high interpretability. We provide a theoretical analysis of the convergence of Riemannian gradient descent for TpopT, and prove that it has a superior dimension scaling to covering. We also propose a practical TpopT framework for nonparametric signal sets, which incorporates techniques of embedding and kernel interpolation, and is further configurable into a trainable network architecture by unrolled optimization. The proposed trainable TpopT exhibits significantly improved efficiency-accuracy tradeoffs for gravitational wave detection, where matched filtering is currently a method of choice. We further illustrate the general applicability of this approach with experiments on handwritten digit data.", "url": "https://arxiv.org/abs/2310.10039"}, {"metadata": {"arXiv": "2310.10045", "Date": "Mon, 16 Oct 2023 04:03:36 ", "Title": "Symmetrical SyncMap for Imbalanced General Chunking Problems", "Authors": ["Heng Zhang and Danilo Vasconcellos Vargas"], "Categories": "cs.LG cs.NE", "Comments": ["40 pages", "19 figures"], "Journal-ref": "Heng Zhang, Danilo Vasconcellos Vargas, Symmetrical SyncMap for imbalanced general chunking problems, Physica D: Nonlinear Phenomena, Volume 456, 2023, 133923, ISSN 0167-2789", "DOI": "10.1016/j.physd.2023.133923"}, "abstract": "Recently, SyncMap pioneered an approach to learn complex structures from sequences as well as adapt to any changes in underlying structures. This is achieved by using only nonlinear dynamical equations inspired by neuron group behaviors, i.e., without loss functions. Here we propose Symmetrical SyncMap that goes beyond the original work to show how to create dynamical equations and attractor-repeller points which are stable over the long run, even dealing with imbalanced continual general chunking problems (CGCPs). The main idea is to apply equal updates from negative and positive feedback loops by symmetrical activation. We then introduce the concept of memory window to allow for more positive updates. Our algorithm surpasses or ties other unsupervised state-of-the-art baselines in all 12 imbalanced CGCPs with various difficulties, including dynamically changing ones. To verify its performance in real-world scenarios, we conduct experiments on several well-studied structure learning problems. The proposed method surpasses substantially other methods in 3 out of 4 scenarios, suggesting that symmetrical activation plays a critical role in uncovering topological structures and even hierarchies encoded in temporal data.", "url": "https://arxiv.org/abs/2310.10045"}, {"metadata": {"arXiv": "2310.10056", "Date": "Mon, 16 Oct 2023 04:35:44 ", "Title": "Latent Conservative Objective Models for Data-Driven Crystal Structure Prediction", "Authors": ["Han Qi", "Xinyang Geng", "Stefano Rando", "Iku Ohama", "Aviral Kumar", "Sergey Levine"], "Categories": "cs.LG"}, "abstract": "In computational chemistry, crystal structure prediction (CSP) is an optimization problem that involves discovering the lowest energy stable crystal structure for a given chemical formula. This problem is challenging as it requires discovering globally optimal designs with the lowest energies on complex manifolds. One approach to tackle this problem involves building simulators based on density functional theory (DFT) followed by running search in simulation, but these simulators are painfully slow. In this paper, we study present and study an alternate, data-driven approach to crystal structure prediction: instead of directly searching for the most stable structures in simulation, we train a surrogate model of the crystal formation energy from a database of existing crystal structures, and then optimize this model with respect to the parameters of the crystal structure. This surrogate model is trained to be conservative so as to prevent exploitation of its errors by the optimizer. To handle optimization in the non-Euclidean space of crystal structures, we first utilize a state-of-the-art graph diffusion auto-encoder (CD-VAE) to convert a crystal structure into a vector-based search space and then optimize a conservative surrogate model of the crystal energy, trained on top of this vector representation. We show that our approach, dubbed LCOMs (latent conservative objective models), performs comparably to the best current approaches in terms of success rate of structure prediction, while also drastically reducing computational cost.", "url": "https://arxiv.org/abs/2310.10056"}, {"metadata": {"arXiv": "2310.10060", "Date": "Mon, 16 Oct 2023 04:49:51 ", "Title": "Data Augmentation for Time-Series Classification: a Comprehensive Survey", "Authors": ["Zijun Gao", "Lingbo Li and Tianhua Xu"], "Categories": "cs.LG"}, "abstract": "Data Augmentation (DA) for Time Series Classification (TSC) is a common technique in machine learning to increase the number of training samples, which enhances model performance, enriches the dataset variety, and helps mitigate overfitting. Nonetheless, this technique is currently faced with challenges characterized by incomplete reviews, ambiguous taxonomies, insufficient evaluations, and user-unfriendly tools. This study undertakes a detailed exploration of DA for TSC. We first conducted a thorough review of the developments in the field of DA for TSC over the past 10 years since existing surveys on DA for TSC are not comprehensive enough. Our efforts encompassed gathering more than 60 distinct DA techniques from a pool over 100 research papers. This endeavor culminated in the creation of an innovative taxonomy exclusively tailored to DA within the TSC domain. The taxonomy organizes methods into five main categories: Transformation-Based, Pattern-Based, Generative, Decomposition-Based, and Automated Data Augmentation. This classification serves as a sturdy reference for researchers when choosing methods. In addition, since there is a lack of comprehensive and detailed evaluations of popular data augmentation methods, we conduct a comprehensive assessment. More than 15 DA methods were tested on 8 UCR time-series datasets using the ResNet and deploying a multi-metric evaluation strategy that includes Accuracy, Method Ranking, and Residual Analysis, the outcome was a baseline accuracy of 88.94 +- 11.83%. Findings highlighted the variable effectiveness of DA methods, for instance, methods like Permutation enhanced performance while Rotation decreased accuracy. Dataset properties also profoundly influence DA efficacy, we give users accurate and practical advice based on our experimental results to guide them in choosing the most appropriate DA methods for different data characteristics.", "url": "https://arxiv.org/abs/2310.10060"}, {"metadata": {"arXiv": "2310.10074", "Date": "Mon, 16 Oct 2023 05:15:35 ", "Title": "SoTTA: Robust Test-Time Adaptation on Noisy Data Streams", "Authors": ["Taesik Gong", "Yewon Kim", "Taeckyung Lee", "Sorn Chottananurak", "Sung-Ju Lee"], "Categories": "cs.LG", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Test-time adaptation (TTA) aims to address distributional shifts between training and testing data using only unlabeled test data streams for continual model adaptation. However, most TTA methods assume benign test streams, while test samples could be unexpectedly diverse in the wild. For instance, an unseen object or noise could appear in autonomous driving. This leads to a new threat to existing TTA algorithms; we found that prior TTA algorithms suffer from those noisy test samples as they blindly adapt to incoming samples. To address this problem, we present Screening-out Test-Time Adaptation (SoTTA), a novel TTA algorithm that is robust to noisy samples. The key enabler of SoTTA is two-fold: (i) input-wise robustness via high-confidence uniform-class sampling that effectively filters out the impact of noisy samples and (ii) parameter-wise robustness via entropy-sharpness minimization that improves the robustness of model parameters against large gradients from noisy samples. Our evaluation with standard TTA benchmarks with various noisy scenarios shows that our method outperforms state-of-the-art TTA methods under the presence of noisy samples and achieves comparable accuracy to those methods without noisy samples. The source code is available at https://github.com/taeckyung/SoTTA .", "url": "https://arxiv.org/abs/2310.10074"}, {"metadata": {"arXiv": "2310.10089", "Date": "Mon, 16 Oct 2023 05:49:28 ", "Title": "Over-the-Air Federated Learning and Optimization", "Authors": ["Jingyang Zhu", "Yuanming Shi", "Yong Zhou", "Chunxiao Jiang", "Wei Chen", "Khaled B. Letaief"], "Categories": "cs.LG cs.IT eess.SP math.IT", "Comments": ["31 pages", "11 figures"]}, "abstract": "Federated learning (FL), as an emerging distributed machine learning paradigm, allows a mass of edge devices to collaboratively train a global model while preserving privacy. In this tutorial, we focus on FL via over-the-air computation (AirComp), which is proposed to reduce the communication overhead for FL over wireless networks at the cost of compromising in the learning performance due to model aggregation error arising from channel fading and noise. We first provide a comprehensive study on the convergence of AirComp-based FedAvg (AirFedAvg) algorithms under both strongly convex and non-convex settings with constant and diminishing learning rates in the presence of data heterogeneity. Through convergence and asymptotic analysis, we characterize the impact of aggregation error on the convergence bound and provide insights for system design with convergence guarantees. Then we derive convergence rates for AirFedAvg algorithms for strongly convex and non-convex objectives. For different types of local updates that can be transmitted by edge devices (i.e., local model, gradient, and model difference), we reveal that transmitting local model in AirFedAvg may cause divergence in the training procedure. In addition, we consider more practical signal processing schemes to improve the communication efficiency and further extend the convergence analysis to different forms of model aggregation error caused by these signal processing schemes. Extensive simulation results under different settings of objective functions, transmitted local information, and communication schemes verify the theoretical conclusions.", "url": "https://arxiv.org/abs/2310.10089"}, {"metadata": {"arXiv": "2310.10092", "Date": "Mon, 16 Oct 2023 05:54:30 ", "Title": "Label Differential Privacy via Aggregation", "Authors": ["Anand Brahmbhatt", "Rishi Saket", "Shreyas Havaldar", "Anshul Nasery and Aravindan Raghuveer"], "Categories": "cs.LG stat.ML"}, "abstract": "In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]. It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\\varepsilon, \\delta)$-label-DP for any $\\varepsilon > 0$ with $\\delta \\approx \\exp(-\\Omega(\\sqrt{k}))$ assuming a lower bound on the linear-mse regression loss. Further, this preserves the optimum over linear mse-regressors of bounded norm to within $(1 \\pm o(1))$-factor w.p. $\\approx 1 - \\exp(-\\Omega(m))$. We emphasize that no additive label noise is required. The analogous weighted-LLP does not however admit label-DP. Nevertheless, we show that if additive $N(0, 1)$ noise can be added to any constant fraction of the instance labels, then the noisy weighted-LLP admits similar label-DP guarantees without assumptions on the dataset, while preserving the utility of Lipschitz-bounded neural mse-regression tasks. Our work is the first to demonstrate that label-DP can be achieved by randomly weighted aggregation for regression tasks, using no or little additive noise.", "url": "https://arxiv.org/abs/2310.10092"}, {"metadata": {"arXiv": "2310.10096", "Date": "Mon, 16 Oct 2023 05:58:25 ", "Title": "LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions", "Authors": ["Anand Brahmbhatt", "Mohith Pokala", "Rishi Saket and Aravindan Raghuveer"], "Categories": "cs.LG stat.ML"}, "abstract": "In the task of Learning from Label Proportions (LLP), a model is trained on groups (a.k.a bags) of instances and their corresponding label proportions to predict labels for individual instances. LLP has been applied pre-dominantly on two types of datasets - image and tabular. In image LLP, bags of fixed size are created by randomly sampling instances from an underlying dataset. Bags created via this methodology are called random bags. Experimentation on Image LLP has been mostly on random bags on CIFAR-* and MNIST datasets. Despite being a very crucial task in privacy sensitive applications, tabular LLP does not yet have a open, large scale LLP benchmark. One of the unique properties of tabular LLP is the ability to create feature bags where all the instances in a bag have the same value for a given feature. It has been shown in prior research that feature bags are very common in practical, real world applications [Chen et. al '23, Saket et. al. '22]. In this paper, we address the lack of a open, large scale tabular benchmark. First we propose LLP-Bench, a suite of 56 LLP datasets (52 feature bag and 4 random bag datasets) created from the Criteo CTR prediction dataset consisting of 45 million instances. The 56 datasets represent diverse ways in which bags can be constructed from underlying tabular data. To the best of our knowledge, LLP-Bench is the first large scale tabular LLP benchmark with an extensive diversity in constituent datasets. Second, we propose four metrics that characterize and quantify the hardness of a LLP dataset. Using these four metrics we present deep analysis of the 56 datasets in LLP-Bench. Finally we present the performance of 9 SOTA and popular tabular LLP techniques on all the 56 datasets. To the best of our knowledge, our study consisting of more than 2500 experiments is the most extensive study of popular tabular LLP techniques in literature.", "url": "https://arxiv.org/abs/2310.10096"}, {"metadata": {"arXiv": "2310.10098", "Date": "Mon, 16 Oct 2023 05:59:34 ", "Title": "PAC Learning Linear Thresholds from Label Proportions", "Authors": ["Anand Brahmbhatt", "Rishi Saket and Aravindan Raghuveer"], "Categories": "cs.LG stat.ML", "Comments": ["Spotlight paper at Neural Information Processing Systems (NeurIPS)", "2023"]}, "abstract": "Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by [Saket'21, Saket'22] who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem on natural distributions. In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(\\mathbf{\\mu}, \\mathbf{\\Sigma})$. Our work shows that a certain matrix -- formed using covariances of the differences of feature-vectors sampled from the bags with and without replacement -- necessarily has its principal component, after a transformation, in the direction of the normal vector of the LTF. Our algorithm estimates the means and covariance matrices using subgaussian concentration bounds which we show can be applied to efficiently sample bags for approximating the normal direction. Using this in conjunction with novel generalization error bounds in the bag setting, we show that a low error hypothesis LTF can be identified. For some special cases of the $N(\\mathbf{0}, \\mathbf{I})$ distribution we provide a simpler mean estimation based algorithm. We include an experimental evaluation of our learning algorithms along with a comparison with those of [Saket'21, Saket'22] and random LTFs, demonstrating the effectiveness of our techniques.", "url": "https://arxiv.org/abs/2310.10098"}, {"metadata": {"arXiv": "2310.10117", "Date": "Mon, 16 Oct 2023 06:51:32 ", "Title": "A proximal augmented Lagrangian based algorithm for federated learning with global and local convex conic constraints", "Authors": ["Chuan He", "Le Peng", "Ju Sun"], "Categories": "cs.LG math.OC"}, "abstract": "This paper considers federated learning (FL) with constraints, where the central server and all local clients collectively minimize a sum of convex local objective functions subject to global and local convex conic constraints. To train the model without moving local data from clients to the central server, we propose an FL framework in which each local client performs multiple updates using the local objective and local constraint, while the central server handles the global constraint and performs aggregation based on the updated local models. In particular, we develop a proximal augmented Lagrangian (AL) based algorithm for FL with global and local convex conic constraints. The subproblems arising in this algorithm are solved by an inexact alternating direction method of multipliers (ADMM) in a federated fashion. Under a local Lipschitz condition and mild assumptions, we establish the worst-case complexity bounds of the proposed algorithm for finding an approximate KKT solution. To the best of our knowledge, this work proposes the first algorithm for FL with global and local constraints. Our numerical experiments demonstrate the practical advantages of our algorithm in performing Neyman-Pearson classification and enhancing model fairness in the context of FL.", "url": "https://arxiv.org/abs/2310.10117"}, {"metadata": {"arXiv": "2310.10151", "Date": "Mon, 16 Oct 2023 07:43:30 ", "Title": "DNA: Denoised Neighborhood Aggregation for Fine-grained Category Discovery", "Authors": ["Wenbin An", "Feng Tian", "Wenkai Shi", "Yan Chen", "Qinghua Zheng", "QianYing Wang", "Ping Chen"], "Categories": "cs.LG cs.CL cs.IR", "Comments": ["Accepted by EMNLP 2023 Main"]}, "abstract": "Discovering fine-grained categories from coarsely labeled data is a practical and challenging task, which can bridge the gap between the demand for fine-grained analysis and the high annotation cost. Previous works mainly focus on instance-level discrimination to learn low-level features, but ignore semantic similarities between data, which may prevent these models learning compact cluster representations. In this paper, we propose Denoised Neighborhood Aggregation (DNA), a self-supervised framework that encodes semantic structures of data into the embedding space. Specifically, we retrieve k-nearest neighbors of a query as its positive keys to capture semantic similarities between data and then aggregate information from the neighbors to learn compact cluster representations, which can make fine-grained categories more separatable. However, the retrieved neighbors can be noisy and contain many false-positive keys, which can degrade the quality of learned embeddings. To cope with this challenge, we propose three principles to filter out these false neighbors for better representation learning. Furthermore, we theoretically justify that the learning objective of our framework is equivalent to a clustering loss, which can capture semantic similarities between data to form compact fine-grained clusters. Extensive experiments on three benchmark datasets show that our method can retrieve more accurate neighbors (21.31% accuracy improvement) and outperform state-of-the-art models by a large margin (average 9.96% improvement on three metrics). Our code and data are available at https://github.com/Lackel/DNA.", "url": "https://arxiv.org/abs/2310.10151"}, {"metadata": {"arXiv": "2310.10177", "Date": "Mon, 16 Oct 2023 08:35:23 ", "Title": "Hypergraph Echo State Network", "Authors": ["Justin Lien"], "Categories": "cs.LG", "Comments": ["28 pages", "5 figures"]}, "abstract": "A hypergraph as a generalization of graphs records higher-order interactions among nodes, yields a more flexible network model, and allows non-linear features for a group of nodes. In this article, we propose a hypergraph echo state network (HypergraphESN) as a generalization of graph echo state network (GraphESN) designed for efficient processing of hypergraph-structured data, derive convergence conditions for the algorithm, and discuss its versatility in comparison to GraphESN. The numerical experiments on the binary classification tasks demonstrate that HypergraphESN exhibits comparable or superior accuracy performance to GraphESN for hypergraph-structured data, and accuracy increases if more higher-order interactions in a network are identified.", "url": "https://arxiv.org/abs/2310.10177"}, {"metadata": {"arXiv": "2310.10187", "Date": "Mon, 16 Oct 2023 08:48:52 ", "Title": "An Interpretable Deep-Learning Framework for Predicting Hospital Readmissions From Electronic Health Records", "Authors": ["Fabio Azzalini", "Tommaso Dolci and Marco Vagaggini"], "Categories": "cs.LG cs.IR"}, "abstract": "With the increasing availability of patients' data, modern medicine is shifting towards prospective healthcare. Electronic health records contain a variety of information useful for clinical patient description and can be exploited for the construction of predictive models, given that similar medical histories will likely lead to similar progressions. One example is unplanned hospital readmission prediction, an essential task for reducing hospital costs and improving patient health. Despite predictive models showing very good performances especially with deep-learning models, they are often criticized for the poor interpretability of their results, a fundamental characteristic in the medical field, where incorrect predictions might have serious consequences for the patient health. In this paper we propose a novel, interpretable deep-learning framework for predicting unplanned hospital readmissions, supported by NLP findings on word embeddings and by neural-network models (ConvLSTM) for better handling temporal data. We validate our system on the two predictive tasks of hospital readmission within 30 and 180 days, using real-world data. In addition, we introduce and test a model-dependent technique to make the representation of results easily interpretable by the medical staff. Our solution achieves better performances compared to traditional models based on machine learning, while providing at the same time more interpretable results.", "url": "https://arxiv.org/abs/2310.10187"}, {"metadata": {"arXiv": "2310.10195", "Date": "Mon, 16 Oct 2023 09:04:28 ", "Title": "AdaLomo: Low-memory Optimization with Adaptive Learning Rate", "Authors": ["Kai Lv", "Hang Yan", "Qipeng Guo", "Haijun Lv", "Xipeng Qiu"], "Categories": "cs.LG cs.CL"}, "abstract": "Large language models have achieved remarkable success, but their extensive parameter size necessitates substantial memory for training, thereby setting a high threshold. While the recently proposed low-memory optimization (LOMO) reduces memory footprint, its optimization technique, akin to stochastic gradient descent, is sensitive to hyper-parameters and exhibits suboptimal convergence, failing to match the performance of the prevailing optimizer for large language models, AdamW. Through empirical analysis of the Adam optimizer, we found that, compared to momentum, the adaptive learning rate is more critical for bridging the gap. Building on this insight, we introduce the low-memory optimization with adaptive learning rate (AdaLomo), which offers an adaptive learning rate for each parameter. To maintain memory efficiency, we employ non-negative matrix factorization for the second-order moment estimation in the optimizer state. Additionally, we suggest the use of a grouped update normalization to stabilize convergence. Our experiments with instruction-tuning and further pre-training demonstrate that AdaLomo achieves results on par with AdamW, while significantly reducing memory requirements, thereby lowering the hardware barrier to training large language models.", "url": "https://arxiv.org/abs/2310.10195"}, {"metadata": {"arXiv": "2310.10203", "Date": "Mon, 16 Oct 2023 09:17:10 ", "Title": "Interpretable Predictive Models to Understand Risk Factors for Maternal and Fetal Outcomes", "Authors": ["Tomas M. Bosschieter", "Zifei Xu", "Hui Lan", "Benjamin J. Lengerich", "Harsha Nori", "Ian Painter", "Vivienne Souter", "Rich Caruana"], "Categories": "cs.LG", "Comments": ["25 pages (including appendix and references)", "12 figures", "2 tables"], "Journal-ref": "Bosschieter, T.M., Xu, Z., Lan, H. et al. Interpretable Predictive Models to Understand Risk Factors for Maternal and Fetal Outcomes. J Healthc Inform Res (2023). https://doi.org/10.1007/s41666-023-00151-4", "DOI": "10.1007/s41666-023-00151-4"}, "abstract": "Although most pregnancies result in a good outcome, complications are not uncommon and can be associated with serious implications for mothers and babies. Predictive modeling has the potential to improve outcomes through better understanding of risk factors, heightened surveillance for high risk patients, and more timely and appropriate interventions, thereby helping obstetricians deliver better care. We identify and study the most important risk factors for four types of pregnancy complications: (i) severe maternal morbidity, (ii) shoulder dystocia, (iii) preterm preeclampsia, and (iv) antepartum stillbirth. We use an Explainable Boosting Machine (EBM), a high-accuracy glass-box learning method, for prediction and identification of important risk factors. We undertake external validation and perform an extensive robustness analysis of the EBM models. EBMs match the accuracy of other black-box ML methods such as deep neural networks and random forests, and outperform logistic regression, while being more interpretable. EBMs prove to be robust. The interpretability of the EBM models reveals surprising insights into the features contributing to risk (e.g. maternal height is the second most important feature for shoulder dystocia) and may have potential for clinical application in the prediction and prevention of serious complications in pregnancy.", "url": "https://arxiv.org/abs/2310.10203"}, {"metadata": {"arXiv": "2310.10207", "Date": "Mon, 16 Oct 2023 09:19:18 ", "Title": "Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World", "Authors": ["Rujie Wu", "Xiaojian Ma", "Qing Li", "Wei Wang", "Zhenliang Zhang", "Song-Chun Zhu", "Yizhou Wang"], "Categories": "cs.LG", "Comments": ["Project page: https://joyjayng.github.io/Bongard-OpenWorld.github.io"]}, "abstract": "We introduce Bongard-OpenWorld, a new benchmark for evaluating real-world few-shot reasoning for machine vision. It originates from the classical Bongard Problems (BPs): Given two sets of images (positive and negative), the model needs to identify the set that query images belong to by inducing the visual concepts, which is exclusively depicted by images from the positive set. Our benchmark inherits the few-shot concept induction of the original BPs while adding the two novel layers of challenge: 1) open-world free-form concepts, as the visual concepts in Bongard-OpenWorld are unique compositions of terms from an open vocabulary, ranging from object categories to abstract visual attributes and commonsense factual knowledge; 2) real-world images, as opposed to the synthetic diagrams used by many counterparts. In our exploration, Bongard-OpenWorld already imposes a significant challenge to current few-shot reasoning algorithms. We further investigate to which extent the recently introduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can solve our task, by directly probing VLMs, and combining VLMs and LLMs in an interactive reasoning scheme. We even designed a neuro-symbolic reasoning approach that reconciles LLMs & VLMs with logical reasoning to emulate the human problem-solving process for Bongard Problems. However, none of these approaches manage to close the human-machine gap, as the best learner achieves 64% accuracy while human participants easily reach 91%. We hope Bongard-OpenWorld can help us better understand the limitations of current visual intelligence and facilitate future research on visual agents with stronger few-shot visual reasoning capabilities.", "url": "https://arxiv.org/abs/2310.10207"}, {"metadata": {"arXiv": "2310.10211", "Date": "Mon, 16 Oct 2023 09:24:20 ", "Title": "GEVO-ML: Optimizing Machine Learning Code with Evolutionary Computation", "Authors": ["Jhe-Yu Liou", "Stephanie Forrest", "Carole-Jean Wu"], "Categories": "cs.LG"}, "abstract": "Parallel accelerators, such as GPUs, are key enablers for large-scale Machine Learning (ML) applications. However, ML model developers often lack detailed knowledge of the underlying system architectures, while system programmers usually do not have a high-level understanding of the ML model that runs on the specific system. To mitigate this gap between two relevant aspects of domain knowledge, this paper proposes GEVO-ML, a tool for automatically discovering optimization opportunities and tuning the performance of ML kernels, where the model and training/prediction processes are uniformly represented in a single intermediate language, the Multiple-Layer Intermediate Representation (MLIR). GEVO-ML uses multi-objective evolutionary search to find edits (mutations) to MLIR code that ultimately runs on GPUs, improving performance on desired criteria while retaining required functionality. We demonstrate GEVO-ML on two different ML workloads for both model training and prediction. GEVO-ML finds significant Pareto improvements for these models, achieving 90.43% performance improvement when model accuracy is relaxed by 2%, from 91.2% to 89.3%. For the training workloads, GEVO-ML finds a 4.88% improvement in model accuracy, from 91% to 96%, without sacrificing training or testing speed. Our analysis of key GEVO-ML mutations reveals diverse code modifications, while might be foreign to human developers, achieving similar effects with how human developers improve model design, for example, by changing learning rates or pruning non-essential layer parameters.", "url": "https://arxiv.org/abs/2310.10211"}, {"metadata": {"arXiv": "2310.10250", "Date": "Mon, 16 Oct 2023 10:19:45 ", "Title": "Leveraging Topological Maps in Deep Reinforcement Learning for Multi-Object Navigation", "Authors": ["Simon Hakenes", "Tobias Glasmachers"], "Categories": "cs.LG", "Comments": ["Extended Abstract", "Northern Lights Deep Learning Conference 2024", "3 pages", "2 figures"]}, "abstract": "This work addresses the challenge of navigating expansive spaces with sparse rewards through Reinforcement Learning (RL). Using topological maps, we elevate elementary actions to object-oriented macro actions, enabling a simple Deep Q-Network (DQN) agent to solve otherwise practically impossible environments.", "url": "https://arxiv.org/abs/2310.10250"}, {"metadata": {"arXiv": "2310.10259", "Date": "Mon, 16 Oct 2023 10:34:41 ", "Title": "Leveraging heterogeneous spillover effects in maximizing contextual bandit rewards", "Authors": ["Ahmed Sayeed Faruk", "Elena Zheleva"], "Categories": "cs.LG cs.SI"}, "abstract": "Recommender systems relying on contextual multi-armed bandits continuously improve relevant item recommendations by taking into account the contextual information. The objective of these bandit algorithms is to learn the best arm (i.e., best item to recommend) for each user and thus maximize the cumulative rewards from user engagement with the recommendations. However, current approaches ignore potential spillover between interacting users, where the action of one user can impact the actions and rewards of other users. Moreover, spillover may vary for different people based on their preferences and the closeness of ties to other users. This leads to heterogeneity in the spillover effects, i.e., the extent to which the action of one user can impact the action of another. Here, we propose a framework that allows contextual multi-armed bandits to account for such heterogeneous spillovers when choosing the best arm for each user. By experimenting on several real-world datasets using prominent linear and non-linear contextual bandit algorithms, we observe that our proposed method leads to significantly higher rewards than existing solutions that ignore spillover.", "url": "https://arxiv.org/abs/2310.10259"}, {"metadata": {"arXiv": "2310.10280", "Date": "Mon, 16 Oct 2023 11:11:43 ", "Title": "Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in Fine Motor Skill Acquisition", "Authors": ["Hadar Mulian", "Segev Shlomov", "and Lior Limonad"], "Categories": "cs.LG", "Comments": ["17 pages", "3 figures"]}, "abstract": "Motor skills, especially fine motor skills like handwriting, play an essential role in academic pursuits and everyday life. Traditional methods to teach these skills, although effective, can be time-consuming and inconsistent. With the rise of advanced technologies like robotics and artificial intelligence, there is increasing interest in automating such teaching processes using these technologies, via human-robot and human-computer interactions. In this study, we examine the potential of a virtual AI teacher in emulating the techniques of human educators for motor skill acquisition. We introduce an AI teacher model that captures the distinct characteristics of human instructors. Using a Reinforcement Learning environment tailored to mimic teacher-learner interactions, we tested our AI model against four guiding hypotheses, emphasizing improved learner performance, enhanced rate of skill acquisition, and reduced variability in learning outcomes. Our findings, validated on synthetic learners, revealed significant improvements across all tested hypotheses. Notably, our model showcased robustness across different learners and settings and demonstrated adaptability to handwriting. This research underscores the potential of integrating Reinforcement Learning and Imitation Learning models with robotics in revolutionizing the teaching of critical motor skills.", "url": "https://arxiv.org/abs/2310.10280"}, {"metadata": {"arXiv": "2310.10321", "Date": "Mon, 16 Oct 2023 12:03:27 ", "Title": "Hamming Encoder: Mining Discriminative k-mers for Discrete Sequence Classification", "Authors": ["Junjie Dong", "Mudi Jiang", "Lianyu Hu", "Zengyou He"], "Categories": "cs.LG", "Comments": ["12 pages"]}, "abstract": "Sequence classification has numerous applications in various fields. Despite extensive studies in the last decades, many challenges still exist, particularly in pattern-based methods. Existing pattern-based methods measure the discriminative power of each feature individually during the mining process, leading to the result of missing some combinations of features with discriminative power. Furthermore, it is difficult to ensure the overall discriminative performance after converting sequences into feature vectors. To address these challenges, we propose a novel approach called Hamming Encoder, which utilizes a binarized 1D-convolutional neural network (1DCNN) architecture to mine discriminative k-mer sets. In particular, we adopt a Hamming distance-based similarity measure to ensure consistency in the feature mining and classification procedure. Our method involves training an interpretable CNN encoder for sequential data and performing a gradient-based search for discriminative k-mer combinations. Experiments show that the Hamming Encoder method proposed in this paper outperforms existing state-of-the-art methods in terms of classification accuracy.", "url": "https://arxiv.org/abs/2310.10321"}, {"metadata": {"arXiv": "2310.10368", "Date": "Mon, 16 Oct 2023 13:05:47 ", "Title": "Machine learning in physics: a short guide", "Authors": ["Francisco A. Rodrigues"], "Categories": "cs.LG cond-mat.stat-mech physics.app-ph", "Comments": ["8 pages", "1 figure"], "Journal-ref": "Europhysics Letters (EPL), 2023"}, "abstract": "Machine learning is a rapidly growing field with the potential to revolutionize many areas of science, including physics. This review provides a brief overview of machine learning in physics, covering the main concepts of supervised, unsupervised, and reinforcement learning, as well as more specialized topics such as causal inference, symbolic regression, and deep learning. We present some of the principal applications of machine learning in physics and discuss the associated challenges and perspectives.", "url": "https://arxiv.org/abs/2310.10368"}, {"metadata": {"arXiv": "2310.10374", "Date": "Mon, 16 Oct 2023 13:12:27 ", "Title": "Multi-Factor Spatio-Temporal Prediction based on Graph Decomposition Learning", "Authors": ["Jiahao Ji", "Jingyuan Wang", "Yu Mou", "and Cheng Long"], "Categories": "cs.LG"}, "abstract": "Spatio-temporal (ST) prediction is an important and widely used technique in data mining and analytics, especially for ST data in urban systems such as transportation data. In practice, the ST data generation is usually influenced by various latent factors tied to natural phenomena or human socioeconomic activities, impacting specific spatial areas selectively. However, existing ST prediction methods usually do not refine the impacts of different factors, but directly model the entangled impacts of multiple factors. This amplifies the modeling complexity of ST data and compromises model interpretability. To this end, we propose a multi-factor ST prediction task that predicts partial ST data evolution under different factors, and combines them for a final prediction. We make two contributions to this task: an effective theoretical solution and a portable instantiation framework. Specifically, we first propose a theoretical solution called decomposed prediction strategy and prove its effectiveness from the perspective of information entropy theory. On top of that, we instantiate a novel model-agnostic framework, named spatio-temporal graph decomposition learning (STGDL), for multi-factor ST prediction. The framework consists of two main components: an automatic graph decomposition module that decomposes the original graph structure inherent in ST data into subgraphs corresponding to different factors, and a decomposed learning network that learns the partial ST data on each subgraph separately and integrates them for the final prediction. We conduct extensive experiments on four real-world ST datasets of two types of graphs, i.e., grid graph and network graph. Results show that our framework significantly reduces prediction errors of various ST models by 9.41% on average (35.36% at most). Furthermore, a case study reveals the interpretability potential of our framework.", "url": "https://arxiv.org/abs/2310.10374"}, {"metadata": {"arXiv": "2310.10379", "Date": "Mon, 16 Oct 2023 13:20:13 ", "Title": "Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification", "Authors": ["Tianjun Ke", "Haoqun Cao", "Zenan Ling", "Feng Zhou"], "Categories": "cs.LG stat.ML"}, "abstract": "Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \\textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than softmax. Utilizing modified logistic-softmax, we integrate the data augmentation technique into the deep kernel based Gaussian process meta-learning framework, and derive an analytical mean-field approximation for task-specific updates. Our approach yields well-calibrated uncertainty estimates and achieves comparable or superior results on standard benchmark datasets. Code is publicly available at \\url{https://github.com/keanson/revisit-logistic-softmax}.", "url": "https://arxiv.org/abs/2310.10379"}, {"metadata": {"arXiv": "2310.10399", "Date": "Mon, 16 Oct 2023 13:41:09 ", "Title": "Towards Fair and Calibrated Models", "Authors": ["Anand Brahmbhatt", "Vipul Rathore", "Mausam and Parag Singla"], "Categories": "cs.LG stat.ML"}, "abstract": "Recent literature has seen a significant focus on building machine learning models with specific properties such as fairness, i.e., being non-biased with respect to a given set of attributes, calibration i.e., model confidence being aligned with its predictive accuracy, and explainability, i.e., ability to be understandable to humans. While there has been work focusing on each of these aspects individually, researchers have shied away from simultaneously addressing more than one of these dimensions. In this work, we address the problem of building models which are both fair and calibrated. We work with a specific definition of fairness, which closely matches [Biswas et. al. 2019], and has the nice property that Bayes optimal classifier has the maximum possible fairness under our definition. We show that an existing negative result towards achieving a fair and calibrated model [Kleinberg et. al. 2017] does not hold for our definition of fairness. Further, we show that ensuring group-wise calibration with respect to the sensitive attributes automatically results in a fair model under our definition. Using this result, we provide a first cut approach for achieving fair and calibrated models, via a simple post-processing technique based on temperature scaling. We then propose modifications of existing calibration losses to perform group-wise calibration, as a way of achieving fair and calibrated models in a variety of settings. Finally, we perform extensive experimentation of these techniques on a diverse benchmark of datasets, and present insights on the pareto-optimality of the resulting solutions.", "url": "https://arxiv.org/abs/2310.10399"}, {"metadata": {"arXiv": "2310.10425", "Date": "Mon, 16 Oct 2023 14:09:59 ", "Title": "Continuously Adapting Random Sampling (CARS) for Power Electronics Parameter Design", "Authors": ["Dominik Happel", "Philipp Brendel", "Andreas Rosskopf", "Stefan Ditze"], "Categories": "cs.LG"}, "abstract": "To date, power electronics parameter design tasks are usually tackled using detailed optimization approaches with detailed simulations or using brute force grid search grid search with very fast simulations. A new method, named \"Continuously Adapting Random Sampling\" (CARS) is proposed, which provides a continuous method in between. This allows for very fast, and / or large amounts of simulations, but increasingly focuses on the most promising parameter ranges. Inspirations are drawn from multi-armed bandit research and lead to prioritized sampling of sub-domains in one high-dimensional parameter tensor. Performance has been evaluated on three exemplary power electronic use-cases, where resulting designs appear competitive to genetic algorithms, but additionally allow for highly parallelizable simulation, as well as continuous progression between explorative and exploitative settings.", "url": "https://arxiv.org/abs/2310.10425"}, {"metadata": {"arXiv": "2310.10443", "Date": "Mon, 16 Oct 2023 14:25:50 ", "Title": "Taming the Sigmoid Bottleneck: Provably Argmaxable Sparse Multi-Label Classification", "Authors": ["Andreas Grivas and Antonio Vergari and Adam Lopez"], "Categories": "cs.LG", "Comments": ["Under Review"]}, "abstract": "Sigmoid output layers are widely used in multi-label classification (MLC) tasks, in which multiple labels can be assigned to any input. In many practical MLC tasks, the number of possible labels is in the thousands, often exceeding the number of input features and resulting in a low-rank output layer. In multi-class classification, it is known that such a low-rank output layer is a bottleneck that can result in unargmaxable classes: classes which cannot be predicted for any input. In this paper, we show that for MLC tasks, the analogous sigmoid bottleneck results in exponentially many unargmaxable label combinations. We explain how to detect these unargmaxable outputs and demonstrate their presence in three widely used MLC datasets. We then show that they can be prevented in practice by introducing a Discrete Fourier Transform (DFT) output layer, which guarantees that all sparse label combinations with up to $k$ active labels are argmaxable. Our DFT layer trains faster and is more parameter efficient, matching the F1@k score of a sigmoid layer while using up to 50% fewer trainable parameters. Our code is publicly available at https://github.com/andreasgrv/sigmoid-bottleneck.", "url": "https://arxiv.org/abs/2310.10443"}, {"metadata": {"arXiv": "2310.10461", "Date": "Mon, 16 Oct 2023 14:42:22 ", "Title": "Model Selection of Anomaly Detectors in the Absence of Labeled Validation Data", "Authors": ["Clement Fung", "Chen Qiu", "Aodong Li", "Maja Rudolph"], "Categories": "cs.LG cs.CV", "Comments": ["16 pages"]}, "abstract": "Anomaly detection requires detecting abnormal samples in large unlabeled datasets. While progress in deep learning and the advent of foundation models has produced powerful unsupervised anomaly detection methods, their deployment in practice is often hindered by the lack of labeled data -- without it, the detection accuracy of an anomaly detector cannot be evaluated reliably. In this work, we propose a general-purpose framework for evaluating image-based anomaly detectors with synthetically generated validation data. Our method assumes access to a small support set of normal images which are processed with a pre-trained diffusion model (our proposed method requires no training or fine-tuning) to produce synthetic anomalies. When mixed with normal samples from the support set, the synthetic anomalies create detection tasks that compose a validation framework for anomaly detection evaluation and model selection. In an extensive empirical study, ranging from natural images to industrial applications, we find that our synthetic validation framework selects the same models and hyper-parameters as selection with a ground-truth validation set. In addition, we find that prompts selected by our method for CLIP-based anomaly detection outperforms all other prompt selection strategies, and leads to the overall best detection accuracy, even on the challenging MVTec-AD dataset.", "url": "https://arxiv.org/abs/2310.10461"}, {"metadata": {"arXiv": "2310.10462", "Date": "Mon, 16 Oct 2023 14:43:02 ", "Title": "Adaptive Neural Ranking Framework: Toward Maximized Business Goal for Cascade Ranking Systems", "Authors": ["Yunli Wang", "Zhiqiang Wang", "Jian Yang", "Shiyang Wen", "Dongying Kong", "Han Li", "Kun Gai"], "Categories": "cs.LG"}, "abstract": "Cascade ranking is widely used for large-scale top-k selection problems in online advertising and recommendation systems, and learning-to-rank is an important way to optimize the models in cascade ranking systems. Previous works on learning-to-rank usually focus on letting the model learn the complete order or pay more attention to the order of top materials, and adopt the corresponding rank metrics as optimization targets. However, these optimization targets can not adapt to various cascade ranking scenarios with varying data complexities and model capabilities; and the existing metric-driven methods such as the Lambda framework can only optimize a rough upper bound of the metric, potentially resulting in performance misalignment. To address these issues, we first propose a novel perspective on optimizing cascade ranking systems by highlighting the adaptability of optimization targets to data complexities and model capabilities. Concretely, we employ multi-task learning framework to adaptively combine the optimization of relaxed and full targets, which refers to metrics Recall@m@k and OAP respectively. Then we introduce a permutation matrix to represent the rank metrics and employ differentiable sorting techniques to obtain a relaxed permutation matrix with controllable approximate error bound. This enables us to optimize both the relaxed and full targets directly and more appropriately using the proposed surrogate losses within the deep learning framework. We named this method as Adaptive Neural Ranking Framework. We use the NeuralSort method to obtain the relaxed permutation matrix and draw on the uncertainty weight method in multi-task learning to optimize the proposed losses jointly. Experiments on a total of 4 public and industrial benchmarks show the effectiveness and generalization of our method, and online experiment shows that our method has significant application value.", "url": "https://arxiv.org/abs/2310.10462"}, {"metadata": {"arXiv": "2310.10505", "Date": "Mon, 16 Oct 2023 15:25:14 ", "Title": "ReMax: A Simple, Effective, and Efficient Method for Aligning Large Language Models", "Authors": ["Ziniu Li", "Tian Xu", "Yushun Zhang", "Yang Yu", "Ruoyu Sun", "Zhi-Quan Luo"], "Categories": "cs.LG"}, "abstract": "Alignment is of critical importance for training large language models (LLMs). The predominant strategy to address this is through Reinforcement Learning from Human Feedback (RLHF), where PPO serves as the de-facto algorithm. Yet, PPO is known to suffer from computational inefficiency, a challenge that this paper aims to address. We identify three important properties in RLHF tasks: fast simulation, deterministic transitions, and trajectory-level rewards, which are not leveraged in PPO. Based on such observations, we develop a new algorithm tailored for RLHF, called ReMax. The algorithm design of ReMax is built on a celebrated algorithm REINFORCE but is equipped with a new variance-reduction technique. Our method has three-fold advantages over PPO: first, it saves about 50% memory usage in principle. As a result, PPO runs out-of-memory when fine-tuning a Llama2 (7B) model on 8xA100-40GB GPUs, whereas ReMax can afford training. This memory improvement is achieved by removing the value model in PPO. Second, ReMax is simple to implement and removes many hyper-parameters in PPO, which are scale-sensitive and laborious to tune. Third, on GPT2 (137M), we observe 2.2x speed-up in terms of wall-clock time. Importantly, the above computational improvements do not sacrifice the performance. We hypothesize these advantages can be maintained in larger-scaled models. Our implementation of ReMax is available at https://github.com/liziniu/ReMax", "url": "https://arxiv.org/abs/2310.10505"}, {"metadata": {"arXiv": "2310.10534", "Date": "Mon, 16 Oct 2023 16:00:58 ", "Title": "Comparing Comparators in Generalization Bounds", "Authors": ["Fredrik Hellstr\\\"om", "Benjamin Guedj"], "Categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "Comments": ["29 pages"]}, "abstract": "We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training and population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\\'er function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.", "url": "https://arxiv.org/abs/2310.10534"}, {"metadata": {"arXiv": "2310.10553", "Date": "Mon, 16 Oct 2023 16:25:15 ", "Title": "TacticAI: an AI assistant for football tactics", "Authors": ["Zhe Wang", "Petar Veli\\v{c}kovi\\'c", "Daniel Hennes", "Nenad Toma\\v{s}ev", "Laurel Prince", "Michael Kaisers", "Yoram Bachrach", "Romuald Elie", "Li Kevin Wenliang", "Federico Piccinini", "William Spearman", "Ian Graham", "Jerome Connor", "Yi Yang", "Adri\\`a Recasens", "Mina Khan", "Nathalie Beauguerlange", "Pablo Sprechmann", "Pol Moreno", "Nicolas Heess", "Michael Bowling", "Demis Hassabis", "Karl Tuyls"], "Categories": "cs.LG cs.MA stat.ML", "Comments": ["32 pages", "10 figures"]}, "abstract": "Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liverpool FC. We show that TacticAI's model suggestions are not only indistinguishable from real tactics, but also favoured over existing tactics 90% of the time, and that TacticAI offers an effective corner kick retrieval system. TacticAI achieves these results despite the limited availability of gold-standard data, achieving data efficiency through geometric deep learning.", "url": "https://arxiv.org/abs/2310.10553"}, {"metadata": {"arXiv": "2310.10555", "Date": "Mon, 16 Oct 2023 16:26:40 ", "Title": "Population-based wind farm monitoring based on a spatial autoregressive approach", "Authors": ["W. Lin", "K. Worden and E.J. Cross"], "Categories": "cs.LG physics.flu-dyn", "Comments": ["8 pages", "4 figures", "submitted to the Modern Practice in Stress and Vibration Analysis (MPSVA) 2022 Conference Proceedings"]}, "abstract": "An important challenge faced by wind farm operators is to reduce operation and maintenance cost. Structural health monitoring provides a means of cost reduction through minimising unnecessary maintenance trips as well as prolonging turbine service life. Population-based structural health monitoring can further reduce the cost of health monitoring systems by implementing one system for multiple structures (i.e.~turbines). At the same time, shared data within a population of structures may improve the predictions of structural behaviour. To monitor turbine performance at a population/farm level, an important initial step is to construct a model that describes the behaviour of all turbines under normal conditions. This paper proposes a population-level model that explicitly captures the spatial and temporal correlations (between turbines) induced by the wake effect. The proposed model is a Gaussian process-based spatial autoregressive model, named here a GP-SPARX model. This approach is developed since (a) it reflects our physical understanding of the wake effect, and (b) it benefits from a stochastic data-based learner. A case study is provided to demonstrate the capability of the GP-SPARX model in capturing spatial and temporal variations as well as its potential applicability in a health monitoring system.", "url": "https://arxiv.org/abs/2310.10555"}, {"metadata": {"arXiv": "2310.10556", "Date": "Mon, 16 Oct 2023 16:27:06 ", "Title": "Sample Complexity of Preference-Based Nonparametric Off-Policy Evaluation with Deep Networks", "Authors": ["Zihao Li", "Xiang Ji", "Minshuo Chen", "Mengdi Wang"], "Categories": "cs.LG stat.ML"}, "abstract": "A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Under the assumption of high reward smoothness, our results \\textit{almost align with the classical OPE results with observable reward data}. To the best of our knowledge, this is the first result that establishes a \\textit{provably efficient} guarantee for off-policy evaluation with RLHF.", "url": "https://arxiv.org/abs/2310.10556"}, {"metadata": {"arXiv": "2310.10565", "Date": "Mon, 16 Oct 2023 16:38:32 ", "Title": "HelmSim: Learning Helmholtz Dynamics for Interpretable Fluid Simulation", "Authors": ["Lanxiang Xing", "Haixu Wu", "Yuezhou Ma", "Jianmin Wang", "Mingsheng Long"], "Categories": "cs.LG"}, "abstract": "Fluid simulation is a long-standing challenge due to the intrinsic high-dimensional non-linear dynamics. Previous methods usually utilize the non-linear modeling capability of deep models to directly estimate velocity fields for future prediction. However, skipping over inherent physical properties but directly learning superficial velocity fields will overwhelm the model from generating precise or physics-reliable results. In this paper, we propose the HelmSim toward an accurate and interpretable simulator for fluid. Inspired by the Helmholtz theorem, we design a HelmDynamic block to learn the Helmholtz dynamics, which decomposes fluid dynamics into more solvable curl-free and divergence-free parts, physically corresponding to potential and stream functions of fluid. By embedding the HelmDynamic block into a Multiscale Integration Network, HelmSim can integrate learned Helmholtz dynamics along temporal dimension in multiple spatial scales to yield future fluid. Comparing with previous velocity estimating methods, HelmSim is faithfully derived from Helmholtz theorem and ravels out complex fluid dynamics with physically interpretable evidence. Experimentally, our proposed HelmSim achieves the consistent state-of-the-art in both numerical simulated and real-world observed benchmarks, even for scenarios with complex boundaries.", "url": "https://arxiv.org/abs/2310.10565"}, {"metadata": {"arXiv": "2310.10611", "Date": "Mon, 16 Oct 2023 17:35:29 ", "Title": "IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation", "Authors": ["Taejong Joo", "Diego Klabjan"], "Categories": "cs.LG stat.ML"}, "abstract": "Reasoning about a model's accuracy on a test sample from its confidence is a central problem in machine learning, being connected to important applications such as uncertainty representation, model selection, and exploration. While these connections have been well-studied in the i.i.d. settings, distribution shifts pose significant challenges to the traditional methods. Therefore, model calibration and model selection remain challenging in the unsupervised domain adaptation problem--a scenario where the goal is to perform well in a distribution shifted domain without labels. In this work, we tackle difficulties coming from distribution shifts by developing a novel importance weighted group accuracy estimator. Specifically, we formulate an optimization problem for finding an importance weight that leads to an accurate group accuracy estimation in the distribution shifted domain with theoretical analyses. Extensive experiments show the effectiveness of group accuracy estimation on model calibration and model selection. Our results emphasize the significance of group accuracy estimation for addressing challenges in unsupervised domain adaptation, as an orthogonal improvement direction with improving transferability of accuracy.", "url": "https://arxiv.org/abs/2310.10611"}, {"metadata": {"arXiv": "2310.10616", "Date": "Mon, 16 Oct 2023 17:40:49 ", "Title": "How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations", "Authors": ["Tianyu Guo", "Wei Hu", "Song Mei", "Huan Wang", "Caiming Xiong", "Silvio Savarese", "Yu Bai"], "Categories": "cs.LG"}, "abstract": "While large language models based on the transformer architecture have demonstrated remarkable in-context learning (ICL) capabilities, understandings of such capabilities are still in an early stage, where existing theory and mechanistic understanding focus mostly on simple scenarios such as learning simple function classes. This paper takes initial steps on understanding ICL in more complex scenarios, by studying learning with representations. Concretely, we construct synthetic in-context learning problems with a compositional structure, where the label depends on the input through a possibly complex but fixed representation function, composed with a linear function that differs in each instance. By construction, the optimal ICL algorithm first transforms the inputs by the representation function, and then performs linear ICL on top of the transformed dataset. We show theoretically the existence of transformers that approximately implement such algorithms with mild depth and size. Empirically, we find trained transformers consistently achieve near-optimal ICL performance in this setting, and exhibit the desired dissection where lower layers transforms the dataset and upper layers perform linear ICL. Through extensive probing and a new pasting experiment, we further reveal several mechanisms within the trained transformers, such as concrete copying behaviors on both the inputs and the representations, linear ICL capability of the upper layers alone, and a post-ICL representation selection mechanism in a harder mixture setting. These observed mechanisms align well with our theory and may shed light on how transformers perform ICL in more realistic scenarios.", "url": "https://arxiv.org/abs/2310.10616"}, {"metadata": {"arXiv": "2310.10629", "Date": "Mon, 16 Oct 2023 17:53:30 ", "Title": "Certainty In, Certainty Out: REVQCs for Quantum Machine Learning", "Authors": ["Hannah Helgesen", "Michael Felsberg", "Jan-{\\AA}ke Larsson"], "Categories": "cs.LG quant-ph", "Comments": ["9 pages", "5 figures"], "ACM-class": "I.2.6; I.6.5"}, "abstract": "The field of Quantum Machine Learning (QML) has emerged recently in the hopes of finding new machine learning protocols or exponential speedups for classical ones. Apart from problems with vanishing gradients and efficient encoding methods, these speedups are hard to find because the sampling nature of quantum computers promotes either simulating computations classically or running them many times on quantum computers in order to use approximate expectation values in gradient calculations. In this paper, we make a case for setting high single-sample accuracy as a primary goal. We discuss the statistical theory which enables highly accurate and precise sample inference, and propose a method of reversed training towards this end. We show the effectiveness of this training method by assessing several effective variational quantum circuits (VQCs), trained in both the standard and reversed directions, on random binary subsets of the MNIST and MNIST Fashion datasets, on which our method provides an increase of $10-15\\%$ in single-sample inference accuracy.", "url": "https://arxiv.org/abs/2310.10629"}, {"metadata": {"arXiv": "2310.10636", "Date": "Mon, 16 Oct 2023 17:55:43 ", "Title": "Efficacy of Dual-Encoders for Extreme Multi-Label Classification", "Authors": ["Nilesh Gupta", "Devvrit Khatri", "Ankit S Rawat", "Srinadh Bhojanapalli", "Prateek Jain", "Inderjit S Dhillon"], "Categories": "cs.LG", "Comments": ["26 pages", "8 figures"]}, "abstract": "Dual-encoder models have demonstrated significant success in dense retrieval tasks for open-domain question answering that mostly involves zero-shot and few-shot scenarios. However, their performance in many-shot retrieval problems where training data is abundant, such as extreme multi-label classification (XMC), remains under-explored. Existing empirical evidence suggests that, for such problems, the dual-encoder method's accuracies lag behind the performance of state-of-the-art (SOTA) extreme classification methods that grow the number of learnable parameters linearly with the number of classes. As a result, some recent extreme classification techniques use a combination of dual-encoders and a learnable classification head for each class to excel on these tasks. In this paper, we investigate the potential of \"pure\" DE models in XMC tasks. Our findings reveal that when trained correctly standard dual-encoders can match or outperform SOTA extreme classification methods by up to 2% at Precision@1 even on the largest XMC datasets while being 20x smaller in terms of the number of trainable parameters. We further propose a differentiable topk error-based loss function, which can be used to specifically optimize for Recall@k metrics. We include our PyTorch implementation along with other resources for reproducing the results in the supplementary material.", "url": "https://arxiv.org/abs/2310.10636"}, {"metadata": {"arXiv": "2310.10649", "Date": "Mon, 16 Oct 2023 17:59:54 ", "Title": "A Computational Framework for Solving Wasserstein Lagrangian Flows", "Authors": ["Kirill Neklyudov", "Rob Brekelmans", "Alexander Tong", "Lazar Atanackovic", "Qiang Liu", "Alireza Makhzani"], "Categories": "cs.LG math.OC"}, "abstract": "The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry ($\\textit{kinetic energy}$), and the regularization of density paths ($\\textit{potential energy}$). These combinations yield different variational problems ($\\textit{Lagrangians}$), encompassing many variations of the optimal transport problem such as the Schr\\\"odinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others. In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging. Leveraging the dual formulation of the Lagrangians, we propose a novel deep learning based framework approaching all of these problems from a unified perspective. Our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings. We showcase the versatility of the proposed framework by outperforming previous approaches for the single-cell trajectory inference, where incorporating prior knowledge into the dynamics is crucial for correct predictions.", "url": "https://arxiv.org/abs/2310.10649"}, {"metadata": {"arXiv": "2310.09543", "Date": "Sat, 14 Oct 2023 09:36:01 ", "Title": "Benchmarking the Sim-to-Real Gap in Cloth Manipulation", "Authors": ["David Blanco-Mulero", "Oriol Barbany", "Gokhan Alcan", "Adri\\`a Colom\\'e", "Carme Torras", "Ville Kyrki"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Submitted to IEEE Robotics and Automation Letters. 8 pages", "6 figures. Supplementary material available at https://sites.google.com/view/cloth-sim2real-benchmark"]}, "abstract": "Realistic physics engines play a crucial role for learning to manipulate deformable objects such as garments in simulation. By doing so, researchers can circumvent challenges such as sensing the deformation of the object in the real-world. In spite of the extensive use of simulations for this task, few works have evaluated the reality gap between deformable object simulators and real-world data. We present a benchmark dataset to evaluate the sim-to-real gap in cloth manipulation. The dataset is collected by performing a dynamic cloth manipulation task involving contact with a rigid table. We use the dataset to evaluate the reality gap, computational time, and simulation stability of four popular deformable object simulators: MuJoCo, Bullet, Flex, and SOFA. Additionally, we discuss the benefits and drawbacks of each simulator. The benchmark dataset is open-source. Supplementary material, videos, and code, can be found at https://sites.google.com/view/cloth-sim2real-benchmark.", "url": "https://arxiv.org/abs/2310.09543"}, {"metadata": {"arXiv": "2310.10606", "Date": "Mon, 16 Oct 2023 17:32:23 ", "Title": "BayRnTune: Adaptive Bayesian Domain Randomization via Strategic Fine-tuning", "Authors": ["Tianle Huang", "Nitish Sontakke", "K. Niranjan Kumar", "Irfan Essa", "Stefanos Nikolaidis", "Dennis W. Hong", "Sehoon Ha"], "Categories": "cs.RO cs.LG"}, "abstract": "Domain randomization (DR), which entails training a policy with randomized dynamics, has proven to be a simple yet effective algorithm for reducing the gap between simulation and the real world. However, DR often requires careful tuning of randomization parameters. Methods like Bayesian Domain Randomization (Bayesian DR) and Active Domain Randomization (Adaptive DR) address this issue by automating parameter range selection using real-world experience. While effective, these algorithms often require long computation time, as a new policy is trained from scratch every iteration. In this work, we propose Adaptive Bayesian Domain Randomization via Strategic Fine-tuning (BayRnTune), which inherits the spirit of BayRn but aims to significantly accelerate the learning processes by fine-tuning from previously learned policy. This idea leads to a critical question: which previous policy should we use as a prior during fine-tuning? We investigated four different fine-tuning strategies and compared them against baseline algorithms in five simulated environments, ranging from simple benchmark tasks to more complex legged robot environments. Our analysis demonstrates that our method yields better rewards in the same amount of timesteps compared to vanilla domain randomization or Bayesian DR.", "url": "https://arxiv.org/abs/2310.10606"}, {"metadata": {"arXiv": "2310.09920", "Date": "Sun, 15 Oct 2023 19:08:18 ", "Title": "BONES: Near-Optimal Neural-Enhanced Video Streaming", "Authors": ["Lingdong Wang", "Simran Singh", "Jacob Chakareski", "Mohammad Hajiesmaili", "Ramesh K. Sitaraman"], "Categories": "eess.SY cs.LG cs.NI cs.SY"}, "abstract": "Accessing high-quality video content can be challenging due to insufficient and unstable network bandwidth. Recent advances in neural enhancement have shown promising results in improving the quality of degraded videos through deep learning. Neural-Enhanced Streaming (NES) incorporates this new approach into video streaming, allowing users to download low-quality video segments and then enhance them to obtain high-quality content without violating the playback of the video stream. We introduce BONES, an NES control algorithm that jointly manages the network and computational resources to maximize the quality of experience (QoE) of the user. BONES formulates NES as a Lyapunov optimization problem and solves it in an online manner with near-optimal performance, making it the first NES algorithm to provide a theoretical performance guarantee. Our comprehensive experimental results indicate that BONES increases QoE by 4% to 13% over state-of-the-art algorithms, demonstrating its potential to enhance the video streaming experience for users. Our code and data will be released to the public.", "url": "https://arxiv.org/abs/2310.09920"}, {"metadata": {"arXiv": "2310.09383", "Date": "Fri, 13 Oct 2023 20:03:22 ", "Title": "Integrating Symbolic Reasoning into Neural Generative Models for Design Generation", "Authors": ["Maxwell Joseph Jacobson", "Yexiang Xue"], "Categories": "cs.AI"}, "abstract": "Design generation requires tight integration of neural and symbolic reasoning, as good design must meet explicit user needs and honor implicit rules for aesthetics, utility, and convenience. Current automated design tools driven by neural networks produce appealing designs, but cannot satisfy user specifications and utility requirements. Symbolic reasoning tools, such as constraint programming, cannot perceive low-level visual information in images or capture subtle aspects such as aesthetics. We introduce the Spatial Reasoning Integrated Generator (SPRING) for design generation. SPRING embeds a neural and symbolic integrated spatial reasoning module inside the deep generative network. The spatial reasoning module decides the locations of objects to be generated in the form of bounding boxes, which are predicted by a recurrent neural network and filtered by symbolic constraint satisfaction. Embedding symbolic reasoning into neural generation guarantees that the output of SPRING satisfies user requirements. Furthermore, SPRING offers interpretability, allowing users to visualize and diagnose the generation process through the bounding boxes. SPRING is also adept at managing novel user specifications not encountered during its training, thanks to its proficiency in zero-shot constraint transfer. Quantitative evaluations and a human study reveal that SPRING outperforms baseline generative models, excelling in delivering high design quality and better meeting user specifications.", "url": "https://arxiv.org/abs/2310.09383"}, {"metadata": {"arXiv": "2310.09688", "Date": "Sun, 15 Oct 2023 00:25:07 ", "Title": "Recursively-Constrained Partially Observable Markov Decision Processes", "Authors": ["Qi Heng Ho", "Tyler Becker", "Ben Kraske", "Zakariya Laouar", "Martin Feather", "Federico Rossi", "Morteza Lahijanian", "Zachary N. Sunberg"], "Categories": "cs.AI cs.RO"}, "abstract": "In many problems, it is desirable to optimize an objective function while imposing constraints on some other aspect of the problem. A Constrained Partially Observable Markov Decision Process (C-POMDP) allows modelling of such problems while subject to transition uncertainty and partial observability. Typically, the constraints in C-POMDPs enforce a threshold on expected cumulative costs starting from an initial state distribution. In this work, we first show that optimal C-POMDP policies may violate Bellman's principle of optimality and thus may exhibit pathological behaviors, which can be undesirable for many applications. To address this drawback, we introduce a new formulation, the Recursively-Constrained POMDP (RC-POMDP), that imposes additional history dependent cost constraints on the C-POMDP. We show that, unlike C-POMDPs, RC-POMDPs always have deterministic optimal policies, and that optimal policies obey Bellman's principle of optimality. We also present a point-based dynamic programming algorithm that synthesizes optimal policies for RC-POMDPs. In our evaluations, we show that policies for RC-POMDPs produce more desirable behavior than policies for C-POMDPs and demonstrate the efficacy of our algorithm across a set of benchmark problems.", "url": "https://arxiv.org/abs/2310.09688"}, {"metadata": {"arXiv": "2310.09689", "Date": "Sun, 15 Oct 2023 00:29:35 ", "Title": "A Partially Supervised Reinforcement Learning Framework for Visual Active Search", "Authors": ["Anindya Sarkar", "Nathan Jacobs", "Yevgeniy Vorobeychik"], "Categories": "cs.AI cs.CV", "Comments": ["26 pages", "20 figures", "Accepted to NeurIPS 2023", "Code is available at https://github.com/anindyasarkarIITH/PSRL_VAS/"]}, "abstract": "Visual active search (VAS) has been proposed as a modeling framework in which visual cues are used to guide exploration, with the goal of identifying regions of interest in a large geospatial area. Its potential applications include identifying hot spots of rare wildlife poaching activity, search-and-rescue scenarios, identifying illegal trafficking of weapons, drugs, or people, and many others. State of the art approaches to VAS include applications of deep reinforcement learning (DRL), which yield end-to-end search policies, and traditional active search, which combines predictions with custom algorithmic approaches. While the DRL framework has been shown to greatly outperform traditional active search in such domains, its end-to-end nature does not make full use of supervised information attained either during training, or during actual search, a significant limitation if search tasks differ significantly from those in the training distribution. We propose an approach that combines the strength of both DRL and conventional active search by decomposing the search policy into a prediction module, which produces a geospatial distribution of regions of interest based on task embedding and search history, and a search module, which takes the predictions and search history as input and outputs the search distribution. We develop a novel meta-learning approach for jointly learning the resulting combined policy that can make effective use of supervised information obtained both at training and decision time. Our extensive experiments demonstrate that the proposed representation and meta-learning frameworks significantly outperform state of the art in visual active search on several problem domains.", "url": "https://arxiv.org/abs/2310.09689"}, {"metadata": {"arXiv": "2310.09696", "Date": "Sun, 15 Oct 2023 01:18:39 ", "Title": "Progressive Evidence Refinement for Open-domain Multimodal Retrieval Question Answering", "Authors": ["Shuwen Yang", "Anran Wu", "Xingjiao Wu", "Luwei Xiao", "Tianlong Ma", "Cheng Jin", "Liang He"], "Categories": "cs.AI"}, "abstract": "Pre-trained multimodal models have achieved significant success in retrieval-based question answering. However, current multimodal retrieval question-answering models face two main challenges. Firstly, utilizing compressed evidence features as input to the model results in the loss of fine-grained information within the evidence. Secondly, a gap exists between the feature extraction of evidence and the question, which hinders the model from effectively extracting critical features from the evidence based on the given question. We propose a two-stage framework for evidence retrieval and question-answering to alleviate these issues. First and foremost, we propose a progressive evidence refinement strategy for selecting crucial evidence. This strategy employs an iterative evidence retrieval approach to uncover the logical sequence among the evidence pieces. It incorporates two rounds of filtering to optimize the solution space, thus further ensuring temporal efficiency. Subsequently, we introduce a semi-supervised contrastive learning training strategy based on negative samples to expand the scope of the question domain, allowing for a more thorough exploration of latent knowledge within known samples. Finally, in order to mitigate the loss of fine-grained information, we devise a multi-turn retrieval and question-answering strategy to handle multimodal inputs. This strategy involves incorporating multimodal evidence directly into the model as part of the historical dialogue and question. Meanwhile, we leverage a cross-modal attention mechanism to capture the underlying connections between the evidence and the question, and the answer is generated through a decoding generation approach. We validate the model's effectiveness through extensive experiments, achieving outstanding performance on WebQA and MultimodelQA benchmark tests.", "url": "https://arxiv.org/abs/2310.09696"}, {"metadata": {"arXiv": "2310.09754", "Date": "Sun, 15 Oct 2023 06:46:15 ", "Title": "EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification", "Authors": ["Huanhuan Ma and Weizhi Xu and Yifan Wei and Liuji Chen and Liang Wang and Qiang Liu and Shu Wu and Liang Wang"], "Categories": "cs.AI"}, "abstract": "Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in the accuracy improvement, let alone the explainability, a critical capability of fact verification system. Constructing an explainable fact verification system in a complex multi-hop scenario is consistently impeded by the absence of a relevant high-quality dataset. Previous dataset either suffer from excessive simplification or fail to incorporate essential considerations for explainability. To address this, we present EX-FEVER, a pioneering dataset for multi-hop explainable fact verification. With over 60,000 claims involving 2-hop and 3-hop reasoning, each is created by summarizing and modifying information from hyperlinked Wikipedia documents. Each instance is accompanied by a veracity label and an explanation that outlines the reasoning path supporting the veracity classification. Additionally, we demonstrate a novel baseline system on our EX-FEVER dataset, showcasing document retrieval, explanation generation, and claim verification and observe that existing fact verification models trained on previous datasets struggle to perform well on our dataset. Furthermore, we highlight the potential of utilizing Large Language Models in the fact verification task. We hope our dataset could make a significant contribution by providing ample opportunities to explore the integration of natural language explanations in the domain of fact verification.", "url": "https://arxiv.org/abs/2310.09754"}, {"metadata": {"arXiv": "2310.09774", "Date": "Sun, 15 Oct 2023 08:24:02 ", "Title": "Worst-Case Analysis is Maximum-A-Posteriori Estimation", "Authors": ["Hongjun Wu and Di Wang"], "Categories": "cs.AI"}, "abstract": "The worst-case resource usage of a program can provide useful information for many software-engineering tasks, such as performance optimization and algorithmic-complexity-vulnerability discovery. This paper presents a generic, adaptive, and sound fuzzing framework, called DSE-SMC, for estimating worst-case resource usage. DSE-SMC is generic because it is black-box as long as the user provides an interface for retrieving resource-usage information on a given input; adaptive because it automatically balances between exploration and exploitation of candidate inputs; and sound because it is guaranteed to converge to the true resource-usage distribution of the analyzed program. DSE-SMC is built upon a key observation: resource accumulation in a program is isomorphic to the soft-conditioning mechanism in Bayesian probabilistic programming; thus, worst-case resource analysis is isomorphic to the maximum-a-posteriori-estimation problem of Bayesian statistics. DSE-SMC incorporates sequential Monte Carlo (SMC) -- a generic framework for Bayesian inference -- with adaptive evolutionary fuzzing algorithms, in a sound manner, i.e., DSE-SMC asymptotically converges to the posterior distribution induced by resource-usage behavior of the analyzed program. Experimental evaluation on Java applications demonstrates that DSE-SMC is significantly more effective than existing black-box fuzzing methods for worst-case analysis.", "url": "https://arxiv.org/abs/2310.09774"}, {"metadata": {"arXiv": "2310.09781", "Date": "Sun, 15 Oct 2023 09:01:24 ", "Title": "Negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding", "Authors": ["Xiangnan Chen", "Wen Zhang", "Zhen Yao", "Mingyang Chen", "Siliang Tang"], "Categories": "cs.AI", "Comments": ["Accepted by ISWC 2023"]}, "abstract": "Knowledge graph embedding (KGE) aims to map entities and relations of a knowledge graph (KG) into a low-dimensional and dense vector space via contrasting the positive and negative triples. In the training process of KGEs, negative sampling is essential to find high-quality negative triples since KGs only contain positive triples. Most existing negative sampling methods assume that non-existent triples with high scores are high-quality negative triples. However, negative triples sampled by these methods are likely to contain noise. Specifically, they ignore that non-existent triples with high scores might also be true facts due to the incompleteness of KGs, which are usually called false negative triples. To alleviate the above issue, we propose an easily pluggable denoising mixup method called DeMix, which generates high-quality triples by refining sampled negative triples in a self-supervised manner. Given a sampled unlabeled triple, DeMix firstly classifies it into a marginal pseudo-negative triple or a negative triple based on the judgment of the KGE model itself. Secondly, it selects an appropriate mixup partner for the current triple to synthesize a partially positive or a harder negative triple. Experimental results on the knowledge graph completion task show that the proposed DeMix is superior to other negative sampling techniques, ensuring corresponding KGEs a faster convergence and better link prediction results.", "url": "https://arxiv.org/abs/2310.09781"}, {"metadata": {"arXiv": "2310.09926", "Date": "Sun, 15 Oct 2023 19:24:52 ", "Title": "Estimating Uncertainty in Multimodal Foundation Models using Public Internet Data", "Authors": ["Shiladitya Dutta", "Hongbo Wei", "Lars van der Laan", "Ahmed M. Alaa"], "Categories": "cs.AI"}, "abstract": "Foundation models are trained on vast amounts of data at scale using self-supervised learning, enabling adaptation to a wide range of downstream tasks. At test time, these models exhibit zero-shot capabilities through which they can classify previously unseen (user-specified) categories. In this paper, we address the problem of quantifying uncertainty in these zero-shot predictions. We propose a heuristic approach for uncertainty estimation in zero-shot settings using conformal prediction with web data. Given a set of classes at test time, we conduct zero-shot classification with CLIP-style models using a prompt template, e.g., \"an image of a <category>\", and use the same template as a search query to source calibration data from the open web. Given a web-based calibration set, we apply conformal prediction with a novel conformity score that accounts for potential errors in retrieved web data. We evaluate the utility of our proposed method in Biomedical foundation models; our preliminary results show that web-based conformal prediction sets achieve the target coverage with satisfactory efficiency on a variety of biomedical datasets.", "url": "https://arxiv.org/abs/2310.09926"}, {"metadata": {"arXiv": "2310.10174", "Date": "Mon, 16 Oct 2023 08:34:41 ", "Title": "Analyzing An After-Sales Service Process Using Object-Centric Process Mining: A Case Study", "Authors": ["Gyunam Park", "Sevde Aydin", "Cuneyt Ugur", "Wil M. P. van der Aalst"], "Categories": "cs.AI"}, "abstract": "Process mining, a technique turning event data into business process insights, has traditionally operated on the assumption that each event corresponds to a singular case or object. However, many real-world processes are intertwined with multiple objects, making them object-centric. This paper focuses on the emerging domain of object-centric process mining, highlighting its potential yet underexplored benefits in actual operational scenarios. Through an in-depth case study of Borusan Cat's after-sales service process, this study emphasizes the capability of object-centric process mining to capture entangled business process details. Utilizing an event log of approximately 65,000 events, our analysis underscores the importance of embracing this paradigm for richer business insights and enhanced operational improvements.", "url": "https://arxiv.org/abs/2310.10174"}, {"metadata": {"arXiv": "2310.10274", "Date": "Mon, 16 Oct 2023 10:59:22 ", "Title": "No Compromise in Solution Quality: Speeding Up Belief-dependent Continuous POMDPs via Adaptive Multilevel Simplification", "Authors": ["Andrey Zhitnikov", "Ori Sztyglic", "Vadim Indelman"], "Categories": "cs.AI cs.RO"}, "abstract": "Continuous POMDPs with general belief-dependent rewards are notoriously difficult to solve online. In this paper, we present a complete provable theory of adaptive multilevel simplification for the setting of a given externally constructed belief tree and MCTS that constructs the belief tree on the fly using an exploration technique. Our theory allows to accelerate POMDP planning with belief-dependent rewards without any sacrifice in the quality of the obtained solution. We rigorously prove each theoretical claim in the proposed unified theory. Using the general theoretical results, we present three algorithms to accelerate continuous POMDP online planning with belief-dependent rewards. Our two algorithms, SITH-BSP and LAZY-SITH-BSP, can be utilized on top of any method that constructs a belief tree externally. The third algorithm, SITH-PFT, is an anytime MCTS method that permits to plug-in any exploration technique. All our methods are guaranteed to return exactly the same optimal action as their unsimplified equivalents. We replace the costly computation of information-theoretic rewards with novel adaptive upper and lower bounds which we derive in this paper, and are of independent interest. We show that they are easy to calculate and can be tightened by the demand of our algorithms. Our approach is general; namely, any bounds that monotonically converge to the reward can be easily plugged-in to achieve significant speedup without any loss in performance. Our theory and algorithms support the challenging setting of continuous states, actions, and observations. The beliefs can be parametric or general and represented by weighted particles. We demonstrate in simulation a significant speedup in planning compared to baseline approaches with guaranteed identical performance.", "url": "https://arxiv.org/abs/2310.10274"}, {"metadata": {"arXiv": "2310.10436", "Date": "Mon, 16 Oct 2023 14:19:40 ", "Title": "Large Language Model-Empowered Agents for Simulating Macroeconomic Activities", "Authors": ["Nian Li", "Chen Gao", "Yong Li", "Qingmin Liao"], "Categories": "cs.AI"}, "abstract": "The advent of the Web has brought about a paradigm shift in traditional economics, particularly in the digital economy era, enabling the precise recording and analysis of individual economic behavior. This has led to a growing emphasis on data-driven modeling in macroeconomics. In macroeconomic research, Agent-based modeling (ABM) emerged as an alternative, evolving through rule-based agents, machine learning-enhanced decision-making, and, more recently, advanced AI agents. However, the existing works are suffering from three main challenges when endowing agents with human-like decision-making, including agent heterogeneity, the influence of macroeconomic trends, and multifaceted economic factors. Large language models (LLMs) have recently gained prominence in offering autonomous human-like characteristics. Therefore, leveraging LLMs in macroeconomic simulation presents an opportunity to overcome traditional limitations. In this work, we take an early step in introducing a novel approach that leverages LLMs in macroeconomic simulation. We design prompt-engineering-driven LLM agents to exhibit human-like decision-making and adaptability in the economic environment, with the abilities of perception, reflection, and decision-making to address the abovementioned challenges. Simulation experiments on macroeconomic activities show that LLM-empowered agents can make realistic work and consumption decisions and emerge more reasonable macroeconomic phenomena than existing rule-based or AI agents. Our work demonstrates the promising potential to simulate macroeconomics based on LLM and its human-like characteristics.", "url": "https://arxiv.org/abs/2310.10436"}, {"metadata": {"arXiv": "2310.09479", "Date": "Sat, 14 Oct 2023 03:26:21 ", "Title": "Unified High-binding Watermark for Unconditional Image Generation Models", "Authors": ["Ruinan Ma", "Yu-an Tan", "Shangbo Wu", "Tian Chen", "Yajie Wang", "Yuanzhang Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep learning techniques have implemented many unconditional image generation (UIG) models, such as GAN, Diffusion model, etc. The extremely realistic images (also known as AI-Generated Content, AIGC for short) produced by these models bring urgent needs for intellectual property protection such as data traceability and copyright certification. An attacker can steal the output images of the target model and use them as part of the training data to train a private surrogate UIG model. The implementation mechanisms of UIG models are diverse and complex, and there is no unified and effective protection and verification method at present. To address these issues, we propose a two-stage unified watermark verification mechanism with high-binding effects for such models. In the first stage, we use an encoder to invisibly write the watermark image into the output images of the original AIGC tool, and reversely extract the watermark image through the corresponding decoder. In the second stage, we design the decoder fine-tuning process, and the fine-tuned decoder can make correct judgments on whether the suspicious model steals the original AIGC tool data. Experiments demonstrate our method can complete the verification work with almost zero false positive rate under the condition of only using the model output images. Moreover, the proposed method can achieve data steal verification across different types of UIG models, which further increases the practicality of the method.", "url": "https://arxiv.org/abs/2310.09479"}, {"metadata": {"arXiv": "2310.09560", "Date": "Sat, 14 Oct 2023 11:03:04 ", "Title": "UNIQA: A Unified Framework for Both Full-Reference and No-Reference Image Quality Assessment", "Authors": ["Yi Ke Yun", "Weisi Lin"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "The human visual system (HVS) is effective at distinguishing low-quality images due to its ability to sense the distortion level and the resulting semantic impact. Prior research focuses on developing dedicated networks based on the presence and absence of pristine images, respectively, and this results in limited application scope and potential performance inconsistency when switching from NR to FR IQA. In addition, most methods heavily rely on spatial distortion modeling through difference maps or weighted features, and this may not be able to well capture the correlations between distortion and the semantic impact it causes. To this end, we aim to design a unified network for both Full-Reference (FR) and No-Reference (NR) IQA via semantic impact modeling. Specifically, we employ an encoder to extract multi-level features from input images. Then a Hierarchical Self-Attention (HSA) module is proposed as a universal adapter for both FR and NR inputs to model the spatial distortion level at each encoder stage. Furthermore, considering that distortions contaminate encoder stages and damage image semantic meaning differently, a Cross-Scale Cross-Attention (CSCA) module is proposed to examine correlations between distortion at shallow stages and deep ones. By adopting HSA and CSCA, the proposed network can effectively perform both FR and NR IQA. Extensive experiments demonstrate that the proposed simple network is effective and outperforms the relevant state-of-the-art FR and NR methods on four synthetic-distorted datasets and three authentic-distorted datasets.", "url": "https://arxiv.org/abs/2310.09560"}, {"metadata": {"arXiv": "2310.09612", "Date": "Sat, 14 Oct 2023 16:28:57 ", "Title": "Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations", "Authors": ["Alexa R. Tartaglini", "Sheridan Feucht", "Michael A. Lepori", "Wai Keen Vong", "Charles Lovering", "Brenden M. Lake", "and Ellie Pavlick"], "Categories": "cs.CV cs.AI"}, "abstract": "Although deep neural networks can achieve human-level performance on many object recognition benchmarks, prior work suggests that these same models fail to learn simple abstract relations, such as determining whether two objects are the same or different. Much of this prior work focuses on training convolutional neural networks to classify images of two same or two different abstract shapes, testing generalization on within-distribution stimuli. In this article, we comprehensively study whether deep neural networks can acquire and generalize same-different relations both within and out-of-distribution using a variety of architectures, forms of pretraining, and fine-tuning datasets. We find that certain pretrained transformers can learn a same-different relation that generalizes with near perfect accuracy to out-of-distribution stimuli. Furthermore, we find that fine-tuning on abstract shapes that lack texture or color provides the strongest out-of-distribution generalization. Our results suggest that, with the right approach, deep neural networks can learn generalizable same-different visual relations.", "url": "https://arxiv.org/abs/2310.09612"}, {"metadata": {"arXiv": "2310.09755", "Date": "Sun, 15 Oct 2023 06:46:15 ", "Title": "Beyond Segmentation: Road Network Generation with Multi-Modal LLMs", "Authors": ["Sumedh Rasal and Sanjay Kumar Boddhu"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper introduces an innovative approach to road network generation through the utilization of a multi-modal Large Language Model (LLM). Our model is specifically designed to process aerial images of road layouts and produce detailed, navigable road networks within the input images. The core innovation of our system lies in the unique training methodology employed for the large language model to generate road networks as its output. This approach draws inspiration from the BLIP-2 architecture arXiv:2301.12597, leveraging pre-trained frozen image encoders and large language models to create a versatile multi-modal LLM. Our work also offers an alternative to the reasoning segmentation method proposed in the LISA paper arXiv:2308.00692. By training the large language model with our approach, the necessity for generating binary segmentation masks, as suggested in the LISA paper arXiv:2308.00692, is effectively eliminated. Experimental results underscore the efficacy of our multi-modal LLM in providing precise and valuable navigational guidance. This research represents a significant stride in bolstering autonomous navigation systems, especially in road network scenarios, where accurate guidance is of paramount importance.", "url": "https://arxiv.org/abs/2310.09755"}, {"metadata": {"arXiv": "2310.09761", "Date": "Sun, 15 Oct 2023 07:20:22 ", "Title": "CAPro: Webly Supervised Learning with Cross-Modality Aligned Prototypes", "Authors": ["Yulei Qin", "Xingyu Chen", "Yunhang Shen", "Chaoyou Fu", "Yun Gu", "Ke Li", "Xing Sun", "Rongrong Ji"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at NeurIPS2023"]}, "abstract": "Webly supervised learning has attracted increasing attention for its effectiveness in exploring publicly accessible data at scale without manual annotation. However, most existing methods of learning with web datasets are faced with challenges from label noise, and they have limited assumptions on clean samples under various noise. For instance, web images retrieved with queries of tiger cat (a cat species) and drumstick (a musical instrument) are almost dominated by images of tigers and chickens, which exacerbates the challenge of fine-grained visual concept learning. In this case, exploiting both web images and their associated texts is a requisite solution to combat real-world noise. In this paper, we propose Cross-modality Aligned Prototypes (CAPro), a unified prototypical contrastive learning framework to learn visual representations with correct semantics. For one thing, we leverage textual prototypes, which stem from the distinct concept definition of classes, to select clean images by text matching and thus disambiguate the formation of visual prototypes. For another, to handle missing and mismatched noisy texts, we resort to the visual feature space to complete and enhance individual texts and thereafter improve text matching. Such semantically aligned visual prototypes are further polished up with high-quality samples, and engaged in both cluster regularization and noise removal. Besides, we propose collective bootstrapping to encourage smoother and wiser label reference from appearance-similar instances in a manner of dictionary look-up. Extensive experiments on WebVision1k and NUS-WIDE (Web) demonstrate that CAPro well handles realistic noise under both single-label and multi-label scenarios. CAPro achieves new state-of-the-art performance and exhibits robustness to open-set recognition. Codes are available at https://github.com/yuleiqin/capro.", "url": "https://arxiv.org/abs/2310.09761"}, {"metadata": {"arXiv": "2310.10038", "Date": "Mon, 16 Oct 2023 03:47:08 ", "Title": "Smart City Transportation: Deep Learning Ensemble Approach for Traffic Accident Detection", "Authors": ["Victor Adewopo", "Nelly Elsayed"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "4 figures"]}, "abstract": "The dynamic and unpredictable nature of road traffic necessitates effective accident detection methods for enhancing safety and streamlining traffic management in smart cities. This paper offers a comprehensive exploration study of prevailing accident detection techniques, shedding light on the nuances of other state-of-the-art methodologies while providing a detailed overview of distinct traffic accident types like rear-end collisions, T-bone collisions, and frontal impact accidents. Our novel approach introduces the I3D-CONVLSTM2D model architecture, a lightweight solution tailored explicitly for accident detection in smart city traffic surveillance systems by integrating RGB frames with optical flow information. Our experimental study's empirical analysis underscores our approach's efficacy, with the I3D-CONVLSTM2D RGB + Optical-Flow (Trainable) model outperforming its counterparts, achieving an impressive 87\\% Mean Average Precision (MAP). Our findings further elaborate on the challenges posed by data imbalances, particularly when working with a limited number of datasets, road structures, and traffic scenarios. Ultimately, our research illuminates the path towards a sophisticated vision-based accident detection system primed for real-time integration into edge IoT devices within smart urban infrastructures.", "url": "https://arxiv.org/abs/2310.10038"}, {"metadata": {"arXiv": "2310.10070", "Date": "Mon, 16 Oct 2023 05:04:21 ", "Title": "GreatSplicing: A Semantically Rich Splicing Dataset", "Authors": ["Xiuli Bi and Jiaming Liang"], "Categories": "cs.CV cs.AI"}, "abstract": "In existing splicing forgery datasets, the insufficient semantic variety of spliced regions causes a problem that trained detection models overfit semantic features rather than splicing traces. Meanwhile, because of the absence of a reasonable dataset, different detection methods proposed cannot reach a consensus on experimental settings. To address these urgent issues, GreatSplicing, an manually created splicing dataset with considerable amount and high quality, is proposed in this paper. GreatSplicing comprises 5,000 spliced images and covers spliced regions with 335 distinct semantic categories, allowing neural networks to grasp splicing traces better. Extensive experiments demonstrate that models trained on GreatSplicing exhibit minimal misidentification rates and superior cross-dataset detection capabilities compared to existing datasets. Furthermore, GreatSplicing is available for all research purposes and could be downloaded from www.greatsplicing.net.", "url": "https://arxiv.org/abs/2310.10070"}, {"metadata": {"arXiv": "2310.10149", "Date": "Mon, 16 Oct 2023 07:37:20 ", "Title": "Recursive Segmentation Living Image: An eXplainable AI (XAI) Approach for Computing Structural Beauty of Images or the Livingness of Space", "Authors": ["Yao Qianxiang and Bin Jiang"], "Categories": "cs.CV cs.AI"}, "abstract": "This study introduces the concept of \"structural beauty\" as an objective computational approach for evaluating the aesthetic appeal of images. Through the utilization of the Segment anything model (SAM), we propose a method that leverages recursive segmentation to extract finer-grained substructures. Additionally, by reconstructing the hierarchical structure, we obtain a more accurate representation of substructure quantity and hierarchy. This approach reproduces and extends our previous research, allowing for the simultaneous assessment of Livingness in full-color images without the need for grayscale conversion or separate computations for foreground and background Livingness. Furthermore, the application of our method to the Scenic or Not dataset, a repository of subjective scenic ratings, demonstrates a high degree of consistency with subjective ratings in the 0-6 score range. This underscores that structural beauty is not solely a subjective perception, but a quantifiable attribute accessible through objective computation. Through our case studies, we have arrived at three significant conclusions. 1) our method demonstrates the capability to accurately segment meaningful objects, including trees, buildings, and windows, as well as abstract substructures within paintings. 2) we observed that the clarity of an image impacts our computational results; clearer images tend to yield higher Livingness scores. However, for equally blurry images, Livingness does not exhibit a significant reduction, aligning with human visual perception. 3) our approach fundamentally differs from methods employing Convolutional Neural Networks (CNNs) for predicting image scores. Our method not only provides computational results but also offers transparency and interpretability, positioning it as a novel avenue in the realm of Explainable AI (XAI).", "url": "https://arxiv.org/abs/2310.10149"}, {"metadata": {"arXiv": "2310.10219", "Date": "Mon, 16 Oct 2023 09:29:52 ", "Title": "Using Global Land Cover Product as Prompt for Cropland Mapping via Visual Foundation Model", "Authors": ["Chao Tao", "Aoran Hu", "Rong Xiao", "Haifeng Li", "and Yuze Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Data-driven deep learning methods have shown great potential in cropland mapping. However, due to multiple factors such as attributes of cropland (topography, climate, crop type) and imaging conditions (viewing angle, illumination, scale), croplands under different scenes demonstrate a great domain gap. This makes it difficult for models trained in the specific scenes to directly generalize to other scenes. A common way to handle this problem is through the \"Pretrain+Fine-tuning\" paradigm. Unfortunately, considering the variety of features of cropland that are affected by multiple factors, it is hardly to handle the complex domain gap between pre-trained data and target data using only sparse fine-tuned samples as general constraints. Moreover, as the number of model parameters grows, fine-tuning is no longer an easy and low-cost task. With the emergence of prompt learning via visual foundation models, the \"Pretrain+Prompting\" paradigm redesigns the optimization target by introducing individual prompts for each single sample. This simplifies the domain adaption from generic to specific scenes during model reasoning processes. Therefore, we introduce the \"Pretrain+Prompting\" paradigm to interpreting cropland scenes and design the auto-prompting (APT) method based on freely available global land cover product. It can achieve a fine-grained adaptation process from generic scenes to specialized cropland scenes without introducing additional label costs. To our best knowledge, this work pioneers the exploration of the domain adaption problems for cropland mapping under prompt learning perspectives. Our experiments using two sub-meter cropland datasets from southern and northern China demonstrated that the proposed method via visual foundation models outperforms traditional supervised learning and fine-tuning approaches in the field of remote sensing.", "url": "https://arxiv.org/abs/2310.10219"}, {"metadata": {"arXiv": "2310.10431", "Date": "Mon, 16 Oct 2023 14:16:04 ", "Title": "Longitudinal Self-supervised Learning Using Neural Ordinary Differential Equation", "Authors": ["Rachid Zeghlache", "Pierre-Henri Conze", "Mostafa El Habib Daho", "Yihao Li", "Hugo Le Boit\\'e", "Ramin Tadayoni", "Pascal Massin", "B\\'eatrice Cochener", "Ikram Brahim", "Gwenol\\'e Quellec", "Mathieu Lamard"], "Categories": "cs.CV cs.AI", "Journal-ref": "Predictive Intelligence in Medicine. PRIME 2023. Part of the Lecture Notes in Computer Science book series (LNCS,volume 14277)", "DOI": "10.1007/978-3-031-46005-0_1"}, "abstract": "Longitudinal analysis in medical imaging is crucial to investigate the progressive changes in anatomical structures or disease progression over time. In recent years, a novel class of algorithms has emerged with the goal of learning disease progression in a self-supervised manner, using either pairs of consecutive images or time series of images. By capturing temporal patterns without external labels or supervision, longitudinal self-supervised learning (LSSL) has become a promising avenue. To better understand this core method, we explore in this paper the LSSL algorithm under different scenarios. The original LSSL is embedded in an auto-encoder (AE) structure. However, conventional self-supervised strategies are usually implemented in a Siamese-like manner. Therefore, (as a first novelty) in this study, we explore the use of Siamese-like LSSL. Another new core framework named neural ordinary differential equation (NODE). NODE is a neural network architecture that learns the dynamics of ordinary differential equations (ODE) through the use of neural networks. Many temporal systems can be described by ODE, including modeling disease progression. We believe that there is an interesting connection to make between LSSL and NODE. This paper aims at providing a better understanding of those core algorithms for learning the disease progression with the mentioned change. In our different experiments, we employ a longitudinal dataset, named OPHDIAT, targeting diabetic retinopathy (DR) follow-up. Our results demonstrate the application of LSSL without including a reconstruction term, as well as the potential of incorporating NODE in conjunction with LSSL.", "url": "https://arxiv.org/abs/2310.10431"}, {"metadata": {"arXiv": "2310.10453", "Date": "Mon, 16 Oct 2023 14:35:29 ", "Title": "On the Relevance of Temporal Features for Medical Ultrasound Video Recognition", "Authors": ["D. Hudson Smith", "John Paul Lineberger", "George H. Baker"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "4 figures", "published in MICCAI 23"], "Journal-ref": "International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 744-753. Cham: Springer Nature Switzerland, 2023", "DOI": "10.1007/978-3-031-43895-0_70"}, "abstract": "Many medical ultrasound video recognition tasks involve identifying key anatomical features regardless of when they appear in the video suggesting that modeling such tasks may not benefit from temporal features. Correspondingly, model architectures that exclude temporal features may have better sample efficiency. We propose a novel multi-head attention architecture that incorporates these hypotheses as inductive priors to achieve better sample efficiency on common ultrasound tasks. We compare the performance of our architecture to an efficient 3D CNN video recognition model in two settings: one where we expect not to require temporal features and one where we do. In the former setting, our model outperforms the 3D CNN - especially when we artificially limit the training data. In the latter, the outcome reverses. These results suggest that expressive time-independent models may be more effective than state-of-the-art video recognition models for some common ultrasound tasks in the low-data regime.", "url": "https://arxiv.org/abs/2310.10453"}, {"metadata": {"arXiv": "2310.10541", "Date": "Mon, 16 Oct 2023 16:13:53 ", "Title": "Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories", "Authors": ["Jiyuan Shen", "Wenzhuo Yang", "Kwok-Yan Lam"], "Categories": "cs.CV cs.AI"}, "abstract": "Training a large and state-of-the-art machine learning model typically necessitates the use of large-scale datasets, which, in turn, makes the training and parameter-tuning process expensive and time-consuming. Some researchers opt to distil information from real-world datasets into tiny and compact synthetic datasets while maintaining their ability to train a well-performing model, hence proposing a data-efficient method known as Dataset Distillation (DD). Despite recent progress in this field, existing methods still underperform and cannot effectively replace large datasets. In this paper, unlike previous methods that focus solely on improving the efficacy of student distillation, we are the first to recognize the important interplay between expert and student. We argue the significant impact of expert smoothness when employing more potent expert trajectories in subsequent dataset distillation. Based on this, we introduce the integration of clipping loss and gradient penalty to regulate the rate of parameter changes in expert trajectories. Furthermore, in response to the sensitivity exhibited towards randomly initialized variables during distillation, we propose representative initialization for synthetic dataset and balanced inner-loop loss. Finally, we present two enhancement strategies, namely intermediate matching loss and weight perturbation, to mitigate the potential occurrence of cumulative errors. We conduct extensive experiments on datasets of different scales, sizes, and resolutions. The results demonstrate that the proposed method significantly outperforms prior methods.", "url": "https://arxiv.org/abs/2310.10541"}, {"metadata": {"arXiv": "2310.09658", "Date": "Sat, 14 Oct 2023 20:18:49 ", "Title": "A Generalized Extensive-Form Fictitious Play Algorithm", "Authors": ["Tim P. Schulze"], "Categories": "cs.GT cs.AI"}, "abstract": "We introduce a simple extensive-form algorithm for finding equilibria of two-player, zero-sum games. The algorithm is realization equivalent to a generalized form of Fictitious Play. We compare its performance to that of a similar extensive-form fictitious play algorithm and a counter-factual regret minimization algorithm. All three algorithms share the same advantages over normal-form fictitious play in terms of reducing storage requirements and computational complexity. The new algorithm is intuitive and straightforward to implement, making it an appealing option for those looking for a quick and easy game solving tool.", "url": "https://arxiv.org/abs/2310.09658"}, {"metadata": {"arXiv": "2310.09463", "Date": "Sat, 14 Oct 2023 01:17:56 ", "Title": "HIO-SDF: Hierarchical Incremental Online Signed Distance Fields", "Authors": ["Vasileios Vasilopoulos", "Suveer Garg", "Jinwook Huh", "Bhoram Lee", "Volkan Isler"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "7 figures"]}, "abstract": "A good representation of a large, complex mobile robot workspace must be space-efficient yet capable of encoding relevant geometric details. When exploring unknown environments, it needs to be updatable incrementally in an online fashion. We introduce HIO-SDF, a new method that represents the environment as a Signed Distance Field (SDF). State of the art representations of SDFs are based on either neural networks or voxel grids. Neural networks are capable of representing the SDF continuously. However, they are hard to update incrementally as neural networks tend to forget previously observed parts of the environment unless an extensive sensor history is stored for training. Voxel-based representations do not have this problem but they are not space-efficient especially in large environments with fine details. HIO-SDF combines the advantages of these representations using a hierarchical approach which employs a coarse voxel grid that captures the observed parts of the environment together with high-resolution local information to train a neural network. HIO-SDF achieves a 46% lower mean global SDF error across all test scenes than a state of the art continuous representation, and a 30% lower error than a discrete representation at the same resolution as our coarse global SDF grid.", "url": "https://arxiv.org/abs/2310.09463"}, {"metadata": {"arXiv": "2310.09676", "Date": "Sat, 14 Oct 2023 22:24:58 ", "Title": "Mastering Robot Manipulation with Multimodal Prompts through Pretraining and Multi-task Fine-tuning", "Authors": ["Jiachen Li", "Qiaozi Gao", "Michael Johnston", "Xiaofeng Gao", "Xuehai He", "Suhaila Shakiah", "Hangjie Shi", "Reza Ghanadan", "William Yang Wang"], "Categories": "cs.RO cs.AI"}, "abstract": "Prompt-based learning has been demonstrated as a compelling paradigm contributing to large language models' tremendous success (LLMs). Inspired by their success in language tasks, existing research has leveraged LLMs in embodied instruction following and task planning. However, not much attention has been paid to embodied tasks with multimodal prompts, combining vision signals with text descriptions. This type of task poses a major challenge to robots' capability to understand the interconnection and complementarity between vision and language signals. In this work, we introduce an effective framework that learns a policy to perform robot manipulation with multimodal prompts from multi-task expert trajectories. Our methods consist of a two-stage training pipeline that performs inverse dynamics pretraining and multi-task finetuning. To facilitate multimodal understanding, we design our multimodal prompt encoder by augmenting a pretrained LM with a residual connection to the visual input and model the dependencies among action dimensions. Empirically, we evaluate the efficacy of our method on the VIMA-BENCH and establish a new state-of-the-art (10% improvement in success rate). Moreover, we demonstrate that our model exhibits remarkable in-context learning ability.", "url": "https://arxiv.org/abs/2310.09676"}, {"metadata": {"arXiv": "2310.10307", "Date": "Mon, 16 Oct 2023 11:42:54 ", "Title": "Learning visual-based deformable object rearrangement with local graph neural networks", "Authors": ["Yuhong Deng", "Xueqian Wang", "Lipeng chen"], "Categories": "cs.RO cs.AI", "Journal-ref": "Complex & Intelligent Systems, 2023: 1-14"}, "abstract": "Goal-conditioned rearrangement of deformable objects (e.g. straightening a rope and folding a cloth) is one of the most common deformable manipulation tasks, where the robot needs to rearrange a deformable object into a prescribed goal configuration with only visual observations. These tasks are typically confronted with two main challenges: the high dimensionality of deformable configuration space and the underlying complexity, nonlinearity and uncertainty inherent in deformable dynamics. To address these challenges, we propose a novel representation strategy that can efficiently model the deformable object states with a set of keypoints and their interactions. We further propose local-graph neural network (GNN), a light local GNN learning to jointly model the deformable rearrangement dynamics and infer the optimal manipulation actions (e.g. pick and place) by constructing and updating two dynamic graphs. Both simulated and real experiments have been conducted to demonstrate that the proposed dynamic graph representation shows superior expressiveness in modeling deformable rearrangement dynamics. Our method reaches much higher success rates on a variety of deformable rearrangement tasks (96.3% on average) than state-of-the-art method in simulation experiments. Besides, our method is much more lighter and has a 60% shorter inference time than state-of-the-art methods. We also demonstrate that our method performs well in the multi-task learning scenario and can be transferred to real-world applications with an average success rate of 95% by solely fine tuning a keypoint detector.", "url": "https://arxiv.org/abs/2310.10307"}, {"metadata": {"arXiv": "2310.10645", "Date": "Mon, 16 Oct 2023 17:59:12 ", "Title": "Interactive Task Planning with Language Models", "Authors": ["Boyi Li and Philipp Wu and Pieter Abbeel and Jitendra Malik"], "Categories": "cs.RO cs.AI cs.CL cs.HC"}, "abstract": "An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution. However, most traditional methods require predefined module design, which makes it hard to generalize to different goals. Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain-specific pretrained models. To tackle this, we propose a simple framework that achieves interactive task planning with language models. Our system incorporates both high-level planning and low-level function execution via language. We verify the robustness of our system in generating novel high-level instructions for unseen objectives and its ease of adaptation to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering. Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps. Please check more details on our https://wuphilipp.github.io/itp_site and https://youtu.be/TrKLuyv26_g.", "url": "https://arxiv.org/abs/2310.10645"}, {"metadata": {"arXiv": "2310.09412", "Date": "Fri, 13 Oct 2023 21:26:16 ", "Title": "Hybrid Reinforcement Learning for Optimizing Pump Sustainability in Real-World Water Distribution Networks", "Authors": ["Harsh Patel", "Yuan Zhou", "Alexander P Lamb", "Shu Wang", "Jieliang Luo"], "Categories": "cs.AI cs.LG"}, "abstract": "This article addresses the pump-scheduling optimization problem to enhance real-time control of real-world water distribution networks (WDNs). Our primary objectives are to adhere to physical operational constraints while reducing energy consumption and operational costs. Traditional optimization techniques, such as evolution-based and genetic algorithms, often fall short due to their lack of convergence guarantees. Conversely, reinforcement learning (RL) stands out for its adaptability to uncertainties and reduced inference time, enabling real-time responsiveness. However, the effective implementation of RL is contingent on building accurate simulation models for WDNs, and prior applications have been limited by errors in simulation training data. These errors can potentially cause the RL agent to learn misleading patterns and actions and recommend suboptimal operational strategies. To overcome these challenges, we present an improved \"hybrid RL\" methodology. This method integrates the benefits of RL while anchoring it in historical data, which serves as a baseline to incrementally introduce optimal control recommendations. By leveraging operational data as a foundation for the agent's actions, we enhance the explainability of the agent's actions, foster more robust recommendations, and minimize error. Our findings demonstrate that the hybrid RL agent can significantly improve sustainability, operational efficiency, and dynamically adapt to emerging scenarios in real-world WDNs.", "url": "https://arxiv.org/abs/2310.09412"}, {"metadata": {"arXiv": "2310.09454", "Date": "Sat, 14 Oct 2023 00:07:03 ", "Title": "LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents", "Authors": ["Yash Shukla", "Wenchang Gao", "Vasanth Sarathy", "Alvaro Velasquez", "Robert Wright", "Jivko Sinapov"], "Categories": "cs.AI cs.LG"}, "abstract": "Recent advancements in reasoning abilities of Large Language Models (LLM) has promoted their usage in problems that require high-level planning for robots and artificial agents. However, current techniques that utilize LLMs for such planning tasks make certain key assumptions such as, access to datasets that permit finetuning, meticulously engineered prompts that only provide relevant and essential information to the LLM, and most importantly, a deterministic approach to allow execution of the LLM responses either in the form of existing policies or plan operators. In this work, we propose LgTS (LLM-guided Teacher-Student learning), a novel approach that explores the planning abilities of LLMs to provide a graphical representation of the sub-goals to a reinforcement learning (RL) agent that does not have access to the transition dynamics of the environment. The RL agent uses Teacher-Student learning algorithm to learn a set of successful policies for reaching the goal state from the start state while simultaneously minimizing the number of environmental interactions. Unlike previous methods that utilize LLMs, our approach does not assume access to a propreitary or a fine-tuned LLM, nor does it require pre-trained policies that achieve the sub-goals proposed by the LLM. Through experiments on a gridworld based DoorKey domain and a search-and-rescue inspired domain, we show that generating a graphical structure of sub-goals helps in learning policies for the LLM proposed sub-goals and the Teacher-Student learning algorithm minimizes the number of environment interactions when the transition dynamics are unknown.", "url": "https://arxiv.org/abs/2310.09454"}, {"metadata": {"arXiv": "2310.09462", "Date": "Sat, 14 Oct 2023 01:08:52 ", "Title": "A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading", "Authors": ["Rasoul Amirzadeh", "Dhananjay Thiruvady", "Asef Nazari", "Mong Shan Ee"], "Categories": "cs.AI cs.LG"}, "abstract": "Despite advances in artificial intelligence-enhanced trading methods, developing a profitable automated trading system remains challenging in the rapidly evolving cryptocurrency market. This study aims to address these challenges by developing a reinforcement learning-based automated trading system for five popular altcoins~(cryptocurrencies other than Bitcoin): Binance Coin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present CausalReinforceNet, a framework framed as a decision support system. Designed as the foundational architecture of the trading system, the CausalReinforceNet framework enhances the capabilities of the reinforcement learning agent through causal analysis. Within this framework, we use Bayesian networks in the feature engineering process to identify the most relevant features with causal relationships that influence cryptocurrency price movements. Additionally, we incorporate probabilistic price direction signals from dynamic Bayesian networks to enhance our reinforcement learning agent's decision-making. Due to the high volatility of the cryptocurrency market, we design our framework to adopt a conservative approach that limits sell and buy position sizes to manage risk. We develop two agents using the CausalReinforceNet framework, each based on distinct reinforcement learning algorithms. The results indicate that our framework substantially surpasses the Buy-and-Hold benchmark strategy in profitability. Additionally, both agents generated notable returns on investment for Binance Coin and Ethereum.", "url": "https://arxiv.org/abs/2310.09462"}, {"metadata": {"arXiv": "2310.09605", "Date": "Sat, 14 Oct 2023 15:48:15 ", "Title": "Penetrative AI: Making LLMs Comprehend the Physical World", "Authors": ["Huatao Xu", "Liying Han", "Mo Li", "Mani Srivastava"], "Categories": "cs.AI cs.LG", "Comments": ["2pages"]}, "abstract": "Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term \"\\textit{Penetrative AI}\". The paper explores such an extension at two levels of LLMs' ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the knowledge they learned during training for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.", "url": "https://arxiv.org/abs/2310.09605"}, {"metadata": {"arXiv": "2310.09838", "Date": "Sun, 15 Oct 2023 13:57:50 ", "Title": "Explaining How a Neural Network Play the Go Game and Let People Learn", "Authors": ["Huilin Zhou", "Huijie Tang", "Mingjie Li", "Hao Zhang", "Zhenyu Liu", "Quanshi Zhang"], "Categories": "cs.AI cs.CV cs.LG"}, "abstract": "The AI model has surpassed human players in the game of Go, and it is widely believed that the AI model has encoded new knowledge about the Go game beyond human players. In this way, explaining the knowledge encoded by the AI model and using it to teach human players represent a promising-yet-challenging issue in explainable AI. To this end, mathematical supports are required to ensure that human players can learn accurate and verifiable knowledge, rather than specious intuitive analysis. Thus, in this paper, we extract interaction primitives between stones encoded by the value network for the Go game, so as to enable people to learn from the value network. Experiments show the effectiveness of our method.", "url": "https://arxiv.org/abs/2310.09838"}, {"metadata": {"arXiv": "2310.09997", "Date": "Mon, 16 Oct 2023 01:13:26 ", "Title": "Forecaster: Towards Temporally Abstract Tree-Search Planning from Pixels", "Authors": ["Thomas Jiralerspong", "Flemming Kondrup", "Doina Precup", "Khimya Khetarpal"], "Categories": "cs.AI cs.LG cs.SY eess.SY"}, "abstract": "The ability to plan at many different levels of abstraction enables agents to envision the long-term repercussions of their decisions and thus enables sample-efficient learning. This becomes particularly beneficial in complex environments from high-dimensional state space such as pixels, where the goal is distant and the reward sparse. We introduce Forecaster, a deep hierarchical reinforcement learning approach which plans over high-level goals leveraging a temporally abstract world model. Forecaster learns an abstract model of its environment by modelling the transitions dynamics at an abstract level and training a world model on such transition. It then uses this world model to choose optimal high-level goals through a tree-search planning procedure. It additionally trains a low-level policy that learns to reach those goals. Our method not only captures building world models with longer horizons, but also, planning with such models in downstream tasks. We empirically demonstrate Forecaster's potential in both single-task learning and generalization to new tasks in the AntMaze domain.", "url": "https://arxiv.org/abs/2310.09997"}, {"metadata": {"arXiv": "2310.10312", "Date": "Mon, 16 Oct 2023 11:46:45 ", "Title": "End-to-end Offline Reinforcement Learning for Glycemia Control", "Authors": ["Tristan Beolet", "Alice Adenis", "Erik Huneker", "Maxime Louis"], "Categories": "cs.AI cs.LG q-bio.QM"}, "abstract": "The development of closed-loop systems for glycemia control in type I diabetes relies heavily on simulated patients. Improving the performances and adaptability of these close-loops raises the risk of over-fitting the simulator. This may have dire consequences, especially in unusual cases which were not faithfully-if at all-captured by the simulator. To address this, we propose to use offline RL agents, trained on real patient data, to perform the glycemia control. To further improve the performances, we propose an end-to-end personalization pipeline, which leverages offline-policy evaluation methods to remove altogether the need of a simulator, while still enabling an estimation of clinically relevant metrics for diabetes.", "url": "https://arxiv.org/abs/2310.10312"}, {"metadata": {"arXiv": "2310.10610", "Date": "Mon, 16 Oct 2023 17:34:54 ", "Title": "Quantifying Assistive Robustness Via the Natural-Adversarial Frontier", "Authors": ["Jerry Zhi-Yang He", "Zackory Erickson", "Daniel S. Brown", "Anca D. Dragan"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "Our ultimate goal is to build robust policies for robots that assist people. What makes this hard is that people can behave unexpectedly at test time, potentially interacting with the robot outside its training distribution and leading to failures. Even just measuring robustness is a challenge. Adversarial perturbations are the default, but they can paint the wrong picture: they can correspond to human motions that are unlikely to occur during natural interactions with people. A robot policy might fail under small adversarial perturbations but work under large natural perturbations. We propose that capturing robustness in these interactive settings requires constructing and analyzing the entire natural-adversarial frontier: the Pareto-frontier of human policies that are the best trade-offs between naturalness and low robot performance. We introduce RIGID, a method for constructing this frontier by training adversarial human policies that trade off between minimizing robot reward and acting human-like (as measured by a discriminator). On an Assistive Gym task, we use RIGID to analyze the performance of standard collaborative Reinforcement Learning, as well as the performance of existing methods meant to increase robustness. We also compare the frontier RIGID identifies with the failures identified in expert adversarial interaction, and with naturally-occurring failures during user interaction. Overall, we find evidence that RIGID can provide a meaningful measure of robustness predictive of deployment performance, and uncover failure cases in human-robot interaction that are difficult to find manually. https://ood-human.github.io.", "url": "https://arxiv.org/abs/2310.10610"}, {"metadata": {"arXiv": "2310.09562", "Date": "Sat, 14 Oct 2023 11:24:28 ", "Title": "Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?", "Authors": ["Prasanna Mayilvahanan", "Thadd\\\"aus Wiedemer", "Evgenia Rusak", "Matthias Bethge", "Wieland Brendel"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Foundation models like CLIP are trained on hundreds of millions of samples and effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows stellar zero-shot and few-shot capabilities on a wide range of out-of-distribution (OOD) benchmarks, which prior works attribute mainly to today's large and comprehensive training dataset (like LAION). However, it is questionable how meaningful terms like out-of-distribution generalization are for CLIP as it seems likely that web-scale datasets like LAION simply contain many samples that are similar to common OOD benchmarks originally designed for ImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that replicate ImageNet's train-test similarity with respect to common OOD benchmarks. While we observe a performance drop on some benchmarks, surprisingly, CLIP's overall performance remains high. This shows that high train-test similarity is insufficient to explain CLIP's OOD performance, and other properties of the training data must drive CLIP to learn more generalizable representations. Additionally, by pruning data points that are dissimilar to the OOD benchmarks, we uncover a 100M split of LAION ($\\frac{1}{4}$th of its original size) on which CLIP can be trained to match its original OOD performance.", "url": "https://arxiv.org/abs/2310.09562"}, {"metadata": {"arXiv": "2310.09709", "Date": "Sun, 15 Oct 2023 02:30:27 ", "Title": "New Advances in Body Composition Assessment with ShapedNet: A Single Image Deep Regression Approach", "Authors": ["Navar Medeiros M. Nascimento", "Pedro Cavalcante de Sousa Junior", "Pedro Yuri Rodrigues Nunes", "Suane Pires Pinheiro da Silva", "Luiz Lannes Loureiro", "Victor Zaban Bittencourt", "Valden Luis Matos Capistrano Junior", "Pedro Pedrosa Rebou\\c{c}as Filho"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Preprinted version in October 2023. The paper is under consideration at Pattern Recognition Letters"]}, "abstract": "We introduce a novel technique called ShapedNet to enhance body composition assessment. This method employs a deep neural network capable of estimating Body Fat Percentage (BFP), performing individual identification, and enabling localization using a single photograph. The accuracy of ShapedNet is validated through comprehensive comparisons against the gold standard method, Dual-Energy X-ray Absorptiometry (DXA), utilizing 1273 healthy adults spanning various ages, sexes, and BFP levels. The results demonstrate that ShapedNet outperforms in 19.5% state of the art computer vision-based approaches for body fat estimation, achieving a Mean Absolute Percentage Error (MAPE) of 4.91% and Mean Absolute Error (MAE) of 1.42. The study evaluates both gender-based and Gender-neutral approaches, with the latter showcasing superior performance. The method estimates BFP with 95% confidence within an error margin of 4.01% to 5.81%. This research advances multi-task learning and body composition assessment theory through ShapedNet.", "url": "https://arxiv.org/abs/2310.09709"}, {"metadata": {"arXiv": "2310.09978", "Date": "Sun, 15 Oct 2023 23:05:17 ", "Title": "Chinese Painting Style Transfer Using Deep Generative Models", "Authors": ["Weijian Ma", "Yanyang Kong"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Artistic style transfer aims to modify the style of the image while preserving its content. Style transfer using deep learning models has been widely studied since 2015, and most of the applications are focused on specific artists like Van Gogh, Monet, Cezanne. There are few researches and applications on traditional Chinese painting style transfer. In this paper, we will study and leverage different state-of-the-art deep generative models for Chinese painting style transfer and evaluate the performance both qualitatively and quantitatively. In addition, we propose our own algorithm that combines several style transfer models for our task. Specifically, we will transfer two main types of traditional Chinese painting style, known as \"Gong-bi\" and \"Shui-mo\" (to modern images like nature objects, portraits and landscapes.", "url": "https://arxiv.org/abs/2310.09978"}, {"metadata": {"arXiv": "2310.10008", "Date": "Mon, 16 Oct 2023 02:05:03 ", "Title": "Towards Unified and Effective Domain Generalization", "Authors": ["Yiyuan Zhang", "Kaixiong Gong", "Xiaohan Ding", "Kaipeng Zhang", "Fangrui Lv", "Kurt Keutzer", "Xiangyu Yue"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project Website: https://invictus717.github.io/Generalization/"]}, "abstract": "We propose $\\textbf{UniDG}$, a novel and $\\textbf{Uni}$fied framework for $\\textbf{D}$omain $\\textbf{G}$eneralization that is capable of significantly enhancing the out-of-distribution generalization performance of foundation models regardless of their architectures. The core idea of UniDG is to finetune models during the inference stage, which saves the cost of iterative training. Specifically, we encourage models to learn the distribution of test data in an unsupervised manner and impose a penalty regarding the updating step of model parameters. The penalty term can effectively reduce the catastrophic forgetting issue as we would like to maximally preserve the valuable knowledge in the original model. Empirically, across 12 visual backbones, including CNN-, MLP-, and Transformer-based models, ranging from 1.89M to 303M parameters, UniDG shows an average accuracy improvement of +5.4% on DomainBed. These performance results demonstrate the superiority and versatility of UniDG. The code is publicly available at https://github.com/invictus717/UniDG", "url": "https://arxiv.org/abs/2310.10008"}, {"metadata": {"arXiv": "2310.10059", "Date": "Mon, 16 Oct 2023 04:49:06 ", "Title": "Flow Dynamics Correction for Action Recognition", "Authors": ["Lei Wang and Piotr Koniusz"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Technical report"]}, "abstract": "Various research studies indicate that action recognition performance highly depends on the types of motions being extracted and how accurate the human actions are represented. In this paper, we investigate different optical flow, and features extracted from these optical flow that capturing both short-term and long-term motion dynamics. We perform power normalization on the magnitude component of optical flow for flow dynamics correction to boost subtle or dampen sudden motions. We show that existing action recognition models which rely on optical flow are able to get performance boosted with our corrected optical flow. To further improve performance, we integrate our corrected flow dynamics into popular models through a simple hallucination step by selecting only the best performing optical flow features, and we show that by 'translating' the CNN feature maps into these optical flow features with different scales of motions leads to the new state-of-the-art performance on several benchmarks including HMDB-51, YUP++, fine-grained action recognition on MPII Cooking Activities, and large-scale Charades.", "url": "https://arxiv.org/abs/2310.10059"}, {"metadata": {"arXiv": "2310.10375", "Date": "Mon, 16 Oct 2023 13:16:09 ", "Title": "GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers", "Authors": ["Takeru Miyato", "Bernhard Jaeger", "Max Welling", "Andreas Geiger"], "Categories": "cs.CV cs.AI cs.LG stat.ML", "Comments": ["26 pages", "17 figures"]}, "abstract": "As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-based NVS models without any additional learned parameters and only minor computational overhead.", "url": "https://arxiv.org/abs/2310.10375"}, {"metadata": {"arXiv": "2310.10391", "Date": "Mon, 16 Oct 2023 13:32:53 ", "Title": "Towards Open World Active Learning for 3D Object Detection", "Authors": ["Zhuoxiao Chen", "Yadan Luo", "Zixin Wang", "Zijian Wang", "Xin Yu", "Zi Huang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2301.09249"]}, "abstract": "Significant strides have been made in closed world 3D object detection, testing systems in environments with known classes. However, the challenge arises in open world scenarios where new object classes appear. Existing efforts sequentially learn novel classes from streams of labeled data at a significant annotation cost, impeding efficient deployment to the wild. To seek effective solutions, we investigate a more practical yet challenging research task: Open World Active Learning for 3D Object Detection (OWAL-3D), aiming at selecting a small number of 3D boxes to annotate while maximizing detection performance on both known and unknown classes. The core difficulty centers on striking a balance between mining more unknown instances and minimizing the labeling expenses of point clouds. Empirically, our study finds the harmonious and inverse relationship between box quantities and their confidences can help alleviate the dilemma, avoiding the repeated selection of common known instances and focusing on uncertain objects that are potentially unknown. We unify both relational constraints into a simple and effective AL strategy namely OpenCRB, which guides to acquisition of informative point clouds with the least amount of boxes to label. Furthermore, we develop a comprehensive codebase for easy reproducing and future research, supporting 15 baseline methods (i.e., active learning, out-of-distribution detection and open world detection), 2 types of modern 3D detectors (i.e., one-stage SECOND and two-stage PV-RCNN) and 3 benchmark 3D datasets (i.e., KITTI, nuScenes and Waymo). Extensive experiments evidence that the proposed Open-CRB demonstrates superiority and flexibility in recognizing both novel and shared categories with very limited labeling costs, compared to state-of-the-art baselines.", "url": "https://arxiv.org/abs/2310.10391"}, {"metadata": {"arXiv": "2310.10625", "Date": "Mon, 16 Oct 2023 17:48:45 ", "Title": "Video Language Planning", "Authors": ["Yilun Du", "Mengjiao Yang", "Pete Florence", "Fei Xia", "Ayzaan Wahid", "Brian Ichter", "Pierre Sermanet", "Tianhe Yu", "Pieter Abbeel", "Joshua B. Tenenbaum", "Leslie Kaelbling", "Andy Zeng", "Jonathan Tompson"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["https://video-language-planning.github.io/"]}, "abstract": "We are interested in enabling visual planning for complex long-horizon tasks in the space of generated videos and language, leveraging recent advances in large generative models pretrained on Internet-scale data. To this end, we present video language planning (VLP), an algorithm that consists of a tree search procedure, where we train (i) vision-language models to serve as both policies and value functions, and (ii) text-to-video models as dynamics models. VLP takes as input a long-horizon task instruction and current image observation, and outputs a long video plan that provides detailed multimodal (video and language) specifications that describe how to complete the final task. VLP scales with increasing computation budget where more computation time results in improved video plans, and is able to synthesize long-horizon video plans across different robotics domains: from multi-object rearrangement, to multi-camera bi-arm dexterous manipulation. Generated video plans can be translated into real robot actions via goal-conditioned policies, conditioned on each intermediate frame of the generated video. Experiments show that VLP substantially improves long-horizon task success rates compared to prior methods on both simulated and real robots (across 3 hardware platforms).", "url": "https://arxiv.org/abs/2310.10625"}, {"metadata": {"arXiv": "2310.10647", "Date": "Mon, 16 Oct 2023 17:59:28 ", "Title": "A Survey on Video Diffusion Models", "Authors": ["Zhen Xing", "Qijun Feng", "Haoran Chen", "Qi Dai", "Han Hu", "Hang Xu", "Zuxuan Wu", "Yu-Gang Jiang"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement. Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research. However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain. To address this gap, this paper presents a comprehensive review of video diffusion models in the AIGC era. Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models. Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks. We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field. Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends. A comprehensive list of video diffusion models studied in this survey is available at https://github.com/ChenHsing/Awesome-Video-Diffusion-Models.", "url": "https://arxiv.org/abs/2310.10647"}, {"metadata": {"arXiv": "2310.09297", "Date": "Sun, 01 Oct 2023 08:12:55 ", "Title": "Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms", "Authors": ["Xiangyu Zeng", "Jie Lin", "Piao Hu", "Ruizheng Huang", "Zhicheng Zhang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "How humans and machines make sense of current inputs for relation reasoning and question-answering while putting the perceived information into context of our past memories, has been a challenging conundrum in cognitive science and artificial intelligence. Inspired by human brain's memory system and cognitive architectures, we propose a PMI framework that consists of perception, memory and inference components. Notably, the memory module comprises working and long-term memory, with the latter endowed with a higher-order structure to retain more accumulated knowledge and experiences. Through a differentiable competitive write access, current perceptions update working memory, which is later merged with long-term memory via outer product associations, averting memory overflow and minimizing information conflicts. In the inference module, relevant information is retrieved from two separate memory origins and associatively integrated to attain a more comprehensive and precise interpretation of current perceptions. We exploratively apply our PMI to improve prevailing Transformers and CNN models on question-answering tasks like bAbI-20k and Sort-of-CLEVR datasets, as well as relation calculation and image classification tasks, and in each case, our PMI enhancements consistently outshine their original counterparts significantly. Visualization analyses reveal that memory consolidation, along with the interaction and integration of information from diverse memory sources, substantially contributes to the model effectiveness on inference tasks.", "url": "https://arxiv.org/abs/2310.09297"}, {"metadata": {"arXiv": "2310.09338", "Date": "Fri, 13 Oct 2023 18:05:25 ", "Title": "Uncertainty Quantification using Generative Approach", "Authors": ["Yunsheng Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "We present the Incremental Generative Monte Carlo (IGMC) method, designed to measure uncertainty in deep neural networks using deep generative approaches. IGMC iteratively trains generative models, adding their output to the dataset, to compute the posterior distribution of the expectation of a random variable. We provide a theoretical guarantee of the convergence rate of IGMC relative to the sample size and sampling depth. Due to its compatibility with deep generative approaches, IGMC is adaptable to both neural network classification and regression tasks. We empirically study the behavior of IGMC on the MNIST digit classification task.", "url": "https://arxiv.org/abs/2310.09338"}, {"metadata": {"arXiv": "2310.09358", "Date": "Fri, 13 Oct 2023 18:53:30 ", "Title": "When are Bandits Robust to Misspecification?", "Authors": ["Debangshu Banerjee and Aditya Gopalan"], "Categories": "cs.LG cs.AI"}, "abstract": "Parametric feature-based reward models are widely employed by algorithms for decision making settings such as bandits and contextual bandits. The typical assumption under which they are analysed is realizability, i.e., that the true rewards of actions are perfectly explained by some parametric model in the class. We are, however, interested in the situation where the true rewards are (potentially significantly) misspecified with respect to the model class. For parameterized bandits and contextual bandits, we identify sufficient conditions, depending on the problem instance and model class, under which classic algorithms such as $\\epsilon$-greedy and LinUCB enjoy sublinear (in the time horizon) regret guarantees under even grossly misspecified rewards. This is in contrast to existing worst-case results for misspecified bandits which show regret bounds that scale linearly with time, and shows that there can be a nontrivially large set of bandit instances that are robust to misspecification.", "url": "https://arxiv.org/abs/2310.09358"}, {"metadata": {"arXiv": "2310.09394", "Date": "Fri, 13 Oct 2023 20:29:55 ", "Title": "Semantics Alignment via Split Learning for Resilient Multi-User Semantic Communication", "Authors": ["Jinhyuk Choi", "Jihong Park", "Seung-Woo Ko", "Jinho Choi", "Mehdi Bennis", "Seong-Lyun Kim"], "Categories": "cs.LG cs.AI cs.IT cs.NI math.IT", "Comments": ["5 pages", "4 figures", "1 table", "submitted to the IEEE for possible publication"]}, "abstract": "Recent studies on semantic communication commonly rely on neural network (NN) based transceivers such as deep joint source and channel coding (DeepJSCC). Unlike traditional transceivers, these neural transceivers are trainable using actual source data and channels, enabling them to extract and communicate semantics. On the flip side, each neural transceiver is inherently biased towards specific source data and channels, making different transceivers difficult to understand intended semantics, particularly upon their initial encounter. To align semantics over multiple neural transceivers, we propose a distributed learning based solution, which leverages split learning (SL) and partial NN fine-tuning techniques. In this method, referred to as SL with layer freezing (SLF), each encoder downloads a misaligned decoder, and locally fine-tunes a fraction of these encoder-decoder NN layers. By adjusting this fraction, SLF controls computing and communication costs. Simulation results confirm the effectiveness of SLF in aligning semantics under different source data and channel dissimilarities, in terms of classification accuracy, reconstruction errors, and recovery time for comprehending intended semantics from misalignment.", "url": "https://arxiv.org/abs/2310.09394"}, {"metadata": {"arXiv": "2310.09486", "Date": "Sat, 14 Oct 2023 04:21:52 ", "Title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification", "Authors": ["Mridul Gupta and Sahil Manchanda and Sayan Ranu and Hariprasad Kodamana"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages", "14 figures"]}, "abstract": "GNNs, like other deep learning models, are data and computation hungry. There is a pressing need to scale training of GNNs on large datasets to enable their usage on low-resource environments. Graph distillation is an effort in that direction with the aim to construct a smaller synthetic training set from the original training data without significantly compromising model performance. While initial efforts are promising, this work is motivated by two key observations: (1) Existing graph distillation algorithms themselves rely on training with the full dataset, which undermines the very premise of graph distillation. (2) The distillation process is specific to the target GNN architecture and hyper-parameters and thus not robust to changes in the modeling pipeline. We circumvent these limitations by designing a distillation algorithm called Mirage for graph classification. Mirage is built on the insight that a message-passing GNN decomposes the input graph into a multiset of computation trees. Furthermore, the frequency distribution of computation trees is often skewed in nature, enabling us to condense this data into a concise distilled summary. By compressing the computation data itself, as opposed to emulating gradient flows on the original training set-a prevalent approach to date-Mirage transforms into an unsupervised and architecture-agnostic distillation algorithm. Extensive benchmarking on real-world datasets underscores Mirage's superiority, showcasing enhanced generalization accuracy, data compression, and distillation efficiency when compared to state-of-the-art baselines.", "url": "https://arxiv.org/abs/2310.09486"}, {"metadata": {"arXiv": "2310.09561", "Date": "Sat, 14 Oct 2023 11:09:17 ", "Title": "Graph Neural Network approaches for single-cell data: A recent overview", "Authors": ["Konstantinos Lazaros", "Dimitris E. Koumadorakis", "Panagiotis Vlamos", "Aristidis G. Vrahatis"], "Categories": "cs.LG cs.AI q-bio.GN"}, "abstract": "Graph Neural Networks (GNN) are reshaping our understanding of biomedicine and diseases by revealing the deep connections among genes and cells. As both algorithmic and biomedical technologies have advanced significantly, we're entering a transformative phase of personalized medicine. While pioneering tools like Graph Attention Networks (GAT) and Graph Convolutional Neural Networks (Graph CNN) are advancing graph-based learning, the rise of single-cell sequencing techniques is reshaping our insights on cellular diversity and function. Numerous studies have combined GNNs with single-cell data, showing promising results. In this work, we highlight the GNN methodologies tailored for single-cell data over the recent years. We outline the diverse range of graph deep learning architectures that center on GAT methodologies. Furthermore, we underscore the several objectives of GNN strategies in single-cell data contexts, ranging from cell-type annotation, data integration and imputation, gene regulatory network reconstruction, clustering and many others. This review anticipates a future where GNNs become central to single-cell analysis efforts, particularly as vast omics datasets are continuously generated and the interconnectedness of cells and genes enhances our depth of knowledge in biomedicine.", "url": "https://arxiv.org/abs/2310.09561"}, {"metadata": {"arXiv": "2310.09650", "Date": "Sat, 14 Oct 2023 19:43:06 ", "Title": "Multimodal Federated Learning in Healthcare: a review", "Authors": ["Jacob Thrasher", "Alina Devkota", "Prasiddha Siwakotai", "Rohit Chivukula", "Pranav Poudel", "Chaunbo Hu", "Binod Bhattarai", "Prashnna Gyawali"], "Categories": "cs.LG cs.AI", "Comments": ["23 pages", "5 figures"]}, "abstract": "Recent advancements in multimodal machine learning have empowered the development of accurate and robust AI systems in the medical domain, especially within centralized database systems. Simultaneously, Federated Learning (FL) has progressed, providing a decentralized mechanism where data need not be consolidated, thereby enhancing the privacy and security of sensitive healthcare data. The integration of these two concepts supports the ongoing progress of multimodal learning in healthcare while ensuring the security and privacy of patient records within local data-holding agencies. This paper offers a concise overview of the significance of FL in healthcare and outlines the current state-of-the-art approaches to Multimodal Federated Learning (MMFL) within the healthcare domain. It comprehensively examines the existing challenges in the field, shedding light on the limitations of present models. Finally, the paper outlines potential directions for future advancements in the field, aiming to bridge the gap between cutting-edge AI technology and the imperative need for patient data privacy in healthcare applications.", "url": "https://arxiv.org/abs/2310.09650"}, {"metadata": {"arXiv": "2310.09667", "Date": "Sat, 14 Oct 2023 21:19:15 ", "Title": "Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices", "Authors": ["Zhepeng Wang", "Isaacshubhanand Putla", "Weiwen Jiang", "Youzuo Lin"], "Categories": "cs.LG cs.AI eess.SP physics.geo-ph"}, "abstract": "Seismic full waveform inversion (FWI) is a widely used technique in geophysics for inferring subsurface structures from seismic data. And InversionNet is one of the most successful data-driven machine learning models that is applied to seismic FWI. However, the high computing costs to run InversionNet have made it challenging to be efficiently deployed on edge devices that are usually resource-constrained. Therefore, we propose to employ the structured pruning algorithm to get a lightweight version of InversionNet, which can make an efficient inference on edge devices. And we also made a prototype with Raspberry Pi to run the lightweight InversionNet. Experimental results show that the pruned InversionNet can achieve up to 98.2 % reduction in computing resources with moderate model performance degradation.", "url": "https://arxiv.org/abs/2310.09667"}, {"metadata": {"arXiv": "2310.09675", "Date": "Sat, 14 Oct 2023 22:24:26 ", "Title": "Efficient Model-Agnostic Multi-Group Equivariant Networks", "Authors": ["Razan Baltaji and Sourya Basu and Lav R. Varshney"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Constructing model-agnostic group equivariant networks, such as equitune (Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be computationally expensive for large product groups. We address this by providing efficient model-agnostic equivariant designs for two related problems: one where the network has multiple inputs each with potentially different groups acting on them, and another where there is a single input but the group acting on it is a large product group. For the first design, we initially consider a linear model and characterize the entire equivariant space that satisfies this constraint. This characterization gives rise to a novel fusion layer between different channels that satisfies an invariance-symmetry (IS) constraint, which we call an IS layer. We then extend this design beyond linear models, similar to equitune, consisting of equivariant and IS layers. We also show that the IS layer is a universal approximator of invariant-symmetric functions. Inspired by the first design, we use the notion of the IS property to design a second efficient model-agnostic equivariant design for large product groups acting on a single input. For the first design, we provide experiments on multi-image classification where each view is transformed independently with transformations such as rotations. We find equivariant models are robust to such transformations and perform competitively otherwise. For the second design, we consider three applications: language compositionality on the SCAN dataset to product groups; fairness in natural language generation from GPT-2 to address intersectionality; and robust zero-shot image classification with CLIP. Overall, our methods are simple and general, competitive with equitune and its variants, while also being computationally more efficient.", "url": "https://arxiv.org/abs/2310.09675"}, {"metadata": {"arXiv": "2310.09685", "Date": "Sun, 15 Oct 2023 00:02:22 ", "Title": "Generative artificial intelligence for de novo protein design", "Authors": ["Adam Winnifrith", "Carlos Outeiral and Brian Hie"], "Categories": "cs.LG cs.AI q-bio.BM", "Comments": ["32 pages", "5 figures", "1 table"]}, "abstract": "Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called \"de novo\" design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications and other cellular processes. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.", "url": "https://arxiv.org/abs/2310.09685"}, {"metadata": {"arXiv": "2310.09764", "Date": "Sun, 15 Oct 2023 07:45:30 ", "Title": "DropMix: Better Graph Contrastive Learning with Harder Negative Samples", "Authors": ["Yueqi Ma", "Minjie Chen", "Xiang Li"], "Categories": "cs.LG cs.AI"}, "abstract": "While generating better negative samples for contrastive learning has been widely studied in the areas of CV and NLP, very few work has focused on graph-structured data. Recently, Mixup has been introduced to synthesize hard negative samples in graph contrastive learning (GCL). However, due to the unsupervised learning nature of GCL, without the help of soft labels, directly mixing representations of samples could inadvertently lead to the information loss of the original hard negative and further adversely affect the quality of the newly generated harder negative. To address the problem, in this paper, we propose a novel method DropMix to synthesize harder negative samples, which consists of two main steps. Specifically, we first select some hard negative samples by measuring their hardness from both local and global views in the graph simultaneously. After that, we mix hard negatives only on partial representation dimensions to generate harder ones and decrease the information loss caused by Mixup. We conduct extensive experiments to verify the effectiveness of DropMix on six benchmark datasets. Our results show that our method can lead to better GCL performance. Our data and codes are publicly available at https://github.com/Mayueq/DropMix-Code.", "url": "https://arxiv.org/abs/2310.09764"}, {"metadata": {"arXiv": "2310.09780", "Date": "Sun, 15 Oct 2023 08:56:15 ", "Title": "Notes on Applicability of Explainable AI Methods to Machine Learning Models Using Features Extracted by Persistent Homology", "Authors": ["Naofumi Hama"], "Categories": "cs.LG cs.AI"}, "abstract": "Data analysis that uses the output of topological data analysis as input for machine learning algorithms has been the subject of extensive research. This approach offers a means of capturing the global structure of data. Persistent homology (PH), a common methodology within the field of TDA, has found wide-ranging applications in machine learning. One of the key reasons for the success of the PH-ML pipeline lies in the deterministic nature of feature extraction conducted through PH. The ability to achieve satisfactory levels of accuracy with relatively simple downstream machine learning models, when processing these extracted features, underlines the pipeline's superior interpretability. However, it must be noted that this interpretation has encountered issues. Specifically, it fails to accurately reflect the feasible parameter region in the data generation process, and the physical or chemical constraints that restrict this process. Against this backdrop, we explore the potential application of explainable AI methodologies to this PH-ML pipeline. We apply this approach to the specific problem of predicting gas adsorption in metal-organic frameworks and demonstrate that it can yield suggestive results. The codes to reproduce our results are available at https://github.com/naofumihama/xai_ph_ml", "url": "https://arxiv.org/abs/2310.09780"}, {"metadata": {"arXiv": "2310.09819", "Date": "Sun, 15 Oct 2023 12:35:27 ", "Title": "Optimizing K-means for Big Data: A Comparative Study", "Authors": ["Ravil Mussabayev", "Rustam Mussabayev"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "This paper presents a comparative analysis of different optimization techniques for the K-means algorithm in the context of big data. K-means is a widely used clustering algorithm, but it can suffer from scalability issues when dealing with large datasets. The paper explores different approaches to overcome these issues, including parallelization, approximation, and sampling methods. The authors evaluate the performance of these techniques on various benchmark datasets and compare them in terms of speed, quality of clustering, and scalability according to the LIMA dominance criterion. The results show that different techniques are more suitable for different types of datasets and provide insights into the trade-offs between speed and accuracy in K-means clustering for big data. Overall, the paper offers a comprehensive guide for practitioners and researchers on how to optimize K-means for big data applications.", "url": "https://arxiv.org/abs/2310.09819"}, {"metadata": {"arXiv": "2310.09833", "Date": "Sun, 15 Oct 2023 13:35:51 ", "Title": "MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by Mutual Information Regularization", "Authors": ["Simin Li", "Ruixiao Xu", "Jun Guo", "Pu Feng", "Jiakai Wang", "Aishan Liu", "Yaodong Yang", "Xianglong Liu", "Weifeng Lv"], "Categories": "cs.LG cs.AI"}, "abstract": "Robust multi-agent reinforcement learning (MARL) necessitates resilience to uncertain or worst-case actions by unknown allies. Existing max-min optimization techniques in robust MARL seek to enhance resilience by training agents against worst-case adversaries, but this becomes intractable as the number of agents grows, leading to exponentially increasing worst-case scenarios. Attempts to simplify this complexity often yield overly pessimistic policies, inadequate robustness across scenarios and high computational demands. Unlike these approaches, humans naturally learn adaptive and resilient behaviors without the necessity of preparing for every conceivable worst-case scenario. Motivated by this, we propose MIR2, which trains policy in routine scenarios and minimize Mutual Information as Robust Regularization. Theoretically, we frame robustness as an inference problem and prove that minimizing mutual information between histories and actions implicitly maximizes a lower bound on robustness under certain assumptions. Further analysis reveals that our proposed approach prevents agents from overreacting to others through an information bottleneck and aligns the policy with a robust action prior. Empirically, our MIR2 displays even greater resilience against worst-case adversaries than max-min optimization in StarCraft II, Multi-agent Mujoco and rendezvous. Our superiority is consistent when deployed in challenging real-world robot swarm control scenario. See code and demo videos in Supplementary Materials.", "url": "https://arxiv.org/abs/2310.09833"}, {"metadata": {"arXiv": "2310.09858", "Date": "Sun, 15 Oct 2023 15:26:54 ", "Title": "Federated Reinforcement Learning for Resource Allocation in V2X Networks", "Authors": ["Kaidi Xu", "Shenglong Zhou", "and Geoffrey Ye Li"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["Submitted to TWC"]}, "abstract": "Resource allocation significantly impacts the performance of vehicle-to-everything (V2X) networks. Most existing algorithms for resource allocation are based on optimization or machine learning (e.g., reinforcement learning). In this paper, we explore resource allocation in a V2X network under the framework of federated reinforcement learning (FRL). On one hand, the usage of RL overcomes many challenges from the model-based optimization schemes. On the other hand, federated learning (FL) enables agents to deal with a number of practical issues, such as privacy, communication overhead, and exploration efficiency. The framework of FRL is then implemented by the inexact alternative direction method of multipliers (ADMM), where subproblems are solved approximately using policy gradients and accelerated by an adaptive step size calculated from their second moments. The developed algorithm, PASM, is proven to be convergent under mild conditions and has a nice numerical performance compared with some baseline methods for solving the resource allocation problem in a V2X network.", "url": "https://arxiv.org/abs/2310.09858"}, {"metadata": {"arXiv": "2310.09866", "Date": "Sun, 15 Oct 2023 15:45:51 ", "Title": "Federated Multi-Objective Learning", "Authors": ["Haibo Yang", "Zhuqing Liu", "Jia Liu", "Chaosheng Dong", "Michinari Momma"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["Accepted in NeurIPS 2023"]}, "abstract": "In recent years, multi-objective optimization (MOO) emerges as a foundational problem underpinning many multi-agent multi-task learning applications. However, existing algorithms in MOO literature remain limited to centralized learning settings, which do not satisfy the distributed nature and data privacy needs of such multi-agent multi-task learning applications. This motivates us to propose a new federated multi-objective learning (FMOL) framework with multiple clients distributively and collaboratively solving an MOO problem while keeping their training data private. Notably, our FMOL framework allows a different set of objective functions across different clients to support a wide range of applications, which advances and generalizes the MOO formulation to the federated learning paradigm for the first time. For this FMOL framework, we propose two new federated multi-objective optimization (FMOO) algorithms called federated multi-gradient descent averaging (FMGDA) and federated stochastic multi-gradient descent averaging (FSMGDA). Both algorithms allow local updates to significantly reduce communication costs, while achieving the {\\em same} convergence rates as those of the their algorithmic counterparts in the single-objective federated learning. Our extensive experiments also corroborate the efficacy of our proposed FMOO algorithms.", "url": "https://arxiv.org/abs/2310.09866"}, {"metadata": {"arXiv": "2310.09877", "Date": "Sun, 15 Oct 2023 16:17:21 ", "Title": "Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)", "Authors": ["Chitu Okoli"], "Categories": "cs.LG cs.AI"}, "abstract": "Accumulated Local Effects (ALE) is a model-agnostic approach for global explanations of the results of black-box machine learning (ML) algorithms. There are at least three challenges with conducting statistical inference based on ALE: ensuring the reliability of ALE analyses, especially in the context of small datasets; intuitively characterizing a variable's overall effect in ML; and making robust inferences from ML data analysis. In response, we introduce innovative tools and techniques for statistical inference using ALE, establishing bootstrapped confidence intervals tailored to dataset size and introducing ALE effect size measures that intuitively indicate effects on both the outcome variable scale and a normalized scale. Furthermore, we demonstrate how to use these tools to draw reliable statistical inferences, reflecting the flexible patterns ALE adeptly highlights, with implementations available in the 'ale' package in R. This work propels the discourse on ALE and its applicability in ML and statistical analysis forward, offering practical solutions to prevailing challenges in the field.", "url": "https://arxiv.org/abs/2310.09877"}, {"metadata": {"arXiv": "2310.09949", "Date": "Sun, 15 Oct 2023 20:57:25 ", "Title": "Chameleon: a Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models", "Authors": ["Wenqi Jiang", "Marco Zeller", "Roger Waleffe", "Torsten Hoefler", "Gustavo Alonso"], "Categories": "cs.LG cs.AI cs.AR cs.CL"}, "abstract": "A Retrieval-Augmented Language Model (RALM) augments a generative language model by retrieving context-specific knowledge from an external database. This strategy facilitates impressive text generation quality even with smaller models, thus reducing orders of magnitude of computational demands. However, RALMs introduce unique system design challenges due to (a) the diverse workload characteristics between LM inference and retrieval and (b) the various system requirements and bottlenecks for different RALM configurations such as model sizes, database sizes, and retrieval frequencies. We propose Chameleon, a heterogeneous accelerator system that integrates both LM and retrieval accelerators in a disaggregated architecture. The heterogeneity ensures efficient acceleration of both LM inference and retrieval, while the accelerator disaggregation enables the system to independently scale both types of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype implements retrieval accelerators on FPGAs and assigns LM inference to GPUs, with a CPU server orchestrating these accelerators over the network. Compared to CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x speedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon exhibits up to 2.16x reduction in latency and 3.18x speedup in throughput compared to the hybrid CPU-GPU architecture. These promising results pave the way for bringing accelerator heterogeneity and disaggregation into future RALM systems.", "url": "https://arxiv.org/abs/2310.09949"}, {"metadata": {"arXiv": "2310.09983", "Date": "Sun, 15 Oct 2023 23:23:27 ", "Title": "Farzi Data: Autoregressive Data Distillation", "Authors": ["Noveen Sachdeva", "Zexue He", "Wang-Cheng Kang", "Jianmo Ni", "Derek Zhiyuan Cheng", "Julian McAuley"], "Categories": "cs.LG cs.AI cs.CL cs.IR", "Comments": ["Under review. 23 pages", "9 figures"]}, "abstract": "We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences -- Farzi Data -- which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, Farzi conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98-120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.", "url": "https://arxiv.org/abs/2310.09983"}, {"metadata": {"arXiv": "2310.09986", "Date": "Sun, 15 Oct 2023 23:59:57 ", "Title": "On Statistical Learning of Branch and Bound for Vehicle Routing Optimization", "Authors": ["Andrew Naguib", "Waleed A. Yousef", "Issa Traor\\'e", "Mohammed Mamun"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "Recently, machine learning of the branch and bound algorithm has shown promise in approximating competent solutions to NP-hard problems. In this paper, we utilize and comprehensively compare the outcomes of three neural networks--graph convolutional neural network (GCNN), GraphSAGE, and graph attention network (GAT)--to solve the capacitated vehicle routing problem. We train these neural networks to emulate the decision-making process of the computationally expensive Strong Branching strategy. The neural networks are trained on six instances with distinct topologies from the CVRPLIB and evaluated on eight additional instances. Moreover, we reduced the minimum number of vehicles required to solve a CVRP instance to a bin-packing problem, which was addressed in a similar manner. Through rigorous experimentation, we found that this approach can match or improve upon the performance of the branch and bound algorithm with the Strong Branching strategy while requiring significantly less computational time. The source code that corresponds to our research findings and methodology is readily accessible and available for reference at the following web address: \\href{https://isotlaboratory.github.io/ml4vrp/}{https://isotlaboratory.github.io/ml4vrp/}.", "url": "https://arxiv.org/abs/2310.09986"}, {"metadata": {"arXiv": "2310.10049", "Date": "Mon, 16 Oct 2023 04:17:13 ", "Title": "FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models", "Authors": ["Tao Fan", "Yan Kang", "Guoqiang Ma", "Weijing Chen", "Wenbin Wei", "Lixin Fan", "Qiang Yang"], "Categories": "cs.LG cs.AI"}, "abstract": "Large Language Models (LLMs), such as ChatGPT, LLaMA, GLM, and PaLM, have exhibited remarkable performances across various tasks in recent years. However, LLMs face two main challenges in real-world applications. One challenge is that training LLMs consumes vast computing resources, preventing LLMs from being adopted by small and medium-sized enterprises with limited computing resources. Another is that training LLM requires a large amount of high-quality data, which are often scattered among enterprises. To address these challenges, we propose FATE-LLM, an industrial-grade federated learning framework for large language models. FATE-LLM (1) facilitates federated learning for large language models (coined FedLLM); (2) promotes efficient training of FedLLM using parameter-efficient fine-tuning methods; (3) protects the intellectual property of LLMs; (4) preserves data privacy during training and inference through privacy-preserving mechanisms. We release the code of FATE-LLM at https://github.com/FederatedAI/FATE-LLM to facilitate the research of FedLLM and enable a broad range of industrial applications.", "url": "https://arxiv.org/abs/2310.10049"}, {"metadata": {"arXiv": "2310.10064", "Date": "Mon, 16 Oct 2023 04:57:30 ", "Title": "Learning Graph Filters for Spectral GNNs via Newton Interpolation", "Authors": ["Junjie Xu", "Enyan Dai", "Dongsheng Luo", "Xiang Zhang", "Suhang Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Spectral Graph Neural Networks (GNNs) are gaining attention because they can surpass the limitations of message-passing GNNs by learning spectral filters that capture essential frequency information in graph data through task supervision. However, previous research suggests that the choice of filter frequency is tied to the graph's homophily level, a connection that hasn't been thoroughly explored in existing spectral GNNs. To address this gap, the study conducts both theoretical and empirical analyses, revealing that low-frequency filters have a positive correlation with homophily, while high-frequency filters have a negative correlation. This leads to the introduction of a shape-aware regularization technique applied to a Newton Interpolation-based spectral filter, enabling the customization of polynomial spectral filters that align with desired homophily levels. Extensive experiments demonstrate that NewtonNet successfully achieves the desired filter shapes and exhibits superior performance on both homophilous and heterophilous datasets.", "url": "https://arxiv.org/abs/2310.10064"}, {"metadata": {"arXiv": "2310.10090", "Date": "Mon, 16 Oct 2023 05:50:34 ", "Title": "Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning", "Authors": ["Yanbiao Ma", "Licheng Jiao", "Fang Liu", "Shuyuan Yang", "Xu Liu", "Lingling Li"], "Categories": "cs.LG cs.AI", "Comments": ["10pages,Accepted by ACM MM 2023"]}, "abstract": "In scenarios with long-tailed distributions, the model's ability to identify tail classes is limited due to the under-representation of tail samples. Class rebalancing, information augmentation, and other techniques have been proposed to facilitate models to learn the potential distribution of tail classes. The disadvantage is that these methods generally pursue models with balanced class accuracy on the data manifold, while ignoring the ability of the model to resist interference. By constructing noisy data manifold, we found that the robustness of models trained on unbalanced data has a long-tail phenomenon. That is, even if the class accuracy is balanced on the data domain, it still has bias on the noisy data manifold. However, existing methods cannot effectively mitigate the above phenomenon, which makes the model vulnerable in long-tailed scenarios. In this work, we propose an Orthogonal Uncertainty Representation (OUR) of feature embedding and an end-to-end training strategy to improve the long-tail phenomenon of model robustness. As a general enhancement tool, OUR has excellent compatibility with other methods and does not require additional data generation, ensuring fast and efficient training. Comprehensive evaluations on long-tailed datasets show that our method significantly improves the long-tail phenomenon of robustness, bringing consistent performance gains to other long-tailed learning methods.", "url": "https://arxiv.org/abs/2310.10090"}, {"metadata": {"arXiv": "2310.10107", "Date": "Mon, 16 Oct 2023 06:41:13 ", "Title": "Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs", "Authors": ["Dengwang Tang", "Rahul Jain", "Ashutosh Nayyar", "Pierluigi Nuzzo"], "Categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "Comments": ["32 pages", "1 figure"], "MSC-class": "93E35"}, "abstract": "Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\\Omega(H^2\\sqrt{SA})$ over the recent result by arXiv:2204.08967.", "url": "https://arxiv.org/abs/2310.10107"}, {"metadata": {"arXiv": "2310.10121", "Date": "Mon, 16 Oct 2023 06:57:24 ", "Title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond", "Authors": ["Andi Han", "Dai Shi", "Lequan Lin", "Junbin Gao"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuous perspective of GNNs. To this end, we introduce foundational ingredients for adapting continuous dynamics to GNNs, along with a general framework for the design of graph neural dynamics. We then review and categorize existing works based on their driven mechanisms and underlying dynamics. We also summarize how the limitations of classic GNNs can be addressed under the continuous framework. We conclude by identifying multiple open research directions.", "url": "https://arxiv.org/abs/2310.10121"}, {"metadata": {"arXiv": "2310.10126", "Date": "Mon, 16 Oct 2023 07:09:47 ", "Title": "A Non-monotonic Smooth Activation Function", "Authors": ["Koushik Biswas", "Meghana Karri", "Ula\\c{s} Ba\\u{g}c{\\i}"], "Categories": "cs.LG cs.AI", "Comments": ["12 Pages"]}, "abstract": "Activation functions are crucial in deep learning models since they introduce non-linearity into the networks, allowing them to learn from errors and make adjustments, which is essential for learning complex patterns. The essential purpose of activation functions is to transform unprocessed input signals into significant output activations, promoting information transmission throughout the neural network. In this study, we propose a new activation function called Sqish, which is a non-monotonic and smooth function and an alternative to existing ones. We showed its superiority in classification, object detection, segmentation tasks, and adversarial robustness experiments. We got an 8.21% improvement over ReLU on the CIFAR100 dataset with the ShuffleNet V2 model in the FGSM adversarial attack. We also got a 5.87% improvement over ReLU on image classification on the CIFAR100 dataset with the ShuffleNet V2 model.", "url": "https://arxiv.org/abs/2310.10126"}, {"metadata": {"arXiv": "2310.10170", "Date": "Mon, 16 Oct 2023 08:26:45 ", "Title": "Leveraging Knowledge Distillation for Efficient Deep Reinforcement Learning in Resource-Constrained Environments", "Authors": ["Guanlin Meng"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper aims to explore the potential of combining Deep Reinforcement Learning (DRL) with Knowledge Distillation (KD) by distilling various DRL algorithms and studying their distillation effects. By doing so, the computational burden of deep models could be reduced while maintaining the performance. The primary objective is to provide a benchmark for evaluating the performance of different DRL algorithms that have been refined using KD techniques. By distilling these algorithms, the goal is to develop efficient and fast DRL models. This research is expected to provide valuable insights that can facilitate further advancements in this promising direction. By exploring the combination of DRL and KD, this work aims to promote the development of models that require fewer GPU resources, learn more quickly, and make faster decisions in complex environments. The results of this research have the capacity to significantly advance the field of DRL and pave the way for the future deployment of resource-efficient, decision-making intelligent systems.", "url": "https://arxiv.org/abs/2310.10170"}, {"metadata": {"arXiv": "2310.10196", "Date": "Mon, 16 Oct 2023 09:06:00 ", "Title": "Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook", "Authors": ["Ming Jin", "Qingsong Wen", "Yuxuan Liang", "Chaoli Zhang", "Siqiao Xue", "Xue Wang", "James Zhang", "Yi Wang", "Haifeng Chen", "Xiaoli Li", "Shirui Pan", "Vincent S. Tseng", "Yu Zheng", "Lei Chen", "Hui Xiong"], "Categories": "cs.LG cs.AI", "Comments": ["Ongoing work; 25 pages", "3 figures", "3 tables; Github page: https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM"]}, "abstract": "Temporal data, notably time series and spatio-temporal data, are prevalent in real-world applications. They capture dynamic system measurements and are produced in vast quantities by both physical and virtual sensors. Analyzing these data types is vital to harnessing the rich information they encompass and thus benefits a wide range of downstream tasks. Recent advances in large language and other foundational models have spurred increased use of these models in time series and spatio-temporal data mining. Such methodologies not only enable enhanced pattern recognition and reasoning across diverse domains but also lay the groundwork for artificial general intelligence capable of comprehending and processing common temporal data. In this survey, we offer a comprehensive and up-to-date review of large models tailored (or adapted) for time series and spatio-temporal data, spanning four key facets: data types, model categories, model scopes, and application areas/tasks. Our objective is to equip practitioners with the knowledge to develop applications and further research in this underexplored domain. We primarily categorize the existing literature into two major clusters: large models for time series analysis (LM4TS) and spatio-temporal data mining (LM4STD). On this basis, we further classify research based on model scopes (i.e., general vs. domain-specific) and application areas/tasks. We also provide a comprehensive collection of pertinent resources, including datasets, model assets, and useful tools, categorized by mainstream applications. This survey coalesces the latest strides in large model-centric research on time series and spatio-temporal data, underscoring the solid foundations, current advances, practical applications, abundant resources, and future research opportunities.", "url": "https://arxiv.org/abs/2310.10196"}, {"metadata": {"arXiv": "2310.10237", "Date": "Mon, 16 Oct 2023 09:51:24 ", "Title": "SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection", "Authors": ["Zhihao Ding and Jieming Shi"], "Categories": "cs.LG cs.AI", "Comments": ["Under Review"]}, "abstract": "Graph-level representation learning is important in a wide range of applications. However, existing graph-level models are generally built on i.i.d. assumption for both training and testing graphs, which is not realistic in an open world, where models can encounter out-of-distribution (OOD) testing graphs that are from different distributions unknown during training. A trustworthy model should not only produce accurate predictions for in-distribution (ID) data, but also detect OOD graphs to avoid unreliable prediction. In this paper, we present SGOOD, a novel graph-level OOD detection framework. We find that substructure differences commonly exist between ID and OOD graphs. Hence, SGOOD explicitly utilizes substructures to learn powerful representations to achieve superior performance. Specifically, we build a super graph of substructures for every graph, and design a two-level graph encoding pipeline that works on both original graphs and super graphs to obtain substructure-enhanced graph representations. To further distinguish ID and OOD graphs, we develop three graph augmentation techniques that preserve substructures and increase expressiveness. Extensive experiments against 10 competitors on numerous graph datasets demonstrate the superiority of SGOOD, often surpassing existing methods by a significant margin. The code is available at https://anonymous.4open.science/r/SGOOD-0958.", "url": "https://arxiv.org/abs/2310.10237"}, {"metadata": {"arXiv": "2310.10348", "Date": "Mon, 16 Oct 2023 12:34:43 ", "Title": "Attribution Patching Outperforms Automated Circuit Discovery", "Authors": ["Aaquib Syed", "Can Rager", "Arthur Conmy"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Automated interpretability research has recently attracted attention as a potential research direction that could scale explanations of neural network behavior to large models. Existing automated circuit discovery work applies activation patching to identify subnetworks responsible for solving specific tasks (circuits). In this work, we show that a simple method based on attribution patching outperforms all existing methods while requiring just two forward passes and a backward pass. We apply a linear approximation to activation patching to estimate the importance of each edge in the computational subgraph. Using this approximation, we prune the least important edges of the network. We survey the performance and limitations of this method, finding that averaged over all tasks our method has greater AUC from circuit recovery than other methods.", "url": "https://arxiv.org/abs/2310.10348"}, {"metadata": {"arXiv": "2310.10362", "Date": "Mon, 16 Oct 2023 12:58:04 ", "Title": "Prompt Tuning for Multi-View Graph Contrastive Learning", "Authors": ["Chenghua Gong", "Xiang Li", "Jianxiang Yu", "Cheng Yao", "Jiaqi Tan", "Chengcheng Yu", "Dawei Yin"], "Categories": "cs.LG cs.AI"}, "abstract": "In recent years, \"pre-training and fine-tuning\" has emerged as a promising approach in addressing the issues of label dependency and poor generalization performance in traditional GNNs. To reduce labeling requirement, the \"pre-train, fine-tune\" and \"pre-train, prompt\" paradigms have become increasingly common. In particular, prompt tuning is a popular alternative to \"pre-training and fine-tuning\" in natural language processing, which is designed to narrow the gap between pre-training and downstream objectives. However, existing study of prompting on graphs is still limited, lacking a framework that can accommodate commonly used graph pre-training methods and downstream tasks. In this paper, we propose a multi-view graph contrastive learning method as pretext and design a prompting tuning for it. Specifically, we first reformulate graph pre-training and downstream tasks into a common format. Second, we construct multi-view contrasts to capture relevant information of graphs by GNN. Third, we design a prompting tuning method for our multi-view graph contrastive learning method to bridge the gap between pretexts and downsteam tasks. Finally, we conduct extensive experiments on benchmark datasets to evaluate and analyze our proposed method.", "url": "https://arxiv.org/abs/2310.10362"}, {"metadata": {"arXiv": "2310.10402", "Date": "Mon, 16 Oct 2023 13:45:26 ", "Title": "Real-Fake: Effective Training Data Synthesis Through Distribution Matching", "Authors": ["Jianhao Yuan and Jie Zhang and Shuyang Sun and Philip Torr and Bo Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["Code released at (https://github.com/BAAI-DCAI/Training-Data-Synthesis)"]}, "abstract": "Synthetic training data has gained prominence in numerous learning tasks and scenarios, offering advantages such as dataset augmentation, generalization evaluation, and privacy preservation. Despite these benefits, the efficiency of synthetic data generated by current methodologies remains inferior when training advanced deep models exclusively, limiting its practical utility. To address this challenge, we analyze the principles underlying training data synthesis for supervised learning and elucidate a principled theoretical framework from the distribution-matching perspective that explicates the mechanisms governing synthesis efficacy. Through extensive experiments, we demonstrate the effectiveness of our synthetic data across diverse image classification tasks, both as a replacement for and augmentation to real datasets, while also benefits challenging tasks such as out-of-distribution generalization and privacy preservation.", "url": "https://arxiv.org/abs/2310.10402"}, {"metadata": {"arXiv": "2310.10418", "Date": "Mon, 16 Oct 2023 14:00:07 ", "Title": "Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms", "Authors": ["Seungju Han and Junhyeok Kim and Jack Hessel and Liwei Jiang and Jiwan Chung and Yejin Son and Yejin Choi and Youngjae Yu"], "Categories": "cs.LG cs.AI", "Comments": ["Published as a conference paper at EMNLP 2023 (long)"]}, "abstract": "Commonsense norms are defeasible by context: reading books is usually great, but not when driving a car. While contexts can be explicitly described in language, in embodied scenarios, contexts are often provided visually. This type of visually grounded reasoning about defeasible commonsense norms is generally easy for humans, but (as we show) poses a challenge for machines, as it necessitates both visual understanding and reasoning about commonsense norms. We construct a new multimodal benchmark for studying visual-grounded commonsense norms: NORMLENS. NORMLENS consists of 10K human judgments accompanied by free-form explanations covering 2K multimodal situations, and serves as a probe to address two questions: (1) to what extent can models align with average human judgment? and (2) how well can models explain their predicted judgments? We find that state-of-the-art model judgments and explanations are not well-aligned with human annotation. Additionally, we present a new approach to better align models with humans by distilling social commonsense knowledge from large language models. The data and code are released at https://seungjuhan.me/normlens.", "url": "https://arxiv.org/abs/2310.10418"}, {"metadata": {"arXiv": "2310.10537", "Date": "Mon, 16 Oct 2023 16:07:41 ", "Title": "Microscaling Data Formats for Deep Learning", "Authors": ["Bita Darvish Rouhani", "Ritchie Zhao", "Ankit More", "Mathew Hall", "Alireza Khodamoradi", "Summer Deng", "Dhruv Choudhary", "Marius Cornea", "Eric Dellinger", "Kristof Denolf", "Stosic Dusan", "Venmugil Elango", "Maximilian Golub", "Alexander Heinecke", "Phil James-Roxby", "Dharmesh Jani", "Gaurav Kolhe", "Martin Langhammer", "Ada Li", "Levi Melnick", "Maral Mesmakhosroshahi", "Andres Rodriguez", "Michael Schulte", "Rasoul Shafipour", "Lei Shao", "Michael Siu", "Pradeep Dubey", "Paulius Micikevicius", "Maxim Naumov", "Colin Verilli", "Ralph Wittig", "Eric Chung"], "Categories": "cs.LG cs.AI"}, "abstract": "Narrow bit-width data formats are key to reducing the computational and storage costs of modern deep learning applications. This paper evaluates Microscaling (MX) data formats that combine a per-block scaling factor with narrow floating-point and integer types for individual elements.MX formats balance the competing needs of hardware efficiency, model accuracy, and user friction. Empirical results on over two dozen benchmarks demonstrate practicality of MX data formats as a drop-in replacement for baseline FP32 for AI inference and training with low user friction. We also show the first instance of training generative language models at sub-8-bit weights, activations, and gradients with minimal accuracy loss and no modifications to the training recipe.", "url": "https://arxiv.org/abs/2310.10537"}, {"metadata": {"arXiv": "2310.10550", "Date": "Mon, 16 Oct 2023 16:17:33 ", "Title": "Deep learning applied to EEG data with different montages using spatial attention", "Authors": ["Dung Truong", "Muhammad Abdullah Khalid", "Arnaud Delorme"], "Categories": "cs.LG cs.AI"}, "abstract": "The ability of Deep Learning to process and extract relevant information in complex brain dynamics from raw EEG data has been demonstrated in various recent works. Deep learning models, however, have also been shown to perform best on large corpora of data. When processing EEG, a natural approach is to combine EEG datasets from different experiments to train large deep-learning models. However, most EEG experiments use custom channel montages, requiring the data to be transformed into a common space. Previous methods have used the raw EEG signal to extract features of interest and focused on using a common feature space across EEG datasets. While this is a sensible approach, it underexploits the potential richness of EEG raw data. Here, we explore using spatial attention applied to EEG electrode coordinates to perform channel harmonization of raw EEG data, allowing us to train deep learning on EEG data using different montages. We test this model on a gender classification task. We first show that spatial attention increases model performance. Then, we show that a deep learning model trained on data using different channel montages performs significantly better than deep learning models trained on fixed 23- and 128-channel data montages.", "url": "https://arxiv.org/abs/2310.10550"}, {"metadata": {"arXiv": "2310.10560", "Date": "Mon, 16 Oct 2023 16:35:03 ", "Title": "Towards the Imagenets of ML4EDA", "Authors": ["Animesh Basak Chowdhury", "Shailja Thakur", "Hammond Pearce", "Ramesh Karri", "Siddharth Garg"], "Categories": "cs.LG cs.AI cs.AR cs.PL", "Comments": ["Invited paper", "ICCAD 2023"], "Report-no": "October 16 Update", "Journal-ref": "ICCAD 2023"}, "abstract": "Despite the growing interest in ML-guided EDA tools from RTL to GDSII, there are no standard datasets or prototypical learning tasks defined for the EDA problem domain. Experience from the computer vision community suggests that such datasets are crucial to spur further progress in ML for EDA. Here we describe our experience curating two large-scale, high-quality datasets for Verilog code generation and logic synthesis. The first, VeriGen, is a dataset of Verilog code collected from GitHub and Verilog textbooks. The second, OpenABC-D, is a large-scale, labeled dataset designed to aid ML for logic synthesis tasks. The dataset consists of 870,000 And-Inverter-Graphs (AIGs) produced from 1500 synthesis runs on a large number of open-source hardware projects. In this paper we will discuss challenges in curating, maintaining and growing the size and scale of these datasets. We will also touch upon questions of dataset quality and security, and the use of novel data augmentation tools that are tailored for the hardware domain.", "url": "https://arxiv.org/abs/2310.10560"}, {"metadata": {"arXiv": "2310.10603", "Date": "Mon, 16 Oct 2023 17:31:25 ", "Title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems", "Authors": ["Chendi Qian", "Didier Ch\\'etelat", "Christopher Morris"], "Categories": "cs.LG cs.AI cs.NE math.OC stat.ML"}, "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.", "url": "https://arxiv.org/abs/2310.10603"}, {"metadata": {"arXiv": "2310.10635", "Date": "Mon, 16 Oct 2023 17:55:14 ", "Title": "Towards Scenario-based Safety Validation for Autonomous Trains with Deep Generative Models", "Authors": ["Thomas Decker", "Ananta R. Bhattarai", "and Michael Lebacher"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["International Conference on Computer Safety", "Reliability", "and Security 2023"], "DOI": "10.1007/978-3-031-40923-3_20"}, "abstract": "Modern AI techniques open up ever-increasing possibilities for autonomous vehicles, but how to appropriately verify the reliability of such systems remains unclear. A common approach is to conduct safety validation based on a predefined Operational Design Domain (ODD) describing specific conditions under which a system under test is required to operate properly. However, collecting sufficient realistic test cases to ensure comprehensive ODD coverage is challenging. In this paper, we report our practical experiences regarding the utility of data simulation with deep generative models for scenario-based ODD validation. We consider the specific use case of a camera-based rail-scene segmentation system designed to support autonomous train operation. We demonstrate the capabilities of semantically editing railway scenes with deep generative models to make a limited amount of test data more representative. We also show how our approach helps to analyze the degree to which a system complies with typical ODD requirements. Specifically, we focus on evaluating proper operation under different lighting and weather conditions as well as while transitioning between them.", "url": "https://arxiv.org/abs/2310.10635"}, {"metadata": {"arXiv": "2310.10021", "Date": "Mon, 16 Oct 2023 02:43:47 ", "Title": "Bootstrap Your Own Skills: Learning to Solve New Tasks with Large Language Model Guidance", "Authors": ["Jesse Zhang", "Jiahui Zhang", "Karl Pertsch", "Ziyi Liu", "Xiang Ren", "Minsuk Chang", "Shao-Hua Sun", "Joseph J. Lim"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["CoRL 2023 (Oral); 24 pages", "11 figures"]}, "abstract": "We propose BOSS, an approach that automatically learns to solve new long-horizon, complex, and meaningful tasks by growing a learned skill library with minimal supervision. Prior work in reinforcement learning require expert supervision, in the form of demonstrations or rich reward functions, to learn long-horizon tasks. Instead, our approach BOSS (BOotStrapping your own Skills) learns to accomplish new tasks by performing \"skill bootstrapping,\" where an agent with a set of primitive skills interacts with the environment to practice new skills without receiving reward feedback for tasks outside of the initial skill set. This bootstrapping phase is guided by large language models (LLMs) that inform the agent of meaningful skills to chain together. Through this process, BOSS builds a wide range of complex and useful behaviors from a basic set of primitive skills. We demonstrate through experiments in realistic household environments that agents trained with our LLM-guided bootstrapping procedure outperform those trained with naive bootstrapping as well as prior unsupervised skill acquisition methods on zero-shot execution of unseen, long-horizon tasks in new environments. Website at clvrai.com/boss.", "url": "https://arxiv.org/abs/2310.10021"}, {"metadata": {"arXiv": "2310.10103", "Date": "Mon, 16 Oct 2023 06:21:06 ", "Title": "Navigation with Large Language Models: Semantic Guesswork as a Heuristic for Planning", "Authors": ["Dhruv Shah", "Michael Equi", "Blazej Osinski", "Fei Xia", "Brian Ichter", "Sergey Levine"], "Categories": "cs.RO cs.AI cs.CL cs.LG", "Comments": ["Videos", "code", "and an interactive Colab notebook that runs in your browser https://sites.google.com/view/lfg-nav/"]}, "abstract": "Navigation in unfamiliar environments presents a major challenge for robots: while mapping and planning techniques can be used to build up a representation of the world, quickly discovering a path to a desired goal in unfamiliar settings with such methods often requires lengthy mapping and exploration. Humans can rapidly navigate new environments, particularly indoor environments that are laid out logically, by leveraging semantics -- e.g., a kitchen often adjoins a living room, an exit sign indicates the way out, and so forth. Language models can provide robots with such knowledge, but directly using language models to instruct a robot how to reach some destination can also be impractical: while language models might produce a narrative about how to reach some goal, because they are not grounded in real-world observations, this narrative might be arbitrarily wrong. Therefore, in this paper we study how the ``semantic guesswork'' produced by language models can be utilized as a guiding heuristic for planning algorithms. Our method, Language Frontier Guide (LFG), uses the language model to bias exploration of novel real-world environments by incorporating the semantic knowledge stored in language models as a search heuristic for planning with either topological or metric maps. We evaluate LFG in challenging real-world environments and simulated benchmarks, outperforming uninformed exploration and other ways of using language models.", "url": "https://arxiv.org/abs/2310.10103"}, {"metadata": {"arXiv": "2310.10486", "Date": "Mon, 16 Oct 2023 15:06:16 ", "Title": "ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse Quadruped Robots", "Authors": ["Milad Shafiee", "Guillaume Bellegarda and Auke Ijspeert"], "Categories": "cs.RO cs.AI cs.LG cs.SY eess.SY"}, "abstract": "Learning a locomotion policy for quadruped robots has traditionally been constrained to specific robot morphology, mass, and size. The learning process must usually be repeated for every new robot, where hyperparameters and reward function weights must be re-tuned to maximize performance for each new system. Alternatively, attempting to train a single policy to accommodate different robot sizes, while maintaining the same degrees of freedom (DoF) and morphology, requires either complex learning frameworks, or mass, inertia, and dimension randomization, which leads to prolonged training periods. In our study, we show that drawing inspiration from animal motor control allows us to effectively train a single locomotion policy capable of controlling a diverse range of quadruped robots. These differences encompass a variable number of DoFs, (i.e. 12 or 16 joints), three distinct morphologies, a broad mass range spanning from 2 kg to 200 kg, and nominal standing heights ranging from 16 cm to 100 cm. Our policy modulates a representation of the Central Pattern Generator (CPG) in the spinal cord, effectively coordinating both frequencies and amplitudes of the CPG to produce rhythmic output (Rhythm Generation), which is then mapped to a Pattern Formation (PF) layer. Across different robots, the only varying component is the PF layer, which adjusts the scaling parameters for the stride height and length. Subsequently, we evaluate the sim-to-real transfer by testing the single policy on both the Unitree Go1 and A1 robots. Remarkably, we observe robust performance, even when adding a 15 kg load, equivalent to 125% of the A1 robot's nominal mass.", "url": "https://arxiv.org/abs/2310.10486"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

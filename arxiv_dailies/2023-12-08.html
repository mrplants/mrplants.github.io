<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2312.03763", "Date": "Tue, 05 Dec 2023 19:05:58 ", "Title": "Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and Editing", "Authors": ["Yushi Lan", "Feitong Tan", "Di Qiu", "Qiangeng Xu", "Kyle Genova", "Zeng Huang", "Sean Fanello", "Rohit Pandey", "Thomas Funkhouser", "Chen Change Loy", "Yinda Zhang"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "We present a novel framework for generating photorealistic 3D human head and subsequently manipulating and reposing them with remarkable flexibility. The proposed approach leverages an implicit function representation of 3D human heads, employing 3D Gaussians anchored on a parametric face model. To enhance representational capabilities and encode spatial information, we embed a lightweight tri-plane payload within each Gaussian rather than directly storing color and opacity. Additionally, we parameterize the Gaussians in a 2D UV space via a 3DMM, enabling effective utilization of the diffusion model for 3D head avatar generation. Our method facilitates the creation of diverse and realistic 3D human heads with fine-grained editing over facial features and expressions. Extensive experiments demonstrate the effectiveness of our method.", "url": "https://arxiv.org/abs/2312.03763"}, {"metadata": {"arXiv": "2312.03806", "Date": "Wed, 06 Dec 2023 16:23:26 ", "Title": "XCube ($\\mathcal{X}^3$): Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies", "Authors": ["Xuanchi Ren", "Jiahui Huang", "Xiaohui Zeng", "Ken Museth", "Sanja Fidler", "Francis Williams"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "We present $\\mathcal{X}^3$ (pronounced XCube), a novel generative model for high-resolution sparse 3D voxel grids with arbitrary attributes. Our model can generate millions of voxels with a finest effective resolution of up to $1024^3$ in a feed-forward fashion without time-consuming test-time optimization. To achieve this, we employ a hierarchical voxel latent diffusion model which generates progressively higher resolution grids in a coarse-to-fine manner using a custom framework built on the highly efficient VDB data structure. Apart from generating high-resolution objects, we demonstrate the effectiveness of XCube on large outdoor scenes at scales of 100m$\\times$100m with a voxel size as small as 10cm. We observe clear qualitative and quantitative improvements over past approaches. In addition to unconditional generation, we show that our model can be used to solve a variety of tasks such as user-guided editing, scene completion from a single scan, and text-to-3D. More results and details can be found at https://research.nvidia.com/labs/toronto-ai/xcube/.", "url": "https://arxiv.org/abs/2312.03806"}, {"metadata": {"arXiv": "2312.03936", "Date": "Wed, 06 Dec 2023 22:29:16 ", "Title": "The Potential of Vision-Language Models for Content Moderation of Children's Videos", "Authors": ["Syed Hammad Ahmed", "Shengnan Hu", "Gita Sukthankar"], "Categories": "cs.CV cs.CY cs.LG cs.SI", "Comments": ["5 pages", "1 figure. Accepted at IEEE ICMLA 2023"]}, "abstract": "Natural language supervision has been shown to be effective for zero-shot learning in many computer vision tasks, such as object detection and activity recognition. However, generating informative prompts can be challenging for more subtle tasks, such as video content moderation. This can be difficult, as there are many reasons why a video might be inappropriate, beyond violence and obscenity. For example, scammers may attempt to create junk content that is similar to popular educational videos but with no meaningful information. This paper evaluates the performance of several CLIP variations for content moderation of children's cartoons in both the supervised and zero-shot setting. We show that our proposed model (Vanilla CLIP with Projection Layer) outperforms previous work conducted on the Malicious or Benign (MOB) benchmark for video content moderation. This paper presents an in depth analysis of how context-specific language prompts affect content moderation performance. Our results indicate that it is important to include more context in content moderation prompts, particularly for cartoon videos as they are not well represented in the CLIP training data.", "url": "https://arxiv.org/abs/2312.03936"}, {"metadata": {"arXiv": "2312.04036", "Date": "Thu, 07 Dec 2023 04:39:22 ", "Title": "DiffusionPhase: Motion Diffusion in Frequency Domain", "Authors": ["Weilin Wan", "Yiming Huang", "Shutong Wu", "Taku Komura", "Wenping Wang", "Dinesh Jayaraman", "Lingjie Liu"], "Categories": "cs.CV cs.LG"}, "abstract": "In this study, we introduce a learning-based method for generating high-quality human motion sequences from text descriptions (e.g., ``A person walks forward\"). Existing techniques struggle with motion diversity and smooth transitions in generating arbitrary-length motion sequences, due to limited text-to-motion datasets and the pose representations used that often lack expressiveness or compactness. To address these issues, we propose the first method for text-conditioned human motion generation in the frequency domain of motions. We develop a network encoder that converts the motion space into a compact yet expressive parameterized phase space with high-frequency details encoded, capturing the local periodicity of motions in time and space with high accuracy. We also introduce a conditional diffusion model for predicting periodic motion parameters based on text descriptions and a start pose, efficiently achieving smooth transitions between motion sequences associated with different text descriptions. Experiments demonstrate that our approach outperforms current methods in generating a broader variety of high-quality motions, and synthesizing long sequences with natural transitions.", "url": "https://arxiv.org/abs/2312.04036"}, {"metadata": {"arXiv": "2312.04145", "Date": "Thu, 07 Dec 2023 08:59:20 ", "Title": "Diffusing Colors: Image Colorization with Text Guided Diffusion", "Authors": ["Nir Zabari", "Aharon Azulay", "Alexey Gorkor", "Tavi Halperin", "Ohad Fried"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["SIGGRAPH Asia 2023"]}, "abstract": "The colorization of grayscale images is a complex and subjective task with significant challenges. Despite recent progress in employing large-scale datasets with deep neural networks, difficulties with controllability and visual quality persist. To tackle these issues, we present a novel image colorization framework that utilizes image diffusion techniques with granular text prompts. This integration not only produces colorization outputs that are semantically appropriate but also greatly improves the level of control users have over the colorization process. Our method provides a balance between automation and control, outperforming existing techniques in terms of visual quality and semantic coherence. We leverage a pretrained generative Diffusion Model, and show that we can finetune it for the colorization task without losing its generative power or attention to text prompts. Moreover, we present a novel CLIP-based ranking model that evaluates color vividness, enabling automatic selection of the most suitable level of vividness based on the specific scene semantics. Our approach holds potential particularly for color enhancement and historical image colorization.", "url": "https://arxiv.org/abs/2312.04145"}, {"metadata": {"arXiv": "2312.04554", "Date": "Thu, 07 Dec 2023 18:59:22 ", "Title": "Improved Visual Grounding through Self-Consistent Explanations", "Authors": ["Ruozhen He", "Paola Cascante-Bonilla", "Ziyan Yang", "Alexander C. Berg", "Vicente Ordonez"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["Project Page: https://catherine-r-he.github.io/SelfEQ/"]}, "abstract": "Vision-and-language models trained to match images with text can be combined with visual explanation methods to point to the locations of specific objects in an image. Our work shows that the localization --\"grounding\"-- abilities of these models can be further improved by finetuning for self-consistent visual explanations. We propose a strategy for augmenting existing text-image datasets with paraphrases using a large language model, and SelfEQ, a weakly-supervised strategy on visual explanation maps for paraphrases that encourages self-consistency. Specifically, for an input textual phrase, we attempt to generate a paraphrase and finetune the model so that the phrase and paraphrase map to the same region in the image. We posit that this both expands the vocabulary that the model is able to handle, and improves the quality of the object locations highlighted by gradient-based visual explanation methods (e.g. GradCAM). We demonstrate that SelfEQ improves performance on Flickr30k, ReferIt, and RefCOCO+ over a strong baseline method and several prior works. Particularly, comparing to other methods that do not use any type of box annotations, we obtain 84.07% on Flickr30k (an absolute improvement of 4.69%), 67.40% on ReferIt (an absolute improvement of 7.68%), and 75.10%, 55.49% on RefCOCO+ test sets A and B respectively (an absolute improvement of 3.74% on average).", "url": "https://arxiv.org/abs/2312.04554"}, {"metadata": {"arXiv": "2312.03780", "Date": "Wed, 06 Dec 2023 08:40:54 ", "Title": "Predicting the Transportation Activities of Construction Waste Hauling Trucks: An Input-Output Hidden Markov Approach", "Authors": ["Hongtai Yang", "Boyi Lei", "Ke Han", "Luna Liu"], "Categories": "cs.LG", "Comments": ["21 pages", "8 figures"]}, "abstract": "Construction waste hauling trucks (CWHTs), as one of the most commonly seen heavy-duty vehicles in major cities around the globe, are usually subject to a series of regulations and spatial-temporal access restrictions because they not only produce significant NOx and PM emissions but also causes on-road fugitive dust. The timely and accurate prediction of CWHTs' destinations and dwell times play a key role in effective environmental management. To address this challenge, we propose a prediction method based on an interpretable activity-based model, input-output hidden Markov model (IOHMM), and validate it on 300 CWHTs in Chengdu, China. Contextual factors are considered in the model to improve its prediction power. Results show that the IOHMM outperforms several baseline models, including Markov chains, linear regression, and long short-term memory. Factors influencing the predictability of CWHTs' transportation activities are also explored using linear regression models. Results suggest the proposed model holds promise in assisting authorities by predicting the upcoming transportation activities of CWHTs and administering intervention in a timely and effective manner.", "url": "https://arxiv.org/abs/2312.03780"}, {"metadata": {"arXiv": "2312.03788", "Date": "Wed, 06 Dec 2023 11:10:55 ", "Title": "SmoothQuant+: Accurate and Efficient 4-bit Post-Training WeightQuantization for LLM", "Authors": ["Jiayi Pan", "Chengcan Wang", "Kaifu Zheng", "Yangguang Li", "Zhenyu Wang", "Bin Feng"], "Categories": "cs.LG cs.CL"}, "abstract": "Large language models (LLMs) have shown remarkable capabilities in various tasks. However their huge model size and the consequent demand for computational and memory resources also pose challenges to model deployment. Currently, 4-bit post-training quantization (PTQ) has achieved some success in LLMs, reducing the memory footprint by approximately 75% compared to FP16 models, albeit with some accuracy loss. In this paper, we propose SmoothQuant+, an accurate and efficient 4-bit weight-only PTQ that requires no additional training, which enables lossless in accuracy for LLMs for the first time. Based on the fact that the loss of weight quantization is amplified by the activation outliers, SmoothQuant+ smoothes the activation outliers by channel before quantization, while adjusting the corresponding weights for mathematical equivalence, and then performs group-wise 4-bit weight quantization for linear layers. We have integrated SmoothQuant+ into the vLLM framework, an advanced high-throughput inference engine specially developed for LLMs, and equipped it with an efficient W4A16 CUDA kernels, so that vLLM can seamlessly support SmoothQuant+ 4-bit weight quantization. Our results show that, with SmoothQuant+, the Code Llama-34B model can be quantized and deployed on a A100 40GB GPU, achieving lossless accuracy and a throughput increase of 1.9 to 4.0 times compared to the FP16 model deployed on two A100 40GB GPUs. Moreover, the latency per token is only 68% of the FP16 model deployed on two A100 40GB GPUs. This is the state-of-the-art 4-bit weight quantization for LLMs as we know.", "url": "https://arxiv.org/abs/2312.03788"}, {"metadata": {"arXiv": "2312.03865", "Date": "Wed, 06 Dec 2023 19:23:53 ", "Title": "Learning Genomic Sequence Representations using Graph Neural Networks over De Bruijn Graphs", "Authors": ["Kacper Kapu\\'sniak", "Manuel Burger", "Gunnar R\\\"atsch", "Amir Joudaki"], "Categories": "cs.LG q-bio.GN", "Comments": ["Poster at \"NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)\""]}, "abstract": "The rapid expansion of genomic sequence data calls for new methods to achieve robust sequence representations. Existing techniques often neglect intricate structural details, emphasizing mainly contextual information. To address this, we developed k-mer embeddings that merge contextual and structural string information by enhancing De Bruijn graphs with structural similarity connections. Subsequently, we crafted a self-supervised method based on Contrastive Learning that employs a heterogeneous Graph Convolutional Network encoder and constructs positive pairs based on node similarities. Our embeddings consistently outperform prior techniques for Edit Distance Approximation and Closest String Retrieval tasks.", "url": "https://arxiv.org/abs/2312.03865"}, {"metadata": {"arXiv": "2312.03867", "Date": "Wed, 06 Dec 2023 19:25:32 ", "Title": "Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing", "Authors": ["Lucas Monteiro Paes", "Ananda Theertha Suresh", "Alex Beutel", "Flavio P. Calmon", "Ahmad Beirami"], "Categories": "cs.LG cs.CY cs.IT math.IT stat.ML"}, "abstract": "Machine learning (ML) models used in prediction and classification tasks may display performance disparities across population groups determined by sensitive attributes (e.g., race, sex, age). We consider the problem of evaluating the performance of a fixed ML model across population groups defined by multiple sensitive attributes (e.g., race and sex and age). Here, the sample complexity for estimating the worst-case performance gap across groups (e.g., the largest difference in error rates) increases exponentially with the number of group-denoting sensitive attributes. To address this issue, we propose an approach to test for performance disparities based on Conditional Value-at-Risk (CVaR). By allowing a small probabilistic slack on the groups over which a model has approximately equal performance, we show that the sample complexity required for discovering performance violations is reduced exponentially to be at most upper bounded by the square root of the number of groups. As a byproduct of our analysis, when the groups are weighted by a specific prior distribution, we show that R\\'enyi entropy of order $2/3$ of the prior distribution captures the sample complexity of the proposed CVaR test algorithm. Finally, we also show that there exists a non-i.i.d. data collection strategy that results in a sample complexity independent of the number of groups.", "url": "https://arxiv.org/abs/2312.03867"}, {"metadata": {"arXiv": "2312.03878", "Date": "Wed, 06 Dec 2023 19:49:06 ", "Title": "Domain constraints improve risk prediction when outcome data is missing", "Authors": ["Sidhika Balachandar", "Nikhil Garg", "Emma Pierson"], "Categories": "cs.LG"}, "abstract": "Machine learning models are often trained to predict the outcome resulting from a human decision. For example, if a doctor decides to test a patient for disease, will the patient test positive? A challenge is that the human decision censors the outcome data: we only observe test outcomes for patients doctors historically tested. Untested patients, for whom outcomes are unobserved, may differ from tested patients along observed and unobserved dimensions. We propose a Bayesian model class which captures this setting. The purpose of the model is to accurately estimate risk for both tested and untested patients. Estimating this model is challenging due to the wide range of possibilities for untested patients. To address this, we propose two domain constraints which are plausible in health settings: a prevalence constraint, where the overall disease prevalence is known, and an expertise constraint, where the human decision-maker deviates from purely risk-based decision-making only along a constrained feature set. We show theoretically and on synthetic data that domain constraints improve parameter inference. We apply our model to a case study of cancer risk prediction, showing that the model's inferred risk predicts cancer diagnoses, its inferred testing policy captures known public health policies, and it can identify suboptimalities in test allocation. Though our case study is in healthcare, our analysis reveals a general class of domain constraints which can improve model estimation in many settings.", "url": "https://arxiv.org/abs/2312.03878"}, {"metadata": {"arXiv": "2312.03885", "Date": "Wed, 06 Dec 2023 20:24:05 ", "Title": "Adapting Newton's Method to Neural Networks through a Summary of Higher-Order Derivatives", "Authors": ["Pierre Wolinski"], "Categories": "cs.LG math.OC"}, "abstract": "We consider a gradient-based optimization method applied to a function $\\mathcal{L}$ of a vector of variables $\\boldsymbol{\\theta}$, in the case where $\\boldsymbol{\\theta}$ is represented as a tuple of tensors $(\\mathbf{T}_1, \\cdots, \\mathbf{T}_S)$. This framework encompasses many common use-cases, such as training neural networks by gradient descent. First, we propose a computationally inexpensive technique providing higher-order information on $\\mathcal{L}$, especially about the interactions between the tensors $\\mathbf{T}_s$, based on automatic differentiation and computational tricks. Second, we use this technique at order 2 to build a second-order optimization method which is suitable, among other things, for training deep neural networks of various architectures. This second-order method leverages the partition structure of $\\boldsymbol{\\theta}$ into tensors $(\\mathbf{T}_1, \\cdots, \\mathbf{T}_S)$, in such a way that it requires neither the computation of the Hessian of $\\mathcal{L}$ according to $\\boldsymbol{\\theta}$, nor any approximation of it. The key part consists in computing a smaller matrix interpretable as a \"Hessian according to the partition\", which can be computed exactly and efficiently. In contrast to many existing practical second-order methods used in neural networks, which perform a diagonal or block-diagonal approximation of the Hessian or its inverse, the method we propose does not neglect interactions between layers. Finally, we can tune the coarseness of the partition to recover well-known optimization methods: the coarsest case corresponds to Cauchy's steepest descent method, the finest case corresponds to the usual Newton's method.", "url": "https://arxiv.org/abs/2312.03885"}, {"metadata": {"arXiv": "2312.03903", "Date": "Wed, 06 Dec 2023 20:56:23 ", "Title": "Adaptive Dependency Learning Graph Neural Networks", "Authors": ["Abishek Sriramulu", "Nicolas Fourrier and Christoph Bergmeir"], "Categories": "cs.LG", "Journal-ref": "Information Sciences, 625, 700-714 (2023)", "DOI": "10.1016/j.ins.2022.12.086"}, "abstract": "Graph Neural Networks (GNN) have recently gained popularity in the forecasting domain due to their ability to model complex spatial and temporal patterns in tasks such as traffic forecasting and region-based demand forecasting. Most of these methods require a predefined graph as input, whereas in real-life multivariate time series problems, a well-predefined dependency graph rarely exists. This requirement makes it harder for GNNs to be utilised widely for multivariate forecasting problems in other domains such as retail or energy. In this paper, we propose a hybrid approach combining neural networks and statistical structure learning models to self-learn the dependencies and construct a dynamically changing dependency graph from multivariate data aiming to enable the use of GNNs for multivariate forecasting even when a well-defined graph does not exist. The statistical structure modeling in conjunction with neural networks provides a well-principled and efficient approach by bringing in causal semantics to determine dependencies among the series. Finally, we demonstrate significantly improved performance using our proposed approach on real-world benchmark datasets without a pre-defined dependency graph.", "url": "https://arxiv.org/abs/2312.03903"}, {"metadata": {"arXiv": "2312.03911", "Date": "Wed, 06 Dec 2023 21:09:18 ", "Title": "Improving Gradient-guided Nested Sampling for Posterior Inference", "Authors": ["Pablo Lemos", "Nikolay Malkin", "Will Handley", "Yoshua Bengio", "Yashar Hezaveh", "Laurence Perreault-Levasseur"], "Categories": "cs.LG stat.CO stat.ME stat.ML", "Comments": ["10 pages", "5 figures. Code available at https://github.com/Pablo-Lemos/GGNS"]}, "abstract": "We present a performant, general-purpose gradient-guided nested sampling algorithm, ${\\tt GGNS}$, combining the state of the art in differentiable programming, Hamiltonian slice sampling, clustering, mode separation, dynamic nested sampling, and parallelization. This unique combination allows ${\\tt GGNS}$ to scale well with dimensionality and perform competitively on a variety of synthetic and real-world problems. We also show the potential of combining nested sampling with generative flow networks to obtain large amounts of high-quality samples from the posterior distribution. This combination leads to faster mode discovery and more accurate estimates of the partition function.", "url": "https://arxiv.org/abs/2312.03911"}, {"metadata": {"arXiv": "2312.03928", "Date": "Wed, 06 Dec 2023 22:09:52 ", "Title": "Adaptive Weighted Co-Learning for Cross-Domain Few-Shot Learning", "Authors": ["Abdullah Alchihabi", "Marzi Heidari", "Yuhong Guo"], "Categories": "cs.LG"}, "abstract": "Due to the availability of only a few labeled instances for the novel target prediction task and the significant domain shift between the well annotated source domain and the target domain, cross-domain few-shot learning (CDFSL) induces a very challenging adaptation problem. In this paper, we propose a simple Adaptive Weighted Co-Learning (AWCoL) method to address the CDFSL challenge by adapting two independently trained source prototypical classification models to the target task in a weighted co-learning manner. The proposed method deploys a weighted moving average prediction strategy to generate probabilistic predictions from each model, and then conducts adaptive co-learning by jointly fine-tuning the two models in an alternating manner based on the pseudo-labels and instance weights produced from the predictions. Moreover, a negative pseudo-labeling regularizer is further deployed to improve the fine-tuning process by penalizing false predictions. Comprehensive experiments are conducted on multiple benchmark datasets and the empirical results demonstrate that the proposed method produces state-of-the-art CDFSL performance.", "url": "https://arxiv.org/abs/2312.03928"}, {"metadata": {"arXiv": "2312.03951", "Date": "Wed, 06 Dec 2023 23:29:00 ", "Title": "Understanding the Role of Optimization in Double Descent", "Authors": ["Chris Yuhao Liu", "Jeffrey Flanigan"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS Workshop 2023 Optimization for Machine Learning"]}, "abstract": "The phenomenon of model-wise double descent, where the test error peaks and then reduces as the model size increases, is an interesting topic that has attracted the attention of researchers due to the striking observed gap between theory and practice \\citep{Belkin2018ReconcilingMM}. Additionally, while double descent has been observed in various tasks and architectures, the peak of double descent can sometimes be noticeably absent or diminished, even without explicit regularization, such as weight decay and early stopping. In this paper, we investigate this intriguing phenomenon from the optimization perspective and propose a simple optimization-based explanation for why double descent sometimes occurs weakly or not at all. To the best of our knowledge, we are the first to demonstrate that many disparate factors contributing to model-wise double descent (initialization, normalization, batch size, learning rate, optimization algorithm) are unified from the viewpoint of optimization: model-wise double descent is observed if and only if the optimizer can find a sufficiently low-loss minimum. These factors directly affect the condition number of the optimization problem or the optimizer and thus affect the final minimum found by the optimizer, reducing or increasing the height of the double descent peak. We conduct a series of controlled experiments on random feature models and two-layer neural networks under various optimization settings, demonstrating this optimization-based unified view. Our results suggest the following implication: Double descent is unlikely to be a problem for real-world machine learning setups. Additionally, our results help explain the gap between weak double descent peaks in practice and strong peaks observable in carefully designed setups.", "url": "https://arxiv.org/abs/2312.03951"}, {"metadata": {"arXiv": "2312.03979", "Date": "Thu, 07 Dec 2023 01:24:48 ", "Title": "Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks", "Authors": ["Yuni Lai", "Yulin Zhu", "Bailin Pan", "Kai Zhou"], "Categories": "cs.LG cs.CR"}, "abstract": "Deep Graph Learning (DGL) has emerged as a crucial technique across various domains. However, recent studies have exposed vulnerabilities in DGL models, such as susceptibility to evasion and poisoning attacks. While empirical and provable robustness techniques have been developed to defend against graph modification attacks (GMAs), the problem of certified robustness against graph injection attacks (GIAs) remains largely unexplored. To bridge this gap, we introduce the node-aware bi-smoothing framework, which is the first certifiably robust approach for general node classification tasks against GIAs. Notably, the proposed node-aware bi-smoothing scheme is model-agnostic and is applicable for both evasion and poisoning attacks. Through rigorous theoretical analysis, we establish the certifiable conditions of our smoothing scheme. We also explore the practical implications of our node-aware bi-smoothing schemes in two contexts: as an empirical defense approach against real-world GIAs and in the context of recommendation systems. Furthermore, we extend two state-of-the-art certified robustness frameworks to address node injection attacks and compare our approach against them. Extensive evaluations demonstrate the effectiveness of our proposed certificates.", "url": "https://arxiv.org/abs/2312.03979"}, {"metadata": {"arXiv": "2312.03989", "Date": "Thu, 07 Dec 2023 02:14:39 ", "Title": "Rapid detection of rare events from in situ X-ray diffraction data using machine learning", "Authors": ["Weijian Zheng", "Jun-Sang Park", "Peter Kenesei", "Ahsan Ali", "Zhengchun Liu", "Ian T. Foster", "Nicholas Schwarz", "Rajkumar Kettimuthu", "Antonino Miceli", "Hemant Sharma"], "Categories": "cs.LG cond-mat.mtrl-sci eess.IV physics.data-an"}, "abstract": "High-energy X-ray diffraction methods can non-destructively map the 3D microstructure and associated attributes of metallic polycrystalline engineering materials in their bulk form. These methods are often combined with external stimuli such as thermo-mechanical loading to take snapshots over time of the evolving microstructure and attributes. However, the extreme data volumes and the high costs of traditional data acquisition and reduction approaches pose a barrier to quickly extracting actionable insights and improving the temporal resolution of these snapshots. Here we present a fully automated technique capable of rapidly detecting the onset of plasticity in high-energy X-ray microscopy data. Our technique is computationally faster by at least 50 times than the traditional approaches and works for data sets that are up to 9 times sparser than a full data set. This new technique leverages self-supervised image representation learning and clustering to transform massive data into compact, semantic-rich representations of visually salient characteristics (e.g., peak shapes). These characteristics can be a rapid indicator of anomalous events such as changes in diffraction peak shapes. We anticipate that this technique will provide just-in-time actionable information to drive smarter experiments that effectively deploy multi-modal X-ray diffraction methods that span many decades of length scales.", "url": "https://arxiv.org/abs/2312.03989"}, {"metadata": {"arXiv": "2312.03998", "Date": "Thu, 07 Dec 2023 02:30:40 ", "Title": "Series2Vec: Similarity-based Self-supervised Representation Learning for Time Series Classification", "Authors": ["Navid Mohammadi Foumani", "Chang Wei Tan", "Geoffrey I. Webb", "Mahsa Salehi"], "Categories": "cs.LG"}, "abstract": "We argue that time series analysis is fundamentally different in nature to either vision or natural language processing with respect to the forms of meaningful self-supervised learning tasks that can be defined. Motivated by this insight, we introduce a novel approach called \\textit{Series2Vec} for self-supervised representation learning. Unlike other self-supervised methods in time series, which carry the risk of positive sample variants being less similar to the anchor sample than series in the negative set, Series2Vec is trained to predict the similarity between two series in both temporal and spectral domains through a self-supervised task. Series2Vec relies primarily on the consistency of the unsupervised similarity step, rather than the intrinsic quality of the similarity measurement, without the need for hand-crafted data augmentation. To further enforce the network to learn similar representations for similar time series, we propose a novel approach that applies order-invariant attention to each representation within the batch during training. Our evaluation of Series2Vec on nine large real-world datasets, along with the UCR/UEA archive, shows enhanced performance compared to current state-of-the-art self-supervised techniques for time series. Additionally, our extensive experiments show that Series2Vec performs comparably with fully supervised training and offers high efficiency in datasets with limited-labeled data. Finally, we show that the fusion of Series2Vec with other representation learning models leads to enhanced performance for time series classification. Code and models are open-source at \\url{https://github.com/Navidfoumani/Series2Vec.}", "url": "https://arxiv.org/abs/2312.03998"}, {"metadata": {"arXiv": "2312.04000", "Date": "Thu, 07 Dec 2023 02:31:28 ", "Title": "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "Authors": ["Vimal Thilak and Chen Huang and Omid Saremi and Laurent Dinh and Hanlin Goh and Preetum Nakkiran and Joshua M. Susskind and Etai Littwin"], "Categories": "cs.LG cs.CV", "Comments": ["Technical report"]}, "abstract": "Joint embedding (JE) architectures have emerged as a promising avenue for acquiring transferable data representations. A key obstacle to using JE methods, however, is the inherent challenge of evaluating learned representations without access to a downstream task, and an annotated dataset. Without efficient and reliable evaluation, it is difficult to iterate on architectural and training choices for JE methods. In this paper, we introduce LiDAR (Linear Discriminant Analysis Rank), a metric designed to measure the quality of representations within JE architectures. Our metric addresses several shortcomings of recent approaches based on feature covariance rank by discriminating between informative and uninformative features. In essence, LiDAR quantifies the rank of the Linear Discriminant Analysis (LDA) matrix associated with the surrogate SSL task -- a measure that intuitively captures the information content as it pertains to solving the SSL task. We empirically demonstrate that LiDAR significantly surpasses naive rank based approaches in its predictive power of optimal hyperparameters. Our proposed criterion presents a more robust and intuitive means of assessing the quality of representations within JE architectures, which we hope facilitates broader adoption of these powerful techniques in various domains.", "url": "https://arxiv.org/abs/2312.04000"}, {"metadata": {"arXiv": "2312.04038", "Date": "Thu, 07 Dec 2023 04:43:04 ", "Title": "Reconstruction of dynamical systems from data without time labels", "Authors": ["Zhijun Zeng", "Pipi Hu", "Chenglong Bao", "Yi Zhu", "Zuoqiang Shi"], "Categories": "cs.LG cs.NA math.DS math.NA"}, "abstract": "In this paper, we study the method to reconstruct dynamical systems from data without time labels. Data without time labels appear in many applications, such as molecular dynamics, single-cell RNA sequencing etc. Reconstruction of dynamical system from time sequence data has been studied extensively. However, these methods do not apply if time labels are unknown. Without time labels, sequence data becomes distribution data. Based on this observation, we propose to treat the data as samples from a probability distribution and try to reconstruct the underlying dynamical system by minimizing the distribution loss, sliced Wasserstein distance more specifically. Extensive experiment results demonstrate the effectiveness of the proposed method.", "url": "https://arxiv.org/abs/2312.04038"}, {"metadata": {"arXiv": "2312.04055", "Date": "Thu, 07 Dec 2023 05:27:24 ", "Title": "Jointly spatial-temporal representation learning for individual trajectories", "Authors": ["Fei Huang", "Jianrong Lv and Yang Yue"], "Categories": "cs.LG", "Comments": ["27 pages", "3 tables", "7 figures"]}, "abstract": "Individual trajectories, containing substantial information on human-environment interactions across space and time, is a crucial input for geospatial foundation models (GeoFMs). However, existing attempts, leveraging trajectory data for various applications have overlooked the implicit spatial-temporal dependency within trajectories and failed to encode and represent it in a format friendly to deep learning, posing a challenge in obtaining general-purpose trajectory representations. Therefore, this paper proposes a spatial-temporal joint representation learning method (ST-GraphRL) to formalize learnable spatial-temporal dependencies into trajectory representations. The proposed ST-GraphRL consists of three compositions: (i) a weighted directed spatial-temporal graph to explicitly construct mobility interactions over both space and time dimensions; (ii) a two-stage jointly encoder (i.e., decoupling and fusion) to learn entangled spatial-temporal dependencies by independently decomposing and jointly aggregating space and time information; (iii) a decoder guides ST-GraphRL to learn explicit mobility regularities by simulating the spatial-temporal distributions of trajectories. Tested on three real-world human mobility datasets, the proposed ST-GraphRL outperformed all the baseline models in predicting movement spatial-temporal distributions and preserving trajectory similarity with high spatial-temporal correlations. We also explore how spatial-temporal features presented in latent space, validating that ST-GraphRL understands spatial-temporal patterns. This method is also transferable for general-purpose geospatial data representations for broad downstream tasks, as well advancing GeoFMs developing.", "url": "https://arxiv.org/abs/2312.04055"}, {"metadata": {"arXiv": "2312.04065", "Date": "Thu, 07 Dec 2023 06:09:21 ", "Title": "A Robust and Efficient Boundary Point Detection Method by Measuring Local Direction Dispersion", "Authors": ["Dehua Peng", "Zhipeng Gui", "Huayi Wu"], "Categories": "cs.LG", "Comments": ["11 pages", "6 figures", "3 tables"], "ACM-class": "I.5.2"}, "abstract": "Boundary points pose a significant challenge for machine learning tasks, including classification, clustering, and dimensionality reduction. Due to the similarity of features, boundary areas can result in mixed-up classes or clusters, leading to a crowding problem in dimensionality reduction. To address this challenge, numerous boundary point detection methods have been developed, but they are insufficiently to accurately and efficiently identify the boundary points in non-convex structures and high-dimensional manifolds. In this work, we propose a robust and efficient method for detecting boundary points using Local Direction Dispersion (LoDD). LoDD considers that internal points are surrounded by neighboring points in all directions, while neighboring points of a boundary point tend to be distributed only in a certain directional range. LoDD adopts a density-independent K-Nearest Neighbors (KNN) method to determine neighboring points, and defines a statistic-based metric using the eigenvalues of the covariance matrix of KNN coordinates to measure the centrality of a query point. We demonstrated the validity of LoDD on five synthetic datasets (2-D and 3-D) and ten real-world benchmarks, and tested its clustering performance by equipping with two typical clustering methods, K-means and Ncut. Our results show that LoDD achieves promising and robust detection accuracy in a time-efficient manner.", "url": "https://arxiv.org/abs/2312.04065"}, {"metadata": {"arXiv": "2312.04067", "Date": "Thu, 07 Dec 2023 06:19:39 ", "Title": "MeanCut: A Greedy-Optimized Graph Clustering via Path-based Similarity and Degree Descent Criterion", "Authors": ["Dehua Peng", "Zhipeng Gui", "Huayi Wu"], "Categories": "cs.LG", "Comments": ["17 pages", "8 figures", "6 tables"], "ACM-class": "I.5.3"}, "abstract": "As the most typical graph clustering method, spectral clustering is popular and attractive due to the remarkable performance, easy implementation, and strong adaptability. Classical spectral clustering measures the edge weights of graph using pairwise Euclidean-based metric, and solves the optimal graph partition by relaxing the constraints of indicator matrix and performing Laplacian decomposition. However, Euclidean-based similarity might cause skew graph cuts when handling non-spherical data distributions, and the relaxation strategy introduces information loss. Meanwhile, spectral clustering requires specifying the number of clusters, which is hard to determine without enough prior knowledge. In this work, we leverage the path-based similarity to enhance intra-cluster associations, and propose MeanCut as the objective function and greedily optimize it in degree descending order for a nondestructive graph partition. This algorithm enables the identification of arbitrary shaped clusters and is robust to noise. To reduce the computational complexity of similarity calculation, we transform optimal path search into generating the maximum spanning tree (MST), and develop a fast MST (FastMST) algorithm to further improve its time-efficiency. Moreover, we define a density gradient factor (DGF) for separating the weakly connected clusters. The validity of our algorithm is demonstrated by testifying on real-world benchmarks and application of face recognition. The source code of MeanCut is available at https://github.com/ZPGuiGroupWhu/MeanCut-Clustering.", "url": "https://arxiv.org/abs/2312.04067"}, {"metadata": {"arXiv": "2312.04070", "Date": "Thu, 07 Dec 2023 06:27:48 ", "Title": "A Transformer Model for Symbolic Regression towards Scientific Discovery", "Authors": ["Florian Lalande", "Yoshitomo Matsubara", "Naoya Chiba", "Tatsunori Taniai", "Ryo Igarashi", "Yoshitala Ushiku"], "Categories": "cs.LG", "Comments": ["Accepted for oral presentation at NeurIPS2023 AI4Science Workshop. OpenReview: https://openreview.net/forum?id=AIfqWNHKjo"]}, "abstract": "Symbolic Regression (SR) searches for mathematical expressions which best describe numerical datasets. This allows to circumvent interpretation issues inherent to artificial neural networks, but SR algorithms are often computationally expensive. This work proposes a new Transformer model aiming at Symbolic Regression particularly focused on its application for Scientific Discovery. We propose three encoder architectures with increasing flexibility but at the cost of column-permutation equivariance violation. Training results indicate that the most flexible architecture is required to prevent from overfitting. Once trained, we apply our best model to the SRSD datasets (Symbolic Regression for Scientific Discovery datasets) which yields state-of-the-art results using the normalized tree-based edit distance, at no extra computational cost.", "url": "https://arxiv.org/abs/2312.04070"}, {"metadata": {"arXiv": "2312.04083", "Date": "Thu, 07 Dec 2023 06:51:55 ", "Title": "On the adaptation of in-context learners for system identification", "Authors": ["Dario Piga and Filippo Pura and Marco Forgione"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "In-context system identification aims at constructing meta-models to describe classes of systems, differently from traditional approaches that model single systems. This paradigm facilitates the leveraging of knowledge acquired from observing the behaviour of different, yet related dynamics. This paper discusses the role of meta-model adaptation. Through numerical examples, we demonstrate how meta-model adaptation can enhance predictive performance in three realistic scenarios: tailoring the meta-model to describe a specific system rather than a class; extending the meta-model to capture the behaviour of systems beyond the initial training class; and recalibrating the model for new prediction tasks. Results highlight the effectiveness of meta-model adaptation to achieve a more robust and versatile meta-learning framework for system identification.", "url": "https://arxiv.org/abs/2312.04083"}, {"metadata": {"arXiv": "2312.04095", "Date": "Thu, 07 Dec 2023 07:17:24 ", "Title": "Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection", "Authors": ["Tuan Hoang and Santu Rana and Sunil Gupta and Svetha Venkatesh"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Recent data-privacy laws have sparked interest in machine unlearning, which involves removing the effect of specific training samples from a learnt model as if they were never present in the original training dataset. The challenge of machine unlearning is to discard information about the ``forget'' data in the learnt model without altering the knowledge about the remaining dataset and to do so more efficiently than the naive retraining approach. To achieve this, we adopt a projected-gradient based learning method, named as Projected-Gradient Unlearning (PGU), in which the model takes steps in the orthogonal direction to the gradient subspaces deemed unimportant for the retaining dataset, so as to its knowledge is preserved. By utilizing Stochastic Gradient Descent (SGD) to update the model weights, our method can efficiently scale to any model and dataset size. We provide empirically evidence to demonstrate that our unlearning method can produce models that behave similar to models retrained from scratch across various metrics even when the training dataset is no longer accessible. Our code is available at https://github.com/hnanhtuan/projected_gradient_unlearning.", "url": "https://arxiv.org/abs/2312.04095"}, {"metadata": {"arXiv": "2312.04166", "Date": "Thu, 07 Dec 2023 09:36:18 ", "Title": "Improving Communication Efficiency of Federated Distillation via Accumulating Local Updates", "Authors": ["Zhiyuan Wu", "Sheng Sun", "Yuwei Wang", "Min Liu", "Tian Wen", "Wen Wang"], "Categories": "cs.LG cs.DC", "Comments": ["2 pages", "3 figures"]}, "abstract": "As an emerging federated learning paradigm, federated distillation enables communication-efficient model training by transmitting only small-scale knowledge during the learning process. To further improve the communication efficiency of federated distillation, we propose a novel technique, ALU, which accumulates multiple rounds of local updates before transferring the knowledge to the central server. ALU drastically decreases the frequency of communication in federated distillation, thereby significantly reducing the communication overhead during the training process. Empirical experiments demonstrate the substantial effect of ALU in improving the communication efficiency of federated distillation.", "url": "https://arxiv.org/abs/2312.04166"}, {"metadata": {"arXiv": "2312.04167", "Date": "Thu, 07 Dec 2023 09:36:31 ", "Title": "Mixture of Dynamical Variational Autoencoders for Multi-Source Trajectory Modeling and Separation", "Authors": ["Xiaoyu Lin", "Laurent Girin", "Xavier Alameda-Pineda"], "Categories": "cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2202.09315"]}, "abstract": "In this paper, we propose a latent-variable generative model called mixture of dynamical variational autoencoders (MixDVAE) to model the dynamics of a system composed of multiple moving sources. A DVAE model is pre-trained on a single-source dataset to capture the source dynamics. Then, multiple instances of the pre-trained DVAE model are integrated into a multi-source mixture model with a discrete observation-to-source assignment latent variable. The posterior distributions of both the discrete observation-to-source assignment variable and the continuous DVAE variables representing the sources content/position are estimated using a variational expectation-maximization algorithm, leading to multi-source trajectories estimation. We illustrate the versatility of the proposed MixDVAE model on two tasks: a computer vision task, namely multi-object tracking, and an audio processing task, namely single-channel audio source separation. Experimental results show that the proposed method works well on these two tasks, and outperforms several baseline methods.", "url": "https://arxiv.org/abs/2312.04167"}, {"metadata": {"arXiv": "2312.04171", "Date": "Thu, 07 Dec 2023 09:45:14 ", "Title": "A novel feature selection framework for incomplete data", "Authors": ["Cong Guo"], "Categories": "cs.LG"}, "abstract": "Feature selection on incomplete datasets is an exceptionally challenging task. Existing methods address this challenge by first employing imputation methods to complete the incomplete data and then conducting feature selection based on the imputed data. Since imputation and feature selection are entirely independent steps, the importance of features cannot be considered during imputation. However, in real-world scenarios or datasets, different features have varying degrees of importance. To address this, we propose a novel incomplete data feature selection framework that considers feature importance. The framework mainly consists of two alternating iterative stages: the M-stage and the W-stage. In the M-stage, missing values are imputed based on a given feature importance vector and multiple initial imputation results. In the W-stage, an improved reliefF algorithm is employed to learn the feature importance vector based on the imputed data. Specifically, the feature importance vector obtained in the current iteration of the W-stage serves as input for the next iteration of the M-stage. Experimental results on both artificially generated and real incomplete datasets demonstrate that the proposed method outperforms other approaches significantly.", "url": "https://arxiv.org/abs/2312.04171"}, {"metadata": {"arXiv": "2312.04209", "Date": "Thu, 07 Dec 2023 10:52:06 ", "Title": "Constrained Hierarchical Clustering via Graph Coarsening and Optimal Cuts", "Authors": ["Eliabelle Mauduit and Andrea Simonetto"], "Categories": "cs.LG math.OC", "Comments": ["5 pages", "appeared at the Asilomar Conference on Signals", "Systems", "and Computer", "11/2023"]}, "abstract": "Motivated by extracting and summarizing relevant information in short sentence settings, such as satisfaction questionnaires, hotel reviews, and X/Twitter, we study the problem of clustering words in a hierarchical fashion. In particular, we focus on the problem of clustering with horizontal and vertical structural constraints. Horizontal constraints are typically cannot-link and must-link among words, while vertical constraints are precedence constraints among cluster levels. We overcome state-of-the-art bottlenecks by formulating the problem in two steps: first, as a soft-constrained regularized least-squares which guides the result of a sequential graph coarsening algorithm towards the horizontal feasible set. Then, flat clusters are extracted from the resulting hierarchical tree by computing optimal cut heights based on the available constraints. We show that the resulting approach compares very well with respect to existing algorithms and is computationally light.", "url": "https://arxiv.org/abs/2312.04209"}, {"metadata": {"arXiv": "2312.04216", "Date": "Thu, 07 Dec 2023 11:04:37 ", "Title": "CODEX: A Cluster-Based Method for Explainable Reinforcement Learning", "Authors": ["Timothy K. Mathes", "Jessica Inman", "Andr\\'es Col\\'on", "Simon Khan"], "Categories": "cs.LG", "Comments": ["Presented at the International Joint Conference on Artificial Intelligence (IJCAI) 2023 Workshop on Explainable Artificial Intelligence (XAI)"]}, "abstract": "Despite the impressive feats demonstrated by Reinforcement Learning (RL), these algorithms have seen little adoption in high-risk, real-world applications due to current difficulties in explaining RL agent actions and building user trust. We present Counterfactual Demonstrations for Explanation (CODEX), a method that incorporates semantic clustering, which can effectively summarize RL agent behavior in the state-action space. Experimentation on the MiniGrid and StarCraft II gaming environments reveals the semantic clusters retain temporal as well as entity information, which is reflected in the constructed summary of agent behavior. Furthermore, clustering the discrete+continuous game-state latent representations identifies the most crucial episodic events, demonstrating a relationship between the latent and semantic spaces. This work contributes to the growing body of work that strives to unlock the power of RL for widespread use by leveraging and extending techniques from Natural Language Processing.", "url": "https://arxiv.org/abs/2312.04216"}, {"metadata": {"arXiv": "2312.04273", "Date": "Thu, 07 Dec 2023 12:53:05 ", "Title": "Invariant Random Forest: Tree-Based Model Solution for OOD Generalization", "Authors": ["Yufan Liao", "Qi Wu", "Xing Yan"], "Categories": "cs.LG"}, "abstract": "Out-Of-Distribution (OOD) generalization is an essential topic in machine learning. However, recent research is only focusing on the corresponding methods for neural networks. This paper introduces a novel and effective solution for OOD generalization of decision tree models, named Invariant Decision Tree (IDT). IDT enforces a penalty term with regard to the unstable/varying behavior of a split across different environments during the growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is constructed. Our proposed method is motivated by a theoretical result under mild conditions, and validated by numerical tests with both synthetic and real datasets. The superior performance compared to non-OOD tree models implies that considering OOD generalization for tree models is absolutely necessary and should be given more attention.", "url": "https://arxiv.org/abs/2312.04273"}, {"metadata": {"arXiv": "2312.04275", "Date": "Thu, 07 Dec 2023 12:54:16 ", "Title": "Estimating Countries with Similar Maternal Mortality Rate using Cluster Analysis and Pairing Countries with Identical MMR", "Authors": ["S. Nandini and Sanjjushri Varshini R"], "Categories": "cs.LG cs.CY", "Comments": ["14 pages", "6 figures"]}, "abstract": "In the evolving world, we require more additionally the young era to flourish and evolve into developed land. Most of the population all around the world are unaware of the complications involved in the routine they follow while they are pregnant and how hospital facilities affect maternal health. Maternal Mortality is the death of a pregnant woman due to intricacies correlated to pregnancy, underlying circumstances exacerbated by the pregnancy or management of these situations. It is crucial to consider the Maternal Mortality Rate (MMR) in diverse locations and determine which human routines and hospital facilities diminish the Maternal Mortality Rate (MMR). This research aims to examine and discover the countries which are keeping more lavish threats of MMR and countries alike in MMR encountered. Data is examined and collected for various countries, data consists of the earlier years' observation. From the perspective of Machine Learning, Unsupervised Machine Learning is implemented to perform Cluster Analysis. Therefore the pairs of countries with similar MMR as well as the extreme opposite pair concerning the MMR are found.", "url": "https://arxiv.org/abs/2312.04275"}, {"metadata": {"arXiv": "2312.04307", "Date": "Thu, 07 Dec 2023 14:04:38 ", "Title": "A Structural-Clustering Based Active Learning for Graph Neural Networks", "Authors": ["Ricky Maulana Fajri", "Yulong Pei", "Lu Yin", "and Mykola Pechenizkiy"], "Categories": "cs.LG"}, "abstract": "In active learning for graph-structured data, Graph Neural Networks (GNNs) have shown effectiveness. However, a common challenge in these applications is the underutilization of crucial structural information. To address this problem, we propose the Structural-Clustering PageRank method for improved Active learning (SPA) specifically designed for graph-structured data. SPA integrates community detection using the SCAN algorithm with the PageRank scoring method for efficient and informative sample selection. SPA prioritizes nodes that are not only informative but also central in structure. Through extensive experiments, SPA demonstrates higher accuracy and macro-F1 score over existing methods across different annotation budgets and achieves significant reductions in query time. In addition, the proposed method only adds two hyperparameters, $\\epsilon$ and $\\mu$ in the algorithm to finely tune the balance between structural learning and node selection. This simplicity is a key advantage in active learning scenarios, where extensive hyperparameter tuning is often impractical.", "url": "https://arxiv.org/abs/2312.04307"}, {"metadata": {"arXiv": "2312.04311", "Date": "Thu, 07 Dec 2023 14:09:18 ", "Title": "Finding Interpretable Class-Specific Patterns through Efficient Neural Search", "Authors": ["Nils Philipp Walter", "Jonas Fischer", "Jilles Vreeken"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Discovering patterns in data that best describe the differences between classes allows to hypothesize and reason about class-specific mechanisms. In molecular biology, for example, this bears promise of advancing the understanding of cellular processes differing between tissues or diseases, which could lead to novel treatments. To be useful in practice, methods that tackle the problem of finding such differential patterns have to be readily interpretable by domain experts, and scalable to the extremely high-dimensional data. In this work, we propose a novel, inherently interpretable binary neural network architecture DIFFNAPS that extracts differential patterns from data. DiffNaps is scalable to hundreds of thousands of features and robust to noise, thus overcoming the limitations of current state-of-the-art methods in large-scale applications such as in biology. We show on synthetic and real world data, including three biological applications, that, unlike its competitors, DiffNaps consistently yields accurate, succinct, and interpretable class descriptions", "url": "https://arxiv.org/abs/2312.04311"}, {"metadata": {"arXiv": "2312.04327", "Date": "Thu, 07 Dec 2023 14:38:07 ", "Title": "Learning to sample in Cartesian MRI", "Authors": ["Thomas Sanchez"], "Categories": "cs.LG eess.IV", "Comments": ["PhD Thesis; 198 pages"], "DOI": "10.5075/epfl-thesis-9981"}, "abstract": "Despite its exceptional soft tissue contrast, Magnetic Resonance Imaging (MRI) faces the challenge of long scanning times compared to other modalities like X-ray radiography. Shortening scanning times is crucial in clinical settings, as it increases patient comfort, decreases examination costs and improves throughput. Recent advances in compressed sensing (CS) and deep learning allow accelerated MRI acquisition by reconstructing high-quality images from undersampled data. While reconstruction algorithms have received most of the focus, designing acquisition trajectories to optimize reconstruction quality remains an open question. This thesis explores two approaches to address this gap in the context of Cartesian MRI. First, we propose two algorithms, lazy LBCS and stochastic LBCS, that significantly improve upon G\\\"ozc\\\"u et al.'s greedy learning-based CS (LBCS) approach. These algorithms scale to large, clinically relevant scenarios like multi-coil 3D MR and dynamic MRI, previously inaccessible to LBCS. Additionally, we demonstrate that generative adversarial networks (GANs) can serve as a natural criterion for adaptive sampling by leveraging variance in the measurement domain to guide acquisition. Second, we delve into the underlying structures or assumptions that enable mask design algorithms to perform well in practice. Our experiments reveal that state-of-the-art deep reinforcement learning (RL) approaches, while capable of adaptation and long-horizon planning, offer only marginal improvements over stochastic LBCS, which is neither adaptive nor does long-term planning. Altogether, our findings suggest that stochastic LBCS and similar methods represent promising alternatives to deep RL. They shine in particular by their scalability and computational efficiency and could be key in the deployment of optimized acquisition trajectories in Cartesian MRI.", "url": "https://arxiv.org/abs/2312.04327"}, {"metadata": {"arXiv": "2312.04339", "Date": "Thu, 07 Dec 2023 14:59:15 ", "Title": "Merging by Matching Models in Task Subspaces", "Authors": ["Derek Tam", "Mohit Bansal", "Colin Raffel"], "Categories": "cs.LG cs.CL"}, "abstract": "Model merging aims to cheaply combine individual task-specific models into a single multitask model. In this work, we view past merging methods as leveraging different notions of a ''task subspace'' in which models are matched before being merged. We connect the task subspace of a given model to its loss landscape and formalize how this approach to model merging can be seen as solving a linear system of equations. While past work has generally been limited to linear systems that have a closed-form solution, we consider using the conjugate gradient method to find a solution. We show that using the conjugate gradient method can outperform closed-form solutions, enables merging via linear systems that are otherwise intractable to solve, and flexibly allows choosing from a wide variety of initializations and estimates for the ''task subspace''. We ultimately demonstrate that our merging framework called ''Matching Models in their Task Subspace'' (MaTS) achieves state-of-the-art results in multitask and intermediate-task model merging. We release all of the code and checkpoints used in our work at https://github.com/r-three/mats.", "url": "https://arxiv.org/abs/2312.04339"}, {"metadata": {"arXiv": "2312.04346", "Date": "Thu, 07 Dec 2023 15:06:06 ", "Title": "Improved Efficient Two-Stage Denoising Diffusion Power System Measurement Recovery Against False Data Injection Attacks and Data Losses", "Authors": ["Jianhua Pei", "Jingyu Wang", "Dongyuan Shi", "Ping Wang"], "Categories": "cs.LG cs.CR"}, "abstract": "Measurement uncertainties, represented by cyber-attacks and data losses, seriously degrade the quality of power system measurements. Fortunately, the powerful generation ability of the denoising diffusion models can enable more precise measurement generation for power system data recovery. However, the controllable data generation and efficient computing methods of denoising diffusion models for deterministic trajectory still need further investigation. To this end, this paper proposes an improved two-stage denoising diffusion model (TSDM) to identify and reconstruct the measurements with various measurement uncertainties. The first stage of the model comprises a classifier-guided conditional anomaly detection component, while the second stage involves diffusion-based measurement imputation component. Moreover, the proposed TSDM adopts precise means and optimal variances to accelerate the diffusion generation process with subsequence sampling. Extensive numerical case studies demonstrate that the proposed TSDM can accurately recover power system measurements despite strong randomness under renewable energy integration and highly nonlinear dynamics under complex cyber-physical contingencies. Additionally, the proposed TSDM has stronger robustness compared to existing reconstruction networks and exhibits lower computational complexity than general denoising diffusion models.", "url": "https://arxiv.org/abs/2312.04346"}, {"metadata": {"arXiv": "2312.04404", "Date": "Thu, 07 Dec 2023 16:17:34 ", "Title": "On the Impact of Multi-dimensional Local Differential Privacy on Fairness", "Authors": ["karima Makhlouf", "Heber H. Arcolezi", "Sami Zhioua", "Ghassen Ben Brahim", "and Catuscia Palamidessi"], "Categories": "cs.LG cs.CR cs.CY"}, "abstract": "Automated decision systems are increasingly used to make consequential decisions in people's lives. Due to the sensitivity of the manipulated data as well as the resulting decisions, several ethical concerns need to be addressed for the appropriate use of such technologies, in particular, fairness and privacy. Unlike previous work, which focused on centralized differential privacy (DP) or local DP (LDP) for a single sensitive attribute, in this paper, we examine the impact of LDP in the presence of several sensitive attributes (i.e., multi-dimensional data) on fairness. Detailed empirical analysis on synthetic and benchmark datasets revealed very relevant observations. In particular, (1) multi-dimensional LDP is an efficient approach to reduce disparity, (2) the multi-dimensional approach of LDP (independent vs. combined) matters only at low privacy guarantees, and (3) the outcome Y distribution has an important effect on which group is more sensitive to the obfuscation. Last, we summarize our findings in the form of recommendations to guide practitioners in adopting effective privacy-preserving practices while maintaining fairness and utility in ML applications.", "url": "https://arxiv.org/abs/2312.04404"}, {"metadata": {"arXiv": "2312.04416", "Date": "Thu, 07 Dec 2023 16:38:20 ", "Title": "Monitoring Sustainable Global Development Along Shared Socioeconomic Pathways", "Authors": ["Michelle W.L. Wan", "Jeffrey N. Clark", "Edward A. Small", "Elena Fillola Mayoral", "Ra\\'ul Santos-Rodr\\'iguez"], "Categories": "cs.LG cs.CY", "Comments": ["5 pages", "1 figure. Presented at NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning"]}, "abstract": "Sustainable global development is one of the most prevalent challenges facing the world today, hinging on the equilibrium between socioeconomic growth and environmental sustainability. We propose approaches to monitor and quantify sustainable development along the Shared Socioeconomic Pathways (SSPs), including mathematically derived scoring algorithms, and machine learning methods. These integrate socioeconomic and environmental datasets, to produce an interpretable metric for SSP alignment. An initial study demonstrates promising results, laying the groundwork for the application of different methods to the monitoring of sustainable global development.", "url": "https://arxiv.org/abs/2312.04416"}, {"metadata": {"arXiv": "2312.04464", "Date": "Thu, 07 Dec 2023 17:35:34 ", "Title": "Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation", "Authors": ["Jiayi Huang", "Han Zhong", "Liwei Wang", "Lin F. Yang"], "Categories": "cs.LG stat.ML"}, "abstract": "To tackle long planning horizon problems in reinforcement learning with general function approximation, we propose the first algorithm, termed as UCRL-WVTR, that achieves both \\emph{horizon-free} and \\emph{instance-dependent}, since it eliminates the polynomial dependency on the planning horizon. The derived regret bound is deemed \\emph{sharp}, as it matches the minimax lower bound when specialized to linear mixture MDPs up to logarithmic factors. Furthermore, UCRL-WVTR is \\emph{computationally efficient} with access to a regression oracle. The achievement of such a horizon-free, instance-dependent, and sharp regret bound hinges upon (i) novel algorithm designs: weighted value-targeted regression and a high-order moment estimator in the context of general function approximation; and (ii) fine-grained analyses: a novel concentration bound of weighted non-linear least squares and a refined analysis which leads to the tight instance-dependent bound. We also conduct comprehensive experiments to corroborate our theoretical findings.", "url": "https://arxiv.org/abs/2312.04464"}, {"metadata": {"arXiv": "2312.04469", "Date": "Thu, 07 Dec 2023 17:41:44 ", "Title": "On the Learnability of Watermarks for Language Models", "Authors": ["Chenchen Gu", "Xiang Lisa Li", "Percy Liang", "Tatsunori Hashimoto"], "Categories": "cs.LG cs.CL cs.CR"}, "abstract": "Watermarking of language model outputs enables statistical detection of model-generated text, which has many applications in the responsible deployment of language models. Existing watermarking strategies operate by altering the decoder of an existing language model, and the ability for a language model to directly learn to generate the watermark would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, allowing for open models to benefit from watermarking. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three distinct decoding-based watermarking strategies and various hyperparameter settings, finding that models can learn to generate watermarked text with high detectability. We also find limitations to learnability, including the loss of watermarking capabilities under fine-tuning on normal text and high sample complexity when learning low-distortion watermarks.", "url": "https://arxiv.org/abs/2312.04469"}, {"metadata": {"arXiv": "2312.04535", "Date": "Thu, 07 Dec 2023 18:53:27 ", "Title": "Trajeglish: Learning the Language of Driving Scenarios", "Authors": ["Jonah Philion", "Xue Bin Peng", "Sanja Fidler"], "Categories": "cs.LG cs.RO", "Comments": ["Preprint"]}, "abstract": "A longstanding challenge for self-driving development is simulating dynamic driving scenarios seeded from recorded driving logs. In pursuit of this functionality, we apply tools from discrete sequence modeling to model how vehicles, pedestrians and cyclists interact in driving scenarios. Using a simple data-driven tokenization scheme, we discretize trajectories to centimeter-level resolution using a small vocabulary. We then model the multi-agent sequence of motion tokens with a GPT-like encoder-decoder that is autoregressive in time and takes into account intra-timestep interaction between agents. Scenarios sampled from our model exhibit state-of-the-art realism; our model tops the Waymo Sim Agents Benchmark, surpassing prior work along the realism meta metric by 3.3% and along the interaction metric by 9.9%. We ablate our modeling choices in full autonomy and partial autonomy settings, and show that the representations learned by our model can quickly be adapted to improve performance on nuScenes. We additionally evaluate the scalability of our model with respect to parameter count and dataset size, and use density estimates from our model to quantify the saliency of context length and intra-timestep interaction for the traffic modeling task.", "url": "https://arxiv.org/abs/2312.04535"}, {"metadata": {"arXiv": "2312.04402", "Date": "Thu, 07 Dec 2023 16:16:47 ", "Title": "Semi-Supervised Active Learning for Semantic Segmentation in Unknown Environments Using Informative Path Planning", "Authors": ["Julius R\\\"uckin", "Federico Magistri", "Cyrill Stachniss", "Marija Popovi\\'c"], "Categories": "cs.RO cs.LG", "Comments": ["8 pages", "9 figures"]}, "abstract": "Semantic segmentation enables robots to perceive and reason about their environments beyond geometry. Most of such systems build upon deep learning approaches. As autonomous robots are commonly deployed in initially unknown environments, pre-training on static datasets cannot always capture the variety of domains and limits the robot's perception performance during missions. Recently, self-supervised and fully supervised active learning methods emerged to improve a robot's vision. These approaches rely on large in-domain pre-training datasets or require substantial human labelling effort. We propose a planning method for semi-supervised active learning of semantic segmentation that substantially reduces human labelling requirements compared to fully supervised approaches. We leverage an adaptive map-based planner guided towards the frontiers of unexplored space with high model uncertainty collecting training data for human labelling. A key aspect of our approach is to combine the sparse high-quality human labels with pseudo labels automatically extracted from highly certain environment map areas. Experimental results show that our method reaches segmentation performance close to fully supervised approaches with drastically reduced human labelling effort while outperforming self-supervised approaches.", "url": "https://arxiv.org/abs/2312.04402"}, {"metadata": {"arXiv": "2312.04533", "Date": "Thu, 07 Dec 2023 18:51:19 ", "Title": "Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language Models", "Authors": ["Ivan Kapelyukh", "Yifei Ren", "Ignacio Alzugaray", "Edward Johns"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project webpage with videos: https://www.robot-learning.uk/dream2real"]}, "abstract": "We introduce Dream2Real, a robotics framework which integrates vision-language models (VLMs) trained on 2D data into a 3D object rearrangement pipeline. This is achieved by the robot autonomously constructing a 3D representation of the scene, where objects can be rearranged virtually and an image of the resulting arrangement rendered. These renders are evaluated by a VLM, so that the arrangement which best satisfies the user instruction is selected and recreated in the real world with pick-and-place. This enables language-conditioned rearrangement to be performed zero-shot, without needing to collect a training dataset of example arrangements. Results on a series of real-world tasks show that this framework is robust to distractors, controllable by language, capable of understanding complex multi-object relations, and readily applicable to both tabletop and 6-DoF rearrangement tasks.", "url": "https://arxiv.org/abs/2312.04533"}, {"metadata": {"arXiv": "2312.03758", "Date": "Mon, 04 Dec 2023 22:27:43 ", "Title": "Stock Movement and Volatility Prediction from Tweets, Macroeconomic Factors and Historical Prices", "Authors": ["Shengkun Wang", "YangXiao Bai", "Taoran Ji", "Kaiqun Fu", "Linhan Wang", "Chang-Tien Lu"], "Categories": "cs.AI cs.CL"}, "abstract": "Predicting stock market is vital for investors and policymakers, acting as a barometer of the economic health. We leverage social media data, a potent source of public sentiment, in tandem with macroeconomic indicators as government-compiled statistics, to refine stock market predictions. However, prior research using tweet data for stock market prediction faces three challenges. First, the quality of tweets varies widely. While many are filled with noise and irrelevant details, only a few genuinely mirror the actual market scenario. Second, solely focusing on the historical data of a particular stock without considering its sector can lead to oversight. Stocks within the same industry often exhibit correlated price behaviors. Lastly, simply forecasting the direction of price movement without assessing its magnitude is of limited value, as the extent of the rise or fall truly determines profitability. In this paper, diverging from the conventional methods, we pioneer an ECON. The framework has following advantages: First, ECON has an adept tweets filter that efficiently extracts and decodes the vast array of tweet data. Second, ECON discerns multi-level relationships among stocks, sectors, and macroeconomic factors through a self-aware mechanism in semantic space. Third, ECON offers enhanced accuracy in predicting substantial stock price fluctuations by capitalizing on stock price movement. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility.", "url": "https://arxiv.org/abs/2312.03758"}, {"metadata": {"arXiv": "2312.04134", "Date": "Thu, 07 Dec 2023 08:48:54 ", "Title": "Using a Large Language Model to generate a Design Structure Matrix", "Authors": ["Edwin C. Y. Koh"], "Categories": "cs.AI cs.CL", "Comments": ["16 pages", "7 Figures", "6 Tables"]}, "abstract": "The Design Structure Matrix (DSM) is an established method used in dependency modelling, especially in the design of complex engineering systems. The generation of DSM is traditionally carried out through manual means and can involve interviewing experts to elicit critical system elements and the relationships between them. Such manual approaches can be time-consuming and costly. This paper presents a workflow that uses a Large Language Model (LLM) to support the generation of DSM and improve productivity. A prototype of the workflow was developed in this work and applied on a diesel engine DSM published previously. It was found that the prototype could reproduce 357 out of 462 DSM entries published (i.e. 77.3%), suggesting that the work can aid DSM generation. A no-code version of the prototype is made available online to support future research.", "url": "https://arxiv.org/abs/2312.04134"}, {"metadata": {"arXiv": "2312.04180", "Date": "Thu, 07 Dec 2023 10:06:34 ", "Title": "AI and Jobs: Has the Inflection Point Arrived? Evidence from an Online Labor Platform", "Authors": ["Dandan Qiao", "Huaxia Rui", "and Qian Xiong"], "Categories": "cs.AI cs.CY econ.GN q-fin.EC", "Comments": ["42 pages", "6 figures", "9 tables"], "ACM-class": "J.4"}, "abstract": "Artificial intelligence (AI) refers to the ability of machines or software to mimic or even surpass human intelligence in a given cognitive task. While humans learn by both induction and deduction, the success of current AI is rooted in induction, relying on its ability to detect statistical regularities in task input -- an ability learnt from a vast amount of training data using enormous computation resources. We examine the performance of such a statistical AI in a human task through the lens of four factors, including task learnability, statistical resource, computation resource, and learning techniques, and then propose a three-phase visual framework to understand the evolving relation between AI and jobs. Based on this conceptual framework, we develop a simple economic model of competition to show the existence of an inflection point for each occupation. Before AI performance crosses the inflection point, human workers always benefit from an improvement in AI performance, but after the inflection point, human workers become worse off whenever such an improvement occurs. To offer empirical evidence, we first argue that AI performance has passed the inflection point for the occupation of translation but not for the occupation of web development. We then study how the launch of ChatGPT, which led to significant improvement of AI performance on many tasks, has affected workers in these two occupations on a large online labor platform. Consistent with the inflection point conjecture, we find that translators are negatively affected by the shock both in terms of the number of accepted jobs and the earnings from those jobs, while web developers are positively affected by the very same shock. Given the potentially large disruption of AI on employment, more studies on more occupations using data from different platforms are urgently needed.", "url": "https://arxiv.org/abs/2312.04180"}, {"metadata": {"arXiv": "2312.04210", "Date": "Thu, 07 Dec 2023 10:52:16 ", "Title": "Constraint Model for the Satellite Image Mosaic Selection Problem", "Authors": ["Manuel Combarro Sim\\'on", "Pierre Talbot", "Gr\\'egoire Danoy", "Jedrzej Musial", "Mohammed Alswaitti", "and Pascal Bouvry"], "Categories": "cs.AI cs.CG cs.CV eess.IV", "Comments": ["This paper contains minor corrections from the original document presented at the 29th International Conference on Principles and Practice of Constraint Programming (CP 2023). Minor corrections in Figures 5a and 5b that do not affect the analysis result. Minor typo corrections in Appendix A"], "Journal-ref": "In 29th International Conference on Principles and Practice of Constraint Programming. Leibniz International Proceedings in Informatics (LIPIcs), Volume 280, pp. 44:1-44:15, Schloss Dagstuhl - Leibniz-Zentrum f\\\"ur Informatik (2023)", "DOI": "10.4230/LIPIcs.CP.2023.44"}, "abstract": "Satellite imagery solutions are widely used to study and monitor different regions of the Earth. However, a single satellite image can cover only a limited area. In cases where a larger area of interest is studied, several images must be stitched together to create a single larger image, called a mosaic, that can cover the area. Today, with the increasing number of satellite images available for commercial use, selecting the images to build the mosaic is challenging, especially when the user wants to optimize one or more parameters, such as the total cost and the cloud coverage percentage in the mosaic. More precisely, for this problem the input is an area of interest, several satellite images intersecting the area, a list of requirements relative to the image and the mosaic, such as cloud coverage percentage, image resolution, and a list of objectives to optimize. We contribute to the constraint and mixed integer lineal programming formulation of this new problem, which we call the \\textit{satellite image mosaic selection problem}, which is a multi-objective extension of the polygon cover problem. We propose a dataset of realistic and challenging instances, where the images were captured by the satellite constellations SPOT, Pl\\'eiades and Pl\\'eiades Neo. We evaluate and compare the two proposed models and show their efficiency for large instances, up to 200 images.", "url": "https://arxiv.org/abs/2312.04210"}, {"metadata": {"arXiv": "2312.04249", "Date": "Thu, 07 Dec 2023 12:11:25 ", "Title": "Extending Answer Set Programming with Rational Numbers", "Authors": ["Francesco Pacenza and Jessica Zangari"], "Categories": "cs.AI cs.LO cs.PL cs.SE", "ACM-class": "D.1.6; D.3.1; D.3.3; I.2.4; I.2.5"}, "abstract": "Answer Set Programming (ASP) is a widely used declarative programming paradigm that has shown great potential in solving complex computational problems. However, the inability to natively support non-integer arithmetic has been highlighted as a major drawback in real-world applications. This feature is crucial to accurately model and manage real-world data and information as emerged in various contexts, such as the smooth movement of video game characters, the 3D movement of mechanical arms, and data streamed by sensors. Nevertheless, extending ASP in this direction, without affecting its declarative nature and its well-defined semantics, poses non-trivial challenges; thus, no ASP system is able to reason natively with non-integer domains. Indeed, the widespread floating-point arithmetic is not applicable to the ASP case, as the reproducibility of results cannot be guaranteed and the semantics of an ASP program would not be uniquely and declaratively determined, regardless of the employed machine or solver. To overcome such limitations and in the realm of pure ASP, this paper proposes an extension of ASP in which non-integers are approximated to rational numbers, fully granting reproducibility and declarativity. We provide a well-defined semantics for the ASP-Core-2 standard extended with rational numbers and an implementation thereof. We hope this work could serve as a stepping stone towards a more expressive and versatile ASP language that can handle a broader range of real-world problems.", "url": "https://arxiv.org/abs/2312.04249"}, {"metadata": {"arXiv": "2312.04379", "Date": "Thu, 07 Dec 2023 15:49:39 ", "Title": "How much informative is your XAI? A decision-making assessment task to objectively measure the goodness of explanations", "Authors": ["Marco Matarese", "Francesco Rea", "Alessandra Sciutti"], "Categories": "cs.AI cs.HC cs.RO"}, "abstract": "There is an increasing consensus about the effectiveness of user-centred approaches in the explainable artificial intelligence (XAI) field. Indeed, the number and complexity of personalised and user-centred approaches to XAI have rapidly grown in recent years. Often, these works have a two-fold objective: (1) proposing novel XAI techniques able to consider the users and (2) assessing the \\textit{goodness} of such techniques with respect to others. From these new works, it emerged that user-centred approaches to XAI positively affect the interaction between users and systems. However, so far, the goodness of XAI systems has been measured through indirect measures, such as performance. In this paper, we propose an assessment task to objectively and quantitatively measure the goodness of XAI systems in terms of their \\textit{information power}, which we intended as the amount of information the system provides to the users during the interaction. Moreover, we plan to use our task to objectively compare two XAI techniques in a human-robot decision-making task to understand deeper whether user-centred approaches are more informative than classical ones.", "url": "https://arxiv.org/abs/2312.04379"}, {"metadata": {"arXiv": "2312.04423", "Date": "Thu, 07 Dec 2023 16:48:32 ", "Title": "Scalable Knowledge Graph Construction and Inference on Human Genome Variants", "Authors": ["Shivika Prasanna", "Deepthi Rao", "Eduardo Simoes", "Praveen Rao"], "Categories": "cs.AI cs.DB q-bio.QM"}, "abstract": "Real-world knowledge can be represented as a graph consisting of entities and relationships between the entities. The need for efficient and scalable solutions arises when dealing with vast genomic data, like RNA-sequencing. Knowledge graphs offer a powerful approach for various tasks in such large-scale genomic data, such as analysis and inference. In this work, variant-level information extracted from the RNA-sequences of vaccine-na\\\"ive COVID-19 patients have been represented as a unified, large knowledge graph. Variant call format (VCF) files containing the variant-level information were annotated to include further information for each variant. The data records in the annotated files were then converted to Resource Description Framework (RDF) triples. Each VCF file obtained had an associated CADD scores file that contained the raw and Phred-scaled scores for each variant. An ontology was defined for the VCF and CADD scores files. Using this ontology and the extracted information, a large, scalable knowledge graph was created. Available graph storage was then leveraged to query and create datasets for further downstream tasks. We also present a case study using the knowledge graph and perform a classification task using graph machine learning. We also draw comparisons between different Graph Neural Networks (GNNs) for the case study.", "url": "https://arxiv.org/abs/2312.04423"}, {"metadata": {"arXiv": "2312.03767", "Date": "Tue, 05 Dec 2023 20:07:51 ", "Title": "Unknown Sample Discovery for Source Free Open Set Domain Adaptation", "Authors": ["Chowdhury Sadman Jahan and Andreas Savakis"], "Categories": "cs.CV cs.AI"}, "abstract": "Open Set Domain Adaptation (OSDA) aims to adapt a model trained on a source domain to a target domain that undergoes distribution shift and contains samples from novel classes outside the source domain. Source-free OSDA (SF-OSDA) techniques eliminate the need to access source domain samples, but current SF-OSDA methods utilize only the known classes in the target domain for adaptation, and require access to the entire target domain even during inference after adaptation, to make the distinction between known and unknown samples. In this paper, we introduce Unknown Sample Discovery (USD) as an SF-OSDA method that utilizes a temporally ensembled teacher model to conduct known-unknown target sample separation and adapts the student model to the target domain over all classes using co-training and temporal consistency between the teacher and the student. USD promotes Jensen-Shannon distance (JSD) as an effective measure for known-unknown sample separation. Our teacher-student framework significantly reduces error accumulation resulting from imperfect known-unknown sample separation, while curriculum guidance helps to reliably learn the distinction between target known and target unknown subspaces. USD appends the target model with an unknown class node, thus readily classifying a target sample into any of the known or unknown classes in subsequent post-adaptation inference stages. Empirical results show that USD is superior to existing SF-OSDA methods and is competitive with current OSDA models that utilize both source and target domains during adaptation.", "url": "https://arxiv.org/abs/2312.03767"}, {"metadata": {"arXiv": "2312.03781", "Date": "Wed, 06 Dec 2023 09:39:38 ", "Title": "Lite-Mind: Towards Efficient and Versatile Brain Representation Network", "Authors": ["Zixuan Gong", "Qi Zhang", "Duoqian Miao", "Guangyin Bao", "Liang Hu"], "Categories": "cs.CV cs.AI"}, "abstract": "Research in decoding visual information from the brain, particularly through the non-invasive fMRI method, is rapidly progressing. The challenge arises from the limited data availability and the low signal-to-noise ratio of fMRI signals, leading to a low-precision task of fMRI-to-image retrieval. State-of-the-art MindEye remarkably improves fMRI-to-image retrieval performance by leveraging a deep MLP with a high parameter count orders of magnitude, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to the final hidden layer of CLIP's vision transformer. However, significant individual variations exist among subjects, even within identical experimental setups, mandating the training of subject-specific models. The substantial parameters pose significant challenges in deploying fMRI decoding on practical devices, especially with the necessitating of specific models for each subject. To this end, we propose Lite-Mind, a lightweight, efficient, and versatile brain representation network based on discrete Fourier transform, that efficiently aligns fMRI voxels to fine-grained information of CLIP. Our experiments demonstrate that Lite-Mind achieves an impressive 94.3% fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7% fewer parameters than MindEye. Lite-Mind is also proven to be able to be migrated to smaller brain datasets and establishes a new state-of-the-art for zero-shot classification on the GOD dataset. The code is available at https://github.com/gongzix/Lite-Mind.", "url": "https://arxiv.org/abs/2312.03781"}, {"metadata": {"arXiv": "2312.03799", "Date": "Wed, 06 Dec 2023 14:58:03 ", "Title": "Low-power, Continuous Remote Behavioral Localization with Event Cameras", "Authors": ["Friedhelm Hamann", "Suman Ghosh", "Ignacio Juarez Martinez", "Tom Hart", "Alex Kacelnik", "Guillermo Gallego"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "7 figures", "11 tables", "Project page: https://tub-rip.github.io/eventpenguins/"]}, "abstract": "Researchers in natural science need reliable methods for quantifying animal behavior. Recently, numerous computer vision methods emerged to automate the process. However, observing wild species at remote locations remains a challenging task due to difficult lighting conditions and constraints on power supply and data storage. Event cameras offer unique advantages for battery-dependent remote monitoring due to their low power consumption and high dynamic range capabilities. We use this novel sensor to quantify a behavior in Chinstrap penguins called ecstatic display. We formulate the problem as a temporal action detection task, determining the start and end times of the behavior. For this purpose, we recorded a colony of breeding penguins in Antarctica during several weeks and labeled event data on 16 nests. The developed method consists of a generator of candidate time intervals (proposals) and a classifier of the actions within them. The experiments show that the event cameras' natural response to motion is effective for continuous behavior monitoring and detection, reaching a mean average precision (mAP) of 58% (which increases to 63% in good weather conditions). The results also demonstrate the robustness against various lighting conditions contained in the challenging dataset. The low-power capabilities of the event camera allows to record three times longer than with a conventional camera. This work pioneers the use of event cameras for remote wildlife observation, opening new interdisciplinary opportunities. https://tub-rip.github.io/eventpenguins/", "url": "https://arxiv.org/abs/2312.03799"}, {"metadata": {"arXiv": "2312.03970", "Date": "Thu, 07 Dec 2023 01:01:45 ", "Title": "Improving Medical Report Generation with Adapter Tuning and Knowledge Enhancement in Vision-Language Foundation Models", "Authors": ["Shibin Wu", "Bang Yang", "Zhiyu Ye", "Haoqian Wang", "Hairong Zheng", "Tong Zhang"], "Categories": "cs.CV cs.AI cs.CE"}, "abstract": "Medical report generation demands automatic creation of coherent and precise descriptions for medical images. However, the scarcity of labelled medical image-report pairs poses formidable challenges in developing large-scale neural networks capable of harnessing the potential of artificial intelligence, exemplified by large language models. This study builds upon the state-of-the-art vision-language pre-training and fine-tuning approach, BLIP-2, to customize general large-scale foundation models. Integrating adapter tuning and a medical knowledge enhancement loss, our model significantly improves accuracy and coherence. Validation on the dataset of ImageCLEFmedical 2023 demonstrates our model's prowess, achieving the best-averaged results against several state-of-the-art methods. Significant improvements in ROUGE and CIDEr underscore our method's efficacy, highlighting promising outcomes for the rapid medical-domain adaptation of the vision-language foundation models in addressing challenges posed by data scarcity.", "url": "https://arxiv.org/abs/2312.03970"}, {"metadata": {"arXiv": "2312.03993", "Date": "Thu, 07 Dec 2023 02:21:31 ", "Title": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion", "Authors": ["Sloke Shrestha", "Sundar Sripada V. S.", "Asvin Venkataramanan"], "Categories": "cs.CV cs.AI", "Comments": ["Project report for ECE 371Q Digital Image Processing at UT Austin"]}, "abstract": "This project report summarizes our journey to perform stable diffusion fine-tuning on a dataset containing Calvin and Hobbes comics. The purpose is to convert any given input image into the comic style of Calvin and Hobbes, essentially performing style transfer. We train stable-diffusion-v1.5 using Low Rank Adaptation (LoRA) to efficiently speed up the fine-tuning process. The diffusion itself is handled by a Variational Autoencoder (VAE), which is a U-net. Our results were visually appealing for the amount of training time and the quality of input data that went into training.", "url": "https://arxiv.org/abs/2312.03993"}, {"metadata": {"arXiv": "2312.04005", "Date": "Thu, 07 Dec 2023 02:46:18 ", "Title": "KOALA: Self-Attention Matters in Knowledge Distillation of Latent Diffusion Models for Memory-Efficient and Fast Image Synthesis", "Authors": ["Youngwan Lee and Kwanyong Park and Yoorhim Cho and Yong-Ju Lee and Sung Ju Hwang"], "Categories": "cs.CV cs.AI", "Comments": ["Project page: https://youngwanlee.github.io/KOALA/"]}, "abstract": "Stable diffusion is the mainstay of the text-to-image (T2I) synthesis in the community due to its generation performance and open-source nature. Recently, Stable Diffusion XL (SDXL), the successor of stable diffusion, has received a lot of attention due to its significant performance improvements with a higher resolution of 1024x1024 and a larger model. However, its increased computation cost and model size require higher-end hardware(e.g., bigger VRAM GPU) for end-users, incurring higher costs of operation. To address this problem, in this work, we propose an efficient latent diffusion model for text-to-image synthesis obtained by distilling the knowledge of SDXL. To this end, we first perform an in-depth analysis of the denoising U-Net in SDXL, which is the main bottleneck of the model, and then design a more efficient U-Net based on the analysis. Secondly, we explore how to effectively distill the generation capability of SDXL into an efficient U-Net and eventually identify four essential factors, the core of which is that self-attention is the most important part. With our efficient U-Net and self-attention-based knowledge distillation strategy, we build our efficient T2I models, called KOALA-1B & -700M, while reducing the model size up to 54% and 69% of the original SDXL model. In particular, the KOALA-700M is more than twice as fast as SDXL while still retaining a decent generation quality. We hope that due to its balanced speed-performance tradeoff, our KOALA models can serve as a cost-effective alternative to SDXL in resource-constrained environments.", "url": "https://arxiv.org/abs/2312.04005"}, {"metadata": {"arXiv": "2312.04029", "Date": "Thu, 07 Dec 2023 03:55:20 ", "Title": "Improved Face Representation via Joint Label Classification and Supervised Contrastive Clustering", "Authors": ["Zhenduo Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages"]}, "abstract": "Face clustering tasks can learn hierarchical semantic information from large-scale data, which has the potential to help facilitate face recognition. However, there are few works on this problem. This paper explores it by proposing a joint optimization task of label classification and supervised contrastive clustering to introduce the cluster knowledge to the traditional face recognition task in two ways. We first extend ArcFace with a cluster-guided angular margin to adjust the within-class feature distribution according to the hard level of face clustering. Secondly, we propose a supervised contrastive clustering approach to pull the features to the cluster center and propose the cluster-aligning procedure to align the cluster center and the learnable class center in the classifier for joint training. Finally, extensive qualitative and quantitative experiments on popular facial benchmarks demonstrate the effectiveness of our paradigm and its superiority over the existing approaches to face recognition.", "url": "https://arxiv.org/abs/2312.04029"}, {"metadata": {"arXiv": "2312.04043", "Date": "Thu, 07 Dec 2023 05:04:33 ", "Title": "Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes", "Authors": ["Hmrishav Bandyopadhyay", "Subhadeep Koley", "Ayan Das", "Aneeshan Sain", "Pinaki Nath Chowdhury", "Tao Xiang", "Ayan Kumar Bhunia", "Yi-Zhe Song"], "Categories": "cs.CV cs.AI", "Comments": ["Project Page: https://hmrishavbandy.github.io/doodle23d/"]}, "abstract": "In this paper, we democratise 3D content creation, enabling precise generation of 3D shapes from abstract sketches while overcoming limitations tied to drawing skills. We introduce a novel part-level modelling and alignment framework that facilitates abstraction modelling and cross-modal correspondence. Leveraging the same part-level decoder, our approach seamlessly extends to sketch modelling by establishing correspondence between CLIPasso edgemaps and projected 3D part regions, eliminating the need for a dataset pairing human sketches and 3D shapes. Additionally, our method introduces a seamless in-position editing process as a byproduct of cross-modal part-aligned modelling. Operating in a low-dimensional implicit space, our approach significantly reduces computational demands and processing time.", "url": "https://arxiv.org/abs/2312.04043"}, {"metadata": {"arXiv": "2312.04087", "Date": "Thu, 07 Dec 2023 06:53:55 ", "Title": "VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal Models", "Authors": ["Zongjie Li", "Chaozheng Wang", "Chaowei Liu", "Pingchuan Ma", "Daoyuan Wu", "Shuai Wang", "Cuiyun Gao"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages"]}, "abstract": "With recent advancements in Large Multimodal Models (LMMs) across various domains, a novel prompting method called visual referring prompting has emerged, showing significant potential in enhancing human-computer interaction within multimodal systems. This method offers a more natural and flexible approach to human interaction with these systems compared to traditional text descriptions or coordinates. However, the categorization of visual referring prompting remains undefined, and its impact on the performance of LMMs has yet to be formally examined. In this study, we conduct the first comprehensive analysis of LMMs using a variety of visual referring prompting strategies. We introduce a benchmark dataset called VRPTEST, comprising 3 different visual tasks and 2,275 images, spanning diverse combinations of prompt strategies. Using VRPTEST, we conduct a comprehensive evaluation of eight versions of prominent open-source and proprietary foundation models, including two early versions of GPT-4V. We develop an automated assessment framework based on software metamorphic testing techniques to evaluate the accuracy of LMMs without the need for human intervention or manual labeling. We find that the current proprietary models generally outperform the open-source ones, showing an average accuracy improvement of 22.70%; however, there is still potential for improvement. Moreover, our quantitative analysis shows that the choice of prompt strategy significantly affects the accuracy of LMMs, with variations ranging from -17.5% to +7.3%. Further case studies indicate that an appropriate visual referring prompting strategy can improve LMMs' understanding of context and location information, while an unsuitable one might lead to answer rejection. We also provide insights on minimizing the negative impact of visual referring prompting on LMMs.", "url": "https://arxiv.org/abs/2312.04087"}, {"metadata": {"arXiv": "2312.04189", "Date": "Thu, 07 Dec 2023 10:16:21 ", "Title": "Joint-Individual Fusion Structure with Fusion Attention Module for Multi-Modal Skin Cancer Classification", "Authors": ["Peng Tang", "Xintong Yan", "Yang Nan", "Xiaobin Hu", "Xiaobin Hu", "Bjoern H Menzee.Sebastian Krammer", "Tobias Lasser"], "Categories": "cs.CV cs.AI", "Comments": ["submitted to Pattern Recognition journal before 2022"]}, "abstract": "Most convolutional neural network (CNN) based methods for skin cancer classification obtain their results using only dermatological images. Although good classification results have been shown, more accurate results can be achieved by considering the patient's metadata, which is valuable clinical information for dermatologists. Current methods only use the simple joint fusion structure (FS) and fusion modules (FMs) for the multi-modal classification methods, there still is room to increase the accuracy by exploring more advanced FS and FM. Therefore, in this paper, we design a new fusion method that combines dermatological images (dermoscopy images or clinical images) and patient metadata for skin cancer classification from the perspectives of FS and FM. First, we propose a joint-individual fusion (JIF) structure that learns the shared features of multi-modality data and preserves specific features simultaneously. Second, we introduce a fusion attention (FA) module that enhances the most relevant image and metadata features based on both the self and mutual attention mechanism to support the decision-making pipeline. We compare the proposed JIF-MMFA method with other state-of-the-art fusion methods on three different public datasets. The results show that our JIF-MMFA method improves the classification results for all tested CNN backbones and performs better than the other fusion methods on the three public datasets, demonstrating our method's effectiveness and robustness", "url": "https://arxiv.org/abs/2312.04189"}, {"metadata": {"arXiv": "2312.04231", "Date": "Thu, 07 Dec 2023 11:31:20 ", "Title": "Adventures of Trustworthy Vision-Language Models: A Survey", "Authors": ["Mayank Vatsa", "Anubhooti Jain", "Richa Singh"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in AAAI 2024"]}, "abstract": "Recently, transformers have become incredibly popular in computer vision and vision-language tasks. This notable rise in their usage can be primarily attributed to the capabilities offered by attention mechanisms and the outstanding ability of transformers to adapt and apply themselves to a variety of tasks and domains. Their versatility and state-of-the-art performance have established them as indispensable tools for a wide array of applications. However, in the constantly changing landscape of machine learning, the assurance of the trustworthiness of transformers holds utmost importance. This paper conducts a thorough examination of vision-language transformers, employing three fundamental principles of responsible AI: Bias, Robustness, and Interpretability. The primary objective of this paper is to delve into the intricacies and complexities associated with the practical use of transformers, with the overarching goal of advancing our comprehension of how to enhance their reliability and accountability.", "url": "https://arxiv.org/abs/2312.04231"}, {"metadata": {"arXiv": "2312.04236", "Date": "Thu, 07 Dec 2023 11:41:26 ", "Title": "Detecting and Restoring Non-Standard Hands in Stable Diffusion Generated Images", "Authors": ["Yiqun Zhang", "Zhenyue Qin", "Yang Liu", "Dylan Campbell"], "Categories": "cs.CV cs.AI"}, "abstract": "We introduce a pipeline to address anatomical inaccuracies in Stable Diffusion generated hand images. The initial step involves constructing a specialized dataset, focusing on hand anomalies, to train our models effectively. A finetuned detection model is pivotal for precise identification of these anomalies, ensuring targeted correction. Body pose estimation aids in understanding hand orientation and positioning, crucial for accurate anomaly correction. The integration of ControlNet and InstructPix2Pix facilitates sophisticated inpainting and pixel-level transformation, respectively. This dual approach allows for high-fidelity image adjustments. This comprehensive approach ensures the generation of images with anatomically accurate hands, closely resembling real-world appearances. Our experimental results demonstrate the pipeline's efficacy in enhancing hand image realism in Stable Diffusion outputs. We provide an online demo at https://fixhand.yiqun.io", "url": "https://arxiv.org/abs/2312.04236"}, {"metadata": {"arXiv": "2312.04479", "Date": "Thu, 07 Dec 2023 17:53:02 ", "Title": "GSGFormer: Generative Social Graph Transformer for Multimodal Pedestrian Trajectory Prediction", "Authors": ["Zhongchang Luo", "Marion Robin and Pavan Vasishta"], "Categories": "cs.CV cs.AI"}, "abstract": "Pedestrian trajectory prediction, vital for selfdriving cars and socially-aware robots, is complicated due to intricate interactions between pedestrians, their environment, and other Vulnerable Road Users. This paper presents GSGFormer, an innovative generative model adept at predicting pedestrian trajectories by considering these complex interactions and offering a plethora of potential modal behaviors. We incorporate a heterogeneous graph neural network to capture interactions between pedestrians, semantic maps, and potential destinations. The Transformer module extracts temporal features, while our novel CVAE-Residual-GMM module promotes diverse behavioral modality generation. Through evaluations on multiple public datasets, GSGFormer not only outperforms leading methods with ample data but also remains competitive when data is limited.", "url": "https://arxiv.org/abs/2312.04479"}, {"metadata": {"arXiv": "2312.04560", "Date": "Thu, 07 Dec 2023 18:59:41 ", "Title": "NeRFiller: Completing Scenes via Generative 3D Inpainting", "Authors": ["Ethan Weber and Aleksander Ho{\\l}y\\'nski and Varun Jampani and Saurabh Saxena and Noah Snavely and Abhishek Kar and Angjoo Kanazawa"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Project page: https://ethanweber.me/nerfiller"]}, "abstract": "We propose NeRFiller, an approach that completes missing portions of a 3D capture via generative 3D inpainting using off-the-shelf 2D visual generative models. Often parts of a captured 3D scene or object are missing due to mesh reconstruction failures or a lack of observations (e.g., contact regions, such as the bottom of objects, or hard-to-reach areas). We approach this challenging 3D inpainting problem by leveraging a 2D inpainting diffusion model. We identify a surprising behavior of these models, where they generate more 3D consistent inpaints when images form a 2$\\times$2 grid, and show how to generalize this behavior to more than four images. We then present an iterative framework to distill these inpainted regions into a single consistent 3D scene. In contrast to related works, we focus on completing scenes rather than deleting foreground objects, and our approach does not require tight 2D object masks or text. We compare our approach to relevant baselines adapted to our setting on a variety of scenes, where NeRFiller creates the most 3D consistent and plausible scene completions. Our project page is at https://ethanweber.me/nerfiller.", "url": "https://arxiv.org/abs/2312.04560"}, {"metadata": {"arXiv": "2312.04417", "Date": "Thu, 07 Dec 2023 16:38:32 ", "Title": "Temporal Fairness in Multiwinner Voting", "Authors": ["Edith Elkind", "Svetlana Obratzsova", "Nicholas Teh"], "Categories": "cs.GT cs.AI econ.TH", "Comments": ["Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI)", "2024"]}, "abstract": "Multiwinner voting captures a wide variety of settings, from parliamentary elections in democratic systems to product placement in online shopping platforms. There is a large body of work dealing with axiomatic characterizations, computational complexity, and algorithmic analysis of multiwinner voting rules. Although many challenges remain, significant progress has been made in showing existence of fair and representative outcomes as well as efficient algorithmic solutions for many commonly studied settings. However, much of this work focuses on single-shot elections, even though in numerous real-world settings elections are held periodically and repeatedly. Hence, it is imperative to extend the study of multiwinner voting to temporal settings. Recently, there have been several efforts to address this challenge. However, these works are difficult to compare, as they model multi-period voting in very different ways. We propose a unified framework for studying temporal fairness in this domain, drawing connections with various existing bodies of work, and consolidating them within a general framework. We also identify gaps in existing literature, outline multiple opportunities for future work, and put forward a vision for the future of multiwinner voting in temporal settings.", "url": "https://arxiv.org/abs/2312.04417"}, {"metadata": {"arXiv": "2312.04245", "Date": "Thu, 07 Dec 2023 12:02:14 ", "Title": "Mastering Complex Coordination through Attention-based Dynamic Graph", "Authors": ["Guangchong Zhou", "Zhiwei Xu", "Zeren Zhang and Guoliang Fan"], "Categories": "cs.MA cs.AI"}, "abstract": "The coordination between agents in multi-agent systems has become a popular topic in many fields. To catch the inner relationship between agents, the graph structure is combined with existing methods and improves the results. But in large-scale tasks with numerous agents, an overly complex graph would lead to a boost in computational cost and a decline in performance. Here we present DAGMIX, a novel graph-based value factorization method. Instead of a complete graph, DAGMIX generates a dynamic graph at each time step during training, on which it realizes a more interpretable and effective combining process through the attention mechanism. Experiments show that DAGMIX significantly outperforms previous SOTA methods in large-scale scenarios, as well as achieving promising results on other tasks.", "url": "https://arxiv.org/abs/2312.04245"}, {"metadata": {"arXiv": "2312.04072", "Date": "Thu, 07 Dec 2023 06:31:04 ", "Title": "Voice Recognition Robot with Real-Time Surveillance and Automation", "Authors": ["Lochan Basyal"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "16 figures"], "Journal-ref": "International Journal of Creative Research Thoughts (2018)"}, "abstract": "Voice recognition technology enables the execution of real-world operations through a single voice command. This paper introduces a voice recognition system that involves converting input voice signals into corresponding text using an Android application. The text messages are then transmitted through Bluetooth connectivity, serving as a communication platform. Simultaneously, a controller circuit, equipped with a Bluetooth module, receives the text signal and, following a coding mechanism, executes real-world operations. The paper extends the application of voice recognition to real-time surveillance and automation, incorporating obstacle detection and avoidance mechanisms, as well as control over lighting and horn functions through predefined voice commands. The proposed technique not only serves as an assistive tool for individuals with disabilities but also finds utility in industrial automation, enabling robots to perform specific tasks with precision.", "url": "https://arxiv.org/abs/2312.04072"}, {"metadata": {"arXiv": "2312.04316", "Date": "Thu, 07 Dec 2023 14:17:17 ", "Title": "Towards Knowledge-driven Autonomous Driving", "Authors": ["Xin Li", "Yeqi Bai", "Pinlong Cai", "Licheng Wen", "Daocheng Fu", "Bo Zhang", "Xuemeng Yang", "Xinyu Cai", "Tao Ma", "Jianfei Guo", "Xing Gao", "Min Dou", "Botian Shi", "Yong Liu", "Liang He", "Yu Qiao"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "This paper explores the emerging knowledge-driven autonomous driving technologies. Our investigation highlights the limitations of current autonomous driving systems, in particular their sensitivity to data bias, difficulty in handling long-tail scenarios, and lack of interpretability. Conversely, knowledge-driven methods with the abilities of cognition, generalization and life-long learning emerge as a promising way to overcome these challenges. This paper delves into the essence of knowledge-driven autonomous driving and examines its core components: dataset \\& benchmark, environment, and driver agent. By leveraging large language models, world models, neural rendering, and other advanced artificial intelligence techniques, these components collectively contribute to a more holistic, adaptive, and intelligent autonomous driving system. The paper systematically organizes and reviews previous research efforts in this area, and provides insights and guidance for future research and practical applications of autonomous driving. We will continually share the latest updates on cutting-edge developments in knowledge-driven autonomous driving along with the relevant valuable open-source resources at: \\url{https://github.com/PJLab-ADG/awesome-knowledge-driven-AD}.", "url": "https://arxiv.org/abs/2312.04316"}, {"metadata": {"arXiv": "2312.04030", "Date": "Thu, 07 Dec 2023 03:55:51 ", "Title": "Modeling Boundedly Rational Agents with Latent Inference Budgets", "Authors": ["Athul Paul Jacob", "Abhishek Gupta", "Jacob Andreas"], "Categories": "cs.AI cs.LG"}, "abstract": "We study the problem of modeling a population of agents pursuing unknown goals subject to unknown computational constraints. In standard models of bounded rationality, sub-optimal decision-making is simulated by adding homoscedastic noise to optimal decisions rather than explicitly simulating constrained inference. In this work, we introduce a latent inference budget model (L-IBM) that models agents' computational constraints explicitly, via a latent variable (inferred jointly with a model of agents' goals) that controls the runtime of an iterative inference algorithm. L-IBMs make it possible to learn agent models using data from diverse populations of suboptimal actors. In three modeling tasks -- inferring navigation goals from routes, inferring communicative intents from human utterances, and predicting next moves in human chess games -- we show that L-IBMs match or outperform Boltzmann models of decision-making under uncertainty. Inferred inference budgets are themselves meaningful, efficient to compute, and correlated with measures of player skill, partner skill and task difficulty.", "url": "https://arxiv.org/abs/2312.04030"}, {"metadata": {"arXiv": "2312.04103", "Date": "Thu, 07 Dec 2023 07:37:15 ", "Title": "Enhancing the Rationale-Input Alignment for Self-explaining Rationalization", "Authors": ["Wei Liu", "Haozhao Wang", "Jun Wang", "Zhiying Deng", "YuanKai Zhang", "Cheng Wang", "Ruixuan Li"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Accept at ICDE 2024"]}, "abstract": "Rationalization empowers deep learning models with self-explaining capabilities through a cooperative game, where a generator selects a semantically consistent subset of the input as a rationale, and a subsequent predictor makes predictions based on the selected rationale. In this paper, we discover that rationalization is prone to a problem named \\emph{rationale shift}, which arises from the algorithmic bias of the cooperative game. Rationale shift refers to a situation where the semantics of the selected rationale may deviate from the original input, but the predictor still produces accurate predictions based on the deviation, resulting in a compromised generator with misleading feedback. To address this issue, we first demonstrate the importance of the alignment between the rationale and the full input through both empirical observations and theoretical analysis. Subsequently, we introduce a novel approach called DAR (\\textbf{D}iscriminatively \\textbf{A}ligned \\textbf{R}ationalization), which utilizes an auxiliary module pretrained on the full input to discriminatively align the selected rationale and the original input. We theoretically illustrate how DAR accomplishes the desired alignment, thereby overcoming the rationale shift problem. The experiments on two widely used real-world benchmarks show that the proposed method significantly improves the explanation quality (measured by the overlap between the model-selected explanation and the human-annotated rationale) as compared to state-of-the-art techniques. Additionally, results on two synthetic settings further validate the effectiveness of DAR in addressing the rationale shift problem.", "url": "https://arxiv.org/abs/2312.04103"}, {"metadata": {"arXiv": "2312.04318", "Date": "Thu, 07 Dec 2023 14:21:31 ", "Title": "MIMo: A Multi-Modal Infant Model for Studying Cognitive Development", "Authors": ["Dominik Mattern", "Pierre Schumacher", "Francisco M. L\\'opez", "Marcel C. Raabe", "Markus R. Ernst", "Arthur Aubret", "Jochen Triesch"], "Categories": "cs.AI cs.LG", "Comments": ["11 pages", "8 figures. Submitted to IEEE Transactions on Congnitive and Developmental Systems (TCDS)"]}, "abstract": "Human intelligence and human consciousness emerge gradually during the process of cognitive development. Understanding this development is an essential aspect of understanding the human mind and may facilitate the construction of artificial minds with similar properties. Importantly, human cognitive development relies on embodied interactions with the physical and social environment, which is perceived via complementary sensory modalities. These interactions allow the developing mind to probe the causal structure of the world. This is in stark contrast to common machine learning approaches, e.g., for large language models, which are merely passively ``digesting'' large amounts of training data, but are not in control of their sensory inputs. However, computational modeling of the kind of self-determined embodied interactions that lead to human intelligence and consciousness is a formidable challenge. Here we present MIMo, an open-source multi-modal infant model for studying early cognitive development through computer simulations. MIMo's body is modeled after an 18-month-old child with detailed five-fingered hands. MIMo perceives its surroundings via binocular vision, a vestibular system, proprioception, and touch perception through a full-body virtual skin, while two different actuation models allow control of his body. We describe the design and interfaces of MIMo and provide examples illustrating its use. All code is available at https://github.com/trieschlab/MIMo .", "url": "https://arxiv.org/abs/2312.04318"}, {"metadata": {"arXiv": "2312.03818", "Date": "Wed, 06 Dec 2023 18:59:30 ", "Title": "Alpha-CLIP: A CLIP Model Focusing on Wherever You Want", "Authors": ["Zeyi Sun", "Ye Fang", "Tong Wu", "Pan Zhang", "Yuhang Zang", "Shu Kong", "Yuanjun Xiong", "Dahua Lin", "Jiaqi Wang"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["project page: https://aleafy.github.io/alpha-clip; code: https://github.com/SunzeY/AlphaCLIP"]}, "abstract": "Contrastive Language-Image Pre-training (CLIP) plays an essential role in extracting valuable content information from images across diverse tasks. It aligns textual and visual modalities to comprehend the entire image, including all the details, even those irrelevant to specific tasks. However, for a finer understanding and controlled editing of images, it becomes crucial to focus on specific regions of interest, which can be indicated as points, masks, or boxes by humans or perception models. To fulfill the requirements, we introduce Alpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to suggest attentive regions and fine-tuned with constructed millions of RGBA region-text pairs. Alpha-CLIP not only preserves the visual recognition ability of CLIP but also enables precise control over the emphasis of image contents. It demonstrates effectiveness in various tasks, including but not limited to open-world recognition, multimodal large language models, and conditional 2D / 3D generation. It has a strong potential to serve as a versatile tool for image-related tasks.", "url": "https://arxiv.org/abs/2312.03818"}, {"metadata": {"arXiv": "2312.04118", "Date": "Thu, 07 Dec 2023 08:18:40 ", "Title": "Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic Play", "Authors": ["Timothy Schauml\\\"offel", "Arthur Aubret", "Gemma Roig", "Jochen Triesch"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Proceedings of the 2023 IEEE International Conference on Development and Learning (ICDL)"]}, "abstract": "Infants' ability to recognize and categorize objects develops gradually. The second year of life is marked by both the emergence of more semantic visual representations and a better understanding of word meaning. This suggests that language input may play an important role in shaping visual representations. However, even in suitable contexts for word learning like dyadic play sessions, caregivers utterances are sparse and ambiguous, often referring to objects that are different from the one to which the child attends. Here, we systematically investigate to what extent caregivers' utterances can nevertheless enhance visual representations. For this we propose a computational model of visual representation learning during dyadic play. We introduce a synthetic dataset of ego-centric images perceived by a toddler-agent that moves and rotates toy objects in different parts of its home environment while hearing caregivers' utterances, modeled as captions. We propose to model toddlers' learning as simultaneously aligning representations for 1) close-in-time images and 2) co-occurring images and utterances. We show that utterances with statistics matching those of real caregivers give rise to representations supporting improved category recognition. Our analysis reveals that a small decrease/increase in object-relevant naming frequencies can drastically impact the learned representations. This affects the attention on object names within an utterance, which is required for efficient visuo-linguistic alignment. Overall, our results support the hypothesis that caregivers' naming utterances can improve toddlers' visual representations.", "url": "https://arxiv.org/abs/2312.04118"}, {"metadata": {"arXiv": "2312.04168", "Date": "Thu, 07 Dec 2023 09:37:28 ", "Title": "Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient Semantic Segmentation", "Authors": ["Jiawei Fan", "Chao Li", "Xiaolong Liu", "Meina Song", "Anbang Yao"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["The paper of Af-DCD is accepted to NeurIPS 2023. Code and models are available at https://github.com/OSVAI/Af-DCD"]}, "abstract": "In recent years, knowledge distillation methods based on contrastive learning have achieved promising results on image classification and object detection tasks. However, in this line of research, we note that less attention is paid to semantic segmentation. Existing methods heavily rely on data augmentation and memory buffer, which entail high computational resource demands when applying them to handle semantic segmentation that requires to preserve high-resolution feature maps for making dense pixel-wise predictions. In order to address this problem, we present Augmentation-free Dense Contrastive Knowledge Distillation (Af-DCD), a new contrastive distillation learning paradigm to train compact and accurate deep neural networks for semantic segmentation applications. Af-DCD leverages a masked feature mimicking strategy, and formulates a novel contrastive learning loss via taking advantage of tactful feature partitions across both channel and spatial dimensions, allowing to effectively transfer dense and structured local knowledge learnt by the teacher model to a target student model while maintaining training efficiency. Extensive experiments on five mainstream benchmarks with various teacher-student network pairs demonstrate the effectiveness of our approach. For instance, the DeepLabV3-Res18|DeepLabV3-MBV2 model trained by Af-DCD reaches 77.03%|76.38% mIOU on Cityscapes dataset when choosing DeepLabV3-Res101 as the teacher, setting new performance records. Besides that, Af-DCD achieves an absolute mIOU improvement of 3.26%|3.04%|2.75%|2.30%|1.42% compared with individually trained counterpart on Cityscapes|Pascal VOC|Camvid|ADE20K|COCO-Stuff-164K. Code is available at https://github.com/OSVAI/Af-DCD", "url": "https://arxiv.org/abs/2312.04168"}, {"metadata": {"arXiv": "2312.04398", "Date": "Thu, 07 Dec 2023 16:10:10 ", "Title": "Intelligent Anomaly Detection for Lane Rendering Using Transformer with Self-Supervised Pre-Training and Customized Fine-Tuning", "Authors": ["Yongqi Dong", "Xingmin Lu", "Ruohan Li", "Wei Song", "Bart van Arem", "Haneen Farah"], "Categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "Comments": ["20 pages", "6 figures", "accepted by the 103rd Transportation Research Board (TRB) Annual Meeting", "under review by Transportation Research Record: Journal of the Transportation Research Board"]}, "abstract": "The burgeoning navigation services using digital maps provide great convenience to drivers. Nevertheless, the presence of anomalies in lane rendering map images occasionally introduces potential hazards, as such anomalies can be misleading to human drivers and consequently contribute to unsafe driving conditions. In response to this concern and to accurately and effectively detect the anomalies, this paper transforms lane rendering image anomaly detection into a classification problem and proposes a four-phase pipeline consisting of data pre-processing, self-supervised pre-training with the masked image modeling (MiM) method, customized fine-tuning using cross-entropy based loss with label smoothing, and post-processing to tackle it leveraging state-of-the-art deep learning techniques, especially those involving Transformer models. Various experiments verify the effectiveness of the proposed pipeline. Results indicate that the proposed pipeline exhibits superior performance in lane rendering image anomaly detection, and notably, the self-supervised pre-training with MiM can greatly enhance the detection accuracy while significantly reducing the total training time. For instance, employing the Swin Transformer with Uniform Masking as self-supervised pretraining (Swin-Trans-UM) yielded a heightened accuracy at 94.77% and an improved Area Under The Curve (AUC) score of 0.9743 compared with the pure Swin Transformer without pre-training (Swin-Trans) with an accuracy of 94.01% and an AUC of 0.9498. The fine-tuning epochs were dramatically reduced to 41 from the original 280. In conclusion, the proposed pipeline, with its incorporation of self-supervised pre-training using MiM and other advanced deep learning techniques, emerges as a robust solution for enhancing the accuracy and efficiency of lane rendering image anomaly detection in digital navigation systems.", "url": "https://arxiv.org/abs/2312.04398"}, {"metadata": {"arXiv": "2312.04461", "Date": "Thu, 07 Dec 2023 17:32:29 ", "Title": "PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding", "Authors": ["Zhen Li", "Mingdeng Cao", "Xintao Wang", "Zhongang Qi", "Ming-Ming Cheng", "Ying Shan"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "Comments": ["Tech report; Project page: https://photo-maker.github.io/"]}, "abstract": "Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts. However, existing personalized generation methods cannot simultaneously satisfy the requirements of high efficiency, promising identity (ID) fidelity, and flexible text controllability. In this work, we introduce PhotoMaker, an efficient personalized text-to-image generation method, which mainly encodes an arbitrary number of input ID images into a stack ID embedding for preserving ID information. Such an embedding, serving as a unified ID representation, can not only encapsulate the characteristics of the same input ID comprehensively, but also accommodate the characteristics of different IDs for subsequent integration. This paves the way for more intriguing and practically valuable applications. Besides, to drive the training of our PhotoMaker, we propose an ID-oriented data construction pipeline to assemble the training data. Under the nourishment of the dataset constructed through the proposed pipeline, our PhotoMaker demonstrates better ID preservation ability than test-time fine-tuning based methods, yet provides significant speed improvements, high-quality generation results, strong generalization capabilities, and a wide range of applications. Our project page is available at https://photo-maker.github.io/", "url": "https://arxiv.org/abs/2312.04461"}, {"metadata": {"arXiv": "2312.04548", "Date": "Thu, 07 Dec 2023 18:59:14 ", "Title": "Multiview Aerial Visual Recognition (MAVREC): Can Multi-view Improve Aerial Visual Perception?", "Authors": ["Aritra Dutta", "Srijan Das", "Jacob Nielsen", "Rajatsubhra Chakraborty", "Mubarak Shah"], "Categories": "cs.CV cs.AI cs.LG", "ACM-class": "I.4.0; I.4.8; I.5.1; I.5.4; I.2.10"}, "abstract": "Despite the commercial abundance of UAVs, aerial data acquisition remains challenging, and the existing Asia and North America-centric open-source UAV datasets are small-scale or low-resolution and lack diversity in scene contextuality. Additionally, the color content of the scenes, solar-zenith angle, and population density of different geographies influence the data diversity. These two factors conjointly render suboptimal aerial-visual perception of the deep neural network (DNN) models trained primarily on the ground-view data, including the open-world foundational models. To pave the way for a transformative era of aerial detection, we present Multiview Aerial Visual RECognition or MAVREC, a video dataset where we record synchronized scenes from different perspectives -- ground camera and drone-mounted camera. MAVREC consists of around 2.5 hours of industry-standard 2.7K resolution video sequences, more than 0.5 million frames, and 1.1 million annotated bounding boxes. This makes MAVREC the largest ground and aerial-view dataset, and the fourth largest among all drone-based datasets across all modalities and tasks. Through our extensive benchmarking on MAVREC, we recognize that augmenting object detectors with ground-view images from the corresponding geographical location is a superior pre-training strategy for aerial detection. Building on this strategy, we benchmark MAVREC with a curriculum-based semi-supervised object detection approach that leverages labeled (ground and aerial) and unlabeled (only aerial) images to enhance the aerial detection. We publicly release the MAVREC dataset: https://mavrec.github.io.", "url": "https://arxiv.org/abs/2312.04548"}, {"metadata": {"arXiv": "2312.04552", "Date": "Thu, 07 Dec 2023 18:59:20 ", "Title": "Generating Illustrated Instructions", "Authors": ["Sachit Menon", "Ishan Misra", "Rohit Girdhar"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "Comments": ["Project website: http://facebookresearch.github.io/IllustratedInstructions"]}, "abstract": "We introduce the new task of generating Illustrated Instructions, i.e., visual instructions customized to a user's needs. We identify desiderata unique to this task, and formalize it through a suite of automatic and human evaluation metrics, designed to measure the validity, consistency, and efficacy of the generations. We combine the power of large language models (LLMs) together with strong text-to-image generation diffusion models to propose a simple approach called StackedDiffusion, which generates such illustrated instructions given text as input. The resulting model strongly outperforms baseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases, users even prefer it to human-generated articles. Most notably, it enables various new and exciting applications far beyond what static articles on the web can provide, such as personalized instructions complete with intermediate steps and pictures in response to a user's individual situation.", "url": "https://arxiv.org/abs/2312.04552"}, {"metadata": {"arXiv": "2312.03762", "Date": "Tue, 05 Dec 2023 19:00:46 ", "Title": "Colour versus Shape Goal Misgeneralization in Reinforcement Learning: A Case Study", "Authors": ["Karolis Ramanauskas", "\\\"Ozg\\\"ur \\c{S}im\\c{s}ek"], "Categories": "cs.LG cs.AI", "Comments": ["ATTRIB: Workshop on Attributing Model Behavior at Scale at NeurIPS 2023"]}, "abstract": "We explore colour versus shape goal misgeneralization originally demonstrated by Di Langosco et al. (2022) in the Procgen Maze environment, where, given an ambiguous choice, the agents seem to prefer generalization based on colour rather than shape. After training over 1,000 agents in a simplified version of the environment and evaluating them on over 10 million episodes, we conclude that the behaviour can be attributed to the agents learning to detect the goal object through a specific colour channel. This choice is arbitrary. Additionally, we show how, due to underspecification, the preferences can change when retraining the agents using exactly the same procedure except for using a different random seed for the training run. Finally, we demonstrate the existence of outliers in out-of-distribution behaviour based on training random seed alone.", "url": "https://arxiv.org/abs/2312.03762"}, {"metadata": {"arXiv": "2312.03764", "Date": "Tue, 05 Dec 2023 19:26:01 ", "Title": "Similarity-based Knowledge Transfer for Cross-Domain Reinforcement Learning", "Authors": ["Sergio A. Serrano and Jose Martinez-Carranza and L. Enrique Sucar"], "Categories": "cs.LG cs.AI", "Comments": ["30 pages", "7 figures"], "MSC-class": "68T37, 68T42, 68T07, 68T05"}, "abstract": "Transferring knowledge in cross-domain reinforcement learning is a challenging setting in which learning is accelerated by reusing knowledge from a task with different observation and/or action space. However, it is often necessary to carefully select the source of knowledge for the receiving end to benefit from the transfer process. In this article, we study how to measure the similarity between cross-domain reinforcement learning tasks to select a source of knowledge that will improve the performance of the learning agent. We developed a semi-supervised alignment loss to match different spaces with a set of encoder-decoders, and use them to measure similarity and transfer policies across tasks. In comparison to prior works, our method does not require data to be aligned, paired or collected by expert policies. Experimental results, on a set of varied Mujoco control tasks, show the robustness of our method in effectively selecting and transferring knowledge, without the supervision of a tailored set of source tasks.", "url": "https://arxiv.org/abs/2312.03764"}, {"metadata": {"arXiv": "2312.03796", "Date": "Wed, 06 Dec 2023 14:33:50 ", "Title": "Multi-Scale and Multi-Modal Contrastive Learning Network for Biomedical Time Series", "Authors": ["Hongbo Guo", "Xinzi Xu", "Hao Wu", "and Guoxing Wang"], "Categories": "cs.LG cs.AI", "Comments": ["4 pages", "3 figures", "submitted to ICASSP 2024"]}, "abstract": "Multi-modal biomedical time series (MBTS) data offers a holistic view of the physiological state, holding significant importance in various bio-medical applications. Owing to inherent noise and distribution gaps across different modalities, MBTS can be complex to model. Various deep learning models have been developed to learn representations of MBTS but still fall short in robustness due to the ignorance of modal-to-modal variations. This paper presents a multi-scale and multi-modal biomedical time series representation learning (MBSL) network with contrastive learning to migrate these variations. Firstly, MBTS is grouped based on inter-modal distances, then each group with minimum intra-modal variations can be effectively modeled by individual encoders. Besides, to enhance the multi-scale feature extraction (encoder), various patch lengths and mask ratios are designed to generate tokens with semantic information at different scales and diverse contextual perspectives respectively. Finally, cross-modal contrastive learning is proposed to maximize consistency among inter-modal groups, maintaining useful information and eliminating noises. Experiments against four bio-medical applications show that MBSL outperforms state-of-the-art models by 33.9% mean average errors (MAE) in respiration rate, by 13.8% MAE in exercise heart rate, by 1.41% accuracy in human activity recognition, and by 1.14% F1-score in obstructive sleep apnea-hypopnea syndrome.", "url": "https://arxiv.org/abs/2312.03796"}, {"metadata": {"arXiv": "2312.03801", "Date": "Wed, 06 Dec 2023 15:19:28 ", "Title": "Generalization to New Sequential Decision Making Tasks with In-Context Learning", "Authors": ["Sharath Chandra Raparthy", "Eric Hambro", "Robert Kirk", "Mikael Henaff", "Roberta Raileanu"], "Categories": "cs.LG cs.AI"}, "abstract": "Training autonomous agents that can learn new tasks from only a handful of demonstrations is a long-standing problem in machine learning. Recently, transformers have been shown to learn new language or vision tasks without any weight updates from only a few examples, also referred to as in-context learning. However, the sequential decision making setting poses additional challenges having a lower tolerance for errors since the environment's stochasticity or the agent's actions can lead to unseen, and sometimes unrecoverable, states. In this paper, we use an illustrative example to show that naively applying transformers to sequential decision making problems does not enable in-context learning of new tasks. We then demonstrate how training on sequences of trajectories with certain distributional properties leads to in-context learning of new sequential decision making tasks. We investigate different design choices and find that larger model and dataset sizes, as well as more task diversity, environment stochasticity, and trajectory burstiness, all result in better in-context learning of new out-of-distribution tasks. By training on large diverse offline datasets, our model is able to learn new MiniHack and Procgen tasks without any weight updates from just a handful of demonstrations.", "url": "https://arxiv.org/abs/2312.03801"}, {"metadata": {"arXiv": "2312.03814", "Date": "Wed, 06 Dec 2023 18:29:23 ", "Title": "Pearl: A Production-ready Reinforcement Learning Agent", "Authors": ["Zheqing Zhu", "Rodrigo de Salvo Braz", "Jalaj Bhandari", "Daniel Jiang", "Yi Wan", "Yonathan Efroni", "Liyuan Wang", "Ruiyang Xu", "Hongbo Guo", "Alex Nikulkov", "Dmytro Korenkevych", "Urun Dogan", "Frank Cheng", "Zheng Wu", "Wanqiao Xu"], "Categories": "cs.LG cs.AI"}, "abstract": "Reinforcement Learning (RL) offers a versatile framework for achieving long-term goals. Its generality allows us to formalize a wide range of problems that real-world intelligent systems encounter, such as dealing with delayed rewards, handling partial observability, addressing the exploration and exploitation dilemma, utilizing offline data to improve online performance, and ensuring safety constraints are met. Despite considerable progress made by the RL research community in addressing these issues, existing open-source RL libraries tend to focus on a narrow portion of the RL solution pipeline, leaving other aspects largely unattended. This paper introduces Pearl, a Production-ready RL agent software package explicitly designed to embrace these challenges in a modular fashion. In addition to presenting preliminary benchmark results, this paper highlights Pearl's industry adoptions to demonstrate its readiness for production usage. Pearl is open sourced on Github at github.com/facebookresearch/pearl and its official website is located at pearlagent.github.io.", "url": "https://arxiv.org/abs/2312.03814"}, {"metadata": {"arXiv": "2312.03881", "Date": "Wed, 06 Dec 2023 20:11:02 ", "Title": "FoMo Rewards: Can we cast foundation models as reward functions?", "Authors": ["Ekdeep Singh Lubana", "Johann Brehmer", "Pim de Haan", "Taco Cohen"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS FMDM workshop"]}, "abstract": "We explore the viability of casting foundation models as generic reward functions for reinforcement learning. To this end, we propose a simple pipeline that interfaces an off-the-shelf vision model with a large language model. Specifically, given a trajectory of observations, we infer the likelihood of an instruction describing the task that the user wants an agent to perform. We show that this generic likelihood function exhibits the characteristics ideally expected from a reward function: it associates high values with the desired behaviour and lower values for several similar, but incorrect policies. Overall, our work opens the possibility of designing open-ended agents for interactive tasks via foundation models.", "url": "https://arxiv.org/abs/2312.03881"}, {"metadata": {"arXiv": "2312.03886", "Date": "Wed, 06 Dec 2023 20:24:17 ", "Title": "On The Fairness Impacts of Hardware Selection in Machine Learning", "Authors": ["Sree Harsha Nelaturu", "Nishaanth Kanna Ravichandran", "Cuong Tran", "Sara Hooker", "Ferdinando Fioretto"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "In the machine learning ecosystem, hardware selection is often regarded as a mere utility, overshadowed by the spotlight on algorithms and data. This oversight is particularly problematic in contexts like ML-as-a-service platforms, where users often lack control over the hardware used for model deployment. How does the choice of hardware impact generalization properties? This paper investigates the influence of hardware on the delicate balance between model performance and fairness. We demonstrate that hardware choices can exacerbate existing disparities, attributing these discrepancies to variations in gradient flows and loss surfaces across different demographic groups. Through both theoretical and empirical analysis, the paper not only identifies the underlying factors but also proposes an effective strategy for mitigating hardware-induced performance imbalances.", "url": "https://arxiv.org/abs/2312.03886"}, {"metadata": {"arXiv": "2312.03889", "Date": "Wed, 06 Dec 2023 20:29:23 ", "Title": "A Masked Pruning Approach for Dimensionality Reduction in Communication-Efficient Federated Learning Systems", "Authors": ["Tamir L.S. Gez", "Kobi Cohen"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["12 pages", "9 figures"]}, "abstract": "Federated Learning (FL) represents a growing machine learning (ML) paradigm designed for training models across numerous nodes that retain local datasets, all without directly exchanging the underlying private data with the parameter server (PS). Its increasing popularity is attributed to notable advantages in terms of training deep neural network (DNN) models under privacy aspects and efficient utilization of communication resources. Unfortunately, DNNs suffer from high computational and communication costs, as well as memory consumption in intricate tasks. These factors restrict the applicability of FL algorithms in communication-constrained systems with limited hardware resources. In this paper, we develop a novel algorithm that overcomes these limitations by synergistically combining a pruning-based method with the FL process, resulting in low-dimensional representations of the model with minimal communication cost, dubbed Masked Pruning over FL (MPFL). The algorithm operates by initially distributing weights to the nodes through the PS. Subsequently, each node locally trains its model and computes pruning masks. These low-dimensional masks are then transmitted back to the PS, which generates a consensus pruning mask, broadcasted back to the nodes. This iterative process enhances the robustness and stability of the masked pruning model. The generated mask is used to train the FL model, achieving significant bandwidth savings. We present an extensive experimental study demonstrating the superior performance of MPFL compared to existing methods. Additionally, we have developed an open-source software package for the benefit of researchers and developers in related fields.", "url": "https://arxiv.org/abs/2312.03889"}, {"metadata": {"arXiv": "2312.03905", "Date": "Wed, 06 Dec 2023 20:58:07 ", "Title": "A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints", "Authors": ["Kareem Ahmed", "Kai-Wei Chang", "Guy Van den Broeck"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Neuro-symbolic AI bridges the gap between purely symbolic and neural approaches to learning. This often requires maximizing the likelihood of a symbolic constraint w.r.t the neural network's output distribution. Such output distributions are typically assumed to be fully-factorized. This limits the applicability of neuro-symbolic learning to the more expressive autoregressive distributions, e.g., transformers. Under such distributions, computing the likelihood of even simple constraints is #P-hard. Instead of attempting to enforce the constraint on the entire output distribution, we propose to do so on a random, local approximation thereof. More precisely, we optimize the likelihood of the constraint under a pseudolikelihood-based approximation centered around a model sample. Our approximation is factorized, allowing the reuse of solutions to sub-problems, a main tenet for efficiently computing neuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of the likelihood, exhibiting low entropy and KL-divergence around the model sample. We evaluate our approach on Sudoku and shortest-path prediction cast as autoregressive generation, and observe that we greatly improve upon the base model's ability to predict logically-consistent outputs. We also evaluate on the task of detoxifying large language models. Using a simple constraint disallowing a list of toxic words, we are able to steer the model's outputs away from toxic generations, achieving SoTA detoxification compared to previous approaches.", "url": "https://arxiv.org/abs/2312.03905"}, {"metadata": {"arXiv": "2312.03991", "Date": "Thu, 07 Dec 2023 02:17:45 ", "Title": "MICRO: Model-Based Offline Reinforcement Learning with a Conservative Bellman Operator", "Authors": ["Xiao-Yin Liu", "Xiao-Hu Zhou", "Guo-Tao Li", "Hao Li", "Mei-Jiang Gui", "Tian-Yu Xiang", "De-Xing Huang and Zeng-Guang Hou"], "Categories": "cs.LG cs.AI", "Comments": ["13 pages", "5 figures"]}, "abstract": "Offline reinforcement learning (RL) faces a significant challenge of distribution shift. Model-free offline RL penalizes the Q value for out-of-distribution (OOD) data or constrains the policy closed to the behavior policy to tackle this problem, but this inhibits the exploration of the OOD region. Model-based offline RL, which uses the trained environment model to generate more OOD data and performs conservative policy optimization within that model, has become an effective method for this problem. However, the current model-based algorithms rarely consider agent robustness when incorporating conservatism into policy. Therefore, the new model-based offline algorithm with a conservative Bellman operator (MICRO) is proposed. This method trades off performance and robustness via introducing the robust Bellman operator into the algorithm. Compared with previous model-based algorithms with robust adversarial models, MICRO can significantly reduce the computation cost by only choosing the minimal Q value in the state uncertainty set. Extensive experiments demonstrate that MICRO outperforms prior RL algorithms in offline RL benchmark and is considerably robust to adversarial perturbations.", "url": "https://arxiv.org/abs/2312.03991"}, {"metadata": {"arXiv": "2312.04024", "Date": "Thu, 07 Dec 2023 03:42:48 ", "Title": "k* Distribution: Evaluating the Latent Space of Deep Neural Networks using Local Neighborhood Analysis", "Authors": ["Shashank Kotyan", "Ueda Tatsuya and Danilo Vasconcellos Vargas"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Most examinations of neural networks' learned latent spaces typically employ dimensionality reduction techniques such as t-SNE or UMAP. While these methods effectively capture the overall sample distribution in the entire learned latent space, they tend to distort the structure of sample distributions within specific classes in the subset of the latent space. This distortion complicates the task of easily distinguishing classes identifiable by neural networks. In response to this challenge, we introduce the k* Distribution methodology. This approach focuses on capturing the characteristics and structure of sample distributions for individual classes within the subset of the learned latent space using local neighborhood analysis. The key concept is to facilitate easy comparison of different k* distributions, enabling analysis of how various classes are processed by the same neural network. This provides a more profound understanding of existing contemporary visualizations. Our study reveals three distinct distributions of samples within the learned latent space subset: a) Fractured, b) Overlapped, and c) Clustered. We note and demonstrate that the distribution of samples within the network's learned latent space significantly varies depending on the class. Furthermore, we illustrate that our analysis can be applied to explore the latent space of diverse neural network architectures, various layers within neural networks, transformations applied to input samples, and the distribution of training and testing data for neural networks. We anticipate that our approach will facilitate more targeted investigations into neural networks by collectively examining the distribution of different samples within the learned latent space.", "url": "https://arxiv.org/abs/2312.04024"}, {"metadata": {"arXiv": "2312.04027", "Date": "Thu, 07 Dec 2023 03:53:17 ", "Title": "The sample complexity of multi-distribution learning", "Authors": ["Binghui Peng"], "Categories": "cs.LG cs.AI cs.DS stat.ML"}, "abstract": "Multi-distribution learning generalizes the classic PAC learning to handle data coming from multiple distributions. Given a set of $k$ data distributions and a hypothesis class of VC dimension $d$, the goal is to learn a hypothesis that minimizes the maximum population loss over $k$ distributions, up to $\\epsilon$ additive error. In this paper, we settle the sample complexity of multi-distribution learning by giving an algorithm of sample complexity $\\widetilde{O}((d+k)\\epsilon^{-2}) \\cdot (k/\\epsilon)^{o(1)}$. This matches the lower bound up to sub-polynomial factor and resolves the COLT 2023 open problem of Awasthi, Haghtalab and Zhao [AHZ23].", "url": "https://arxiv.org/abs/2312.04027"}, {"metadata": {"arXiv": "2312.04111", "Date": "Thu, 07 Dec 2023 07:54:11 ", "Title": "Breaking the Entanglement of Homophily and Heterophily in Semi-supervised Node Classification", "Authors": ["Henan Sun", "Xunkai Li", "Zhengyu Wu", "Daohan Su", "Rong-Hua Li", "Guoren Wang"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["14 pages", "7 figures"]}, "abstract": "Recently, graph neural networks (GNNs) have shown prominent performance in semi-supervised node classification by leveraging knowledge from the graph database. However, most existing GNNs follow the homophily assumption, where connected nodes are more likely to exhibit similar feature distributions and the same labels, and such an assumption has proven to be vulnerable in a growing number of practical applications. As a supplement, heterophily reflects dissimilarity in connected nodes, which has gained significant attention in graph learning. To this end, data engineers aim to develop a powerful GNN model that can ensure performance under both homophily and heterophily. Despite numerous attempts, most existing GNNs struggle to achieve optimal node representations due to the constraints of undirected graphs. The neglect of directed edges results in sub-optimal graph representations, thereby hindering the capacity of GNNs. To address this issue, we introduce AMUD, which quantifies the relationship between node profiles and topology from a statistical perspective, offering valuable insights for \\underline{A}daptively \\underline{M}odeling the natural directed graphs as the \\underline{U}ndirected or \\underline{D}irected graph to maximize the benefits from subsequent graph learning. Furthermore, we propose \\underline{A}daptive \\underline{D}irected \\underline{P}attern \\underline{A}ggregation (ADPA) as a new directed graph learning paradigm for AMUD. Empirical studies have demonstrated that AMUD guides efficient graph learning. Meanwhile, extensive experiments on 14 benchmark datasets substantiate the impressive performance of ADPA, outperforming baselines by significant margins of 3.96\\%.", "url": "https://arxiv.org/abs/2312.04111"}, {"metadata": {"arXiv": "2312.04142", "Date": "Thu, 07 Dec 2023 08:56:44 ", "Title": "TimeDRL: Disentangled Representation Learning for Multivariate Time-Series", "Authors": ["Ching Chang", "Chiao-Tung Chan", "Wei-Yao Wang", "Wen-Chih Peng", "Tien-Fu Chen"], "Categories": "cs.LG cs.AI", "Comments": ["This paper is currently under review. The code will be made available upon acceptance"]}, "abstract": "Multivariate time-series data in numerous real-world applications (e.g., healthcare and industry) are informative but challenging due to the lack of labels and high dimensionality. Recent studies in self-supervised learning have shown their potential in learning rich representations without relying on labels, yet they fall short in learning disentangled embeddings and addressing issues of inductive bias (e.g., transformation-invariance). To tackle these challenges, we propose TimeDRL, a generic multivariate time-series representation learning framework with disentangled dual-level embeddings. TimeDRL is characterized by three novel features: (i) disentangled derivation of timestamp-level and instance-level embeddings from patched time-series data using a [CLS] token strategy; (ii) utilization of timestamp-predictive and instance-contrastive tasks for disentangled representation learning, with the former optimizing timestamp-level embeddings with predictive loss, and the latter optimizing instance-level embeddings with contrastive loss; and (iii) avoidance of augmentation methods to eliminate inductive biases, such as transformation-invariance from cropping and masking. Comprehensive experiments on 6 time-series forecasting datasets and 5 time-series classification datasets have shown that TimeDRL consistently surpasses existing representation learning approaches, achieving an average improvement of forecasting by 57.98% in MSE and classification by 1.25% in accuracy. Furthermore, extensive ablation studies confirmed the relative contribution of each component in TimeDRL's architecture, and semi-supervised learning evaluations demonstrated its effectiveness in real-world scenarios, even with limited labeled data.", "url": "https://arxiv.org/abs/2312.04142"}, {"metadata": {"arXiv": "2312.04234", "Date": "Thu, 07 Dec 2023 11:40:32 ", "Title": "Graph Convolutions Enrich the Self-Attention in Transformers!", "Authors": ["Jeongwhan Choi", "Hyowon Wi", "Jayoung Kim", "Yehjin Shin", "Kookjin Lee", "Nathaniel Trask", "Noseong Park"], "Categories": "cs.LG cs.AI"}, "abstract": "Transformers, renowned for their self-attention mechanism, have achieved state-of-the-art performance across various tasks in natural language processing, computer vision, time-series modeling, etc. However, one of the challenges with deep Transformer models is the oversmoothing problem, where representations across layers converge to indistinguishable values, leading to significant performance degradation. We interpret the original self-attention as a simple graph filter and redesign it from a graph signal processing (GSP) perspective. We propose graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism. We demonstrate that GFSA improves the performance of Transformers in various fields, including computer vision, natural language processing, graph pattern classification, speech recognition, and code classification.", "url": "https://arxiv.org/abs/2312.04234"}, {"metadata": {"arXiv": "2312.04330", "Date": "Thu, 07 Dec 2023 14:48:30 ", "Title": "Surrogate Modelling for Sea Ice Concentration using Lightweight Neural Ensemble", "Authors": ["Julia Borisova", "Nikolay O. Nikitin"], "Categories": "cs.LG cs.AI physics.ao-ph", "Comments": ["7 pages", "6 figures"]}, "abstract": "The modeling and forecasting of sea ice conditions in the Arctic region are important tasks for ship routing, offshore oil production, and environmental monitoring. We propose the adaptive surrogate modeling approach named LANE-SI (Lightweight Automated Neural Ensembling for Sea Ice) that uses ensemble of relatively simple deep learning models with different loss functions for forecasting of spatial distribution for sea ice concentration in the specified water area. Experimental studies confirm the quality of a long-term forecast based on a deep learning model fitted to the specific water area is comparable to resource-intensive physical modeling, and for some periods of the year, it is superior. We achieved a 20% improvement against the state-of-the-art physics-based forecast system SEAS5 for the Kara Sea.", "url": "https://arxiv.org/abs/2312.04330"}, {"metadata": {"arXiv": "2312.04343", "Date": "Thu, 07 Dec 2023 15:05:26 ", "Title": "Causality and Explainability for Trustworthy Integrated Pest Management", "Authors": ["Ilias Tsoumas", "Vasileios Sitokonstantinou", "Georgios Giannarakis", "Evagelia Lampiri", "Christos Athanassiou", "Gustau Camps-Valls", "Charalampos Kontoes", "Ioannis Athanasiadis"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning: Blending New and Existing Knowledge Systems"]}, "abstract": "Pesticides serve as a common tool in agricultural pest control but significantly contribute to the climate crisis. To combat this, Integrated Pest Management (IPM) stands as a climate-smart alternative. Despite its potential, IPM faces low adoption rates due to farmers' skepticism about its effectiveness. To address this challenge, we introduce an advanced data analysis framework tailored to enhance IPM adoption. Our framework provides i) robust pest population predictions across diverse environments with invariant and causal learning, ii) interpretable pest presence predictions using transparent models, iii) actionable advice through counterfactual explanations for in-season IPM interventions, iv) field-specific treatment effect estimations, and v) assessments of the effectiveness of our advice using causal inference. By incorporating these features, our framework aims to alleviate skepticism and encourage wider adoption of IPM practices among farmers.", "url": "https://arxiv.org/abs/2312.04343"}, {"metadata": {"arXiv": "2312.04386", "Date": "Thu, 07 Dec 2023 15:55:58 ", "Title": "Model-Based Epistemic Variance of Values for Risk-Aware Policy Optimization", "Authors": ["Carlos E. Luis", "Alessandro G. Bottero", "Julia Vinogradska", "Felix Berkenkamp", "Jan Peters"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2302.12526"]}, "abstract": "We consider the problem of quantifying uncertainty over expected cumulative rewards in model-based reinforcement learning. In particular, we focus on characterizing the variance over values induced by a distribution over MDPs. Previous work upper bounds the posterior variance over values by solving a so-called uncertainty Bellman equation (UBE), but the over-approximation may result in inefficient exploration. We propose a new UBE whose solution converges to the true posterior variance over values and leads to lower regret in tabular exploration problems. We identify challenges to apply the UBE theory beyond tabular problems and propose a suitable approximation. Based on this approximation, we introduce a general-purpose policy optimization algorithm, Q-Uncertainty Soft Actor-Critic (QU-SAC), that can be applied for either risk-seeking or risk-averse policy optimization with minimal changes. Experiments in both online and offline RL demonstrate improved performance compared to other uncertainty estimation methods.", "url": "https://arxiv.org/abs/2312.04386"}, {"metadata": {"arXiv": "2312.04501", "Date": "Thu, 07 Dec 2023 18:21:52 ", "Title": "Graph Metanetworks for Processing Diverse Neural Architectures", "Authors": ["Derek Lim", "Haggai Maron", "Marc T. Law", "Jonathan Lorraine", "James Lucas"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["29 pages"]}, "abstract": "Neural networks efficiently encode learned information within their parameters. Consequently, many tasks can be unified by treating neural networks themselves as input data. When doing so, recent studies demonstrated the importance of accounting for the symmetries and geometry of parameter spaces. However, those works developed architectures tailored to specific networks such as MLPs and CNNs without normalization layers, and generalizing such architectures to other types of networks can be challenging. In this work, we overcome these challenges by building new metanetworks - neural networks that take weights from other neural networks as input. Put simply, we carefully build graphs representing the input neural networks and process the graphs using graph neural networks. Our approach, Graph Metanetworks (GMNs), generalizes to neural architectures where competing methods struggle, such as multi-head attention layers, normalization layers, convolutional layers, ResNet blocks, and group-equivariant linear layers. We prove that GMNs are expressive and equivariant to parameter permutation symmetries that leave the input neural network functions unchanged. We validate the effectiveness of our method on several metanetwork tasks over diverse neural network architectures.", "url": "https://arxiv.org/abs/2312.04501"}, {"metadata": {"arXiv": "2312.04504", "Date": "Thu, 07 Dec 2023 18:24:19 ", "Title": "Coordination-free Decentralised Federated Learning on Complex Networks: Overcoming Heterogeneity", "Authors": ["Lorenzo Valerio", "Chiara Boldrini", "Andrea Passarella", "J\\'anos Kert\\'esz", "M\\'arton Karsai", "Gerardo I\\~niguez"], "Categories": "cs.LG cs.AI cs.DC cs.MA cs.SI", "Comments": ["Supported by the H2020 HumaneAI Net (#952026)", "H2020 INFRAIA-01-2018-2019 SoBigData++ (#871042)", "and by the CHIST-ERA-19-XAI010 SAI projects", "FWF (grant No. I 5205). Also funded by PNRR MUR Partenariato Esteso PE00000013 FAIR", "PNRR MUR Partenariato Esteso PE00000001 - \"RESTART\""]}, "abstract": "Federated Learning (FL) is a well-known framework for successfully performing a learning task in an edge computing scenario where the devices involved have limited resources and incomplete data representation. The basic assumption of FL is that the devices communicate directly or indirectly with a parameter server that centrally coordinates the whole process, overcoming several challenges associated with it. However, in highly pervasive edge scenarios, the presence of a central controller that oversees the process cannot always be guaranteed, and the interactions (i.e., the connectivity graph) between devices might not be predetermined, resulting in a complex network structure. Moreover, the heterogeneity of data and devices further complicates the learning process. This poses new challenges from a learning standpoint that we address by proposing a communication-efficient Decentralised Federated Learning (DFL) algorithm able to cope with them. Our solution allows devices communicating only with their direct neighbours to train an accurate model, overcoming the heterogeneity induced by data and different training histories. Our results show that the resulting local models generalise better than those trained with competing approaches, and do so in a more communication-efficient way.", "url": "https://arxiv.org/abs/2312.04504"}, {"metadata": {"arXiv": "2312.04528", "Date": "Thu, 07 Dec 2023 18:46:50 ", "Title": "Using Large Language Models for Hyperparameter Optimization", "Authors": ["Michael R. Zhang", "Nishkrit Desai", "Juhan Bae", "Jonathan Lorraine", "Jimmy Ba"], "Categories": "cs.LG cs.AI", "Comments": ["29 pages"]}, "abstract": "This paper studies using foundational large language models (LLMs) to make decisions during hyperparameter optimization (HPO). Empirical evaluations demonstrate that in settings with constrained search budgets, LLMs can perform comparably or better than traditional HPO methods like random search and Bayesian optimization on standard benchmarks. Furthermore, we propose to treat the code specifying our model as a hyperparameter, which the LLM outputs, going beyond the capabilities of existing HPO approaches. Our findings suggest that LLMs are a promising tool for improving efficiency in the traditional decision-making problem of hyperparameter optimization.", "url": "https://arxiv.org/abs/2312.04528"}, {"metadata": {"arXiv": "2312.04540", "Date": "Thu, 07 Dec 2023 18:57:03 ", "Title": "Sim-to-Real Causal Transfer: A Metric Learning Approach to Causally-Aware Interaction Representations", "Authors": ["Yuejiang Liu", "Ahmad Rahimi", "Po-Chien Luan", "Frano Raji\\v{c}", "Alexandre Alahi"], "Categories": "cs.LG cs.AI cs.CV cs.MA cs.RO", "Comments": ["Preprint"]}, "abstract": "Modeling spatial-temporal interactions among neighboring agents is at the heart of multi-agent problems such as motion forecasting and crowd navigation. Despite notable progress, it remains unclear to which extent modern representations can capture the causal relationships behind agent interactions. In this work, we take an in-depth look at the causal awareness of these representations, from computational formalism to real-world practice. First, we cast doubt on the notion of non-causal robustness studied in the recent CausalAgents benchmark. We show that recent representations are already partially resilient to perturbations of non-causal agents, and yet modeling indirect causal effects involving mediator agents remains challenging. To address this challenge, we introduce a metric learning approach that regularizes latent representations with causal annotations. Our controlled experiments show that this approach not only leads to higher degrees of causal awareness but also yields stronger out-of-distribution robustness. To further operationalize it in practice, we propose a sim-to-real causal transfer method via cross-domain multi-task learning. Experiments on pedestrian datasets show that our method can substantially boost generalization, even in the absence of real-world causal annotations. We hope our work provides a new perspective on the challenges and potential pathways towards causally-aware representations of multi-agent interactions. Our code is available at https://github.com/socialcausality.", "url": "https://arxiv.org/abs/2312.04540"}, {"metadata": {"arXiv": "2312.04546", "Date": "Thu, 07 Dec 2023 18:58:40 ", "Title": "Adversarial Learning for Feature Shift Detection and Correction", "Authors": ["Miriam Barrabes", "Daniel Mas Montserrat", "Margarita Geleta", "Xavier Giro-i-Nieto", "Alexander G. Ioannidis"], "Categories": "cs.LG cs.AI stat.AP stat.ML"}, "abstract": "Data shift is a phenomenon present in many real-world applications, and while there are multiple methods attempting to detect shifts, the task of localizing and correcting the features originating such shifts has not been studied in depth. Feature shifts can occur in many datasets, including in multi-sensor data, where some sensors are malfunctioning, or in tabular and structured data, including biomedical, financial, and survey data, where faulty standardization and data processing pipelines can lead to erroneous features. In this work, we explore using the principles of adversarial learning, where the information from several discriminators trained to distinguish between two distributions is used to both detect the corrupted features and fix them in order to remove the distribution shift between datasets. We show that mainstream supervised classifiers, such as random forest or gradient boosting trees, combined with simple iterative heuristics, can localize and correct feature shifts, outperforming current statistical and neural network-based techniques. The code is available at https://github.com/AI-sandbox/DataFix.", "url": "https://arxiv.org/abs/2312.04546"}, {"metadata": {"arXiv": "2312.04374", "Date": "Thu, 07 Dec 2023 15:44:56 ", "Title": "Deep Dynamics: Vehicle Dynamics Modeling with a Physics-Informed Neural Network for Autonomous Racing", "Authors": ["John Chrosniak and Jingyun Ning and Madhur Behl"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["This work has been submitted to the IEEE RA-L for possible publication"], "ACM-class": "I.2.9; I.6"}, "abstract": "Autonomous racing is a critical research area for autonomous driving, presenting significant challenges in vehicle dynamics modeling, such as balancing model precision and computational efficiency at high speeds (>280kmph), where minor errors in modeling have severe consequences. Existing physics-based models for vehicle dynamics require elaborate testing setups and tuning, which are hard to implement, time-intensive, and cost-prohibitive. Conversely, purely data-driven approaches do not generalize well and cannot adequately ensure physical constraints on predictions. This paper introduces Deep Dynamics, a physics-informed neural network (PINN) for vehicle dynamics modeling of an autonomous racecar. It combines physics coefficient estimation and dynamical equations to accurately predict vehicle states at high speeds and includes a unique Physics Guard layer to ensure internal coefficient estimates remain within their nominal physical ranges. Open-loop and closed-loop performance assessments, using a physics-based simulator and full-scale autonomous Indy racecar data, highlight Deep Dynamics as a promising approach for modeling racecar vehicle dynamics.", "url": "https://arxiv.org/abs/2312.04374"}, {"metadata": {"arXiv": "2312.04549", "Date": "Thu, 07 Dec 2023 18:59:14 ", "Title": "PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play", "Authors": ["Lili Chen", "Shikhar Bahl", "Deepak Pathak"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "Comments": ["In CoRL 2023. Website at https://play-fusion.github.io"]}, "abstract": "Learning from unstructured and uncurated data has become the dominant paradigm for generative approaches in language and vision. Such unstructured and unguided behavior data, commonly known as play, is also easier to collect in robotics but much more difficult to learn from due to its inherently multimodal, noisy, and suboptimal nature. In this paper, we study this problem of learning goal-directed skill policies from unstructured play data which is labeled with language in hindsight. Specifically, we leverage advances in diffusion models to learn a multi-task diffusion model to extract robotic skills from play data. Using a conditional denoising diffusion process in the space of states and actions, we can gracefully handle the complexity and multimodality of play data and generate diverse and interesting robot behaviors. To make diffusion models more useful for skill learning, we encourage robotic agents to acquire a vocabulary of skills by introducing discrete bottlenecks into the conditional behavior generation process. In our experiments, we demonstrate the effectiveness of our approach across a wide variety of environments in both simulation and the real world. Results visualizations and videos at https://play-fusion.github.io", "url": "https://arxiv.org/abs/2312.04549"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

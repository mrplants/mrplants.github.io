<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.09810", "Date": "Wed, 19 Jul 2023 07:58:21 ", "Title": "GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity in Web Images Via a New Generalized KL Divergence", "Authors": ["Xia Huang", "Kai Fong Ernest Chong"], "Categories": "cs.CV cs.IT cs.LG math.IT", "Comments": ["Published (with open access) at International Journal of Computer Vision (IJCV", "2023). 25 pages", "8 figures. Code is available at: https://github.com/codetopaper/GenKL"], "ACM-class": "I.2.0; I.4.0", "DOI": "10.1007/s11263-023-01815-9"}, "abstract": "Web image datasets curated online inherently contain ambiguous in-distribution (ID) instances and out-of-distribution (OOD) instances, which we collectively call non-conforming (NC) instances. In many recent approaches for mitigating the negative effects of NC instances, the core implicit assumption is that the NC instances can be found via entropy maximization. For \"entropy\" to be well-defined, we are interpreting the output prediction vector of an instance as the parameter vector of a multinomial random variable, with respect to some trained model with a softmax output layer. Hence, entropy maximization is based on the idealized assumption that NC instances have predictions that are \"almost\" uniformly distributed. However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed. To tackle the limitation of entropy maximization, we propose $(\\alpha, \\beta)$-generalized KL divergence, $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$, which can be used to identify significantly more NC instances. Theoretical properties of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ are proven, and we also show empirically that a simple use of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ outperforms all baselines on the NC instance identification task. Building upon $(\\alpha,\\beta)$-generalized KL divergence, we also introduce a new iterative training framework, GenKL, that identifies and relabels NC instances. When evaluated on three web image datasets, Clothing1M, Food101/Food101N, and mini WebVision 1.0, we achieved new state-of-the-art classification accuracies: $81.34\\%$, $85.73\\%$ and $78.99\\%$/$92.54\\%$ (top-1/top-5), respectively.", "url": "https://arxiv.org/abs/2307.09810"}, {"metadata": {"arXiv": "2307.09931", "Date": "Wed, 19 Jul 2023 12:12:17 ", "Title": "DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration", "Authors": ["Matteo Ronchetti", "Wolfgang Wein", "Nassir Navab", "Oliver Zettinig", "Raphael Prevost"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["This preprint was submitted to MICCAI 2023. The Version of Record of this contribution will be published in Springer LNCS"]}, "abstract": "Multimodal image registration is a challenging but essential step for numerous image-guided procedures. Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities. Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings. We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration. We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data. Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one. Experiments on three different datasets demonstrate that our approach generalizes well beyond the training data, yielding a broad capture range even on unseen anatomies and modality pairs, without the need for specialized retraining. We make our training code and data publicly available.", "url": "https://arxiv.org/abs/2307.09931"}, {"metadata": {"arXiv": "2307.10062", "Date": "Wed, 19 Jul 2023 15:33:11 ", "Title": "Unsupervised Accuracy Estimation of Deep Visual Models using Domain-Adaptive Adversarial Perturbation without Source Samples", "Authors": ["JoonHo Lee", "Jae Oh Woo", "Hankyu Moon and Kwonho Lee"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Deploying deep visual models can lead to performance drops due to the discrepancies between source and target distributions. Several approaches leverage labeled source data to estimate target domain accuracy, but accessing labeled source data is often prohibitively difficult due to data confidentiality or resource limitations on serving devices. Our work proposes a new framework to estimate model accuracy on unlabeled target data without access to source data. We investigate the feasibility of using pseudo-labels for accuracy estimation and evolve this idea into adopting recent advances in source-free domain adaptation algorithms. Our approach measures the disagreement rate between the source hypothesis and the target pseudo-labeling function, adapted from the source hypothesis. We mitigate the impact of erroneous pseudo-labels that may arise due to a high ideal joint hypothesis risk by employing adaptive adversarial perturbation on the input of the target model. Our proposed source-free framework effectively addresses the challenging distribution shift scenarios and outperforms existing methods requiring source data and labels for training.", "url": "https://arxiv.org/abs/2307.10062"}, {"metadata": {"arXiv": "2307.09488", "Date": "Tue, 18 Jul 2023 07:11:14 ", "Title": "PLiNIO: A User-Friendly Library of Gradient-based Methods for Complexity-aware DNN Optimization", "Authors": ["Daniele Jahier Pagliari", "Matteo Risso", "Beatrice Alessandra Motetti", "Alessio Burrello"], "Categories": "cs.LG", "Comments": ["Accepted at the 2023 Forum on Specification & Design Languages (FDL)"]}, "abstract": "Accurate yet efficient Deep Neural Networks (DNNs) are in high demand, especially for applications that require their execution on constrained edge devices. Finding such DNNs in a reasonable time for new applications requires automated optimization pipelines since the huge space of hyper-parameter combinations is impossible to explore extensively by hand. In this work, we propose PLiNIO, an open-source library implementing a comprehensive set of state-of-the-art DNN design automation techniques, all based on lightweight gradient-based optimization, under a unified and user-friendly interface. With experiments on several edge-relevant tasks, we show that combining the various optimizations available in PLiNIO leads to rich sets of solutions that Pareto-dominate the considered baselines in terms of accuracy vs model size. Noteworthy, PLiNIO achieves up to 94.34% memory reduction for a <1% accuracy drop compared to a baseline architecture.", "url": "https://arxiv.org/abs/2307.09488"}, {"metadata": {"arXiv": "2307.09542", "Date": "Tue, 18 Jul 2023 18:36:29 ", "Title": "Can Neural Network Memorization Be Localized?", "Authors": ["Pratyush Maini", "Michael C. Mozer", "Hanie Sedghi", "Zachary C. Lipton", "J. Zico Kolter", "Chiyuan Zhang"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at ICML 2023"]}, "abstract": "Recent efforts at explaining the interplay of memorization and generalization in deep overparametrized networks have posited that neural networks $\\textit{memorize}$ \"hard\" examples in the final few layers of the model. Memorization refers to the ability to correctly predict on $\\textit{atypical}$ examples of the training set. In this work, we show that rather than being confined to individual layers, memorization is a phenomenon confined to a small set of neurons in various layers of the model. First, via three experimental sources of converging evidence, we find that most layers are redundant for the memorization of examples and the layers that contribute to example memorization are, in general, not the final layers. The three sources are $\\textit{gradient accounting}$ (measuring the contribution to the gradient norms from memorized and clean examples), $\\textit{layer rewinding}$ (replacing specific model weights of a converged model with previous training checkpoints), and $\\textit{retraining}$ (training rewound layers only on clean examples). Second, we ask a more generic question: can memorization be localized $\\textit{anywhere}$ in a model? We discover that memorization is often confined to a small number of neurons or channels (around 5) of the model. Based on these insights we propose a new form of dropout -- $\\textit{example-tied dropout}$ that enables us to direct the memorization of examples to an apriori determined set of neurons. By dropping out these neurons, we are able to reduce the accuracy on memorized examples from $100\\%\\to3\\%$, while also reducing the generalization gap.", "url": "https://arxiv.org/abs/2307.09542"}, {"metadata": {"arXiv": "2307.09550", "Date": "Tue, 18 Jul 2023 18:48:54 ", "Title": "The semantic landscape paradigm for neural networks", "Authors": ["Shreyas Gokhale"], "Categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech", "Comments": ["14 pages", "4 figures"]}, "abstract": "Deep neural networks exhibit a fascinating spectrum of phenomena ranging from predictable scaling laws to the unpredictable emergence of new capabilities as a function of training time, dataset size and network size. Analysis of these phenomena has revealed the existence of concepts and algorithms encoded within the learned representations of these networks. While significant strides have been made in explaining observed phenomena separately, a unified framework for understanding, dissecting, and predicting the performance of neural networks is lacking. Here, we introduce the semantic landscape paradigm, a conceptual and mathematical framework that describes the training dynamics of neural networks as trajectories on a graph whose nodes correspond to emergent algorithms that are instrinsic to the learned representations of the networks. This abstraction enables us to describe a wide range of neural network phenomena in terms of well studied problems in statistical physics. Specifically, we show that grokking and emergence with scale are associated with percolation phenomena, and neural scaling laws are explainable in terms of the statistics of random walks on graphs. Finally, we discuss how the semantic landscape paradigm complements existing theoretical and practical approaches aimed at understanding and interpreting deep neural networks.", "url": "https://arxiv.org/abs/2307.09550"}, {"metadata": {"arXiv": "2307.09552", "Date": "Tue, 18 Jul 2023 18:59:42 ", "Title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth", "Authors": ["Philipp M. Faller (1)", "Leena Chennuru Vankadara (2)", "Atalanti A. Mastakouri (2)", "Francesco Locatello (2)", "Dominik Janzing (2) ((1) Karlsruhe Institute of Technology", "(2) Amazon Research Tuebingen)"], "Categories": "cs.LG stat.ME stat.ML", "Comments": ["28 pages", "10 figures"]}, "abstract": "As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection.", "url": "https://arxiv.org/abs/2307.09552"}, {"metadata": {"arXiv": "2307.09613", "Date": "Thu, 13 Jul 2023 18:54:50 ", "Title": "Retrieving Continuous Time Event Sequences using Neural Temporal Point Processes with Learnable Hashing", "Authors": ["Vinayak Gupta and Srikanta Bedathur and Abir De"], "Categories": "cs.LG cs.IR", "Comments": ["Extended version of Gupta et al. [arXiv:2202.11485] (AAAI 2022). Under review in a journal"]}, "abstract": "Temporal sequences have become pervasive in various real-world applications. Consequently, the volume of data generated in the form of continuous time-event sequence(s) or CTES(s) has increased exponentially in the past few years. Thus, a significant fraction of the ongoing research on CTES datasets involves designing models to address downstream tasks such as next-event prediction, long-term forecasting, sequence classification etc. The recent developments in predictive modeling using marked temporal point processes (MTPP) have enabled an accurate characterization of several real-world applications involving the CTESs. However, due to the complex nature of these CTES datasets, the task of large-scale retrieval of temporal sequences has been overlooked by the past literature. In detail, by CTES retrieval we mean that for an input query sequence, a retrieval system must return a ranked list of relevant sequences from a large corpus. To tackle this, we propose NeuroSeqRet, a first-of-its-kind framework designed specifically for end-to-end CTES retrieval. Specifically, NeuroSeqRet introduces multiple enhancements over standard retrieval frameworks and first applies a trainable unwarping function on the query sequence which makes it comparable with corpus sequences, especially when a relevant query-corpus pair has individually different attributes. Next, it feeds the unwarped query sequence and the corpus sequence into MTPP-guided neural relevance models. We develop four variants of the relevance model for different kinds of applications based on the trade-off between accuracy and efficiency. We also propose an optimization framework to learn binary sequence embeddings from the relevance scores, suitable for the locality-sensitive hashing. Our experiments show the significant accuracy boost of NeuroSeqRet as well as the efficacy of our hashing mechanism.", "url": "https://arxiv.org/abs/2307.09613"}, {"metadata": {"arXiv": "2307.09619", "Date": "Tue, 18 Jul 2023 20:27:45 ", "Title": "Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning", "Authors": ["Zachary Charles", "Nicole Mitchell", "Krishna Pillutla", "Michael Reneer", "Zachary Garrett"], "Categories": "cs.LG cs.DC", "Comments": ["Dataset Grouper is available at https://github.com/google-research/dataset_grouper"]}, "abstract": "We introduce a library, Dataset Grouper, to create large-scale group-structured (e.g., federated) datasets, enabling federated learning simulation at the scale of foundation models. This library allows the creation of group-structured versions of existing datasets based on user-specified partitions, and directly leads to a variety of useful heterogeneous datasets that can be plugged into existing software frameworks. Dataset Grouper offers three key advantages. First, it scales to settings where even a single group's dataset is too large to fit in memory. Second, it provides flexibility, both in choosing the base (non-partitioned) dataset and in defining partitions. Finally, it is framework-agnostic. We empirically demonstrate that Dataset Grouper allows for large-scale federated language modeling simulations on datasets that are orders of magnitude larger than in previous work. Our experimental results show that algorithms like FedAvg operate more as meta-learning methods than as empirical risk minimization methods at this scale, suggesting their utility in downstream personalization and task-specific adaptation.", "url": "https://arxiv.org/abs/2307.09619"}, {"metadata": {"arXiv": "2307.09660", "Date": "Tue, 18 Jul 2023 22:01:08 ", "Title": "Neural Priority Queues for Graph Neural Networks", "Authors": ["Rishabh Jain", "Petar Veli\\v{c}kovi\\'c", "Pietro Li\\`o"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) have shown considerable success in neural algorithmic reasoning. Many traditional algorithms make use of an explicit memory in the form of a data structure. However, there has been limited exploration on augmenting GNNs with external memory. In this paper, we present Neural Priority Queues, a differentiable analogue to algorithmic priority queues, for GNNs. We propose and motivate a desiderata for memory modules, and show that Neural PQs exhibit the desiderata, and reason about their use with algorithmic reasoning. This is further demonstrated by empirical results on the CLRS-30 dataset. Furthermore, we find the Neural PQs useful in capturing long-range interactions, as empirically shown on a dataset from the Long-Range Graph Benchmark.", "url": "https://arxiv.org/abs/2307.09660"}, {"metadata": {"arXiv": "2307.09661", "Date": "Tue, 18 Jul 2023 22:03:43 ", "Title": "Physics-based Reduced Order Modeling for Uncertainty Quantification of Guided Wave Propagation using Bayesian Optimization", "Authors": ["G. I. Drakoulas", "T. V. Gortsas", "D. Polyzos"], "Categories": "cs.LG"}, "abstract": "In the context of digital twins, structural health monitoring (SHM) constitutes the backbone of condition-based maintenance, facilitating the interconnection between virtual and physical assets. Guided wave propagation (GWP) is commonly employed for the inspection of structures in SHM. However, GWP is sensitive to variations in the material properties of the structure, leading to false alarms. In this direction, uncertainty quantification (UQ) is regularly applied to improve the reliability of predictions. Computational mechanics is a useful tool for the simulation of GWP, and is often applied for UQ. Even so, the application of UQ methods requires numerous simulations, while large-scale, transient numerical GWP solutions increase the computational cost. Reduced order models (ROMs) are commonly employed to provide numerical results in a limited amount of time. In this paper, we propose a machine learning (ML)-based ROM, mentioned as BO-ML-ROM, to decrease the computational time related to the simulation of the GWP. The ROM is integrated with a Bayesian optimization (BO) framework, to adaptively sample the parameters for the ROM training. The finite element method is used for the simulation of the high-fidelity models. The formulated ROM is used for forward UQ of the GWP in an aluminum plate with varying material properties. To determine the influence of each parameter perturbation, a global, variance-based sensitivity analysis is implemented based on Sobol' indices. It is shown that Bayesian optimization outperforms one-shot sampling methods, both in terms of accuracy and speed-up. The predicted results reveal the efficiency of BO-ML-ROM for GWP and demonstrate its value for UQ.", "url": "https://arxiv.org/abs/2307.09661"}, {"metadata": {"arXiv": "2307.09672", "Date": "Tue, 18 Jul 2023 22:54:51 ", "Title": "Convex Geometry of ReLU-layers, Injectivity on the Ball and Local Reconstruction", "Authors": ["Daniel Haider", "Martin Ehler", "Peter Balazs"], "Categories": "cs.LG math.OC", "Comments": ["10 pages main paper + 2 pages appendix", "4 figures", "2 algorithms", "conference"]}, "abstract": "The paper uses a frame-theoretic setting to study the injectivity of a ReLU-layer on the closed ball of $\\mathbb{R}^n$ and its non-negative part. In particular, the interplay between the radius of the ball and the bias vector is emphasized. Together with a perspective from convex geometry, this leads to a computationally feasible method of verifying the injectivity of a ReLU-layer under reasonable restrictions in terms of an upper bound of the bias vector. Explicit reconstruction formulas are provided, inspired by the duality concept from frame theory. All this gives rise to the possibility of quantifying the invertibility of a ReLU-layer and a concrete reconstruction algorithm for any input vector on the ball.", "url": "https://arxiv.org/abs/2307.09672"}, {"metadata": {"arXiv": "2307.09742", "Date": "Wed, 19 Jul 2023 04:07:33 ", "Title": "Improved Distribution Matching for Dataset Condensation", "Authors": ["Ganlong Zhao", "Guanbin Li", "Yipeng Qin", "Yizhou Yu"], "Categories": "cs.LG cs.CV", "Comments": ["CVPR2023"]}, "abstract": "Dataset Condensation aims to condense a large dataset into a smaller one while maintaining its ability to train a well-performing model, thus reducing the storage cost and training effort in deep learning applications. However, conventional dataset condensation methods are optimization-oriented and condense the dataset by performing gradient or parameter matching during model optimization, which is computationally intensive even on small datasets and models. In this paper, we propose a novel dataset condensation method based on distribution matching, which is more efficient and promising. Specifically, we identify two important shortcomings of naive distribution matching (i.e., imbalanced feature numbers and unvalidated embeddings for distance computation) and address them with three novel techniques (i.e., partitioning and expansion augmentation, efficient and enriched model sampling, and class-aware distribution regularization). Our simple yet effective method outperforms most previous optimization-oriented methods with much fewer computational resources, thereby scaling data condensation to larger datasets and models. Extensive experiments demonstrate the effectiveness of our method. Codes are available at https://github.com/uitrbn/IDM", "url": "https://arxiv.org/abs/2307.09742"}, {"metadata": {"arXiv": "2307.09759", "Date": "Wed, 19 Jul 2023 05:41:40 ", "Title": "Constructing Extreme Learning Machines with zero Spectral Bias", "Authors": ["Kaumudi Joshi", "Vukka Snigdha", "Arya Kumar Bhattacharya"], "Categories": "cs.LG"}, "abstract": "The phenomena of Spectral Bias, where the higher frequency components of a function being learnt in a feedforward Artificial Neural Network (ANN) are seen to converge more slowly than the lower frequencies, is observed ubiquitously across ANNs. This has created technology challenges in fields where resolution of higher frequencies is crucial, like in Physics Informed Neural Networks (PINNs). Extreme Learning Machines (ELMs) that obviate an iterative solution process which provides the theoretical basis of Spectral Bias (SB), should in principle be free of the same. This work verifies the reliability of this assumption, and shows that it is incorrect. However, the structure of ELMs makes them naturally amenable to implementation of variants of Fourier Feature Embeddings, which have been shown to mitigate SB in ANNs. This approach is implemented and verified to completely eliminate SB, thus bringing into feasibility the application of ELMs for practical problems like PINNs where resolution of higher frequencies is essential.", "url": "https://arxiv.org/abs/2307.09759"}, {"metadata": {"arXiv": "2307.09768", "Date": "Wed, 19 Jul 2023 06:05:33 ", "Title": "How Curvature Enhance the Adaptation Power of Framelet GCNs", "Authors": ["Dai Shi", "Yi Guo", "Zhiqi Shao", "Junbin Gao"], "Categories": "cs.LG"}, "abstract": "Graph neural network (GNN) has been demonstrated powerful in modeling graph-structured data. However, despite many successful cases of applying GNNs to various graph classification and prediction tasks, whether the graph geometrical information has been fully exploited to enhance the learning performance of GNNs is not yet well understood. This paper introduces a new approach to enhance GNN by discrete graph Ricci curvature. Specifically, the graph Ricci curvature defined on the edges of a graph measures how difficult the information transits on one edge from one node to another based on their neighborhoods. Motivated by the geometric analogy of Ricci curvature in the graph setting, we prove that by inserting the curvature information with different carefully designed transformation function $\\zeta$, several known computational issues in GNN such as over-smoothing can be alleviated in our proposed model. Furthermore, we verified that edges with very positive Ricci curvature (i.e., $\\kappa_{i,j} \\approx 1$) are preferred to be dropped to enhance model's adaption to heterophily graph and one curvature based graph edge drop algorithm is proposed. Comprehensive experiments show that our curvature-based GNN model outperforms the state-of-the-art baselines in both homophily and heterophily graph datasets, indicating the effectiveness of involving graph geometric information in GNNs.", "url": "https://arxiv.org/abs/2307.09768"}, {"metadata": {"arXiv": "2307.09796", "Date": "Wed, 19 Jul 2023 07:30:01 ", "Title": "Forecasting Early with Meta Learning", "Authors": ["Shayan Jawed", "Kiran Madhusudhanan", "Vijaya Krishna Yalavarthi and Lars Schmidt-Thieme"], "Categories": "cs.LG", "Comments": ["IJCNN 2023"]}, "abstract": "In the early observation period of a time series, there might be only a few historic observations available to learn a model. However, in cases where an existing prior set of datasets is available, Meta learning methods can be applicable. In this paper, we devise a Meta learning method that exploits samples from additional datasets and learns to augment time series through adversarial learning as an auxiliary task for the target dataset. Our model (FEML), is equipped with a shared Convolutional backbone that learns features for varying length inputs from different datasets and has dataset specific heads to forecast for different output lengths. We show that FEML can meta learn across datasets and by additionally learning on adversarial generated samples as auxiliary samples for the target dataset, it can improve the forecasting performance compared to single task learning, and various solutions adapted from Joint learning, Multi-task learning and classic forecasting baselines.", "url": "https://arxiv.org/abs/2307.09796"}, {"metadata": {"arXiv": "2307.09801", "Date": "Wed, 19 Jul 2023 07:40:51 ", "Title": "Graph Federated Learning Based on the Decentralized Framework", "Authors": ["Peilin Liu", "Yanni Tang", "Mingyue Zhang", "and Wu Chen"], "Categories": "cs.LG cs.DC", "Comments": ["12 pages", "4 figures", "4 tables"]}, "abstract": "Graph learning has a wide range of applications in many scenarios, which require more need for data privacy. Federated learning is an emerging distributed machine learning approach that leverages data from individual devices or data centers to improve the accuracy and generalization of the model, while also protecting the privacy of user data. Graph-federated learning is mainly based on the classical federated learning framework i.e., the Client-Server framework. However, the Client-Server framework faces problems such as a single point of failure of the central server and poor scalability of network topology. First, we introduce the decentralized framework to graph-federated learning. Second, determine the confidence among nodes based on the similarity of data among nodes, subsequently, the gradient information is then aggregated by linear weighting based on confidence. Finally, the proposed method is compared with FedAvg, Fedprox, GCFL, and GCFL+ to verify the effectiveness of the proposed method. Experiments demonstrate that the proposed method outperforms other methods.", "url": "https://arxiv.org/abs/2307.09801"}, {"metadata": {"arXiv": "2307.09829", "Date": "Wed, 19 Jul 2023 08:34:25 ", "Title": "What do neural networks learn in image classification? A frequency shortcut perspective", "Authors": ["Shunxin Wang", "Raymond Veldhuis", "Christoph Brune", "Nicola Strisciuglio"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at ICCV2023"]}, "abstract": "Frequency analysis is useful for understanding the mechanisms of representation learning in neural networks (NNs). Most research in this area focuses on the learning dynamics of NNs for regression tasks, while little for classification. This study empirically investigates the latter and expands the understanding of frequency shortcuts. First, we perform experiments on synthetic datasets, designed to have a bias in different frequency bands. Our results demonstrate that NNs tend to find simple solutions for classification, and what they learn first during training depends on the most distinctive frequency characteristics, which can be either low- or high-frequencies. Second, we confirm this phenomenon on natural images. We propose a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts. The results show that frequency shortcuts can be texture-based or shape-based, depending on what best simplifies the objective. Third, we validate the transferability of frequency shortcuts on out-of-distribution (OOD) test sets. Our results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation. We recommend that future research should focus on effective training schemes mitigating frequency shortcut learning.", "url": "https://arxiv.org/abs/2307.09829"}, {"metadata": {"arXiv": "2307.09836", "Date": "Wed, 19 Jul 2023 08:47:41 ", "Title": "Near-Linear Time Projection onto the $\\ell_{1,\\infty}$ Ball; Application to Sparse Autoencoders", "Authors": ["Guillaume Perez and Laurent Condat and Michel Barlaud"], "Categories": "cs.LG math.OC", "Comments": ["22 pages", "8 figures"]}, "abstract": "Looking for sparsity is nowadays crucial to speed up the training of large-scale neural networks. Projections onto the $\\ell_{1,2}$ and $\\ell_{1,\\infty}$ are among the most efficient techniques to sparsify and reduce the overall cost of neural networks. In this paper, we introduce a new projection algorithm for the $\\ell_{1,\\infty}$ norm ball. The worst-case time complexity of this algorithm is $\\mathcal{O}\\big(nm+J\\log(nm)\\big)$ for a matrix in $\\mathbb{R}^{n\\times m}$. $J$ is a term that tends to 0 when the sparsity is high, and to $nm$ when the sparsity is low. Its implementation is easy and it is guaranteed to converge to the exact solution in a finite time. Moreover, we propose to incorporate the $\\ell_{1,\\infty}$ ball projection while training an autoencoder to enforce feature selection and sparsity of the weights. Sparsification appears in the encoder to primarily do feature selection due to our application in biology, where only a very small part ($<2\\%$) of the data is relevant. We show that both in the biological case and in the general case of sparsity that our method is the fastest.", "url": "https://arxiv.org/abs/2307.09836"}, {"metadata": {"arXiv": "2307.09883", "Date": "Wed, 19 Jul 2023 10:27:34 ", "Title": "Symmetric Equilibrium Learning of VAEs", "Authors": ["Boris Flach and Dmitrij Schlesinger and Alexander Shekhovtsov"], "Categories": "cs.LG", "Comments": ["13 pages", "6 figures"]}, "abstract": "We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa. The standard learning approach for VAEs, i.e. maximisation of the evidence lower bound (ELBO), has an obvious asymmetry in that respect. Moreover, it requires a closed form a-priori latent distribution. This limits the applicability of VAEs in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors. We propose a Nash equilibrium learning approach that relaxes these restrictions and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling. The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks. We show experimentally that the models learned by this method are comparable to those obtained by ELBO learning and demonstrate its applicability for tasks that are not accessible by standard VAE learning.", "url": "https://arxiv.org/abs/2307.09883"}, {"metadata": {"arXiv": "2307.09912", "Date": "Wed, 19 Jul 2023 11:32:24 ", "Title": "Deep projection networks for learning time-homogeneous dynamical systems", "Authors": ["Vladimir R. Kostic", "Pietro Novelli", "Riccardo Grazzi", "Karim Lounici", "Massimiliano Pontil"], "Categories": "cs.LG"}, "abstract": "We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data. This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables. The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA). However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios. Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation. We apply our method to challenging discrete dynamical systems, discussing improvements over previous methods, as well as to continuous dynamical systems.", "url": "https://arxiv.org/abs/2307.09912"}, {"metadata": {"arXiv": "2307.09943", "Date": "Wed, 19 Jul 2023 12:35:16 ", "Title": "Impatient Bandits: Optimizing for the Long-Term Without Delay", "Authors": ["Thomas McDonald", "Lucas Maystre", "Mounia Lalmas", "Daniel Russo", "Kamil Ciosek"], "Categories": "cs.LG stat.ML", "Comments": ["Presented at the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23)"]}, "abstract": "Recommender systems are a ubiquitous feature of online platforms. Increasingly, they are explicitly tasked with increasing users' long-term satisfaction. In this context, we study a content exploration task, which we formalize as a multi-armed bandit problem with delayed rewards. We observe that there is an apparent trade-off in choosing the learning signal: Waiting for the full reward to become available might take several weeks, hurting the rate at which learning happens, whereas measuring short-term proxy rewards reflects the actual long-term goal only imperfectly. We address this challenge in two steps. First, we develop a predictive model of delayed rewards that incorporates all information obtained to date. Full observations as well as partial (short or medium-term) outcomes are combined through a Bayesian filter to obtain a probabilistic belief. Second, we devise a bandit algorithm that takes advantage of this new predictive model. The algorithm quickly learns to identify content aligned with long-term success by carefully balancing exploration and exploitation. We apply our approach to a podcast recommendation problem, where we seek to identify shows that users engage with repeatedly over two months. We empirically validate that our approach results in substantially better performance compared to approaches that either optimize for short-term proxies, or wait for the long-term outcome to be fully realized.", "url": "https://arxiv.org/abs/2307.09943"}, {"metadata": {"arXiv": "2307.09977", "Date": "Wed, 19 Jul 2023 13:33:43 ", "Title": "Learner Referral for Cost-Effective Federated Learning Over Hierarchical IoT Networks", "Authors": ["Yulan Gao", "Ziqiang Ye", "Yue Xiao", "and Wei Xiang"], "Categories": "cs.LG cs.NI"}, "abstract": "The paradigm of federated learning (FL) to address data privacy concerns by locally training parameters on resource-constrained clients in a distributed manner has garnered significant attention. Nonetheless, FL is not applicable when not all clients within the coverage of the FL server are registered with the FL network. To bridge this gap, this paper proposes joint learner referral aided federated client selection (LRef-FedCS), along with communications and computing resource scheduling, and local model accuracy optimization (LMAO) methods. These methods are designed to minimize the cost incurred by the worst-case participant and ensure the long-term fairness of FL in hierarchical Internet of Things (HieIoT) networks. Utilizing the Lyapunov optimization technique, we reformulate the original problem into a stepwise joint optimization problem (JOP). Subsequently, to tackle the mixed-integer non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO through the centralized method and self-adaptive global best harmony search (SGHS) algorithm, respectively. To enhance scalability, we further propose a distributed LRef-FedCS approach based on a matching game to replace the centralized method described above. Numerical simulations and experimental results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS approach could achieve a good balance between pursuing high global accuracy and reducing cost.", "url": "https://arxiv.org/abs/2307.09977"}, {"metadata": {"arXiv": "2307.09988", "Date": "Wed, 19 Jul 2023 13:49:12 ", "Title": "TinyTrain: Deep Neural Network Training at the Extreme Edge", "Authors": ["Young D. Kwon", "Rui Li", "Stylianos I. Venieris", "Jagmohan Chauhan", "Nicholas D. Lane", "and Cecilia Mascolo"], "Categories": "cs.LG cs.CV"}, "abstract": "On-device training is essential for user personalisation and privacy. With the pervasiveness of IoT devices and microcontroller units (MCU), this task becomes more challenging due to the constrained memory and compute resources, and the limited availability of labelled user data. Nonetheless, prior works neglect the data scarcity issue, require excessively long training time (e.g. a few hours), or induce substantial accuracy loss ($\\geq$10\\%). We propose TinyTrain, an on-device training approach that drastically reduces training time by selectively updating parts of the model and explicitly coping with data scarcity. TinyTrain introduces a task-adaptive sparse-update method that dynamically selects the layer/channel based on a multi-objective criterion that jointly captures user data, the memory, and the compute capabilities of the target device, leading to high accuracy on unseen tasks with reduced computation and memory footprint. TinyTrain outperforms vanilla fine-tuning of the entire network by 3.6-5.0\\% in accuracy, while reducing the backward-pass memory and computation cost by up to 2,286$\\times$ and 7.68$\\times$, respectively. Targeting broadly used real-world edge devices, TinyTrain achieves 9.5$\\times$ faster and 3.5$\\times$ more energy-efficient training over status-quo approaches, and 2.8$\\times$ smaller memory footprint than SOTA approaches, while remaining within the 1 MB memory envelope of MCU-grade platforms.", "url": "https://arxiv.org/abs/2307.09988"}, {"metadata": {"arXiv": "2307.09994", "Date": "Wed, 19 Jul 2023 13:58:01 ", "Title": "Impact of Disentanglement on Pruning Neural Networks", "Authors": ["Carl Shneider", "Peyman Rostami", "Anis Kacem", "Nilotpal Sinha", "Abd El Rahman Shabayek", "Djamila Aouada"], "Categories": "cs.LG cs.CV eess.SP", "Comments": ["Presented in ISCS23"], "Report-no": "ISCS23-19"}, "abstract": "Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency. This can be realized via efficient model compression. Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand. We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification. In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works.", "url": "https://arxiv.org/abs/2307.09994"}, {"metadata": {"arXiv": "2307.10022", "Date": "Wed, 19 Jul 2023 15:05:55 ", "Title": "Europepolls: A Dataset of Country-Level Opinion Polling Data for the European Union and the UK", "Authors": ["Konstantinos Pitas"], "Categories": "cs.LG"}, "abstract": "I propose an open dataset of country-level historical opinion polling data for the European Union and the UK. The dataset aims to fill a gap in available opinion polling data for the European Union. Some existing datasets are restricted to the past five years, limiting research opportunities. At the same time, some larger proprietary datasets exist but are available only in a visual preprocessed time series format. Finally, while other large datasets for individual countries might exist, these could be inaccessible due to language barriers. The data was gathered from Wikipedia, and preprocessed using the pandas library. Both the raw and the preprocessed data are in the .csv format. I hope that given the recent advances in LLMs and deep learning in general, this large dataset will enable researchers to uncover complex interactions between multimodal data (news articles, economic indicators, social media) and voting behavior. The raw data, the preprocessed data, and the preprocessing scripts are available on GitHub.", "url": "https://arxiv.org/abs/2307.10022"}, {"metadata": {"arXiv": "2307.10026", "Date": "Wed, 19 Jul 2023 15:11:04 ", "Title": "Contextual Reliability: When Different Features Matter in Different Contexts", "Authors": ["Gaurav Ghosal", "Amrith Setlur", "Daniel S. Brown", "Anca D. Dragan", "and Aditi Raghunathan"], "Categories": "cs.LG", "Comments": ["ICML 2023 Camera Ready Version"]}, "abstract": "Deep neural networks often fail catastrophically by relying on spurious correlations. Most prior work assumes a clear dichotomy into spurious and reliable features; however, this is often unrealistic. For example, most of the time we do not want an autonomous car to simply copy the speed of surrounding cars -- we don't want our car to run a red light if a neighboring car does so. However, we cannot simply enforce invariance to next-lane speed, since it could provide valuable information about an unobservable pedestrian at a crosswalk. Thus, universally ignoring features that are sometimes (but not always) reliable can lead to non-robust performance. We formalize a new setting called contextual reliability which accounts for the fact that the \"right\" features to use may vary depending on the context. We propose and analyze a two-stage framework called Explicit Non-spurious feature Prediction (ENP) which first identifies the relevant features to use for a given context, then trains a model to rely exclusively on these features. Our work theoretically and empirically demonstrates the advantages of ENP over existing methods and provides new benchmarks for contextual reliability.", "url": "https://arxiv.org/abs/2307.10026"}, {"metadata": {"arXiv": "2307.10073", "Date": "Fri, 14 Jul 2023 12:54:56 ", "Title": "Scalable Deep Learning for RNA Secondary Structure Prediction", "Authors": ["J\\\"org K.H. Franke", "Frederic Runge", "Frank Hutter"], "Categories": "cs.LG q-bio.BM", "Comments": ["Accepted at the 2023 ICML Workshop on Computational Biology. Honolulu", "Hawaii", "USA", "2023"]}, "abstract": "The field of RNA secondary structure prediction has made significant progress with the adoption of deep learning techniques. In this work, we present the RNAformer, a lean deep learning model using axial attention and recycling in the latent space. We gain performance improvements by designing the architecture for modeling the adjacency matrix directly in the latent space and by scaling the size of the model. Our approach achieves state-of-the-art performance on the popular TS0 benchmark dataset and even outperforms methods that use external information. Further, we show experimentally that the RNAformer can learn a biophysical model of the RNA folding process.", "url": "https://arxiv.org/abs/2307.10073"}, {"metadata": {"arXiv": "2307.10078", "Date": "Wed, 19 Jul 2023 15:51:25 ", "Title": "A Dual Formulation for Probabilistic Principal Component Analysis", "Authors": ["Henri De Plaen", "Johan A. K. Suykens"], "Categories": "cs.LG stat.ML", "Comments": ["ICML 2023 Workshop on Duality for Modern Machine Learning (DP4ML). 14 pages (8 main + 5 appendix)", "4 figures and 4 tables"]}, "abstract": "In this paper, we characterize Probabilistic Principal Component Analysis in Hilbert spaces and demonstrate how the optimal solution admits a representation in dual space. This allows us to develop a generative framework for kernel methods. Furthermore, we show how it englobes Kernel Principal Component Analysis and illustrate its working on a toy and a real dataset.", "url": "https://arxiv.org/abs/2307.10078"}, {"metadata": {"arXiv": "2307.10088", "Date": "Wed, 19 Jul 2023 15:57:24 ", "Title": "Android in the Wild: A Large-Scale Dataset for Android Device Control", "Authors": ["Christopher Rawles", "Alice Li", "Daniel Rodriguez", "Oriana Riva", "Timothy Lillicrap"], "Categories": "cs.LG cs.CL cs.HC"}, "abstract": "There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly controlling its user interface. We present a dataset for device-control research, Android in the Wild (AITW), which is orders of magnitude larger than current datasets. The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions. It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10-13),and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It contains multi-step tasks that require semantic understanding of language and visual context. This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance. And, instead of simple UI element-based actions, the action space consists of precise gestures (e.g., horizontal scrolls to operate carousel widgets). We organize our dataset to encourage robustness analysis of device-control systems, i.e., how well a system performs in the presence of new task descriptions, new applications, or new platform versions. We develop two agents and report performance across the dataset. The dataset is available at https://github.com/google-research/google-research/tree/master/android_in_the_wild.", "url": "https://arxiv.org/abs/2307.10088"}, {"metadata": {"arXiv": "2307.10093", "Date": "Wed, 19 Jul 2023 16:00:29 ", "Title": "Revisiting invariances and introducing priors in Gromov-Wasserstein distances", "Authors": ["Pinar Demetci", "Quang Huy Tran", "Ievgen Redko", "Ritambhara Singh"], "Categories": "cs.LG q-bio.GN stat.ML"}, "abstract": "Gromov-Wasserstein distance has found many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariance property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport-based distance, called Augmented Gromov-Wasserstein, that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We present theoretical insights into the proposed metric. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and a transfer learning scenario in machine learning.", "url": "https://arxiv.org/abs/2307.10093"}, {"metadata": {"arXiv": "2307.09564", "Date": "Thu, 13 Jul 2023 11:30:50 ", "Title": "Reinforcement Learning for Syntax-Guided Synthesis", "Authors": ["Julian Parsert and Elizabeth Polgreen"], "Categories": "cs.AI"}, "abstract": "Program synthesis is the task of automatically generating code based on a specification. In Syntax-Guided Synthesis(SyGuS) this specification is a combination of a syntactic template and a logical formula, and any generated code is proven to satisfy both. Techniques like SyGuS are critical to guaranteeing correct synthesis results. Despite the proliferation of machine learning in other types of program synthesis, state-of-the-art techniques in SyGuS are still driven by automated reasoning tools and simple enumeration. We hypothesize this is for two reasons: first the complexity of the search problem, and second the relatively small data sets available. In this work, we tackle these challenges by framing general SyGuS problems as a tree-search, and present a reinforcement learning guided synthesis algorithm for SyGuS based on Monte-Carlo Tree Search (MCTS). Our algorithm incorporates learned policy and value functions combined with the upper confidence bound for trees to balance exploration and exploitation. We incorporate this search procedure in a reinforcement learning setup in order to iteratively improve our policy and value estimators which are based on boosted tree models. To address the scarcity of training data, we present a method for automatically generating training data for SyGuS based on \\emph{anti-unification} of existing first-order satisfiability problems, which we use to train our MCTS policy. We implement and evaluate this setup and demonstrate that learned policy and value improve the synthesis performance over a baseline enumerator by over $26$ percentage points in the training and testing sets. With these results our tool outperforms state-of-the-art-tools such as CVC5 on the training set and performs comparably on the testing set. We make our data set publicly available, enabling further application of machine learning methods to the SyGuS problem.", "url": "https://arxiv.org/abs/2307.09564"}, {"metadata": {"arXiv": "2307.09673", "Date": "Tue, 18 Jul 2023 22:55:04 ", "Title": "What's meant by explainable model: A Scoping Review", "Authors": ["Mallika Mainali", "Rosina O Weber"], "Categories": "cs.AI", "Comments": ["8 pages", "2 figures. This paper was accepted at IJCAI 2023 workshop on Explainable Artificial Intelligence (XAI)"]}, "abstract": "We often see the term explainable in the titles of papers that describe applications based on artificial intelligence (AI). However, the literature in explainable artificial intelligence (XAI) indicates that explanations in XAI are application- and domain-specific, hence requiring evaluation whenever they are employed to explain a model that makes decisions for a specific application problem. Additionally, the literature reveals that the performance of post-hoc methods, particularly feature attribution methods, varies substantially hinting that they do not represent a solution to AI explainability. Therefore, when using XAI methods, the quality and suitability of their information outputs should be evaluated within the specific application. For these reasons, we used a scoping review methodology to investigate papers that apply AI models and adopt methods to generate post-hoc explanations while referring to said models as explainable. This paper investigates whether the term explainable model is adopted by authors under the assumption that incorporating a post-hoc XAI method suffices to characterize a model as explainable. To inspect this problem, our review analyzes whether these papers conducted evaluations. We found that 81% of the application papers that refer to their approaches as an explainable model do not conduct any form of evaluation on the XAI method they used.", "url": "https://arxiv.org/abs/2307.09673"}, {"metadata": {"arXiv": "2307.09711", "Date": "Wed, 19 Jul 2023 01:46:38 ", "Title": "Two Tales of Platoon Intelligence for Autonomous Mobility Control: Enabling Deep Learning Recipes", "Authors": ["Soohyun Park", "Haemin Lee", "Chanyoung Park", "Soyi Jung", "Minseok Choi", "Joongheon Kim"], "Categories": "cs.AI", "Comments": ["8 pages", "3 figures"]}, "abstract": "This paper presents the deep learning-based recent achievements to resolve the problem of autonomous mobility control and efficient resource management of autonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning (MARL), and (ii) neural Myerson auction. Representatively, communication network (CommNet), which is one of the most popular MARL algorithms, is introduced to enable multiple agents to take actions in a distributed manner for their shared goals by training all agents' states and actions in a single neural network. Moreover, the neural Myerson auction guarantees trustfulness among multiple agents as well as achieves the optimal revenue of highly dynamic systems. Therefore, we survey the recent studies on autonomous mobility control based on MARL and neural Myerson auction. Furthermore, we emphasize that integration of MARL and neural Myerson auction is expected to be critical for efficient and trustful autonomous mobility services.", "url": "https://arxiv.org/abs/2307.09711"}, {"metadata": {"arXiv": "2307.09721", "Date": "Wed, 19 Jul 2023 02:11:19 ", "Title": "Multi-Grained Multimodal Interaction Network for Entity Linking", "Authors": ["Pengfei Luo", "Tong Xu", "Shiwei Wu", "Chen Zhu", "Linli Xu", "Enhong Chen"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted by KDD 2023"]}, "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous mentions to a multimodal knowledge graph, has attracted wide attention in recent years. Though large efforts have been made to explore the complementary effect among multiple modalities, however, they may fail to fully absorb the comprehensive expression of abbreviated textual context and implicit visual indication. Even worse, the inevitable noisy data may cause inconsistency of different modalities during the learning process, which severely degenerates the performance. To address the above issues, in this paper, we propose a novel Multi-GraIned Multimodal InteraCtion Network $\\textbf{(MIMIC)}$ framework for solving the MEL task. Specifically, the unified inputs of mentions and entities are first encoded by textual/visual encoders separately, to extract global descriptive features and local detailed features. Then, to derive the similarity matching score for each mention-entity pair, we device three interaction units to comprehensively explore the intra-modal interaction and inter-modal fusion among features of entities and mentions. In particular, three modules, namely the Text-based Global-Local interaction Unit (TGLU), Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based interaction Unit (CMFU) are designed to capture and integrate the fine-grained representation lying in abbreviated text and implicit visual cues. Afterwards, we introduce a unit-consistency objective function via contrastive learning to avoid inconsistency and model degradation. Experimental results on three public benchmark datasets demonstrate that our solution outperforms various state-of-the-art baselines, and ablation studies verify the effectiveness of designed modules.", "url": "https://arxiv.org/abs/2307.09721"}, {"metadata": {"arXiv": "2307.09777", "Date": "Wed, 19 Jul 2023 06:36:01 ", "Title": "Generating Redstone Style Cities in Minecraft", "Authors": ["Shuo Huang", "Chengpeng Hu", "Julian Togelius", "Jialin Liu"], "Categories": "cs.AI"}, "abstract": "Procedurally generating cities in Minecraft provides players more diverse scenarios and could help understand and improve the design of cities in other digital worlds and the real world. This paper presents a city generator that was submitted as an entry to the 2023 Edition of Minecraft Settlement Generation Competition for Minecraft. The generation procedure is composed of six main steps, namely vegetation clearing, terrain reshaping, building layout generation, route planning, streetlight placement, and wall construction. Three algorithms, including a heuristic-based algorithm, an evolving layout algorithm, and a random one are applied to generate the building layout, thus determining where to place different redstone style buildings, and tested by generating cities on random maps in limited time. Experimental results show that the heuristic-based algorithm is capable of finding an acceptable building layout faster for flat maps, while the evolving layout algorithm performs better in evolving layout for rugged maps. A user study is conducted to compare our generator with outstanding entries of the competition's 2022 edition using the competition's evaluation criteria and shows that our generator performs well in the adaptation and functionality criteria", "url": "https://arxiv.org/abs/2307.09777"}, {"metadata": {"arXiv": "2307.09831", "Date": "Wed, 19 Jul 2023 08:36:31 ", "Title": "A Fast and Map-Free Model for Trajectory Prediction in Traffics", "Authors": ["Junhong Xiang", "Jingmin Zhang and Zhixiong Nan"], "Categories": "cs.AI", "Comments": ["7 pages", "3 figures"]}, "abstract": "To handle the two shortcomings of existing methods, (i)nearly all models rely on high-definition (HD) maps, yet the map information is not always available in real traffic scenes and HD map-building is expensive and time-consuming and (ii) existing models usually focus on improving prediction accuracy at the expense of reducing computing efficiency, yet the efficiency is crucial for various real applications, this paper proposes an efficient trajectory prediction model that is not dependent on traffic maps. The core idea of our model is encoding single-agent's spatial-temporal information in the first stage and exploring multi-agents' spatial-temporal interactions in the second stage. By comprehensively utilizing attention mechanism, LSTM, graph convolution network and temporal transformer in the two stages, our model is able to learn rich dynamic and interaction information of all agents. Our model achieves the highest performance when comparing with existing map-free methods and also exceeds most map-based state-of-the-art methods on the Argoverse dataset. In addition, our model also exhibits a faster inference speed than the baseline methods.", "url": "https://arxiv.org/abs/2307.09831"}, {"metadata": {"arXiv": "2307.09858", "Date": "Wed, 19 Jul 2023 09:38:52 ", "Title": "Towards Reliable Rare Category Analysis on Graphs via Individual Calibration", "Authors": ["Longfeng Wu", "Bowen Lei", "Dongkuan Xu", "Dawei Zhou"], "Categories": "cs.AI"}, "abstract": "Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis. Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution. While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis? How can we quantify the uncertainty in the learning process and enable reliable rare category analysis? To answer these questions, we start by investigating miscalibration in existing RCA methods. Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confident in predicting majority classes. Motivated by the observation, we propose a novel individual calibration framework, named CALIRARE, for alleviating the unique challenges of RCA, thus enabling reliable rare category analysis. In particular, to quantify the uncertainties in RCA, we develop a node-level uncertainty quantification algorithm to model the overlapping support regions with high uncertainty; to handle the rarity of minority classes in miscalibration calculation, we generalize the distribution-based calibration metric to the instance level and propose the first individual calibration measurement on graphs named Expected Individual Calibration Error (EICE). We perform extensive experimental evaluations on real-world datasets, including rare category characterization and model calibration tasks, which demonstrate the significance of our proposed framework.", "url": "https://arxiv.org/abs/2307.09858"}, {"metadata": {"arXiv": "2307.09878", "Date": "Wed, 19 Jul 2023 10:17:35 ", "Title": "Amortised Experimental Design and Parameter Estimation for User Models of Pointing", "Authors": ["Antti Keurulainen", "Isak Westerlund", "Oskar Keurulainen", "Andrew Howes"], "Categories": "cs.AI", "Journal-ref": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany", "DOI": "10.1145/3544548.3581483"}, "abstract": "User models play an important role in interaction design, supporting automation of interaction design choices. In order to do so, model parameters must be estimated from user data. While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement. In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants. Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data. The approach is demonstrated for three progressively complex models of pointing.", "url": "https://arxiv.org/abs/2307.09878"}, {"metadata": {"arXiv": "2307.09891", "Date": "Wed, 19 Jul 2023 10:42:56 ", "Title": "Amortised Design Optimization for Item Response Theory", "Authors": ["Antti Keurulainen", "Isak Westerlund", "Oskar Keurulainen", "Andrew Howes"], "Categories": "cs.AI", "Comments": ["Artificial Intelligence in Education. AIED 2023. Communications in Computer and Information Science", "vol 1831. Springer", "Cham"]}, "abstract": "Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology. In education, IRT is used to infer student abilities and characteristics of test items from student responses. Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities. Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications. In response, we propose incorporating amortised experimental design into IRT. Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data. The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes. During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close to real-time, by taking into account the history of experiments and outcomes.", "url": "https://arxiv.org/abs/2307.09891"}, {"metadata": {"arXiv": "2307.09905", "Date": "Wed, 19 Jul 2023 11:08:59 ", "Title": "PyTAG: Challenges and Opportunities for Reinforcement Learning in Tabletop Games", "Authors": ["Martin Balla", "George E.M. Long", "Dominik Jeurissen", "James Goodman", "Raluca D. Gaina", "Diego Perez-Liebana"], "Categories": "cs.AI", "Comments": ["Accepted for Publication in: IEEE Conference on Games (2023)"]}, "abstract": "In recent years, Game AI research has made important breakthroughs using Reinforcement Learning (RL). Despite this, RL for modern tabletop games has gained little to no attention, even when they offer a range of unique challenges compared to video games. To bridge this gap, we introduce PyTAG, a Python API for interacting with the Tabletop Games framework (TAG). TAG contains a growing set of more than 20 modern tabletop games, with a common API for AI agents. We present techniques for training RL agents in these games and introduce baseline results after training Proximal Policy Optimisation algorithms on a subset of games. Finally, we discuss the unique challenges complex modern tabletop games provide, now open to RL research through PyTAG.", "url": "https://arxiv.org/abs/2307.09905"}, {"metadata": {"arXiv": "2307.09909", "Date": "Wed, 19 Jul 2023 11:25:12 ", "Title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining", "Authors": ["Urszula Jessen", "Michal Sroka", "Dirk Fahland"], "Categories": "cs.AI", "Comments": ["11 pages", "3 figures"]}, "abstract": "This research investigates the application of Large Language Models (LLMs) to augment conversational agents in process mining, aiming to tackle its inherent complexity and diverse skill requirements. While LLM advancements present novel opportunities for conversational process mining, generating efficient outputs is still a hurdle. We propose an innovative approach that amend many issues in existing solutions, informed by prior research on Natural Language Processing (NLP) for conversational agents. Leveraging LLMs, our framework improves both accessibility and agent performance, as demonstrated by experiments on public question and data sets. Our research sets the stage for future explorations into LLMs' role in process mining and concludes with propositions for enhancing LLM memory, implementing real-time user testing, and examining diverse data sets.", "url": "https://arxiv.org/abs/2307.09909"}, {"metadata": {"arXiv": "2307.10004", "Date": "Wed, 19 Jul 2023 14:38:30 ", "Title": "6G Network Business Support System", "Authors": ["Ye Ouyang", "Yaqin Zhang", "Peng Wang", "Yunxin Liu", "Wen Qiao", "Jun Zhu", "Yang Liu", "Feng Zhang", "Shuling Wang", "Xidong Wang"], "Categories": "cs.AI"}, "abstract": "6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society. As the core support system for mobile communication network, 6 6G BSS need to integrate with new business models brought about by the development of the next-generation Internet and IT, upgrade from \"network-centric\" to \"business and service centric\" and \"customer-centric\". 6G OSS and BSS systems need to strengthen their integration to improve the operational efficiency and benefits of customers by connecting the digital intelligence support capabilities on both sides of supply and demand. This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G BSS systems. It also presents an evolutionary roadmap and technological prospects for the BSS systems from 5G to 6G.", "url": "https://arxiv.org/abs/2307.10004"}, {"metadata": {"arXiv": "2307.10085", "Date": "Wed, 19 Jul 2023 15:55:25 ", "Title": "A decision making framework for recommended maintenance of road segments", "Authors": ["Haoyu Sun", "Yan Yan"], "Categories": "cs.AI", "Comments": ["20 pages", "8 figures", "4 tables", "and 2 algorithms"], "ACM-class": "F.2.2, I.2.7, I.2.1, J.0"}, "abstract": "With the rapid development of global road transportation, countries worldwide have completed the construction of road networks. However, the ensuing challenge lies in the maintenance of existing roads. It is well-known that countries allocate limited budgets to road maintenance projects, and road management departments face difficulties in making scientifically informed maintenance decisions. Therefore, integrating various artificial intelligence decision-making techniques to thoroughly explore historical maintenance data and adapt them to the context of road maintenance scientific decision-making has become an urgent issue. This integration aims to provide road management departments with more scientific tools and evidence for decision-making. The framework proposed in this paper primarily addresses the following four issues: 1) predicting the pavement performance of various routes, 2) determining the prioritization of maintenance routes, 3) making maintenance decisions based on the evaluation of the effects of past maintenance, and considering comprehensive technical and management indicators, and 4) determining the prioritization of maintenance sections based on the maintenance effectiveness and recommended maintenance effectiveness. By tackling these four problems, the framework enables intelligent decision-making for the optimal maintenance plan and maintenance sections, taking into account limited funding and historical maintenance management experience.", "url": "https://arxiv.org/abs/2307.10085"}, {"metadata": {"arXiv": "2307.09588", "Date": "Tue, 18 Jul 2023 19:51:28 ", "Title": "Automating Wood Species Detection and Classification in Microscopic Images of Fibrous Materials with Deep Learning", "Authors": ["Lars Nieradzik", "J\\\"ordis Sieburg-Rockel", "Stephanie Helmling", "Janis Keuper", "Thomas Weibel", "Andrea Olbrich", "Henrike Stephani"], "Categories": "cs.CV cs.AI"}, "abstract": "We have developed a methodology for the systematic generation of a large image dataset of macerated wood references, which we used to generate image data for nine hardwood genera. This is the basis for a substantial approach to automate, for the first time, the identification of hardwood species in microscopic images of fibrous materials by deep learning. Our methodology includes a flexible pipeline for easy annotation of vessel elements. We compare the performance of different neural network architectures and hyperparameters. Our proposed method performs similarly well to human experts. In the future, this will improve controls on global wood fiber product flows to protect forests.", "url": "https://arxiv.org/abs/2307.09588"}, {"metadata": {"arXiv": "2307.09636", "Date": "Tue, 18 Jul 2023 20:56:41 ", "Title": "Traffic-Domain Video Question Answering with Automatic Captioning", "Authors": ["Ehsan Qasemi", "Jonathan M. Francis", "Alessandro Oltramari"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in ITSC2023"]}, "abstract": "Video Question Answering (VidQA) exhibits remarkable potential in facilitating advanced machine reasoning capabilities within the domains of Intelligent Traffic Monitoring and Intelligent Transportation Systems. Nevertheless, the integration of urban traffic scene knowledge into VidQA systems has received limited attention in previous research endeavors. In this work, we present a novel approach termed Traffic-domain Video Question Answering with Automatic Captioning (TRIVIA), which serves as a weak-supervision technique for infusing traffic-domain knowledge into large video-language models. Empirical findings obtained from the SUTD-TrafficQA task highlight the substantial enhancements achieved by TRIVIA, elevating the accuracy of representative video-language models by a remarkable 6.5 points (19.88%) compared to baseline settings. This pioneering methodology holds great promise for driving advancements in the field, inspiring researchers and practitioners alike to unlock the full potential of emerging video-language models in traffic-related applications.", "url": "https://arxiv.org/abs/2307.09636"}, {"metadata": {"arXiv": "2307.09755", "Date": "Wed, 19 Jul 2023 05:39:15 ", "Title": "Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation", "Authors": ["Changqi Wang", "Haoyu Xie", "Yuhui Yuan", "Chong Fu", "Xiangyu Yue"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model with limited labeled images and a substantial volume of unlabeled images. To improve the robustness of representations, powerful methods introduce a pixel-wise contrastive learning approach in latent space (i.e., representation space) that aggregates the representations to their prototypes in a fully supervised manner. However, previous contrastive-based S4 methods merely rely on the supervision from the model's output (logits) in logit space during unlabeled training. In contrast, we utilize the outputs in both logit space and representation space to obtain supervision in a collaborative way. The supervision from two spaces plays two roles: 1) reduces the risk of over-fitting to incorrect semantic information in logits with the help of representations; 2) enhances the knowledge exchange between the two spaces. Furthermore, unlike previous approaches, we use the similarity between representations and prototypes as a new indicator to tilt training those under-performing representations and achieve a more efficient contrastive learning process. Results on two public benchmarks demonstrate the competitive performance of our method compared with state-of-the-art methods.", "url": "https://arxiv.org/abs/2307.09755"}, {"metadata": {"arXiv": "2307.09763", "Date": "Wed, 19 Jul 2023 05:46:56 ", "Title": "Towards Building More Robust Models with Frequency Bias", "Authors": ["Qingwen Bu", "Dong Huang", "Heming Cui"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV23"]}, "abstract": "The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad applications, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters directly to input images leads to irreversible loss of discriminative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference Control Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representations, providing better utilization of frequency in robust learning. Empirical studies show that our proposed module can be easily incorporated into any adversarial training framework, further improving model robustness across different architectures and datasets. Additionally, experiments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights.", "url": "https://arxiv.org/abs/2307.09763"}, {"metadata": {"arXiv": "2307.09886", "Date": "Wed, 19 Jul 2023 10:31:35 ", "Title": "A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading", "Authors": ["Tatiana Fountoukidou and Raphael Sznitman"], "Categories": "cs.CV cs.AI", "Comments": ["16 pages (+ 23 pages supplementary material)"], "Journal-ref": "Medical image analysis 87 (2023): 102822", "DOI": "10.1016/j.media.2023.102822"}, "abstract": "Recent advances in machine learning models have greatly increased the performance of automated methods in medical image analysis. However, the internal functioning of such models is largely hidden, which hinders their integration in clinical practice. Explainability and trust are viewed as important aspects of modern methods, for the latter's widespread use in clinical communities. As such, validation of machine learning models represents an important aspect and yet, most methods are only validated in a limited way. In this work, we focus on providing a richer and more appropriate validation approach for highly powerful Visual Question Answering (VQA) algorithms. To better understand the performance of these methods, which answer arbitrary questions related to images, this work focuses on an automatic visual Turing test (VTT). That is, we propose an automatic adaptive questioning method, that aims to expose the reasoning behavior of a VQA algorithm. Specifically, we introduce a reinforcement learning (RL) agent that observes the history of previously asked questions, and uses it to select the next question to pose. We demonstrate our approach in the context of evaluating algorithms that automatically answer questions related to diabetic macular edema (DME) grading. The experiments show that such an agent has similar behavior to a clinician, whereby asking questions that are relevant to key clinical concepts.", "url": "https://arxiv.org/abs/2307.09886"}, {"metadata": {"arXiv": "2307.09906", "Date": "Wed, 19 Jul 2023 11:10:26 ", "Title": "Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation", "Authors": ["Fa-Ting Hong and Dan Xu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features for the generation. Furthermore, we propose an effective query mechanism based on implicit identity representations learned from the discrete keypoints of the source image. It can greatly facilitate the retrieval of more correlated information from the memory bank for the compensation. Extensive experiments demonstrate that MCNet can learn representative and complementary facial memory, and can clearly outperform previous state-of-the-art talking head generation methods on VoxCeleb1 and CelebV datasets. Please check our \\href{https://github.com/harlanhong/ICCV2023-MCNET}{Project}.", "url": "https://arxiv.org/abs/2307.09906"}, {"metadata": {"arXiv": "2307.09947", "Date": "Wed, 19 Jul 2023 12:41:54 ", "Title": "U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation", "Authors": ["Steven Landgraf", "Markus Hillemann", "Kira Wursthorn", "Markus Ulrich"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "3 figures", "7 tables", "1 algorithm"]}, "abstract": "Deep neural networks have shown exceptional performance in various tasks, but their lack of robustness, reliability, and tendency to be overconfident pose challenges for their deployment in safety-critical applications like autonomous driving. In this regard, quantifying the uncertainty inherent to a model's prediction is a promising endeavour to address these shortcomings. In this work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that incorporates dynamic predictive uncertainties into the training process by pixel-wise weighting of the well-known cross-entropy loss (CE). Through extensive experimentation, we demonstrate the superiority of U-CE over regular CE training on two benchmark datasets, Cityscapes and ACDC, using two common backbone architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train models that not only improve their segmentation performance but also provide meaningful uncertainties after training. Consequently, we contribute to the development of more robust and reliable segmentation models, ultimately advancing the state-of-the-art in safety-critical applications and beyond.", "url": "https://arxiv.org/abs/2307.09947"}, {"metadata": {"arXiv": "2307.09652", "Date": "Tue, 18 Jul 2023 21:51:47 ", "Title": "VISER: A Tractable Solution Concept for Games with Information Asymmetry", "Authors": ["Jeremy McMahan", "Young Wu", "Yudong Chen", "Xiaojin Zhu", "Qiaomin Xie"], "Categories": "cs.GT cs.AI cs.CR cs.MA cs.SY eess.SY", "Comments": ["17 pages", "6 figures"], "MSC-class": "91A27 (Primary), 93E20 (Secondary)", "ACM-class": "F.2.1; G.3; I.2.8"}, "abstract": "Many real-world games suffer from information asymmetry: one player is only aware of their own payoffs while the other player has the full game information. Examples include the critical domain of security games and adversarial multi-agent reinforcement learning. Information asymmetry renders traditional solution concepts such as Strong Stackelberg Equilibrium (SSE) and Robust-Optimization Equilibrium (ROE) inoperative. We propose a novel solution concept called VISER (Victim Is Secure, Exploiter best-Responds). VISER enables an external observer to predict the outcome of such games. In particular, for security applications, VISER allows the victim to better defend itself while characterizing the most damaging attacks available to the attacker. We show that each player's VISER strategy can be computed independently in polynomial time using linear programming (LP). We also extend VISER to its Markov-perfect counterpart for Markov games, which can be solved efficiently using a series of LPs.", "url": "https://arxiv.org/abs/2307.09652"}, {"metadata": {"arXiv": "2307.09485", "Date": "Sun, 11 Jun 2023 08:13:42 ", "Title": "Enhancing Evacuation Planning through Multi-Agent Simulation and Artificial Intelligence: Understanding Human Behavior in Hazardous Environments", "Authors": ["Afnan Alazbah and Khalid Fakeeh and Osama Rabie"], "Categories": "cs.MA cs.AI", "Comments": ["21 pages,15 figures"]}, "abstract": "This paper focuses on the crucial task of addressing the evacuation of hazardous places, which holds great importance for coordinators, event hosts, and authorities. To facilitate the development of effective solutions, the paper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent Systems (MAS), to construct a simulation model for evacuation. NetLogo is selected as the simulation tool of choice due to its ability to provide a comprehensive understanding of human behaviour in distressing situations within hazardous environments. The primary objective of this paper is to enhance our comprehension of how individuals react and respond during such distressing situations. By leveraging AI and MAS, the simulation model aims to capture the complex dynamics of evacuation scenarios, enabling policymakers and emergency planners to make informed decisions and implement more efficient and effective evacuation strategies. This paper endeavours to contribute to the advancement of evacuation planning and ultimately improve the safety and well-being of individuals in hazardous places", "url": "https://arxiv.org/abs/2307.09485"}, {"metadata": {"arXiv": "2307.09827", "Date": "Wed, 19 Jul 2023 08:32:59 ", "Title": "Online Continual Learning for Robust Indoor Object Recognition", "Authors": ["Umberto Michieli", "Mete Ozay"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["IROS 2023"]}, "abstract": "Vision systems mounted on home robots need to interact with unseen classes in changing environments. Robots have limited computational resources, labelled data and storage capability. These requirements pose some unique challenges: models should adapt without forgetting past knowledge in a data- and parameter-efficient way. We characterize the problem as few-shot (FS) online continual learning (OCL), where robotic agents learn from a non-repeated stream of few-shot data updating only a few model parameters. Additionally, such models experience variable conditions at test time, where objects may appear in different poses (e.g., horizontal or vertical) and environments (e.g., day or night). To improve robustness of CL agents, we propose RobOCLe, which; 1) constructs an enriched feature space computing high order statistical moments from the embedded features of samples; and 2) computes similarity between high order statistics of the samples on the enriched feature space, and predicts their class labels. We evaluate robustness of CL models to train/test augmentations in various cases. We show that different moments allow RobOCLe to capture different properties of deformations, providing higher robustness with no decrease of inference speed.", "url": "https://arxiv.org/abs/2307.09827"}, {"metadata": {"arXiv": "2307.10018", "Date": "Wed, 19 Jul 2023 14:58:30 ", "Title": "Rob\\^oCIn Small Size League Extended Team Description Paper for RoboCup 2023", "Authors": ["Aline Lima de Oliveira", "Cau\\^e Addae da Silva Gomes", "Cec\\'ilia Virginia Santos da Silva", "Charles Matheus de Sousa Alves", "Danilo Andrade Martins de Souza", "Driele Pires Ferreira Ara\\'ujo Xavier", "Edgleyson Pereira da Silva", "Felipe Bezerra Martins", "Lucas Henrique Cavalcanti Santos", "Lucas Dias Maciel", "Matheus Paix\\~ao Gumercindo dos Santos", "Matheus Lafayette Vasconcelos", "Matheus Vin\\'icius Teotonio do Nascimento Andrade", "Jo\\~ao Guilherme Oliveira Carvalho de Melo", "Jo\\~ao Pedro Souza Pereira de Moura", "Jos\\'e Ronald da Silva", "Jos\\'e Victor Silva Cruz", "Pedro Henrique Santana de Morais", "Pedro Paulo Salman de Oliveira", "Riei Joaquim Matos Rodrigues", "Roberto Costa Fernandes", "Ryan Vinicius Santos Morais", "Tamara Mayara Ramos Teobaldo", "Washington Igor dos Santos Silva", "Edna Natividade Silva Barros"], "Categories": "cs.RO cs.AI"}, "abstract": "Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its first world title in 2022 (Division B), and is currently a three-times Latin-American champion. This paper presents our improvements to defend the Small Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France. This paper aims to share some of the academic research that our team developed over the past year. Our team has successfully published 2 articles related to SSL at two high-impact conferences: the 25th RoboCup International Symposium and the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last year, we have been continuously migrating from our past codebase to Unification. We will describe the new architecture implemented and some points of software and AI refactoring. In addition, we discuss the process of integrating machined components into the mechanical system, our development for participating in the vision blackout challenge last year and what we are preparing for this year.", "url": "https://arxiv.org/abs/2307.10018"}, {"metadata": {"arXiv": "2307.09591", "Date": "Tue, 18 Jul 2023 19:56:20 ", "Title": "Gradient strikes back: How filtering out high frequencies improves explanations", "Authors": ["Sabine Muzellec", "Leo Andeol", "Thomas Fel", "Rufin VanRullen", "Thomas Serre"], "Categories": "cs.AI cs.CV cs.LG"}, "abstract": "Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthermore, our analysis reveals that the operations used in Convolutional Neural Networks (CNNs) for downsampling appear to be a significant source of this high-frequency content -- suggesting aliasing as a possible underlying basis. We then apply an optimal low-pass filter for attribution maps and demonstrate that it improves gradient-based attribution methods. We show that (i) removing high-frequency noise yields significant improvements in the explainability scores obtained with gradient-based methods across multiple models -- leading to (ii) a novel ranking of state-of-the-art methods with gradient-based methods at the top. We believe that our results will spur renewed interest in simpler and computationally more efficient gradient-based methods for explainability.", "url": "https://arxiv.org/abs/2307.09591"}, {"metadata": {"arXiv": "2307.09781", "Date": "Wed, 19 Jul 2023 06:56:07 ", "Title": "Text2Layer: Layered Image Generation using Latent Diffusion Model", "Authors": ["Xinyang Zhang", "Wentian Zhao", "Xin Lu", "Jeff Chien"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Preprint. Work in progress"]}, "abstract": "Layer compositing is one of the most popular image editing workflows among both amateurs and professionals. Motivated by the success of diffusion models, we explore layer compositing from a layered image generation perspective. Instead of generating an image, we propose to generate background, foreground, layer mask, and the composed image simultaneously. To achieve layered image generation, we train an autoencoder that is able to reconstruct layered images and train diffusion models on the latent representation. One benefit of the proposed problem is to enable better compositing workflows in addition to the high-quality image output. Another benefit is producing higher-quality layer masks compared to masks produced by a separate step of image segmentation. Experimental results show that the proposed method is able to generate high-quality layered images and initiates a benchmark for future work.", "url": "https://arxiv.org/abs/2307.09781"}, {"metadata": {"arXiv": "2307.10003", "Date": "Wed, 19 Jul 2023 14:23:26 ", "Title": "TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction", "Authors": ["Amirhossein Aminimehr", "Pouya Khani", "Amirali Molaei", "Amirmohammad Kazemeini", "Erik Cambria"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "DOI": "10.2139/ssrn.4385953"}, "abstract": "The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models. Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions. Heatmaps are almost understandable to humans, yet they are not without flaws. Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors). Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually explain them based on the statistics of objects in the input image when the initial prediction is unreliable. To assess the trustworthiness and validity of the text-based explanations, we conducted a qualitative experiment, and the findings indicated that these explanations are sufficiently reliable. Furthermore, our quantitative and qualitative experiments on TbExplain with scene classification datasets reveal an improvement in classification accuracy over ResNet variants.", "url": "https://arxiv.org/abs/2307.10003"}, {"metadata": {"arXiv": "2307.09602", "Date": "Sun, 16 Jul 2023 17:01:20 ", "Title": "A max-affine spline approximation of neural networks using the Legendre transform of a convex-concave representation", "Authors": ["Adam Perrett", "Danny Wood", "Gavin Brown"], "Categories": "cs.LG cs.AI"}, "abstract": "This work presents a novel algorithm for transforming a neural network into a spline representation. Unlike previous work that required convex and piecewise-affine network operators to create a max-affine spline alternate form, this work relaxes this constraint. The only constraint is that the function be bounded and possess a well-define second derivative, although this was shown experimentally to not be strictly necessary. It can also be performed over the whole network rather than on each layer independently. As in previous work, this bridges the gap between neural networks and approximation theory but also enables the visualisation of network feature maps. Mathematical proof and experimental investigation of the technique is performed with approximation error and feature maps being extracted from a range of architectures, including convolutional neural networks.", "url": "https://arxiv.org/abs/2307.09602"}, {"metadata": {"arXiv": "2307.09607", "Date": "Thu, 13 Jul 2023 16:38:01 ", "Title": "Sequential Monte Carlo Learning for Time Series Structure Discovery", "Authors": ["Feras A. Saad", "Brian J. Patton", "Matthew D. Hoffman", "Rif A. Saurous", "Vikash K. Mansinghka"], "Categories": "cs.LG cs.AI stat.ME stat.ML", "Comments": ["17 pages", "8 figures", "2 tables. Appearing in ICML 2023"], "Journal-ref": "Proceedings of the 40th International Conference on Machine Learning, PMLR 202:29473-29489, 2023"}, "abstract": "This paper presents a new approach to automatically discovering accurate models of complex time series data. Working within a Bayesian nonparametric prior over a symbolic space of Gaussian process time series models, we present a novel structure learning algorithm that integrates sequential Monte Carlo (SMC) and involutive MCMC for highly effective posterior inference. Our method can be used both in \"online\" settings, where new data is incorporated sequentially in time, and in \"offline\" settings, by using nested subsets of historical data to anneal the posterior. Empirical measurements on real-world time series show that our method can deliver 10x--100x runtime speedups over previous MCMC and greedy-search structure learning algorithms targeting the same model family. We use our method to perform the first large-scale evaluation of Gaussian process time series structure learning on a prominent benchmark of 1,428 econometric datasets. The results show that our method discovers sensible models that deliver more accurate point forecasts and interval forecasts over multiple horizons as compared to widely used statistical and neural baselines that struggle on this challenging data.", "url": "https://arxiv.org/abs/2307.09607"}, {"metadata": {"arXiv": "2307.09615", "Date": "Fri, 14 Jul 2023 04:50:04 ", "Title": "Looking deeper into interpretable deep learning in neuroimaging: a comprehensive survey", "Authors": ["Md. Mahfuzur Rahman", "Vince D. Calhoun", "Sergey M. Plis"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["109 pages", "21 figures"]}, "abstract": "Deep learning (DL) models have been popular due to their ability to learn directly from the raw data in an end-to-end paradigm, alleviating the concern of a separate error-prone feature extraction phase. Recent DL-based neuroimaging studies have also witnessed a noticeable performance advancement over traditional machine learning algorithms. But the challenges of deep learning models still exist because of the lack of transparency in these models for their successful deployment in real-world applications. In recent years, Explainable AI (XAI) has undergone a surge of developments mainly to get intuitions of how the models reached the decisions, which is essential for safety-critical domains such as healthcare, finance, and law enforcement agencies. While the interpretability domain is advancing noticeably, researchers are still unclear about what aspect of model learning a post hoc method reveals and how to validate its reliability. This paper comprehensively reviews interpretable deep learning models in the neuroimaging domain. Firstly, we summarize the current status of interpretability resources in general, focusing on the progression of methods, associated challenges, and opinions. Secondly, we discuss how multiple recent neuroimaging studies leveraged model interpretability to capture anatomical and functional brain alterations most relevant to model predictions. Finally, we discuss the limitations of the current practices and offer some valuable insights and guidance on how we can steer our future research directions to make deep learning models substantially interpretable and thus advance scientific understanding of brain disorders.", "url": "https://arxiv.org/abs/2307.09615"}, {"metadata": {"arXiv": "2307.09638", "Date": "Tue, 18 Jul 2023 20:59:52 ", "Title": "Promoting Exploration in Memory-Augmented Adam using Critical Momenta", "Authors": ["Pranshu Malviya", "Gon\\c{c}alo Mordido", "Aristide Baratin", "Reza Babanezhad Harikandeh", "Jerry Huang", "Simon Lacoste-Julien", "Razvan Pascanu", "Sarath Chandar"], "Categories": "cs.LG cs.AI"}, "abstract": "Adaptive gradient-based optimizers, particularly Adam, have left their mark in training large-scale deep learning models. The strength of such optimizers is that they exhibit fast convergence while being more robust to hyperparameter choice. However, they often generalize worse than non-adaptive methods. Recent studies have tied this performance gap to flat minima selection: adaptive methods tend to find solutions in sharper basins of the loss landscape, which in turn hurts generalization. To overcome this issue, we propose a new memory-augmented version of Adam that promotes exploration towards flatter minima by using a buffer of critical momentum terms during training. Intuitively, the use of the buffer makes the optimizer overshoot outside the basin of attraction if it is not wide enough. We empirically show that our method improves the performance of several variants of Adam on standard supervised language modelling and image classification tasks.", "url": "https://arxiv.org/abs/2307.09638"}, {"metadata": {"arXiv": "2307.09653", "Date": "Tue, 18 Jul 2023 21:53:40 ", "Title": "HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual Learning", "Authors": ["Xiaotian Duan"], "Categories": "cs.LG cs.AI"}, "abstract": "Catastrophic forgetting, the phenomenon in which a neural network loses previously obtained knowledge during the learning of new tasks, poses a significant challenge in continual learning. The Hard-Attention-to-the-Task (HAT) mechanism has shown potential in mitigating this problem, but its practical implementation has been complicated by issues of usability and compatibility, and a lack of support for existing network reuse. In this paper, we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT mechanism. HAT-CL not only automates gradient manipulation but also streamlines the transformation of PyTorch modules into HAT modules. It achieves this by providing a comprehensive suite of modules that can be seamlessly integrated into existing architectures. Additionally, HAT-CL offers ready-to-use HAT networks that are smoothly integrated with the TIMM library. Beyond the redesign and reimplementation of HAT, we also introduce novel mask manipulation techniques for HAT, which have consistently shown improvements across various experiments. Our work paves the way for a broader application of the HAT mechanism, opening up new possibilities in continual learning across diverse models and applications.", "url": "https://arxiv.org/abs/2307.09653"}, {"metadata": {"arXiv": "2307.09665", "Date": "Tue, 18 Jul 2023 22:17:07 ", "Title": "Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers", "Authors": ["Sameera Horawalavithana", "Ellyn Ayton", "Anastasiya Usenko", "Robin Cosbey", "Svitlana Volkova"], "Categories": "cs.LG cs.AI cs.SI"}, "abstract": "The ability to anticipate technical expertise and capability evolution trends globally is essential for national and global security, especially in safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by (a) forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b) relying on both discrete -- and continuous -- time inputs. We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains. DGT model performance exceeds the best-performing static graph baseline models by 30-80% across AI and NN domains. Our findings demonstrate that DGT models boost inductive task performance, when previously unseen nodes appear in the test data, for the domains with emerging collaboration patterns (e.g., AI). Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice-versa in the AI domain.", "url": "https://arxiv.org/abs/2307.09665"}, {"metadata": {"arXiv": "2307.09692", "Date": "Wed, 19 Jul 2023 00:31:58 ", "Title": "STRAPPER: Preference-based Reinforcement Learning via Self-training Augmentation and Peer Regularization", "Authors": ["Yachen Kang", "Li He", "Jinxin Liu", "Zifeng Zhuang", "Donglin Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Preference-based reinforcement learning (PbRL) promises to learn a complex reward function with binary human preference. However, such human-in-the-loop formulation requires considerable human effort to assign preference labels to segment pairs, hindering its large-scale applications. Recent approache has tried to reuse unlabeled segments, which implicitly elucidates the distribution of segments and thereby alleviates the human effort. And consistency regularization is further considered to improve the performance of semi-supervised learning. However, we notice that, unlike general classification tasks, in PbRL there exits a unique phenomenon that we defined as similarity trap in this paper. Intuitively, human can have diametrically opposite preferredness for similar segment pairs, but such similarity may trap consistency regularization fail in PbRL. Due to the existence of similarity trap, such consistency regularization improperly enhances the consistency possiblity of the model's predictions between segment pairs, and thus reduces the confidence in reward learning, since the augmented distribution does not match with the original one in PbRL. To overcome such issue, we present a self-training method along with our proposed peer regularization, which penalizes the reward model memorizing uninformative labels and acquires confident predictions. Empirically, we demonstrate that our approach is capable of learning well a variety of locomotion and robotic manipulation behaviors using different semi-supervised alternatives and peer regularization.", "url": "https://arxiv.org/abs/2307.09692"}, {"metadata": {"arXiv": "2307.09767", "Date": "Wed, 19 Jul 2023 05:58:21 ", "Title": "Sig-Splines: universal approximation and convex calibration of time series generative models", "Authors": ["Magnus Wiese", "Phillip Murray", "Ralf Korn"], "Categories": "cs.LG cs.AI q-fin.CP q-fin.ST"}, "abstract": "We propose a novel generative model for multivariate discrete-time time series data. Drawing inspiration from the construction of neural spline flows, our algorithm incorporates linear transformations and the signature transform as a seamless substitution for traditional neural networks. This approach enables us to achieve not only the universality property inherent in neural networks but also introduces convexity in the model's parameters.", "url": "https://arxiv.org/abs/2307.09767"}, {"metadata": {"arXiv": "2307.09779", "Date": "Wed, 19 Jul 2023 06:48:33 ", "Title": "Beyond Single-Feature Importance with ICECREAM", "Authors": ["Michael Oesterle", "Patrick Bl\\\"obaum", "Atalanti A. Mastakouri", "Elke Kirschbaum"], "Categories": "cs.LG cs.AI"}, "abstract": "Which set of features was responsible for a certain output of a machine learning model? Which components caused the failure of a cloud computing application? These are just two examples of questions we are addressing in this work by Identifying Coalition-based Explanations for Common and Rare Events in Any Model (ICECREAM). Specifically, we propose an information-theoretic quantitative measure for the influence of a coalition of variables on the distribution of a target variable. This allows us to identify which set of factors is essential to obtain a certain outcome, as opposed to well-established explainability and causal contribution analysis methods which can assign contributions only to individual factors and rank them by their importance. In experiments with synthetic and real-world data, we show that ICECREAM outperforms state-of-the-art methods for explainability and root cause analysis, and achieves impressive accuracy in both tasks.", "url": "https://arxiv.org/abs/2307.09779"}, {"metadata": {"arXiv": "2307.09782", "Date": "Wed, 19 Jul 2023 06:58:03 ", "Title": "ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats", "Authors": ["Xiaoxia Wu and Zhewei Yao and Yuxiong He"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints for weight quantization that negligibly impact the performance compared to the standard W4A8 model. We additionally enhance our quantization methods by integrating the Low Rank Compensation (LoRC) strategy, yielding improvements especially in smaller models. The results of our investigation emphasize the immense potential of FP quantization for LLMs, paving the way for high-efficiency deployment in resource-limited settings.", "url": "https://arxiv.org/abs/2307.09782"}, {"metadata": {"arXiv": "2307.09797", "Date": "Wed, 19 Jul 2023 07:31:37 ", "Title": "Probabilistic Forecasting with Coherent Aggregation", "Authors": ["Geoffrey N\\'egiar and Ruijun Ma and O. Nangba Meetei and Mengfei Cao and Michael W. Mahoney"], "Categories": "cs.LG cs.AI"}, "abstract": "Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation. The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure. In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction. This is a consequence of a simple (exchangeability) observation: permuting \\textit{}base-level series in the hierarchy does not change their aggregates. Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probability Score and quantile losses. We can choose arbitrary continuous distributions for the factor and the base-level distributions. We compare our method to two previous methods which can be optimized end-to-end, while enforcing coherent aggregation. Our model achieves significant improvements: between $11.8-41.4\\%$ on three hierarchical forecasting datasets. We also analyze the influence of parameters in our model with respect to base-level distribution and number of factors.", "url": "https://arxiv.org/abs/2307.09797"}, {"metadata": {"arXiv": "2307.09862", "Date": "Wed, 19 Jul 2023 09:45:41 ", "Title": "Towards a population-informed approach to the definition of data-driven models for structural dynamics", "Authors": ["G. Tsialiamanis", "N. Dervilis", "D.J. Wagg", "K. Worden"], "Categories": "cs.LG cs.AI eess.SP", "Journal-ref": "Mechanical Systems and Signal Processing, Volume 200, 1 October 2023, 110581", "DOI": "10.1016/j.ymssp.2023.110581"}, "abstract": "Machine learning has affected the way in which many phenomena for various domains are modelled, one of these domains being that of structural dynamics. However, because machine-learning algorithms are problem-specific, they often fail to perform efficiently in cases of data scarcity. To deal with such issues, combination of physics-based approaches and machine learning algorithms have been developed. Although such methods are effective, they also require the analyser's understanding of the underlying physics of the problem. The current work is aimed at motivating the use of models which learn such relationships from a population of phenomena, whose underlying physics are similar. The development of such models is motivated by the way that physics-based models, and more specifically finite element models, work. Such models are considered transferrable, explainable and trustworthy, attributes which are not trivially imposed or achieved for machine-learning models. For this reason, machine-learning approaches are less trusted by industry and often considered more difficult to form validated models. To achieve such data-driven models, a population-based scheme is followed here and two different machine-learning algorithms from the meta-learning domain are used. The two algorithms are the model-agnostic meta-learning (MAML) algorithm and the conditional neural processes (CNP) model. The algorithms seem to perform as intended and outperform a traditional machine-learning algorithm at approximating the quantities of interest. Moreover, they exhibit behaviour similar to traditional machine learning algorithms (e.g. neural networks or Gaussian processes), concerning their performance as a function of the available structures in the training population.", "url": "https://arxiv.org/abs/2307.09862"}, {"metadata": {"arXiv": "2307.09866", "Date": "Wed, 19 Jul 2023 09:53:56 ", "Title": "Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network", "Authors": ["Jinzhu Mao", "Liu Cao", "Chen Gao", "Huandong Wang", "Hangyu Fan", "Depeng Jin", "Yong Li"], "Categories": "cs.LG cs.AI cs.SI"}, "abstract": "Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine-assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities. Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components.", "url": "https://arxiv.org/abs/2307.09866"}, {"metadata": {"arXiv": "2307.09882", "Date": "Wed, 19 Jul 2023 10:26:29 ", "Title": "Adversarial Likelihood Estimation with One-way Flows", "Authors": ["Omri Ben-Dov", "Pravir Singh Gupta", "Victoria Abrevaya", "Michael J. Black", "Partha Ghosh"], "Categories": "cs.LG cs.AI"}, "abstract": "Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples. However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy). We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; 2) when optimizing for likelihood, one must maximize generator entropy. This is hypothesized to provide a better mode coverage. Different from previous works, we explicitly compute the density of the generated samples. This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term. The generator density is obtained via a new type of flow network, called one-way flow network, that is less constrained in terms of architecture, as it does not require to have a tractable inverse function. Our experimental results show that we converge faster, produce comparable sample quality to GANs with similar architecture, successfully avoid over-fitting to commonly used datasets and produce smooth low-dimensional latent representations of the training data.", "url": "https://arxiv.org/abs/2307.09882"}, {"metadata": {"arXiv": "2307.09933", "Date": "Wed, 19 Jul 2023 12:15:06 ", "Title": "Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features", "Authors": ["Cian Eastwood", "Shashank Singh", "Andrei Liviu Nicolicioiu", "Marin Vlastelica", "Julius von K\\\"ugelgen", "Bernhard Sch\\\"olkopf"], "Categories": "cs.LG cs.AI cs.CV stat.ML"}, "abstract": "To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the \"spurious\" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain. Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain. Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels. Empirically, we demonstrate the effectiveness of SFB on real and synthetic data.", "url": "https://arxiv.org/abs/2307.09933"}, {"metadata": {"arXiv": "2307.09942", "Date": "Wed, 19 Jul 2023 12:35:09 ", "Title": "TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network", "Authors": ["Brandon Theodorou", "Cao Xiao", "and Jimeng Sun"], "Categories": "cs.LG cs.AI"}, "abstract": "Clinical trials are critical for drug development but often suffer from expensive and inefficient patient recruitment. In recent years, machine learning models have been proposed for speeding up patient recruitment via automatically matching patients with clinical trials based on longitudinal patient electronic health records (EHR) data and eligibility criteria of clinical trials. However, they either depend on trial-specific expert rules that cannot expand to other trials or perform matching at a very general level with a black-box model where the lack of interpretability makes the model results difficult to be adopted. To provide accurate and interpretable patient trial matching, we introduce a personalized dynamic tree-based memory network model named TREEMENT. It utilizes hierarchical clinical ontologies to expand the personalized patient representation learned from sequential EHR data, and then uses an attentional beam-search query learned from eligibility criteria embedding to offer a granular level of alignment for improved performance and interpretability. We evaluated TREEMENT against existing models on real-world datasets and demonstrated that TREEMENT outperforms the best baseline by 7% in terms of error reduction in criteria-level matching and achieves state-of-the-art results in its trial-level matching ability. Furthermore, we also show TREEMENT can offer good interpretability to make the model results easier for adoption.", "url": "https://arxiv.org/abs/2307.09942"}, {"metadata": {"arXiv": "2307.10171", "Date": "Wed, 19 Jul 2023 17:57:27 ", "Title": "LightPath: Lightweight and Scalable Path Representation Learning", "Authors": ["Sean Bin Yang", "Jilin Hu", "Chenjuan Guo", "Bin Yang and Christian S. Jensen"], "Categories": "cs.LG cs.AI cs.DB", "Comments": ["This paper has been accepted by ACM SIGKDD-23"]}, "abstract": "Movement paths are used widely in intelligent transportation and smart city applications. To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation. In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential. Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability. We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability. More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good scalability with respect to path length. Next, we propose a relational reasoning framework to enable faster training of more robust sparse path encoders. We also propose global-local knowledge distillation to further reduce the size and improve the performance of sparse path encoders. Finally, we report extensive experiments on two real-world datasets to offer insight into the efficiency, scalability, and effectiveness of the proposed framework.", "url": "https://arxiv.org/abs/2307.10171"}, {"metadata": {"arXiv": "2307.09668", "Date": "Tue, 18 Jul 2023 22:37:30 ", "Title": "Towards A Unified Agent with Foundation Models", "Authors": ["Norman Di Palo", "Arunkumar Byravan", "Leonard Hasenclever", "Markus Wulfmeier", "Nicolas Heess", "Martin Riedmiller"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve novel tasks or imitate videos of human experts.", "url": "https://arxiv.org/abs/2307.09668"}, {"metadata": {"arXiv": "2307.09955", "Date": "Wed, 19 Jul 2023 12:51:28 ", "Title": "XSkill: Cross Embodiment Skill Discovery", "Authors": ["Mengda Xu", "Zhenjia Xu", "Cheng Chi", "Manuela Veloso", "Shuran Song"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Human demonstration videos are a widely available data source for robot learning and an intuitive user interface for expressing desired behavior. However, directly extracting reusable robot manipulation skills from unstructured human videos is challenging due to the big embodiment difference and unobserved action parameters. To bridge this embodiment gap, this paper introduces XSkill, an imitation learning framework that 1) discovers a cross-embodiment representation called skill prototypes purely from unlabeled human and robot manipulation videos, 2) transfers the skill representation to robot actions using conditional diffusion policy, and finally, 3) composes the learned skill to accomplish unseen tasks specified by a human prompt video. Our experiments in simulation and real-world environments show that the discovered skill prototypes facilitate both skill transfer and composition for unseen tasks, resulting in a more general and scalable imitation learning framework. The performance of XSkill is best understood from the anonymous website: https://xskillcorl.github.io.", "url": "https://arxiv.org/abs/2307.09955"}, {"metadata": {"arXiv": "2307.10142", "Date": "Wed, 19 Jul 2023 17:12:28 ", "Title": "Benchmarking Potential Based Rewards for Learning Humanoid Locomotion", "Authors": ["Se Hwan Jeon", "Steve Heim", "Charles Khazoom", "Sangbae Kim"], "Categories": "cs.RO cs.AI cs.LG", "Journal-ref": "2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9204-9210", "DOI": "10.1109/ICRA48891.2023.10160885"}, "abstract": "The main challenge in developing effective reinforcement learning (RL) pipelines is often the design and tuning the reward functions. Well-designed shaping reward can lead to significantly faster learning. Naively formulated rewards, however, can conflict with the desired behavior and result in overfitting or even erratic performance if not properly tuned. In theory, the broad class of potential based reward shaping (PBRS) can help guide the learning process without affecting the optimal policy. Although several studies have explored the use of potential based reward shaping to accelerate learning convergence, most have been limited to grid-worlds and low-dimensional systems, and RL in robotics has predominantly relied on standard forms of reward shaping. In this paper, we benchmark standard forms of shaping with PBRS for a humanoid robot. We find that in this high-dimensional system, PBRS has only marginal benefits in convergence speed. However, the PBRS reward terms are significantly more robust to scaling than typical reward shaping approaches, and thus easier to tune.", "url": "https://arxiv.org/abs/2307.10142"}, {"metadata": {"arXiv": "2307.10160", "Date": "Wed, 19 Jul 2023 17:42:36 ", "Title": "Robust Driving Policy Learning with Guided Meta Reinforcement Learning", "Authors": ["Kanghoon Lee", "Jiachen Li", "David Isele", "Jinkyoo Park", "Kikuo Fujimura", "Mykel J. Kochenderfer"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "Comments": ["ITSC 2023"]}, "abstract": "Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unseen situations with out-of-distribution (OOD) social agents' behaviors in a challenging uncontrolled T-intersection scenario.", "url": "https://arxiv.org/abs/2307.10160"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

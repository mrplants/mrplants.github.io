<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.04787", "Date": "Tue, 04 Jul 2023 17:31:50 ", "Title": "Collaborative Score Distillation for Consistent Visual Synthesis", "Authors": ["Subin Kim", "Kyungmin Lee", "June Suk Choi", "Jongheon Jeong", "Kihyuk Sohn", "Jinwoo Shin"], "Categories": "cs.CV cs.LG", "Comments": ["Project page with visuals: https://subin-kim-cv.github.io/CSD/"]}, "abstract": "Generative priors of large-scale text-to-image diffusion models enable a wide range of new generation and editing applications on diverse visual modalities. However, when adapting these priors to complex visual modalities, often represented as multiple images (e.g., video), achieving consistency across a set of images is challenging. In this paper, we address this challenge with a novel method, Collaborative Score Distillation (CSD). CSD is based on the Stein Variational Gradient Descent (SVGD). Specifically, we propose to consider multiple samples as \"particles\" in the SVGD update and combine their score functions to distill generative priors over a set of images synchronously. Thus, CSD facilitates seamless integration of information across 2D images, leading to a consistent visual synthesis across multiple samples. We show the effectiveness of CSD in a variety of tasks, encompassing the visual editing of panorama images, videos, and 3D scenes. Our results underline the competency of CSD as a versatile method for enhancing inter-sample consistency, thereby broadening the applicability of text-to-image diffusion models.", "url": "https://arxiv.org/abs/2307.04787"}, {"metadata": {"arXiv": "2307.04838", "Date": "Mon, 10 Jul 2023 18:15:03 ", "Title": "CREPE: Learnable Prompting With CLIP Improves Visual Relationship Prediction", "Authors": ["Rakshith Subramanyam", "T. S. Jayram", "Rushil Anirudh and Jayaraman J. Thiagarajan"], "Categories": "cs.CV cs.LG"}, "abstract": "In this paper, we explore the potential of Vision-Language Models (VLMs), specifically CLIP, in predicting visual object relationships, which involves interpreting visual features from images into language-based relations. Current state-of-the-art methods use complex graphical models that utilize language cues and visual features to address this challenge. We hypothesize that the strong language priors in CLIP embeddings can simplify these graphical models paving for a simpler approach. We adopt the UVTransE relation prediction framework, which learns the relation as a translational embedding with subject, object, and union box embeddings from a scene. We systematically explore the design of CLIP-based subject, object, and union-box representations within the UVTransE framework and propose CREPE (CLIP Representation Enhanced Predicate Estimation). CREPE utilizes text-based representations for all three bounding boxes and introduces a novel contrastive training strategy to automatically infer the text prompt for union-box. Our approach achieves state-of-the-art performance in predicate estimation, mR@5 27.79, and mR@20 31.95 on the Visual Genome benchmark, achieving a 15.3\\% gain in performance over recent state-of-the-art at mR@20. This work demonstrates CLIP's effectiveness in object relation prediction and encourages further research on VLMs in this challenging domain.", "url": "https://arxiv.org/abs/2307.04838"}, {"metadata": {"arXiv": "2307.04859", "Date": "Mon, 10 Jul 2023 19:15:32 ", "Title": "Articulated 3D Head Avatar Generation using Text-to-Image Diffusion Models", "Authors": ["Alexander W. Bergman", "Wang Yifan", "Gordon Wetzstein"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project website: http://www.computationalimaging.org/publications/articulated-diffusion/"]}, "abstract": "The ability to generate diverse 3D articulated head avatars is vital to a plethora of applications, including augmented reality, cinematography, and education. Recent work on text-guided 3D object generation has shown great promise in addressing these needs. These methods directly leverage pre-trained 2D text-to-image diffusion models to generate 3D-multi-view-consistent radiance fields of generic objects. However, due to the lack of geometry and texture priors, these methods have limited control over the generated 3D objects, making it difficult to operate inside a specific domain, e.g., human heads. In this work, we develop a new approach to text-guided 3D head avatar generation to address this limitation. Our framework directly operates on the geometry and texture of an articulable 3D morphable model (3DMM) of a head, and introduces novel optimization procedures to update the geometry and texture while keeping the 2D and 3D facial features aligned. The result is a 3D head avatar that is consistent with the text description and can be readily articulated using the deformation model of the 3DMM. We show that our diffusion-based articulated head avatars outperform state-of-the-art approaches for this task. The latter are typically based on CLIP, which is known to provide limited diversity of generation and accuracy for 3D object generation.", "url": "https://arxiv.org/abs/2307.04859"}, {"metadata": {"arXiv": "2307.04946", "Date": "Tue, 11 Jul 2023 00:21:38 ", "Title": "DDGM: Solving inverse problems by Diffusive Denoising of Gradient-based Minimization", "Authors": ["Kyle Luther", "H. Sebastian Seung"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Solving inverse problems using gradient minimization coupled with a diffusion prior"]}, "abstract": "Inverse problems generally require a regularizer or prior for a good solution. A recent trend is to train a convolutional net to denoise images, and use this net as a prior when solving the inverse problem. Several proposals depend on a singular value decomposition of the forward operator, and several others backpropagate through the denoising net at runtime. Here we propose a simpler approach that combines the traditional gradient-based minimization of reconstruction error with denoising. Noise is also added at each step, so the iterative dynamics resembles a Langevin or diffusion process. Both the level of added noise and the size of the denoising step decay exponentially with time. We apply our method to the problem of tomographic reconstruction from electron micrographs acquired at multiple tilt angles. With empirical studies using simulated tilt views, we find parameter settings for our method that produce good results. We show that high accuracy can be achieved with as few as 50 denoising steps. We also compare with DDRM and DPS, more complex diffusion methods of the kinds mentioned above. These methods are less accurate (as measured by MSE and SSIM) for our tomography problem, even after the generation hyperparameters are optimized. Finally we extend our method to reconstruction of arbitrary-sized images and show results on 128 $\\times$ 1568 pixel images", "url": "https://arxiv.org/abs/2307.04946"}, {"metadata": {"arXiv": "2307.04952", "Date": "Tue, 11 Jul 2023 00:46:59 ", "Title": "Compact Twice Fusion Network for Edge Detection", "Authors": ["Yachuan Li", "Zongmin Li", "Xavier Soria P.", "Chaozhi Yang", "Qian Xiao", "Yun Bai", "Hua Li", "Xiangdong Wang"], "Categories": "cs.CV cs.LG", "Comments": ["Manuscript submitted to a Springer journal"]}, "abstract": "The significance of multi-scale features has been gradually recognized by the edge detection community. However, the fusion of multi-scale features increases the complexity of the model, which is not friendly to practical application. In this work, we propose a Compact Twice Fusion Network (CTFN) to fully integrate multi-scale features while maintaining the compactness of the model. CTFN includes two lightweight multi-scale feature fusion modules: a Semantic Enhancement Module (SEM) that can utilize the semantic information contained in coarse-scale features to guide the learning of fine-scale features, and a Pseudo Pixel-level Weighting (PPW) module that aggregate the complementary merits of multi-scale features by assigning weights to all features. Notwithstanding all this, the interference of texture noise makes the correct classification of some pixels still a challenge. For these hard samples, we propose a novel loss function, coined Dynamic Focal Loss, which reshapes the standard cross-entropy loss and dynamically adjusts the weights to correct the distribution of hard samples. We evaluate our method on three datasets, i.e., BSDS500, NYUDv2, and BIPEDv2. Compared with state-of-the-art methods, CTFN achieves competitive accuracy with less parameters and computational cost. Apart from the backbone, CTFN requires only 0.1M additional parameters, which reduces its computation cost to just 60% of other state-of-the-art methods. The codes are available at https://github.com/Li-yachuan/CTFN-pytorch-master.", "url": "https://arxiv.org/abs/2307.04952"}, {"metadata": {"arXiv": "2307.05014", "Date": "Tue, 11 Jul 2023 05:17:42 ", "Title": "Test-Time Training on Video Streams", "Authors": ["Renhao Wang", "Yu Sun", "Yossi Gandelsman", "Xinlei Chen", "Alexei A. Efros", "Xiaolong Wang"], "Categories": "cs.CV cs.LG", "Comments": ["Project website with videos", "dataset and code: https://video-ttt.github.io/"]}, "abstract": "Prior work has established test-time training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is trained on the same instance using a self-supervised task, such as image reconstruction with masked autoencoders. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The relative improvement is 45% and 66% for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses more information, training on all frames from the entire test video regardless of temporal order. This differs from previous findings using synthetic videos. We conceptualize locality as the advantage of online over offline TTT. We analyze the role of locality with ablations and a theory based on bias-variance trade-off.", "url": "https://arxiv.org/abs/2307.05014"}, {"metadata": {"arXiv": "2307.05356", "Date": "Wed, 28 Jun 2023 15:16:24 ", "Title": "VisText: A Benchmark for Semantically Rich Chart Captioning", "Authors": ["Benny J. Tang", "Angie Boggust and Arvind Satyanarayan"], "Categories": "cs.CV cs.HC cs.LG", "Comments": ["Published at ACL 2023", "29 pages", "10 figures"]}, "abstract": "Captions that describe or explain charts help improve recall and comprehension of the depicted data and provide a more accessible medium for people with visual disabilities. However, current approaches for automatically generating such captions struggle to articulate the perceptual or cognitive features that are the hallmark of charts (e.g., complex trends and patterns). In response, we introduce VisText: a dataset of 12,441 pairs of charts and captions that describe the charts' construction, report key statistics, and identify perceptual and cognitive phenomena. In VisText, a chart is available as three representations: a rasterized image, a backing data table, and a scene graph -- a hierarchical representation of a chart's visual elements akin to a web page's Document Object Model (DOM). To evaluate the impact of VisText, we fine-tune state-of-the-art language models on our chart captioning task and apply prefix-tuning to produce captions that vary the semantic content they convey. Our models generate coherent, semantically rich captions and perform on par with state-of-the-art chart captioning models across machine translation and text generation metrics. Through qualitative analysis, we identify six broad categories of errors that our models make that can inform future work.", "url": "https://arxiv.org/abs/2307.05356"}, {"metadata": {"arXiv": "2307.04770", "Date": "Fri, 07 Jul 2023 19:38:45 ", "Title": "Predicting Outcomes in Long COVID Patients with Spatiotemporal Attention", "Authors": ["Degan Hao and Mohammadreza Negahdar"], "Categories": "cs.LG"}, "abstract": "Long COVID is a general term of post-acute sequelae of COVID-19. Patients with long COVID can endure long-lasting symptoms including fatigue, headache, dyspnea and anosmia, etc. Identifying the cohorts with severe long-term complications in COVID-19 could benefit the treatment planning and resource arrangement. However, due to the heterogeneous phenotype presented in long COVID patients, it is difficult to predict their outcomes from their longitudinal data. In this study, we proposed a spatiotemporal attention mechanism to weigh feature importance jointly from the temporal dimension and feature space. Considering that medical examinations can have interchangeable orders in adjacent time points, we restricted the learning of short-term dependency with a Local-LSTM and the learning of long-term dependency with the joint spatiotemporal attention. We also compared the proposed method with several state-of-the-art methods and a method in clinical practice. The methods are evaluated on a hard-to-acquire clinical dataset of patients with long COVID. Experimental results show the Local-LSTM with joint spatiotemporal attention outperformed related methods in outcome prediction. The proposed method provides a clinical tool for the severity assessment of long COVID.", "url": "https://arxiv.org/abs/2307.04770"}, {"metadata": {"arXiv": "2307.04772", "Date": "Sat, 08 Jul 2023 12:52:31 ", "Title": "Digital Twins for Patient Care via Knowledge Graphs and Closed-Form Continuous-Time Liquid Neural Networks", "Authors": ["Logan Nye"], "Categories": "cs.LG", "Comments": ["6 pages"]}, "abstract": "Digital twin technology has is anticipated to transform healthcare, enabling personalized medicines and support, earlier diagnoses, simulated treatment outcomes, and optimized surgical plans. Digital twins are readily gaining traction in industries like manufacturing, supply chain logistics, and civil infrastructure. Not in patient care, however. The challenge of modeling complex diseases with multimodal patient data and the computational complexities of analyzing it have stifled digital twin adoption in the biomedical vertical. Yet, these major obstacles can potentially be handled by approaching these models in a different way. This paper proposes a novel framework for addressing the barriers to clinical twin modeling created by computational costs and modeling complexities. We propose structuring patient health data as a knowledge graph and using closed-form continuous-time liquid neural networks, for real-time analytics. By synthesizing multimodal patient data and leveraging the flexibility and efficiency of closed form continuous time networks and knowledge graph ontologies, our approach enables real time insights, personalized medicine, early diagnosis and intervention, and optimal surgical planning. This novel approach provides a comprehensive and adaptable view of patient health along with real-time analytics, paving the way for digital twin simulations and other anticipated benefits in healthcare.", "url": "https://arxiv.org/abs/2307.04772"}, {"metadata": {"arXiv": "2307.04777", "Date": "Sun, 09 Jul 2023 22:30:47 ", "Title": "MentalHealthAI: Utilizing Personal Health Device Data to Optimize Psychiatry Treatment", "Authors": ["Manan Shukla and Oshani Seneviratne"], "Categories": "cs.LG cs.CY", "Comments": ["Accepted at AMIA 2023 Annual Symposium"]}, "abstract": "Mental health disorders remain a significant challenge in modern healthcare, with diagnosis and treatment often relying on subjective patient descriptions and past medical history. To address this issue, we propose a personalized mental health tracking and mood prediction system that utilizes patient physiological data collected through personal health devices. Our system leverages a decentralized learning mechanism that combines transfer and federated machine learning concepts using smart contracts, allowing data to remain on users' devices and enabling effective tracking of mental health conditions for psychiatric treatment and management in a privacy-aware and accountable manner. We evaluate our model using a popular mental health dataset that demonstrates promising results. By utilizing connected health systems and machine learning models, our approach offers a novel solution to the challenge of providing psychiatrists with further insight into their patients' mental health outside of traditional office visits.", "url": "https://arxiv.org/abs/2307.04777"}, {"metadata": {"arXiv": "2307.04778", "Date": "Mon, 10 Jul 2023 05:43:31 ", "Title": "Formulating A Strategic Plan Based On Statistical Analyses And Applications For Financial Companies Through A Real-World Use Case", "Authors": ["Saman Sarraf"], "Categories": "cs.LG cs.CE"}, "abstract": "Business statistics play a crucial role in implementing a data-driven strategic plan at the enterprise level to employ various analytics where the outcomes of such a plan enable an enterprise to enhance the decision-making process or to mitigate risks to the organization. In this work, a strategic plan informed by the statistical analysis is introduced for a financial company called LendingClub, where the plan is comprised of exploring the possibility of onboarding a big data platform along with advanced feature selection capacities. The main objectives of such a plan are to increase the company's revenue while reducing the risks of granting loans to borrowers who cannot return their loans. In this study, different hypotheses formulated to address the company's concerns are studied, where the results reveal that the amount of loans profoundly impacts the number of borrowers charging off their loans. Also, the proposed strategic plan includes onboarding advanced analytics such as machine learning technologies that allow the company to build better generalized data-driven predictive models.", "url": "https://arxiv.org/abs/2307.04778"}, {"metadata": {"arXiv": "2307.04780", "Date": "Mon, 10 Jul 2023 08:20:45 ", "Title": "Comparison of Point Cloud and Image-based Models for Calorimeter Fast Simulation", "Authors": ["Fernando Torales Acosta", "Vinicius Mikuni", "Benjamin Nachman", "Miguel Arratia", "Kenneth Barish", "Bishnu Karki", "Ryan Milton", "Piyush Karande", "and Aaron Angerami"], "Categories": "cs.LG nucl-ex", "Comments": ["11 pages", "6 figures", "1 table"]}, "abstract": "Score based generative models are a new class of generative models that have been shown to accurately generate high dimensional calorimeter datasets. Recent advances in generative models have used images with 3D voxels to represent and model complex calorimeter showers. Point clouds, however, are likely a more natural representation of calorimeter showers, particularly in calorimeters with high granularity. Point clouds preserve all of the information of the original simulation, more naturally deal with sparse datasets, and can be implemented with more compact models and data files. In this work, two state-of-the-art score based models are trained on the same set of calorimeter simulation and directly compared.", "url": "https://arxiv.org/abs/2307.04780"}, {"metadata": {"arXiv": "2307.04868", "Date": "Mon, 10 Jul 2023 19:32:52 ", "Title": "Leveraging an Alignment Set in Tackling Instance-Dependent Label Noise", "Authors": ["Donna Tjandra and Jenna Wiens"], "Categories": "cs.LG", "Journal-ref": "In Conference on Health, Inference, and Learning (pp. 477-497). PMLR (2023)"}, "abstract": "Noisy training labels can hurt model performance. Most approaches that aim to address label noise assume label noise is independent from the input features. In practice, however, label noise is often feature or \\textit{instance-dependent}, and therefore biased (i.e., some instances are more likely to be mislabeled than others). E.g., in clinical care, female patients are more likely to be under-diagnosed for cardiovascular disease compared to male patients. Approaches that ignore this dependence can produce models with poor discriminative performance, and in many healthcare settings, can exacerbate issues around health disparities. In light of these limitations, we propose a two-stage approach to learn in the presence instance-dependent label noise. Our approach utilizes \\textit{\\anchor points}, a small subset of data for which we know the observed and ground truth labels. On several tasks, our approach leads to consistent improvements over the state-of-the-art in discriminative performance (AUROC) while mitigating bias (area under the equalized odds curve, AUEOC). For example, when predicting acute respiratory failure onset on the MIMIC-III dataset, our approach achieves a harmonic mean (AUROC and AUEOC) of 0.84 (SD [standard deviation] 0.01) while that of the next best baseline is 0.81 (SD 0.01). Overall, our approach improves accuracy while mitigating potential bias compared to existing approaches in the presence of instance-dependent label noise.", "url": "https://arxiv.org/abs/2307.04868"}, {"metadata": {"arXiv": "2307.04870", "Date": "Mon, 10 Jul 2023 19:34:41 ", "Title": "Onion Universe Algorithm: Applications in Weakly Supervised Learning", "Authors": ["Woojoo Na"], "Categories": "cs.LG math.OC", "Comments": ["12 pages"]}, "abstract": "We introduce Onion Universe Algorithm (OUA), a novel classification method in ensemble learning. In particular, we show its applicability as a label model for weakly supervised learning. OUA offers simplicity in implementation, computational efficiency, and does not rely on any assumptions regarding the data or weak signals. The model is well suited for scenarios where fully labeled data is not available. Our method is built upon geometrical interpretation of the space spanned by weak signals. Empirical results support our analysis of the hidden geometric structure underlying general set of weak signals and also illustrates that OUA works well in practice. We show empirical evidence that OUA performs favorably on common benchmark datasets compared to existing label models for weakly supervised learning.", "url": "https://arxiv.org/abs/2307.04870"}, {"metadata": {"arXiv": "2307.04905", "Date": "Mon, 10 Jul 2023 21:08:52 ", "Title": "FedYolo: Augmenting Federated Learning with Pretrained Transformers", "Authors": ["Xuechen Zhang", "Mingchen Li", "Xiangyu Chang", "Jiasi Chen", "Amit K. Roy-Chowdhury", "Ananda Theertha Suresh", "Samet Oymak"], "Categories": "cs.LG cs.DC", "Comments": ["20 pages", "18 figures"]}, "abstract": "The growth and diversity of machine learning applications motivate a rethinking of learning with mobile and edge devices. How can we address diverse client goals and learn with scarce heterogeneous data? While federated learning aims to address these issues, it has challenges hindering a unified solution. Large transformer models have been shown to work across a variety of tasks achieving remarkable few-shot adaptation. This raises the question: Can clients use a single general-purpose model, rather than custom models for each task, while obeying device and network constraints? In this work, we investigate pretrained transformers (PTF) to achieve these on-device learning goals and thoroughly explore the roles of model size and modularity, where the latter refers to adaptation through modules such as prompts or adapters. Focusing on federated learning, we demonstrate that: (1) Larger scale shrinks the accuracy gaps between alternative approaches and improves heterogeneity robustness. Scale allows clients to run more local SGD epochs which can significantly reduce the number of communication rounds. At the extreme, clients can achieve respectable accuracy locally highlighting the potential of fully-local learning. (2) Modularity, by design, enables $>$100$\\times$ less communication in bits. Surprisingly, it also boosts the generalization capability of local adaptation methods and the robustness of smaller PTFs. Finally, it enables clients to solve multiple unrelated tasks simultaneously using a single PTF, whereas full updates are prone to catastrophic forgetting. These insights on scale and modularity motivate a new federated learning approach we call \"You Only Load Once\" (FedYolo): The clients load a full PTF model once and all future updates are accomplished through communication-efficient modules with limited catastrophic-forgetting, where each task is assigned to its own module.", "url": "https://arxiv.org/abs/2307.04905"}, {"metadata": {"arXiv": "2307.04927", "Date": "Mon, 10 Jul 2023 22:28:33 ", "Title": "Probabilistic Counterexample Guidance for Safer Reinforcement Learning", "Authors": ["Xiaotong Ji and Antonio Filieri"], "Categories": "cs.LG cs.LO", "Comments": ["Accepted and Evaluated by the 20th International Conference on Quantitative Evaluation of Systems 2023"]}, "abstract": "Safe exploration aims at addressing the limitations of Reinforcement Learning (RL) in safety-critical scenarios, where failures during trial-and-error learning may incur high costs. Several methods exist to incorporate external knowledge or to use proximal sensor data to limit the exploration of unsafe states. However, reducing exploration risks in unknown environments, where an agent must discover safety threats during exploration, remains challenging. In this paper, we target the problem of safe exploration by guiding the training with counterexamples of the safety requirement. Our method abstracts both continuous and discrete state-space systems into compact abstract models representing the safety-relevant knowledge acquired by the agent during exploration. We then exploit probabilistic counterexample generation to construct minimal simulation submodels eliciting safety requirement violations, where the agent can efficiently train offline to refine its policy towards minimising the risk of safety violations during the subsequent online exploration. We demonstrate our method's effectiveness in reducing safety violations during online exploration in preliminary experiments by an average of 40.3% compared with QL and DQN standard algorithms and 29.1% compared with previous related work, while achieving comparable cumulative rewards with respect to unrestricted exploration and alternative approaches.", "url": "https://arxiv.org/abs/2307.04927"}, {"metadata": {"arXiv": "2307.04937", "Date": "Mon, 10 Jul 2023 23:28:03 ", "Title": "Improving Fairness of Graph Neural Networks: A Graph Counterfactual Perspective", "Authors": ["Zhimeng Guo", "Jialiang Li", "Teng Xiao", "Yao Ma", "Suhang Wang"], "Categories": "cs.LG"}, "abstract": "Graph neural networks have shown great ability in representation (GNNs) learning on graphs, facilitating various tasks. Despite their great performance in modeling graphs, recent works show that GNNs tend to inherit and amplify the bias from training data, causing concerns of the adoption of GNNs in high-stake scenarios. Hence, many efforts have been taken for fairness-aware GNNs. However, most existing fair GNNs learn fair node representations by adopting statistical fairness notions, which may fail to alleviate bias in the presence of statistical anomalies. Motivated by causal theory, there are several attempts utilizing graph counterfactual fairness to mitigate root causes of unfairness. However, these methods suffer from non-realistic counterfactuals obtained by perturbation or generation. In this paper, we take a causal view on fair graph learning problem. Guided by the casual analysis, we propose a novel framework CAF, which can select counterfactuals from training data to avoid non-realistic counterfactuals and adopt selected counterfactuals to learn fair node representations for node classification task. Extensive experiments on synthetic and real-world datasets show the effectiveness of CAF.", "url": "https://arxiv.org/abs/2307.04937"}, {"metadata": {"arXiv": "2307.04942", "Date": "Tue, 11 Jul 2023 00:14:45 ", "Title": "Benchmarking Algorithms for Federated Domain Generalization", "Authors": ["Ruqi Bai", "Saurabh Bagchi", "David I. Inouye"], "Categories": "cs.LG"}, "abstract": "While prior domain generalization (DG) benchmarks consider train-test dataset heterogeneity, we evaluate Federated DG which introduces federated learning (FL) specific challenges. Additionally, we explore domain-based heterogeneity in clients' local datasets - a realistic Federated DG scenario. Prior Federated DG evaluations are limited in terms of the number or heterogeneity of clients and dataset diversity. To address this gap, we propose an Federated DG benchmark methodology that enables control of the number and heterogeneity of clients and provides metrics for dataset difficulty. We then apply our methodology to evaluate 13 Federated DG methods, which include centralized DG methods adapted to the FL context, FL methods that handle client heterogeneity, and methods designed specifically for Federated DG. Our results suggest that despite some progress, there remain significant performance gaps in Federated DG particularly when evaluating with a large number of clients, high client heterogeneity, or more realistic datasets. Please check our extendable benchmark code here: https://github.com/inouye-lab/FedDG_Benchmark.", "url": "https://arxiv.org/abs/2307.04942"}, {"metadata": {"arXiv": "2307.04954", "Date": "Tue, 11 Jul 2023 00:56:44 ", "Title": "Hybrid hidden Markov LSTM for short-term traffic flow prediction", "Authors": ["Agnimitra Sengupta", "Adway Das", "S. Ilgin Guler"], "Categories": "cs.LG stat.ML"}, "abstract": "Deep learning (DL) methods have outperformed parametric models such as historical average, ARIMA and variants in predicting traffic variables into short and near-short future, that are critical for traffic management. Specifically, recurrent neural network (RNN) and its variants (e.g. long short-term memory) are designed to retain long-term temporal correlations and therefore are suitable for modeling sequences. However, multi-regime models assume the traffic system to evolve through multiple states (say, free-flow, congestion in traffic) with distinct characteristics, and hence, separate models are trained to characterize the traffic dynamics within each regime. For instance, Markov-switching models with a hidden Markov model (HMM) for regime identification is capable of capturing complex dynamic patterns and non-stationarity. Interestingly, both HMM and LSTM can be used for modeling an observation sequence from a set of latent or, hidden state variables. In LSTM, the latent variable is computed in a deterministic manner from the current observation and the previous latent variable, while, in HMM, the set of latent variables is a Markov chain. Inspired by research in natural language processing, a hybrid hidden Markov-LSTM model that is capable of learning complementary features in traffic data is proposed for traffic flow prediction. Results indicate significant performance gains in using hybrid architecture compared to conventional methods such as Markov switching ARIMA and LSTM.", "url": "https://arxiv.org/abs/2307.04954"}, {"metadata": {"arXiv": "2307.04988", "Date": "Tue, 11 Jul 2023 02:58:10 ", "Title": "Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect Estimation", "Authors": ["Chris Chinenye Emezue", "Alexandre Drouin", "Tristan Deleu", "Stefan Bauer", "Yoshua Bengio"], "Categories": "cs.LG stat.ME", "Comments": ["Peer-Reviewed and Accepted to ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling"]}, "abstract": "The practical utility of causality in decision-making is widely recognized, with causal discovery and inference being inherently intertwined. Nevertheless, a notable gap exists in the evaluation of causal discovery methods, where insufficient emphasis is placed on downstream inference. To address this gap, we evaluate six established baseline causal discovery methods and a newly proposed method based on GFlowNets, on the downstream task of treatment effect estimation. Through the implementation of a robust evaluation procedure, we offer valuable insights into the efficacy of these causal discovery methods for treatment effect estimation, considering both synthetic and real-world scenarios, as well as low-data scenarios. Furthermore, the results of our study demonstrate that GFlowNets possess the capability to effectively capture a wide range of useful and diverse ATE modes.", "url": "https://arxiv.org/abs/2307.04988"}, {"metadata": {"arXiv": "2307.04995", "Date": "Tue, 11 Jul 2023 03:17:40 ", "Title": "PowerFusion: A Tensor Compiler with Explicit Data Movement Description and Instruction-level Graph IR", "Authors": ["Zixuan Ma", "Haojie Wang", "Jingze Xing", "Liyan Zheng", "Chen Zhang", "Huanqi Cao", "Kezhao Huang", "Shizhi Tang", "Penghan Wang and Jidong Zhai"], "Categories": "cs.LG cs.PL", "Comments": ["12 pages", "14 figures"]}, "abstract": "Deep neural networks (DNNs) are of critical use in different domains. To accelerate DNN computation, tensor compilers are proposed to generate efficient code on different domain-specific accelerators. Existing tensor compilers mainly focus on optimizing computation efficiency. However, memory access is becoming a key performance bottleneck because the computational performance of accelerators is increasing much faster than memory performance. The lack of direct description of memory access and data dependence in current tensor compilers' intermediate representation (IR) brings significant challenges to generate memory-efficient code. In this paper, we propose IntelliGen, a tensor compiler that can generate high-performance code for memory-intensive operators by considering both computation and data movement optimizations. IntelliGen represent a DNN program using GIR, which includes primitives indicating its computation, data movement, and parallel strategies. This information will be further composed as an instruction-level dataflow graph to perform holistic optimizations by searching different memory access patterns and computation operations, and generating memory-efficient code on different hardware. We evaluate IntelliGen on NVIDIA GPU, AMD GPU, and Cambricon MLU, showing speedup up to 1.97x, 2.93x, and 16.91x(1.28x, 1.23x, and 2.31x on average), respectively, compared to current most performant frameworks.", "url": "https://arxiv.org/abs/2307.04995"}, {"metadata": {"arXiv": "2307.05029", "Date": "Tue, 11 Jul 2023 06:05:06 ", "Title": "FairLay-ML: Intuitive Remedies for Unfairness in Data-Driven Social-Critical Algorithms", "Authors": ["Normen Yu", "Gang Tan", "Saeid Tizpaz-Niari"], "Categories": "cs.LG cs.CY"}, "abstract": "This thesis explores open-sourced machine learning (ML) model explanation tools to understand whether these tools can allow a layman to visualize, understand, and suggest intuitive remedies to unfairness in ML-based decision-support systems. Machine learning models trained on datasets biased against minority groups are increasingly used to guide life-altering social decisions, prompting the urgent need to study their logic for unfairness. Due to this problem's impact on vast populations of the general public, it is critical for the layperson -- not just subject matter experts in social justice or machine learning experts -- to understand the nature of unfairness within these algorithms and the potential trade-offs. Existing research on fairness in machine learning focuses mostly on the mathematical definitions and tools to understand and remedy unfair models, with some directly citing user-interactive tools as necessary for future work. This thesis presents FairLay-ML, a proof-of-concept GUI integrating some of the most promising tools to provide intuitive explanations for unfair logic in ML models by integrating existing research tools (e.g. Local Interpretable Model-Agnostic Explanations) with existing ML-focused GUI (e.g. Python Streamlit). We test FairLay-ML using models of various accuracy and fairness generated by an unfairness detector tool, Parfait-ML, and validate our results using Themis. Our study finds that the technology stack used for FairLay-ML makes it easy to install and provides real-time black-box explanations of pre-trained models to users. Furthermore, the explanations provided translate to actionable remedies.", "url": "https://arxiv.org/abs/2307.05029"}, {"metadata": {"arXiv": "2307.05080", "Date": "Tue, 11 Jul 2023 07:29:09 ", "Title": "Estimating label quality and errors in semantic segmentation data via any model", "Authors": ["Vedang Lad", "Jonas Mueller"], "Categories": "cs.LG cs.CV", "Comments": ["ICML Workshop on Data-centric Machine Learning Research 2023"]}, "abstract": "The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly. We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled. This helps prioritize what data to review in order to ensure a high-quality training/evaluation dataset, which is critical in sensitive applications such as medical imaging and autonomous vehicles. Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized. Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset. Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error.", "url": "https://arxiv.org/abs/2307.05080"}, {"metadata": {"arXiv": "2307.05109", "Date": "Tue, 11 Jul 2023 08:36:12 ", "Title": "Conformalization of Sparse Generalized Linear Models", "Authors": ["Etash Kumar Guha and Eugene Ndiaye and Xiaoming Huo"], "Categories": "cs.LG stat.ML", "Comments": ["ICML 2023"]}, "abstract": "Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$, the conformal prediction method estimates a confidence set for $y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely assuming that the joint distribution of the data is permutation invariant. Although attractive, computing such a set is computationally infeasible in most regression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can take an infinite number of possible candidate values, and generating conformal sets requires retraining a predictive model for each candidate. In this paper, we focus on a sparse linear model with only a subset of variables for prediction and use numerical continuation techniques to approximate the solution path efficiently. The critical property we exploit is that the set of selected variables is invariant under a small perturbation of the input data. Therefore, it is sufficient to enumerate and refit the model only at the change points of the set of active features and smoothly interpolate the rest of the solution via a Predictor-Corrector mechanism. We show how our path-following algorithm accurately approximates conformal prediction sets and illustrate its performance using synthetic and real data examples.", "url": "https://arxiv.org/abs/2307.05109"}, {"metadata": {"arXiv": "2307.05121", "Date": "Tue, 11 Jul 2023 08:56:53 ", "Title": "Transaction Fraud Detection via Spatial-Temporal-Aware Graph Transformer", "Authors": ["Yue Tian", "Guanjun Liu"], "Categories": "cs.LG q-fin.GN"}, "abstract": "How to obtain informative representations of transactions and then perform the identification of fraudulent transactions is a crucial part of ensuring financial security. Recent studies apply Graph Neural Networks (GNNs) to the transaction fraud detection problem. Nevertheless, they encounter challenges in effectively learning spatial-temporal information due to structural limitations. Moreover, few prior GNN-based detectors have recognized the significance of incorporating global information, which encompasses similar behavioral patterns and offers valuable insights for discriminative representation learning. Therefore, we propose a novel heterogeneous graph neural network called Spatial-Temporal-Aware Graph Transformer (STA-GT) for transaction fraud detection problems. Specifically, we design a temporal encoding strategy to capture temporal dependencies and incorporate it into the graph neural network framework, enhancing spatial-temporal information modeling and improving expressive ability. Furthermore, we introduce a transformer module to learn local and global information. Pairwise node-node interactions overcome the limitation of the GNN structure and build up the interactions with the target node and long-distance ones. Experimental results on two financial datasets compared to general GNN models and GNN-based fraud detectors demonstrate that our proposed method STA-GT is effective on the transaction fraud detection task.", "url": "https://arxiv.org/abs/2307.05121"}, {"metadata": {"arXiv": "2307.05126", "Date": "Tue, 11 Jul 2023 09:01:49 ", "Title": "Enhancing Continuous Time Series Modelling with a Latent ODE-LSTM Approach", "Authors": ["C. Coelho", "M. Fernanda P. Costa", "L.L. Ferr\\'as"], "Categories": "cs.LG math.OC", "ACM-class": "I.5.1; G.1.7"}, "abstract": "Due to their dynamic properties such as irregular sampling rate and high-frequency sampling, Continuous Time Series (CTS) are found in many applications. Since CTS with irregular sampling rate are difficult to model with standard Recurrent Neural Networks (RNNs), RNNs have been generalised to have continuous-time hidden dynamics defined by a Neural Ordinary Differential Equation (Neural ODE), leading to the ODE-RNN model. Another approach that provides a better modelling is that of the Latent ODE model, which constructs a continuous-time model where a latent state is defined at all times. The Latent ODE model uses a standard RNN as the encoder and a Neural ODE as the decoder. However, since the RNN encoder leads to difficulties with missing data and ill-defined latent variables, a Latent ODE-RNN model has recently been proposed that uses a ODE-RNN model as the encoder instead. Both the Latent ODE and Latent ODE-RNN models are difficult to train due to the vanishing and exploding gradients problem. To overcome this problem, the main contribution of this paper is to propose and illustrate a new model based on a new Latent ODE using an ODE-LSTM (Long Short-Term Memory) network as an encoder -- the Latent ODE-LSTM model. To limit the growth of the gradients the Norm Gradient Clipping strategy was embedded on the Latent ODE-LSTM model. The performance evaluation of the new Latent ODE-LSTM (with and without Norm Gradient Clipping) for modelling CTS with regular and irregular sampling rates is then demonstrated. Numerical experiments show that the new Latent ODE-LSTM performs better than Latent ODE-RNNs and can avoid the vanishing and exploding gradients during training.", "url": "https://arxiv.org/abs/2307.05126"}, {"metadata": {"arXiv": "2307.05163", "Date": "Tue, 11 Jul 2023 10:41:41 ", "Title": "A Mapping Study of Machine Learning Methods for Remaining Useful Life Estimation of Lead-Acid Batteries", "Authors": ["S\\'ergio F Chevtchenko", "Elisson da Silva Rocha", "Bruna Cruz", "Ermeson Carneiro de Andrade", "Danilo Ricardo Barbosa de Ara\\'ujo"], "Categories": "cs.LG"}, "abstract": "Energy storage solutions play an increasingly important role in modern infrastructure and lead-acid batteries are among the most commonly used in the rechargeable category. Due to normal degradation over time, correctly determining the battery's State of Health (SoH) and Remaining Useful Life (RUL) contributes to enhancing predictive maintenance, reliability, and longevity of battery systems. Besides improving the cost savings, correct estimation of the SoH can lead to reduced pollution though reuse of retired batteries. This paper presents a mapping study of the state-of-the-art in machine learning methods for estimating the SoH and RUL of lead-acid batteries. These two indicators are critical in the battery management systems of electric vehicles, renewable energy systems, and other applications that rely heavily on this battery technology. In this study, we analyzed the types of machine learning algorithms employed for estimating SoH and RUL, and evaluated their performance in terms of accuracy and inference time. Additionally, this mapping identifies and analyzes the most commonly used combinations of sensors in specific applications, such as vehicular batteries. The mapping concludes by highlighting potential gaps and opportunities for future research, which lays the foundation for further advancements in the field.", "url": "https://arxiv.org/abs/2307.05163"}, {"metadata": {"arXiv": "2307.05189", "Date": "Tue, 11 Jul 2023 11:53:25 ", "Title": "Using Linear Regression for Iteratively Training Neural Networks", "Authors": ["Harshad Khadilkar"], "Categories": "cs.LG", "Comments": ["9 pages"]}, "abstract": "We present a simple linear regression based approach for learning the weights and biases of a neural network, as an alternative to standard gradient based backpropagation. The present work is exploratory in nature, and we restrict the description and experiments to (i) simple feedforward neural networks, (ii) scalar (single output) regression problems, and (iii) invertible activation functions. However, the approach is intended to be extensible to larger, more complex architectures. The key idea is the observation that the input to every neuron in a neural network is a linear combination of the activations of neurons in the previous layer, as well as the parameters (weights and biases) of the layer. If we are able to compute the ideal total input values to every neuron by working backwards from the output, we can formulate the learning problem as a linear least squares problem which iterates between updating the parameters and the activation values. We present an explicit algorithm that implements this idea, and we show that (at least for simple problems) the approach is more stable and faster than gradient-based backpropagation.", "url": "https://arxiv.org/abs/2307.05189"}, {"metadata": {"arXiv": "2307.05193", "Date": "Tue, 11 Jul 2023 11:59:04 ", "Title": "Membership Inference Attacks on DNNs using Adversarial Perturbations", "Authors": ["Hassan Ali", "Adnan Qayyum", "Ala Al-Fuqaha", "Junaid Qadir"], "Categories": "cs.LG cs.CR"}, "abstract": "Several membership inference (MI) attacks have been proposed to audit a target DNN. Given a set of subjects, MI attacks tell which subjects the target DNN has seen during training. This work focuses on the post-training MI attacks emphasizing high confidence membership detection -- True Positive Rates (TPR) at low False Positive Rates (FPR). Current works in this category -- likelihood ratio attack (LiRA) and enhanced MI attack (EMIA) -- only perform well on complex datasets (e.g., CIFAR-10 and Imagenet) where the target DNN overfits its train set, but perform poorly on simpler datasets (0% TPR by both attacks on Fashion-MNIST, 2% and 0% TPR respectively by LiRA and EMIA on MNIST at 1% FPR). To address this, firstly, we unify current MI attacks by presenting a framework divided into three stages -- preparation, indication and decision. Secondly, we utilize the framework to propose two novel attacks: (1) Adversarial Membership Inference Attack (AMIA) efficiently utilizes the membership and the non-membership information of the subjects while adversarially minimizing a novel loss function, achieving 6% TPR on both Fashion-MNIST and MNIST datasets; and (2) Enhanced AMIA (E-AMIA) combines EMIA and AMIA to achieve 8% and 4% TPRs on Fashion-MNIST and MNIST datasets respectively, at 1% FPR. Thirdly, we introduce two novel augmented indicators that positively leverage the loss information in the Gaussian neighborhood of a subject. This improves TPR of all four attacks on average by 2.5% and 0.25% respectively on Fashion-MNIST and MNIST datasets at 1% FPR. Finally, we propose simple, yet novel, evaluation metric, the running TPR average (RTA) at a given FPR, that better distinguishes different MI attacks in the low FPR region. We also show that AMIA and E-AMIA are more transferable to the unknown DNNs (other than the target DNN) and are more robust to DP-SGD training as compared to LiRA and EMIA.", "url": "https://arxiv.org/abs/2307.05193"}, {"metadata": {"arXiv": "2307.05199", "Date": "Tue, 11 Jul 2023 12:09:14 ", "Title": "Reject option models comprising out-of-distribution detection", "Authors": ["Vojtech Franc", "Daniel Prusa", "Jakub Paplham"], "Categories": "cs.LG"}, "abstract": "The optimal prediction strategy for out-of-distribution (OOD) setups is a fundamental question in machine learning. In this paper, we address this question and present several contributions. We propose three reject option models for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the Bounded Precision-Recall model. These models extend the standard reject option models used in non-OOD setups and define the notion of an optimal OOD selective classifier. We establish that all the proposed models, despite their different formulations, share a common class of optimal strategies. Motivated by the optimal strategy, we introduce double-score OOD methods that leverage uncertainty scores from two chosen OOD detectors: one focused on OOD/ID discrimination and the other on misclassification detection. The experimental results consistently demonstrate the superior performance of this simple strategy compared to state-of-the-art methods. Additionally, we propose novel evaluation metrics derived from the definition of the optimal strategy under the proposed OOD rejection models. These new metrics provide a comprehensive and reliable assessment of OOD methods without the deficiencies observed in existing evaluation approaches.", "url": "https://arxiv.org/abs/2307.05199"}, {"metadata": {"arXiv": "2307.05217", "Date": "Tue, 11 Jul 2023 12:43:23 ", "Title": "Supervised Attention Using Homophily in Graph Neural Networks", "Authors": ["Michail Chatzianastasis", "Giannis Nikolentzos", "Michalis Vazirgiannis"], "Categories": "cs.LG cs.SI", "Comments": ["Accepted at ICANN 2023"]}, "abstract": "Graph neural networks have become the standard approach for dealing with learning problems on graphs. Among the different variants of graph neural networks, graph attention networks (GATs) have been applied with great success to different tasks. In the GAT model, each node assigns an importance score to its neighbors using an attention mechanism. However, similar to other graph neural networks, GATs aggregate messages from nodes that belong to different classes, and therefore produce node representations that are not well separated with respect to the different classes, which might hurt their performance. In this work, to alleviate this problem, we propose a new technique that can be incorporated into any graph attention model to encourage higher attention scores between nodes that share the same class label. We evaluate the proposed method on several node classification datasets demonstrating increased performance over standard baseline models.", "url": "https://arxiv.org/abs/2307.05217"}, {"metadata": {"arXiv": "2307.05232", "Date": "Tue, 11 Jul 2023 13:06:42 ", "Title": "A Survey From Distributed Machine Learning to Distributed Deep Learning", "Authors": ["Mohammad Dehghani", "Zahra Yazdanparast"], "Categories": "cs.LG cs.DC"}, "abstract": "Artificial intelligence has achieved significant success in handling complex tasks in recent years. This success is due to advances in machine learning algorithms and hardware acceleration. In order to obtain more accurate results and solve more complex problems, algorithms must be trained with more data. This huge amount of data could be time-consuming to process and require a great deal of computation. This solution could be achieved by distributing the data and algorithm across several machines, which is known as distributed machine learning. There has been considerable effort put into distributed machine learning algorithms, and different methods have been proposed so far. In this article, we present a comprehensive summary of the current state-of-the-art in the field through the review of these algorithms. We divide this algorithms in classification and clustering (traditional machine learning), deep learning and deep reinforcement learning groups. Distributed deep learning has gained more attention in recent years and most of studies worked on this algorithms. As a result, most of the articles we discussed here belong to this category. Based on our investigation of algorithms, we highlight limitations that should be addressed in future research.", "url": "https://arxiv.org/abs/2307.05232"}, {"metadata": {"arXiv": "2307.05252", "Date": "Tue, 11 Jul 2023 13:35:27 ", "Title": "MAP- and MLE-Based Teaching", "Authors": ["Hans Ulrich Simon", "Jan Arne Telle"], "Categories": "cs.LG stat.ML"}, "abstract": "Imagine a learner L who tries to infer a hidden concept from a collection of observations. Building on the work [4] of Ferri et al., we assume the learner to be parameterized by priors P(c) and by c-conditional likelihoods P(z|c) where c ranges over all concepts in a given class C and z ranges over all observations in an observation set Z. L is called a MAP-learner (resp. an MLE-learner) if it thinks of a collection S of observations as a random sample and returns the concept with the maximum a-posteriori probability (resp. the concept which maximizes the c-conditional likelihood of S). Depending on whether L assumes that S is obtained from ordered or unordered sampling resp. from sampling with or without replacement, we can distinguish four different sampling modes. Given a target concept c in C, a teacher for a MAP-learner L aims at finding a smallest collection of observations that causes L to return c. This approach leads in a natural manner to various notions of a MAP- or MLE-teaching dimension of a concept class C. Our main results are: We show that this teaching model has some desirable monotonicity properties. We clarify how the four sampling modes are related to each other. As for the (important!) special case, where concepts are subsets of a domain and observations are 0,1-labeled examples, we obtain some additional results. First of all, we characterize the MAP- and MLE-teaching dimension associated with an optimally parameterized MAP-learner graph-theoretically. From this central result, some other ones are easy to derive. It is shown, for instance, that the MLE-teaching dimension is either equal to the MAP-teaching dimension or exceeds the latter by 1. It is shown furthermore that these dimensions can be bounded from above by the so-called antichain number, the VC-dimension and related combinatorial parameters. Moreover they can be computed in polynomial time.", "url": "https://arxiv.org/abs/2307.05252"}, {"metadata": {"arXiv": "2307.05275", "Date": "Tue, 11 Jul 2023 14:08:51 ", "Title": "CareFall: Automatic Fall Detection through Wearable Devices and AI Methods", "Authors": ["Juan Carlos Ruiz-Garcia", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Carlos Moro"], "Categories": "cs.LG eess.SP", "Comments": ["3 pages", "1 figure", "2 tables"]}, "abstract": "The aging population has led to a growing number of falls in our society, affecting global public health worldwide. This paper presents CareFall, an automatic Fall Detection System (FDS) based on wearable devices and Artificial Intelligence (AI) methods. CareFall considers the accelerometer and gyroscope time signals extracted from a smartwatch. Two different approaches are used for feature extraction and classification: i) threshold-based, and ii) machine learning-based. Experimental results on two public databases show that the machine learning-based approach, which combines accelerometer and gyroscope information, outperforms the threshold-based approach in terms of accuracy, sensitivity, and specificity. This research contributes to the design of smart and user-friendly solutions to mitigate the negative consequences of falls among older people.", "url": "https://arxiv.org/abs/2307.05275"}, {"metadata": {"arXiv": "2307.05299", "Date": "Tue, 11 Jul 2023 14:43:25 ", "Title": "Discovering Symbolic Laws Directly from Trajectories with Hamiltonian Graph Neural Networks", "Authors": ["Suresh Bishnoi", "Ravinder Bhattoo", "Jayadeva", "Sayan Ranu", "N M Anoop Krishnan"], "Categories": "cs.LG cond-mat.dis-nn cond-mat.mtrl-sci physics.comp-ph"}, "abstract": "The time evolution of physical systems is described by differential equations, which depend on abstract quantities like energy and force. Traditionally, these quantities are derived as functionals based on observables such as positions and velocities. Discovering these governing symbolic laws is the key to comprehending the interactions in nature. Here, we present a Hamiltonian graph neural network (HGNN), a physics-enforced GNN that learns the dynamics of systems directly from their trajectory. We demonstrate the performance of HGNN on n-springs, n-pendulums, gravitational systems, and binary Lennard Jones systems; HGNN learns the dynamics in excellent agreement with the ground truth from small amounts of data. We also evaluate the ability of HGNN to generalize to larger system sizes, and to hybrid spring-pendulum system that is a combination of two original systems (spring and pendulum) on which the models are trained independently. Finally, employing symbolic regression on the learned HGNN, we infer the underlying equations relating the energy functionals, even for complex systems such as the binary Lennard-Jones liquid. Our framework facilitates the interpretable discovery of interaction laws directly from physical system trajectories. Furthermore, this approach can be extended to other systems with topology-dependent dynamics, such as cells, polydisperse gels, or deformable bodies.", "url": "https://arxiv.org/abs/2307.05299"}, {"metadata": {"arXiv": "2307.05350", "Date": "Fri, 07 Jul 2023 01:10:18 ", "Title": "Route, Interpret, Repeat: Blurring the line between post hoc explainability and interpretable models", "Authors": ["Shantanu Ghosh", "Ke Yu", "Forough Arabshahi", "Kayhan Batmanghelich"], "Categories": "cs.LG cs.CV cs.CY", "Comments": ["appeared as v1 of arXiv:2302.10289 which was replaced in error", "which drifted into a different work"]}, "abstract": "The current approach to ML model design is either to choose a flexible Blackbox model and explain it post hoc or to start with an interpretable model. Blackbox models are flexible but difficult to explain, whereas interpretable models are designed to be explainable. However, developing interpretable models necessitates extensive ML knowledge, and the resulting models tend to be less flexible, offering potentially subpar performance compared to their Blackbox equivalents. This paper aims to blur the distinction between a post hoc explanation of a BlackBox and constructing interpretable models. We propose beginning with a flexible BlackBox model and gradually \\emph{carving out} a mixture of interpretable models and a \\emph{residual network}. Our design identifies a subset of samples and \\emph{routes} them through the interpretable models. The remaining samples are routed through a flexible residual network. We adopt First Order Logic (FOL) as the interpretable model's backbone, which provides basic reasoning on concepts retrieved from the BlackBox model. On the residual network, we repeat the method until the proportion of data explained by the residual network falls below a desired threshold. Our approach offers several advantages. First, the mixture of interpretable and flexible residual networks results in almost no compromise in performance. Second, the route, interpret, and repeat approach yields a highly flexible interpretable model. Our extensive experiment demonstrates the performance of the model on various datasets. We show that by editing the FOL model, we can fix the shortcut learned by the original BlackBox model. Finally, our method provides a framework for a hybrid symbolic-connectionist network that is simple to train and adaptable to many applications.", "url": "https://arxiv.org/abs/2307.05350"}, {"metadata": {"arXiv": "2307.05432", "Date": "Tue, 11 Jul 2023 16:52:22 ", "Title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations", "Authors": ["Gr\\'egoire Mialon", "Quentin Garrido", "Hannah Lawrence", "Danyal Rehman", "Yann LeCun", "Bobak T. Kiani"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs.", "url": "https://arxiv.org/abs/2307.05432"}, {"metadata": {"arXiv": "2307.05435", "Date": "Tue, 11 Jul 2023 16:57:17 ", "Title": "One-Versus-Others Attention: Scalable Multimodal Integration", "Authors": ["Michal Golovanevsky", "Eva Schiller", "Akira Nair", "Ritambhara Singh", "Carsten Eickhoff"], "Categories": "cs.LG"}, "abstract": "Multimodal learning models have become increasingly important as they surpass single-modality approaches on diverse tasks ranging from question-answering to autonomous driving. Despite the importance of multimodal learning, existing efforts focus on NLP applications, where the number of modalities is typically less than four (audio, video, text, images). However, data inputs in other domains, such as the medical field, may include X-rays, PET scans, MRIs, genetic screening, clinical notes, and more, creating a need for both efficient and accurate information fusion. Many state-of-the-art models rely on pairwise cross-modal attention, which does not scale well for applications with more than three modalities. For $n$ modalities, computing attention will result in $n \\choose 2$ operations, potentially requiring considerable amounts of computational resources. To address this, we propose a new domain-neutral attention mechanism, One-Versus-Others (OvO) attention, that scales linearly with the number of modalities and requires only $n$ attention operations, thus offering a significant reduction in computational complexity compared to existing cross-modal attention algorithms. Using three diverse real-world datasets as well as an additional simulation experiment, we show that our method improves performance compared to popular fusion techniques while decreasing computation costs.", "url": "https://arxiv.org/abs/2307.05435"}, {"metadata": {"arXiv": "2307.05439", "Date": "Tue, 11 Jul 2023 17:05:23 ", "Title": "Metropolis Sampling for Constrained Diffusion Models", "Authors": ["Nic Fishman", "Leo Klarner", "Emile Mathieu", "Michael Hutchinson", "Valentin de Bortoli"], "Categories": "cs.LG"}, "abstract": "Denoising diffusion models have recently emerged as the predominant paradigm for generative modelling. Their extension to Riemannian manifolds has facilitated their application to an array of problems in the natural sciences. Yet, in many practical settings, such manifolds are defined by a set of constraints and are not covered by the existing (Riemannian) diffusion model methodology. Recent work has attempted to address this issue by employing novel noising processes based on logarithmic barrier methods or reflected Brownian motions. However, the associated samplers are computationally burdensome as the complexity of the constraints increases. In this paper, we introduce an alternative simple noising scheme based on Metropolis sampling that affords substantial gains in computational efficiency and empirical performance compared to the earlier samplers. Of independent interest, we prove that this new process corresponds to a valid discretisation of the reflected Brownian motion. We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modelling, robotics and protein design.", "url": "https://arxiv.org/abs/2307.05439"}, {"metadata": {"arXiv": "2307.05141", "Date": "Tue, 11 Jul 2023 09:34:15 ", "Title": "Deep Probabilistic Movement Primitives with a Bayesian Aggregator", "Authors": ["Michael Przystupa", "Faezeh Haghverd", "Martin Jagersand", "Samuele Tosatto"], "Categories": "cs.RO cs.LG"}, "abstract": "Movement primitives are trainable parametric models that reproduce robotic movements starting from a limited set of demonstrations. Previous works proposed simple linear models that exhibited high sample efficiency and generalization power by allowing temporal modulation of movements (reproducing movements faster or slower), blending (merging two movements into one), via-point conditioning (constraining a movement to meet some particular via-points) and context conditioning (generation of movements based on an observed variable, e.g., position of an object). Previous works have proposed neural network-based motor primitive models, having demonstrated their capacity to perform tasks with some forms of input conditioning or time-modulation representations. However, there has not been a single unified deep motor primitive's model proposed that is capable of all previous operations, limiting neural motor primitive's potential applications. This paper proposes a deep movement primitive architecture that encodes all the operations above and uses a Bayesian context aggregator that allows a more sound context conditioning and blending. Our results demonstrate our approach can scale to reproduce complex motions on a larger variety of input choices compared to baselines while maintaining operations of linear movement primitives provide.", "url": "https://arxiv.org/abs/2307.05141"}, {"metadata": {"arXiv": "2307.05405", "Date": "Tue, 11 Jul 2023 16:12:15 ", "Title": "Boosting Feedback Efficiency of Interactive Reinforcement Learning by Adaptive Learning from Scores", "Authors": ["Shukai Liu", "Chenming Wu", "Ying Li", "Liangjun Zhang"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)"]}, "abstract": "Interactive reinforcement learning has shown promise in learning complex robotic tasks. However, the process can be human-intensive due to the requirement of large amount of interactive feedback. This paper presents a new method that uses scores provided by humans, instead of pairwise preferences, to improve the feedback efficiency of interactive reinforcement learning. Our key insight is that scores can yield significantly more data than pairwise preferences. Specifically, we require a teacher to interactively score the full trajectories of an agent to train a behavioral policy in a sparse reward environment. To avoid unstable scores given by human negatively impact the training process, we propose an adaptive learning scheme. This enables the learning paradigm to be insensitive to imperfect or unreliable scores. We extensively evaluate our method on robotic locomotion and manipulation tasks. The results show that the proposed method can efficiently learn near-optimal policies by adaptive learning from scores, while requiring less feedback compared to pairwise preference learning methods. The source codes are publicly available at https://github.com/SSKKai/Interactive-Scoring-IRL.", "url": "https://arxiv.org/abs/2307.05405"}, {"metadata": {"arXiv": "2307.04986", "Date": "Tue, 11 Jul 2023 02:52:32 ", "Title": "Epidemic Modeling with Generative Agents", "Authors": ["Ross Williams", "Niyousha Hosseinichimeh", "Aritra Majumdar", "Navid Ghaffarzadegan"], "Categories": "cs.AI cs.MA econ.GN nlin.AO physics.soc-ph q-fin.EC"}, "abstract": "This study offers a new paradigm of individual-level modeling to address the grand challenge of incorporating human behavior in epidemic models. Using generative artificial intelligence in an agent-based epidemic model, each agent is empowered to make its own reasonings and decisions via connecting to a large language model such as ChatGPT. Through various simulation experiments, we present compelling evidence that generative agents mimic real-world behaviors such as quarantining when sick and self-isolation when cases rise. Collectively, the agents demonstrate patterns akin to multiple waves observed in recent pandemics followed by an endemic period. Moreover, the agents successfully flatten the epidemic curve. This study creates potential to improve dynamic system modeling by offering a way to represent human brain, reasoning, and decision making.", "url": "https://arxiv.org/abs/2307.04986"}, {"metadata": {"arXiv": "2307.05036", "Date": "Tue, 11 Jul 2023 06:29:31 ", "Title": "Neural-Symbolic Recommendation with Graph-Enhanced Information", "Authors": ["Bang Chen", "Wei Peng", "Maonian Wu", "Bo Zheng", "Shaojun Zhu"], "Categories": "cs.AI cs.IR", "Comments": ["12 pages", "2 figures", "conference"]}, "abstract": "The recommendation system is not only a problem of inductive statistics from data but also a cognitive task that requires reasoning ability. The most advanced graph neural networks have been widely used in recommendation systems because they can capture implicit structured information from graph-structured data. However, like most neural network algorithms, they only learn matching patterns from a perception perspective. Some researchers use user behavior for logic reasoning to achieve recommendation prediction from the perspective of cognitive reasoning, but this kind of reasoning is a local one and ignores implicit information on a global scale. In this work, we combine the advantages of graph neural networks and propositional logic operations to construct a neuro-symbolic recommendation model with both global implicit reasoning ability and local explicit logic reasoning ability. We first build an item-item graph based on the principle of adjacent interaction and use graph neural networks to capture implicit information in global data. Then we transform user behavior into propositional logic expressions to achieve recommendations from the perspective of cognitive reasoning. Extensive experiments on five public datasets show that our proposed model outperforms several state-of-the-art methods, source code is avaliable at [https://github.com/hanzo2020/GNNLR].", "url": "https://arxiv.org/abs/2307.05036"}, {"metadata": {"arXiv": "2307.05043", "Date": "Tue, 11 Jul 2023 06:50:49 ", "Title": "Epistemic Syllogistic: First Steps", "Authors": ["Yipu Li (Peking University)", "Yanjing Wang (Peking University)"], "Categories": "cs.AI cs.LO cs.MA", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 392-406", "DOI": "10.4204/EPTCS.379.31"}, "abstract": "Aristotle's discussions on modal syllogistic have often been viewed as error-prone and have garnered significant attention in the literature due to historical and philosophical interests. However, from a contemporary standpoint, they also introduced natural fragments of first-order modal logic, warranting a comprehensive technical analysis. In this paper, drawing inspiration from the natural logic program, we propose and examine several variants of modal syllogistic within the epistemic context, thereby coining the term Epistemic Syllogistic. Specifically, we concentrate on the de re interpretation of epistemic syllogisms containing non-trivial yet natural expressions such as \"all things known to be A are also known to be not B.\" We explore the epistemic apodeictic syllogistic and its extensions, which accommodate more complex terms. Our main contributions include several axiomatizations of these logics, with completeness proofs that may be of independent interest.", "url": "https://arxiv.org/abs/2307.05043"}, {"metadata": {"arXiv": "2307.05071", "Date": "Tue, 11 Jul 2023 07:14:53 ", "Title": "Mining for Unknown Unknowns", "Authors": ["Bernard Sinclair-Desgagn\\'e"], "Categories": "cs.AI cs.IR", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 507-517", "DOI": "10.4204/EPTCS.379.38"}, "abstract": "Unknown unknowns are future relevant contingencies that lack an ex ante description. While there are numerous retrospective accounts showing that significant gains or losses might have been achieved or avoided had such contingencies been previously uncovered, getting hold of unknown unknowns still remains elusive, both in practice and conceptually. Using Formal Concept Analysis (FCA) - a subfield of lattice theory which is increasingly applied for mining and organizing data - this paper introduces a simple framework to systematically think out of the box and direct the search for unknown unknowns.", "url": "https://arxiv.org/abs/2307.05071"}, {"metadata": {"arXiv": "2307.05072", "Date": "Tue, 11 Jul 2023 07:15:11 ", "Title": "Aggregating Credences into Beliefs: Agenda Conditions for Impossibility Results", "Authors": ["Minkyung Wang", "Chisu Kim"], "Categories": "cs.AI cs.GT cs.LO", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 518-526", "DOI": "10.4204/EPTCS.379.39"}, "abstract": "Binarizing belief aggregation addresses how to rationally aggregate individual probabilistic beliefs into collective binary beliefs. Similar to the development of judgment aggregation theory, formulating axiomatic requirements, proving impossibility theorems, and identifying exact agenda conditions of impossibility theorems are natural and important research topics in binarizing belief aggregation. Building on our previous research on impossibility theorems, we use an agenda-theoretic approach to generalize the results and to determine the necessary and sufficient level of logical interconnection between the issues in an agenda for the impossibility theorems to arise. We demonstrate that (1) path-connectedness and even-negatability constitute the exact agenda condition for the oligarchy result stating that binarizing belief aggregation satisfying proposition-wise independence and deductive closure of collective beliefs yields the oligarchies under minor conditions; (2) negation-connectedness is the condition for the triviality result obtained by adding anonymity to the oligarchy result; and (3) blockedness is the condition for the impossibility result, which follows by adding completeness and consistency of collective beliefs. Moreover, we compare these novel findings with existing agenda-theoretic characterization theorems in judgment aggregation and belief binarization.", "url": "https://arxiv.org/abs/2307.05072"}, {"metadata": {"arXiv": "2307.05082", "Date": "Tue, 11 Jul 2023 07:31:58 ", "Title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning", "Authors": ["Oleksandr Palagin", "Vladislav Kaverinskiy", "Anna Litvin and Kyrylo Malakhov"], "Categories": "cs.AI cs.CL cs.HC", "Comments": ["14 pages", "1 figure. Published. International Journal of Computing", "22(2)", "170-183. https://doi.org/10.47839/ijc.22.2.3086"], "MSC-class": "68T30, 68T50, 68T42", "ACM-class": "H.4.2; H.1.0; I.2.4; I.2.1; I.2.7; E.1", "Journal-ref": "International Journal of Computing (2023), 22(2), 170-183", "DOI": "10.47839/ijc.22.2.3086"}, "abstract": "This research presents a comprehensive methodology for utilizing an ontology-driven structured prompts system in interplay with ChatGPT, a widely used large language model (LLM). The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT's meta-learning capabilities. The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems. The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation. By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses. The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2 LLM. The underlying principles of meta-learning, structured prompts, and ontology-driven information retrieval form the core of the proposed methodology, enabling their adaptation and utilization in various LLM-based systems. This versatile approach opens up new possibilities for NLP and dialogue systems, empowering developers to enhance the performance and functionality of chatbot systems across different domains and languages.", "url": "https://arxiv.org/abs/2307.05082"}, {"metadata": {"arXiv": "2307.05150", "Date": "Tue, 11 Jul 2023 10:13:25 ", "Title": "A Modal Logic for Explaining some Graph Neural Networks", "Authors": ["Pierre Nunn and Fran\\c{c}ois Schwarzentruber"], "Categories": "cs.AI cs.LO"}, "abstract": "In this paper, we propose a modal logic in which counting modalities appear in linear inequalities. We show that each formula can be transformed into an equivalent graph neural network (GNN). We also show that each GNN can be transformed into a formula. We show that the satisfiability problem is decidable. We also discuss some variants that are in PSPACE.", "url": "https://arxiv.org/abs/2307.05150"}, {"metadata": {"arXiv": "2307.05156", "Date": "Tue, 11 Jul 2023 10:26:05 ", "Title": "Stable Normative Explanations: From Argumentation to Deontic Logic", "Authors": ["Cecilia Di Florio", "Guido Governatori", "Antonino Rotolo", "Giovanni Sartor"], "Categories": "cs.AI cs.LO", "Comments": ["15 pages", "extended version of the short paper accepted at JELIA 2023"]}, "abstract": "This paper examines how a notion of stable explanation developed elsewhere in Defeasible Logic can be expressed in the context of formal argumentation. With this done, we discuss the deontic meaning of this reconstruction and show how to build from argumentation neighborhood structures for deontic logic where this notion of explanation can be characterised. Some direct complexity results are offered.", "url": "https://arxiv.org/abs/2307.05156"}, {"metadata": {"arXiv": "2307.05258", "Date": "Tue, 11 Jul 2023 13:47:26 ", "Title": "Integrated Planning in Hospitals: A Review", "Authors": ["Sebastian Rachuba", "Melanie Reuter-Oppermann", "Clemens Thielen"], "Categories": "cs.AI cs.DM math.OC"}, "abstract": "Efficient planning of scarce resources in hospitals is a challenging task for which a large variety of Operations Research and Management Science approaches have been developed since the 1950s. While efficient planning of single resources such as operating rooms, beds, or specific types of staff can already lead to enormous efficiency gains, integrated planning of several resources has been shown to hold even greater potential, and a large number of integrated planning approaches have been presented in the literature over the past decades. This paper provides the first literature review that focuses specifically on the Operations Research and Management Science literature related to integrated planning of different resources in hospitals. We collect the relevant literature and analyze it regarding different aspects such as uncertainty modeling and the use of real-life data. Several cross comparisons reveal interesting insights concerning, e.g., relations between the modeling and solution methods used and the practical implementation of the approaches developed. Moreover, we provide a high-level taxonomy for classifying different resource-focused integration approaches and point out gaps in the literature as well as promising directions for future research.", "url": "https://arxiv.org/abs/2307.05258"}, {"metadata": {"arXiv": "2307.05300", "Date": "Tue, 11 Jul 2023 14:45:19 ", "Title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration", "Authors": ["Zhenhailong Wang", "Shaoguang Mao", "Wenshan Wu", "Tao Ge", "Furu Wei", "Heng Ji"], "Categories": "cs.AI cs.CL", "Comments": ["work in progress"]}, "abstract": "Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assigning multiple, fine-grained personas in LLMs elicits better problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP effectively elicits internal knowledge acquisition abilities, reduces hallucination, and maintains strong reasoning capabilities. Code, data, and prompts can be found at: https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.", "url": "https://arxiv.org/abs/2307.05300"}, {"metadata": {"arXiv": "2307.05075", "Date": "Tue, 11 Jul 2023 07:18:15 ", "Title": "Uni-Removal: A Semi-Supervised Framework for Simultaneously Addressing Multiple Degradations in Real-World Images", "Authors": ["Yongheng Zhang", "Danfeng Yan", "Yuanqiang Cai"], "Categories": "cs.CV cs.AI"}, "abstract": "Removing multiple degradations, such as haze, rain, and blur, from real-world images poses a challenging and illposed problem. Recently, unified models that can handle different degradations have been proposed and yield promising results. However, these approaches focus on synthetic images and experience a significant performance drop when applied to realworld images. In this paper, we introduce Uni-Removal, a twostage semi-supervised framework for addressing the removal of multiple degradations in real-world images using a unified model and parameters. In the knowledge transfer stage, Uni-Removal leverages a supervised multi-teacher and student architecture in the knowledge transfer stage to facilitate learning from pretrained teacher networks specialized in different degradation types. A multi-grained contrastive loss is introduced to enhance learning from feature and image spaces. In the domain adaptation stage, unsupervised fine-tuning is performed by incorporating an adversarial discriminator on real-world images. The integration of an extended multi-grained contrastive loss and generative adversarial loss enables the adaptation of the student network from synthetic to real-world domains. Extensive experiments on real-world degraded datasets demonstrate the effectiveness of our proposed method. We compare our Uni-Removal framework with state-of-the-art supervised and unsupervised methods, showcasing its promising results in real-world image dehazing, deraining, and deblurring simultaneously.", "url": "https://arxiv.org/abs/2307.05075"}, {"metadata": {"arXiv": "2307.05182", "Date": "Tue, 11 Jul 2023 11:35:40 ", "Title": "Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery", "Authors": ["Long Bai", "Mobarakol Islam", "Hongliang Ren"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["To appear in MICCAI 2023. Code availability: https://github.com/longbai1006/CAT-ViL"]}, "abstract": "Medical students and junior surgeons often rely on senior surgeons and specialists to answer their questions when learning surgery. However, experts are often busy with clinical and academic work, and have little time to give guidance. Meanwhile, existing deep learning (DL)-based surgical Visual Question Answering (VQA) systems can only provide simple answers without the location of the answers. In addition, vision-language (ViL) embedding is still a less explored research in these kinds of tasks. Therefore, a surgical Visual Question Localized-Answering (VQLA) system would be helpful for medical students and junior surgeons to learn and understand from recorded surgical videos. We propose an end-to-end Transformer with Co-Attention gaTed Vision-Language (CAT-ViL) for VQLA in surgical scenarios, which does not require feature extraction through detection models. The CAT-ViL embedding module is designed to fuse heterogeneous features from visual and textual sources. The fused embedding will feed a standard Data-Efficient Image Transformer (DeiT) module, before the parallel classifier and detector for joint prediction. We conduct the experimental validation on public surgical videos from MICCAI EndoVis Challenge 2017 and 2018. The experimental results highlight the superior performance and robustness of our proposed model compared to the state-of-the-art approaches. Ablation studies further prove the outstanding performance of all the proposed components. The proposed method provides a promising solution for surgical scene understanding, and opens up a primary step in the Artificial Intelligence (AI)-based VQLA system for surgical training. Our code is publicly available.", "url": "https://arxiv.org/abs/2307.05182"}, {"metadata": {"arXiv": "2307.05256", "Date": "Sat, 17 Jun 2023 15:32:16 ", "Title": "Towards exploring adversarial learning for anomaly detection in complex driving scenes", "Authors": ["Nour Habib", "Yunsu Cho", "Abhishek Buragohain", "Andreas Rausch"], "Categories": "cs.CV cs.AI", "Comments": ["22"]}, "abstract": "One of the many Autonomous Systems (ASs), such as autonomous driving cars, performs various safety-critical functions. Many of these autonomous systems take advantage of Artificial Intelligence (AI) techniques to perceive their environment. But these perceiving components could not be formally verified, since, the accuracy of such AI-based components has a high dependency on the quality of training data. So Machine learning (ML) based anomaly detection, a technique to identify data that does not belong to the training data could be used as a safety measuring indicator during the development and operational time of such AI-based components. Adversarial learning, a sub-field of machine learning has proven its ability to detect anomalies in images and videos with impressive results on simple data sets. Therefore, in this work, we investigate and provide insight into the performance of such techniques on a highly complex driving scenes dataset called Berkeley DeepDrive.", "url": "https://arxiv.org/abs/2307.05256"}, {"metadata": {"arXiv": "2307.05314", "Date": "Tue, 11 Jul 2023 15:00:11 ", "Title": "Masked Vision and Language Pre-training with Unimodal and Multimodal Contrastive Losses for Medical Visual Question Answering", "Authors": ["Pengfei Li", "Gang Liu", "Jinlong He", "Zixu Zhao and Shenjun Zhong"], "Categories": "cs.CV cs.AI", "Comments": ["accepted by MICCAI2023"]}, "abstract": "Medical visual question answering (VQA) is a challenging task that requires answering clinical questions of a given medical image, by taking consider of both visual and language information. However, due to the small scale of training data for medical VQA, pre-training fine-tuning paradigms have been a commonly used solution to improve model generalization performance. In this paper, we present a novel self-supervised approach that learns unimodal and multimodal feature representations of input images and text using medical image caption datasets, by leveraging both unimodal and multimodal contrastive losses, along with masked language modeling and image text matching as pretraining objectives. The pre-trained model is then transferred to downstream medical VQA tasks. The proposed approach achieves state-of-the-art (SOTA) performance on three publicly available medical VQA datasets with significant accuracy improvements of 2.2%, 14.7%, and 1.7% respectively. Besides, we conduct a comprehensive analysis to validate the effectiveness of different components of the approach and study different pre-training settings. Our codes and models are available at https://github.com/pengfeiliHEU/MUMC.", "url": "https://arxiv.org/abs/2307.05314"}, {"metadata": {"arXiv": "2307.05317", "Date": "Tue, 11 Jul 2023 15:01:42 ", "Title": "Automatic Generation of Semantic Parts for Face Image Synthesis", "Authors": ["Tomaso Fontanini", "Claudio Ferrari", "Massimo Bertozzi", "Andrea Prati"], "Categories": "cs.CV cs.AI", "Comments": ["Preprint", "accepted for publication at ICIAP 2023"]}, "abstract": "Semantic image synthesis (SIS) refers to the problem of generating realistic imagery given a semantic segmentation mask that defines the spatial layout of object classes. Most of the approaches in the literature, other than the quality of the generated images, put effort in finding solutions to increase the generation diversity in terms of style i.e. texture. However, they all neglect a different feature, which is the possibility of manipulating the layout provided by the mask. Currently, the only way to do so is manually by means of graphical users interfaces. In this paper, we describe a network architecture to address the problem of automatically manipulating or generating the shape of object classes in semantic segmentation masks, with specific focus on human faces. Our proposed model allows embedding the mask class-wise into a latent space where each class embedding can be independently edited. Then, a bi-directional LSTM block and a convolutional decoder output a new, locally manipulated mask. We report quantitative and qualitative results on the CelebMask-HQ dataset, which show our model can both faithfully reconstruct and modify a segmentation mask at the class level. Also, we show our model can be put before a SIS generator, opening the way to a fully automatic generation control of both shape and texture. Code available at https://github.com/TFonta/Semantic-VAE.", "url": "https://arxiv.org/abs/2307.05317"}, {"metadata": {"arXiv": "2307.05396", "Date": "Tue, 11 Jul 2023 15:57:15 ", "Title": "Handwritten Text Recognition Using Convolutional Neural Network", "Authors": ["Atman Mishra", "A. Sharath Ram", "Kavyashree C"], "Categories": "cs.CV cs.AI", "Comments": ["6 pages", "15 figures"]}, "abstract": "OCR (Optical Character Recognition) is a technology that offers comprehensive alphanumeric recognition of handwritten and printed characters at electronic speed by merely scanning the document. Recently, the understanding of visual data has been termed Intelligent Character Recognition (ICR). Intelligent Character Recognition (ICR) is the OCR module that can convert scans of handwritten or printed characters into ASCII text. ASCII data is the standard format for data encoding in electronic communication. ASCII assigns standard numeric values to letters, numeral, symbols, white-spaces and other characters. In more technical terms, OCR is the process of using an electronic device to transform 2-Dimensional textual information into machine-encoded text. Anything that contains text both machine written or handwritten can be scanned either through a scanner or just simply a picture of the text is enough for the recognition system to distinguish the text. The goal of this papers is to show the results of a Convolutional Neural Network model which has been trained on National Institute of Science and Technology (NIST) dataset containing over a 100,000 images. The network learns from the features extracted from the images and use it to generate the probability of each class to which the picture belongs to. We have achieved an accuracy of 90.54% with a loss of 2.53%.", "url": "https://arxiv.org/abs/2307.05396"}, {"metadata": {"arXiv": "2307.05409", "Date": "Tue, 11 Jul 2023 16:23:19 ", "Title": "3D detection of roof sections from a single satellite image and application to LOD2-building reconstruction", "Authors": ["Johann Lussange", "Mulin Yu", "Yuliya Tarabalka", "Florent Lafarge"], "Categories": "cs.CV astro-ph.IM cs.AI"}, "abstract": "Reconstructing urban areas in 3D out of satellite raster images has been a long-standing and challenging goal of both academical and industrial research. The rare methods today achieving this objective at a Level Of Details $2$ rely on procedural approaches based on geometry, and need stereo images and/or LIDAR data as input. We here propose a method for urban 3D reconstruction named KIBS(\\textit{Keypoints Inference By Segmentation}), which comprises two novel features: i) a full deep learning approach for the 3D detection of the roof sections, and ii) only one single (non-orthogonal) satellite raster image as model input. This is achieved in two steps: i) by a Mask R-CNN model performing a 2D segmentation of the buildings' roof sections, and after blending these latter segmented pixels within the RGB satellite raster image, ii) by another identical Mask R-CNN model inferring the heights-to-ground of the roof sections' corners via panoptic segmentation, unto full 3D reconstruction of the buildings and city. We demonstrate the potential of the KIBS method by reconstructing different urban areas in a few minutes, with a Jaccard index for the 2D segmentation of individual roof sections of $88.55\\%$ and $75.21\\%$ on our two data sets resp., and a height's mean error of such correctly segmented pixels for the 3D reconstruction of $1.60$ m and $2.06$ m on our two data sets resp., hence within the LOD2 precision range.", "url": "https://arxiv.org/abs/2307.05409"}, {"metadata": {"arXiv": "2307.05447", "Date": "Tue, 11 Jul 2023 17:22:22 ", "Title": "Bio-Inspired Night Image Enhancement Based on Contrast Enhancement and Denoising", "Authors": ["Xinyi Bai", "Steffi Agino Priyanka", "Hsiao-Jung Tung", "and Yuankai Wang"], "Categories": "cs.CV cs.AI", "Comments": ["International Conference on Cognitive Systems and Signal Processing (2016)"], "ACM-class": "I.4.3; I.4.4", "DOI": "10.1007/978-981-10-5230-9_9"}, "abstract": "Due to the low accuracy of object detection and recognition in many intelligent surveillance systems at nighttime, the quality of night images is crucial. Compared with the corresponding daytime image, nighttime image is characterized as low brightness, low contrast and high noise. In this paper, a bio-inspired image enhancement algorithm is proposed to convert a low illuminance image to a brighter and clear one. Different from existing bio-inspired algorithm, the proposed method doesn't use any training sequences, we depend on a novel chain of contrast enhancement and denoising algorithms without using any forms of recursive functions. Our method can largely improve the brightness and contrast of night images, besides, suppress noise. Then we implement on real experiment, and simulation experiment to test our algorithms. Both results show the advantages of proposed algorithm over contrast pair, Meylan and Retinex.", "url": "https://arxiv.org/abs/2307.05447"}, {"metadata": {"arXiv": "2307.05059", "Date": "Tue, 11 Jul 2023 07:08:34 ", "Title": "On Imperfect Recall in Multi-Agent Influence Diagrams", "Authors": ["James Fox", "Matt MacDermott", "Lewis Hammond", "Paul Harrenstein", "Alessandro Abate", "Michael Wooldridge"], "Categories": "cs.GT cs.AI cs.MA", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 201-220", "DOI": "10.4204/EPTCS.379.17"}, "abstract": "Multi-agent influence diagrams (MAIDs) are a popular game-theoretic model based on Bayesian networks. In some settings, MAIDs offer significant advantages over extensive-form game representations. Previous work on MAIDs has assumed that agents employ behavioural policies, which set independent conditional probability distributions over actions for each of their decisions. In settings with imperfect recall, however, a Nash equilibrium in behavioural policies may not exist. We overcome this by showing how to solve MAIDs with forgetful and absent-minded agents using mixed policies and two types of correlated equilibrium. We also analyse the computational complexity of key decision problems in MAIDs, and explore tractable cases. Finally, we describe applications of MAIDs to Markov games and team situations, where imperfect recall is often unavoidable.", "url": "https://arxiv.org/abs/2307.05059"}, {"metadata": {"arXiv": "2307.04895", "Date": "Mon, 10 Jul 2023 20:35:22 ", "Title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer", "Authors": ["Zhun Yang", "Adam Ishay", "Joohyung Lee"], "Categories": "cs.AI cs.LG", "Comments": ["22 pages. The Eleventh International Conference on Learning Representations (ICLR 2023)"]}, "abstract": "Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.", "url": "https://arxiv.org/abs/2307.04895"}, {"metadata": {"arXiv": "2307.05004", "Date": "Tue, 11 Jul 2023 03:53:46 ", "Title": "Control as Probabilistic Inference as an Emergent Communication Mechanism in Multi-Agent Reinforcement Learning", "Authors": ["Tomoaki Nakamura", "Akira Taniguchi", "Tadahiro Taniguchi"], "Categories": "cs.AI cs.LG cs.MA"}, "abstract": "This paper proposes a generative probabilistic model integrating emergent communication and multi-agent reinforcement learning. The agents plan their actions by probabilistic inference, called control as inference, and communicate using messages that are latent variables and estimated based on the planned actions. Through these messages, each agent can send information about its actions and know information about the actions of another agent. Therefore, the agents change their actions according to the estimated messages to achieve cooperative tasks. This inference of messages can be considered as communication, and this procedure can be formulated by the Metropolis-Hasting naming game. Through experiments in the grid world environment, we show that the proposed PGM can infer meaningful messages to achieve the cooperative task.", "url": "https://arxiv.org/abs/2307.05004"}, {"metadata": {"arXiv": "2307.05068", "Date": "Tue, 11 Jul 2023 07:13:29 ", "Title": "A Theory of Bounded Inductive Rationality", "Authors": ["Caspar Oesterheld (Carnegie Mellon University)", "Abram Demski (Machine Intelligence Research Institute)", "Vincent Conitzer (Carnegie Mellon University)"], "Categories": "cs.AI cs.GT cs.LG", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "ACM-class": "I.2", "Journal-ref": "EPTCS 379, 2023, pp. 421-440", "DOI": "10.4204/EPTCS.379.33"}, "abstract": "The dominant theories of rational choice assume logical omniscience. That is, they assume that when facing a decision problem, an agent can perform all relevant computations and determine the truth value of all relevant logical/mathematical claims. This assumption is unrealistic when, for example, we offer bets on remote digits of pi or when an agent faces a computationally intractable planning problem. Furthermore, the assumption of logical omniscience creates contradictions in cases where the environment can contain descriptions of the agent itself. Importantly, strategic interactions as studied in game theory are decision problems in which a rational agent is predicted by its environment (the other players). In this paper, we develop a theory of rational decision making that does not assume logical omniscience. We consider agents who repeatedly face decision problems (including ones like betting on digits of pi or games against other agents). The main contribution of this paper is to provide a sensible theory of rationality for such agents. Roughly, we require that a boundedly rational inductive agent tests each efficiently computable hypothesis infinitely often and follows those hypotheses that keep their promises of high rewards. We then prove that agents that are rational in this sense have other desirable properties. For example, they learn to value random and pseudo-random lotteries at their expected reward. Finally, we consider strategic interactions between different agents and prove a folk theorem for what strategies bounded rational inductive agents can converge to.", "url": "https://arxiv.org/abs/2307.05068"}, {"metadata": {"arXiv": "2307.05209", "Date": "Tue, 11 Jul 2023 12:28:05 ", "Title": "Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning", "Authors": ["Guy Azran", "Mohamad H. Danesh", "Stefano V. Albrecht", "Sarah Keren"], "Categories": "cs.AI cs.LG", "Comments": ["IJCAI Workshop on Planning and Reinforcement Learning", "2023"]}, "abstract": "Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.", "url": "https://arxiv.org/abs/2307.05209"}, {"metadata": {"arXiv": "2307.05330", "Date": "Sat, 08 Jul 2023 20:17:24 ", "Title": "The Value of Chess Squares", "Authors": ["Aditya Gupta and Shiva Maharaj and Nicholas Polson and Vadim Sokolov"], "Categories": "cs.AI cs.LG"}, "abstract": "Valuing chess squares and determining the placement of pieces on the board are the main objectives of our study. With the emergence of chess AI, it has become possible to accurately assess the worth of positions in a game of chess. The conventional approach assigns fixed values to pieces $(\\symking=\\infty, \\symqueen=9, \\symrook=5, \\symbishop=3, \\symknight=3, \\sympawn=1)$. We enhance this analysis by introducing marginal valuations for both pieces and squares. We demonstrate our method by examining the positioning of Knights and Bishops, and also provide valuable insights into the valuation of pawns. Notably, Nimzowitsch was among the pioneers in advocating for the significance of Pawn structure and valuation. Finally, we conclude by suggesting potential avenues for future research.", "url": "https://arxiv.org/abs/2307.05330"}, {"metadata": {"arXiv": "2307.05017", "Date": "Tue, 11 Jul 2023 05:33:46 ", "Title": "Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification", "Authors": ["Yi Liao", "Yongsheng Gao", "Weichuan Zhang"], "Categories": "cs.CV cs.AI cs.LG cs.PF", "Comments": ["14 pages"]}, "abstract": "Decisions made by convolutional neural networks(CNN) can be understood and explained by visualizing discriminative regions on images. To this end, Class Activation Map (CAM) based methods were proposed as powerful interpretation tools, making the prediction of deep learning models more explainable, transparent, and trustworthy. However, all the CAM-based methods (e.g., CAM, Grad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with fully-connected (FC) layers as a classifier. It is worth noting that many deep learning models classify images without FC layers, e.g., few-shot learning image classification, contrastive learning image classification, and image retrieval tasks. In this work, a post-hoc interpretation tool named feature activation map (FAM) is proposed, which can interpret deep learning models without FC layers as a classifier. In the proposed FAM algorithm, the channel-wise contribution weights are derived from the similarity scores between two image embeddings. The activation maps are linearly combined with the corresponding normalized contribution weights, forming the explanation map for visualization. The quantitative and qualitative experiments conducted on ten deep learning models for few-shot image classification, contrastive learning image classification and image retrieval tasks demonstrate the effectiveness of the proposed FAM algorithm.", "url": "https://arxiv.org/abs/2307.05017"}, {"metadata": {"arXiv": "2307.05134", "Date": "Tue, 11 Jul 2023 09:23:05 ", "Title": "TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation", "Authors": ["Paul Grimal", "Herv\\'e Le Borgne", "Olivier Ferret", "Julien Tourille"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "The progress in the generation of synthetic images has made it crucial to assess their quality. While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered. In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images. It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color. We conducted a study on several recent T2I models about various aspects. An additional interesting result we obtained with our approach is that image quality can vary drastically depending on the latent noise used as a seed for the images. We also quantify the influence of the number of concepts in the prompt, their order as well as their (color) attributes. Finally, our method allows us to identify some latent seeds that produce better images than others, opening novel directions of research on this understudied topic.", "url": "https://arxiv.org/abs/2307.05134"}, {"metadata": {"arXiv": "2307.04849", "Date": "Mon, 10 Jul 2023 18:40:25 ", "Title": "SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees", "Authors": ["Aleksei Sorokin", "Xinran Zhu", "Eric Hans Lee", "Bolong Cheng"], "Categories": "cs.LG cs.AI cs.MS", "Journal-ref": "Knowledge-Based Systems Volume 273, 3 August 2023, 110604", "DOI": "10.1016/j.knosys.2023.110604"}, "abstract": "Gradient boosted trees (GBTs) are ubiquitous models used by researchers, machine learning (ML) practitioners, and data scientists because of their robust performance, interpretable behavior, and ease-of-use. One critical challenge in training GBTs is the tuning of their hyperparameters. In practice, selecting these hyperparameters is often done manually. Recently, the ML community has advocated for tuning hyperparameters through black-box optimization and developed state-of-the-art systems to do so. However, applying such systems to tune GBTs suffers from two drawbacks. First, these systems are not \\textit{model-aware}, rather they are designed to apply to a \\textit{generic} model; this leaves significant optimization performance on the table. Second, using these systems requires \\textit{domain knowledge} such as the choice of hyperparameter search space, which is an antithesis to the automatic experimentation that black-box optimization aims to provide. In this paper, we present SigOpt Mulch, a model-aware hyperparameter tuning system specifically designed for automated tuning of GBTs that provides two improvements over existing systems. First, Mulch leverages powerful techniques in metalearning and multifidelity optimization to perform model-aware hyperparameter optimization. Second, it automates the process of learning performant hyperparameters by making intelligent decisions about the optimization search space, thus reducing the need for user domain knowledge. These innovations allow Mulch to identify good GBT hyperparameters far more efficiently -- and in a more seamless and user-friendly way -- than existing black-box hyperparameter tuning systems.", "url": "https://arxiv.org/abs/2307.04849"}, {"metadata": {"arXiv": "2307.04850", "Date": "Mon, 10 Jul 2023 18:42:45 ", "Title": "SHAP@k:Efficient and Probably Approximately Correct (PAC) Identification of Top-k Features", "Authors": ["Sanjay Kariyappa", "Leonidas Tsepenekas", "Freddy L\\'ecu\\'e", "Daniele Magazzeni"], "Categories": "cs.LG cs.AI"}, "abstract": "The SHAP framework provides a principled method to explain the predictions of a model by computing feature importance. Motivated by applications in finance, we introduce the Top-k Identification Problem (TkIP), where the objective is to identify the k features with the highest SHAP values. While any method to compute SHAP values with uncertainty estimates (such as KernelSHAP and SamplingSHAP) can be trivially adapted to solve TkIP, doing so is highly sample inefficient. The goal of our work is to improve the sample efficiency of existing methods in the context of solving TkIP. Our key insight is that TkIP can be framed as an Explore-m problem--a well-studied problem related to multi-armed bandits (MAB). This connection enables us to improve sample efficiency by leveraging two techniques from the MAB literature: (1) a better stopping-condition (to stop sampling) that identifies when PAC (Probably Approximately Correct) guarantees have been met and (2) a greedy sampling scheme that judiciously allocates samples between different features. By adopting these methods we develop KernelSHAP@k and SamplingSHAP@k to efficiently solve TkIP, offering an average improvement of $5\\times$ in sample-efficiency and runtime across most common credit related datasets.", "url": "https://arxiv.org/abs/2307.04850"}, {"metadata": {"arXiv": "2307.04869", "Date": "Mon, 10 Jul 2023 19:32:53 ", "Title": "Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning", "Authors": ["Gaurav Bagwe and Xiaoyong Yuan and Miao Pan and Lan Zhang"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted by FL-ICML 2023"]}, "abstract": "Federated continual learning (FCL) learns incremental tasks over time from confidential datasets distributed across clients. This paper focuses on rehearsal-free FCL, which has severe forgetting issues when learning new tasks due to the lack of access to historical task data. To address this issue, we propose Fed-CPrompt based on prompt learning techniques to obtain task-specific prompts in a communication-efficient way. Fed-CPrompt introduces two key components, asynchronous prompt learning, and contrastive continual loss, to handle asynchronous task arrival and heterogeneous data distributions in FCL, respectively. Extensive experiments demonstrate the effectiveness of Fed-CPrompt in achieving SOTA rehearsal-free FCL performance.", "url": "https://arxiv.org/abs/2307.04869"}, {"metadata": {"arXiv": "2307.04887", "Date": "Mon, 10 Jul 2023 20:20:20 ", "Title": "Measuring and Mitigating Interference in Reinforcement Learning", "Authors": ["Vincent Liu", "Han Wang", "Ruo Yu Tao", "Khurram Javed", "Adam White", "Martha White"], "Categories": "cs.LG cs.AI", "Comments": ["Published at Conference on Lifelong Learning Agents (CoLLAs) 2023"]}, "abstract": "Catastrophic interference is common in many network-based learning systems, and many proposals exist for mitigating it. Before overcoming interference we must understand it better. In this work, we provide a definition and novel measure of interference for value-based reinforcement learning methods such as Fitted Q-Iteration and DQN. We systematically evaluate our measure of interference, showing that it correlates with instability in control performance, across a variety of network architectures. Our new interference measure allows us to ask novel scientific questions about commonly used deep learning architectures and study learning algorithms which mitigate interference. Lastly, we outline a class of algorithms which we call online-aware that are designed to mitigate interference, and show they do reduce interference according to our measure and that they improve stability and performance in several classic control environments.", "url": "https://arxiv.org/abs/2307.04887"}, {"metadata": {"arXiv": "2307.04893", "Date": "Mon, 10 Jul 2023 20:31:23 ", "Title": "Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies", "Authors": ["Rubens O. Moraes", "David S. Aleixo", "Lucas N. Ferreira", "Levi H. S. Lelis"], "Categories": "cs.LG cs.AI", "Comments": ["International Joint Conference on Artificial Intelligence (IJCAI) 2023"]}, "abstract": "This paper introduces Local Learner (2L), an algorithm for providing a set of reference strategies to guide the search for programmatic strategies in two-player zero-sum games. Previous learning algorithms, such as Iterated Best Response (IBR), Fictitious Play (FP), and Double-Oracle (DO), can be computationally expensive or miss important information for guiding search algorithms. 2L actively selects a set of reference strategies to improve the search signal. We empirically demonstrate the advantages of our approach while guiding a local search algorithm for synthesizing strategies in three games, including MicroRTS, a challenging real-time strategy game. Results show that 2L learns reference strategies that provide a stronger search signal than IBR, FP, and DO. We also simulate a tournament of MicroRTS, where a synthesizer using 2L outperformed the winners of the two latest MicroRTS competitions, which were programmatic strategies written by human programmers.", "url": "https://arxiv.org/abs/2307.04893"}, {"metadata": {"arXiv": "2307.04957", "Date": "Tue, 11 Jul 2023 01:20:09 ", "Title": "Reinforcement Learning with Non-Cumulative Objective", "Authors": ["Wei Cui and Wei Yu"], "Categories": "cs.LG cs.AI cs.NI math.OC stat.ML", "Comments": ["13 pages", "6 figures. To appear in IEEE Transactions on Machine Learning in Communications and Networking (TMLCN)"]}, "abstract": "In reinforcement learning, the objective is almost always defined as a \\emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision process under which the globally optimal convergence of the generalized Bellman updates can be guaranteed. We demonstrate the idea experimentally with the bottleneck objective, i.e., the objectives determined by the minimum reward along the process, on classical optimal control and reinforcement learning tasks, as well as on two network routing problems on maximizing the flow rates.", "url": "https://arxiv.org/abs/2307.04957"}, {"metadata": {"arXiv": "2307.04962", "Date": "Tue, 11 Jul 2023 01:52:08 ", "Title": "Intrinsically motivated graph exploration using network theories of human curiosity", "Authors": ["Shubhankar P. Patankar", "Mathieu Ouellet", "Juan Cervino", "Alejandro Ribeiro", "Kieran A. Murphy and Dani S. Bassett"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["14 pages", "5 figures in main text", "and 15 pages", "8 figures in supplement"]}, "abstract": "Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by the visited nodes in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to larger environments and to longer exploratory walks than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bear particular relevance for recommender systems. We demonstrate that curiosity-based recommendations are more predictive of human behavior than PageRank centrality for several real-world graph datasets, including MovieLens, Amazon Books, and Wikispeedia.", "url": "https://arxiv.org/abs/2307.04962"}, {"metadata": {"arXiv": "2307.04990", "Date": "Tue, 11 Jul 2023 03:02:44 ", "Title": "Monotone deep Boltzmann machines", "Authors": ["Zhili Feng", "Ezra Winston", "J. Zico Kolter"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \\emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular choice of activation results in a fixed-point iteration that gives a variational mean-field solution. While this approach is still largely conceptual, it is the first architecture that allows for efficient approximate inference in fully-general weight structures for DBMs. We apply this approach to simple deep convolutional Boltzmann architectures and demonstrate that it allows for tasks such as the joint completion and classification of images, within a single deep probabilistic setting, while avoiding the pitfalls of mean-field inference in traditional RBMs.", "url": "https://arxiv.org/abs/2307.04990"}, {"metadata": {"arXiv": "2307.04998", "Date": "Tue, 11 Jul 2023 03:32:20 ", "Title": "Selective Sampling and Imitation Learning via Online Regression", "Authors": ["Ayush Sekhari", "Karthik Sridharan", "Wen Sun", "Runzhe Wu"], "Categories": "cs.LG cs.AI math.ST stat.ML stat.TH"}, "abstract": "We consider the problem of Imitation Learning (IL) by actively querying noisy expert for feedback. While imitation learning has been empirically successful, much of prior work assumes access to noiseless expert feedback which is not practical in many applications. In fact, when one only has access to noisy expert feedback, algorithms that rely on purely offline data (non-interactive IL) can be shown to need a prohibitively large number of samples to be successful. In contrast, in this work, we provide an interactive algorithm for IL that uses selective sampling to actively query the noisy expert for feedback. Our contributions are twofold: First, we provide a new selective sampling algorithm that works with general function classes and multiple actions, and obtains the best-known bounds for the regret and the number of queries. Next, we extend this analysis to the problem of IL with noisy expert feedback and provide a new IL algorithm that makes limited queries. Our algorithm for selective sampling leverages function approximation, and relies on an online regression oracle w.r.t.~the given model class to predict actions, and to decide whether to query the expert for its label. On the theoretical side, the regret bound of our algorithm is upper bounded by the regret of the online regression oracle, while the query complexity additionally depends on the eluder dimension of the model class. We complement this with a lower bound that demonstrates that our results are tight. We extend our selective sampling algorithm for IL with general function approximation and provide bounds on both the regret and the number of queries made to the noisy expert. A key novelty here is that our regret and query complexity bounds only depend on the number of times the optimal policy (and not the noisy expert, or the learner) go to states that have a small margin.", "url": "https://arxiv.org/abs/2307.04998"}, {"metadata": {"arXiv": "2307.05025", "Date": "Tue, 11 Jul 2023 05:58:20 ", "Title": "Unleashing the Potential of Regularization Strategies in Learning with Noisy Labels", "Authors": ["Hui Kang", "Sheng Liu", "Huaxi Huang", "Jun Yu", "Bo Han", "Dadong Wang", "Tongliang Liu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In recent years, research on learning with noisy labels has focused on devising novel algorithms that can achieve robustness to noisy training labels while generalizing to clean data. These algorithms often incorporate sophisticated techniques, such as noise modeling, label correction, and co-training. In this study, we demonstrate that a simple baseline using cross-entropy loss, combined with widely used regularization strategies like learning rate decay, model weights average, and data augmentations, can outperform state-of-the-art methods. Our findings suggest that employing a combination of regularization strategies can be more effective than intricate algorithms in tackling the challenges of learning with noisy labels. While some of these regularization strategies have been utilized in previous noisy label learning research, their full potential has not been thoroughly explored. Our results encourage a reevaluation of benchmarks for learning with noisy labels and prompt reconsideration of the role of specialized learning algorithms designed for training with noisy labels.", "url": "https://arxiv.org/abs/2307.05025"}, {"metadata": {"arXiv": "2307.05104", "Date": "Tue, 11 Jul 2023 08:26:08 ", "Title": "A Deep Dive into Perturbations as Evaluation Technique for Time Series XAI", "Authors": ["Udo Schlegel", "Daniel A. Keim"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "2 pages references", "5 figures", "3 tables", "submitted and accepted at xAI 2023"]}, "abstract": "Explainable Artificial Intelligence (XAI) has gained significant attention recently as the demand for transparency and interpretability of machine learning models has increased. In particular, XAI for time series data has become increasingly important in finance, healthcare, and climate science. However, evaluating the quality of explanations, such as attributions provided by XAI techniques, remains challenging. This paper provides an in-depth analysis of using perturbations to evaluate attributions extracted from time series models. A perturbation analysis involves systematically modifying the input data and evaluating the impact on the attributions generated by the XAI method. We apply this approach to several state-of-the-art XAI techniques and evaluate their performance on three time series classification datasets. Our results demonstrate that the perturbation analysis approach can effectively evaluate the quality of attributions and provide insights into the strengths and limitations of XAI techniques. Such an approach can guide the selection of XAI methods for time series data, e.g., focusing on return time rather than precision, and facilitate the development of more reliable and interpretable machine learning models for time series analysis.", "url": "https://arxiv.org/abs/2307.05104"}, {"metadata": {"arXiv": "2307.05213", "Date": "Tue, 11 Jul 2023 12:32:13 ", "Title": "Score Function Gradient Estimation to Widen the Applicability of Decision-Focused Learning", "Authors": ["Mattia Silvestri", "Senne Berden", "Jayanta Mandi", "Ali \\.Irfan Mahmuto\\u{g}ullar{\\i}", "Maxime Mulamba", "Allegra De Filippo", "Tias Guns", "Michele Lombardi"], "Categories": "cs.LG cs.AI"}, "abstract": "Many real-world optimization problems contain unknown parameters that must be predicted prior to solving. To train the predictive machine learning (ML) models involved, the commonly adopted approach focuses on maximizing predictive accuracy. However, this approach does not always lead to the minimization of the downstream task loss. Decision-focused learning (DFL) is a recently proposed paradigm whose goal is to train the ML model by directly minimizing the task loss. However, state-of-the-art DFL methods are limited by the assumptions they make about the structure of the optimization problem (e.g., that the problem is linear) and by the fact that can only predict parameters that appear in the objective function. In this work, we address these limitations by instead predicting \\textit{distributions} over parameters and adopting score function gradient estimation (SFGE) to compute decision-focused updates to the predictive model, thereby widening the applicability of DFL. Our experiments show that by using SFGE we can: (1) deal with predictions that occur both in the objective function and in the constraints; and (2) effectively tackle two-stage stochastic optimization problems.", "url": "https://arxiv.org/abs/2307.05213"}, {"metadata": {"arXiv": "2307.05284", "Date": "Tue, 11 Jul 2023 14:25:10 ", "Title": "On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets", "Authors": ["Jiashuo Liu", "Tianyu Wang", "Peng Cui", "Hongseok Namkoong"], "Categories": "cs.LG cs.AI", "Comments": ["41 pages"]}, "abstract": "Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithmic and data-based interventions. Our testbed highlights the importance of future research that builds an understanding of how distributions differ.", "url": "https://arxiv.org/abs/2307.05284"}, {"metadata": {"arXiv": "2307.05358", "Date": "Tue, 11 Jul 2023 15:45:03 ", "Title": "Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators", "Authors": ["Sikai Bai", "Shuaicheng Li", "Weiming Zhuang", "Kunlin Yang", "Jun Hou", "Shuai Yi", "Shuai Zhang", "Junyu Gao", "Jie Zhang", "Song Guo"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning has become a popular method to learn from decentralized heterogeneous data. Federated semi-supervised learning (FSSL) emerges to train models from a small fraction of labeled data due to label scarcity on decentralized clients. Existing FSSL methods assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client. This work studies a more practical and challenging scenario of FSSL, where data distribution is different not only across clients but also within a client between labeled and unlabeled data. To address this challenge, we propose a novel FSSL framework with dual regulators, FedDure.} FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of the local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored for unlabeled instances in each client. We further formulate the client model training as bi-level optimization that adaptively optimizes the model in the client with two regulators. Theoretically, we show the convergence guarantee of the dual regulators. Empirically, we demonstrate that FedDure is superior to the existing methods across a wide range of settings, notably by more than 11% on CIFAR-10 and CINIC-10 datasets.", "url": "https://arxiv.org/abs/2307.05358"}, {"metadata": {"arXiv": "2307.05399", "Date": "Tue, 11 Jul 2023 16:01:44 ", "Title": "Domain-Agnostic Neural Architecture for Class Incremental Continual Learning in Document Processing Platform", "Authors": ["Mateusz W\\'ojcik", "Witold Ko\\'sciukiewicz", "Mateusz Baran", "Tomasz Kajdanowicz", "Adam Gonczarek"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2211.14963"]}, "abstract": "Production deployments in complex systems require ML architectures to be highly efficient and usable against multiple tasks. Particularly demanding are classification problems in which data arrives in a streaming fashion and each class is presented separately. Recent methods with stochastic gradient learning have been shown to struggle in such setups or have limitations like memory buffers, and being restricted to specific domains that disable its usage in real-world scenarios. For this reason, we present a fully differentiable architecture based on the Mixture of Experts model, that enables the training of high-performance classifiers when examples from each class are presented separately. We conducted exhaustive experiments that proved its applicability in various domains and ability to learn online in production environments. The proposed technique achieves SOTA results without a memory buffer and clearly outperforms the reference methods.", "url": "https://arxiv.org/abs/2307.05399"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

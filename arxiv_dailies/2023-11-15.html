<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.08141", "Date": "Tue, 14 Nov 2023 13:12:47 ", "Title": "GMTR: Graph Matching Transformers", "Authors": ["Jinpei Guo", "Shaofeng Zhang", "Runzhong Wang", "Chang Liu", "Junchi Yan"], "Categories": "cs.CV cs.LG", "Comments": ["Preprint"]}, "abstract": "Vision transformers (ViTs) have recently been used for visual matching beyond object detection and segmentation. However, the original grid dividing strategy of ViTs neglects the spatial information of the keypoints, limiting the sensitivity to local information. Therefore, we propose \\textbf{QueryTrans} (Query Transformer), which adopts a cross-attention module and keypoints-based center crop strategy for better spatial information extraction. We further integrate the graph attention module and devise a transformer-based graph matching approach \\textbf{GMTR} (Graph Matching TRansformers) whereby the combinatorial nature of GM is addressed by a graph transformer neural GM solver. On standard GM benchmarks, GMTR shows competitive performance against the SOTA frameworks. Specifically, on Pascal VOC, GMTR achieves $\\mathbf{83.6\\%}$ accuracy, $\\mathbf{0.9\\%}$ higher than the SOTA framework. On Spair-71k, GMTR shows great potential and outperforms most of the previous works. Meanwhile, on Pascal VOC, QueryTrans improves the accuracy of NGMv2 from $80.1\\%$ to $\\mathbf{83.3\\%}$, and BBGM from $79.0\\%$ to $\\mathbf{84.5\\%}$. On Spair-71k, QueryTrans improves NGMv2 from $80.6\\%$ to $\\mathbf{82.5\\%}$, and BBGM from $82.1\\%$ to $\\mathbf{83.9\\%}$. Source code will be made publicly available.", "url": "https://arxiv.org/abs/2311.08141"}, {"metadata": {"arXiv": "2311.07614", "Date": "Sun, 12 Nov 2023 07:09:11 ", "Title": "Application of a Dense Fusion Attention Network in Fault Diagnosis of Centrifugal Fan", "Authors": ["Ruijun Wang", "Yuan Liu", "Zhixia Fan", "Xiaogang Xu", "Huijie Wang"], "Categories": "cs.LG"}, "abstract": "Although the deep learning recognition model has been widely used in the condition monitoring of rotating machinery. However, it is still a challenge to understand the correspondence between the structure and function of the model and the diagnosis process. Therefore, this paper discusses embedding distributed attention modules into dense connections instead of traditional dense cascading operations. It not only decouples the influence of space and channel on fault feature adaptive recalibration feature weights, but also forms a fusion attention function. The proposed dense fusion focuses on the visualization of the network diagnosis process, which increases the interpretability of model diagnosis. How to continuously and effectively integrate different functions to enhance the ability to extract fault features and the ability to resist noise is answered. Centrifugal fan fault data is used to verify this network. Experimental results show that the network has stronger diagnostic performance than other advanced fault diagnostic models.", "url": "https://arxiv.org/abs/2311.07614"}, {"metadata": {"arXiv": "2311.07625", "Date": "Mon, 13 Nov 2023 08:18:44 ", "Title": "Activity Sparsity Complements Weight Sparsity for Efficient RNN Inference", "Authors": ["Rishav Mukherji", "Mark Sch\\\"one", "Khaleelulla Khan Nazeer", "Christian Mayr", "Anand Subramoney"], "Categories": "cs.LG", "Comments": ["Accepted to the First MLNCP Workshop @ NeurIPS 2023"]}, "abstract": "Artificial neural networks open up unprecedented machine learning capabilities at the cost of ever growing computational requirements. Sparsifying the parameters, often achieved through weight pruning, has been identified as a powerful technique to compress the number of model parameters and reduce the computational operations of neural networks. Yet, sparse activations, while omnipresent in both biological neural networks and deep learning systems, have not been fully utilized as a compression technique in deep learning. Moreover, the interaction between sparse activations and weight pruning is not fully understood. In this work, we demonstrate that activity sparsity can compose multiplicatively with parameter sparsity in a recurrent neural network model based on the GRU that is designed to be activity sparse. We achieve up to $20\\times$ reduction of computation while maintaining perplexities below $60$ on the Penn Treebank language modeling task. This magnitude of reduction has not been achieved previously with solely sparsely connected LSTMs, and the language modeling performance of our model has not been achieved previously with any sparsely activated recurrent neural networks or spiking neural networks. Neuromorphic computing devices are especially good at taking advantage of the dynamic activity sparsity, and our results provide strong evidence that making deep learning models activity sparse and porting them to neuromorphic devices can be a viable strategy that does not compromise on task performance. Our results also drive further convergence of methods from deep learning and neuromorphic computing for efficient machine learning.", "url": "https://arxiv.org/abs/2311.07625"}, {"metadata": {"arXiv": "2311.07627", "Date": "Mon, 13 Nov 2023 08:42:17 ", "Title": "A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph Learning", "Authors": ["Thomas Bonald (IP Paris)", "Nathan de Lara (IP Paris)"], "Categories": "cs.LG cs.SI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2008.11944"], "Journal-ref": "Complex Networks, 2023, Menton, France"}, "abstract": "The task of semi-supervised classification aims at assigning labels to all nodes of a graph based on the labels known for a few nodes, called the seeds. One of the most popular algorithms relies on the principle of heat diffusion, where the labels of the seeds are spread by thermoconductance and the temperature of each node at equilibrium is used as a score function for each label. In this paper, we prove that this algorithm is not consistent unless the temperatures of the nodes at equilibrium are centered before scoring. This crucial step does not only make the algorithm provably consistent on a block model but brings significant performance gains on real graphs.", "url": "https://arxiv.org/abs/2311.07627"}, {"metadata": {"arXiv": "2311.07693", "Date": "Mon, 13 Nov 2023 19:22:37 ", "Title": "Matching aggregate posteriors in the variational autoencoder", "Authors": ["Surojit Saha", "Sarang Joshi", "and Ross Whitaker"], "Categories": "cs.LG"}, "abstract": "The variational autoencoder (VAE) is a well-studied, deep, latent-variable model (DLVM) that efficiently optimizes the variational lower bound of the log marginal data likelihood and has a strong theoretical foundation. However, the VAE's known failure to match the aggregate posterior often results in \\emph{pockets/holes} in the latent distribution (i.e., a failure to match the prior) and/or \\emph{posterior collapse}, which is associated with a loss of information in the latent space. This paper addresses these shortcomings in VAEs by reformulating the objective function associated with VAEs in order to match the aggregate/marginal posterior distribution to the prior. We use kernel density estimate (KDE) to model the aggregate posterior in high dimensions. The proposed method is named the \\emph{aggregate variational autoencoder} (AVAE) and is built on the theoretical framework of the VAE. Empirical evaluation of the proposed method on multiple benchmark data sets demonstrates the effectiveness of the AVAE relative to state-of-the-art (SOTA) methods.", "url": "https://arxiv.org/abs/2311.07693"}, {"metadata": {"arXiv": "2311.07744", "Date": "Mon, 13 Nov 2023 20:54:52 ", "Title": "Dynamic Local Attention with Hierarchical Patching for Irregular Clinical Time Series", "Authors": ["Xingyu Chen and Xiaochen Zheng and Amina Mollaysa and Manuel Sch\\\"urch and Ahmed Allam and Michael Krauthammer"], "Categories": "cs.LG cs.CY", "Comments": ["Findings of Machine Learning for Health (ML4H) 2023"]}, "abstract": "Irregular multivariate time series data is prevalent in the clinical and healthcare domains. It is characterized by time-wise and feature-wise irregularities, making it challenging for machine learning methods to work with. To solve this, we introduce a new model architecture composed of two modules: (1) DLA, a Dynamic Local Attention mechanism that uses learnable queries and feature-specific local windows when computing the self-attention operation. This results in aggregating irregular time steps raw input within each window to a harmonized regular latent space representation while taking into account the different features' sampling rates. (2) A hierarchical MLP mixer that processes the output of DLA through multi-scale patching to leverage information at various scales for the downstream tasks. Our approach outperforms state-of-the-art methods on three real-world datasets, including the latest clinical MIMIC IV dataset.", "url": "https://arxiv.org/abs/2311.07744"}, {"metadata": {"arXiv": "2311.07765", "Date": "Mon, 13 Nov 2023 21:31:07 ", "Title": "FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based Human Activity Recognition", "Authors": ["Egemen \\.I\\c{s}g\\\"uder and \\\"Ozlem Durmaz \\.Incel"], "Categories": "cs.LG cs.CV", "Comments": ["Subimtted to Asian Conference in Machine Learning (ACML) 2023", "Pattern Recognition in Health Analysis Workshop", "7 pages", "3 figures"]}, "abstract": "Motion sensors integrated into wearable and mobile devices provide valuable information about the device users. Machine learning and, recently, deep learning techniques have been used to characterize sensor data. Mostly, a single task, such as recognition of activities, is targeted, and the data is processed centrally at a server or in a cloud environment. However, the same sensor data can be utilized for multiple tasks and distributed machine-learning techniques can be used without the requirement of the transmission of data to a centre. This paper explores Federated Transfer Learning in a Multi-Task manner for both sensor-based human activity recognition and device position identification tasks. The OpenHAR framework is used to train the models, which contains ten smaller datasets. The aim is to obtain model(s) applicable for both tasks in different datasets, which may include only some label types. Multiple experiments are carried in the Flower federated learning environment using the DeepConvLSTM architecture. Results are presented for federated and centralized versions under different parameters and restrictions. By utilizing transfer learning and training a task-specific and personalized federated model, we obtained a similar accuracy with training each client individually and higher accuracy than a fully centralized approach.", "url": "https://arxiv.org/abs/2311.07765"}, {"metadata": {"arXiv": "2311.07784", "Date": "Mon, 13 Nov 2023 22:21:27 ", "Title": "A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks", "Authors": ["Sara Babakniya", "Zalan Fabian", "Chaoyang He", "Mahdi Soltanolkotabi", "Salman Avestimehr"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted in NeurIPS 2023. arXiv admin note: text overlap with arXiv:2307.00497"]}, "abstract": "Deep learning models often suffer from forgetting previously learned information when trained on new data. This problem is exacerbated in federated learning (FL), where the data is distributed and can change independently for each user. Many solutions are proposed to resolve this catastrophic forgetting in a centralized setting. However, they do not apply directly to FL because of its unique complexities, such as privacy concerns and resource limitations. To overcome these challenges, this paper presents a framework for \\textbf{federated class incremental learning} that utilizes a generative model to synthesize samples from past distributions. This data can be later exploited alongside the training data to mitigate catastrophic forgetting. To preserve privacy, the generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Moreover, our solution does not demand the users to store old data or models, which gives them the freedom to join/leave the training at any time. Additionally, we introduce SuperImageNet, a new regrouping of the ImageNet dataset specifically tailored for federated continual learning. We demonstrate significant improvements compared to existing baselines through extensive experiments on multiple datasets.", "url": "https://arxiv.org/abs/2311.07784"}, {"metadata": {"arXiv": "2311.07788", "Date": "Mon, 13 Nov 2023 22:46:43 ", "Title": "CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion", "Authors": ["Anders Vestergaard N{\\o}rskov", "Alexander Neergaard Zahid and Morten M{\\o}rup"], "Categories": "cs.LG cs.CV eess.SP stat.ML", "Comments": ["Accepted for publication at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Electroencephalography (EEG) is a prominent non-invasive neuroimaging technique providing insights into brain function. Unfortunately, EEG data exhibit a high degree of noise and variability across subjects hampering generalizable signal extraction. Therefore, a key aim in EEG analysis is to extract the underlying neural activation (content) as well as to account for the individual subject variability (style). We hypothesize that the ability to convert EEG signals between tasks and subjects requires the extraction of latent representations accounting for content and style. Inspired by recent advancements in voice conversion technologies, we propose a novel contrastive split-latent permutation autoencoder (CSLP-AE) framework that directly optimizes for EEG conversion. Importantly, the latent representations are guided using contrastive learning to promote the latent splits to explicitly represent subject (style) and task (content). We contrast CSLP-AE to conventional supervised, unsupervised (AE), and self-supervised (contrastive learning) training and find that the proposed approach provides favorable generalizable characterizations of subject and task. Importantly, the procedure also enables zero-shot conversion between unseen subjects. While the present work only considers conversion of EEG, the proposed CSLP-AE provides a general framework for signal conversion and extraction of content (task activation) and style (subject variability) components of general interest for the modeling and analysis of biological signals.", "url": "https://arxiv.org/abs/2311.07788"}, {"metadata": {"arXiv": "2311.07790", "Date": "Mon, 13 Nov 2023 22:55:56 ", "Title": "Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning", "Authors": ["Paula Chen", "Tingwei Meng", "Zongren Zou", "J\\'er\\^ome Darbon", "George Em Karniadakis"], "Categories": "cs.LG math.OC"}, "abstract": "We address two major challenges in scientific machine learning (SciML): interpretability and computational efficiency. We increase the interpretability of certain learning processes by establishing a new theoretical connection between optimization problems arising from SciML and a generalized Hopf formula, which represents the viscosity solution to a Hamilton-Jacobi partial differential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show that when we solve certain regularized learning problems with integral-type losses, we actually solve an optimal control problem and its associated HJ PDE with time-dependent Hamiltonian. This connection allows us to reinterpret incremental updates to learned models as the evolution of an associated HJ PDE and optimal control problem in time, where all of the previous information is intrinsically encoded in the solution to the HJ PDE. As a result, existing HJ PDE solvers and optimal control algorithms can be reused to design new efficient training approaches for SciML that naturally coincide with the continual learning framework, while avoiding catastrophic forgetting. As a first exploration of this connection, we consider the special case of linear regression and leverage our connection to develop a new Riccati-based methodology for solving these learning problems that is amenable to continual learning applications. We also provide some corresponding numerical examples that demonstrate the potential computational and memory advantages our Riccati-based approach can provide.", "url": "https://arxiv.org/abs/2311.07790"}, {"metadata": {"arXiv": "2311.07797", "Date": "Mon, 13 Nov 2023 23:15:29 ", "Title": "Explainable History Distillation by Marked Temporal Point Process", "Authors": ["Sishun Liu", "Ke Deng", "Yan Wang", "Xiuzhen Zhang"], "Categories": "cs.LG"}, "abstract": "Explainability of machine learning models is mandatory when researchers introduce these commonly believed black boxes to real-world tasks, especially high-stakes ones. In this paper, we build a machine learning system to automatically generate explanations of happened events from history by \\gls{ca} based on the \\acrfull{tpp}. Specifically, we propose a new task called \\acrfull{ehd}. This task requires a model to distill as few events as possible from observed history. The target is that the event distribution conditioned on left events predicts the observed future noticeably worse. We then regard distilled events as the explanation for the future. To efficiently solve \\acrshort{ehd}, we rewrite the task into a \\gls{01ip} and directly estimate the solution to the program by a model called \\acrfull{model}. This work fills the gap between our task and existing works, which only spot the difference between factual and counterfactual worlds after applying a predefined modification to the environment. Experiment results on Retweet and StackOverflow datasets prove that \\acrshort{model} significantly outperforms other \\acrshort{ehd} baselines and can reveal the rationale underpinning real-world processes.", "url": "https://arxiv.org/abs/2311.07797"}, {"metadata": {"arXiv": "2311.07798", "Date": "Mon, 13 Nov 2023 23:25:18 ", "Title": "Probabilistic Physics-integrated Neural Differentiable Modeling for Isothermal Chemical Vapor Infiltration Process", "Authors": ["Deepak Akhare", "Zeping Chen", "Richard Gulotty", "Tengfei Luo", "Jian-Xun Wang"], "Categories": "cs.LG"}, "abstract": "Chemical vapor infiltration (CVI) is a widely adopted manufacturing technique used in producing carbon-carbon and carbon-silicon carbide composites. These materials are especially valued in the aerospace and automotive industries for their robust strength and lightweight characteristics. The densification process during CVI critically influences the final performance, quality, and consistency of these composite materials. Experimentally optimizing the CVI processes is challenging due to long experimental time and large optimization space. To address these challenges, this work takes a modeling-centric approach. Due to the complexities and limited experimental data of the isothermal CVI densification process, we have developed a data-driven predictive model using the physics-integrated neural differentiable (PiNDiff) modeling framework. An uncertainty quantification feature has been embedded within the PiNDiff method, bolstering the model's reliability and robustness. Through comprehensive numerical experiments involving both synthetic and real-world manufacturing data, the proposed method showcases its capability in modeling densification during the CVI process. This research highlights the potential of the PiNDiff framework as an instrumental tool for advancing our understanding, simulation, and optimization of the CVI manufacturing process, particularly when faced with sparse data and an incomplete description of the underlying physics.", "url": "https://arxiv.org/abs/2311.07798"}, {"metadata": {"arXiv": "2311.07821", "Date": "Tue, 14 Nov 2023 00:45:53 ", "Title": "Statistical Parameterized Physics-Based Machine Learning Digital Twin Models for Laser Powder Bed Fusion Process", "Authors": ["Yangfan Li", "Satyajit Mojumder", "Ye Lu", "Abdullah Al Amin", "Jiachen Guo", "Xiaoyu Xie", "Wei Chen", "Gregory J. Wagner", "Jian Cao", "Wing Kam Liu"], "Categories": "cs.LG cs.CE cs.NA math.NA physics.data-an", "Comments": ["arXiv admin note: text overlap with arXiv:2208.02907"]}, "abstract": "A digital twin (DT) is a virtual representation of physical process, products and/or systems that requires a high-fidelity computational model for continuous update through the integration of sensor data and user input. In the context of laser powder bed fusion (LPBF) additive manufacturing, a digital twin of the manufacturing process can offer predictions for the produced parts, diagnostics for manufacturing defects, as well as control capabilities. This paper introduces a parameterized physics-based digital twin (PPB-DT) for the statistical predictions of LPBF metal additive manufacturing process. We accomplish this by creating a high-fidelity computational model that accurately represents the melt pool phenomena and subsequently calibrating and validating it through controlled experiments. In PPB-DT, a mechanistic reduced-order method-driven stochastic calibration process is introduced, which enables the statistical predictions of the melt pool geometries and the identification of defects such as lack-of-fusion porosity and surface roughness, specifically for diagnostic applications. Leveraging data derived from this physics-based model and experiments, we have trained a machine learning-based digital twin (PPB-ML-DT) model for predicting, monitoring, and controlling melt pool geometries. These proposed digital twin models can be employed for predictions, control, optimization, and quality assurance within the LPBF process, ultimately expediting product development and certification in LPBF-based metal additive manufacturing.", "url": "https://arxiv.org/abs/2311.07821"}, {"metadata": {"arXiv": "2311.07833", "Date": "Tue, 14 Nov 2023 01:26:20 ", "Title": "Toward Efficient and Incremental Spectral Clustering via Parametric Spectral Clustering", "Authors": ["Jo-Chun Chen", "Hung-Hsuan Chen"], "Categories": "cs.LG"}, "abstract": "Spectral clustering is a popular method for effectively clustering nonlinearly separable data. However, computational limitations, memory requirements, and the inability to perform incremental learning challenge its widespread application. To overcome these limitations, this paper introduces a novel approach called parametric spectral clustering (PSC). By extending the capabilities of spectral clustering, PSC addresses the challenges associated with big data and real-time scenarios and enables efficient incremental clustering with new data points. Experimental evaluations conducted on various open datasets demonstrate the superiority of PSC in terms of computational efficiency while achieving clustering quality mostly comparable to standard spectral clustering. The proposed approach has significant potential for incremental and real-time data analysis applications, facilitating timely and accurate clustering in dynamic and evolving datasets. The findings of this research contribute to the advancement of clustering techniques and open new avenues for efficient and effective data analysis. We publish the experimental code at https://github.com/109502518/PSC_BigData.", "url": "https://arxiv.org/abs/2311.07833"}, {"metadata": {"arXiv": "2311.07841", "Date": "Tue, 14 Nov 2023 01:40:21 ", "Title": "PEMS: Pre-trained Epidmic Time-series Models", "Authors": ["Harshavardhan Kamarthi", "B. Aditya Prakash"], "Categories": "cs.LG cs.SI", "Comments": ["18 pages"]}, "abstract": "Providing accurate and reliable predictions about the future of an epidemic is an important problem for enabling informed public health decisions. Recent works have shown that leveraging data-driven solutions that utilize advances in deep learning methods to learn from past data of an epidemic often outperform traditional mechanistic models. However, in many cases, the past data is sparse and may not sufficiently capture the underlying dynamics. While there exists a large amount of data from past epidemics, leveraging prior knowledge from time-series data of other diseases is a non-trivial challenge. Motivated by the success of pre-trained models in language and vision tasks, we tackle the problem of pre-training epidemic time-series models to learn from multiple datasets from different diseases and epidemics. We introduce Pre-trained Epidemic Time-Series Models (PEMS) that learn from diverse time-series datasets of a variety of diseases by formulating pre-training as a set of self-supervised learning (SSL) tasks. We tackle various important challenges specific to pre-training for epidemic time-series such as dealing with heterogeneous dynamics and efficiently capturing useful patterns from multiple epidemic datasets by carefully designing the SSL tasks to learn important priors about the epidemic dynamics that can be leveraged for fine-tuning to multiple downstream tasks. The resultant PEM outperforms previous state-of-the-art methods in various downstream time-series tasks across datasets of varying seasonal patterns, geography, and mechanism of contagion including the novel Covid-19 pandemic unseen in pre-trained data with better efficiency using smaller fraction of datasets.", "url": "https://arxiv.org/abs/2311.07841"}, {"metadata": {"arXiv": "2311.07864", "Date": "Tue, 14 Nov 2023 02:33:54 ", "Title": "Probing clustering in neural network representations", "Authors": ["Thao Nguyen", "Simon Kornblith"], "Categories": "cs.LG cs.CV"}, "abstract": "Neural network representations contain structure beyond what was present in the training labels. For instance, representations of images that are visually or semantically similar tend to lie closer to each other than to dissimilar images, regardless of their labels. Clustering these representations can thus provide insights into dataset properties as well as the network internals. In this work, we study how the many design choices involved in neural network training affect the clusters formed in the hidden representations. To do so, we establish an evaluation setup based on the BREEDS hierarchy, for the task of subclass clustering after training models with only superclass information. We isolate the training dataset and architecture as important factors affecting clusterability. Datasets with labeled classes consisting of unrelated subclasses yield much better clusterability than those following a natural hierarchy. When using pretrained models to cluster representations on downstream datasets, models pretrained on subclass labels provide better clusterability than models pretrained on superclass labels, but only when there is a high degree of domain overlap between the pretraining and downstream data. Architecturally, we find that normalization strategies affect which layers yield the best clustering performance, and, surprisingly, Vision Transformers attain lower subclass clusterability than ResNets.", "url": "https://arxiv.org/abs/2311.07864"}, {"metadata": {"arXiv": "2311.07867", "Date": "Tue, 14 Nov 2023 02:55:37 ", "Title": "Mixture of Coupled HMMs for Robust Modeling of Multivariate Healthcare Time Series", "Authors": ["Onur Poyraz", "Pekka Marttinen"], "Categories": "cs.LG stat.AP stat.ML", "Comments": ["9 pages", "7 figures", "Proceedings of Machine Learning Research", "Machine Learning for Health (ML4H) 2023"]}, "abstract": "Analysis of multivariate healthcare time series data is inherently challenging: irregular sampling, noisy and missing values, and heterogeneous patient groups with different dynamics violating exchangeability. In addition, interpretability and quantification of uncertainty are critically important. Here, we propose a novel class of models, a mixture of coupled hidden Markov models (M-CHMM), and demonstrate how it elegantly overcomes these challenges. To make the model learning feasible, we derive two algorithms to sample the sequences of the latent variables in the CHMM: samplers based on (i) particle filtering and (ii) factorized approximation. Compared to existing inference methods, our algorithms are computationally tractable, improve mixing, and allow for likelihood estimation, which is necessary to learn the mixture model. Experiments on challenging real-world epidemiological and semi-synthetic data demonstrate the advantages of the M-CHMM: improved data fit, capacity to efficiently handle missing and noisy measurements, improved prediction accuracy, and ability to identify interpretable subsets in the data.", "url": "https://arxiv.org/abs/2311.07867"}, {"metadata": {"arXiv": "2311.07929", "Date": "Tue, 14 Nov 2023 06:15:16 ", "Title": "Self-supervised Heterogeneous Graph Variational Autoencoders", "Authors": ["Yige Zhao", "Jianxiang Yu", "Yao Cheng", "Chengcheng Yu", "Yiding Liu", "Xiang Li", "Shuaiqiang Wang"], "Categories": "cs.LG cs.SI"}, "abstract": "Heterogeneous Information Networks (HINs), which consist of various types of nodes and edges, have recently demonstrated excellent performance in graph mining. However, most existing heterogeneous graph neural networks (HGNNs) ignore the problems of missing attributes, inaccurate attributes and scarce labels for nodes, which limits their expressiveness. In this paper, we propose a generative self-supervised model SHAVA to address these issues simultaneously. Specifically, SHAVA first initializes all the nodes in the graph with a low-dimensional representation matrix. After that, based on the variational graph autoencoder framework, SHAVA learns both node-level and attribute-level embeddings in the encoder, which can provide fine-grained semantic information to construct node attributes. In the decoder, SHAVA reconstructs both links and attributes. Instead of directly reconstructing raw features for attributed nodes, SHAVA generates the initial low-dimensional representation matrix for all the nodes, based on which raw features of attributed nodes are further reconstructed to leverage accurate attributes. In this way, SHAVA can not only complete informative features for non-attributed nodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct extensive experiments to show the superiority of SHAVA in tackling HINs with missing and inaccurate attributes.", "url": "https://arxiv.org/abs/2311.07929"}, {"metadata": {"arXiv": "2311.07966", "Date": "Tue, 14 Nov 2023 07:44:46 ", "Title": "Higher-Order Expander Graph Propagation", "Authors": ["Thomas Christie", "Yu He"], "Categories": "cs.LG", "Comments": ["9 pages", "2 figures"]}, "abstract": "Graph neural networks operate on graph-structured data via exchanging messages along edges. One limitation of this message passing paradigm is the over-squashing problem. Over-squashing occurs when messages from a node's expanded receptive field are compressed into fixed-size vectors, potentially causing information loss. To address this issue, recent works have explored using expander graphs, which are highly-connected sparse graphs with low diameters, to perform message passing. However, current methods on expander graph propagation only consider pair-wise interactions, ignoring higher-order structures in complex data. To explore the benefits of capturing these higher-order correlations while still leveraging expander graphs, we introduce higher-order expander graph propagation. We propose two methods for constructing bipartite expanders and evaluate their performance on both synthetic and real-world datasets.", "url": "https://arxiv.org/abs/2311.07966"}, {"metadata": {"arXiv": "2311.07967", "Date": "Tue, 14 Nov 2023 07:46:03 ", "Title": "Comparison of two data fusion approaches for land use classification", "Authors": ["Martin Cubaud (LaSTIG)", "Arnaud Le Bris (LaSTIG)", "Laurence Jolivet (LaSTIG)", "Ana-Maria Olteanu-Raimond (LaSTIG)"], "Categories": "cs.LG cs.CV", "Journal-ref": "ISPRS Geospatial Week 2023, Sep 2023, Cairo, Egypt., Egypt"}, "abstract": "Accurate land use maps, describing the territory from an anthropic utilisation point of view, are useful tools for land management and planning. To produce them, the use of optical images alone remains limited. It is therefore necessary to make use of several heterogeneous sources, each carrying complementary or contradictory information due to their imperfections or their different specifications. This study compares two different approaches i.e. a pre-classification and a post-classification fusion approach for combining several sources of spatial data in the context of land use classification. The approaches are applied on authoritative land use data located in the Gers department in the southwest of France. Pre-classification fusion, while not explicitly modeling imperfections, has the best final results, reaching an overall accuracy of 97% and a macro-mean F1 score of 88%.", "url": "https://arxiv.org/abs/2311.07967"}, {"metadata": {"arXiv": "2311.07975", "Date": "Tue, 14 Nov 2023 08:05:02 ", "Title": "Out-of-Distribution Knowledge Distillation via Confidence Amendment", "Authors": ["Zhilin Zhao and Longbing Cao and Yixuan Zhang"], "Categories": "cs.LG"}, "abstract": "Out-of-distribution (OOD) detection is essential in identifying test samples that deviate from the in-distribution (ID) data upon which a standard network is trained, ensuring network robustness and reliability. This paper introduces OOD knowledge distillation, a pioneering learning framework applicable whether or not training ID data is available, given a standard network. This framework harnesses OOD-sensitive knowledge from the standard network to craft a binary classifier adept at distinguishing between ID and OOD samples. To accomplish this, we introduce Confidence Amendment (CA), an innovative methodology that transforms an OOD sample into an ID one while progressively amending prediction confidence derived from the standard network. This approach enables the simultaneous synthesis of both ID and OOD samples, each accompanied by an adjusted prediction confidence, thereby facilitating the training of a binary classifier sensitive to OOD. Theoretical analysis provides bounds on the generalization error of the binary classifier, demonstrating the pivotal role of confidence amendment in enhancing OOD sensitivity. Extensive experiments spanning various datasets and network architectures confirm the efficacy of the proposed method in detecting OOD samples.", "url": "https://arxiv.org/abs/2311.07975"}, {"metadata": {"arXiv": "2311.08053", "Date": "Tue, 14 Nov 2023 10:23:00 ", "Title": "Communication-Constrained Bayesian Active Knowledge Distillation", "Authors": ["Victor Croisfelt and Shashi Raj Pandey and Osvaldo Simeone and Petar Popovski"], "Categories": "cs.LG", "Comments": ["6 pages", "4 figures", "conference version", "submitted to IEEE ICC 2024"]}, "abstract": "Consider an active learning setting in which a learner has a training set with few labeled examples and a pool set with many unlabeled inputs, while a remote teacher has a pre-trained model that is known to perform well for the learner's task. The learner actively transmits batches of unlabeled inputs to the teacher through a constrained communication channel for labeling. This paper addresses the following key questions: (i) Active batch selection: Which batch of inputs should be sent to the teacher to acquire the most useful information and thus reduce the number of required communication rounds? (ii) Batch encoding: How do we encode the batch of inputs for transmission to the teacher to reduce the communication resources required at each round? We introduce Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD), a novel protocol that integrates Bayesian active learning with compression via a linear mix-up mechanism. Bayesian active learning selects the batch of inputs based on their epistemic uncertainty, addressing the \"confirmation bias\" that is known to increase the number of required communication rounds. Furthermore, the proposed mix-up compression strategy is integrated with the epistemic uncertainty-based active batch selection process to reduce the communication overhead per communication round.", "url": "https://arxiv.org/abs/2311.08053"}, {"metadata": {"arXiv": "2311.08105", "Date": "Tue, 14 Nov 2023 12:05:45 ", "Title": "DiLoCo: Distributed Low-Communication Training of Language Models", "Authors": ["Arthur Douillard", "Qixuan Feng", "Andrei A. Rusu", "Rachita Chhaparia", "Yani Donchev", "Adhiguna Kuncoro", "Marc'Aurelio Ranzato", "Arthur Szlam", "Jiajun Shen"], "Categories": "cs.LG cs.CL"}, "abstract": "Large language models (LLM) have become a critical component in many applications of machine learning. However, standard approaches to training LLM require a large number of tightly interconnected accelerators, with devices exchanging gradients and other intermediate states at each optimization step. While it is difficult to build and maintain a single computing cluster hosting many accelerators, it might be easier to find several computing clusters each hosting a smaller number of devices. In this work, we propose a distributed optimization algorithm, Distributed Low-Communication (DiLoCo), that enables training of language models on islands of devices that are poorly connected. The approach is a variant of federated averaging, where the number of inner steps is large, the inner optimizer is AdamW, and the outer optimizer is Nesterov momentum. On the widely used C4 dataset, we show that DiLoCo on 8 workers performs as well as fully synchronous optimization while communicating 500 times less. DiLoCo exhibits great robustness to the data distribution of each worker. It is also robust to resources becoming unavailable over time, and vice versa, it can seamlessly leverage resources that become available during training.", "url": "https://arxiv.org/abs/2311.08105"}, {"metadata": {"arXiv": "2311.08123", "Date": "Tue, 14 Nov 2023 12:37:25 ", "Title": "Memory-efficient Stochastic methods for Memory-based Transformers", "Authors": ["Vishwajit Kumar Vishnu", "C. Chandra Sekhar"], "Categories": "cs.LG cs.CL"}, "abstract": "Training Memory-based transformers can require a large amount of memory and can be quite inefficient. We propose a novel two-phase training mechanism and a novel regularization technique to improve the training efficiency of memory-based transformers, which are often used for long-range context problems. For our experiments, we consider transformer-XL as our baseline model which is one of memorybased transformer models. We show that our resultant model, Skip Cross-head TransformerXL, outperforms the baseline on character level language modeling task with similar parameters and outperforms the baseline on word level language modelling task with almost 20% fewer parameters. Our proposed methods do not require any additional memory. We also demonstrate the effectiveness of our regularization mechanism on BERT which shows similar performance with reduction in standard deviation of scores of around 30% on multiple GLUE tasks.", "url": "https://arxiv.org/abs/2311.08123"}, {"metadata": {"arXiv": "2311.08125", "Date": "Tue, 14 Nov 2023 12:41:22 ", "Title": "Lite it fly: An All-Deformable-Butterfly Network", "Authors": ["Rui Lin", "Jason Chun Lok Li", "Jiajun Zhou", "Binxiao Huang", "Jie Ran and Ngai Wong"], "Categories": "cs.LG", "Comments": ["7 pages", "3 figures", "accepted as a brief paper in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)"]}, "abstract": "Most deep neural networks (DNNs) consist fundamentally of convolutional and/or fully connected layers, wherein the linear transform can be cast as the product between a filter matrix and a data matrix obtained by arranging feature tensors into columns. The lately proposed deformable butterfly (DeBut) decomposes the filter matrix into generalized, butterflylike factors, thus achieving network compression orthogonal to the traditional ways of pruning or low-rank decomposition. This work reveals an intimate link between DeBut and a systematic hierarchy of depthwise and pointwise convolutions, which explains the empirically good performance of DeBut layers. By developing an automated DeBut chain generator, we show for the first time the viability of homogenizing a DNN into all DeBut layers, thus achieving an extreme sparsity and compression. Various examples and hardware benchmarks verify the advantages of All-DeBut networks. In particular, we show it is possible to compress a PointNet to < 5% parameters with < 5% accuracy drop, a record not achievable by other compression schemes.", "url": "https://arxiv.org/abs/2311.08125"}, {"metadata": {"arXiv": "2311.08149", "Date": "Tue, 14 Nov 2023 13:25:41 ", "Title": "Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes", "Authors": ["C\\'ecile Trottet", "Manuel Sch\\\"urch", "Ahmed Allam", "Imon Barua", "Liubov Petelytska", "Oliver Distler", "Anna-Maria Hoffmann-Vold", "Michael Krauthammer", "the EUSTAR collaborators"], "Categories": "cs.LG stat.ML", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "23 pages"]}, "abstract": "In this paper, we propose a deep generative time series approach using latent temporal processes for modeling and holistically analyzing complex disease trajectories. We aim to find meaningful temporal latent representations of an underlying generative process that explain the observed disease trajectories in an interpretable and comprehensive way. To enhance the interpretability of these latent temporal processes, we develop a semi-supervised approach for disentangling the latent space using established medical concepts. By combining the generative approach with medical knowledge, we leverage the ability to discover novel aspects of the disease while integrating medical concepts into the model. We show that the learned temporal latent processes can be utilized for further data analysis and clinical hypothesis testing, including finding similar patients and clustering the disease into new sub-types. Moreover, our method enables personalized online monitoring and prediction of multivariate time series including uncertainty quantification. We demonstrate the effectiveness of our approach in modeling systemic sclerosis, showcasing the potential of our machine learning model to capture complex disease trajectories and acquire new medical knowledge.", "url": "https://arxiv.org/abs/2311.08149"}, {"metadata": {"arXiv": "2311.08202", "Date": "Tue, 14 Nov 2023 14:37:33 ", "Title": "Federated Skewed Label Learning with Logits Fusion", "Authors": ["Yuwei Wang", "Runhan Li", "Hao Tan", "Xuefeng Jiang", "Sheng Sun", "Min Liu", "Bo Gao", "Zhiyuan Wu"], "Categories": "cs.LG", "Comments": ["9 pages", "4 figures", "4 tables"]}, "abstract": "Federated learning (FL) aims to collaboratively train a shared model across multiple clients without transmitting their local data. Data heterogeneity is a critical challenge in realistic FL settings, as it causes significant performance deterioration due to discrepancies in optimization among local models. In this work, we focus on label distribution skew, a common scenario in data heterogeneity, where the data label categories are imbalanced on each client. To address this issue, we propose FedBalance, which corrects the optimization bias among local models by calibrating their logits. Specifically, we introduce an extra private weak learner on the client side, which forms an ensemble model with the local model. By fusing the logits of the two models, the private weak learner can capture the variance of different data, regardless of their category. Therefore, the optimization direction of local models can be improved by increasing the penalty for misclassifying minority classes and reducing the attention to majority classes, resulting in a better global model. Extensive experiments show that our method can gain 13\\% higher average accuracy compared with state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.08202"}, {"metadata": {"arXiv": "2311.08228", "Date": "Tue, 14 Nov 2023 15:08:14 ", "Title": "Counterfactual Explanation for Regression via Disentanglement in Latent Space", "Authors": ["Xuan Zhao and Klaus Broelemann and Gjergji Kasneci"], "Categories": "cs.LG", "Comments": ["CXAI workshop @ ICDM 2023"]}, "abstract": "Counterfactual Explanations (CEs) help address the question: How can the factors that influence the prediction of a predictive model be changed to achieve a more favorable outcome from a user's perspective? Thus, they bear the potential to guide the user's interaction with AI systems since they represent easy-to-understand explanations. To be applicable, CEs need to be realistic and actionable. In the literature, various methods have been proposed to generate CEs. However, the majority of research on CEs focuses on classification problems where questions like ``What should I do to get my rejected loan approved?\" are raised. In practice, answering questions like ``What should I do to increase my salary?\" are of a more regressive nature. In this paper, we introduce a novel method to generate CEs for a pre-trained regressor by first disentangling the label-relevant from the label-irrelevant dimensions in the latent space. CEs are then generated by combining the label-irrelevant dimensions and the predefined output. The intuition behind this approach is that the ideal counterfactual search should focus on the label-irrelevant characteristics of the input and suggest changes toward target-relevant characteristics. Searching in the latent space could help achieve this goal. We show that our method maintains the characteristics of the query sample during the counterfactual search. In various experiments, we demonstrate that the proposed method is competitive based on different quality measures on image and tabular datasets in regression problem settings. It efficiently returns results closer to the original data manifold compared to three state-of-the-art methods, which is essential for realistic high-dimensional machine learning applications. Our code will be made available as an open-source package upon the publication of this work.", "url": "https://arxiv.org/abs/2311.08228"}, {"metadata": {"arXiv": "2311.08271", "Date": "Tue, 14 Nov 2023 16:06:11 ", "Title": "Mobility-Induced Graph Learning for WiFi Positioning", "Authors": ["Kyuwon Han", "Seung Min Yu", "Seong-Lyun Kim", "Seung-Woo Ko"], "Categories": "cs.LG cs.IT cs.NI eess.SP math.IT", "Comments": ["submitted to a possible IEEE journal"]}, "abstract": "A smartphone-based user mobility tracking could be effective in finding his/her location, while the unpredictable error therein due to low specification of built-in inertial measurement units (IMUs) rejects its standalone usage but demands the integration to another positioning technique like WiFi positioning. This paper aims to propose a novel integration technique using a graph neural network called Mobility-INduced Graph LEarning (MINGLE), which is designed based on two types of graphs made by capturing different user mobility features. Specifically, considering sequential measurement points (MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor MPs as edges, called time-driven mobility graph (TMG). Second, a user's relatively straight transition at a constant pace when moving from one position to another can be captured by connecting the nodes on each path, called a direction-driven mobility graph (DMG). Then, we can design graph convolution network (GCN)-based cross-graph learning, where two different GCN models for TMG and DMG are jointly trained by feeding different input features created by WiFi RTTs yet sharing their weights. Besides, the loss function includes a mobility regularization term such that the differences between adjacent location estimates should be less variant due to the user's stable moving pace. Noting that the regularization term does not require ground-truth location, MINGLE can be designed under semi- and self-supervised learning frameworks. The proposed MINGLE's effectiveness is extensively verified through field experiments, showing a better positioning accuracy than benchmarks, say root mean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and semi-supervised learning cases, respectively.", "url": "https://arxiv.org/abs/2311.08271"}, {"metadata": {"arXiv": "2311.08290", "Date": "Tue, 14 Nov 2023 16:37:28 ", "Title": "On-Policy Policy Gradient Reinforcement Learning Without On-Policy Sampling", "Authors": ["Nicholas E. Corrado", "Josiah P. Hanna"], "Categories": "cs.LG"}, "abstract": "On-policy reinforcement learning (RL) algorithms perform policy updates using i.i.d. trajectories collected by the current policy. However, after observing only a finite number of trajectories, on-policy sampling may produce data that fails to match the expected on-policy data distribution. This sampling error leads to noisy updates and data inefficient on-policy learning. Recent work in the policy evaluation setting has shown that non-i.i.d., off-policy sampling can produce data with lower sampling error than on-policy sampling can produce. Motivated by this observation, we introduce an adaptive, off-policy sampling method to improve the data efficiency of on-policy policy gradient algorithms. Our method, Proximal Robust On-Policy Sampling (PROPS), reduces sampling error by collecting data with a behavior policy that increases the probability of sampling actions that are under-sampled with respect to the current policy. Rather than discarding data from old policies -- as is commonly done in on-policy algorithms -- PROPS uses data collection to adjust the distribution of previously collected data to be approximately on-policy. We empirically evaluate PROPS on both continuous-action MuJoCo benchmark tasks as well as discrete-action tasks and demonstrate that (1) PROPS decreases sampling error throughout training and (2) improves the data efficiency of on-policy policy gradient algorithms. Our work improves the RL community's understanding of a nuance in the on-policy vs off-policy dichotomy: on-policy learning requires on-policy data, not on-policy sampling.", "url": "https://arxiv.org/abs/2311.08290"}, {"metadata": {"arXiv": "2311.08309", "Date": "Tue, 14 Nov 2023 16:55:12 ", "Title": "Introducing an Improved Information-Theoretic Measure of Predictive Uncertainty", "Authors": ["Kajetan Schweighofer and Lukas Aichberger and Mykyta Ielanskyi and Sepp Hochreiter"], "Categories": "cs.LG stat.ML", "Comments": ["M3L & InfoCog Workshops NeurIPS 23"]}, "abstract": "Applying a machine learning model for decision-making in the real world requires to distinguish what the model knows from what it does not. A critical factor in assessing the knowledge of a model is to quantify its predictive uncertainty. Predictive uncertainty is commonly measured by the entropy of the Bayesian model average (BMA) predictive distribution. Yet, the properness of this current measure of predictive uncertainty was recently questioned. We provide new insights regarding those limitations. Our analyses show that the current measure erroneously assumes that the BMA predictive distribution is equivalent to the predictive distribution of the true model that generated the dataset. Consequently, we introduce a theoretically grounded measure to overcome these limitations. We experimentally verify the benefits of our introduced measure of predictive uncertainty. We find that our introduced measure behaves more reasonably in controlled synthetic tasks. Moreover, our evaluations on ImageNet demonstrate that our introduced measure is advantageous in real-world applications utilizing predictive uncertainty.", "url": "https://arxiv.org/abs/2311.08309"}, {"metadata": {"arXiv": "2311.08357", "Date": "Tue, 14 Nov 2023 17:59:51 ", "Title": "Sparsity-Preserving Differentially Private Training of Large Embedding Models", "Authors": ["Badih Ghazi", "Yangsibo Huang", "Pritish Kamath", "Ravi Kumar", "Pasin Manurangsi", "Amer Sinha", "Chiyuan Zhang"], "Categories": "cs.LG cs.CR", "Comments": ["Neural Information Processing Systems (NeurIPS) 2023"]}, "abstract": "As the use of large embedding models in recommendation systems and language applications increases, concerns over user data privacy have also risen. DP-SGD, a training algorithm that combines differential privacy with stochastic gradient descent, has been the workhorse in protecting user privacy without compromising model accuracy by much. However, applying DP-SGD naively to embedding models can destroy gradient sparsity, leading to reduced training efficiency. To address this issue, we present two new algorithms, DP-FEST and DP-AdaFEST, that preserve gradient sparsity during private training of large embedding models. Our algorithms achieve substantial reductions ($10^6 \\times$) in gradient size, while maintaining comparable levels of accuracy, on benchmark real-world datasets.", "url": "https://arxiv.org/abs/2311.08357"}, {"metadata": {"arXiv": "2311.08362", "Date": "Tue, 14 Nov 2023 18:09:15 ", "Title": "Transformers can optimally learn regression mixture models", "Authors": ["Reese Pathak", "Rajat Sen", "Weihao Kong", "Abhimanyu Das"], "Categories": "cs.LG stat.ML", "Comments": ["24 pages", "9 figures"]}, "abstract": "Mixture models arise in many regression problems, but most methods have seen limited adoption partly due to these algorithms' highly-tailored and model-specific nature. On the other hand, transformers are flexible, neural sequence models that present the intriguing possibility of providing general-purpose prediction methods, even in this mixture setting. In this work, we investigate the hypothesis that transformers can learn an optimal predictor for mixtures of regressions. We construct a generative process for a mixture of linear regressions for which the decision-theoretic optimal procedure is given by data-driven exponential weights on a finite set of parameters. We observe that transformers achieve low mean-squared error on data generated via this process. By probing the transformer's output at inference time, we also show that transformers typically make predictions that are close to the optimal predictor. Our experiments also demonstrate that transformers can learn mixtures of regressions in a sample-efficient fashion and are somewhat robust to distribution shifts. We complement our experimental observations by proving constructively that the decision-theoretic optimal procedure is indeed implementable by a transformer.", "url": "https://arxiv.org/abs/2311.08362"}, {"metadata": {"arXiv": "2311.07613", "Date": "Sun, 12 Nov 2023 00:11:52 ", "Title": "A Physics-informed Machine Learning-based Control Method for Nonlinear Dynamic Systems with Highly Noisy Measurements", "Authors": ["Mason Ma", "Jiajie Wu", "Chase Post", "Tony Shi", "Jingang Yi", "Tony Schmitz", "and Hong Wang"], "Categories": "eess.SY cs.LG cs.SY math.DS"}, "abstract": "This study presents a physics-informed machine learning-based control method for nonlinear dynamic systems with highly noisy measurements. Existing data-driven control methods that use machine learning for system identification cannot effectively cope with highly noisy measurements, resulting in unstable control performance. To address this challenge, the present study extends current physics-informed machine learning capabilities for modeling nonlinear dynamics with control and integrates them into a model predictive control framework. To demonstrate the capability of the proposed method we test and validate with two noisy nonlinear dynamic systems: the chaotic Lorenz 3 system, and turning machine tool. Analysis of the results illustrate that the proposed method outperforms state-of-the-art benchmarks as measured by both modeling accuracy and control performance for nonlinear dynamic systems under high-noise conditions.", "url": "https://arxiv.org/abs/2311.07613"}, {"metadata": {"arXiv": "2311.07745", "Date": "Mon, 13 Nov 2023 20:55:02 ", "Title": "Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice", "Authors": ["Idan Lev-Yehudi", "Moran Barenboim", "Vadim Indelman"], "Categories": "cs.AI cs.RO"}, "abstract": "Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to access the costly model at all during planning, which is also a novel result. Finally, we demonstrate in simulation how to integrate the bound into the routine of an existing continuous online POMDP solver.", "url": "https://arxiv.org/abs/2311.07745"}, {"metadata": {"arXiv": "2311.07759", "Date": "Mon, 13 Nov 2023 21:20:17 ", "Title": "Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems", "Authors": ["Alessandro Oltramari"], "Categories": "cs.AI"}, "abstract": "High-level reasoning can be defined as the capability to generalize over knowledge acquired via experience, and to exhibit robust behavior in novel situations. Such form of reasoning is a basic skill in humans, who seamlessly use it in a broad spectrum of tasks, from language communication to decision making in complex situations. When it manifests itself in understanding and manipulating the everyday world of objects and their interactions, we talk about common sense or commonsense reasoning. State-of-the-art AI systems don't possess such capability: for instance, Large Language Models have recently become popular by demonstrating remarkable fluency in conversing with humans, but they still make trivial mistakes when probed for commonsense competence; on a different level, performance degradation outside training data prevents self-driving vehicles to safely adapt to unseen scenarios, a serious and unsolved problem that limits the adoption of such technology. In this paper we propose to enable high-level reasoning in AI systems by integrating cognitive architectures with external neuro-symbolic components. We illustrate a hybrid framework centered on ACT-R and we discuss the role of generative models in recent and future applications.", "url": "https://arxiv.org/abs/2311.07759"}, {"metadata": {"arXiv": "2311.07815", "Date": "Tue, 14 Nov 2023 00:23:21 ", "Title": "Cooperative AI via Decentralized Commitment Devices", "Authors": ["Xinyuan Sun and Davide Crapis and Matt Stephenson and Barnab\\'e Monnot and Thomas Thiery and Jonathan Passerat-Palmbach"], "Categories": "cs.AI cs.CR cs.GT cs.MA", "Comments": ["NeurIPS 2023- Multi-Agent Security Workshop"]}, "abstract": "Credible commitment devices have been a popular approach for robust multi-agent coordination. However, existing commitment mechanisms face limitations like privacy, integrity, and susceptibility to mediator or user strategic behavior. It is unclear if the cooperative AI techniques we study are robust to real-world incentives and attack vectors. However, decentralized commitment devices that utilize cryptography have been deployed in the wild, and numerous studies have shown their ability to coordinate algorithmic agents facing adversarial opponents with significant economic incentives, currently in the order of several million to billions of dollars. In this paper, we use examples in the decentralization and, in particular, Maximal Extractable Value (MEV) (arXiv:1904.05234) literature to illustrate the potential security issues in cooperative AI. We call for expanded research into decentralized commitments to advance cooperative AI capabilities for secure coordination in open environments and empirical testing frameworks to evaluate multi-agent coordination ability given real-world commitment constraints.", "url": "https://arxiv.org/abs/2311.07815"}, {"metadata": {"arXiv": "2311.07954", "Date": "Tue, 14 Nov 2023 07:13:10 ", "Title": "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning", "Authors": ["Ruixin Hong", "Hongming Zhang", "Xinyu Pang", "Dong Yu", "Changshui Zhang"], "Categories": "cs.AI cs.CL", "Comments": ["work in progress"]}, "abstract": "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.", "url": "https://arxiv.org/abs/2311.07954"}, {"metadata": {"arXiv": "2311.08086", "Date": "Tue, 14 Nov 2023 11:13:00 ", "Title": "CPSOR-GCN: A Vehicle Trajectory Prediction Method Powered by Emotion and Cognitive Theory", "Authors": ["L. Tang", "Y. Li", "J. Yuan", "A. Fu", "J. Sun"], "Categories": "cs.AI", "Comments": ["15 pages", "31 figures", "submitted to IEEE Transactions on Intelligent Vehicles"]}, "abstract": "Active safety systems on vehicles often face problems with false alarms. Most active safety systems predict the driver's trajectory with the assumption that the driver is always in a normal emotion, and then infer risks. However, the driver's trajectory uncertainty increases under abnormal emotions. This paper proposes a new trajectory prediction model: CPSOR-GCN, which predicts vehicle trajectories under abnormal emotions. At the physical level, the interaction features between vehicles are extracted by the physical GCN module. At the cognitive level, SOR cognitive theory is used as prior knowledge to build a Dynamic Bayesian Network (DBN) structure. The conditional probability and state transition probability of nodes from the calibrated SOR-DBN quantify the causal relationship between cognitive factors, which is embedded into the cognitive GCN module to extract the characteristics of the influence mechanism of emotions on driving behavior. The CARLA-SUMO joint driving simulation platform was built to develop dangerous pre-crash scenarios. Methods of recreating traffic scenes were used to naturally induce abnormal emotions. The experiment collected data from 26 participants to verify the proposed model. Compared with the model that only considers physical motion features, the prediction accuracy of the proposed model is increased by 68.70%. Furthermore,considering the SOR-DBN reduces the prediction error of the trajectory by 15.93%. Compared with other advanced trajectory prediction models, the results of CPSOR-GCN also have lower errors. This model can be integrated into active safety systems to better adapt to the driver's emotions, which could effectively reduce false alarms.", "url": "https://arxiv.org/abs/2311.08086"}, {"metadata": {"arXiv": "2311.07616", "Date": "Sun, 12 Nov 2023 07:37:07 ", "Title": "ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT challenge at MaCVi of WACV24", "Authors": ["Kaer Huang", "Weitu Chong"], "Categories": "cs.CV cs.AI"}, "abstract": "Multi-Object Tracking is one of the most important technologies in maritime computer vision. Our solution tries to explore Multi-Object Tracking in maritime Unmanned Aerial vehicles (UAVs) and Unmanned Surface Vehicles (USVs) usage scenarios. Most of the current Multi-Object Tracking algorithms require complex association strategies and association information (2D location and motion, 3D motion, 3D depth, 2D appearance) to achieve better performance, which makes the entire tracking system extremely complex and heavy. At the same time, most of the current Multi-Object Tracking algorithms still require video annotation data which is costly to obtain for training. Our solution tries to explore Multi-Object Tracking in a completely unsupervised way. The scheme accomplishes instance representation learning by using self-supervision on ImageNet. Then, by cooperating with high-quality detectors, the multi-target tracking task can be completed simply and efficiently. The scheme achieved top 3 performance on both UAV-based Multi-Object Tracking with Reidentification and USV-based Multi-Object Tracking benchmarks and the solution won the championship in many multiple Multi-Object Tracking competitions. such as BDD100K MOT,MOTS, Waymo 2D MOT", "url": "https://arxiv.org/abs/2311.07616"}, {"metadata": {"arXiv": "2311.07711", "Date": "Mon, 13 Nov 2023 19:51:46 ", "Title": "Histopathologic Cancer Detection", "Authors": ["Varan Singh Rohila", "Neeraj Lalwani", "Lochan Basyal"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages", "5 figures", "2 tables"]}, "abstract": "Early diagnosis of the cancer cells is necessary for making an effective treatment plan and for the health and safety of a patient. Nowadays, doctors usually use a histological grade that pathologists determine by performing a semi-quantitative analysis of the histopathological and cytological features of hematoxylin-eosin (HE) stained histopathological images. This research contributes a potential classification model for cancer prognosis to efficiently utilize the valuable information underlying the HE-stained histopathological images. This work uses the PatchCamelyon benchmark datasets and trains them in a multi-layer perceptron and convolution model to observe the model's performance in terms of precision, Recall, F1 Score, Accuracy, and AUC Score. The evaluation result shows that the baseline convolution model outperforms the baseline MLP model. Also, this paper introduced ResNet50 and InceptionNet models with data augmentation, where ResNet50 is able to beat the state-of-the-art model. Furthermore, the majority vote and concatenation ensemble were evaluated and provided the future direction of using transfer learning and segmentation to understand the specific features.", "url": "https://arxiv.org/abs/2311.07711"}, {"metadata": {"arXiv": "2311.07761", "Date": "Mon, 13 Nov 2023 21:21:43 ", "Title": "Amodal Optical Flow", "Authors": ["Maximilian Luz", "Rohit Mohan", "Ahmed Rida Sekkat", "Oliver Sawade", "Elmar Matthes", "Thomas Brox", "Abhinav Valada"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "Optical flow estimation is very challenging in situations with transparent or occluded objects. In this work, we address these challenges at the task level by introducing Amodal Optical Flow, which integrates optical flow with amodal perception. Instead of only representing the visible regions, we define amodal optical flow as a multi-layered pixel-level motion field that encompasses both visible and occluded regions of the scene. To facilitate research on this new task, we extend the AmodalSynthDrive dataset to include pixel-level labels for amodal optical flow estimation. We present several strong baselines, along with the Amodal Flow Quality metric to quantify the performance in an interpretable manner. Furthermore, we propose the novel AmodalFlowNet as an initial step toward addressing this task. AmodalFlowNet consists of a transformer-based cost-volume encoder paired with a recurrent transformer decoder which facilitates recurrent hierarchical feature propagation and amodal semantic grounding. We demonstrate the tractability of amodal optical flow in extensive experiments and show its utility for downstream tasks such as panoptic tracking. We make the dataset, code, and trained models publicly available at http://amodal-flow.cs.uni-freiburg.de.", "url": "https://arxiv.org/abs/2311.07761"}, {"metadata": {"arXiv": "2311.07840", "Date": "Tue, 14 Nov 2023 01:40:08 ", "Title": "Enabling Decision-Support Systems through Automated Cell Tower Detection", "Authors": ["Natasha Krell", "Will Gleave", "Daniel Nakada", "Justin Downes", "Amanda Willet and Matthew Baran"], "Categories": "cs.CV cs.AI"}, "abstract": "Cell phone coverage and high-speed service gaps persist in rural areas in sub-Saharan Africa, impacting public access to mobile-based financial, educational, and humanitarian services. Improving maps of telecommunications infrastructure can help inform strategies to eliminate gaps in mobile coverage. Deep neural networks, paired with remote sensing images, can be used for object detection of cell towers and eliminate the need for inefficient and burdensome manual mapping to find objects over large geographic regions. In this study, we demonstrate a partially automated workflow to train an object detection model to locate cell towers using OpenStreetMap (OSM) features and high-resolution Maxar imagery. For model fine-tuning and evaluation, we curated a diverse dataset of over 6,000 unique images of cell towers in 26 countries in eastern, southern, and central Africa using automatically generated annotations from OSM points. Our model achieves an average precision at 50% Intersection over Union (IoU) (AP@50) of 81.2 with good performance across different geographies and out-of-sample testing. Accurate localization of cell towers can yield more accurate cell coverage maps, in turn enabling improved delivery of digital services for decision-support applications.", "url": "https://arxiv.org/abs/2311.07840"}, {"metadata": {"arXiv": "2311.07880", "Date": "Tue, 14 Nov 2023 03:19:55 ", "Title": "VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications", "Authors": ["Vinit Katariya", "Fatema-E- Jannat", "Armin Danesh Pazho", "Ghazal Alinezhad Noghre", "Hamed Tabkhi"], "Categories": "cs.CV cs.AI eess.SP"}, "abstract": "Vehicle anomaly detection plays a vital role in highway safety applications such as accident prevention, rapid response, traffic flow optimization, and work zone safety. With the surge of the Internet of Things (IoT) in recent years, there has arisen a pressing demand for Artificial Intelligence (AI) based anomaly detection methods designed to meet the requirements of IoT devices. Catering to this futuristic vision, we introduce a lightweight approach to vehicle anomaly detection by utilizing the power of trajectory prediction. Our proposed design identifies vehicles deviating from expected paths, indicating highway risks from different camera-viewing angles from real-world highway datasets. On top of that, we present VegaEdge - a sophisticated AI confluence designed for real-time security and surveillance applications in modern highway settings through edge-centric IoT-embedded platforms equipped with our anomaly detection approach. Extensive testing across multiple platforms and traffic scenarios showcases the versatility and effectiveness of VegaEdge. This work also presents the Carolinas Anomaly Dataset (CAD), to bridge the existing gap in datasets tailored for highway anomalies. In real-world scenarios, our anomaly detection approach achieves an AUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform, processes 738 trajectories per second in a typical highway setting. The dataset is available at https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set .", "url": "https://arxiv.org/abs/2311.07880"}, {"metadata": {"arXiv": "2311.07885", "Date": "Tue, 14 Nov 2023 03:40:25 ", "Title": "One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion", "Authors": ["Minghua Liu", "Ruoxi Shi", "Linghao Chen", "Zhuoyang Zhang", "Chao Xu", "Xinyue Wei", "Hansheng Chen", "Chong Zeng", "Jiayuan Gu", "Hao Su"], "Categories": "cs.CV cs.AI cs.GR"}, "abstract": "Recent advancements in open-world 3D object generation have been remarkable, with image-to-3D methods offering superior fine-grained control over their text-to-3D counterparts. However, most existing models fall short in simultaneously providing rapid generation speeds and high fidelity to input images - two features essential for practical applications. In this paper, we present One-2-3-45++, an innovative method that transforms a single image into a detailed 3D textured mesh in approximately one minute. Our approach aims to fully harness the extensive knowledge embedded in 2D diffusion models and priors from valuable yet limited 3D data. This is achieved by initially finetuning a 2D diffusion model for consistent multi-view image generation, followed by elevating these images to 3D with the aid of multi-view conditioned 3D native diffusion models. Extensive experimental evaluations demonstrate that our method can produce high-quality, diverse 3D assets that closely mirror the original input image. Our project webpage: https://sudo-ai-3d.github.io/One2345plus_page.", "url": "https://arxiv.org/abs/2311.07885"}, {"metadata": {"arXiv": "2311.07955", "Date": "Tue, 14 Nov 2023 07:20:38 ", "Title": "Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle Imagery: Review and Experimental Comparisons", "Authors": ["Chenjie Zhao", "Ryan Wen Liu", "Jingxiang Qu", "Ruobin Gao"], "Categories": "cs.CV cs.AI", "Comments": ["31 pages", "16 figures"]}, "abstract": "With the advancement of maritime unmanned aerial vehicles (UAVs) and deep learning technologies, the application of UAV-based object detection has become increasingly significant in the fields of maritime industry and ocean engineering. Endowed with intelligent sensing capabilities, the maritime UAVs enable effective and efficient maritime surveillance. To further promote the development of maritime UAV-based object detection, this paper provides a comprehensive review of challenges, relative methods, and UAV aerial datasets. Specifically, in this work, we first briefly summarize four challenges for object detection on maritime UAVs, i.e., object feature diversity, device limitation, maritime environment variability, and dataset scarcity. We then focus on computational methods to improve maritime UAV-based object detection performance in terms of scale-aware, small object detection, view-aware, rotated object detection, lightweight methods, and others. Next, we review the UAV aerial image/video datasets and propose a maritime UAV aerial dataset named MS2ship for ship detection. Furthermore, we conduct a series of experiments to present the performance evaluation and robustness analysis of object detection methods on maritime datasets. Eventually, we give the discussion and outlook on future works for maritime UAV-based object detection. The MS2ship dataset is available at \\href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}.", "url": "https://arxiv.org/abs/2311.07955"}, {"metadata": {"arXiv": "2311.08077", "Date": "Tue, 14 Nov 2023 11:05:08 ", "Title": "Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)", "Authors": ["Virmarie Maquiling", "Sean Anthony Byrne", "Diederick C. Niehorster", "Marcus Nystr\\\"om", "Enkelejda Kasneci"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["14 pages", "8 figures", "1 table", "submitted to ETRA 2024: ACM Symposium on Eye Tracking Research & Applications"]}, "abstract": "The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image segmentation. In this study, we evaluate SAM's ability to segment features from eye images recorded in virtual reality setups. The increasing requirement for annotated eye-image datasets presents a significant opportunity for SAM to redefine the landscape of data annotation in gaze estimation. Our investigation centers on SAM's zero-shot learning abilities and the effectiveness of prompts like bounding boxes or point clicks. Our results are consistent with studies in other domains, demonstrating that SAM's segmentation effectiveness can be on-par with specialized models depending on the feature, with prompts improving its performance, evidenced by an IoU of 93.34% for pupil segmentation in one dataset. Foundation models like SAM could revolutionize gaze estimation by enabling quick and easy image segmentation, reducing reliance on specialized models and extensive manual annotation.", "url": "https://arxiv.org/abs/2311.08077"}, {"metadata": {"arXiv": "2311.08265", "Date": "Tue, 14 Nov 2023 16:00:29 ", "Title": "On The Relationship Between Universal Adversarial Attacks And Sparse Representations", "Authors": ["Dana Weitzner and Raja Giryes"], "Categories": "cs.CV cs.AI", "DOI": "10.1109/OJSP.2023.3244486"}, "abstract": "The prominent success of neural networks, mainly in computer vision tasks, is increasingly shadowed by their sensitivity to small, barely perceivable adversarial perturbations in image input. In this work, we aim at explaining this vulnerability through the framework of sparsity. We show the connection between adversarial attacks and sparse representations, with a focus on explaining the universality and transferability of adversarial examples in neural networks. To this end, we show that sparse coding algorithms, and the neural network-based learned iterative shrinkage thresholding algorithm (LISTA) among them, suffer from this sensitivity, and that common attacks on neural networks can be expressed as attacks on the sparse representation of the input image. The phenomenon that we observe holds true also when the network is agnostic to the sparse representation and dictionary, and thus can provide a possible explanation for the universality and transferability of adversarial attacks. The code is available at https://github.com/danawr/adversarial_attacks_and_sparse_representations.", "url": "https://arxiv.org/abs/2311.08265"}, {"metadata": {"arXiv": "2311.07822", "Date": "Tue, 14 Nov 2023 00:49:12 ", "Title": "A Neuro-Inspired Hierarchical Reinforcement Learning for Motor Control", "Authors": ["Pei Zhang", "Zhaobo Hua", "Jinliang Ding"], "Categories": "cs.RO cs.AI"}, "abstract": "Designing controllers to achieve natural motion capabilities for multi-joint robots is a significant challenge. However, animals in nature are naturally with basic motor abilities and can master various complex motor skills through acquired learning. On the basis of analyzing the mechanism of the central motor system in mammals, we propose a neuro-inspired hierarchical reinforcement learning algorithm that enables robots to learn rich motor skills and apply them to complex task environments without relying on external data. We first design a skills network similar to the cerebellum by utilizing the selection mechanism of voluntary movements in the basal ganglia and the regulatory ability of the cerebellum to regulate movement. Subsequently, by imitating the structure of advanced centers in the motion system, we propose a high-level policy to generate different skill combinations, thereby enabling the robot to acquire natural motor abilities. We conduct experiments on 4 types of robots and 22 task environments, and the results show that the proposed method can enable different types of robots to achieve flexible motion skills. Overall, our research provides a promising framework for the design of robotic neural motor controllers.", "url": "https://arxiv.org/abs/2311.07822"}, {"metadata": {"arXiv": "2311.07992", "Date": "Tue, 14 Nov 2023 08:45:32 ", "Title": "Probable Object Location (POLo) Score Estimation for Efficient Object Goal Navigation", "Authors": ["Jiaming Wang and Harold Soh"], "Categories": "cs.RO cs.AI", "Comments": ["Under review"]}, "abstract": "To advance the field of autonomous robotics, particularly in object search tasks within unexplored environments, we introduce a novel framework centered around the Probable Object Location (POLo) score. Utilizing a 3D object probability map, the POLo score allows the agent to make data-driven decisions for efficient object search. We further enhance the framework's practicality by introducing POLoNet, a neural network trained to approximate the computationally intensive POLo score. Our approach addresses critical limitations of both end-to-end reinforcement learning methods, which suffer from memory decay over long-horizon tasks, and traditional map-based methods that neglect visibility constraints. Our experiments, involving the first phase of the OVMM 2023 challenge, demonstrate that an agent equipped with POLoNet significantly outperforms a range of baseline methods, including end-to-end RL techniques and prior map-based strategies. To provide a comprehensive evaluation, we introduce new performance metrics that offer insights into the efficiency and effectiveness of various agents in object goal navigation.", "url": "https://arxiv.org/abs/2311.07992"}, {"metadata": {"arXiv": "2311.08153", "Date": "Tue, 14 Nov 2023 13:29:01 ", "Title": "When Mining Electric Locomotives Meet Reinforcement Learning", "Authors": ["Ying Li", "Zhencai Zhu", "Xiaoqiang Li", "Chunyu Yang and Hao Lu"], "Categories": "eess.SY cs.AI cs.SY"}, "abstract": "As the most important auxiliary transportation equipment in coal mines, mining electric locomotives are mostly operated manually at present. However, due to the complex and ever-changing coal mine environment, electric locomotive safety accidents occur frequently these years. A mining electric locomotive control method that can adapt to different complex mining environments is needed. Reinforcement Learning (RL) is concerned with how artificial agents ought to take actions in an environment so as to maximize reward, which can help achieve automatic control of mining electric locomotive. In this paper, we present how to apply RL to the autonomous control of mining electric locomotives. To achieve more precise control, we further propose an improved epsilon-greedy (IEG) algorithm which can better balance the exploration and exploitation. To verify the effectiveness of this method, a co-simulation platform for autonomous control of mining electric locomotives is built which can complete closed-loop simulation of the vehicles. The simulation results show that this method ensures the locomotives following the front vehicle safely and responding promptly in the event of sudden obstacles on the road when the vehicle in complex and uncertain coal mine environments.", "url": "https://arxiv.org/abs/2311.08153"}, {"metadata": {"arXiv": "2311.07595", "Date": "Fri, 10 Nov 2023 10:21:09 ", "Title": "A Decision Support System for Liver Diseases Prediction: Integrating Batch Processing, Rule-Based Event Detection and SPARQL Query", "Authors": ["Ritesh Chandra", "Sadhana Tiwari", "Satyam Rastogi", "Sonali Agarwal"], "Categories": "cs.AI cs.LG"}, "abstract": "Liver diseases pose a significant global health burden, impacting a substantial number of individuals and exerting substantial economic and social consequences. Rising liver problems are considered a fatal disease in many countries, such as Egypt, Molda, etc. The objective of this study is to construct a predictive model for liver illness using Basic Formal Ontology (BFO) and detection rules derived from a decision tree algorithm. Based on these rules, events are detected through batch processing using the Apache Jena framework. Based on the event detected, queries can be directly processed using SPARQL. To make the ontology operational, these Decision Tree (DT) rules are converted into Semantic Web Rule Language (SWRL). Using this SWRL in the ontology for predicting different types of liver disease with the help of the Pellet and Drool inference engines in Protege Tools, a total of 615 records are taken from different liver diseases. After inferring the rules, the result can be generated for the patient according to the DT rules, and other patient-related details along with different precautionary suggestions can be obtained based on these results. Combining query results of batch processing and ontology-generated results can give more accurate suggestions for disease prevention and detection. This work aims to provide a comprehensive approach that is applicable for liver disease prediction, rich knowledge graph representation, and smart querying capabilities. The results show that combining RDF data, SWRL rules, and SPARQL queries for analysing and predicting liver disease can help medical professionals to learn more about liver diseases and make a Decision Support System (DSS) for health care.", "url": "https://arxiv.org/abs/2311.07595"}, {"metadata": {"arXiv": "2311.07607", "Date": "Sat, 11 Nov 2023 11:13:07 ", "Title": "Modeling Choice via Self-Attention", "Authors": ["Joohwan Ko", "Andrew A. Li"], "Categories": "cs.AI cs.LG"}, "abstract": "Models of choice are a fundamental input to many now-canonical optimization problems in the field of Operations Management, including assortment, inventory, and price optimization. Naturally, accurate estimation of these models from data is a critical step in the application of these optimization problems in practice, and so it is perhaps surprising that such choice estimation has to now been accomplished almost exclusively, both in theory and in practice, (a) without the use of deep learning in any meaningful way, and (b) via evaluation on limited data with constantly-changing metrics. This is in stark contrast to the vast majority of similar learning applications, for which the practice of machine learning suggests that (a) neural network-based models are typically state-of-the-art, and (b) strict standardization on evaluation procedures (datasets, metrics, etc.) is crucial. Thus motivated, we first propose a choice model that is the first to successfully (both theoretically and practically) leverage a modern neural network architectural concept (self-attention). Theoretically, we show that our attention-based choice model is a low-rank generalization of the Halo Multinomial Logit model, a recent model that parsimoniously captures irrational choice effects and has seen empirical success. We prove that whereas the Halo-MNL requires $\\Omega(m^2)$ data samples to estimate, where $m$ is the number of products, our model supports a natural nonconvex estimator (in particular, that which a standard neural network implementation would apply) which admits a near-optimal stationary point with $O(m)$ samples. We then establish the first realistic-scale benchmark for choice estimation on real data and use this benchmark to run the largest evaluation of existing choice models to date. We find that the model we propose is dominant over both short-term and long-term data periods.", "url": "https://arxiv.org/abs/2311.07607"}, {"metadata": {"arXiv": "2311.07708", "Date": "Mon, 13 Nov 2023 19:46:22 ", "Title": "Reinforcement Learning for Solving Stochastic Vehicle Routing Problem", "Authors": ["Zangir Iklassov", "Ikboljon Sobirov", "Ruben Solozabal", "Martin Takac"], "Categories": "cs.AI cs.CE cs.LG", "Comments": ["14 pages", "accepted to ACML24"]}, "abstract": "This study addresses a gap in the utilization of Reinforcement Learning (RL) and Machine Learning (ML) techniques in solving the Stochastic Vehicle Routing Problem (SVRP) that involves the challenging task of optimizing vehicle routes under uncertain conditions. We propose a novel end-to-end framework that comprehensively addresses the key sources of stochasticity in SVRP and utilizes an RL agent with a simple yet effective architecture and a tailored training method. Through comparative analysis, our proposed model demonstrates superior performance compared to a widely adopted state-of-the-art metaheuristic, achieving a significant 3.43% reduction in travel costs. Furthermore, the model exhibits robustness across diverse SVRP settings, highlighting its adaptability and ability to learn optimal routing strategies in varying environments. The publicly available implementation of our framework serves as a valuable resource for future research endeavors aimed at advancing RL-based solutions for SVRP.", "url": "https://arxiv.org/abs/2311.07708"}, {"metadata": {"arXiv": "2311.07723", "Date": "Mon, 13 Nov 2023 20:07:36 ", "Title": "Generalization Analogies (GENIES): A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains", "Authors": ["Joshua Clymer", "Garrett Baker", "Rohan Subramani", "Sam Wang"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Code: https://github.com/Joshuaclymer/GENIES Website: https://joshuaclymer.github.io/generalization-analogies-website/"]}, "abstract": "As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable. To better understand how reward models generalize, we craft 69 distribution shifts spanning 8 categories. We find that reward models do not learn to evaluate `instruction-following' by default and instead favor personas that resemble internet text. Techniques for interpreting reward models' internal representations achieve better generalization than standard fine-tuning, but still frequently fail to distinguish instruction-following from conflated behaviors. We consolidate the 15 most challenging distribution shifts into the GENaralization analogIES (GENIES) benchmark, which we hope will enable progress toward controlling reward model generalization.", "url": "https://arxiv.org/abs/2311.07723"}, {"metadata": {"arXiv": "2311.08022", "Date": "Tue, 14 Nov 2023 09:32:02 ", "Title": "Two-Stage Predict+Optimize for Mixed Integer Linear Programs with Unknown Parameters in Constraints", "Authors": ["Xinyi Hu", "Jasper C.H. Lee", "Jimmy H.M. Lee"], "Categories": "cs.AI cs.LG"}, "abstract": "Consider the setting of constrained optimization, with some parameters unknown at solving time and requiring prediction from relevant features. Predict+Optimize is a recent framework for end-to-end training supervised learning models for such predictions, incorporating information about the optimization problem in the training process in order to yield better predictions in terms of the quality of the predicted solution under the true parameters. Almost all prior works have focused on the special case where the unknowns appear only in the optimization objective and not the constraints. Hu et al.~proposed the first adaptation of Predict+Optimize to handle unknowns appearing in constraints, but the framework has somewhat ad-hoc elements, and they provided a training algorithm only for covering and packing linear programs. In this work, we give a new \\emph{simpler} and \\emph{more powerful} framework called \\emph{Two-Stage Predict+Optimize}, which we believe should be the canonical framework for the Predict+Optimize setting. We also give a training algorithm usable for all mixed integer linear programs, vastly generalizing the applicability of the framework. Experimental results demonstrate the superior prediction performance of our training framework over all classical and state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.08022"}, {"metadata": {"arXiv": "2311.08083", "Date": "Tue, 14 Nov 2023 11:10:46 ", "Title": "Solving ARC visual analogies with neural embeddings and vector arithmetic: A generalized method", "Authors": ["Luca H. Thoms", "Karel A. Veldkamp", "Hannes Rosenbusch and Claire E. Stevenson"], "Categories": "cs.AI cs.CV cs.LG", "Comments": ["Data and code can be found on https://github.com/foger3/ARC_DeepLearning"], "DOI": "10.17605/OSF.IO/AKP86"}, "abstract": "Analogical reasoning derives information from known relations and generalizes this information to similar yet unfamiliar situations. One of the first generalized ways in which deep learning models were able to solve verbal analogies was through vector arithmetic of word embeddings, essentially relating words that were mapped to a vector space (e.g., king - man + woman = __?). In comparison, most attempts to solve visual analogies are still predominantly task-specific and less generalizable. This project focuses on visual analogical reasoning and applies the initial generalized mechanism used to solve verbal analogies to the visual realm. Taking the Abstraction and Reasoning Corpus (ARC) as an example to investigate visual analogy solving, we use a variational autoencoder (VAE) to transform ARC items into low-dimensional latent vectors, analogous to the word embeddings used in the verbal approaches. Through simple vector arithmetic, underlying rules of ARC items are discovered and used to solve them. Results indicate that the approach works well on simple items with fewer dimensions (i.e., few colors used, uniform shapes), similar input-to-output examples, and high reconstruction accuracy on the VAE. Predictions on more complex items showed stronger deviations from expected outputs, although, predictions still often approximated parts of the item's rule set. Error patterns indicated that the model works as intended. On the official ARC paradigm, the model achieved a score of 2% (cf. current world record is 21%) and on ConceptARC it scored 8.8%. Although the methodology proposed involves basic dimensionality reduction techniques and standard vector arithmetic, this approach demonstrates promising outcomes on ARC and can easily be generalized to other abstract visual reasoning tasks.", "url": "https://arxiv.org/abs/2311.08083"}, {"metadata": {"arXiv": "2311.08166", "Date": "Tue, 14 Nov 2023 13:49:03 ", "Title": "MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge", "Authors": ["Bo Ni and Markus J. Buehler"], "Categories": "cs.AI cond-mat.dis-nn cond-mat.mtrl-sci cs.CL cs.LG"}, "abstract": "Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems.", "url": "https://arxiv.org/abs/2311.08166"}, {"metadata": {"arXiv": "2311.07578", "Date": "Wed, 04 Oct 2023 16:37:38 ", "Title": "A Metacognitive Approach to Out-of-Distribution Detection for Segmentation", "Authors": ["Meghna Gummadi", "Cassandra Kent", "Karl Schmeckpeper", "and Eric Eaton"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Despite outstanding semantic scene segmentation in closed-worlds, deep neural networks segment novel instances poorly, which is required for autonomous agents acting in an open world. To improve out-of-distribution (OOD) detection for segmentation, we introduce a metacognitive approach in the form of a lightweight module that leverages entropy measures, segmentation predictions, and spatial context to characterize the segmentation model's uncertainty and detect pixel-wise OOD data in real-time. Additionally, our approach incorporates a novel method of generating synthetic OOD data in context with in-distribution data, which we use to fine-tune existing segmentation models with maximum entropy training. This further improves the metacognitive module's performance without requiring access to OOD data while enabling compatibility with established pre-trained models. Our resulting approach can reliably detect OOD instances in a scene, as shown by state-of-the-art performance on OOD detection for semantic segmentation benchmarks.", "url": "https://arxiv.org/abs/2311.07578"}, {"metadata": {"arXiv": "2311.07750", "Date": "Mon, 13 Nov 2023 21:07:07 ", "Title": "SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification", "Authors": ["S.M. Nabil Ashraf", "Md. Adyelullahil Mamun", "Hasnat Md. Abdullah", "Md. Golam Rabiul Alam"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted in International Conference on Computer and Information Technology (ICCIT) 2023"]}, "abstract": "Chest X-rays are widely used to diagnose thoracic diseases, but the lack of detailed information about these abnormalities makes it challenging to develop accurate automated diagnosis systems, which is crucial for early detection and effective treatment. To address this challenge, we employed deep learning techniques to identify patterns in chest X-rays that correspond to different diseases. We conducted experiments on the \"ChestX-ray14\" dataset using various pre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical models. The best individual model was the CoAtNet, which achieved an area under the receiver operating characteristic curve (AUROC) of 84.2%. By combining the predictions of all trained models using a weighted average ensemble where the weight of each model was determined using differential evolution, we further improved the AUROC to 85.4%, outperforming other state-of-the-art methods in this field. Our findings demonstrate the potential of deep learning techniques, particularly ensemble deep learning, for improving the accuracy of automatic diagnosis of thoracic diseases from chest X-rays.", "url": "https://arxiv.org/abs/2311.07750"}, {"metadata": {"arXiv": "2311.07766", "Date": "Mon, 13 Nov 2023 21:32:37 ", "Title": "Vision-Language Integration in Multimodal Video Transformers (Partially) Aligns with the Brain", "Authors": ["Dota Tianai Dong and Mariya Toneva"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Integrating information from multiple modalities is arguably one of the essential prerequisites for grounding artificial intelligence systems with an understanding of the real world. Recent advances in video transformers that jointly learn from vision, text, and sound over time have made some progress toward this goal, but the degree to which these models integrate information from modalities still remains unclear. In this work, we present a promising approach for probing a pre-trained multimodal video transformer model by leveraging neuroscientific evidence of multimodal information processing in the brain. Using brain recordings of participants watching a popular TV show, we analyze the effects of multi-modal connections and interactions in a pre-trained multi-modal video transformer on the alignment with uni- and multi-modal brain regions. We find evidence that vision enhances masked prediction performance during language processing, providing support that cross-modal representations in models can benefit individual modalities. However, we don't find evidence of brain-relevant information captured by the joint multi-modal transformer representations beyond that captured by all of the individual modalities. We finally show that the brain alignment of the pre-trained joint representation can be improved by fine-tuning using a task that requires vision-language inferences. Overall, our results paint an optimistic picture of the ability of multi-modal transformers to integrate vision and language in partially brain-relevant ways but also show that improving the brain alignment of these models may require new approaches.", "url": "https://arxiv.org/abs/2311.07766"}, {"metadata": {"arXiv": "2311.07928", "Date": "Tue, 14 Nov 2023 06:13:52 ", "Title": "Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning", "Authors": ["Shashank Kotyan and Danilo Vasconcellos Vargas"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Neural networks have revolutionized various domains, exhibiting remarkable accuracy in tasks like natural language processing and computer vision. However, their vulnerability to slight alterations in input samples poses challenges, particularly in safety-critical applications like autonomous driving. Current approaches, such as introducing distortions during training, fall short in addressing unforeseen corruptions. This paper proposes an innovative adversarial contrastive learning framework to enhance neural network robustness simultaneously against adversarial attacks and common corruptions. By generating instance-wise adversarial examples and optimizing contrastive loss, our method fosters representations that resist adversarial perturbations and remain robust in real-world scenarios. Subsequent contrastive learning then strengthens the similarity between clean samples and their adversarial counterparts, fostering representations resistant to both adversarial attacks and common distortions. By focusing on improving performance under adversarial and real-world conditions, our approach aims to bolster the robustness of neural networks in safety-critical applications, such as autonomous vehicles navigating unpredictable weather conditions. We anticipate that this framework will contribute to advancing the reliability of neural networks in challenging environments, facilitating their widespread adoption in mission-critical scenarios.", "url": "https://arxiv.org/abs/2311.07928"}, {"metadata": {"arXiv": "2311.08094", "Date": "Tue, 14 Nov 2023 11:38:38 ", "Title": "Act-VIT: A Representationally Robust Attention Architecture for Skeleton Based Action Recognition Using Vision Transformer", "Authors": ["Ozge Oztimur Karadag"], "Categories": "cs.CV cs.AI cs.LG cs.RO"}, "abstract": "Skeleton-based action recognition receives the attention of many researchers as it is robust to viewpoint and illumination changes, and its processing is much more efficient than video frames. With the emergence of deep learning models, it has become very popular to represent the skeleton data in pseudo-image form and apply Convolutional Neural Networks for action recognition. Thereafter, studies concentrated on finding effective methods for forming pseudo-images. Recently, attention networks, more specifically transformers have provided promising results in various vision problems. In this study, the effectiveness of vision transformers for skeleton-based action recognition is examined and its robustness on the pseudo-image representation scheme is investigated. To this end, a three-level architecture, Act-VIT is proposed, which forms a set of pseudo images apply a classifier on each of the representation and combine their results to find the final action class. The classifiers of Act-VIT are first realized by CNNs and then by VITs and their performances are compared. Experimental studies reveal that the vision transformer is less sensitive to the initial pseudo-image representation compared to CNN. Nevertheless, even with the vision transformer, the recognition performance can be further improved by consensus of classifiers.", "url": "https://arxiv.org/abs/2311.08094"}, {"metadata": {"arXiv": "2311.08148", "Date": "Tue, 14 Nov 2023 13:25:41 ", "Title": "Cattle Identification Using Muzzle Images and Deep Learning Techniques", "Authors": ["G. N. Kimani", "P. Oluwadara", "P. Fashingabo", "M. Busogi", "E. Luhanga", "K. Sowon", "L. Chacha ((1) CyLab-Africa / Upanzi Network", "(2) Carnegie Mellon University Africa and (3) Carnegie Mellon University Pittsburgh)"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "4 figures", "2 tables"]}, "abstract": "Traditional animal identification methods such as ear-tagging, ear notching, and branding have been effective but pose risks to the animal and have scalability issues. Electrical methods offer better tracking and monitoring but require specialized equipment and are susceptible to attacks. Biometric identification using time-immutable dermatoglyphic features such as muzzle prints and iris patterns is a promising solution. This project explores cattle identification using 4923 muzzle images collected from 268 beef cattle. Two deep learning classification models are implemented - wide ResNet50 and VGG16\\_BN and image compression is done to lower the image quality and adapt the models to work for the African context. From the experiments run, a maximum accuracy of 99.5\\% is achieved while using the wide ResNet50 model with a compression retaining 25\\% of the original image. From the study, it is noted that the time required by the models to train and converge as well as recognition time are dependent on the machine used to run the model.", "url": "https://arxiv.org/abs/2311.08148"}, {"metadata": {"arXiv": "2311.08393", "Date": "Tue, 14 Nov 2023 18:53:28 ", "Title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable Trajectory Generation", "Authors": ["Ehsan Asali", "Prashant Doshi", "Jin Sun"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["Conference on Robot Learning 2023 (CoRL2023)"]}, "abstract": "The learn-from-observation (LfO) paradigm is a human-inspired mode for a robot to learn to perform a task simply by watching it being performed. LfO can facilitate robot integration on factory floors by minimizing disruption and reducing tedious programming. A key component of the LfO pipeline is a transformation of the depth camera frames to the corresponding task state and action pairs, which are then relayed to learning techniques such as imitation or inverse reinforcement learning for understanding the task parameters. While several existing computer vision models analyze videos for activity recognition, SA-Net specifically targets robotic LfO from RGB-D data. However, SA-Net and many other models analyze frame data captured from a single viewpoint. Their analysis is therefore highly sensitive to occlusions of the observed task, which are frequent in deployments. An obvious way of reducing occlusions is to simultaneously observe the task from multiple viewpoints and synchronously fuse the multiple streams in the model. Toward this, we present multi-view SA-Net, which generalizes the SA-Net model to allow the perception of multiple viewpoints of the task activity, integrate them, and better recognize the state and action in each frame. Performance evaluations on two distinct domains establish that MVSA-Net recognizes the state-action pairs under occlusion more accurately compared to single-view MVSA-Net and other baselines. Our ablation studies further evaluate its performance under different ambient conditions and establish the contribution of the architecture components. As such, MVSA-Net offers a significantly more robust and deployable state-action trajectory generation compared to previous methods.", "url": "https://arxiv.org/abs/2311.08393"}, {"metadata": {"arXiv": "2311.08403", "Date": "Tue, 14 Nov 2023 18:59:59 ", "Title": "Instant3D: Instant Text-to-3D Generation", "Authors": ["Ming Li", "Pan Zhou", "Jia-Wei Liu", "Jussi Keppo", "Min Lin", "Shuicheng Yan", "Xiangyu Xu"], "Categories": "cs.CV cs.AI cs.GR cs.LG cs.MM", "Comments": ["Project page: https://ming1993li.github.io/Instant3DProj"]}, "abstract": "Text-to-3D generation, which aims to synthesize vivid 3D objects from text prompts, has attracted much attention from the computer vision community. While several existing works have achieved impressive results for this task, they mainly rely on a time-consuming optimization paradigm. Specifically, these methods optimize a neural field from scratch for each text prompt, taking approximately one hour or more to generate one object. This heavy and repetitive training cost impedes their practical deployment. In this paper, we propose a novel framework for fast text-to-3D generation, dubbed Instant3D. Once trained, Instant3D is able to create a 3D object for an unseen text prompt in less than one second with a single run of a feedforward network. We achieve this remarkable speed by devising a new network that directly constructs a 3D triplane from a text prompt. The core innovation of our Instant3D lies in our exploration of strategies to effectively inject text conditions into the network. Furthermore, we propose a simple yet effective activation function, the scaled-sigmoid, to replace the original sigmoid function, which speeds up the training convergence by more than ten times. Finally, to address the Janus (multi-head) problem in 3D generation, we propose an adaptive Perp-Neg algorithm that can dynamically adjust its concept negation scales according to the severity of the Janus problem during training, effectively reducing the multi-head effect. Extensive experiments on a wide variety of benchmark datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods both qualitatively and quantitatively, while achieving significantly better efficiency. The project page is at https://ming1993li.github.io/Instant3DProj.", "url": "https://arxiv.org/abs/2311.08403"}, {"metadata": {"arXiv": "2311.07579", "Date": "Tue, 10 Oct 2023 10:41:45 ", "Title": "Relative intrinsic dimensionality is intrinsic to learning", "Authors": ["Oliver J. Sutton", "Qinghua Zhou", "Alexander N. Gorban and Ivan Y. Tyukin"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "5 figures"], "MSC-class": "68T09, 68T10", "Journal-ref": "Artificial Neural Networks and Machine Learning ICANN 2023. Lecture Notes in Computer Science, vol 14254, pp 516-529. Springer, Cham", "DOI": "10.1007/978-3-031-44207-0_43"}, "abstract": "High dimensional data can have a surprising property: pairs of data points may be easily separated from each other, or even from arbitrary subsets, with high probability using just simple linear classifiers. However, this is more of a rule of thumb than a reliable property as high dimensionality alone is neither necessary nor sufficient for successful learning. Here, we introduce a new notion of the intrinsic dimension of a data distribution, which precisely captures the separability properties of the data. For this intrinsic dimension, the rule of thumb above becomes a law: high intrinsic dimension guarantees highly separable data. We extend this notion to that of the relative intrinsic dimension of two data distributions, which we show provides both upper and lower bounds on the probability of successfully learning and generalising in a binary classification problem", "url": "https://arxiv.org/abs/2311.07579"}, {"metadata": {"arXiv": "2311.07597", "Date": "Fri, 10 Nov 2023 12:06:23 ", "Title": "Enhancing Actuarial Non-Life Pricing Models via Transformers", "Authors": ["Alexej Brauer"], "Categories": "cs.LG cs.AI q-fin.ST stat.AP", "MSC-class": "62 68"}, "abstract": "Currently, there is a lot of research in the field of neural networks for non-life insurance pricing. The usual goal is to improve the predictive power via neural networks while building upon the generalized linear model, which is the current industry standard. Our paper contributes to this current journey via novel methods to enhance actuarial non-life models with transformer models for tabular data. We build here upon the foundation laid out by the combined actuarial neural network as well as the localGLMnet and enhance those models via the feature tokenizer transformer. The manuscript demonstrates the performance of the proposed methods on a real-world claim frequency dataset and compares them with several benchmark models such as generalized linear models, feed-forward neural networks, combined actuarial neural networks, LocalGLMnet, and pure feature tokenizer transformer. The paper shows that the new methods can achieve better results than the benchmark models while preserving certain generalized linear model advantages. The paper also discusses the practical implications and challenges of applying transformer models in actuarial settings.", "url": "https://arxiv.org/abs/2311.07597"}, {"metadata": {"arXiv": "2311.07604", "Date": "Sat, 11 Nov 2023 05:40:54 ", "Title": "Finetuning Text-to-Image Diffusion Models for Fairness", "Authors": ["Xudong Shen", "Chao Du", "Tianyu Pang", "Min Lin", "Yongkang Wong", "Mohan Kankanhalli"], "Categories": "cs.LG cs.AI cs.CV cs.CY", "Comments": ["preprint under review"]}, "abstract": "The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a distorted worldview and limit opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) biased direct finetuning of diffusion model's sampling process, which leverages a biased gradient to more effectively optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a $75\\%$ young and $25\\%$ old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We hope our work facilitates the social alignment of T2I generative AI. We will share code and various debiased diffusion model adaptors.", "url": "https://arxiv.org/abs/2311.07604"}, {"metadata": {"arXiv": "2311.07608", "Date": "Sat, 11 Nov 2023 11:14:07 ", "Title": "MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital Readmission Prediction", "Authors": ["Yan Miao", "Lequan Yu"], "Categories": "cs.LG cs.AI"}, "abstract": "Hospital readmission prediction is considered an essential approach to decreasing readmission rates, which is a key factor in assessing the quality and efficacy of a healthcare system. Previous studies have extensively utilized three primary modalities, namely electronic health records (EHR), medical images, and clinical notes, to predict hospital readmissions. However, the majority of these studies did not integrate information from all three modalities or utilize the spatiotemporal relationships present in the dataset. This study introduces a novel model called the Multimodal Spatiotemporal Graph-Transformer (MuST) for predicting hospital readmissions. By employing Graph Convolution Networks and temporal transformers, we can effectively capture spatial and temporal dependencies in EHR and chest radiographs. We then propose a fusion transformer to combine the spatiotemporal features from the two modalities mentioned above with the features from clinical notes extracted by a pre-trained, domain-specific transformer. We assess the effectiveness of our methods using the latest publicly available dataset, MIMIC-IV. The experimental results indicate that the inclusion of multimodal features in MuST improves its performance in comparison to unimodal methods. Furthermore, our proposed pipeline outperforms the current leading methods in the prediction of hospital readmissions.", "url": "https://arxiv.org/abs/2311.07608"}, {"metadata": {"arXiv": "2311.07618", "Date": "Sun, 12 Nov 2023 07:52:32 ", "Title": "Large Language Models' Understanding of Math: Source Criticism and Extrapolation", "Authors": ["Roozbeh Yousefzadeh and Xuenan Cao"], "Categories": "cs.LG cs.AI cs.CL math.HO"}, "abstract": "It has been suggested that large language models such as GPT-4 have acquired some form of understanding beyond the correlations among the words in text including some understanding of mathematics as well. Here, we perform a critical inquiry into this claim by evaluating the mathematical understanding of the GPT-4 model. Considering that GPT-4's training set is a secret, it is not straightforward to evaluate whether the model's correct answers are based on a mathematical understanding or based on replication of proofs that the model has seen before. We specifically craft mathematical questions which their formal proofs are not readily available on the web, proofs that are more likely not seen by the GPT-4. We see that GPT-4 is unable to solve those problems despite their simplicity. It is hard to find scientific evidence suggesting that GPT-4 has acquired an understanding of even basic mathematical concepts. A straightforward way to find failure modes of GPT-4 in theorem proving is to craft questions where their formal proofs are not available on the web. Our finding suggests that GPT-4's ability is to reproduce, rephrase, and polish the mathematical proofs that it has seen before, and not in grasping mathematical concepts. We also see that GPT-4's ability to prove mathematical theorems is continuously expanding over time despite the claim that it is a fixed model. We suggest that the task of proving mathematical theorems in formal language is comparable to the methods used in search engines such as Google while predicting the next word in a sentence may be a misguided approach, a recipe that often leads to excessive extrapolation and eventual failures. Prompting the GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question whether it is valuable for machine learning or for theorem proving.", "url": "https://arxiv.org/abs/2311.07618"}, {"metadata": {"arXiv": "2311.07632", "Date": "Mon, 13 Nov 2023 13:16:35 ", "Title": "ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering", "Authors": ["Zecheng Yin"], "Categories": "cs.LG cs.AI q-bio.MN", "Comments": ["In progress"]}, "abstract": "Biomedical information graphs are crucial for interaction discovering of biomedical information in modern age, such as identification of multifarious molecular interactions and drug discovery, which attracts increasing interests in biomedicine, bioinformatics, and human healthcare communities. Nowadays, more and more graph neural networks have been proposed to learn the entities of biomedical information and precisely reveal biomedical molecule interactions with state-of-the-art results. These methods remedy the fading of features from a far distance but suffer from remedying such problem at the expensive cost of redundant memory and time. In our paper, we propose a novel Residual Message Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction prediction in a different idea. Specifically, instead of enhancing the message from far nodes, ResMGCN aggregates lower-order information with the next round higher information to guide the node update to obtain a more meaningful node representation. ResMGCN is able to perceive and preserve various messages from the previous layer and high-order information in the current layer with least memory and time cost to obtain informative representations of biomedical entities. We conduct experiments on four biomedical interaction network datasets, including protein-protein, drug-drug, drug-target, and gene-disease interactions, which demonstrates that ResMGCN outperforms previous state-of-the-art models while achieving superb effectiveness on both storage and time.", "url": "https://arxiv.org/abs/2311.07632"}, {"metadata": {"arXiv": "2311.07633", "Date": "Mon, 13 Nov 2023 13:19:34 ", "Title": "Rethinking and Benchmarking Predict-then-Optimize Paradigm for Combinatorial Optimization Problems", "Authors": ["Haoyu Geng", "Han Ruan", "Runzhong Wang", "Yang Li", "Yang Wang", "Lei Chen", "Junchi Yan"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "Numerous web applications rely on solving combinatorial optimization problems, such as energy cost-aware scheduling, budget allocation on web advertising, and graph matching on social networks. However, many optimization problems involve unknown coefficients, and improper predictions of these factors may lead to inferior decisions which may cause energy wastage, inefficient resource allocation, inappropriate matching in social networks, etc. Such a research topic is referred to as \"Predict-Then-Optimize (PTO)\" which considers the performance of prediction and decision-making in a unified system. A noteworthy recent development is the end-to-end methods by directly optimizing the ultimate decision quality which claims to yield better results in contrast to the traditional two-stage approach. However, the evaluation benchmarks in this field are fragmented and the effectiveness of various models in different scenarios remains unclear, hindering the comprehensive assessment and fast deployment of these methods. To address these issues, we provide a comprehensive categorization of current approaches and integrate existing experimental scenarios to establish a unified benchmark, elucidating the circumstances under which end-to-end training yields improvements, as well as the contexts in which it performs ineffectively. We also introduce a new dataset for the industrial combinatorial advertising problem for inclusive finance to open-source. We hope the rethinking and benchmarking of PTO could facilitate more convenient evaluation and deployment, and inspire further improvements both in the academy and industry within this field.", "url": "https://arxiv.org/abs/2311.07633"}, {"metadata": {"arXiv": "2311.07692", "Date": "Mon, 13 Nov 2023 19:21:25 ", "Title": "On The Truthfulness of 'Surprisingly Likely' Responses of Large Language Models", "Authors": ["Naman Goel"], "Categories": "cs.LG cs.AI cs.CL cs.GT"}, "abstract": "The surprisingly likely criterion in the seminal work of Prelec (the Bayesian Truth Serum) guarantees truthfulness in a game-theoretic multi-agent setting, by rewarding rational agents to maximise the expected information gain with their answers w.r.t. their probabilistic beliefs. We investigate the relevance of a similar criterion for responses of LLMs. We hypothesize that if the surprisingly likely criterion works in LLMs, under certain conditions, the responses that maximize the reward under this criterion should be more accurate than the responses that only maximize the posterior probability. Using benchmarks including the TruthfulQA benchmark and using openly available LLMs: GPT-2 and LLaMA-2, we show that the method indeed improves the accuracy significantly (for example, upto 24 percentage points aggregate improvement on TruthfulQA and upto 70 percentage points improvement on individual categories of questions).", "url": "https://arxiv.org/abs/2311.07692"}, {"metadata": {"arXiv": "2311.07705", "Date": "Mon, 13 Nov 2023 19:42:33 ", "Title": "Robust and Scalable Hyperdimensional Computing With Brain-Like Neural Adaptations", "Authors": ["Junyao Wang", "Mohammad Abdullah Al Faruque"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2304.05503"]}, "abstract": "The Internet of Things (IoT) has facilitated many applications utilizing edge-based machine learning (ML) methods to analyze locally collected data. Unfortunately, popular ML algorithms often require intensive computations beyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional computing (HDC) has been introduced to address this issue. However, existing HDCs use static encoders, requiring extremely high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a huge efficiency loss, severely impeding the application of HDCs in IoT systems. We observed that a main cause is that the encoding module of existing HDCs lacks the capability to utilize and adapt to information learned during training. In contrast, neurons in human brains dynamically regenerate all the time and provide more useful functionalities when learning new information. While the goal of HDC is to exploit the high-dimensionality of randomly generated base hypervectors to represent the information as a pattern of neural activity, it remains challenging for existing HDCs to support a similar behavior as brain neural regeneration. In this work, we present dynamic HDC learning frameworks that identify and regenerate undesired dimensions to provide adequate accuracy with significantly lowered dimensionalities, thereby accelerating both the training and inference.", "url": "https://arxiv.org/abs/2311.07705"}, {"metadata": {"arXiv": "2311.07763", "Date": "Mon, 13 Nov 2023 21:26:24 ", "Title": "The Disagreement Problem in Faithfulness Metrics", "Authors": ["Brian Barr", "Noah Fatsi", "Leif Hancox-Li", "Peter Richter", "Daniel Proano", "and Caleb Mok"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages (excluding refs and appendix)"]}, "abstract": "The field of explainable artificial intelligence (XAI) aims to explain how black-box machine learning models work. Much of the work centers around the holy grail of providing post-hoc feature attributions to any model architecture. While the pace of innovation around novel methods has slowed down, the question remains of how to choose a method, and how to make it fit for purpose. Recently, efforts around benchmarking XAI methods have suggested metrics for that purpose -- but there are many choices. That bounty of choice still leaves an end user unclear on how to proceed. This paper focuses on comparing metrics with the aim of measuring faithfulness of local explanations on tabular classification problems -- and shows that the current metrics don't agree; leaving users unsure how to choose the most faithful explanations.", "url": "https://arxiv.org/abs/2311.07763"}, {"metadata": {"arXiv": "2311.07868", "Date": "Tue, 14 Nov 2023 02:57:37 ", "Title": "Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography", "Authors": ["Young-Seok Kweon", "Gi-Hwan Shin", "Heon-Gyu Kwak", "Ha-Na Jo", "Seong-Whan Lee"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["Proc. 12th IEEE International Winter Conference on Brain-Computer Interface"]}, "abstract": "Polysomnography (PSG) is an indispensable diagnostic tool in sleep medicine, essential for identifying various sleep disorders. By capturing physiological signals, including EEG, EOG, EMG, and cardiorespiratory metrics, PSG presents a patient's sleep architecture. However, its dependency on complex equipment and expertise confines its use to specialized clinical settings. Addressing these limitations, our study aims to perform PSG by developing a system that requires only a single EEG measurement. We propose a novel system capable of reconstructing multi-signal PSG from a single-channel EEG based on a masked autoencoder. The masked autoencoder was trained and evaluated using the Sleep-EDF-20 dataset, with mean squared error as the metric for assessing the similarity between original and reconstructed signals. The model demonstrated proficiency in reconstructing multi-signal data. Our results present promise for the development of more accessible and long-term sleep monitoring systems. This suggests the expansion of PSG's applicability, enabling its use beyond the confines of clinics.", "url": "https://arxiv.org/abs/2311.07868"}, {"metadata": {"arXiv": "2311.07876", "Date": "Tue, 14 Nov 2023 03:12:43 ", "Title": "Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback", "Authors": ["Canzhe Zhao", "Ruofeng Yang", "Baoxiang Wang", "Xuezhou Zhang", "Shuai Li"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "In this work, we study the low-rank MDPs with adversarially changed losses in the full-information feedback setting. In particular, the unknown transition probability kernel admits a low-rank matrix decomposition \\citep{REPUCB22}, and the loss functions may change adversarially but are revealed to the learner at the end of each episode. We propose a policy optimization-based algorithm POLO, and we prove that it attains the $\\widetilde{O}(K^{\\frac{5}{6}}A^{\\frac{1}{2}}d\\ln(1+M)/(1-\\gamma)^2)$ regret guarantee, where $d$ is rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\\gamma$ is the discounted factor. Notably, our algorithm is oracle-efficient and has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\\Omega(\\frac{\\gamma^2}{1-\\gamma} \\sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses.", "url": "https://arxiv.org/abs/2311.07876"}, {"metadata": {"arXiv": "2311.08005", "Date": "Tue, 14 Nov 2023 09:03:33 ", "Title": "Iterative missing value imputation based on feature importance", "Authors": ["Cong Guo", "Chun Liu", "Wei Yang"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Many datasets suffer from missing values due to various reasons,which not only increases the processing difficulty of related tasks but also reduces the accuracy of classification. To address this problem, the mainstream approach is to use missing value imputation to complete the dataset. Existing imputation methods estimate the missing parts based on the observed values in the original feature space, and they treat all features as equally important during data completion, while in fact different features have different importance. Therefore, we have designed an imputation method that considers feature importance. This algorithm iteratively performs matrix completion and feature importance learning, and specifically, matrix completion is based on a filling loss that incorporates feature importance. Our experimental analysis involves three types of datasets: synthetic datasets with different noisy features and missing values, real-world datasets with artificially generated missing values, and real-world datasets originally containing missing values. The results on these datasets consistently show that the proposed method outperforms the existing five imputation algorithms.To the best of our knowledge, this is the first work that considers feature importance in the imputation model.", "url": "https://arxiv.org/abs/2311.08005"}, {"metadata": {"arXiv": "2311.08035", "Date": "Tue, 14 Nov 2023 09:55:03 ", "Title": "Data-driven building energy efficiency prediction based on envelope heat losses using physics-informed neural networks", "Authors": ["Vasilis Michalakopoulos", "Sotiris Pelekis", "Giorgos Kormpakis", "Vagelis Karakolis", "Spiros Mouzakitis", "Dimitris Askounis"], "Categories": "cs.LG cs.AI cs.CE", "Comments": ["8 pages", "1 figure"]}, "abstract": "The analytical prediction of building energy performance in residential buildings based on the heat losses of its individual envelope components is a challenging task. It is worth noting that this field is still in its infancy, with relatively limited research conducted in this specific area to date, especially when it comes for data-driven approaches. In this paper we introduce a novel physics-informed neural network model for addressing this problem. Through the employment of unexposed datasets that encompass general building information, audited characteristics, and heating energy consumption, we feed the deep learning model with general building information, while the model's output consists of the structural components and several thermal properties that are in fact the basic elements of an energy performance certificate (EPC). On top of this neural network, a function, based on physics equations, calculates the energy consumption of the building based on heat losses and enhances the loss function of the deep learning model. This methodology is tested on a real case study for 256 buildings located in Riga, Latvia. Our investigation comes up with promising results in terms of prediction accuracy, paving the way for automated, and data-driven energy efficiency performance prediction based on basic properties of the building, contrary to exhaustive energy efficiency audits led by humans, which are the current status quo.", "url": "https://arxiv.org/abs/2311.08035"}, {"metadata": {"arXiv": "2311.08118", "Date": "Tue, 14 Nov 2023 12:33:19 ", "Title": "Evaluating Neighbor Explainability for Graph Neural Networks", "Authors": ["Oscar Llorente", "P\\'eter Vaderna", "S\\'andor Laki", "Roland Kotrocz\\'o", "Rita Csoma and J\\'anos M\\'ark Szalai-Gindl"], "Categories": "cs.LG cs.AI"}, "abstract": "Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.", "url": "https://arxiv.org/abs/2311.08118"}, {"metadata": {"arXiv": "2311.08150", "Date": "Tue, 14 Nov 2023 13:26:49 ", "Title": "The Hyperdimensional Transform for Distributional Modelling, Regression and Classification", "Authors": ["Pieter Dewulf", "Bernard De Baets", "Michiel Stock"], "Categories": "cs.LG cs.AI cs.AR"}, "abstract": "Hyperdimensional computing (HDC) is an increasingly popular computing paradigm with immense potential for future intelligent applications. Although the main ideas already took form in the 1990s, HDC recently gained significant attention, especially in the field of machine learning and data science. Next to efficiency, interoperability and explainability, HDC offers attractive properties for generalization as it can be seen as an attempt to combine connectionist ideas from neural networks with symbolic aspects. In recent work, we introduced the hyperdimensional transform, revealing deep theoretical foundations for representing functions and distributions as high-dimensional holographic vectors. Here, we present the power of the hyperdimensional transform to a broad data science audience. We use the hyperdimensional transform as a theoretical basis and provide insight into state-of-the-art HDC approaches for machine learning. We show how existing algorithms can be modified and how this transform can lead to a novel, well-founded toolbox. Next to the standard regression and classification tasks of machine learning, our discussion includes various aspects of statistical modelling, such as representation, learning and deconvolving distributions, sampling, Bayesian inference, and uncertainty estimation.", "url": "https://arxiv.org/abs/2311.08150"}, {"metadata": {"arXiv": "2311.08170", "Date": "Tue, 14 Nov 2023 13:54:35 ", "Title": "Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach", "Authors": ["Giovanni Luca Marchetti", "Gabriele Cesa", "Kumar Pratik", "Arash Behboodi"], "Categories": "cs.LG cs.AI cs.DM", "Comments": ["Symmetry and Geometry in Neural Representations - NeurReps Workshop @ NeurIPS 2023"]}, "abstract": "Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. In this work, we address lattice reduction via deep learning methods. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant and equivariant with respect to appropriate continuous and discrete groups.", "url": "https://arxiv.org/abs/2311.08170"}, {"metadata": {"arXiv": "2311.08360", "Date": "Tue, 14 Nov 2023 18:03:20 ", "Title": "The Transient Nature of Emergent In-Context Learning in Transformers", "Authors": ["Aaditya K. Singh", "Stephanie C.Y. Chan", "Ted Moskovitz", "Erin Grant", "Andrew M. Saxe", "Felix Hill"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["19 pages", "16 figures"]}, "abstract": "Transformer neural networks can exhibit a surprising capacity for in-context learning (ICL) despite not being explicitly trained for it. Prior work has provided a deeper understanding of how ICL emerges in transformers, e.g. through the lens of mechanistic interpretability, Bayesian inference, or by examining the distributional properties of training data. However, in each of these cases, ICL is treated largely as a persistent phenomenon; namely, once ICL emerges, it is assumed to persist asymptotically. Here, we show that the emergence of ICL during transformer training is, in fact, often transient. We train transformers on synthetic data designed so that both ICL and in-weights learning (IWL) strategies can lead to correct predictions. We find that ICL first emerges, then disappears and gives way to IWL, all while the training loss decreases, indicating an asymptotic preference for IWL. The transient nature of ICL is observed in transformers across a range of model sizes and datasets, raising the question of how much to \"overtrain\" transformers when seeking compact, cheaper-to-run models. We find that L2 regularization may offer a path to more persistent ICL that removes the need for early stopping based on ICL-style validation tasks. Finally, we present initial evidence that ICL transience may be caused by competition between ICL and IWL circuits.", "url": "https://arxiv.org/abs/2311.08360"}, {"metadata": {"arXiv": "2311.08364", "Date": "Tue, 14 Nov 2023 18:14:56 ", "Title": "Plum: Prompt Learning using Metaheuristic", "Authors": ["Rui Pan", "Shuo Xing", "Shizhe Diao", "Xiang Liu", "Kashun Shum", "Jipeng Zhang", "Tong Zhang"], "Categories": "cs.LG cs.AI cs.DM"}, "abstract": "Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly \"general\", i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in black-box prompt learning and Chain-of-Thought prompt tuning. Furthermore, we show that these methods can be used to discover more human-understandable prompts that were previously unknown, opening the door to a cornucopia of possibilities in prompt optimization. We release all the codes in \\url{https://github.com/research4pan/Plum}.", "url": "https://arxiv.org/abs/2311.08364"}, {"metadata": {"arXiv": "2311.08384", "Date": "Tue, 14 Nov 2023 18:45:56 ", "Title": "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees", "Authors": ["Yifei Zhou", "Ayush Sekhari", "Yuda Song", "Wen Sun"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["The first two authors contributed equally"]}, "abstract": "Hybrid RL is the setting where an RL agent has access to both offline data and online data by interacting with the real-world environment. In this work, we propose a new hybrid RL algorithm that combines an on-policy actor-critic method with offline data. On-policy methods such as policy gradient and natural policy gradient (NPG) have shown to be more robust to model misspecification, though sometimes it may not be as sample efficient as methods that rely on off-policy learning. On the other hand, offline methods that depend on off-policy training often require strong assumptions in theory and are less stable to train in practice. Our new approach integrates a procedure of off-policy training on the offline data into an on-policy NPG framework. We show that our approach, in theory, can obtain a best-of-both-worlds type of result -- it achieves the state-of-art theoretical guarantees of offline RL when offline RL-specific assumptions hold, while at the same time maintaining the theoretical guarantees of on-policy NPG regardless of the offline RL assumptions' validity. Experimentally, in challenging rich-observation environments, we show that our approach outperforms a state-of-the-art hybrid RL baseline which only relies on off-policy policy optimization, demonstrating the empirical benefit of combining on-policy and off-policy learning. Our code is publicly available at https://github.com/YifeiZhou02/HNPG.", "url": "https://arxiv.org/abs/2311.08384"}, {"metadata": {"arXiv": "2311.07888", "Date": "Tue, 14 Nov 2023 03:49:20 ", "Title": "RoboSense At Edge: Detecting Slip, Crumple and Shape of the Object in Robotic Hand for Teleoprations", "Authors": ["Sudev Kumar Padhi", "Mohit Kumar", "Debanka Giri", "Subidh Ali"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Slip and crumple detection is essential for performing robust manipulation tasks with a robotic hand (RH) like remote surgery. It has been one of the challenging problems in the robotics manipulation community. In this work, we propose a technique based on machine learning (ML) based techniques to detect the slip, and crumple as well as the shape of an object that is currently held in the robotic hand. We proposed ML model will detect the slip, crumple, and shape using the force/torque exerted and the angular positions of the actuators present in the RH. The proposed model would be integrated into the loop of a robotic hand(RH) and haptic glove(HG). This would help us to reduce the latency in case of teleoperation", "url": "https://arxiv.org/abs/2311.07888"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.10013", "Date": "Mon, 18 Sep 2023 14:51:46 ", "Title": "Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin", "Authors": ["Gabriel Moreira", "Manuel Marques", "Jo\\~ao Paulo Costeira", "Alexander Hauptmann"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted for WACV 2024"]}, "abstract": "Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension.", "url": "https://arxiv.org/abs/2309.10013"}, {"metadata": {"arXiv": "2309.10019", "Date": "Mon, 18 Sep 2023 17:50:56 ", "Title": "Parameter-Efficient Long-Tailed Recognition", "Authors": ["Jiang-Xin Shi", "Tong Wei", "Zhi Zhou", "Xin-Yan Han", "Jie-Jing Shao", "Yu-Feng Li"], "Categories": "cs.CV cs.LG"}, "abstract": "The \"pre-training and fine-tuning\" paradigm in addressing long-tailed recognition tasks has sparked significant interest since the emergence of large vision-language models like the contrastive language-image pre-training (CLIP). While previous studies have shown promise in adapting pre-trained models for these tasks, they often undesirably require extensive training epochs or additional training data to maintain good performance. In this paper, we propose PEL, a fine-tuning method that can effectively adapt pre-trained models to long-tailed recognition tasks in fewer than 20 epochs without the need for extra data. We first empirically find that commonly used fine-tuning methods, such as full fine-tuning and classifier fine-tuning, suffer from overfitting, resulting in performance deterioration on tail classes. To mitigate this issue, PEL introduces a small number of task-specific parameters by adopting the design of any existing parameter-efficient fine-tuning method. Additionally, to expedite convergence, PEL presents a novel semantic-aware classifier initialization technique derived from the CLIP textual encoder without adding any computational overhead. Our experimental results on four long-tailed datasets demonstrate that PEL consistently outperforms previous state-of-the-art approaches. The source code is available at https://github.com/shijxcs/PEL.", "url": "https://arxiv.org/abs/2309.10019"}, {"metadata": {"arXiv": "2309.10361", "Date": "Tue, 19 Sep 2023 06:43:31 ", "Title": "Improving CLIP Robustness with Knowledge Distillation and Self-Training", "Authors": ["Clement Laroudie", "Andrei Bursuc", "Mai Lan Ha", "Gianni Franchi"], "Categories": "cs.CV cs.LG cs.MM"}, "abstract": "This paper examines the robustness of a multi-modal computer vision model, CLIP (Contrastive Language-Image Pretraining), in the context of unsupervised learning. The main objective is twofold: first, to evaluate the robustness of CLIP, and second, to explore strategies for augmenting its robustness. To achieve this, we introduce a novel approach named LP-CLIP. This technique involves the distillation of CLIP features through the incorporation of a linear probing layer positioned atop its encoding structure. This newly added layer is trained utilizing pseudo-labels produced by CLIP, coupled with a self-training strategy. The LP-CLIP technique offers a promising approach to enhance the robustness of CLIP without the need for annotations. By leveraging a simple linear probing layer, we aim to improve the model's ability to withstand various uncertainties and challenges commonly encountered in real-world scenarios. Importantly, our approach does not rely on annotated data, which makes it particularly valuable in situations where labeled data might be scarce or costly to obtain. Our proposed approach increases the robustness of CLIP with SOTA results compared to supervised technique on various datasets.", "url": "https://arxiv.org/abs/2309.10361"}, {"metadata": {"arXiv": "2309.10511", "Date": "Tue, 19 Sep 2023 10:47:32 ", "Title": "Single-Image based unsupervised joint segmentation and denoising", "Authors": ["Nadja Gruber", "Johannes Schwab", "No\\'emie Debroux", "Nicolas Papadakis", "Markus Haltmeier"], "Categories": "cs.CV cs.LG math.OC", "MSC-class": "65K10, 68U05, 68U15, 68T07, 68U10"}, "abstract": "In this work, we develop an unsupervised method for the joint segmentation and denoising of a single image. To this end, we combine the advantages of a variational segmentation method with the power of a self-supervised, single-image based deep learning approach. One major strength of our method lies in the fact, that in contrast to data-driven methods, where huge amounts of labeled samples are necessary, our model can segment an image into multiple meaningful regions without any training database. Further, we introduce a novel energy functional in which denoising and segmentation are coupled in a way that both tasks benefit from each other. The limitations of existing single-image based variational segmentation methods, which are not capable of dealing with high noise or generic texture, are tackled by this specific combination with self-supervised image denoising. We propose a unified optimisation strategy and show that, especially for very noisy images available in microscopy, our proposed joint approach outperforms its sequential counterpart as well as alternative methods focused purely on denoising or segmentation. Another comparison is conducted with a supervised deep learning approach designed for the same application, highlighting the good performance of our approach.", "url": "https://arxiv.org/abs/2309.10511"}, {"metadata": {"arXiv": "2309.10586", "Date": "Tue, 19 Sep 2023 12:54:09 ", "Title": "Adversarial Attacks Against Uncertainty Quantification", "Authors": ["Emanuele Ledda", "Daniele Angioni", "Giorgio Piras", "Giorgio Fumera", "Battista Biggio and Fabio Roli"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Machine-learning models can be fooled by adversarial examples, i.e., carefully-crafted input perturbations that force models to output wrong predictions. While uncertainty quantification has been recently proposed to detect adversarial inputs, under the assumption that such attacks exhibit a higher prediction uncertainty than pristine data, it has been shown that adaptive attacks specifically aimed at reducing also the uncertainty estimate can easily bypass this defense mechanism. In this work, we focus on a different adversarial scenario in which the attacker is still interested in manipulating the uncertainty estimate, but regardless of the correctness of the prediction; in particular, the goal is to undermine the use of machine-learning models when their outputs are consumed by a downstream module or by a human operator. Following such direction, we: \\textit{(i)} design a threat model for attacks targeting uncertainty quantification; \\textit{(ii)} devise different attack strategies on conceptually different UQ techniques spanning for both classification and semantic segmentation problems; \\textit{(iii)} conduct a first complete and extensive analysis to compare the differences between some of the most employed UQ approaches under attack. Our extensive experimental analysis shows that our attacks are more effective in manipulating uncertainty quantification measures than attacks aimed to also induce misclassifications.", "url": "https://arxiv.org/abs/2309.10586"}, {"metadata": {"arXiv": "2309.10619", "Date": "Tue, 19 Sep 2023 13:52:06 ", "Title": "Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image", "Authors": ["Jinye Ran", "Guanghua Zhang", "Ximei Zhang", "Juan Xie", "Fan Xia", "Hao Zhang"], "Categories": "cs.CV cs.LG"}, "abstract": "Domain adaptation (DA) has been widely applied in the diabetic retinopathy (DR) grading of unannotated ultra-wide-field (UWF) fundus images, which can transfer annotated knowledge from labeled color fundus images. However, suffering from huge domain gaps and complex real-world scenarios, the DR grading performance of most mainstream DA is far from that of clinical diagnosis. To tackle this, we propose a novel source-free active domain adaptation (SFADA) in this paper. Specifically, we focus on DR grading problem itself and propose to generate features of color fundus images with continuously evolving relationships of DRs, actively select a few valuable UWF fundus images for labeling with local representation matching, and adapt model on UWF fundus images with DR lesion prototypes. Notably, the SFADA also takes data privacy and computational efficiency into consideration. Extensive experimental results demonstrate that our proposed SFADA achieves state-of-the-art DR grading performance, increasing accuracy by 20.9% and quadratic weighted kappa by 18.63% compared with baseline and reaching 85.36% and 92.38% respectively. These investigations show that the potential of our approach for real clinical practice is promising.", "url": "https://arxiv.org/abs/2309.10619"}, {"metadata": {"arXiv": "2309.09987", "Date": "Thu, 14 Sep 2023 19:29:14 ", "Title": "TCGF: A unified tensorized consensus graph framework for multi-view representation learning", "Authors": ["Xiangzhu Meng", "Wei Wei", "Qiang Liu", "Shu Wu", "Liang Wang"], "Categories": "cs.LG"}, "abstract": "Multi-view learning techniques have recently gained significant attention in the machine learning domain for their ability to leverage consistency and complementary information across multiple views. However, there remains a lack of sufficient research on generalized multi-view frameworks that unify existing works into a scalable and robust learning framework, as most current works focus on specific styles of multi-view models. Additionally, most multi-view learning works rely heavily on specific-scale scenarios and fail to effectively comprehend multiple scales holistically. These limitations hinder the effective fusion of essential information from multiple views, resulting in poor generalization. To address these limitations, this paper proposes a universal multi-view representation learning framework named Tensorized Consensus Graph Framework (TCGF). Specifically, it first provides a unified framework for existing multi-view works to exploit the representations for individual view, which aims to be suitable for arbitrary assumptions and different-scales datasets. Then, stacks them into a tensor under alignment basics as a high-order representation, allowing for the smooth propagation of consistency and complementary information across all views. Moreover, TCGF proposes learning a consensus embedding shared by adaptively collaborating all views to uncover the essential structure of the multi-view data, which utilizes view-consensus grouping effect to regularize the view-consensus representation. To further facilitate related research, we provide a specific implementation of TCGF for large-scale datasets, which can be efficiently solved by applying the alternating optimization strategy. Experimental results conducted on seven different-scales datasets indicate the superiority of the proposed TCGF against existing state-of-the-art multi-view learning methods.", "url": "https://arxiv.org/abs/2309.09987"}, {"metadata": {"arXiv": "2309.09993", "Date": "Fri, 15 Sep 2023 21:36:43 ", "Title": "Long-term Neurological Sequelae in Post-COVID-19 Patients: A Machine Learning Approach to Predict Outcomes", "Authors": ["Hayder A. Albaqer", "Kadhum J. Al-Jibouri", "John Martin", "Fadhil G. Al-Amran", "Salman Rawaf", "Maitham G. Yousif"], "Categories": "cs.LG q-bio.BM q-bio.NC"}, "abstract": "The COVID-19 pandemic has brought to light a concerning aspect of long-term neurological complications in post-recovery patients. This study delved into the investigation of such neurological sequelae in a cohort of 500 post-COVID-19 patients, encompassing individuals with varying illness severity. The primary aim was to predict outcomes using a machine learning approach based on diverse clinical data and neuroimaging parameters. The results revealed that 68% of the post-COVID-19 patients reported experiencing neurological symptoms, with fatigue, headache, and anosmia being the most common manifestations. Moreover, 22% of the patients exhibited more severe neurological complications, including encephalopathy and stroke. The application of machine learning models showed promising results in predicting long-term neurological outcomes. Notably, the Random Forest model achieved an accuracy of 85%, sensitivity of 80%, and specificity of 90% in identifying patients at risk of developing neurological sequelae. These findings underscore the importance of continuous monitoring and follow-up care for post-COVID-19 patients, particularly in relation to potential neurological complications. The integration of machine learning-based outcome prediction offers a valuable tool for early intervention and personalized treatment strategies, aiming to improve patient care and clinical decision-making. In conclusion, this study sheds light on the prevalence of long-term neurological complications in post-COVID-19 patients and demonstrates the potential of machine learning in predicting outcomes, thereby contributing to enhanced patient management and better health outcomes. Further research and larger studies are warranted to validate and refine these predictive models and to gain deeper insights into the underlying mechanisms of post-COVID-19 neurological sequelae.", "url": "https://arxiv.org/abs/2309.09993"}, {"metadata": {"arXiv": "2309.10000", "Date": "Sun, 17 Sep 2023 07:34:57 ", "Title": "Detecting covariate drift in text data using document embeddings and dimensionality reduction", "Authors": ["Vinayak Sodar", "Ankit Sekseria"], "Categories": "cs.LG cs.CL"}, "abstract": "Detecting covariate drift in text data is essential for maintaining the reliability and performance of text analysis models. In this research, we investigate the effectiveness of different document embeddings, dimensionality reduction techniques, and drift detection methods for identifying covariate drift in text data. We explore three popular document embeddings: term frequency-inverse document frequency (TF-IDF) using Latent semantic analysis(LSA) for dimentionality reduction and Doc2Vec, and BERT embeddings, with and without using principal component analysis (PCA) for dimensionality reduction. To quantify the divergence between training and test data distributions, we employ the Kolmogorov-Smirnov (KS) statistic and the Maximum Mean Discrepancy (MMD) test as drift detection methods. Experimental results demonstrate that certain combinations of embeddings, dimensionality reduction techniques, and drift detection methods outperform others in detecting covariate drift. Our findings contribute to the advancement of reliable text analysis models by providing insights into effective approaches for addressing covariate drift in text data.", "url": "https://arxiv.org/abs/2309.10000"}, {"metadata": {"arXiv": "2309.10002", "Date": "Sun, 17 Sep 2023 15:05:27 ", "Title": "Energy stable neural network for gradient flow equations", "Authors": ["Ganghua Fan", "Tianyu Jin", "Yuan Lan", "Yang Xiang", "Luchan Zhang"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "In this paper, we propose an energy stable network (EStable-Net) for solving gradient flow equations. The solution update scheme in our neural network EStable-Net is inspired by a proposed auxiliary variable based equivalent form of the gradient flow equation. EStable-Net enables decreasing of a discrete energy along the neural network, which is consistent with the property in the evolution process of the gradient flow equation. The architecture of the neural network EStable-Net consists of a few energy decay blocks, and the output of each block can be interpreted as an intermediate state of the evolution process of the gradient flow equation. This design provides a stable, efficient and interpretable network structure. Numerical experimental results demonstrate that our network is able to generate high accuracy and stable predictions.", "url": "https://arxiv.org/abs/2309.10002"}, {"metadata": {"arXiv": "2309.10010", "Date": "Mon, 18 Sep 2023 06:08:26 ", "Title": "Machine Learning Approaches to Predict and Detect Early-Onset of Digital Dermatitis in Dairy Cows using Sensor Data", "Authors": ["Jennifer Magana", "Dinu Gavojdian", "Yakir Menachem", "Teddy Lazebnik", "Anna Zamansky", "Amber Adams-Progar"], "Categories": "cs.LG eess.SP"}, "abstract": "The aim of this study was to employ machine learning algorithms based on sensor behavior data for (1) early-onset detection of digital dermatitis (DD); and (2) DD prediction in dairy cows. With the ultimate goal to set-up early warning tools for DD prediction, which would than allow a better monitoring and management of DD under commercial settings, resulting in a decrease of DD prevalence and severity, while improving animal welfare. A machine learning model that is capable of predicting and detecting digital dermatitis in cows housed under free-stall conditions based on behavior sensor data has been purposed and tested in this exploratory study. The model for DD detection on day 0 of the appearance of the clinical signs has reached an accuracy of 79%, while the model for prediction of DD 2 days prior to the appearance of the first clinical signs has reached an accuracy of 64%. The proposed machine learning models could help to develop a real-time automated tool for monitoring and diagnostic of DD in lactating dairy cows, based on behavior sensor data under conventional dairy environments. Results showed that alterations in behavioral patterns at individual levels can be used as inputs in an early warning system for herd management in order to detect variances in health of individual cows.", "url": "https://arxiv.org/abs/2309.10010"}, {"metadata": {"arXiv": "2309.10014", "Date": "Mon, 18 Sep 2023 15:04:40 ", "Title": "Prognosis of Multivariate Battery State of Performance and Health via Transformers", "Authors": ["Noah H. Paulson", "Joseph J. Kubal", "Susan J. Babinec"], "Categories": "cs.LG", "Comments": ["19 pages (main text)", "8 figures (main text)", "5 tables (main text)", "14 pages (SI)", "27 figures (SI)"]}, "abstract": "Batteries are an essential component in a deeply decarbonized future. Understanding battery performance and \"useful life\" as a function of design and use is of paramount importance to accelerating adoption. Historically, battery state of health (SOH) was summarized by a single parameter, the fraction of a battery's capacity relative to its initial state. A more useful approach, however, is a comprehensive characterization of its state and complexities, using an interrelated set of descriptors including capacity, energy, ionic and electronic impedances, open circuit voltages, and microstructure metrics. Indeed, predicting across an extensive suite of properties as a function of battery use is a \"holy grail\" of battery science; it can provide unprecedented insights toward the design of better batteries with reduced experimental effort, and de-risking energy storage investments that are necessary to meet CO2 reduction targets. In this work, we present a first step in that direction via deep transformer networks for the prediction of 28 battery state of health descriptors using two cycling datasets representing six lithium-ion cathode chemistries (LFP, NMC111, NMC532, NMC622, HE5050, and 5Vspinel), multiple electrolyte/anode compositions, and different charge-discharge scenarios. The accuracy of these predictions versus battery life (with an unprecedented mean absolute error of 19 cycles in predicting end of life for an LFP fast-charging dataset) illustrates the promise of deep learning towards providing deeper understanding and control of battery health.", "url": "https://arxiv.org/abs/2309.10014"}, {"metadata": {"arXiv": "2309.10047", "Date": "Mon, 18 Sep 2023 18:05:06 ", "Title": "A Modular Spatial Clustering Algorithm with Noise Specification", "Authors": ["Akhil K", "Srikanth H R"], "Categories": "cs.LG cs.DB", "Comments": ["Presented at International Conference for Machine Learning and Data Science 2018"]}, "abstract": "Clustering techniques have been the key drivers of data mining, machine learning and pattern recognition for decades. One of the most popular clustering algorithms is DBSCAN due to its high accuracy and noise tolerance. Many superior algorithms such as DBSCAN have input parameters that are hard to estimate. Therefore, finding those parameters is a time consuming process. In this paper, we propose a novel clustering algorithm Bacteria-Farm, which balances the performance and ease of finding the optimal parameters for clustering. Bacteria- Farm algorithm is inspired by the growth of bacteria in closed experimental farms - their ability to consume food and grow - which closely represents the ideal cluster growth desired in clustering algorithms. In addition, the algorithm features a modular design to allow the creation of versions of the algorithm for specific tasks / distributions of data. In contrast with other clustering algorithms, our algorithm also has a provision to specify the amount of noise to be excluded during clustering.", "url": "https://arxiv.org/abs/2309.10047"}, {"metadata": {"arXiv": "2309.10058", "Date": "Mon, 18 Sep 2023 18:11:31 ", "Title": "Dual Student Networks for Data-Free Model Stealing", "Authors": ["James Beetham", "Navid Kardan", "Ajmal Mian", "Mubarak Shah"], "Categories": "cs.LG", "Comments": ["Published in the ICLR 2023 - The Eleventh International Conference on Learning Representations"]}, "abstract": "Existing data-free model stealing methods use a generator to produce samples in order to train a student model to match the target model outputs. To this end, the two main challenges are estimating gradients of the target model without access to its parameters, and generating a diverse set of training samples that thoroughly explores the input space. We propose a Dual Student method where two students are symmetrically trained in order to provide the generator a criterion to generate samples that the two students disagree on. On one hand, disagreement on a sample implies at least one student has classified the sample incorrectly when compared to the target model. This incentive towards disagreement implicitly encourages the generator to explore more diverse regions of the input space. On the other hand, our method utilizes gradients of student models to indirectly estimate gradients of the target model. We show that this novel training objective for the generator network is equivalent to optimizing a lower bound on the generator's loss if we had access to the target model gradients. We show that our new optimization framework provides more accurate gradient estimation of the target model and better accuracies on benchmark classification datasets. Additionally, our approach balances improved query efficiency with training computation cost. Finally, we demonstrate that our method serves as a better proxy model for transfer-based adversarial attacks than existing data-free model stealing methods.", "url": "https://arxiv.org/abs/2309.10058"}, {"metadata": {"arXiv": "2309.10095", "Date": "Mon, 18 Sep 2023 19:07:41 ", "Title": "A Semi-Supervised Approach for Power System Event Identification", "Authors": ["Nima Taghipourbazargani", "Lalitha Sankar", "Oliver Kosut"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Event identification is increasingly recognized as crucial for enhancing the reliability, security, and stability of the electric power system. With the growing deployment of Phasor Measurement Units (PMUs) and advancements in data science, there are promising opportunities to explore data-driven event identification via machine learning classification techniques. However, obtaining accurately-labeled eventful PMU data samples remains challenging due to its labor-intensive nature and uncertainty about the event type (class) in real-time. Thus, it is natural to use semi-supervised learning techniques, which make use of both labeled and unlabeled samples. %We propose a novel semi-supervised framework to assess the effectiveness of incorporating unlabeled eventful samples to enhance existing event identification methodologies. We evaluate three categories of classical semi-supervised approaches: (i) self-training, (ii) transductive support vector machines (TSVM), and (iii) graph-based label spreading (LS) method. Our approach characterizes events using physically interpretable features extracted from modal analysis of synthetic eventful PMU data. In particular, we focus on the identification of four event classes whose identification is crucial for grid operations. We have developed and publicly shared a comprehensive Event Identification package which consists of three aspects: data generation, feature extraction, and event identification with limited labels using semi-supervised methodologies. Using this package, we generate and evaluate eventful PMU data for the South Carolina synthetic network. Our evaluation consistently demonstrates that graph-based LS outperforms the other two semi-supervised methods that we consider, and can noticeably improve event identification performance relative to the setting with only a small number of labeled samples.", "url": "https://arxiv.org/abs/2309.10095"}, {"metadata": {"arXiv": "2309.10131", "Date": "Mon, 18 Sep 2023 20:12:17 ", "Title": "Deep Prompt Tuning for Graph Transformers", "Authors": ["Reza Shirkavand", "Heng Huang"], "Categories": "cs.LG cs.CV"}, "abstract": "Graph transformers have gained popularity in various graph-based tasks by addressing challenges faced by traditional Graph Neural Networks. However, the quadratic complexity of self-attention operations and the extensive layering in graph transformer architectures present challenges when applying them to graph based prediction tasks. Fine-tuning, a common approach, is resource-intensive and requires storing multiple copies of large models. We propose a novel approach called deep graph prompt tuning as an alternative to fine-tuning for leveraging large graph transformer models in downstream graph based prediction tasks. Our method introduces trainable feature nodes to the graph and pre-pends task-specific tokens to the graph transformer, enhancing the model's expressive power. By freezing the pre-trained parameters and only updating the added tokens, our approach reduces the number of free parameters and eliminates the need for multiple model copies, making it suitable for small datasets and scalable to large graphs. Through extensive experiments on various-sized datasets, we demonstrate that deep graph prompt tuning achieves comparable or even superior performance to fine-tuning, despite utilizing significantly fewer task-specific parameters. Our contributions include the introduction of prompt tuning for graph transformers, its application to both graph transformers and message passing graph neural networks, improved efficiency and resource utilization, and compelling experimental results. This work brings attention to a promising approach to leverage pre-trained models in graph based prediction tasks and offers new opportunities for exploring and advancing graph representation learning.", "url": "https://arxiv.org/abs/2309.10131"}, {"metadata": {"arXiv": "2309.10140", "Date": "Mon, 18 Sep 2023 20:39:12 ", "Title": "A Geometric Framework for Neural Feature Learning", "Authors": ["Xiangxiang Xu", "Lizhong Zheng"], "Categories": "cs.LG stat.ML", "Comments": ["70 pages", "23 figures"]}, "abstract": "We present a novel framework for learning system design based on neural feature extractors by exploiting geometric structures in feature spaces. First, we introduce the feature geometry, which unifies statistical dependence and features in the same functional space with geometric structures. By applying the feature geometry, we formulate each learning problem as solving the optimal feature approximation of the dependence component specified by the learning setting. We propose a nesting technique for designing learning algorithms to learn the optimal features from data samples, which can be applied to off-the-shelf network architectures and optimizers. To demonstrate the application of the nesting technique, we further discuss multivariate learning problems, including conditioned inference and multimodal learning, where we present the optimal features and reveal their connections to classical approaches.", "url": "https://arxiv.org/abs/2309.10140"}, {"metadata": {"arXiv": "2309.10193", "Date": "Mon, 18 Sep 2023 22:53:17 ", "Title": "Stochastic Deep Koopman Model for Quality Propagation Analysis in Multistage Manufacturing Systems", "Authors": ["Zhiyi Chen", "Harshal Maske", "Huanyi Shui", "Devesh Upadhyay", "Michael Hopka", "Joseph Cohen", "Xingjian Lai", "Xun Huan", "Jun Ni"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "The modeling of multistage manufacturing systems (MMSs) has attracted increased attention from both academia and industry. Recent advancements in deep learning methods provide an opportunity to accomplish this task with reduced cost and expertise. This study introduces a stochastic deep Koopman (SDK) framework to model the complex behavior of MMSs. Specifically, we present a novel application of Koopman operators to propagate critical quality information extracted by variational autoencoders. Through this framework, we can effectively capture the general nonlinear evolution of product quality using a transferred linear representation, thus enhancing the interpretability of the data-driven model. To evaluate the performance of the SDK framework, we carried out a comparative study on an open-source dataset. The main findings of this paper are as follows. Our results indicate that SDK surpasses other popular data-driven models in accuracy when predicting stagewise product quality within the MMS. Furthermore, the unique linear propagation property in the stochastic latent space of SDK enables traceability for quality evolution throughout the process, thereby facilitating the design of root cause analysis schemes. Notably, the proposed framework requires minimal knowledge of the underlying physics of production lines. It serves as a virtual metrology tool that can be applied to various MMSs, contributing to the ultimate goal of Zero Defect Manufacturing.", "url": "https://arxiv.org/abs/2309.10193"}, {"metadata": {"arXiv": "2309.10211", "Date": "Mon, 18 Sep 2023 23:49:42 ", "Title": "Causal Theories and Structural Data Representations for Improving Out-of-Distribution Classification", "Authors": ["Donald Martin", "Jr. and David Kinney"], "Categories": "cs.LG cs.HC stat.ME", "Comments": ["22 pages", "5 figures"]}, "abstract": "We consider how human-centered causal theories and tools from the dynamical systems literature can be deployed to guide the representation of data when training neural networks for complex classification tasks. Specifically, we use simulated data to show that training a neural network with a data representation that makes explicit the invariant structural causal features of the data generating process of an epidemic system improves out-of-distribution (OOD) generalization performance on a classification task as compared to a more naive approach to data representation. We take these results to demonstrate that using human-generated causal knowledge to reduce the epistemic uncertainty of ML developers can lead to more well-specified ML pipelines. This, in turn, points to the utility of a dynamical systems approach to the broader effort aimed at improving the robustness and safety of machine learning systems via improved ML system development practices.", "url": "https://arxiv.org/abs/2309.10211"}, {"metadata": {"arXiv": "2309.10231", "Date": "Tue, 19 Sep 2023 01:03:39 ", "Title": "Multi-fidelity climate model parameterization for better generalization and extrapolation", "Authors": ["Mohamed Aziz Bhouri", "Liran Peng", "Michael S. Pritchard", "Pierre Gentine"], "Categories": "cs.LG math.DS physics.ao-ph physics.comp-ph", "Comments": ["27 pages", "16 figures"]}, "abstract": "Machine-learning-based parameterizations (i.e. representation of sub-grid processes) of global climate models or turbulent simulations have recently been proposed as a powerful alternative to physical, but empirical, representations, offering a lower computational cost and higher accuracy. Yet, those approaches still suffer from a lack of generalization and extrapolation beyond the training data, which is however critical to projecting climate change or unobserved regimes of turbulence. Here we show that a multi-fidelity approach, which integrates datasets of different accuracy and abundance, can provide the best of both worlds: the capacity to extrapolate leveraging the physically-based parameterization and a higher accuracy using the machine-learning-based parameterizations. In an application to climate modeling, the multi-fidelity framework yields more accurate climate projections without requiring major increase in computational resources. Our multi-fidelity randomized prior networks (MF-RPNs) combine physical parameterization data as low-fidelity and storm-resolving historical run's data as high-fidelity. To extrapolate beyond the training data, the MF-RPNs are tested on high-fidelity warming scenarios, $+4K$, data. We show the MF-RPN's capacity to return much more skillful predictions compared to either low- or high-fidelity (historical data) simulations trained only on one regime while providing trustworthy uncertainty quantification across a wide range of scenarios. Our approach paves the way for the use of machine-learning based methods that can optimally leverage historical observations or high-fidelity simulations and extrapolate to unseen regimes such as climate change.", "url": "https://arxiv.org/abs/2309.10231"}, {"metadata": {"arXiv": "2309.10302", "Date": "Tue, 19 Sep 2023 04:06:41 ", "Title": "Decoupled Training: Return of Frustratingly Easy Multi-Domain Learning", "Authors": ["Ximei Wang", "Junwei Pan", "Xingzhuo Guo", "Dapeng Liu", "Jie Jiang"], "Categories": "cs.LG cs.CV cs.IR"}, "abstract": "Multi-domain learning (MDL) aims to train a model with minimal average risk across multiple overlapping but non-identical domains. To tackle the challenges of dataset bias and domain domination, numerous MDL approaches have been proposed from the perspectives of seeking commonalities by aligning distributions to reduce domain gap or reserving differences by implementing domain-specific towers, gates, and even experts. MDL models are becoming more and more complex with sophisticated network architectures or loss functions, introducing extra parameters and enlarging computation costs. In this paper, we propose a frustratingly easy and hyperparameter-free multi-domain learning method named Decoupled Training(D-Train). D-Train is a tri-phase general-to-specific training strategy that first pre-trains on all domains to warm up a root model, then post-trains on each domain by splitting into multi heads, and finally fine-tunes the heads by fixing the backbone, enabling decouple training to achieve domain independence. Despite its extraordinary simplicity and efficiency, D-Train performs remarkably well in extensive evaluations of various datasets from standard benchmarks to applications of satellite imagery and recommender systems.", "url": "https://arxiv.org/abs/2309.10302"}, {"metadata": {"arXiv": "2309.10310", "Date": "Tue, 19 Sep 2023 04:48:01 ", "Title": "TensorCodec: Compact Lossy Compression of Tensors without Strong Data Assumptions", "Authors": ["Taehyung Kwon", "Jihoon Ko", "Jinhong Jung", "and Kijung Shin"], "Categories": "cs.LG", "Comments": ["Accepted to ICDM 2023 - IEEE International Conference on Data Mining 2023"]}, "abstract": "Many real-world datasets are represented as tensors, i.e., multi-dimensional arrays of numerical values. Storing them without compression often requires substantial space, which grows exponentially with the order. While many tensor compression algorithms are available, many of them rely on strong data assumptions regarding its order, sparsity, rank, and smoothness. In this work, we propose TENSORCODEC, a lossy compression algorithm for general tensors that do not necessarily adhere to strong input data assumptions. TENSORCODEC incorporates three key ideas. The first idea is Neural Tensor-Train Decomposition (NTTD) where we integrate a recurrent neural network into Tensor-Train Decomposition to enhance its expressive power and alleviate the limitations imposed by the low-rank assumption. Another idea is to fold the input tensor into a higher-order tensor to reduce the space required by NTTD. Finally, the mode indices of the input tensor are reordered to reveal patterns that can be exploited by NTTD for improved approximation. Our analysis and experiments on 8 real-world datasets demonstrate that TENSORCODEC is (a) Concise: it gives up to 7.38x more compact compression than the best competitor with similar reconstruction error, (b) Accurate: given the same budget for compressed size, it yields up to 3.33x more accurate reconstruction than the best competitor, (c) Scalable: its empirical compression time is linear in the number of tensor entries, and it reconstructs each entry in logarithmic time. Our code and datasets are available at https://github.com/kbrother/TensorCodec.", "url": "https://arxiv.org/abs/2309.10310"}, {"metadata": {"arXiv": "2309.10340", "Date": "Tue, 19 Sep 2023 05:51:13 ", "Title": "Striking a Balance: An Optimal Mechanism Design for Heterogenous Differentially Private Data Acquisition for Logistic Regression", "Authors": ["Ameya Anjarlekar", "Rasoul Etesami", "R. Srikant"], "Categories": "cs.LG cs.GT"}, "abstract": "We investigate the problem of performing logistic regression on data collected from privacy-sensitive sellers. Since the data is private, sellers must be incentivized through payments to provide their data. Thus, the goal is to design a mechanism that optimizes a weighted combination of test loss, seller privacy, and payment, i.e., strikes a balance between multiple objectives of interest. We solve the problem by combining ideas from game theory, statistical learning theory, and differential privacy. The buyer's objective function can be highly non-convex. However, we show that, under certain conditions on the problem parameters, the problem can be convexified by using a change of variables. We also provide asymptotic results characterizing the buyer's test error and payments when the number of sellers becomes large. Finally, we demonstrate our ideas by applying them to a real healthcare data set.", "url": "https://arxiv.org/abs/2309.10340"}, {"metadata": {"arXiv": "2309.10346", "Date": "Tue, 19 Sep 2023 06:13:24 ", "Title": "Explaining Agent Behavior with Large Language Models", "Authors": ["Xijia Zhang", "Yue Guo", "Simon Stepputtis", "Katia Sycara", "and Joseph Campbell"], "Categories": "cs.LG", "Comments": ["Human Multi-Robot Interaction Workshop at IROS 2023"]}, "abstract": "Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts, however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, agnostic to the underlying model representation. We show how a compact representation of the agent's behavior can be learned and used to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those generated by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.", "url": "https://arxiv.org/abs/2309.10346"}, {"metadata": {"arXiv": "2309.10348", "Date": "Tue, 19 Sep 2023 06:17:18 ", "Title": "Language Guided Adversarial Purification", "Authors": ["Himanshu Singh", "A V Subramanyam"], "Categories": "cs.LG cs.CV", "MSC-class": "68T45 (Primary), 68T10 (Secondary)", "ACM-class": "I.5.4"}, "abstract": "Adversarial purification using generative models demonstrates strong adversarial defense performance. These methods are classifier and attack-agnostic, making them versatile but often computationally intensive. Recent strides in diffusion and score networks have improved image generation and, by extension, adversarial purification. Another highly efficient class of adversarial defense methods known as adversarial training requires specific knowledge of attack vectors, forcing them to be trained extensively on adversarial examples. To overcome these limitations, we introduce a new framework, namely Language Guided Adversarial Purification (LGAP), utilizing pre-trained diffusion models and caption generators to defend against adversarial attacks. Given an input image, our method first generates a caption, which is then used to guide the adversarial purification process through a diffusion network. Our approach has been evaluated against strong adversarial attacks, proving its effectiveness in enhancing adversarial robustness. Our results indicate that LGAP outperforms most existing adversarial defense techniques without requiring specialized network training. This underscores the generalizability of models trained on large datasets, highlighting a promising direction for further research.", "url": "https://arxiv.org/abs/2309.10348"}, {"metadata": {"arXiv": "2309.10402", "Date": "Tue, 19 Sep 2023 08:04:48 ", "Title": "Minimum width for universal approximation using ReLU networks on compact domain", "Authors": ["Namjun Kim", "Chanho Min", "Sejun Park"], "Categories": "cs.LG stat.ML"}, "abstract": "The universal approximation property of width-bounded networks has been studied as a dual of the classical universal approximation theorem for depth-bounded ones. There were several attempts to characterize the minimum width $w_{\\min}$ enabling the universal approximation property; however, only a few of them found the exact values. In this work, we show that the minimum width for the universal approximation of $L^p$ functions from $[0,1]^{d_x}$ to $\\mathbb R^{d_y}$ is exactly $\\max\\{d_x,d_y,2\\}$ if an activation function is ReLU-Like (e.g., ReLU, GELU, Softplus). Compared to the known result $w_{\\min}=\\max\\{d_x+1,d_y\\}$ when the domain is ${\\mathbb R^{d_x}}$, our result first shows that approximation on a compact domain requires smaller width than on ${\\mathbb R^{d_x}}$. We next prove a lower bound on $w_{\\min}$ for uniform approximation using general activation functions including ReLU: $w_{\\min}\\ge d_y+1$ if $d_x<d_y\\le2d_x$. Together with our first result, this shows a dichotomy between $L^p$ and uniform approximations for general activation functions and input/output dimensions.", "url": "https://arxiv.org/abs/2309.10402"}, {"metadata": {"arXiv": "2309.10418", "Date": "Tue, 19 Sep 2023 08:30:10 ", "Title": "Graph Neural Networks for Dynamic Modeling of Roller Bearing", "Authors": ["Vinay Sharma (1)", "Jens Ravesloot (2)", "Cees Taal (2)", "Olga Fink (1) ((1) EPFL", "Intelligent Maintenance and Operations Systems", "Lausanne", "Switzerland", "(2) SKF", "Research and Technology Development", "Houten", "the Netherlands)"], "Categories": "cs.LG cs.CE cs.NA math.NA"}, "abstract": "In the presented work, we propose to apply the framework of graph neural networks (GNNs) to predict the dynamics of a rolling element bearing. This approach offers generalizability and interpretability, having the potential for scalable use in real-time operational digital twin systems for monitoring the health state of rotating machines. By representing the bearing's components as nodes in a graph, the GNN can effectively model the complex relationships and interactions among them. We utilize a dynamic spring-mass-damper model of a bearing to generate the training data for the GNN. In this model, discrete masses represent bearing components such as rolling elements, inner raceways, and outer raceways, while a Hertzian contact model is employed to calculate the forces between these components. We evaluate the learning and generalization capabilities of the proposed GNN framework by testing different bearing configurations that deviate from the training configurations. Through this approach, we demonstrate the effectiveness of the GNN-based method in accurately predicting the dynamics of rolling element bearings, highlighting its potential for real-time health monitoring of rotating machinery.", "url": "https://arxiv.org/abs/2309.10418"}, {"metadata": {"arXiv": "2309.10612", "Date": "Tue, 19 Sep 2023 13:37:47 ", "Title": "An Extendable Python Implementation of Robust Optimisation Monte Carlo", "Authors": ["Vasilis Gkolemis", "Michael Gutmann", "Henri Pesonen"], "Categories": "cs.LG cs.SE stat.CO", "Comments": ["the publication is based on the manuscript of MSc. thesis arXiv:2011.03977"]}, "abstract": "Performing inference in statistical models with an intractable likelihood is challenging, therefore, most likelihood-free inference (LFI) methods encounter accuracy and efficiency limitations. In this paper, we present the implementation of the LFI method Robust Optimisation Monte Carlo (ROMC) in the Python package ELFI. ROMC is a novel and efficient (highly-parallelizable) LFI framework that provides accurate weighted samples from the posterior. Our implementation can be used in two ways. First, a scientist may use it as an out-of-the-box LFI algorithm; we provide an easy-to-use API harmonized with the principles of ELFI, enabling effortless comparisons with the rest of the methods included in the package. Additionally, we have carefully split ROMC into isolated components for supporting extensibility. A researcher may experiment with novel method(s) for solving part(s) of ROMC without reimplementing everything from scratch. In both scenarios, the ROMC parts can run in a fully-parallelized manner, exploiting all CPU cores. We also provide helpful functionalities for (i) inspecting the inference process and (ii) evaluating the obtained samples. Finally, we test the robustness of our implementation on some typical LFI examples.", "url": "https://arxiv.org/abs/2309.10612"}, {"metadata": {"arXiv": "2309.10656", "Date": "Tue, 19 Sep 2023 14:39:03 ", "Title": "A spectrum of physics-informed Gaussian processes for regression in engineering", "Authors": ["Elizabeth J Cross", "Timothy J Rogers", "Daniel J Pitchforth", "Samuel J Gibson and Matthew R Jones"], "Categories": "cs.LG"}, "abstract": "Despite the growing availability of sensing and data in general, we remain unable to fully characterise many in-service engineering systems and structures from a purely data-driven approach. The vast data and resources available to capture human activity are unmatched in our engineered world, and, even in cases where data could be referred to as ``big,'' they will rarely hold information across operational windows or life spans. This paper pursues the combination of machine learning technology and physics-based reasoning to enhance our ability to make predictive models with limited data. By explicitly linking the physics-based view of stochastic processes with a data-based regression approach, a spectrum of possible Gaussian process models are introduced that enable the incorporation of different levels of expert knowledge of a system. Examples illustrate how these approaches can significantly reduce reliance on data collection whilst also increasing the interpretability of the model, another important consideration in this context.", "url": "https://arxiv.org/abs/2309.10656"}, {"metadata": {"arXiv": "2309.10658", "Date": "Tue, 19 Sep 2023 14:40:13 ", "Title": "Implementing a new fully stepwise decomposition-based sampling technique for the hybrid water level forecasting model in real-world application", "Authors": ["Ziqian Zhang", "Nana Bao", "Xingting Yan", "Aokai Zhu", "Chenyang Li and Mingyu Liu"], "Categories": "cs.LG physics.geo-ph"}, "abstract": "Various time variant non-stationary signals need to be pre-processed properly in hydrological time series forecasting in real world, for example, predictions of water level. Decomposition method is a good candidate and widely used in such a pre-processing problem. However, decomposition methods with an inappropriate sampling technique may introduce future data which is not available in practical applications, and result in incorrect decomposition-based forecasting models. In this work, a novel Fully Stepwise Decomposition-Based (FSDB) sampling technique is well designed for the decomposition-based forecasting model, strictly avoiding introducing future information. This sampling technique with decomposition methods, such as Variational Mode Decomposition (VMD) and Singular spectrum analysis (SSA), is applied to predict water level time series in three different stations of Guoyang and Chaohu basins in China. Results of VMD-based hybrid model using FSDB sampling technique show that Nash-Sutcliffe Efficiency (NSE) coefficient is increased by 6.4%, 28.8% and 7.0% in three stations respectively, compared with those obtained from the currently most advanced sampling technique. In the meantime, for series of SSA-based experiments, NSE is increased by 3.2%, 3.1% and 1.1% respectively. We conclude that the newly developed FSDB sampling technique can be used to enhance the performance of decomposition-based hybrid model in water level time series forecasting in real world.", "url": "https://arxiv.org/abs/2309.10658"}, {"metadata": {"arXiv": "2309.10688", "Date": "Tue, 19 Sep 2023 15:23:07 ", "Title": "On the different regimes of Stochastic Gradient Descent", "Authors": ["Antonio Sclocchi and Matthieu Wyart"], "Categories": "cs.LG cond-mat.dis-nn stat.ML", "Comments": ["8 pages", "4 figures; Appendix: 16 pages", "8 figures"]}, "abstract": "Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\\eta$. For small $B$ and large $\\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\\equiv \\eta/B$. Yet this description is observed to break down for sufficiently large batches $B\\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small. Understanding where these cross-overs take place remains a central challenge. Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks. Specifically, we obtain a phase diagram in the $B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a noise-dominated SGD governed by temperature, $\\textit{(ii)}$ a large-first-step-dominated SGD and $\\textit{(iii)}$ GD. These different phases also corresponds to different regimes of generalization error. Remarkably, our analysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$ and $\\textit{(ii)}$ scale with the size $P$ of the training set, with an exponent that characterizes the hardness of the classification problem.", "url": "https://arxiv.org/abs/2309.10688"}, {"metadata": {"arXiv": "2309.10730", "Date": "Tue, 19 Sep 2023 16:14:57 ", "Title": "GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models", "Authors": ["Yonggan Fu", "Yongan Zhang", "Zhongzhi Yu", "Sixu Li", "Zhifan Ye", "Chaojian Li", "Cheng Wan", "Yingyan Lin"], "Categories": "cs.LG cs.AR", "Comments": ["Accepted by ICCAD 2023"]}, "abstract": "The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators. Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive. While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development. Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design. Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages. Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design. Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design. To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation. Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools.", "url": "https://arxiv.org/abs/2309.10730"}, {"metadata": {"arXiv": "2309.10736", "Date": "Tue, 19 Sep 2023 16:29:34 ", "Title": "Mixture Weight Estimation and Model Prediction in Multi-source Multi-target Domain Adaptation", "Authors": ["Yuyang Deng", "Ilja Kuzborskij", "Mehrdad Mahdavi"], "Categories": "cs.LG"}, "abstract": "We consider the problem of learning a model from multiple heterogeneous sources with the goal of performing well on a new target distribution. The goal of learner is to mix these data sources in a target-distribution aware way and simultaneously minimize the empirical risk on the mixed source. The literature has made some tangible advancements in establishing theory of learning on mixture domain. However, there are still two unsolved problems. Firstly, how to estimate the optimal mixture of sources, given a target domain; Secondly, when there are numerous target domains, how to solve empirical risk minimization (ERM) for each target using possibly unique mixture of data sources in a computationally efficient manner. In this paper we address both problems efficiently and with guarantees. We cast the first problem, mixture weight estimation, as a convex-nonconcave compositional minimax problem, and propose an efficient stochastic algorithm with provable stationarity guarantees. Next, for the second problem, we identify that for certain regimes, solving ERM for each target domain individually can be avoided, and instead parameters for a target optimal model can be viewed as a non-linear function on a space of the mixture coefficients. Building upon this, we show that in the offline setting, a GD-trained overparameterized neural network can provably learn such function to predict the model of target domain instead of solving a designated ERM problem. Finally, we also consider an online setting and propose a label efficient online algorithm, which predicts parameters for new targets given an arbitrary sequence of mixing coefficients, while enjoying regret guarantees.", "url": "https://arxiv.org/abs/2309.10736"}, {"metadata": {"arXiv": "2309.10773", "Date": "Tue, 19 Sep 2023 17:20:58 ", "Title": "Semi-supervised Domain Adaptation in Graph Transfer Learning", "Authors": ["Ziyue Qiao", "Xiao Luo", "Meng Xiao", "Hao Dong", "Yuanchun Zhou", "and Hui Xiong"], "Categories": "cs.LG"}, "abstract": "As a specific case of graph transfer learning, unsupervised domain adaptation on graphs aims for knowledge transfer from label-rich source graphs to unlabeled target graphs. However, graphs with topology and attributes usually have considerable cross-domain disparity and there are numerous real-world scenarios where merely a subset of nodes are labeled in the source graph. This imposes critical challenges on graph transfer learning due to serious domain shifts and label scarcity. To address these challenges, we propose a method named Semi-supervised Graph Domain Adaptation (SGDA). To deal with the domain shift, we add adaptive shift parameters to each of the source nodes, which are trained in an adversarial manner to align the cross-domain distributions of node embedding, thus the node classifier trained on labeled source nodes can be transferred to the target nodes. Moreover, to address the label scarcity, we propose pseudo-labeling on unlabeled nodes, which improves classification on the target graph via measuring the posterior influence of nodes based on their relative position to the class centroids. Finally, extensive experiments on a range of publicly accessible datasets validate the effectiveness of our proposed SGDA in different experimental settings.", "url": "https://arxiv.org/abs/2309.10773"}, {"metadata": {"arXiv": "2309.10150", "Date": "Mon, 18 Sep 2023 21:00:38 ", "Title": "Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions", "Authors": ["Yevgen Chebotar", "Quan Vuong", "Alex Irpan", "Karol Hausman", "Fei Xia", "Yao Lu", "Aviral Kumar", "Tianhe Yu", "Alexander Herzog", "Karl Pertsch", "Keerthana Gopalakrishnan", "Julian Ibarz", "Ofir Nachum", "Sumedh Sontakke", "Grecia Salazar", "Huong T Tran", "Jodilyn Peralta", "Clayton Tan", "Deeksha Manjunath", "Jaspiar Singht", "Brianna Zitkovich", "Tomas Jackson", "Kanishka Rao", "Chelsea Finn", "Sergey Levine"], "Categories": "cs.RO cs.LG", "Comments": ["See website at https://q-transformer.github.io"]}, "abstract": "In this work, we present a scalable reinforcement learning method for training multi-task policies from large offline datasets that can leverage both human demonstrations and autonomously collected data. Our method uses a Transformer to provide a scalable representation for Q-functions trained via offline temporal difference backups. We therefore refer to the method as Q-Transformer. By discretizing each action dimension and representing the Q-value of each action dimension as separate tokens, we can apply effective high-capacity sequence modeling techniques for Q-learning. We present several design decisions that enable good performance with offline RL training, and show that Q-Transformer outperforms prior offline RL algorithms and imitation learning techniques on a large diverse real-world robotic manipulation task suite. The project's website and videos can be found at https://q-transformer.github.io", "url": "https://arxiv.org/abs/2309.10150"}, {"metadata": {"arXiv": "2309.10175", "Date": "Mon, 18 Sep 2023 21:50:26 ", "Title": "One ACT Play: Single Demonstration Behavior Cloning with Action Chunking Transformers", "Authors": ["Abraham George and Amir Barati Farimani"], "Categories": "cs.RO cs.LG", "Comments": ["7 pages", "6 figures"]}, "abstract": "Learning from human demonstrations (behavior cloning) is a cornerstone of robot learning. However, most behavior cloning algorithms require a large number of demonstrations to learn a task, especially for general tasks that have a large variety of initial conditions. Humans, however, can learn to complete tasks, even complex ones, after only seeing one or two demonstrations. Our work seeks to emulate this ability, using behavior cloning to learn a task given only a single human demonstration. We achieve this goal by using linear transforms to augment the single demonstration, generating a set of trajectories for a wide range of initial conditions. With these demonstrations, we are able to train a behavior cloning agent to successfully complete three block manipulation tasks. Additionally, we developed a novel addition to the temporal ensembling method used by action chunking agents during inference. By incorporating the standard deviation of the action predictions into the ensembling method, our approach is more robust to unforeseen changes in the environment, resulting in significant performance improvements.", "url": "https://arxiv.org/abs/2309.10175"}, {"metadata": {"arXiv": "2309.10298", "Date": "Tue, 19 Sep 2023 04:03:42 ", "Title": "Learning Orbitally Stable Systems for Diagrammatically Teaching", "Authors": ["Weiming Zhi", "Kangni Liu", "Tianyi Zhang", "Matthew Johnson-Roberson"], "Categories": "cs.RO cs.LG"}, "abstract": "Diagrammatic Teaching is a paradigm for robots to acquire novel skills, whereby the user provides 2D sketches over images of the scene to shape the robot's motion. In this work, we tackle the problem of teaching a robot to approach a surface and then follow cyclic motion on it, where the cycle of the motion can be arbitrarily specified by a single user-provided sketch over an image from the robot's camera. Accordingly, we introduce the \\emph{Stable Diffeomorphic Diagrammatic Teaching} (SDDT) framework. SDDT models the robot's motion as an \\emph{Orbitally Asymptotically Stable} (O.A.S.) dynamical system that learns to follow the user-specified sketch. This is achieved by applying a \\emph{diffeomorphism}, i.e. a differentiable and invertible function, to morph a known O.A.S. system. The parameterised diffeomorphism is then optimised with respect to the Hausdorff distance between the limit cycle of our modelled system and the sketch, to produce the desired robot motion. We provide theoretical insight into the behaviour of the optimised system and also empirically evaluate SDDT, both in simulation and on a quadruped with a mounted 6-DOF manipulator. Results show that we can diagrammatically teach complex cyclic motion patterns with a high degree of accuracy.", "url": "https://arxiv.org/abs/2309.10298"}, {"metadata": {"arXiv": "2309.10657", "Date": "Tue, 19 Sep 2023 14:39:39 ", "Title": "Learning Adaptive Safety for Multi-Agent Systems", "Authors": ["Luigi Berducci", "Shuo Yang", "Rahul Mangharam", "Radu Grosu"], "Categories": "cs.RO cs.LG cs.MA cs.SY eess.SY"}, "abstract": "Ensuring safety in dynamic multi-agent systems is challenging due to limited information about the other agents. Control Barrier Functions (CBFs) are showing promise for safety assurance but current methods make strong assumptions about other agents and often rely on manual tuning to balance safety, feasibility, and performance. In this work, we delve into the problem of adaptive safe learning for multi-agent systems with CBF. We show how emergent behavior can be profoundly influenced by the CBF configuration, highlighting the necessity for a responsive and dynamic approach to CBF design. We present ASRL, a novel adaptive safe RL framework, to fully automate the optimization of policy and CBF coefficients, to enhance safety and long-term performance through reinforcement learning. By directly interacting with the other agents, ASRL learns to cope with diverse agent behaviours and maintains the cost violations below a desired limit. We evaluate ASRL in a multi-robot system and a competitive multi-agent racing scenario, against learning-based and control-theoretic approaches. We empirically demonstrate the efficacy and flexibility of ASRL, and assess generalization and scalability to out-of-distribution scenarios. Code and supplementary material are public online.", "url": "https://arxiv.org/abs/2309.10657"}, {"metadata": {"arXiv": "2309.09992", "Date": "Fri, 15 Sep 2023 20:00:27 ", "Title": "OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?", "Authors": ["Andrew Blair-Stanek", "Nils Holzenberger", "Benjamin Van Durme"], "Categories": "cs.AI cs.CL", "Comments": ["5 pages"], "ACM-class": "I.2.7; I.2.0", "Journal-ref": "180 TAX NOTES FEDERAL 1101 (AUG. 14, 2023)"}, "abstract": "The authors explain where OpenAI got the tax law example in its livestream demonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails to reliably calculate taxes.", "url": "https://arxiv.org/abs/2309.09992"}, {"metadata": {"arXiv": "2309.10066", "Date": "Mon, 18 Sep 2023 18:33:40 ", "Title": "Automatic Personalized Impression Generation for PET Reports Using Large Language Models", "Authors": ["Xin Tie", "Muheon Shin", "Ali Pirasteh", "Nevein Ibrahim", "Zachary Huemann", "Sharon M. Castellino", "Kara M. Kelly", "John Garrett", "Junjie Hu", "Steve Y. Cho", "Tyler J. Bradshaw"], "Categories": "cs.AI cs.CL physics.med-ph", "Comments": ["18 pages for the main body", "13 pages for the appendix. 6 figures and 3 tables in the main body. This manuscript is submitted to Radiology: Artificial Intelligence"]}, "abstract": "Purpose: To determine if fine-tuned large language models (LLMs) can generate accurate, personalized impressions for whole-body PET reports. Materials and Methods: Twelve language models were trained on a corpus of PET reports using the teacher-forcing algorithm, with the report findings as input and the clinical impressions as reference. An extra input token encodes the reading physician's identity, allowing models to learn physician-specific reporting styles. Our corpus comprised 37,370 retrospective PET reports collected from our institution between 2010 and 2022. To identify the best LLM, 30 evaluation metrics were benchmarked against quality scores from two nuclear medicine (NM) physicians, with the most aligned metrics selecting the model for expert evaluation. In a subset of data, model-generated impressions and original clinical impressions were assessed by three NM physicians according to 6 quality dimensions and an overall utility score (5-point scale). Each physician reviewed 12 of their own reports and 12 reports from other physicians. Bootstrap resampling was used for statistical analysis. Results: Of all evaluation metrics, domain-adapted BARTScore and PEGASUSScore showed the highest Spearman's rho correlations (0.568 and 0.563) with physician preferences. Based on these metrics, the fine-tuned PEGASUS model was selected as the top LLM. When physicians reviewed PEGASUS-generated impressions in their own style, 89% were considered clinically acceptable, with a mean utility score of 4.08/5. Physicians rated these personalized impressions as comparable in overall utility to the impressions dictated by other physicians (4.03, P=0.41). Conclusion: Personalized impressions generated by PEGASUS were clinically useful, highlighting its potential to expedite PET reporting.", "url": "https://arxiv.org/abs/2309.10066"}, {"metadata": {"arXiv": "2309.10129", "Date": "Mon, 18 Sep 2023 20:10:28 ", "Title": "Adaptive Liquidity Provision in Uniswap V3 with Deep Reinforcement Learning", "Authors": ["Haochen Zhang and Xi Chen and Lin F. Yang"], "Categories": "cs.AI", "Comments": ["15 pages", "5 figures", "9 tables", "submitted to Financial Cryptography and Data Security 2024"]}, "abstract": "Decentralized exchanges (DEXs) are a cornerstone of decentralized finance (DeFi), allowing users to trade cryptocurrencies without the need for third-party authorization. Investors are incentivized to deposit assets into liquidity pools, against which users can trade directly, while paying fees to liquidity providers (LPs). However, a number of unresolved issues related to capital efficiency and market risk hinder DeFi's further development. Uniswap V3, a leading and groundbreaking DEX project, addresses capital efficiency by enabling LPs to concentrate their liquidity within specific price ranges for deposited assets. Nevertheless, this approach exacerbates market risk, as LPs earn trading fees only when asset prices are within these predetermined brackets. To mitigate this issue, this paper introduces a deep reinforcement learning (DRL) solution designed to adaptively adjust these price ranges, maximizing profits and mitigating market risks. Our approach also neutralizes price-change risks by hedging the liquidity position through a rebalancing portfolio in a centralized futures exchange. The DRL policy aims to optimize trading fees earned by LPs against associated costs, such as gas fees and hedging expenses, which is referred to as loss-versus-rebalancing (LVR). Using simulations with a profit-and-loss (PnL) benchmark, our method demonstrates superior performance in ETH/USDC and ETH/USDT pools compared to existing baselines. We believe that this strategy not only offers investors a valuable asset management tool but also introduces a new incentive mechanism for DEX designers.", "url": "https://arxiv.org/abs/2309.10129"}, {"metadata": {"arXiv": "2309.10209", "Date": "Mon, 18 Sep 2023 23:48:22 ", "Title": "Towards Effective Semantic OOD Detection in Unseen Domains: A Domain Generalization Perspective", "Authors": ["Haoliang Wang", "Chen Zhao", "Yunhui Guo", "Kai Jiang", "Feng Chen"], "Categories": "cs.AI"}, "abstract": "Two prevalent types of distributional shifts in machine learning are the covariate shift (as observed across different domains) and the semantic shift (as seen across different classes). Traditional OOD detection techniques typically address only one of these shifts. However, real-world testing environments often present a combination of both covariate and semantic shifts. In this study, we introduce a novel problem, semantic OOD detection across domains, which simultaneously addresses both distributional shifts. To this end, we introduce two regularization strategies: domain generalization regularization, which ensures semantic invariance across domains to counteract the covariate shift, and OOD detection regularization, designed to enhance OOD detection capabilities against the semantic shift through energy bounding. Through rigorous testing on three standard domain generalization benchmarks, our proposed framework showcases its superiority over conventional domain generalization approaches in terms of OOD detection performance. Moreover, it holds its ground by maintaining comparable InD classification accuracy.", "url": "https://arxiv.org/abs/2309.10209"}, {"metadata": {"arXiv": "2309.10216", "Date": "Tue, 19 Sep 2023 00:02:05 ", "Title": "Safe POMDP Online Planning via Shielding", "Authors": ["Shili Sheng", "David Parker and Lu Feng"], "Categories": "cs.AI"}, "abstract": "Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees that are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions violating almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored variants designed to improve scalability. Experimental results on a set of benchmark domains demonstrate that the proposed shielding methods successfully guarantee safety (unlike the baseline POMCP without shielding) on large POMDPs, with negligible impact on the runtime for online planning.", "url": "https://arxiv.org/abs/2309.10216"}, {"metadata": {"arXiv": "2309.10253", "Date": "Tue, 19 Sep 2023 02:19:48 ", "Title": "GPTFUZZER : Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts", "Authors": ["Jiahao Yu", "Xingwei Lin", "Xinyu Xing"], "Categories": "cs.AI"}, "abstract": "Large language models (LLMs) have recently experienced tremendous popularity and are widely used from casual conversations to AI-driven programming. However, despite their considerable success, LLMs are not entirely reliable and can give detailed guidance on how to conduct harmful or illegal activities. While safety measures can reduce the risk of such outputs, adversarial \"jailbreak\" attacks can still exploit LLMs to produce harmful content. These jailbreak templates are typically manually crafted, making large-scale testing challenging. In this paper, we introduce \\fuzzer, a novel black-box jailbreak fuzzing framework inspired by AFL fuzzing framework. Instead of manual engineering, \\fuzzer automates the generation of jailbreak templates for red-teaming LLMs. At its core, \\fuzzer starts with human-written templates as seeds, then mutates them using mutate operators to produce new templates. We detail three key components of \\fuzzer: a seed selection strategy for balancing efficiency and variability, metamorphic relations for creating semantically equivalent or similar sentences, and a judgment model to assess the success of a jailbreak attack. We tested \\fuzzer on various commercial and open-source LLMs, such as ChatGPT, LLaMa-2, and Claude2, under diverse attack scenarios. Our results indicate that \\fuzzer consistently produces jailbreak templates with a high success rate, even in settings where all human-crafted templates fail. Notably, even starting with suboptimal seed templates, \\fuzzer maintains over 90\\% attack success rate against ChatGPT and Llama-2 models. We believe \\fuzzer will aid researchers and practitioners in assessing LLM robustness and will spur further research into LLM safety.", "url": "https://arxiv.org/abs/2309.10253"}, {"metadata": {"arXiv": "2309.10293", "Date": "Tue, 19 Sep 2023 03:50:30 ", "Title": "QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Haoran Xie", "Lin Li", "Juan D. Velasquez", "Niall Higgins"], "Categories": "cs.AI", "Comments": ["This work has been submitted to the ELSEVIER for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Artificial Intelligence techniques can be used to classify a patient's physical activities and predict vital signs for remote patient monitoring. Regression analysis based on non-linear models like deep learning models has limited explainability due to its black-box nature. This can require decision-makers to make blind leaps of faith based on non-linear model results, especially in healthcare applications. In non-invasive monitoring, patient data from tracking sensors and their predisposing clinical attributes act as input features for predicting future vital signs. Explaining the contributions of various features to the overall output of the monitoring application is critical for a clinician's decision-making. In this study, an Explainable AI for Quantitative analysis (QXAI) framework is proposed with post-hoc model explainability and intrinsic explainability for regression and classification tasks in a supervised learning approach. This was achieved by utilizing the Shapley values concept and incorporating attention mechanisms in deep learning models. We adopted the artificial neural networks (ANN) and attention-based Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and classification of physical activities based on sensor data. The deep learning models achieved state-of-the-art results in both prediction and classification tasks. Global explanation and local explanation were conducted on input data to understand the feature contribution of various patient data. The proposed QXAI framework was evaluated using PPG-DaLiA data to predict heart rate and mobile health (MHEALTH) data to classify physical activities based on sensor data. Monte Carlo approximation was applied to the framework to overcome the time complexity and high computation power requirements required for Shapley value calculations.", "url": "https://arxiv.org/abs/2309.10293"}, {"metadata": {"arXiv": "2309.10318", "Date": "Tue, 19 Sep 2023 05:00:34 ", "Title": "Who to Trust, How and Why: Untangling AI Ethics Principles, Trustworthiness and Trust", "Authors": ["Andreas Duenser and David M. Douglas"], "Categories": "cs.AI cs.CY", "Comments": ["7 pages", "1 table"], "ACM-class": "I.2.0; J.4; K.4.1"}, "abstract": "We present an overview of the literature on trust in AI and AI trustworthiness and argue for the need to distinguish these concepts more clearly and to gather more empirically evidence on what contributes to people s trusting behaviours. We discuss that trust in AI involves not only reliance on the system itself, but also trust in the developers of the AI system. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system s trustworthiness is not as abundance or not that clear. AI systems should be recognised as socio-technical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognising these nuances, trust in AI and trustworthy AI risk becoming nebulous terms for any desirable feature for AI systems.", "url": "https://arxiv.org/abs/2309.10318"}, {"metadata": {"arXiv": "2309.10324", "Date": "Tue, 19 Sep 2023 05:12:02 ", "Title": "Metastatic Breast Cancer Prognostication Through Multimodal Integration of Dimensionality Reduction Algorithms and Classification Algorithms", "Authors": ["Bliss Singhal", "Fnu Pooja"], "Categories": "cs.AI", "Comments": ["10 pages", "14 figures"]}, "abstract": "Machine learning (ML) is a branch of Artificial Intelligence (AI) where computers analyze data and find patterns in the data. The study focuses on the detection of metastatic cancer using ML. Metastatic cancer is the point where the cancer has spread to other parts of the body and is the cause of approximately 90% of cancer related deaths. Normally, pathologists spend hours each day to manually classify whether tumors are benign or malignant. This tedious task contributes to mislabeling metastasis being over 60% of time and emphasizes the importance to be aware of human error, and other inefficiencies. ML is a good candidate to improve the correct identification of metastatic cancer saving thousands of lives and can also improve the speed and efficiency of the process thereby taking less resources and time. So far, deep learning methodology of AI has been used in the research to detect cancer. This study is a novel approach to determine the potential of using preprocessing algorithms combined with classification algorithms in detecting metastatic cancer. The study used two preprocessing algorithms: principal component analysis (PCA) and the genetic algorithm to reduce the dimensionality of the dataset, and then used three classification algorithms: logistic regression, decision tree classifier, and k-nearest neighbors to detect metastatic cancer in the pathology scans. The highest accuracy of 71.14% was produced by the ML pipeline comprising of PCA, the genetic algorithm, and the k-nearest neighbors algorithm, suggesting that preprocessing and classification algorithms have great potential for detecting metastatic cancer.", "url": "https://arxiv.org/abs/2309.10324"}, {"metadata": {"arXiv": "2309.10371", "Date": "Tue, 19 Sep 2023 07:12:55 ", "Title": "Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs", "Authors": ["Ben Goertzel"], "Categories": "cs.AI"}, "abstract": "A moderately detailed consideration of interactive LLMs as cognitive systems is given, focusing on LLMs circa mid-2023 such as ChatGPT, GPT-4, Bard, Llama, etc.. Cognitive strengths of these systems are reviewed, and then careful attention is paid to the substantial differences between the sort of cognitive system these LLMs are, and the sort of cognitive systems human beings are. It is found that many of the practical weaknesses of these AI systems can be tied specifically to lacks in the basic cognitive architectures according to which these systems are built. It is argued that incremental improvement of such LLMs is not a viable approach to working toward human-level AGI, in practical terms given realizable amounts of compute resources. This does not imply there is nothing to learn about human-level AGI from studying and experimenting with LLMs, nor that LLMs cannot form significant parts of human-level AGI architectures that also incorporate other ideas. Social and ethical matters regarding LLMs are very briefly touched from this perspective, which implies that while care should be taken regarding misinformation and other issues, and economic upheavals will need their own social remedies based on their unpredictable course as with any powerfully impactful technology, overall the sort of policy needed as regards modern LLMs is quite different than would be the case if a more credible approximation to human-level AGI were at hand.", "url": "https://arxiv.org/abs/2309.10371"}, {"metadata": {"arXiv": "2309.10398", "Date": "Tue, 19 Sep 2023 07:59:13 ", "Title": "Adaptive questionnaires for facilitating patient data entry in clinical decision support systems: Methods and application to STOPP/START v2", "Authors": ["Jean-Baptiste Lamy", "Abdelmalek Mouazer", "Karima Sedki", "Sophie Dubois", "Hector Falcoff"], "Categories": "cs.AI cs.HC"}, "abstract": "Clinical decision support systems are software tools that help clinicians to make medical decisions. However, their acceptance by clinicians is usually rather low. A known problem is that they often require clinicians to manually enter lots of patient data, which is long and tedious. Existing solutions, such as the automatic data extraction from electronic health record, are not fully satisfying, because of low data quality and availability. In practice, many systems still include long questionnaire for data entry. In this paper, we propose an original solution to simplify patient data entry, using an adaptive questionnaire, i.e. a questionnaire that evolves during user interaction, showing or hiding questions dynamically. Considering a rule-based decision support systems, we designed methods for translating the system's clinical rules into display rules that determine the items to show in the questionnaire, and methods for determining the optimal order of priority among the items in the questionnaire. We applied this approach to a decision support system implementing STOPP/START v2, a guideline for managing polypharmacy. We show that it permits reducing by about two thirds the number of clinical conditions displayed in the questionnaire. Presented to clinicians during focus group sessions, the adaptive questionnaire was found \"pretty easy to use\". In the future, this approach could be applied to other guidelines, and adapted for data entry by patients.", "url": "https://arxiv.org/abs/2309.10398"}, {"metadata": {"arXiv": "2309.10424", "Date": "Tue, 19 Sep 2023 08:37:22 ", "Title": "Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare", "Authors": ["Juan M. Garc\\'ia-G\\'omez", "Vicent Blanes-Selva", "Jos\\'e Carlos de Bartolom\\'e Cenzano", "Jaime Cebolla-Cornejo and Ascensi\\'on Do\\~nate-Mart\\'inez"], "Categories": "cs.AI", "Comments": ["14 pages", "1 figure", "1 table"], "MSC-class": "68"}, "abstract": "The Directorate General for Parliamentary Research Services of the European Parliament has prepared a report to the Members of the European Parliament where they enumerate seven main risks of Artificial Intelligence (AI) in medicine and healthcare: patient harm due to AI errors, misuse of medical AI tools, bias in AI and the perpetuation of existing inequities, lack of transparency, privacy and security issues, gaps in accountability, and obstacles in implementation. In this study, we propose fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose: AI passport, User management, Regulation check, Academic use only disclaimer, data quality assessment, Clinicians double check, Continuous performance evaluation, Audit trail, Continuous usability test, Review of retrospective/simulated cases, Bias check, eXplainable AI, Encryption and use of field-tested libraries, and Semantic interoperability. Our intention here is to provide specific high-level specifications of technical solutions to ensure continuous good performance and use of AI systems to benefit patients in compliance with the future EU regulatory framework.", "url": "https://arxiv.org/abs/2309.10424"}, {"metadata": {"arXiv": "2309.10444", "Date": "Tue, 19 Sep 2023 09:04:15 ", "Title": "Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models", "Authors": ["Qiming Bao", "Juho Leinonen", "Alex Yuxuan Peng", "Wanjun Zhong", "Tim Pistotti", "Alice Huang", "Paul Denny", "Michael Witbrock and Jiamou Liu"], "Categories": "cs.AI cs.CL", "Comments": ["Preprint. Under review"]}, "abstract": "Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates the manner in which students compose explanations at the relevant grade level. For evaluation, we had a human subject-matter expert compare the explanations generated by students with the explanations created by the open-source large language model Vicuna-13B, a version of Vicuna-13B that had been fine-tuned using our method, and by GPT-4. We observed that, when compared to other large language models, GPT-4 exhibited a higher level of creativity in generating explanations. We also found that explanations generated by GPT-4 were ranked higher by the human expert than both those created by the other models and the original student-created explanations. Our findings represent a significant advancement in enriching the learnersourcing experience for students and enhancing the capabilities of large language models in educational applications.", "url": "https://arxiv.org/abs/2309.10444"}, {"metadata": {"arXiv": "2309.10448", "Date": "Tue, 19 Sep 2023 09:09:59 ", "Title": "Human-AI Interactions and Societal Pitfalls", "Authors": ["Francisco Castro", "Jian Gao", "S\\'ebastien Martin"], "Categories": "cs.AI cs.HC econ.GN q-fin.EC"}, "abstract": "When working with generative artificial intelligence (AI), users may see productivity gains, but the AI-generated content may not match their preferences exactly. To study this effect, we introduce a Bayesian framework in which heterogeneous users choose how much information to share with the AI, facing a trade-off between output fidelity and communication cost. We show that the interplay between these individual-level decisions and AI training may lead to societal challenges. Outputs may become more homogenized, especially when the AI is trained on AI-generated content. And any AI bias may become societal bias. A solution to the homogenization and bias issues is to improve human-AI interactions, enabling personalized outputs without sacrificing productivity.", "url": "https://arxiv.org/abs/2309.10448"}, {"metadata": {"arXiv": "2309.10532", "Date": "Tue, 19 Sep 2023 11:18:01 ", "Title": "A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning Using Contrastive Perceptual and Conceptual Processing", "Authors": ["Yuan Yang", "Deepayan Sanyal", "James Ainooson", "Joel Michelson", "Effat Farhana", "Maithilee Kunda"], "Categories": "cs.AI"}, "abstract": "We introduce a new neural architecture for solving visual abstract reasoning tasks inspired by human cognition, specifically by observations that human abstract reasoning often interleaves perceptual and conceptual processing as part of a flexible, iterative, and dynamic cognitive process. Inspired by this principle, our architecture models visual abstract reasoning as an iterative, self-contrasting learning process that pursues consistency between perceptual and conceptual processing of visual stimuli. We explain how this new Contrastive Perceptual-Conceptual Network (CPCNet) works using matrix reasoning problems in the style of the well-known Raven's Progressive Matrices intelligence test. Experiments on the machine learning dataset RAVEN show that CPCNet achieves higher accuracy than all previously published models while also using the weakest inductive bias. We also point out a substantial and previously unremarked class imbalance in the original RAVEN dataset, and we propose a new variant of RAVEN -- AB-RAVEN -- that is more balanced in terms of abstract concepts.", "url": "https://arxiv.org/abs/2309.10532"}, {"metadata": {"arXiv": "2309.10547", "Date": "Tue, 19 Sep 2023 11:52:57 ", "Title": "Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion", "Authors": ["Zhilun Zhou", "Jingtao Ding", "Yu Liu", "Depeng Jin", "Yong Li"], "Categories": "cs.AI cs.SI"}, "abstract": "Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of urban applications. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.", "url": "https://arxiv.org/abs/2309.10547"}, {"metadata": {"arXiv": "2309.10625", "Date": "Tue, 19 Sep 2023 14:04:04 ", "Title": "Exploring the Influence of Information Entropy Change in Learning Systems", "Authors": ["Xiaowei Yu", "Yao Xue", "Lu Zhang", "Li Wang", "Tianming Liu", "Dajiang Zhu"], "Categories": "cs.AI cs.CV", "Comments": ["Information Entropy", "CNN", "Transformer"]}, "abstract": "In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features. The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields. Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the information entropy to define the complexity of the task. We categorize the noise into two types, positive noise (PN) and harmful noise (HN), based on whether the noise can help reduce the complexity of the task. Extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, where we achieved an unprecedented top 1 accuracy of over 95% on ImageNet. Both theoretical analysis and empirical evidence have confirmed that the presence of positive noise can benefit the learning process, while the traditionally perceived harmful noise indeed impairs deep learning models. The different roles of noise offer new explanations for deep models on specific tasks and provide a new paradigm for improving model performance. Moreover, it reminds us that we can influence the performance of learning systems via information entropy change.", "url": "https://arxiv.org/abs/2309.10625"}, {"metadata": {"arXiv": "2309.10701", "Date": "Tue, 19 Sep 2023 15:40:42 ", "Title": "Measurement Simplification in \\rho-POMDP with Performance Guarantees", "Authors": ["Tom Yotam", "Vadim Indelman"], "Categories": "cs.AI cs.RO"}, "abstract": "Decision making under uncertainty is at the heart of any autonomous system acting with imperfect information. The cost of solving the decision making problem is exponential in the action and observation spaces, thus rendering it unfeasible for many online systems. This paper introduces a novel approach to efficient decision-making, by partitioning the high-dimensional observation space. Using the partitioned observation space, we formulate analytical bounds on the expected information-theoretic reward, for general belief distributions. These bounds are then used to plan efficiently while keeping performance guarantees. We show that the bounds are adaptive, computationally efficient, and that they converge to the original solution. We extend the partitioning paradigm and present a hierarchy of partitioned spaces that allows greater efficiency in planning. We then propose a specific variant of these bounds for Gaussian beliefs and show a theoretical performance improvement of at least a factor of 4. Finally, we compare our novel method to other state of the art algorithms in active SLAM scenarios, in simulation and in real experiments. In both cases we show a significant speed-up in planning with performance guarantees.", "url": "https://arxiv.org/abs/2309.10701"}, {"metadata": {"arXiv": "2309.10737", "Date": "Tue, 19 Sep 2023 16:32:04 ", "Title": "Monte-Carlo tree search with uncertainty propagation via optimal transport", "Authors": ["Tuan Dam", "Pascal Stenger", "Lukas Schneider", "Joni Pajarinen", "Carlo D'Eramo", "Odalric-Ambrym Maillard"], "Categories": "cs.AI"}, "abstract": "This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) designed for highly stochastic and partially observable Markov decision processes. We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions. We introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node. We study our novel backup operator when using a novel combination of $L^1$-Wasserstein barycenter with $\\alpha$-divergence, by drawing a notable connection to the generalized mean backup operator. We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm. We provide theoretical guarantees of asymptotic convergence to the optimal policy, and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines.", "url": "https://arxiv.org/abs/2309.10737"}, {"metadata": {"arXiv": "2309.10144", "Date": "Mon, 18 Sep 2023 20:47:57 ", "Title": "Human Gait Recognition using Deep Learning: A Comprehensive Review", "Authors": ["Muhammad Imran Sharif", "Mehwish Mehmood", "Muhammad Irfan Sharif and Md Palash Uddin"], "Categories": "cs.CV cs.AI"}, "abstract": "Gait recognition (GR) is a growing biometric modality used for person identification from a distance through visual cameras. GR provides a secure and reliable alternative to fingerprint and face recognition, as it is harder to distinguish between false and authentic signals. Furthermore, its resistance to spoofing makes GR suitable for all types of environments. With the rise of deep learning, steadily improving strides have been made in GR technology with promising results in various contexts. As video surveillance becomes more prevalent, new obstacles arise, such as ensuring uniform performance evaluation across different protocols, reliable recognition despite shifting lighting conditions, fluctuations in gait patterns, and protecting privacy.This survey aims to give an overview of GR and analyze the environmental elements and complications that could affect it in comparison to other biometric recognition systems. The primary goal is to examine the existing deep learning (DL) techniques employed for human GR that may generate new research opportunities.", "url": "https://arxiv.org/abs/2309.10144"}, {"metadata": {"arXiv": "2309.10217", "Date": "Tue, 19 Sep 2023 00:07:57 ", "Title": "An Empirical Study of Attention Networks for Semantic Segmentation", "Authors": ["Hao Guo", "Hongbiao Si", "Guilin Jiang", "Wei Zhang", "Zhiyan Liu", "Xuanyi Zhu", "Xulong Zhang", "Yang Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by the 7th APWeb-WAIM International Joint Conference on Web and Big Data. (APWeb 2023)"]}, "abstract": "Semantic segmentation is a vital problem in computer vision. Recently, a common solution to semantic segmentation is the end-to-end convolution neural network, which is much more accurate than traditional methods.Recently, the decoders based on attention achieve state-of-the-art (SOTA) performance on various datasets. But these networks always are compared with the mIoU of previous SOTA networks to prove their superiority and ignore their characteristics without considering the computation complexity and precision in various categories, which is essential for engineering applications. Besides, the methods to analyze the FLOPs and memory are not consistent between different networks, which makes the comparison hard to be utilized. What's more, various methods utilize attention in semantic segmentation, but the conclusion of these methods is lacking. This paper first conducts experiments to analyze their computation complexity and compare their performance. Then it summarizes suitable scenes for these networks and concludes key points that should be concerned when constructing an attention network. Last it points out some future directions of the attention network.", "url": "https://arxiv.org/abs/2309.10217"}, {"metadata": {"arXiv": "2309.10219", "Date": "Tue, 19 Sep 2023 00:18:50 ", "Title": "Multi-level feature fusion network combining attention mechanisms for polyp segmentation", "Authors": ["Junzhuo Liu", "Qiaosong Chen", "Ye Zhang", "Zhixiang Wang", "Deng Xin", "Jin Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Clinically, automated polyp segmentation techniques have the potential to significantly improve the efficiency and accuracy of medical diagnosis, thereby reducing the risk of colorectal cancer in patients. Unfortunately, existing methods suffer from two significant weaknesses that can impact the accuracy of segmentation. Firstly, features extracted by encoders are not adequately filtered and utilized. Secondly, semantic conflicts and information redundancy caused by feature fusion are not attended to. To overcome these limitations, we propose a novel approach for polyp segmentation, named MLFF-Net, which leverages multi-level feature fusion and attention mechanisms. Specifically, MLFF-Net comprises three modules: Multi-scale Attention Module (MAM), High-level Feature Enhancement Module (HFEM), and Global Attention Module (GAM). Among these, MAM is used to extract multi-scale information and polyp details from the shallow output of the encoder. In HFEM, the deep features of the encoders complement each other by aggregation. Meanwhile, the attention mechanism redistributes the weight of the aggregated features, weakening the conflicting redundant parts and highlighting the information useful to the task. GAM combines features from the encoder and decoder features, as well as computes global dependencies to prevent receptive field locality. Experimental results on five public datasets show that the proposed method not only can segment multiple types of polyps but also has advantages over current state-of-the-art methods in both accuracy and generalization ability.", "url": "https://arxiv.org/abs/2309.10219"}, {"metadata": {"arXiv": "2309.10360", "Date": "Tue, 19 Sep 2023 06:43:18 ", "Title": "OccluTrack: Rethinking Awareness of Occlusion for Enhancing Multiple Pedestrian Tracking", "Authors": ["Jianjun Gao", "Yi Wang", "Kim-Hui Yap", "Kratika Garg", "and Boon Siew Han"], "Categories": "cs.CV cs.AI"}, "abstract": "Multiple pedestrian tracking faces the challenge of tracking pedestrians in the presence of occlusion. Existing methods suffer from inaccurate motion estimation, appearance feature extraction, and association due to occlusion, leading to inadequate Identification F1-Score (IDF1), excessive ID switches (IDSw), and insufficient association accuracy and recall (AssA and AssR). We found that the main reason is abnormal detections caused by partial occlusion. In this paper, we suggest that the key insight is explicit motion estimation, reliable appearance features, and fair association in occlusion scenes. Specifically, we propose an adaptive occlusion-aware multiple pedestrian tracker, OccluTrack. We first introduce an abnormal motion suppression mechanism into the Kalman Filter to adaptively detect and suppress outlier motions caused by partial occlusion. Second, we propose a pose-guided re-ID module to extract discriminative part features for partially occluded pedestrians. Last, we design a new occlusion-aware association method towards fair IoU and appearance embedding distance measurement for occluded pedestrians. Extensive evaluation results demonstrate that our OccluTrack outperforms state-of-the-art methods on MOT-Challenge datasets. Particularly, the improvements on IDF1, IDSw, AssA, and AssR demonstrate the effectiveness of our OccluTrack on tracking and association performance.", "url": "https://arxiv.org/abs/2309.10360"}, {"metadata": {"arXiv": "2309.10399", "Date": "Tue, 19 Sep 2023 08:00:26 ", "Title": "Exploiting Causality Signals in Medical Images: A Pilot Study with Empirical Results", "Authors": ["Gianluca Carloni", "Sara Colantonio"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "4 figures", "submitted to Elsevier"], "ACM-class": "I.5; I.2.6; I.4.7; I.4.10; J.3"}, "abstract": "We present a new method for automatically classifying medical images that uses weak causal signals in the scene to model how the presence of a feature in one part of the image affects the appearance of another feature in a different part of the image. Our method consists of two components: a convolutional neural network backbone and a causality-factors extractor module. The latter computes weights for the feature maps to enhance each feature map according to its causal influence in the image's scene. We can modify the functioning of the causality module by using two external signals, thus obtaining different variants of our method. We evaluate our method on a public dataset of prostate MRI images for prostate cancer diagnosis, using quantitative experiments, qualitative assessment, and ablation studies. Our results show that our method improves classification performance and produces more robust predictions, focusing on relevant parts of the image. That is especially important in medical imaging, where accurate and reliable classifications are essential for effective diagnosis and treatment planning.", "url": "https://arxiv.org/abs/2309.10399"}, {"metadata": {"arXiv": "2309.10472", "Date": "Tue, 19 Sep 2023 09:39:55 ", "Title": "Fully automated landmarking and facial segmentation on 3D photographs", "Authors": ["Bo Berends", "Freek Bielevelt", "Ruud Schreurs", "Shankeeth Vinayahalingam", "Thomas Maal and Guido de Jong"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "4 figures", "7 tables", "repository https://github.com/rumc3dlab/3dlandmarkdetection/"]}, "abstract": "Three-dimensional facial stereophotogrammetry provides a detailed representation of craniofacial soft tissue without the use of ionizing radiation. While manual annotation of landmarks serves as the current gold standard for cephalometric analysis, it is a time-consuming process and is prone to human error. The aim in this study was to develop and evaluate an automated cephalometric annotation method using a deep learning-based approach. Ten landmarks were manually annotated on 2897 3D facial photographs by a single observer. The automated landmarking workflow involved two successive DiffusionNet models and additional algorithms for facial segmentation. The dataset was randomly divided into a training and test dataset. The training dataset was used to train the deep learning networks, whereas the test dataset was used to evaluate the performance of the automated workflow. The precision of the workflow was evaluated by calculating the Euclidean distances between the automated and manual landmarks and compared to the intra-observer and inter-observer variability of manual annotation and the semi-automated landmarking method. The workflow was successful in 98.6% of all test cases. The deep learning-based landmarking method achieved precise and consistent landmark annotation. The mean precision of 1.69 (+/-1.15) mm was comparable to the inter-observer variability (1.31 +/-0.91 mm) of manual annotation. The Euclidean distance between the automated and manual landmarks was within 2 mm in 69%. Automated landmark annotation on 3D photographs was achieved with the DiffusionNet-based approach. The proposed method allows quantitative analysis of large datasets and may be used in diagnosis, follow-up, and virtual surgical planning.", "url": "https://arxiv.org/abs/2309.10472"}, {"metadata": {"arXiv": "2309.10522", "Date": "Tue, 19 Sep 2023 11:07:24 ", "Title": "Visible and NIR Image Fusion Algorithm Based on Information Complementarity", "Authors": ["Zhuo Li", "Bo Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Visible and near-infrared(NIR) band sensors provide images that capture complementary spectral radiations from a scene. And the fusion of the visible and NIR image aims at utilizing their spectrum properties to enhance image quality. However, currently visible and NIR fusion algorithms cannot well take advantage of spectrum properties, as well as lack information complementarity, which results in color distortion and artifacts. Therefore, this paper designs a complementary fusion model from the level of physical signals. First, in order to distinguish between noise and useful information, we use two layers of the weight-guided filter and guided filter to obtain texture and edge layers, respectively. Second, to generate the initial visible-NIR complementarity weight map, the difference maps of visible and NIR are filtered by the extend-DoG filter. After that, the significant region of NIR night-time compensation guides the initial complementarity weight map by the arctanI function. Finally, the fusion images can be generated by the complementarity weight maps of visible and NIR images, respectively. The experimental results demonstrate that the proposed algorithm can not only well take advantage of the spectrum properties and the information complementarity, but also avoid color unnatural while maintaining naturalness, which outperforms the state-of-the-art.", "url": "https://arxiv.org/abs/2309.10522"}, {"metadata": {"arXiv": "2309.10561", "Date": "Tue, 19 Sep 2023 12:15:06 ", "Title": "A multimodal deep learning architecture for smoking detection with a small data approach", "Authors": ["Robert Lakatos", "Peter Pollner", "Andras Hajdu", "Tamas Joo"], "Categories": "cs.CV cs.AI"}, "abstract": "Introduction: Covert tobacco advertisements often raise regulatory measures. This paper presents that artificial intelligence, particularly deep learning, has great potential for detecting hidden advertising and allows unbiased, reproducible, and fair quantification of tobacco-related media content. Methods: We propose an integrated text and image processing model based on deep learning, generative methods, and human reinforcement, which can detect smoking cases in both textual and visual formats, even with little available training data. Results: Our model can achieve 74\\% accuracy for images and 98\\% for text. Furthermore, our system integrates the possibility of expert intervention in the form of human reinforcement. Conclusions: Using the pre-trained multimodal, image, and text processing models available through deep learning makes it possible to detect smoking in different media even with few training data.", "url": "https://arxiv.org/abs/2309.10561"}, {"metadata": {"arXiv": "2309.10724", "Date": "Tue, 19 Sep 2023 16:04:50 ", "Title": "Sound Source Localization is All about Cross-Modal Alignment", "Authors": ["Arda Senocak", "Hyeonggon Ryu", "Junsik Kim", "Tae-Hyun Oh", "Hanspeter Pfister", "Joon Son Chung"], "Categories": "cs.CV cs.AI cs.MM cs.SD eess.AS", "Comments": ["ICCV 2023"]}, "abstract": "Humans can easily perceive the direction of sound sources in a visual scene, termed sound source localization. Recent studies on learning-based sound source localization have mainly explored the problem from a localization perspective. However, prior arts and existing benchmarks do not account for a more important aspect of the problem, cross-modal semantic understanding, which is essential for genuine sound source localization. Cross-modal semantic understanding is important in understanding semantically mismatched audio-visual events, e.g., silent objects, or off-screen sounds. To account for this, we propose a cross-modal alignment task as a joint task with sound source localization to better learn the interaction between audio and visual modalities. Thereby, we achieve high localization performance with strong cross-modal semantic understanding. Our method outperforms the state-of-the-art approaches in both sound source localization and cross-modal retrieval. Our work suggests that jointly tackling both tasks is necessary to conquer genuine sound source localization.", "url": "https://arxiv.org/abs/2309.10724"}, {"metadata": {"arXiv": "2309.10725", "Date": "Tue, 19 Sep 2023 16:08:33 ", "Title": "Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI", "Authors": ["Gianluca Carloni", "Eva Pachetti", "Sara Colantonio"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "2 figures", "accepted on Aug 07 2023 for ICCV-CVAMD 2023 and to be published in the proceedings"], "ACM-class": "I.2; I.4; I.5; J.3"}, "abstract": "In this paper, we present a novel method to automatically classify medical images that learns and leverages weak causal signals in the image. Our framework consists of a convolutional neural network backbone and a causality-extractor module that extracts cause-effect relationships between feature maps that can inform the model on the appearance of a feature in one place of the image, given the presence of another feature within some other place of the image. To evaluate the effectiveness of our approach in low-data scenarios, we train our causality-driven architecture in a One-shot learning scheme, where we propose a new meta-learning procedure entailing meta-training and meta-testing tasks that are designed using related classes but at different levels of granularity. We conduct binary and multi-class classification experiments on a publicly available dataset of prostate MRI images. To validate the effectiveness of the proposed causality-driven module, we perform an ablation study and conduct qualitative assessments using class activation maps to highlight regions strongly influencing the network's decision-making process. Our findings show that causal relationships among features play a crucial role in enhancing the model's ability to discern relevant information and yielding more reliable and interpretable predictions. This would make it a promising approach for medical image classification tasks.", "url": "https://arxiv.org/abs/2309.10725"}, {"metadata": {"arXiv": "2309.10783", "Date": "Tue, 19 Sep 2023 17:32:21 ", "Title": "Language as the Medium: Multimodal Video Classification through text only", "Authors": ["Laura Hanu", "Anita L. Ver\\H{o}", "James Thewlis"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Accepted at \"What is Next in Multimodal Foundation Models?\" (MMFM) workshop at ICCV 2023"]}, "abstract": "Despite an exciting new wave of multimodal machine learning models, current approaches still struggle to interpret the complex contextual relationships between the different modalities present in videos. Going beyond existing methods that emphasize simple activities or objects, we propose a new model-agnostic approach for generating detailed textual descriptions that captures multimodal video information. Our method leverages the extensive knowledge learnt by large language models, such as GPT-3.5 or Llama2, to reason about textual descriptions of the visual and aural modalities, obtained from BLIP-2, Whisper and ImageBind. Without needing additional finetuning of video-text models or datasets, we demonstrate that available LLMs have the ability to use these multimodal textual descriptions as proxies for ``sight'' or ``hearing'' and perform zero-shot multimodal classification of videos in-context. Our evaluations on popular action recognition benchmarks, such as UCF-101 or Kinetics, show these context-rich descriptions can be successfully used in video understanding tasks. This method points towards a promising new research direction in multimodal classification, demonstrating how an interplay between textual, visual and auditory machine learning models can enable more holistic video understanding.", "url": "https://arxiv.org/abs/2309.10783"}, {"metadata": {"arXiv": "2309.10064", "Date": "Mon, 18 Sep 2023 18:24:31 ", "Title": "Toward collision-free trajectory for autonomous and pilot-controlled unmanned aerial vehicles", "Authors": ["Kaya Kuru", "John Michael Pinder", "Benjamin Jon Watkinson", "Darren Ansell", "Keith Vinning", "Lee Moore", "Chris Gilbert", "Aadithya Sujit", "and David Jones"], "Categories": "cs.RO cs.AI", "DOI": "10.1109/ACCESS.2023.3314504"}, "abstract": "For drones, as safety-critical systems, there is an increasing need for onboard detect & avoid (DAA) technology i) to see, sense or detect conflicting traffic or imminent non-cooperative threats due to their high mobility with multiple degrees of freedom and the complexity of deployed unstructured environments, and subsequently ii) to take the appropriate actions to avoid collisions depending upon the level of autonomy. The safe and efficient integration of UAV traffic management (UTM) systems with air traffic management (ATM) systems, using intelligent autonomous approaches, is an emerging requirement where the number of diverse UAV applications is increasing on a large scale in dense air traffic environments for completing swarms of multiple complex missions flexibly and simultaneously. Significant progress over the past few years has been made in detecting UAVs present in aerospace, identifying them, and determining their existing flight path. This study makes greater use of electronic conspicuity (EC) information made available by PilotAware Ltd in developing an advanced collision management methodology -- Drone Aware Collision Management (DACM) -- capable of determining and executing a variety of time-optimal evasive collision avoidance (CA) manoeuvres using a reactive geometric conflict detection and resolution (CDR) technique. The merits of the DACM methodology have been demonstrated through extensive simulations and real-world field tests in avoiding mid-air collisions (MAC) between UAVs and manned aeroplanes. The results show that the proposed methodology can be employed successfully in avoiding collisions while limiting the deviation from the original trajectory in highly dynamic aerospace without requiring sophisticated sensors and prior training.", "url": "https://arxiv.org/abs/2309.10064"}, {"metadata": {"arXiv": "2309.10092", "Date": "Mon, 18 Sep 2023 19:05:25 ", "Title": "Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help", "Authors": ["Jun Wang", "Jiaming Tong", "Kaiyuan Tan", "Yevgeniy Vorobeychik", "Yiannis Kantaros"], "Categories": "cs.RO cs.AI"}, "abstract": "This paper addresses a new motion planning problem for mobile robots tasked with accomplishing multiple high-level sub-tasks, expressed using natural language (NL), in a temporal and logical order. To formally define such missions, we leverage LTL defined over NL-based atomic predicates modeling the considered NL-based sub-tasks. This is contrast to related planning approaches that define LTL tasks over atomic predicates capturing desired low-level system configurations. Our goal is to design robot plans that satisfy LTL tasks defined over NL-based atomic propositions. A novel technical challenge arising in this setup lies in reasoning about correctness of a robot plan with respect to such LTL-encoded tasks. To address this problem, we propose HERACLEs, a hierarchical conformal natural language planner, that relies on a novel integration of existing tools that include (i) automata theory to determine the NL-specified sub-task the robot should accomplish next to make mission progress; (ii) Large Language Models to design robot plans satisfying these sub-tasks; and (iii) conformal prediction to reason probabilistically about correctness of the designed plans and mission satisfaction and to determine if external assistance is required. We provide extensive comparative experiments on mobile manipulation tasks. The project website is ltl-llm.github.io.", "url": "https://arxiv.org/abs/2309.10092"}, {"metadata": {"arXiv": "2309.10103", "Date": "Mon, 18 Sep 2023 19:24:21 ", "Title": "Reasoning about the Unseen for Efficient Outdoor Object Navigation", "Authors": ["Quanting Xie", "Tianyi Zhang", "Kedi Xu", "Matthew Johnson-Roberson", "and Yonatan Bisk"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "7 figures"]}, "abstract": "Robots should exist anywhere humans do: indoors, outdoors, and even unmapped environments. In contrast, the focus of recent advancements in Object Goal Navigation(OGN) has targeted navigating in indoor environments by leveraging spatial and semantic cues that do not generalize outdoors. While these contributions provide valuable insights into indoor scenarios, the broader spectrum of real-world robotic applications often extends to outdoor settings. As we transition to the vast and complex terrains of outdoor environments, new challenges emerge. Unlike the structured layouts found indoors, outdoor environments lack clear spatial delineations and are riddled with inherent semantic ambiguities. Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain. Additionally, we show impressive results on both a simulated drone and physical quadruped in outdoor environments. Our agent has no premapping and our formalism outperforms naive LLM-based approaches", "url": "https://arxiv.org/abs/2309.10103"}, {"metadata": {"arXiv": "2309.10164", "Date": "Mon, 18 Sep 2023 21:20:50 ", "Title": "Asynchronous Perception-Action-Communication with Graph Neural Networks", "Authors": ["Saurav Agarwal", "Alejandro Ribeiro", "Vijay Kumar"], "Categories": "cs.RO cs.AI", "Comments": ["Under review: IEEE International Conference on Robotics and Automation (ICRA) 2024"]}, "abstract": "Collaboration in large robot swarms to achieve a common global objective is a challenging problem in large environments due to limited sensing and communication capabilities. The robots must execute a Perception-Action-Communication (PAC) loop -- they perceive their local environment, communicate with other robots, and take actions in real time. A fundamental challenge in decentralized PAC systems is to decide what information to communicate with the neighboring robots and how to take actions while utilizing the information shared by the neighbors. Recently, this has been addressed using Graph Neural Networks (GNNs) for applications such as flocking and coverage control. Although conceptually, GNN policies are fully decentralized, the evaluation and deployment of such policies have primarily remained centralized or restrictively decentralized. Furthermore, existing frameworks assume sequential execution of perception and action inference, which is very restrictive in real-world applications. This paper proposes a framework for asynchronous PAC in robot swarms, where decentralized GNNs are used to compute navigation actions and generate messages for communication. In particular, we use aggregated GNNs, which enable the exchange of hidden layer information between robots for computational efficiency and decentralized inference of actions. Furthermore, the modules in the framework are asynchronous, allowing robots to perform sensing, extracting information, communication, action inference, and control execution at different frequencies. We demonstrate the effectiveness of GNNs executed in the proposed framework in navigating large robot swarms for collaborative coverage of large environments.", "url": "https://arxiv.org/abs/2309.10164"}, {"metadata": {"arXiv": "2309.10269", "Date": "Tue, 19 Sep 2023 02:46:17 ", "Title": "Using an Uncrewed Surface Vehicle to Create a Volumetric Model of Non-Navigable Rivers and Other Shallow Bodies of Water", "Authors": ["Jayesh Tripathi and Robin Murphy"], "Categories": "cs.RO cs.AI"}, "abstract": "Non-navigable rivers and retention ponds play important roles in buffering communities from flooding, yet emergency planners often have no data as to the volume of water that they can carry before flooding the surrounding. This paper describes a practical approach for using an uncrewed marine surface vehicle (USV) to collect and merge bathymetric maps with digital surface maps of the banks of shallow bodies of water into a unified volumetric model. The below-waterline mesh is developed by applying the Poisson surface reconstruction algorithm to the sparse sonar depth readings of the underwater surface. Dense above-waterline meshes of the banks are created using commercial structure from motion (SfM) packages. Merging is challenging for many reasons, the most significant is gaps in sensor coverage, i.e., the USV cannot collect sonar depth data or visually see sandy beaches leading to a bank thus the two meshes may not intersect. The approach is demonstrated on a Hydronalix EMILY USV with a Humminbird single beam echosounder and Teledyne FLIR camera at Lake ESTI at the Texas A&M Engineering Extension Service Disaster City complex.", "url": "https://arxiv.org/abs/2309.10269"}, {"metadata": {"arXiv": "2309.10426", "Date": "Tue, 19 Sep 2023 08:40:46 ", "Title": "Multi-Object Graph Affordance Network: Enabling Goal-Oriented Planning through Compound Object Affordances", "Authors": ["Tuba Girgin", "Emre Ugur"], "Categories": "cs.RO cs.AI"}, "abstract": "Learning object affordances is an effective tool in the field of robot learning. While the data-driven models delve into the exploration of affordances of single or paired objects, there is a notable gap in the investigation of affordances of compound objects that are composed of an arbitrary number of objects with complex shapes. In this study, we propose Multi-Object Graph Affordance Network (MOGAN) that models compound object affordances and predicts the effect of placing new objects on top of the existing compound. Given different tasks, such as building towers of specific heights or properties, we used a search based planning to find the sequence of stack actions with the objects of suitable affordances. We showed that our system was able to correctly model the affordances of very complex compound objects that include stacked spheres and cups, poles, and rings that enclose the poles. We demonstrated the applicability of our system in both simulated and real-world environments, comparing our systems with a baseline model to highlight its advantages.", "url": "https://arxiv.org/abs/2309.10426"}, {"metadata": {"arXiv": "2309.10443", "Date": "Tue, 19 Sep 2023 09:04:10 ", "Title": "Rethinking Imitation-based Planner for Autonomous Driving", "Authors": ["Jie Cheng", "Yingbing Chen", "Xiaodong Mei", "Bowen Yang", "Bo Li and Ming Liu"], "Categories": "cs.RO cs.AI", "Comments": ["Project website https://jchengai.github.io/planTF"]}, "abstract": "In recent years, imitation-based driving planners have reported considerable success. However, due to the absence of a standardized benchmark, the effectiveness of various designs remains unclear. The newly released nuPlan addresses this issue by offering a large-scale real-world dataset and a standardized closed-loop benchmark for equitable comparisons. Utilizing this platform, we conduct a comprehensive study on two fundamental yet underexplored aspects of imitation-based planners: the essential features for ego planning and the effective data augmentation techniques to reduce compounding errors. Furthermore, we highlight an imitation gap that has been overlooked by current learning systems. Finally, integrating our findings, we propose a strong baseline model-PlanTF. Our results demonstrate that a well-designed, purely imitation-based planner can achieve highly competitive performance compared to state-of-the-art methods involving hand-crafted rules and exhibit superior generalization capabilities in long-tail cases. Our models and benchmarks are publicly available. Project website https://jchengai.github.io/planTF.", "url": "https://arxiv.org/abs/2309.10443"}, {"metadata": {"arXiv": "2309.10683", "Date": "Tue, 19 Sep 2023 15:07:26 ", "Title": "Learning-Initialized Trajectory Planning in Unknown Environments", "Authors": ["Yicheng Chen", "Jinjie Li", "Wenyuan Qin", "Yongzhao Hua", "Xiwang Dong", "Qingdong Li"], "Categories": "cs.RO cs.AI"}, "abstract": "Autonomous flight in unknown environments requires precise planning for both the spatial and temporal profiles of trajectories, which generally involves nonconvex optimization, leading to high time costs and susceptibility to local optima. To address these limitations, we introduce the Learning-Initialized Trajectory Planner (LIT-Planner), a novel approach that guides optimization using a Neural Network (NN) Planner to provide initial values. We first leverage the spatial-temporal optimization with batch sampling to generate training cases, aiming to capture multimodality in trajectories. Based on these data, the NN-Planner maps visual and inertial observations to trajectory parameters for handling unknown environments. The network outputs are then optimized to enhance both reliability and explainability, ensuring robust performance. Furthermore, we propose a framework that supports robust online replanning with tolerance to planning latency. Comprehensive simulations validate the LIT-Planner's time efficiency without compromising trajectory quality compared to optimization-based methods. Real-world experiments further demonstrate its practical suitability for autonomous drone navigation.", "url": "https://arxiv.org/abs/2309.10683"}, {"metadata": {"arXiv": "2309.10722", "Date": "Tue, 19 Sep 2023 16:04:09 ", "Title": "LEA*: An A* Variant Algorithm with Improved Edge Efficiency for Robot Motion Planning", "Authors": ["Dongliang Zheng and Panagiotis Tsiotras"], "Categories": "cs.RO cs.AI"}, "abstract": "In this work, we introduce a new graph search algorithm, lazy edged based A* (LEA*), for robot motion planning. By using an edge queue and exploiting the idea of lazy search, LEA* is optimally vertex efficient similar to A*, and has improved edge efficiency compared to A*. LEA* is simple and easy to implement with minimum modification to A*, resulting in a very small overhead compared to previous lazy search algorithms. We also explore the effect of inflated heuristics, which results in the weighted LEA* (wLEA*). We show that the edge efficiency of wLEA* becomes close to LazySP and, thus is near-optimal. We test LEA* and wLEA* on 2D planning problems and planning of a 7-DOF manipulator. We perform a thorough comparison with previous algorithms by considering sparse, medium, and cluttered random worlds and small, medium, and large graph sizes. Our results show that LEA* and wLEA* are the fastest algorithms to find the plan compared to previous algorithms.", "url": "https://arxiv.org/abs/2309.10722"}, {"metadata": {"arXiv": "2309.10796", "Date": "Tue, 19 Sep 2023 17:43:11 ", "Title": "Heuristic Search for Path Finding with Refuelling", "Authors": ["Anushtup Nandy", "Zhongqiang Ren", "Sivakumar Rathinam", "Howie Choset"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "6 figures", "ICRA 2024 submission", "path planning", "robotics"], "MSC-class": "68T40"}, "abstract": "This paper considers a generalization of the Path Finding (PF) with refueling constraints referred to as the Refuelling Path Finding (RF-PF) problem. Just like PF, the RF-PF problem is defined over a graph, where vertices are gas stations with known fuel prices, and edge costs depend on the gas consumption between the corresponding vertices. RF-PF seeks a minimum-cost path from the start to the goal vertex for a robot with a limited gas tank and a limited number of refuelling stops. While RF-PF is polynomial-time solvable, it remains a challenge to quickly compute an optimal solution in practice since the robot needs to simultaneously determine the path, where to make the stops, and the amount to refuel at each stop. This paper develops a heuristic search algorithm called Refuel A* (RF-A* ) that iteratively constructs partial solution paths from the start to the goal guided by a heuristic function while leveraging dominance rules for state pruning during planning. RF-A* is guaranteed to find an optimal solution and runs more than an order of magnitude faster than the existing state of the art (a polynomial time algorithm) when tested in large city maps with hundreds of gas stations.", "url": "https://arxiv.org/abs/2309.10796"}, {"metadata": {"arXiv": "2309.10237", "Date": "Tue, 19 Sep 2023 01:21:36 ", "Title": "On Explicit Curvature Regularization in Deep Generative Models", "Authors": ["Yonghyeon Lee and Frank Chongwoo Park"], "Categories": "cs.AI cs.LG", "Comments": ["2nd Annual Workshop on Topology", "Algebra", "and Geometry in Machine Learning (TAG-ML) at the ICML 2023"]}, "abstract": "We propose a family of curvature-based regularization terms for deep generative model learning. Explicit coordinate-invariant formulas for both intrinsic and extrinsic curvature measures are derived for the case of arbitrary data manifolds embedded in higher-dimensional Euclidean space. Because computing the curvature is a highly computation-intensive process involving the evaluation of second-order derivatives, efficient formulas are derived for approximately evaluating intrinsic and extrinsic curvatures. Comparative studies are conducted that compare the relative efficacy of intrinsic versus extrinsic curvature-based regularization measures, as well as performance comparisons against existing autoencoder training methods. Experiments involving noisy motion capture data confirm that curvature-based methods outperform existing autoencoder regularization methods, with intrinsic curvature measures slightly more effective than extrinsic curvature measures.", "url": "https://arxiv.org/abs/2309.10237"}, {"metadata": {"arXiv": "2309.10618", "Date": "Tue, 19 Sep 2023 13:48:26 ", "Title": "A Dynamic Linear Bias Incorporation Scheme for Nonnegative Latent Factor Analysis", "Authors": ["Yurong Zhong", "Zhe Xie", "Weiling Li and Xin Luo"], "Categories": "cs.AI cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2306.03911", "arXiv:2302.12122", "arXiv:2306.03647"]}, "abstract": "High-Dimensional and Incomplete (HDI) data is commonly encountered in big data-related applications like social network services systems, which are concerning the limited interactions among numerous nodes. Knowledge acquisition from HDI data is a vital issue in the domain of data science due to their embedded rich patterns like node behaviors, where the fundamental task is to perform HDI data representation learning. Nonnegative Latent Factor Analysis (NLFA) models have proven to possess the superiority to address this issue, where a linear bias incorporation (LBI) scheme is important in present the training overshooting and fluctuation, as well as preventing the model from premature convergence. However, existing LBI schemes are all statistic ones where the linear biases are fixed, which significantly restricts the scalability of the resultant NLFA model and results in loss of representation learning ability to HDI data. Motivated by the above discoveries, this paper innovatively presents the dynamic linear bias incorporation (DLBI) scheme. It firstly extends the linear bias vectors into matrices, and then builds a binary weight matrix to switch the active/inactive states of the linear biases. The weight matrix's each entry switches between the binary states dynamically corresponding to the linear bias value variation, thereby establishing the dynamic linear biases for an NLFA model. Empirical studies on three HDI datasets from real applications demonstrate that the proposed DLBI-based NLFA model obtains higher representation accuracy several than state-of-the-art models do, as well as highly-competitive computational efficiency.", "url": "https://arxiv.org/abs/2309.10618"}, {"metadata": {"arXiv": "2309.09982", "Date": "Mon, 11 Sep 2023 16:21:13 ", "Title": "Introspective Deep Metric Learning", "Authors": ["Chengkun Wang", "Wenzhao Zheng", "Zheng Zhu", "Jie Zhou", "Jiwen Lu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted to T-PAMI. Code is available at: https://github.com/wzzheng/IDML. arXiv admin note: substantial text overlap with arXiv:2205.04449"]}, "abstract": "This paper proposes an introspective deep metric learning (IDML) framework for uncertainty-aware comparisons of images. Conventional deep metric learning methods focus on learning a discriminative embedding to describe the semantic features of images, which ignore the existence of uncertainty in each image resulting from noise or semantic ambiguity. Training without awareness of these uncertainties causes the model to overfit the annotated labels during training and produce unsatisfactory judgments during inference. Motivated by this, we argue that a good similarity model should consider the semantic discrepancies with awareness of the uncertainty to better deal with ambiguous images for more robust training. To achieve this, we propose to represent an image using not only a semantic embedding but also an accompanying uncertainty embedding, which describes the semantic characteristics and ambiguity of an image, respectively. We further propose an introspective similarity metric to make similarity judgments between images considering both their semantic differences and ambiguities. The gradient analysis of the proposed metric shows that it enables the model to learn at an adaptive and slower pace to deal with the uncertainty during training. The proposed IDML framework improves the performance of deep metric learning through uncertainty modeling and attains state-of-the-art results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets for image retrieval and clustering. We further provide an in-depth analysis of our framework to demonstrate the effectiveness and reliability of IDML. Code: https://github.com/wzzheng/IDML.", "url": "https://arxiv.org/abs/2309.09982"}, {"metadata": {"arXiv": "2309.10091", "Date": "Mon, 18 Sep 2023 19:04:37 ", "Title": "Unified Coarse-to-Fine Alignment for Video-Text Retrieval", "Authors": ["Ziyang Wang", "Yi-Lin Sung", "Feng Cheng", "Gedas Bertasius", "Mohit Bansal"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "The canonical approach to video-text retrieval leverages a coarse-grained or fine-grained alignment between visual and textual information. However, retrieving the correct video according to the text query is often challenging as it requires the ability to reason about both high-level (scene) and low-level (object) visual clues and how they relate to the text query. To this end, we propose a Unified Coarse-to-fine Alignment model, dubbed UCoFiA. Specifically, our model captures the cross-modal similarity information at different granularity levels. To alleviate the effect of irrelevant visual clues, we also apply an Interactive Similarity Aggregation module (ISA) to consider the importance of different visual features while aggregating the cross-modal similarity to obtain a similarity score for each granularity. Finally, we apply the Sinkhorn-Knopp algorithm to normalize the similarities of each level before summing them, alleviating over- and under-representation issues at different levels. By jointly considering the crossmodal similarity of different granularity, UCoFiA allows the effective unification of multi-grained alignments. Empirically, UCoFiA outperforms previous state-of-the-art CLIP-based methods on multiple video-text retrieval benchmarks, achieving 2.4%, 1.4% and 1.3% improvements in text-to-video retrieval R@1 on MSR-VTT, Activity-Net, and DiDeMo, respectively. Our code is publicly available at https://github.com/Ziyang412/UCoFiA.", "url": "https://arxiv.org/abs/2309.10091"}, {"metadata": {"arXiv": "2309.10109", "Date": "Mon, 18 Sep 2023 19:34:23 ", "Title": "AR-TTA: A Simple Method for Real-World Continual Test-Time Adaptation", "Authors": ["Damian S\\'ojka", "Sebastian Cygert", "Bart{\\l}omiej Twardowski and Tomasz Trzci\\'nski"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Test-time adaptation is a promising research direction that allows the source model to adapt itself to changes in data distribution without any supervision. Yet, current methods are usually evaluated on benchmarks that are only a simplification of real-world scenarios. Hence, we propose to validate test-time adaptation methods using the recently introduced datasets for autonomous driving, namely CLAD-C and SHIFT. We observe that current test-time adaptation methods struggle to effectively handle varying degrees of domain shift, often resulting in degraded performance that falls below that of the source model. We noticed that the root of the problem lies in the inability to preserve the knowledge of the source model and adapt to dynamically changing, temporally correlated data streams. Therefore, we enhance well-established self-training framework by incorporating a small memory buffer to increase model stability and at the same time perform dynamic adaptation based on the intensity of domain shift. The proposed method, named AR-TTA, outperforms existing approaches on both synthetic and more real-world benchmarks and shows robustness across a variety of TTA scenarios.", "url": "https://arxiv.org/abs/2309.10109"}, {"metadata": {"arXiv": "2309.10748", "Date": "Tue, 19 Sep 2023 16:48:29 ", "Title": "SHOWMe: Benchmarking Object-agnostic Hand-Object 3D Reconstruction", "Authors": ["Anilkumar Swamy", "Vincent Leroy", "Philippe Weinzaepfel", "Fabien Baradel", "Salma Galaaoui", "Romain Bregier", "Matthieu Armando", "Jean-Sebastien Franco", "Gregory Rogez"], "Categories": "cs.CV cs.AI cs.GR cs.LG cs.RO", "Comments": ["Paper and Appendix", "Accepted in ACVR workshop at ICCV conference"]}, "abstract": "Recent hand-object interaction datasets show limited real object variability and rely on fitting the MANO parametric model to obtain groundtruth hand shapes. To go beyond these limitations and spur further research, we introduce the SHOWMe dataset which consists of 96 videos, annotated with real and detailed hand-object 3D textured meshes. Following recent work, we consider a rigid hand-object scenario, in which the pose of the hand with respect to the object remains constant during the whole video sequence. This assumption allows us to register sub-millimetre-precise groundtruth 3D scans to the image sequences in SHOWMe. Although simpler, this hypothesis makes sense in terms of applications where the required accuracy and level of detail is important eg., object hand-over in human-robot collaboration, object scanning, or manipulation and contact point analysis. Importantly, the rigidity of the hand-object systems allows to tackle video-based 3D reconstruction of unknown hand-held objects using a 2-stage pipeline consisting of a rigid registration step followed by a multi-view reconstruction (MVR) part. We carefully evaluate a set of non-trivial baselines for these two stages and show that it is possible to achieve promising object-agnostic 3D hand-object reconstructions employing an SfM toolbox or a hand pose estimator to recover the rigid transforms and off-the-shelf MVR algorithms. However, these methods remain sensitive to the initial camera pose estimates which might be imprecise due to lack of textures on the objects or heavy occlusions of the hands, leaving room for improvements in the reconstruction. Code and dataset are available at https://europe.naverlabs.com/research/showme", "url": "https://arxiv.org/abs/2309.10748"}, {"metadata": {"arXiv": "2309.10012", "Date": "Mon, 18 Sep 2023 13:45:49 ", "Title": "Looking through the past: better knowledge retention for generative replay in continual learning", "Authors": ["Valeriya Khan", "Sebastian Cygert", "Kamil Deja", "Tomasz Trzci\\'nski", "Bart{\\l}omiej Twardowski"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In this work, we improve the generative replay in a continual learning setting to perform well on challenging scenarios. Current generative rehearsal methods are usually benchmarked on small and simple datasets as they are not powerful enough to generate more complex data with a greater number of classes. We notice that in VAE-based generative replay, this could be attributed to the fact that the generated features are far from the original ones when mapped to the latent space. Therefore, we propose three modifications that allow the model to learn and generate complex data. More specifically, we incorporate the distillation in latent space between the current and previous models to reduce feature drift. Additionally, a latent matching for the reconstruction and original data is proposed to improve generated features alignment. Further, based on the observation that the reconstructions are better for preserving knowledge, we add the cycling of generations through the previously trained model to make them closer to the original data. Our method outperforms other generative replay methods in various scenarios. Code available at https://github.com/valeriya-khan/looking-through-the-past.", "url": "https://arxiv.org/abs/2309.10012"}, {"metadata": {"arXiv": "2309.10016", "Date": "Mon, 18 Sep 2023 16:17:44 ", "Title": "Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction", "Authors": ["Shaika Chowdhury", "Sivaraman Rajaganapathy", "Lichao Sun", "James Cerhan", "Nansu Zong"], "Categories": "cs.LG cs.AI"}, "abstract": "In this study, we investigated the potential of GPT-3 for the anti-cancer drug sensitivity prediction task using structured pharmacogenomics data across five tissue types and evaluated its performance with zero-shot prompting and fine-tuning paradigms. The drug's smile representation and cell line's genomic mutation features were predictive of the drug response. The results from this study have the potential to pave the way for designing more efficient treatment protocols in precision oncology.", "url": "https://arxiv.org/abs/2309.10016"}, {"metadata": {"arXiv": "2309.10077", "Date": "Mon, 18 Sep 2023 18:46:00 ", "Title": "GAME: Generalized deep learning model towards multimodal data integration for early screening of adolescent mental disorders", "Authors": ["Zhicheng Du", "Chenyao Jiang", "Xi Yuan", "Shiyao Zhai", "Zhengyang Lei", "Shuyue Ma", "Yang Liu", "Qihui Ye", "Chufan Xiao", "Qiming Huang", "Ming Xu", "Dongmei Yu", "Peiwu Qin"], "Categories": "cs.LG cs.AI"}, "abstract": "The timely identification of mental disorders in adolescents is a global public health challenge.Single factor is difficult to detect the abnormality due to its complex and subtle nature. Additionally, the generalized multimodal Computer-Aided Screening (CAS) systems with interactive robots for adolescent mental disorders are not available. Here, we design an android application with mini-games and chat recording deployed in a portable robot to screen 3,783 middle school students and construct the multimodal screening dataset, including facial images, physiological signs, voice recordings, and textual transcripts.We develop a model called GAME (Generalized Model with Attention and Multimodal EmbraceNet) with novel attention mechanism that integrates cross-modal features into the model. GAME evaluates adolescent mental conditions with high accuracy (73.34%-92.77%) and F1-Score (71.32%-91.06%).We find each modality contributes dynamically to the mental disorders screening and comorbidities among various mental disorders, indicating the feasibility of explainable model. This study provides a system capable of acquiring multimodal information and constructs a generalized multimodal integration algorithm with novel attention mechanisms for the early screening of adolescent mental disorders.", "url": "https://arxiv.org/abs/2309.10077"}, {"metadata": {"arXiv": "2309.10134", "Date": "Mon, 18 Sep 2023 20:17:10 ", "Title": "GDM: Dual Mixup for Graph Classification with Limited Supervision", "Authors": ["Abdullah Alchihabi and Yuhong Guo"], "Categories": "cs.LG cs.AI", "Comments": ["ECML 2023"]}, "abstract": "Graph Neural Networks (GNNs) require a large number of labeled graph samples to obtain good performance on the graph classification task. The performance of GNNs degrades significantly as the number of labeled graph samples decreases. To reduce the annotation cost, it is therefore important to develop graph augmentation methods that can generate new graph instances to increase the size and diversity of the limited set of available labeled graph samples. In this work, we propose a novel mixup-based graph augmentation method, Graph Dual Mixup (GDM), that leverages both functional and structural information of the graph instances to generate new labeled graph samples. GDM employs a graph structural auto-encoder to learn structural embeddings of the graph samples, and then applies mixup to the structural information of the graphs in the learned structural embedding space and generates new graph structures from the mixup structural embeddings. As for the functional information, GDM applies mixup directly to the input node features of the graph samples to generate functional node feature information for new mixup graph instances. Jointly, the generated input node features and graph structures yield new graph samples which can supplement the set of original labeled graphs. Furthermore, we propose two novel Balanced Graph Sampling methods to enhance the balanced difficulty and diversity for the generated graph samples. Experimental results on the benchmark datasets demonstrate that our proposed method substantially outperforms the state-of-the-art graph augmentation methods when the labeled graphs are scarce.", "url": "https://arxiv.org/abs/2309.10134"}, {"metadata": {"arXiv": "2309.10136", "Date": "Mon, 18 Sep 2023 20:22:27 ", "Title": "Efficient Low-Rank GNN Defense Against Structural Attacks", "Authors": ["Abdullah Alchihabi", "Qing En", "Yuhong Guo"], "Categories": "cs.LG cs.AI", "Comments": ["ICKG 2023"]}, "abstract": "Graph Neural Networks (GNNs) have been shown to possess strong representation abilities over graph data. However, GNNs are vulnerable to adversarial attacks, and even minor perturbations to the graph structure can significantly degrade their performance. Existing methods either are ineffective against sophisticated attacks or require the optimization of dense adjacency matrices, which is time-consuming and prone to local minima. To remedy this problem, we propose an Efficient Low-Rank Graph Neural Network (ELR-GNN) defense method, which aims to learn low-rank and sparse graph structures for defending against adversarial attacks, ensuring effective defense with greater efficiency. Specifically, ELR-GNN consists of two modules: a Coarse Low-Rank Estimation Module and a Fine-Grained Estimation Module. The first module adopts the truncated Singular Value Decomposition (SVD) to initialize the low-rank adjacency matrix estimation, which serves as a starting point for optimizing the low-rank matrix. In the second module, the initial estimate is refined by jointly learning a low-rank sparse graph structure with the GNN model. Sparsity is incorporated into the learned low-rank adjacency matrix by pruning weak connections, which can reduce redundant data while maintaining valuable information. As a result, instead of using the dense adjacency matrix directly, ELR-GNN can learn a low-rank and sparse estimate of it in a simple, efficient and easy to optimize manner. The experimental results demonstrate that ELR-GNN outperforms the state-of-the-art GNN defense methods in the literature, in addition to being very efficient and easy to train.", "url": "https://arxiv.org/abs/2309.10136"}, {"metadata": {"arXiv": "2309.10149", "Date": "Mon, 18 Sep 2023 21:00:01 ", "Title": "Analysis of the Memorization and Generalization Capabilities of AI Agents: Are Continual Learners Robust?", "Authors": ["Minsu Kim and Walid Saad"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to ICASSP 2024"]}, "abstract": "In continual learning (CL), an AI agent (e.g., autonomous vehicles or robotics) learns from non-stationary data streams under dynamic environments. For the practical deployment of such applications, it is important to guarantee robustness to unseen environments while maintaining past experiences. In this paper, a novel CL framework is proposed to achieve robust generalization to dynamic environments while retaining past knowledge. The considered CL agent uses a capacity-limited memory to save previously observed environmental information to mitigate forgetting issues. Then, data points are sampled from the memory to estimate the distribution of risks over environmental change so as to obtain predictors that are robust with unseen changes. The generalization and memorization performance of the proposed framework are theoretically analyzed. This analysis showcases the tradeoff between memorization and generalization with the memory size. Experiments show that the proposed algorithm outperforms memory-based CL baselines across all environments while significantly improving the generalization performance on unseen target environments.", "url": "https://arxiv.org/abs/2309.10149"}, {"metadata": {"arXiv": "2309.10186", "Date": "Mon, 18 Sep 2023 22:25:12 ", "Title": "Graph-enabled Reinforcement Learning for Time Series Forecasting with Adaptive Intelligence", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Haoran Xie", "Lin Li", "Jianming Yong", "and Yuefeng Li"], "Categories": "cs.LG cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Reinforcement learning is well known for its ability to model sequential tasks and learn latent data patterns adaptively. Deep learning models have been widely explored and adopted in regression and classification tasks. However, deep learning has its limitations such as the assumption of equally spaced and ordered data, and the lack of ability to incorporate graph structure in terms of time-series prediction. Graphical neural network (GNN) has the ability to overcome these challenges and capture the temporal dependencies in time-series data. In this study, we propose a novel approach for predicting time-series data using GNN and monitoring with Reinforcement Learning (RL). GNNs are able to explicitly incorporate the graph structure of the data into the model, allowing them to capture temporal dependencies in a more natural way. This approach allows for more accurate predictions in complex temporal structures, such as those found in healthcare, traffic and weather forecasting. We also fine-tune our GraphRL model using a Bayesian optimisation technique to further improve performance. The proposed framework outperforms the baseline models in time-series forecasting and monitoring. The contributions of this study include the introduction of a novel GraphRL framework for time-series prediction and the demonstration of the effectiveness of GNNs in comparison to traditional deep learning models such as RNNs and LSTMs. Overall, this study demonstrates the potential of GraphRL in providing accurate and efficient predictions in dynamic RL environments.", "url": "https://arxiv.org/abs/2309.10186"}, {"metadata": {"arXiv": "2309.10283", "Date": "Tue, 19 Sep 2023 03:13:17 ", "Title": "FRAMU: Attention-based Machine Unlearning using Federated Reinforcement Learning", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Lin Li", "Haoran Xie", "Taotao Cai", "Xiaofeng Zhu", "and Qing Li"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Machine Unlearning is an emerging field that addresses data privacy issues by enabling the removal of private or irrelevant data from the Machine Learning process. Challenges related to privacy and model efficiency arise from the use of outdated, private, and irrelevant data. These issues compromise both the accuracy and the computational efficiency of models in both Machine Learning and Unlearning. To mitigate these challenges, we introduce a novel framework, Attention-based Machine Unlearning using Federated Reinforcement Learning (FRAMU). This framework incorporates adaptive learning mechanisms, privacy preservation techniques, and optimization strategies, making it a well-rounded solution for handling various data sources, either single-modality or multi-modality, while maintaining accuracy and privacy. FRAMU's strength lies in its adaptability to fluctuating data landscapes, its ability to unlearn outdated, private, or irrelevant data, and its support for continual model evolution without compromising privacy. Our experiments, conducted on both single-modality and multi-modality datasets, revealed that FRAMU significantly outperformed baseline models. Additional assessments of convergence behavior and optimization strategies further validate the framework's utility in federated learning applications. Overall, FRAMU advances Machine Unlearning by offering a robust, privacy-preserving solution that optimizes model performance while also addressing key challenges in dynamic data environments.", "url": "https://arxiv.org/abs/2309.10283"}, {"metadata": {"arXiv": "2309.10291", "Date": "Tue, 19 Sep 2023 03:42:55 ", "Title": "Koopman Invertible Autoencoder: Leveraging Forward and Backward Dynamics for Temporal Modeling", "Authors": ["Kshitij Tayal", "Arvind Renganathan", "Rahul Ghosh", "Xiaowei Jia", "Vipin Kumar"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at IEEE International Conference on Data Mining (ICDM) 2023"]}, "abstract": "Accurate long-term predictions are the foundations for many machine learning applications and decision-making processes. However, building accurate long-term prediction models remains challenging due to the limitations of existing temporal models like recurrent neural networks (RNNs), as they capture only the statistical connections in the training data and may fail to learn the underlying dynamics of the target system. To tackle this challenge, we propose a novel machine learning model based on Koopman operator theory, which we call Koopman Invertible Autoencoders (KIA), that captures the inherent characteristic of the system by modeling both forward and backward dynamics in the infinite-dimensional Hilbert space. This enables us to efficiently learn low-dimensional representations, resulting in more accurate predictions of long-term system behavior. Moreover, our method's invertibility design guarantees reversibility and consistency in both forward and inverse operations. We illustrate the utility of KIA on pendulum and climate datasets, demonstrating 300% improvements in long-term prediction capability for pendulum while maintaining robustness against noise. Additionally, our method excels in long-term climate prediction, further validating our method's effectiveness.", "url": "https://arxiv.org/abs/2309.10291"}, {"metadata": {"arXiv": "2309.10337", "Date": "Tue, 19 Sep 2023 05:44:18 ", "Title": "FedWOA: A Federated Learning Model that uses the Whale Optimization Algorithm for Renewable Energy Prediction", "Authors": ["Viorica Chifu", "Tudor Cioara", "Cristian Anitiei", "Cristina Pop", "Ionut Anghel"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Privacy is important when dealing with sensitive personal information in machine learning models, which require large data sets for training. In the energy field, access to household prosumer energy data is crucial for energy predictions to support energy grid management and large-scale adoption of renewables however citizens are often hesitant to grant access to cloud-based machine learning models. Federated learning has been proposed as a solution to privacy challenges however report issues in generating the global prediction model due to data heterogeneity, variations in generation patterns, and the high number of parameters leading to even lower prediction accuracy. This paper addresses these challenges by introducing FedWOA a novel federated learning model that employs the Whale Optimization Algorithm to aggregate global prediction models from the weights of local LTSM neural network models trained on prosumer energy data. The proposed solution identifies the optimal vector of weights in the search spaces of the local models to construct the global shared model and then is subsequently transmitted to the local nodes to improve the prediction quality at the prosumer site while for handling non-IID data K-Means was used for clustering prosumers with similar scale of energy data. The evaluation results on prosumers energy data have shown that FedWOA can effectively enhance the accuracy of energy prediction models accuracy by 25% for MSE and 16% for MAE compared to FedAVG while demonstrating good convergence and reduced loss.", "url": "https://arxiv.org/abs/2309.10337"}, {"metadata": {"arXiv": "2309.10367", "Date": "Tue, 19 Sep 2023 07:04:50 ", "Title": "Toward efficient resource utilization at edge nodes in federated learning", "Authors": ["Sadi Alawadi", "Addi Ait-Mlouk", "Salman Toor and Andreas Hellander"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "5 tables", "8 figures"]}, "abstract": "Federated learning (FL) enables edge nodes to collaboratively contribute to constructing a global model without sharing their data. This is accomplished by devices computing local, private model updates that are then aggregated by a server. However, computational resource constraints and network communication can become a severe bottleneck for larger model sizes typical for deep learning applications. Edge nodes tend to have limited hardware resources (RAM, CPU), and the network bandwidth and reliability at the edge is a concern for scaling federated fleet applications. In this paper, we propose and evaluate a FL strategy inspired by transfer learning in order to reduce resource utilization on devices, as well as the load on the server and network in each global training round. For each local model update, we randomly select layers to train, freezing the remaining part of the model. In doing so, we can reduce both server load and communication costs per round by excluding all untrained layer weights from being transferred to the server. The goal of this study is to empirically explore the potential trade-off between resource utilization on devices and global model convergence under the proposed strategy. We implement the approach using the federated learning framework FEDn. A number of experiments were carried out over different datasets (CIFAR-10, CASA, and IMDB), performing different tasks using different deep-learning model architectures. Our results show that training the model partially can accelerate the training process, efficiently utilizes resources on-device, and reduce the data transmission by around 75% and 53% when we train 25%, and 50% of the model layers, respectively, without harming the resulting global model accuracy.", "url": "https://arxiv.org/abs/2309.10367"}, {"metadata": {"arXiv": "2309.10370", "Date": "Tue, 19 Sep 2023 07:12:41 ", "Title": "Geometric structure of shallow neural networks and constructive ${\\mathcal L}^2$ cost minimization", "Authors": ["Thomas Chen", "Patricia Mu\\~noz Ewald"], "Categories": "cs.LG cs.AI math-ph math.MP math.OC stat.ML", "Comments": ["AMS Latex", "29 pages"], "MSC-class": "57R70, 62M45"}, "abstract": "In this paper, we provide a geometric interpretation of the structure of shallow neural networks characterized by one hidden layer, a ramp activation function, an ${\\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input space ${\\mathbb R}^M$, output space ${\\mathbb R}^Q$ with $Q\\leq M$, and training input sample size $N>QM$. We prove an upper bound on the minimum of the cost function of order $O(\\delta_P$ where $\\delta_P$ measures the signal to noise ratio of training inputs. We obtain an approximate optimizer using projections adapted to the averages $\\overline{x_{0,j}}$ of training input vectors belonging to the same output vector $y_j$, $j=1,\\dots,Q$. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function; the sharp value differs from the upper bound obtained for $Q\\leq M$ by a relative error $O(\\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes the $Q$-dimensional subspace in the input space ${\\mathbb R}^M$ spanned by $\\overline{x_{0,j}}$, $j=1,\\dots,Q$. We comment on the characterization of the global minimum of the cost function in the given context.", "url": "https://arxiv.org/abs/2309.10370"}, {"metadata": {"arXiv": "2309.10376", "Date": "Tue, 19 Sep 2023 07:24:10 ", "Title": "Graph Contrastive Learning Meets Graph Meta Learning: A Unified Method for Few-shot Node Tasks", "Authors": ["Hao Liu", "Jiarui Feng", "Lecheng Kong", "Dacheng Tao", "Yixin Chen", "Muhan Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph Neural Networks (GNNs) have become popular in Graph Representation Learning (GRL). One fundamental application is few-shot node classification. Most existing methods follow the meta learning paradigm, showing the ability of fast generalization to few-shot tasks. However, recent works indicate that graph contrastive learning combined with fine-tuning can significantly outperform meta learning methods. Despite the empirical success, there is limited understanding of the reasons behind it. In our study, we first identify two crucial advantages of contrastive learning compared to meta learning, including (1) the comprehensive utilization of graph nodes and (2) the power of graph augmentations. To integrate the strength of both contrastive learning and meta learning on the few-shot node classification tasks, we introduce a new paradigm: Contrastive Few-Shot Node Classification (COLA). Specifically, COLA employs graph augmentations to identify semantically similar nodes, which enables the construction of meta-tasks without the need for label information. Therefore, COLA can utilize all nodes to construct meta-tasks, further reducing the risk of overfitting. Through extensive experiments, we validate the essentiality of each component in our design and demonstrate that COLA achieves new state-of-the-art on all tasks.", "url": "https://arxiv.org/abs/2309.10376"}, {"metadata": {"arXiv": "2309.10408", "Date": "Tue, 19 Sep 2023 08:17:48 ", "Title": "Unsupervised Learning via Network-Aware Embeddings", "Authors": ["Anne Sophie Riis Damstrup", "Sofie Tosti Madsen", "Michele Coscia"], "Categories": "cs.LG cs.AI cs.SI physics.data-an"}, "abstract": "Data clustering, the task of grouping observations according to their similarity, is a key component of unsupervised learning -- with real world applications in diverse fields such as biology, medicine, and social science. Often in these fields the data comes with complex interdependencies between the dimensions of analysis, for instance the various characteristics and opinions people can have live on a complex social network. Current clustering methods are ill-suited to tackle this complexity: deep learning can approximate these dependencies, but not take their explicit map as the input of the analysis. In this paper, we aim at fixing this blind spot in the unsupervised learning literature. We can create network-aware embeddings by estimating the network distance between numeric node attributes via the generalized Euclidean distance. Differently from all methods in the literature that we know of, we do not cluster the nodes of the network, but rather its node attributes. In our experiments we show that having these network embeddings is always beneficial for the learning task; that our method scales to large networks; and that we can actually provide actionable insights in applications in a variety of fields such as marketing, economics, and political science. Our method is fully open source and data and code are available to reproduce all results in the paper.", "url": "https://arxiv.org/abs/2309.10408"}, {"metadata": {"arXiv": "2309.10498", "Date": "Tue, 19 Sep 2023 10:20:11 ", "Title": "A Configurable Library for Generating and Manipulating Maze Datasets", "Authors": ["Michael Igorevich Ivanitskiy (1)", "Rusheb Shah", "Alex F. Spies (2)", "Tilman R\\\"auker", "Dan Valentine", "Can Rager", "Lucia Quirke", "Chris Mathwin", "Guillaume Corlouer", "Cecilia Diniz Behn (1)", "Samy Wu Fung (1) ((1) Colorado School of Mines", "Department of Applied Mathematics and Statistics (2) Imperial College London)"], "Categories": "cs.LG cs.AI cs.SE", "Comments": ["9 pages", "5 figures", "1 table. Corresponding author: Michael Ivanitskiy (mivanits@umich.edu). Code available at https://github.com/understanding-search/maze-dataset"]}, "abstract": "Understanding how machine learning models respond to distributional shifts is a key research challenge. Mazes serve as an excellent testbed due to varied generation algorithms offering a nuanced platform to simulate both subtle and pronounced distributional shifts. To enable systematic investigations of model behavior on out-of-distribution data, we present $\\texttt{maze-dataset}$, a comprehensive library for generating, processing, and visualizing datasets consisting of maze-solving tasks. With this library, researchers can easily create datasets, having extensive control over the generation algorithm used, the parameters fed to the algorithm of choice, and the filters that generated mazes must satisfy. Furthermore, it supports multiple output formats, including rasterized and text-based, catering to convolutional neural networks and autoregressive transformer models. These formats, along with tools for visualizing and converting between them, ensure versatility and adaptability in research applications.", "url": "https://arxiv.org/abs/2309.10498"}, {"metadata": {"arXiv": "2309.10544", "Date": "Tue, 19 Sep 2023 11:45:29 ", "Title": "Model Leeching: An Extraction Attack Targeting LLMs", "Authors": ["Lewis Birch", "William Hackett", "Stefan Trawicki", "Neeraj Suri", "Peter Garraghan"], "Categories": "cs.LG cs.AI cs.CL cs.CR"}, "abstract": "Model Leeching is a novel extraction attack targeting Large Language Models (LLMs), capable of distilling task-specific knowledge from a target LLM into a reduced parameter model. We demonstrate the effectiveness of our attack by extracting task capability from ChatGPT-3.5-Turbo, achieving 73% Exact Match (EM) similarity, and SQuAD EM and F1 accuracy scores of 75% and 87%, respectively for only $50 in API cost. We further demonstrate the feasibility of adversarial attack transferability from an extracted model extracted via Model Leeching to perform ML attack staging against a target LLM, resulting in an 11% increase to attack success rate when applied to ChatGPT-3.5-Turbo.", "url": "https://arxiv.org/abs/2309.10544"}, {"metadata": {"arXiv": "2309.10551", "Date": "Tue, 19 Sep 2023 11:58:08 ", "Title": "A Neighbourhood-Aware Differential Privacy Mechanism for Static Word Embeddings", "Authors": ["Danushka Bollegala", "Shuichi Otake", "Tomoya Machide", "Ken-ichi Kawarabayashi"], "Categories": "cs.LG cs.AI cs.CL cs.CR", "Comments": ["Accepted to IJCNLP-AACL 2023"]}, "abstract": "We propose a Neighbourhood-Aware Differential Privacy (NADP) mechanism considering the neighbourhood of a word in a pretrained static word embedding space to determine the minimal amount of noise required to guarantee a specified privacy level. We first construct a nearest neighbour graph over the words using their embeddings, and factorise it into a set of connected components (i.e. neighbourhoods). We then separately apply different levels of Gaussian noise to the words in each neighbourhood, determined by the set of words in that neighbourhood. Experiments show that our proposed NADP mechanism consistently outperforms multiple previously proposed DP mechanisms such as Laplacian, Gaussian, and Mahalanobis in multiple downstream tasks, while guaranteeing higher levels of privacy.", "url": "https://arxiv.org/abs/2309.10551"}, {"metadata": {"arXiv": "2309.10576", "Date": "Tue, 19 Sep 2023 12:35:08 ", "Title": "PDRL: Multi-Agent based Reinforcement Learning for Predictive Monitoring", "Authors": ["Thanveer Shaik", "Xiaohui Tao", "Lin Li", "Haoran Xie", "U R Acharya", "Raj Gururajan", "Xujuan Zhou"], "Categories": "cs.LG cs.AI", "Comments": ["This work has been submitted to the Springer for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Reinforcement learning has been increasingly applied in monitoring applications because of its ability to learn from previous experiences and can make adaptive decisions. However, existing machine learning-based health monitoring applications are mostly supervised learning algorithms, trained on labels and they cannot make adaptive decisions in an uncertain complex environment. This study proposes a novel and generic system, predictive deep reinforcement learning (PDRL) with multiple RL agents in a time series forecasting environment. The proposed generic framework accommodates virtual Deep Q Network (DQN) agents to monitor predicted future states of a complex environment with a well-defined reward policy so that the agent learns existing knowledge while maximizing their rewards. In the evaluation process of the proposed framework, three DRL agents were deployed to monitor a subject's future heart rate, respiration, and temperature predicted using a BiLSTM model. With each iteration, the three agents were able to learn the associated patterns and their cumulative rewards gradually increased. It outperformed the baseline models for all three monitoring agents. The proposed PDRL framework is able to achieve state-of-the-art performance in the time series forecasting process. The proposed DRL agents and deep learning model in the PDRL framework are customized to implement the transfer learning in other forecasting applications like traffic and weather and monitor their states. The PDRL framework is able to learn the future states of the traffic and weather forecasting and the cumulative rewards are gradually increasing over each episode.", "url": "https://arxiv.org/abs/2309.10576"}, {"metadata": {"arXiv": "2309.10639", "Date": "Tue, 19 Sep 2023 14:20:55 ", "Title": "Geometric structure of Deep Learning networks and construction of global ${\\mathcal L}^2$ minimizers", "Authors": ["Thomas Chen", "Patricia Mu\\~noz Ewald"], "Categories": "cs.LG cs.AI math-ph math.MP math.OC stat.ML", "Comments": ["AMS Latex", "20 pages"], "MSC-class": "57R70, 62M45"}, "abstract": "In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\\mathbb R}^Q$ with equal dimension $Q\\geq1$. The hidden layers are defined on spaces ${\\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network \"curate\" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.", "url": "https://arxiv.org/abs/2309.10639"}, {"metadata": {"arXiv": "2309.10645", "Date": "Tue, 19 Sep 2023 14:28:09 ", "Title": "Towards Energy-Aware Federated Traffic Prediction for Cellular Networks", "Authors": ["Vasileios Perifanis", "Nikolaos Pavlidis", "Selim F. Yilmaz", "Francesc Wilhelmi", "Elia Guerra", "Marco Miozzo", "Pavlos S. Efraimidis", "Paolo Dini", "Remous-Aris Koutsiamanis"], "Categories": "cs.LG cs.AI cs.DC cs.NI", "Comments": ["International Symposium on Federated Learning Technologies and Applications (FLTA)", "2023"]}, "abstract": "Cellular traffic prediction is a crucial activity for optimizing networks in fifth-generation (5G) networks and beyond, as accurate forecasting is essential for intelligent network design, resource allocation and anomaly mitigation. Although machine learning (ML) is a promising approach to effectively predict network traffic, the centralization of massive data in a single data center raises issues regarding confidentiality, privacy and data transfer demands. To address these challenges, federated learning (FL) emerges as an appealing ML training framework which offers high accurate predictions through parallel distributed computations. However, the environmental impact of these methods is often overlooked, which calls into question their sustainability. In this paper, we address the trade-off between accuracy and energy consumption in FL by proposing a novel sustainability indicator that allows assessing the feasibility of ML models. Then, we comprehensively evaluate state-of-the-art deep learning (DL) architectures in a federated scenario using real-world measurements from base station (BS) sites in the area of Barcelona, Spain. Our findings indicate that larger ML models achieve marginally improved performance but have a significant environmental impact in terms of carbon footprint, which make them impractical for real-world applications.", "url": "https://arxiv.org/abs/2309.10645"}, {"metadata": {"arXiv": "2309.10668", "Date": "Tue, 19 Sep 2023 14:50:38 ", "Title": "Language Modeling Is Compression", "Authors": ["Gr\\'egoire Del\\'etang", "Anian Ruoss", "Paul-Ambroise Duquenne", "Elliot Catt", "Tim Genewein", "Christopher Mattern", "Jordi Grau-Moya", "Li Kevin Wenliang", "Matthew Aitchison", "Laurent Orseau", "Marcus Hutter", "Joel Veness"], "Categories": "cs.LG cs.AI cs.CL cs.IT math.IT"}, "abstract": "It has long been established that predictive models can be transformed into lossless compressors and vice versa. Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models. Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors. In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models. We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning. For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4% and LibriSpeech samples to 16.4% of their raw size, beating domain-specific compressors like PNG (58.5%) or FLAC (30.3%), respectively. Finally, we show that the prediction-compression equivalence allows us to use any compressor (like gzip) to build a conditional generative model.", "url": "https://arxiv.org/abs/2309.10668"}, {"metadata": {"arXiv": "2309.10790", "Date": "Tue, 19 Sep 2023 17:39:20 ", "Title": "Guide Your Agent with Adaptive Multimodal Rewards", "Authors": ["Changyeon Kim", "Younggyo Seo", "Hao Liu", "Lisa Lee", "Jinwoo Shin", "Honglak Lee", "Kimin Lee"], "Categories": "cs.LG cs.AI cs.CV cs.RO", "Comments": ["Project webpage: https://sites.google.com/view/2023arp"]}, "abstract": "Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. In this work, we present Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance. Video demonstrations and source code are available on the project website: https://sites.google.com/view/2023arp.", "url": "https://arxiv.org/abs/2309.10790"}, {"metadata": {"arXiv": "2309.10808", "Date": "Tue, 19 Sep 2023 17:50:27 ", "Title": "AI Foundation Models for Weather and Climate: Applications, Design, and Implementation", "Authors": ["S. Karthik Mukkavilli", "Daniel Salles Civitarese", "Johannes Schmude", "Johannes Jakubik", "Anne Jones", "Nam Nguyen", "Christopher Phillips", "Sujit Roy", "Shraddha Singh", "Campbell Watson", "Raghu Ganti", "Hendrik Hamann", "Udaysankar Nair", "Rahul Ramachandran", "Kommy Weldemariam"], "Categories": "cs.LG cs.AI physics.ao-ph", "Comments": ["44 pages", "1 figure"], "MSC-class": "68T07 (Primary), 68T01, 86A08", "ACM-class": "I.2.0; I.4.0; J.2.5"}, "abstract": "Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting. There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth. Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks. With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI. In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks. Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models. Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology. We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions. We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers. In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model.", "url": "https://arxiv.org/abs/2309.10808"}, {"metadata": {"arXiv": "2309.10007", "Date": "Mon, 18 Sep 2023 02:43:59 ", "Title": "Multi-Agent Deep Reinforcement Learning for Cooperative and Competitive Autonomous Vehicles using AutoDRIVE Ecosystem", "Authors": ["Tanmay Vilas Samak", "Chinmay Vilas Samak and Venkat Krovi"], "Categories": "cs.RO cs.AI cs.LG cs.MA"}, "abstract": "This work presents a modular and parallelizable multi-agent deep reinforcement learning framework for imbibing cooperative as well as competitive behaviors within autonomous vehicles. We introduce AutoDRIVE Ecosystem as an enabler to develop physically accurate and graphically realistic digital twins of Nigel and F1TENTH, two scaled autonomous vehicle platforms with unique qualities and capabilities, and leverage this ecosystem to train and deploy multi-agent reinforcement learning policies. We first investigate an intersection traversal problem using a set of cooperative vehicles (Nigel) that share limited state information with each other in single as well as multi-agent learning settings using a common policy approach. We then investigate an adversarial head-to-head autonomous racing problem using a different set of vehicles (F1TENTH) in a multi-agent learning setting using an individual policy approach. In either set of experiments, a decentralized learning architecture was adopted, which allowed robust training and testing of the approaches in stochastic environments, since the agents were mutually independent and exhibited asynchronous motion behavior. The problems were further aggravated by providing the agents with sparse observation spaces and requiring them to sample control commands that implicitly satisfied the imposed kinodynamic as well as safety constraints. The experimental results for both problem statements are reported in terms of quantitative metrics and qualitative remarks for training as well as deployment phases.", "url": "https://arxiv.org/abs/2309.10007"}, {"metadata": {"arXiv": "2309.10275", "Date": "Tue, 19 Sep 2023 03:02:43 ", "Title": "Crowd-Aware Multi-Agent Pathfinding With Boosted Curriculum Reinforcement Learning", "Authors": ["Phu Pham", "Aniket Bera"], "Categories": "cs.RO cs.AI cs.LG cs.MA", "Comments": ["8 pages", "3 figures", "1 table"]}, "abstract": "Multi-Agent Path Finding (MAPF) in crowded environments presents a challenging problem in motion planning, aiming to find collision-free paths for all agents in the system. MAPF finds a wide range of applications in various domains, including aerial swarms, autonomous warehouse robotics, and self-driving vehicles. The current approaches for MAPF can be broadly categorized into two main categories: centralized and decentralized planning. Centralized planning suffers from the curse of dimensionality and thus does not scale well in large and complex environments. On the other hand, decentralized planning enables agents to engage in real-time path planning within a partially observable environment, demonstrating implicit coordination. However, they suffer from slow convergence and performance degradation in dense environments. In this paper, we introduce CRAMP, a crowd-aware decentralized approach to address this problem by leveraging reinforcement learning guided by a boosted curriculum-based training strategy. We test CRAMP on simulated environments and demonstrate that our method outperforms the state-of-the-art decentralized methods for MAPF on various metrics. CRAMP improves the solution quality up to 58% measured in makespan and collision count, and up to 5% in success rate in comparison to previous methods.", "url": "https://arxiv.org/abs/2309.10275"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

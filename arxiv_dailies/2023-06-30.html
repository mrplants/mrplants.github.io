<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2306.16541", "Date": "Wed, 28 Jun 2023 20:29:35 ", "Title": "Envisioning a Next Generation Extended Reality Conferencing System with Efficient Photorealistic Human Rendering", "Authors": ["Chuanyue Shen", "Letian Zhang", "Zhangsihao Yang", "Masood Mortazavi", "Xiyun Song", "Liang Peng", "Heather Yu"], "Categories": "cs.CV cs.GR cs.LG cs.MM", "Comments": ["Accepted to CVPR 2023 ECV Workshop"]}, "abstract": "Meeting online is becoming the new normal. Creating an immersive experience for online meetings is a necessity towards more diverse and seamless environments. Efficient photorealistic rendering of human 3D dynamics is the core of immersive meetings. Current popular applications achieve real-time conferencing but fall short in delivering photorealistic human dynamics, either due to limited 2D space or the use of avatars that lack realistic interactions between participants. Recent advances in neural rendering, such as the Neural Radiance Field (NeRF), offer the potential for greater realism in metaverse meetings. However, the slow rendering speed of NeRF poses challenges for real-time conferencing. We envision a pipeline for a future extended reality metaverse conferencing system that leverages monocular video acquisition and free-viewpoint synthesis to enhance data and hardware efficiency. Towards an immersive conferencing experience, we explore an accelerated NeRF-based free-viewpoint synthesis algorithm for rendering photorealistic human dynamics more efficiently. We show that our algorithm achieves comparable rendering quality while performing training and inference 44.5% and 213% faster than state-of-the-art methods, respectively. Our exploration provides a design basis for constructing metaverse conferencing systems that can handle complex application scenarios, including dynamic scene relighting with customized themes and multi-user conferencing that harmonizes real-world people into an extended world.", "url": "https://arxiv.org/abs/2306.16541"}, {"metadata": {"arXiv": "2306.16635", "Date": "Thu, 29 Jun 2023 02:19:49 ", "Title": "Improving Fairness in Deepfake Detection", "Authors": ["Yan Ju", "Shu Hu", "Shan Jia", "George H. Chen", "Siwei Lyu"], "Categories": "cs.CV cs.CY cs.LG"}, "abstract": "Despite the development of effective deepfake detection models in recent years, several recent studies have demonstrated that biases in the training data utilized to develop deepfake detection models can lead to unfair performance for demographic groups of different races and/or genders. Such can result in these groups being unfairly targeted or excluded from detection, allowing misclassified deepfakes to manipulate public opinion and erode trust in the model. While these studies have focused on identifying and evaluating the unfairness in deepfake detection, no methods have been developed to address the fairness issue of deepfake detection at the algorithm level. In this work, we make the first attempt to improve deepfake detection fairness by proposing novel loss functions to train fair deepfake detection models in ways that are agnostic or aware of demographic factors. Extensive experiments on four deepfake datasets and five deepfake detectors demonstrate the effectiveness and flexibility of our approach in improving the deepfake detection fairness.", "url": "https://arxiv.org/abs/2306.16635"}, {"metadata": {"arXiv": "2306.16662", "Date": "Thu, 29 Jun 2023 03:46:44 ", "Title": "Joint Level Generation and Translation Using Gameplay Videos", "Authors": ["Negar Mirgati and Matthew Guzdial"], "Categories": "cs.CV cs.LG", "Comments": ["8 pages", "4 figures"], "Journal-ref": "IEEE Conference on Games 2023"}, "abstract": "Procedural Content Generation via Machine Learning (PCGML) faces a significant hurdle that sets it apart from other fields, such as image or text generation, which is limited annotated data. Many existing methods for procedural level generation via machine learning require a secondary representation besides level images. However, the current methods for obtaining such representations are laborious and time-consuming, which contributes to this problem. In this work, we aim to address this problem by utilizing gameplay videos of two human-annotated games to develop a novel multi-tail framework that learns to perform simultaneous level translation and generation. The translation tail of our framework can convert gameplay video frames to an equivalent secondary representation, while its generation tail can produce novel level segments. Evaluation results and comparisons between our framework and baselines suggest that combining the level generation and translation tasks can lead to an overall improved performance regarding both tasks. This represents a possible solution to limited annotated level data, and we demonstrate the potential for future versions to generalize to unseen games.", "url": "https://arxiv.org/abs/2306.16662"}, {"metadata": {"arXiv": "2306.16678", "Date": "Thu, 29 Jun 2023 04:48:02 ", "Title": "BinaryViT: Pushing Binary Vision Transformers Towards Convolutional Models", "Authors": ["Phuoc-Hoan Charles Le", "Xinlin Li"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted in CVPR 2023 Workshop on Efficient Deep Learning for Computer Vision (ECV)"], "Journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2023"}, "abstract": "With the increasing popularity and the increasing size of vision transformers (ViTs), there has been an increasing interest in making them more efficient and less computationally costly for deployment on edge devices with limited computing resources. Binarization can be used to help reduce the size of ViT models and their computational cost significantly, using popcount operations when the weights and the activations are in binary. However, ViTs suffer a larger performance drop when directly applying convolutional neural network (CNN) binarization methods or existing binarization methods to binarize ViTs compared to CNNs on datasets with a large number of classes such as ImageNet-1k. With extensive analysis, we find that binary vanilla ViTs such as DeiT miss out on a lot of key architectural properties that CNNs have that allow binary CNNs to have much higher representational capability than binary vanilla ViT. Therefore, we propose BinaryViT, in which inspired by the CNN architecture, we include operations from the CNN architecture into a pure ViT architecture to enrich the representational capability of a binary ViT without introducing convolutions. These include an average pooling layer instead of a token pooling layer, a block that contains multiple average pooling branches, an affine transformation right before the addition of each main residual connection, and a pyramid structure. Experimental results on the ImageNet-1k dataset show the effectiveness of these operations that allow a binary pure ViT model to be competitive with previous state-of-the-art (SOTA) binary CNN models.", "url": "https://arxiv.org/abs/2306.16678"}, {"metadata": {"arXiv": "2306.16805", "Date": "Thu, 29 Jun 2023 09:35:53 ", "Title": "CLIPAG: Towards Generator-Free Text-to-Image Generation", "Authors": ["Roy Ganz", "Michael Elad"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Perceptually Aligned Gradients (PAG) refer to an intriguing property observed in robust image classification models, wherein their input gradients align with human perception and pose semantic meanings. While this phenomenon has gained significant research attention, it was solely studied in the context of unimodal vision-only architectures. In this work, we extend the study of PAG to Vision-Language architectures, which form the foundations for diverse image-text tasks and applications. Through an adversarial robustification finetuning of CLIP, we demonstrate that robust Vision-Language models exhibit PAG in contrast to their vanilla counterparts. This work reveals the merits of CLIP with PAG (CLIPAG) in several vision-language generative tasks. Notably, we show that seamlessly integrating CLIPAG in a \"plug-n-play\" manner leads to substantial improvements in vision-language generative applications. Furthermore, leveraging its PAG property, CLIPAG enables text-to-image generation without any generative model, which typically requires huge generators.", "url": "https://arxiv.org/abs/2306.16805"}, {"metadata": {"arXiv": "2306.16917", "Date": "Thu, 29 Jun 2023 13:09:31 ", "Title": "The Drunkard's Odometry: Estimating Camera Motion in Deforming Scenes", "Authors": ["David Recasens", "Martin R. Oswald", "Marc Pollefeys", "Javier Civera"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "Estimating camera motion in deformable scenes poses a complex and open research challenge. Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference. However, this assumption does not hold true in certain relevant application cases such as endoscopies. Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies. To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments. This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time. Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality. We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations. In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data. Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/", "url": "https://arxiv.org/abs/2306.16917"}, {"metadata": {"arXiv": "2306.16999", "Date": "Thu, 29 Jun 2023 14:59:43 ", "Title": "Spectral Batch Normalization: Normalization in the Frequency Domain", "Authors": ["Rinor Cakaj", "Jens Mehnert", "Bin Yang"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by The International Joint Conference on Neural Network (IJCNN) 2023"], "Journal-ref": "IJCNN 2023"}, "abstract": "Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks. In this paper, we introduce spectral batch normalization (SBN), a novel effective method to improve generalization by normalizing feature maps in the frequency (spectral) domain. The activations of residual networks without batch normalization (BN) tend to explode exponentially in the depth of the network at initialization. This leads to extremely large feature map norms even though the parameters are relatively small. These explosive dynamics can be very detrimental to learning. BN makes weight decay regularization on the scaling factors $\\gamma, \\beta$ approximately equivalent to an additive penalty on the norm of the feature maps, which prevents extremely large feature map norms to a certain degree. However, we show experimentally that, despite the approximate additive penalty of BN, feature maps in deep neural networks (DNNs) tend to explode at the beginning of the network and that feature maps of DNNs contain large values during the whole training. This phenomenon also occurs in a weakened form in non-residual networks. SBN addresses large feature maps by normalizing them in the frequency domain. In our experiments, we empirically show that SBN prevents exploding feature maps at initialization and large feature map values during the training. Moreover, the normalization of feature maps in the frequency domain leads to more uniform distributed frequency components. This discourages the DNNs to rely on single frequency components of feature maps. These, together with other effects of SBN, have a regularizing effect on the training of residual and non-residual networks. We show experimentally that using SBN in addition to standard regularization methods improves the performance of DNNs by a relevant margin, e.g. ResNet50 on ImageNet by 0.71%.", "url": "https://arxiv.org/abs/2306.16999"}, {"metadata": {"arXiv": "2306.17091", "Date": "Thu, 29 Jun 2023 16:48:15 ", "Title": "The Importance of Robust Features in Mitigating Catastrophic Forgetting", "Authors": ["Hikmat Khan", "Nidhal C. Bouaynaya", "Ghulam Rasoom"], "Categories": "cs.CV cs.LG"}, "abstract": "Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions. The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness. However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL. In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets. Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset. Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting.", "url": "https://arxiv.org/abs/2306.17091"}, {"metadata": {"arXiv": "2306.16884", "Date": "Thu, 29 Jun 2023 12:07:30 ", "Title": "Policy Space Diversity for Non-Transitive Games", "Authors": ["Jian Yao", "Weiming Liu", "Haobo Fu", "Yaodong Yang", "Stephen McAleer", "Qiang Fu", "Wei Yang"], "Categories": "cs.GT cs.LG cs.MA"}, "abstract": "Policy-Space Response Oracles (PSRO) is an influential algorithm framework for approximating a Nash Equilibrium (NE) in multi-agent non-transitive games. Many previous studies have been trying to promote policy diversity in PSRO. A major weakness in existing diversity metrics is that a more diverse (according to their diversity metrics) population does not necessarily mean (as we proved in the paper) a better approximation to a NE. To alleviate this problem, we propose a new diversity metric, the improvement of which guarantees a better approximation to a NE. Meanwhile, we develop a practical and well-justified method to optimize our diversity metric using only state-action samples. By incorporating our diversity regularization into the best response solving in PSRO, we obtain a new PSRO variant, Policy Space Diversity PSRO (PSD-PSRO). We present the convergence property of PSD-PSRO. Empirically, extensive experiments on various games demonstrate that PSD-PSRO is more effective in producing significantly less exploitable policies than state-of-the-art PSRO variants.", "url": "https://arxiv.org/abs/2306.16884"}, {"metadata": {"arXiv": "2306.16427", "Date": "Tue, 27 Jun 2023 14:02:10 ", "Title": "Long-Term Hourly Scenario Generation for Correlated Wind and Solar Power combining Variational Autoencoders with Radial Basis Function Kernels", "Authors": ["Julio Alberto Silva Dias"], "Categories": "cs.LG"}, "abstract": "Accurate generation of realistic future scenarios of renewable energy generation is crucial for long-term planning and operation of electrical systems, especially considering the increasing focus on sustainable energy and the growing penetration of renewable generation in energy matrices. These predictions enable power system operators and energy planners to effectively manage the variability and intermittency associated with renewable generation, allowing for better grid stability, improved energy management, and enhanced decision-making processes. In this paper, we propose an innovative method for generating long-term hourly scenarios for wind and solar power generation, taking into consideration the correlation between these two energy sources. To achieve this, we combine the capabilities of a Variational Autoencoder (VAE) with the additional benefits of incorporating the Radial Basis Function (RBF) kernel in our artificial neural network architecture. By incorporating them, we aim to obtain a latent space with improved regularization properties. To evaluate the effectiveness of our proposed method, we conduct experiments in a representative study scenario, utilizing real-world wind and solar power generation data from the Brazil system. We compare the scenarios generated by our model with the observed data and with other sets of scenarios produced by a conventional VAE architecture. Our experimental results demonstrate that the proposed method can generate long-term hourly scenarios for wind and solar power generation that are highly correlated, accurately capturing the temporal and spatial characteristics of these energy sources. Taking advantage of the benefits of RBF in obtaining a well-regularized latent space, our approach offers improved accuracy and robustness in generating long-term hourly scenarios for renewable energy generation.", "url": "https://arxiv.org/abs/2306.16427"}, {"metadata": {"arXiv": "2306.16428", "Date": "Wed, 28 Jun 2023 07:01:08 ", "Title": "Complex-valued Adaptive System Identification via Low-Rank Tensor Decomposition", "Authors": ["Oliver Ploder", "Christina Auer", "Oliver Lang", "Thomas Paireder", "Mario Huemer"], "Categories": "cs.LG math.ST stat.TH"}, "abstract": "Machine learning (ML) and tensor-based methods have been of significant interest for the scientific community for the last few decades. In a previous work we presented a novel tensor-based system identification framework to ease the computational burden of tensor-only architectures while still being able to achieve exceptionally good performance. However, the derived approach only allows to process real-valued problems and is therefore not directly applicable on a wide range of signal processing and communications problems, which often deal with complex-valued systems. In this work we therefore derive two new architectures to allow the processing of complex-valued signals, and show that these extensions are able to surpass the trivial, complex-valued extension of the original architecture in terms of performance, while only requiring a slight overhead in computational resources to allow for complex-valued operations.", "url": "https://arxiv.org/abs/2306.16428"}, {"metadata": {"arXiv": "2306.16430", "Date": "Wed, 28 Jun 2023 15:21:27 ", "Title": "DNA-TEQ: An Adaptive Exponential Quantization of Tensors for DNN Inference", "Authors": ["Bahareh Khabbazan", "Marc Riera", "Antonio Gonz\\'alez"], "Categories": "cs.LG cs.AR", "Comments": ["8 pages", "8 figures", "5 tables"]}, "abstract": "Quantization is commonly used in Deep Neural Networks (DNNs) to reduce the storage and computational complexity by decreasing the arithmetical precision of activations and weights, a.k.a. tensors. Efficient hardware architectures employ linear quantization to enable the deployment of recent DNNs onto embedded systems and mobile devices. However, linear uniform quantization cannot usually reduce the numerical precision to less than 8 bits without sacrificing high performance in terms of model accuracy. The performance loss is due to the fact that tensors do not follow uniform distributions. In this paper, we show that a significant amount of tensors fit into an exponential distribution. Then, we propose DNA-TEQ to exponentially quantize DNN tensors with an adaptive scheme that achieves the best trade-off between numerical precision and accuracy loss. The experimental results show that DNA-TEQ provides a much lower quantization bit-width compared to previous proposals, resulting in an average compression ratio of 40% over the linear INT8 baseline, with negligible accuracy loss and without retraining the DNNs. Besides, DNA-TEQ leads the way in performing dot-product operations in the exponential domain, which saves 66% of energy consumption on average for a set of widely used DNNs.", "url": "https://arxiv.org/abs/2306.16430"}, {"metadata": {"arXiv": "2306.16484", "Date": "Wed, 28 Jun 2023 18:14:22 ", "Title": "Towards a Better Theoretical Understanding of Independent Subnetwork Training", "Authors": ["Egor Shulgin and Peter Richt\\'arik"], "Categories": "cs.LG cs.DC math.OC", "Comments": ["32 pages"]}, "abstract": "Modern advancements in large-scale machine learning would be impossible without the paradigm of data-parallel distributed computing. Since distributed computing with large-scale models imparts excessive pressure on communication channels, significant recent research has been directed toward co-designing communication compression strategies and training algorithms with the goal of reducing communication costs. While pure data parallelism allows better data scaling, it suffers from poor model scaling properties. Indeed, compute nodes are severely limited by memory constraints, preventing further increases in model size. For this reason, the latest achievements in training giant neural network models also rely on some form of model parallelism. In this work, we take a closer theoretical look at Independent Subnetwork Training (IST), which is a recently proposed and highly effective technique for solving the aforementioned problems. We identify fundamental differences between IST and alternative approaches, such as distributed methods with compressed communication, and provide a precise analysis of its optimization performance on a quadratic model.", "url": "https://arxiv.org/abs/2306.16484"}, {"metadata": {"arXiv": "2306.16504", "Date": "Wed, 28 Jun 2023 18:52:27 ", "Title": "Momentum Benefits Non-IID Federated Learning Simply and Provably", "Authors": ["Ziheng Cheng", "Xinmeng Huang", "Kun Yuan"], "Categories": "cs.LG math.OC"}, "abstract": "Federated learning is a powerful paradigm for large-scale machine learning, but it faces significant challenges due to unreliable network connections, slow communication, and substantial data heterogeneity across clients. FedAvg and SCAFFOLD are two fundamental algorithms to address these challenges. In particular, FedAvg employs multiple local updates before communicating with a central server, while SCAFFOLD maintains a control variable on each client to compensate for \"client drift\" in its local updates. Various methods have been proposed in literature to enhance the convergence of these two algorithms, but they either make impractical adjustments to algorithmic structure, or rely on the assumption of bounded data heterogeneity. This paper explores the utilization of momentum to enhance the performance of FedAvg and SCAFFOLD. When all clients participate in the training process, we demonstrate that incorporating momentum allows FedAvg to converge without relying on the assumption of bounded data heterogeneity even using a constant local learning rate. This is a novel result since existing analyses for FedAvg require bounded data heterogeneity even with diminishing local learning rates. In the case of partial client participation, we show that momentum enables SCAFFOLD to converge provably faster without imposing any additional assumptions. Furthermore, we use momentum to develop new variance-reduced extensions of FedAvg and SCAFFOLD, which exhibit state-of-the-art convergence rates. Our experimental results support all theoretical findings.", "url": "https://arxiv.org/abs/2306.16504"}, {"metadata": {"arXiv": "2306.16531", "Date": "Wed, 28 Jun 2023 20:03:18 ", "Title": "Prediction of Rapid Early Progression and Survival Risk with Pre-Radiation MRI in WHO Grade 4 Glioma Patients", "Authors": ["Walia Farzana", "Mustafa M Basree", "Norou Diawara", "Zeina A. Shboul", "Sagel Dubey", "Marie M Lockhart", "Mohamed Hamza", "Joshua D. Palmer", "Khan M. Iftekharuddin"], "Categories": "cs.LG"}, "abstract": "Recent clinical research describes a subset of glioblastoma patients that exhibit REP prior to start of radiation therapy. Current literature has thus far described this population using clinicopathologic features. To our knowledge, this study is the first to investigate the potential of conventional ra-diomics, sophisticated multi-resolution fractal texture features, and different molecular features (MGMT, IDH mutations) as a diagnostic and prognostic tool for prediction of REP from non-REP cases using computational and statistical modeling methods. Radiation-planning T1 post-contrast (T1C) MRI sequences of 70 patients are analyzed. Ensemble method with 5-fold cross validation over 1000 iterations offers AUC of 0.793 with standard deviation of 0.082 for REP and non-REP classification. In addition, copula-based modeling under dependent censoring (where a subset of the patients may not be followed up until death) identifies significant features (p-value <0.05) for survival probability and prognostic grouping of patient cases. The prediction of survival for the patients cohort produces precision of 0.881 with standard deviation of 0.056. The prognostic index (PI) calculated using the fused features suggests that 84.62% of REP cases fall under the bad prognostic group, suggesting potentiality of fused features to predict a higher percentage of REP cases. The experimental result further shows that mul-ti-resolution fractal texture features perform better than conventional radiomics features for REP and survival outcomes.", "url": "https://arxiv.org/abs/2306.16531"}, {"metadata": {"arXiv": "2306.16557", "Date": "Wed, 28 Jun 2023 20:53:49 ", "Title": "Non-Convex Optimizations for Machine Learning with Theoretical Guarantee: Robust Matrix Completion and Neural Network Learning", "Authors": ["Shuai Zhang"], "Categories": "cs.LG eess.SP", "Comments": ["PhD thesis"]}, "abstract": "Despite the recent development in machine learning, most learning systems are still under the concept of \"black box\", where the performance cannot be understood and derived. With the rise of safety and privacy concerns in public, designing an explainable learning system has become a new trend in machine learning. In general, many machine learning problems are formulated as minimizing (or maximizing) some loss function. Since real data are most likely generated from non-linear models, the loss function is non-convex in general. Unlike the convex optimization problem, gradient descent algorithms will be trapped in spurious local minima in solving non-convex optimization. Therefore, it is challenging to provide explainable algorithms when studying non-convex optimization problems. In this thesis, two popular non-convex problems are studied: (1) low-rank matrix completion and (2) neural network learning.", "url": "https://arxiv.org/abs/2306.16557"}, {"metadata": {"arXiv": "2306.16578", "Date": "Wed, 28 Jun 2023 21:59:11 ", "Title": "Allocating Divisible Resources on Arms with Unknown and Random Rewards", "Authors": ["Ningyuan Chen", "Wenhao Li"], "Categories": "cs.LG math.ST stat.ML stat.TH"}, "abstract": "We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. In particular, if the decision maker allocates resource $A_i$ to arm $i$ in a period, then the reward $Y_i$ is$Y_i(A_i)=A_i \\mu_i+A_i^b \\xi_{i}$, where $\\mu_i$ is the unknown mean and the noise $\\xi_{i}$ is independent and sub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables whose weights are fractional, adapted to the filtration, and monotonic.", "url": "https://arxiv.org/abs/2306.16578"}, {"metadata": {"arXiv": "2306.16738", "Date": "Thu, 29 Jun 2023 07:29:23 ", "Title": "Towards Optimal Randomized Strategies in Adversarial Example Game", "Authors": ["Jiahao Xie", "Chao Zhang", "Weijie Liu", "Wensong Bai", "Hui Qian"], "Categories": "cs.LG cs.CR cs.GT", "Comments": ["Extended version of paper https://doi.org/10.1609/aaai.v37i9.26247 which appeared in AAAI 2023"], "DOI": "10.1609/aaai.v37i9.26247"}, "abstract": "The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converges to a mixed Nash equilibria in a zero-sum game formed by a defender and an attacker. Experimental results also demonstrate the efficiency of FRAT on CIFAR-10 and CIFAR-100 datasets.", "url": "https://arxiv.org/abs/2306.16738"}, {"metadata": {"arXiv": "2306.16780", "Date": "Thu, 29 Jun 2023 08:34:01 ", "Title": "Graph Sampling-based Meta-Learning for Molecular Property Prediction", "Authors": ["Xiang Zhuang", "Qiang Zhang", "Bin Wu", "Keyan Ding", "Yin Fang", "Huajun Chen"], "Categories": "cs.LG q-bio.BM", "Comments": ["Accepted by IJCAI 2023"]}, "abstract": "Molecular property is usually observed with a limited number of samples, and researchers have considered property prediction as a few-shot problem. One important fact that has been ignored by prior works is that each molecule can be recorded with several different properties simultaneously. To effectively utilize many-to-many correlations of molecules and properties, we propose a Graph Sampling-based Meta-learning (GS-Meta) framework for few-shot molecular property prediction. First, we construct a Molecule-Property relation Graph (MPG): molecule and properties are nodes, while property labels decide edges. Then, to utilize the topological information of MPG, we reformulate an episode in meta-learning as a subgraph of the MPG, containing a target property node, molecule nodes, and auxiliary property nodes. Third, as episodes in the form of subgraphs are no longer independent of each other, we propose to schedule the subgraph sampling process with a contrastive loss function, which considers the consistency and discrimination of subgraphs. Extensive experiments on 5 commonly-used benchmarks show GS-Meta consistently outperforms state-of-the-art methods by 5.71%-6.93% in ROC-AUC and verify the effectiveness of each proposed module. Our code is available at https://github.com/HICAI-ZJU/GS-Meta.", "url": "https://arxiv.org/abs/2306.16780"}, {"metadata": {"arXiv": "2306.16803", "Date": "Thu, 29 Jun 2023 09:27:27 ", "Title": "Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis", "Authors": ["Alexander Meulemans", "Simon Schug", "Seijin Kobayashi", "Nathaniel Daw", "Gregory Wayne"], "Categories": "cs.LG stat.ML"}, "abstract": "To make reinforcement learning more sample efficient, we need better credit assignment methods that measure an action's influence on future rewards. Building upon Hindsight Credit Assignment (HCA), we introduce Counterfactual Contribution Analysis (COCOA), a new family of model-based credit assignment algorithms. Our algorithms achieve precise credit assignment by measuring the contribution of actions upon obtaining subsequent rewards, by quantifying a counterfactual query: \"Would the agent still have reached this reward if it had taken another action?\". We show that measuring contributions w.r.t. rewarding states, as is done in HCA, results in spurious estimates of contributions, causing HCA to degrade towards the high-variance REINFORCE estimator in many relevant environments. Instead, we measure contributions w.r.t. rewards or learned representations of the rewarding objects, resulting in gradient estimates with lower variance. We run experiments on a suite of problems specifically designed to evaluate long-term credit assignment capabilities. By using dynamic programming, we measure ground-truth policy gradients and show that the improved performance of our new model-based credit assignment methods is due to lower bias and variance compared to HCA and common baselines. Our results demonstrate how modeling action contributions towards rewarding outcomes can be leveraged for credit assignment, opening a new path towards sample-efficient reinforcement learning.", "url": "https://arxiv.org/abs/2306.16803"}, {"metadata": {"arXiv": "2306.16823", "Date": "Thu, 29 Jun 2023 09:58:21 ", "Title": "Length of Stay prediction for Hospital Management using Domain Adaptation", "Authors": ["Lyse Naomi Wamba Momo", "Nyalleng Moorosi", "Elaine O. Nsoesie", "Frank Rademakers", "Bart De Moor"], "Categories": "cs.LG"}, "abstract": "Inpatient length of stay (LoS) is an important managerial metric which if known in advance can be used to efficiently plan admissions, allocate resources and improve care. Using historical patient data and machine learning techniques, LoS prediction models can be developed. Ethically, these models can not be used for patient discharge in lieu of unit heads but are of utmost necessity for hospital management systems in charge of effective hospital planning. Therefore, the design of the prediction system should be adapted to work in a true hospital setting. In this study, we predict early hospital LoS at the granular level of admission units by applying domain adaptation to leverage information learned from a potential source domain. Time-varying data from 110,079 and 60,492 patient stays to 8 and 9 intensive care units were respectively extracted from eICU-CRD and MIMIC-IV. These were fed into a Long-Short Term Memory and a Fully connected network to train a source domain model, the weights of which were transferred either partially or fully to initiate training in target domains. Shapley Additive exPlanations (SHAP) algorithms were used to study the effect of weight transfer on model explanability. Compared to the benchmark, the proposed weight transfer model showed statistically significant gains in prediction accuracy (between 1% and 5%) as well as computation time (up to 2hrs) for some target domains. The proposed method thus provides an adapted clinical decision support system for hospital management that can ease processes of data access via ethical committee, computation infrastructures and time.", "url": "https://arxiv.org/abs/2306.16823"}, {"metadata": {"arXiv": "2306.16827", "Date": "Thu, 29 Jun 2023 10:02:39 ", "Title": "SaGess: Sampling Graph Denoising Diffusion Model for Scalable Graph Generation", "Authors": ["Stratis Limnios", "Praveen Selvaraj", "Mihai Cucuringu", "Carsten Maple", "Gesine Reinert", "Andrew Elliott"], "Categories": "cs.LG"}, "abstract": "Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images. These approaches have also proved successful in other applications such as tabular and graph data generation. However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling. In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework. The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress. SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress. We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction. In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task.", "url": "https://arxiv.org/abs/2306.16827"}, {"metadata": {"arXiv": "2306.16830", "Date": "Thu, 29 Jun 2023 10:13:36 ", "Title": "Sampling weights of deep neural networks", "Authors": ["Erik Lien Bolager and Iryna Burak and Chinmay Datar and Qing Sun and Felix Dietrich"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["41 pages incl. references and appendix", "15 figures"], "MSC-class": "68T07", "ACM-class": "G.1; G.3"}, "abstract": "We introduce a probability distribution, combined with an efficient sampling algorithm, for weights and biases of fully-connected neural networks. In a supervised learning context, no iterative optimization or gradient computations of internal network parameters are needed to obtain a trained network. The sampling is based on the idea of random feature models. However, instead of a data-agnostic distribution, e.g., a normal distribution, we use both the input and the output training data of the supervised learning problem to sample both shallow and deep networks. We prove that the sampled networks we construct are universal approximators. We also show that our sampling scheme is invariant to rigid body transformations and scaling of the input data. This implies many popular pre-processing techniques are no longer required. For Barron functions, we show that the $L^2$-approximation error of sampled shallow networks decreases with the square root of the number of neurons. In numerical experiments, we demonstrate that sampled networks achieve comparable accuracy as iteratively trained ones, but can be constructed orders of magnitude faster. Our test cases involve a classification benchmark from OpenML, sampling of neural operators to represent maps in function spaces, and transfer learning using well-known architectures.", "url": "https://arxiv.org/abs/2306.16830"}, {"metadata": {"arXiv": "2306.16844", "Date": "Thu, 29 Jun 2023 10:34:23 ", "Title": "Macro Placement by Wire-Mask-Guided Black-Box Optimization", "Authors": ["Yunqi Shi", "Ke Xue", "Lei Song", "Chao Qian"], "Categories": "cs.LG"}, "abstract": "The development of very large-scale integration (VLSI) technology has posed new challenges for electronic design automation (EDA) techniques in chip floorplanning. During this process, macro placement is an important subproblem, which tries to determine the positions of all macros with the aim of minimizing half-perimeter wirelength (HPWL) and avoiding overlapping. Previous methods include packing-based, analytical and reinforcement learning methods. In this paper, we propose a new black-box optimization (BBO) framework (called WireMask-BBO) for macro placement, by using a wire-mask-guided greedy procedure for objective evaluation. Equipped with different BBO algorithms, WireMask-BBO empirically achieves significant improvements over previous methods, i.e., achieves significantly shorter HPWL by using much less time. Furthermore, it can fine-tune existing placements by treating them as initial solutions, which can bring up to 50% improvement in HPWL. WireMask-BBO has the potential to significantly improve the quality and efficiency of chip floorplanning, which makes it appealing to researchers and practitioners in EDA and will also promote the application of BBO.", "url": "https://arxiv.org/abs/2306.16844"}, {"metadata": {"arXiv": "2306.16854", "Date": "Thu, 29 Jun 2023 11:01:48 ", "Title": "On the Relationship Between RNN Hidden State Vectors and Semantic Ground Truth", "Authors": ["Edi Mu\\v{s}kardin and Martin Tappler and Ingo Pill and Bernhard K. Aichernig and Thomas Pock"], "Categories": "cs.LG"}, "abstract": "We examine the assumption that the hidden-state vectors of recurrent neural networks (RNNs) tend to form clusters of semantically similar vectors, which we dub the clustering hypothesis. While this hypothesis has been assumed in the analysis of RNNs in recent years, its validity has not been studied thoroughly on modern neural network architectures. We examine the clustering hypothesis in the context of RNNs that were trained to recognize regular languages. This enables us to draw on perfect ground-truth automata in our evaluation, against which we can compare the RNN's accuracy and the distribution of the hidden-state vectors. We start with examining the (piecewise linear) separability of an RNN's hidden-state vectors into semantically different classes. We continue the analysis by computing clusters over the hidden-state vector space with multiple state-of-the-art unsupervised clustering approaches. We formally analyze the accuracy of computed clustering functions and the validity of the clustering hypothesis by determining whether clusters group semantically similar vectors to the same state in the ground-truth model. Our evaluation supports the validity of the clustering hypothesis in the majority of examined cases. We observed that the hidden-state vectors of well-trained RNNs are separable, and that the unsupervised clustering techniques succeed in finding clusters of similar state vectors.", "url": "https://arxiv.org/abs/2306.16854"}, {"metadata": {"arXiv": "2306.16869", "Date": "Thu, 29 Jun 2023 11:38:22 ", "Title": "NeuralFuse: Learning to Improve the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes", "Authors": ["Hao-Lun Sun", "Lei Hsiung", "Nandhini Chandramoorthy", "Pin-Yu Chen", "Tsung-Yi Ho"], "Categories": "cs.LG cs.AR cs.CV"}, "abstract": "Deep neural networks (DNNs) have become ubiquitous in machine learning, but their energy consumption remains a notable issue. Lowering the supply voltage is an effective strategy for reducing energy consumption. However, aggressively scaling down the supply voltage can lead to accuracy degradation due to random bit flips in static random access memory (SRAM) where model parameters are stored. To address this challenge, we introduce NeuralFuse, a novel add-on module that addresses the accuracy-energy tradeoff in low-voltage regimes by learning input transformations to generate error-resistant data representations. NeuralFuse protects DNN accuracy in both nominal and low-voltage scenarios. Moreover, NeuralFuse is easy to implement and can be readily applied to DNNs with limited access, such as non-configurable hardware or remote access to cloud-based APIs. Experimental results demonstrate that, at a 1% bit error rate, NeuralFuse can reduce SRAM memory access energy by up to 24% while improving accuracy by up to 57%. To the best of our knowledge, this is the first model-agnostic approach (i.e., no model retraining) to address low-voltage-induced bit errors. The source code is available at https://github.com/IBM/NeuralFuse.", "url": "https://arxiv.org/abs/2306.16869"}, {"metadata": {"arXiv": "2306.16873", "Date": "Thu, 29 Jun 2023 11:55:37 ", "Title": "Understanding the Overfitting of the Episodic Meta-training", "Authors": ["Siqi Hui", "Sanping Zhou", "Ye deng", "Jinjun Wang"], "Categories": "cs.LG cs.CV"}, "abstract": "Despite the success of two-stage few-shot classification methods, in the episodic meta-training stage, the model suffers severe overfitting. We hypothesize that it is caused by over-discrimination, i.e., the model learns to over-rely on the superficial features that fit for base class discrimination while suppressing the novel class generalization. To penalize over-discrimination, we introduce knowledge distillation techniques to keep novel generalization knowledge from the teacher model during training. Specifically, we select the teacher model as the one with the best validation accuracy during meta-training and restrict the symmetric Kullback-Leibler (SKL) divergence between the output distribution of the linear classifier of the teacher model and that of the student model. This simple approach outperforms the standard meta-training process. We further propose the Nearest Neighbor Symmetric Kullback-Leibler (NNSKL) divergence for meta-training to push the limits of knowledge distillation techniques. NNSKL takes few-shot tasks as input and penalizes the output of the nearest neighbor classifier, which possesses an impact on the relationships between query embedding and support centers. By combining SKL and NNSKL in meta-training, the model achieves even better performance and surpasses state-of-the-art results on several benchmarks.", "url": "https://arxiv.org/abs/2306.16873"}, {"metadata": {"arXiv": "2306.16879", "Date": "Thu, 29 Jun 2023 12:02:16 ", "Title": "Surgical Phase and Instrument Recognition: How to identify appropriate Dataset Splits", "Authors": ["Georgii Kostiuchik", "Lalith Sharan", "Benedikt Mayer", "Ivo Wolf", "Bernhard Preim", "Sandy Engelhardt"], "Categories": "cs.LG", "Comments": ["Accepted at the 14th International Conference on Information Processing in Computer-Assisted Interventions (IPCAI 2023); 9 pages", "4 figures", "1 table"]}, "abstract": "Purpose: The development of machine learning models for surgical workflow and instrument recognition from temporal data represents a challenging task due to the complex nature of surgical workflows. In particular, the imbalanced distribution of data is one of the major challenges in the domain of surgical workflow recognition. In order to obtain meaningful results, careful partitioning of data into training, validation, and test sets, as well as the selection of suitable evaluation metrics are crucial. Methods: In this work, we present an openly available web-based application that enables interactive exploration of dataset partitions. The proposed visual framework facilitates the assessment of dataset splits for surgical workflow recognition, especially with regard to identifying sub-optimal dataset splits. Currently, it supports visualization of surgical phase and instrument annotations. Results: In order to validate the dedicated interactive visualizations, we use a dataset split of the Cholec80 dataset. This dataset split was specifically selected to reflect a case of strong data imbalance. Using our software, we were able to identify phases, phase transitions, and combinations of surgical instruments that were not represented in one of the sets. Conclusion: In order to obtain meaningful results in highly unbalanced class distributions, special care should be taken with respect to the selection of an appropriate split. Interactive data visualization represents a promising approach for the assessment of machine learning datasets. The source code is available at https://github.com/Cardio-AI/endovis-ml", "url": "https://arxiv.org/abs/2306.16879"}, {"metadata": {"arXiv": "2306.16893", "Date": "Thu, 29 Jun 2023 12:29:21 ", "Title": "Traceable Group-Wise Self-Optimizing Feature Transformation Learning: A Dual Optimization Perspective", "Authors": ["Meng Xiao", "Dongjie Wang", "Min Wu", "Kunpeng Liu", "Hui Xiong", "Yuanchun Zhou", "Yanjie Fu"], "Categories": "cs.LG", "Comments": ["21 pages", "submitted to TKDD. arXiv admin note: text overlap with arXiv:2209.08044", "arXiv:2205.14526"]}, "abstract": "Feature transformation aims to reconstruct an effective representation space by mathematically refining the existing features. It serves as a pivotal approach to combat the curse of dimensionality, enhance model generalization, mitigate data sparsity, and extend the applicability of classical models. Existing research predominantly focuses on domain knowledge-based feature engineering or learning latent representations. However, these methods, while insightful, lack full automation and fail to yield a traceable and optimal representation space. An indispensable question arises: Can we concurrently address these limitations when reconstructing a feature space for a machine-learning task? Our initial work took a pioneering step towards this challenge by introducing a novel self-optimizing framework. This framework leverages the power of three cascading reinforced agents to automatically select candidate features and operations for generating improved feature transformation combinations. Despite the impressive strides made, there was room for enhancing its effectiveness and generalization capability. In this extended journal version, we advance our initial work from two distinct yet interconnected perspectives: 1) We propose a refinement of the original framework, which integrates a graph-based state representation method to capture the feature interactions more effectively and develop different Q-learning strategies to alleviate Q-value overestimation further. 2) We utilize a new optimization technique (actor-critic) to train the entire self-optimizing framework in order to accelerate the model convergence and improve the feature transformation performance. Finally, to validate the improved effectiveness and generalization capability of our framework, we perform extensive experiments and conduct comprehensive analyses.", "url": "https://arxiv.org/abs/2306.16893"}, {"metadata": {"arXiv": "2306.16916", "Date": "Thu, 29 Jun 2023 13:08:36 ", "Title": "Obeying the Order: Introducing Ordered Transfer Hyperparameter Optimisation", "Authors": ["Sigrid Passano Hellan", "Huibin Shen", "Fran\\c{c}ois-Xavier Aubet", "David Salinas and Aaron Klein"], "Categories": "cs.LG", "Comments": ["To be presented at the AutoML 2023 Workshop Track"]}, "abstract": "We introduce ordered transfer hyperparameter optimisation (OTHPO), a version of transfer learning for hyperparameter optimisation (HPO) where the tasks follow a sequential order. Unlike for state-of-the-art transfer HPO, the assumption is that each task is most correlated to those immediately before it. This matches many deployed settings, where hyperparameters are retuned as more data is collected; for instance tuning a sequence of movie recommendation systems as more movies and ratings are added. We propose a formal definition, outline the differences to related problems and propose a basic OTHPO method that outperforms state-of-the-art transfer HPO. We empirically show the importance of taking order into account using ten benchmarks. The benchmarks are in the setting of gradually accumulating data, and span XGBoost, random forest, approximate k-nearest neighbor, elastic net, support vector machines and a separate real-world motivated optimisation problem. We open source the benchmarks to foster future research on ordered transfer HPO.", "url": "https://arxiv.org/abs/2306.16916"}, {"metadata": {"arXiv": "2306.16921", "Date": "Thu, 29 Jun 2023 13:14:42 ", "Title": "Provable Advantage of Curriculum Learning on Parity Targets with Mixed Inputs", "Authors": ["Emmanuel Abbe", "Elisabetta Cornacchia", "Aryo Lotfi"], "Categories": "cs.LG stat.ML", "Comments": ["34 pages", "8 figures"]}, "abstract": "Experimental results have shown that curriculum learning, i.e., presenting simpler examples before more complex ones, can improve the efficiency of learning. Some recent theoretical results also showed that changing the sampling distribution can help neural networks learn parities, with formal results only for large learning rates and one-step arguments. Here we show a separation result in the number of training steps with standard (bounded) learning rates on a common sample distribution: if the data distribution is a mixture of sparse and dense inputs, there exists a regime in which a 2-layer ReLU neural network trained by a curriculum noisy-GD (or SGD) algorithm that uses sparse examples first, can learn parities of sufficiently large degree, while any fully connected neural network of possibly larger width or depth trained by noisy-GD on the unordered samples cannot learn without additional steps. We also provide experimental results supporting the qualitative separation beyond the specific regime of the theoretical results.", "url": "https://arxiv.org/abs/2306.16921"}, {"metadata": {"arXiv": "2306.16938", "Date": "Thu, 29 Jun 2023 13:34:35 ", "Title": "Restore Translation Using Equivariant Neural Networks", "Authors": ["Yihan Wang and Lijia Yu and Xiao-Shan Gao"], "Categories": "cs.LG cs.CV"}, "abstract": "Invariance to spatial transformations such as translations and rotations is a desirable property and a basic design principle for classification neural networks. However, the commonly used convolutional neural networks (CNNs) are actually very sensitive to even small translations. There exist vast works to achieve exact or approximate transformation invariance by designing transformation-invariant models or assessing the transformations. These works usually make changes to the standard CNNs and harm the performance on standard datasets. In this paper, rather than modifying the classifier, we propose a pre-classifier restorer to recover translated (or even rotated) inputs to the original ones which will be fed into any classifier for the same dataset. The restorer is based on a theoretical result which gives a sufficient and necessary condition for an affine operator to be translational equivariant on a tensor space.", "url": "https://arxiv.org/abs/2306.16938"}, {"metadata": {"arXiv": "2306.16993", "Date": "Thu, 29 Jun 2023 14:52:04 ", "Title": "Weight Compander: A Simple Weight Reparameterization for Regularization", "Authors": ["Rinor Cakaj", "Jens Mehnert", "Bin Yang"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted by The International Joint Conference on Neural Network (IJCNN) 2023"], "Journal-ref": "IJCNN 2023"}, "abstract": "Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks. In this paper, we introduce weight compander (WC), a novel effective method to improve generalization by reparameterizing each weight in deep neural networks using a nonlinear function. It is a general, intuitive, cheap and easy to implement method, which can be combined with various other regularization techniques. Large weights in deep neural networks are a sign of a more complex network that is overfitted to the training data. Moreover, regularized networks tend to have a greater range of weights around zero with fewer weights centered at zero. We introduce a weight reparameterization function which is applied to each weight and implicitly reduces overfitting by restricting the magnitude of the weights while forcing them away from zero at the same time. This leads to a more democratic decision-making in the network. Firstly, individual weights cannot have too much influence in the prediction process due to the restriction of their magnitude. Secondly, more weights are used in the prediction process, since they are forced away from zero during the training. This promotes the extraction of more features from the input data and increases the level of weight redundancy, which makes the network less sensitive to statistical differences between training and test data. We extend our method to learn the hyperparameters of the introduced weight reparameterization function. This avoids hyperparameter search and gives the network the opportunity to align the weight reparameterization with the training progress. We show experimentally that using weight compander in addition to standard regularization methods improves the performance of neural networks.", "url": "https://arxiv.org/abs/2306.16993"}, {"metadata": {"arXiv": "2306.17038", "Date": "Thu, 29 Jun 2023 15:37:19 ", "Title": "Comparison of Single- and Multi- Objective Optimization Quality for Evolutionary Equation Discovery", "Authors": ["Mikhail Maslyaev and Alexander Hvatov"], "Categories": "cs.LG cs.NE"}, "abstract": "Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library. The equation discovery field contains two independent directions. The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others. The second one is dedicated purely to the optimizational problem statement. Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature. In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation. The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation.", "url": "https://arxiv.org/abs/2306.17038"}, {"metadata": {"arXiv": "2306.17062", "Date": "Thu, 29 Jun 2023 16:10:07 ", "Title": "Gesture Recognition with mmWave Wi-Fi Access Points: Lessons Learned", "Authors": ["Nabeel Nisar Bhat", "Rafael Berkvens", "Jeroen Famaey"], "Categories": "cs.LG eess.SP"}, "abstract": "In recent years, channel state information (CSI) at sub-6 GHz has been widely exploited for Wi-Fi sensing, particularly for activity and gesture recognition. In this work, we instead explore mmWave (60 GHz) Wi-Fi signals for gesture recognition/pose estimation. Our focus is on the mmWave Wi-Fi signals so that they can be used not only for high data rate communication but also for improved sensing e.g., for extended reality (XR) applications. For this reason, we extract spatial beam signal-to-noise ratios (SNRs) from the periodic beam training employed by IEEE 802.11ad devices. We consider a set of 10 gestures/poses motivated by XR applications. We conduct experiments in two environments and with three people.As a comparison, we also collect CSI from IEEE 802.11ac devices. To extract features from the CSI and the beam SNR, we leverage a deep neural network (DNN). The DNN classifier achieves promising results on the beam SNR task with state-of-the-art 96.7% accuracy in a single environment, even with a limited dataset. We also investigate the robustness of the beam SNR against CSI across different environments. Our experiments reveal that features from the CSI generalize without additional re-training, while those from beam SNRs do not. Therefore, re-training is required in the latter case.", "url": "https://arxiv.org/abs/2306.17062"}, {"metadata": {"arXiv": "2306.17066", "Date": "Thu, 29 Jun 2023 16:14:43 ", "Title": "On the Predictive Accuracy of Neural Temporal Point Process Models for Continuous-time Event Data", "Authors": ["Tanguy Bosser and Souhaib Ben Taieb"], "Categories": "cs.LG"}, "abstract": "Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations.", "url": "https://arxiv.org/abs/2306.17066"}, {"metadata": {"arXiv": "2306.17089", "Date": "Thu, 29 Jun 2023 16:47:11 ", "Title": "Concept-Oriented Deep Learning with Large Language Models", "Authors": ["Daniel T. Chang"], "Categories": "cs.LG cs.CL"}, "abstract": "Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots.", "url": "https://arxiv.org/abs/2306.17089"}, {"metadata": {"arXiv": "2306.17090", "Date": "Thu, 29 Jun 2023 16:48:00 ", "Title": "Sparsity exploitation via discovering graphical models in multi-variate time-series forecasting", "Authors": ["Ngoc-Dung Do", "Truong Son Hy", "Duy Khuong Nguyen"], "Categories": "cs.LG"}, "abstract": "Graph neural networks (GNNs) have been widely applied in multi-variate time-series forecasting (MTSF) tasks because of their capability in capturing the correlations among different time-series. These graph-based learning approaches improve the forecasting performance by discovering and understanding the underlying graph structures, which represent the data correlation. When the explicit prior graph structures are not available, most existing works cannot guarantee the sparsity of the generated graphs that make the overall model computational expensive and less interpretable. In this work, we propose a decoupled training method, which includes a graph generating module and a GNNs forecasting module. First, we use Graphical Lasso (or GraphLASSO) to directly exploit the sparsity pattern from data to build graph structures in both static and time-varying cases. Second, we fit these graph structures and the input data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting model. The experimental results on three real-world datasets show that our novel approach has competitive performance against existing state-of-the-art forecasting algorithms while providing sparse, meaningful and explainable graph structures and reducing training time by approximately 40%. Our PyTorch implementation is publicly available at https://github.com/HySonLab/GraphLASSO", "url": "https://arxiv.org/abs/2306.17090"}, {"metadata": {"arXiv": "2306.17105", "Date": "Thu, 29 Jun 2023 17:07:34 ", "Title": "Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations", "Authors": ["Yongyi Yang", "Jacob Steinhardt", "Wei Hu"], "Categories": "cs.LG", "Comments": ["This paper has been accepted as a conference paper at ICML 2023"]}, "abstract": "Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.", "url": "https://arxiv.org/abs/2306.17105"}, {"metadata": {"arXiv": "2306.17108", "Date": "Thu, 29 Jun 2023 17:08:53 ", "Title": "ManimML: Communicating Machine Learning Architectures with Animation", "Authors": ["Alec Helbling and Duen Horng (Polo) Chau"], "Categories": "cs.LG cs.HC"}, "abstract": "There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering. However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind. Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms. However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software. We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code. We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software. ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch. A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network. ManimML is open source and available at https://github.com/helblazer811/ManimML.", "url": "https://arxiv.org/abs/2306.17108"}, {"metadata": {"arXiv": "2306.16700", "Date": "Thu, 29 Jun 2023 05:51:44 ", "Title": "Dynamic-Resolution Model Learning for Object Pile Manipulation", "Authors": ["Yixuan Wang", "Yunzhu Li", "Katherine Driggs-Campbell", "Li Fei-Fei", "Jiajun Wu"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Accepted to Robotics: Science and Systems (RSS 2023). The first two authors contributed equally. Project Page: https://https://robopil.github.io/dyn-res-pile-manip"]}, "abstract": "Dynamics models learned from visual observations have shown to be effective in various robotic manipulation tasks. One of the key questions for learning such dynamics models is what scene representation to use. Prior works typically assume representation at a fixed dimension or resolution, which may be inefficient for simple tasks and ineffective for more complicated tasks. In this work, we investigate how to learn dynamic and adaptive representations at different levels of abstraction to achieve the optimal trade-off between efficiency and effectiveness. Specifically, we construct dynamic-resolution particle representations of the environment and learn a unified dynamics model using graph neural networks (GNNs) that allows continuous selection of the abstraction level. During test time, the agent can adaptively determine the optimal resolution at each model-predictive control (MPC) step. We evaluate our method in object pile manipulation, a task we commonly encounter in cooking, agriculture, manufacturing, and pharmaceutical applications. Through comprehensive evaluations both in the simulation and the real world, we show that our method achieves significantly better performance than state-of-the-art fixed-resolution baselines at the gathering, sorting, and redistribution of granular object piles made with various instances like coffee beans, almonds, corn, etc.", "url": "https://arxiv.org/abs/2306.16700"}, {"metadata": {"arXiv": "2306.16857", "Date": "Thu, 29 Jun 2023 11:07:14 ", "Title": "ArrayBot: Reinforcement Learning for Generalizable Distributed Manipulation through Touch", "Authors": ["Zhengrong Xue", "Han Zhang", "Jingwen Cheng", "Zhengmao He", "Yuanchen Ju", "Changyi Lin", "Gu Zhang", "Huazhe Xu"], "Categories": "cs.RO cs.LG"}, "abstract": "We present ArrayBot, a distributed manipulation system consisting of a $16 \\times 16$ array of vertically sliding pillars integrated with tactile sensors, which can simultaneously support, perceive, and manipulate the tabletop objects. Towards generalizable distributed manipulation, we leverage reinforcement learning (RL) algorithms for the automatic discovery of control policies. In the face of the massively redundant actions, we propose to reshape the action space by considering the spatially local action patch and the low-frequency actions in the frequency domain. With this reshaped action space, we train RL agents that can relocate diverse objects through tactile observations only. Surprisingly, we find that the discovered policy can not only generalize to unseen object shapes in the simulator but also transfer to the physical robot without any domain randomization. Leveraging the deployed policy, we present abundant real-world manipulation tasks, illustrating the vast potential of RL on ArrayBot for distributed manipulation.", "url": "https://arxiv.org/abs/2306.16857"}, {"metadata": {"arXiv": "2306.16978", "Date": "Thu, 29 Jun 2023 14:32:06 ", "Title": "End-to-end Reinforcement Learning for Online Coverage Path Planning in Unknown Environments", "Authors": ["Arvi Jonnarth", "Jie Zhao", "Michael Felsberg"], "Categories": "cs.RO cs.LG cs.SY eess.SY"}, "abstract": "Coverage path planning is the problem of finding the shortest path that covers the entire free space of a given confined area, with applications ranging from robotic lawn mowing and vacuum cleaning, to demining and search-and-rescue tasks. While offline methods can find provably complete, and in some cases optimal, paths for known environments, their value is limited in online scenarios where the environment is not known beforehand, especially in the presence of non-static obstacles. We propose an end-to-end reinforcement learning-based approach in continuous state and action space, for the online coverage path planning problem that can handle unknown environments. We construct the observation space from both global maps and local sensory inputs, allowing the agent to plan a long-term path, and simultaneously act on short-term obstacle detections. To account for large-scale environments, we propose to use a multi-scale map input representation. Furthermore, we propose a novel total variation reward term for eliminating thin strips of uncovered space in the learned path. To validate the effectiveness of our approach, we perform extensive experiments in simulation with a distance sensor, surpassing the performance of a recent reinforcement learning-based approach.", "url": "https://arxiv.org/abs/2306.16978"}, {"metadata": {"arXiv": "2306.17101", "Date": "Thu, 29 Jun 2023 16:58:08 ", "Title": "Identifying Important Sensory Feedback for Learning Locomotion Skills", "Authors": ["Wanming Yu", "Chuanyu Yang", "Christopher McGreavy", "Eleftherios Triantafyllidis", "Guillaume Bellegarda", "Milad Shafiee", "Auke Jan Ijspeert", "and Zhibin Li"], "Categories": "cs.RO cs.LG"}, "abstract": "Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings. While the selection of state observations is crucial, there has been a lack of quantitative analysis to date. Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL. Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping. By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills. The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rate will drop significantly if key states are missing. This work provides quantitative insights into the relationship between state observations and specific types of motor skills, serving as a guideline for robot motor learning. The proposed method is applicable to differentiable state-action mapping, such as neural network based control policies, enabling the learning of a wide range of motor skills with minimal sensing dependencies.", "url": "https://arxiv.org/abs/2306.17101"}, {"metadata": {"arXiv": "2306.16697", "Date": "Thu, 29 Jun 2023 05:39:58 ", "Title": "Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features", "Authors": ["Mingli Zhu", "Shaokui Wei", "Hongyuan Zha", "Baoyuan Wu"], "Categories": "cs.AI cs.CR"}, "abstract": "Recent studies have demonstrated the susceptibility of deep neural networks to backdoor attacks. Given a backdoored model, its prediction of a poisoned sample with trigger will be dominated by the trigger information, though trigger information and benign information coexist. Inspired by the mechanism of the optical polarizer that a polarizer could pass light waves with particular polarizations while filtering light waves with other polarizations, we propose a novel backdoor defense method by inserting a learnable neural polarizer into the backdoored model as an intermediate layer, in order to purify the poisoned sample via filtering trigger information while maintaining benign information. The neural polarizer is instantiated as one lightweight linear transformation layer, which is learned through solving a well designed bi-level optimization problem, based on a limited clean dataset. Compared to other fine-tuning-based defense methods which often adjust all parameters of the backdoored model, the proposed method only needs to learn one additional layer, such that it is more efficient and requires less clean data. Extensive experiments demonstrate the effectiveness and efficiency of our method in removing backdoors across various neural network architectures and datasets, especially in the case of very limited clean data.", "url": "https://arxiv.org/abs/2306.16697"}, {"metadata": {"arXiv": "2306.16902", "Date": "Thu, 29 Jun 2023 12:48:00 ", "Title": "From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data", "Authors": ["Taiyu Ban", "Lyvzhou Chen", "Xiangyu Wang", "Huanhuan Chen"], "Categories": "cs.AI"}, "abstract": "Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law. Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality. In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning. To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning. We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data. We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them. As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis.", "url": "https://arxiv.org/abs/2306.16902"}, {"metadata": {"arXiv": "2306.16914", "Date": "Thu, 29 Jun 2023 13:08:12 ", "Title": "Computationally Assisted Quality Control for Public Health Data Streams", "Authors": ["Ananya Joshi", "Kathryn Mazaitis", "Roni Rosenfeld", "Bryan Wilder"], "Categories": "cs.AI", "Comments": ["https://github.com/cmu-delphi/covidcast-indicators/tree/main/_delphi_utils_python/delphi_utils/flash_eval"]}, "abstract": "Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.", "url": "https://arxiv.org/abs/2306.16914"}, {"metadata": {"arXiv": "2306.16958", "Date": "Thu, 29 Jun 2023 14:05:35 ", "Title": "Identifiability of direct effects from summary causal graphs", "Authors": ["Simon Ferreira and Charles K. Assaad"], "Categories": "cs.AI"}, "abstract": "Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant. The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph. Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion. However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information. This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summary causal graphs and gives two sound finite adjustment sets that can be used to estimate the direct effect whenever it is identifiable.", "url": "https://arxiv.org/abs/2306.16958"}, {"metadata": {"arXiv": "2306.17034", "Date": "Thu, 29 Jun 2023 15:35:34 ", "Title": "Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion", "Authors": ["Tao He", "Ming Liu", "Yixin Cao", "Zekun Wang", "Zihao Zheng", "Zheng Chu", "and Bing Qin"], "Categories": "cs.AI cs.CL", "Comments": ["12 pages", "5 figures"]}, "abstract": "Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity. This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications. To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC. The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller. The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor. This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue. Furthermore, the path distiller further distills logical reasoning knowledge from these mined reasoning paths into the predictor. These two components are jointly optimized using a well-designed variational EM algorithm. Extensive experiments and analyses on four sparse benchmarks demonstrate the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2306.17034"}, {"metadata": {"arXiv": "2306.17059", "Date": "Thu, 29 Jun 2023 16:05:40 ", "Title": "The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps", "Authors": ["Jina Kim", "Zekun Li", "Yijun Lin", "Min Namgung", "Leeje Jang", "Yao-Yi Chiang"], "Categories": "cs.AI cs.CL cs.CV", "Comments": ["4 pages", "4 figures"]}, "abstract": "Documents hold spatial focus and valuable locality characteristics. For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods. This information is valuable to characterize how humans perceive their environment. However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document. Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document. This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location. Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage. In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches. Additionally, topic modeling methods are often applied to broad topics of news articles where context is easily distinguishable. To identify the geographic focus of a document effectively, we present a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which jointly learns representations with separate encoders of document and location. JELLY significantly outperforms state-of-the-art methods for identifying spatial focus from documents from a number of sources. We also demonstrate case studies on the arithmetic of the learned representations, including identifying cities with similar locality characteristics and zero-shot learning to identify document spatial focus.", "url": "https://arxiv.org/abs/2306.17059"}, {"metadata": {"arXiv": "2306.17070", "Date": "Thu, 29 Jun 2023 16:17:04 ", "Title": "Interdisciplinary Methods in Computational Creativity: How Human Variables Shape Human-Inspired AI Research", "Authors": ["Nadia M. Ady and Faun Rice"], "Categories": "cs.AI", "Comments": ["5 pages", "published in the Proceedings of the 14th International Conference on Computational Creativity", "ICCC'23"], "ACM-class": "I.2.0; K.7.0"}, "abstract": "The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more. The question of what creativity means when it is part of a computational system might be considered core to CC. Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI). Yet, the human processes shaping human-inspired computational systems have been little investigated. In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry. This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area. This paper focuses on findings most relevant to CC. We suggest that which human literature enters AI bears greater scrutiny because ideas may become disconnected from context in their home discipline. Accordingly, we recommend that CC researchers document the decisions and context of their practices, particularly those practices formalizing human concepts for machines. Publishing reflexive commentary on human elements in CC and AI would provide a useful record and permit greater dialogue with other disciplines.", "url": "https://arxiv.org/abs/2306.17070"}, {"metadata": {"arXiv": "2306.16533", "Date": "Wed, 28 Jun 2023 20:06:36 ", "Title": "ICSVR: Investigating Compositional and Semantic Understanding in Video Retrieval Models", "Authors": ["Avinash Madasu", "Vasudev Lal"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Video retrieval (VR) involves retrieving the ground truth video from the video database given a text caption or vice-versa. The two important components of compositionality: objects \\& attributes and actions are joined using correct semantics to form a proper text query. These components (objects \\& attributes, actions and semantics) each play an important role to help distinguish among videos and retrieve the correct ground truth video. However, it is unclear what is the effect of these components on the video retrieval performance. We therefore, conduct a systematic study to evaluate the compositional and semantic understanding of video retrieval models on standard benchmarks such as MSRVTT, MSVD and DIDEMO. The study is performed on two categories of video retrieval models: (i) which are pre-trained on video-text pairs and fine-tuned on downstream video retrieval datasets (Eg. Frozen-in-Time, Violet, MCQ etc.) (ii) which adapt pre-trained image-text representations like CLIP for video retrieval (Eg. CLIP4Clip, XCLIP, CLIP2Video etc.). Our experiments reveal that actions and semantics play a minor role compared to objects \\& attributes in video understanding. Moreover, video retrieval models that use pre-trained image-text representations (CLIP) have better semantic and compositional understanding as compared to models pre-trained on video-text data.", "url": "https://arxiv.org/abs/2306.16533"}, {"metadata": {"arXiv": "2306.16538", "Date": "Wed, 28 Jun 2023 20:24:53 ", "Title": "CLANet: A Comprehensive Framework for Cross-Batch Cell Line Identification Using Brightfield Images", "Authors": ["Lei Tong", "Adam Corrigan", "Navin Rathna Kumar", "Kerry Hallbrook", "Jonathan Orme", "Yinhai Wang", "Huiyu Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["15 pages", "10 figures"]}, "abstract": "Cell line authentication plays a crucial role in the biomedical field, ensuring researchers work with accurately identified cells. Supervised deep learning has made remarkable strides in cell line identification by studying cell morphological features through cell imaging. However, batch effects, a significant issue stemming from the different times at which data is generated, lead to substantial shifts in the underlying data distribution, thus complicating reliable differentiation between cell lines from distinct batch cultures. To address this challenge, we introduce CLANet, a pioneering framework for cross-batch cell line identification using brightfield images, specifically designed to tackle three distinct batch effects. We propose a cell cluster-level selection method to efficiently capture cell density variations, and a self-supervised learning strategy to manage image quality variations, thus producing reliable patch representations. Additionally, we adopt multiple instance learning(MIL) for effective aggregation of instance-level features for cell line identification. Our innovative time-series segment sampling module further enhances MIL's feature-learning capabilities, mitigating biases from varying incubation times across batches. We validate CLANet using data from 32 cell lines across 93 experimental batches from the AstraZeneca Global Cell Bank. Our results show that CLANet outperforms related approaches (e.g. domain adaptation, MIL), demonstrating its effectiveness in addressing batch effects in cell line identification.", "url": "https://arxiv.org/abs/2306.16538"}, {"metadata": {"arXiv": "2306.16539", "Date": "Wed, 28 Jun 2023 20:27:11 ", "Title": "A systematic study of the foreground-background imbalance problem in deep learning for object detection", "Authors": ["Hanxue Gu", "Haoyu Dong", "Nicholas Konz", "Maciej A. Mazurowski"], "Categories": "cs.CV cs.AI"}, "abstract": "The class imbalance problem in deep learning has been explored in several studies, but there has yet to be a systematic analysis of this phenomenon in object detection. Here, we present comprehensive analyses and experiments of the foreground-background (F-B) imbalance problem in object detection, which is very common and caused by small, infrequent objects of interest. We experimentally study the effects of different aspects of F-B imbalance (object size, number of objects, dataset size, object type) on detection performance. In addition, we also compare 9 leading methods for addressing this problem, including Faster-RCNN, SSD, OHEM, Libra-RCNN, Focal-Loss, GHM, PISA, YOLO-v3, and GFL with a range of datasets from different imaging domains. We conclude that (1) the F-B imbalance can indeed cause a significant drop in detection performance, (2) The detection performance is more affected by F-B imbalance when fewer training data are available, (3) in most cases, decreasing object size leads to larger performance drop than decreasing number of objects, given the same change in the ratio of object pixels to non-object pixels, (6) among all selected methods, Libra-RCNN and PISA demonstrate the best performance in addressing the issue of F-B imbalance. (7) When the training dataset size is large, the choice of method is not impactful (8) Soft-sampling methods, including focal-loss, GHM, and GFL, perform fairly well on average but are relatively unstable.", "url": "https://arxiv.org/abs/2306.16539"}, {"metadata": {"arXiv": "2306.16581", "Date": "Wed, 28 Jun 2023 22:20:19 ", "Title": "Does Saliency-Based Training bring Robustness for Deep Neural Networks in Image Classification?", "Authors": ["Ali Karkehabadi"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep Neural Networks are powerful tools to understand complex patterns and making decisions. However, their black-box nature impedes a complete understanding of their inner workings. While online saliency-guided training methods try to highlight the prominent features in the model's output to alleviate this problem, it is still ambiguous if the visually explainable features align with robustness of the model against adversarial examples. In this paper, we investigate the saliency trained model's vulnerability to adversarial examples methods. Models are trained using an online saliency-guided training method and evaluated against popular algorithms of adversarial examples. We quantify the robustness and conclude that despite the well-explained visualizations in the model's output, the salient models suffer from the lower performance against adversarial examples attacks.", "url": "https://arxiv.org/abs/2306.16581"}, {"metadata": {"arXiv": "2306.16736", "Date": "Thu, 29 Jun 2023 07:22:20 ", "Title": "GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction", "Authors": ["Sihan Ma", "Qiong Cao", "Hongwei Yi", "Jing Zhang", "Dacheng Tao"], "Categories": "cs.CV cs.AI", "Comments": ["The code will be available at https://github.com/xymsh/GraMMaR"]}, "abstract": "Demystifying complex human-ground interactions is essential for accurate and realistic 3D human motion reconstruction from RGB videos, as it ensures consistency between the humans and the ground plane. Prior methods have modeled human-ground interactions either implicitly or in a sparse manner, often resulting in unrealistic and incorrect motions when faced with noise and uncertainty. In contrast, our approach explicitly represents these interactions in a dense and continuous manner. To this end, we propose a novel Ground-aware Motion Model for 3D Human Motion Reconstruction, named GraMMaR, which jointly learns the distribution of transitions in both pose and interaction between every joint and ground plane at each time step of a motion sequence. It is trained to explicitly promote consistency between the motion and distance change towards the ground. After training, we establish a joint optimization strategy that utilizes GraMMaR as a dual-prior, regularizing the optimization towards the space of plausible ground-aware motions. This leads to realistic and coherent motion reconstruction, irrespective of the assumed or learned ground plane. Through extensive evaluation on the AMASS and AIST++ datasets, our model demonstrates good generalization and discriminating abilities in challenging cases including complex and ambiguous human-ground interactions. The code will be released.", "url": "https://arxiv.org/abs/2306.16736"}, {"metadata": {"arXiv": "2306.16798", "Date": "Thu, 29 Jun 2023 09:17:58 ", "Title": "Evaluation of Environmental Conditions on Object Detection using Oriented Bounding Boxes for AR Applications", "Authors": ["Vladislav Li", "Barbara Villarini", "Jean-Christophe Nebel", "Thomas Lagkas", "Panagiotis Sarigiannidis", "Vasileios Argyriou"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "4 figures", "conference"], "MSC-class": "ACM-class: I.2.10"}, "abstract": "The objective of augmented reality (AR) is to add digital content to natural images and videos to create an interactive experience between the user and the environment. Scene analysis and object recognition play a crucial role in AR, as they must be performed quickly and accurately. In this study, a new approach is proposed that involves using oriented bounding boxes with a detection and recognition deep network to improve performance and processing time. The approach is evaluated using two datasets: a real image dataset (DOTA dataset) commonly used for computer vision tasks, and a synthetic dataset that simulates different environmental, lighting, and acquisition conditions. The focus of the evaluation is on small objects, which are difficult to detect and recognise. The results indicate that the proposed approach tends to produce better Average Precision and greater accuracy for small objects in most of the tested conditions.", "url": "https://arxiv.org/abs/2306.16798"}, {"metadata": {"arXiv": "2306.16862", "Date": "Thu, 29 Jun 2023 11:19:06 ", "Title": "Sustainable Palm Tree Farming: Leveraging IoT and Multi-Modal Data for Early Detection and Mapping of Red Palm Weevil", "Authors": ["Yosra Hajjaji", "Ayyub Alzahem", "Wadii Boulila", "Imed Riadh Farah", "Anis Koubaa"], "Categories": "cs.CV cs.AI"}, "abstract": "The Red Palm Weevil (RPW) is a highly destructive insect causing economic losses and impacting palm tree farming worldwide. This paper proposes an innovative approach for sustainable palm tree farming by utilizing advanced technologies for the early detection and management of RPW. Our approach combines computer vision, deep learning (DL), the Internet of Things (IoT), and geospatial data to detect and classify RPW-infested palm trees effectively. The main phases include; (1) DL classification using sound data from IoT devices, (2) palm tree detection using YOLOv8 on UAV images, and (3) RPW mapping using geospatial data. Our custom DL model achieves 100% precision and recall in detecting and localizing infested palm trees. Integrating geospatial data enables the creation of a comprehensive RPW distribution map for efficient monitoring and targeted management strategies. This technology-driven approach benefits agricultural authorities, farmers, and researchers in managing RPW infestations and safeguarding palm tree plantations' productivity.", "url": "https://arxiv.org/abs/2306.16862"}, {"metadata": {"arXiv": "2306.16894", "Date": "Wed, 28 Jun 2023 11:10:20 ", "Title": "PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing", "Authors": ["Wenjing Huang", "Shikui Tu", "Lei Xu"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["18 pages", "15 figures"]}, "abstract": "Diffusion models have showcased their remarkable capability to synthesize diverse and high-quality images, sparking interest in their application for real image editing. However, existing diffusion-based approaches for local image editing often suffer from undesired artifacts due to the pixel-level blending of the noised target images and diffusion latent variables, which lack the necessary semantics for maintaining image consistency. To address these issues, we propose PFB-Diff, a Progressive Feature Blending method for Diffusion-based image editing. Unlike previous methods, PFB-Diff seamlessly integrates text-guided generated content into the target image through multi-level feature blending. The rich semantics encoded in deep features and the progressive blending scheme from high to low levels ensure semantic coherence and high quality in edited images. Additionally, we introduce an attention masking mechanism in the cross-attention layers to confine the impact of specific words to desired regions, further improving the performance of background editing. PFB-Diff can effectively address various editing tasks, including object/background replacement and object attribute editing. Our method demonstrates its superior performance in terms of image fidelity, editing accuracy, efficiency, and faithfulness to the original image, without the need for fine-tuning or training.", "url": "https://arxiv.org/abs/2306.16894"}, {"metadata": {"arXiv": "2306.16928", "Date": "Thu, 29 Jun 2023 13:28:16 ", "Title": "One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization", "Authors": ["Minghua Liu", "Chao Xu", "Haian Jin", "Linghao Chen", "Mukund Varma T", "Zexiang Xu", "Hao Su"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["project website: one-2-3-45.com"]}, "abstract": "Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods. Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image. We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime. In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models.", "url": "https://arxiv.org/abs/2306.16928"}, {"metadata": {"arXiv": "2306.16950", "Date": "Thu, 29 Jun 2023 13:49:06 ", "Title": "Alternative Telescopic Displacement: An Efficient Multimodal Alignment Method", "Authors": ["Jiahao Qin and Yitao Xu and Zihong Luo Chengzhi Liu and Zong Lu and Xiaojun Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages,7 figures"]}, "abstract": "Feature alignment is the primary means of fusing multimodal data. We propose a feature alignment method that fully fuses multimodal information, which alternately shifts and expands feature information from different modalities to have a consistent representation in a feature space. The proposed method can robustly capture high-level interactions between features of different modalities, thus significantly improving the performance of multimodal learning. We also show that the proposed method outperforms other popular multimodal schemes on multiple tasks. Experimental evaluation of ETT and MIT-BIH-Arrhythmia, datasets shows that the proposed method achieves state of the art performance.", "url": "https://arxiv.org/abs/2306.16950"}, {"metadata": {"arXiv": "2306.17074", "Date": "Thu, 29 Jun 2023 16:24:32 ", "Title": "Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation", "Authors": ["Zhongwei Qiu", "Qiansheng Yang", "Jian Wang", "Xiyu Wang", "Chang Xu", "Dongmei Fu", "Kun Yao", "Junyu Han", "Errui Ding", "Jingdong Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network. Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers. In this paper, we propose \\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps. During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature. During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way. Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information. Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets, respectively.", "url": "https://arxiv.org/abs/2306.17074"}, {"metadata": {"arXiv": "2306.16784", "Date": "Thu, 29 Jun 2023 08:42:18 ", "Title": "A Survey on Datasets for Decision-making of Autonomous Vehicle", "Authors": ["Yuning Wang", "Zeyu Han", "Yining Xing", "Shaobing Xu", "Jianqiang Wang"], "Categories": "cs.RO cs.AI cs.MA"}, "abstract": "Autonomous vehicles (AV) are expected to reshape future transportation systems, and decision-making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more and more focus. The datasets to be used in developing data-driven methods dramatically influences the performance of decision-making, hence it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle, environment, and driver related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also concludes the potential applications of datasets on various aspects of AV decision-making, assisting researchers to find appropriate ones to support their own research. The future trends of AV dataset development are summarized.", "url": "https://arxiv.org/abs/2306.16784"}, {"metadata": {"arXiv": "2306.17030", "Date": "Thu, 29 Jun 2023 15:25:51 ", "Title": "SkiROS2: A skill-based Robot Control Platform for ROS", "Authors": ["Matthias Mayr", "Francesco Rovida", "Volker Krueger"], "Categories": "cs.RO cs.AI", "Comments": ["8 pages", "3 figures. Accepted at 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"]}, "abstract": "The need for autonomous robot systems in both the service and the industrial domain is larger than ever. In the latter, the transition to small batches or even \"batch size 1\" in production created a need for robot control system architectures that can provide the required flexibility. Such architectures must not only have a sufficient knowledge integration framework. It must also support autonomous mission execution and allow for interchangeability and interoperability between different tasks and robot systems. We introduce SkiROS2, a skill-based robot control platform on top of ROS. SkiROS2 proposes a layered, hybrid control structure for automated task planning, and reactive execution, supported by a knowledge base for reasoning about the world state and entities. The scheduling formulation builds on the extended behavior tree model that merges task-level planning and execution. This allows for a high degree of modularity and a fast reaction to changes in the environment. The skill formulation based on pre-, hold- and post-conditions allows to organize robot programs and to compose diverse skills reaching from perception to low-level control and the incorporation of external tools. We relate SkiROS2 to the field and outline three example use cases that cover task planning, reasoning, multisensory input, integration in a manufacturing execution system and reinforcement learning.", "url": "https://arxiv.org/abs/2306.17030"}, {"metadata": {"arXiv": "2306.16619", "Date": "Thu, 29 Jun 2023 01:28:14 ", "Title": "Laxity-Aware Scalable Reinforcement Learning for HVAC Control", "Authors": ["Ruohong Liu", "Yuxin Pan", "Yize Chen"], "Categories": "eess.SY cs.AI cs.SY math.OC", "Comments": ["In Submission"]}, "abstract": "Demand flexibility plays a vital role in maintaining grid balance, reducing peak demand, and saving customers' energy bills. Given their highly shiftable load and significant contribution to a building's energy consumption, Heating, Ventilation, and Air Conditioning (HVAC) systems can provide valuable demand flexibility to the power systems by adjusting their energy consumption in response to electricity price and power system needs. To exploit this flexibility in both operation time and power, it is imperative to accurately model and aggregate the load flexibility of a large population of HVAC systems as well as designing effective control algorithms. In this paper, we tackle the curse of dimensionality issue in modeling and control by utilizing the concept of laxity to quantify the emergency level of each HVAC operation request. We further propose a two-level approach to address energy optimization for a large population of HVAC systems. The lower level involves an aggregator to aggregate HVAC load laxity information and use least-laxity-first (LLF) rule to allocate real-time power for individual HVAC systems based on the controller's total power. Due to the complex and uncertain nature of HVAC systems, we leverage a reinforcement learning (RL)-based controller to schedule the total power based on the aggregated laxity information and electricity price. We evaluate the temperature control and energy cost saving performance of a large-scale group of HVAC systems in both single-zone and multi-zone scenarios, under varying climate and electricity market conditions. The experiment results indicate that proposed approach outperforms the centralized methods in the majority of test scenarios, and performs comparably to model-based method in some scenarios.", "url": "https://arxiv.org/abs/2306.16619"}, {"metadata": {"arXiv": "2306.16424", "Date": "Thu, 22 Jun 2023 10:32:51 ", "Title": "Realistic Synthetic Financial Transactions for Anti-Money Laundering Models", "Authors": ["Erik Altman", "B\\'eni Egressy", "Jovan Blanu\\v{s}a", "Kubilay Atasu"], "Categories": "cs.AI cs.LG q-fin.CP"}, "abstract": "With the widespread digitization of finance and the increasing popularity of cryptocurrencies, the sophistication of fraud schemes devised by cybercriminals is growing. Money laundering -- the movement of illicit funds to conceal their origins -- can cross bank and national boundaries, producing complex transaction patterns. The UN estimates 2-5\\% of global GDP or \\$0.8 - \\$2.0 trillion dollars are laundered globally each year. Unfortunately, real data to train machine learning models to detect laundering is generally not available, and previous synthetic data generators have had significant shortcomings. A realistic, standardized, publicly-available benchmark is needed for comparing models and for the advancement of the area. To this end, this paper contributes a synthetic financial transaction dataset generator and a set of synthetically generated AML (Anti-Money Laundering) datasets. We have calibrated this agent-based generator to match real transactions as closely as possible and made the datasets public. We describe the generator in detail and demonstrate how the datasets generated can help compare different Graph Neural Networks in terms of their AML abilities. In a key way, using synthetic data in these comparisons can be even better than using real data: the ground truth labels are complete, whilst many laundering transactions in real data are never detected.", "url": "https://arxiv.org/abs/2306.16424"}, {"metadata": {"arXiv": "2306.16612", "Date": "Thu, 29 Jun 2023 00:55:51 ", "Title": "GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps", "Authors": ["Minsoo Kang", "Suhyun Kim"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Published at AAAI2023 (Oral)"], "Journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 2023, 1096-1104", "DOI": "10.1609/aaai.v37i1.25191"}, "abstract": "Data augmentation is now an essential part of the image training process, as it effectively prevents overfitting and makes the model more robust against noisy datasets. Recent mixing augmentation strategies have advanced to generate the mixup mask that can enrich the saliency information, which is a supervisory signal. However, these methods incur a significant computational burden to optimize the mixup mask. From this motivation, we propose a novel saliency-aware mixup method, GuidedMixup, which aims to retain the salient regions in mixup images with low computational overhead. We develop an efficient pairing algorithm that pursues to minimize the conflict of salient regions of paired images and achieve rich saliency in mixup images. Moreover, GuidedMixup controls the mixup ratio for each pixel to better preserve the salient region by interpolating two paired images smoothly. The experiments on several datasets demonstrate that GuidedMixup provides a good trade-off between augmentation overhead and generalization performance on classification datasets. In addition, our method shows good performance in experiments with corrupted or reduced datasets.", "url": "https://arxiv.org/abs/2306.16612"}, {"metadata": {"arXiv": "2306.16661", "Date": "Thu, 29 Jun 2023 03:43:29 ", "Title": "NaturalInversion: Data-Free Image Synthesis Improving Real-World Consistency", "Authors": ["Yujin Kim", "Dogyun Park", "Dohee Kim", "Suhyun Kim"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Published at AAAI 2022"], "Journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence, 36(1), 2022, 1201-1209", "DOI": "10.1609/aaai.v36i1.20006"}, "abstract": "We introduce NaturalInversion, a novel model inversion-based method to synthesize images that agrees well with the original data distribution without using real data. In NaturalInversion, we propose: (1) a Feature Transfer Pyramid which uses enhanced image prior of the original data by combining the multi-scale feature maps extracted from the pre-trained classifier, (2) a one-to-one approach generative model where only one batch of images are synthesized by one generator to bring the non-linearity to optimization and to ease the overall optimizing process, (3) learnable Adaptive Channel Scaling parameters which are end-to-end trained to scale the output image channel to utilize the original image prior further. With our NaturalInversion, we synthesize images from classifiers trained on CIFAR-10/100 and show that our images are more consistent with original data distribution than prior works by visualization and additional analysis. Furthermore, our synthesized images outperform prior works on various applications such as knowledge distillation and pruning, demonstrating the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2306.16661"}, {"metadata": {"arXiv": "2306.16699", "Date": "Thu, 29 Jun 2023 05:49:07 ", "Title": "Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation", "Authors": ["Hanqiu Chen", "Hang Yang", "Stephen BR Fitzmeyer", "Cong Hao"], "Categories": "cs.CV cs.AI cs.AR cs.LG", "Comments": ["Submitted to ICCAD 2023", "under review"]}, "abstract": "Implicit Neural Representation (INR) is an innovative approach for representing complex shapes or objects without explicitly defining their geometry or surface structure. Instead, INR represents objects as continuous functions. Previous research has demonstrated the effectiveness of using neural networks as INR for image compression, showcasing comparable performance to traditional methods such as JPEG. However, INR holds potential for various applications beyond image compression. This paper introduces Rapid-INR, a novel approach that utilizes INR for encoding and compressing images, thereby accelerating neural network training in computer vision tasks. Our methodology involves storing the whole dataset directly in INR format on a GPU, mitigating the significant data communication overhead between the CPU and GPU during training. Additionally, the decoding process from INR to RGB format is highly parallelized and executed on-the-fly. To further enhance compression, we propose iterative and dynamic pruning, as well as layer-wise quantization, building upon previous work. We evaluate our framework on the image classification task, utilizing the ResNet-18 backbone network and three commonly used datasets with varying image sizes. Rapid-INR reduces memory consumption to only 5% of the original dataset size and achieves a maximum 6$\\times$ speedup over the PyTorch training pipeline, as well as a maximum 1.2x speedup over the DALI training pipeline, with only a marginal decrease in accuracy. Importantly, Rapid-INR can be readily applied to other computer vision tasks and backbone networks with reasonable engineering efforts. Our implementation code is publicly available at https://anonymous.4open.science/r/INR-4BF7.", "url": "https://arxiv.org/abs/2306.16699"}, {"metadata": {"arXiv": "2306.16713", "Date": "Thu, 29 Jun 2023 06:22:43 ", "Title": "Answer Mining from a Pool of Images: Towards Retrieval-Based Visual Question Answering", "Authors": ["Abhirama Subramanyam Penamakuri", "Manish Gupta", "Mithun Das Gupta", "Anand Mishra"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted to IJCAI 2023"]}, "abstract": "We study visual question answering in a setting where the answer has to be mined from a pool of relevant and irrelevant images given as a context. For such a setting, a model must first retrieve relevant images from the pool and answer the question from these retrieved images. We refer to this problem as retrieval-based visual question answering (or RETVQA in short). The RETVQA is distinctively different and more challenging than the traditionally-studied Visual Question Answering (VQA), where a given question has to be answered with a single relevant image in context. Towards solving the RETVQA task, we propose a unified Multi Image BART (MI-BART) that takes a question and retrieved images using our relevance encoder for free-form fluent answer generation. Further, we introduce the largest dataset in this space, namely RETVQA, which has the following salient features: multi-image and retrieval requirement for VQA, metadata-independent questions over a pool of heterogeneous images, expecting a mix of classification-oriented and open-ended generative answers. Our proposed framework achieves an accuracy of 76.5% and a fluency of 79.3% on the proposed dataset, namely RETVQA and also outperforms state-of-the-art methods by 4.9% and 11.8% on the image segment of the publicly available WebQA dataset on the accuracy and fluency metrics, respectively.", "url": "https://arxiv.org/abs/2306.16713"}, {"metadata": {"arXiv": "2306.16772", "Date": "Thu, 29 Jun 2023 08:13:57 ", "Title": "Learning from Synthetic Human Group Activities", "Authors": ["Che-Jui Chang", "Honglu Zhou", "Parth Goel", "Aditya Bhat", "Seonghyeon Moon", "Samuel S. Sohn", "Sejong Yoon", "Vladimir Pavlovic", "Mubbasir Kapadia"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision. However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets. To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator. Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process. Our data generator is capable of generating large-scale datasets of human activities with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories). Using M3Act, we perform synthetic data pre-training for 2D skeleton-based group activity recognition and RGB-based multi-person pose tracking. The results indicate that learning from our synthetic datasets largely improves the model performances on real-world datasets, with the highest gain of 5.59% and 7.32% respectively in group and person recognition accuracy on CAD2, as well as an improvement of 6.63 in MOTP on HiEve. Pre-training with our synthetic data also leads to faster model convergence on downstream tasks (up to 6.8% faster). Moreover, M3Act opens new research problems for 3D group activity generation. We release M3Act3D, an 87.6-hour 3D motion dataset of human activities with larger group sizes and higher complexity of inter-person interactions than previous multi-person datasets. We define multiple metrics and propose a competitive baseline for the novel task.", "url": "https://arxiv.org/abs/2306.16772"}, {"metadata": {"arXiv": "2306.17010", "Date": "Thu, 29 Jun 2023 15:06:21 ", "Title": "milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing", "Authors": ["Fangqiang Ding", "Zhen Luo", "Peijun Zhao", "Chris Xiaoxuan Lu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["15 pages", "8 figures"]}, "abstract": "Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \\textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporating scene flow information, we achieve remarkable improvements in human activity recognition, human parsing, and human body part tracking. To foster further research in this area, we provide our codebase and dataset for open access.", "url": "https://arxiv.org/abs/2306.17010"}, {"metadata": {"arXiv": "2306.17165", "Date": "Thu, 29 Jun 2023 17:59:57 ", "Title": "An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training", "Authors": ["Zitian Chen", "Mingyu Ding", "Yikang Shen", "Wei Zhan", "Masayoshi Tomizuka", "Erik Learned-Miller", "Chuang Gan"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and ADE20K. Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks. Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks. We can fine-tune it with fewer training parameters, fewer model parameters, and less computation. Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios. Finally, these functions can be controlled and combined to meet various demands of downstream tasks.", "url": "https://arxiv.org/abs/2306.17165"}, {"metadata": {"arXiv": "2306.16431", "Date": "Wed, 28 Jun 2023 15:23:28 ", "Title": "Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions", "Authors": ["Joran Michiels", "Maarten De Vos", "Johan Suykens"], "Categories": "cs.LG cs.AI"}, "abstract": "Model-agnostic feature attributions can provide local insights in complex ML models. If the explanation is correct, a domain expert can validate and trust the model's decision. However, if it contradicts the expert's knowledge, related work only corrects irrelevant features to improve the model. To allow for unlimited interaction, in this paper we provide model-agnostic implementations for two popular explanation methods (Occlusion and Shapley values) to enforce entirely different attributions in the complex model. For a particular set of samples, we use the corrected feature attributions to generate extra local data, which is used to retrain the model to have the right explanation for the samples. Through simulated and real data experiments on a variety of models we show how our proposed approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to active learning settings increases the sample efficiency significantly and outperforms existing explanatory interactive strategies. Additionally we explore how a domain expert can provide feature attributions which are sufficiently correct to improve the model.", "url": "https://arxiv.org/abs/2306.16431"}, {"metadata": {"arXiv": "2306.16503", "Date": "Wed, 28 Jun 2023 18:50:18 ", "Title": "SARC: Soft Actor Retrospective Critic", "Authors": ["Sukriti Verma", "Ayush Chopra", "Jayakumar Subramanian", "Mausoom Sarkar", "Nikaash Puri", "Piyush Gupta", "Balaji Krishnamurthy"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at RLDM 2022"]}, "abstract": "The two-time scale nature of SAC, which is an actor-critic algorithm, is characterised by the fact that the critic estimate has not converged for the actor at any given time, but since the critic learns faster than the actor, it ensures eventual consistency between the two. Various strategies have been introduced in literature to learn better gradient estimates to help achieve better convergence. Since gradient estimates depend upon the critic, we posit that improving the critic can provide a better gradient estimate for the actor at each time. Utilizing this, we propose Soft Actor Retrospective Critic (SARC), where we augment the SAC critic loss with another loss term - retrospective loss - leading to faster critic convergence and consequently, better policy gradient estimates for the actor. An existing implementation of SAC can be easily adapted to SARC with minimal modifications. Through extensive experimentation and analysis, we show that SARC provides consistent improvement over SAC on benchmark environments. We plan to open-source the code and all experiment data at: https://github.com/sukritiverma1996/SARC.", "url": "https://arxiv.org/abs/2306.16503"}, {"metadata": {"arXiv": "2306.16524", "Date": "Wed, 28 Jun 2023 19:45:45 ", "Title": "HNO: Hyena Neural Operator for solving PDEs", "Authors": ["Saurabh Patil", "Zijie Li", "Amir Barati Farimani"], "Categories": "cs.LG cs.AI cs.NA math.NA"}, "abstract": "Numerically solving partial differential equations (PDEs) typically requires fine discretization to resolve necessary spatiotemporal scales, which can be computationally expensive. Recent advances in deep learning have provided a new approach to solving PDEs that involves the use of neural operators. Neural operators are neural network architectures that learn mappings between function spaces and have the capability to solve partial differential equations based on data. This study utilizes a novel neural operator called Hyena, which employs a long convolutional filter that is parameterized by a multilayer perceptron. The Hyena operator is an operation that enjoys sub-quadratic complexity and state space model to parameterize long convolution that enjoys global receptive field. This mechanism enhances the model's comprehension of the input's context and enables data-dependent weight for different PDE instances. To measure how effective the layers are in solving PDEs, we conduct experiments on Burger's equation and Navier Stokes equation. Our findings indicate Hyena Neural operator can serve as an efficient and accurate model for learning PDEs' solution operator. The data and code used can be found at: https://github.com/Saupatil07/Hyena-Neural-Operator", "url": "https://arxiv.org/abs/2306.16524"}, {"metadata": {"arXiv": "2306.16552", "Date": "Wed, 28 Jun 2023 20:42:04 ", "Title": "Learning Fair Classifiers via Min-Max F-divergence Regularization", "Authors": ["Meiyu Zhong", "Ravi Tandon"], "Categories": "cs.LG cs.AI cs.CY cs.IT math.IT"}, "abstract": "As machine learning (ML) based systems are adopted in domains such as law enforcement, criminal justice, finance, hiring and admissions, ensuring the fairness of ML aided decision-making is becoming increasingly important. In this paper, we focus on the problem of fair classification, and introduce a novel min-max F-divergence regularization framework for learning fair classification models while preserving high accuracy. Our framework consists of two trainable networks, namely, a classifier network and a bias/fairness estimator network, where the fairness is measured using the statistical notion of F-divergence. We show that F-divergence measures possess convexity and differentiability properties, and their variational representation make them widely applicable in practical gradient based training methods. The proposed framework can be readily adapted to multiple sensitive attributes and for high dimensional datasets. We study the F-divergence based training paradigm for two types of group fairness constraints, namely, demographic parity and equalized odds. We present a comprehensive set of experiments for several real-world data sets arising in multiple domains (including COMPAS, Law Admissions, Adult Income, and CelebA datasets). To quantify the fairness-accuracy tradeoff, we introduce the notion of fairness-accuracy receiver operating characteristic (FA-ROC) and a corresponding \\textit{low-bias} FA-ROC, which we argue is an appropriate measure to evaluate different classifiers. In comparison to several existing approaches for learning fair classifiers (including pre-processing, post-processing and other regularization methods), we show that the proposed F-divergence based framework achieves state-of-the-art performance with respect to the trade-off between accuracy and fairness.", "url": "https://arxiv.org/abs/2306.16552"}, {"metadata": {"arXiv": "2306.16559", "Date": "Wed, 28 Jun 2023 21:00:52 ", "Title": "Feature Selection: A perspective on inter-attribute cooperation", "Authors": ["Gustavo Sosa-Cabrera", "Santiago G\\'omez-Guerrero", "Miguel Garc\\'ia-Torres", "Christian E. Schaerer"], "Categories": "cs.LG cs.AI cs.IT math.IT", "Comments": ["17 pages", "2 figures"]}, "abstract": "High-dimensional datasets depict a challenge for learning tasks in data mining and machine learning. Feature selection is an effective technique in dealing with dimensionality reduction. It is often an essential data processing step prior to applying a learning algorithm. Over the decades, filter feature selection methods have evolved from simple univariate relevance ranking algorithms to more sophisticated relevance-redundancy trade-offs and to multivariate dependencies-based approaches in recent years. This tendency to capture multivariate dependence aims at obtaining unique information about the class from the intercooperation among features. This paper presents a comprehensive survey of the state-of-the-art work on filter feature selection methods assisted by feature intercooperation, and summarizes the contributions of different approaches found in the literature. Furthermore, current issues and challenges are introduced to identify promising future research and development.", "url": "https://arxiv.org/abs/2306.16559"}, {"metadata": {"arXiv": "2306.16601", "Date": "Wed, 28 Jun 2023 23:55:51 ", "Title": "An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs", "Authors": ["Haihao Shen", "Hengyu Meng", "Bo Dong", "Zhe Wang", "Ofir Zafrir", "Yi Ding", "Yu Luo", "Hanwen Chang", "Qun Gao", "Ziheng Wang", "Guy Boudoukh", "and Moshe Wasserblat"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "In recent years, Transformer-based language models have become the standard approach for natural language processing tasks. However, stringent throughput and latency requirements in industrial applications are limiting their adoption. To mitigate the gap, model compression techniques such as structured pruning are being used to improve inference efficiency. However, most existing neural network inference runtimes lack adequate support for structured sparsity. In this paper, we propose an efficient sparse deep learning inference software stack for Transformer-based language models where the weights are pruned with constant block size. Our sparse software accelerator leverages Intel Deep Learning Boost to maximize the performance of sparse matrix - dense matrix multiplication (commonly abbreviated as SpMM) on CPUs. Our SpMM kernel outperforms the existing sparse libraries (oneMKL, TVM, and LIBXSMM) by an order of magnitude on a wide range of GEMM shapes under 5 representative sparsity ratios (70%, 75%, 80%, 85%, 90%). Moreover, our SpMM kernel shows up to 5x speedup over dense GEMM kernel of oneDNN, a well-optimized dense library widely used in industry. We apply our sparse accelerator on widely-used Transformer-based language models including Bert-Mini, DistilBERT, Bert-Base, and BERT-Large. Our sparse inference software shows up to 1.5x speedup over Neural Magic's Deepsparse under same configurations on Xeon on Amazon Web Services under proxy production latency constraints. We also compare our solution with two framework-based inference solutions, ONNX Runtime and PyTorch, and demonstrate up to 37x speedup over ONNX Runtime and 345x over PyTorch on Xeon under the latency constraints. All the source code is publicly available on Github: https://github.com/intel/intel-extension-for-transformers.", "url": "https://arxiv.org/abs/2306.16601"}, {"metadata": {"arXiv": "2306.16614", "Date": "Thu, 29 Jun 2023 01:07:12 ", "Title": "Group-based Robustness: A General Framework for Customized Robustness in the Real World", "Authors": ["Weiran Lin and Keane Lucas and Neo Eyal and Lujo Bauer and Michael K. Reiter and Mahmood Sharif"], "Categories": "cs.LG cs.AI cs.CR cs.CV"}, "abstract": "Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss functions and 2) identify three new attack strategies. We show empirically that with comparable success rates, finding evasive samples using our new loss functions saves computation by a factor as large as the number of targeted classes, and finding evasive samples using our new attack strategies saves time by up to 99\\% compared to brute-force search methods. Finally, we propose a defense method that increases group-based robustness by up to 3.52$\\times$.", "url": "https://arxiv.org/abs/2306.16614"}, {"metadata": {"arXiv": "2306.16666", "Date": "Thu, 29 Jun 2023 03:55:09 ", "Title": "Game Level Blending using a Learned Level Representation", "Authors": ["Venkata Sai Revanth Atmakuri", "Seth Cooper and Matthew Guzdial"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages", "3 figures"], "Journal-ref": "IEEE Conference on Games 2023"}, "abstract": "Game level blending via machine learning, the process of combining features of game levels to create unique and novel game levels using Procedural Content Generation via Machine Learning (PCGML) techniques, has gained increasing popularity in recent years. However, many existing techniques rely on human-annotated level representations, which limits game level blending to a limited number of annotated games. Even with annotated games, researchers often need to author an additional shared representation to make blending possible. In this paper, we present a novel approach to game level blending that employs Clustering-based Tile Embeddings (CTE), a learned level representation technique that can serve as a level representation for unannotated games and a unified level representation across games without the need for human annotation. CTE represents game level tiles as a continuous vector representation, unifying their visual, contextual, and behavioral information. We apply this approach to two classic Nintendo games, Lode Runner and The Legend of Zelda. We run an evaluation comparing the CTE representation to a common, human-annotated representation in the blending task and find that CTE has comparable or better performance without the need for human annotation.", "url": "https://arxiv.org/abs/2306.16666"}, {"metadata": {"arXiv": "2306.16703", "Date": "Thu, 29 Jun 2023 05:58:47 ", "Title": "Elastically-Constrained Meta-Learner for Federated Learning", "Authors": ["Peng Lan", "Donglai Chen", "Xie Chong", "Keshu Chen", "Jinyuan He", "Juntao Zhang", "Yonghong Chen and Yan Xu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["FL-IJCAI'23"]}, "abstract": "Federated learning is an approach to collaboratively training machine learning models for multiple parties that prohibit data sharing. One of the challenges in federated learning is non-IID data between clients, as a single model can not fit the data distribution for all clients. Meta-learning, such as Per-FedAvg, is introduced to cope with the challenge. Meta-learning learns shared initial parameters for all clients. Each client employs gradient descent to adapt the initialization to local data distributions quickly to realize model personalization. However, due to non-convex loss function and randomness of sampling update, meta-learning approaches have unstable goals in local adaptation for the same client. This fluctuation in different adaptation directions hinders the convergence in meta-learning. To overcome this challenge, we use the historical local adapted model to restrict the direction of the inner loop and propose an elastic-constrained method. As a result, the current round inner loop keeps historical goals and adapts to better solutions. Experiments show our method boosts meta-learning convergence and improves personalization without additional calculation and communication. Our method achieved SOTA on all metrics in three public datasets.", "url": "https://arxiv.org/abs/2306.16703"}, {"metadata": {"arXiv": "2306.16750", "Date": "Thu, 29 Jun 2023 07:47:32 ", "Title": "Eigensubspace of Temporal-Difference Dynamics and How It Improves Value Approximation in Reinforcement Learning", "Authors": ["Qiang He and Tianyi Zhou and Meng Fang and Setareh Maghsudi"], "Categories": "cs.LG cs.AI cs.SY eess.SY", "Comments": ["Accepted to ECML23. Website: https://sites.google.com/view/erc-ecml23/"]}, "abstract": "We propose a novel value approximation method, namely Eigensubspace Regularized Critic (ERC) for deep reinforcement learning (RL). ERC is motivated by an analysis of the dynamics of Q-value approximation error in the Temporal-Difference (TD) method, which follows a path defined by the 1-eigensubspace of the transition kernel associated with the Markov Decision Process (MDP). It reveals a fundamental property of TD learning that has remained unused in previous deep RL approaches. In ERC, we propose a regularizer that guides the approximation error tending towards the 1-eigensubspace, resulting in a more efficient and stable path of value approximation. Moreover, we theoretically prove the convergence of the ERC method. Besides, theoretical analysis and experiments demonstrate that ERC effectively reduces the variance of value functions. Among 26 tasks in the DMControl benchmark, ERC outperforms state-of-the-art methods for 20. Besides, it shows significant advantages in Q-value approximation and variance reduction. Our code is available at https://sites.google.com/view/erc-ecml23/.", "url": "https://arxiv.org/abs/2306.16750"}, {"metadata": {"arXiv": "2306.16788", "Date": "Thu, 29 Jun 2023 08:49:41 ", "Title": "Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging", "Authors": ["Max Zimmer", "Christoph Spiegel", "Sebastian Pokutta"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "5 pages references", "7 pages appendix"]}, "abstract": "Neural networks can be significantly compressed by pruning, leading to sparse models requiring considerably less storage and floating-point operations while maintaining predictive performance. Model soups (Wortsman et al., 2022) improve generalization and out-of-distribution performance by averaging the parameters of multiple models into a single one without increased inference time. However, identifying models in the same loss basin to leverage both sparsity and parameter averaging is challenging, as averaging arbitrary sparse models reduces the overall sparsity due to differing sparse connectivities. In this work, we address these challenges by demonstrating that exploring a single retraining phase of Iterative Magnitude Pruning (IMP) with varying hyperparameter configurations, such as batch ordering or weight decay, produces models that are suitable for averaging and share the same sparse connectivity by design. Averaging these models significantly enhances generalization performance compared to their individual components. Building on this idea, we introduce Sparse Model Soups (SMS), a novel method for merging sparse models by initiating each prune-retrain cycle with the averaged model of the previous phase. SMS maintains sparsity, exploits sparse network benefits being modular and fully parallelizable, and substantially improves IMP's performance. Additionally, we demonstrate that SMS can be adapted to enhance the performance of state-of-the-art pruning during training approaches.", "url": "https://arxiv.org/abs/2306.16788"}, {"metadata": {"arXiv": "2306.16817", "Date": "Thu, 29 Jun 2023 09:53:24 ", "Title": "Improving Online Continual Learning Performance and Stability with Temporal Ensembles", "Authors": ["Albin Soutif--Cormerais", "Antonio Carta", "Joost Van de Weijer"], "Categories": "cs.LG cs.AI", "Comments": ["CoLLAs 2023 accepted paper"]}, "abstract": "Neural networks are very effective when trained on large datasets for a large number of iterations. However, when they are trained on non-stationary streams of data and in an online fashion, their performance is reduced (1) by the online setup, which limits the availability of data, (2) due to catastrophic forgetting because of the non-stationary nature of the data. Furthermore, several recent works (Caccia et al., 2022; Lange et al., 2023) arXiv:2205.1345(2) showed that replay methods used in continual learning suffer from the stability gap, encountered when evaluating the model continually (rather than only on task boundaries). In this article, we study the effect of model ensembling as a way to improve performance and stability in online continual learning. We notice that naively ensembling models coming from a variety of training tasks increases the performance in online continual learning considerably. Starting from this observation, and drawing inspirations from semi-supervised learning ensembling methods, we use a lightweight temporal ensemble that computes the exponential moving average of the weights (EMA) at test time, and show that it can drastically increase the performance and stability when used in combination with several methods from the literature.", "url": "https://arxiv.org/abs/2306.16817"}, {"metadata": {"arXiv": "2306.16913", "Date": "Thu, 29 Jun 2023 13:05:12 ", "Title": "AutoML in Heavily Constrained Applications", "Authors": ["Felix Neutatz and Marius Lindauer and Ziawasch Abedjan"], "Categories": "cs.LG cs.AI cs.DB"}, "abstract": "Optimizing a machine learning pipeline for a task at hand requires careful configuration of various hyperparameters, typically supported by an AutoML system that optimizes the hyperparameters for the given training dataset. Yet, depending on the AutoML system's own second-order meta-configuration, the performance of the AutoML process can vary significantly. Current AutoML systems cannot automatically adapt their own configuration to a specific use case. Further, they cannot compile user-defined application constraints on the effectiveness and efficiency of the pipeline and its generation. In this paper, we propose Caml, which uses meta-learning to automatically adapt its own AutoML parameters, such as the search strategy, the validation strategy, and the search space, for a task at hand. The dynamic AutoML strategy of Caml takes user-defined constraints into account and obtains constraint-satisfying pipelines with high predictive performance.", "url": "https://arxiv.org/abs/2306.16913"}, {"metadata": {"arXiv": "2306.16976", "Date": "Thu, 29 Jun 2023 14:31:07 ", "Title": "Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters", "Authors": ["Ahmed Begga", "Francisco Escolano", "Miguel Angel Lozano", "Edwin R. Hancock"], "Categories": "cs.LG cs.AI"}, "abstract": "High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scattered nodes with the same label. Actually, the full process is controlled by the classification loss. Both the jumps and the diffusion distances react to classification errors (i.e. they are learnable). Homophiliation, i.e., the process of learning piecewise smooth latent spaces in the heterophilic regime, is formulated as a Dirichlet problem: the known labels determine the border nodes and the diffusion-pump ensures a minimal deviation of the semi-supervised grouping from a canonical unsupervised grouping. This triggers the update of both the diffusion distances and, consequently, the jumps in order to minimize the classification error. The Dirichlet formulation has several advantages. It leads to the definition of structural heterophily, a novel measure beyond edge heterophily. It also allows us to investigate links with (learnable) diffusion distances, absorbing random walks and stochastic diffusion.", "url": "https://arxiv.org/abs/2306.16976"}, {"metadata": {"arXiv": "2306.17033", "Date": "Thu, 29 Jun 2023 15:34:26 ", "Title": "Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning", "Authors": ["Kevin Leahy and Makai Mann and Zachary Serlin"], "Categories": "cs.LG cs.AI"}, "abstract": "Compositionality is a critical aspect of scalable system design. Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition. In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition. Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints. We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces. We demonstrate these techniques using modified versions of value iteration in a grid world, Deep Q-Network (DQN) in a grid world with image observations, and Twin Delayed DDPG (TD3) in a continuous-observation and continuous-action Bullet physics environment. We believe that these contributions advance the theory of safe reinforcement learning by allowing zero-shot composition of policies satisfying safety properties.", "url": "https://arxiv.org/abs/2306.17033"}, {"metadata": {"arXiv": "2306.17052", "Date": "Thu, 29 Jun 2023 15:57:07 ", "Title": "Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning", "Authors": ["Matej Jusup", "Barna P\\'asztor", "Tadeusz Janik", "Kenan Zhang", "Francesco Corman", "Andreas Krause and Ilija Bogunovic"], "Categories": "cs.LG cs.AI cs.MA stat.ML", "Comments": ["25 pages", "14 figures", "3 tables"]}, "abstract": "Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critical areas while ensuring service accessibility in regions with low demand.", "url": "https://arxiv.org/abs/2306.17052"}, {"metadata": {"arXiv": "2306.17100", "Date": "Thu, 29 Jun 2023 16:57:22 ", "Title": "RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark", "Authors": ["Federico Berto", "Chuanbo Hua", "Junyoung Park", "Minsu Kim", "Hyeonah Kim", "Jiwoo Son", "Haeyeon Kim", "Joungho Kim", "Jinkyoo Park"], "Categories": "cs.LG cs.AI"}, "abstract": "We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will encourage the exploration of novel solutions to complex real-world tasks, allowing to compare with existing methods through a standardized interface that decouples the science from the software engineering. We make our library publicly available at https://github.com/kaist-silab/rl4co.", "url": "https://arxiv.org/abs/2306.17100"}, {"metadata": {"arXiv": "2306.17109", "Date": "Thu, 29 Jun 2023 17:08:57 ", "Title": "Synthetic Demographic Data Generation for Card Fraud Detection Using GANs", "Authors": ["Shuo Wang", "Terrence Tricco", "Xianta Jiang", "Charles Robertson", "John Hawkin"], "Categories": "cs.LG cs.AI"}, "abstract": "Using machine learning models to generate synthetic data has become common in many fields. Technology to generate synthetic transactions that can be used to detect fraud is also growing fast. Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money. It does not usually contain the individual user's characteristics (age and gender are occasionally included). Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance. Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation. In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation. Our model generates samples during model training, which we found important to overcame class imbalance issues. This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection.", "url": "https://arxiv.org/abs/2306.17109"}, {"metadata": {"arXiv": "2306.16740", "Date": "Thu, 29 Jun 2023 07:31:43 ", "Title": "Principles and Guidelines for Evaluating Social Robot Navigation Algorithms", "Authors": ["Anthony Francis (1)", "Claudia Perez-D'Arpino (2)", "Chengshu Li (3)", "Fei Xia (4)", "Alexandre Alahi (5)", "Rachid Alami (15)", "Aniket Bera (6)", "Abhijat Biswas (7)", "Joydeep Biswas (8)", "Rohan Chandra (8)", "Hao-Tien Lewis Chiang (4)", "Michael Everett (10)", "Sehoon Ha (11)", "Justin Hart (8)", "Jonathan P. How (9)", "Haresh Karnan (8)", "Tsang-Wei Edward Lee (4)", "Luis J. Manso (12)", "Reuth Mirksy (13)", "Soeren Pirk (14)", "Phani Teja Singamaneni (15)", "Peter Stone (8,16)", "Ada V. Taylor (7)", "Peter Trautman (17)", "Nathan Tsoi (18)", "Marynel Vazquez (18)", "Xuesu Xiao (19)", "Peng Xu (4)", "Naoki Yokoyama (11)", "Alexander Toshev (20)", "Roberto Martin-Martin (8) ((1) Logical Robotics", "(2) NVIDIA", "(3) Stanford", "(4) Google", "(5) EPFL", "(6) Purdue", "(7) CMU", "(8) UT Austin", "(9) MIT", "(10) Northeastern", "(11) Georgia Tech", "(12) Aston", "(13) Bar Ilan", "(14) Adobe", "(15) LAAS-CNRS", "Universite de Toulouse", "(16) Sony AI", "(17) Honda", "(18) Yale", "(19) GMU", "(20) Apple)"], "Categories": "cs.RO cs.AI cs.HC cs.LG", "Comments": ["43 pages", "11 figures", "6 tables"], "ACM-class": "I.2.9"}, "abstract": "A major challenge to deploying robots widely is navigation in human-populated environments, commonly referred to as social robot navigation. While the field of social navigation has advanced tremendously in recent years, the fair evaluation of algorithms that tackle social navigation remains hard because it involves not just robotic agents moving in static environments but also dynamic human agents and their perceptions of the appropriateness of robot behavior. In contrast, clear, repeatable, and accessible benchmarks have accelerated progress in fields like computer vision, natural language processing and traditional robot navigation by enabling researchers to fairly compare algorithms, revealing limitations of existing solutions and illuminating promising new directions. We believe the same approach can benefit social navigation. In this paper, we pave the road towards common, widely accessible, and repeatable benchmarking criteria to evaluate social robot navigation. Our contributions include (a) a definition of a socially navigating robot as one that respects the principles of safety, comfort, legibility, politeness, social competency, agent understanding, proactivity, and responsiveness to context, (b) guidelines for the use of metrics, development of scenarios, benchmarks, datasets, and simulators to evaluate social navigation, and (c) a design of a social navigation metrics framework to make it easier to compare results from different simulators, robots and datasets.", "url": "https://arxiv.org/abs/2306.16740"}, {"metadata": {"arXiv": "2306.16927", "Date": "Thu, 29 Jun 2023 14:17:24 ", "Title": "End-to-end Autonomous Driving: Challenges and Frontiers", "Authors": ["Li Chen", "Penghao Wu", "Kashyap Chitta", "Bernhard Jaeger", "Andreas Geiger", "Hongyang Li"], "Categories": "cs.RO cs.AI cs.CV cs.LG"}, "abstract": "The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 250 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework. To facilitate future research, we maintain an active repository that contains up-to-date links to relevant literature and open-source projects at https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving.", "url": "https://arxiv.org/abs/2306.16927"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

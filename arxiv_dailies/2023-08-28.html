<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.13168", "Date": "Fri, 25 Aug 2023 04:14:02 ", "Title": "IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization", "Authors": ["Zekun Li", "Lei Qi", "Yinghuan Shi", "Yang Gao"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by ICCV 2023", "selected for an Oral presentation"]}, "abstract": "Semi-supervised learning (SSL) aims to leverage massive unlabeled data when labels are expensive to obtain. Unfortunately, in many real-world applications, the collected unlabeled data will inevitably contain unseen-class outliers not belonging to any of the labeled classes. To deal with the challenging open-set SSL task, the mainstream methods tend to first detect outliers and then filter them out. However, we observe a surprising fact that such approach could result in more severe performance degradation when labels are extremely scarce, as the unreliable outlier detector may wrongly exclude a considerable portion of valuable inliers. To tackle with this issue, we introduce a novel open-set SSL framework, IOMatch, which can jointly utilize inliers and outliers, even when it is difficult to distinguish exactly between them. Specifically, we propose to employ a multi-binary classifier in combination with the standard closed-set classifier for producing unified open-set classification targets, which regard all outliers as a single new class. By adopting these targets as open-set pseudo-labels, we optimize an open-set classifier with all unlabeled samples including both inliers and outliers. Extensive experiments have shown that IOMatch significantly outperforms the baseline methods across different benchmark datasets and different settings despite its remarkable simplicity. Our code and models are available at https://github.com/nukezil/IOMatch.", "url": "https://arxiv.org/abs/2308.13168"}, {"metadata": {"arXiv": "2308.13217", "Date": "Fri, 25 Aug 2023 07:30:18 ", "Title": "GEMTrans: A General, Echocardiography-based, Multi-Level Transformer Framework for Cardiovascular Diagnosis", "Authors": ["Masoud Mokhtari", "Neda Ahmadi", "Teresa S. M. Tsang", "Purang Abolmaesumi", "Renjie Liao"], "Categories": "cs.CV cs.LG", "Comments": ["To be published in MLMI 2023"]}, "abstract": "Echocardiography (echo) is an ultrasound imaging modality that is widely used for various cardiovascular diagnosis tasks. Due to inter-observer variability in echo-based diagnosis, which arises from the variability in echo image acquisition and the interpretation of echo images based on clinical experience, vision-based machine learning (ML) methods have gained popularity to act as secondary layers of verification. For such safety-critical applications, it is essential for any proposed ML method to present a level of explainability along with good accuracy. In addition, such methods must be able to process several echo videos obtained from various heart views and the interactions among them to properly produce predictions for a variety of cardiovascular measurements or interpretation tasks. Prior work lacks explainability or is limited in scope by focusing on a single cardiovascular task. To remedy this, we propose a General, Echo-based, Multi-Level Transformer (GEMTrans) framework that provides explainability, while simultaneously enabling multi-video training where the inter-play among echo image patches in the same frame, all frames in the same video, and inter-video relationships are captured based on a downstream task. We show the flexibility of our framework by considering two critical tasks including ejection fraction (EF) and aortic stenosis (AS) severity detection. Our model achieves mean absolute errors of 4.15 and 4.84 for single and dual-video EF estimation and an accuracy of 96.5 % for AS detection, while providing informative task-specific attention maps and prototypical explainability.", "url": "https://arxiv.org/abs/2308.13217"}, {"metadata": {"arXiv": "2308.13011", "Date": "Thu, 24 Aug 2023 18:23:59 ", "Title": "Extreme Risk Mitigation in Reinforcement Learning using Extreme Value Theory", "Authors": ["Karthik Somayaji NS", "Yu Wang", "Malachi Schram", "Jan Drgona", "Mahantesh Halappanavar", "Frank Liu", "Peng Li"], "Categories": "cs.LG"}, "abstract": "Risk-sensitive reinforcement learning (RL) has garnered significant attention in recent years due to the growing interest in deploying RL agents in real-world scenarios. A critical aspect of risk awareness involves modeling highly rare risk events (rewards) that could potentially lead to catastrophic outcomes. These infrequent occurrences present a formidable challenge for data-driven methods aiming to capture such risky events accurately. While risk-aware RL techniques do exist, their level of risk aversion heavily relies on the precision of the state-action value function estimation when modeling these rare occurrences. Our work proposes to enhance the resilience of RL agents when faced with very rare and risky events by focusing on refining the predictions of the extreme values predicted by the state-action value function distribution. To achieve this, we formulate the extreme values of the state-action value function distribution as parameterized distributions, drawing inspiration from the principles of extreme value theory (EVT). This approach effectively addresses the issue of infrequent occurrence by leveraging EVT-based parameterization. Importantly, we theoretically demonstrate the advantages of employing these parameterized distributions in contrast to other risk-averse algorithms. Our evaluations show that the proposed method outperforms other risk averse RL algorithms on a diverse range of benchmark tasks, each encompassing distinct risk scenarios.", "url": "https://arxiv.org/abs/2308.13011"}, {"metadata": {"arXiv": "2308.13049", "Date": "Thu, 24 Aug 2023 19:35:58 ", "Title": "Bayesian Exploration Networks", "Authors": ["Mattie Fellows", "Brandon Kaplowitz", "Christian Schroeder de Witt and Shimon Whiteson"], "Categories": "cs.LG"}, "abstract": "Bayesian reinforcement learning (RL) offers a principled and elegant approach for sequential decision making under uncertainty. Most notably, Bayesian agents do not face an exploration/exploitation dilemma, a major pathology of frequentist methods. A key challenge for Bayesian RL is the computational complexity of learning Bayes-optimal policies, which is only tractable in toy domains. In this paper we propose a novel model-free approach to address this challenge. Rather than modelling uncertainty in high-dimensional state transition distributions as model-based approaches do, we model uncertainty in a one-dimensional Bellman operator. Our theoretical analysis reveals that existing model-free approaches either do not propagate epistemic uncertainty through the MDP or optimise over a set of contextual policies instead of all history-conditioned policies. Both approximations yield policies that can be arbitrarily Bayes-suboptimal. To overcome these issues, we introduce the Bayesian exploration network (BEN) which uses normalising flows to model both the aleatoric uncertainty (via density estimation) and epistemic uncertainty (via variational inference) in the Bellman operator. In the limit of complete optimisation, BEN learns true Bayes-optimal policies, but like in variational expectation-maximisation, partial optimisation renders our approach tractable. Empirical results demonstrate that BEN can learn true Bayes-optimal policies in tasks where existing model-free approaches fail.", "url": "https://arxiv.org/abs/2308.13049"}, {"metadata": {"arXiv": "2308.13066", "Date": "Thu, 24 Aug 2023 20:22:22 ", "Title": "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE", "Authors": ["Chenghui Zhou", "Barnabas Poczos"], "Categories": "cs.LG q-bio.QM", "Comments": ["arXiv admin note: text overlap with arXiv:2212.02750"]}, "abstract": "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.", "url": "https://arxiv.org/abs/2308.13066"}, {"metadata": {"arXiv": "2308.13104", "Date": "Thu, 24 Aug 2023 22:36:22 ", "Title": "Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records", "Authors": ["Mohsen Nayebi Kerdabadi", "Arya Hadizadeh Moghaddam", "Bin Liu", "Mei Liu", "Zijun Yao"], "Categories": "cs.LG", "Comments": ["This paper has been accepted for publication at the CIKM 2023 conference"]}, "abstract": "Survival analysis plays a crucial role in many healthcare decisions, where the risk prediction for the events of interest can support an informative outlook for a patient's medical journey. Given the existence of data censoring, an effective way of survival analysis is to enforce the pairwise temporal concordance between censored and observed data, aiming to utilize the time interval before censoring as partially observed time-to-event labels for supervised learning. Although existing studies mostly employed ranking methods to pursue an ordering objective, contrastive methods which learn a discriminative embedding by having data contrast against each other, have not been explored thoroughly for survival analysis. Therefore, in this paper, we propose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv) analysis framework that utilizes survival durations from both censored and observed data to define temporal distinctiveness and construct negative sample pairs with adjustable hardness for contrastive learning. Specifically, we first use an ontological encoder and a sequential self-attention encoder to represent the longitudinal EHR data with rich contexts. Second, we design a temporal contrastive loss to capture varying survival durations in a supervised setting through a hardness-aware negative sampling mechanism. Last, we incorporate the contrastive task into the time-to-event predictive task with multiple loss components. We conduct extensive experiments using a large EHR dataset to forecast the risk of hospitalized patients who are in danger of developing acute kidney injury (AKI), a critical and urgent medical condition. The effectiveness and explainability of the proposed model are validated through comprehensive quantitative and qualitative studies.", "url": "https://arxiv.org/abs/2308.13104"}, {"metadata": {"arXiv": "2308.13111", "Date": "Thu, 24 Aug 2023 23:06:21 ", "Title": "Bayesian low-rank adaptation for large language models", "Authors": ["Adam X. Yang", "Maxime Robeyns", "Xi Wang", "Laurence Aitchison"], "Categories": "cs.LG"}, "abstract": "Parameter-efficient fine-tuning (PEFT) has emerged as a new paradigm for cost-efficient fine-tuning of large language models (LLMs), with low-rank adaptation (LoRA) being a widely adopted choice. However, fine-tuned LLMs often become overconfident especially on when fine-tuned on smaller datasets. Bayesian methods, with their inherent ability to estimate uncertainty, serve as potent tools to mitigate overconfidence and enhance calibration. In this work, we introduce Laplace-LoRA, a straightforward yet effective Bayesian method, which applies the Laplace approximation to the LoRA parameters and, considerably boosts the calibration of fine-tuned LLMs.", "url": "https://arxiv.org/abs/2308.13111"}, {"metadata": {"arXiv": "2308.13118", "Date": "Thu, 24 Aug 2023 23:49:27 ", "Title": "Business Metric-Aware Forecasting for Inventory Management", "Authors": ["Helen Zhou", "Sercan O. Arik", "Jingtao Wang"], "Categories": "cs.LG"}, "abstract": "Time-series forecasts play a critical role in business planning. However, forecasters typically optimize objectives that are agnostic to downstream business goals and thus can produce forecasts misaligned with business preferences. In this work, we demonstrate that optimization of conventional forecasting metrics can often lead to sub-optimal downstream business performance. Focusing on the inventory management setting, we derive an efficient procedure for computing and optimizing proxies of common downstream business metrics in an end-to-end differentiable manner. We explore a wide range of plausible cost trade-off scenarios, and empirically demonstrate that end-to-end optimization often outperforms optimization of standard business-agnostic forecasting metrics (by up to 45.7% for a simple scaling model, and up to 54.0% for an LSTM encoder-decoder model). Finally, we discuss how our findings could benefit other business contexts.", "url": "https://arxiv.org/abs/2308.13118"}, {"metadata": {"arXiv": "2308.13137", "Date": "Fri, 25 Aug 2023 02:28:35 ", "Title": "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", "Authors": ["Wenqi Shao", "Mengzhao Chen", "Zhaoyang Zhang", "Peng Xu", "Lirui Zhao", "Zhiqian Li", "Kaipeng Zhang", "Peng Gao", "Yu Qiao", "Ping Luo"], "Categories": "cs.LG cs.CL", "Comments": ["A differentiable quantization method for LLM"]}, "abstract": "Large language models (LLMs) have revolutionized natural language processing tasks. However, their practical deployment is hindered by their immense memory and computation requirements. Although recent post-training quantization (PTQ) methods are effective in reducing memory footprint and improving the computational efficiency of LLM, they hand-craft quantization parameters, which leads to low performance and fails to deal with extremely low-bit quantization. To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters. OmniQuant comprises two innovative components including Learnable Weight Clipping (LWC) and Learnable Equivalent Transformation (LET). LWC modulates the extreme values of weights by optimizing the clipping threshold. Meanwhile, LET tackles activation outliers by shifting the challenge of quantization from activations to weights through a learnable equivalent transformation. Operating within a differentiable framework using block-wise error minimization, OmniQuant can optimize the quantization process efficiently for both weight-only and weight-activation quantization. For instance, the LLaMA-2 model family with the size of 7-70B can be processed with OmniQuant on a single A100-40G GPU within 1-16 hours using 128 samples. Extensive experiments validate OmniQuant's superior performance across diverse quantization configurations such as W4A4, W6A6, W4A16, W3A16, and W2A16. Additionally, OmniQuant demonstrates effectiveness in instruction-tuned models and delivers notable improvements in inference speed and memory reduction on real devices. Codes and models are available at \\url{https://github.com/OpenGVLab/OmniQuant}.", "url": "https://arxiv.org/abs/2308.13137"}, {"metadata": {"arXiv": "2308.13157", "Date": "Fri, 25 Aug 2023 03:31:22 ", "Title": "Federated Learning in IoT: a Survey from a Resource-Constrained Perspective", "Authors": ["Ishmeet Kaur andAdwaita Janardhan Jadhav"], "Categories": "cs.LG", "Comments": ["Presented and accepted at The IEEE 2023 International Conference on Artificial Intelligence", "Robotics", "Signal and Image Processing (AIRoSIP)"]}, "abstract": "The IoT ecosystem is able to leverage vast amounts of data for intelligent decision-making. Federated Learning (FL), a decentralized machine learning technique, is widely used to collect and train machine learning models from a variety of distributed data sources. Both IoT and FL systems can be complementary and used together. However, the resource-constrained nature of IoT devices prevents the widescale deployment FL in the real world. This research paper presents a comprehensive survey of the challenges and solutions associated with implementing Federated Learning (FL) in resource-constrained Internet of Things (IoT) environments, viewed from 2 levels, client and server. We focus on solutions regarding limited client resources, presence of heterogeneous client data, server capacity, and high communication costs, and assess their effectiveness in various scenarios. Furthermore, we categorize the solutions based on the location of their application, i.e., the IoT client, and the FL server. In addition to a comprehensive review of existing research and potential future directions, this paper also presents new evaluation metrics that would allow researchers to evaluate their solutions on resource-constrained IoT devices.", "url": "https://arxiv.org/abs/2308.13157"}, {"metadata": {"arXiv": "2308.13242", "Date": "Fri, 25 Aug 2023 08:27:43 ", "Title": "Optimizing Group-Fair Plackett-Luce Ranking Models for Relevance and Ex-Post Fairness", "Authors": ["Sruthi Gorantla", "Eshaan Bhansali", "Amit Deshpande", "Anand Louis"], "Categories": "cs.LG cs.CY cs.IR", "Comments": ["20 pages"]}, "abstract": "In learning-to-rank (LTR), optimizing only the relevance (or the expected ranking utility) can cause representational harm to certain categories of items. Moreover, if there is implicit bias in the relevance scores, LTR models may fail to optimize for true relevance. Previous works have proposed efficient algorithms to train stochastic ranking models that achieve fairness of exposure to the groups ex-ante (or, in expectation), which may not guarantee representation fairness to the groups ex-post, that is, after realizing a ranking from the stochastic ranking model. Typically, ex-post fairness is achieved by post-processing, but previous work does not train stochastic ranking models that are aware of this post-processing. In this paper, we propose a novel objective that maximizes expected relevance only over those rankings that satisfy given representation constraints to ensure ex-post fairness. Building upon recent work on an efficient sampler for ex-post group-fair rankings, we propose a group-fair Plackett-Luce model and show that it can be efficiently optimized for our objective in the LTR framework. Experiments on three real-world datasets show that our group-fair algorithm guarantees fairness alongside usually having better relevance compared to the LTR baselines. In addition, our algorithm also achieves better relevance than post-processing baselines, which also ensures ex-post fairness. Further, when implicit bias is injected into the training data, our algorithm typically outperforms existing LTR baselines in relevance.", "url": "https://arxiv.org/abs/2308.13242"}, {"metadata": {"arXiv": "2308.13246", "Date": "Fri, 25 Aug 2023 08:42:45 ", "Title": "Model-free Reinforcement Learning with Stochastic Reward Stabilization for Recommender Systems", "Authors": ["Tianchi Cai", "Shenliao Bao", "Jiyan Jiang", "Shiji Zhou", "Wenpeng Zhang", "Lihong Gu", "Jinjie Gu", "Guannan Zhang"], "Categories": "cs.LG", "Comments": ["SIGIR '23"], "DOI": "10.1145/3539618.3592022"}, "abstract": "Model-free RL-based recommender systems have recently received increasing research attention due to their capability to handle partial feedback and long-term rewards. However, most existing research has ignored a critical feature in recommender systems: one user's feedback on the same item at different times is random. The stochastic rewards property essentially differs from that in classic RL scenarios with deterministic rewards, which makes RL-based recommender systems much more challenging. In this paper, we first demonstrate in a simulator environment where using direct stochastic feedback results in a significant drop in performance. Then to handle the stochastic feedback more efficiently, we design two stochastic reward stabilization frameworks that replace the direct stochastic feedback with that learned by a supervised model. Both frameworks are model-agnostic, i.e., they can effectively utilize various supervised models. We demonstrate the superiority of the proposed frameworks over different RL-based recommendation baselines with extensive experiments on a recommendation simulator as well as an industrial-level recommender system.", "url": "https://arxiv.org/abs/2308.13246"}, {"metadata": {"arXiv": "2308.13252", "Date": "Fri, 25 Aug 2023 08:59:03 ", "Title": "Kissing to Find a Match: Efficient Low-Rank Permutation Representation", "Authors": ["Hannah Dr\\\"oge", "Zorah L\\\"ahner", "Yuval Bahat", "Onofre Martorell", "Felix Heide", "Michael M\\\"oller"], "Categories": "cs.LG cs.CV", "Comments": ["13 pages", "6 figures"]}, "abstract": "Permutation matrices play a key role in matching and assignment problems across the fields, especially in computer vision and robotics. However, memory for explicitly representing permutation matrices grows quadratically with the size of the problem, prohibiting large problem instances. In this work, we propose to tackle the curse of dimensionality of large permutation matrices by approximating them using low-rank matrix factorization, followed by a nonlinearity. To this end, we rely on the Kissing number theory to infer the minimal rank required for representing a permutation matrix of a given size, which is significantly smaller than the problem size. This leads to a drastic reduction in computation and memory costs, e.g., up to $3$ orders of magnitude less memory for a problem of size $n=20000$, represented using $8.4\\times10^5$ elements in two small matrices instead of using a single huge matrix with $4\\times 10^8$ elements. The proposed representation allows for accurate representations of large permutation matrices, which in turn enables handling large problems that would have been infeasible otherwise. We demonstrate the applicability and merits of the proposed approach through a series of experiments on a range of problems that involve predicting permutation matrices, from linear and quadratic assignment to shape matching problems.", "url": "https://arxiv.org/abs/2308.13252"}, {"metadata": {"arXiv": "2308.13265", "Date": "Fri, 25 Aug 2023 09:37:02 ", "Title": "Heterogeneous Federated Learning via Personalized Generative Networks", "Authors": ["Zahra Taghiyarrenani", "Abdallah Abdallah", "Slawomir Nowaczyk", "Sepideh Pashami"], "Categories": "cs.LG"}, "abstract": "Federated Learning (FL) allows several clients to construct a common global machine-learning model without having to share their data. FL, however, faces the challenge of statistical heterogeneity between the client's data, which degrades performance and slows down the convergence toward the global model. In this paper, we provide theoretical proof that minimizing heterogeneity between clients facilitates the convergence of a global model for every single client. This becomes particularly important under empirical concept shifts among clients, rather than merely considering imbalanced classes, which have been studied until now. Therefore, we propose a method for knowledge transfer between clients where the server trains client-specific generators. Each generator generates samples for the corresponding client to remove the conflict with other clients' models. Experiments conducted on synthetic and real data, along with a theoretical study, support the effectiveness of our method in constructing a well-generalizable global model by reducing the conflict between local models.", "url": "https://arxiv.org/abs/2308.13265"}, {"metadata": {"arXiv": "2308.13269", "Date": "Fri, 25 Aug 2023 09:42:54 ", "Title": "Heterogeneous Decentralized Machine Unlearning with Seed Model Distillation", "Authors": ["Guanhua Ye", "Guanhua Ye", "Quoc Viet Hung Nguyen", "Hongzhi Yin"], "Categories": "cs.LG"}, "abstract": "As some recent information security legislation endowed users with unconditional rights to be forgotten by any trained machine learning model, personalized IoT service providers have to put unlearning functionality into their consideration. The most straightforward method to unlearn users' contribution is to retrain the model from the initial state, which is not realistic in high throughput applications with frequent unlearning requests. Though some machine unlearning frameworks have been proposed to speed up the retraining process, they fail to match decentralized learning scenarios. In this paper, we design a decentralized unlearning framework called HDUS, which uses distilled seed models to construct erasable ensembles for all clients. Moreover, the framework is compatible with heterogeneous on-device models, representing stronger scalability in real-world applications. Extensive experiments on three real-world datasets show that our HDUS achieves state-of-the-art performance.", "url": "https://arxiv.org/abs/2308.13269"}, {"metadata": {"arXiv": "2308.13292", "Date": "Fri, 25 Aug 2023 10:33:44 ", "Title": "A Bayesian Active Learning Approach to Comparative Judgement", "Authors": ["Andy Gray", "Alma Rahat", "Tom Crick", "Stephen Lindsay", "Darren Wallace"], "Categories": "cs.LG cs.IR cs.IT math.IT", "Comments": ["16 pages"]}, "abstract": "Assessment is a crucial part of education. Traditional marking is a source of inconsistencies and unconscious bias, placing a high cognitive load on the assessors. An approach to address these issues is comparative judgement (CJ). In CJ, the assessor is presented with a pair of items and is asked to select the better one. Following a series of comparisons, a rank is derived using a ranking model, for example, the BTM, based on the results. While CJ is considered a reliable method for marking, there are concerns around transparency, and the ideal number of pairwise comparisons to generate a reliable estimation of the rank order is not known. Additionally, there have been attempts to generate a method of selecting pairs that should be compared next in an informative manner, but some existing methods are known to have created their own bias within results inflating the reliability metric used. As a result, a random selection approach is usually deployed. We propose a novel Bayesian approach to CJ (BCJ) for determining the ranks of compared items alongside a new way to select the pairs to present to the marker(s) using active learning (AL), addressing the key shortcomings of traditional CJ. Furthermore, we demonstrate how the entire approach may provide transparency by providing the user insights into how it is making its decisions and, at the same time, being more efficient. Results from our experiments confirm that the proposed BCJ combined with entropy-driven AL pair-selection method is superior to other alternatives. We also find that the more comparisons done, the more accurate BCJ becomes, which solves the issue the current method has of the model deteriorating if too many comparisons are performed. As our approach can generate the complete predicted rank distribution for an item, we also show how this can be utilised in devising a predicted grade, guided by the assessor.", "url": "https://arxiv.org/abs/2308.13292"}, {"metadata": {"arXiv": "2308.13294", "Date": "Fri, 25 Aug 2023 10:40:46 ", "Title": "Training normalizing flows with computationally intensive target probability distributions", "Authors": ["Piotr Bialas", "Piotr Korcyl", "Tomasz Stebel"], "Categories": "cs.LG cond-mat.stat-mech hep-lat", "Comments": ["15 pages", "5 figures", "4 tables", "3 listings"], "MSC-class": "cc:68T07", "ACM-class": "J.2; I.2.6"}, "abstract": "Machine learning techniques, in particular the so-called normalizing flows, are becoming increasingly popular in the context of Monte Carlo simulations as they can effectively approximate target probability distributions. In the case of lattice field theories (LFT) the target distribution is given by the exponential of the action. The common loss function's gradient estimator based on the \"reparametrization trick\" requires the calculation of the derivative of the action with respect to the fields. This can present a significant computational cost for complicated, non-local actions like e.g. fermionic action in QCD. In this contribution, we propose an estimator for normalizing flows based on the REINFORCE algorithm that avoids this issue. We apply it to two dimensional Schwinger model with Wilson fermions at criticality and show that it is up to ten times faster in terms of the wall-clock time as well as requiring up to $30\\%$ less memory than the reparameterization trick estimator. It is also more numerically stable allowing for single precision calculations and the use of half-float tensor cores. We present an in-depth analysis of the origins of those improvements. We believe that these benefits will appear also outside the realm of the LFT, in each case where the target probability distribution is computationally intensive.", "url": "https://arxiv.org/abs/2308.13294"}, {"metadata": {"arXiv": "2308.13298", "Date": "Fri, 25 Aug 2023 10:47:37 ", "Title": "Federated Linear Bandit Learning via Over-the-Air Computation", "Authors": ["Jiali Wang and Yuning Jiang and Xin Liu and Ting Wang and Yuanming Shi"], "Categories": "cs.LG eess.SP"}, "abstract": "In this paper, we investigate federated contextual linear bandit learning within a wireless system that comprises a server and multiple devices. Each device interacts with the environment, selects an action based on the received reward, and sends model updates to the server. The primary objective is to minimize cumulative regret across all devices within a finite time horizon. To reduce the communication overhead, devices communicate with the server via over-the-air computation (AirComp) over noisy fading channels, where the channel noise may distort the signals. In this context, we propose a customized federated linear bandits scheme, where each device transmits an analog signal, and the server receives a superposition of these signals distorted by channel noise. A rigorous mathematical analysis is conducted to determine the regret bound of the proposed scheme. Both theoretical analysis and numerical experiments demonstrate the competitive performance of our proposed scheme in terms of regret bounds in various settings.", "url": "https://arxiv.org/abs/2308.13298"}, {"metadata": {"arXiv": "2308.13320", "Date": "Fri, 25 Aug 2023 11:49:51 ", "Title": "Fine-tuning can cripple your foundation model; preserving features may be the solution", "Authors": ["Jishnu Mukhoti", "Yarin Gal", "Philip H.S. Torr", "Puneet K. Dokania"], "Categories": "cs.LG cs.CV"}, "abstract": "Pre-trained foundation models, owing primarily to their enormous capacity and exposure to vast amount of training data scraped from the internet, enjoy the advantage of storing knowledge about plenty of real-world concepts. Such models are typically fine-tuned on downstream datasets to produce remarkable state-of-the-art performances. While various fine-tuning methods have been devised and are shown to be highly effective, we observe that a fine-tuned model's ability to recognize concepts on tasks $\\textit{different}$ from the downstream one is reduced significantly compared to its pre-trained counterpart. This is clearly undesirable as a huge amount of time and money went into learning those very concepts in the first place. We call this undesirable phenomenon \"concept forgetting\" and via experiments show that most end-to-end fine-tuning approaches suffer heavily from this side effect. To this end, we also propose a rather simple fix to this problem by designing a method called LDIFS (short for $\\ell_2$ distance in feature space) that simply preserves the features of the original foundation model during fine-tuning. We show that LDIFS significantly reduces concept forgetting without having noticeable impact on the downstream task performance.", "url": "https://arxiv.org/abs/2308.13320"}, {"metadata": {"arXiv": "2308.13406", "Date": "Fri, 25 Aug 2023 14:33:59 ", "Title": "Using Visual and Vehicular Sensors for Driver Behavior Analysis: A Survey", "Authors": ["Bikram Adhikari"], "Categories": "cs.LG cs.CV", "Comments": ["10 pages", "2 figures", "5 tables"]}, "abstract": "Risky drivers account for 70% of fatal accidents in the United States. With recent advances in sensors and intelligent vehicular systems, there has been significant research on assessing driver behavior to improve driving experiences and road safety. This paper examines the various techniques used to analyze driver behavior using visual and vehicular data, providing an overview of the latest research in this field. The paper also discusses the challenges and open problems in the field and offers potential recommendations for future research. The survey concludes that integrating vision and vehicular information can significantly enhance the accuracy and effectiveness of driver behavior analysis, leading to improved safety measures and reduced traffic accidents.", "url": "https://arxiv.org/abs/2308.13406"}, {"metadata": {"arXiv": "2308.13418", "Date": "Fri, 25 Aug 2023 15:03:36 ", "Title": "Nougat: Neural Optical Understanding for Academic Documents", "Authors": ["Lukas Blecher", "Guillem Cucurull", "Thomas Scialom", "Robert Stojnic"], "Categories": "cs.LG cs.CV", "Comments": ["17 pages", "10 figures"]}, "abstract": "Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs. However, the PDF format leads to a loss of semantic information, particularly for mathematical expressions. We propose Nougat (Neural Optical Understanding for Academic Documents), a Visual Transformer model that performs an Optical Character Recognition (OCR) task for processing scientific documents into a markup language, and demonstrate the effectiveness of our model on a new dataset of scientific documents. The proposed approach offers a promising solution to enhance the accessibility of scientific knowledge in the digital age, by bridging the gap between human-readable documents and machine-readable text. We release the models and code to accelerate future work on scientific text recognition.", "url": "https://arxiv.org/abs/2308.13418"}, {"metadata": {"arXiv": "2308.13466", "Date": "Fri, 25 Aug 2023 16:10:44 ", "Title": "Staleness-Alleviated Distributed GNN Training via Online Dynamic-Embedding Prediction", "Authors": ["Guangji Bai", "Ziyang Yu", "Zheng Chai", "Yue Cheng", "Liang Zhao"], "Categories": "cs.LG", "Comments": ["Preprint. Do not distribute. arXiv admin note: text overlap with arXiv:2206.00057"]}, "abstract": "Despite the recent success of Graph Neural Networks (GNNs), it remains challenging to train GNNs on large-scale graphs due to neighbor explosions. As a remedy, distributed computing becomes a promising solution by leveraging abundant computing resources (e.g., GPU). However, the node dependency of graph data increases the difficulty of achieving high concurrency in distributed GNN training, which suffers from the massive communication overhead. To address it, Historical value approximation is deemed a promising class of distributed training techniques. It utilizes an offline memory to cache historical information (e.g., node embedding) as an affordable approximation of the exact value and achieves high concurrency. However, such benefits come at the cost of involving dated training information, leading to staleness, imprecision, and convergence issues. To overcome these challenges, this paper proposes SAT (Staleness-Alleviated Training), a novel and scalable distributed GNN training framework that reduces the embedding staleness adaptively. The key idea of SAT is to model the GNN's embedding evolution as a temporal graph and build a model upon it to predict future embedding, which effectively alleviates the staleness of the cached historical embedding. We propose an online algorithm to train the embedding predictor and the distributed GNN alternatively and further provide a convergence analysis. Empirically, we demonstrate that SAT can effectively reduce embedding staleness and thus achieve better performance and convergence speed on multiple large-scale graph datasets.", "url": "https://arxiv.org/abs/2308.13466"}, {"metadata": {"arXiv": "2308.13490", "Date": "Fri, 25 Aug 2023 17:04:35 ", "Title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs", "Authors": ["Phitchaya Mangpo Phothilimthana", "Sami Abu-El-Haija", "Kaidi Cao", "Bahare Fatemi", "Charith Mendis", "Bryan Perozzi"], "Categories": "cs.LG cs.AR cs.SI"}, "abstract": "Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and Transformer. TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality.", "url": "https://arxiv.org/abs/2308.13490"}, {"metadata": {"arXiv": "2308.13504", "Date": "Fri, 25 Aug 2023 17:28:58 ", "Title": "A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance", "Authors": ["Ian Colbert", "Alessandro Pappalardo", "Jakoba Petri-Koenig"], "Categories": "cs.LG cs.AR cs.CV", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2301.13376"]}, "abstract": "We present accumulator-aware quantization (A2Q), a novel weight quantization method designed to train quantized neural networks (QNNs) to avoid overflow when using low-precision accumulators during inference. A2Q introduces a unique formulation inspired by weight normalization that constrains the L1-norm of model weights according to accumulator bit width bounds that we derive. Thus, in training QNNs for low-precision accumulation, A2Q also inherently promotes unstructured weight sparsity to guarantee overflow avoidance. We apply our method to deep learning-based computer vision tasks to show that A2Q can train QNNs for low-precision accumulators while maintaining model accuracy competitive with a floating-point baseline. In our evaluations, we consider the impact of A2Q on both general-purpose platforms and programmable hardware. However, we primarily target model deployment on FPGAs because they can be programmed to fully exploit custom accumulator bit widths. Our experimentation shows accumulator bit width significantly impacts the resource efficiency of FPGA-based accelerators. On average across our benchmarks, A2Q offers up to a 2.3x reduction in resource utilization over 32-bit accumulator counterparts with 99.2% of the floating-point model accuracy.", "url": "https://arxiv.org/abs/2308.13504"}, {"metadata": {"arXiv": "2308.13513", "Date": "Fri, 25 Aug 2023 17:46:43 ", "Title": "Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs", "Authors": ["Tianyi Zhao", "Hui Hu and Lu Cheng"], "Categories": "cs.LG cs.SI", "Comments": ["CIKM 2023"]}, "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning representations on graphs, such as social networks. However, their vulnerability to privacy inference attacks restricts their practicality, especially in high-stake domains. To address this issue, privacy-preserving GNNs have been proposed, focusing on preserving node and/or link privacy. This work takes a step back and investigates how GNNs contribute to privacy leakage. Through theoretical analysis and simulations, we identify message passing under structural bias as the core component that allows GNNs to \\textit{propagate} and \\textit{amplify} privacy leakage. Building upon these findings, we propose a principled privacy-preserving GNN framework that effectively safeguards both node and link privacy, referred to as dual-privacy preservation. The framework comprises three major modules: a Sensitive Information Obfuscation Module that removes sensitive information from node embeddings, a Dynamic Structure Debiasing Module that dynamically corrects the structural bias, and an Adversarial Learning Module that optimizes the privacy-utility trade-off. Experimental results on four benchmark datasets validate the effectiveness of the proposed model in protecting both node and link privacy while preserving high utility for downstream tasks, such as node classification.", "url": "https://arxiv.org/abs/2308.13513"}, {"metadata": {"arXiv": "2308.13380", "Date": "Fri, 25 Aug 2023 13:50:17 ", "Title": "In-context learning for model-free system identification", "Authors": ["Marco Forgione", "Filippo Pura", "Dario Piga"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "In traditional system identification, we estimate a model of an unknown dynamical system based on given input/output sequences and available physical knowledge. Yet, is it also possible to understand the intricacies of dynamical systems not solely from their input/output patterns, but by observing the behavior of other systems within the same class? This central question drives the study presented in this paper. In response to this query, we introduce a novel paradigm for system identification, addressing two primary tasks: one-step-ahead prediction and multi-step simulation. Unlike conventional methods, we do not directly estimate a model for the specific system. Instead, we pretrain a meta model that represents a class of dynamical systems. This meta model is trained from a potentially infinite stream of synthetic data, generated by systems randomly extracted from a certain distribution. At its core, the meta model serves as an implicit representation of the main characteristics of a class of dynamical systems. When provided with a brief context from a new system - specifically, a short input/output sequence - the meta model implicitly discerns its dynamics, enabling predictions of its behavior. The proposed approach harnesses the power of Transformer architectures, renowned for their in-context learning capabilities in Natural Language Processing tasks. For one-step prediction, a GPT-like decoder-only architecture is utilized, whereas the simulation problem employs an encoder-decoder structure. Initial experimental results affirmatively answer our foundational question, opening doors to fresh research avenues in system identification.", "url": "https://arxiv.org/abs/2308.13380"}, {"metadata": {"arXiv": "2308.12985", "Date": "Thu, 24 Aug 2023 13:51:16 ", "Title": "Perimeter Control with Heterogeneous Cordon Signal Behaviors: A Semi-Model Dependent Reinforcement Learning Approach", "Authors": ["Jiajie Yu", "Pierre-Antoine Laharotte", "Yu Han", "Ludovic Leclercq"], "Categories": "cs.AI cs.SY eess.SY"}, "abstract": "Perimeter Control (PC) strategies have been proposed to address urban road network control in oversaturated situations by monitoring transfer flows of the Protected Network (PN). The uniform metering rate for cordon signals in existing studies ignores the variety of local traffic states at the intersection level, which may cause severe local traffic congestion and ruin the network stability. This paper introduces a semi-model dependent Multi-Agent Reinforcement Learning (MARL) framework to conduct PC with heterogeneous cordon signal behaviors. The proposed strategy integrates the MARL-based signal control method with centralized feedback PC policy and is applied to cordon signals of the PN. It operates as a two-stage system, with the feedback PC strategy detecting the overall traffic state within the PN and then distributing local instructions to cordon signals controlled by agents in the MARL framework. Each cordon signal acts independently and differently, creating a slack and distributed PC for the PN. The combination of the model-free and model-based methods is achieved by reconstructing the action-value function of the local agents with PC feedback reward without violating the integrity of the local signal control policy learned from the RL training process. Through numerical tests with different demand patterns in a microscopic traffic environment, the proposed PC strategy (a) is shown robustness, scalability, and transferability, (b) outperforms state-of-the-art model-based PC strategies in increasing network throughput, reducing cordon queue and carbon emission.", "url": "https://arxiv.org/abs/2308.12985"}, {"metadata": {"arXiv": "2308.13067", "Date": "Thu, 24 Aug 2023 20:23:13 ", "Title": "Causal Parrots: Large Language Models May Talk Causality But Are Not Causal", "Authors": ["Matej Ze\\v{c}evi\\'c and Moritz Willig and Devendra Singh Dhami and Kristian Kersting"], "Categories": "cs.AI", "Comments": ["Published in Transactions in Machine Learning Research (TMLR) (08/2023). Main paper: 17 pages", "References: 3 pages", "Appendix: 7 pages. Figures: 5 main", "3 appendix. Tables: 3 main"], "Journal-ref": "Transactions in Machine Learning Research (08/2023)"}, "abstract": "Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'", "url": "https://arxiv.org/abs/2308.13067"}, {"metadata": {"arXiv": "2308.13147", "Date": "Fri, 25 Aug 2023 02:55:19 ", "Title": "Diverse, Top-k, and Top-Quality Planning Over Simulators", "Authors": ["Lyndon Benke", "Tim Miller", "Michael Papasimeon", "and Nir Lipovetzky"], "Categories": "cs.AI", "Comments": ["This paper has been accepted at the 26th European Conference on Artificial Intelligence (ECAI 2023)"]}, "abstract": "Diverse, top-k, and top-quality planning are concerned with the generation of sets of solutions to sequential decision problems. Previously this area has been the domain of classical planners that require a symbolic model of the problem instance. This paper proposes a novel alternative approach that uses Monte Carlo Tree Search (MCTS), enabling application to problems for which only a black-box simulation model is available. We present a procedure for extracting bounded sets of plans from pre-generated search trees in best-first order, and a metric for evaluating the relative quality of paths through a search tree. We demonstrate this approach on a path-planning problem with hidden information, and suggest adaptations to the MCTS algorithm to increase the diversity of generated plans. Our results show that our method can generate diverse and high-quality plan sets in domains where classical planners are not applicable.", "url": "https://arxiv.org/abs/2308.13147"}, {"metadata": {"arXiv": "2308.13192", "Date": "Fri, 25 Aug 2023 06:05:57 ", "Title": "Formalising Natural Language Quantifiers for Human-Robot Interactions", "Authors": ["Stefan Morar", "Adrian Groza", "Mihai Pomarlan"], "Categories": "cs.AI cs.CL"}, "abstract": "We present a method for formalising quantifiers in natural language in the context of human-robot interactions. The solution is based on first-order logic extended with capabilities to represent the cardinality of variables, operating similarly to generalised quantifiers. To demonstrate the method, we designed an end-to-end system able to receive input as natural language, convert it into a formal logical representation, evaluate it, and return a result or send a command to a simulated robot.", "url": "https://arxiv.org/abs/2308.13192"}, {"metadata": {"arXiv": "2308.13433", "Date": "Fri, 25 Aug 2023 15:25:57 ", "Title": "Representing Timed Automata and Timing Anomalies of Cyber-Physical Production Systems in Knowledge Graphs", "Authors": ["Tom Westermann", "Milapji Singh Gill", "Alexander Fay"], "Categories": "cs.AI"}, "abstract": "Model-Based Anomaly Detection has been a successful approach to identify deviations from the expected behavior of Cyber-Physical Production Systems. Since manual creation of these models is a time-consuming process, it is advantageous to learn them from data and represent them in a generic formalism like timed automata. However, these models - and by extension, the detected anomalies - can be challenging to interpret due to a lack of additional information about the system. This paper aims to improve model-based anomaly detection in CPPS by combining the learned timed automaton with a formal knowledge graph about the system. Both the model and the detected anomalies are described in the knowledge graph in order to allow operators an easier interpretation of the model and the detected anomalies. The authors additionally propose an ontology of the necessary concepts. The approach was validated on a five-tank mixing CPPS and was able to formally define both automata model as well as timing anomalies in automata execution.", "url": "https://arxiv.org/abs/2308.13433"}, {"metadata": {"arXiv": "2308.13004", "Date": "Thu, 24 Aug 2023 18:07:37 ", "Title": "Spherical Vision Transformer for 360-degree Video Saliency Prediction", "Authors": ["Mert Cokelek", "Nevrez Imamoglu", "Cagri Ozcinar", "Erkut Erdem", "Aykut Erdem"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["12 pages", "4 figures", "accepted to BMVC 2023"]}, "abstract": "The growing interest in omnidirectional videos (ODVs) that capture the full field-of-view (FOV) has gained 360-degree saliency prediction importance in computer vision. However, predicting where humans look in 360-degree scenes presents unique challenges, including spherical distortion, high resolution, and limited labelled data. We propose a novel vision-transformer-based model for omnidirectional videos named SalViT360 that leverages tangent image representations. We introduce a spherical geometry-aware spatiotemporal self-attention mechanism that is capable of effective omnidirectional video understanding. Furthermore, we present a consistency-based unsupervised regularization term for projection-based 360-degree dense-prediction models to reduce artefacts in the predictions that occur after inverse projection. Our approach is the first to employ tangent images for omnidirectional saliency prediction, and our experimental results on three ODV saliency datasets demonstrate its effectiveness compared to the state-of-the-art.", "url": "https://arxiv.org/abs/2308.13004"}, {"metadata": {"arXiv": "2308.13142", "Date": "Fri, 25 Aug 2023 02:35:54 ", "Title": "A Survey of Diffusion Based Image Generation Models: Issues and Their Solutions", "Authors": ["Tianyi Zhang", "Zheng Wang", "Jing Huang", "Mohiuddin Muhammad Tasnim", "Wei Shi"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, there has been significant progress in the development of large models. Following the success of ChatGPT, numerous language models have been introduced, demonstrating remarkable performance. Similar advancements have also been observed in image generation models, such as Google's Imagen model, OpenAI's DALL-E 2, and stable diffusion models, which have exhibited impressive capabilities in generating images. However, similar to large language models, these models still encounter unresolved challenges. Fortunately, the availability of open-source stable diffusion models and their underlying mathematical principles has enabled the academic community to extensively analyze the performance of current image generation models and make improvements based on this stable diffusion framework. This survey aims to examine the existing issues and the current solutions pertaining to image generation models.", "url": "https://arxiv.org/abs/2308.13142"}, {"metadata": {"arXiv": "2308.13218", "Date": "Fri, 25 Aug 2023 07:32:34 ", "Title": "MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual Captioning", "Authors": ["Bang Yang", "Fenglin Liu", "Xian Wu", "Yaowei Wang", "Xu Sun", "and Yuexian Zou"], "Categories": "cs.CV cs.AI", "Comments": ["ACL'2023", "13 pages", "4 figures"], "DOI": "10.18653/v1/2023.acl-long.664"}, "abstract": "Supervised visual captioning models typically require a large scale of images or videos paired with descriptions in a specific language (i.e., the vision-caption pairs) for training. However, collecting and labeling large-scale datasets is time-consuming and expensive for many scenarios and languages. Therefore, sufficient labeled pairs are usually not available. To deal with the label shortage problem, we present a simple yet effective zero-shot approach MultiCapCLIP that can generate visual captions for different scenarios and languages without any labeled vision-caption pairs of downstream datasets. In the training stage, MultiCapCLIP only requires text data for input. Then it conducts two main steps: 1) retrieving concept prompts that preserve the corresponding domain knowledge of new scenarios; 2) auto-encoding the prompts to learn writing styles to output captions in a desired language. In the testing stage, MultiCapCLIP instead takes visual data as input directly to retrieve the concept prompts to generate the final visual descriptions. The extensive experiments on image and video captioning across four benchmarks and four languages (i.e., English, Chinese, German, and French) confirm the effectiveness of our approach. Compared with state-of-the-art zero-shot and weakly-supervised methods, our method achieves 4.8% and 21.5% absolute improvements in terms of BLEU@4 and CIDEr metrics. Our code is available at https://github.com/yangbang18/MultiCapCLIP.", "url": "https://arxiv.org/abs/2308.13218"}, {"metadata": {"arXiv": "2308.13305", "Date": "Fri, 25 Aug 2023 11:07:11 ", "Title": "Dynamic Residual Classifier for Class Incremental Learning", "Authors": ["Xiuwei Chen", "Xiaobin Chang"], "Categories": "cs.CV cs.AI"}, "abstract": "The rehearsal strategy is widely used to alleviate the catastrophic forgetting problem in class incremental learning (CIL) by preserving limited exemplars from previous tasks. With imbalanced sample numbers between old and new classes, the classifier learning can be biased. Existing CIL methods exploit the long-tailed (LT) recognition techniques, e.g., the adjusted losses and the data re-sampling methods, to handle the data imbalance issue within each increment task. In this work, the dynamic nature of data imbalance in CIL is shown and a novel Dynamic Residual Classifier (DRC) is proposed to handle this challenging scenario. Specifically, DRC is built upon a recent advance residual classifier with the branch layer merging to handle the model-growing problem. Moreover, DRC is compatible with different CIL pipelines and substantially improves them. Combining DRC with the model adaptation and fusion (MAF) pipeline, this method achieves state-of-the-art results on both the conventional CIL and the LT-CIL benchmarks. Extensive experiments are also conducted for a detailed analysis. The code is publicly available.", "url": "https://arxiv.org/abs/2308.13305"}, {"metadata": {"arXiv": "2308.13343", "Date": "Fri, 25 Aug 2023 12:30:48 ", "Title": "Squeeze aggregated excitation network", "Authors": ["Mahendran N"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "5 figures", "3 tables"]}, "abstract": "Convolutional neural networks have spatial representations which read patterns in the vision tasks. Squeeze and excitation links the channel wise representations by explicitly modeling on channel level. Multi layer perceptrons learn global representations and in most of the models it is used often at the end after all convolutional layers to gather all the information learned before classification. We propose a method of inducing the global representations within channels to have better performance of the model. We propose SaEnet, Squeeze aggregated excitation network, for learning global channelwise representation in between layers. The proposed module takes advantage of passing important information after squeeze by having aggregated excitation before regaining its shape. We also introduce a new idea of having a multibranch linear(dense) layer in the network. This learns global representations from the condensed information which enhances the representational power of the network. The proposed module have undergone extensive experiments by using Imagenet and CIFAR100 datasets and compared with closely related architectures. The analyzes results that proposed models outputs are comparable and in some cases better than existing state of the art architectures.", "url": "https://arxiv.org/abs/2308.13343"}, {"metadata": {"arXiv": "2308.13492", "Date": "Fri, 25 Aug 2023 17:06:30 ", "Title": "Ultrafast-and-Ultralight ConvNet-Based Intelligent Monitoring System for Diagnosing Early-Stage Mpox Anytime and Anywhere", "Authors": ["Yubiao Yue", "Xiaoqiang Shi", "Li Qin", "Xinyue Zhang", "Yanmei Chen", "Jialong Xu", "Zipei Zheng", "Yujun Cao", "Di Liu", "Zhenzhang Li", "Yang Li"], "Categories": "cs.CV cs.AI", "Comments": ["This paper has been submitted to Neurocomputing"]}, "abstract": "Due to the lack of more efficient diagnostic tools for monkeypox, its spread remains unchecked, presenting a formidable challenge to global health. While the high efficacy of deep learning models for monkeypox diagnosis has been demonstrated in related studies, the overlook of inference speed, the parameter size and diagnosis performance for early-stage monkeypox renders the models inapplicable in real-world settings. To address these challenges, we proposed an ultrafast and ultralight network named Fast-MpoxNet. Fast-MpoxNet possesses only 0.27M parameters and can process input images at 68 frames per second (FPS) on the CPU. To counteract the diagnostic performance limitation brought about by the small model capacity, it integrates the attention-based feature fusion module and the multiple auxiliary losses enhancement strategy for better detecting subtle image changes and optimizing weights. Using transfer learning and five-fold cross-validation, Fast-MpoxNet achieves 94.26% Accuracy on the Mpox dataset. Notably, its recall for early-stage monkeypox achieves 93.65%. By adopting data augmentation, our model's Accuracy rises to 98.40% and attains a Practicality Score (A new metric for measuring model practicality in real-time diagnosis application) of 0.80. We also developed an application system named Mpox-AISM V2 for both personal computers and mobile phones. Mpox-AISM V2 features ultrafast responses, offline functionality, and easy deployment, enabling accurate and real-time diagnosis for both the public and individuals in various real-world settings, especially in populous settings during the outbreak. Our work could potentially mitigate future monkeypox outbreak and illuminate a fresh paradigm for developing real-time diagnostic tools in the healthcare field.", "url": "https://arxiv.org/abs/2308.13492"}, {"metadata": {"arXiv": "2308.13495", "Date": "Fri, 25 Aug 2023 17:10:22 ", "Title": "Open Gaze: An Open-Source Implementation Replicating Google's Eye Tracking Paper", "Authors": ["Sushmanth reddy Mereddy", "Jyothi Swaroop Reddy and Somnath Sharma"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages ", "15 figures"], "MSC-class": "68T10(primary), secondary", "ACM-class": "I.2.1; I.4.1"}, "abstract": "Eye tracking has been a pivotal tool in diverse fields such as vision research, language analysis, and usability assessment. The majority of prior investigations, however, have concentrated on expansive desktop displays employing specialized, costly eye tracking hardware that lacks scalability. Remarkably little insight exists into ocular movement patterns on smartphones, despite their widespread adoption and significant usage. In this manuscript, we present an open-source implementation of a smartphone-based gaze tracker that emulates the methodology proposed by a GooglePaper (whose source code remains proprietary). Our focus is on attaining accuracy comparable to that attained through the GooglePaper's methodology, without the necessity for supplementary hardware. Through the integration of machine learning techniques, we unveil an accurate eye tracking solution that is native to smartphones. Our approach demonstrates precision akin to the state-of-the-art mobile eye trackers, which are characterized by a cost that is two orders of magnitude higher. Leveraging the vast MIT GazeCapture dataset, which is available through registration on the dataset's website, we successfully replicate crucial findings from previous studies concerning ocular motion behavior in oculomotor tasks and saliency analyses during natural image observation. Furthermore, we emphasize the applicability of smartphone-based gaze tracking in discerning reading comprehension challenges. Our findings exhibit the inherent potential to amplify eye movement research by significant proportions, accommodating participation from thousands of subjects with explicit consent. This scalability not only fosters advancements in vision research, but also extends its benefits to domains such as accessibility enhancement and healthcare applications.", "url": "https://arxiv.org/abs/2308.13495"}, {"metadata": {"arXiv": "2308.13503", "Date": "Fri, 25 Aug 2023 17:28:23 ", "Title": "Attending Generalizability in Course of Deep Fake Detection by Exploring Multi-task Learning", "Authors": ["Pranav Balaji", "Abhijit Das", "Srijan Das", "Antitza Dantcheva"], "Categories": "cs.CV cs.AI"}, "abstract": "This work explores various ways of exploring multi-task learning (MTL) techniques aimed at classifying videos as original or manipulated in cross-manipulation scenario to attend generalizability in deep fake scenario. The dataset used in our evaluation is FaceForensics++, which features 1000 original videos manipulated by four different techniques, with a total of 5000 videos. We conduct extensive experiments on multi-task learning and contrastive techniques, which are well studied in literature for their generalization benefits. It can be concluded that the proposed detection model is quite generalized, i.e., accurately detects manipulation methods not encountered during training as compared to the state-of-the-art.", "url": "https://arxiv.org/abs/2308.13503"}, {"metadata": {"arXiv": "2308.13307", "Date": "Fri, 25 Aug 2023 11:14:24 ", "Title": "Asch Meets HRI: Human Conformity to Robot Groups", "Authors": ["Jasmina Bernotat", "Doreen Jirak", "Eduardo Benitez Sandoval", "Francisco Cruz"], "Categories": "cs.RO cs.AI", "Comments": ["5 pages", "2 figures"]}, "abstract": "We present a research outline that aims at investigating group dynamics and peer pressure in the context of industrial robots. Our research plan was motivated by the fact that industrial robots became already an integral part of human-robot co-working. However, industrial robots have been sparsely integrated into research on robot credibility, group dynamics, and potential users' tendency to follow a robot's indication. Therefore, we aim to transfer the classic Asch experiment (see \\cite{Asch_51}) into HRI with industrial robots. More precisely, we will test to what extent participants follow a robot's response when confronted with a group (vs. individual) industrial robot arms (vs. human) peers who give a false response. We are interested in highlighting the effects of group size, perceived robot credibility, psychological stress, and peer pressure in the context of industrial robots. With the results of this research, we hope to highlight group dynamics that might underlie HRI in industrial settings in which numerous robots already work closely together with humans in shared environments.", "url": "https://arxiv.org/abs/2308.13307"}, {"metadata": {"arXiv": "2308.13491", "Date": "Fri, 25 Aug 2023 17:05:41 ", "Title": "Towards Optimal Head-to-head Autonomous Racing with Curriculum Reinforcement Learning", "Authors": ["Dvij Kalaria", "Qin Lin and John M. Dolan"], "Categories": "cs.RO cs.AI", "Comments": ["Submitted to MAD games IROS workshop"]}, "abstract": "Head-to-head autonomous racing is a challenging problem, as the vehicle needs to operate at the friction or handling limits in order to achieve minimum lap times while also actively looking for strategies to overtake/stay ahead of the opponent. In this work we propose a head-to-head racing environment for reinforcement learning which accurately models vehicle dynamics. Some previous works have tried learning a policy directly in the complex vehicle dynamics environment but have failed to learn an optimal policy. In this work, we propose a curriculum learning-based framework by transitioning from a simpler vehicle model to a more complex real environment to teach the reinforcement learning agent a policy closer to the optimal policy. We also propose a control barrier function-based safe reinforcement learning algorithm to enforce the safety of the agent in a more effective way while not compromising on optimality.", "url": "https://arxiv.org/abs/2308.13491"}, {"metadata": {"arXiv": "2308.13317", "Date": "Fri, 25 Aug 2023 11:41:05 ", "Title": "Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics", "Authors": ["Aline Ioste"], "Categories": "cs.AI cs.LG"}, "abstract": "This paper presents a novel approach named Persona-Grouping-Intelligence (PGI), which has been crafted to tackle the challenges posed by GPT models when applied to real-world business issues. PGI leverages the inherent capabilities of the GPT model to comprehend intricate language structures and generate responses that are contextually relevant. The experiment occurred in a business scenario where human intelligence was being underutilized due to less optimized business processes. The primary objective of this approach is to leverage GPT models to reduce the workload on humans in tasks that are extensive, monotonous, and repetitive. Instead, the focus is redirected toward decision-making activities. Remarkably, the experiment yielded an accuracy rate of 93.81% in validating 4,000 responses generated by the model, underscoring the effectiveness of the PGI strategies. Effectively addressing the issue of underutilized human intelligence, this paradigm shift aligns business environments with dynamic machine intelligence, enabling them to navigate the intricacies of real-world challenges. This approach facilitates the practical utilization of these models to tackle actual problems. The methodology offers an opportunity to reshape the fundamental structure of business processes by seamlessly integrating human decision-making with adaptable machine intelligence. Consequently, this optimization enhances operational efficiency and elevates strategic decision-making across diverse business contexts.", "url": "https://arxiv.org/abs/2308.13317"}, {"metadata": {"arXiv": "2308.13182", "Date": "Fri, 25 Aug 2023 05:24:23 ", "Title": "Structural Cycle GAN for Virtual Immunohistochemistry Staining of Gland Markers in the Colon", "Authors": ["Shikha Dubey", "Tushar Kataria", "Beatrice Knudsen", "and Shireen Y. Elhabian"], "Categories": "cs.CV cs.AI cs.LG q-bio.QM", "Comments": ["Accepted to MICCAI Workshop 2023"]}, "abstract": "With the advent of digital scanners and deep learning, diagnostic operations may move from a microscope to a desktop. Hematoxylin and Eosin (H&E) staining is one of the most frequently used stains for disease analysis, diagnosis, and grading, but pathologists do need different immunohistochemical (IHC) stains to analyze specific structures or cells. Obtaining all of these stains (H&E and different IHCs) on a single specimen is a tedious and time-consuming task. Consequently, virtual staining has emerged as an essential research direction. Here, we propose a novel generative model, Structural Cycle-GAN (SC-GAN), for synthesizing IHC stains from H&E images, and vice versa. Our method expressly incorporates structural information in the form of edges (in addition to color data) and employs attention modules exclusively in the decoder of the proposed generator model. This integration enhances feature localization and preserves contextual information during the generation process. In addition, a structural loss is incorporated to ensure accurate structure alignment between the generated and input markers. To demonstrate the efficacy of the proposed model, experiments are conducted with two IHC markers emphasizing distinct structures of glands in the colon: the nucleus of epithelial cells (CDX2) and the cytoplasm (CK818). Quantitative metrics such as FID and SSIM are frequently used for the analysis of generative models, but they do not correlate explicitly with higher-quality virtual staining results. Therefore, we propose two new quantitative metrics that correlate directly with the virtual staining specificity of IHC markers.", "url": "https://arxiv.org/abs/2308.13182"}, {"metadata": {"arXiv": "2308.13047", "Date": "Thu, 24 Aug 2023 19:27:59 ", "Title": "Federated Learning of Causal Effects from Incomplete Observational Data", "Authors": ["Thanh Vinh Vo", "Young lee", "Tze-Yun Leong"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["Preprint"]}, "abstract": "Decentralized and incomplete data sources are prevalent in real-world applications, posing a formidable challenge for causal inference. These sources cannot be consolidated into a single entity owing to privacy constraints, and the presence of missing values within them can potentially introduce bias to the causal estimands. We introduce a new approach for federated causal inference from incomplete data, enabling the estimation of causal effects from multiple decentralized and incomplete data sources. Our approach disentangles the loss function into multiple components, each corresponding to a specific data source with missing values. Our approach accounts for the missing data under the missing at random assumption, while also estimating higher-order statistics of the causal estimands. Our method recovers the conditional distribution of missing confounders given the observed confounders from the decentralized data sources to identify causal effects. Our framework estimates heterogeneous causal effects without the sharing of raw training data among sources, which helps to mitigate privacy risks. The efficacy of our approach is demonstrated through a collection of simulated and real-world instances, illustrating its potential and practicality.", "url": "https://arxiv.org/abs/2308.13047"}, {"metadata": {"arXiv": "2308.13068", "Date": "Thu, 24 Aug 2023 20:24:12 ", "Title": "Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology", "Authors": ["Mohamed El Amine Sehili and Zonghua Zhang"], "Categories": "cs.LG cs.AI cs.PF stat.CO stat.ML", "ACM-class": "G.3; I.2.6; I.2.m"}, "abstract": "Multivariate Time Series (MVTS) anomaly detection is a long-standing and challenging research topic that has attracted tremendous research effort from both industry and academia recently. However, a careful study of the literature makes us realize that 1) the community is active but not as organized as other sibling machine learning communities such as Computer Vision (CV) and Natural Language Processing (NLP), and 2) most proposed solutions are evaluated using either inappropriate or highly flawed protocols, with an apparent lack of scientific foundation. So flawed is one very popular protocol, the so-called \\pa protocol, that a random guess can be shown to systematically outperform \\emph{all} algorithms developed so far. In this paper, we review and evaluate many recent algorithms using more robust protocols and discuss how a normally good protocol may have weaknesses in the context of MVTS anomaly detection and how to mitigate them. We also share our concerns about benchmark datasets, experiment design and evaluation methodology we observe in many works. Furthermore, we propose a simple, yet challenging, baseline algorithm based on Principal Components Analysis (PCA) that surprisingly outperforms many recent Deep Learning (DL) based approaches on popular benchmark datasets. The main objective of this work is to stimulate more effort towards important aspects of the research such as data, experiment design, evaluation methodology and result interpretability, instead of putting the highest weight on the design of increasingly more complex and \"fancier\" algorithms.", "url": "https://arxiv.org/abs/2308.13068"}, {"metadata": {"arXiv": "2308.13158", "Date": "Fri, 25 Aug 2023 03:35:29 ", "Title": "DAG-ACFL: Asynchronous Clustered Federated Learning based on DAG-DLT", "Authors": ["Xiaofeng Xue", "Haokun Mao and Qiong Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning (FL) aims to collaboratively train a global model while ensuring client data privacy. However, FL faces challenges from the non-IID data distribution among clients. Clustered FL (CFL) has emerged as a promising solution, but most existing CFL frameworks adopt synchronous frameworks lacking asynchrony. An asynchronous CFL framework called SDAGFL based on directed acyclic graph distributed ledger techniques (DAG-DLT) was proposed, but its complete decentralization leads to high communication and storage costs. We propose DAG-ACFL, an asynchronous clustered FL framework based on directed acyclic graph distributed ledger techniques (DAG-DLT). We first detail the components of DAG-ACFL. A tip selection algorithm based on the cosine similarity of model parameters is then designed to aggregate models from clients with similar distributions. An adaptive tip selection algorithm leveraging change-point detection dynamically determines the number of selected tips. We evaluate the clustering and training performance of DAG-ACFL on multiple datasets and analyze its communication and storage costs. Experiments show the superiority of DAG-ACFL in asynchronous clustered FL. By combining DAG-DLT with clustered FL, DAG-ACFL realizes robust, decentralized and private model training with efficient performance.", "url": "https://arxiv.org/abs/2308.13158"}, {"metadata": {"arXiv": "2308.13212", "Date": "Fri, 25 Aug 2023 07:15:58 ", "Title": "Physics-Inspired Neural Graph ODE for Long-term Dynamical Simulation", "Authors": ["Yang Liu", "Jiashun Cheng", "Haihong Zhao", "Tingyang Xu", "Peilin Zhao", "Fugee Tsung", "Jia Li", "Yu Rong"], "Categories": "cs.LG cs.AI"}, "abstract": "Simulating and modeling the long-term dynamics of multi-object physical systems is an essential and challenging task. Current studies model the physical systems utilizing Graph Neural Networks (GNNs) with equivariant properties. Specifically, they model the dynamics as a sequence of discrete states with a fixed time interval and learn a direct mapping for all the two adjacent states. However, this direct mapping overlooks the continuous nature between the two states. Namely, we have verified that there are countless possible trajectories between two discrete dynamic states in current GNN-based direct mapping models. This issue greatly hinders the model generalization ability, leading to poor performance of the long-term simulation. In this paper, to better model the latent trajectory through discrete supervision signals, we propose a Physics-Inspired Neural Graph ODE (PINGO) algorithm. In PINGO, to ensure the uniqueness of the trajectory, we construct a Physics-Inspired Neural ODE framework to update the latent trajectory. Meanwhile, to effectively capture intricate interactions among objects, we use a GNN-based model to parameterize Neural ODE in a plug-and-play manner. Furthermore, we prove that the discrepancy between the learned trajectory of PIGNO and the true trajectory can be theoretically bounded. Extensive experiments verify our theoretical findings and demonstrate that our model yields an order-of-magnitude improvement over the state-of-the-art baselines, especially on long-term predictions and roll-out errors.", "url": "https://arxiv.org/abs/2308.13212"}, {"metadata": {"arXiv": "2308.13278", "Date": "Fri, 25 Aug 2023 10:00:06 ", "Title": "Integrating LLMs and Decision Transformers for Language Grounded Generative Quality-Diversity", "Authors": ["Achkan Salehi and Stephane Doncieux"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["16 pages", "9 figures", "2 tables"]}, "abstract": "Quality-Diversity is a branch of stochastic optimization that is often applied to problems from the Reinforcement Learning and control domains in order to construct repertoires of well-performing policies/skills that exhibit diversity with respect to a behavior space. Such archives are usually composed of a finite number of reactive agents which are each associated to a unique behavior descriptor, and instantiating behavior descriptors outside of that coarsely discretized space is not straight-forward. While a few recent works suggest solutions to that issue, the trajectory that is generated is not easily customizable beyond the specification of a target behavior descriptor. We propose to jointly solve those problems in environments where semantic information about static scene elements is available by leveraging a Large Language Model to augment the repertoire with natural language descriptions of trajectories, and training a policy conditioned on those descriptions. Thus, our method allows a user to not only specify an arbitrary target behavior descriptor, but also provide the model with a high-level textual prompt to shape the generated trajectory. We also propose an LLM-based approach to evaluating the performance of such generative agents. Furthermore, we develop a benchmark based on simulated robot navigation in a 2d maze that we use for experimental validation.", "url": "https://arxiv.org/abs/2308.13278"}, {"metadata": {"arXiv": "2308.13279", "Date": "Fri, 25 Aug 2023 10:01:53 ", "Title": "Hyperbolic Random Forests", "Authors": ["Lars Doorenbos", "Pablo M\\'arquez-Neila", "Raphael Sznitman", "Pascal Mettes"], "Categories": "cs.LG cs.AI", "Comments": ["Code available at https://github.com/LarsDoorenbos/HoroRF"]}, "abstract": "Hyperbolic space is becoming a popular choice for representing data due to the hierarchical structure - whether implicit or explicit - of many real-world datasets. Along with it comes a need for algorithms capable of solving fundamental tasks, such as classification, in hyperbolic space. Recently, multiple papers have investigated hyperbolic alternatives to hyperplane-based classifiers, such as logistic regression and SVMs. While effective, these approaches struggle with more complex hierarchical data. We, therefore, propose to generalize the well-known random forests to hyperbolic space. We do this by redefining the notion of a split using horospheres. Since finding the globally optimal split is computationally intractable, we find candidate horospheres through a large-margin classifier. To make hyperbolic random forests work on multi-class data and imbalanced experiments, we furthermore outline a new method for combining classes based on their lowest common ancestor and a class-balanced version of the large-margin loss. Experiments on standard and new benchmarks show that our approach outperforms both conventional random forest algorithms and recent hyperbolic classifiers.", "url": "https://arxiv.org/abs/2308.13279"}, {"metadata": {"arXiv": "2308.13300", "Date": "Fri, 25 Aug 2023 10:51:02 ", "Title": "Learning Compact Neural Networks with Deep Overparameterised Multitask Learning", "Authors": ["Shen Ren", "Haosen Shi"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted for IJCAI2023 workshop", "1st International Workshop on Generalizing from Limited Resources in the Open World"]}, "abstract": "Compact neural network offers many benefits for real-world applications. However, it is usually challenging to train the compact neural networks with small parameter sizes and low computational costs to achieve the same or better model performance compared to more complex and powerful architecture. This is particularly true for multitask learning, with different tasks competing for resources. We present a simple, efficient and effective multitask learning overparameterisation neural network design by overparameterising the model architecture in training and sharing the overparameterised model parameters more effectively across tasks, for better optimisation and generalisation. Experiments on two challenging multitask datasets (NYUv2 and COCO) demonstrate the effectiveness of the proposed method across various convolutional networks and parameter sizes.", "url": "https://arxiv.org/abs/2308.13300"}, {"metadata": {"arXiv": "2308.13352", "Date": "Fri, 25 Aug 2023 12:47:59 ", "Title": "A Generic Machine Learning Framework for Fully-Unsupervised Anomaly Detection with Contaminated Data", "Authors": ["Markus Ulmer", "Jannik Zgraggen", "and Lilach Goren Huber"], "Categories": "cs.LG cs.AI"}, "abstract": "Anomaly detection (AD) tasks have been solved using machine learning algorithms in various domains and applications. The great majority of these algorithms use normal data to train a residual-based model, and assign anomaly scores to unseen samples based on their dissimilarity with the learned normal regime. The underlying assumption of these approaches is that anomaly-free data is available for training. This is, however, often not the case in real-world operational settings, where the training data may be contaminated with a certain fraction of abnormal samples. Training with contaminated data, in turn, inevitably leads to a deteriorated AD performance of the residual-based algorithms. In this paper we introduce a framework for a fully unsupervised refinement of contaminated training data for AD tasks. The framework is generic and can be applied to any residual-based machine learning model. We demonstrate the application of the framework to two public datasets of multivariate time series machine data from different application fields. We show its clear superiority over the naive approach of training with contaminated data without refinement. Moreover, we compare it to the ideal, unrealistic reference in which anomaly-free data would be available for training. Since the approach exploits information from the anomalies, and not only from the normal regime, it is comparable and often outperforms the ideal baseline as well.", "url": "https://arxiv.org/abs/2308.13352"}, {"metadata": {"arXiv": "2308.13386", "Date": "Fri, 25 Aug 2023 14:01:43 ", "Title": "TFDNet: Time-Frequency Enhanced Decomposed Network for Long-term Time Series Forecasting", "Authors": ["Yuxiao Luo", "Ziyu Lyu", "Xingyu Huang"], "Categories": "cs.LG cs.AI"}, "abstract": "Long-term time series forecasting is a vital task and has a wide range of real applications. Recent methods focus on capturing the underlying patterns from one single domain (e.g. the time domain or the frequency domain), and have not taken a holistic view to process long-term time series from the time-frequency domains. In this paper, we propose a Time-Frequency Enhanced Decomposed Network (TFDNet) to capture both the long-term underlying patterns and temporal periodicity from the time-frequency domain. In TFDNet, we devise a multi-scale time-frequency enhanced encoder backbone and develop two separate trend and seasonal time-frequency blocks to capture the distinct patterns within the decomposed trend and seasonal components in multi-resolutions. Diverse kernel learning strategies of the kernel operations in time-frequency blocks have been explored, by investigating and incorporating the potential different channel-wise correlation patterns of multivariate time series. Experimental evaluation of eight datasets from five benchmark domains demonstrated that TFDNet is superior to state-of-the-art approaches in both effectiveness and efficiency.", "url": "https://arxiv.org/abs/2308.13386"}, {"metadata": {"arXiv": "2308.13453", "Date": "Fri, 25 Aug 2023 15:54:22 ", "Title": "Learning to Intervene on Concept Bottlenecks", "Authors": ["David Steinmann", "Wolfgang Stammer", "Felix Friedrich", "Kristian Kersting"], "Categories": "cs.LG cs.AI"}, "abstract": "While traditional deep learning models often lack interpretability, concept bottleneck models (CBMs) provide inherent explanations via their concept representations. Specifically, they allow users to perform interventional interactions on these concepts by updating the concept values and thus correcting the predictive output of the model. Traditionally, however, these interventions are applied to the model only once and discarded afterward. To rectify this, we present concept bottleneck memory models (CB2M), an extension to CBMs. Specifically, a CB2M learns to generalize interventions to appropriate novel situations via a two-fold memory with which it can learn to detect mistakes and to reapply previous interventions. In this way, a CB2M learns to automatically improve model performance from a few initially obtained interventions. If no prior human interventions are available, a CB2M can detect potential mistakes of the CBM bottleneck and request targeted interventions. In our experimental evaluations on challenging scenarios like handling distribution shifts and confounded training data, we illustrate that CB2M are able to successfully generalize interventions to unseen data and can indeed identify wrongly inferred concepts. Overall, our results show that CB2M is a great tool for users to provide interactive feedback on CBMs, e.g., by guiding a user's interaction and requiring fewer interventions.", "url": "https://arxiv.org/abs/2308.13453"}, {"metadata": {"arXiv": "2308.13498", "Date": "Fri, 25 Aug 2023 17:13:42 ", "Title": "Escaping the Sample Trap: Fast and Accurate Epistemic Uncertainty Estimation with Pairwise-Distance Estimators", "Authors": ["Lucas Berry", "David Meger"], "Categories": "cs.LG cs.AI"}, "abstract": "This work introduces a novel approach for epistemic uncertainty estimation for ensemble models using pairwise-distance estimators (PaiDEs). These estimators utilize the pairwise-distance between model components to establish bounds on entropy and uses said bounds as estimates for information-based criterion. Unlike recent deep learning methods for epistemic uncertainty estimation, which rely on sample-based Monte Carlo estimators, PaiDEs are able to estimate epistemic uncertainty up to 100$\\times$ faster, over a larger space (up to 100$\\times$) and perform more accurately in higher dimensions. To validate our approach, we conducted a series of experiments commonly used to evaluate epistemic uncertainty estimation: 1D sinusoidal data, Pendulum-v0, Hopper-v2, Ant-v2 and Humanoid-v2. For each experimental setting, an Active Learning framework was applied to demonstrate the advantages of PaiDEs for epistemic uncertainty estimation.", "url": "https://arxiv.org/abs/2308.13498"}, {"metadata": {"arXiv": "2308.13088", "Date": "Thu, 24 Aug 2023 21:16:03 ", "Title": "Racing Towards Reinforcement Learning based control of an Autonomous Formula SAE Car", "Authors": ["Aakaash Salvaji", "Harry Taylor", "David Valencia", "Trevor Gee", "Henry Williams"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted at the Australasian Conference on Robotics and Automation (ACRA 2022)"]}, "abstract": "With the rising popularity of autonomous navigation research, Formula Student (FS) events are introducing a Driverless Vehicle (DV) category to their event list. This paper presents the initial investigation into utilising Deep Reinforcement Learning (RL) for end-to-end control of an autonomous FS race car for these competitions. We train two state-of-the-art RL algorithms in simulation on tracks analogous to the full-scale design on a Turtlebot2 platform. The results demonstrate that our approach can successfully learn to race in simulation and then transfer to a real-world racetrack on the physical platform. Finally, we provide insights into the limitations of the presented approach and guidance into the future directions for applying RL toward full-scale autonomous FS racing.", "url": "https://arxiv.org/abs/2308.13088"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

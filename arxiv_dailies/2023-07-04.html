<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.00149", "Date": "Fri, 30 Jun 2023 21:49:41 ", "Title": "Hierarchical Neural Coding for Controllable CAD Model Generation", "Authors": ["Xiang Xu", "Pradeep Kumar Jayaraman", "Joseph G. Lambourne", "Karl D.D. Willis", "Yasutaka Furukawa"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICML 2023. Project website at https://hnc-cad.github.io/"]}, "abstract": "This paper presents a novel generative model for Computer Aided Design (CAD) that 1) represents high-level design concepts of a CAD model as a three-level hierarchical tree of neural codes, from global part arrangement down to local curve geometry; and 2) controls the generation or completion of CAD models by specifying the target design using a code tree. Concretely, a novel variant of a vector quantized VAE with \"masked skip connection\" extracts design variations as neural codebooks at three levels. Two-stage cascaded auto-regressive transformers learn to generate code trees from incomplete CAD models and then complete CAD models following the intended design. Extensive experiments demonstrate superior performance on conventional tasks such as random generation while enabling novel interaction capabilities on conditional generation tasks. The code is available at https://github.com/samxuxiang/hnc-cad.", "url": "https://arxiv.org/abs/2307.00149"}, {"metadata": {"arXiv": "2307.00213", "Date": "Sat, 01 Jul 2023 03:31:30 ", "Title": "More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data", "Authors": ["Andrew Kean Gao"], "Categories": "cs.CV cs.LG", "Comments": ["9 pages", "4 figures", "2 tables"], "MSC-class": "I.4.9, I.2.10"}, "abstract": "Transformers are very powerful tools for a variety of tasks across domains, from text generation to image captioning. However, transformers require substantial amounts of training data, which is often a challenge in biomedical settings, where high quality labeled data can be challenging or expensive to obtain. This study investigates the efficacy of Compact Convolutional Transformers (CCT) for robust medical image classification with limited data, addressing a key issue faced by conventional Vision Transformers - their requirement for large datasets. A hybrid of transformers and convolutional layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed a benchmark dataset of peripheral blood cell images of eight distinct cell types, each represented by approximately 2,000 low-resolution (28x28x3 pixel) samples. Despite the dataset size being smaller than those typically used with Vision Transformers, we achieved a commendable classification accuracy of 92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly, exceeding 80% validation accuracy after five epochs. Analysis of per-class precision, recall, F1, and ROC showed that performance was strong across cell types. Our findings underscore the robustness of CCTs, indicating their potential as a solution to data scarcity issues prevalent in biomedical imaging. We substantiate the applicability of CCTs in data-constrained areas and encourage further work on CCTs.", "url": "https://arxiv.org/abs/2307.00213"}, {"metadata": {"arXiv": "2307.00226", "Date": "Sat, 01 Jul 2023 05:02:46 ", "Title": "S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture", "Authors": ["Ye Xue", "Diego Klabjan", "Jean Utke"], "Categories": "cs.CV cs.LG"}, "abstract": "Multimodal multitask learning has attracted an increasing interest in recent years. Singlemodal models have been advancing rapidly and have achieved astonishing results on various tasks across multiple domains. Multimodal learning offers opportunities for further improvements by integrating data from multiple modalities. Many methods are proposed to learn on a specific type of multimodal data, such as vision and language data. A few of them are designed to handle several modalities and tasks at a time. In this work, we extend and improve Omninet, an architecture that is capable of handling multiple modalities and tasks at a time, by introducing cross-cache attention, integrating patch embeddings for vision inputs, and supporting structured data. The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model that is capable of learning from structured data of various dimensions effectively with unstructured data through cross-cache attention, which enables interactions among spatial, temporal, and structured features. We also enhance spatial representations in a spatial cache with patch embeddings. We evaluate the proposed model on several multimodal datasets and demonstrate a significant improvement over the baseline, Omninet.", "url": "https://arxiv.org/abs/2307.00226"}, {"metadata": {"arXiv": "2307.00290", "Date": "Sat, 01 Jul 2023 10:12:46 ", "Title": "All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning", "Authors": ["Can Cui", "Ruining Deng", "Quan Liu", "Tianyuan Yao", "Shunxing Bao", "Lucas W. Remedios", "Yucheng Tang", "Yuankai Huo"], "Categories": "cs.CV cs.LG"}, "abstract": "The Segment Anything Model (SAM) is a recently proposed prompt-based segmentation model in a generic zero-shot segmentation approach. With the zero-shot segmentation capacity, SAM achieved impressive flexibility and precision on various segmentation tasks. However, the current pipeline requires manual prompts during the inference stage, which is still resource intensive for biomedical image segmentation. In this paper, instead of using prompts during the inference stage, we introduce a pipeline that utilizes the SAM, called all-in-SAM, through the entire AI development workflow (from annotation generation to model finetuning) without requiring manual prompts during the inference stage. Specifically, SAM is first employed to generate pixel-level annotations from weak prompts (e.g., points, bounding box). Then, the pixel-level annotations are used to finetune the SAM segmentation model rather than training from scratch. Our experimental results reveal two key findings: 1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a nuclei segmentation task on the public Monuseg dataset, and 2) the utilization of weak and few annotations for SAM finetuning achieves competitive performance compared to using strong pixel-wise annotated data.", "url": "https://arxiv.org/abs/2307.00290"}, {"metadata": {"arXiv": "2307.00309", "Date": "Sat, 01 Jul 2023 11:46:36 ", "Title": "Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey", "Authors": ["Hanieh Naderi and Ivan V. Baji\\'c"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Deep learning has successfully solved a wide range of tasks in 2D vision as a dominant AI technique. Recently, deep learning on 3D point clouds is becoming increasingly popular for addressing various tasks in this field. Despite remarkable achievements, deep learning algorithms are vulnerable to adversarial attacks. These attacks are imperceptible to the human eye but can easily fool deep neural networks in the testing and deployment stage. To encourage future research, this survey summarizes the current progress on adversarial attack and defense techniques on point cloud classification. This paper first introduces the principles and characteristics of adversarial attacks and summarizes and analyzes the adversarial example generation methods in recent years. Besides, it classifies defense strategies as input transformation, data optimization, and deep model modification. Finally, it presents several challenging issues and future research directions in this domain.", "url": "https://arxiv.org/abs/2307.00309"}, {"metadata": {"arXiv": "2307.00324", "Date": "Sat, 01 Jul 2023 12:30:58 ", "Title": "DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum", "Authors": ["Kishore Babu Nampalle", "Pradeep Singh", "Uppala Vivek Narayan", "Balasubramanian Raman"], "Categories": "cs.CV cs.LG", "Comments": ["23 pages", "3 figures", "4 tables", "1 algorithm"], "ACM-class": "I.2.1"}, "abstract": "In the rapidly evolving landscape of medical imaging diagnostics, achieving high accuracy while preserving computational efficiency remains a formidable challenge. This work presents \\texttt{DeepMediX}, a groundbreaking, resource-efficient model that significantly addresses this challenge. Built on top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI scans and skin cancer images, with superior performance demonstrated on both binary and multiclass skin cancer datasets. It provides a solution to labor-intensive manual processes, the need for large datasets, and complexities related to image properties. DeepMediX's design also includes the concept of Federated Learning, enabling a collaborative learning approach without compromising data privacy. This approach allows diverse healthcare institutions to benefit from shared learning experiences without the necessity of direct data access, enhancing the model's predictive power while preserving the privacy and integrity of sensitive patient data. Its low computational footprint makes DeepMediX suitable for deployment on handheld devices, offering potential for real-time diagnostic support. Through rigorous testing on standard datasets, including the ISIC2018 for dermatological research, DeepMediX demonstrates exceptional diagnostic capabilities, matching the performance of existing models on almost all tasks and even outperforming them in some cases. The findings of this study underline significant implications for the development and deployment of AI-based tools in medical imaging and their integration into point-of-care settings. The source code and models generated would be released at https://github.com/kishorebabun/DeepMediX.", "url": "https://arxiv.org/abs/2307.00324"}, {"metadata": {"arXiv": "2307.00395", "Date": "Sat, 01 Jul 2023 17:49:12 ", "Title": "MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications", "Authors": ["Mustafa Munir", "William Avery", "Radu Marculescu"], "Categories": "cs.CV cs.LG", "Comments": ["Proceedings of the 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops"]}, "abstract": "Traditionally, convolutional neural networks (CNN) and vision transformers (ViT) have dominated computer vision. However, recently proposed vision graph neural networks (ViG) provide a new avenue for exploration. Unfortunately, for mobile applications, ViGs are computationally expensive due to the overhead of representing images as graph structures. In this work, we propose a new graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA), that is designed for ViGs running on mobile devices. Additionally, we propose the first hybrid CNN-GNN architecture for vision tasks on mobile devices, MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats existing ViG models and existing mobile CNN and ViT architectures in terms of accuracy and/or speed on image classification, object detection, and instance segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU (compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7% top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model, MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is faster and more accurate than the similarly sized EfficientFormer-L3 model (2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN architectures can be a new avenue of exploration for designing models that are extremely fast and accurate on mobile devices. Our code is publicly available at https://github.com/SLDGroup/MobileViG.", "url": "https://arxiv.org/abs/2307.00395"}, {"metadata": {"arXiv": "2307.00438", "Date": "Sat, 01 Jul 2023 23:20:38 ", "Title": "One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale", "Authors": ["Pranav Kulkarni", "Adway Kanhere", "Eliot Siegel", "Paul H. Yi", "Vishwa S. Parekh"], "Categories": "cs.CV cs.IR cs.LG", "Comments": ["13 pages", "4 figures", "2 tables"]}, "abstract": "Large-scale medical imaging datasets have accelerated development of artificial intelligence tools for clinical decision support. However, the large size of these datasets is a bottleneck for users with limited storage and bandwidth. Many users may not even require such large datasets as AI models are often trained on lower resolution images. If users could directly download at their desired resolution, storage and bandwidth requirements would significantly decrease. However, it is impossible to anticipate every users' requirements and impractical to store the data at multiple resolutions. What if we could store images at a single resolution but send them at different ones? We propose MIST, an open-source framework to operationalize progressive resolution for streaming medical images at multiple resolutions from a single high-resolution copy. We demonstrate that MIST can dramatically reduce imaging infrastructure inefficiencies for hosting and streaming medical images by >90%, while maintaining diagnostic quality for deep learning applications.", "url": "https://arxiv.org/abs/2307.00438"}, {"metadata": {"arXiv": "2307.00676", "Date": "Sun, 02 Jul 2023 22:08:24 ", "Title": "Pay Attention to the Atlas: Atlas-Guided Test-Time Adaptation Method for Robust 3D Medical Image Segmentation", "Authors": ["Jingjie Guo", "Weitong Zhang", "Matthew Sinclair", "Daniel Rueckert", "Chen Chen"], "Categories": "cs.CV cs.LG"}, "abstract": "Convolutional neural networks (CNNs) often suffer from poor performance when tested on target data that differs from the training (source) data distribution, particularly in medical imaging applications where variations in imaging protocols across different clinical sites and scanners lead to different imaging appearances. However, re-accessing source training data for unsupervised domain adaptation or labeling additional test data for model fine-tuning can be difficult due to privacy issues and high labeling costs, respectively. To solve this problem, we propose a novel atlas-guided test-time adaptation (TTA) method for robust 3D medical image segmentation, called AdaAtlas. AdaAtlas only takes one single unlabeled test sample as input and adapts the segmentation network by minimizing an atlas-based loss. Specifically, the network is adapted so that its prediction after registration is aligned with the learned atlas in the atlas space, which helps to reduce anatomical segmentation errors at test time. In addition, different from most existing TTA methods which restrict the adaptation to batch normalization blocks in the segmentation network only, we further exploit the use of channel and spatial attention blocks for improved adaptability at test time. Extensive experiments on multiple datasets from different sites show that AdaAtlas with attention blocks adapted (AdaAtlas-Attention) achieves superior performance improvements, greatly outperforming other competitive TTA methods.", "url": "https://arxiv.org/abs/2307.00676"}, {"metadata": {"arXiv": "2307.01004", "Date": "Mon, 03 Jul 2023 13:40:20 ", "Title": "Joint Coordinate Regression and Association For Multi-Person Pose Estimation, A Pure Neural Network Approach", "Authors": ["Dongyang Yu and Yunshi Xie and Wangpeng An and Li Zhang and Yufeng Yao"], "Categories": "cs.CV cs.LG"}, "abstract": "We introduce a novel one-stage end-to-end multi-person 2D pose estimation algorithm, known as Joint Coordinate Regression and Association (JCRA), that produces human pose joints and associations without requiring any post-processing. The proposed algorithm is fast, accurate, effective, and simple. The one-stage end-to-end network architecture significantly improves the inference speed of JCRA. Meanwhile, we devised a symmetric network structure for both the encoder and decoder, which ensures high accuracy in identifying keypoints. It follows an architecture that directly outputs part positions via a transformer network, resulting in a significant improvement in performance. Extensive experiments on the MS COCO and CrowdPose benchmarks demonstrate that JCRA outperforms state-of-the-art approaches in both accuracy and efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\\% faster at inference acceleration than previous state-of-the-art bottom-up algorithms. The code for this algorithm will be publicly available.", "url": "https://arxiv.org/abs/2307.01004"}, {"metadata": {"arXiv": "2307.01146", "Date": "Mon, 03 Jul 2023 16:37:10 ", "Title": "AVSegFormer: Audio-Visual Segmentation with Transformer", "Authors": ["Shengyi Gao", "Zhe Chen", "Guo Chen", "Wenhai Wang", "Tong Lu"], "Categories": "cs.CV cs.LG cs.SD eess.AS", "Comments": ["9 pages", "7 figures"]}, "abstract": "The combination of audio and vision has long been a topic of interest in the multi-modal community. Recently, a new audio-visual segmentation (AVS) task has been introduced, aiming to locate and segment the sounding objects in a given video. This task demands audio-driven pixel-level scene understanding for the first time, posing significant challenges. In this paper, we propose AVSegFormer, a novel framework for AVS tasks that leverages the transformer architecture. Specifically, we introduce audio queries and learnable queries into the transformer decoder, enabling the network to selectively attend to interested visual features. Besides, we present an audio-visual mixer, which can dynamically adjust visual features by amplifying relevant and suppressing irrelevant spatial channels. Additionally, we devise an intermediate mask loss to enhance the supervision of the decoder, encouraging the network to produce more accurate intermediate predictions. Extensive experiments demonstrate that AVSegFormer achieves state-of-the-art results on the AVS benchmark. The code is available at https://github.com/vvvb-github/AVSegFormer.", "url": "https://arxiv.org/abs/2307.01146"}, {"metadata": {"arXiv": "2307.00035", "Date": "Fri, 30 Jun 2023 07:17:19 ", "Title": "Parameter Identification for Partial Differential Equations with Spatiotemporal Varying Coefficients", "Authors": ["Guangtao Zhang and Yiting Duan and Guanyu Pan and Qijing Chen and Huiyu Yang and Zhikun Zhang"], "Categories": "cs.LG"}, "abstract": "To comprehend complex systems with multiple states, it is imperative to reveal the identity of these states by system outputs. Nevertheless, the mathematical models describing these systems often exhibit nonlinearity so that render the resolution of the parameter inverse problem from the observed spatiotemporal data a challenging endeavor. Starting from the observed data obtained from such systems, we propose a novel framework that facilitates the investigation of parameter identification for multi-state systems governed by spatiotemporal varying parametric partial differential equations. Our framework consists of two integral components: a constrained self-adaptive physics-informed neural network, encompassing a sub-network, as our methodology for parameter identification, and a finite mixture model approach to detect regions of probable parameter variations. Through our scheme, we can precisely ascertain the unknown varying parameters of the complex multi-state system, thereby accomplishing the inversion of the varying parameters. Furthermore, we have showcased the efficacy of our framework on two numerical cases: the 1D Burgers' equation with time-varying parameters and the 2D wave equation with a space-varying parameter.", "url": "https://arxiv.org/abs/2307.00035"}, {"metadata": {"arXiv": "2307.00036", "Date": "Fri, 30 Jun 2023 08:47:27 ", "Title": "Machine learning for potion development at Hogwarts", "Authors": ["Christoph F. Kurz", "Adriana N. K\\\"onig"], "Categories": "cs.LG q-bio.OT"}, "abstract": "Objective: To determine whether machine learning methods can generate useful potion recipes for research and teaching at Hogwarts School of Witchcraft and Wizardry. Design: Using deep neural networks to classify generated recipes into a standard drug classification system. Setting: Hogwarts School of Witchcraft and Wizardry. Data sources: 72 potion recipes from the Hogwarts curriculum, extracted from the Harry Potter Wiki. Results: Most generated recipes fall into the categories of psychoanaleptics and dermatologicals. The number of recipes predicted for each category reflected the number of training recipes. Predicted probabilities were often above 90% but some recipes were classified into 2 or more categories with similar probabilities which complicates anticipating the predicted effects. Conclusions: Machine learning powered methods are able to generate potentially useful potion recipes for teaching and research at Hogwarts. This corresponds to similar efforts in the non-magical world where such methods have been applied to identify potentially effective drug combinations.", "url": "https://arxiv.org/abs/2307.00036"}, {"metadata": {"arXiv": "2307.00066", "Date": "Fri, 30 Jun 2023 18:12:22 ", "Title": "Improving the Transferability of Time Series Forecasting with Decomposition Adaptation", "Authors": ["Yan Gao", "Yan Wang", "Qiang Wang"], "Categories": "cs.LG", "Comments": ["15 pages", "7 figures"]}, "abstract": "Due to effective pattern mining and feature representation, neural forecasting models based on deep learning have achieved great progress. The premise of effective learning is to collect sufficient data. However, in time series forecasting, it is difficult to obtain enough data, which limits the performance of neural forecasting models. To alleviate the data scarcity limitation, we design Sequence Decomposition Adaptation Network (SeDAN) which is a novel transfer architecture to improve forecasting performance on the target domain by aligning transferable knowledge from cross-domain datasets. Rethinking the transferability of features in time series data, we propose Implicit Contrastive Decomposition to decompose the original features into components including seasonal and trend features, which are easier to transfer. Then we design the corresponding adaptation methods for decomposed features in different domains. Specifically, for seasonal features, we perform joint distribution adaptation and for trend features, we design an Optimal Local Adaptation. We conduct extensive experiments on five benchmark datasets for multivariate time series forecasting. The results demonstrate the effectiveness of our SeDAN. It can provide more efficient and stable knowledge transfer.", "url": "https://arxiv.org/abs/2307.00066"}, {"metadata": {"arXiv": "2307.00079", "Date": "Fri, 30 Jun 2023 18:33:27 ", "Title": "Dataset balancing can hurt model performance", "Authors": ["R. Channing Moore", "Daniel P. W. Ellis", "Eduardo Fonseca", "Shawn Hershey", "Aren Jansen", "Manoj Plakal"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["5 pages", "3 figures", "ICASSP 2023"], "Journal-ref": "ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Rhodes Island, Greece, 2023, pp. 1-5", "DOI": "10.1109/ICASSP49357.2023.10095255"}, "abstract": "Machine learning from training data with a skewed distribution of examples per class can lead to models that favor performance on common classes at the expense of performance on rare ones. AudioSet has a very wide range of priors over its 527 sound event classes. Classification performance on AudioSet is usually evaluated by a simple average over per-class metrics, meaning that performance on rare classes is equal in importance to the performance on common ones. Several recent papers have used dataset balancing techniques to improve performance on AudioSet. We find, however, that while balancing improves performance on the public AudioSet evaluation data it simultaneously hurts performance on an unpublished evaluation set collected under the same conditions. By varying the degree of balancing, we show that its benefits are fragile and depend on the evaluation set. We also do not find evidence indicating that balancing improves rare class performance relative to common classes. We therefore caution against blind application of balancing, as well as against paying too much attention to small improvements on a public evaluation set.", "url": "https://arxiv.org/abs/2307.00079"}, {"metadata": {"arXiv": "2307.00080", "Date": "Fri, 30 Jun 2023 18:33:45 ", "Title": "Inter-case Predictive Process Monitoring: A candidate for Quantum Machine Learning?", "Authors": ["Stefan Hill", "David Fitzek", "Patrick Delfmann", "Carl Corea"], "Categories": "cs.LG quant-ph", "Comments": ["17 pages", "6 figures", "5 appendixes"]}, "abstract": "Regardless of the domain, forecasting the future behaviour of a running process instance is a question of interest for decision makers, especially when multiple instances interact. Fostered by the recent advances in machine learning research, several methods have been proposed to predict the next activity, outcome or remaining time of a process automatically. Still, building a model with high predictive power requires both - intrinsic knowledge of how to extract meaningful features from the event log data and a model that captures complex patterns in data. This work builds upon the recent progress in inter-case Predictive Process Monitoring (PPM) and comprehensively benchmarks the impact of inter-case features on prediction accuracy. Moreover, it includes quantum machine learning models, which are expected to provide an advantage over classical models with a scaling amount of feature dimensions. The evaluation on real-world training data from the BPI challenge shows that the inter-case features provide a significant boost by more than four percent in accuracy and quantum algorithms are indeed competitive in a handful of feature configurations. Yet, as quantum hardware is still in its early stages of development, this paper critically discusses these findings in the light of runtime, noise and the risk to overfit on the training data. Finally, the implementation of an open-source plugin demonstrates the technical feasibility to connect a state-of-the-art workflow engine such as Camunda to an IBM quantum computing cloud service.", "url": "https://arxiv.org/abs/2307.00080"}, {"metadata": {"arXiv": "2307.00088", "Date": "Fri, 30 Jun 2023 19:00:04 ", "Title": "Redeeming Data Science by Decision Modelling", "Authors": ["John Mark Agosta and Robert Horton"], "Categories": "cs.LG stat.ME", "Comments": ["Accepted for the 16th Bayesian Modelling Applications Workshop (@UAI2022) (BMAW 2022)"]}, "abstract": "With the explosion of applications of Data Science, the field is has come loose from its foundations. This article argues for a new program of applied research in areas familiar to researchers in Bayesian methods in AI that are needed to ground the practice of Data Science by borrowing from AI techniques for model formulation that we term ``Decision Modelling.'' This article briefly reviews the formulation process as building a causal graphical model, then discusses the process in terms of six principles that comprise \\emph{Decision Quality}, a framework from the popular business literature. We claim that any successful applied ML modelling effort must include these six principles. We explain how Decision Modelling combines a conventional machine learning model with an explicit value model. To give a specific example we show how this is done by integrating a model's ROC curve with a utility model.", "url": "https://arxiv.org/abs/2307.00088"}, {"metadata": {"arXiv": "2307.00106", "Date": "Fri, 30 Jun 2023 19:46:20 ", "Title": "Distance Functions and Normalization Under Stream Scenarios", "Authors": ["Eduardo V. L. Barboza", "Paulo R. Lisboa de Almeida", "Alceu de Souza Britto Jr", "Rafael M. O. Cruz"], "Categories": "cs.LG", "Comments": ["Paper accepted to the 2022 International Joint Conference on Neural Networks"]}, "abstract": "Data normalization is an essential task when modeling a classification system. When dealing with data streams, data normalization becomes especially challenging since we may not know in advance the properties of the features, such as their minimum/maximum values, and these properties may change over time. We compare the accuracies generated by eight well-known distance functions in data streams without normalization, normalized considering the statistics of the first batch of data received, and considering the previous batch received. We argue that experimental protocols for streams that consider the full stream as normalized are unrealistic and can lead to biased and poor results. Our results indicate that using the original data stream without applying normalization, and the Canberra distance, can be a good combination when no information about the data stream is known beforehand.", "url": "https://arxiv.org/abs/2307.00106"}, {"metadata": {"arXiv": "2307.00134", "Date": "Fri, 30 Jun 2023 20:56:38 ", "Title": "Generalization Limits of Graph Neural Networks in Identity Effects Learning", "Authors": ["Giuseppe Alessio D'Inverno and Simone Brugiapaglia and Mirco Ravanelli"], "Categories": "cs.LG", "Comments": ["13 pages", "10 figures"]}, "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for data-driven learning on various graph domains. They are usually based on a message-passing mechanism and have gained increasing popularity for their intuitive formulation, which is closely linked to the Weisfeiler-Lehman (WL) test for graph isomorphism to which they have been proven equivalent in terms of expressive power. In this work, we establish new generalization properties and fundamental limits of GNNs in the context of learning so-called identity effects, i.e., the task of determining whether an object is composed of two identical components or not. Our study is motivated by the need to understand the capabilities of GNNs when performing simple cognitive tasks, with potential applications in computational linguistics and chemistry. We analyze two case studies: (i) two-letters words, for which we show that GNNs trained via stochastic gradient descent are unable to generalize to unseen letters when utilizing orthogonal encodings like one-hot representations; (ii) dicyclic graphs, i.e., graphs composed of two cycles, for which we present positive existence results leveraging the connection between GNNs and the WL test. Our theoretical analysis is supported by an extensive numerical study.", "url": "https://arxiv.org/abs/2307.00134"}, {"metadata": {"arXiv": "2307.00141", "Date": "Fri, 30 Jun 2023 21:20:04 ", "Title": "Risk-sensitive Actor-free Policy via Convex Optimization", "Authors": ["Ruoqi Zhang", "Jens Sj\\\"olund"], "Categories": "cs.LG", "Comments": ["Accepted by The IJCAI-2023 AlSafety and SafeRL Joint Workshop"]}, "abstract": "Traditional reinforcement learning methods optimize agents without considering safety, potentially resulting in unintended consequences. In this paper, we propose an optimal actor-free policy that optimizes a risk-sensitive criterion based on the conditional value at risk. The risk-sensitive objective function is modeled using an input-convex neural network ensuring convexity with respect to the actions and enabling the identification of globally optimal actions through simple gradient-following methods. Experimental results demonstrate the efficacy of our approach in maintaining effective risk control.", "url": "https://arxiv.org/abs/2307.00141"}, {"metadata": {"arXiv": "2307.00142", "Date": "Fri, 30 Jun 2023 21:26:24 ", "Title": "BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting", "Authors": ["Patrick Emami", "Abhijeet Sahu", "Peter Graf"], "Categories": "cs.LG", "Comments": ["32 pages. Code available at https://github.com/NREL/BuildingsBench/ and data available at https://data.openei.org/submissions/5859"]}, "abstract": "Short-term forecasting of residential and commercial building energy consumption is widely used in power systems and continues to grow in importance. Data-driven short-term load forecasting (STLF), although promising, has suffered from a lack of open, large-scale datasets with high building diversity. This has hindered exploring the pretrain-then-finetune paradigm for STLF. To help address this, we present BuildingsBench, which consists of 1) Buildings-900K, a large-scale dataset of 900K simulated buildings representing the U.S. building stock, and 2) an evaluation platform with over 1,900 real residential and commercial buildings from 7 open datasets. BuildingsBench benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model is evaluated on unseen buildings without fine-tuning, and transfer learning, where a pretrained model is fine-tuned on a target building. The main finding of our benchmark analysis is that synthetically pretrained models generalize surprisingly well to real commercial buildings. An exploration of the effect of increasing dataset size and diversity on zero-shot commercial building performance reveals a power-law with diminishing returns. We also show that fine-tuning pretrained models on real commercial and residential buildings improves performance for a majority of target buildings. We hope that BuildingsBench encourages and facilitates future research on generalizable STLF. All datasets and code can be accessed from \\url{https://github.com/NREL/BuildingsBench}.", "url": "https://arxiv.org/abs/2307.00142"}, {"metadata": {"arXiv": "2307.00144", "Date": "Fri, 30 Jun 2023 21:32:32 ", "Title": "Abide by the Law and Follow the Flow: Conservation Laws for Gradient Flows", "Authors": ["Sibylle Marcotte", "R\\'emi Gribonval", "Gabriel Peyr\\'e"], "Categories": "cs.LG math.OC"}, "abstract": "Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This \"implicit bias\" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of \"conservation laws\", which are maximal sets of independent quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the exact number of these quantities by performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms (implemented in SageMath) to: a) compute a family of polynomial laws; b) compute the number of (not necessarily polynomial) conservation laws. We provide showcase examples that we fully work out theoretically. Besides, applying the two algorithms confirms for a number of ReLU network architectures that all known laws are recovered by the algorithm, and that there are no other laws. Such computational tools pave the way to understanding desirable properties of optimization initialization in large machine learning models.", "url": "https://arxiv.org/abs/2307.00144"}, {"metadata": {"arXiv": "2307.00157", "Date": "Fri, 30 Jun 2023 22:25:01 ", "Title": "The Effect of Balancing Methods on Model Behavior in Imbalanced Classification Problems", "Authors": ["Adrian Stando", "Mustafa Cavus", "Przemys{\\l}aw Biecek"], "Categories": "cs.LG stat.ML"}, "abstract": "Imbalanced data poses a significant challenge in classification as model performance is affected by insufficient learning from minority classes. Balancing methods are often used to address this problem. However, such techniques can lead to problems such as overfitting or loss of information. This study addresses a more challenging aspect of balancing methods - their impact on model behavior. To capture these changes, Explainable Artificial Intelligence tools are used to compare models trained on datasets before and after balancing. In addition to the variable importance method, this study uses the partial dependence profile and accumulated local effects techniques. Real and simulated datasets are tested, and an open-source Python package edgaro is developed to facilitate this analysis. The results obtained show significant changes in model behavior due to balancing methods, which can lead to biased models toward a balanced distribution. These findings confirm that balancing analysis should go beyond model performance comparisons to achieve higher reliability of machine learning models. Therefore, we propose a new method performance gain plot for informed data balancing strategy to make an optimal selection of balancing method by analyzing the measure of change in model behavior versus performance gain.", "url": "https://arxiv.org/abs/2307.00157"}, {"metadata": {"arXiv": "2307.00168", "Date": "Fri, 30 Jun 2023 23:05:26 ", "Title": "U-Calibration: Forecasting for an Unknown Agent", "Authors": ["Robert Kleinberg", "Renato Paes Leme", "Jon Schneider", "Yifeng Teng"], "Categories": "cs.LG cs.GT", "Comments": ["Accepted for presentation at the Conference on Learning Theory (COLT) 2023"]}, "abstract": "We consider the problem of evaluating forecasts of binary events whose predictions are consumed by rational agents who take an action in response to a prediction, but whose utility is unknown to the forecaster. We show that optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot guarantee low regret for all possible agents. In contrast, forecasts that are well-calibrated guarantee that all agents incur sublinear regret. However, calibration is not a necessary criterion here (it is possible for miscalibrated forecasts to provide good regret guarantees for all possible agents), and calibrated forecasting procedures have provably worse convergence rates than forecasting procedures targeting a single scoring rule. Motivated by this, we present a new metric for evaluating forecasts that we call U-calibration, equal to the maximal regret of the sequence of forecasts when evaluated under any bounded scoring rule. We show that sublinear U-calibration error is a necessary and sufficient condition for all agents to achieve sublinear regret guarantees. We additionally demonstrate how to compute the U-calibration error efficiently and provide an online algorithm that achieves $O(\\sqrt{T})$ U-calibration error (on par with optimal rates for optimizing for a single scoring rule, and bypassing lower bounds for the traditionally calibrated learning procedures). Finally, we discuss generalizations to the multiclass prediction setting.", "url": "https://arxiv.org/abs/2307.00168"}, {"metadata": {"arXiv": "2307.00222", "Date": "Sat, 01 Jul 2023 04:44:43 ", "Title": "Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals", "Authors": ["Tingting Dan and Jiaqi Ding and Ziquan Wei and Shahar Z Kovalsky and Minjeong Kim and Won Hwa Kim and Guorong Wu"], "Categories": "cs.LG cs.GR", "Comments": ["23 papers", "10 figures"], "MSC-class": "05C85", "ACM-class": "I.2.6"}, "abstract": "Graph neural networks (GNNs) are widely used in domains like social networks and biological systems. However, the locality assumption of GNNs, which limits information exchange to neighboring nodes, hampers their ability to capture long-range dependencies and global patterns in graphs. To address this, we propose a new inductive bias based on variational analysis, drawing inspiration from the Brachistochrone problem. Our framework establishes a mapping between discrete GNN models and continuous diffusion functionals. This enables the design of application-specific objective functions in the continuous domain and the construction of discrete deep models with mathematical guarantees. To tackle over-smoothing in GNNs, we analyze the existing layer-by-layer graph embedding models and identify that they are equivalent to l2-norm integral functionals of graph gradients, which cause over-smoothing. Similar to edge-preserving filters in image denoising, we introduce total variation (TV) to align the graph diffusion pattern with global community topologies. Additionally, we devise a selective mechanism to address the trade-off between model depth and over-smoothing, which can be easily integrated into existing GNNs. Furthermore, we propose a novel generative adversarial network (GAN) that predicts spreading flows in graphs through a neural transport equation. To mitigate vanishing flows, we customize the objective function to minimize transportation within each community while maximizing inter-community flows. Our GNN models achieve state-of-the-art (SOTA) performance on popular graph learning benchmarks such as Cora, Citeseer, and Pubmed.", "url": "https://arxiv.org/abs/2307.00222"}, {"metadata": {"arXiv": "2307.00228", "Date": "Sat, 01 Jul 2023 05:23:28 ", "Title": "InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs", "Authors": ["Dalong Zhang", "Xianzheng Song", "Zhiyang Hu", "Yang Li", "Miao Tao", "Binbin Hu", "Lin Wang", "Zhiqiang Zhang", "Jun Zhou"], "Categories": "cs.LG", "Comments": ["Accepted by ICDE 2023"]}, "abstract": "GNN inference is a non-trivial task, especially in industrial scenarios with giant graphs, given three main challenges, i.e., scalability tailored for full-graph inference on huge graphs, inconsistency caused by stochastic acceleration strategies (e.g., sampling), and the serious redundant computation issue. To address the above challenges, we propose a scalable system named InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired by the philosophy of ``think-like-a-vertex\", a GAS-like (Gather-Apply-Scatter) schema is proposed to describe the computation paradigm and data flow of GNN inference. The computation of GNNs is expressed in an iteration manner, in which a vertex would gather messages via in-edges and update its state information by forwarding an associated layer of GNNs with those messages and then send the updated information to other vertexes via out-edges. Following the schema, the proposed InferTurbo can be built with alternative backends (e.g., batch processing system or graph computing system). Moreover, InferTurbo introduces several strategies like shadow-nodes and partial-gather to handle nodes with large degrees for better load balancing. With InferTurbo, GNN inference can be hierarchically conducted over the full graph without sampling and redundant computation. Experimental results demonstrate that our system is robust and efficient for inference tasks over graphs containing some hub nodes with many adjacent edges. Meanwhile, the system gains a remarkable performance compared with the traditional inference pipeline, and it can finish a GNN inference task over a graph with tens of billions of nodes and hundreds of billions of edges within 2 hours.", "url": "https://arxiv.org/abs/2307.00228"}, {"metadata": {"arXiv": "2307.00233", "Date": "Sat, 01 Jul 2023 05:45:23 ", "Title": "Hierarchical Federated Learning Incentivization for Gas Usage Estimation", "Authors": ["Has Sun", "Xiaoli Tang", "Chengyi Yang", "Zhenpeng Yu", "Xiuli Wang", "Qijie Ding", "Zengxiang Li", "Han Yu"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "Accurately estimating gas usage is essential for the efficient functioning of gas distribution networks and saving operational costs. Traditional methods rely on centralized data processing, which poses privacy risks. Federated learning (FL) offers a solution to this problem by enabling local data processing on each participant, such as gas companies and heating stations. However, local training and communication overhead may discourage gas companies and heating stations from actively participating in the FL training process. To address this challenge, we propose a Hierarchical FL Incentive Mechanism for Gas Usage Estimation (HI-GAS), which has been testbedded in the ENN Group, one of the leading players in the natural gas and green energy industry. It is designed to support horizontal FL among gas companies, and vertical FL among each gas company and heating station within a hierarchical FL ecosystem, rewarding participants based on their contributions to FL. In addition, a hierarchical FL model aggregation approach is also proposed to improve the gas usage estimation performance by aggregating models at different levels of the hierarchy. The incentive scheme employs a multi-dimensional contribution-aware reward distribution function that combines the evaluation of data quality and model contribution to incentivize both gas companies and heating stations within their jurisdiction while maintaining fairness. Results of extensive experiments validate the effectiveness of the proposed mechanism.", "url": "https://arxiv.org/abs/2307.00233"}, {"metadata": {"arXiv": "2307.00268", "Date": "Sat, 01 Jul 2023 08:19:56 ", "Title": "Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning", "Authors": ["Md Tamjid Hossain", "Hung La"], "Categories": "cs.LG cs.CR cs.MA", "Comments": ["Accepted for publication in the proceeding of ICMLC 2023", "9-11 July 2023", "The University of Adelaide", "Adelaide", "Australia"], "Report-no": "Paper ID: 3053"}, "abstract": "Lately, differential privacy (DP) has been introduced in cooperative multiagent reinforcement learning (CMARL) to safeguard the agents' privacy against adversarial inference during knowledge sharing. Nevertheless, we argue that the noise introduced by DP mechanisms may inadvertently give rise to a novel poisoning threat, specifically in the context of private knowledge sharing during CMARL, which remains unexplored in the literature. To address this shortcoming, we present an adaptive, privacy-exploiting, and evasion-resilient localized poisoning attack (PeLPA) that capitalizes on the inherent DP-noise to circumvent anomaly detection systems and hinder the optimal convergence of the CMARL model. We rigorously evaluate our proposed PeLPA attack in diverse environments, encompassing both non-adversarial and multiple-adversarial contexts. Our findings reveal that, in a medium-scale environment, the PeLPA attack with attacker ratios of 20% and 40% can lead to an increase in average steps to goal by 50.69% and 64.41%, respectively. Furthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x computational time increase in optimal reward attainment and a 1.18x and 1.38x slower convergence for attacker ratios of 20% and 40%, respectively.", "url": "https://arxiv.org/abs/2307.00268"}, {"metadata": {"arXiv": "2307.00274", "Date": "Sat, 01 Jul 2023 09:07:12 ", "Title": "Common Knowledge Learning for Generating Transferable Adversarial Examples", "Authors": ["Ruijie Yang", "Yuanfang Guo", "Junfu Wang", "Jiantao Zhou and Yunhong Wang"], "Categories": "cs.LG cs.CV", "Comments": ["11 pages", "5 figures"]}, "abstract": "This paper focuses on an important type of black-box attacks, i.e., transfer-based adversarial attacks, where the adversary generates adversarial examples by a substitute (source) model and utilize them to attack an unseen target model, without knowing its information. Existing methods tend to give unsatisfactory adversarial transferability when the source and target models are from different types of DNN architectures (e.g. ResNet-18 and Swin Transformer). In this paper, we observe that the above phenomenon is induced by the output inconsistency problem. To alleviate this problem while effectively utilizing the existing DNN models, we propose a common knowledge learning (CKL) framework to learn better network weights to generate adversarial examples with better transferability, under fixed network architectures. Specifically, to reduce the model-specific features and obtain better output distributions, we construct a multi-teacher framework, where the knowledge is distilled from different teacher architectures into one student network. By considering that the gradient of input is usually utilized to generated adversarial examples, we impose constraints on the gradients between the student and teacher models, to further alleviate the output inconsistency problem and enhance the adversarial transferability. Extensive experiments demonstrate that our proposed work can significantly improve the adversarial transferability.", "url": "https://arxiv.org/abs/2307.00274"}, {"metadata": {"arXiv": "2307.00285", "Date": "Sat, 01 Jul 2023 09:46:59 ", "Title": "Assembled-OpenML: Creating Efficient Benchmarks for Ensembles in AutoML with OpenML", "Authors": ["Lennart Purucker", "Joeran Beel"], "Categories": "cs.LG", "Comments": ["5 pages main paper", "13 pages references and appendix", "2 figures", "1 table", "poster presented at: International Conference on Automated Machine Learning 2022", "Workshop Track"], "ACM-class": "E.m; I.2.6"}, "abstract": "Automated Machine Learning (AutoML) frameworks regularly use ensembles. Developers need to compare different ensemble techniques to select appropriate techniques for an AutoML framework from the many potential techniques. So far, the comparison of ensemble techniques is often computationally expensive, because many base models must be trained and evaluated one or multiple times. Therefore, we present Assembled-OpenML. Assembled-OpenML is a Python tool, which builds meta-datasets for ensembles using OpenML. A meta-dataset, called Metatask, consists of the data of an OpenML task, the task's dataset, and prediction data from model evaluations for the task. We can make the comparison of ensemble techniques computationally cheaper by using the predictions stored in a metatask instead of training and evaluating base models. To introduce Assembled-OpenML, we describe the first version of our tool. Moreover, we present an example of using Assembled-OpenML to compare a set of ensemble techniques. For this example comparison, we built a benchmark using Assembled-OpenML and implemented ensemble techniques expecting predictions instead of base models as input. In our example comparison, we gathered the prediction data of $1523$ base models for $31$ datasets. Obtaining the prediction data for all base models using Assembled-OpenML took ${\\sim} 1$ hour in total. In comparison, obtaining the prediction data by training and evaluating just one base model on the most computationally expensive dataset took ${\\sim} 37$ minutes.", "url": "https://arxiv.org/abs/2307.00285"}, {"metadata": {"arXiv": "2307.00286", "Date": "Sat, 01 Jul 2023 09:47:59 ", "Title": "CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable Failure", "Authors": ["Lennart Purucker", "Joeran Beel"], "Categories": "cs.LG cs.NE", "Comments": ["10 pages main paper", "13 pages references and appendix", "4 figures", "14 subfigures", "10 tables", "to be published in: International Conference on Automated Machine Learning 2023"], "ACM-class": "I.2.6; I.5.1"}, "abstract": "Many state-of-the-art automated machine learning (AutoML) systems use greedy ensemble selection (GES) by Caruana et al. (2004) to ensemble models found during model selection post hoc. Thereby, boosting predictive performance and likely following Auto-Sklearn 1's insight that alternatives, like stacking or gradient-free numerical optimization, overfit. Overfitting in Auto-Sklearn 1 is much more likely than in other AutoML systems because it uses only low-quality validation data for post hoc ensembling. Therefore, we were motivated to analyze whether Auto-Sklearn 1's insight holds true for systems with higher-quality validation data. Consequently, we compared the performance of covariance matrix adaptation evolution strategy (CMA-ES), state-of-the-art gradient-free numerical optimization, to GES on the 71 classification datasets from the AutoML benchmark for AutoGluon. We found that Auto-Sklearn's insight depends on the chosen metric. For the metric ROC AUC, CMA-ES overfits drastically and is outperformed by GES -- statistically significantly for multi-class classification. For the metric balanced accuracy, CMA-ES does not overfit and outperforms GES significantly. Motivated by the successful application of CMA-ES for balanced accuracy, we explored methods to stop CMA-ES from overfitting for ROC AUC. We propose a method to normalize the weights produced by CMA-ES, inspired by GES, that avoids overfitting for CMA-ES and makes CMA-ES perform better than or similar to GES for ROC AUC.", "url": "https://arxiv.org/abs/2307.00286"}, {"metadata": {"arXiv": "2307.00305", "Date": "Sat, 01 Jul 2023 11:28:43 ", "Title": "Applied Bayesian Structural Health Monitoring: inclinometer data anomaly detection and forecasting", "Authors": ["David K. E. Green", "Adam Jaspan"], "Categories": "cs.LG stat.ML", "Comments": ["6 Pages. Conference proceedings from GAMM23"]}, "abstract": "Inclinometer probes are devices that can be used to measure deformations within earthwork slopes. This paper demonstrates a novel application of Bayesian techniques to real-world inclinometer data, providing both anomaly detection and forecasting. Specifically, this paper details an analysis of data collected from inclinometer data across the entire UK rail network. Practitioners have effectively two goals when processing monitoring data. The first is to identify any anomalous or dangerous movements, and the second is to predict potential future adverse scenarios by forecasting. In this paper we apply Uncertainty Quantification (UQ) techniques by implementing a Bayesian approach to anomaly detection and forecasting for inclinometer data. Subsequently, both costs and risks may be minimised by quantifying and evaluating the appropriate uncertainties. This framework may then act as an enabler for enhanced decision making and risk analysis. We show that inclinometer data can be described by a latent autocorrelated Markov process derived from measurements. This can be used as the transition model of a non-linear Bayesian filter. This allows for the prediction of system states. This learnt latent model also allows for the detection of anomalies: observations that are far from their expected value may be considered to have `high surprisal', that is they have a high information content relative to the model encoding represented by the learnt latent model. We successfully apply the forecasting and anomaly detection techniques to a large real-world data set in a computationally efficient manner. Although this paper studies inclinometers in particular, the techniques are broadly applicable to all areas of engineering UQ and Structural Health Monitoring (SHM).", "url": "https://arxiv.org/abs/2307.00305"}, {"metadata": {"arXiv": "2307.00337", "Date": "Sat, 01 Jul 2023 13:33:03 ", "Title": "Recursive Algorithmic Reasoning", "Authors": ["Dulhan Jayalath", "Jonas J\\\"ur{\\ss}", "Petar Veli\\v{c}kovi\\'c"], "Categories": "cs.LG", "Comments": ["11 pages", "5 figures. Accepted at the workshop on Knowledge and Logical Reasoning in the Era of Data-Driven Learning at ICML 2023"]}, "abstract": "Learning models that execute algorithms can enable us to address a key problem in deep learning: generalizing to out-of-distribution data. However, neural networks are currently unable to execute recursive algorithms because they do not have arbitrarily large memory to store and recall state. To address this, we (1) propose a way to augment graph neural networks (GNNs) with a stack, and (2) develop an approach for capturing intermediate algorithm trajectories that improves algorithmic alignment with recursive algorithms over previous methods. The stack allows the network to learn to store and recall a portion of the state of the network at a particular time, analogous to the action of a call stack in a recursive algorithm. This augmentation permits the network to reason recursively. We empirically demonstrate that our proposals significantly improve generalization to larger input graphs over prior work on depth-first search (DFS).", "url": "https://arxiv.org/abs/2307.00337"}, {"metadata": {"arXiv": "2307.00356", "Date": "Sat, 01 Jul 2023 15:01:03 ", "Title": "Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data", "Authors": ["Zekai Chen", "Fuyi Wang", "Zhiwei Zheng", "Ximeng Liu", "Yujie Lin"], "Categories": "cs.LG cs.CR", "Comments": ["Accepted by IEEE ICME 2023"]}, "abstract": "Federated learning (FL) enables multiple clients to collaboratively train deep learning models while considering sensitive local datasets' privacy. However, adversaries can manipulate datasets and upload models by injecting triggers for federated backdoor attacks (FBA). Existing defense strategies against FBA consider specific and limited attacker models, and a sufficient amount of noise to be injected only mitigates rather than eliminates FBA. To address these deficiencies, we introduce a Flexible Federated Backdoor Defense Framework (Fedward) to ensure the elimination of adversarial backdoors. We decompose FBA into various attacks, and design amplified magnitude sparsification (AmGrad) and adaptive OPTICS clustering (AutoOPTICS) to address each attack. Meanwhile, Fedward uses the adaptive clipping method by regarding the number of samples in the benign group as constraints on the boundary. This ensures that Fedward can maintain the performance for the Non-IID scenario. We conduct experimental evaluations over three benchmark datasets and thoroughly compare them to state-of-the-art studies. The results demonstrate the promising defense performance from Fedward, moderately improved by 33% $\\sim$ 75 in clustering defense methods, and 96.98%, 90.74%, and 89.8% for Non-IID to the utmost extent for the average FBA success rate over MNIST, FMNIST, and CIFAR10, respectively.", "url": "https://arxiv.org/abs/2307.00356"}, {"metadata": {"arXiv": "2307.00365", "Date": "Sat, 01 Jul 2023 15:26:08 ", "Title": "Understanding recent deep-learning techniques for identifying collective variables of molecular dynamics", "Authors": ["Wei Zhang", "Christof Sch\\\"utte"], "Categories": "cs.LG math.OC", "Comments": ["16 pages"]}, "abstract": "The dynamics of a high-dimensional metastable molecular system can often be characterised by a few features of the system, i.e. collective variables (CVs). Thanks to the rapid advance in the area of machine learning, various deep learning-based CV identification techniques have been developed in recent years, allowing accurate modelling and efficient simulation of complex molecular systems. In this paper, we look at two different categories of deep learning-based approaches for finding CVs, either by computing leading eigenfunctions of infinitesimal generator or transfer operator associated to the underlying dynamics, or by learning an autoencoder via minimisation of reconstruction error. We present a concise overview of the mathematics behind these two approaches and conduct a comparative numerical study of these two approaches on illustrative examples.", "url": "https://arxiv.org/abs/2307.00365"}, {"metadata": {"arXiv": "2307.00379", "Date": "Sat, 01 Jul 2023 16:29:55 ", "Title": "Residual-based attention and connection to information bottleneck theory in PINNs", "Authors": ["Sokratis J. Anagnostopoulos", "Juan Diego Toscano", "Nikolaos Stergiopulos", "George Em Karniadakis"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Driven by the need for more efficient and seamless integration of physical models and data, physics-informed neural networks (PINNs) have seen a surge of interest in recent years. However, ensuring the reliability of their convergence and accuracy remains a challenge. In this work, we propose an efficient, gradient-less weighting scheme for PINNs, that accelerates the convergence of dynamic or static systems. This simple yet effective attention mechanism is a function of the evolving cumulative residuals and aims to make the optimizer aware of problematic regions at no extra computational cost or adversarial learning. We illustrate that this general method consistently achieves a relative $L^{2}$ error of the order of $10^{-5}$ using standard optimizers on typical benchmark cases of the literature. Furthermore, by investigating the evolution of weights during training, we identify two distinct learning phases reminiscent of the fitting and diffusion phases proposed by the information bottleneck (IB) theory. Subsequent gradient analysis supports this hypothesis by aligning the transition from high to low signal-to-noise ratio (SNR) with the transition from fitting to diffusion regimes of the adopted weights. This novel correlation between PINNs and IB theory could open future possibilities for understanding the underlying mechanisms behind the training and stability of PINNs and, more broadly, of neural operators.", "url": "https://arxiv.org/abs/2307.00379"}, {"metadata": {"arXiv": "2307.00405", "Date": "Sat, 01 Jul 2023 18:35:21 ", "Title": "Provably Efficient UCB-type Algorithms For Learning Predictive State Representations", "Authors": ["Ruiquan Huang", "Yingbin Liang", "Jing Yang"], "Categories": "cs.LG stat.ML"}, "abstract": "The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the total variation distance between the estimated and true models. We further characterize the sample complexity bounds for our designed UCB-type algorithms for both online and offline PSRs. In contrast to existing approaches for PSRs, our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed near-optimal policy, and guaranteed model accuracy.", "url": "https://arxiv.org/abs/2307.00405"}, {"metadata": {"arXiv": "2307.00444", "Date": "Sat, 01 Jul 2023 23:59:23 ", "Title": "An Adaptive Optimization Approach to Personalized Financial Incentives in Mobile Behavioral Weight Loss Interventions", "Authors": ["Qiaomei Li", "Yonatan Mintz", "Kara Gavin", "Corrine Voils"], "Categories": "cs.LG math.OC", "Comments": ["48 pages", "5 figures"]}, "abstract": "Obesity is a critical healthcare issue affecting the United States. The least risky treatments available for obesity are behavioral interventions meant to promote diet and exercise. Often these interventions contain a mobile component that allows interventionists to collect participants level data and provide participants with incentives and goals to promote long term behavioral change. Recently, there has been interest in using direct financial incentives to promote behavior change. However, adherence is challenging in these interventions, as each participant will react differently to different incentive structure and amounts, leading researchers to consider personalized interventions. The key challenge for personalization, is that the clinicians do not know a priori how best to administer incentives to participants, and given finite intervention budgets how to disburse costly resources efficiently. In this paper, we consider this challenge of designing personalized weight loss interventions that use direct financial incentives to motivate weight loss while remaining within a budget. We create a machine learning approach that is able to predict how individuals may react to different incentive schedules within the context of a behavioral intervention. We use this predictive model in an adaptive framework that over the course of the intervention computes what incentives to disburse to participants and remain within the study budget. We provide both theoretical guarantees for our modeling and optimization approaches as well as demonstrate their performance in a simulated weight loss study. Our results highlight the cost efficiency and effectiveness of our personalized intervention design for weight loss.", "url": "https://arxiv.org/abs/2307.00444"}, {"metadata": {"arXiv": "2307.00465", "Date": "Sun, 02 Jul 2023 03:47:10 ", "Title": "Towards Unbiased Exploration in Partial Label Learning", "Authors": ["Zsolt Zombori and Agapi Rissaki and Krist\\'of Szab\\'o and Wolfgang Gatterbauer and Michael Benedikt"], "Categories": "cs.LG cs.LO"}, "abstract": "We consider learning a probabilistic classifier from partially-labelled supervision (inputs denoted with multiple possibilities) using standard neural architectures with a softmax as the final layer. We identify a bias phenomenon that can arise from the softmax layer in even simple architectures that prevents proper exploration of alternative options, making the dynamics of gradient descent overly sensitive to initialisation. We introduce a novel loss function that allows for unbiased exploration within the space of alternative outputs. We give a theoretical justification for our loss function, and provide an extensive evaluation of its impact on synthetic data, on standard partially labelled benchmarks and on a contributed novel benchmark related to an existing rule learning challenge.", "url": "https://arxiv.org/abs/2307.00465"}, {"metadata": {"arXiv": "2307.00467", "Date": "Sun, 02 Jul 2023 03:49:47 ", "Title": "MissDiff: Training Diffusion Models on Tabular Data with Missing Values", "Authors": ["Yidong Ouyang", "Liyan Xie", "Chongxuan Li", "Guang Cheng"], "Categories": "cs.LG stat.ML", "Comments": ["22 pages", "short version is accepted by ICML workshop on Structured Probabilistic Inference & Generative Modeling 2023"], "Report-no": "22"}, "abstract": "The diffusion model has shown remarkable performance in modeling data distributions and synthesizing data. However, the vanilla diffusion model requires complete or fully observed data for training. Incomplete data is a common issue in various real-world applications, including healthcare and finance, particularly when dealing with tabular datasets. This work presents a unified and principled diffusion-based framework for learning from data with missing values under various missing mechanisms. We first observe that the widely adopted \"impute-then-generate\" pipeline may lead to a biased learning objective. Then we propose to mask the regression loss of Denoising Score Matching in the training phase. We prove the proposed method is consistent in learning the score of data distributions, and the proposed training objective serves as an upper bound for the negative likelihood in certain cases. The proposed framework is evaluated on multiple tabular datasets using realistic and efficacious metrics and is demonstrated to outperform state-of-the-art diffusion model on tabular data with \"impute-then-generate\" pipeline by a large margin.", "url": "https://arxiv.org/abs/2307.00467"}, {"metadata": {"arXiv": "2307.00469", "Date": "Sun, 02 Jul 2023 04:30:20 ", "Title": "Data-Driven Probabilistic Energy Consumption Estimation for Battery Electric Vehicles with Model Uncertainty", "Authors": ["Ayan Maity", "Sudeshna Sarkar"], "Categories": "cs.LG", "Comments": ["This paper is under review at the International Journal of Green Energy"]}, "abstract": "This paper presents a novel probabilistic data-driven approach to trip-level energy consumption estimation of battery electric vehicles (BEVs). As there are very few electric vehicle (EV) charging stations, EV trip energy consumption estimation can make EV routing and charging planning easier for drivers. In this research article, we propose a new driver behaviour-centric EV energy consumption estimation model using probabilistic neural networks with model uncertainty. By incorporating model uncertainty into neural networks, we have created an ensemble of neural networks using Monte Carlo approximation. Our method comprehensively considers various vehicle dynamics, driver behaviour and environmental factors to estimate EV energy consumption for a given trip. We propose relative positive acceleration (RPA), average acceleration and average deceleration as driver behaviour factors in EV energy consumption estimation and this paper shows that the use of these driver behaviour features improves the accuracy of the EV energy consumption model significantly. Instead of predicting a single-point estimate for EV trip energy consumption, this proposed method predicts a probability distribution for the EV trip energy consumption. The experimental results of our approach show that our proposed probabilistic neural network with weight uncertainty achieves a mean absolute percentage error of 9.3% and outperforms other existing EV energy consumption models in terms of accuracy.", "url": "https://arxiv.org/abs/2307.00469"}, {"metadata": {"arXiv": "2307.00472", "Date": "Sun, 02 Jul 2023 04:44:19 ", "Title": "Equal Confusion Fairness: Measuring Group-Based Disparities in Automated Decision Systems", "Authors": ["Furkan Gursoy and Ioannis A. Kakadiaris"], "Categories": "cs.LG cs.CY", "Journal-ref": "2022 IEEE International Conference on Data Mining Workshops (ICDMW), Orlando, FL, USA, 2022, pp. 137-146", "DOI": "10.1109/ICDMW58026.2022.00027"}, "abstract": "As artificial intelligence plays an increasingly substantial role in decisions affecting humans and society, the accountability of automated decision systems has been receiving increasing attention from researchers and practitioners. Fairness, which is concerned with eliminating unjust treatment and discrimination against individuals or sensitive groups, is a critical aspect of accountability. Yet, for evaluating fairness, there is a plethora of fairness metrics in the literature that employ different perspectives and assumptions that are often incompatible. This work focuses on group fairness. Most group fairness metrics desire a parity between selected statistics computed from confusion matrices belonging to different sensitive groups. Generalizing this intuition, this paper proposes a new equal confusion fairness test to check an automated decision system for fairness and a new confusion parity error to quantify the extent of any unfairness. To further analyze the source of potential unfairness, an appropriate post hoc analysis methodology is also presented. The usefulness of the test, metric, and post hoc analysis is demonstrated via a case study on the controversial case of COMPAS, an automated decision system employed in the US to assist judges with assessing recidivism risks. Overall, the methods and metrics provided here may assess automated decision systems' fairness as part of a more extensive accountability assessment, such as those based on the system accountability benchmark.", "url": "https://arxiv.org/abs/2307.00472"}, {"metadata": {"arXiv": "2307.00498", "Date": "Sun, 02 Jul 2023 07:16:29 ", "Title": "Data-Free Quantization via Mixed-Precision Compensation without Fine-Tuning", "Authors": ["Jun Chen", "Shipeng Bai", "Tianxin Huang", "Mengmeng Wang", "Guanzhong Tian", "Yong Liu"], "Categories": "cs.LG cs.CV", "Comments": ["This paper has been accepted for publication in the Pattern Recognition"], "Journal-ref": "Pattern Recognition 2023"}, "abstract": "Neural network quantization is a very promising solution in the field of model compression, but its resulting accuracy highly depends on a training/fine-tuning process and requires the original data. This not only brings heavy computation and time costs but also is not conducive to privacy and sensitive information protection. Therefore, a few recent works are starting to focus on data-free quantization. However, data-free quantization does not perform well while dealing with ultra-low precision quantization. Although researchers utilize generative methods of synthetic data to address this problem partially, data synthesis needs to take a lot of computation and time. In this paper, we propose a data-free mixed-precision compensation (DF-MPC) method to recover the performance of an ultra-low precision quantized model without any data and fine-tuning process. By assuming the quantized error caused by a low-precision quantized layer can be restored via the reconstruction of a high-precision quantized layer, we mathematically formulate the reconstruction loss between the pre-trained full-precision model and its layer-wise mixed-precision quantized model. Based on our formulation, we theoretically deduce the closed-form solution by minimizing the reconstruction loss of the feature maps. Since DF-MPC does not require any original/synthetic data, it is a more efficient method to approximate the full-precision model. Experimentally, our DF-MPC is able to achieve higher accuracy for an ultra-low precision quantized model compared to the recent methods without any data and fine-tuning process.", "url": "https://arxiv.org/abs/2307.00498"}, {"metadata": {"arXiv": "2307.00501", "Date": "Sun, 02 Jul 2023 07:20:47 ", "Title": "Classifying World War II Era Ciphers with Machine Learning", "Authors": ["Brooke Dalton and Mark Stamp"], "Categories": "cs.LG cs.CR"}, "abstract": "We determine the accuracy with which machine learning and deep learning techniques can classify selected World War II era ciphers when only ciphertext is available. The specific ciphers considered are Enigma, M-209, Sigaba, Purple, and Typex. We experiment with three classic machine learning models, namely, Support Vector Machines (SVM), $k$-Nearest Neighbors ($k$-NN), and Random Forest (RF). We also experiment with four deep learning neural network-based models: Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM), Extreme Learning Machines (ELM), and Convolutional Neural Networks (CNN). Each model is trained on features consisting of histograms, digrams, and raw ciphertext letter sequences. Furthermore, the classification problem is considered under four distinct scenarios: Fixed plaintext with fixed keys, random plaintext with fixed keys, fixed plaintext with random keys, and random plaintext with random keys. Under the most realistic scenario, given 1000 characters per ciphertext, we are able to distinguish the ciphers with greater than 97% accuracy. In addition, we consider the accuracy of a subset of the learning techniques as a function of the length of the ciphertext messages. Somewhat surprisingly, our classic machine learning models perform at least as well as our deep learning models. We also find that ciphers that are more similar in design are somewhat more challenging to distinguish, but not as difficult as might be expected.", "url": "https://arxiv.org/abs/2307.00501"}, {"metadata": {"arXiv": "2307.00534", "Date": "Sun, 02 Jul 2023 10:03:01 ", "Title": "Shared Growth of Graph Neural Networks via Free-direction Knowledge Distillation", "Authors": ["Kaituo Feng", "Yikun Miao", "Changsheng Li", "Ye Yuan", "Guoren Wang"], "Categories": "cs.LG", "Comments": ["14 pages. arXiv admin note: substantial text overlap with arXiv:2206.06561"]}, "abstract": "Knowledge distillation (KD) has shown to be effective to boost the performance of graph neural networks (GNNs), where the typical objective is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is often quite challenging to train a satisfactory deeper GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. Our core idea is to collaboratively learn two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often exhibits better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that involves two levels of actions: 1) node-level action determines the directions of knowledge transfer between the corresponding nodes of two networks; and then 2) structure-level action determines which of the local structures generated by the node-level actions to be propagated. Furthermore, considering the diverse knowledge present in different GNNs when dealing with multi-view inputs, we introduce FreeKD++ as a solution to enable free-direction knowledge transfer among multiple shallow GNNs operating on multi-view inputs. Extensive experiments on five benchmark datasets demonstrate our approaches outperform the base GNNs in a large margin, and shows their efficacy to various GNNs. More surprisingly, our FreeKD has comparable or even better performance than traditional KD algorithms that distill knowledge from a deeper and stronger teacher GNN.", "url": "https://arxiv.org/abs/2307.00534"}, {"metadata": {"arXiv": "2307.00547", "Date": "Sun, 02 Jul 2023 11:47:21 ", "Title": "Is Risk-Sensitive Reinforcement Learning Properly Resolved?", "Authors": ["Ruiwen Zhou", "Minghuan Liu", "Kan Ren", "Xufang Luo", "Weinan Zhang", "Dongsheng Li"], "Categories": "cs.LG"}, "abstract": "Due to the nature of risk management in learning applicable policies, risk-sensitive reinforcement learning (RSRL) has been realized as an important direction. RSRL is usually achieved by learning risk-sensitive objectives characterized by various risk measures, under the framework of distributional reinforcement learning. However, it remains unclear if the distributional Bellman operator properly optimizes the RSRL objective in the sense of risk measures. In this paper, we prove that the existing RSRL methods do not achieve unbiased optimization and can not guarantee optimality or even improvements regarding risk measures over accumulated return distributions. To remedy this issue, we further propose a novel algorithm, namely Trajectory Q-Learning (TQL), for RSRL problems with provable convergence to the optimal policy. Based on our new learning architecture, we are free to introduce a general and practical implementation for different risk measures to learn disparate risk-sensitive policies. In the experiments, we verify the learnability of our algorithm and show how our method effectively achieves better performances toward risk-sensitive objectives.", "url": "https://arxiv.org/abs/2307.00547"}, {"metadata": {"arXiv": "2307.00553", "Date": "Sun, 02 Jul 2023 12:27:02 ", "Title": "Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples", "Authors": ["Shuo He", "Lei Feng", "Guowu Yang"], "Categories": "cs.LG cs.CV"}, "abstract": "Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (out-of-candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.", "url": "https://arxiv.org/abs/2307.00553"}, {"metadata": {"arXiv": "2307.00558", "Date": "Sun, 02 Jul 2023 12:52:41 ", "Title": "Conditionally Invariant Representation Learning for Disentangling Cellular Heterogeneity", "Authors": ["Hananeh Aliee", "Ferdinand Kapl", "Soroor Hediyeh-Zadeh", "Fabian J. Theis"], "Categories": "cs.LG q-bio.QM"}, "abstract": "This paper presents a novel approach that leverages domain variability to learn representations that are conditionally invariant to unwanted variability or distractors. Our approach identifies both spurious and invariant latent features necessary for achieving accurate reconstruction by placing distinct conditional priors on latent features. The invariant signals are disentangled from noise by enforcing independence which facilitates the construction of an interpretable model with a causal semantic. By exploiting the interplay between data domains and labels, our method simultaneously identifies invariant features and builds invariant predictors. We apply our method to grand biological challenges, such as data integration in single-cell genomics with the aim of capturing biological variations across datasets with many samples, obtained from different conditions or multiple laboratories. Our approach allows for the incorporation of specific biological mechanisms, including gene programs, disease states, or treatment conditions into the data integration process, bridging the gap between the theoretical assumptions and real biological applications. Specifically, the proposed approach helps to disentangle biological signals from data biases that are unrelated to the target task or the causal explanation of interest. Through extensive benchmarking using large-scale human hematopoiesis and human lung cancer data, we validate the superiority of our approach over existing methods and demonstrate that it can empower deeper insights into cellular heterogeneity and the identification of disease cell states.", "url": "https://arxiv.org/abs/2307.00558"}, {"metadata": {"arXiv": "2307.00580", "Date": "Sun, 02 Jul 2023 14:18:04 ", "Title": "IoT-Based Air Quality Monitoring System with Machine Learning for Accurate and Real-time Data Analysis", "Authors": ["Hemanth Karnati"], "Categories": "cs.LG", "Comments": ["18 pages", "10 figures"]}, "abstract": "Air pollution in urban areas has severe consequences for both human health and the environment, predominantly caused by exhaust emissions from vehicles. To address the issue of air pollution awareness, Air Pollution Monitoring systems are used to measure the concentration of gases like CO2, smoke, alcohol, benzene, and NH3 present in the air. However, current mobile applications are unable to provide users with real-time data specific to their location. In this paper, we propose the development of a portable air quality detection device that can be used anywhere. The data collected will be stored and visualized using the cloud-based web app ThinkSpeak. The device utilizes two sensors, MQ135 and MQ3, to detect harmful gases and measure air quality in parts per million (PPM). Additionally, machine learning analysis will be employed on the collected data.", "url": "https://arxiv.org/abs/2307.00580"}, {"metadata": {"arXiv": "2307.00610", "Date": "Sun, 02 Jul 2023 16:35:54 ", "Title": "Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets", "Authors": ["Raphael Frick", "Inna Vogel"], "Categories": "cs.LG", "Comments": ["8 pages"], "Journal-ref": "CLEF 2023"}, "abstract": "The option of sharing images, videos and audio files on social media opens up new possibilities for distinguishing between false information and fake news on the Internet. Due to the vast amount of data shared every second on social media, not all data can be verified by a computer or a human expert. Here, a check-worthiness analysis can be used as a first step in the fact-checking pipeline and as a filtering mechanism to improve efficiency. This paper proposes a novel way of detecting the check-worthiness in multi-modal tweets. It takes advantage of two classifiers, each trained on a single modality. For image data, extracting the embedded text with an OCR analysis has shown to perform best. By combining the two classifiers, the proposed solution was able to place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297 achieved on the private test set.", "url": "https://arxiv.org/abs/2307.00610"}, {"metadata": {"arXiv": "2307.00618", "Date": "Sun, 02 Jul 2023 17:18:17 ", "Title": "Bounce: a Reliable Bayesian Optimization Algorithm for Combinatorial and Mixed Spaces", "Authors": ["Leonard Papenmeier", "Luigi Nardi", "Matthias Poloczek"], "Categories": "cs.LG", "Comments": ["27 pages", "17 figures"]}, "abstract": "Impactful applications such as materials discovery, hardware design, neural architecture search, or portfolio optimization require optimizing high-dimensional black-box functions with mixed and combinatorial input spaces. While Bayesian optimization has recently made significant progress in solving such problems, an in-depth analysis reveals that the current state-of-the-art methods are not reliable. Their performances degrade substantially when the unknown optima of the function do not have a certain structure. To fill the need for a reliable algorithm for combinatorial and mixed spaces, this paper proposes Bounce that relies on a novel map of various variable types into nested embeddings of increasing dimensionality. Comprehensive experiments show that Bounce reliably achieves and often even improves upon state-of-the-art performance on a variety of high-dimensional problems.", "url": "https://arxiv.org/abs/2307.00618"}, {"metadata": {"arXiv": "2307.00623", "Date": "Sun, 02 Jul 2023 17:29:41 ", "Title": "Variational Autoencoding Molecular Graphs with Denoising Diffusion Probabilistic Model", "Authors": ["Daiki Koge", "Naoaki Ono and Shigehiko Kanaya"], "Categories": "cs.LG stat.ML", "Comments": ["2 pages. Short paper submitted to IEEE CIBCB 2023"]}, "abstract": "In data-driven drug discovery, designing molecular descriptors is a very important task. Deep generative models such as variational autoencoders (VAEs) offer a potential solution by designing descriptors as probabilistic latent vectors derived from molecular structures. These models can be trained on large datasets, which have only molecular structures, and applied to transfer learning. Nevertheless, the approximate posterior distribution of the latent vectors of the usual VAE assumes a simple multivariate Gaussian distribution with zero covariance, which may limit the performance of representing the latent features. To overcome this limitation, we propose a novel molecular deep generative model that incorporates a hierarchical structure into the probabilistic latent vectors. We achieve this by a denoising diffusion probabilistic model (DDPM). We demonstrate that our model can design effective molecular latent vectors for molecular property prediction from some experiments by small datasets on physical properties and activity. The results highlight the superior prediction performance and robustness of our model compared to existing approaches.", "url": "https://arxiv.org/abs/2307.00623"}, {"metadata": {"arXiv": "2307.00631", "Date": "Sun, 02 Jul 2023 18:16:06 ", "Title": "Bidirectional Looking with A Novel Double Exponential Moving Average to Adaptive and Non-adaptive Momentum Optimizers", "Authors": ["Yineng Chen", "Zuchao Li", "Lefei Zhang", "Bo Du", "Hai Zhao"], "Categories": "cs.LG math.OC"}, "abstract": "Optimizer is an essential component for the success of deep learning, which guides the neural network to update the parameters according to the loss on the training set. SGD and Adam are two classical and effective optimizers on which researchers have proposed many variants, such as SGDM and RAdam. In this paper, we innovatively combine the backward-looking and forward-looking aspects of the optimizer algorithm and propose a novel \\textsc{Admeta} (\\textbf{A} \\textbf{D}ouble exponential \\textbf{M}oving averag\\textbf{E} \\textbf{T}o \\textbf{A}daptive and non-adaptive momentum) optimizer framework. For backward-looking part, we propose a DEMA variant scheme, which is motivated by a metric in the stock market, to replace the common exponential moving average scheme. While in the forward-looking part, we present a dynamic lookahead strategy which asymptotically approaches a set value, maintaining its speed at early stage and high convergence performance at final stage. Based on this idea, we provide two optimizer implementations, \\textsc{AdmetaR} and \\textsc{AdmetaS}, the former based on RAdam and the latter based on SGDM. Through extensive experiments on diverse tasks, we find that the proposed \\textsc{Admeta} optimizer outperforms our base optimizers and shows advantages over recently proposed competitive optimizers. We also provide theoretical proof of these two algorithms, which verifies the convergence of our proposed \\textsc{Admeta}.", "url": "https://arxiv.org/abs/2307.00631"}, {"metadata": {"arXiv": "2307.00642", "Date": "Sun, 02 Jul 2023 19:26:58 ", "Title": "Multiclass Boosting: Simple and Intuitive Weak Learning Criteria", "Authors": ["Nataly Brukhim", "Amit Daniely", "Yishay Mansour", "Shay Moran"], "Categories": "cs.LG"}, "abstract": "We study a generalization of boosting to the multiclass setting. We introduce a weak learning condition for multiclass classification that captures the original notion of weak learnability as being \"slightly better than random guessing\". We give a simple and efficient boosting algorithm, that does not require realizability assumptions and its sample and oracle complexity bounds are independent of the number of classes. In addition, we utilize our new boosting technique in several theoretical applications within the context of List PAC Learning. First, we establish an equivalence to weak PAC learning. Furthermore, we present a new result on boosting for list learners, as well as provide a novel proof for the characterization of multiclass PAC learning and List PAC learning. Notably, our technique gives rise to a simplified analysis, and also implies an improved error bound for large list sizes, compared to previous results.", "url": "https://arxiv.org/abs/2307.00642"}, {"metadata": {"arXiv": "2307.00662", "Date": "Sun, 02 Jul 2023 20:44:01 ", "Title": "Numerical Association Rule Mining: A Systematic Literature Review", "Authors": ["Minakshi Kaushik and Rahul Sharma and Iztok Fister Jr. and Dirk Draheim"], "Categories": "cs.LG cs.DB"}, "abstract": "Numerical association rule mining is a widely used variant of the association rule mining technique, and it has been extensively used in discovering patterns and relationships in numerical data. Initially, researchers and scientists integrated numerical attributes in association rule mining using various discretization approaches; however, over time, a plethora of alternative methods have emerged in this field. Unfortunately, the increase of alternative methods has resulted into a significant knowledge gap in understanding diverse techniques employed in numerical association rule mining -- this paper attempts to bridge this knowledge gap by conducting a comprehensive systematic literature review. We provide an in-depth study of diverse methods, algorithms, metrics, and datasets derived from 1,140 scholarly articles published from the inception of numerical association rule mining in the year 1996 to 2022. In compliance with the inclusion, exclusion, and quality evaluation criteria, 68 papers were chosen to be extensively evaluated. To the best of our knowledge, this systematic literature review is the first of its kind to provide an exhaustive analysis of the current literature and previous surveys on numerical association rule mining. The paper discusses important research issues, the current status, and future possibilities of numerical association rule mining. On the basis of this systematic review, the article also presents a novel discretization measure that contributes by providing a partitioning of numerical data that meets well human perception of partitions.", "url": "https://arxiv.org/abs/2307.00662"}, {"metadata": {"arXiv": "2307.00668", "Date": "Sun, 02 Jul 2023 21:14:49 ", "Title": "Active Sensing with Predictive Coding and Uncertainty Minimization", "Authors": ["Abdelrahman Sharafeldin", "Nabil Imam", "Hannah Choi"], "Categories": "cs.LG cs.NE"}, "abstract": "We present an end-to-end procedure for embodied exploration based on two biologically inspired computations: predictive coding and uncertainty minimization. The procedure can be applied to any exploration setting in a task-independent and intrinsically driven manner. We first demonstrate our approach in a maze navigation task and show that our model is capable of discovering the underlying transition distribution and reconstructing the spatial features of the environment. Second, we apply our model to the more complex task of active vision, where an agent must actively sample its visual environment to gather information. We show that our model is able to build unsupervised representations that allow it to actively sample and efficiently categorize sensory scenes. We further show that using these representations as input for downstream classification leads to superior data efficiency and learning speed compared to other baselines, while also maintaining lower parameter complexity. Finally, the modularity of our model allows us to analyze its internal mechanisms and to draw insight into the interactions between perception and action during exploratory behavior.", "url": "https://arxiv.org/abs/2307.00668"}, {"metadata": {"arXiv": "2307.00670", "Date": "Sun, 02 Jul 2023 21:31:47 ", "Title": "Automatic MILP Solver Configuration By Learning Problem Similarities", "Authors": ["Abdelrahman Hosny", "Sherief Reda"], "Categories": "cs.LG math.OC", "Comments": ["To appear in Annals of Operations Research (ANOR)"]}, "abstract": "A large number of real-world optimization problems can be formulated as Mixed Integer Linear Programs (MILP). MILP solvers expose numerous configuration parameters to control their internal algorithms. Solutions, and their associated costs or runtimes, are significantly affected by the choice of the configuration parameters, even when problem instances have the same number of decision variables and constraints. On one hand, using the default solver configuration leads to suboptimal solutions. On the other hand, searching and evaluating a large number of configurations for every problem instance is time-consuming and, in some cases, infeasible. In this study, we aim to predict configuration parameters for unseen problem instances that yield lower-cost solutions without the time overhead of searching-and-evaluating configurations at the solving time. Toward that goal, we first investigate the cost correlation of MILP problem instances that come from the same distribution when solved using different configurations. We show that instances that have similar costs using one solver configuration also have similar costs using another solver configuration in the same runtime environment. After that, we present a methodology based on Deep Metric Learning to learn MILP similarities that correlate with their final solutions' costs. At inference time, given a new problem instance, it is first projected into the learned metric space using the trained model, and configuration parameters are instantly predicted using previously-explored configurations from the nearest neighbor instance in the learned embedding space. Empirical results on real-world problem benchmarks show that our method predicts configuration parameters that improve solutions' costs by up to 38% compared to existing approaches.", "url": "https://arxiv.org/abs/2307.00670"}, {"metadata": {"arXiv": "2307.00680", "Date": "Sun, 02 Jul 2023 22:52:58 ", "Title": "CLIMAX: An exploration of Classifier-Based Contrastive Explanations", "Authors": ["Praharsh Nanavati", "Ranjitha Prasad"], "Categories": "cs.LG", "Comments": ["11 Pages", "8 figures", "2 tables", "2 algorithms"]}, "abstract": "Explainable AI is an evolving area that deals with understanding the decision making of machine learning models so that these models are more transparent, accountable, and understandable for humans. In particular, post-hoc model-agnostic interpretable AI techniques explain the decisions of a black-box ML model for a single instance locally, without the knowledge of the intrinsic nature of the ML model. Despite their simplicity and capability in providing valuable insights, existing approaches fail to deliver consistent and reliable explanations. Moreover, in the context of black-box classifiers, existing approaches justify the predicted class, but these methods do not ensure that the explanation scores strongly differ as compared to those of another class. In this work we propose a novel post-hoc model agnostic XAI technique that provides contrastive explanations justifying the classification of a black box classifier along with a reasoning as to why another class was not predicted. Our method, which we refer to as CLIMAX which is short for Contrastive Label-aware Influence-based Model Agnostic XAI, is based on local classifiers . In order to ensure model fidelity of the explainer, we require the perturbations to be such that it leads to a class-balanced surrogate dataset. Towards this, we employ a label-aware surrogate data generation method based on random oversampling and Gaussian Mixture Model sampling. Further, we propose influence subsampling in order to retaining effective samples and hence ensure sample complexity. We show that we achieve better consistency as compared to baselines such as LIME, BayLIME, and SLIME. We also depict results on textual and image based datasets, where we generate contrastive explanations for any black-box classification model where one is able to only query the class probabilities for an instance of interest.", "url": "https://arxiv.org/abs/2307.00680"}, {"metadata": {"arXiv": "2307.00682", "Date": "Sun, 02 Jul 2023 23:27:00 ", "Title": "Tools for Verifying Neural Models' Training Data", "Authors": ["Dami Choi", "Yonadav Shavit", "David Duvenaud"], "Categories": "cs.LG cs.CR"}, "abstract": "It is important that consumers and regulators can verify the provenance of large neural models to evaluate their capabilities and risks. We introduce the concept of a \"Proof-of-Training-Data\": any protocol that allows a model trainer to convince a Verifier of the training data that produced a set of model weights. Such protocols could verify the amount and kind of data and compute used to train the model, including whether it was trained on specific harmful or beneficial data sources. We explore efficient verification strategies for Proof-of-Training-Data that are compatible with most current large-model training procedures. These include a method for the model-trainer to verifiably pre-commit to a random seed used in training, and a method that exploits models' tendency to temporarily overfit to training data in order to detect whether a given data-point was included in training. We show experimentally that our verification procedures can catch a wide variety of attacks, including all known attacks from the Proof-of-Learning literature.", "url": "https://arxiv.org/abs/2307.00682"}, {"metadata": {"arXiv": "2307.00721", "Date": "Mon, 03 Jul 2023 03:00:22 ", "Title": "Neural Polytopes", "Authors": ["Koji Hashimoto", "Tomoya Naito", "Hisashi Naito"], "Categories": "cs.LG cs.GR hep-th math.GT", "Comments": ["5 pages", "9 figures. Accepted at the 1st Workshop on the Synergy of Scientific and Machine Learning Modeling at International Conference on Machine Learning (ICML)", "Honolulu", "Hawaii", "USA. 2023"]}, "abstract": "We find that simple neural networks with ReLU activation generate polytopes as an approximation of a unit sphere in various dimensions. The species of polytopes are regulated by the network architecture, such as the number of units and layers. For a variety of activation functions, generalization of polytopes is obtained, which we call neural polytopes. They are a smooth analogue of polytopes, exhibiting geometric duality. This finding initiates research of discrete geometry via machine learning and also a visualization of trained networks.", "url": "https://arxiv.org/abs/2307.00721"}, {"metadata": {"arXiv": "2307.00755", "Date": "Mon, 03 Jul 2023 04:57:53 ", "Title": "Graph-level Anomaly Detection via Hierarchical Memory Networks", "Authors": ["Chaoxi Niu", "Guansong Pang", "Ling Chen"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted to ECML-PKDD 2023"]}, "abstract": "Graph-level anomaly detection aims to identify abnormal graphs that exhibit deviant structures and node attributes compared to the majority in a graph set. One primary challenge is to learn normal patterns manifested in both fine-grained and holistic views of graphs for identifying graphs that are abnormal in part or in whole. To tackle this challenge, we propose a novel approach called Hierarchical Memory Networks (HimNet), which learns hierarchical memory modules -- node and graph memory modules -- via a graph autoencoder network architecture. The node-level memory module is trained to model fine-grained, internal graph interactions among nodes for detecting locally abnormal graphs, while the graph-level memory module is dedicated to the learning of holistic normal patterns for detecting globally abnormal graphs. The two modules are jointly optimized to detect both locally- and globally-anomalous graphs. Extensive empirical results on 16 real-world graph datasets from various domains show that i) HimNet significantly outperforms the state-of-art methods and ii) it is robust to anomaly contamination. Codes are available at: https://github.com/Niuchx/HimNet.", "url": "https://arxiv.org/abs/2307.00755"}, {"metadata": {"arXiv": "2307.00823", "Date": "Mon, 03 Jul 2023 08:06:22 ", "Title": "Analysis of Task Transferability in Large Pre-trained Classifiers", "Authors": ["Akshay Mehra", "Yunbei Zhang", "and Jihun Hamm"], "Categories": "cs.LG"}, "abstract": "Transfer learning transfers the knowledge acquired by a model from a source task to multiple downstream target tasks with minimal fine-tuning. The success of transfer learning at improving performance, especially with the use of large pre-trained models has made transfer learning an essential tool in the machine learning toolbox. However, the conditions under which the performance is transferable to downstream tasks are not understood very well. In this work, we analyze the transfer of performance for classification tasks, when only the last linear layer of the source model is fine-tuned on the target task. We propose a novel Task Transfer Analysis approach that transforms the source distribution (and classifier) by changing the class prior distribution, label, and feature spaces to produce a new source distribution (and classifier) and allows us to relate the loss of the downstream task (i.e., transferability) to that of the source task. Concretely, our bound explains transferability in terms of the Wasserstein distance between the transformed source and downstream task's distribution, conditional entropy between the label distributions of the two tasks, and weighted loss of the source classifier on the source task. Moreover, we propose an optimization problem for learning the transforms of the source task to minimize the upper bound on transferability. We perform a large-scale empirical study by using state-of-the-art pre-trained models and demonstrate the effectiveness of our bound and optimization at predicting transferability. The results of our experiments demonstrate how factors such as task relatedness, pretraining method, and model architecture affect transferability.", "url": "https://arxiv.org/abs/2307.00823"}, {"metadata": {"arXiv": "2307.00859", "Date": "Mon, 03 Jul 2023 08:58:32 ", "Title": "CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery", "Authors": ["Abhijit Gupta and Arnab Mukherjee"], "Categories": "cs.LG q-bio.QM stat.AP stat.ML"}, "abstract": "In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential applications in drug discovery and drug interactions are vast, from identifying new drug targets to predicting drug-to-drug interactions and enabling novel drug discovery. This innovative approach provides an AI-enhanced methodology in drug development, utilizing SSL combined with GNNs to overcome existing limitations and pave the way for a richer exploration of the vast combinatorial chemical space in drug discovery.", "url": "https://arxiv.org/abs/2307.00859"}, {"metadata": {"arXiv": "2307.00863", "Date": "Mon, 03 Jul 2023 09:04:41 ", "Title": "Thompson Sampling under Bernoulli Rewards with Local Differential Privacy", "Authors": ["Bo Jiang", "Tianchi Zhao", "Ming Li"], "Categories": "cs.LG cs.CR", "Comments": ["Accepted by ICML 22 workshop"]}, "abstract": "This paper investigates the problem of regret minimization for multi-armed bandit (MAB) problems with local differential privacy (LDP) guarantee. Given a fixed privacy budget $\\epsilon$, we consider three privatizing mechanisms under Bernoulli scenario: linear, quadratic and exponential mechanisms. Under each mechanism, we derive stochastic regret bound for Thompson Sampling algorithm. Finally, we simulate to illustrate the convergence of different mechanisms under different privacy budgets.", "url": "https://arxiv.org/abs/2307.00863"}, {"metadata": {"arXiv": "2307.00865", "Date": "Mon, 03 Jul 2023 09:08:01 ", "Title": "A Survey on Graph Classification and Link Prediction based on GNN", "Authors": ["Xingyu Liu", "Juan Chen", "Quan Wen"], "Categories": "cs.LG", "Comments": ["18pages,4figures"]}, "abstract": "Traditional convolutional neural networks are limited to handling Euclidean space data, overlooking the vast realm of real-life scenarios represented as graph data, including transportation networks, social networks, and reference networks. The pivotal step in transferring convolutional neural networks to graph data analysis and processing lies in the construction of graph convolutional operators and graph pooling operators. This comprehensive review article delves into the world of graph convolutional neural networks. Firstly, it elaborates on the fundamentals of graph convolutional neural networks. Subsequently, it elucidates the graph neural network models based on attention mechanisms and autoencoders, summarizing their application in node classification, graph classification, and link prediction along with the associated datasets.", "url": "https://arxiv.org/abs/2307.00865"}, {"metadata": {"arXiv": "2307.00907", "Date": "Mon, 03 Jul 2023 10:10:34 ", "Title": "Enhancing the Robustness of QMIX against State-adversarial Attacks", "Authors": ["Weiran Guo", "Guanjun Liu", "Ziyuan Zhou", "Ling Wang", "Jiacun Wang"], "Categories": "cs.LG cs.CR cs.MA"}, "abstract": "Deep reinforcement learning (DRL) performance is generally impacted by state-adversarial attacks, a perturbation applied to an agent's observation. Most recent research has concentrated on robust single-agent reinforcement learning (SARL) algorithms against state-adversarial attacks. Still, there has yet to be much work on robust multi-agent reinforcement learning. Using QMIX, one of the popular cooperative multi-agent reinforcement algorithms, as an example, we discuss four techniques to improve the robustness of SARL algorithms and extend them to multi-agent scenarios. To increase the robustness of multi-agent reinforcement learning (MARL) algorithms, we train models using a variety of attacks in this research. We then test the models taught using the other attacks by subjecting them to the corresponding attacks throughout the training phase. In this way, we organize and summarize techniques for enhancing robustness when used with MARL.", "url": "https://arxiv.org/abs/2307.00907"}, {"metadata": {"arXiv": "2307.00924", "Date": "Mon, 03 Jul 2023 10:50:44 ", "Title": "Semi-supervised multi-view concept decomposition", "Authors": ["Qi Jiang", "Guoxu Zhou and Qibin Zhao"], "Categories": "cs.LG cs.CV"}, "abstract": "Concept Factorization (CF), as a novel paradigm of representation learning, has demonstrated superior performance in multi-view clustering tasks. It overcomes limitations such as the non-negativity constraint imposed by traditional matrix factorization methods and leverages kernel methods to learn latent representations that capture the underlying structure of the data, thereby improving data representation. However, existing multi-view concept factorization methods fail to consider the limited labeled information inherent in real-world multi-view data. This often leads to significant performance loss. To overcome these limitations, we propose a novel semi-supervised multi-view concept factorization model, named SMVCF. In the SMVCF model, we first extend the conventional single-view CF to a multi-view version, enabling more effective exploration of complementary information across multiple views. We then integrate multi-view CF, label propagation, and manifold learning into a unified framework to leverage and incorporate valuable information present in the data. Additionally, an adaptive weight vector is introduced to balance the importance of different views in the clustering process. We further develop targeted optimization methods specifically tailored for the SMVCF model. Finally, we conduct extensive experiments on four diverse datasets with varying label ratios to evaluate the performance of SMVCF. The experimental results demonstrate the effectiveness and superiority of our proposed approach in multi-view clustering tasks.", "url": "https://arxiv.org/abs/2307.00924"}, {"metadata": {"arXiv": "2307.00972", "Date": "Mon, 03 Jul 2023 12:44:07 ", "Title": "MoVie: Visual Model-Based Policy Adaptation for View Generalization", "Authors": ["Sizhe Yang", "Yanjie Ze", "Huazhe Xu"], "Categories": "cs.LG cs.RO"}, "abstract": "Visual Reinforcement Learning (RL) agents trained on limited views face significant challenges in generalizing their learned abilities to unseen views. This inherent difficulty is known as the problem of $\\textit{view generalization}$. In this work, we systematically categorize this fundamental problem into four distinct and highly challenging scenarios that closely resemble real-world situations. Subsequently, we propose a straightforward yet effective approach to enable successful adaptation of visual $\\textbf{Mo}$del-based policies for $\\textbf{Vie}$w generalization ($\\textbf{MoVie}$) during test time, without any need for explicit reward signals and any modification during training time. Our method demonstrates substantial advancements across all four scenarios encompassing a total of $\\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative improvement of $\\mathbf{33}$%, $\\mathbf{86}$%, and $\\mathbf{152}$% respectively. The superior results highlight the immense potential of our approach for real-world robotics applications. Videos are available at https://yangsizhe.github.io/MoVie/ .", "url": "https://arxiv.org/abs/2307.00972"}, {"metadata": {"arXiv": "2307.01023", "Date": "Mon, 03 Jul 2023 13:54:50 ", "Title": "Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future and Past Trends in Time Series Data", "Authors": ["C.Coelho", "M. Fernanda P. Costa and L.L. Ferr\\'as"], "Categories": "cs.LG", "Comments": ["Under review at journal"], "ACM-class": "I.5.1; G.1.7"}, "abstract": "This work introduces Neural Chronos Ordinary Differential Equations (Neural CODE), a deep neural network architecture that fits a continuous-time ODE dynamics for predicting the chronology of a system both forward and backward in time. To train the model, we solve the ODE as an initial value problem and a final value problem, similar to Neural ODEs. We also explore two approaches to combining Neural CODE with Recurrent Neural Networks by replacing Neural ODE with Neural CODE (CODE-RNN), and incorporating a bidirectional RNN for full information flow in both time directions (CODE-BiRNN), and variants with other update cells namely GRU and LSTM: CODE-GRU, CODE-BiGRU, CODE-LSTM, CODE-BiLSTM. Experimental results demonstrate that Neural CODE outperforms Neural ODE in learning the dynamics of a spiral forward and backward in time, even with sparser data. We also compare the performance of CODE-RNN/-GRU/-LSTM and CODE-BiRNN/-BiGRU/-BiLSTM against ODE-RNN/-GRU/-LSTM on three real-life time series data tasks: imputation of missing data for lower and higher dimensional data, and forward and backward extrapolation with shorter and longer time horizons. Our findings show that the proposed architectures converge faster, with CODE-BiRNN/-BiGRU/-BiLSTM consistently outperforming the other architectures on all tasks.", "url": "https://arxiv.org/abs/2307.01023"}, {"metadata": {"arXiv": "2307.01073", "Date": "Mon, 03 Jul 2023 14:54:13 ", "Title": "When Can Linear Learners be Robust to Indiscriminate Poisoning Attacks?", "Authors": ["Fnu Suya", "Xiao Zhang", "Yuan Tian", "David Evans"], "Categories": "cs.LG cs.CR"}, "abstract": "We study indiscriminate poisoning for linear learners where an adversary injects a few crafted examples into the training data with the goal of forcing the induced model to incur higher test error. Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners. For theoretical Gaussian distributions, we rigorously characterize the behavior of an optimal poisoning attack, defined as the poisoning strategy that attains the maximum risk of the induced model at a given poisoning budget. Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small. These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks.", "url": "https://arxiv.org/abs/2307.01073"}, {"metadata": {"arXiv": "2307.01088", "Date": "Mon, 03 Jul 2023 15:08:28 ", "Title": "Empirically Validating Conformal Prediction on Modern Vision Architectures Under Distribution Shift and Long-tailed Data", "Authors": ["Kevin Kasa and Graham W. Taylor"], "Categories": "cs.LG stat.ML"}, "abstract": "Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees. Yet, its performance is known to degrade under distribution shift and long-tailed class distributions, which are often present in real world applications. Here, we characterize the performance of several post-hoc and training-based conformal prediction methods under these settings, providing the first empirical evaluation on large-scale datasets and models. We show that across numerous conformal methods and neural network families, performance greatly degrades under distribution shifts violating safety guarantees. Similarly, we show that in long-tailed settings the guarantees are frequently violated on many classes. Understanding the limitations of these methods is necessary for deployment in real world and safety-critical applications.", "url": "https://arxiv.org/abs/2307.01088"}, {"metadata": {"arXiv": "2307.01157", "Date": "Mon, 03 Jul 2023 17:05:29 ", "Title": "A novel approach for predicting epidemiological forecasting parameters based on real-time signals and Data Assimilation", "Authors": ["Romain Molinas", "C\\'esar Quilodr\\'an Casas", "Rossella Arcucci", "Ovidiu \\c{S}erban"], "Categories": "cs.LG cs.NE cs.SI"}, "abstract": "This paper proposes a novel approach to predict epidemiological parameters by integrating new real-time signals from various sources of information, such as novel social media-based population density maps and Air Quality data. We implement an ensemble of Convolutional Neural Networks (CNN) models using various data sources and fusion methodology to build robust predictions and simulate several dynamic parameters that could improve the decision-making process for policymakers. Additionally, we used data assimilation to estimate the state of our system from fused CNN predictions. The combination of meteorological signals and social media-based population density maps improved the performance and flexibility of our prediction of the COVID-19 outbreak in London. While the proposed approach outperforms standard models, such as compartmental models traditionally used in disease forecasting (SEIR), generating robust and consistent predictions allows us to increase the stability of our model while increasing its accuracy.", "url": "https://arxiv.org/abs/2307.01157"}, {"metadata": {"arXiv": "2307.01166", "Date": "Mon, 03 Jul 2023 17:18:50 ", "Title": "Coupled Gradient Flows for Strategic Non-Local Distribution Shift", "Authors": ["Lauren Conger", "Franca Hoffmann", "Eric Mazumdar", "Lillian Ratliff"], "Categories": "cs.LG math.AP"}, "abstract": "We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed. Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure. In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift. We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users. For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters. To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems. Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture.", "url": "https://arxiv.org/abs/2307.01166"}, {"metadata": {"arXiv": "2307.01170", "Date": "Mon, 03 Jul 2023 17:29:58 ", "Title": "Online nearest neighbor classification", "Authors": ["Sanjoy Dasgupta and Geelon So"], "Categories": "cs.LG"}, "abstract": "We study an instance of online non-parametric classification in the realizable setting. In particular, we consider the classical 1-nearest neighbor algorithm, and show that it achieves sublinear regret - that is, a vanishing mistake rate - against dominated or smoothed adversaries in the realizable setting.", "url": "https://arxiv.org/abs/2307.01170"}, {"metadata": {"arXiv": "2307.01177", "Date": "Mon, 03 Jul 2023 17:40:58 ", "Title": "Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space", "Authors": ["Zhengdao Chen"], "Categories": "cs.LG math.FA math.OC math.PR stat.ML", "Comments": ["Extended from the paper titled \"Multi-Layer Neural Networks as Trainable Ladders of Hilbert Spaces\" at ICML 2023"]}, "abstract": "The characterization of the functions spaces explored by neural networks (NNs) is an important aspect of deep learning theory. In this work, we view a multi-layer NN with arbitrary width as defining a particular hierarchy of reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL). This allows us to define a function space and a complexity measure that generalize prior results for shallow NNs, and we then examine their theoretical properties and implications in several aspects. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with the complexity measure controlled. Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized as the dynamics of multiple random fields. Fourth, we show examples of depth separation in NHLs under ReLU and quadratic activation functions. Finally, we complement the theory with numerical results to illustrate the learning of RKHS in NN training.", "url": "https://arxiv.org/abs/2307.01177"}, {"metadata": {"arXiv": "2307.01198", "Date": "Mon, 03 Jul 2023 17:58:26 ", "Title": "Improved sampling via learned diffusions", "Authors": ["Lorenz Richter", "Julius Berner", "Guan-Horng Liu"], "Categories": "cs.LG math.OC math.PR stat.ML", "Comments": ["Accepted at ICML 2023 Workshop on New Frontiers in Learning", "Control", "and Dynamical Systems"]}, "abstract": "Recently, a series of papers proposed deep learning-based approaches to sample from unnormalized target densities using controlled diffusion processes. In this work, we identify these approaches as special cases of the Schr\\\"odinger bridge problem, seeking the most likely stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches.", "url": "https://arxiv.org/abs/2307.01198"}, {"metadata": {"arXiv": "2307.00117", "Date": "Fri, 30 Jun 2023 20:09:39 ", "Title": "Goal Representations for Instruction Following: A Semi-Supervised Language Interface to Control", "Authors": ["Vivek Myers", "Andre He", "Kuan Fang", "Homer Walke", "Philippe Hansen-Estruch", "Ching-An Cheng", "Mihai Jalobeanu", "Andrey Kolobov", "Anca Dragan", "Sergey Levine"], "Categories": "cs.RO cs.LG", "Comments": ["15 pages", "5 figures"]}, "abstract": "Our goal is for robots to follow natural language instructions like \"put the towel next to the microwave.\" But getting large amounts of labeled data, i.e. data that contains demonstrations of tasks labeled with the language instruction, is prohibitive. In contrast, obtaining policies that respond to image goals is much easier, because any autonomous trial or demonstration can be labeled in hindsight with its final state as the goal. In this work, we contribute a method that taps into joint image- and goal- conditioned policies with language using only a small amount of language data. Prior work has made progress on this using vision-language models or by jointly training language-goal-conditioned policies, but so far neither method has scaled effectively to real-world robot tasks without significant human annotation. Our method achieves robust performance in the real world by learning an embedding from the labeled data that aligns language not to the goal image, but rather to the desired change between the start and goal images that the instruction corresponds to. We then train a policy on this embedding: the policy benefits from all the unlabeled data, but the aligned embedding provides an interface for language to steer the policy. We show instruction following across a variety of manipulation tasks in different scenes, with generalization to language instructions outside of the labeled data. Videos and code for our approach can be found on our website: http://tiny.cc/grif .", "url": "https://arxiv.org/abs/2307.00117"}, {"metadata": {"arXiv": "2307.00123", "Date": "Fri, 30 Jun 2023 20:29:48 ", "Title": "How Do Human Users Teach a Continual Learning Robot in Repeated Interactions?", "Authors": ["Ali Ayub", "Jainish Mehta", "Zachary De Francesco", "Patrick Holthaus", "Kerstin Dautenhahn and Chrystopher L. Nehaniv"], "Categories": "cs.RO cs.HC cs.LG", "Comments": ["Accepted to the IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "2023"]}, "abstract": "Continual learning (CL) has emerged as an important avenue of research in recent years, at the intersection of Machine Learning (ML) and Human-Robot Interaction (HRI), to allow robots to continually learn in their environments over long-term interactions with humans. Most research in continual learning, however, has been robot-centered to develop continual learning algorithms that can quickly learn new information on static datasets. In this paper, we take a human-centered approach to continual learning, to understand how humans teach continual learning robots over the long term and if there are variations in their teaching styles. We conducted an in-person study with 40 participants that interacted with a continual learning robot in 200 sessions. In this between-participant study, we used two different CL models deployed on a Fetch mobile manipulator robot. An extensive qualitative and quantitative analysis of the data collected in the study shows that there is significant variation among the teaching styles of individual users indicating the need for personalized adaptation to their distinct teaching styles. The results also show that although there is a difference in the teaching styles between expert and non-expert users, the style does not have an effect on the performance of the continual learning robot. Finally, our analysis shows that the constrained experimental setups that have been widely used to test most continual learning techniques are not adequate, as real users interact with and teach continual learning robots in a variety of ways. Our code is available at https://github.com/aliayub7/cl_hri.", "url": "https://arxiv.org/abs/2307.00123"}, {"metadata": {"arXiv": "2307.00125", "Date": "Fri, 30 Jun 2023 20:35:22 ", "Title": "RObotic MAnipulation Network (ROMAN) -- Hybrid Hierarchical Learning for Solving Complex Sequential Tasks", "Authors": ["Eleftherios Triantafyllidis", "Fernando Acero", "Zhaocheng Liu and Zhibin Li"], "Categories": "cs.RO cs.LG", "Comments": ["To appear in Nature Machine Intelligence. Includes the main and supplementary manuscript. Total of 70 pages", "with a total of 9 Figures and 17 Tables"]}, "abstract": "Solving long sequential tasks poses a significant challenge in embodied artificial intelligence. Enabling a robotic system to perform diverse sequential tasks with a broad range of manipulation skills is an active area of research. In this work, we present a Hybrid Hierarchical Learning framework, the Robotic Manipulation Network (ROMAN), to address the challenge of solving multiple complex tasks over long time horizons in robotic manipulation. ROMAN achieves task versatility and robust failure recovery by integrating behavioural cloning, imitation learning, and reinforcement learning. It consists of a central manipulation network that coordinates an ensemble of various neural networks, each specialising in distinct re-combinable sub-tasks to generate their correct in-sequence actions for solving complex long-horizon manipulation tasks. Experimental results show that by orchestrating and activating these specialised manipulation experts, ROMAN generates correct sequential activations for accomplishing long sequences of sophisticated manipulation tasks and achieving adaptive behaviours beyond demonstrations, while exhibiting robustness to various sensory noises. These results demonstrate the significance and versatility of ROMAN's dynamic adaptability featuring autonomous failure recovery capabilities, and highlight its potential for various autonomous manipulation tasks that demand adaptive motor skills.", "url": "https://arxiv.org/abs/2307.00125"}, {"metadata": {"arXiv": "2307.00837", "Date": "Mon, 03 Jul 2023 08:20:19 ", "Title": "Surgical fine-tuning for Grape Bunch Segmentation under Visual Domain Shifts", "Authors": ["Agnese Chiatti", "Riccardo Bertoglio", "Nico Catalano", "Matteo Gatti", "Matteo Matteucci"], "Categories": "cs.RO cs.CV cs.LG"}, "abstract": "Mobile robots will play a crucial role in the transition towards sustainable agriculture. To autonomously and effectively monitor the state of plants, robots ought to be equipped with visual perception capabilities that are robust to the rapid changes that characterise agricultural settings. In this paper, we focus on the challenging task of segmenting grape bunches from images collected by mobile robots in vineyards. In this context, we present the first study that applies surgical fine-tuning to instance segmentation tasks. We show how selectively tuning only specific model layers can support the adaptation of pre-trained Deep Learning models to newly-collected grape images that introduce visual domain shifts, while also substantially reducing the number of tuned parameters.", "url": "https://arxiv.org/abs/2307.00837"}, {"metadata": {"arXiv": "2307.00828", "Date": "Mon, 03 Jul 2023 08:16:01 ", "Title": "Model-Assisted Probabilistic Safe Adaptive Control With Meta-Bayesian Learning", "Authors": ["Shengbo Wang", "Ke Li", "Yin Yang", "Yuting Cao", "Tingwen Huang and Shiping Wen"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "Breaking safety constraints in control systems can lead to potential risks, resulting in unexpected costs or catastrophic damage. Nevertheless, uncertainty is ubiquitous, even among similar tasks. In this paper, we develop a novel adaptive safe control framework that integrates meta learning, Bayesian models, and control barrier function (CBF) method. Specifically, with the help of CBF method, we learn the inherent and external uncertainties by a unified adaptive Bayesian linear regression (ABLR) model, which consists of a forward neural network (NN) and a Bayesian output layer. Meta learning techniques are leveraged to pre-train the NN weights and priors of the ABLR model using data collected from historical similar tasks. For a new control task, we refine the meta-learned models using a few samples, and introduce pessimistic confidence bounds into CBF constraints to ensure safe control. Moreover, we provide theoretical criteria to guarantee probabilistic safety during the control processes. To validate our approach, we conduct comparative experiments in various obstacle avoidance scenarios. The results demonstrate that our algorithm significantly improves the Bayesian model-based CBF method, and is capable for efficient safe exploration even with multiple uncertain constraints.", "url": "https://arxiv.org/abs/2307.00828"}, {"metadata": {"arXiv": "2307.00065", "Date": "Fri, 30 Jun 2023 18:08:25 ", "Title": "Qualitative Prediction of Multi-Agent Spatial Interactions", "Authors": ["Sariah Mghames", "Luca Castri", "Marc Hanheide", "Nicola Bellotto"], "Categories": "cs.AI cs.RO", "Comments": ["This work will be published in the proceedings of IEEE RO-MAN 2023 (https://ro-man2023.org/main). arXiv admin note: text overlap with arXiv:2304.11740"]}, "abstract": "Deploying service robots in our daily life, whether in restaurants, warehouses or hospitals, calls for the need to reason on the interactions happening in dense and dynamic scenes. In this paper, we present and benchmark three new approaches to model and predict multi-agent interactions in dense scenes, including the use of an intuitive qualitative representation. The proposed solutions take into account static and dynamic context to predict individual interactions. They exploit an input- and a temporal-attention mechanism, and are tested on medium and long-term time horizons. The first two approaches integrate different relations from the so-called Qualitative Trajectory Calculus (QTC) within a state-of-the-art deep neural network to create a symbol-driven neural architecture for predicting spatial interactions. The third approach implements a purely data-driven network for motion prediction, the output of which is post-processed to predict QTC spatial interactions. Experimental results on a popular robot dataset of challenging crowded scenarios show that the purely data-driven prediction approach generally outperforms the other two. The three approaches were further evaluated on a different but related human scenarios to assess their generalisation capability.", "url": "https://arxiv.org/abs/2307.00065"}, {"metadata": {"arXiv": "2307.00653", "Date": "Sun, 02 Jul 2023 20:04:01 ", "Title": "Neuro-Symbolic Sudoku Solver", "Authors": ["Ashutosh Hathidara", "Lalit Pandey"], "Categories": "cs.AI cs.GT", "Comments": ["Published as a conference paper at KDD KiML 2023"]}, "abstract": "Deep Neural Networks have achieved great success in some of the complex tasks that humans can do with ease. These include image recognition/classification, natural language processing, game playing etc. However, modern Neural Networks fail or perform poorly when trained on tasks that can be solved easily using backtracking and traditional algorithms. Therefore, we use the architecture of the Neuro Logic Machine (NLM) and extend its functionality to solve a 9X9 game of Sudoku. To expand the application of NLMs, we generate a random grid of cells from a dataset of solved games and assign up to 10 new empty cells. The goal of the game is then to find a target value ranging from 1 to 9 and fill in the remaining empty cells while maintaining a valid configuration. In our study, we showcase an NLM which is capable of obtaining 100% accuracy for solving a Sudoku with empty cells ranging from 3 to 10. The purpose of this study is to demonstrate that NLMs can also be used for solving complex problems and games like Sudoku. We also analyze the behaviour of NLMs with a backtracking algorithm by comparing the convergence time using a graph plot on the same problem. With this study we show that Neural Logic Machines can be trained on the tasks that traditional Deep Learning architectures fail using Reinforcement Learning. We also aim to propose the importance of symbolic learning in explaining the systematicity in the hybrid model of NLMs.", "url": "https://arxiv.org/abs/2307.00653"}, {"metadata": {"arXiv": "2307.00660", "Date": "Sun, 02 Jul 2023 20:27:55 ", "Title": "Minimum Levels of Interpretability for Artificial Moral Agents", "Authors": ["Avish Vijayaraghavan", "Cosmin Badea"], "Categories": "cs.AI cs.CY"}, "abstract": "As artificial intelligence (AI) models continue to scale up, they are becoming more capable and integrated into various forms of decision-making systems. For models involved in moral decision-making, also known as artificial moral agents (AMA), interpretability provides a way to trust and understand the agent's internal reasoning mechanisms for effective use and error correction. In this paper, we provide an overview of this rapidly-evolving sub-field of AI interpretability, introduce the concept of the Minimum Level of Interpretability (MLI) and recommend an MLI for various types of agents, to aid their safe deployment in real-world settings.", "url": "https://arxiv.org/abs/2307.00660"}, {"metadata": {"arXiv": "2307.00663", "Date": "Sun, 02 Jul 2023 20:52:16 ", "Title": "Solving Multi-Agent Target Assignment and Path Finding with a Single Constraint Tree", "Authors": ["Yimin Tang", "Zhongqiang Ren", "Jiaoyang Li", "Katia Sycara"], "Categories": "cs.AI cs.RO"}, "abstract": "Combined Target-Assignment and Path-Finding problem (TAPF) requires simultaneously assigning targets to agents and planning collision-free paths for agents from their start locations to their assigned targets. As a leading approach to address TAPF, Conflict-Based Search with Target Assignment (CBS-TA) leverages both K-best target assignments to create multiple search trees and Conflict-Based Search (CBS) to resolve collisions in each search tree. While being able to find an optimal solution, CBS-TA suffers from scalability due to the duplicated collision resolution in multiple trees and the expensive computation of K-best assignments. We therefore develop Incremental Target Assignment CBS (ITA-CBS) to bypass these two computational bottlenecks. ITA-CBS generates only a single search tree and avoids computing K-best assignments by incrementally computing new 1-best assignments during the search. We show that, in theory, ITA-CBS is guaranteed to find an optimal solution and, in practice, is computationally efficient.", "url": "https://arxiv.org/abs/2307.00663"}, {"metadata": {"arXiv": "2307.00735", "Date": "Mon, 03 Jul 2023 03:44:12 ", "Title": "Novelty and Lifted Helpful Actions in Generalized Planning", "Authors": ["Chao Lei", "Nir Lipovetzky", "Krista A. Ehinger"], "Categories": "cs.AI", "Comments": ["Accepted at SoCS 2023 (extended version)"]}, "abstract": "It has been shown recently that successful techniques in classical planning, such as goal-oriented heuristics and landmarks, can improve the ability to compute planning programs for generalized planning (GP) problems. In this work, we introduce the notion of action novelty rank, which computes novelty with respect to a planning program, and propose novelty-based generalized planning solvers, which prune a newly generated planning program if its most frequent action repetition is greater than a given bound $v$, implemented by novelty-based best-first search BFS($v$) and its progressive variant PGP($v$). Besides, we introduce lifted helpful actions in GP derived from action schemes, and propose new evaluation functions and structural program restrictions to scale up the search. Our experiments show that the new algorithms BFS($v$) and PGP($v$) outperform the state-of-the-art in GP over the standard generalized planning benchmarks. Practical findings on the above-mentioned methods in generalized planning are briefly discussed.", "url": "https://arxiv.org/abs/2307.00735"}, {"metadata": {"arXiv": "2307.00952", "Date": "Mon, 03 Jul 2023 11:51:00 ", "Title": "Towards Explainable AI for Channel Estimation in Wireless Communications", "Authors": ["Abdul Karim Gizzini", "Yahia Medjahdi", "Ali J. Ghandour", "Laurent Clavier"], "Categories": "cs.AI cs.IT math.IT", "Comments": ["This paper has been submitted to the IEEE Transactions on Vehicular Technology (TVT) as a correspondence paper on 25/04/2023"]}, "abstract": "Research into 6G networks has been initiated to support a variety of critical artificial intelligence (AI) assisted applications such as autonomous driving. In such applications, AI-based decisions should be performed in a real-time manner. These decisions include resource allocation, localization, channel estimation, etc. Considering the black-box nature of existing AI-based models, it is highly challenging to understand and trust the decision-making behavior of such models. Therefore, explaining the logic behind those models through explainable AI (XAI) techniques is essential for their employment in critical applications. This manuscript proposes a novel XAI-based channel estimation (XAI-CHEST) scheme that provides detailed reasonable interpretability of the deep learning (DL) models that are employed in doubly-selective channel estimation. The aim of the proposed XAI-CHEST scheme is to identify the relevant model inputs by inducing high noise on the irrelevant ones. As a result, the behavior of the studied DL-based channel estimators can be further analyzed and evaluated based on the generated interpretations. Simulation results show that the proposed XAI-CHEST scheme provides valid interpretations of the DL-based channel estimators for different scenarios.", "url": "https://arxiv.org/abs/2307.00952"}, {"metadata": {"arXiv": "2307.01135", "Date": "Mon, 03 Jul 2023 16:15:34 ", "Title": "ChatGPT vs. Google: A Comparative Study of Search Performance and User Experience", "Authors": ["Ruiyun Xu (Rayna)", "Yue Feng (Katherine)", "and Hailiang Chen"], "Categories": "cs.AI cs.HC cs.IR", "Comments": ["30 pages", "5 figures", "2 tables"]}, "abstract": "The advent of ChatGPT, a large language model-powered chatbot, has prompted questions about its potential implications for traditional search engines. In this study, we investigate the differences in user behavior when employing search engines and chatbot tools for information-seeking tasks. We carry out a randomized online experiment, dividing participants into two groups: one using a ChatGPT-like tool and the other using a Google Search-like tool. Our findings reveal that the ChatGPT group consistently spends less time on all tasks, with no significant difference in overall task performance between the groups. Notably, ChatGPT levels user search performance across different education levels and excels in answering straightforward questions and providing general solutions but falls short in fact-checking tasks. Users perceive ChatGPT's responses as having higher information quality compared to Google Search, despite displaying a similar level of trust in both tools. Furthermore, participants using ChatGPT report significantly better user experiences in terms of usefulness, enjoyment, and satisfaction, while perceived ease of use remains comparable between the two tools. However, ChatGPT may also lead to overreliance and generate or replicate misinformation, yielding inconsistent results. Our study offers valuable insights for search engine management and highlights opportunities for integrating chatbot technologies into search engine designs.", "url": "https://arxiv.org/abs/2307.01135"}, {"metadata": {"arXiv": "2307.00040", "Date": "Fri, 30 Jun 2023 17:37:48 ", "Title": "DisCo: Disentangled Control for Referring Human Dance Generation in Real World", "Authors": ["Tan Wang", "Linjie Li", "Kevin Lin", "Chung-Ching Lin", "Zhengyuan Yang", "Hanwang Zhang", "Zicheng Liu", "Lijuan Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Project Page: https://disco-dance.github.io/; Github Page: https://github.com/Wangt-CN/DisCo"]}, "abstract": "Generative AI has made significant strides in computer vision, particularly in image/video synthesis conditioned on text descriptions. Despite the advancements, it remains challenging especially in the generation of human-centric content such as dance synthesis. Existing dance synthesis methods struggle with the gap between synthesized content and real-world dance scenarios. In this paper, we define a new problem setting: Referring Human Dance Generation, which focuses on real-world dance scenarios with three important properties: (i) Faithfulness: the synthesis should retain the appearance of both human subject foreground and background from the reference image, and precisely follow the target pose; (ii) Generalizability: the model should generalize to unseen human subjects, backgrounds, and poses; (iii) Compositionality: it should allow for composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce a novel approach, DISCO, which includes a novel model architecture with disentangled control to improve the faithfulness and compositionality of dance synthesis, and an effective human attribute pre-training for better generalizability to unseen humans. Extensive qualitative and quantitative results demonstrate that DISCO can generate high-quality human dance images and videos with diverse appearances and flexible motions. Code, demo, video and visualization are available at: https://disco-dance.github.io/.", "url": "https://arxiv.org/abs/2307.00040"}, {"metadata": {"arXiv": "2307.00209", "Date": "Sat, 01 Jul 2023 03:23:56 ", "Title": "Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection", "Authors": ["Huixuan Zhang", "Xiaojun Wan"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["11 pages", "6 figures. 6 tables"]}, "abstract": "Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different models. These studies can serve as a benchmark and point out the direction of further study on multimodal hyperbole detection.", "url": "https://arxiv.org/abs/2307.00209"}, {"metadata": {"arXiv": "2307.00240", "Date": "Sat, 01 Jul 2023 06:02:22 ", "Title": "VesselMorph: Domain-Generalized Retinal Vessel Segmentation via Shape-Aware Representation", "Authors": ["Dewei Hu", "Hao Li", "Han Liu", "Xing Yao", "Jiacheng Wang", "Ipek Oguz"], "Categories": "cs.CV cs.AI"}, "abstract": "Due to the absence of a single standardized imaging protocol, domain shift between data acquired from different sites is an inherent property of medical images and has become a major obstacle for large-scale deployment of learning-based algorithms. For retinal vessel images, domain shift usually presents as the variation of intensity, contrast and resolution, while the basic tubular shape of vessels remains unaffected. Thus, taking advantage of such domain-invariant morphological features can greatly improve the generalizability of deep models. In this study, we propose a method named VesselMorph which generalizes the 2D retinal vessel segmentation task by synthesizing a shape-aware representation. Inspired by the traditional Frangi filter and the diffusion tensor imaging literature, we introduce a Hessian-based bipolar tensor field to depict the morphology of the vessels so that the shape information is taken into account. We map the intensity image and the tensor field to a latent space for feature extraction. Then we fuse the two latent representations via a weight-balancing trick and feed the result to a segmentation network. We evaluate on six public datasets of fundus and OCT angiography images from diverse patient populations. VesselMorph achieves superior generalization performance compared with competing methods in different domain shift scenarios.", "url": "https://arxiv.org/abs/2307.00240"}, {"metadata": {"arXiv": "2307.00257", "Date": "Sat, 01 Jul 2023 07:39:08 ", "Title": "Efficient Subclass Segmentation in Medical Images", "Authors": ["Linrui Dai", "Wenhui Lei", "Xiaofan Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["MICCAI 2023 early accept"]}, "abstract": "As research interests in medical image analysis become increasingly fine-grained, the cost for extensive annotation also rises. One feasible way to reduce the cost is to annotate with coarse-grained superclass labels while using limited fine-grained annotations as a complement. In this way, fine-grained data learning is assisted by ample coarse annotations. Recent studies in classification tasks have adopted this method to achieve satisfactory results. However, there is a lack of research on efficient learning of fine-grained subclasses in semantic segmentation tasks. In this paper, we propose a novel approach that leverages the hierarchical structure of categories to design network architecture. Meanwhile, a task-driven data generation method is presented to make it easier for the network to recognize different subclass categories. Specifically, we introduce a Prior Concatenation module that enhances confidence in subclass segmentation by concatenating predicted logits from the superclass classifier, a Separate Normalization module that stretches the intra-class distance within the same superclass to facilitate subclass segmentation, and a HierarchicalMix model that generates high-quality pseudo labels for unlabeled samples by fusing only similar superclass regions from labeled and unlabeled images. Our experiments on the BraTS2021 and ACDC datasets demonstrate that our approach achieves comparable accuracy to a model trained with full subclass annotations, with limited subclass annotations and sufficient superclass annotations. Our approach offers a promising solution for efficient fine-grained subclass segmentation in medical images. Our code is publicly available here.", "url": "https://arxiv.org/abs/2307.00257"}, {"metadata": {"arXiv": "2307.00407", "Date": "Sat, 01 Jul 2023 18:41:34 ", "Title": "WavePaint: Resource-efficient Token-mixer for Self-supervised Inpainting", "Authors": ["Pranav Jeevan", "Dharshan Sampath Kumar", "Amit Sethi"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "7 figures"], "ACM-class": "I.2.10; I.4.0; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.2.10; I.5.1; I.5.2; I.5.4"}, "abstract": "Image inpainting, which refers to the synthesis of missing regions in an image, can help restore occluded or degraded areas and also serve as a precursor task for self-supervision. The current state-of-the-art models for image inpainting are computationally heavy as they are based on transformer or CNN backbones that are trained in adversarial or diffusion settings. This paper diverges from vision transformers by using a computationally-efficient WaveMix-based fully convolutional architecture -- WavePaint. It uses a 2D-discrete wavelet transform (DWT) for spatial and multi-resolution token-mixing along with convolutional layers. The proposed model outperforms the current state-of-the-art models for image inpainting on reconstruction quality while also using less than half the parameter count and considerably lower training and evaluation times. Our model even outperforms current GAN-based architectures in CelebA-HQ dataset without using an adversarially trainable discriminator. Our work suggests that neural architectures that are modeled after natural image priors require fewer parameters and computations to achieve generalization comparable to transformers.", "url": "https://arxiv.org/abs/2307.00407"}, {"metadata": {"arXiv": "2307.00430", "Date": "Sat, 01 Jul 2023 21:25:03 ", "Title": "WaveMixSR: A Resource-efficient Neural Network for Image Super-resolution", "Authors": ["Pranav Jeevan", "Akella Srinidhi", "Pasunuri Prathiba", "Amit Sethi"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "3 figures"], "ACM-class": "I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.2.10; I.5.1; I.5.2; I.5.4; I.4.3; I.4.4; I.4.5"}, "abstract": "Image super-resolution research recently been dominated by transformer models which need higher computational resources than CNNs due to the quadratic complexity of self-attention. We propose a new neural network -- WaveMixSR -- for image super-resolution based on WaveMix architecture which uses a 2D-discrete wavelet transform for spatial token-mixing. Unlike transformer-based models, WaveMixSR does not unroll the image as a sequence of pixels/patches. It uses the inductive bias of convolutions along with the lossless token-mixing property of wavelet transform to achieve higher performance while requiring fewer resources and training data. We compare the performance of our network with other state-of-the-art methods for image super-resolution. Our experiments show that WaveMixSR achieves competitive performance in all datasets and reaches state-of-the-art performance in the BSD100 dataset on multiple super-resolution tasks. Our model is able to achieve this performance using less training data and computational resources while maintaining high parameter efficiency compared to current state-of-the-art models.", "url": "https://arxiv.org/abs/2307.00430"}, {"metadata": {"arXiv": "2307.00464", "Date": "Sun, 02 Jul 2023 03:24:58 ", "Title": "Human-to-Human Interaction Detection", "Authors": ["Zhenhua Wang", "Kaining Ying", "Jiajun Meng", "Jifeng Ning", "Cong Bai"], "Categories": "cs.CV cs.AI"}, "abstract": "A comprehensive understanding of interested human-to-human interactions in video streams, such as queuing, handshaking, fighting and chasing, is of immense importance to the surveillance of public security in regions like campuses, squares and parks. Different from conventional human interaction recognition, which uses choreographed videos as inputs, neglects concurrent interactive groups, and performs detection and recognition in separate stages, we introduce a new task named human-to-human interaction detection (HID). HID devotes to detecting subjects, recognizing person-wise actions, and grouping people according to their interactive relations, in one model. First, based on the popular AVA dataset created for action detection, we establish a new HID benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and 86,338 interactive groups, and each image includes up to 4 concurrent interactive groups. Second, we present a novel baseline approach SaMFormer for HID, containing a visual feature extractor, a split stage which leverages a Transformer-based model to decode action instances and interactive groups, and a merging stage which reconstructs the relationship between instances and groups. All SaMFormer components are jointly trained in an end-to-end manner. Extensive experiments on AVA-I validate the superiority of SaMFormer over representative methods. The dataset and code will be made public to encourage more follow-up studies.", "url": "https://arxiv.org/abs/2307.00464"}, {"metadata": {"arXiv": "2307.00750", "Date": "Mon, 03 Jul 2023 04:56:17 ", "Title": "Feasibility of Universal Anomaly Detection without Knowing the Abnormality in Medical Images", "Authors": ["Can Cui", "Yaohong Wang", "Shunxing Bao", "Yucheng Tang", "Ruining Deng", "Lucas W. Remedios", "Zuhayr Asad", "Joseph T. Roland", "Ken S. Lau", "Qi Liu", "Lori A. Coburn", "Keith T. Wilson", "Bennett A. Landman", "and Yuankai Huo"], "Categories": "cs.CV cs.AI"}, "abstract": "Many anomaly detection approaches, especially deep learning methods, have been recently developed to identify abnormal image morphology by only employing normal images during training. Unfortunately, many prior anomaly detection methods were optimized for a specific \"known\" abnormality (e.g., brain tumor, bone fraction, cell types). Moreover, even though only the normal images were used in the training process, the abnormal images were oftenly employed during the validation process (e.g., epoch selection, hyper-parameter tuning), which might leak the supposed ``unknown\" abnormality unintentionally. In this study, we investigated these two essential aspects regarding universal anomaly detection in medical images by (1) comparing various anomaly detection methods across four medical datasets, (2) investigating the inevitable but often neglected issues on how to unbiasedly select the optimal anomaly detection model during the validation phase using only normal images, and (3) proposing a simple decision-level ensemble method to leverage the advantage of different kinds of anomaly detection without knowing the abnormality. The results of our experiments indicate that none of the evaluated methods consistently achieved the best performance across all datasets. Our proposed method enhanced the robustness of performance in general (average AUC 0.956).", "url": "https://arxiv.org/abs/2307.00750"}, {"metadata": {"arXiv": "2307.00773", "Date": "Mon, 03 Jul 2023 06:33:49 ", "Title": "DifFSS: Diffusion Model for Few-Shot Semantic Segmentation", "Authors": ["Weimin Tan", "Siyuan Chen", "Bo Yan"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models have demonstrated excellent performance in image generation. Although various few-shot semantic segmentation (FSS) models with different network structures have been proposed, performance improvement has reached a bottleneck. This paper presents the first work to leverage the diffusion model for FSS task, called DifFSS. DifFSS, a novel FSS paradigm, can further improve the performance of the state-of-the-art FSS models by a large margin without modifying their network structure. Specifically, we utilize the powerful generation ability of diffusion models to generate diverse auxiliary support images by using the semantic mask, scribble or soft HED boundary of the support image as control conditions. This generation process simulates the variety within the class of the query image, such as color, texture variation, lighting, $etc$. As a result, FSS models can refer to more diverse support images, yielding more robust representations, thereby achieving a consistent improvement in segmentation performance. Extensive experiments on three publicly available datasets based on existing advanced FSS models demonstrate the effectiveness of the diffusion model for FSS task. Furthermore, we explore in detail the impact of different input settings of the diffusion model on segmentation performance. Hopefully, this completely new paradigm will bring inspiration to the study of FSS task integrated with AI-generated content.", "url": "https://arxiv.org/abs/2307.00773"}, {"metadata": {"arXiv": "2307.00811", "Date": "Mon, 03 Jul 2023 07:51:08 ", "Title": "Review helps learn better: Temporal Supervised Knowledge Distillation", "Authors": ["Dongwei Wang", "Zhi Han", "Yanmei Wang", "Xiai Chen", "Baichen Liu and Yandong Tang"], "Categories": "cs.CV cs.AI", "Comments": ["Under review in NIPS 2023"]}, "abstract": "Reviewing plays an important role when learning knowledge. The knowledge acquisition at a certain time point may be strongly inspired with the help of previous experience. Thus the knowledge growing procedure should show strong relationship along the temporal dimension. In our research, we find that during the network training, the evolution of feature map follows temporal sequence property. A proper temporal supervision may further improve the network training performance. Inspired by this observation, we design a novel knowledge distillation method. Specifically, we extract the spatiotemporal features in the different training phases of student by convolutional Long Short-term memory network (Conv-LSTM). Then, we train the student net through a dynamic target, rather than static teacher network features. This process realizes the refinement of old knowledge in student network, and utilizes them to assist current learning. Extensive experiments verify the effectiveness and advantages of our method over existing knowledge distillation methods, including various network architectures, different tasks (image classification and object detection) .", "url": "https://arxiv.org/abs/2307.00811"}, {"metadata": {"arXiv": "2307.00855", "Date": "Mon, 03 Jul 2023 08:48:49 ", "Title": "Review of Large Vision Models and Visual Prompt Engineering", "Authors": ["Jiaqi Wang", "Zhengliang Liu", "Lin Zhao", "Zihao Wu", "Chong Ma", "Sigang Yu", "Haixing Dai", "Qiushi Yang", "Yiheng Liu", "Songyao Zhang", "Enze Shi", "Yi Pan", "Tuo Zhang", "Dajiang Zhu", "Xiang Li", "Xi Jiang", "Bao Ge", "Yixuan Yuan", "Dinggang Shen", "Tianming Liu", "Shu Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities. As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident. Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction. This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering. We present influential large models in the visual domain and a range of prompt engineering methods employed on these models. It is our hope that this review provides a comprehensive and systematic description of prompt engineering methods based on large visual models, offering valuable insights for future researchers in their exploration of this field.", "url": "https://arxiv.org/abs/2307.00855"}, {"metadata": {"arXiv": "2307.00883", "Date": "Mon, 03 Jul 2023 09:29:27 ", "Title": "Augmenting Deep Learning Adaptation for Wearable Sensor Data through Combined Temporal-Frequency Image Encoding", "Authors": ["Yidong Zhu", "Md Mahmudur Rahman", "Mohammad Arif Ul Alam"], "Categories": "cs.CV cs.AI", "Comments": ["Under review in IEEE-EMBS International Conference on Body Sensor Networks: Sensor and Systems for Digital Health (IEEE BSN 2023)"]}, "abstract": "Deep learning advancements have revolutionized scalable classification in many domains including computer vision. However, when it comes to wearable-based classification and domain adaptation, existing computer vision-based deep learning architectures and pretrained models trained on thousands of labeled images for months fall short. This is primarily because wearable sensor data necessitates sensor-specific preprocessing, architectural modification, and extensive data collection. To overcome these challenges, researchers have proposed encoding of wearable temporal sensor data in images using recurrent plots. In this paper, we present a novel modified-recurrent plot-based image representation that seamlessly integrates both temporal and frequency domain information. Our approach incorporates an efficient Fourier transform-based frequency domain angular difference estimation scheme in conjunction with the existing temporal recurrent plot image. Furthermore, we employ mixup image augmentation to enhance the representation. We evaluate the proposed method using accelerometer-based activity recognition data and a pretrained ResNet model, and demonstrate its superior performance compared to existing approaches.", "url": "https://arxiv.org/abs/2307.00883"}, {"metadata": {"arXiv": "2307.00910", "Date": "Mon, 03 Jul 2023 10:14:33 ", "Title": "Contextual Prompt Learning for Vision-Language Understanding", "Authors": ["Koustava Goswami", "Srikrishna Karanam", "Joseph K J", "Prateksha Udhayanan and Balaji Vasan Srinivasan"], "Categories": "cs.CV cs.AI"}, "abstract": "Recent advances in multimodal learning has resulted in powerful vision-language models, whose representations are generalizable across a variety of downstream tasks. Recently, their generalizability has been further extended by incorporating trainable prompts, borrowed from the natural language processing literature. While such prompt learning techniques have shown impressive results, we identify that these prompts are trained based on global image features which limits itself in two aspects: First, by using global features, these prompts could be focusing less on the discriminative foreground image, resulting in poor generalization to various out-of-distribution test cases. Second, existing work weights all prompts equally whereas our intuition is that these prompts are more specific to the type of the image. We address these issues with as part of our proposed Contextual Prompt Learning (CoPL) framework, capable of aligning the prompts to the localized features of the image. Our key innovations over earlier works include using local image features as part of the prompt learning process, and more crucially, learning to weight these prompts based on local features that are appropriate for the task at hand. This gives us dynamic prompts that are both aligned to local image features as well as aware of local contextual relationships. Our extensive set of experiments on a variety of standard and few-shot datasets show that our method produces substantially improved performance when compared to the current state of the art methods. We also demonstrate both few-shot and out-of-distribution performance to establish the utility of learning dynamic prompts that are aligned to local image features.", "url": "https://arxiv.org/abs/2307.00910"}, {"metadata": {"arXiv": "2307.00919", "Date": "Mon, 03 Jul 2023 10:41:34 ", "Title": "Why do CNNs excel at feature extraction? A mathematical explanation", "Authors": ["Vinoth Nandakumar", "Arush Tagade", "Tongliang Liu"], "Categories": "cs.CV cs.AI", "ACM-class": "I.2.0; I.4.0"}, "abstract": "Over the past decade deep learning has revolutionized the field of computer vision, with convolutional neural network models proving to be very effective for image classification benchmarks. However, a fundamental theoretical questions remain answered: why can they solve discrete image classification tasks that involve feature extraction? We address this question in this paper by introducing a novel mathematical model for image classification, based on feature extraction, that can be used to generate images resembling real-world datasets. We show that convolutional neural network classifiers can solve these image classification tasks with zero error. In our proof, we construct piecewise linear functions that detect the presence of features, and show that they can be realized by a convolutional network.", "url": "https://arxiv.org/abs/2307.00919"}, {"metadata": {"arXiv": "2307.00997", "Date": "Mon, 03 Jul 2023 13:21:58 ", "Title": "RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation", "Authors": ["Yonglin Li and Jing Zhang and Xiao Teng and Long Lan"], "Categories": "cs.CV cs.AI", "Comments": ["The code and models will be made publicly at https://github.com/LancasterLi/RefSAM"]}, "abstract": "The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation. However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and limited understanding of different modalities, such as language and vision. This paper presents the RefSAM model, which for the first time explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps. Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts. Subsequently, a parameter-efficient tuning strategy is employed to effectively align and fuse the language and vision features. Through comprehensive ablation studies, we demonstrate the practical and effective design choices of our strategy. Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasets validate the superiority and effectiveness of our RefSAM model over existing methods. The code and models will be made publicly at \\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}.", "url": "https://arxiv.org/abs/2307.00997"}, {"metadata": {"arXiv": "2307.01187", "Date": "Mon, 03 Jul 2023 17:52:44 ", "Title": "SAMAug: Point Prompt Augmentation for Segment Anything Model", "Authors": ["Haixing Dai", "Chong Ma", "Zhengliang Liu", "Yiwei Li", "Peng Shu", "Xiaozheng Wei", "Lin Zhao", "Zihao Wu", "Dajiang Zhu", "Wei Liu", "Quanzheng Li", "Tianming Liu", "and Xiang Li"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper introduces SAMAug, a novel visual point augmentation method for the Segment Anything Model (SAM) that enhances interactive image segmentation performance. SAMAug generates augmented point prompts to provide more information to SAM. From the initial point prompt, SAM produces the initial mask, which is then fed into our proposed SAMAug to generate augmented point prompts. By incorporating these extra points, SAM can generate augmented segmentation masks based on the augmented point prompts and the initial prompt, resulting in improved segmentation performance. We evaluate four point augmentation techniques: random selection, maximum difference entropy, maximum distance, and a saliency model. Experiments on the COCO, Fundus, and Chest X-ray datasets demonstrate that SAMAug can boost SAM's segmentation results, especially using the maximum distance and saliency model methods. SAMAug underscores the potential of visual prompt engineering to advance interactive computer vision models.", "url": "https://arxiv.org/abs/2307.01187"}, {"metadata": {"arXiv": "2307.01085", "Date": "Mon, 03 Jul 2023 15:07:10 ", "Title": "Some challenges of calibrating differentiable agent-based models", "Authors": ["Arnau Quera-Bofarull", "Joel Dyer", "Anisoara Calinescu", "Michael Wooldridge"], "Categories": "cs.MA cs.AI q-fin.TR stat.ML", "Comments": ["Accepted at the ICML 2023 Differentiable Almost Everything Workshop"]}, "abstract": "Agent-based models (ABMs) are a promising approach to modelling and reasoning about complex systems, yet their application in practice is impeded by their complexity, discrete nature, and the difficulty of performing parameter inference and optimisation tasks. This in turn has sparked interest in the construction of differentiable ABMs as a strategy for combatting these difficulties, yet a number of challenges remain. In this paper, we discuss and present experiments that highlight some of these challenges, along with potential solutions.", "url": "https://arxiv.org/abs/2307.01085"}, {"metadata": {"arXiv": "2307.00114", "Date": "Fri, 30 Jun 2023 19:57:15 ", "Title": "A Personalized Household Assistive Robot that Learns and Creates New Breakfast Options through Human-Robot Interaction", "Authors": ["Ali Ayub", "Chrystopher L. Nehaniv and Kerstin Dautenhahn"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["Accepted at IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "2023"]}, "abstract": "For robots to assist users with household tasks, they must first learn about the tasks from the users. Further, performing the same task every day, in the same way, can become boring for the robot's user(s), therefore, assistive robots must find creative ways to perform tasks in the household. In this paper, we present a cognitive architecture for a household assistive robot that can learn personalized breakfast options from its users and then use the learned knowledge to set up a table for breakfast. The architecture can also use the learned knowledge to create new breakfast options over a longer period of time. The proposed cognitive architecture combines state-of-the-art perceptual learning algorithms, computational implementation of cognitive models of memory encoding and learning, a task planner for picking and placing objects in the household, a graphical user interface (GUI) to interact with the user and a novel approach for creating new breakfast options using the learned knowledge. The architecture is integrated with the Fetch mobile manipulator robot and validated, as a proof-of-concept system evaluation in a large indoor environment with multiple kitchen objects. Experimental results demonstrate the effectiveness of our architecture to learn personalized breakfast options from the user and generate new breakfast options never learned by the robot.", "url": "https://arxiv.org/abs/2307.00114"}, {"metadata": {"arXiv": "2307.00206", "Date": "Sat, 01 Jul 2023 03:13:17 ", "Title": "General Part Assembly Planning", "Authors": ["Yulong Li", "Andy Zeng", "Shuran Song"], "Categories": "cs.RO cs.AI", "Comments": ["Project website: https://general-part-assembly.github.io/"]}, "abstract": "Most successes in autonomous robotic assembly have been restricted to single target or category. We propose to investigate general part assembly, the task of creating novel target assemblies with unseen part shapes. To tackle the planning of general part assembly, we present General Part Assembly Transformer (GPAT), a transformer based model architecture that accurately predicts part poses by inferring how each part shape corresponds to the target shape. Our experiments on both 3D CAD models and real-world scans demonstrate GPAT's generalization abilities to novel and diverse target and part shapes. Project website: https://general-part-assembly.github.io/", "url": "https://arxiv.org/abs/2307.00206"}, {"metadata": {"arXiv": "2307.00329", "Date": "Sat, 01 Jul 2023 12:51:02 ", "Title": "DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment", "Authors": ["Yanjiang Guo", "Yen-Jen Wang", "Lihan Zha", "Zheyuan Jiang", "Jianyu Chen"], "Categories": "cs.RO cs.AI", "Comments": ["22 pages", "12 figures"]}, "abstract": "Large language models encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous research has explored how to ground language models in robotic tasks to ensure that the sequences generated by the language model are both logically correct and practically executable. However, low-level execution may deviate from the high-level plan due to environmental perturbations or imperfect controller design. In this paper, we propose DoReMi, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, during low-level skill execution, we use a vision question answering (VQA) model to regularly detect plan-execution misalignments. If certain misalignment occurs, our method will call the language model to re-plan in order to recover from misalignments. Experiments on various complex tasks including robot arms and humanoid robots demonstrate that our method can lead to higher task success rates and shorter task completion times. Videos of DoReMi are available at https://sites.google.com/view/doremi-paper.", "url": "https://arxiv.org/abs/2307.00329"}, {"metadata": {"arXiv": "2307.00595", "Date": "Sun, 02 Jul 2023 15:33:31 ", "Title": "RH20T: A Robotic Dataset for Learning Diverse Skills in One-Shot", "Authors": ["Hao-Shu Fang", "Hongjie Fang", "Zhenyu Tang", "Jirong Liu", "Junbo Wang", "Haoyi Zhu", "Cewu Lu"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["RSS 2023 workshop on LTAMP. The project page is at rh20t.github.io"]}, "abstract": "A key challenge in robotic manipulation in open domains is how to acquire diverse and generalizable skills for robots. Recent research in one-shot imitation learning has shown promise in transferring trained policies to new tasks based on demonstrations. This feature is attractive for enabling robots to acquire new skills and improving task and motion planning. However, due to limitations in the training dataset, the current focus of the community has mainly been on simple cases, such as push or pick-place tasks, relying solely on visual guidance. In reality, there are many complex skills, some of which may even require both visual and tactile perception to solve. This paper aims to unlock the potential for an agent to generalize to hundreds of real-world skills with multi-modal perception. To achieve this, we have collected a dataset comprising over 110,000 \\emph{contact-rich} robot manipulation sequences across diverse skills, contexts, robots, and camera viewpoints, all collected \\emph{in the real world}. Each sequence in the dataset includes visual, force, audio, and action information, along with a corresponding human demonstration video. We have invested significant efforts in calibrating all the sensors and ensuring a high-quality dataset. The dataset is made publicly available at rh20t.github.io", "url": "https://arxiv.org/abs/2307.00595"}, {"metadata": {"arXiv": "2307.01159", "Date": "Mon, 03 Jul 2023 17:10:19 ", "Title": "Soft Gripping: Specifying for Trustworthiness", "Authors": ["Dhaminda B. Abeywickrama", "Nguyen Hao Le", "Greg Chance", "Peter D. Winter", "Arianna Manzini", "Alix J. Partridge", "Jonathan Ives", "John Downer", "Graham Deacon", "Jonathan Rossiter", "Kerstin Eder", "Shane Windsor"], "Categories": "cs.RO cs.AI", "Comments": ["9 pages", "2 figures", "1 table", "34 references"], "ACM-class": "D.2.1; I.2.9"}, "abstract": "Soft robotics is an emerging technology in which engineers create flexible devices for use in a variety of applications. In order to advance the wide adoption of soft robots, ensuring their trustworthiness is essential; if soft robots are not trusted, they will not be used to their full potential. In order to demonstrate trustworthiness, a specification needs to be formulated to define what is trustworthy. However, even for soft robotic grippers, which is one of the most mature areas in soft robotics, the soft robotics community has so far given very little attention to formulating specifications. In this work, we discuss the importance of developing specifications during development of soft robotic systems, and present an extensive example specification for a soft gripper for pick-and-place tasks for grocery items. The proposed specification covers both functional and non-functional requirements, such as reliability, safety, adaptability, predictability, ethics, and regulations. We also highlight the need to promote verifiability as a first-class objective in the design of a soft gripper.", "url": "https://arxiv.org/abs/2307.01159"}, {"metadata": {"arXiv": "2307.00067", "Date": "Fri, 30 Jun 2023 18:14:20 ", "Title": "Transformers in Healthcare: A Survey", "Authors": ["Subhash Nerella", "Sabyasachi Bandyopadhyay", "Jiaqing Zhang", "Miguel Contreras", "Scott Siegel", "Aysegul Bumin", "Brandon Silva", "Jessica Sena", "Benjamin Shickel", "Azra Bihorac", "Kia Khezeli", "Parisa Rashidi"], "Categories": "cs.AI cs.CY cs.LG"}, "abstract": "With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of data, including medical imaging, structured and unstructured Electronic Health Records (EHR), social media, physiological signals, and biomolecular sequences. Those models could help in clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. We identified relevant studies using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.", "url": "https://arxiv.org/abs/2307.00067"}, {"metadata": {"arXiv": "2307.00171", "Date": "Fri, 30 Jun 2023 23:33:11 ", "Title": "The Integer Linear Programming Inference Cookbook", "Authors": ["Vivek Srikumar", "Dan Roth"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Over the years, integer linear programs have been employed to model inference in many natural language processing problems. This survey is meant to guide the reader through the process of framing a new inference problem as an instance of an integer linear program and is structured as a collection of recipes. At the end, we will see two worked examples to illustrate the use of these recipes.", "url": "https://arxiv.org/abs/2307.00171"}, {"metadata": {"arXiv": "2307.00028", "Date": "Thu, 29 Jun 2023 00:24:42 ", "Title": "Seeing in Words: Learning to Classify through Language Bottlenecks", "Authors": ["Khalid Saifullah", "Yuxin Wen", "Jonas Geiping", "Micah Goldblum", "Tom Goldstein"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["5 pages", "2 figures", "Published as a Tiny Paper at ICLR 2023"]}, "abstract": "Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature representations are text. We show that such a model can effectively classify ImageNet images, and we discuss the challenges we encountered when training it.", "url": "https://arxiv.org/abs/2307.00028"}, {"metadata": {"arXiv": "2307.00104", "Date": "Fri, 30 Jun 2023 19:45:43 ", "Title": "Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems", "Authors": ["Uma Meleti and Abolfazl Razi"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["6 pages", "6 figures"]}, "abstract": "This research paper addresses the challenge of detecting obscured wildfires (when the fire flames are covered by trees, smoke, clouds, and other natural barriers) in real-time using drones equipped only with RGB cameras. We propose a novel methodology that employs semantic segmentation based on the temporal analysis of smoke patterns in video sequences. Our approach utilizes an encoder-decoder architecture based on deep convolutional neural network architecture with a pre-trained CNN encoder and 3D convolutions for decoding while using sequential stacking of features to exploit temporal variations. The predicted fire locations can assist drones in effectively combating forest fires and pinpoint fire retardant chemical drop on exact flame locations. We applied our method to a curated dataset derived from the FLAME2 dataset that includes RGB video along with IR video to determine the ground truth. Our proposed method has a unique property of detecting obscured fire and achieves a Dice score of 85.88%, while achieving a high precision of 92.47% and classification accuracy of 90.67% on test data showing promising results when inspected visually. Indeed, our method outperforms other methods by a significant margin in terms of video-level fire classification as we obtained about 100% accuracy using MobileNet+CBAM as the encoder backbone.", "url": "https://arxiv.org/abs/2307.00104"}, {"metadata": {"arXiv": "2307.00154", "Date": "Fri, 30 Jun 2023 22:05:34 ", "Title": "Stitched ViTs are Flexible Vision Backbones", "Authors": ["Zizheng Pan", "Jing Liu", "Haoyu He", "Jianfei Cai", "Bohan Zhuang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Tech report"]}, "abstract": "Large pretrained plain vision Transformers (ViTs) have been the workhorse for many downstream tasks. However, existing works utilizing off-the-shelf ViTs are inefficient in terms of training and deployment, because adopting ViTs with individual sizes requires separate training and is restricted by fixed performance-efficiency trade-offs. In this paper, we are inspired by stitchable neural networks, which is a new framework that cheaply produces a single model that covers rich subnetworks by stitching pretrained model families, supporting diverse performance-efficiency trade-offs at runtime. Building upon this foundation, we introduce SN-Netv2, a systematically improved model stitching framework to facilitate downstream task adaptation. Specifically, we first propose a Two-way stitching scheme to enlarge the stitching space. We then design a resource-constrained sampling strategy that takes into account the underlying FLOPs distributions in the space for improved sampling. Finally, we observe that learning stitching layers is a low-rank update, which plays an essential role on downstream tasks to stabilize training and ensure a good Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K, COCO-Stuff-10K, NYUv2 and COCO-2017, SN-Netv2 demonstrates strong ability to serve as a flexible vision backbone, achieving great advantages in both training efficiency and adaptation. Code will be released at https://github.com/ziplab/SN-Netv2.", "url": "https://arxiv.org/abs/2307.00154"}, {"metadata": {"arXiv": "2307.00231", "Date": "Sat, 01 Jul 2023 05:39:28 ", "Title": "Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study", "Authors": ["Sidike Paheding and Abel A. Reyes-Angulo"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The back-propagation algorithm has long been the de-facto standard in optimizing weights and biases in neural networks, particularly in cutting-edge deep learning models. Its widespread adoption in fields like natural language processing, computer vision, and remote sensing has revolutionized automation in various tasks. The popularity of back-propagation stems from its ability to achieve outstanding performance in tasks such as classification, detection, and segmentation. Nevertheless, back-propagation is not without its limitations, encompassing sensitivity to initial conditions, vanishing gradients, overfitting, and computational complexity. The recent introduction of a forward-forward algorithm (FFA), which computes local goodness functions to optimize network parameters, alleviates the dependence on substantial computational resources and the constant need for architectural scaling. This study investigates the application of FFA for hyperspectral image classification. Experimental results and comparative analysis are provided with the use of the traditional back-propagation algorithm. Preliminary results show the potential behind FFA and its promises.", "url": "https://arxiv.org/abs/2307.00231"}, {"metadata": {"arXiv": "2307.00306", "Date": "Sat, 01 Jul 2023 11:28:53 ", "Title": "SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation", "Authors": ["Fabian Duffhauss", "Sebastian Koch", "Hanna Ziesche", "Ngo Anh Vien and Gerhard Neumann"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at the IEEE Robotics and Automation Letters (RA-L) 2023"]}, "abstract": "Detecting objects and estimating their 6D poses is essential for automated systems to interact safely with the environment. Most 6D pose estimators, however, rely on a single camera frame and suffer from occlusions and ambiguities due to object symmetries. We overcome this issue by presenting a novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach efficiently fuses the RGB-D frames from multiple perspectives in a deep multi-directional fusion network and predicts predefined keypoints for all objects in the scene simultaneously. Based on the keypoints and an instance semantic segmentation, we efficiently compute the 6D poses by least-squares fitting. To address the ambiguity issues for symmetric objects, we propose a novel training procedure for symmetry-aware keypoint detection including a new objective function. Our SyMFM6D network significantly outperforms the state-of-the-art in both single-view and multi-view 6D pose estimation. We furthermore show the effectiveness of our symmetry-aware training procedure and demonstrate that our approach is robust towards inaccurate camera calibration and dynamic camera setups.", "url": "https://arxiv.org/abs/2307.00306"}, {"metadata": {"arXiv": "2307.00398", "Date": "Sat, 01 Jul 2023 18:16:06 ", "Title": "ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models", "Authors": ["Uddeshya Upadhyay", "Shyamgopal Karthik", "Massimiliano Mancini", "Zeynep Akata"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose active learning and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly, we present a novel technique for visualizing the embedding distributions using a large-scale pre-trained latent diffusion model.", "url": "https://arxiv.org/abs/2307.00398"}, {"metadata": {"arXiv": "2307.00522", "Date": "Sun, 02 Jul 2023 09:11:09 ", "Title": "LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance", "Authors": ["Linoy Tsaban (1)", "Apolin\\'ario Passos (1) ((1) Hugging Face)"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "5 figures", "1 table. This report builds up on the works introduced in - arXiv:2304.06140", "arXiv:2301.12247"]}, "abstract": "Recent large-scale text-guided diffusion models provide powerful image-generation capabilities. Currently, a significant effort is given to enable the modification of these images using text only as means to offer intuitive and versatile editing. However, editing proves to be difficult for these generative models due to the inherent nature of editing techniques, which involves preserving certain content from the original image. Conversely, in text-based models, even minor modifications to the text prompt frequently result in an entirely distinct result, making attaining one-shot generation that accurately corresponds to the users intent exceedingly challenging. In addition, to edit a real image using these state-of-the-art tools, one must first invert the image into the pre-trained models domain - adding another factor affecting the edit quality, as well as latency. In this exploratory report, we propose LEDITS - a combined lightweight approach for real-image editing, incorporating the Edit Friendly DDPM inversion technique with Semantic Guidance, thus extending Semantic Guidance to real image editing, while harnessing the editing capabilities of DDPM inversion as well. This approach achieves versatile edits, both subtle and extensive as well as alterations in composition and style, while requiring no optimization nor extensions to the architecture.", "url": "https://arxiv.org/abs/2307.00522"}, {"metadata": {"arXiv": "2307.00617", "Date": "Sun, 02 Jul 2023 17:01:28 ", "Title": "The Forward-Forward Algorithm as a feature extractor for skin lesion classification: A preliminary study", "Authors": ["Abel Reyes-Angulo and Sidike Paheding"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["This is a camera-ready version of the paper for the LXAI @ ICML'23 workshop"]}, "abstract": "Skin cancer, a deadly form of cancer, exhibits a 23\\% survival rate in the USA with late diagnosis. Early detection can significantly increase the survival rate, and facilitate timely treatment. Accurate biomedical image classification is vital in medical analysis, aiding clinicians in disease diagnosis and treatment. Deep learning (DL) techniques, such as convolutional neural networks and transformers, have revolutionized clinical decision-making automation. However, computational cost and hardware constraints limit the implementation of state-of-the-art DL architectures. In this work, we explore a new type of neural network that does not need backpropagation (BP), namely the Forward-Forward Algorithm (FFA), for skin lesion classification. While FFA is claimed to use very low-power analog hardware, BP still tends to be superior in terms of classification accuracy. In addition, our experimental results suggest that the combination of FFA and BP can be a better alternative to achieve a more accurate prediction.", "url": "https://arxiv.org/abs/2307.00617"}, {"metadata": {"arXiv": "2307.00648", "Date": "Sun, 02 Jul 2023 19:56:43 ", "Title": "Intra- & Extra-Source Exemplar-Based Style Synthesis for Improved Domain Generalization", "Authors": ["Yumeng Li", "Dan Zhang", "Margret Keuper", "Anna Khoreva"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["An extended version of the accepted WACV paper arXiv:2210.10175"]}, "abstract": "The generalization with respect to domain shifts, as they frequently appear in applications such as autonomous driving, is one of the remaining big challenges for deep learning models. Therefore, we propose an exemplar-based style synthesis pipeline to improve domain generalization in semantic segmentation. Our method is based on a novel masked noise encoder for StyleGAN2 inversion. The model learns to faithfully reconstruct the image, preserving its semantic layout through noise prediction. Using the proposed masked noise encoder to randomize style and content combinations in the training set, i.e., intra-source style augmentation (ISSA) effectively increases the diversity of training data and reduces spurious correlation. As a result, we achieve up to $12.4\\%$ mIoU improvements on driving-scene semantic segmentation under different types of data shifts, i.e., changing geographic locations, adverse weather conditions, and day to night. ISSA is model-agnostic and straightforwardly applicable with CNNs and Transformers. It is also complementary to other domain generalization techniques, e.g., it improves the recent state-of-the-art solution RobustNet by $3\\%$ mIoU in Cityscapes to Dark Z\\\"urich. In addition, we demonstrate the strong plug-n-play ability of the proposed style synthesis pipeline, which is readily usable for extra-source exemplars e.g., web-crawled images, without any retraining or fine-tuning. Moreover, we study a new use case to indicate neural network's generalization capability by building a stylized proxy validation set. This application has significant practical sense for selecting models to be deployed in the open-world environment. Our code is available at \\url{https://github.com/boschresearch/ISSA}.", "url": "https://arxiv.org/abs/2307.00648"}, {"metadata": {"arXiv": "2307.00764", "Date": "Mon, 03 Jul 2023 06:02:15 ", "Title": "Hierarchical Open-vocabulary Universal Image Segmentation", "Authors": ["Xudong Wang and Shufan Li and Konstantinos Kallidromitis and Yusuke Kato and Kazuki Kozuka and Trevor Darrell"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project web-page: http://people.eecs.berkeley.edu/~xdwang/projects/HIPIE/"]}, "abstract": "Open-vocabulary image segmentation aims to partition an image into semantic regions according to arbitrary text descriptions. However, complex visual scenes can be naturally decomposed into simpler parts and abstracted at multiple levels of granularity, introducing inherent segmentation ambiguity. Unlike existing methods that typically sidestep this ambiguity and treat it as an external factor, our approach actively incorporates a hierarchical representation encompassing different semantic-levels into the learning process. We propose a decoupled text-image fusion mechanism and representation learning modules for both \"things\" and \"stuff\".1 Additionally, we systematically examine the differences that exist in the textual and visual features between these types of categories. Our resulting model, named HIPIE, tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within a unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO, Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the state-of-the-art results at various levels of image comprehension, including semantic-level (e.g., semantic segmentation), instance-level (e.g., panoptic/referring segmentation and object detection), as well as part-level (e.g., part/subpart segmentation) tasks. Our code is released at https://github.com/berkeley-hipie/HIPIE.", "url": "https://arxiv.org/abs/2307.00764"}, {"metadata": {"arXiv": "2307.01139", "Date": "Mon, 03 Jul 2023 16:25:49 ", "Title": "SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions", "Authors": ["Sameera Horawalavithana", "Sai Munikoti", "Ian Stewart", "Henry Kvinge"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Preprint. Work in progress"]}, "abstract": "Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity, this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines, concepts and goals. In this work, we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions. To test our methodology, we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding. In comparison to the models that are finetuned with machine generated data only, LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark.", "url": "https://arxiv.org/abs/2307.01139"}, {"metadata": {"arXiv": "2307.01199", "Date": "Mon, 03 Jul 2023 17:59:20 ", "Title": "NeuBTF: Neural fields for BTF encoding and transfer", "Authors": ["Carlos Rodriguez-Pardo", "Konstantinos Kazatzis", "Jorge Lopez-Moreno", "Elena Garces"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["9 pages", "7 figures. Accepted to Computers & Graphics (Special Section on CEIG 2023). Project Website: https://carlosrodriguezpardo.es/projects/NeuBTF/"], "MSC-class": "68T07 (Primary) 68T45, 68U10, 68U05 (Secondary)", "ACM-class": "I.4.0; I.2.6; I.3.0", "Journal-ref": "Computers & Graphics, Volume 114, 2023, Pages 239-246, ISSN 0097-8493", "DOI": "10.1016/j.cag.2023.06.018"}, "abstract": "Neural material representations are becoming a popular way to represent materials for rendering. They are more expressive than analytic models and occupy less memory than tabulated BTFs. However, existing neural materials are immutable, meaning that their output for a certain query of UVs, camera, and light vector is fixed once they are trained. While this is practical when there is no need to edit the material, it can become very limiting when the fragment of the material used for training is too small or not tileable, which frequently happens when the material has been captured with a gonioreflectometer. In this paper, we propose a novel neural material representation which jointly tackles the problems of BTF compression, tiling, and extrapolation. At test time, our method uses a guidance image as input to condition the neural BTF to the structural features of this input image. Then, the neural BTF can be queried as a regular BTF using UVs, camera, and light vectors. Every component in our framework is purposefully designed to maximize BTF encoding quality at minimal parameter count and computational complexity, achieving competitive compression rates compared with previous work. We demonstrate the results of our method on a variety of synthetic and captured materials, showing its generality and capacity to learn to represent many optical properties.", "url": "https://arxiv.org/abs/2307.01199"}, {"metadata": {"arXiv": "2307.00161", "Date": "Fri, 30 Jun 2023 22:32:44 ", "Title": "FFPDG: Fast, Fair and Private Data Generation", "Authors": ["Weijie Xu", "Jinjin Zhao", "Francis Iannacci", "Bo Wang"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "2 figures", "ICLR 2021 Workshop on Synthetic Data Generation"], "MSC-class": "94-10", "Journal-ref": "ICLR 2021 Workshop on Synthetic Data Generation"}, "abstract": "Generative modeling has been used frequently in synthetic data generation. Fairness and privacy are two big concerns for synthetic data. Although Recent GAN [\\cite{goodfellow2014generative}] based methods show good results in preserving privacy, the generated data may be more biased. At the same time, these methods require high computation resources. In this work, we design a fast, fair, flexible and private data generation method. We show the effectiveness of our method theoretically and empirically. We show that models trained on data generated by the proposed method can perform well (in inference stage) on real application scenarios.", "url": "https://arxiv.org/abs/2307.00161"}, {"metadata": {"arXiv": "2307.00185", "Date": "Sat, 01 Jul 2023 01:07:20 ", "Title": "An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application", "Authors": ["Jing Nan", "Wei Dai", "Guan Yuan", "and Ping Zhou"], "Categories": "cs.LG cs.AI"}, "abstract": "Incremental random weight neural networks (IRWNNs) have gained attention in view of its easy implementation and fast learning. However, a significant drawback of IRWNNs is that the elationship between the hidden parameters (node)and the residual error (model performance) is difficult to be interpreted. To address the above issue, this article proposes an interpretable constructive algorithm (ICA) with geometric information constraint. First, based on the geometric relationship between the hidden parameters and the residual error, an interpretable geometric information constraint is proposed to randomly assign the hidden parameters. Meanwhile, a node pool strategy is employed to obtain hidden parameters that is more conducive to convergence from hidden parameters satisfying the proposed constraint. Furthermore, the universal approximation property of the ICA is proved. Finally, a lightweight version of ICA is presented for large-scale data modeling tasks. Experimental results on six benchmark datasets and a numerical simulation dataset demonstrate that the ICA outperforms other constructive algorithms in terms of modeling speed, model accuracy, and model network structure. Besides, two practical industrial application case are used to validate the effectiveness of ICA in practical applications.", "url": "https://arxiv.org/abs/2307.00185"}, {"metadata": {"arXiv": "2307.00252", "Date": "Sat, 01 Jul 2023 07:17:33 ", "Title": "An ML approach to resolution of singularities", "Authors": ["Gergely B\\'erczi and Honglu Fan and Mingcong Zeng"], "Categories": "cs.LG cs.AI cs.SC math.AG", "Comments": ["To appear in Proceedings of the 40th International Conference on Machine Learning TAG Workshop (ICML-TAG 2023)"]}, "abstract": "The solution set of a system of polynomial equations typically contains ill-behaved, singular points. Resolution is a fundamental process in geometry in which we replace singular points with smooth points, while keeping the rest of the solution set unchanged. Resolutions are not unique: the usual way to describe them involves repeatedly performing a fundamental operation known as \"blowing-up\", and the complexity of the resolution highly depends on certain choices. The process can be translated into various versions of a 2-player game, the so-called Hironaka game, and a winning strategy for the first player provides a solution to the resolution problem. In this paper we introduce a new approach to the Hironaka game that uses reinforcement learning agents to find optimal resolutions of singularities. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.", "url": "https://arxiv.org/abs/2307.00252"}, {"metadata": {"arXiv": "2307.00280", "Date": "Sat, 01 Jul 2023 09:22:54 ", "Title": "SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency", "Authors": ["Yan Wang", "Yuhang Li", "Ruihao Gong", "Aishan Liu", "Yanfei Wang", "Jian Hu", "Yongqiang Yao", "Yunchen Zhang", "Tianzi Xiao", "Fengwei Yu", "Xianglong Liu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Proceedings of Machine Learning and Systems. 2023 Mar 18"], "Journal-ref": "Proceedings of Machine Learning and Systems 2023"}, "abstract": "Extensive studies have shown that deep learning models are vulnerable to adversarial and natural noises, yet little is known about model robustness on noises caused by different system implementations. In this paper, we for the first time introduce SysNoise, a frequently occurred but often overlooked noise in the deep learning training-deployment cycle. In particular, SysNoise happens when the source training system switches to a disparate target system in deployments, where various tiny system mismatch adds up to a non-negligible difference. We first identify and classify SysNoise into three categories based on the inference stage; we then build a holistic benchmark to quantitatively measure the impact of SysNoise on 20+ models, comprehending image classification, object detection, instance segmentation and natural language processing tasks. Our extensive experiments revealed that SysNoise could bring certain impacts on model robustness across different tasks and common mitigations like data augmentation and adversarial training show limited effects on it. Together, our findings open a new research topic and we hope this work will raise research attention to deep learning deployment systems accounting for model performance. We have open-sourced the benchmark and framework at https://modeltc.github.io/systemnoise_web.", "url": "https://arxiv.org/abs/2307.00280"}, {"metadata": {"arXiv": "2307.00310", "Date": "Sat, 01 Jul 2023 11:51:56 ", "Title": "Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD", "Authors": ["Anvith Thudi", "Hengrui Jia", "Casey Meehan", "Ilia Shumailov", "Nicolas Papernot"], "Categories": "cs.LG cs.AI cs.CR stat.ML"}, "abstract": "Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we observe that correctly classified points obtain better privacy guarantees than misclassified points.", "url": "https://arxiv.org/abs/2307.00310"}, {"metadata": {"arXiv": "2307.00316", "Date": "Sat, 01 Jul 2023 12:05:20 ", "Title": "SHARCS: Shared Concept Space for Explainable Multimodal Learning", "Authors": ["Gabriele Dominici", "Pietro Barbiero", "Lucie Charlotte Magister", "Pietro Li\\`o", "Nikola Simidjievski"], "Categories": "cs.LG cs.AI"}, "abstract": "Multimodal learning is an essential paradigm for addressing complex real-world problems, where individual data modalities are typically insufficient to accurately solve a given modelling task. While various deep learning approaches have successfully addressed these challenges, their reasoning process is often opaque; limiting the capabilities for a principled explainable cross-modal analysis and any domain-expert intervention. In this paper, we introduce SHARCS (SHARed Concept Space) -- a novel concept-based approach for explainable multimodal learning. SHARCS learns and maps interpretable concepts from different heterogeneous modalities into a single unified concept-manifold, which leads to an intuitive projection of semantically similar cross-modal concepts. We demonstrate that such an approach can lead to inherently explainable task predictions while also improving downstream predictive performance. Moreover, we show that SHARCS can operate and significantly outperform other approaches in practically significant scenarios, such as retrieval of missing modalities and cross-modal explanations. Our approach is model-agnostic and easily applicable to different types (and number) of modalities, thus advancing the development of effective, interpretable, and trustworthy multimodal approaches.", "url": "https://arxiv.org/abs/2307.00316"}, {"metadata": {"arXiv": "2307.00331", "Date": "Sat, 01 Jul 2023 13:01:39 ", "Title": "Variation-aware Vision Transformer Quantization", "Authors": ["Xijie Huang", "Zhiqiang Shen", "Kwang-Ting Cheng"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Code is available at https://github.com/HuangOwen/VVTQ"]}, "abstract": "Despite the remarkable performance of Vision Transformers (ViTs) in various visual tasks, the expanding computation and model size of ViTs have increased the demand for improved efficiency during training and inference. To address the heavy computation and parameter drawbacks, quantization is frequently studied in the community as a representative model compression technique and has seen extensive use on CNNs. However, due to the unique properties of CNNs and ViTs, the quantization applications on ViTs are still limited and underexplored. In this paper, we identify the difficulty of ViT quantization on its unique variation behaviors, which differ from traditional CNN architectures. The variations indicate the magnitude of the parameter fluctuations and can also measure outlier conditions. Moreover, the variation behaviors reflect the various sensitivities to the quantization of each module. The quantization sensitivity analysis and comparison of ViTs with CNNs help us locate the underlying differences in variations. We also find that the variations in ViTs cause training oscillations, bringing instability during quantization-aware training (QAT). Correspondingly, we solve the variation problem with an efficient knowledge-distillation-based variation-aware quantization method. The multi-crop knowledge distillation scheme can accelerate and stabilize the training and alleviate the variation's influence during QAT. We also proposed a module-dependent quantization scheme and a variation-aware regularization term to suppress the oscillation of weights. On ImageNet-1K, we obtain a 77.66% Top-1 accuracy on the extremely low-bit scenario of 2-bit Swin-T, outperforming the previous state-of-the-art quantized model by 3.35%.", "url": "https://arxiv.org/abs/2307.00331"}, {"metadata": {"arXiv": "2307.00359", "Date": "Sat, 01 Jul 2023 15:09:38 ", "Title": "When Synthetic Data Met Regulation", "Authors": ["Georgi Ganev"], "Categories": "cs.LG cs.AI cs.CR cs.CY", "Comments": ["Accepted to the 1st Workshop on Generative AI and Law (GenLaw 2023)", "part of ICML 2023"]}, "abstract": "In this paper, we argue that synthetic data produced by Differentially Private generative models can be sufficiently anonymized and, therefore, anonymous data and regulatory compliant.", "url": "https://arxiv.org/abs/2307.00359"}, {"metadata": {"arXiv": "2307.00361", "Date": "Sat, 01 Jul 2023 15:18:00 ", "Title": "A Comparative Study of Machine Learning Algorithms for Anomaly Detection in Industrial Environments: Performance and Environmental Impact", "Authors": ["\\'Alvaro Huertas-Garc\\'ia and Carlos Mart\\'i-Gonz\\'alez and Rub\\'en Garc\\'ia Maezo and Alejandro Echeverr\\'ia Rey"], "Categories": "cs.LG cs.AI", "Comments": ["29 references", "8 figures", "9 tables", "18 pages"]}, "abstract": "In the context of Industry 4.0, the use of artificial intelligence (AI) and machine learning for anomaly detection is being hampered by high computational requirements and associated environmental effects. This study seeks to address the demands of high-performance machine learning models with environmental sustainability, contributing to the emerging discourse on 'Green AI.' An extensive variety of machine learning algorithms, coupled with various Multilayer Perceptron (MLP) configurations, were meticulously evaluated. Our investigation encapsulated a comprehensive suite of evaluation metrics, comprising Accuracy, Area Under the Curve (AUC), Recall, Precision, F1 Score, Kappa Statistic, Matthews Correlation Coefficient (MCC), and F1 Macro. Simultaneously, the environmental footprint of these models was gauged through considerations of time duration, CO2 equivalent, and energy consumption during the training, cross-validation, and inference phases. Traditional machine learning algorithms, such as Decision Trees and Random Forests, demonstrate robust efficiency and performance. However, superior outcomes were obtained with optimised MLP configurations, albeit with a commensurate increase in resource consumption. The study incorporated a multi-objective optimisation approach, invoking Pareto optimality principles, to highlight the trade-offs between a model's performance and its environmental impact. The insights derived underscore the imperative of striking a balance between model performance, complexity, and environmental implications, thus offering valuable directions for future work in the development of environmentally conscious machine learning models for industrial applications.", "url": "https://arxiv.org/abs/2307.00361"}, {"metadata": {"arXiv": "2307.00364", "Date": "Sat, 01 Jul 2023 15:24:47 ", "Title": "The future of human-centric eXplainable Artificial Intelligence (XAI) is not post-hoc explanations", "Authors": ["Vinitra Swamy", "Jibril Frej", "Tanja K\\\"aser"], "Categories": "cs.LG cs.AI cs.CY cs.HC", "Comments": ["Viewpoint paper", "under review at JAIR"]}, "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in enabling human understanding and trust in deep learning systems, often defined as determining which features are most important to a model's prediction. As models get larger, more ubiquitous, and pervasive in aspects of daily life, explainability is necessary to avoid or minimize adverse effects of model mistakes. Unfortunately, current approaches in human-centric XAI (e.g. predictive tasks in healthcare, education, or personalized ads) tend to rely on a single explainer. This is a particularly concerning trend when considering that recent work has identified systematic disagreement in explainability methods when applied to the same points and underlying black-box models. In this paper, we therefore present a call for action to address the limitations of current state-of-the-art explainers. We propose to shift from post-hoc explainability to designing interpretable neural network architectures; moving away from approximation techniques in human-centric and high impact applications. We identify five needs of human-centric XAI (real-time, accurate, actionable, human-interpretable, and consistent) and propose two schemes for interpretable-by-design neural network workflows (adaptive routing for interpretable conditional computation and diagnostic benchmarks for iterative model learning). We postulate that the future of human-centric XAI is neither in explaining black-boxes nor in reverting to traditional, interpretable models, but in neural networks that are intrinsically interpretable.", "url": "https://arxiv.org/abs/2307.00364"}, {"metadata": {"arXiv": "2307.00368", "Date": "Sat, 01 Jul 2023 15:44:01 ", "Title": "Minimizing Energy Consumption of Deep Learning Models by Energy-Aware Training", "Authors": ["Dario Lazzaro", "Antonio Emanuele Cin\\`a", "Maura Pintor", "Ambra Demontis", "Battista Biggio", "Fabio Roli", "Marcello Pelillo"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["12 pages", "3 figures. Paper accepted at the 22nd International Conference on Image Analysis and Processing (ICIAP) 2023"]}, "abstract": "Deep learning models undergo a significant increase in the number of parameters they possess, leading to the execution of a larger number of operations during inference. This expansion significantly contributes to higher energy consumption and prediction latency. In this work, we propose EAT, a gradient-based algorithm that aims to reduce energy consumption during model training. To this end, we leverage a differentiable approximation of the $\\ell_0$ norm, and use it as a sparse penalty over the training loss. Through our experimental analysis conducted on three datasets and two deep neural networks, we demonstrate that our energy-aware training algorithm EAT is able to train networks with a better trade-off between classification performance and energy efficiency.", "url": "https://arxiv.org/abs/2307.00368"}, {"metadata": {"arXiv": "2307.00384", "Date": "Sat, 01 Jul 2023 16:52:18 ", "Title": "CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis", "Authors": ["Abdallah Alshantti", "Damiano Varagnolo", "Adil Rasheed", "Aria Rahmati and Frank Westad"], "Categories": "cs.LG cs.AI"}, "abstract": "Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilized for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model well captures the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.", "url": "https://arxiv.org/abs/2307.00384"}, {"metadata": {"arXiv": "2307.00426", "Date": "Sat, 01 Jul 2023 20:59:05 ", "Title": "Sparsity aware generalization theory for deep neural networks", "Authors": ["Ramchandran Muthukumar", "Jeremias Sulam"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors in specific settings, even in over-parametrized models.", "url": "https://arxiv.org/abs/2307.00426"}, {"metadata": {"arXiv": "2307.00493", "Date": "Sun, 02 Jul 2023 06:48:19 ", "Title": "Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting", "Authors": ["Nhat Thanh Tran", "Jack Xin"], "Categories": "cs.LG cs.AI", "Comments": ["13 pages (main)", "2 pages (appendix)", "2 figures"]}, "abstract": "We study a fast local-global window-based attention method to accelerate Informer for long sequence time-series forecasting. While window attention is local and a considerable computational saving, it lacks the ability to capture global token information which is compensated by a subsequent Fourier transform block. Our method, named FWin, does not rely on query sparsity hypothesis and an empirical approximation underlying the ProbSparse attention of Informer. Through experiments on univariate and multivariate datasets, we show that FWin transformers improve the overall prediction accuracies of Informer while accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear regression model that a learned FWin type attention approaches or even outperforms softmax full attention based on key vectors extracted from an Informer model's full attention layer acting on time series data.", "url": "https://arxiv.org/abs/2307.00493"}, {"metadata": {"arXiv": "2307.00495", "Date": "Sun, 02 Jul 2023 06:56:52 ", "Title": "STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural Networks for Traffic Prediction", "Authors": ["Xunlian Luo", "Chunjiang Zhu", "Detian Zhang", "Qing Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Traffic prediction has been an active research topic in the domain of spatial-temporal data mining. Accurate real-time traffic prediction is essential to improve the safety, stability, and versatility of smart city systems, i.e., traffic control and optimal routing. The complex and highly dynamic spatial-temporal dependencies make effective predictions still face many challenges. Recent studies have shown that spatial-temporal graph neural networks exhibit great potential applied to traffic prediction, which combines sequential models with graph convolutional networks to jointly model temporal and spatial correlations. However, a survey study of graph learning, spatial-temporal graph models for traffic, as well as a fair comparison of baseline models are pending and unavoidable issues. In this paper, we first provide a systematic review of graph learning strategies and commonly used graph convolution algorithms. Then we conduct a comprehensive analysis of the strengths and weaknesses of recently proposed spatial-temporal graph network models. Furthermore, we build a study called STG4Traffic using the deep learning framework PyTorch to establish a standardized and scalable benchmark on two types of traffic datasets. We can evaluate their performance by personalizing the model settings with uniform metrics. Finally, we point out some problems in the current study and discuss future directions. Source codes are available at https://github.com/trainingl/STG4Traffic.", "url": "https://arxiv.org/abs/2307.00495"}, {"metadata": {"arXiv": "2307.00497", "Date": "Sun, 02 Jul 2023 07:06:45 ", "Title": "Don't Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory", "Authors": ["Sara Babakniya", "Zalan Fabian", "Chaoyang He", "Mahdi Soltanolkotabi", "Salman Avestimehr"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep learning models are prone to forgetting information learned in the past when trained on new data. This problem becomes even more pronounced in the context of federated learning (FL), where data is decentralized and subject to independent changes for each user. Continual Learning (CL) studies this so-called \\textit{catastrophic forgetting} phenomenon primarily in centralized settings, where the learner has direct access to the complete training dataset. However, applying CL techniques to FL is not straightforward due to privacy concerns and resource limitations. This paper presents a framework for federated class incremental learning that utilizes a generative model to synthesize samples from past distributions instead of storing part of past data. Then, clients can leverage the generative model to mitigate catastrophic forgetting locally. The generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Therefore, it reduces the risk of data leakage as opposed to training it on the client's private data. We demonstrate significant improvements for the CIFAR-100 dataset compared to existing baselines.", "url": "https://arxiv.org/abs/2307.00497"}, {"metadata": {"arXiv": "2307.00504", "Date": "Sun, 02 Jul 2023 07:38:56 ", "Title": "On efficient computation in active inference", "Authors": ["Aswin Paul", "Noor Sajid", "Lancelot Da Costa", "Adeel Razi"], "Categories": "cs.LG cs.AI q-bio.NC", "Comments": ["23 pages", "7 figures. Project repo: https://github.com/aswinpaul/dpefe_2023"]}, "abstract": "Despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behaviour in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behaviour even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.", "url": "https://arxiv.org/abs/2307.00504"}, {"metadata": {"arXiv": "2307.00507", "Date": "Sun, 02 Jul 2023 07:50:36 ", "Title": "Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with Stochastic Configuration Networks", "Authors": ["Wei Dai", "Jiang Liu", "and Lanhao Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Fault diagnosis of rolling bearings is of great significance for post-maintenance in rotating machinery, but it is a challenging work to diagnose faults efficiently with a few samples. Additionally, faults commonly occur with randomness and fuzziness due to the complexity of the external environment and the structure of rolling bearings, hindering effective mining of fault characteristics and eventually restricting accuracy of fault diagnosis. To overcome these problems, stochastic configuration network (SCN) based cloud ensemble learning, called SCN-CEL, is developed in this work. Concretely, a cloud feature extraction method is first developed by using a backward cloud generator of normal cloud model to mine the uncertainty of fault information. Then, a cloud sampling method, which generates enough cloud droplets using bidirectional cloud generator, is proposed to extend the cloud feature samples. Finally, an ensemble model with SCNs is developed to comprehensively characterize the uncertainty of fault information and advance the generalization performance of fault diagnosis machine. Experimental results demonstrate that the proposed method indeed performs favorably for distinguishing fault categories of rolling bearings in the few shot scenarios.", "url": "https://arxiv.org/abs/2307.00507"}, {"metadata": {"arXiv": "2307.00518", "Date": "Sun, 02 Jul 2023 08:53:10 ", "Title": "DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for Traffic Forecasting", "Authors": ["Binqing Wu", "Ling Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Traffic forecasting is essential to intelligent transportation systems, which is challenging due to the complicated spatial and temporal dependencies within a road network. Existing works usually learn spatial and temporal dependencies separately, ignoring the dependencies crossing spatial and temporal dimensions. In this paper, we propose DSTCGCN, a dynamic spatial-temporal cross graph convolution network to learn dynamic spatial and temporal dependencies jointly via graphs for traffic forecasting. Specifically, we introduce a fast Fourier transform (FFT) based attentive selector to choose relevant time steps for each time step based on time-varying traffic data. Given the selected time steps, we introduce a dynamic cross graph construction module, consisting of the spatial graph construction, temporal connection graph construction, and fusion modules, to learn dynamic spatial-temporal cross dependencies without pre-defined priors. Extensive experiments on six real-world datasets demonstrate that DSTCGCN achieves the state-of-the-art performance.", "url": "https://arxiv.org/abs/2307.00518"}, {"metadata": {"arXiv": "2307.00541", "Date": "Sun, 02 Jul 2023 11:09:00 ", "Title": "Collaborative Policy Learning for Dynamic Scheduling Tasks in Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning", "Authors": ["Do-Yup Kim", "Da-Eun Lee", "Ji-Wan Kim", "Hyun-Suk Lee"], "Categories": "cs.LG cs.AI cs.DC eess.SP", "Comments": ["14 pages", "16 figures", "IEEEtran.cls"], "MSC-class": "68M20, 68T05, 68T07", "ACM-class": "C.2.1; C.2.4; I.2.8; I.2.11"}, "abstract": "In this paper, we examine cloud-edge-terminal IoT networks, where edges undertake a range of typical dynamic scheduling tasks. In these IoT networks, a central policy for each task can be constructed at a cloud server. The central policy can be then used by the edges conducting the task, thereby mitigating the need for them to learn their own policy from scratch. Furthermore, this central policy can be collaboratively learned at the cloud server by aggregating local experiences from the edges, thanks to the hierarchical architecture of the IoT networks. To this end, we propose a novel collaborative policy learning framework for dynamic scheduling tasks using federated reinforcement learning. For effective learning, our framework adaptively selects the tasks for collaborative learning in each round, taking into account the need for fairness among tasks. In addition, as a key enabler of the framework, we propose an edge-agnostic policy structure that enables the aggregation of local policies from different edges. We then provide the convergence analysis of the framework. Through simulations, we demonstrate that our proposed framework significantly outperforms the approaches without collaborative policy learning. Notably, it accelerates the learning speed of the policies and allows newly arrived edges to adapt to their tasks more easily.", "url": "https://arxiv.org/abs/2307.00541"}, {"metadata": {"arXiv": "2307.00543", "Date": "Sun, 02 Jul 2023 11:23:33 ", "Title": "Defending Against Malicious Behaviors in Federated Learning with Blockchain", "Authors": ["Nanqing Dong", "Zhipeng Wang", "Jiahao Sun", "Michael Kampffmeyer", "Yizhe Wen", "Shuoying Zhang", "William Knottenbelt", "Eric Xing"], "Categories": "cs.LG cs.AI cs.CR cs.GT"}, "abstract": "In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.", "url": "https://arxiv.org/abs/2307.00543"}, {"metadata": {"arXiv": "2307.00552", "Date": "Sun, 02 Jul 2023 12:22:02 ", "Title": "Adaptive reinforcement learning of multi-agent ethically-aligned behaviours: the QSOM and QDSOM algorithms", "Authors": ["R\\'emy Chaput", "Olivier Boissier", "Mathieu Guillermin"], "Categories": "cs.LG cs.AI cs.CY cs.MA", "Comments": ["30 pages", "7 figures", "7 tables"]}, "abstract": "The numerous deployed Artificial Intelligence systems need to be aligned with our ethical considerations. However, such ethical considerations might change as time passes: our society is not fixed, and our social mores evolve. This makes it difficult for these AI systems; in the Machine Ethics field especially, it has remained an under-studied challenge. In this paper, we present two algorithms, named QSOM and QDSOM, which are able to adapt to changes in the environment, and especially in the reward function, which represents the ethical considerations that we want these systems to be aligned with. They associate the well-known Q-Table to (Dynamic) Self-Organizing Maps to handle the continuous and multi-dimensional state and action spaces. We evaluate them on a use-case of multi-agent energy repartition within a small Smart Grid neighborhood, and prove their ability to adapt, and their higher performance compared to baseline Reinforcement Learning algorithms.", "url": "https://arxiv.org/abs/2307.00552"}, {"metadata": {"arXiv": "2307.00619", "Date": "Sun, 02 Jul 2023 17:21:30 ", "Title": "Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models", "Authors": ["Litu Rout and Negin Raoof and Giannis Daras and Constantine Caramanis and Alexandros G. Dimakis and Sanjay Shakkottai"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Preprint"]}, "abstract": "We present the first framework to solve linear inverse problems leveraging pre-trained latent diffusion models. Previously proposed algorithms (such as DPS and DDRM) only apply to pixel-space diffusion models. We theoretically analyze our algorithm showing provable sample recovery in a linear model setting. The algorithmic insight obtained from our analysis extends to more general settings often considered in practice. Experimentally, we outperform previously proposed posterior sampling algorithms in a wide variety of problems including random inpainting, block inpainting, denoising, deblurring, destriping, and super-resolution.", "url": "https://arxiv.org/abs/2307.00619"}, {"metadata": {"arXiv": "2307.00677", "Date": "Sun, 02 Jul 2023 22:30:08 ", "Title": "SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption", "Authors": ["Hao Shu"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages"]}, "abstract": "Density-based clustering could be the most popular clustering algorithm since it can identify clusters of arbitrary shape as long as different (high-density) clusters are separated by low-density regions. However, the requirement of the separateness of clusters by low-density regions is not trivial since a high-density region might have different structures which should be clustered into different groups. Such a situation demonstrates the main flaw of all previous density-based clustering algorithms we have known--structures in a high-density cluster could not be detected. Therefore, this paper aims to provide a density-based clustering scheme that not only has the ability previous ones have but could also detect structures in a high-density region not separated by low-density ones. The algorithm employs secondary directed differential, hierarchy, normalized density, as well as the self-adaption coefficient, and thus is called Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption, dubbed by SDC-HSDD-NDSA for short. To illustrate its effectiveness, we run the algorithm in several data sets. The results verify its validity in structure detection, robustness over noises, as well as independence of granularities, and demonstrate that it could outperform previous ones. The Python code of the paper could be found on https://github.com/Hao-B-Shu/SDC-HSDD-NDSA.", "url": "https://arxiv.org/abs/2307.00677"}, {"metadata": {"arXiv": "2307.00712", "Date": "Mon, 03 Jul 2023 02:25:19 ", "Title": "Worth of knowledge in deep learning", "Authors": ["Hao Xu", "Yuntian Chen", "Dongxiao Zhang"], "Categories": "cs.LG cs.AI cs.IT math.IT stat.ML"}, "abstract": "Knowledge constitutes the accumulated understanding and experience that humans use to gain insight into the world. In deep learning, prior knowledge is essential for mitigating shortcomings of data-driven models, such as data dependence, generalization ability, and compliance with constraints. To enable efficient evaluation of the worth of knowledge, we present a framework inspired by interpretable machine learning. Through quantitative experiments, we assess the influence of data volume and estimation range on the worth of knowledge. Our findings elucidate the complex relationship between data and knowledge, including dependence, synergistic, and substitution effects. Our model-agnostic framework can be applied to a variety of common network architectures, providing a comprehensive understanding of the role of prior knowledge in deep learning models. It can also be used to improve the performance of informed machine learning, as well as distinguish improper prior knowledge.", "url": "https://arxiv.org/abs/2307.00712"}, {"metadata": {"arXiv": "2307.00751", "Date": "Mon, 03 Jul 2023 04:56:55 ", "Title": "Population Age Group Sensitivity for COVID-19 Infections with Deep Learning", "Authors": ["Md Khairul Islam", "Tyler Valentine", "Royal Wang", "Levi Davis", "Matt Manner", "Judy Fox"], "Categories": "cs.LG cs.AI q-bio.PE"}, "abstract": "The COVID-19 pandemic has created unprecedented challenges for governments and healthcare systems worldwide, highlighting the critical importance of understanding the factors that contribute to virus transmission. This study aimed to identify the most influential age groups in COVID-19 infection rates at the US county level using the Modified Morris Method and deep learning for time series. Our approach involved training the state-of-the-art time-series model Temporal Fusion Transformer on different age groups as a static feature and the population vaccination status as the dynamic feature. We analyzed the impact of those age groups on COVID-19 infection rates by perturbing individual input features and ranked them based on their Morris sensitivity scores, which quantify their contribution to COVID-19 transmission rates. The findings are verified using ground truth data from the CDC and US Census, which provide the true infection rates for each age group. The results suggest that young adults were the most influential age group in COVID-19 transmission at the county level between March 1, 2020, and November 27, 2021. Using these results can inform public health policies and interventions, such as targeted vaccination strategies, to better control the spread of the virus. Our approach demonstrates the utility of feature sensitivity analysis in identifying critical factors contributing to COVID-19 transmission and can be applied in other public health domains.", "url": "https://arxiv.org/abs/2307.00751"}, {"metadata": {"arXiv": "2307.00754", "Date": "Mon, 03 Jul 2023 04:57:40 ", "Title": "ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection", "Authors": ["Yuhang Chen", "Chaoyun Zhang", "Minghua Ma", "Yudong Liu", "Ruomeng Ding", "Bowen Li", "Shilin He", "Saravan Rajmohan", "Qingwei Lin", "Dongmei Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "Anomaly detection in multivariate time series data is of paramount importance for ensuring the efficient operation of large-scale systems across diverse domains. However, accurately detecting anomalies in such data poses significant challenges. Existing approaches, including forecasting and reconstruction-based methods, struggle to address these challenges effectively. To overcome these limitations, we propose a novel anomaly detection framework named ImDiffusion, which combines time series imputation and diffusion models to achieve accurate and robust anomaly detection. The imputation-based approach employed by ImDiffusion leverages the information from neighboring values in the time series, enabling precise modeling of temporal and inter-correlated dependencies, reducing uncertainty in the data, thereby enhancing the robustness of the anomaly detection process. ImDiffusion further leverages diffusion models as time series imputers to accurately capturing complex dependencies. We leverage the step-by-step denoised outputs generated during the inference process to serve as valuable signals for anomaly prediction, resulting in improved accuracy and robustness of the detection process. We evaluate the performance of ImDiffusion via extensive experiments on benchmark datasets. The results demonstrate that our proposed framework significantly outperforms state-of-the-art approaches in terms of detection accuracy and timeliness. ImDiffusion is further integrated into the real production system in Microsoft and observe a remarkable 11.4% increase in detection F1 score compared to the legacy approach. To the best of our knowledge, ImDiffusion represents a pioneering approach that combines imputation-based techniques with time series anomaly detection, while introducing the novel use of diffusion models to the field.", "url": "https://arxiv.org/abs/2307.00754"}, {"metadata": {"arXiv": "2307.00777", "Date": "Mon, 03 Jul 2023 06:41:15 ", "Title": "GA-DRL: Graph Neural Network-Augmented Deep Reinforcement Learning for DAG Task Scheduling over Dynamic Vehicular Clouds", "Authors": ["Zhang Liu and Lianfen Huang and Zhibin Gao and Manman Luo and Seyyedali Hosseinalipour and Huaiyu Dai"], "Categories": "cs.LG cs.AI", "Comments": ["15 pages", "12 figures", "regular journal"]}, "abstract": "Vehicular clouds (VCs) are modern platforms for processing of computation-intensive tasks over vehicles. Such tasks are often represented as directed acyclic graphs (DAGs) consisting of interdependent vertices/subtasks and directed edges. In this paper, we propose a graph neural network-augmented deep reinforcement learning scheme (GA-DRL) for scheduling DAG tasks over dynamic VCs. In doing so, we first model the VC-assisted DAG task scheduling as a Markov decision process. We then adopt a multi-head graph attention network (GAT) to extract the features of DAG subtasks. Our developed GAT enables a two-way aggregation of the topological information in a DAG task by simultaneously considering predecessors and successors of each subtask. We further introduce non-uniform DAG neighborhood sampling through codifying the scheduling priority of different subtasks, which makes our developed GAT generalizable to completely unseen DAG task topologies. Finally, we augment GAT into a double deep Q-network learning module to conduct subtask-to-vehicle assignment according to the extracted features of subtasks, while considering the dynamics and heterogeneity of the vehicles in VCs. Through simulating various DAG tasks under real-world movement traces of vehicles, we demonstrate that GA-DRL outperforms existing benchmarks in terms of DAG task completion time.", "url": "https://arxiv.org/abs/2307.00777"}, {"metadata": {"arXiv": "2307.00897", "Date": "Mon, 03 Jul 2023 09:50:08 ", "Title": "Fixing confirmation bias in feature attribution methods via semantic match", "Authors": ["Giovanni Cin\\`a", "Daniel Fernandez-Llaneza", "Nishant Mishra", "Tabea E. R\\\"ober", "Sandro Pezzelle", "Iacer Calixto", "Rob Goedhart", "\\c{S}. \\.Ilker Birbil"], "Categories": "cs.LG cs.AI"}, "abstract": "Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the \"semantic match\" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spanning tabular and image data, and show how the assessment of semantic match can give insight into both desirable (e.g., focusing on an object relevant for prediction) and undesirable model behaviors (e.g., focusing on a spurious correlation). We couple our experimental results with an analysis on the metrics to measure semantic match, and argue that this approach constitutes the first step towards resolving the issue of confirmation bias in XAI.", "url": "https://arxiv.org/abs/2307.00897"}, {"metadata": {"arXiv": "2307.00923", "Date": "Mon, 03 Jul 2023 10:49:31 ", "Title": "Achieving Stable Training of Reinforcement Learning Agents in Bimodal Environments through Batch Learning", "Authors": ["E. Hurwitz", "N. Peace", "G. Cevora"], "Categories": "cs.LG cs.AI"}, "abstract": "Bimodal, stochastic environments present a challenge to typical Reinforcement Learning problems. This problem is one that is surprisingly common in real world applications, being particularly applicable to pricing problems. In this paper we present a novel learning approach to the tabular Q-learning algorithm, tailored to tackling these specific challenges by using batch updates. A simulation of pricing problem is used as a testbed to compare a typically updated agent with a batch learning agent. The batch learning agents are shown to be both more effective than the typically-trained agents, and to be more resilient to the fluctuations in a large stochastic environment. This work has a significant potential to enable practical, industrial deployment of Reinforcement Learning in the context of pricing and others.", "url": "https://arxiv.org/abs/2307.00923"}, {"metadata": {"arXiv": "2307.00928", "Date": "Mon, 03 Jul 2023 11:02:40 ", "Title": "Learning Differentiable Logic Programs for Abstract Visual Reasoning", "Authors": ["Hikaru Shindo", "Viktor Pfanschilling", "Devendra Singh Dhami", "Kristian Kersting"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["under review"]}, "abstract": "Visual reasoning is essential for building intelligent agents that understand the world and perform problem-solving beyond perception. Differentiable forward reasoning has been developed to integrate reasoning with gradient-based machine learning paradigms. However, due to the memory intensity, most existing approaches do not bring the best of the expressivity of first-order logic, excluding a crucial ability to solve abstract visual reasoning, where agents need to perform reasoning by using analogies on abstract concepts in different scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner, passing messages in a memory-efficient manner and handling structured programs with functors. Moreover, we propose a computationally-efficient structure learning algorithm to perform explanatory program induction on complex visual scenes. To evaluate, in addition to conventional visual reasoning tasks, we propose a new task, visual reasoning behind-the-scenes, where agents need to learn abstract programs and then answer queries by imagining scenes that are not observed. We empirically demonstrate that NEUMANN solves visual reasoning tasks efficiently, outperforming neural, symbolic, and neuro-symbolic baselines.", "url": "https://arxiv.org/abs/2307.00928"}, {"metadata": {"arXiv": "2307.00936", "Date": "Mon, 03 Jul 2023 11:21:09 ", "Title": "OpenAPMax: Abnormal Patterns-based Model for Real-World Alzheimer's Disease Diagnosis", "Authors": ["Yunyou Huang", "Xianglong Guan", "Xiangjiang Lu", "Xiaoshuang Liang", "Xiuxia Miao", "Jiyue Xie", "Wenjing Liu", "Li Ma", "Suqin Tang", "Zhifei Zhang", "and Jianfeng Zhan"], "Categories": "cs.LG cs.AI", "Comments": ["Alzheimer's Disease", "Abnormal Patterns", "Open-set Recognition", "OpenAPMax"]}, "abstract": "Alzheimer's disease (AD) cannot be reversed, but early diagnosis will significantly benefit patients' medical treatment and care. In recent works, AD diagnosis has the primary assumption that all categories are known a prior -- a closed-set classification problem, which contrasts with the open-set recognition problem. This assumption hinders the application of the model in natural clinical settings. Although many open-set recognition technologies have been proposed in other fields, they are challenging to use for AD diagnosis directly since 1) AD is a degenerative disease of the nervous system with similar symptoms at each stage, and it is difficult to distinguish from its pre-state, and 2) diversified strategies for AD diagnosis are challenging to model uniformly. In this work, inspired by the concerns of clinicians during diagnosis, we propose an open-set recognition model, OpenAPMax, based on the anomaly pattern to address AD diagnosis in real-world settings. OpenAPMax first obtains the abnormal pattern of each patient relative to each known category through statistics or a literature search, clusters the patients' abnormal pattern, and finally, uses extreme value theory (EVT) to model the distance between each patient's abnormal pattern and the center of their category and modify the classification probability. We evaluate the performance of the proposed method with recent open-set recognition, where we obtain state-of-the-art results.", "url": "https://arxiv.org/abs/2307.00936"}, {"metadata": {"arXiv": "2307.00960", "Date": "Mon, 03 Jul 2023 12:25:09 ", "Title": "Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in Multi-Objective Neural Architecture Search", "Authors": ["Simone Sarti", "Eugenio Lomurno", "Matteo Matteucci"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Deep learning is increasingly impacting various aspects of contemporary society. Artificial neural networks have emerged as the dominant models for solving an expanding range of tasks. The introduction of Neural Architecture Search (NAS) techniques, which enable the automatic design of task-optimal networks, has led to remarkable advances. However, the NAS process is typically associated with long execution times and significant computational resource requirements. Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2), have been developed to mitigate these challenges. While maintaining exceptional performance and eliminating the need for retraining, they aim to build a single super-network model capable of directly extracting sub-networks satisfying different constraints. Neural Architecture Transfer (NAT) was developed to maximise the effectiveness of extracting sub-networks from a super-network. In this paper, we present NATv2, an extension of NAT that improves multi-objective search algorithms applied to dynamic super-network architectures. NATv2 achieves qualitative improvements in the extractable sub-networks by exploiting the improved super-networks generated by OFAv2 and incorporating new policies for initialisation, pre-processing and updating its networks archive. In addition, a post-processing pipeline based on fine-tuning is introduced. Experimental results show that NATv2 successfully improves NAT and is highly recommended for investigating high-performance architectures with a minimal number of parameters.", "url": "https://arxiv.org/abs/2307.00960"}, {"metadata": {"arXiv": "2307.00965", "Date": "Mon, 03 Jul 2023 12:35:03 ", "Title": "OpenClinicalAI: An Open and Dynamic Model for Alzheimer's Disease Diagnosis", "Authors": ["Yunyou Huang", "Xiaoshuang Liang", "Xiangjiang Lu", "Xiuxia Miao", "Jiyue Xie", "Wenjing Liu", "Fan Zhang", "Guoxin Kang", "Li Ma", "Suqin Tang", "Zhifei Zhang", "Jianfeng Zhan"], "Categories": "cs.LG cs.AI", "Comments": ["Real-world clinical setting,Alzheimer's disease,diagnose,AI,deep learning. arXiv admin note: text overlap with arXiv:2109.04004"]}, "abstract": "Although Alzheimer's disease (AD) cannot be reversed or cured, timely diagnosis can significantly reduce the burden of treatment and care. Current research on AD diagnosis models usually regards the diagnosis task as a typical classification task with two primary assumptions: 1) All target categories are known a priori; 2) The diagnostic strategy for each patient is consistent, that is, the number and type of model input data for each patient are the same. However, real-world clinical settings are open, with complexity and uncertainty in terms of both subjects and the resources of the medical institutions. This means that diagnostic models may encounter unseen disease categories and need to dynamically develop diagnostic strategies based on the subject's specific circumstances and available medical resources. Thus, the AD diagnosis task is tangled and coupled with the diagnosis strategy formulation. To promote the application of diagnostic systems in real-world clinical settings, we propose OpenClinicalAI for direct AD diagnosis in complex and uncertain clinical settings. This is the first powerful end-to-end model to dynamically formulate diagnostic strategies and provide diagnostic results based on the subject's conditions and available medical resources. OpenClinicalAI combines reciprocally coupled deep multiaction reinforcement learning (DMARL) for diagnostic strategy formulation and multicenter meta-learning (MCML) for open-set recognition. The experimental results show that OpenClinicalAI achieves better performance and fewer clinical examinations than the state-of-the-art model. Our method provides an opportunity to embed the AD diagnostic system into the current health care system to cooperate with clinicians to improve current health care.", "url": "https://arxiv.org/abs/2307.00965"}, {"metadata": {"arXiv": "2307.00968", "Date": "Mon, 03 Jul 2023 12:39:26 ", "Title": "REAL: A Representative Error-Driven Approach for Active Learning", "Authors": ["Cheng Chen", "Yong Wang", "Lizi Liao", "Yueguo Chen", "Xiaoyong Du"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by ECML/PKDD 2023"]}, "abstract": "Given a limited labeling budget, active learning (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training. To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity. However, it does not consider erroneous instances with their neighborhood error density, which have great potential to improve the model performance. To address this limitation, we propose $REAL$, a novel approach to select data instances with $\\underline{R}$epresentative $\\underline{E}$rrors for $\\underline{A}$ctive $\\underline{L}$earning. It identifies minority predictions as \\emph{pseudo errors} within a cluster and allocates an adaptive sampling budget for the cluster based on estimated error density. Extensive experiments on five text classification datasets demonstrate that $REAL$ consistently outperforms all best-performing baselines regarding accuracy and F1-macro scores across a wide range of hyperparameter settings. Our analysis also shows that $REAL$ selects the most representative pseudo errors that match the distribution of ground-truth errors along the decision boundary. Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real.", "url": "https://arxiv.org/abs/2307.00968"}, {"metadata": {"arXiv": "2307.01026", "Date": "Mon, 03 Jul 2023 13:58:20 ", "Title": "Temporal Graph Benchmark for Machine Learning on Temporal Graphs", "Authors": ["Shenyang Huang", "Farimah Poursafaei", "Jacob Danovitch", "Matthias Fey", "Weihua Hu", "Emanuele Rossi", "Jure Leskovec", "Michael Bronstein", "Guillaume Rabusseau", "Reihaneh Rabbany"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "4 figures", "5 tables", "preprint"]}, "abstract": "We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on temporal graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, experiment setup and performance evaluation. TGB will be maintained and updated on a regular basis and welcomes community feedback. TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/ .", "url": "https://arxiv.org/abs/2307.01026"}, {"metadata": {"arXiv": "2307.01053", "Date": "Mon, 03 Jul 2023 14:33:14 ", "Title": "ENGAGE: Explanation Guided Data Augmentation for Graph Representation Learning", "Authors": ["Yucheng Shi", "Kaixiong Zhou", "Ninghao Liu"], "Categories": "cs.LG cs.AI cs.IT math.IT", "Comments": ["Accepted by ECML-PKDD 2023"]}, "abstract": "The recent contrastive learning methods, due to their effectiveness in representation learning, have been widely applied to modeling graph data. Random perturbation is widely used to build contrastive views for graph data, which however, could accidentally break graph structures and lead to suboptimal performance. In addition, graph data is usually highly abstract, so it is hard to extract intuitive meanings and design more informed augmentation schemes. Effective representations should preserve key characteristics in data and abandon superfluous information. In this paper, we propose ENGAGE (ExplaNation Guided data AuGmEntation), where explanation guides the contrastive augmentation process to preserve the key parts in graphs and explore removing superfluous information. Specifically, we design an efficient unsupervised explanation method called smoothed activation map as the indicator of node importance in representation learning. Then, we design two data augmentation schemes on graphs for perturbing structural and feature information, respectively. We also provide justification for the proposed method in the framework of information theories. Experiments of both graph-level and node-level tasks, on various model architectures and on different real-world graphs, are conducted to demonstrate the effectiveness and flexibility of ENGAGE. The code of ENGAGE can be found: https://github.com/sycny/ENGAGE.", "url": "https://arxiv.org/abs/2307.01053"}, {"metadata": {"arXiv": "2307.01158", "Date": "Mon, 03 Jul 2023 17:07:18 ", "Title": "Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning", "Authors": ["Ini Oguntola", "Joseph Campbell", "Simon Stepputtis", "Katia Sycara"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["To appear at ICML 2023 Workshop on Theory of Mind"]}, "abstract": "The ability to model the mental states of others is crucial to human social intelligence, and can offer similar benefits to artificial agents with respect to the social dynamics induced in multi-agent settings. We present a method of grounding semantically meaningful, human-interpretable beliefs within policies modeled by deep networks. We then consider the task of 2nd-order belief prediction. We propose that ability of each agent to predict the beliefs of the other agents can be used as an intrinsic reward signal for multi-agent reinforcement learning. Finally, we present preliminary empirical results in a mixed cooperative-competitive environment.", "url": "https://arxiv.org/abs/2307.01158"}, {"metadata": {"arXiv": "2307.01168", "Date": "Mon, 03 Jul 2023 17:23:34 ", "Title": "Don't freeze: Finetune encoders for better Self-Supervised HAR", "Authors": ["Vitor Fortes Rey", "Dominique Nshimyimana", "Paul Lukowicz"], "Categories": "cs.LG cs.AI"}, "abstract": "Recently self-supervised learning has been proposed in the field of human activity recognition as a solution to the labelled data availability problem. The idea being that by using pretext tasks such as reconstruction or contrastive predictive coding, useful representations can be learned that then can be used for classification. Those approaches follow the pretrain, freeze and fine-tune procedure. In this paper we will show how a simple change - not freezing the representation - leads to substantial performance gains across pretext tasks. The improvement was found in all four investigated datasets and across all four pretext tasks and is inversely proportional to amount of labelled data. Moreover the effect is present whether the pretext task is carried on the Capture24 dataset or directly in unlabelled data of the target dataset.", "url": "https://arxiv.org/abs/2307.01168"}, {"metadata": {"arXiv": "2307.01180", "Date": "Mon, 03 Jul 2023 17:45:01 ", "Title": "PlanE: Representation Learning over Planar Graphs", "Authors": ["Radoslav Dimitrov", "Zeyang Zhao", "Ralph Abboud", "\\.Ismail \\.Ilkan Ceylan"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph neural networks are prominent models for representation learning over graphs, where the idea is to iteratively compute representations of nodes of an input graph through a series of transformations in such a way that the learned graph function is isomorphism invariant on graphs, which makes the learned representations graph invariants. On the other hand, it is well-known that graph invariants learned by these class of models are incomplete: there are pairs of non-isomorphic graphs which cannot be distinguished by standard graph neural networks. This is unsurprising given the computational difficulty of graph isomorphism testing on general graphs, but the situation begs to differ for special graph classes, for which efficient graph isomorphism testing algorithms are known, such as planar graphs. The goal of this work is to design architectures for efficiently learning complete invariants of planar graphs. Inspired by the classical planar graph isomorphism algorithm of Hopcroft and Tarjan, we propose PlanE as a framework for planar representation learning. PlanE includes architectures which can learn complete invariants over planar graphs while remaining practically scalable. We empirically validate the strong performance of the resulting model architectures on well-known planar graph benchmarks, achieving multiple state-of-the-art results.", "url": "https://arxiv.org/abs/2307.01180"}, {"metadata": {"arXiv": "2307.01193", "Date": "Mon, 03 Jul 2023 17:54:40 ", "Title": "Squeezing Large-Scale Diffusion Models for Mobile", "Authors": ["Jiwoong Choi", "Minkyu Kim", "Daehyun Ahn", "Taesu Kim", "Yulhwa Kim", "Dongwon Jo", "Hyesung Jeon", "Jae-Joon Kim", "Hyungjun Kim"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "8 figures", "ICML 2023 Workshop on Challenges in Deployable Generative AI"]}, "abstract": "The emergence of diffusion models has greatly broadened the scope of high-fidelity image synthesis, resulting in notable advancements in both practical implementation and academic research. With the active adoption of the model in various real-world applications, the need for on-device deployment has grown considerably. However, deploying large diffusion models such as Stable Diffusion with more than one billion parameters to mobile devices poses distinctive challenges due to the limited computational and memory resources, which may vary according to the device. In this paper, we present the challenges and solutions for deploying Stable Diffusion on mobile devices with TensorFlow Lite framework, which supports both iOS and Android devices. The resulting Mobile Stable Diffusion achieves the inference latency of smaller than 7 seconds for a 512x512 image generation on Android devices with mobile GPUs.", "url": "https://arxiv.org/abs/2307.01193"}, {"metadata": {"arXiv": "2307.00014", "Date": "Thu, 22 Jun 2023 14:32:23 ", "Title": "Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions", "Authors": ["Nadav Cohen and Itzik Klein"], "Categories": "cs.RO cs.AI cs.LG cs.SY eess.SY"}, "abstract": "Inertial sensing is used in many applications and platforms, ranging from day-to-day devices such as smartphones to very complex ones such as autonomous vehicles. In recent years, the development of machine learning and deep learning techniques has increased significantly in the field of inertial sensing. This is due to the development of efficient computing hardware and the accessibility of publicly available sensor data. These data-driven approaches are used to empower model-based navigation and sensor fusion algorithms. This paper provides an in-depth review of those deep learning methods. We examine separately, each vehicle operation domain including land, air, and sea. Each domain is divided into pure inertial advances and improvements based on filter parameters learning. In addition, we review deep learning approaches for calibrating and denoising inertial sensors. Throughout the paper, we discuss these trends and future directions. We also provide statistics on the commonly used approaches to illustrate their efficiency and stimulate further research in deep learning embedded in inertial navigation and fusion.", "url": "https://arxiv.org/abs/2307.00014"}, {"metadata": {"arXiv": "2307.00633", "Date": "Sun, 02 Jul 2023 18:40:05 ", "Title": "Effects of Explanation Specificity on Passengers in Autonomous Driving", "Authors": ["Daniel Omeiza", "Raunak Bhattacharyya", "Nick Hawes", "Marina Jirotka", "Lars Kunze"], "Categories": "cs.RO cs.AI cs.CY cs.HC cs.LG"}, "abstract": "The nature of explanations provided by an explainable AI algorithm has been a topic of interest in the explainable AI and human-computer interaction community. In this paper, we investigate the effects of natural language explanations' specificity on passengers in autonomous driving. We extended an existing data-driven tree-based explainer algorithm by adding a rule-based option for explanation generation. We generated auditory natural language explanations with different levels of specificity (abstract and specific) and tested these explanations in a within-subject user study (N=39) using an immersive physical driving simulation setup. Our results showed that both abstract and specific explanations had similar positive effects on passengers' perceived safety and the feeling of anxiety. However, the specific explanations influenced the desire of passengers to takeover driving control from the autonomous vehicle (AV), while the abstract explanations did not. We conclude that natural language auditory explanations are useful for passengers in autonomous driving, and their specificity levels could influence how much in-vehicle participants would wish to be in control of the driving activity.", "url": "https://arxiv.org/abs/2307.00633"}, {"metadata": {"arXiv": "2307.00741", "Date": "Mon, 03 Jul 2023 04:10:55 ", "Title": "UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input", "Authors": ["Muhammad Ibrahim", "Naveed Akhtar", "Saeed Anwar", "and Ajmal Mian"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR", "Radar and/or Camera Input has been accepted for publication in the Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)"]}, "abstract": "Localization is a fundamental task in robotics for autonomous navigation. Existing localization methods rely on a single input data modality or train several computational models to process different modalities. This leads to stringent computational requirements and sub-optimal results that fail to capitalize on the complementary information in other data streams. This paper proposes UnLoc, a novel unified neural modeling approach for localization with multi-sensor input in all weather conditions. Our multi-stream network can handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can work with one or more input sensors, making it robust to sensor failure. UnLoc uses 3D sparse convolutions and cylindrical partitioning of the space to process LiDAR frames and implements ResNet blocks with a slot attention-based feature filtering module for the Radar and image modalities. We introduce a unique learnable modality encoding scheme to distinguish between the input sensor data. Our method is extensively evaluated on Oxford Radar RobotCar, ApolloSouthBay and Perth-WA datasets. The results ascertain the efficacy of our technique.", "url": "https://arxiv.org/abs/2307.00741"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

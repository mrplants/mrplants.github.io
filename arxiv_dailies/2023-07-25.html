<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.11904", "Date": "Fri, 21 Jul 2023 21:07:56 ", "Title": "Model Compression Methods for YOLOv5: A Review", "Authors": ["Mohammad Jani", "Jamil Fayyad", "Younes Al-Younes", "Homayoun Najjaran"], "Categories": "cs.CV cs.LG cs.NE", "Comments": ["18 pages", "7 Figures"]}, "abstract": "Over the past few years, extensive research has been devoted to enhancing YOLO object detectors. Since its introduction, eight major versions of YOLO have been introduced with the purpose of improving its accuracy and efficiency. While the evident merits of YOLO have yielded to its extensive use in many areas, deploying it on resource-limited devices poses challenges. To address this issue, various neural network compression methods have been developed, which fall under three main categories, namely network pruning, quantization, and knowledge distillation. The fruitful outcomes of utilizing model compression methods, such as lowering memory usage and inference time, make them favorable, if not necessary, for deploying large neural networks on hardware-constrained edge devices. In this review paper, our focus is on pruning and quantization due to their comparative modularity. We categorize them and analyze the practical results of applying those methods to YOLOv5. By doing so, we identify gaps in adapting pruning and quantization for compressing YOLOv5, and provide future directions in this area for further exploration. Among several versions of YOLO, we specifically choose YOLOv5 for its excellent trade-off between recency and popularity in literature. This is the first specific review paper that surveys pruning and quantization methods from an implementation point of view on YOLOv5. Our study is also extendable to newer versions of YOLO as implementing them on resource-limited devices poses the same challenges that persist even today. This paper targets those interested in the practical deployment of model compression methods on YOLOv5, and in exploring different compression techniques that can be used for subsequent versions of YOLO.", "url": "https://arxiv.org/abs/2307.11904"}, {"metadata": {"arXiv": "2307.11906", "Date": "Fri, 21 Jul 2023 21:09:54 ", "Title": "Unveiling Vulnerabilities in Interpretable Deep Learning Systems with Query-Efficient Black-box Attacks", "Authors": ["Eldor Abdukhamidov", "Mohammed Abuhamad", "Simon S. Woo", "Eric Chan-Tin", "Tamer Abuhmed"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2307.06496"]}, "abstract": "Deep learning has been rapidly employed in many applications revolutionizing many industries, but it is known to be vulnerable to adversarial attacks. Such attacks pose a serious threat to deep learning-based systems compromising their integrity, reliability, and trust. Interpretable Deep Learning Systems (IDLSes) are designed to make the system more transparent and explainable, but they are also shown to be susceptible to attacks. In this work, we propose a novel microbial genetic algorithm-based black-box attack against IDLSes that requires no prior knowledge of the target model and its interpretation model. The proposed attack is a query-efficient approach that combines transfer-based and score-based methods, making it a powerful tool to unveil IDLS vulnerabilities. Our experiments of the attack show high attack success rates using adversarial examples with attribution maps that are highly similar to those of benign samples which makes it difficult to detect even by human analysts. Our results highlight the need for improved IDLS security to ensure their practical reliability.", "url": "https://arxiv.org/abs/2307.11906"}, {"metadata": {"arXiv": "2307.11986", "Date": "Sat, 22 Jul 2023 05:34:18 ", "Title": "Expert Knowledge-Aware Image Difference Graph Representation Learning for Difference-Aware Medical Visual Question Answering", "Authors": ["Xinyue Hu", "Lin Gu", "Qiyuan An", "Mengliang Zhang", "Liangchen Liu", "Kazuma Kobayashi", "Tatsuya Harada", "Ronald M. Summers", "Yingying Zhu"], "Categories": "cs.CV cs.LG", "DOI": "10.1145/3580305.3599819"}, "abstract": "To contribute to automating the medical vision-language model, we propose a novel Chest-Xray Difference Visual Question Answering (VQA) task. Given a pair of main and reference images, this task attempts to answer several questions on both diseases and, more importantly, the differences between them. This is consistent with the radiologist's diagnosis practice that compares the current image with the reference before concluding the report. We collect a new dataset, namely MIMIC-Diff-VQA, including 700,703 QA pairs from 164,324 pairs of main and reference images. Compared to existing medical VQA datasets, our questions are tailored to the Assessment-Diagnosis-Intervention-Evaluation treatment procedure used by clinical professionals. Meanwhile, we also propose a novel expert knowledge-aware graph representation learning model to address this task. The proposed baseline model leverages expert knowledge such as anatomical structure prior, semantic, and spatial knowledge to construct a multi-relationship graph, representing the image differences between two images for the image difference VQA task. The dataset and code can be found at https://github.com/Holipori/MIMIC-Diff-VQA. We believe this work would further push forward the medical vision language model.", "url": "https://arxiv.org/abs/2307.11986"}, {"metadata": {"arXiv": "2307.12032", "Date": "Sat, 22 Jul 2023 09:44:45 ", "Title": "Flight Contrail Segmentation via Augmented Transfer Learning with Novel SR Loss Function in Hough Space", "Authors": ["Junzi Sun", "Esther Roosenbrand"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Source code available at: https://github.com/junzis/contrail-net"]}, "abstract": "Air transport poses significant environmental challenges, particularly the contribution of flight contrails to climate change due to their potential global warming impact. Detecting contrails from satellite images has been a long-standing challenge. Traditional computer vision techniques have limitations under varying image conditions, and machine learning approaches using typical convolutional neural networks are hindered by the scarcity of hand-labeled contrail datasets and contrail-tailored learning processes. In this paper, we introduce an innovative model based on augmented transfer learning that accurately detects contrails with minimal data. We also propose a novel loss function, SR Loss, which improves contrail line detection by transforming the image space into Hough space. Our research opens new avenues for machine learning-based contrail detection in aviation research, offering solutions to the lack of large hand-labeled datasets, and significantly enhancing contrail detection models.", "url": "https://arxiv.org/abs/2307.12032"}, {"metadata": {"arXiv": "2307.12122", "Date": "Sat, 22 Jul 2023 16:42:26 ", "Title": "Synthesis of Batik Motifs using a Diffusion -- Generative Adversarial Network", "Authors": ["One Octadion", "Novanto Yudistira", "Diva Kurnianingtyas"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Batik, a unique blend of art and craftsmanship, is a distinct artistic and technological creation for Indonesian society. Research on batik motifs is primarily focused on classification. However, further studies may extend to the synthesis of batik patterns. Generative Adversarial Networks (GANs) have been an important deep learning model for generating synthetic data, but often face challenges in the stability and consistency of results. This research focuses on the use of StyleGAN2-Ada and Diffusion techniques to produce realistic and high-quality synthetic batik patterns. StyleGAN2-Ada is a variation of the GAN model that separates the style and content aspects in an image, whereas diffusion techniques introduce random noise into the data. In the context of batik, StyleGAN2-Ada and Diffusion are used to produce realistic synthetic batik patterns. This study also made adjustments to the model architecture and used a well-curated batik dataset. The main goal is to assist batik designers or craftsmen in producing unique and quality batik motifs with efficient production time and costs. Based on qualitative and quantitative evaluations, the results show that the model tested is capable of producing authentic and quality batik patterns, with finer details and rich artistic variations. The dataset and code can be accessed here:https://github.com/octadion/diffusion-stylegan2-ada-pytorch", "url": "https://arxiv.org/abs/2307.12122"}, {"metadata": {"arXiv": "2307.12145", "Date": "Sat, 22 Jul 2023 18:59:27 ", "Title": "A Vision for Cleaner Rivers: Harnessing Snapshot Hyperspectral Imaging to Detect Macro-Plastic Litter", "Authors": ["Nathaniel Hanson", "Ahmet Demirkaya", "Deniz Erdo\\u{g}mu\\c{s}", "Aron Stubbins", "Ta\\c{s}k{\\i}n Pad{\\i}r", "Tales Imbiriba"], "Categories": "cs.CV cs.LG"}, "abstract": "Plastic waste entering the riverine harms local ecosystems leading to negative ecological and economic impacts. Large parcels of plastic waste are transported from inland to oceans leading to a global scale problem of floating debris fields. In this context, efficient and automatized monitoring of mismanaged plastic waste is paramount. To address this problem, we analyze the feasibility of macro-plastic litter detection using computational imaging approaches in river-like scenarios. We enable near-real-time tracking of partially submerged plastics by using snapshot Visible-Shortwave Infrared hyperspectral imaging. Our experiments indicate that imaging strategies associated with machine learning classification approaches can lead to high detection accuracy even in challenging scenarios, especially when leveraging hyperspectral data and nonlinear classifiers. All code, data, and models are available online: https://github.com/RIVeR-Lab/hyperspectral_macro_plastic_detection.", "url": "https://arxiv.org/abs/2307.12145"}, {"metadata": {"arXiv": "2307.12159", "Date": "Sat, 22 Jul 2023 20:16:39 ", "Title": "Facial Point Graphs for Amyotrophic Lateral Sclerosis Identification", "Authors": ["N\\'icolas Barbosa Gomes", "Arissa Yoshida", "Mateus Roder", "Guilherme Camargo de Oliveira and Jo\\~ao Paulo Papa"], "Categories": "cs.CV cs.LG", "Comments": ["7 pages and 7 figures"], "ACM-class": "I.5.1; I.5.4; I.5.2"}, "abstract": "Identifying Amyotrophic Lateral Sclerosis (ALS) in its early stages is essential for establishing the beginning of treatment, enriching the outlook, and enhancing the overall well-being of those affected individuals. However, early diagnosis and detecting the disease's signs is not straightforward. A simpler and cheaper way arises by analyzing the patient's facial expressions through computational methods. When a patient with ALS engages in specific actions, e.g., opening their mouth, the movement of specific facial muscles differs from that observed in a healthy individual. This paper proposes Facial Point Graphs to learn information from the geometry of facial images to identify ALS automatically. The experimental outcomes in the Toronto Neuroface dataset show the proposed approach outperformed state-of-the-art results, fostering promising developments in the area.", "url": "https://arxiv.org/abs/2307.12159"}, {"metadata": {"arXiv": "2307.12229", "Date": "Sun, 23 Jul 2023 05:31:47 ", "Title": "EchoGLAD: Hierarchical Graph Neural Networks for Left Ventricle Landmark Detection on Echocardiograms", "Authors": ["Masoud Mokhtari", "Mobina Mahdavi", "Hooman Vaseli", "Christina Luong", "Purang Abolmaesumi", "Teresa S. M. Tsang", "Renjie Liao"], "Categories": "cs.CV cs.LG", "Comments": ["To be published in MICCAI 2023"]}, "abstract": "The functional assessment of the left ventricle chamber of the heart requires detecting four landmark locations and measuring the internal dimension of the left ventricle and the approximate mass of the surrounding muscle. The key challenge of automating this task with machine learning is the sparsity of clinical labels, i.e., only a few landmark pixels in a high-dimensional image are annotated, leading many prior works to heavily rely on isotropic label smoothing. However, such a label smoothing strategy ignores the anatomical information of the image and induces some bias. To address this challenge, we introduce an echocardiogram-based, hierarchical graph neural network (GNN) for left ventricle landmark detection (EchoGLAD). Our main contributions are: 1) a hierarchical graph representation learning framework for multi-resolution landmark detection via GNNs; 2) induced hierarchical supervision at different levels of granularity using a multi-level loss. We evaluate our model on a public and a private dataset under the in-distribution (ID) and out-of-distribution (OOD) settings. For the ID setting, we achieve the state-of-the-art mean absolute errors (MAEs) of 1.46 mm and 1.86 mm on the two datasets. Our model also shows better OOD generalization than prior works with a testing MAE of 4.3 mm.", "url": "https://arxiv.org/abs/2307.12229"}, {"metadata": {"arXiv": "2307.12241", "Date": "Sun, 23 Jul 2023 06:39:51 ", "Title": "Explainable Depression Detection via Head Motion Patterns", "Authors": ["Monika Gahalawat", "Raul Fernandez Rojas", "Tanaya Guha", "Ramanathan Subramanian", "Roland Goecke"], "Categories": "cs.CV cs.LG"}, "abstract": "While depression has been studied via multimodal non-verbal behavioural cues, head motion behaviour has not received much attention as a biomarker. This study demonstrates the utility of fundamental head-motion units, termed \\emph{kinemes}, for depression detection by adopting two distinct approaches, and employing distinctive features: (a) discovering kinemes from head motion data corresponding to both depressed patients and healthy controls, and (b) learning kineme patterns only from healthy controls, and computing statistics derived from reconstruction errors for both the patient and control classes. Employing machine learning methods, we evaluate depression classification performance on the \\emph{BlackDog} and \\emph{AVEC2013} datasets. Our findings indicate that: (1) head motion patterns are effective biomarkers for detecting depressive symptoms, and (2) explanatory kineme patterns consistent with prior findings can be observed for the two classes. Overall, we achieve peak F1 scores of 0.79 and 0.82, respectively, over BlackDog and AVEC2013 for binary classification over episodic \\emph{thin-slices}, and a peak F1 of 0.72 over videos for AVEC2013.", "url": "https://arxiv.org/abs/2307.12241"}, {"metadata": {"arXiv": "2307.12301", "Date": "Sun, 23 Jul 2023 11:50:27 ", "Title": "RANSAC-NN: Unsupervised Image Outlier Detection using RANSAC", "Authors": ["Chen-Han Tsai", "Yu-Shao Peng"], "Categories": "cs.CV cs.IR cs.LG", "Comments": ["19 pages", "18 figures"]}, "abstract": "Image outlier detection (OD) is crucial for ensuring the quality and accuracy of image datasets used in computer vision tasks. The majority of OD algorithms, however, have not been targeted toward image data. Consequently, the results of applying such algorithms to images are often suboptimal. In this work, we propose RANSAC-NN, a novel unsupervised OD algorithm specifically designed for images. By comparing images in a RANSAC-based approach, our algorithm automatically predicts the outlier score of each image without additional training or label information. We evaluate RANSAC-NN against state-of-the-art OD algorithms on 15 diverse datasets. Without any hyperparameter tuning, RANSAC-NN consistently performs favorably in contrast to other algorithms in almost every dataset category. Furthermore, we provide a detailed analysis to understand each RANSAC-NN component, and we demonstrate its potential applications in image mislabeled detection. Code for RANSAC-NN is provided at https://github.com/mxtsai/ransac-nn", "url": "https://arxiv.org/abs/2307.12301"}, {"metadata": {"arXiv": "2307.12427", "Date": "Sun, 23 Jul 2023 20:47:03 ", "Title": "Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection", "Authors": ["Liu Yuyang", "Cong Yang", "Goswami Dipam", "Liu Xialei", "Joost van de Weijer"], "Categories": "cs.CV cs.LG", "Journal-ref": "2023 International Conference on Computer Vision (ICCV)"}, "abstract": "In incremental learning, replaying stored samples from previous tasks together with current task samples is one of the most efficient approaches to address catastrophic forgetting. However, unlike incremental classification, image replay has not been successfully applied to incremental object detection (IOD). In this paper, we identify the overlooked problem of foreground shift as the main reason for this. Foreground shift only occurs when replaying images of previous tasks and refers to the fact that their background might contain foreground objects of the current task. To overcome this problem, a novel and efficient Augmented Box Replay (ABR) method is developed that only stores and replays foreground objects and thereby circumvents the foreground shift problem. In addition, we propose an innovative Attentive RoI Distillation loss that uses spatial attention from region-of-interest (RoI) features to constrain current model to focus on the most important information from old model. ABR significantly reduces forgetting of previous classes while maintaining high plasticity in current classes. Moreover, it considerably reduces the storage requirements when compared to standard image replay. Comprehensive experiments on Pascal-VOC and COCO datasets support the state-of-the-art performance of our model.", "url": "https://arxiv.org/abs/2307.12427"}, {"metadata": {"arXiv": "2307.12463", "Date": "Mon, 24 Jul 2023 00:53:46 ", "Title": "Rethinking Data Distillation: Do Not Overlook Calibration", "Authors": ["Dongyao Zhu", "Bowen Lei", "Jie Zhang", "Yanbo Fang", "Ruqi Zhang", "Yiqun Xie", "Dongkuan Xu"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Neural networks trained on distilled data often produce over-confident output and require correction by calibration methods. Existing calibration methods such as temperature scaling and mixup work well for networks trained on original large-scale data. However, we find that these methods fail to calibrate networks trained on data distilled from large source datasets. In this paper, we show that distilled data lead to networks that are not calibratable due to (i) a more concentrated distribution of the maximum logits and (ii) the loss of information that is semantically meaningful but unrelated to classification tasks. To address this problem, we propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) which mitigate the limitations of distilled data and achieve better calibration results while maintaining the efficiency of dataset distillation.", "url": "https://arxiv.org/abs/2307.12463"}, {"metadata": {"arXiv": "2307.12532", "Date": "Mon, 24 Jul 2023 05:36:19 ", "Title": "On the Connection between Pre-training Data Diversity and Fine-tuning Robustness", "Authors": ["Vivek Ramanujan", "Thao Nguyen", "Sewoong Oh", "Ludwig Schmidt", "Ali Farhadi"], "Categories": "cs.CV cs.LG"}, "abstract": "Pre-training has been widely adopted in deep learning to improve model performance, especially when the training data for a target task is limited. In our work, we seek to understand the implications of this training strategy on the generalization properties of downstream models. More specifically, we ask the following question: how do properties of the pre-training distribution affect the robustness of a fine-tuned model? The properties we explore include the label space, label semantics, image diversity, data domains, and data quantity of the pre-training distribution. We find that the primary factor influencing downstream effective robustness (Taori et al., 2020) is data quantity, while other factors have limited significance. For example, reducing the number of ImageNet pre-training classes by 4x while increasing the number of images per class by 4x (that is, keeping total data quantity fixed) does not impact the robustness of fine-tuned models. We demonstrate our findings on pre-training distributions drawn from various natural and synthetic data sources, primarily using the iWildCam-WILDS distribution shift as a test for downstream robustness.", "url": "https://arxiv.org/abs/2307.12532"}, {"metadata": {"arXiv": "2307.12872", "Date": "Mon, 24 Jul 2023 15:10:22 ", "Title": "Data-free Black-box Attack based on Diffusion Model", "Authors": ["Mingwen Shao", "Lingzhuang Meng", "Yuanjian Qiao", "Lixu Zhang", "Wangmeng Zuo"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Since the training data for the target model in a data-free black-box attack is not available, most recent schemes utilize GANs to generate data for training substitute model. However, these GANs-based schemes suffer from low training efficiency as the generator needs to be retrained for each target model during the substitute training process, as well as low generation quality. To overcome these limitations, we consider utilizing the diffusion model to generate data, and propose a data-free black-box attack scheme based on diffusion model to improve the efficiency and accuracy of substitute training. Despite the data generated by the diffusion model exhibits high quality, it presents diverse domain distributions and contains many samples that do not meet the discriminative criteria of the target model. To further facilitate the diffusion model to generate data suitable for the target model, we propose a Latent Code Augmentation (LCA) method to guide the diffusion model in generating data. With the guidance of LCA, the data generated by the diffusion model not only meets the discriminative criteria of the target model but also exhibits high diversity. By utilizing this data, it is possible to train substitute model that closely resemble the target model more efficiently. Extensive experiments demonstrate that our LCA achieves higher attack success rates and requires fewer query budgets compared to GANs-based schemes for different target models.", "url": "https://arxiv.org/abs/2307.12872"}, {"metadata": {"arXiv": "2307.12967", "Date": "Mon, 24 Jul 2023 17:45:40 ", "Title": "Learning Dense Correspondences between Photos and Sketches", "Authors": ["Xuanchen Lu", "Xiaolong Wang", "Judith E Fan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICML 2023. Project page: https://photo-sketch-correspondence.github.io"]}, "abstract": "Humans effortlessly grasp the connection between sketches and real-world objects, even when these sketches are far from realistic. Moreover, human sketch understanding goes beyond categorization -- critically, it also entails understanding how individual elements within a sketch correspond to parts of the physical world it represents. What are the computational ingredients needed to support this ability? Towards answering this question, we make two contributions: first, we introduce a new sketch-photo correspondence benchmark, $\\textit{PSC6k}$, containing 150K annotations of 6250 sketch-photo pairs across 125 object categories, augmenting the existing Sketchy dataset with fine-grained correspondence metadata. Second, we propose a self-supervised method for learning dense correspondences between sketch-photo pairs, building upon recent advances in correspondence learning for pairs of photos. Our model uses a spatial transformer network to estimate the warp flow between latent representations of a sketch and photo extracted by a contrastive learning-based ConvNet backbone. We found that this approach outperformed several strong baselines and produced predictions that were quantitatively consistent with other warp-based methods. However, our benchmark also revealed systematic differences between predictions of the suite of models we tested and those of humans. Taken together, our work suggests a promising path towards developing artificial systems that achieve more human-like understanding of visual images at different levels of abstraction. Project page: https://photo-sketch-correspondence.github.io", "url": "https://arxiv.org/abs/2307.12967"}, {"metadata": {"arXiv": "2307.11777", "Date": "Thu, 20 Jul 2023 00:50:26 ", "Title": "Prediction of Handball Matches with Statistically Enhanced Learning via Estimated Team Strengths", "Authors": ["Florian Felice and Christophe Ley"], "Categories": "cs.LG stat.ME"}, "abstract": "We propose a Statistically Enhanced Learning (aka. SEL) model to predict handball games. Our Machine Learning model augmented with SEL features outperforms state-of-the-art models with an accuracy beyond 80%. In this work, we show how we construct the data set to train Machine Learning models on past female club matches. We then compare different models and evaluate them to assess their performance capabilities. Finally, explainability methods allow us to change the scope of our tool from a purely predictive solution to a highly insightful analytical tool. This can become a valuable asset for handball teams' coaches providing valuable statistical and predictive insights to prepare future competitions.", "url": "https://arxiv.org/abs/2307.11777"}, {"metadata": {"arXiv": "2307.11793", "Date": "Thu, 20 Jul 2023 21:42:01 ", "Title": "Leveraging arbitrary mobile sensor trajectories with shallow recurrent decoder networks for full-state reconstruction", "Authors": ["Megan R. Ebers", "Jan P. Williams", "Katherine M. Steele", "J. Nathan Kutz"], "Categories": "cs.LG math.DS", "Comments": ["11 pages", "5 figures", "2 tables"]}, "abstract": "Sensing is one of the most fundamental tasks for the monitoring, forecasting and control of complex, spatio-temporal systems. In many applications, a limited number of sensors are mobile and move with the dynamics, with examples including wearable technology, ocean monitoring buoys, and weather balloons. In these dynamic systems (without regions of statistical-independence), the measurement time history encodes a significant amount of information that can be extracted for critical tasks. Most model-free sensing paradigms aim to map current sparse sensor measurements to the high-dimensional state space, ignoring the time-history all together. Using modern deep learning architectures, we show that a sequence-to-vector model, such as an LSTM (long, short-term memory) network, with a decoder network, dynamic trajectory information can be mapped to full state-space estimates. Indeed, we demonstrate that by leveraging mobile sensor trajectories with shallow recurrent decoder networks, we can train the network (i) to accurately reconstruct the full state space using arbitrary dynamical trajectories of the sensors, (ii) the architecture reduces the variance of the mean-square error of the reconstruction error in comparison with immobile sensors, and (iii) the architecture also allows for rapid generalization (parameterization of dynamics) for data outside the training set. Moreover, the path of the sensor can be chosen arbitrarily, provided training data for the spatial trajectory of the sensor is available. The exceptional performance of the network architecture is demonstrated on three applications: turbulent flows, global sea-surface temperature data, and human movement biomechanics.", "url": "https://arxiv.org/abs/2307.11793"}, {"metadata": {"arXiv": "2307.11796", "Date": "Fri, 21 Jul 2023 08:52:47 ", "Title": "Unsupervised Embedding Learning for Human Activity Recognition Using Wearable Sensor Data", "Authors": ["Taoran Sheng and Manfred Huber"], "Categories": "cs.LG cs.HC eess.SP", "Comments": ["The Thirty-Third International Flairs Conference. 2020"]}, "abstract": "The embedded sensors in widely used smartphones and other wearable devices make the data of human activities more accessible. However, recognizing different human activities from the wearable sensor data remains a challenging research problem in ubiquitous computing. One of the reasons is that the majority of the acquired data has no labels. In this paper, we present an unsupervised approach, which is based on the nature of human activity, to project the human activities into an embedding space in which similar activities will be located closely together. Using this, subsequent clustering algorithms can benefit from the embeddings, forming behavior clusters that represent the distinct activities performed by a person. Results of experiments on three labeled benchmark datasets demonstrate the effectiveness of the framework and show that our approach can help the clustering algorithm achieve improved performance in identifying and categorizing the underlying human activities compared to unsupervised techniques applied directly to the original data set.", "url": "https://arxiv.org/abs/2307.11796"}, {"metadata": {"arXiv": "2307.11807", "Date": "Fri, 21 Jul 2023 17:22:04 ", "Title": "Local Kernel Renormalization as a mechanism for feature learning in overparametrized Convolutional Neural Networks", "Authors": ["R. Aiudi", "R. Pacelli", "A. Vezzani", "R. Burioni", "P. Rotondo"], "Categories": "cs.LG cond-mat.dis-nn", "Comments": ["22 pages", "5 figures", "2 tables. Comments are welcome"]}, "abstract": "Feature learning, or the ability of deep neural networks to automatically learn relevant features from raw data, underlies their exceptional capability to solve complex tasks. However, feature learning seems to be realized in different ways in fully-connected (FC) or convolutional architectures (CNNs). Empirical evidence shows that FC neural networks in the infinite-width limit eventually outperform their finite-width counterparts. Since the kernel that describes infinite-width networks does not evolve during training, whatever form of feature learning occurs in deep FC architectures is not very helpful in improving generalization. On the other hand, state-of-the-art architectures with convolutional layers achieve optimal performances in the finite-width regime, suggesting that an effective form of feature learning emerges in this case. In this work, we present a simple theoretical framework that provides a rationale for these differences, in one hidden layer networks. First, we show that the generalization performance of a finite-width FC network can be obtained by an infinite-width network, with a suitable choice of the Gaussian priors. Second, we derive a finite-width effective action for an architecture with one convolutional hidden layer and compare it with the result available for FC networks. Remarkably, we identify a completely different form of kernel renormalization: whereas the kernel of the FC architecture is just globally renormalized by a single scalar parameter, the CNN kernel undergoes a local renormalization, meaning that the network can select the local components that will contribute to the final prediction in a data-dependent way. This finding highlights a simple mechanism for feature learning that can take place in overparametrized shallow CNNs, but not in shallow FC architectures or in locally connected neural networks without weight sharing.", "url": "https://arxiv.org/abs/2307.11807"}, {"metadata": {"arXiv": "2307.11888", "Date": "Fri, 21 Jul 2023 20:09:06 ", "Title": "On the Universality of Linear Recurrences Followed by Nonlinear Projections", "Authors": ["Antonio Orvieto", "Soham De", "Caglar Gulcehre", "Razvan Pascanu", "Samuel L. Smith"], "Categories": "cs.LG cs.NE", "Comments": ["Accepted at HLD 2023: 1st Workshop on High-dimensional Learning Dynamics"]}, "abstract": "In this note (work in progress towards a full-length paper) we show that a family of sequence models based on recurrent linear layers~(including S4, S5, and the LRU) interleaved with position-wise multi-layer perceptrons~(MLPs) can approximate arbitrarily well any sufficiently regular non-linear sequence-to-sequence map. The main idea behind our result is to see recurrent layers as compression algorithms that can faithfully store information about the input sequence into an inner state, before it is processed by the highly expressive MLP.", "url": "https://arxiv.org/abs/2307.11888"}, {"metadata": {"arXiv": "2307.11899", "Date": "Fri, 21 Jul 2023 20:56:20 ", "Title": "Project Florida: Federated Learning Made Easy", "Authors": ["Daniel Madrigal Diaz", "Andre Manoel", "Jialei Chen", "Nalin Singal", "Robert Sim"], "Categories": "cs.LG cs.DC cs.SE"}, "abstract": "We present Project Florida, a system architecture and software development kit (SDK) enabling deployment of large-scale Federated Learning (FL) solutions across a heterogeneous device ecosystem. Federated learning is an approach to machine learning based on a strong data sovereignty principle, i.e., that privacy and security of data is best enabled by storing it at its origin, whether on end-user devices or in segregated cloud storage silos. Federated learning enables model training across devices and silos while the training data remains within its security boundary, by distributing a model snapshot to a client running inside the boundary, running client code to update the model, and then aggregating updated snapshots across many clients in a central orchestrator. Deploying a FL solution requires implementation of complex privacy and security mechanisms as well as scalable orchestration infrastructure. Scale and performance is a paramount concern, as the model training process benefits from full participation of many client devices, which may have a wide variety of performance characteristics. Project Florida aims to simplify the task of deploying cross-device FL solutions by providing cloud-hosted infrastructure and accompanying task management interfaces, as well as a multi-platform SDK supporting most major programming languages including C++, Java, and Python, enabling FL training across a wide range of operating system (OS) and hardware specifications. The architecture decouples service management from the FL workflow, enabling a cloud service provider to deliver FL-as-a-service (FLaaS) to ML engineers and application developers. We present an overview of Florida, including a description of the architecture, sample code, and illustrative experiments demonstrating system capabilities.", "url": "https://arxiv.org/abs/2307.11899"}, {"metadata": {"arXiv": "2307.11921", "Date": "Fri, 21 Jul 2023 22:00:39 ", "Title": "Poverty rate prediction using multi-modal survey and earth observation data", "Authors": ["Simone Fobi", "Manuel Cardona", "Elliott Collins", "Caleb Robinson", "Anthony Ortiz", "Tina Sederholm", "Rahul Dodhia", "Juan Lavista Ferres"], "Categories": "cs.LG cs.CV", "Comments": ["In 2023 ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies (COMPASS 23) Short Papers Track"]}, "abstract": "This work presents an approach for combining household demographic and living standards survey questions with features derived from satellite imagery to predict the poverty rate of a region. Our approach utilizes visual features obtained from a single-step featurization method applied to freely available 10m/px Sentinel-2 surface reflectance satellite imagery. These visual features are combined with ten survey questions in a proxy means test (PMT) to estimate whether a household is below the poverty line. We show that the inclusion of visual features reduces the mean error in poverty rate estimates from 4.09% to 3.88% over a nationally representative out-of-sample test set. In addition to including satellite imagery features in proxy means tests, we propose an approach for selecting a subset of survey questions that are complementary to the visual features extracted from satellite imagery. Specifically, we design a survey variable selection approach guided by the full survey and image features and use the approach to determine the most relevant set of small survey questions to include in a PMT. We validate the choice of small survey questions in a downstream task of predicting the poverty rate using the small set of questions. This approach results in the best performance -- errors in poverty rate decrease from 4.09% to 3.71%. We show that extracted visual features encode geographic and urbanization differences between regions.", "url": "https://arxiv.org/abs/2307.11921"}, {"metadata": {"arXiv": "2307.11925", "Date": "Fri, 21 Jul 2023 22:08:19 ", "Title": "Mercer Large-Scale Kernel Machines from Ridge Function Perspective", "Authors": ["Karol Dziedziul and Sergey Kryzhevich"], "Categories": "cs.LG math.CA", "Comments": ["14 pages"], "MSC-class": "42A10, 68T07, 26B40"}, "abstract": "To present Mercer large-scale kernel machines from a ridge function perspective, we recall the results by Lin and Pinkus from Fundamentality of ridge functions. We consider the main theorem of the recent paper by Rachimi and Recht, 2008, Random features for large-scale kernel machines in terms of the Approximation Theory. We study which kernels can be approximated by a sum of cosine function products with arguments depending on $x$ and $y$ and present the obstacles of such an approach. The results of this article may have various applications in Deep Learning, especially in problems related to Image Processing.", "url": "https://arxiv.org/abs/2307.11925"}, {"metadata": {"arXiv": "2307.11939", "Date": "Fri, 21 Jul 2023 23:37:37 ", "Title": "Batch Clipping and Adaptive Layerwise Clipping for Differential Private Stochastic Gradient Descent", "Authors": ["Toan N. Nguyen", "Phuong Ha Nguyen", "Lam M. Nguyen", "Marten Van Dijk"], "Categories": "cs.LG", "Comments": ["20 pages", "18 Figures"]}, "abstract": "Each round in Differential Private Stochastic Gradient Descent (DPSGD) transmits a sum of clipped gradients obfuscated with Gaussian noise to a central server which uses this to update a global model which often represents a deep neural network. Since the clipped gradients are computed separately, which we call Individual Clipping (IC), deep neural networks like resnet-18 cannot use Batch Normalization Layers (BNL) which is a crucial component in deep neural networks for achieving a high accuracy. To utilize BNL, we introduce Batch Clipping (BC) where, instead of clipping single gradients as in the orginal DPSGD, we average and clip batches of gradients. Moreover, the model entries of different layers have different sensitivities to the added Gaussian noise. Therefore, Adaptive Layerwise Clipping methods (ALC), where each layer has its own adaptively finetuned clipping constant, have been introduced and studied, but so far without rigorous DP proofs. In this paper, we propose {\\em a new ALC and provide rigorous DP proofs for both BC and ALC}. Experiments show that our modified DPSGD with BC and ALC for CIFAR-$10$ with resnet-$18$ converges while DPSGD with IC and ALC does not.", "url": "https://arxiv.org/abs/2307.11939"}, {"metadata": {"arXiv": "2307.11948", "Date": "Sat, 22 Jul 2023 00:07:49 ", "Title": "The instabilities of large learning rate training: a loss landscape view", "Authors": ["Lawrence Wang and Stephen Roberts"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2305.18490"]}, "abstract": "Modern neural networks are undeniably successful. Numerous works study how the curvature of loss landscapes can affect the quality of solutions. In this work we study the loss landscape by considering the Hessian matrix during network training with large learning rates - an attractive regime that is (in)famously unstable. We characterise the instabilities of gradient descent, and we observe the striking phenomena of \\textit{landscape flattening} and \\textit{landscape shift}, both of which are intimately connected to the instabilities of training.", "url": "https://arxiv.org/abs/2307.11948"}, {"metadata": {"arXiv": "2307.11955", "Date": "Sat, 22 Jul 2023 01:37:52 ", "Title": "Implicit Interpretation of Importance Weight Aware Updates", "Authors": ["Keyi Chen and Francesco Orabona"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2306.00201"]}, "abstract": "Due to its speed and simplicity, subgradient descent is one of the most used optimization algorithms in convex machine learning algorithms. However, tuning its learning rate is probably its most severe bottleneck to achieve consistent good performance. A common way to reduce the dependency on the learning rate is to use implicit/proximal updates. One such variant is the Importance Weight Aware (IWA) updates, which consist of infinitely many infinitesimal updates on each loss function. However, IWA updates' empirical success is not completely explained by their theory. In this paper, we show for the first time that IWA updates have a strictly better regret upper bound than plain gradient updates in the online learning setting. Our analysis is based on the new framework, generalized implicit Follow-the-Regularized-Leader (FTRL) (Chen and Orabona, 2023), to analyze generalized implicit updates using a dual formulation. In particular, our results imply that IWA updates can be considered as approximate implicit/proximal updates.", "url": "https://arxiv.org/abs/2307.11955"}, {"metadata": {"arXiv": "2307.11981", "Date": "Sat, 22 Jul 2023 04:52:27 ", "Title": "Collaborative Graph Neural Networks for Attributed Network Embedding", "Authors": ["Qiaoyu Tan", "Xin Zhang", "Xiao Huang", "Hao Chen", "Jundong Li", "and Xia Hu"], "Categories": "cs.LG cs.IR cs.SI"}, "abstract": "Graph neural networks (GNNs) have shown prominent performance on attributed network embedding. However, existing efforts mainly focus on exploiting network structures, while the exploitation of node attributes is rather limited as they only serve as node features at the initial layer. This simple strategy impedes the potential of node attributes in augmenting node connections, leading to limited receptive field for inactive nodes with few or even no neighbors. Furthermore, the training objectives (i.e., reconstructing network structures) of most GNNs also do not include node attributes, although studies have shown that reconstructing node attributes is beneficial. Thus, it is encouraging to deeply involve node attributes in the key components of GNNs, including graph convolution operations and training objectives. However, this is a nontrivial task since an appropriate way of integration is required to maintain the merits of GNNs. To bridge the gap, in this paper, we propose COllaborative graph Neural Networks--CONN, a tailored GNN architecture for attribute network embedding. It improves model capacity by 1) selectively diffusing messages from neighboring nodes and involved attribute categories, and 2) jointly reconstructing node-to-node and node-to-attribute-category interactions via cross-correlation. Experiments on real-world networks demonstrate that CONN excels state-of-the-art embedding algorithms with a great margin.", "url": "https://arxiv.org/abs/2307.11981"}, {"metadata": {"arXiv": "2307.12022", "Date": "Sat, 22 Jul 2023 08:58:07 ", "Title": "A Flexible Framework for Incorporating Patient Preferences Into Q-Learning", "Authors": ["Joshua P. Zitovsky", "Leslie Wilson and Michael R. Kosorok"], "Categories": "cs.LG stat.ME", "Comments": ["Under Review"]}, "abstract": "In real-world healthcare problems, there are often multiple competing outcomes of interest, such as treatment efficacy and side effect severity. However, statistical methods for estimating dynamic treatment regimes (DTRs) usually assume a single outcome of interest, and the few methods that deal with composite outcomes suffer from important limitations. This includes restrictions to a single time point and two outcomes, the inability to incorporate self-reported patient preferences and limited theoretical guarantees. To this end, we propose a new method to address these limitations, which we dub Latent Utility Q-Learning (LUQ-Learning). LUQ-Learning uses a latent model approach to naturally extend Q-learning to the composite outcome setting and adopt the ideal trade-off between outcomes to each patient. Unlike previous approaches, our framework allows for an arbitrary number of time points and outcomes, incorporates stated preferences and achieves strong asymptotic performance with realistic assumptions on the data. We conduct simulation experiments based on an ongoing trial for low back pain as well as a well-known completed trial for schizophrenia. In all experiments, our method achieves highly competitive empirical performance compared to several alternative baselines.", "url": "https://arxiv.org/abs/2307.12022"}, {"metadata": {"arXiv": "2307.12063", "Date": "Sat, 22 Jul 2023 12:10:23 ", "Title": "Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs", "Authors": ["Qingyang Zhang", "Yiming Yang", "Jingqing Ruan", "Xuantang Xiong", "Dengpeng Xing", "Bo Xu"], "Categories": "cs.LG", "Comments": ["Accepted by the conference of International Joint Conference on Neural Networks (IJCNN) 2023"]}, "abstract": "Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into subgoal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on subgoal representation functions and subgoal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent subgoal representations and lack an efficient subgoal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges. Finally, HILL develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures. Experimental results demonstrate that HILL outperforms state-of-the-art baselines on continuous control tasks with sparse rewards in sample efficiency and asymptotic performance. Our code is available at https://github.com/papercode2022/HILL.", "url": "https://arxiv.org/abs/2307.12063"}, {"metadata": {"arXiv": "2307.12065", "Date": "Sat, 22 Jul 2023 12:20:46 ", "Title": "Spectral Normalized-Cut Graph Partitioning with Fairness Constraints", "Authors": ["Jia Li", "Yanhao Wang", "Arpit Merchant"], "Categories": "cs.LG cs.CY cs.DS", "Comments": ["17 pages", "7 figures", "accepted to the 26th European Conference on Artificial Intelligence (ECAI 2023)"]}, "abstract": "Normalized-cut graph partitioning aims to divide the set of nodes in a graph into $k$ disjoint clusters to minimize the fraction of the total edges between any cluster and all other clusters. In this paper, we consider a fair variant of the partitioning problem wherein nodes are characterized by a categorical sensitive attribute (e.g., gender or race) indicating membership to different demographic groups. Our goal is to ensure that each group is approximately proportionally represented in each cluster while minimizing the normalized cut value. To resolve this problem, we propose a two-phase spectral algorithm called FNM. In the first phase, we add an augmented Lagrangian term based on our fairness criteria to the objective function for obtaining a fairer spectral node embedding. Then, in the second phase, we design a rounding scheme to produce $k$ clusters from the fair embedding that effectively trades off fairness and partition quality. Through comprehensive experiments on nine benchmark datasets, we demonstrate the superior performance of FNM compared with three baseline methods.", "url": "https://arxiv.org/abs/2307.12065"}, {"metadata": {"arXiv": "2307.12135", "Date": "Sat, 22 Jul 2023 18:02:53 ", "Title": "The Sample Complexity of Multi-Distribution Learning for VC Classes", "Authors": ["Pranjal Awasthi", "Nika Haghtalab", "Eric Zhao"], "Categories": "cs.LG stat.ML", "Comments": ["11 pages. Authors are ordered alphabetically. Open problem presented at the 36th Annual Conference on Learning Theory"]}, "abstract": "Multi-distribution learning is a natural generalization of PAC learning to settings with multiple data distributions. There remains a significant gap between the known upper and lower bounds for PAC-learnable classes. In particular, though we understand the sample complexity of learning a VC dimension d class on $k$ distributions to be $O(\\epsilon^{-2} \\ln(k)(d + k) + \\min\\{\\epsilon^{-1} dk, \\epsilon^{-4} \\ln(k) d\\})$, the best lower bound is $\\Omega(\\epsilon^{-2}(d + k \\ln(k)))$. We discuss recent progress on this problem and some hurdles that are fundamental to the use of game dynamics in statistical learning.", "url": "https://arxiv.org/abs/2307.12135"}, {"metadata": {"arXiv": "2307.12136", "Date": "Sat, 22 Jul 2023 18:05:28 ", "Title": "Unlocking Carbon Reduction Potential with Reinforcement Learning for the Three-Dimensional Loading Capacitated Vehicle Routing Problem", "Authors": ["Stefan Schoepf", "Stephen Mak", "Julian Senoner", "Liming Xu", "Netland Torbj\\\"orn", "Alexandra Brintrup"], "Categories": "cs.LG math.OC"}, "abstract": "Heavy goods vehicles are vital backbones of the supply chain delivery system but also contribute significantly to carbon emissions with only 60% loading efficiency in the United Kingdom. Collaborative vehicle routing has been proposed as a solution to increase efficiency, but challenges remain to make this a possibility. One key challenge is the efficient computation of viable solutions for co-loading and routing. Current operations research methods suffer from non-linear scaling with increasing problem size and are therefore bound to limited geographic areas to compute results in time for day-to-day operations. This only allows for local optima in routing and leaves global optimisation potential untouched. We develop a reinforcement learning model to solve the three-dimensional loading capacitated vehicle routing problem in approximately linear time. While this problem has been studied extensively in operations research, no publications on solving it with reinforcement learning exist. We demonstrate the favourable scaling of our reinforcement learning model and benchmark our routing performance against state-of-the-art methods. The model performs within an average gap of 3.83% to 8.10% compared to established methods. Our model not only represents a promising first step towards large-scale logistics optimisation with reinforcement learning but also lays the foundation for this research stream.", "url": "https://arxiv.org/abs/2307.12136"}, {"metadata": {"arXiv": "2307.12149", "Date": "Sat, 22 Jul 2023 19:23:06 ", "Title": "CorrFL: Correlation-Based Neural Network Architecture for Unavailability Concerns in a Heterogeneous IoT Environment", "Authors": ["Ibrahim Shaer", "Abdallah Shami"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["17 pages", "12 figures", "IEEE Transactions on Network and Service Management"], "Journal-ref": "IEEE Transactions on Network and Service Management, vol. 20, no. 2, pp. 1543-1557, June 2023", "DOI": "10.1109/TNSM.2023.3278937."}, "abstract": "The Federated Learning (FL) paradigm faces several challenges that limit its application in real-world environments. These challenges include the local models' architecture heterogeneity and the unavailability of distributed Internet of Things (IoT) nodes due to connectivity problems. These factors posit the question of \"how can the available models fill the training gap of the unavailable models?\". This question is referred to as the \"Oblique Federated Learning\" problem. This problem is encountered in the studied environment that includes distributed IoT nodes responsible for predicting CO2 concentrations. This paper proposes the Correlation-based FL (CorrFL) approach influenced by the representational learning field to address this problem. CorrFL projects the various model weights to a common latent space to address the model heterogeneity. Its loss function minimizes the reconstruction loss when models are absent and maximizes the correlation between the generated models. The latter factor is critical because of the intersection of the feature spaces of the IoT devices. CorrFL is evaluated on a realistic use case, involving the unavailability of one IoT device and heightened activity levels that reflect occupancy. The generated CorrFL models for the unavailable IoT device from the available ones trained on the new environment are compared against models trained on different use cases, referred to as the benchmark model. The evaluation criteria combine the mean absolute error (MAE) of predictions and the impact of the amount of exchanged data on the prediction performance improvement. Through a comprehensive experimental procedure, the CorrFL model outperformed the benchmark model in every criterion.", "url": "https://arxiv.org/abs/2307.12149"}, {"metadata": {"arXiv": "2307.12157", "Date": "Sat, 22 Jul 2023 20:03:16 ", "Title": "Identifying contributors to supply chain outcomes in a multi-echelon setting: a decentralised approach", "Authors": ["Stefan Schoepf", "Jack Foster", "Alexandra Brintrup"], "Categories": "cs.LG"}, "abstract": "Organisations often struggle to identify the causes of change in metrics such as product quality and delivery duration. This task becomes increasingly challenging when the cause lies outside of company borders in multi-echelon supply chains that are only partially observable. Although traditional supply chain management has advocated for data sharing to gain better insights, this does not take place in practice due to data privacy concerns. We propose the use of explainable artificial intelligence for decentralised computing of estimated contributions to a metric of interest in a multi-stage production process. This approach mitigates the need to convince supply chain actors to share data, as all computations occur in a decentralised manner. Our method is empirically validated using data collected from a real multi-stage manufacturing process. The results demonstrate the effectiveness of our approach in detecting the source of quality variations compared to a centralised approach using Shapley additive explanations.", "url": "https://arxiv.org/abs/2307.12157"}, {"metadata": {"arXiv": "2307.12198", "Date": "Sun, 23 Jul 2023 01:27:26 ", "Title": "NCART: Neural Classification and Regression Tree for Tabular Data", "Authors": ["Jiaqi Luo", "Shixin Xu"], "Categories": "cs.LG"}, "abstract": "Deep learning models have become popular in the analysis of tabular data, as they address the limitations of decision trees and enable valuable applications like semi-supervised learning, online learning, and transfer learning. However, these deep-learning approaches often encounter a trade-off. On one hand, they can be computationally expensive when dealing with large-scale or high-dimensional datasets. On the other hand, they may lack interpretability and may not be suitable for small-scale datasets. In this study, we propose a novel interpretable neural network called Neural Classification and Regression Tree (NCART) to overcome these challenges. NCART is a modified version of Residual Networks that replaces fully-connected layers with multiple differentiable oblivious decision trees. By integrating decision trees into the architecture, NCART maintains its interpretability while benefiting from the end-to-end capabilities of neural networks. The simplicity of the NCART architecture makes it well-suited for datasets of varying sizes and reduces computational costs compared to state-of-the-art deep learning models. Extensive numerical experiments demonstrate the superior performance of NCART compared to existing deep learning models, establishing it as a strong competitor to tree-based models.", "url": "https://arxiv.org/abs/2307.12198"}, {"metadata": {"arXiv": "2307.12204", "Date": "Sun, 23 Jul 2023 02:18:30 ", "Title": "Adversarial Agents For Attacking Inaudible Voice Activated Devices", "Authors": ["Forrest McKee and David Noever"], "Categories": "cs.LG cs.SD eess.AS"}, "abstract": "Our analysis of inaudible attacks on voice-activated devices confirms the alarming risk factor of 7.6 out of 10, underlining significant security vulnerabilities scored independently by NIST National Vulnerability Database (NVD). Our baseline network model showcases a scenario in which an attacker uses inaudible voice commands to gain unauthorized access to confidential information on a secured laptop. We simulated many attack scenarios on this baseline network model, revealing the potential for mass exploitation of interconnected devices to discover and own privileged information through physical access without adding new hardware or amplifying device skills. Using Microsoft's CyberBattleSim framework, we evaluated six reinforcement learning algorithms and found that Deep-Q learning with exploitation proved optimal, leading to rapid ownership of all nodes in fewer steps. Our findings underscore the critical need for understanding non-conventional networks and new cybersecurity measures in an ever-expanding digital landscape, particularly those characterized by mobile devices, voice activation, and non-linear microphones susceptible to malicious actors operating stealth attacks in the near-ultrasound or inaudible ranges. By 2024, this new attack surface might encompass more digital voice assistants than people on the planet yet offer fewer remedies than conventional patching or firmware fixes since the inaudible attacks arise inherently from the microphone design and digital signal processing.", "url": "https://arxiv.org/abs/2307.12204"}, {"metadata": {"arXiv": "2307.12219", "Date": "Sun, 23 Jul 2023 03:53:53 ", "Title": "Improving Out-of-Distribution Robustness of Classifiers via Generative Interpolation", "Authors": ["Haoyue Bai", "Ceyuan Yang", "Yinghao Xu", "S.-H. Gary Chan", "Bolei Zhou"], "Categories": "cs.LG"}, "abstract": "Deep neural networks achieve superior performance for learning from independent and identically distributed (i.i.d.) data. However, their performance deteriorates significantly when handling out-of-distribution (OoD) data, where the training and test are drawn from different distributions. In this paper, we explore utilizing the generative models as a data augmentation source for improving out-of-distribution robustness of neural classifiers. Specifically, we develop a simple yet effective method called Generative Interpolation to fuse generative models trained from multiple domains for synthesizing diverse OoD samples. Training a generative model directly on the source domains tends to suffer from mode collapse and sometimes amplifies the data bias. Instead, we first train a StyleGAN model on one source domain and then fine-tune it on the other domains, resulting in many correlated generators where their model parameters have the same initialization thus are aligned. We then linearly interpolate the model parameters of the generators to spawn new sets of generators. Such interpolated generators are used as an extra data augmentation source to train the classifiers. The interpolation coefficients can flexibly control the augmentation direction and strength. In addition, a style-mixing mechanism is applied to further improve the diversity of the generated OoD samples. Our experiments show that the proposed method explicitly increases the diversity of training domains and achieves consistent improvements over baselines across datasets and multiple different distribution shifts.", "url": "https://arxiv.org/abs/2307.12219"}, {"metadata": {"arXiv": "2307.12236", "Date": "Sun, 23 Jul 2023 06:03:12 ", "Title": "Multi-Modal Machine Learning for Assessing Gaming Skills in Online Streaming: A Case Study with CS:GO", "Authors": ["Longxiang Zhang", "Wenping Wang"], "Categories": "cs.LG cs.CV"}, "abstract": "Online streaming is an emerging market that address much attention. Assessing gaming skills from videos is an important task for streaming service providers to discover talented gamers. Service providers require the information to offer customized recommendation and service promotion to their customers. Meanwhile, this is also an important multi-modal machine learning tasks since online streaming combines vision, audio and text modalities. In this study we begin by identifying flaws in the dataset and proceed to clean it manually. Then we propose several variants of latest end-to-end models to learn joint representation of multiple modalities. Through our extensive experimentation, we demonstrate the efficacy of our proposals. Moreover, we identify that our proposed models is prone to identifying users instead of learning meaningful representations. We purpose future work to address the issue in the end.", "url": "https://arxiv.org/abs/2307.12236"}, {"metadata": {"arXiv": "2307.12296", "Date": "Sun, 23 Jul 2023 11:21:34 ", "Title": "Comparative analysis using classification methods versus early stage diabetes", "Authors": ["Alca-Vilca Gabriel Anthony", "Carpio-Vargas Eloy"], "Categories": "cs.LG"}, "abstract": "In this research work, a comparative analysis was carried out using classification methods such as: Discriminant Analysis and Logistic Regression to subsequently predict whether a person may have the presence of early stage diabetes. For this purpose, use was made of a database of the UC IRVINE platform of the year 2020 where specific variables that influence diabetes were used for a better result. Likewise in terms of methodology, the corresponding analysis was performed for each of the 3 classification methods and then take them to a comparative table and analyze the results obtained. Finally we can add that the majority of the studies carried out applying the classification methods to the diseases can be clearly seen that there is a certain attachment and more use of the logistic regression classification method, on the other hand, in the results we could see significant differences in terms of the 2 classification methods that were applied, which was valuable information for later drawing final conclusions.", "url": "https://arxiv.org/abs/2307.12296"}, {"metadata": {"arXiv": "2307.12304", "Date": "Sun, 23 Jul 2023 12:12:44 ", "Title": "Physics-Informed Machine Learning of Argon Gas-Driven Melt Pool Dynamics", "Authors": ["R. Sharma", "W. Grace Guo", "M. Raissi", "Y.B. Guo"], "Categories": "cs.LG cs.CE"}, "abstract": "Melt pool dynamics in metal additive manufacturing (AM) is critical to process stability, microstructure formation, and final properties of the printed materials. Physics-based simulation including computational fluid dynamics (CFD) is the dominant approach to predict melt pool dynamics. However, the physics-based simulation approaches suffer from the inherent issue of very high computational cost. This paper provides a physics-informed machine learning (PIML) method by integrating neural networks with the governing physical laws to predict the melt pool dynamics such as temperature, velocity, and pressure without using any training data on velocity. This approach avoids solving the highly non-linear Navier-Stokes equation numerically, which significantly reduces the computational cost. The difficult-to-determine model constants of the governing equations of the melt pool can also be inferred through data-driven discovery. In addition, the physics-informed neural network (PINN) architecture has been optimized for efficient model training. The data-efficient PINN model is attributed to the soft penalty by incorporating governing partial differential equations (PDEs), initial conditions, and boundary conditions in the PINN model.", "url": "https://arxiv.org/abs/2307.12304"}, {"metadata": {"arXiv": "2307.12333", "Date": "Sun, 23 Jul 2023 14:00:33 ", "Title": "An axiomatized PDE model of deep neural networks", "Authors": ["Tangjun Wang", "Wenqi Tao", "Chenglong Bao", "Zuoqiang Shi"], "Categories": "cs.LG"}, "abstract": "Inspired by the relation between deep neural network (DNN) and partial differential equations (PDEs), we study the general form of the PDE models of deep neural networks. To achieve this goal, we formulate DNN as an evolution operator from a simple base model. Based on several reasonable assumptions, we prove that the evolution operator is actually determined by convection-diffusion equation. This convection-diffusion equation model gives mathematical explanation for several effective networks. Moreover, we show that the convection-diffusion model improves the robustness and reduces the Rademacher complexity. Based on the convection-diffusion equation, we design a new training method for ResNets. Experiments validate the performance of the proposed method.", "url": "https://arxiv.org/abs/2307.12333"}, {"metadata": {"arXiv": "2307.12336", "Date": "Sun, 23 Jul 2023 14:02:33 ", "Title": "TabADM: Unsupervised Tabular Anomaly Detection with Diffusion Models", "Authors": ["Guy Zamberg and Moshe Salhov and Ofir Lindenbaum and Amir Averbuch"], "Categories": "cs.LG"}, "abstract": "Tables are an abundant form of data with use cases across all scientific fields. Real-world datasets often contain anomalous samples that can negatively affect downstream analysis. In this work, we only assume access to contaminated data and present a diffusion-based probabilistic model effective for unsupervised anomaly detection. Our model is trained to learn the density of normal samples by utilizing a unique rejection scheme to attenuate the influence of anomalies on the density estimation. At inference, we identify anomalies as samples in low-density regions. We use real data to demonstrate that our method improves detection capabilities over baselines. Furthermore, our method is relatively stable to the dimension of the data and does not require extensive hyperparameter tuning.", "url": "https://arxiv.org/abs/2307.12336"}, {"metadata": {"arXiv": "2307.12341", "Date": "Sun, 23 Jul 2023 14:32:07 ", "Title": "Rapid detection of soil carbonates by means of NIR spectroscopy, deep learning methods and phase quantification by powder Xray diffraction", "Authors": ["Lykourgos Chiniadis", "Petros Tamvakis"], "Categories": "cs.LG cs.CV eess.IV", "Comments": ["39 pages", "5 figures"]}, "abstract": "Soil NIR spectral absorbance/reflectance libraries are utilized towards improving agricultural production and analysis of soil properties which are key prerequisite for agroecological balance and environmental sustainability. Carbonates in particular, represent a soil property which is mostly affected even by mild, let alone extreme, changes of environmental conditions during climate change. In this study we propose a rapid and efficient way to predict carbonates content in soil by means of FT NIR reflectance spectroscopy and by use of deep learning methods. We exploited multiple machine learning methods, such as: 1) a MLP Regressor and 2) a CNN and compare their performance with other traditional ML algorithms such as PLSR, Cubist and SVM on the combined dataset of two NIR spectral libraries: KSSL (USDA), a dataset of soil samples reflectance spectra collected nationwide, and LUCAS TopSoil (European Soil Library) which contains soil sample absorbance spectra from all over the European Union, and use them to predict carbonate content on never before seen soil samples. Soil samples in KSSL and in TopSoil spectral libraries were acquired in the spectral region of visNIR, however in this study, only the NIR spectral region was utilized. Quantification of carbonates by means of Xray Diffraction is in good agreement with the volumetric method and the MLP prediction. Our work contributes to rapid carbonates content prediction in soil samples in cases where: 1) no volumetric method is available and 2) only NIR spectra absorbance data are available. Up till now and to the best of our knowledge, there exists no other study, that presents a prediction model trained on such an extensive dataset with such promising results on unseen data, undoubtedly supporting the notion that deep learning models present excellent prediction tools for soil carbonates content.", "url": "https://arxiv.org/abs/2307.12341"}, {"metadata": {"arXiv": "2307.12405", "Date": "Sun, 23 Jul 2023 19:12:44 ", "Title": "Optimal Control of Multiclass Fluid Queueing Networks: A Machine Learning Approach", "Authors": ["Dimitris Bertsimas", "Cheol Woo Kim"], "Categories": "cs.LG"}, "abstract": "We propose a machine learning approach to the optimal control of multiclass fluid queueing networks (MFQNETs) that provides explicit and insightful control policies. We prove that a threshold type optimal policy exists for MFQNET control problems, where the threshold curves are hyperplanes passing through the origin. We use Optimal Classification Trees with hyperplane splits (OCT-H) to learn an optimal control policy for MFQNETs. We use numerical solutions of MFQNET control problems as a training set and apply OCT-H to learn explicit control policies. We report experimental results with up to 33 servers and 99 classes that demonstrate that the learned policies achieve 100\\% accuracy on the test set. While the offline training of OCT-H can take days in large networks, the online application takes milliseconds.", "url": "https://arxiv.org/abs/2307.12405"}, {"metadata": {"arXiv": "2307.12409", "Date": "Sun, 23 Jul 2023 19:23:06 ", "Title": "A Machine Learning Approach to Two-Stage Adaptive Robust Optimization", "Authors": ["Dimitris Bertsimas", "Cheol Woo Kim"], "Categories": "cs.LG math.OC"}, "abstract": "We propose an approach based on machine learning to solve two-stage linear adaptive robust optimization (ARO) problems with binary here-and-now variables and polyhedral uncertainty sets. We encode the optimal here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the optimal wait-and-see decisions into what we denote as the strategy. We solve multiple similar ARO instances in advance using the column and constraint generation algorithm and extract the optimal strategies to generate a training set. We train a machine learning model that predicts high-quality strategies for the here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the wait-and-see decisions. We also introduce an algorithm to reduce the number of different target classes the machine learning algorithm needs to be trained on. We apply the proposed approach to the facility location, the multi-item inventory control and the unit commitment problems. Our approach solves ARO problems drastically faster than the state-of-the-art algorithms with high accuracy.", "url": "https://arxiv.org/abs/2307.12409"}, {"metadata": {"arXiv": "2307.12435", "Date": "Sun, 23 Jul 2023 21:18:04 ", "Title": "A Generalized Schwarz-type Non-overlapping Domain Decomposition Method using Physics-constrained Neural Networks", "Authors": ["Shamsulhaq Basir", "Inanc Senocak"], "Categories": "cs.LG cs.DC cs.NA math.NA physics.flu-dyn"}, "abstract": "We present a meshless Schwarz-type non-overlapping domain decomposition method based on artificial neural networks for solving forward and inverse problems involving partial differential equations (PDEs). To ensure the consistency of solutions across neighboring subdomains, we adopt a generalized Robin-type interface condition, assigning unique Robin parameters to each subdomain. These subdomain-specific Robin parameters are learned to minimize the mismatch on the Robin interface condition, facilitating efficient information exchange during training. Our method is applicable to both the Laplace's and Helmholtz equations. It represents local solutions by an independent neural network model which is trained to minimize the loss on the governing PDE while strictly enforcing boundary and interface conditions through an augmented Lagrangian formalism. A key strength of our method lies in its ability to learn a Robin parameter for each subdomain, thereby enhancing information exchange with its neighboring subdomains. We observe that the learned Robin parameters adapt to the local behavior of the solution, domain partitioning and subdomain location relative to the overall domain. Extensive experiments on forward and inverse problems, including one-way and two-way decompositions with crosspoints, demonstrate the versatility and performance of our proposed approach.", "url": "https://arxiv.org/abs/2307.12435"}, {"metadata": {"arXiv": "2307.12461", "Date": "Mon, 24 Jul 2023 00:16:50 ", "Title": "Rates of Approximation by ReLU Shallow Neural Networks", "Authors": ["Tong Mao and Ding-Xuan Zhou"], "Categories": "cs.LG stat.ML"}, "abstract": "Neural networks activated by the rectified linear unit (ReLU) play a central role in the recent development of deep learning. The topic of approximating functions from H\\\"older spaces by these networks is crucial for understanding the efficiency of the induced learning algorithms. Although the topic has been well investigated in the setting of deep neural networks with many layers of hidden neurons, it is still open for shallow networks having only one hidden layer. In this paper, we provide rates of uniform approximation by these networks. We show that ReLU shallow neural networks with $m$ hidden neurons can uniformly approximate functions from the H\\\"older space $W_\\infty^r([-1, 1]^d)$ with rates $O((\\log m)^{\\frac{1}{2} +d}m^{-\\frac{r}{d}\\frac{d+2}{d+4}})$ when $r<d/2 +2$. Such rates are very close to the optimal one $O(m^{-\\frac{r}{d}})$ in the sense that $\\frac{d+2}{d+4}$ is close to $1$, when the dimension $d$ is large.", "url": "https://arxiv.org/abs/2307.12461"}, {"metadata": {"arXiv": "2307.12480", "Date": "Mon, 24 Jul 2023 02:28:50 ", "Title": "Learning Resource Allocation Policy: Vertex-GNN or Edge-GNN?", "Authors": ["Yao Peng", "Jia Guo and Chenyang Yang"], "Categories": "cs.LG eess.SP"}, "abstract": "Graph neural networks (GNNs) update the hidden representations of vertices (called Vertex-GNNs) or hidden representations of edges (called Edge-GNNs) by processing and pooling the information of neighboring vertices and edges and combining to incorporate graph topology. When learning resource allocation policies, GNNs cannot perform well if their expressive power are weak, i.e., if they cannot differentiate all input features such as channel matrices. In this paper, we analyze the expressive power of the Vertex-GNNs and Edge-GNNs for learning three representative wireless policies: link scheduling, power control, and precoding policies. We find that the expressive power of the GNNs depend on the linearity and output dimensions of the processing and combination functions. When linear processors are used, the Vertex-GNNs cannot differentiate all channel matrices due to the loss of channel information, while the Edge-GNNs can. When learning the precoding policy, even the Vertex-GNNs with non-linear processors may not be with strong expressive ability due to the dimension compression. We proceed to provide necessary conditions for the GNNs to well learn the precoding policy. Simulation results validate the analyses and show that the Edge-GNNs can achieve the same performance as the Vertex-GNNs with much lower training and inference time.", "url": "https://arxiv.org/abs/2307.12480"}, {"metadata": {"arXiv": "2307.12491", "Date": "Mon, 24 Jul 2023 02:50:19 ", "Title": "Learning Universal and Robust 3D Molecular Representations with Graph Convolutional Networks", "Authors": ["Shuo Zhang", "Yang Liu", "Li Xie", "Lei Xie"], "Categories": "cs.LG q-bio.BM", "Comments": ["Preprint. Work in progress"]}, "abstract": "To learn accurate representations of molecules, it is essential to consider both chemical and geometric features. To encode geometric information, many descriptors have been proposed in constrained circumstances for specific types of molecules and do not have the properties to be ``robust\": 1. Invariant to rotations and translations; 2. Injective when embedding molecular structures. In this work, we propose a universal and robust Directional Node Pair (DNP) descriptor based on the graph representations of 3D molecules. Our DNP descriptor is robust compared to previous ones and can be applied to multiple molecular types. To combine the DNP descriptor and chemical features in molecules, we construct the Robust Molecular Graph Convolutional Network (RoM-GCN) which is capable to take both node and edge features into consideration when generating molecule representations. We evaluate our model on protein and small molecule datasets. Our results validate the superiority of the DNP descriptor in incorporating 3D geometric information of molecules. RoM-GCN outperforms all compared baselines.", "url": "https://arxiv.org/abs/2307.12491"}, {"metadata": {"arXiv": "2307.12496", "Date": "Mon, 24 Jul 2023 03:04:10 ", "Title": "A faster and simpler algorithm for learning shallow networks", "Authors": ["Sitan Chen", "Shyam Narayanan"], "Categories": "cs.LG cs.DS stat.ML", "Comments": ["14 pages"]}, "abstract": "We revisit the well-studied problem of learning a linear combination of $k$ ReLU activations given labeled examples drawn from the standard $d$-dimensional Gaussian measure. Chen et al. [CDG+23] recently gave the first algorithm for this problem to run in $\\text{poly}(d,1/\\varepsilon)$ time when $k = O(1)$, where $\\varepsilon$ is the target error. More precisely, their algorithm runs in time $(d/\\varepsilon)^{\\mathrm{quasipoly}(k)}$ and learns over multiple stages. Here we show that a much simpler one-stage version of their algorithm suffices, and moreover its runtime is only $(d/\\varepsilon)^{O(k^2)}$.", "url": "https://arxiv.org/abs/2307.12496"}, {"metadata": {"arXiv": "2307.12499", "Date": "Mon, 24 Jul 2023 03:10:02 ", "Title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models", "Authors": ["Xuelong Dai", "Kaisheng Liang and Bin Xiao"], "Categories": "cs.LG cs.CV"}, "abstract": "Unrestricted adversarial attacks present a serious threat to deep learning models and adversarial defense techniques. They pose severe security problems for deep learning applications because they can effectively bypass defense mechanisms. However, previous attack methods often utilize Generative Adversarial Networks (GANs), which are not theoretically provable and thus generate unrealistic examples by incorporating adversarial objectives, especially for large-scale datasets like ImageNet. In this paper, we propose a new method, called AdvDiff, to generate unrestricted adversarial examples with diffusion models. We design two novel adversarial guidance techniques to conduct adversarial sampling in the reverse generation process of diffusion models. These two techniques are effective and stable to generate high-quality, realistic adversarial examples by integrating gradients of the target classifier interpretably. Experimental results on MNIST and ImageNet datasets demonstrate that AdvDiff is effective to generate unrestricted adversarial examples, which outperforms GAN-based methods in terms of attack performance and generation quality.", "url": "https://arxiv.org/abs/2307.12499"}, {"metadata": {"arXiv": "2307.12510", "Date": "Mon, 24 Jul 2023 03:52:11 ", "Title": "An Empirical Evaluation of Temporal Graph Benchmark", "Authors": ["Le Yu"], "Categories": "cs.LG", "Comments": ["preprint", "in progress"]}, "abstract": "In this paper, we conduct an empirical evaluation of Temporal Graph Benchmark (TGB) by extending our Dynamic Graph Library (DyGLib) to TGB. Compared with TGB, we include eleven popular dynamic graph learning methods for more exhaustive comparisons. Through the experiments, we find that (1) some issues need to be addressed in the current version of TGB, including mismatched data statistics, inaccurate evaluation metric computation, and so on; (2) different models depict varying performance across various datasets, which is in line with previous observations; (3) the performance of some baselines can be significantly improved over the reported results in TGB when using DyGLib. This work aims to ease the researchers' efforts in evaluating various dynamic graph learning methods on TGB and attempts to offer results that can be directly referenced in the follow-up research. All the used resources in this project are publicly available at https://github.com/yule-BUAA/DyGLib_TGB. This work is in progress, and feedback from the community is welcomed for improvements.", "url": "https://arxiv.org/abs/2307.12510"}, {"metadata": {"arXiv": "2307.12519", "Date": "Mon, 24 Jul 2023 04:29:00 ", "Title": "DEPHN: Different Expression Parallel Heterogeneous Network using virtual gradient optimization for Multi-task Learning", "Authors": ["Menglin Kong", "Ri Su", "Shaojie Zhao", "Muzhou Hou"], "Categories": "cs.LG"}, "abstract": "Recommendation system algorithm based on multi-task learning (MTL) is the major method for Internet operators to understand users and predict their behaviors in the multi-behavior scenario of platform. Task correlation is an important consideration of MTL goals, traditional models use shared-bottom models and gating experts to realize shared representation learning and information differentiation. However, The relationship between real-world tasks is often more complex than existing methods do not handle properly sharing information. In this paper, we propose an Different Expression Parallel Heterogeneous Network (DEPHN) to model multiple tasks simultaneously. DEPHN constructs the experts at the bottom of the model by using different feature interaction methods to improve the generalization ability of the shared information flow. In view of the model's differentiating ability for different task information flows, DEPHN uses feature explicit mapping and virtual gradient coefficient for expert gating during the training process, and adaptively adjusts the learning intensity of the gated unit by considering the difference of gating values and task correlation. Extensive experiments on artificial and real-world datasets demonstrate that our proposed method can capture task correlation in complex situations and achieve better performance than baseline models\\footnote{Accepted in IJCNN2023}.", "url": "https://arxiv.org/abs/2307.12519"}, {"metadata": {"arXiv": "2307.12524", "Date": "Mon, 24 Jul 2023 04:46:22 ", "Title": "Landslide Surface Displacement Prediction Based on VSXC-LSTM Algorithm", "Authors": ["Menglin Kong", "Ruichen Li", "Fan Liu", "Xingquan Li", "Juan Cheng", "Muzhou Hou", "Cong Cao"], "Categories": "cs.LG physics.geo-ph"}, "abstract": "Landslide is a natural disaster that can easily threaten local ecology, people's lives and property. In this paper, we conduct modelling research on real unidirectional surface displacement data of recent landslides in the research area and propose a time series prediction framework named VMD-SegSigmoid-XGBoost-ClusterLSTM (VSXC-LSTM) based on variational mode decomposition, which can predict the landslide surface displacement more accurately. The model performs well on the test set. Except for the random item subsequence that is hard to fit, the root mean square error (RMSE) and the mean absolute percentage error (MAPE) of the trend item subsequence and the periodic item subsequence are both less than 0.1, and the RMSE is as low as 0.006 for the periodic item prediction module based on XGBoost\\footnote{Accepted in ICANN2023}.", "url": "https://arxiv.org/abs/2307.12524"}, {"metadata": {"arXiv": "2307.12555", "Date": "Mon, 24 Jul 2023 06:41:59 ", "Title": "Homophily-Driven Sanitation View for Robust Graph Contrastive Learning", "Authors": ["Yulin Zhu", "Xing Ai", "Yevgeniy Vorobeychik", "Kai Zhou"], "Categories": "cs.LG cs.SI"}, "abstract": "We investigate adversarial robustness of unsupervised Graph Contrastive Learning (GCL) against structural attacks. First, we provide a comprehensive empirical and theoretical analysis of existing attacks, revealing how and why they downgrade the performance of GCL. Inspired by our analytic results, we present a robust GCL framework that integrates a homophily-driven sanitation view, which can be learned jointly with contrastive learning. A key challenge this poses, however, is the non-differentiable nature of the sanitation objective. To address this challenge, we propose a series of techniques to enable gradient-based end-to-end robust GCL. Moreover, we develop a fully unsupervised hyperparameter tuning method which, unlike prior approaches, does not require knowledge of node labels. We conduct extensive experiments to evaluate the performance of our proposed model, GCHS (Graph Contrastive Learning with Homophily-driven Sanitation View), against two state of the art structural attacks on GCL. Our results demonstrate that GCHS consistently outperforms all state of the art baselines in terms of the quality of generated node embeddings as well as performance on two important downstream tasks.", "url": "https://arxiv.org/abs/2307.12555"}, {"metadata": {"arXiv": "2307.12586", "Date": "Mon, 24 Jul 2023 07:58:18 ", "Title": "InVAErt networks: a data-driven framework for emulation, inference and identifiability analysis", "Authors": ["Guoxiang Grayson Tong", "Carlos A. Sing Long", "Daniele E. Schiavazzi"], "Categories": "cs.LG cs.NA math.NA stat.ML"}, "abstract": "Use of generative models and deep learning for physics-based systems is currently dominated by the task of emulation. However, the remarkable flexibility offered by data-driven architectures would suggest to extend this representation to other aspects of system synthesis including model inversion and identifiability. We introduce inVAErt (pronounced \\emph{invert}) networks, a comprehensive framework for data-driven analysis and synthesis of parametric physical systems which uses a deterministic encoder and decoder to represent the forward and inverse solution maps, normalizing flow to capture the probabilistic distribution of system outputs, and a variational encoder designed to learn a compact latent representation for the lack of bijectivity between inputs and outputs. We formally investigate the selection of penalty coefficients in the loss function and strategies for latent space sampling, since we find that these significantly affect both training and testing performance. We validate our framework through extensive numerical examples, including simple linear, nonlinear, and periodic maps, dynamical systems, and spatio-temporal PDEs.", "url": "https://arxiv.org/abs/2307.12586"}, {"metadata": {"arXiv": "2307.12601", "Date": "Mon, 24 Jul 2023 08:21:13 ", "Title": "Concept backpropagation: An Explainable AI approach for visualising learned concepts in neural network models", "Authors": ["Patrik Hammersborg and Inga Str\\\"umke"], "Categories": "cs.LG"}, "abstract": "Neural network models are widely used in a variety of domains, often as black-box solutions, since they are not directly interpretable for humans. The field of explainable artificial intelligence aims at developing explanation methods to address this challenge, and several approaches have been developed over the recent years, including methods for investigating what type of knowledge these models internalise during the training process. Among these, the method of concept detection, investigates which \\emph{concepts} neural network models learn to represent in order to complete their tasks. In this work, we present an extension to the method of concept detection, named \\emph{concept backpropagation}, which provides a way of analysing how the information representing a given concept is internalised in a given neural network model. In this approach, the model input is perturbed in a manner guided by a trained concept probe for the described model, such that the concept of interest is maximised. This allows for the visualisation of the detected concept directly in the input space of the model, which in turn makes it possible to see what information the model depends on for representing the described concept. We present results for this method applied to a various set of input modalities, and discuss how our proposed method can be used to visualise what information trained concept probes use, and the degree as to which the representation of the probed concept is entangled within the neural network model itself.", "url": "https://arxiv.org/abs/2307.12601"}, {"metadata": {"arXiv": "2307.12617", "Date": "Mon, 24 Jul 2023 08:46:12 ", "Title": "Predicting Ordinary Differential Equations with Transformers", "Authors": ["S\\\"oren Becker", "Michal Klein", "Alexander Neitz", "Giambattista Parascandolo", "Niki Kilbertus"], "Categories": "cs.LG", "Comments": ["Published at ICML 2023"]}, "abstract": "We develop a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from irregularly sampled and noisy observations of a single solution trajectory. We demonstrate in extensive empirical evaluations that our model performs better or on par with existing methods in terms of accurate recovery across various settings. Moreover, our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing law of a new observed solution in a few forward passes of the model.", "url": "https://arxiv.org/abs/2307.12617"}, {"metadata": {"arXiv": "2307.12667", "Date": "Mon, 24 Jul 2023 10:14:51 ", "Title": "TransFusion: Generating Long, High Fidelity Time Series using Diffusion Models with Transformers", "Authors": ["Md Fahim Sikder", "Resmi Ramachandranpillai", "Fredrik Heintz"], "Categories": "cs.LG"}, "abstract": "The generation of high-quality, long-sequenced time-series data is essential due to its wide range of applications. In the past, standalone Recurrent and Convolutional Neural Network-based Generative Adversarial Networks (GAN) were used to synthesize time-series data. However, they are inadequate for generating long sequences of time-series data due to limitations in the architecture. Furthermore, GANs are well known for their training instability and mode collapse problem. To address this, we propose TransFusion, a diffusion, and transformers-based generative model to generate high-quality long-sequence time-series data. We have stretched the sequence length to 384, and generated high-quality synthetic data. To the best of our knowledge, this is the first study that has been done with this long-sequence length. Also, we introduce two evaluation metrics to evaluate the quality of the synthetic data as well as its predictive characteristics. We evaluate TransFusion with a wide variety of visual and empirical metrics, and TransFusion outperforms the previous state-of-the-art by a significant margin.", "url": "https://arxiv.org/abs/2307.12667"}, {"metadata": {"arXiv": "2307.12679", "Date": "Mon, 24 Jul 2023 10:33:32 ", "Title": "An Estimator for the Sensitivity to Perturbations of Deep Neural Networks", "Authors": ["Naman Maheshwari", "Nicholas Malaya", "Scott Moe", "Jaydeep P. Kulkarni", "Sudhanva Gurumurthi"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["Actual work and paper concluded in January 2019"]}, "abstract": "For Deep Neural Networks (DNNs) to become useful in safety-critical applications, such as self-driving cars and disease diagnosis, they must be stable to perturbations in input and model parameters. Characterizing the sensitivity of a DNN to perturbations is necessary to determine minimal bit-width precision that may be used to safely represent the network. However, no general result exists that is capable of predicting the sensitivity of a given DNN to round-off error, noise, or other perturbations in input. This paper derives an estimator that can predict such quantities. The estimator is derived via inequalities and matrix norms, and the resulting quantity is roughly analogous to a condition number for the entire neural network. An approximation of the estimator is tested on two Convolutional Neural Networks, AlexNet and VGG-19, using the ImageNet dataset. For each of these networks, the tightness of the estimator is explored via random perturbations and adversarial attacks.", "url": "https://arxiv.org/abs/2307.12679"}, {"metadata": {"arXiv": "2307.12716", "Date": "Mon, 24 Jul 2023 11:55:32 ", "Title": "Safety Performance of Neural Networks in the Presence of Covariate Shift", "Authors": ["Chih-Hong Cheng", "Harald Ruess", "Konstantinos Theodorou"], "Categories": "cs.LG cs.SE"}, "abstract": "Covariate shift may impact the operational safety performance of neural networks. A re-evaluation of the safety performance, however, requires collecting new operational data and creating corresponding ground truth labels, which often is not possible during operation. We are therefore proposing to reshape the initial test set, as used for the safety performance evaluation prior to deployment, based on an approximation of the operational data. This approximation is obtained by observing and learning the distribution of activation patterns of neurons in the network during operation. The reshaped test set reflects the distribution of neuron activation values as observed during operation, and may therefore be used for re-evaluating safety performance in the presence of covariate shift. First, we derive conservative bounds on the values of neurons by applying finite binning and static dataflow analysis. Second, we formulate a mixed integer linear programming (MILP) constraint for constructing the minimum set of data points to be removed in the test set, such that the difference between the discretized test and operational distributions is bounded. We discuss potential benefits and limitations of this constraint-based approach based on our initial experience with an implemented research prototype.", "url": "https://arxiv.org/abs/2307.12716"}, {"metadata": {"arXiv": "2307.12745", "Date": "Mon, 24 Jul 2023 12:36:05 ", "Title": "Concept-based explainability for an EEG transformer model", "Authors": ["Anders Gj{\\o}lbye Madsen", "William Theodor Lehn-Schi{\\o}ler", "\\'Ashildur J\\'onsd\\'ottir", "Bergd\\'is Arnard\\'ottir", "Lars Kai Hansen"], "Categories": "cs.LG eess.SP stat.ML", "Comments": ["To appear in proceedings of 2023 IEEE International workshop on Machine Learning for Signal Processing"]}, "abstract": "Deep learning models are complex due to their size, structure, and inherent randomness in training procedures. Additional complexity arises from the selection of datasets and inductive biases. Addressing these challenges for explainability, Kim et al. (2018) introduced Concept Activation Vectors (CAVs), which aim to understand deep models' internal states in terms of human-aligned concepts. These concepts correspond to directions in latent space, identified using linear discriminants. Although this method was first applied to image classification, it was later adapted to other domains, including natural language processing. In this work, we attempt to apply the method to electroencephalogram (EEG) data for explainability in Kostas et al.'s BENDR (2021), a large-scale transformer model. A crucial part of this endeavor involves defining the explanatory concepts and selecting relevant datasets to ground concepts in the latent space. Our focus is on two mechanisms for EEG concept formation: the use of externally labeled EEG datasets, and the application of anatomically defined concepts. The former approach is a straightforward generalization of methods used in image classification, while the latter is novel and specific to EEG. We present evidence that both approaches to concept formation yield valuable insights into the representations learned by deep EEG models.", "url": "https://arxiv.org/abs/2307.12745"}, {"metadata": {"arXiv": "2307.12771", "Date": "Mon, 24 Jul 2023 13:19:15 ", "Title": "Detecting disturbances in network-coupled dynamical systems with machine learning", "Authors": ["Per Sebastian Skardal and Juan G. Restrepo"], "Categories": "cs.LG cs.SI"}, "abstract": "Identifying disturbances in network-coupled dynamical systems without knowledge of the disturbances or underlying dynamics is a problem with a wide range of applications. For example, one might want to know which nodes in the network are being disturbed and identify the type of disturbance. Here we present a model-free method based on machine learning to identify such unknown disturbances based only on prior observations of the system when forced by a known training function. We find that this method is able to identify the locations and properties of many different types of unknown disturbances using a variety of known forcing functions. We illustrate our results both with linear and nonlinear disturbances using food web and neuronal activity models. Finally, we discuss how to scale our method to large networks.", "url": "https://arxiv.org/abs/2307.12771"}, {"metadata": {"arXiv": "2307.12797", "Date": "Mon, 24 Jul 2023 13:46:50 ", "Title": "Causal Fair Machine Learning via Rank-Preserving Interventional Distributions", "Authors": ["Ludwig Bothmann", "Susanne Dandl", "Michael Schomaker"], "Categories": "cs.LG cs.CY stat.ML"}, "abstract": "A decision can be defined as fair if equal individuals are treated equally and unequals unequally. Adopting this definition, the task of designing machine learning models that mitigate unfairness in automated decision-making systems must include causal thinking when introducing protected attributes. Following a recent proposal, we define individuals as being normatively equal if they are equal in a fictitious, normatively desired (FiND) world, where the protected attribute has no (direct or indirect) causal effect on the target. We propose rank-preserving interventional distributions to define an estimand of this FiND world and a warping method for estimation. Evaluation criteria for both the method and resulting model are presented and validated through simulations and empirical data. With this, we show that our warping approach effectively identifies the most discriminated individuals and mitigates unfairness.", "url": "https://arxiv.org/abs/2307.12797"}, {"metadata": {"arXiv": "2307.12822", "Date": "Mon, 24 Jul 2023 14:19:36 ", "Title": "Learning Provably Robust Estimators for Inverse Problems via Jittering", "Authors": ["Anselm Krainovic", "Mahdi Soltanolkotabi", "Reinhard Heckel"], "Categories": "cs.LG cs.CV eess.IV"}, "abstract": "Deep neural networks provide excellent performance for inverse problems such as denoising. However, neural networks can be sensitive to adversarial or worst-case perturbations. This raises the question of whether such networks can be trained efficiently to be worst-case robust. In this paper, we investigate whether jittering, a simple regularization technique that adds isotropic Gaussian noise during training, is effective for learning worst-case robust estimators for inverse problems. While well studied for prediction in classification tasks, the effectiveness of jittering for inverse problems has not been systematically investigated. In this paper, we present a novel analytical characterization of the optimal $\\ell_2$-worst-case robust estimator for linear denoising and show that jittering yields optimal robust denoisers. Furthermore, we examine jittering empirically via training deep neural networks (U-nets) for natural image denoising, deconvolution, and accelerated magnetic resonance imaging (MRI). The results show that jittering significantly enhances the worst-case robustness, but can be suboptimal for inverse problems beyond denoising. Moreover, our results imply that training on real data which often contains slight noise is somewhat robustness enhancing.", "url": "https://arxiv.org/abs/2307.12822"}, {"metadata": {"arXiv": "2307.12840", "Date": "Mon, 24 Jul 2023 14:37:22 ", "Title": "Efficiently Learning One-Hidden-Layer ReLU Networks via Schur Polynomials", "Authors": ["Ilias Diakonikolas and Daniel M. Kane"], "Categories": "cs.LG cs.DS math.ST stat.ML stat.TH"}, "abstract": "We study the problem of PAC learning a linear combination of $k$ ReLU activations under the standard Gaussian distribution on $\\mathbb{R}^d$ with respect to the square loss. Our main result is an efficient algorithm for this learning task with sample and computational complexity $(dk/\\epsilon)^{O(k)}$, where $\\epsilon>0$ is the target accuracy. Prior work had given an algorithm for this problem with complexity $(dk/\\epsilon)^{h(k)}$, where the function $h(k)$ scales super-polynomially in $k$. Interestingly, the complexity of our algorithm is near-optimal within the class of Correlational Statistical Query algorithms. At a high-level, our algorithm uses tensor decomposition to identify a subspace such that all the $O(k)$-order moments are small in the orthogonal directions. Its analysis makes essential use of the theory of Schur polynomials to show that the higher-moment error tensors are small given that the lower-order ones are.", "url": "https://arxiv.org/abs/2307.12840"}, {"metadata": {"arXiv": "2307.12851", "Date": "Mon, 24 Jul 2023 14:51:54 ", "Title": "Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization", "Authors": ["Hancheng Min", "Ren\\'e Vidal", "Enrique Mallada"], "Categories": "cs.LG"}, "abstract": "This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons' directional dynamics allows us to provide an $\\mathcal{O}(\\frac{\\log n}{\\sqrt{\\mu}})$ upper bound on the time it takes for all neurons to achieve good alignment with the input data, where $n$ is the number of data points and $\\mu$ measures how well the data are separated. After the early alignment phase, the loss converges to zero at a $\\mathcal{O}(\\frac{1}{t})$ rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings.", "url": "https://arxiv.org/abs/2307.12851"}, {"metadata": {"arXiv": "2307.12971", "Date": "Mon, 24 Jul 2023 17:49:05 ", "Title": "Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques", "Authors": ["Md Abrar Jahin", "Md Sakib Hossain Shovon", "Jungpil Shin", "Istiyaque Ahmed Ridoy", "Yoichi Tomioka", "M. F. Mridha"], "Categories": "cs.LG stat.ML"}, "abstract": "This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and planning efficiency have been illustrated. The cyclic connection within the framework introduces preprocessing optimization based on the post-process KPIs, optimizing the overall control process (inventory management, workforce determination, cost, production and capacity planning). The contribution of this research lies in the standard SC process framework proposal, recommended forecasting data analysis, forecasting effects on SC performance, machine learning algorithms optimization followed, and in shedding light on future research.", "url": "https://arxiv.org/abs/2307.12971"}, {"metadata": {"arXiv": "2307.12975", "Date": "Mon, 24 Jul 2023 17:50:24 ", "Title": "Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems", "Authors": ["Xiang Ji", "Huazheng Wang", "Minshuo Chen", "Tuo Zhao", "Mengdi Wang"], "Categories": "cs.LG math.ST stat.ML stat.TH"}, "abstract": "A crucial task in decision-making problems is reward engineering. It is common in practice that no obvious choice of reward function exists. Thus, a popular approach is to introduce human feedback during training and leverage such feedback to learn a reward function. Among all policy learning methods that use human feedback, preference-based methods have demonstrated substantial success in recent empirical applications such as InstructGPT. In this work, we develop a theory that provably shows the benefits of preference-based methods in offline contextual bandits. In particular, we improve the modeling and suboptimality analysis for running policy learning methods on human-scored samples directly. Then, we compare it with the suboptimality guarantees of preference-based methods and show that preference-based methods enjoy lower suboptimality.", "url": "https://arxiv.org/abs/2307.12975"}, {"metadata": {"arXiv": "2307.12979", "Date": "Mon, 24 Jul 2023 17:56:58 ", "Title": "An Isometric Stochastic Optimizer", "Authors": ["Jacob Jackson"], "Categories": "cs.LG"}, "abstract": "The Adam optimizer is the standard choice in deep learning applications. I propose a simple explanation of Adam's success: it makes each parameter's step size independent of the norms of the other parameters. Based on this principle I derive Iso, a new optimizer which makes the norm of a parameter's update invariant to the application of any linear transformation to its inputs and outputs. I develop a variant of Iso called IsoAdam that allows optimal hyperparameters to be transferred from Adam, and demonstrate that IsoAdam obtains a speedup over Adam when training a small Transformer.", "url": "https://arxiv.org/abs/2307.12979"}, {"metadata": {"arXiv": "2307.12636", "Date": "Mon, 24 Jul 2023 09:19:38 ", "Title": "Identifying drivers and mitigators for congestion and redispatch in the German electric power system with explainable AI", "Authors": ["Maurizio Titz", "Sebastian P\\\"utz", "Dirk Witthaut"], "Categories": "eess.SY cs.LG cs.SY physics.data-an"}, "abstract": "The transition to a sustainable energy supply challenges the operation of electric power systems in manifold ways. Transmission grid loads increase as wind and solar power are often installed far away from the consumers. In extreme cases, system operators must intervene via countertrading or redispatch to ensure grid stability. In this article, we provide a data-driven analysis of congestion in the German transmission grid. We develop an explainable machine learning model to predict the volume of redispatch and countertrade on an hourly basis. The model reveals factors that drive or mitigate grid congestion and quantifies their impact. We show that, as expected, wind power generation is the main driver, but hydropower and cross-border electricity trading also play an essential role. Solar power, on the other hand, has no mitigating effect. Our results suggest that a change to the market design would alleviate congestion.", "url": "https://arxiv.org/abs/2307.12636"}, {"metadata": {"arXiv": "2307.12081", "Date": "Sat, 22 Jul 2023 13:50:34 ", "Title": "Enhancing Temporal Planning Domains by Sequential Macro-actions (Extended Version)", "Authors": ["Marco De Bortoli", "Luk\\'a\\v{s} Chrpa", "Martin Gebser and Gerald Steinbauer-Wagner"], "Categories": "cs.AI"}, "abstract": "Temporal planning is an extension of classical planning involving concurrent execution of actions and alignment with temporal constraints. Durative actions along with invariants allow for modeling domains in which multiple agents operate in parallel on shared resources. Hence, it is often important to avoid resource conflicts, where temporal constraints establish the consistency of concurrent actions and events. Unfortunately, the performance of temporal planning engines tends to sharply deteriorate when the number of agents and objects in a domain gets large. A possible remedy is to use macro-actions that are well-studied in the context of classical planning. In temporal planning settings, however, introducing macro-actions is significantly more challenging when the concurrent execution of actions and shared use of resources, provided the compliance to temporal constraints, should not be suppressed entirely. Our work contributes a general concept of sequential temporal macro-actions that guarantees the applicability of obtained plans, i.e., the sequence of original actions encapsulated by a macro-action is always executable. We apply our approach to several temporal planners and domains, stemming from the International Planning Competition and RoboCup Logistics League. Our experiments yield improvements in terms of obtained satisficing plans as well as plan quality for the majority of tested planners and domains.", "url": "https://arxiv.org/abs/2307.12081"}, {"metadata": {"arXiv": "2307.12087", "Date": "Sat, 22 Jul 2023 14:38:47 ", "Title": "CFR-p: Counterfactual Regret Minimization with Hierarchical Policy Abstraction, and its Application to Two-player Mahjong", "Authors": ["Shiheng Wang"], "Categories": "cs.AI econ.GN q-fin.EC", "Comments": ["8 pages"]}, "abstract": "Counterfactual Regret Minimization(CFR) has shown its success in Texas Hold'em poker. We apply this algorithm to another popular incomplete information game, Mahjong. Compared to the poker game, Mahjong is much more complex with many variants. We study two-player Mahjong by conducting game theoretical analysis and making a hierarchical abstraction to CFR based on winning policies. This framework can be generalized to other imperfect information games.", "url": "https://arxiv.org/abs/2307.12087"}, {"metadata": {"arXiv": "2307.12133", "Date": "Sat, 22 Jul 2023 17:37:43 ", "Title": "Route Planning Using Nature-Inspired Algorithms", "Authors": ["Priyansh Saxena", "Raahat Gupta", "Akshat Maheshwari"], "Categories": "cs.AI", "Comments": ["This work is part of 'High-Performance Vision Intelligence'; Part of the Studies in Computational Intelligence book series (SCI,volume 913) and can be accessed at: https://link.springer.com/chapter/10.1007/978-981-15-6844-2_15"]}, "abstract": "There are many different heuristic algorithms for solving combinatorial optimization problems that are commonly described as Nature-Inspired Algorithms (NIAs). Generally, they are inspired by some natural phenomenon, and due to their inherent converging and stochastic nature, they are known to give optimal results when compared to classical approaches. There are a large number of applications of NIAs, perhaps the most popular being route planning problems in robotics - problems that require a sequence of translation and rotation steps from the start to the goal in an optimized manner while avoiding obstacles in the environment. In this chapter, we will first give an overview of Nature-Inspired Algorithms, followed by their classification and common examples. We will then discuss how the NIAs have applied to solve the route planning problem.", "url": "https://arxiv.org/abs/2307.12133"}, {"metadata": {"arXiv": "2307.12173", "Date": "Sat, 22 Jul 2023 21:39:35 ", "Title": "Named Entity Resolution in Personal Knowledge Graphs", "Authors": ["Mayank Kejriwal"], "Categories": "cs.AI cs.DB", "Comments": ["To appear as a book chapter by the same name in an upcoming (Oct. 2023) book `Personal Knowledge Graphs (PKGs): Methodology", "tools and applications' edited by Tiwari et al"]}, "abstract": "Entity Resolution (ER) is the problem of determining when two entities refer to the same underlying entity. The problem has been studied for over 50 years, and most recently, has taken on new importance in an era of large, heterogeneous 'knowledge graphs' published on the Web and used widely in domains as wide ranging as social media, e-commerce and search. This chapter will discuss the specific problem of named ER in the context of personal knowledge graphs (PKGs). We begin with a formal definition of the problem, and the components necessary for doing high-quality and efficient ER. We also discuss some challenges that are expected to arise for Web-scale data. Next, we provide a brief literature review, with a special focus on how existing techniques can potentially apply to PKGs. We conclude the chapter by covering some applications, as well as promising directions for future research.", "url": "https://arxiv.org/abs/2307.12173"}, {"metadata": {"arXiv": "2307.12184", "Date": "Sat, 22 Jul 2023 23:17:44 ", "Title": "On the Expressivity of Multidimensional Markov Reward", "Authors": ["Shuwa Miura"], "Categories": "cs.AI", "Comments": ["Presented at RLDM Workshop on Reinforcement Learning as a Model of Agency"]}, "abstract": "We consider the expressivity of Markov rewards in sequential decision making under uncertainty. We view reward functions in Markov Decision Processes (MDPs) as a means to characterize desired behaviors of agents. Assuming desired behaviors are specified as a set of acceptable policies, we investigate if there exists a scalar or multidimensional Markov reward function that makes the policies in the set more desirable than the other policies. Our main result states both necessary and sufficient conditions for the existence of such reward functions. We also show that for every non-degenerate set of deterministic policies, there exists a multidimensional Markov reward function that characterizes it", "url": "https://arxiv.org/abs/2307.12184"}, {"metadata": {"arXiv": "2307.12287", "Date": "Sun, 23 Jul 2023 10:41:17 ", "Title": "Decentralized Adaptive Formation via Consensus-Oriented Multi-Agent Communication", "Authors": ["Yuming Xiang", "Sizhao Li", "Rongpeng Li", "Zhifeng Zhao and Honggang Zhang"], "Categories": "cs.AI cs.MA", "Comments": ["6 pages", "5 figures"]}, "abstract": "Adaptive multi-agent formation control, which requires the formation to flexibly adjust along with the quantity variations of agents in a decentralized manner, belongs to one of the most challenging issues in multi-agent systems, especially under communication-limited constraints. In this paper, we propose a novel Consensus-based Decentralized Adaptive Formation (Cons-DecAF) framework. Specifically, we develop a novel multi-agent reinforcement learning method, Consensus-oriented Multi-Agent Communication (ConsMAC), to enable agents to perceive global information and establish the consensus from local states by effectively aggregating neighbor messages. Afterwards, we leverage policy distillation to accomplish the adaptive formation adjustment. Meanwhile, instead of pre-assigning specific positions of agents, we employ a displacement-based formation by Hausdorff distance to significantly improve the formation efficiency. The experimental results through extensive simulations validate that the proposed method has achieved outstanding performance in terms of both speed and stability.", "url": "https://arxiv.org/abs/2307.12287"}, {"metadata": {"arXiv": "2307.12289", "Date": "Sun, 23 Jul 2023 10:52:20 ", "Title": "Controller Synthesis for Timeline-based Games", "Authors": ["Renato Acampora and Luca Geatti and Nicola Gigante and Angelo Montanari and Valentino Picotti"], "Categories": "cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2209.10319"]}, "abstract": "In the timeline-based approach to planning, the evolution over time of a set of state variables (the timelines) is governed by a set of temporal constraints. Traditional timeline-based planning systems excel at the integration of planning with execution by handling temporal uncertainty. In order to handle general nondeterminism as well, the concept of timeline-based games has been recently introduced. It has been proved that finding whether a winning strategy exists for such games is 2EXPTIME-complete. However, a concrete approach to synthesize controllers implementing such strategies is missing. This paper fills this gap, by providing an effective and computationally optimal approach to controller synthesis for timeline-based games.", "url": "https://arxiv.org/abs/2307.12289"}, {"metadata": {"arXiv": "2307.12620", "Date": "Mon, 24 Jul 2023 08:50:12 ", "Title": "Past-present temporal programs over finite traces", "Authors": ["Pedro Cabalar", "Mart\\'in Di\\'eguez", "Fran\\c{c}ois Laferri\\`ere", "Torsten Schaub"], "Categories": "cs.AI"}, "abstract": "Extensions of Answer Set Programming with language constructs from temporal logics, such as temporal equilibrium logic over finite traces (TELf), provide an expressive computational framework for modeling dynamic applications. In this paper, we study the so-called past-present syntactic subclass, which consists of a set of logic programming rules whose body references to the past and head to the present. Such restriction ensures that the past remains independent of the future, which is the case in most dynamic domains. We extend the definitions of completion and loop formulas to the case of past-present formulas, which allows capturing the temporal stable models of a set of past-present temporal programs by means of an LTLf expression.", "url": "https://arxiv.org/abs/2307.12620"}, {"metadata": {"arXiv": "2307.12626", "Date": "Mon, 24 Jul 2023 08:58:25 ", "Title": "Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework", "Authors": ["Jingxuan Wei", "Cheng Tan", "Zhangyang Gao", "Linzhuang Sun", "Siyuan Li", "Bihui Yu", "Ruifeng Guo", "Stan Z. Li"], "Categories": "cs.AI"}, "abstract": "Multimodal reasoning is a critical component in the pursuit of artificial intelligence systems that exhibit human-like intelligence, especially when tackling complex tasks. While the chain-of-thought (CoT) technique has gained considerable attention, the existing ScienceQA dataset, which focuses on multimodal scientific questions and explanations from elementary and high school textbooks, lacks a comprehensive evaluation of diverse approaches. To address this gap, we present COCO Multi-Modal Reasoning Dataset(COCO-MMRD), a novel dataset that encompasses an extensive collection of open-ended questions, rationales, and answers derived from the large object dataset COCO. Unlike previous datasets that rely on multiple-choice questions, our dataset pioneers the use of open-ended questions in the context of multimodal CoT, introducing a more challenging problem that effectively assesses the reasoning capability of CoT models. Through comprehensive evaluations and detailed analyses, we provide valuable insights and propose innovative techniques, including multi-hop cross-modal attention and sentence-level contrastive learning, to enhance the image and text encoders. Extensive experiments demonstrate the efficacy of the proposed dataset and techniques, offering novel perspectives for advancing multimodal reasoning.", "url": "https://arxiv.org/abs/2307.12626"}, {"metadata": {"arXiv": "2307.12933", "Date": "Mon, 24 Jul 2023 16:52:31 ", "Title": "Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning", "Authors": ["Chuming Li", "Ruonan Jia", "Jie Liu", "Yinmin Zhang", "Yazhe Niu", "Yaodong Yang", "Yu Liu", "Wanli Ouyang"], "Categories": "cs.AI"}, "abstract": "Model-based reinforcement learning (RL) has demonstrated remarkable successes on a range of continuous control tasks due to its high sample efficiency. To save the computation cost of conducting planning online, recent practices tend to distill optimized action sequences into an RL policy during the training phase. Although the distillation can incorporate both the foresight of planning and the exploration ability of RL policies, the theoretical understanding of these methods is yet unclear. In this paper, we extend the policy improvement step of Soft Actor-Critic (SAC) by developing an approach to distill from model-based planning to the policy. We then demonstrate that such an approach of policy improvement has a theoretical guarantee of monotonic improvement and convergence to the maximum value defined in SAC. We discuss effective design choices and implement our theory as a practical algorithm -- Model-based Planning Distilled to Policy (MPDP) -- that updates the policy jointly over multiple future time steps. Extensive experiments show that MPDP achieves better sample efficiency and asymptotic performance than both model-free and model-based planning algorithms on six continuous control benchmark tasks in MuJoCo.", "url": "https://arxiv.org/abs/2307.12933"}, {"metadata": {"arXiv": "2307.11823", "Date": "Fri, 21 Jul 2023 18:00:23 ", "Title": "HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness", "Authors": ["Mehmet Kerim Yucel", "Ramazan Gokberk Cinbis", "Pinar Duygulu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Convolutional Neural Networks (CNN) are known to exhibit poor generalization performance under distribution shifts. Their generalization have been studied extensively, and one line of work approaches the problem from a frequency-centric perspective. These studies highlight the fact that humans and CNNs might focus on different frequency components of an image. First, inspired by these observations, we propose a simple yet effective data augmentation method HybridAugment that reduces the reliance of CNNs on high-frequency components, and thus improves their robustness while keeping their clean accuracy high. Second, we propose HybridAugment++, which is a hierarchical augmentation method that attempts to unify various frequency-spectrum augmentations. HybridAugment++ builds on HybridAugment, and also reduces the reliance of CNNs on the amplitude component of images, and promotes phase information instead. This unification results in competitive to or better than state-of-the-art results on clean accuracy (CIFAR-10/100 and ImageNet), corruption benchmarks (ImageNet-C, CIFAR-10-C and CIFAR-100-C), adversarial robustness on CIFAR-10 and out-of-distribution detection on various datasets. HybridAugment and HybridAugment++ are implemented in a few lines of code, does not require extra data, ensemble models or additional networks.", "url": "https://arxiv.org/abs/2307.11823"}, {"metadata": {"arXiv": "2307.11952", "Date": "Sat, 22 Jul 2023 00:59:26 ", "Title": "Pathology-and-genomics Multimodal Transformer for Survival Outcome Prediction", "Authors": ["Kexin Ding", "Mu Zhou", "Dimitris N. Metaxas", "and Shaoting Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to MICCAI2023 (Top14%)"]}, "abstract": "Survival outcome assessment is challenging and inherently associated with multiple clinical factors (e.g., imaging and genomics biomarkers) in cancer. Enabling multimodal analytics promises to reveal novel predictive patterns of patient outcomes. In this study, we propose a multimodal transformer (PathOmics) integrating pathology and genomics insights into colon-related cancer survival prediction. We emphasize the unsupervised pretraining to capture the intrinsic interaction between tissue microenvironments in gigapixel whole slide images (WSIs) and a wide range of genomics data (e.g., mRNA-sequence, copy number variant, and methylation). After the multimodal knowledge aggregation in pretraining, our task-specific model finetuning could expand the scope of data utility applicable to both multi- and single-modal data (e.g., image- or genomics-only). We evaluate our approach on both TCGA colon and rectum cancer cohorts, showing that the proposed approach is competitive and outperforms state-of-the-art studies. Finally, our approach is desirable to utilize the limited number of finetuned samples towards data-efficient analytics for survival outcome prediction. The code is available at https://github.com/Cassie07/PathOmics.", "url": "https://arxiv.org/abs/2307.11952"}, {"metadata": {"arXiv": "2307.11988", "Date": "Sat, 22 Jul 2023 05:43:33 ", "Title": "Sparse then Prune: Toward Efficient Vision Transformers", "Authors": ["Yogi Prasetyo", "Novanto Yudistira", "Agus Wahyu Widodo"], "Categories": "cs.CV cs.AI"}, "abstract": "The Vision Transformer architecture is a deep learning model inspired by the success of the Transformer model in Natural Language Processing. However, the self-attention mechanism, large number of parameters, and the requirement for a substantial amount of training data still make Vision Transformers computationally burdensome. In this research, we investigate the possibility of applying Sparse Regularization to Vision Transformers and the impact of Pruning, either after Sparse Regularization or without it, on the trade-off between performance and efficiency. To accomplish this, we apply Sparse Regularization and Pruning methods to the Vision Transformer architecture for image classification tasks on the CIFAR-10, CIFAR-100, and ImageNet-100 datasets. The training process for the Vision Transformer model consists of two parts: pre-training and fine-tuning. Pre-training utilizes ImageNet21K data, followed by fine-tuning for 20 epochs. The results show that when testing with CIFAR-100 and ImageNet-100 data, models with Sparse Regularization can increase accuracy by 0.12%. Furthermore, applying pruning to models with Sparse Regularization yields even better results. Specifically, it increases the average accuracy by 0.568% on CIFAR-10 data, 1.764% on CIFAR-100, and 0.256% on ImageNet-100 data compared to pruning models without Sparse Regularization. Code can be accesed here: https://github.com/yogiprsty/Sparse-ViT", "url": "https://arxiv.org/abs/2307.11988"}, {"metadata": {"arXiv": "2307.12168", "Date": "Sat, 22 Jul 2023 21:15:56 ", "Title": "Hallucination Improves the Performance of Unsupervised Visual Representation Learning", "Authors": ["Jing Wu", "Jennifer Hobbs", "Naira Hovakimyan"], "Categories": "cs.CV cs.AI", "Comments": ["International Conference on Computer Vision(ICCV)", "2023"]}, "abstract": "Contrastive learning models based on Siamese structure have demonstrated remarkable performance in self-supervised learning. Such a success of contrastive learning relies on two conditions, a sufficient number of positive pairs and adequate variations between them. If the conditions are not met, these frameworks will lack semantic contrast and be fragile on overfitting. To address these two issues, we propose Hallucinator that could efficiently generate additional positive samples for further contrast. The Hallucinator is differentiable and creates new data in the feature space. Thus, it is optimized directly with the pre-training task and introduces nearly negligible computation. Moreover, we reduce the mutual information of hallucinated pairs and smooth them through non-linear operations. This process helps avoid over-confident contrastive learning models during the training and achieves more transformation-invariant feature embeddings. Remarkably, we empirically prove that the proposed Hallucinator generalizes well to various contrastive learning models, including MoCoV1&V2, SimCLR and SimSiam. Under the linear classification protocol, a stable accuracy gain is achieved, ranging from 0.3% to 3.0% on CIFAR10&100, Tiny ImageNet, STL-10 and ImageNet. The improvement is also observed in transferring pre-train encoders to the downstream tasks, including object detection and segmentation.", "url": "https://arxiv.org/abs/2307.12168"}, {"metadata": {"arXiv": "2307.12208", "Date": "Sun, 23 Jul 2023 02:47:30 ", "Title": "DeepCL: Deep Change Feature Learning on Remote Sensing Images in the Metric Space", "Authors": ["Haonan Guo", "Bo Du", "Chen Wu", "Chengxi Han", "Liangpei Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages,7 figures", "submitted to IEEE Transactions on Image Processing"]}, "abstract": "Change detection (CD) is an important yet challenging task in the Earth observation field for monitoring Earth surface dynamics. The advent of deep learning techniques has recently propelled automatic CD into a technological revolution. Nevertheless, deep learning-based CD methods are still plagued by two primary issues: 1) insufficient temporal relationship modeling and 2) pseudo-change misclassification. To address these issues, we complement the strong temporal modeling ability of metric learning with the prominent fitting ability of segmentation and propose a deep change feature learning (DeepCL) framework for robust and explainable CD. Firstly, we designed a hard sample-aware contrastive loss, which reweights the importance of hard and simple samples. This loss allows for explicit modeling of the temporal correlation between bi-temporal remote sensing images. Furthermore, the modeled temporal relations are utilized as knowledge prior to guide the segmentation process for detecting change regions. The DeepCL framework is thoroughly evaluated both theoretically and experimentally, demonstrating its superior feature discriminability, resilience against pseudo changes, and adaptability to a variety of CD algorithms. Extensive comparative experiments substantiate the quantitative and qualitative superiority of DeepCL over state-of-the-art CD approaches.", "url": "https://arxiv.org/abs/2307.12208"}, {"metadata": {"arXiv": "2307.12220", "Date": "Sun, 23 Jul 2023 03:55:13 ", "Title": "Expediting Building Footprint Segmentation from High-resolution Remote Sensing Images via progressive lenient supervision", "Authors": ["Haonan Guo", "Bo Du", "Chen Wu", "Xin Su", "Liangpei Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages,8 figures. Submitted to IEEE Transactions on Neural Networks and Learning Systems"]}, "abstract": "The efficacy of building footprint segmentation from remotely sensed images has been hindered by model transfer effectiveness. Many existing building segmentation methods were developed upon the encoder-decoder architecture of U-Net, in which the encoder is finetuned from the newly developed backbone networks that are pre-trained on ImageNet. However, the heavy computational burden of the existing decoder designs hampers the successful transfer of these modern encoder networks to remote sensing tasks. Even the widely-adopted deep supervision strategy fails to mitigate these challenges due to its invalid loss in hybrid regions where foreground and background pixels are intermixed. In this paper, we conduct a comprehensive evaluation of existing decoder network designs for building footprint segmentation and propose an efficient framework denoted as BFSeg to enhance learning efficiency and effectiveness. Specifically, a densely-connected coarse-to-fine feature fusion decoder network that facilitates easy and fast feature fusion across scales is proposed. Moreover, considering the invalidity of hybrid regions in the down-sampled ground truth during the deep supervision process, we present a lenient deep supervision and distillation strategy that enables the network to learn proper knowledge from deep supervision. Building upon these advancements, we have developed a new family of building segmentation networks, which consistently surpass prior works with outstanding performance and efficiency across a wide range of newly developed encoder networks. The code will be released on https://github.com/HaonanGuo/BFSeg-Efficient-Building-Footprint-Segmentation-Framework.", "url": "https://arxiv.org/abs/2307.12220"}, {"metadata": {"arXiv": "2307.12256", "Date": "Sun, 23 Jul 2023 08:02:37 ", "Title": "Building-road Collaborative Extraction from Remotely Sensed Images via Cross-Interaction", "Authors": ["Haonan Guo", "Xin Su", "Chen Wu", "Bo Du", "Liangpei Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["34 pages,9 figures", "submitted to ISPRS Journal of Photogrammetry and Remote Sensing"]}, "abstract": "Buildings are the basic carrier of social production and human life; roads are the links that interconnect social networks. Building and road information has important application value in the frontier fields of regional coordinated development, disaster prevention, auto-driving, etc. Mapping buildings and roads from very high-resolution (VHR) remote sensing images have become a hot research topic. However, the existing methods often ignore the strong spatial correlation between roads and buildings and extract them in isolation. To fully utilize the complementary advantages between buildings and roads, we propose a building-road collaborative extraction method based on multi-task and cross-scale feature interaction to improve the accuracy of both tasks in a complementary way. A multi-task interaction module is proposed to interact information across tasks and preserve the unique information of each task, which tackle the seesaw phenomenon in multitask learning. By considering the variation in appearance and structure between buildings and roads, a cross-scale interaction module is designed to automatically learn the optimal reception field for different tasks. Compared with many existing methods that train each task individually, the proposed collaborative extraction method can utilize the complementary advantages between buildings and roads by the proposed inter-task and inter-scale feature interactions, and automatically select the optimal reception field for different tasks. Experiments on a wide range of urban and rural scenarios show that the proposed algorithm can achieve building-road extraction with outstanding performance and efficiency.", "url": "https://arxiv.org/abs/2307.12256"}, {"metadata": {"arXiv": "2307.12342", "Date": "Sun, 23 Jul 2023 14:37:13 ", "Title": "Towards Generic and Controllable Attacks Against Object Detection", "Authors": ["Guopeng Li", "Yue Xu", "Jian Ding", "Gui-Song Xia"], "Categories": "cs.CV cs.AI"}, "abstract": "Existing adversarial attacks against Object Detectors (ODs) suffer from two inherent limitations. Firstly, ODs have complicated meta-structure designs, hence most advanced attacks for ODs concentrate on attacking specific detector-intrinsic structures, which makes it hard for them to work on other detectors and motivates us to design a generic attack against ODs. Secondly, most works against ODs make Adversarial Examples (AEs) by generalizing image-level attacks from classification to detection, which brings redundant computations and perturbations in semantically meaningless areas (e.g., backgrounds) and leads to an emergency for seeking controllable attacks for ODs. To this end, we propose a generic white-box attack, LGP (local perturbations with adaptively global attacks), to blind mainstream object detectors with controllable perturbations. For a detector-agnostic attack, LGP tracks high-quality proposals and optimizes three heterogeneous losses simultaneously. In this way, we can fool the crucial components of ODs with a part of their outputs without the limitations of specific structures. Regarding controllability, we establish an object-wise constraint that exploits foreground-background separation adaptively to induce the attachment of perturbations to foregrounds. Experimentally, the proposed LGP successfully attacked sixteen state-of-the-art object detectors on MS-COCO and DOTA datasets, with promising imperceptibility and transferability obtained. Codes are publicly released in https://github.com/liguopeng0923/LGP.git", "url": "https://arxiv.org/abs/2307.12342"}, {"metadata": {"arXiv": "2307.12493", "Date": "Mon, 24 Jul 2023 02:50:44 ", "Title": "TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition", "Authors": ["Shilin Lu", "Yanzhu Liu", "Adams Wai-Kin Kong"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Text-driven diffusion models have exhibited impressive generative capabilities, enabling various image editing tasks. In this paper, we propose TF-ICON, a novel Training-Free Image COmpositioN framework that harnesses the power of text-driven diffusion models for cross-domain image-guided composition. This task aims to seamlessly integrate user-provided objects into a specific visual context. Current diffusion-based methods often involve costly instance-based optimization or finetuning of pretrained models on customized datasets, which can potentially undermine their rich prior. In contrast, TF-ICON can leverage off-the-shelf diffusion models to perform cross-domain image-guided composition without requiring additional training, finetuning, or optimization. Moreover, we introduce the exceptional prompt, which contains no information, to facilitate text-driven diffusion models in accurately inverting real images into latent representations, forming the basis for compositing. Our experiments show that equipping Stable Diffusion with the exceptional prompt outperforms state-of-the-art inversion methods on various datasets (CelebA-HQ, COCO, and ImageNet), and that TF-ICON surpasses prior baselines in versatile visual domains. Code is available at https://github.com/Shilin-LU/TF-ICON", "url": "https://arxiv.org/abs/2307.12493"}, {"metadata": {"arXiv": "2307.12540", "Date": "Mon, 24 Jul 2023 06:04:12 ", "Title": "SelFormaly: Towards Task-Agnostic Unified Anomaly Detection", "Authors": ["Yujin Lee", "Harin Lim", "Hyunsoo Yoon"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "7 figures"]}, "abstract": "The core idea of visual anomaly detection is to learn the normality from normal images, but previous works have been developed specifically for certain tasks, leading to fragmentation among various tasks: defect detection, semantic anomaly detection, multi-class anomaly detection, and anomaly clustering. This one-task-one-model approach is resource-intensive and incurs high maintenance costs as the number of tasks increases. This paper presents SelFormaly, a universal and powerful anomaly detection framework. We emphasize the necessity of our off-the-shelf approach by pointing out a suboptimal issue with fluctuating performance in previous online encoder-based methods. In addition, we question the effectiveness of using ConvNets as previously employed in the literature and confirm that self-supervised ViTs are suitable for unified anomaly detection. We introduce back-patch masking and discover the new role of top k-ratio feature matching to achieve unified and powerful anomaly detection. Back-patch masking eliminates irrelevant regions that possibly hinder target-centric detection with representations of the scene layout. The top k-ratio feature matching unifies various anomaly levels and tasks. Finally, SelFormaly achieves state-of-the-art results across various datasets for all the aforementioned tasks.", "url": "https://arxiv.org/abs/2307.12540"}, {"metadata": {"arXiv": "2307.12542", "Date": "Mon, 24 Jul 2023 06:12:37 ", "Title": "Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging", "Authors": ["Meirui Jiang", "Yuan Zhong", "Anjie Le", "Xiaoxiao Li", "Qi Dou"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'23)"]}, "abstract": "Despite recent progress in enhancing the privacy of federated learning (FL) via differential privacy (DP), the trade-off of DP between privacy protection and performance is still underexplored for real-world medical scenario. In this paper, we propose to optimize the trade-off under the context of client-level DP, which focuses on privacy during communications. However, FL for medical imaging involves typically much fewer participants (hospitals) than other domains (e.g., mobile devices), thus ensuring clients be differentially private is much more challenging. To tackle this problem, we propose an adaptive intermediary strategy to improve performance without harming privacy. Specifically, we theoretically find splitting clients into sub-clients, which serve as intermediaries between hospitals and the server, can mitigate the noises introduced by DP without harming privacy. Our proposed approach is empirically evaluated on both classification and segmentation tasks using two public datasets, and its effectiveness is demonstrated with significant performance improvements and comprehensive analytical studies. Code is available at: https://github.com/med-air/Client-DP-FL.", "url": "https://arxiv.org/abs/2307.12542"}, {"metadata": {"arXiv": "2307.12545", "Date": "Mon, 24 Jul 2023 06:22:37 ", "Title": "Towards Video Anomaly Retrieval from Video Anomaly Detection: New Benchmarks and Model", "Authors": ["Peng Wu", "Jing Liu", "Xiangteng He", "Yuxin Peng", "Peng Wang", "and Yanning Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Video anomaly detection (VAD) has been paid increasing attention due to its potential applications, its current dominant tasks focus on online detecting anomalies% at the frame level, which can be roughly interpreted as the binary or multiple event classification. However, such a setup that builds relationships between complicated anomalous events and single labels, e.g., ``vandalism'', is superficial, since single labels are deficient to characterize anomalous events. In reality, users tend to search a specific video rather than a series of approximate videos. Therefore, retrieving anomalous events using detailed descriptions is practical and positive but few researches focus on this. In this context, we propose a novel task called Video Anomaly Retrieval (VAR), which aims to pragmatically retrieve relevant anomalous videos by cross-modalities, e.g., language descriptions and synchronous audios. Unlike the current video retrieval where videos are assumed to be temporally well-trimmed with short duration, VAR is devised to retrieve long untrimmed videos which may be partially relevant to the given query. To achieve this, we present two large-scale VAR benchmarks, UCFCrime-AR and XDViolence-AR, constructed on top of prevalent anomaly datasets. Meanwhile, we design a model called Anomaly-Led Alignment Network (ALAN) for VAR. In ALAN, we propose an anomaly-led sampling to focus on key segments in long untrimmed videos. Then, we introduce an efficient pretext task to enhance semantic associations between video-text fine-grained representations. Besides, we leverage two complementary alignments to further match cross-modal contents. Experimental results on two benchmarks reveal the challenges of VAR task and also demonstrate the advantages of our tailored method.", "url": "https://arxiv.org/abs/2307.12545"}, {"metadata": {"arXiv": "2307.12580", "Date": "Mon, 24 Jul 2023 07:51:40 ", "Title": "SL: Stable Learning in Source-Free Domain Adaption for Medical Image Segmentation", "Authors": ["Yixin Chen", "Yan Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep learning techniques for medical image analysis usually suffer from the domain shift between source and target data. Most existing works focus on unsupervised domain adaptation (UDA). However, in practical applications, privacy issues are much more severe. For example, the data of different hospitals have domain shifts due to equipment problems, and data of the two domains cannot be available simultaneously because of privacy. In this challenge defined as Source-Free UDA, the previous UDA medical methods are limited. Although a variety of medical source-free unsupervised domain adaption (MSFUDA) methods have been proposed, we found they fall into an over-fitting dilemma called \"longer training, worse performance.\" Therefore, we propose the Stable Learning (SL) strategy to address the dilemma. SL is a scalable method and can be integrated with other research, which consists of Weight Consolidation and Entropy Increase. First, we apply Weight Consolidation to retain domain-invariant knowledge and then we design Entropy Increase to avoid over-learning. Comparative experiments prove the effectiveness of SL. We also have done extensive ablation experiments. Besides, We will release codes including a variety of MSFUDA methods.", "url": "https://arxiv.org/abs/2307.12580"}, {"metadata": {"arXiv": "2307.12612", "Date": "Mon, 24 Jul 2023 08:39:11 ", "Title": "Less is More: Focus Attention for Efficient DETR", "Authors": ["Dehua Zheng", "Wenhui Dong", "Hailin Hu", "Xinghao Chen", "Yunhe Wang"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "6 figures", "accepted to ICCV2023"]}, "abstract": "DETR-like models have significantly boosted the performance of detectors and even outperformed classical convolutional models. However, all tokens are treated equally without discrimination brings a redundant computational burden in the traditional encoder structure. The recent sparsification strategies exploit a subset of informative tokens to reduce attention complexity maintaining performance through the sparse encoder. But these methods tend to rely on unreliable model statistics. Moreover, simply reducing the token population hinders the detection performance to a large extent, limiting the application of these sparse models. We propose Focus-DETR, which focuses attention on more informative tokens for a better trade-off between computation efficiency and model accuracy. Specifically, we reconstruct the encoder with dual attention, which includes a token scoring mechanism that considers both localization and category semantic information of the objects from multi-scale feature maps. We efficiently abandon the background queries and enhance the semantic interaction of the fine-grained object queries based on the scores. Compared with the state-of-the-art sparse DETR-like detectors under the same setting, our Focus-DETR gets comparable complexity while achieving 50.4AP (+2.2) on COCO. The code is available at https://github.com/huawei-noah/noah-research/tree/master/Focus-DETR and https://gitee.com/mindspore/models/tree/master/research/cv/Focus-DETR.", "url": "https://arxiv.org/abs/2307.12612"}, {"metadata": {"arXiv": "2307.12616", "Date": "Mon, 24 Jul 2023 08:44:25 ", "Title": "CTVIS: Consistent Training for Online Video Instance Segmentation", "Authors": ["Kaining Ying", "Qing Zhong", "Weian Mao", "Zhenhua Wang", "Hao Chen", "Lin Yuanbo Wu", "Yifan Liu", "Chengxiang Fan", "Yunzhi Zhuge", "Chunhua Shen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV 2023. The code is available at https://github.com/KainingYing/CTVIS"]}, "abstract": "The discrimination of instance embeddings plays a vital role in associating instances across time for online video instance segmentation (VIS). Instance embedding learning is directly supervised by the contrastive loss computed upon the contrastive items (CIs), which are sets of anchor/positive/negative embeddings. Recent online VIS methods leverage CIs sourced from one reference frame only, which we argue is insufficient for learning highly discriminative embeddings. Intuitively, a possible strategy to enhance CIs is replicating the inference phase during training. To this end, we propose a simple yet effective training strategy, called Consistent Training for Online VIS (CTVIS), which devotes to aligning the training and inference pipelines in terms of building CIs. Specifically, CTVIS constructs CIs by referring inference the momentum-averaged embedding and the memory bank storage mechanisms, and adding noise to the relevant embeddings. Such an extension allows a reliable comparison between embeddings of current instances and the stable representations of historical instances, thereby conferring an advantage in modeling VIS challenges such as occlusion, re-identification, and deformation. Empirically, CTVIS outstrips the SOTA VIS models by up to +5.0 points on three VIS benchmarks, including YTVIS19 (55.1% AP), YTVIS21 (50.1% AP) and OVIS (35.5% AP). Furthermore, we find that pseudo-videos transformed from images can train robust models surpassing fully-supervised ones.", "url": "https://arxiv.org/abs/2307.12616"}, {"metadata": {"arXiv": "2307.12837", "Date": "Mon, 24 Jul 2023 14:35:46 ", "Title": "EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge: Mixed Sequences Prediction", "Authors": ["Amirshayan Nasirimajd", "Simone Alberto Peirone", "Chiara Plizzari", "Barbara Caputo"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["2nd place in the 2023 EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition"]}, "abstract": "This report presents the technical details of our approach for the EPIC-Kitchens-100 Unsupervised Domain Adaptation (UDA) Challenge in Action Recognition. Our approach is based on the idea that the order in which actions are performed is similar between the source and target domains. Based on this, we generate a modified sequence by randomly combining actions from the source and target domains. As only unlabelled target data are available under the UDA setting, we use a standard pseudo-labeling strategy for extracting action labels for the target. We then ask the network to predict the resulting action sequence. This allows to integrate information from both domains during training and to achieve better transfer results on target. Additionally, to better incorporate sequence information, we use a language model to filter unlikely sequences. Lastly, we employed a co-occurrence matrix to eliminate unseen combinations of verbs and nouns. Our submission, labeled as 'sshayan', can be found on the leaderboard, where it currently holds the 2nd position for 'verb' and the 4th position for both 'noun' and 'action'.", "url": "https://arxiv.org/abs/2307.12837"}, {"metadata": {"arXiv": "2307.12907", "Date": "Mon, 24 Jul 2023 16:02:42 ", "Title": "GridMM: Grid Memory Map for Vision-and-Language Navigation", "Authors": ["Zihan Wang and Xiangyang Li and Jiahao Yang and Yeqi Liu and Shuqiang Jiang"], "Categories": "cs.CV cs.AI", "Journal-ref": "ICCV 2023"}, "abstract": "Vision-and-language navigation (VLN) enables the agent to navigate to a remote location following the natural language instruction in 3D environments. To represent the previously visited environment, most approaches for VLN implement memory using recurrent states, topological maps, or top-down semantic maps. In contrast to these approaches, we build the top-down egocentric and dynamically growing Grid Memory Map (i.e., GridMM) to structure the visited environment. From a global perspective, historical observations are projected into a unified grid map in a top-down view, which can better represent the spatial relations of the environment. From a local perspective, we further propose an instruction relevance aggregation method to capture fine-grained visual clues in each grid region. Extensive experiments are conducted on both the REVERIE, R2R, SOON datasets in the discrete environments, and the R2R-CE dataset in the continuous environments, showing the superiority of our proposed method.", "url": "https://arxiv.org/abs/2307.12907"}, {"metadata": {"arXiv": "2307.12914", "Date": "Mon, 24 Jul 2023 16:13:43 ", "Title": "Towards a Visual-Language Foundation Model for Computational Pathology", "Authors": ["Ming Y. Lu", "Bowen Chen", "Drew F. K. Williamson", "Richard J. Chen", "Ivy Liang", "Tong Ding", "Guillaume Jaume", "Igor Odintsov", "Andrew Zhang", "Long Phi Le", "Georg Gerber", "Anil V Parwani", "Faisal Mahmood"], "Categories": "cs.CV cs.AI"}, "abstract": "The accelerated adoption of digital pathology and advances in deep learning have enabled the development of powerful models for various pathology tasks across a diverse array of diseases and patient cohorts. However, model training is often difficult due to label scarcity in the medical domain and the model's usage is limited by the specific task and disease for which it is trained. Additionally, most models in histopathology leverage only image data, a stark contrast to how humans teach each other and reason about histopathologic entities. We introduce CONtrastive learning from Captions for Histopathology (CONCH), a visual-language foundation model developed using diverse sources of histopathology images, biomedical text, and notably over 1.17 million image-caption pairs via task-agnostic pretraining. Evaluated on a suite of 13 diverse benchmarks, CONCH can be transferred to a wide range of downstream tasks involving either or both histopathology images and text, achieving state-of-the-art performance on histology image classification, segmentation, captioning, text-to-image and image-to-text retrieval. CONCH represents a substantial leap over concurrent visual-language pretrained systems for histopathology, with the potential to directly facilitate a wide array of machine learning-based workflows requiring minimal or no further supervised fine-tuning.", "url": "https://arxiv.org/abs/2307.12914"}, {"metadata": {"arXiv": "2307.12917", "Date": "Mon, 24 Jul 2023 16:18:22 ", "Title": "Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification", "Authors": ["Haocong Rao", "Cyril Leung", "Chunyan Miao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by International Journal of Computer Vision (IJCV). Codes are available at https://github.com/Kali-Hac/Hi-MPC. Supplemental materials will be included in the published version"]}, "abstract": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.", "url": "https://arxiv.org/abs/2307.12917"}, {"metadata": {"arXiv": "2307.12898", "Date": "Mon, 24 Jul 2023 15:46:45 ", "Title": "As Time Goes By: Adding a Temporal Dimension Towards Resolving Delegations in Liquid Democracy", "Authors": ["Evangelos Markakis and Georgios Papasotiropoulos"], "Categories": "cs.GT cs.AI"}, "abstract": "In recent years, the study of various models and questions related to Liquid Democracy has been of growing interest among the community of Computational Social Choice. A concern that has been raised, is that current academic literature focuses solely on static inputs, concealing a key characteristic of Liquid Democracy: the right for a voter to change her mind as time goes by, regarding her options of whether to vote herself or delegate her vote to other participants, till the final voting deadline. In real life, a period of extended deliberation preceding the election-day motivates voters to adapt their behaviour over time, either based on observations of the remaining electorate or on information acquired for the topic at hand. By adding a temporal dimension to Liquid Democracy, such adaptations can increase the number of possible delegation paths and reduce the loss of votes due to delegation cycles or delegating paths towards abstaining agents, ultimately enhancing participation. Our work takes a first step to integrate a time horizon into decision-making problems in Liquid Democracy systems. Our approach, via a computational complexity analysis, exploits concepts and tools from temporal graph theory which turn out to be convenient for our framework.", "url": "https://arxiv.org/abs/2307.12898"}, {"metadata": {"arXiv": "2307.12915", "Date": "Mon, 24 Jul 2023 16:16:23 ", "Title": "Consensus-based Participatory Budgeting for Legitimacy: Decision Support via Multi-agent Reinforcement Learning", "Authors": ["Srijoni Majumdar and Evangelos Pournaras"], "Categories": "cs.MA cs.AI", "Comments": ["13 Pages", "8 Figures", "3 Tables", "Accepted in International Conference on Machine Learning", "Optimization", "and Data Science", "2023"], "Journal-ref": "International Conference on Machine Learning, Optimization, and Data Science, 2023"}, "abstract": "The legitimacy of bottom-up democratic processes for the distribution of public funds by policy-makers is challenging and complex. Participatory budgeting is such a process, where voting outcomes may not always be fair or inclusive. Deliberation for which project ideas to put for voting and choose for implementation lack systematization and do not scale. This paper addresses these grand challenges by introducing a novel and legitimate iterative consensus-based participatory budgeting process. Consensus is designed to be a result of decision support via an innovative multi-agent reinforcement learning approach. Voters are assisted to interact with each other to make viable compromises. Extensive experimental evaluation with real-world participatory budgeting data from Poland reveal striking findings: Consensus is reachable, efficient and robust. Compromise is required, which is though comparable to the one of existing voting aggregation methods that promote fairness and inclusion without though attaining consensus.", "url": "https://arxiv.org/abs/2307.12915"}, {"metadata": {"arXiv": "2307.11763", "Date": "Fri, 14 Jul 2023 13:48:37 ", "Title": "Rethinking Trust Repair in Human-Robot Interaction", "Authors": ["Connor Esterwood"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["Pre-Print of Submission for CSCW 2023 Doctoral Consortium"], "DOI": "10.1145/3584931.3608919"}, "abstract": "As robots become increasingly prevalent in work-oriented collaborations, trust has emerged as a critical factor in their acceptance and effectiveness. However, trust is dynamic and can erode when mistakes are made. Despite emerging research on trust repair in human-robot interaction, significant questions remain about identifying reliable approaches to restoring trust in robots after trust violations occur. To address this problem, my research aims to identify effective strategies for designing robots capable of trust repair in human-robot interaction (HRI) and to explore the underlying mechanisms that make these strategies successful. This paper provides an overview of the fundamental concepts and key components of the trust repair process in HRI, as well as a summary of my current published work in this area. Additionally, I discuss the research questions that will guide my future work and the potential contributions that this research could make to the field.", "url": "https://arxiv.org/abs/2307.11763"}, {"metadata": {"arXiv": "2307.12777", "Date": "Mon, 10 Jul 2023 11:11:24 ", "Title": "Proceeding of the 1st Workshop on Social Robots Personalisation At the crossroads between engineering and humanities (CONCATENATE)", "Authors": ["Imene Tarakli", "Georgios Angelopoulos", "Mehdi Hellou", "Camille Vindolet", "Boris Abramovic", "Rocco Limongelli", "Dimitri Lacroix", "Andrea Bertolini", "Silvia Rossi", "Alessandro Di Nuovo", "Angelo Cangelosi", "Gordon Cheng"], "Categories": "cs.RO cs.AI cs.HC"}, "abstract": "Nowadays, robots are expected to interact more physically, cognitively, and socially with people. They should adapt to unpredictable contexts alongside individuals with various behaviours. For this reason, personalisation is a valuable attribute for social robots as it allows them to act according to a specific user's needs and preferences and achieve natural and transparent robot behaviours for humans. If correctly implemented, personalisation could also be the key to the large-scale adoption of social robotics. However, achieving personalisation is arduous as it requires us to expand the boundaries of robotics by taking advantage of the expertise of various domains. Indeed, personalised robots need to analyse and model user interactions while considering their involvement in the adaptative process. It also requires us to address ethical and socio-cultural aspects of personalised HRI to achieve inclusive and diverse interaction and avoid deception and misplaced trust when interacting with the users. At the same time, policymakers need to ensure regulations in view of possible short-term and long-term adaptive HRI. This workshop aims to raise an interdisciplinary discussion on personalisation in robotics. It aims at bringing researchers from different fields together to propose guidelines for personalisation while addressing the following questions: how to define it - how to achieve it - and how it should be guided to fit legal and ethical requirements.", "url": "https://arxiv.org/abs/2307.12777"}, {"metadata": {"arXiv": "2307.12059", "Date": "Sat, 22 Jul 2023 12:00:54 ", "Title": "Fast Knowledge Graph Completion using Graphics Processing Units", "Authors": ["Chun-Hee Lee", "Dong-oh Kang", "Hwa Jeon Song"], "Categories": "cs.AI cs.DB cs.LG"}, "abstract": "Knowledge graphs can be used in many areas related to data semantics such as question-answering systems, knowledge based systems. However, the currently constructed knowledge graphs need to be complemented for better knowledge in terms of relations. It is called knowledge graph completion. To add new relations to the existing knowledge graph by using knowledge graph embedding models, we have to evaluate $N\\times N \\times R$ vector operations, where $N$ is the number of entities and $R$ is the number of relation types. It is very costly. In this paper, we provide an efficient knowledge graph completion framework on GPUs to get new relations using knowledge graph embedding vectors. In the proposed framework, we first define \"transformable to a metric space\" and then provide a method to transform the knowledge graph completion problem into the similarity join problem for a model which is \"transformable to a metric space\". After that, to efficiently process the similarity join problem, we derive formulas using the properties of a metric space. Based on the formulas, we develop a fast knowledge graph completion algorithm. Finally, we experimentally show that our framework can efficiently process the knowledge graph completion problem.", "url": "https://arxiv.org/abs/2307.12059"}, {"metadata": {"arXiv": "2307.12143", "Date": "Sat, 22 Jul 2023 18:47:18 ", "Title": "Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning", "Authors": ["Aqeel Labash", "Florian Fletzer", "Daniel Majoral", "Raul Vicente"], "Categories": "cs.AI cs.LG q-bio.NC", "Comments": ["ICML 2023"]}, "abstract": "Adapting to regularities of the environment is critical for biological organisms to anticipate events and plan. A prominent example is the circadian rhythm corresponding to the internalization by organisms of the $24$-hour period of the Earth's rotation. In this work, we study the emergence of circadian-like rhythms in deep reinforcement learning agents. In particular, we deployed agents in an environment with a reliable periodic variation while solving a foraging task. We systematically characterize the agent's behavior during learning and demonstrate the emergence of a rhythm that is endogenous and entrainable. Interestingly, the internal rhythm adapts to shifts in the phase of the environmental signal without any re-training. Furthermore, we show via bifurcation and phase response curve analyses how artificial neurons develop dynamics to support the internalization of the environmental rhythm. From a dynamical systems view, we demonstrate that the adaptation proceeds by the emergence of a stable periodic orbit in the neuron dynamics with a phase response that allows an optimal phase synchronisation between the agent's dynamics and the environmental rhythm.", "url": "https://arxiv.org/abs/2307.12143"}, {"metadata": {"arXiv": "2307.11978", "Date": "Sat, 22 Jul 2023 04:20:30 ", "Title": "Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?", "Authors": ["Cheng-En Wu", "Yu Tian", "Haichao Yu", "Heng Wang", "Pedro Morgado", "Yu Hen Hu", "Linjie Yang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Vision-language models such as CLIP learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises. This intrigues us to study the key reasons contributing to the robustness of the prompt tuning paradigm. We conducted extensive experiments to explore this property and find the key factors are: 1) the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, significantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CEWu/PTNL.", "url": "https://arxiv.org/abs/2307.11978"}, {"metadata": {"arXiv": "2307.12128", "Date": "Sat, 22 Jul 2023 17:08:13 ", "Title": "AI on the Road: A Comprehensive Analysis of Traffic Accidents and Accident Detection System in Smart Cities", "Authors": ["Victor Adewopo", "Nelly Elsayed", "Zag Elsayed", "Murat Ozer", "Victoria Wangia-Anderson", "Ahmed Abdelgawad"], "Categories": "cs.CV cs.AI cs.CY cs.LG", "Comments": ["8,8"]}, "abstract": "Accident detection and traffic analysis is a critical component of smart city and autonomous transportation systems that can reduce accident frequency, severity and improve overall traffic management. This paper presents a comprehensive analysis of traffic accidents in different regions across the United States using data from the National Highway Traffic Safety Administration (NHTSA) Crash Report Sampling System (CRSS). To address the challenges of accident detection and traffic analysis, this paper proposes a framework that uses traffic surveillance cameras and action recognition systems to detect and respond to traffic accidents spontaneously. Integrating the proposed framework with emergency services will harness the power of traffic cameras and machine learning algorithms to create an efficient solution for responding to traffic accidents and reducing human errors. Advanced intelligence technologies, such as the proposed accident detection systems in smart cities, will improve traffic management and traffic accident severity. Overall, this study provides valuable insights into traffic accidents in the US and presents a practical solution to enhance the safety and efficiency of transportation systems.", "url": "https://arxiv.org/abs/2307.12128"}, {"metadata": {"arXiv": "2307.12450", "Date": "Sun, 23 Jul 2023 22:48:07 ", "Title": "ProtoFL: Unsupervised Federated Learning via Prototypical Distillation", "Authors": ["Hansol Kim", "Youngjun Kwak", "Minyoung Jung", "Jinho Shin", "Youngsung Kim", "Changick Kim"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV 2023. Hansol Kim and Youngjun Kwak contributed equally to this work"]}, "abstract": "Federated learning (FL) is a promising approach for enhancing data privacy preservation, particularly for authentication systems. However, limited round communications, scarce representation, and scalability pose significant challenges to its deployment, hindering its full potential. In this paper, we propose 'ProtoFL', Prototypical Representation Distillation based unsupervised Federated Learning to enhance the representation power of a global model and reduce round communication costs. Additionally, we introduce a local one-class classifier based on normalizing flows to improve performance with limited data. Our study represents the first investigation of using FL to improve one-class classification performance. We conduct extensive experiments on five widely used benchmarks, namely MNIST, CIFAR-10, CIFAR-100, ImageNet-30, and Keystroke-Dynamics, to demonstrate the superior performance of our proposed framework over previous methods in the literature.", "url": "https://arxiv.org/abs/2307.12450"}, {"metadata": {"arXiv": "2307.12526", "Date": "Mon, 24 Jul 2023 04:56:23 ", "Title": "Rethinking Medical Report Generation: Disease Revealing Enhancement with Knowledge Graph", "Authors": ["Yixin Wang", "Zihao Lin", "Haoyu Dong"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Knowledge Graph (KG) plays a crucial role in Medical Report Generation (MRG) because it reveals the relations among diseases and thus can be utilized to guide the generation process. However, constructing a comprehensive KG is labor-intensive and its applications on the MRG process are under-explored. In this study, we establish a complete KG on chest X-ray imaging that includes 137 types of diseases and abnormalities. Based on this KG, we find that the current MRG data sets exhibit a long-tailed problem in disease distribution. To mitigate this problem, we introduce a novel augmentation strategy that enhances the representation of disease types in the tail-end of the distribution. We further design a two-stage MRG approach, where a classifier is first trained to detect whether the input images exhibit any abnormalities. The classified images are then independently fed into two transformer-based generators, namely, ``disease-specific generator\" and ``disease-free generator\" to generate the corresponding reports. To enhance the clinical evaluation of whether the generated reports correctly describe the diseases appearing in the input image, we propose diverse sensitivity (DS), a new metric that checks whether generated diseases match ground truth and measures the diversity of all generated diseases. Results show that the proposed two-stage generation framework and augmentation strategies improve DS by a considerable margin, indicating a notable reduction in the long-tailed problem associated with under-represented diseases.", "url": "https://arxiv.org/abs/2307.12526"}, {"metadata": {"arXiv": "2307.12698", "Date": "Mon, 24 Jul 2023 11:27:14 ", "Title": "MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features", "Authors": ["Adrien Bardes", "Jean Ponce", "Yann LeCun"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects in images and videos. On the other hand, optical flow estimation is a task that does not involve understanding the content of the images on which it is estimated. We unify the two approaches and introduce MC-JEPA, a joint-embedding predictive architecture and self-supervised learning approach to jointly learn optical flow and content features within a shared encoder, demonstrating that the two associated objectives; the optical flow estimation objective and the self-supervised learning objective; benefit from each other and thus learn content features that incorporate motion information. The proposed approach achieves performance on-par with existing unsupervised optical flow benchmarks, as well as with common self-supervised learning approaches on downstream tasks such as semantic segmentation of images and videos.", "url": "https://arxiv.org/abs/2307.12698"}, {"metadata": {"arXiv": "2307.12775", "Date": "Mon, 24 Jul 2023 13:24:56 ", "Title": "Is attention all you need in medical image analysis? A review", "Authors": ["Giorgos Papanastasiou", "Nikolaos Dikaios", "Jiahao Huang", "Chengjia Wang", "Guang Yang"], "Categories": "cs.CV cs.AI cs.LG eess.IV"}, "abstract": "Medical imaging is a key component in clinical diagnosis, treatment planning and clinical trial design, accounting for almost 90% of all healthcare data. CNNs achieved performance gains in medical image analysis (MIA) over the last years. CNNs can efficiently model local pixel interactions and be trained on small-scale MI data. The main disadvantage of typical CNN models is that they ignore global pixel relationships within images, which limits their generalisation ability to understand out-of-distribution data with different 'global' information. The recent progress of Artificial Intelligence gave rise to Transformers, which can learn global relationships from data. However, full Transformer models need to be trained on large-scale data and involve tremendous computational complexity. Attention and Transformer compartments (Transf/Attention) which can well maintain properties for modelling global relationships, have been proposed as lighter alternatives of full Transformers. Recently, there is an increasing trend to co-pollinate complementary local-global properties from CNN and Transf/Attention architectures, which led to a new era of hybrid models. The past years have witnessed substantial growth in hybrid CNN-Transf/Attention models across diverse MIA problems. In this systematic review, we survey existing hybrid CNN-Transf/Attention models, review and unravel key architectural designs, analyse breakthroughs, and evaluate current and future opportunities as well as challenges. We also introduced a comprehensive analysis framework on generalisation opportunities of scientific and clinical impact, based on which new data-driven domain generalisation and adaptation methods can be stimulated.", "url": "https://arxiv.org/abs/2307.12775"}, {"metadata": {"arXiv": "2307.12981", "Date": "Mon, 24 Jul 2023 17:59:02 ", "Title": "3D-LLM: Injecting the 3D World into Large Language Models", "Authors": ["Yining Hong", "Haoyu Zhen", "Peihao Chen", "Shuhong Zheng", "Yilun Du", "Zhenfang Chen", "Chuang Gan"], "Categories": "cs.CV cs.AI cs.CL cs.LG cs.RO", "Comments": ["Project Page: : https://vis-www.cs.umass.edu/3dllm/"]}, "abstract": "Large language models (LLMs) and Vision-Language Models (VLMs) have been proven to excel at multiple tasks, such as commonsense reasoning. Powerful as these models can be, they are not grounded in the 3D physical world, which involves richer concepts such as spatial relationships, affordances, physics, layout, and so on. In this work, we propose to inject the 3D world into large language models and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. Using three types of prompting mechanisms that we design, we are able to collect over 300k 3D-language data covering these tasks. To efficiently train 3D-LLMs, we first utilize a 3D feature extractor that obtains 3D features from rendered multi- view images. Then, we use 2D VLMs as our backbones to train our 3D-LLMs. By introducing a 3D localization mechanism, 3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show that our model outperforms state-of-the-art baselines by a large margin (e.g., the BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore, experiments on our held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative examples also show that our model could perform more tasks beyond the scope of existing LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.", "url": "https://arxiv.org/abs/2307.12981"}, {"metadata": {"arXiv": "2307.11784", "Date": "Thu, 20 Jul 2023 12:40:55 ", "Title": "What, Indeed, is an Achievable Provable Guarantee for Learning-Enabled Safety Critical Systems", "Authors": ["Saddek Bensalem", "Chih-Hong Cheng", "Wei Huang", "Xiaowei Huang", "Changshun Wu", "Xingyu Zhao"], "Categories": "cs.LG cs.AI cs.SE cs.SY"}, "abstract": "Machine learning has made remarkable advancements, but confidently utilising learning-enabled components in safety-critical domains still poses challenges. Among the challenges, it is known that a rigorous, yet practical, way of achieving safety guarantees is one of the most prominent. In this paper, we first discuss the engineering and research challenges associated with the design and verification of such systems. Then, based on the observation that existing works cannot actually achieve provable guarantees, we promote a two-step verification method for the ultimate achievement of provable statistical guarantees.", "url": "https://arxiv.org/abs/2307.11784"}, {"metadata": {"arXiv": "2307.11892", "Date": "Fri, 21 Jul 2023 20:26:54 ", "Title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise", "Authors": ["Avrim Blum", "Princewill Okoroafor", "Aadirupa Saha", "Kevin Stangl"], "Categories": "cs.LG cs.AI cs.CR cs.CY", "MSC-class": "I.2"}, "abstract": "We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. Konstantinov and Lampert (2021) initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in accuracy, where $\\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\\sqrt{\\alpha})$ loss, and give a matching $\\Omega(\\sqrt{\\alpha})$lower bound. In contrast, Konstantinov and Lampert (2021) showed for proper learners the loss in accuracy for both notions is $\\Omega(1)$. The key technical novelty of our work is how randomization can bypass simple \"tricks\" an adversary can use to amplify his power. We also consider additional fairness notions including Equalized Odds and Calibration. For these fairness notions, the excess accuracy clusters into three natural regimes $O(\\alpha)$,$O(\\sqrt{\\alpha})$ and $O(1)$. These results provide a more fine-grained view of the sensitivity of fairness-constrained learning to adversarial noise in training data.", "url": "https://arxiv.org/abs/2307.11892"}, {"metadata": {"arXiv": "2307.11897", "Date": "Fri, 21 Jul 2023 20:54:52 ", "Title": "Hindsight-DICE: Stable Credit Assignment for Deep Reinforcement Learning", "Authors": ["Akash Velu", "Skanda Vaidyanath", "Dilip Arumugam"], "Categories": "cs.LG cs.AI"}, "abstract": "Oftentimes, environments for sequential decision-making problems can be quite sparse in the provision of evaluative feedback to guide reinforcement-learning agents. In the extreme case, long trajectories of behavior are merely punctuated with a single terminal feedback signal, engendering a significant temporal delay between the observation of non-trivial reward and the individual steps of behavior culpable for eliciting such feedback. Coping with such a credit assignment challenge is one of the hallmark characteristics of reinforcement learning and, in this work, we capitalize on existing importance-sampling ratio estimation techniques for off-policy evaluation to drastically improve the handling of credit assignment with policy-gradient methods. While the use of so-called hindsight policies offers a principled mechanism for reweighting on-policy data by saliency to the observed trajectory return, naively applying importance sampling results in unstable or excessively lagged learning. In contrast, our hindsight distribution correction facilitates stable, efficient learning across a broad range of environments where credit assignment plagues baseline methods.", "url": "https://arxiv.org/abs/2307.11897"}, {"metadata": {"arXiv": "2307.11922", "Date": "Fri, 21 Jul 2023 22:02:50 ", "Title": "Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors", "Authors": ["Kolby Nottingham", "Yasaman Razeghi", "Kyungmin Kim", "JB Lanier", "Pierre Baldi", "Roy Fox", "Sameer Singh"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large language models (LLMs) are being applied as actors for sequential decision making tasks in domains such as robotics and games, utilizing their general world knowledge and planning abilities. However, previous work does little to explore what environment state information is provided to LLM actors via language. Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out. In this work, we propose Brief Language INputs for DEcision-making Responses (BLINDER), a method for automatically selecting concise state descriptions by learning a value function for task-conditioned state descriptions. We evaluate BLINDER on the challenging video game NetHack and a robotic manipulation task. Our method improves task success rate, reduces input size and compute costs, and generalizes between LLM actors.", "url": "https://arxiv.org/abs/2307.11922"}, {"metadata": {"arXiv": "2307.11949", "Date": "Sat, 22 Jul 2023 00:17:36 ", "Title": "HIQL: Offline Goal-Conditioned RL with Latent States as Actions", "Authors": ["Seohong Park", "Dibya Ghosh", "Benjamin Eysenbach", "Sergey Levine"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Unsupervised pre-training has recently become the bedrock for computer vision and natural language processing. In reinforcement learning (RL), goal-conditioned RL can potentially provide an analogous self-supervised approach for making use of large quantities of unlabeled (reward-free) data. However, building effective algorithms for goal-conditioned RL that can learn directly from diverse offline data is challenging, because it is hard to accurately estimate the exact value function for faraway goals. Nonetheless, goal-reaching problems exhibit structure, such that reaching distant goals entails first passing through closer subgoals. This structure can be very useful, as assessing the quality of actions for nearby goals is typically easier than for more distant goals. Based on this idea, we propose a hierarchical algorithm for goal-conditioned RL from offline data. Using one action-free value function, we learn two policies that allow us to exploit this structure: a high-level policy that treats states as actions and predicts (a latent representation of) a subgoal and a low-level policy that predicts the action for reaching this subgoal. Through analysis and didactic examples, we show how this hierarchical decomposition makes our method robust to noise in the estimated value function. We then apply our method to offline goal-reaching benchmarks, showing that our method can solve long-horizon tasks that stymie prior methods, can scale to high-dimensional image observations, and can readily make use of action-free data. Our code is available at https://seohong.me/projects/hiql/", "url": "https://arxiv.org/abs/2307.11949"}, {"metadata": {"arXiv": "2307.12062", "Date": "Sat, 22 Jul 2023 12:10:04 ", "Title": "Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations", "Authors": ["Yongyuan Liang", "Yanchao Sun", "Ruijie Zheng", "Xiangyu Liu", "Tuomas Sandholm", "Furong Huang and Stephen McAleer"], "Categories": "cs.LG cs.AI"}, "abstract": "Robust reinforcement learning (RL) seeks to train policies that can perform well under environment perturbations or adversarial attacks. Existing approaches typically assume that the space of possible perturbations remains the same across timesteps. However, in many settings, the space of possible perturbations at a given timestep depends on past perturbations. We formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose GRAD, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium in this game, GRAD ensures the agent's robustness against temporally-coupled perturbations. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupled attacks, in both state and action spaces.", "url": "https://arxiv.org/abs/2307.12062"}, {"metadata": {"arXiv": "2307.12158", "Date": "Sat, 22 Jul 2023 20:05:31 ", "Title": "DIP-RL: Demonstration-Inferred Preference Learning in Minecraft", "Authors": ["Ellen Novoseller", "Vinicius G. Goecks", "David Watkins", "Josh Miller", "Nicholas Waytowich"], "Categories": "cs.LG cs.AI cs.HC", "Comments": ["Paper accepted at The Many Facets of Preference Learning Workshop at the International Conference on Machine Learning (ICML)", "Honolulu", "Hawaii", "USA", "2023"], "ACM-class": "I.2.6; G.3"}, "abstract": "In machine learning for sequential decision-making, an algorithmic agent learns to interact with an environment while receiving feedback in the form of a reward signal. However, in many unstructured real-world settings, such a reward signal is unknown and humans cannot reliably craft a reward signal that correctly captures desired behavior. To solve tasks in such unstructured and open-ended environments, we present Demonstration-Inferred Preference Reinforcement Learning (DIP-RL), an algorithm that leverages human demonstrations in three distinct ways, including training an autoencoder, seeding reinforcement learning (RL) training batches with demonstration data, and inferring preferences over behaviors to learn a reward function to guide RL. We evaluate DIP-RL in a tree-chopping task in Minecraft. Results suggest that the method can guide an RL agent to learn a reward function that reflects human preferences and that DIP-RL performs competitively relative to baselines. DIP-RL is inspired by our previous work on combining demonstrations and pairwise preferences in Minecraft, which was awarded a research prize at the 2022 NeurIPS MineRL BASALT competition, Learning from Human Feedback in Minecraft. Example trajectory rollouts of DIP-RL and baselines are located at https://sites.google.com/view/dip-rl.", "url": "https://arxiv.org/abs/2307.12158"}, {"metadata": {"arXiv": "2307.12226", "Date": "Sun, 23 Jul 2023 04:48:41 ", "Title": "Geometry-Aware Adaptation for Pretrained Models", "Authors": ["Nicholas Roberts", "Xintong Li", "Dyah Adila", "Sonia Cromp", "Tzu-Heng Huang", "Jitian Zhao", "Frederic Sala"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Machine learning models -- including prominent zero-shot models -- are often trained on datasets whose labels are only a small proportion of a larger label space. Such spaces are commonly equipped with a metric that relates the labels via distances between them. We propose a simple approach to exploit this information to adapt the trained model to reliably predict new classes -- or, in the case of zero-shot prediction, to improve its performance -- without any additional training. Our technique is a drop-in replacement of the standard prediction rule, swapping argmax with the Fr\\'echet mean. We provide a comprehensive theoretical analysis for this approach, studying (i) learning-theoretic results trading off label space diameter, sample complexity, and model dimension, (ii) characterizations of the full range of scenarios in which it is possible to predict any unobserved class, and (iii) an optimal active learning-like next class selection procedure to obtain optimal training classes for when it is not possible to predict the entire range of unobserved classes. Empirically, using easily-available external metrics, our proposed approach, Loki, gains up to 29.7% relative improvement over SimCLR on ImageNet and scales to hundreds of thousands of classes. When no such metric is available, Loki can use self-derived metrics from class embeddings and obtains a 10.5% improvement on pretrained zero-shot models such as CLIP.", "url": "https://arxiv.org/abs/2307.12226"}, {"metadata": {"arXiv": "2307.12306", "Date": "Sun, 23 Jul 2023 12:18:12 ", "Title": "Tackling the Curse of Dimensionality with Physics-Informed Neural Networks", "Authors": ["Zheyuan Hu", "Khemraj Shukla", "George Em Karniadakis", "Kenji Kawaguchi"], "Categories": "cs.LG cs.AI cs.NA math.DS math.NA stat.ML", "Comments": ["32 pages", "5 figures"], "MSC-class": "14J60", "ACM-class": "F.2.2; I.2.7"}, "abstract": "The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed method. We experimentally demonstrate that the proposed method allows us to solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman and the Schr\\\"{o}dinger equations in thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. For example, we solve nontrivial nonlinear PDEs (the HJB-Lin equation and the BSB equation) in 100,000 dimensions in 6 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGD can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs.", "url": "https://arxiv.org/abs/2307.12306"}, {"metadata": {"arXiv": "2307.12344", "Date": "Sun, 23 Jul 2023 14:43:17 ", "Title": "Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations?", "Authors": ["Susu Sun", "Lisa M. Koch", "Christian F. Baumgartner"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "While deep neural network models offer unmatched classification performance, they are prone to learning spurious correlations in the data. Such dependencies on confounding information can be difficult to detect using performance metrics if the test data comes from the same distribution as the training data. Interpretable ML methods such as post-hoc explanations or inherently interpretable classifiers promise to identify faulty model reasoning. However, there is mixed evidence whether many of these techniques are actually able to do so. In this paper, we propose a rigorous evaluation strategy to assess an explanation technique's ability to correctly identify spurious correlations. Using this strategy, we evaluate five post-hoc explanation techniques and one inherently interpretable method for their ability to detect three types of artificially added confounders in a chest x-ray diagnosis task. We find that the post-hoc technique SHAP, as well as the inherently interpretable Attri-Net provide the best performance and can be used to reliably identify faulty model behavior.", "url": "https://arxiv.org/abs/2307.12344"}, {"metadata": {"arXiv": "2307.12369", "Date": "Sun, 23 Jul 2023 16:38:16 ", "Title": "Early Prediction of Alzheimers Disease Leveraging Symptom Occurrences from Longitudinal Electronic Health Records of US Military Veterans", "Authors": ["Rumeng Li", "Xun Wang", "Dan Berlowitz", "Brian Silver", "Wen Hu", "Heather Keating", "Raelene Goodwin", "Weisong Liu", "Honghuang Lin", "Hong Yu"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["24 pages"]}, "abstract": "Early prediction of Alzheimer's disease (AD) is crucial for timely intervention and treatment. This study aims to use machine learning approaches to analyze longitudinal electronic health records (EHRs) of patients with AD and identify signs and symptoms that can predict AD onset earlier. We used a case-control design with longitudinal EHRs from the U.S. Department of Veterans Affairs Veterans Health Administration (VHA) from 2004 to 2021. Cases were VHA patients with AD diagnosed after 1/1/2016 based on ICD-10-CM codes, matched 1:9 with controls by age, sex and clinical utilization with replacement. We used a panel of AD-related keywords and their occurrences over time in a patient's longitudinal EHRs as predictors for AD prediction with four machine learning models. We performed subgroup analyses by age, sex, and race/ethnicity, and validated the model in a hold-out and \"unseen\" VHA stations group. Model discrimination, calibration, and other relevant metrics were reported for predictions up to ten years before ICD-based diagnosis. The study population included 16,701 cases and 39,097 matched controls. The average number of AD-related keywords (e.g., \"concentration\", \"speaking\") per year increased rapidly for cases as diagnosis approached, from around 10 to over 40, while remaining flat at 10 for controls. The best model achieved high discriminative accuracy (ROCAUC 0.997) for predictions using data from at least ten years before ICD-based diagnoses. The model was well-calibrated (Hosmer-Lemeshow goodness-of-fit p-value = 0.99) and consistent across subgroups of age, sex and race/ethnicity, except for patients younger than 65 (ROCAUC 0.746). Machine learning models using AD-related keywords identified from EHR notes can predict future AD diagnoses, suggesting its potential use for identifying AD risk using EHR notes, offering an affordable way for early screening on large population.", "url": "https://arxiv.org/abs/2307.12369"}, {"metadata": {"arXiv": "2307.12388", "Date": "Sun, 23 Jul 2023 17:35:49 ", "Title": "Uncertainty-aware Grounded Action Transformation towards Sim-to-Real Transfer for Traffic Signal Control", "Authors": ["Longchao Da", "Hao Mei", "Romir Sharma and Hua Wei"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages", "3 figures"], "ACM-class": "H.4.0"}, "abstract": "Traffic signal control (TSC) is a complex and important task that affects the daily lives of millions of people. Reinforcement Learning (RL) has shown promising results in optimizing traffic signal control, but current RL-based TSC methods are mainly trained in simulation and suffer from the performance gap between simulation and the real world. In this paper, we propose a simulation-to-real-world (sim-to-real) transfer approach called UGAT, which transfers a learned policy trained from a simulated environment to a real-world environment by dynamically transforming actions in the simulation with uncertainty to mitigate the domain gap of transition dynamics. We evaluate our method on a simulated traffic environment and show that it significantly improves the performance of the transferred RL policy in the real world.", "url": "https://arxiv.org/abs/2307.12388"}, {"metadata": {"arXiv": "2307.12518", "Date": "Mon, 24 Jul 2023 04:23:08 ", "Title": "FaFCNN: A General Disease Classification Framework Based on Feature Fusion Neural Networks", "Authors": ["Menglin Kong", "Shaojie Zhao", "Juan Cheng", "Xingquan Li", "Ri Su", "Muzhou Hou", "Cong Cao"], "Categories": "cs.LG cs.AI cs.IR"}, "abstract": "There are two fundamental problems in applying deep learning/machine learning methods to disease classification tasks, one is the insufficient number and poor quality of training samples; another one is how to effectively fuse multiple source features and thus train robust classification models. To address these problems, inspired by the process of human learning knowledge, we propose the Feature-aware Fusion Correlation Neural Network (FaFCNN), which introduces a feature-aware interaction module and a feature alignment module based on domain adversarial learning. This is a general framework for disease classification, and FaFCNN improves the way existing methods obtain sample correlation features. The experimental results show that training using augmented features obtained by pre-training gradient boosting decision tree yields more performance gains than random-forest based methods. On the low-quality dataset with a large amount of missing data in our setup, FaFCNN obtains a consistently optimal performance compared to competitive baselines. In addition, extensive experiments demonstrate the robustness of the proposed method and the effectiveness of each component of the model\\footnote{Accepted in IEEE SMC2023}.", "url": "https://arxiv.org/abs/2307.12518"}, {"metadata": {"arXiv": "2307.12551", "Date": "Mon, 24 Jul 2023 06:38:10 ", "Title": "Continuation Path Learning for Homotopy Optimization", "Authors": ["Xi Lin", "Zhiyuan Yang", "Xiaoyuan Zhang", "Qingfu Zhang"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["Accepted by the 40th International Conference on Machine Learning (ICML 2023)"]}, "abstract": "Homotopy optimization is a traditional method to deal with a complicated optimization problem by solving a sequence of easy-to-hard surrogate subproblems. However, this method can be very sensitive to the continuation schedule design and might lead to a suboptimal solution to the original problem. In addition, the intermediate solutions, often ignored by classic homotopy optimization, could be useful for many real-world applications. In this work, we propose a novel model-based approach to learn the whole continuation path for homotopy optimization, which contains infinite intermediate solutions for any surrogate subproblems. Rather than the classic unidirectional easy-to-hard optimization, our method can simultaneously optimize the original problem and all surrogate subproblems in a collaborative manner. The proposed model also supports real-time generation of any intermediate solution, which could be desirable for many applications. Experimental studies on different problems show that our proposed method can significantly improve the performance of homotopy optimization and provide extra helpful information to support better decision-making.", "url": "https://arxiv.org/abs/2307.12551"}, {"metadata": {"arXiv": "2307.12625", "Date": "Mon, 24 Jul 2023 08:56:25 ", "Title": "De-confounding Representation Learning for Counterfactual Inference on Continuous Treatment via Generative Adversarial Network", "Authors": ["Yonghe Zhao", "Qiang Huang", "Haolong Zeng", "Yun Pen", "Huiyan Sun"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["15 pages,4 figures"]}, "abstract": "Counterfactual inference for continuous rather than binary treatment variables is more common in real-world causal inference tasks. While there are already some sample reweighting methods based on Marginal Structural Model for eliminating the confounding bias, they generally focus on removing the treatment's linear dependence on confounders and rely on the accuracy of the assumed parametric models, which are usually unverifiable. In this paper, we propose a de-confounding representation learning (DRL) framework for counterfactual outcome estimation of continuous treatment by generating the representations of covariates disentangled with the treatment variables. The DRL is a non-parametric model that eliminates both linear and nonlinear dependence between treatment and covariates. Specifically, we train the correlations between the de-confounded representations and the treatment variables against the correlations between the covariate representations and the treatment variables to eliminate confounding bias. Further, a counterfactual inference network is embedded into the framework to make the learned representations serve both de-confounding and trusted inference. Extensive experiments on synthetic datasets show that the DRL model performs superiorly in learning de-confounding representations and outperforms state-of-the-art counterfactual inference models for continuous treatment variables. In addition, we apply the DRL model to a real-world medical dataset MIMIC and demonstrate a detailed causal relationship between red cell width distribution and mortality.", "url": "https://arxiv.org/abs/2307.12625"}, {"metadata": {"arXiv": "2307.12689", "Date": "Mon, 24 Jul 2023 11:04:22 ", "Title": "Addressing the Impact of Localized Training Data in Graph Neural Networks", "Authors": ["Singh Akansha"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages", "4 figures"]}, "abstract": "Graph Neural Networks (GNNs) have achieved notable success in learning from graph-structured data, owing to their ability to capture intricate dependencies and relationships between nodes. They excel in various applications, including semi-supervised node classification, link prediction, and graph generation. However, it is important to acknowledge that the majority of state-of-the-art GNN models are built upon the assumption of an in-distribution setting, which hinders their performance on real-world graphs with dynamic structures. In this article, we aim to assess the impact of training GNNs on localized subsets of the graph. Such restricted training data may lead to a model that performs well in the specific region it was trained on but fails to generalize and make accurate predictions for the entire graph. In the context of graph-based semi-supervised learning (SSL), resource constraints often lead to scenarios where the dataset is large, but only a portion of it can be labeled, affecting the model's performance. This limitation affects tasks like anomaly detection or spam detection when labeling processes are biased or influenced by human subjectivity. To tackle the challenges posed by localized training data, we approach the problem as an out-of-distribution (OOD) data issue by by aligning the distributions between the training data, which represents a small portion of labeled data, and the graph inference process that involves making predictions for the entire graph. We propose a regularization method to minimize distributional discrepancies between localized training data and graph inference, improving model performance on OOD data. Extensive tests on popular GNN models show significant performance improvement on three citation GNN benchmark datasets. The regularization approach effectively enhances model adaptation and generalization, overcoming challenges posed by OOD data.", "url": "https://arxiv.org/abs/2307.12689"}, {"metadata": {"arXiv": "2307.12856", "Date": "Mon, 24 Jul 2023 14:56:30 ", "Title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", "Authors": ["Izzeddin Gur", "Hiroki Furuta", "Austin Huang", "Mustafa Safdari", "Yutaka Matsuo", "Douglas Eck", "Aleksandra Faust"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web navigation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that can complete the tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via generated Python programs from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our recipe improves the success on a real website by over 50%, and that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9% higher success rate than prior SoTA on the MiniWoB web navigation benchmark and better accuracy on offline task planning evaluation.", "url": "https://arxiv.org/abs/2307.12856"}, {"metadata": {"arXiv": "2307.12906", "Date": "Mon, 24 Jul 2023 15:59:36 ", "Title": "QAmplifyNet: Pushing the Boundaries of Supply Chain Backorder Prediction Using Interpretable Hybrid Quantum - Classical Neural Network", "Authors": ["Md Abrar Jahin", "Md Sakib Hossain Shovon", "Md. Saiful Islam", "Jungpil Shin", "M. F. Mridha", "Yuichi Okuyama"], "Categories": "cs.LG cs.AI quant-ph"}, "abstract": "Supply chain management relies on accurate backorder prediction for optimizing inventory control, reducing costs, and enhancing customer satisfaction. However, traditional machine-learning models struggle with large-scale datasets and complex relationships, hindering real-world data collection. This research introduces a novel methodological framework for supply chain backorder prediction, addressing the challenge of handling large datasets. Our proposed model, QAmplifyNet, employs quantum-inspired techniques within a quantum-classical neural network to predict backorders effectively on short and imbalanced datasets. Experimental evaluations on a benchmark dataset demonstrate QAmplifyNet's superiority over classical models, quantum ensembles, quantum neural networks, and deep reinforcement learning. Its proficiency in handling short, imbalanced datasets makes it an ideal solution for supply chain management. To enhance model interpretability, we use Explainable Artificial Intelligence techniques. Practical implications include improved inventory control, reduced backorders, and enhanced operational efficiency. QAmplifyNet seamlessly integrates into real-world supply chain management systems, enabling proactive decision-making and efficient resource allocation. Future work involves exploring additional quantum-inspired techniques, expanding the dataset, and investigating other supply chain applications. This research unlocks the potential of quantum computing in supply chain optimization and paves the way for further exploration of quantum-inspired machine learning models in supply chain management. Our framework and QAmplifyNet model offer a breakthrough approach to supply chain backorder prediction, providing superior performance and opening new avenues for leveraging quantum-inspired techniques in supply chain management.", "url": "https://arxiv.org/abs/2307.12906"}, {"metadata": {"arXiv": "2307.12926", "Date": "Mon, 24 Jul 2023 16:36:04 ", "Title": "Contextual Bandits and Imitation Learning via Preference-Based Active Queries", "Authors": ["Ayush Sekhari", "Karthik Sridharan", "Wen Sun", "Runzhe Wu"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "We consider the problem of contextual bandits and imitation learning, where the learner lacks direct knowledge of the executed action's reward. Instead, the learner can actively query an expert at each round to compare two actions and receive noisy preference feedback. The learner's objective is two-fold: to minimize the regret associated with the executed actions, while simultaneously, minimizing the number of comparison queries made to the expert. In this paper, we assume that the learner has access to a function class that can represent the expert's preference model under appropriate link functions, and provide an algorithm that leverages an online regression oracle with respect to this function class for choosing its actions and deciding when to query. For the contextual bandit setting, our algorithm achieves a regret bound that combines the best of both worlds, scaling as $O(\\min\\{\\sqrt{T}, d/\\Delta\\})$, where $T$ represents the number of interactions, $d$ represents the eluder dimension of the function class, and $\\Delta$ represents the minimum preference of the optimal action over any suboptimal action under all contexts. Our algorithm does not require the knowledge of $\\Delta$, and the obtained regret bound is comparable to what can be achieved in the standard contextual bandits setting where the learner observes reward signals at each round. Additionally, our algorithm makes only $O(\\min\\{T, d^2/\\Delta^2\\})$ queries to the expert. We then extend our algorithm to the imitation learning setting, where the learning agent engages with an unknown environment in episodes of length $H$ each, and provide similar guarantees for regret and query complexity. Interestingly, our algorithm for imitation learning can even learn to outperform the underlying expert, when it is suboptimal, highlighting a practical benefit of preference-based feedback in imitation learning.", "url": "https://arxiv.org/abs/2307.12926"}, {"metadata": {"arXiv": "2307.12941", "Date": "Mon, 24 Jul 2023 17:11:39 ", "Title": "On Privileged and Convergent Bases in Neural Network Representations", "Authors": ["Davis Brown", "Nikhil Vyas", "Yamini Bansal"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["In the Workshop on High-dimensional Learning Dynamics at ICML 2023"]}, "abstract": "In this study, we investigate whether the representations learned by neural networks possess a privileged and convergent basis. Specifically, we examine the significance of feature directions represented by individual neurons. First, we establish that arbitrary rotations of neural representations cannot be inverted (unlike linear networks), indicating that they do not exhibit complete rotational invariance. Subsequently, we explore the possibility of multiple bases achieving identical performance. To do this, we compare the bases of networks trained with the same parameters but with varying random initializations. Our study reveals two findings: (1) Even in wide networks such as WideResNets, neural networks do not converge to a unique basis; (2) Basis correlation increases significantly when a few early layers of the network are frozen identically. Furthermore, we analyze Linear Mode Connectivity, which has been studied as a measure of basis correlation. Our findings give evidence that while Linear Mode Connectivity improves with increased network width, this improvement is not due to an increase in basis correlation.", "url": "https://arxiv.org/abs/2307.12941"}, {"metadata": {"arXiv": "2307.12968", "Date": "Mon, 24 Jul 2023 17:46:32 ", "Title": "A Connection between One-Step Regularization and Critic Regularization in Reinforcement Learning", "Authors": ["Benjamin Eysenbach", "Matthieu Geist", "Sergey Levine", "Ruslan Salakhutdinov"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to ICML 2023. Video (https://www.youtube.com/watch?v=1xlixIHZ0R4) and code (https://github.com/ben-eysenbach/ac-connection)"]}, "abstract": "As with any machine learning problem with limited data, effective offline RL algorithms require careful regularization to avoid overfitting. One-step methods perform regularization by doing just a single step of policy improvement, while critic regularization methods do many steps of policy improvement with a regularized objective. These methods appear distinct. One-step methods, such as advantage-weighted regression and conditional behavioral cloning, truncate policy iteration after just one step. This ``early stopping'' makes one-step RL simple and stable, but can limit its asymptotic performance. Critic regularization typically requires more compute but has appealing lower-bound guarantees. In this paper, we draw a close connection between these methods: applying a multi-step critic regularization method with a regularization coefficient of 1 yields the same policy as one-step RL. While practical implementations violate our assumptions and critic regularization is typically applied with smaller regularization coefficients, our experiments nevertheless show that our analysis makes accurate, testable predictions about practical offline RL methods (CQL and one-step RL) with commonly-used hyperparameters. Our results that every problem can be solved with a single step of policy improvement, but rather that one-step RL might be competitive with critic regularization on RL problems that demand strong regularization.", "url": "https://arxiv.org/abs/2307.12968"}, {"metadata": {"arXiv": "2307.12983", "Date": "Mon, 24 Jul 2023 17:59:37 ", "Title": "Parallel $Q$-Learning: Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation", "Authors": ["Zechu Li", "Tao Chen", "Zhang-Wei Hong", "Anurag Ajay", "Pulkit Agrawal"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted by ICML 2023"]}, "abstract": "Reinforcement learning is time-consuming for complex tasks due to the need for large amounts of training data. Recent advances in GPU-based simulation, such as Isaac Gym, have sped up data collection thousands of times on a commodity GPU. Most prior works used on-policy methods like PPO due to their simplicity and ease of scaling. Off-policy methods are more data efficient but challenging to scale, resulting in a longer wall-clock training time. This paper presents a Parallel $Q$-Learning (PQL) scheme that outperforms PPO in wall-clock time while maintaining superior sample efficiency of off-policy learning. PQL achieves this by parallelizing data collection, policy learning, and value learning. Different from prior works on distributed off-policy learning, such as Apex, our scheme is designed specifically for massively parallel GPU-based simulation and optimized to work on a single workstation. In experiments, we demonstrate that $Q$-learning can be scaled to \\textit{tens of thousands of parallel environments} and investigate important factors affecting learning speed. The code is available at https://github.com/Improbable-AI/pql.", "url": "https://arxiv.org/abs/2307.12983"}, {"metadata": {"arXiv": "2307.11954", "Date": "Sat, 22 Jul 2023 01:16:29 ", "Title": "On-Robot Bayesian Reinforcement Learning for POMDPs", "Authors": ["Hai Nguyen", "Sammie Katt", "Yuchen Xiao", "Christopher Amato"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted at IROS-2023 (Detroit", "USA)"]}, "abstract": "Robot learning is often difficult due to the expense of gathering data. The need for large amounts of data can, and should, be tackled with effective algorithms and leveraging expert information on robot dynamics. Bayesian reinforcement learning (BRL), thanks to its sample efficiency and ability to exploit prior knowledge, is uniquely positioned as such a solution method. Unfortunately, the application of BRL has been limited due to the difficulties of representing expert knowledge as well as solving the subsequent inference problem. This paper advances BRL for robotics by proposing a specialized framework for physical systems. In particular, we capture this knowledge in a factored representation, then demonstrate the posterior factorizes in a similar shape, and ultimately formalize the model in a Bayesian framework. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach can, for example, utilize typical low-level robot simulators and handle uncertainty over unknown dynamics of the environment. We empirically demonstrate its efficiency by performing on-robot learning in two human-robot interaction tasks with uncertainty about human behavior, achieving near-optimal performance after only a handful of real-world episodes. A video of learned policies is at https://youtu.be/H9xp60ngOes.", "url": "https://arxiv.org/abs/2307.11954"}, {"metadata": {"arXiv": "2307.12015", "Date": "Sat, 22 Jul 2023 08:24:06 ", "Title": "Model Predictive Control (MPC) of an Artificial Pancreas with Data-Driven Learning of Multi-Step-Ahead Blood Glucose Predictors", "Authors": ["Eleonora Maria Aiello", "Mehrad Jaloli", "Marzia Cescon"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["10 pages", "5 Figures", "2 Tables"]}, "abstract": "We present the design and \\textit{in-silico} evaluation of a closed-loop insulin delivery algorithm to treat type 1 diabetes (T1D) consisting in a data-driven multi-step-ahead blood glucose (BG) predictor integrated into a Linear Time-Varying (LTV) Model Predictive Control (MPC) framework. Instead of identifying an open-loop model of the glucoregulatory system from available data, we propose to directly fit the entire BG prediction over a predefined prediction horizon to be used in the MPC, as a nonlinear function of past input-ouput data and an affine function of future insulin control inputs. For the nonlinear part, a Long Short-Term Memory (LSTM) network is proposed, while for the affine component a linear regression model is chosen. To assess benefits and drawbacks when compared to a traditional linear MPC based on an auto-regressive with exogenous (ARX) input model identified from data, we evaluated the proposed LSTM-MPC controller in three simulation scenarios: a nominal case with 3 meals per day, a random meal disturbances case where meals were generated with a recently published meal generator, and a case with 25$\\%$ decrease in the insulin sensitivity. Further, in all the scenarios, no feedforward meal bolus was administered. For the more challenging random meal generation scenario, the mean $\\pm$ standard deviation percent time in the range 70-180 [mg/dL] was 74.99 $\\pm$ 7.09 vs. 54.15 $\\pm$ 14.89, the mean $\\pm$ standard deviation percent time in the tighter range 70-140 [mg/dL] was 47.78$\\pm$8.55 vs. 34.62 $\\pm$9.04, while the mean $\\pm$ standard deviation percent time in sever hypoglycemia, i.e., $<$ 54 [mg/dl] was 1.00$\\pm$3.18 vs. 9.45$\\pm$11.71, for our proposed LSTM-MPC controller and the traditional ARX-MPC, respectively. Our approach provided accurate predictions of future glucose concentrations and good closed-loop performances of the overall MPC controller.", "url": "https://arxiv.org/abs/2307.12015"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

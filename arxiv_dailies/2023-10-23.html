<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.12990", "Date": "Fri, 22 Sep 2023 01:28:15 ", "Title": "Wave-informed dictionary learning for high-resolution imaging in complex media", "Authors": ["Miguel Moscoso", "Alexei Novikov", "George Papanicolaou and Chrysoula Tsogka"], "Categories": "cs.CV cs.LG eess.SP math.OC"}, "abstract": "We propose an approach for imaging in scattering media when large and diverse data sets are available. It has two steps. Using a dictionary learning algorithm the first step estimates the true Green's function vectors as columns in an unordered sensing matrix. The array data comes from many sparse sets of sources whose location and strength are not known to us. In the second step, the columns of the estimated sensing matrix are ordered for imaging using Multi-Dimensional Scaling with connectivity information derived from cross-correlations of its columns, as in time reversal. For these two steps to work together we need data from large arrays of receivers so the columns of the sensing matrix are incoherent for the first step, as well as from sub-arrays so that they are coherent enough to obtain the connectivity needed in the second step. Through simulation experiments, we show that the proposed approach is able to provide images in complex media whose resolution is that of a homogeneous medium.", "url": "https://arxiv.org/abs/2310.12990"}, {"metadata": {"arXiv": "2310.13120", "Date": "Thu, 19 Oct 2023 19:32:27 ", "Title": "RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering", "Authors": ["Yuduo Wang", "Pedram Ghamisi"], "Categories": "cs.CV cs.LG", "Comments": ["Submitted to IEEE"]}, "abstract": "In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not only improves adaptation to pre-trained multimodal models but also allows the parameters of the linear transformation layer to be integrated into the preceding FC layers during inference, reducing inference costs. To demonstrate the effectiveness of RSAdapter, we conduct an extensive series of experiments using three distinct RS-VQA datasets and achieve state-of-the-art results on all three datasets. The code for RSAdapter will be available online at https://github.com/Y-D-Wang/RSAdapter.", "url": "https://arxiv.org/abs/2310.13120"}, {"metadata": {"arXiv": "2310.13268", "Date": "Fri, 20 Oct 2023 04:23:12 ", "Title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics", "Authors": ["Kaiwen Zheng", "Cheng Lu", "Jianfei Chen", "Jun Zhu"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Diffusion probabilistic models (DPMs) have exhibited excellent performance for high-fidelity image generation while suffering from inefficient sampling. Recent works accelerate the sampling procedure by proposing fast ODE solvers that leverage the specific ODE form of DPMs. However, they highly rely on specific parameterization during inference (such as noise/data prediction), which might not be the optimal choice. In this work, we propose a novel formulation towards the optimal parameterization during sampling that minimizes the first-order discretization error of the ODE solution. Based on such formulation, we propose \\textit{DPM-Solver-v3}, a new fast ODE solver for DPMs by introducing several coefficients efficiently computed on the pretrained model, which we call \\textit{empirical model statistics}. We further incorporate multistep methods and a predictor-corrector framework, and propose some techniques for improving sample quality at small numbers of function evaluations (NFE) or large guidance scales. Experiments show that DPM-Solver-v3 achieves consistently better or comparable performance in both unconditional and conditional sampling with both pixel-space and latent-space DPMs, especially in 5$\\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE) on unconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable Diffusion, bringing a speed-up of 15\\%$\\sim$30\\% compared to previous state-of-the-art training-free methods. Code is available at \\url{https://github.com/thu-ml/DPM-Solver-v3}.", "url": "https://arxiv.org/abs/2310.13268"}, {"metadata": {"arXiv": "2310.13276", "Date": "Fri, 20 Oct 2023 04:45:44 ", "Title": "InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution", "Authors": ["Xiangru Jian", "Yimu Wang"], "Categories": "cs.CV cs.CL cs.LG cs.MM", "Comments": ["Findings of EMNLP 2023"]}, "abstract": "Over recent decades, significant advancements in cross-modal retrieval are mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance. Our code is available at https://github.com/yimuwangcs/Better_Cross_Modal_Retrieval", "url": "https://arxiv.org/abs/2310.13276"}, {"metadata": {"arXiv": "2310.13292", "Date": "Fri, 20 Oct 2023 05:44:55 ", "Title": "CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training", "Authors": ["Kihyun You", "Jawook Gu", "Jiyeon Ham", "Beomhee Park", "Jiho Kim", "Eun Kyoung Hong", "Woonhyunk Baek", "Byungseok Roh"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by MICCAI 2023"], "DOI": "10.1007/978-3-031-43895-0_10"}, "abstract": "A large-scale image-text pair dataset has greatly contributed to the development of vision-language pre-training (VLP) models, which enable zero-shot or few-shot classification without costly annotation. However, in the medical domain, the scarcity of data remains a significant challenge for developing a powerful VLP model. In this paper, we tackle the lack of image-text data in chest X-ray by expanding image-label pair as image-text pair via general prompt and utilizing multiple images and multiple sections in a radiologic report. We also design two contrastive losses, named ICL and TCL, for learning study-level characteristics of medical images and reports, respectively. Our model outperforms the state-of-the-art models trained under the same conditions. Also, enlarged dataset improve the discriminative power of our pre-trained model for classification, while sacrificing marginal retrieval performance. Code is available at https://github.com/kakaobrain/cxr-clip.", "url": "https://arxiv.org/abs/2310.13292"}, {"metadata": {"arXiv": "2310.13479", "Date": "Fri, 20 Oct 2023 13:20:17 ", "Title": "Segment, Select, Correct: A Framework for Weakly-Supervised Referring Segmentation", "Authors": ["Francisco Eiras", "Kemal Oksuz", "Adel Bibi", "Philip H.S. Torr", "Puneet K. Dokania"], "Categories": "cs.CV cs.LG"}, "abstract": "Referring Image Segmentation (RIS) - the problem of identifying objects in images through natural language sentences - is a challenging task currently mostly solved through supervised learning. However, while collecting referred annotation masks is a time-consuming process, the few existing weakly-supervised and zero-shot approaches fall significantly short in performance compared to fully-supervised learning ones. To bridge the performance gap without mask annotations, we propose a novel weakly-supervised framework that tackles RIS by decomposing it into three steps: obtaining instance masks for the object mentioned in the referencing instruction (segment), using zero-shot learning to select a potentially correct mask for the given instruction (select), and bootstrapping a model which allows for fixing the mistakes of zero-shot selection (correct). In our experiments, using only the first two steps (zero-shot segment and select) outperforms other zero-shot baselines by as much as 19%, while our full method improves upon this much stronger baseline and sets the new state-of-the-art for weakly-supervised RIS, reducing the gap between the weakly-supervised and fully-supervised methods in some cases from around 33% to as little as 14%. Code is available at https://github.com/fgirbal/segment-select-correct.", "url": "https://arxiv.org/abs/2310.13479"}, {"metadata": {"arXiv": "2310.13674", "Date": "Fri, 20 Oct 2023 17:22:57 ", "Title": "Using Human-like Mechanism to Weaken Effect of Pre-training Weight Bias in Face-Recognition Convolutional Neural Network", "Authors": ["Haojiang Ying", "Yi-Fan Li", "Yiyang Chen"], "Categories": "cs.CV cs.LG q-bio.NC", "Comments": ["24 pages", "6 figures"]}, "abstract": "Convolutional neural network (CNN), as an important model in artificial intelligence, has been widely used and studied in different disciplines. The computational mechanisms of CNNs are still not fully revealed due to the their complex nature. In this study, we focused on 4 extensively studied CNNs (AlexNet, VGG11, VGG13, and VGG16) which has been analyzed as human-like models by neuroscientists with ample evidence. We trained these CNNs to emotion valence classification task by transfer learning. Comparing their performance with human data, the data unveiled that these CNNs would partly perform as human does. We then update the object-based AlexNet using self-attention mechanism based on neuroscience and behavioral data. The updated FE-AlexNet outperformed all the other tested CNNs and closely resembles human perception. The results further unveil the computational mechanisms of these CNNs. Moreover, this study offers a new paradigm to better understand and improve CNN performance via human data.", "url": "https://arxiv.org/abs/2310.13674"}, {"metadata": {"arXiv": "2310.13681", "Date": "Fri, 20 Oct 2023 17:40:39 ", "Title": "RealFM: A Realistic Mechanism to Incentivize Data Contribution and Device Participation", "Authors": ["Marco Bornstein", "Amrit Singh Bedi", "Anit Kumar Sahu", "Furqan Khan", "and Furong Huang"], "Categories": "cs.GT cs.CY cs.DC cs.LG econ.TH", "Comments": ["21 pages", "11 figures"]}, "abstract": "Edge device participation in federating learning (FL) has been typically studied under the lens of device-server communication (e.g., device dropout) and assumes an undying desire from edge devices to participate in FL. As a result, current FL frameworks are flawed when implemented in real-world settings, with many encountering the free-rider problem. In a step to push FL towards realistic settings, we propose RealFM: the first truly federated mechanism which (1) realistically models device utility, (2) incentivizes data contribution and device participation, and (3) provably removes the free-rider phenomena. RealFM does not require data sharing and allows for a non-linear relationship between model accuracy and utility, which improves the utility gained by the server and participating devices compared to non-participating devices as well as devices participating in other FL mechanisms. On real-world data, RealFM improves device and server utility, as well as data contribution, by up to 3 magnitudes and 7x respectively compared to baseline mechanisms.", "url": "https://arxiv.org/abs/2310.13681"}, {"metadata": {"arXiv": "2310.13061", "Date": "Thu, 19 Oct 2023 18:01:10 ", "Title": "To grok or not to grok: Disentangling generalization and memorization on corrupted algorithmic datasets", "Authors": ["Darshil Doshi", "Aritra Das", "Tianyu He", "Andrey Gromov"], "Categories": "cs.LG cond-mat.dis-nn stat.ML", "Comments": ["24 pages", "22 figures", "2 tables"]}, "abstract": "Robust generalization is a major challenge in deep learning, particularly when the number of trainable parameters is very large. In general, it is very difficult to know if the network has memorized a particular set of examples or understood the underlying rule (or both). Motivated by this challenge, we study an interpretable model where generalizing representations are understood analytically, and are easily distinguishable from the memorizing ones. Namely, we consider two-layer neural networks trained on modular arithmetic tasks where ($\\xi \\cdot 100\\%$) of labels are corrupted (\\emph{i.e.} some results of the modular operations in the training set are incorrect). We show that (i) it is possible for the network to memorize the corrupted labels \\emph{and} achieve $100\\%$ generalization at the same time; (ii) the memorizing neurons can be identified and pruned, lowering the accuracy on corrupted data and improving the accuracy on uncorrupted data; (iii) regularization methods such as weight decay, dropout and BatchNorm force the network to ignore the corrupted data during optimization, and achieve $100\\%$ accuracy on the uncorrupted dataset; and (iv) the effect of these regularization methods is (``mechanistically'') interpretable: weight decay and dropout force all the neurons to learn generalizing representations, while BatchNorm de-amplifies the output of memorizing neurons and amplifies the output of the generalizing ones. Finally, we show that in the presence of regularization, the training dynamics involves two consecutive stages: first, the network undergoes the \\emph{grokking} dynamics reaching high train \\emph{and} test accuracy; second, it unlearns the memorizing representations, where train accuracy suddenly jumps from $100\\%$ to $100 (1-\\xi)\\%$.", "url": "https://arxiv.org/abs/2310.13061"}, {"metadata": {"arXiv": "2310.13073", "Date": "Thu, 19 Oct 2023 18:12:49 ", "Title": "Using Logic Programming and Kernel-Grouping for Improving Interpretability of Convolutional Neural Networks", "Authors": ["Parth Padalkar", "Gopal Gupta"], "Categories": "cs.LG cs.CV", "Comments": ["arXiv admin note: text overlap with arXiv:2301.12667"]}, "abstract": "Within the realm of deep learning, the interpretability of Convolutional Neural Networks (CNNs), particularly in the context of image classification tasks, remains a formidable challenge. To this end we present a neurosymbolic framework, NeSyFOLD-G that generates a symbolic rule-set using the last layer kernels of the CNN to make its underlying knowledge interpretable. What makes NeSyFOLD-G different from other similar frameworks is that we first find groups of similar kernels in the CNN (kernel-grouping) using the cosine-similarity between the feature maps generated by various kernels. Once such kernel groups are found, we binarize each kernel group's output in the CNN and use it to generate a binarization table which serves as input data to FOLD-SE-M which is a Rule Based Machine Learning (RBML) algorithm. FOLD-SE-M then generates a rule-set that can be used to make predictions. We present a novel kernel grouping algorithm and show that grouping similar kernels leads to a significant reduction in the size of the rule-set generated by FOLD-SE-M, consequently, improving the interpretability. This rule-set symbolically encapsulates the connectionist knowledge of the trained CNN. The rule-set can be viewed as a normal logic program wherein each predicate's truth value depends on a kernel group in the CNN. Each predicate in the rule-set is mapped to a concept using a few semantic segmentation masks of the images used for training, to make it human-understandable. The last layers of the CNN can then be replaced by this rule-set to obtain the NeSy-G model which can then be used for the image classification task. The goal directed ASP system s(CASP) can be used to obtain the justification of any prediction made using the NeSy-G model. We also propose a novel algorithm for labeling each predicate in the rule-set with the semantic concept(s) that its corresponding kernel group represents.", "url": "https://arxiv.org/abs/2310.13073"}, {"metadata": {"arXiv": "2310.13097", "Date": "Thu, 19 Oct 2023 18:55:10 ", "Title": "A Multi-Stage Temporal Convolutional Network for Volleyball Jumps Classification Using a Waist-Mounted IMU", "Authors": ["Meng Shang", "Camilla De Bleecker", "Jos Vanrenterghem", "Roel De Ridder", "Sabine Verschueren", "Carolina Varon", "Walter De Raedt", "and Bart Vanrumste"], "Categories": "cs.LG", "Comments": ["NA"]}, "abstract": "Monitoring the number of jumps for volleyball players during training or a match can be crucial to prevent injuries, yet the measurement requires considerable workload and cost using traditional methods such as video analysis. Also, existing methods do not provide accurate differentiation between different types of jumps. In this study, an unobtrusive system with a single inertial measurement unit (IMU) on the waist was proposed to recognize the types of volleyball jumps. A Multi-Layer Temporal Convolutional Network (MS-TCN) was applied for sample-wise classification. The model was evaluated on ten volleyball players and twenty-six volleyball players, during a lab session with a fixed protocol of jumping and landing tasks, and during four volleyball training sessions, respectively. The MS-TCN model achieved better performance than a state-of-the-art deep learning model but with lower computational cost. In the lab sessions, most jump counts showed small differences between the predicted jumps and video-annotated jumps, with an overall count showing a Limit of Agreement (LoA) of 0.1+-3.40 (r=0.884). For comparison, the proposed algorithm showed slightly worse results than VERT (a commercial jumping assessment device) with a LoA of 0.1+-2.08 (r=0.955) but the differences were still within a comparable range. In the training sessions, the recognition of three types of jumps exhibited a mean difference from observation of less than 10 jumps: block, smash, and overhead serve. These results showed the potential of using a single IMU to recognize the types of volleyball jumps. The sample-wise architecture provided high resolution of recognition and the MS-TCN required fewer parameters to train compared with state-of-the-art models.", "url": "https://arxiv.org/abs/2310.13097"}, {"metadata": {"arXiv": "2310.13098", "Date": "Thu, 19 Oct 2023 18:56:04 ", "Title": "SRAI: Towards Standardization of Geospatial AI", "Authors": ["Piotr Gramacki", "Kacper Le\\'sniara", "Kamil Raczycki", "Szymon Wo\\'zniak", "Marcin Przymus", "Piotr Szyma\\'nski"], "Categories": "cs.LG"}, "abstract": "Spatial Representations for Artificial Intelligence (\\textit{srai}) is a Python library for working with geospatial data. The library can download geospatial data, split a given area into micro-regions using multiple algorithms and train an embedding model using various architectures. It includes baseline models as well as more complex methods from published works. Those capabilities make it possible to use \\textit{srai} in a complete pipeline for geospatial task solving. The proposed library is the first step to standardize the geospatial AI domain toolset. It is fully open-source and published under Apache 2.0 licence.", "url": "https://arxiv.org/abs/2310.13098"}, {"metadata": {"arXiv": "2310.13123", "Date": "Thu, 19 Oct 2023 19:35:38 ", "Title": "Fuel Consumption Prediction for a Passenger Ferry using Machine Learning and In-service Data: A Comparative Study", "Authors": ["Pedram Agand", "Allison Kennedy", "Trevor Harris", "Chanwoo Bae", "Mo Chen", "Edward J Park"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["20 pages", "11 figures", "7 tables"], "Journal-ref": "Ocean Engineering 284 (2023): 115271", "DOI": "10.1016/j.oceaneng.2023.115271"}, "abstract": "As the importance of eco-friendly transportation increases, providing an efficient approach for marine vessel operation is essential. Methods for status monitoring with consideration to the weather condition and forecasting with the use of in-service data from ships requires accurate and complete models for predicting the energy efficiency of a ship. The models need to effectively process all the operational data in real-time. This paper presents models that can predict fuel consumption using in-service data collected from a passenger ship. Statistical and domain-knowledge methods were used to select the proper input variables for the models. These methods prevent over-fitting, missing data, and multicollinearity while providing practical applicability. Prediction models that were investigated include multiple linear regression (MLR), decision tree approach (DT), an artificial neural network (ANN), and ensemble methods. The best predictive performance was from a model developed using the XGboost technique which is a boosting ensemble approach. \\rvv{Our code is available on GitHub at \\url{https://github.com/pagand/model_optimze_vessel/tree/OE} for future research.", "url": "https://arxiv.org/abs/2310.13123"}, {"metadata": {"arXiv": "2310.13139", "Date": "Thu, 19 Oct 2023 20:32:25 ", "Title": "Graph Neural Networks with polynomial activations have limited expressivity", "Authors": ["Sammy Khalife"], "Categories": "cs.LG"}, "abstract": "The expressivity of Graph Neural Networks (GNNs) can be entirely characterized by appropriate fragments of the first order logic. Namely, any query of the two variable fragment of graded modal logic (GC2) interpreted over labelled graphs can be expressed using a GNN whose size depends only on the depth of the query. As pointed out by [Barcelo & Al., 2020, Grohe, 2021 ], this description holds for a family of activation functions, leaving the possibibility for a hierarchy of logics expressible by GNNs depending on the chosen activation function. In this article, we show that such hierarchy indeed exists by proving that GC2 queries cannot be expressed by GNNs with polynomial activation functions. This implies a separation between polynomial and popular non polynomial activations (such as ReLUs, sigmoid and hyperbolic tan and others) and answers an open question formulated by [Grohe, 2021].", "url": "https://arxiv.org/abs/2310.13139"}, {"metadata": {"arXiv": "2310.13164", "Date": "Thu, 19 Oct 2023 21:31:11 ", "Title": "Almost Equivariance via Lie Algebra Convolutions", "Authors": ["Daniel McNeela"], "Categories": "cs.LG", "ACM-class": "I.2.6"}, "abstract": "Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebra convolutions and demonstrate that they offer several benefits over Lie group convolutions, including being well-defined for non-compact groups. From there, we pivot to the realm of theory and demonstrate connections between the notions of equivariance and isometry and those of almost equivariance and almost isometry, respectively. We prove two existence theorems, one showing the existence of almost isometries within bounded distance of isometries of a general manifold, and another showing the converse for Hilbert spaces. We then extend these theorems to prove the existence of almost equivariant manifold embeddings within bounded distance of fully equivariant embedding functions, subject to certain constraints on the group action and the function class. Finally, we demonstrate the validity of our approach by benchmarking against datasets in fully equivariant and almost equivariant settings.", "url": "https://arxiv.org/abs/2310.13164"}, {"metadata": {"arXiv": "2310.13193", "Date": "Thu, 19 Oct 2023 23:04:09 ", "Title": "Heterogeneous Graph Neural Networks for Data-driven Traffic Assignment", "Authors": ["Tong Liu and Hadi Meidani"], "Categories": "cs.LG", "Comments": ["13 pages", "6 figures"]}, "abstract": "The traffic assignment problem is one of the significant components of traffic flow analysis for which various solution approaches have been proposed. However, deploying these approaches for large-scale networks poses significant challenges. In this paper, we leverage the power of heterogeneous graph neural networks to propose a novel data-driven approach for traffic assignment and traffic flow learning. The proposed model is capable of capturing spatial traffic patterns across different links, yielding highly accurate results. We present numerical experiments on urban transportation networks and show that the proposed heterogeneous graph neural network model outperforms other conventional neural network models in terms of convergence rate, training loss, and prediction accuracy. Notably, the proposed heterogeneous graph neural network model can also be generalized to different network topologies. This approach offers a promising solution for complex traffic flow analysis and prediction, enhancing our understanding and management of a wide range of transportation systems.", "url": "https://arxiv.org/abs/2310.13193"}, {"metadata": {"arXiv": "2310.13220", "Date": "Fri, 20 Oct 2023 01:55:34 ", "Title": "In-context Learning with Transformer Is Really Equivalent to a Contrastive Learning Pattern", "Authors": ["Ruifeng Ren and Yong Liu"], "Categories": "cs.LG", "Comments": ["12 pages"]}, "abstract": "Pre-trained large language models based on Transformers have demonstrated amazing in-context learning (ICL) abilities. Given several demonstration examples, the models can implement new tasks without any parameter updates. However, it is still an open question to understand the mechanism of ICL. In this paper, we interpret the inference process of ICL as a gradient descent process in a contrastive learning pattern. Firstly, leveraging kernel methods, we establish the relationship between gradient descent and self-attention mechanism under generally used softmax attention setting instead of linear attention setting. Then, we analyze the corresponding gradient descent process of ICL from the perspective of contrastive learning without negative samples and discuss possible improvements of this contrastive learning pattern, based on which the self-attention layer can be further modified. Finally, we design experiments to support our opinions. To the best of our knowledge, our work is the first to provide the understanding of ICL from the perspective of contrastive learning and has the potential to facilitate future model design by referring to related works on contrastive learning.", "url": "https://arxiv.org/abs/2310.13220"}, {"metadata": {"arXiv": "2310.13236", "Date": "Fri, 20 Oct 2023 02:45:20 ", "Title": "Training A Semantic Communication System with Federated Learning", "Authors": ["Loc X. Nguyen", "Huy Q. Le", "Ye Lin Tun", "Pyae Sone Aung", "Yan Kyaw Tun", "Zhu Han", "Choong Seon Hong"], "Categories": "cs.LG", "Comments": ["5 pages", "4 figures"]}, "abstract": "Semantic communication has emerged as a pillar for the next generation of communication systems due to its capabilities in alleviating data redundancy. Most semantic communication systems are built using advanced deep learning models whose performance heavily depends on data availability. These studies assume that an abundance of training data is available, which is unrealistic. In practice, data is mainly created on the user side. Due to privacy and security concerns, the transmission of data is restricted, which is necessary for conventional centralized training schemes. To address this challenge, we explore semantic communication in federated learning (FL) setting that utilizes user data without leaking privacy. Additionally, we design our system to tackle the communication overhead by reducing the quantity of information delivered in each global round. In this way, we can save significant bandwidth for resource-limited devices and reduce overall network traffic. Finally, we propose a mechanism to aggregate the global model from the clients, called FedLol. Extensive simulation results demonstrate the efficacy of our proposed technique compared to baseline methods.", "url": "https://arxiv.org/abs/2310.13236"}, {"metadata": {"arXiv": "2310.13240", "Date": "Fri, 20 Oct 2023 02:48:29 ", "Title": "Transparency challenges in policy evaluation with causal machine learning -- improving usability and accountability", "Authors": ["Patrick Rehill and Nicholas Biddle"], "Categories": "cs.LG econ.EM", "Comments": ["25 pages", "10 figures"]}, "abstract": "Causal machine learning tools are beginning to see use in real-world policy evaluation tasks to flexibly estimate treatment effects. One issue with these methods is that the machine learning models used are generally black boxes, i.e., there is no globally interpretable way to understand how a model makes estimates. This is a clear problem in policy evaluation applications, particularly in government, because it is difficult to understand whether such models are functioning in ways that are fair, based on the correct interpretation of evidence and transparent enough to allow for accountability if things go wrong. However, there has been little discussion of transparency problems in the causal machine learning literature and how these might be overcome. This paper explores why transparency issues are a problem for causal machine learning in public policy evaluation applications and considers ways these problems might be addressed through explainable AI tools and by simplifying models in line with interpretable AI principles. It then applies these ideas to a case-study using a causal forest model to estimate conditional average treatment effects for a hypothetical change in the school leaving age in Australia. It shows that existing tools for understanding black-box predictive models are poorly suited to causal machine learning and that simplifying the model to make it interpretable leads to an unacceptable increase in error (in this application). It concludes that new tools are needed to properly understand causal machine learning models and the algorithms that fit them.", "url": "https://arxiv.org/abs/2310.13240"}, {"metadata": {"arXiv": "2310.13261", "Date": "Fri, 20 Oct 2023 03:45:29 ", "Title": "DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming with Feasibility Guarantee", "Authors": ["Haoyu Wang", "Jialin Liu", "Xiaohan Chen", "Xinshang Wang", "Pan Li", "Wotao Yin"], "Categories": "cs.LG"}, "abstract": "Mixed-integer linear programming (MILP) stands as a notable NP-hard problem pivotal to numerous crucial industrial applications. The development of effective algorithms, the tuning of solvers, and the training of machine learning models for MILP resolution all hinge on access to extensive, diverse, and representative data. Yet compared to the abundant naturally occurring data in image and text realms, MILP is markedly data deficient, underscoring the vital role of synthetic MILP generation. We present DIG-MILP, a deep generative framework based on variational auto-encoder (VAE), adept at extracting deep-level structural features from highly limited MILP data and producing instances that closely mirror the target data. Notably, by leveraging the MILP duality, DIG-MILP guarantees a correct and complete generation space as well as ensures the boundedness and feasibility of the generated instances. Our empirical study highlights the novelty and quality of the instances generated by DIG-MILP through two distinct downstream tasks: (S1) Data sharing, where solver solution times correlate highly positive between original and DIG-MILP-generated instances, allowing data sharing for solver tuning without publishing the original data; (S2) Data Augmentation, wherein the DIG-MILP-generated instances bolster the generalization performance of machine learning models tasked with resolving MILP problems.", "url": "https://arxiv.org/abs/2310.13261"}, {"metadata": {"arXiv": "2310.13283", "Date": "Fri, 20 Oct 2023 05:24:28 ", "Title": "FedLoRA: Model-Heterogeneous Personalized Federated Learning with LoRA Tuning", "Authors": ["Liping Yi", "Han Yu", "Gang Wang", "Xiaoguang Liu"], "Categories": "cs.LG cs.DC", "Comments": ["11 pages", "11 figures"]}, "abstract": "Federated learning (FL) is an emerging machine learning paradigm in which a central server coordinates multiple participants (a.k.a. FL clients) to train a model collaboratively on decentralized data with privacy protection. This paradigm constrains that all clients have to train models with the same structures (homogeneous). In practice, FL often faces statistical heterogeneity, system heterogeneity and model heterogeneity challenges. These challenging issues inspire the field of Model-Heterogeneous Personalized Federated Learning (MHPFL) which aims to train a personalized and heterogeneous local model for each FL client. Existing MHPFL approaches cannot achieve satisfactory model performance, acceptable computational overhead and efficient communication simultaneously. To bridge this gap, we propose a novel computation- and communication-efficient model-heterogeneous personalized Federated learning framework based on LoRA tuning (FedLoRA). It is designed to incorporate a homogeneous small adapter for each client's heterogeneous local model. Both models are trained following the proposed iterative training for global-local knowledge exchange. The homogeneous small local adapters are sent to the FL server to be aggregated into a global adapter. In this way, FL clients can train heterogeneous local models without incurring high computation and communication costs. We theoretically prove the non-convex convergence rate of FedLoRA. Extensive experiments on two real-world datasets demonstrate that FedLoRA outperforms six state-of-the-art baselines, beating the best approach by 1.35% in terms of test accuracy, 11.81 times computation overhead reduction and 7.41 times communication cost saving.", "url": "https://arxiv.org/abs/2310.13283"}, {"metadata": {"arXiv": "2310.13284", "Date": "Fri, 20 Oct 2023 05:30:30 ", "Title": "Learning Recurrent Models with Temporally Local Rules", "Authors": ["Azwar Abdulsalam and Joseph G. Makin"], "Categories": "cs.LG", "Comments": ["Presented at the \"Localized Learning\" workshop at the International Conference on Machine Learning (ICML)", "July 2023. 6 pages", "5 figures", "2 tables"]}, "abstract": "Fitting generative models to sequential data typically involves two recursive computations through time, one forward and one backward. The latter could be a computation of the loss gradient (as in backpropagation through time), or an inference algorithm (as in the RTS/Kalman smoother). The backward pass in particular is computationally expensive (since it is inherently serial and cannot exploit GPUs), and difficult to map onto biological processes. Work-arounds have been proposed; here we explore a very different one: requiring the generative model to learn the joint distribution over current and previous states, rather than merely the transition probabilities. We show on toy datasets that different architectures employing this principle can learn aspects of the data typically requiring the backward pass.", "url": "https://arxiv.org/abs/2310.13284"}, {"metadata": {"arXiv": "2310.13364", "Date": "Fri, 20 Oct 2023 09:12:10 ", "Title": "Dissecting Causal Biases", "Authors": ["R\\=uta Binkyt\\.e", "Sami Zhioua", "Yassine Turki"], "Categories": "cs.LG"}, "abstract": "Accurately measuring discrimination in machine learning-based automated decision systems is required to address the vital issue of fairness between subpopulations and/or individuals. Any bias in measuring discrimination can lead to either amplification or underestimation of the true value of discrimination. This paper focuses on a class of bias originating in the way training data is generated and/or collected. We call such class causal biases and use tools from the field of causality to formally define and analyze such biases. Four sources of bias are considered, namely, confounding, selection, measurement, and interaction. The main contribution of this paper is to provide, for each source of bias, a closed-form expression in terms of the model parameters. This makes it possible to analyze the behavior of each source of bias, in particular, in which cases they are absent and in which other cases they are maximized. We hope that the provided characterizations help the community better understand the sources of bias in machine learning applications.", "url": "https://arxiv.org/abs/2310.13364"}, {"metadata": {"arXiv": "2310.13369", "Date": "Fri, 20 Oct 2023 09:25:35 ", "Title": "SigFormer: Signature Transformers for Deep Hedging", "Authors": ["Anh Tong and Thanh Nguyen-Tang and Dongeun Lee and Toan Tran and Jaesik Choi"], "Categories": "cs.LG", "Comments": ["ICAIF 2023"], "DOI": "10.1145/3604237.3626841"}, "abstract": "Deep hedging is a promising direction in quantitative finance, incorporating models and techniques from deep learning research. While giving excellent hedging strategies, models inherently requires careful treatment in designing architectures for neural networks. To mitigate such difficulties, we introduce SigFormer, a novel deep learning model that combines the power of path signatures and transformers to handle sequential data, particularly in cases with irregularities. Path signatures effectively capture complex data patterns, while transformers provide superior sequential attention. Our proposed model is empirically compared to existing methods on synthetic data, showcasing faster learning and enhanced robustness, especially in the presence of irregular underlying price data. Additionally, we validate our model performance through a real-world backtest on hedging the SP 500 index, demonstrating positive outcomes.", "url": "https://arxiv.org/abs/2310.13369"}, {"metadata": {"arXiv": "2310.13381", "Date": "Fri, 20 Oct 2023 09:51:42 ", "Title": "Accelerated sparse Kernel Spectral Clustering for large scale data clustering problems", "Authors": ["Mihaly Novak", "Rocco Langone", "Carlos Alzate", "Johan Suykens"], "Categories": "cs.LG"}, "abstract": "An improved version of the sparse multiway kernel spectral clustering (KSC) is presented in this brief. The original algorithm is derived from weighted kernel principal component (KPCA) analysis formulated within the primal-dual least-squares support vector machine (LS-SVM) framework. Sparsity is achieved then by the combination of the incomplete Cholesky decomposition (ICD) based low rank approximation of the kernel matrix with the so called reduced set method. The original ICD based sparse KSC algorithm was reported to be computationally far too demanding, especially when applied on large scale data clustering problems that actually it was designed for, which has prevented to gain more than simply theoretical relevance so far. This is altered by the modifications reported in this brief that drastically improve the computational characteristics. Solving the alternative, symmetrized version of the computationally most demanding core eigenvalue problem eliminates the necessity of forming and SVD of large matrices during the model construction. This results in solving clustering problems now within seconds that were reported to require hours without altering the results. Furthermore, sparsity is also improved significantly, leading to more compact model representation, increasing further not only the computational efficiency but also the descriptive power. These transform the original, only theoretically relevant ICD based sparse KSC algorithm applicable for large scale practical clustering problems. Theoretical results and improvements are demonstrated by computational experiments on carefully selected synthetic data as well as on real life problems such as image segmentation.", "url": "https://arxiv.org/abs/2310.13381"}, {"metadata": {"arXiv": "2310.13384", "Date": "Fri, 20 Oct 2023 09:53:55 ", "Title": "Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing", "Authors": ["Mohammad Malekzadeh and Fahim Kawsar"], "Categories": "cs.LG cs.DC", "Comments": ["6 Pages", "2 Figures"]}, "abstract": "Split inference partitions a deep neural network (DNN) to run the early part at the edge and the later part in the cloud. This meets two key requirements for on-device machine learning: input privacy and compute efficiency. Still, an open question in split inference is output privacy, given that the output of a DNN is visible to the cloud. While encrypted computing can protect output privacy, it mandates extensive computation and communication resources. In this paper, we introduce \"Salted DNNs\": a novel method that lets clients control the semantic interpretation of DNN output at inference time while maintaining accuracy and efficiency very close to that of a standard DNN. Experimental evaluations conducted on both image and sensor data show that Salted DNNs achieve classification accuracy very close to standard DNNs, particularly when the salted layer is positioned within the early part to meet the requirements of split inference. Our method is general and can be applied to various DNNs. We open-source our code and results, as a benchmark for future studies.", "url": "https://arxiv.org/abs/2310.13384"}, {"metadata": {"arXiv": "2310.13397", "Date": "Fri, 20 Oct 2023 10:12:06 ", "Title": "Equivariant Deep Weight Space Alignment", "Authors": ["Aviv Navon", "Aviv Shamsian", "Ethan Fetaya", "Gal Chechik", "Nadav Dym", "Haggai Maron"], "Categories": "cs.LG"}, "abstract": "Permutation symmetries of deep networks make simple operations like model averaging and similarity estimation challenging. In many cases, aligning the weights of the networks, i.e., finding optimal permutations between their weights, is necessary. More generally, weight alignment is essential for a wide range of applications, from model merging, through exploring the optimization landscape of deep neural networks, to defining meaningful distance functions between neural networks. Unfortunately, weight alignment is an NP-hard problem. Prior research has mainly focused on solving relaxed versions of the alignment problem, leading to either time-consuming methods or sub-optimal solutions. To accelerate the alignment process and improve its quality, we propose a novel framework aimed at learning to solve the weight alignment problem, which we name Deep-Align. To that end, we first demonstrate that weight alignment adheres to two fundamental symmetries and then, propose a deep architecture that respects these symmetries. Notably, our framework does not require any labeled data. We provide a theoretical analysis of our approach and evaluate Deep-Align on several types of network architectures and learning setups. Our experimental results indicate that a feed-forward pass with Deep-Align produces better or equivalent alignments compared to those produced by current optimization algorithms. Additionally, our alignments can be used as an initialization for other methods to gain even better solutions with a significant speedup in convergence.", "url": "https://arxiv.org/abs/2310.13397"}, {"metadata": {"arXiv": "2310.13403", "Date": "Fri, 20 Oct 2023 10:21:50 ", "Title": "BRFL: A Blockchain-based Byzantine-Robust Federated Learning Model", "Authors": ["Yang Li", "Chunhe Xia", "Chang Li", "Tianbo Wang"], "Categories": "cs.LG"}, "abstract": "With the increasing importance of machine learning, the privacy and security of training data have become critical. Federated learning, which stores data in distributed nodes and shares only model parameters, has gained significant attention for addressing this concern. However, a challenge arises in federated learning due to the Byzantine Attack Problem, where malicious local models can compromise the global model's performance during aggregation. This article proposes the Blockchain-based Byzantine-Robust Federated Learning (BRLF) model that combines federated learning with blockchain technology. This integration enables traceability of malicious models and provides incentives for locally trained clients. Our approach involves selecting the aggregation node based on Pearson's correlation coefficient, and we perform spectral clustering and calculate the average gradient within each cluster, validating its accuracy using local dataset of the aggregation nodes. Experimental results on public datasets demonstrate the superior byzantine robustness of our secure aggregation algorithm compared to other baseline byzantine robust aggregation methods, and proved our proposed model effectiveness in addressing the resource consumption problem.", "url": "https://arxiv.org/abs/2310.13403"}, {"metadata": {"arXiv": "2310.13433", "Date": "Fri, 20 Oct 2023 11:46:05 ", "Title": "Y-Diagonal Couplings: Approximating Posteriors with Conditional Wasserstein Distances", "Authors": ["Jannis Chemseddine", "Paul Hagemann", "Christian Wald"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["26 pages", "9 figures"]}, "abstract": "In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback Leibler divergence, it does not hold true for the Wasserstein distance. We will introduce a conditional Wasserstein distance with a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. By deriving its dual, we find a rigorous way to motivate the loss of conditional Wasserstein GANs. We outline conditions under which the vanilla and the conditional Wasserstein distance coincide. Furthermore, we will show numerical examples where training with the conditional Wasserstein distance yields favorable properties for posterior sampling.", "url": "https://arxiv.org/abs/2310.13433"}, {"metadata": {"arXiv": "2310.13459", "Date": "Fri, 20 Oct 2023 12:45:12 ", "Title": "Stable Nonconvex-Nonconcave Training via Linear Interpolation", "Authors": ["Thomas Pethick", "Wanyun Xie", "Volkan Cevher"], "Categories": "cs.LG math.OC"}, "abstract": "This paper presents a theoretical analysis of linear interpolation as a principled method for stabilizing (large-scale) neural network training. We argue that instabilities in the optimization process are often caused by the nonmonotonicity of the loss landscape and show how linear interpolation can help by leveraging the theory of nonexpansive operators. We construct a new optimization scheme called relaxed approximate proximal point (RAPP), which is the first explicit method to achieve last iterate convergence rates for the full range of cohypomonotone problems. The construction extends to constrained and regularized settings. By replacing the inner optimizer in RAPP we rediscover the family of Lookahead algorithms for which we establish convergence in cohypomonotone problems even when the base optimizer is taken to be gradient descent ascent. The range of cohypomonotone problems in which Lookahead converges is further expanded by exploiting that Lookahead inherits the properties of the base optimizer. We corroborate the results with experiments on generative adversarial networks which demonstrates the benefits of the linear interpolation present in both RAPP and Lookahead.", "url": "https://arxiv.org/abs/2310.13459"}, {"metadata": {"arXiv": "2310.13490", "Date": "Fri, 20 Oct 2023 13:32:45 ", "Title": "Feature Selection and Hyperparameter Fine-tuning in Artificial Neural Networks for Wood Quality Classification", "Authors": ["Mateus Roder", "Leandro Aparecido Passos", "Jo\\~ao Paulo Papa", "Andr\\'e Luis Debiaso Rossi"], "Categories": "cs.LG", "DOI": "10.1007/978-3-031-45389-2_22"}, "abstract": "Quality classification of wood boards is an essential task in the sawmill industry, which is still usually performed by human operators in small to median companies in developing countries. Machine learning algorithms have been successfully employed to investigate the problem, offering a more affordable alternative compared to other solutions. However, such approaches usually present some drawbacks regarding the proper selection of their hyperparameters. Moreover, the models are susceptible to the features extracted from wood board images, which influence the induction of the model and, consequently, its generalization power. Therefore, in this paper, we investigate the problem of simultaneously tuning the hyperparameters of an artificial neural network (ANN) as well as selecting a subset of characteristics that better describes the wood board quality. Experiments were conducted over a private dataset composed of images obtained from a sawmill industry and described using different feature descriptors. The predictive performance of the model was compared against five baseline methods as well as a random search, performing either ANN hyperparameter tuning and feature selection. Experimental results suggest that hyperparameters should be adjusted according to the feature set, or the features should be selected considering the hyperparameter values. In summary, the best predictive performance, i.e., a balanced accuracy of $0.80$, was achieved in two distinct scenarios: (i) performing only feature selection, and (ii) performing both tasks concomitantly. Thus, we suggest that at least one of the two approaches should be considered in the context of industrial applications.", "url": "https://arxiv.org/abs/2310.13490"}, {"metadata": {"arXiv": "2310.13550", "Date": "Fri, 20 Oct 2023 14:50:28 ", "Title": "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes", "Authors": ["Ruiquan Huang", "Yuan Cheng", "Jing Yang", "Vincent Tan", "Yingbin Liang"], "Categories": "cs.LG stat.ML"}, "abstract": "In multi-task reinforcement learning (RL) under Markov decision processes (MDPs), the presence of shared latent structures among multiple MDPs has been shown to yield significant benefits to the sample efficiency compared to single-task RL. In this paper, we investigate whether such a benefit can extend to more general sequential decision making problems, such as partially observable MDPs (POMDPs) and more general predictive state representations (PSRs). The main challenge here is that the large and complex model space makes it hard to identify what types of common latent structure of multi-task PSRs can reduce the model complexity and improve sample efficiency. To this end, we posit a joint model class for tasks and use the notion of $\\eta$-bracketing number to quantify its complexity; this number also serves as a general metric to capture the similarity of tasks and thus determines the benefit of multi-task over single-task RL. We first study upstream multi-task learning over PSRs, in which all tasks share the same observation and action spaces. We propose a provably efficient algorithm UMT-PSR for finding near-optimal policies for all PSRs, and demonstrate that the advantage of multi-task learning manifests if the joint model class of PSRs has a smaller $\\eta$-bracketing number compared to that of individual single-task learning. We also provide several example multi-task PSRs with small $\\eta$-bracketing numbers, which reap the benefits of multi-task learning. We further investigate downstream learning, in which the agent needs to learn a new target task that shares some commonalities with the upstream tasks via a similarity constraint. By exploiting the learned PSRs from the upstream, we develop a sample-efficient algorithm that provably finds a near-optimal policy.", "url": "https://arxiv.org/abs/2310.13550"}, {"metadata": {"arXiv": "2310.13553", "Date": "Fri, 20 Oct 2023 14:52:25 ", "Title": "On sample complexity of conditional independence testing with Von Mises estimator with application to causal discovery", "Authors": ["Fateme Jamshidi", "Luca Ganassali", "Negar Kiyavash"], "Categories": "cs.LG"}, "abstract": "Motivated by conditional independence testing, an essential step in constraint-based causal discovery algorithms, we study the nonparametric Von Mises estimator for the entropy of multivariate distributions built on a kernel density estimator. We establish an exponential concentration inequality for this estimator. We design a test for conditional independence (CI) based on our estimator, called VM-CI, which achieves optimal parametric rates under smoothness assumptions. Leveraging the exponential concentration, we prove a tight upper bound for the overall error of VM-CI. This, in turn, allows us to characterize the sample complexity of any constraint-based causal discovery algorithm that uses VM-CI for CI tests. To the best of our knowledge, this is the first sample complexity guarantee for causal discovery for continuous variables. Furthermore, we empirically show that VM-CI outperforms other popular CI tests in terms of either time or sample complexity (or both), which translates to a better performance in structure learning as well.", "url": "https://arxiv.org/abs/2310.13553"}, {"metadata": {"arXiv": "2310.13572", "Date": "Fri, 20 Oct 2023 15:10:16 ", "Title": "Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space", "Authors": ["Yufei Gu", "Xiaoqing Zheng", "and Tomaso Aste"], "Categories": "cs.LG"}, "abstract": "Double descent presents a counter-intuitive aspect within the machine learning domain, and researchers have observed its manifestation in various models and tasks. While some theoretical explanations have been proposed for this phenomenon in specific contexts, an accepted theory to account for its occurrence in deep learning remains yet to be established. In this study, we revisit the phenomenon of double descent and demonstrate that its occurrence is strongly influenced by the presence of noisy data. Through conducting a comprehensive analysis of the feature space of learned representations, we unveil that double descent arises in imperfect models trained with noisy data. We argue that double descent is a consequence of the model first learning the noisy data until interpolation and then adding implicit regularization via over-parameterization acquiring therefore capability to separate the information from the noise. We postulate that double descent should never occur in well-regularized models.", "url": "https://arxiv.org/abs/2310.13572"}, {"metadata": {"arXiv": "2310.13607", "Date": "Fri, 20 Oct 2023 15:57:22 ", "Title": "Analyzing the contribution of different passively collected data to predict Stress and Depression", "Authors": ["Irene Bonafonte", "Cristina Bustos", "Abraham Larrazolo", "Gilberto Lorenzo Martinez Luna", "Adolfo Guzman Arenas", "Xavier Baro", "Isaac Tourgeman", "Mercedes Balcells and Agata Lapedriza"], "Categories": "cs.LG"}, "abstract": "The possibility of recognizing diverse aspects of human behavior and environmental context from passively captured data motivates its use for mental health assessment. In this paper, we analyze the contribution of different passively collected sensor data types (WiFi, GPS, Social interaction, Phone Log, Physical Activity, Audio, and Academic features) to predict daily selfreport stress and PHQ-9 depression score. First, we compute 125 mid-level features from the original raw data. These 125 features include groups of features from the different sensor data types. Then, we evaluate the contribution of each feature type by comparing the performance of Neural Network models trained with all features against Neural Network models trained with specific feature groups. Our results show that WiFi features (which encode mobility patterns) and Phone Log features (which encode information correlated with sleep patterns), provide significative information for stress and depression prediction.", "url": "https://arxiv.org/abs/2310.13607"}, {"metadata": {"arXiv": "2310.13683", "Date": "Fri, 20 Oct 2023 17:44:25 ", "Title": "CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages", "Authors": ["Gabriel Oliveira dos Santos", "Diego Alysson Moreia", "Alef Iury Ferreira", "Jhessica Silva", "Luiz Pereira", "Pedro Bueno", "Thiago Sousa", "Helena Maia", "N\\'adia Da Silva", "Esther Colombini", "Helio Pedrini and Sandra Avila"], "Categories": "cs.LG"}, "abstract": "This work introduces CAPIVARA, a cost-efficient framework designed to enhance the performance of multilingual CLIP models in low-resource languages. While CLIP has excelled in zero-shot vision-language tasks, the resource-intensive nature of model training remains challenging. Many datasets lack linguistic diversity, featuring solely English descriptions for images. CAPIVARA addresses this by augmenting text data using image captioning and machine translation to generate multiple synthetic captions in low-resource languages. We optimize the training pipeline with LiT, LoRA, and gradient checkpointing to alleviate the computational cost. Through extensive experiments, CAPIVARA emerges as state of the art in zero-shot tasks involving images and Portuguese texts. We show the potential for significant improvements in other low-resource languages, achieved by fine-tuning the pre-trained multilingual CLIP using CAPIVARA on a single GPU for 2 hours. Our model and code is available at https://github.com/hiaac-nlp/CAPIVARA.", "url": "https://arxiv.org/abs/2310.13683"}, {"metadata": {"arXiv": "2310.13083", "Date": "Thu, 19 Oct 2023 18:21:39 ", "Title": "How Can Everyday Users Efficiently Teach Robots by Demonstrations?", "Authors": ["Maram Sakr", "Zhikai Zhang", "Benjamin Li", "Haomiao Zhang", "H.F. Machiel Van der Loos", "Dana Kulic and Elizabeth Croft"], "Categories": "cs.RO cs.LG"}, "abstract": "Learning from Demonstration (LfD) is a framework that allows lay users to easily program robots. However, the efficiency of robot learning and the robot's ability to generalize to task variations hinges upon the quality and quantity of the provided demonstrations. Our objective is to guide human teachers to furnish more effective demonstrations, thus facilitating efficient robot learning. To achieve this, we propose to use a measure of uncertainty, namely task-related information entropy, as a criterion for suggesting informative demonstration examples to human teachers to improve their teaching skills. In a conducted experiment (N=24), an augmented reality (AR)-based guidance system was employed to train novice users to produce additional demonstrations from areas with the highest entropy within the workspace. These novice users were trained for a few trials to teach the robot a generalizable task using a limited number of demonstrations. Subsequently, the users' performance after training was assessed first on the same task (retention) and then on a novel task (transfer) without guidance. The results indicated a substantial improvement in robot learning efficiency from the teacher's demonstrations, with an improvement of up to 198% observed on the novel task. Furthermore, the proposed approach was compared to a state-of-the-art heuristic rule and found to improve robot learning efficiency by 210% compared to the heuristic rule.", "url": "https://arxiv.org/abs/2310.13083"}, {"metadata": {"arXiv": "2310.13396", "Date": "Fri, 20 Oct 2023 10:06:03 ", "Title": "RL-X: A Deep Reinforcement Learning Library (not only) for RoboCup", "Authors": ["Nico Bohlinger and Klaus Dorer"], "Categories": "cs.RO cs.LG"}, "abstract": "This paper presents the new Deep Reinforcement Learning (DRL) library RL-X and its application to the RoboCup Soccer Simulation 3D League and classic DRL benchmarks. RL-X provides a flexible and easy-to-extend codebase with self-contained single directory algorithms. Through the fast JAX-based implementations, RL-X can reach up to 4.5x speedups compared to well-known frameworks like Stable-Baselines3.", "url": "https://arxiv.org/abs/2310.13396"}, {"metadata": {"arXiv": "2310.13458", "Date": "Fri, 20 Oct 2023 12:42:06 ", "Title": "Correspondence learning between morphologically different robots through task demonstrations", "Authors": ["Hakan Aktas", "Yukie Nagai", "Minoru Asada", "Erhan Oztop", "Emre Ugur"], "Categories": "cs.RO cs.LG", "Comments": ["7 pages", "11 figures", "Submitted to IEEE Robotics Automation Letters (RA-L)"]}, "abstract": "We observe a large variety of robots in terms of their bodies, sensors, and actuators. Given the commonalities in the skill sets, teaching each skill to each different robot independently is inefficient and not scalable when the large variety in the robotic landscape is considered. If we can learn the correspondences between the sensorimotor spaces of different robots, we can expect a skill that is learned in one robot can be more directly and easily transferred to the other robots. In this paper, we propose a method to learn correspondences between robots that have significant differences in their morphologies: a fixed-based manipulator robot with joint control and a differential drive mobile robot. For this, both robots are first given demonstrations that achieve the same tasks. A common latent representation is formed while learning the corresponding policies. After this initial learning stage, the observation of a new task execution by one robot becomes sufficient to generate a latent space representation pertaining to the other robot to achieve the same task. We verified our system in a set of experiments where the correspondence between two simulated robots is learned (1) when the robots need to follow the same paths to achieve the same task, (2) when the robots need to follow different trajectories to achieve the same task, and (3) when complexities of the required sensorimotor trajectories are different for the robots considered. We also provide a proof-of-the-concept realization of correspondence learning between a real manipulator robot and a simulated mobile robot.", "url": "https://arxiv.org/abs/2310.13458"}, {"metadata": {"arXiv": "2310.13007", "Date": "Sun, 15 Oct 2023 08:17:45 ", "Title": "A Critical Survey on Fairness Benefits of XAI", "Authors": ["Luca Deck", "Jakob Schoeffer", "Maria De-Arteaga", "Niklas K\\\"uhl"], "Categories": "cs.AI"}, "abstract": "In this critical survey, we analyze typical claims on the relationship between explainable AI (XAI) and fairness to disentangle the multidimensional relationship between these two concepts. Based on a systematic literature review and a subsequent qualitative content analysis, we identify seven archetypal claims from 175 papers on the alleged fairness benefits of XAI. We present crucial caveats with respect to these claims and provide an entry point for future discussions around the potentials and limitations of XAI for specific fairness desiderata. While the literature often suggests XAI to be an enabler for several fairness desiderata, we notice a misalignment between these desiderata and the capabilities of XAI. We encourage to conceive XAI as one of many tools to approach the multidimensional, sociotechnical challenge of algorithmic fairness and to be more specific about how exactly what kind of XAI method enables whom to address which fairness desideratum.", "url": "https://arxiv.org/abs/2310.13007"}, {"metadata": {"arXiv": "2310.13192", "Date": "Thu, 19 Oct 2023 23:02:46 ", "Title": "The opaque law of artificial intelligence", "Authors": ["Vincenzo Calderonio"], "Categories": "cs.AI", "Comments": ["17 pages", "7 figures"], "ACM-class": "F.0; I.2; J.4; K.4; K.5"}, "abstract": "The purpose of this paper is to analyse the opacity of algorithms, contextualized in the open debate on responsibility for artificial intelligence causation; with an experimental approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative AI (Chat-GPT) to see how far it can go right now and how the shape of a legal regulation of it could be. The analysis of the problem will be supported by a comment of Italian classical law categories such as causality, intent and fault to understand the problem of the usage of AI, focusing in particular on the human-machine interaction. On the computer science side, for a technical point of view of the logic used to craft these algorithms, in the second chapter will be proposed a practical interrogation of Chat-GPT aimed at finding some critical points of the functioning of AI. The end of the paper will concentrate on some existing legal solutions which can be applied to the problem, plus a brief description of the approach proposed by EU Artificial Intelligence act.", "url": "https://arxiv.org/abs/2310.13192"}, {"metadata": {"arXiv": "2310.13691", "Date": "Fri, 20 Oct 2023 17:52:48 ", "Title": "Neural-Base Music Generation for Intelligence Duplication", "Authors": ["Jacob Galajda", "Kien Hua"], "Categories": "cs.AI cs.MM"}, "abstract": "There are two aspects of machine learning and artificial intelligence: (1) interpreting information, and (2) inventing new useful information. Much advance has been made for (1) with a focus on pattern recognition techniques (e.g., interpreting visual data). This paper focuses on (2) with intelligent duplication (ID) for invention. We explore the possibility of learning a specific individual's creative reasoning in order to leverage the learned expertise and talent to invent new information. More specifically, we employ a deep learning system to learn from the great composer Beethoven and capture his composition ability in a hash-based knowledge base. This new form of knowledge base provides a reasoning facility to drive the music composition through a novel music generation method.", "url": "https://arxiv.org/abs/2310.13691"}, {"metadata": {"arXiv": "2310.12985", "Date": "Thu, 07 Sep 2023 15:48:00 ", "Title": "Enabling energy-Efficient object detection with surrogate gradient descent in spiking neural networks", "Authors": ["Jilong Luo", "Shanlin Xiao", "Yinsheng Chen", "Zhiyi Yu"], "Categories": "cs.CV cs.AI"}, "abstract": "Spiking Neural Networks (SNNs) are a biologically plausible neural network model with significant advantages in both event-driven processing and spatio-temporal information processing, rendering SNNs an appealing choice for energyefficient object detection. However, the non-differentiability of the biological neuronal dynamics model presents a challenge during the training of SNNs. Furthermore, a suitable decoding strategy for object detection in SNNs is currently lacking. In this study, we introduce the Current Mean Decoding (CMD) method, which solves the regression problem to facilitate the training of deep SNNs for object detection tasks. Based on the gradient surrogate and CMD, we propose the SNN-YOLOv3 model for object detection. Our experiments demonstrate that SNN-YOLOv3 achieves a remarkable performance with an mAP of 61.87% on the PASCAL VOC dataset, requiring only 6 time steps. Compared to SpikingYOLO, we have managed to increase mAP by nearly 10% while reducing energy consumption by two orders of magnitude.", "url": "https://arxiv.org/abs/2310.12985"}, {"metadata": {"arXiv": "2310.12995", "Date": "Wed, 04 Oct 2023 20:30:49 ", "Title": "Comprehensive Multimodal Segmentation in Medical Imaging: Combining YOLOv8 with SAM and HQ-SAM Models", "Authors": ["Sumit Pandey", "Kuan-Fu Chen", "Erik B. Dam"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper introduces a comprehensive approach for segmenting regions of interest (ROI) in diverse medical imaging datasets, encompassing ultrasound, CT scans, and X-ray images. The proposed method harnesses the capabilities of the YOLOv8 model for approximate boundary box detection across modalities, alongside the Segment Anything Model (SAM) and High Quality (HQ) SAM for fully automatic and precise segmentation. To generate boundary boxes, the YOLOv8 model was trained using a limited set of 100 images and masks from each modality. The results obtained from our approach are extensively computed and analyzed, demonstrating its effectiveness and potential in medical image analysis. Various evaluation metrics, including precision, recall, F1 score, and Dice Score, were employed to quantify the accuracy of the segmentation results. A comparative analysis was conducted to assess the individual and combined performance of the YOLOv8, YOLOv8+SAM, and YOLOv8+HQ-SAM models. The results indicate that the SAM model performs better than the other two models, exhibiting higher segmentation accuracy and overall performance. While HQ-SAM offers potential advantages, its incremental gains over the standard SAM model may not justify the additional computational cost. The YOLOv8+SAM model shows promise for enhancing medical image segmentation and its clinical implications.", "url": "https://arxiv.org/abs/2310.12995"}, {"metadata": {"arXiv": "2310.12997", "Date": "Thu, 05 Oct 2023 07:15:04 ", "Title": "Parking Spot Classification based on surround view camera system", "Authors": ["Andy Xiao", "Deep Doshi", "Lihao Wang", "Harsha Gorantla", "Thomas Heitzmann", "and Peter Groth"], "Categories": "cs.CV cs.AI", "Comments": ["SPIE Optical Engineering + Applications", "2023", "San Diego", "California", "United States. Proc. SPIE 12675", "Applications of Machine Learning 2023"], "DOI": "10.1117/12.2677526"}, "abstract": "Surround-view fisheye cameras are commonly used for near-field sensing in automated driving scenarios, including urban driving and auto valet parking. Four fisheye cameras, one on each side, are sufficient to cover 360{\\deg} around the vehicle capturing the entire near-field region. Based on surround view cameras, there has been much research on parking slot detection with main focus on the occupancy status in recent years, but little work on whether the free slot is compatible with the mission of the ego vehicle or not. For instance, some spots are handicap or electric vehicles accessible only. In this paper, we tackle parking spot classification based on the surround view camera system. We adapt the object detection neural network YOLOv4 with a novel polygon bounding box model that is well-suited for various shaped parking spaces, such as slanted parking slots. To the best of our knowledge, we present the first detailed study on parking spot detection and classification on fisheye cameras for auto valet parking scenarios. The results prove that our proposed classification approach is effective to distinguish between regular, electric vehicle, and handicap parking spots.", "url": "https://arxiv.org/abs/2310.12997"}, {"metadata": {"arXiv": "2310.13336", "Date": "Fri, 20 Oct 2023 07:55:12 ", "Title": "FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From Multi-Source Optical Imagery", "Authors": ["Anatol Garioud", "Nicolas Gonthier", "Loic Landrieu", "Apolline De Wit", "Marion Valette", "Marc Poup\\'ee", "S\\'ebastien Giordano", "Boris Wattrelos"], "Categories": "cs.CV cs.AI", "Comments": ["NeurIPS 2023 - Datasets & Benchmarks Track"]}, "abstract": "We introduce the French Land cover from Aerospace ImageRy (FLAIR), an extensive dataset from the French National Institute of Geographical and Forest Information (IGN) that provides a unique and rich resource for large-scale geospatial analysis. FLAIR contains high-resolution aerial imagery with a ground sample distance of 20 cm and over 20 billion individually labeled pixels for precise land-cover classification. The dataset also integrates temporal and spectral data from optical satellite time series. FLAIR thus combines data with varying spatial, spectral, and temporal resolutions across over 817 km2 of acquisitions representing the full landscape diversity of France. This diversity makes FLAIR a valuable resource for the development and evaluation of novel methods for large-scale land-cover semantic segmentation and raises significant challenges in terms of computer vision, data fusion, and geospatial analysis. We also provide powerful uni- and multi-sensor baseline models that can be employed to assess algorithm's performance and for downstream applications. Through its extent and the quality of its annotation, FLAIR aims to spur improvements in monitoring and understanding key anthropogenic development indicators such as urban growth, deforestation, and soil artificialization. Dataset and codes can be accessed at https://ignf.github.io/FLAIR/", "url": "https://arxiv.org/abs/2310.13336"}, {"metadata": {"arXiv": "2310.13347", "Date": "Fri, 20 Oct 2023 08:22:56 ", "Title": "NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding", "Authors": ["Ming Hu", "Lin Wang", "Siyuan Yan", "Don Ma", "Qingli Ren", "Peng Xia", "Wei Feng", "Peibo Duan", "Lie Ju", "Zongyuan Ge"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by NeurIPS 2023 Datasets and Benchmarks Track"]}, "abstract": "The application of deep learning to nursing procedure activity understanding has the potential to greatly enhance the quality and safety of nurse-patient interactions. By utilizing the technique, we can facilitate training and education, improve quality control, and enable operational compliance monitoring. However, the development of automatic recognition systems in this field is currently hindered by the scarcity of appropriately labeled datasets. The existing video datasets pose several limitations: 1) these datasets are small-scale in size to support comprehensive investigations of nursing activity; 2) they primarily focus on single procedures, lacking expert-level annotations for various nursing procedures and action steps; and 3) they lack temporally localized annotations, which prevents the effective localization of targeted actions within longer video sequences. To mitigate these limitations, we propose NurViD, a large video dataset with expert-level annotation for nursing procedure activity understanding. NurViD consists of over 1.5k videos totaling 144 hours, making it approximately four times longer than the existing largest nursing activity datasets. Notably, it encompasses 51 distinct nursing procedures and 177 action steps, providing a much more comprehensive coverage compared to existing datasets that primarily focus on limited procedures. To evaluate the efficacy of current deep learning methods on nursing activity understanding, we establish three benchmarks on NurViD: procedure recognition on untrimmed videos, procedure and action recognition on trimmed videos, and action detection. Our benchmark and code will be available at \\url{https://github.com/minghu0830/NurViD-benchmark}.", "url": "https://arxiv.org/abs/2310.13347"}, {"metadata": {"arXiv": "2310.13361", "Date": "Fri, 20 Oct 2023 09:06:30 ", "Title": "Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation", "Authors": ["Wenyu Guo", "Qingkai Fang", "Dong Yu", "Yang Feng"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Accepted to EMNLP 2023 main conference"]}, "abstract": "Multimodal machine translation (MMT) simultaneously takes the source sentence and a relevant image as input for translation. Since there is no paired image available for the input sentence in most cases, recent studies suggest utilizing powerful text-to-image generation models to provide image inputs. Nevertheless, synthetic images generated by these models often follow different distributions compared to authentic images. Consequently, using authentic images for training and synthetic images for inference can introduce a distribution shift, resulting in performance degradation during inference. To tackle this challenge, in this paper, we feed synthetic and authentic images to the MMT model, respectively. Then we minimize the gap between the synthetic and authentic images by drawing close the input image representations of the Transformer Encoder and the output distributions of the Transformer Decoder. Therefore, we mitigate the distribution disparity introduced by the synthetic images during inference, thereby freeing the authentic images from the inference process.Experimental results show that our approach achieves state-of-the-art performance on the Multi30K En-De and En-Fr datasets, while remaining independent of authentic images during inference.", "url": "https://arxiv.org/abs/2310.13361"}, {"metadata": {"arXiv": "2310.13447", "Date": "Fri, 20 Oct 2023 12:26:04 ", "Title": "Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation", "Authors": ["Siyu Zhang", "Yeming Chen", "Sirui Cheng", "Yaoru Sun", "Jun Yang", "Lizhi Bai"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of constituent visual patterns, and captures multiscale features by progressively merging adjacent superpixels as graph nodes. Moreover, we predict the differences between adjacent nodes through the graph structure, facilitating key information aggregation of graph nodes to reason actual semantic relations. Afterward, we design a multi-level fusion rule in a bottom-up manner to avoid understanding deviation by learning complementary spatial information at different regional scales. Our proposed method can be well applied to multiple downstream task learning. Extensive experiments demonstrate that our method is competitive with other state-of-the-art methods in visual reasoning. Our code will be released upon publication.", "url": "https://arxiv.org/abs/2310.13447"}, {"metadata": {"arXiv": "2310.13483", "Date": "Fri, 20 Oct 2023 13:23:09 ", "Title": "Application of deep learning for livestock behaviour recognition: A systematic literature review", "Authors": ["Ali Rohan", "Muhammad Saad Rafaq", "Md. Junayed Hasan", "Furqan Asghar", "Ali Kashif Bashir", "Tania Dottorini"], "Categories": "cs.CV cs.AI"}, "abstract": "Livestock health and welfare monitoring has traditionally been a labor-intensive task performed manually. Recent advances have led to the adoption of AI and computer vision techniques, particularly deep learning models, as decision-making tools within the livestock industry. These models have been employed for tasks like animal identification, tracking, body part recognition, and species classification. In the past decade, there has been a growing interest in using these models to explore the connection between livestock behaviour and health issues. While previous review studies have been rather generic, there is currently no review study specifically focusing on DL for livestock behaviour recognition. Hence, this systematic literature review (SLR) was conducted. The SLR involved an initial search across electronic databases, resulting in 1101 publications. After applying defined selection criteria, 126 publications were shortlisted. These publications were further filtered based on quality criteria, resulting in the selection of 44 high-quality primary studies. These studies were analysed to address the research questions. The results showed that DL successfully addressed 13 behaviour recognition problems encompassing 44 different behaviour classes. A variety of DL models and networks were employed, with CNN, Faster R-CNN, YOLOv5, and YOLOv4 being among the most common models, and VGG16, CSPDarknet53, GoogLeNet, ResNet101, and ResNet50 being popular networks. Performance evaluation involved ten different matrices, with precision and accuracy being the most frequently used. Primary studies identified challenges, including occlusion, adhesion, data imbalance, and the complexities of the livestock environment. The SLR study also discussed potential solutions and research directions to facilitate the development of autonomous livestock behaviour recognition systems.", "url": "https://arxiv.org/abs/2310.13483"}, {"metadata": {"arXiv": "2310.13515", "Date": "Fri, 20 Oct 2023 13:58:31 ", "Title": "RaceLens: A Machine Intelligence-Based Application for Racing Photo Analysis", "Authors": ["Andrei Boiarov", "Dmitry Bleklov", "Pavlo Bredikhin", "Nikita Koritsky and Sergey Ulasen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ISACE 2023 Workshop"]}, "abstract": "This paper presents RaceLens, a novel application utilizing advanced deep learning and computer vision models for comprehensive analysis of racing photos. The developed models have demonstrated their efficiency in a wide array of tasks, including detecting racing cars, recognizing car numbers, detecting and quantifying car details, and recognizing car orientations. We discuss the process of collecting a robust dataset necessary for training our models, and describe an approach we have designed to augment and improve this dataset continually. Our method leverages a feedback loop for continuous model improvement, thus enhancing the performance and accuracy of RaceLens over time. A significant part of our study is dedicated to illustrating the practical application of RaceLens, focusing on its successful deployment by NASCAR teams over four seasons. We provide a comprehensive evaluation of our system's performance and its direct impact on the team's strategic decisions and performance metrics. The results underscore the transformative potential of machine intelligence in the competitive and dynamic world of car racing, setting a precedent for future applications.", "url": "https://arxiv.org/abs/2310.13515"}, {"metadata": {"arXiv": "2310.13545", "Date": "Fri, 20 Oct 2023 14:45:52 ", "Title": "ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection", "Authors": ["Zhongzhan Huang", "Pan Zhou", "Shuicheng Yan", "Liang Lin"], "Categories": "cs.CV cs.AI", "Comments": ["accepted by NeurIPS 2023"]}, "abstract": "In diffusion models, UNet is the most popular network backbone, since its long skip connects (LSCs) to connect distant network blocks can aggregate long-distant information and alleviate vanishing gradient. Unfortunately, UNet often suffers from unstable training in diffusion models which can be alleviated by scaling its LSC coefficients smaller. However, theoretical understandings of the instability of UNet in diffusion models and also the performance improvement of LSC scaling remain absent yet. To solve this issue, we theoretically show that the coefficients of LSCs in UNet have big effects on the stableness of the forward and backward propagation and robustness of UNet. Specifically, the hidden feature and gradient of UNet at any layer can oscillate and their oscillation ranges are actually large which explains the instability of UNet training. Moreover, UNet is also provably sensitive to perturbed input, and predicts an output distant from the desired output, yielding oscillatory loss and thus oscillatory gradient. Besides, we also observe the theoretical benefits of the LSC coefficient scaling of UNet in the stableness of hidden features and gradient and also robustness. Finally, inspired by our theory, we propose an effective coefficient scaling framework ScaleLong that scales the coefficients of LSC in UNet and better improves the training stability of UNet. Experimental results on four famous datasets show that our methods are superior to stabilize training and yield about 1.5x training acceleration on different diffusion models with UNet or UViT backbones. Code: https://github.com/sail-sg/ScaleLong", "url": "https://arxiv.org/abs/2310.13545"}, {"metadata": {"arXiv": "2310.13573", "Date": "Fri, 20 Oct 2023 15:10:46 ", "Title": "Boosting Generalization with Adaptive Style Techniques for Fingerprint Liveness Detection", "Authors": ["Kexin Zhu", "Bo Lin", "Yang Qiu", "Adam Yule", "Yao Tang", "Jiajun Liang"], "Categories": "cs.CV cs.AI"}, "abstract": "We introduce a high-performance fingerprint liveness feature extraction technique that secured first place in LivDet 2023 Fingerprint Representation Challenge. Additionally, we developed a practical fingerprint recognition system with 94.68% accuracy, earning second place in LivDet 2023 Liveness Detection in Action. By investigating various methods, particularly style transfer, we demonstrate improvements in accuracy and generalization when faced with limited training data. As a result, our approach achieved state-of-the-art performance in LivDet 2023 Challenges.", "url": "https://arxiv.org/abs/2310.13573"}, {"metadata": {"arXiv": "2310.13295", "Date": "Fri, 20 Oct 2023 05:55:13 ", "Title": "PathRL: An End-to-End Path Generation Method for Collision Avoidance via Deep Reinforcement Learning", "Authors": ["Wenhao Yu", "Jie Peng", "Quecheng Qiu", "Hanyu Wang", "Lu Zhang and Jianmin Ji"], "Categories": "cs.RO cs.AI"}, "abstract": "Robot navigation using deep reinforcement learning (DRL) has shown great potential in improving the performance of mobile robots. Nevertheless, most existing DRL-based navigation methods primarily focus on training a policy that directly commands the robot with low-level controls, like linear and angular velocities, which leads to unstable speeds and unsmooth trajectories of the robot during the long-term execution. An alternative method is to train a DRL policy that outputs the navigation path directly. However, two roadblocks arise for training a DRL policy that outputs paths: (1) The action space for potential paths often involves higher dimensions comparing to low-level commands, which increases the difficulties of training; (2) It takes multiple time steps to track a path instead of a single time step, which requires the path to predicate the interactions of the robot w.r.t. the dynamic environment in multiple time steps. This, in turn, amplifies the challenges associated with training. In response to these challenges, we propose PathRL, a novel DRL method that trains the policy to generate the navigation path for the robot. Specifically, we employ specific action space discretization techniques and tailored state space representation methods to address the associated challenges. In our experiments, PathRL achieves better success rates and reduces angular rotation variability compared to other DRL navigation methods, facilitating stable and smooth robot movement. We demonstrate the competitive edge of PathRL in both real-world scenarios and multiple challenging simulation environments.", "url": "https://arxiv.org/abs/2310.13295"}, {"metadata": {"arXiv": "2310.13377", "Date": "Fri, 20 Oct 2023 09:41:31 ", "Title": "A Human-Robot Mutual Learning System with Affect-Grounded Language Acquisition and Differential Outcomes Training", "Authors": ["Alva Markelius", "Sofia Sj\\\"oberg", "Zakaria Lemhauori", "Laura Cohen", "Martin Bergstr\\\"om", "Robert Lowe", "and Lola Ca\\~namero"], "Categories": "cs.RO cs.AI cs.CL cs.HC", "Comments": ["Preprint: This is the submitted version of a paper to be presented at The Proceedings of the 15th International Conference on Social Robotics (ICSR 2023). Please cite the official publication once it is available"], "ACM-class": "I.2.9; I.2.6; I.2.10"}, "abstract": "This paper presents a novel human-robot interaction setup for robot and human learning of symbolic language for identifying robot homeostatic needs. The robot and human learn to use and respond to the same language symbols that convey homeostatic needs and the stimuli that satisfy the homeostatic needs, respectively. We adopted a differential outcomes training (DOT) protocol whereby the robot provides feedback specific (differential) to its internal needs (e.g. `hunger') when satisfied by the correct stimulus (e.g. cookie). We found evidence that DOT can enhance the human's learning efficiency, which in turn enables more efficient robot language acquisition. The robot used in the study has a vocabulary similar to that of a human infant in the linguistic ``babbling'' phase. The robot software architecture is built upon a model for affect-grounded language acquisition where the robot associates vocabulary with internal needs (hunger, thirst, curiosity) through interactions with the human. The paper presents the results of an initial pilot study conducted with the interactive setup, which reveal that the robot's language acquisition achieves higher convergence rate in the DOT condition compared to the non-DOT control condition. Additionally, participants reported positive affective experiences, feeling of being in control, and an empathetic connection with the robot. This mutual learning (teacher-student learning) approach offers a potential contribution of facilitating cognitive interventions with DOT (e.g. for people with dementia) through increased therapy adherence as a result of engaging humans more in training tasks by taking an active teaching-learning role. The homeostatic motivational grounding of the robot's language acquisition has potential to contribute to more ecologically valid and social (collaborative/nurturing) interactions with robots.", "url": "https://arxiv.org/abs/2310.13377"}, {"metadata": {"arXiv": "2310.13019", "Date": "Wed, 18 Oct 2023 18:50:39 ", "Title": "Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm", "Authors": ["S. M. Fazle Rabby Labib", "Joyanta Jyoti Mondal", "Meem Arafat Manab"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "3 figures", "to be submitted at IEEE Computer Vision and Pattern Recognition (CVPR) 2024"]}, "abstract": "Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across different deep neural network architectures while preserving image integrity as much as possible. Results show that one of the deep convolutional neural network architectures, AlexNet, and one of the state-of-the-art model Vision Transformer exhibit high robustness to getting fooled. Our code will be made public when publishing the paper.", "url": "https://arxiv.org/abs/2310.13019"}, {"metadata": {"arXiv": "2310.13103", "Date": "Thu, 19 Oct 2023 19:01:26 ", "Title": "AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting Multiple Experts for Video Deepfake Detection", "Authors": ["Ammarah Hashmi", "Sahibzada Adil Shahzad", "Chia-Wen Lin", "Yu Tsao", "Hsin-Min Wang"], "Categories": "cs.CV cs.AI cs.LG cs.MM cs.SD eess.AS"}, "abstract": "Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulation and visual manipulation to achieve effective video forgery detection. Specifically, the proposed model integrates several purely transformer-based variants that capture video, audio, and audio-visual salient cues to reach a consensus in prediction. For evaluation, we use the recently released benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed analysis, we evaluate AVTENet, its variants, and several existing methods on multiple test sets of the FakeAVCeleb dataset. Experimental results show that our best model outperforms all existing methods and achieves state-of-the-art performance on Testset-I and Testset-II of the FakeAVCeleb dataset.", "url": "https://arxiv.org/abs/2310.13103"}, {"metadata": {"arXiv": "2310.13157", "Date": "Thu, 19 Oct 2023 21:10:39 ", "Title": "Conditional Generative Modeling for Images, 3D Animations, and Video", "Authors": ["Vikram Voleti"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Doctoral thesis", "Mila", "University of Montreal. 189 pages"]}, "abstract": "This dissertation attempts to drive innovation in the field of generative modeling for computer vision, by exploring novel formulations of conditional generative models, and innovative applications in images, 3D animations, and video. Our research focuses on architectures that offer reversible transformations of noise and visual data, and the application of encoder-decoder architectures for generative tasks and 3D content manipulation. In all instances, we incorporate conditional information to enhance the synthesis of visual data, improving the efficiency of the generation process as well as the generated content. We introduce the use of Neural ODEs to model video dynamics using an encoder-decoder architecture, demonstrating their ability to predict future video frames despite being trained solely to reconstruct current frames. Next, we propose a conditional variant of continuous normalizing flows that enables higher-resolution image generation based on lower-resolution input, achieving comparable image quality while reducing parameters and training time. Our next contribution presents a pipeline that takes human images as input, automatically aligns a user-specified 3D character with the pose of the human, and facilitates pose editing based on partial inputs. Next, we derive the relevant mathematical details for denoising diffusion models that use non-isotropic Gaussian processes, and show comparable generation quality. Finally, we devise a novel denoising diffusion framework capable of solving all three video tasks of prediction, generation, and interpolation. We perform ablation studies, and show SOTA results on multiple datasets. Our contributions are published articles at peer-reviewed venues. Overall, our research aims to make a meaningful contribution to the pursuit of more efficient and flexible generative models, with the potential to shape the future of computer vision.", "url": "https://arxiv.org/abs/2310.13157"}, {"metadata": {"arXiv": "2310.13165", "Date": "Thu, 19 Oct 2023 21:32:21 ", "Title": "CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation", "Authors": ["Sihan Xu", "Ziqiao Ma", "Yidong Huang", "Honglak Lee", "Joyce Chai"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual prompt. Cyclenet is a practical framework, which is robust even with very limited training data (around 2k) and requires minimal computational resources (1 GPU) to train. Project homepage: https://cyclenetweb.github.io/", "url": "https://arxiv.org/abs/2310.13165"}, {"metadata": {"arXiv": "2310.13533", "Date": "Fri, 20 Oct 2023 14:20:21 ", "Title": "Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation", "Authors": ["Damian S\\'ojka", "Yuyang Liu", "Dipam Goswami", "Sebastian Cygert", "Bart{\\l}omiej Twardowski", "Joost van de Weijer"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT dataset, in which there are only six sequences that start and end with the source domain. We conduct an analysis specifically on those sequences. Ground truth data for test split, on which the developed TTA methods are evaluated for leader board ranking, are not publicly available. The proposed solution secured a 3rd place in a challenge and received an innovation award. Contrary to the solutions that scored better, we did not use any external pretrained models or specialized data augmentations, to keep the solutions as general as possible. We have focused on analyzing the distributional shift and developing a method that could adapt to changing data dynamics and generalize across different scenarios.", "url": "https://arxiv.org/abs/2310.13533"}, {"metadata": {"arXiv": "2310.13670", "Date": "Fri, 20 Oct 2023 17:13:52 ", "Title": "ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot Neural Radiance Fields", "Authors": ["Daiju Kanaoka", "Motoharu Sonogashira", "Hakaru Tamukoh", "Yasutomo Kawanishi"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["Accepted by BMVC2023"]}, "abstract": "Novel view synthesis has recently made significant progress with the advent of Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims to achieve this task from only a few images by introducing a new loss function for unknown viewpoints with no input images. The loss function assumes that a pre-trained feature extractor should output the same feature even if input images are captured at different viewpoints since the images contain the same object. However, while that assumption is ideal, in reality, it is known that as viewpoints continuously change, also feature vectors continuously change. Thus, the assumption can harm training. To avoid this harmful training, we propose ManifoldNeRF, a method for supervising feature vectors at unknown viewpoints using interpolated features from neighboring known viewpoints. Since the method provides appropriate supervision for each unknown viewpoint by the interpolated features, the volume representation is learned better than DietNeRF. Experimental results show that the proposed method performs better than others in a complex scene. We also experimented with several subsets of viewpoints from a set of viewpoints and identified an effective set of viewpoints for real environments. This provided a basic policy of viewpoint patterns for real-world application. The code is available at https://github.com/haganelego/ManifoldNeRF_BMVC2023", "url": "https://arxiv.org/abs/2310.13670"}, {"metadata": {"arXiv": "2310.13004", "Date": "Fri, 13 Oct 2023 07:52:04 ", "Title": "Progressively Efficient Learning", "Authors": ["Ruijie Zheng", "Khanh Nguyen", "Hal Daum\\'e III", "Furong Huang", "Karthik Narasimhan"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "Assistant AI agents should be capable of rapidly acquiring novel skills and adapting to new user preferences. Traditional frameworks like imitation learning and reinforcement learning do not facilitate this capability because they support only low-level, inefficient forms of communication. In contrast, humans communicate with progressive efficiency by defining and sharing abstract intentions. Reproducing similar capability in AI agents, we develop a novel learning framework named Communication-Efficient Interactive Learning (CEIL). By equipping a learning agent with an abstract, dynamic language and an intrinsic motivation to learn with minimal communication effort, CEIL leads to emergence of a human-like pattern where the learner and the teacher communicate progressively efficiently by exchanging increasingly more abstract intentions. CEIL demonstrates impressive performance and communication efficiency on a 2D MineCraft domain featuring long-horizon decision-making tasks. Agents trained with CEIL quickly master new tasks, outperforming non-hierarchical and hierarchical imitation learning by up to 50% and 20% in absolute success rate, respectively, given the same number of interactions with the teacher. Especially, the framework performs robustly with teachers modeled after human pragmatic communication behavior.", "url": "https://arxiv.org/abs/2310.13004"}, {"metadata": {"arXiv": "2310.13008", "Date": "Mon, 16 Oct 2023 07:26:24 ", "Title": "LoBaSS: Gauging Learnability in Supervised Fine-tuning Data", "Authors": ["Haotian Zhou", "Tingkai Liu", "Qianli Ma", "Jianbo Yuan", "Pengfei Liu", "Yang You and Hongxia Yang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency. In experimental comparisons involving 7B and 13B models, our LoBaSS method is able to surpass full-data fine-tuning at merely 6% of the total training data. When employing 16.7% of the data, LoBaSS harmonizes the model's capabilities across conversational and mathematical domains, proving its efficacy and adaptability.", "url": "https://arxiv.org/abs/2310.13008"}, {"metadata": {"arXiv": "2310.13022", "Date": "Thu, 19 Oct 2023 02:18:29 ", "Title": "Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding", "Authors": ["Jianing Wang", "Qiushi Sun", "Nuo Chen", "Chengyu Wang", "Jun Huang", "Ming Gao", "Xiang Li"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["Accepted by Findings of EMNLP 2023"]}, "abstract": "The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow the optimization of only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.", "url": "https://arxiv.org/abs/2310.13022"}, {"metadata": {"arXiv": "2310.13027", "Date": "Thu, 19 Oct 2023 07:28:39 ", "Title": "Be Bayesian by Attachments to Catch More Uncertainty", "Authors": ["Shiyu Shen", "Bin Pan", "Tianyang Shi", "Tao Li and Zhenwei Shi"], "Categories": "cs.LG cs.AI"}, "abstract": "Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribution modules aim at extracting the uncertainty from both ID and OOD data. We further provide theoretical analysis for the convergence of ABNN, and experimentally validate its superiority by comparing with some state-of-the-art uncertainty estimation methods Code will be made available.", "url": "https://arxiv.org/abs/2310.13027"}, {"metadata": {"arXiv": "2310.13029", "Date": "Thu, 19 Oct 2023 09:42:02 ", "Title": "Blending gradient boosted trees and neural networks for point and probabilistic forecasting of hierarchical time series", "Authors": ["Ioannis Nasios", "Konstantinos Vogklis"], "Categories": "cs.LG cs.AI physics.data-an q-fin.ST", "Journal-ref": "Volume 38, Issue 4, 2022, Pages 1448-1459", "DOI": "10.1016/j.ijforecast.2022.01.001"}, "abstract": "In this paper we tackle the problem of point and probabilistic forecasting by describing a blending methodology of machine learning models that belong to gradient boosted trees and neural networks families. These principles were successfully applied in the recent M5 Competition on both Accuracy and Uncertainty tracks. The keypoints of our methodology are: a) transform the task to regression on sales for a single day b) information rich feature engineering c) create a diverse set of state-of-the-art machine learning models and d) carefully construct validation sets for model tuning. We argue that the diversity of the machine learning models along with the careful selection of validation examples, where the most important ingredients for the effectiveness of our approach. Although forecasting data had an inherent hierarchy structure (12 levels), none of our proposed solutions exploited that hierarchical scheme. Using the proposed methodology, our team was ranked within the gold medal range in both Accuracy and the Uncertainty track. Inference code along with already trained models are available at https://github.com/IoannisNasios/M5_Uncertainty_3rd_place", "url": "https://arxiv.org/abs/2310.13029"}, {"metadata": {"arXiv": "2310.13037", "Date": "Thu, 19 Oct 2023 14:49:35 ", "Title": "Agri-GNN: A Novel Genotypic-Topological Graph Neural Network Framework Built on GraphSAGE for Optimized Yield Prediction", "Authors": ["Aditya Gupta and Asheesh Singh"], "Categories": "cs.LG cs.AI", "Comments": ["19 pages Regeneron STS entry"]}, "abstract": "Agriculture, as the cornerstone of human civilization, constantly seeks to integrate technology for enhanced productivity and sustainability. This paper introduces $\\textit{Agri-GNN}$, a novel Genotypic-Topological Graph Neural Network Framework tailored to capture the intricate spatial and genotypic interactions of crops, paving the way for optimized predictions of harvest yields. $\\textit{Agri-GNN}$ constructs a Graph $\\mathcal{G}$ that considers farming plots as nodes, and then methodically constructs edges between nodes based on spatial and genotypic similarity, allowing for the aggregation of node information through a genotypic-topological filter. Graph Neural Networks (GNN), by design, consider the relationships between data points, enabling them to efficiently model the interconnected agricultural ecosystem. By harnessing the power of GNNs, $\\textit{Agri-GNN}$ encapsulates both local and global information from plants, considering their inherent connections based on spatial proximity and shared genotypes, allowing stronger predictions to be made than traditional Machine Learning architectures. $\\textit{Agri-GNN}$ is built from the GraphSAGE architecture, because of its optimal calibration with large graphs, like those of farming plots and breeding experiments. $\\textit{Agri-GNN}$ experiments, conducted on a comprehensive dataset of vegetation indices, time, genotype information, and location data, demonstrate that $\\textit{Agri-GNN}$ achieves an $R^2 = .876$ in yield predictions for farming fields in Iowa. The results show significant improvement over the baselines and other work in the field. $\\textit{Agri-GNN}$ represents a blueprint for using advanced graph-based neural architectures to predict crop yield, providing significant improvements over baselines in the field.", "url": "https://arxiv.org/abs/2310.13037"}, {"metadata": {"arXiv": "2310.13040", "Date": "Thu, 19 Oct 2023 17:59:12 ", "Title": "Robust multimodal models have outlier features and encode more concepts", "Authors": ["Jonathan Crabb\\'e", "Pau Rodr\\'iguez", "Vaishaal Shankar", "Luca Zappella", "Arno Blaas"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["29 pages", "18 figures"]}, "abstract": "What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demonstrate that these privileged directions explain most of the predictive power of the model by pruning up to $80 \\%$ of the least important representation space directions without negative impacts on model accuracy and robustness; (2) Robust models encode substantially more concepts in their representation space. While this superposition of concepts allows robust models to store much information, it also results in highly polysemantic features, which makes their interpretation challenging. We discuss how these insights pave the way for future research in various fields, such as model pruning and mechanistic interpretability.", "url": "https://arxiv.org/abs/2310.13040"}, {"metadata": {"arXiv": "2310.13085", "Date": "Thu, 19 Oct 2023 18:25:22 ", "Title": "Unsupervised Representation Learning to Aid Semi-Supervised Meta Learning", "Authors": ["Atik Faysal", "Mohammad Rostami", "Huaxia Wang", "Avimanyu Sahoo", "and Ryan Antle"], "Categories": "cs.LG cs.AI"}, "abstract": "Few-shot learning or meta-learning leverages the data scarcity problem in machine learning. Traditionally, training data requires a multitude of samples and labeling for supervised learning. To address this issue, we propose a one-shot unsupervised meta-learning to learn the latent representation of the training samples. We use augmented samples as the query set during the training phase of the unsupervised meta-learning. A temperature-scaled cross-entropy loss is used in the inner loop of meta-learning to prevent overfitting during unsupervised learning. The learned parameters from this step are applied to the targeted supervised meta-learning in a transfer-learning fashion for initialization and fast adaptation with improved accuracy. The proposed method is model agnostic and can aid any meta-learning model to improve accuracy. We use model agnostic meta-learning (MAML) and relation network (RN) on Omniglot and mini-Imagenet datasets to demonstrate the performance of the proposed method. Furthermore, a meta-learning model with the proposed initialization can achieve satisfactory accuracy with significantly fewer training samples.", "url": "https://arxiv.org/abs/2310.13085"}, {"metadata": {"arXiv": "2310.13102", "Date": "Thu, 19 Oct 2023 19:01:00 ", "Title": "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models", "Authors": ["Gabriele Corso", "Yilun Xu", "Valentin de Bortoli", "Regina Barzilay", "Tommi Jaakkola"], "Categories": "cs.LG cs.AI"}, "abstract": "In light of the widespread success of generative models, a significant amount of research has gone into speeding up their sampling time. However, generative models are often sampled multiple times to obtain a diverse set incurring a cost that is orthogonal to sampling time. We tackle the question of how to improve diversity and sample efficiency by moving beyond the common assumption of independent samples. We propose particle guidance, an extension of diffusion-based generative sampling where a joint-particle time-evolving potential enforces diversity. We analyze theoretically the joint distribution that particle guidance generates, its implications on the choice of potential, and the connections with methods in other disciplines. Empirically, we test the framework both in the setting of conditional image generation, where we are able to increase diversity without affecting quality, and molecular conformer generation, where we reduce the state-of-the-art median error by 13% on average.", "url": "https://arxiv.org/abs/2310.13102"}, {"metadata": {"arXiv": "2310.13110", "Date": "Thu, 19 Oct 2023 19:17:12 ", "Title": "Semi-Supervised Learning of Dynamical Systems with Neural Ordinary Differential Equations: A Teacher-Student Model Approach", "Authors": ["Yu Wang", "Yuxuan Yin", "Karthik Somayaji Nanjangud Suryanarayana", "Jan Drgona", "Malachi Schram", "Mahantesh Halappanavar", "Frank Liu", "Peng Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Modeling dynamical systems is crucial for a wide range of tasks, but it remains challenging due to complex nonlinear dynamics, limited observations, or lack of prior knowledge. Recently, data-driven approaches such as Neural Ordinary Differential Equations (NODE) have shown promising results by leveraging the expressive power of neural networks to model unknown dynamics. However, these approaches often suffer from limited labeled training data, leading to poor generalization and suboptimal predictions. On the other hand, semi-supervised algorithms can utilize abundant unlabeled data and have demonstrated good performance in classification and regression tasks. We propose TS-NODE, the first semi-supervised approach to modeling dynamical systems with NODE. TS-NODE explores cheaply generated synthetic pseudo rollouts to broaden exploration in the state space and to tackle the challenges brought by lack of ground-truth system data under a teacher-student model. TS-NODE employs an unified optimization framework that corrects the teacher model based on the student's feedback while mitigating the potential false system dynamics present in pseudo rollouts. TS-NODE demonstrates significant performance improvements over a baseline Neural ODE model on multiple dynamical system modeling tasks.", "url": "https://arxiv.org/abs/2310.13110"}, {"metadata": {"arXiv": "2310.13121", "Date": "Thu, 19 Oct 2023 19:34:42 ", "Title": "Understanding Addition in Transformers", "Authors": ["Philip Quirke", "Fazl (Kiko) Barez"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "8 figures", "submitted to ICLR 2024"]}, "abstract": "Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.", "url": "https://arxiv.org/abs/2310.13121"}, {"metadata": {"arXiv": "2310.13161", "Date": "Thu, 19 Oct 2023 21:28:20 ", "Title": "A Distributed Approach to Meteorological Predictions: Addressing Data Imbalance in Precipitation Prediction Models through Federated Learning and GANs", "Authors": ["Elaheh Jafarigol", "Theodore Trafalis"], "Categories": "cs.LG cs.AI"}, "abstract": "The classification of weather data involves categorizing meteorological phenomena into classes, thereby facilitating nuanced analyses and precise predictions for various sectors such as agriculture, aviation, and disaster management. This involves utilizing machine learning models to analyze large, multidimensional weather datasets for patterns and trends. These datasets may include variables such as temperature, humidity, wind speed, and pressure, contributing to meteorological conditions. Furthermore, it's imperative that classification algorithms proficiently navigate challenges such as data imbalances, where certain weather events (e.g., storms or extreme temperatures) might be underrepresented. This empirical study explores data augmentation methods to address imbalanced classes in tabular weather data in centralized and federated settings. Employing data augmentation techniques such as the Synthetic Minority Over-sampling Technique or Generative Adversarial Networks can improve the model's accuracy in classifying rare but critical weather events. Moreover, with advancements in federated learning, machine learning models can be trained across decentralized databases, ensuring privacy and data integrity while mitigating the need for centralized data storage and processing. Thus, the classification of weather data stands as a critical bridge, linking raw meteorological data to actionable insights, enhancing our capacity to anticipate and prepare for diverse weather conditions.", "url": "https://arxiv.org/abs/2310.13161"}, {"metadata": {"arXiv": "2310.13225", "Date": "Fri, 20 Oct 2023 02:12:56 ", "Title": "Scalable Neural Network Kernels", "Authors": ["Arijit Sehanobish", "Krzysztof Choromanski", "Yunfan Zhao", "Avinava Dubey", "Valerii Likhosherstov"], "Categories": "cs.LG cs.AI", "Comments": ["Preprint. 23 pages", "10 figures. Comments welcome"]}, "abstract": "We introduce the concept of scalable neural network kernels (SNNKs), the replacements of regular feedforward layers (FFLs), capable of approximating the latter, but with favorable computational properties. SNNKs effectively disentangle the inputs from the parameters of the neural network in the FFL, only to connect them in the final computation via the dot-product kernel. They are also strictly more expressive, as allowing to model complicated relationships beyond the functions of the dot-products of parameter-input vectors. We also introduce the neural network bundling process that applies SNNKs to compactify deep neural network architectures, resulting in additional compression gains. In its extreme version, it leads to the fully bundled network whose optimal parameters can be expressed via explicit formulae for several loss functions (e.g. mean squared error), opening a possibility to bypass backpropagation. As a by-product of our analysis, we introduce the mechanism of the universal random features (or URFs), applied to instantiate several SNNK variants, and interesting on its own in the context of scalable kernel methods. We provide rigorous theoretical analysis of all these concepts as well as an extensive empirical evaluation, ranging from point-wise kernel estimation to Transformers' fine-tuning with novel adapter layers inspired by SNNKs. Our mechanism provides up to 5x reduction in the number of trainable parameters, while maintaining competitive accuracy.", "url": "https://arxiv.org/abs/2310.13225"}, {"metadata": {"arXiv": "2310.13230", "Date": "Fri, 20 Oct 2023 02:40:05 ", "Title": "Absolute Policy Optimization", "Authors": ["Weiye Zhao", "Feihan Li", "Yifan Sun", "Rui Chen", "Tianhao Wei", "Changliu Liu"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "In recent years, trust region on-policy reinforcement learning has achieved impressive results in addressing complex control tasks and gaming scenarios. However, contemporary state-of-the-art algorithms within this category primarily emphasize improvement in expected performance, lacking the ability to control over the worst-case performance outcomes. To address this limitation, we introduce a novel objective function; by optimizing which, it will lead to guaranteed monotonic improvement in the lower bound of near-total performance samples (absolute performance). Considering this groundbreaking theoretical advancement, we then refine this theoretically grounded algorithm through a series of approximations, resulting in a practical solution called Absolute Policy Optimization (APO). Our experiments demonstrate the effectiveness of our approach across challenging continuous control benchmark tasks and extend its applicability to mastering Atari games. Our findings reveal that APO significantly outperforms state-of-the-art policy gradient algorithms, resulting in substantial improvements in both expected performance and worst-case performance.", "url": "https://arxiv.org/abs/2310.13230"}, {"metadata": {"arXiv": "2310.13248", "Date": "Fri, 20 Oct 2023 03:06:41 ", "Title": "FLEE-GNN: A Federated Learning System for Edge-Enhanced Graph Neural Network in Analyzing Geospatial Resilience of Multicommodity Food Flows", "Authors": ["Yuxiao Qu", "Jinmeng Rao", "Song Gao", "Qianheng Zhang", "Wei-Lun Chao", "Yu Su", "Michelle Miller", "Alfonso Morales", "Patrick Huber"], "Categories": "cs.LG cs.AI cs.CY cs.SI", "Comments": ["10 pages", "5 figures"], "ACM-class": "I.2", "Journal-ref": "ACM SIGSPATIAL GeoAI 2023", "DOI": "10.1145/3615886.3627742"}, "abstract": "Understanding and measuring the resilience of food supply networks is a global imperative to tackle increasing food insecurity. However, the complexity of these networks, with their multidimensional interactions and decisions, presents significant challenges. This paper proposes FLEE-GNN, a novel Federated Learning System for Edge-Enhanced Graph Neural Network, designed to overcome these challenges and enhance the analysis of geospatial resilience of multicommodity food flow network, which is one type of spatial networks. FLEE-GNN addresses the limitations of current methodologies, such as entropy-based methods, in terms of generalizability, scalability, and data privacy. It combines the robustness and adaptability of graph neural networks with the privacy-conscious and decentralized aspects of federated learning on food supply network resilience analysis across geographical regions. This paper also discusses FLEE-GNN's innovative data generation techniques, experimental designs, and future directions for improvement. The results show the advancements of this approach to quantifying the resilience of multicommodity food flow networks, contributing to efforts towards ensuring global food security using AI methods. The developed FLEE-GNN has the potential to be applied in other spatial networks with spatially heterogeneous sub-network distributions.", "url": "https://arxiv.org/abs/2310.13248"}, {"metadata": {"arXiv": "2310.13269", "Date": "Fri, 20 Oct 2023 04:30:44 ", "Title": "An Exploratory Study on Simulated Annealing for Feature Selection in Learning-to-Rank", "Authors": ["Mohd. Sayemul Haque", "Md. Fahim", "Muhammad Ibrahim"], "Categories": "cs.LG cs.AI cs.IR", "Comments": ["29 pages"]}, "abstract": "Learning-to-rank is an applied domain of supervised machine learning. As feature selection has been found to be effective for improving the accuracy of learning models in general, it is intriguing to investigate this process for learning-to-rank domain. In this study, we investigate the use of a popular meta-heuristic approach called simulated annealing for this task. Under the general framework of simulated annealing, we explore various neighborhood selection strategies and temperature cooling schemes. We further introduce a new hyper-parameter called the progress parameter that can effectively be used to traverse the search space. Our algorithms are evaluated on five publicly benchmark datasets of learning-to-rank. For a better validation, we also compare the simulated annealing-based feature selection algorithm with another effective meta-heuristic algorithm, namely local beam search. Extensive experimental results shows the efficacy of our proposed models.", "url": "https://arxiv.org/abs/2310.13269"}, {"metadata": {"arXiv": "2310.13367", "Date": "Fri, 20 Oct 2023 09:22:51 ", "Title": "VFedMH: Vertical Federated Learning for Training Multi-party Heterogeneous Models", "Authors": ["Shuo Wang and Keke Gai and Jing Yu and Liehuang Zhu"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["10 pages", "5 figures"]}, "abstract": "Vertical Federated Learning (VFL) has gained increasing attention as a novel training paradigm that integrates sample alignment and feature union. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this issue, this paper proposes a novel approach called Vertical Federated learning for training Multi-parties Heterogeneous models (VFedMH). VFedMH focuses on aggregating the embeddings of each participant's knowledge instead of intermediate results during forward propagation. The active party, who possesses labels and features of the sample, in VFedMH securely aggregates local embeddings to obtain global knowledge embeddings, and sends them to passive parties. The passive parties, who own only features of the sample, then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the labels, so the local model gradient cannot be calculated locally. To overcome this limitation, the active party assists the passive party in computing its local heterogeneous model gradients. Then, each participant trains their local model using the heterogeneous model gradients. The objective is to minimize the loss value of their respective local heterogeneous models. Additionally, the paper provides a theoretical analysis of VFedMH's convergence performance. Extensive experiments are conducted to demonstrate that VFedMH can simultaneously train multiple heterogeneous models with heterogeneous optimization and outperform some recent methods in model performance.", "url": "https://arxiv.org/abs/2310.13367"}, {"metadata": {"arXiv": "2310.13391", "Date": "Fri, 20 Oct 2023 10:03:14 ", "Title": "Learning Successor Representations with Distributed Hebbian Temporal Memory", "Authors": ["Evgenii Dzhivelikian", "Petr Kuderov and Aleksandr I. Panov"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["12 pages", "4 figures"]}, "abstract": "This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare the SRs produced by DHTM to another biologically inspired HMM-like algorithm, CSCG. Our findings suggest that DHTM is a promising approach for addressing the challenges of online hidden representation learning in dynamic environments.", "url": "https://arxiv.org/abs/2310.13391"}, {"metadata": {"arXiv": "2310.13434", "Date": "Fri, 20 Oct 2023 11:46:12 ", "Title": "Random Matrix Analysis to Balance between Supervised and Unsupervised Learning under the Low Density Separation Assumption", "Authors": ["Vasilii Feofanov", "Malik Tiomoko", "Aladin Virmaux"], "Categories": "cs.LG cs.AI stat.ML", "Journal-ref": "Proceedings of the 40th International Conference on Machine Learning, PMLR 202:10008-10033, 2023"}, "abstract": "We propose a theoretical framework to analyze semi-supervised classification under the low density separation assumption in a high-dimensional regime. In particular, we introduce QLDS, a linear classification model, where the low density separation assumption is implemented via quadratic margin maximization. The algorithm has an explicit solution with rich theoretical properties, and we show that particular cases of our algorithm are the least-square support vector machine in the supervised case, the spectral clustering in the fully unsupervised regime, and a class of semi-supervised graph-based approaches. As such, QLDS establishes a smooth bridge between these supervised and unsupervised learning methods. Using recent advances in the random matrix theory, we formally derive a theoretical evaluation of the classification error in the asymptotic regime. As an application, we derive a hyperparameter selection policy that finds the best balance between the supervised and the unsupervised terms of our learning criterion. Finally, we provide extensive illustrations of our framework, as well as an experimental study on several benchmarks to demonstrate that QLDS, while being computationally more efficient, improves over cross-validation for hyperparameter selection, indicating a high promise of the usage of random matrix theory for semi-supervised model selection.", "url": "https://arxiv.org/abs/2310.13434"}, {"metadata": {"arXiv": "2310.13538", "Date": "Fri, 20 Oct 2023 14:32:54 ", "Title": "Positive-Unlabeled Node Classification with Structure-aware Graph Learning", "Authors": ["Hansi Yang", "Yongqi Zhang", "Quanming Yao", "James Kwok"], "Categories": "cs.LG cs.AI", "Comments": ["CIKM 2023"], "DOI": "10.1145/3583780.3615250"}, "abstract": "Node classification on graphs is an important research problem with many applications. Real-world graph data sets may not be balanced and accurate as assumed by most existing works. A challenging setting is positive-unlabeled (PU) node classification, where labeled nodes are restricted to positive nodes. It has diverse applications, e.g., pandemic prediction or network anomaly detection. Existing works on PU node classification overlook information in the graph structure, which can be critical. In this paper, we propose to better utilize graph structure for PU node classification. We first propose a distance-aware PU loss that uses homophily in graphs to introduce more accurate supervision. We also propose a regularizer to align the model with graph structure. Theoretical analysis shows that minimizing the proposed loss also leads to minimizing the expected loss with both positive and negative labels. Extensive empirical evaluation on diverse graph data sets demonstrates its superior performance over existing state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.13538"}, {"metadata": {"arXiv": "2310.13565", "Date": "Fri, 20 Oct 2023 15:04:42 ", "Title": "Reward Shaping for Happier Autonomous Cyber Security Agents", "Authors": ["Elizabeth Bates", "Vasilios Mavroudis", "Chris Hicks"], "Categories": "cs.LG cs.AI", "Comments": ["12 Pages"]}, "abstract": "As machine learning models become more capable, they have exhibited increased potential in solving complex tasks. One of the most promising directions uses deep reinforcement learning to train autonomous agents in computer network defense tasks. This work studies the impact of the reward signal that is provided to the agents when training for this task. Due to the nature of cybersecurity tasks, the reward signal is typically 1) in the form of penalties (e.g., when a compromise occurs), and 2) distributed sparsely across each defense episode. Such reward characteristics are atypical of classic reinforcement learning tasks where the agent is regularly rewarded for progress (cf. to getting occasionally penalized for failures). We investigate reward shaping techniques that could bridge this gap so as to enable agents to train more sample-efficiently and potentially converge to a better performance. We first show that deep reinforcement learning algorithms are sensitive to the magnitude of the penalties and their relative size. Then, we combine penalties with positive external rewards and study their effect compared to penalty-only training. Finally, we evaluate intrinsic curiosity as an internal positive reward mechanism and discuss why it might not be as advantageous for high-level network monitoring tasks.", "url": "https://arxiv.org/abs/2310.13565"}, {"metadata": {"arXiv": "2310.13576", "Date": "Fri, 20 Oct 2023 15:14:18 ", "Title": "Tree Search in DAG Space with Model-based Reinforcement Learning for Causal Discovery", "Authors": ["Victor-Alexandru Darvariu", "Stephen Hailes", "Mirco Musolesi"], "Categories": "cs.LG cs.AI"}, "abstract": "Identifying causal structure is central to many fields ranging from strategic decision-making to biology and economics. In this work, we propose a model-based reinforcement learning method for causal discovery based on tree search, which builds directed acyclic graphs incrementally. We also formalize and prove the correctness of an efficient algorithm for excluding edges that would introduce cycles, which enables deeper discrete search and sampling in DAG space. We evaluate our approach on two real-world tasks, achieving substantially better performance than the state-of-the-art model-free method and greedy search, constituting a promising advancement for combinatorial methods.", "url": "https://arxiv.org/abs/2310.13576"}, {"metadata": {"arXiv": "2310.13590", "Date": "Fri, 20 Oct 2023 15:33:23 ", "Title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction", "Authors": ["Yaorui Shi", "An Zhang", "Enzhi Zhang", "Zhiyuan Liu", "Xiang Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose ReLM, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model's robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at https://github.com/syr-cn/ReLM.", "url": "https://arxiv.org/abs/2310.13590"}, {"metadata": {"arXiv": "2310.13639", "Date": "Fri, 20 Oct 2023 16:37:56 ", "Title": "Contrastive Prefence Learning: Learning from Human Feedback without RL", "Authors": ["Joey Hejna", "Rafael Rafailov", "Harshit Sikchi", "Chelsea Finn", "Scott Niekum", "W. Bradley Knox", "Dorsa Sadigh"], "Categories": "cs.LG cs.AI", "Comments": ["Code released at https://github.com/jhejna/cpl"]}, "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new family of algorithms for optimizing behavior from human feedback using the regret-based model of human preferences. Using the principle of maximum entropy, we derive Contrastive Preference Learning (CPL), an algorithm for learning optimal policies from preferences without learning reward functions, circumventing the need for RL. CPL is fully off-policy, uses only a simple contrastive objective, and can be applied to arbitrary MDPs. This enables CPL to elegantly scale to high-dimensional and sequential RLHF problems while being simpler than prior methods.", "url": "https://arxiv.org/abs/2310.13639"}, {"metadata": {"arXiv": "2310.13654", "Date": "Fri, 20 Oct 2023 16:59:18 ", "Title": "An experimental study for early diagnosing Parkinson's disease using machine learning", "Authors": ["Md. Taufiqul Haque Khan Tusar", "Md. Touhidul Islam", "Abul Hasnat Sakil"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "9 figures", "5 tables"]}, "abstract": "One of the most catastrophic neurological disorders worldwide is Parkinson's Disease. Along with it, the treatment is complicated and abundantly expensive. The only effective action to control the progression is diagnosing it in the early stage. However, this is challenging because early detection necessitates a large and complex clinical study. This experimental work used Machine Learning techniques to automate the early detection of Parkinson's Disease from clinical characteristics, voice features and motor examination. In this study, we develop ML models utilizing a public dataset of 130 individuals, 30 of whom are untreated Parkinson's Disease patients, 50 of whom are Rapid Eye Movement Sleep Behaviour Disorder patients who are at a greater risk of contracting Parkinson's Disease, and 50 of whom are Healthy Controls. We use MinMax Scaler to rescale the data points, Local Outlier Factor to remove outliers, and SMOTE to balance existing class frequency. Afterwards, apply a number of Machine Learning techniques. We implement the approaches in such a way that data leaking and overfitting are not possible. Finally, obtained 100% accuracy in classifying PD and RBD patients, as well as 92% accuracy in classifying PD and HC individuals.", "url": "https://arxiv.org/abs/2310.13654"}, {"metadata": {"arXiv": "2310.13669", "Date": "Fri, 20 Oct 2023 17:13:16 ", "Title": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis", "Authors": ["Philip John Gorinski", "Matthieu Zimmer", "Gerasimos Lampouras", "Derrick Goh Xin Deik", "Ignacio Iacobacci"], "Categories": "cs.LG cs.AI cs.CL cs.PL", "Comments": ["9 pages + 4 pages appendix; 4 Figures", "4 Tables", "1 Algorithm; Accepted to Findings of EMNLP 2023"]}, "abstract": "The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics -- through the use of Unit Tests to check its functional correctness -- lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models' coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model's performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL.", "url": "https://arxiv.org/abs/2310.13669"}, {"metadata": {"arXiv": "2310.13065", "Date": "Thu, 19 Oct 2023 18:02:15 ", "Title": "Creative Robot Tool Use with Large Language Models", "Authors": ["Mengdi Xu", "Peide Huang", "Wenhao Yu", "Shiqi Liu", "Xilun Zhang", "Yaru Niu", "Tingnan Zhang", "Fei Xia", "Jie Tan", "Ding Zhao"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["19 pages", "14 figures", "2 tables"]}, "abstract": "Tool use is a hallmark of advanced intelligence, exemplified in both animal behavior and robotic capabilities. This paper investigates the feasibility of imbuing robots with the ability to creatively use tools in tasks that involve implicit physical constraints and long-term planning. Leveraging Large Language Models (LLMs), we develop RoboTool, a system that accepts natural language instructions and outputs executable code for controlling robots in both simulated and real-world environments. RoboTool incorporates four pivotal components: (i) an \"Analyzer\" that interprets natural language to discern key task-related concepts, (ii) a \"Planner\" that generates comprehensive strategies based on the language input and key concepts, (iii) a \"Calculator\" that computes parameters for each skill, and (iv) a \"Coder\" that translates these plans into executable Python code. Our results show that RoboTool can not only comprehend explicit or implicit physical constraints and environmental factors but also demonstrate creative tool use. Unlike traditional Task and Motion Planning (TAMP) methods that rely on explicit optimization, our LLM-based system offers a more flexible, efficient, and user-friendly solution for complex robotics tasks. Through extensive experiments, we validate that RoboTool is proficient in handling tasks that would otherwise be infeasible without the creative use of tools, thereby expanding the capabilities of robotic systems. Demos are available on our project page: https://creative-robotool.github.io/.", "url": "https://arxiv.org/abs/2310.13065"}, {"metadata": {"arXiv": "2310.13258", "Date": "Fri, 20 Oct 2023 03:34:31 ", "Title": "ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting", "Authors": ["Kushal Kedia", "Prithwish Dan", "Atiksh Bhardwaj", "Sanjiban Choudhury"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["CoRL 2023"]}, "abstract": "Seamless human-robot manipulation in close proximity relies on accurate forecasts of human motion. While there has been significant progress in learning forecast models at scale, when applied to manipulation tasks, these models accrue high errors at critical transition points leading to degradation in downstream planning performance. Our key insight is that instead of predicting the most likely human motion, it is sufficient to produce forecasts that capture how future human motion would affect the cost of a robot's plan. We present ManiCast, a novel framework that learns cost-aware human forecasts and feeds them to a model predictive control planner to execute collaborative manipulation tasks. Our framework enables fluid, real-time interactions between a human and a 7-DoF robot arm across a number of real-world tasks such as reactive stirring, object handovers, and collaborative table setting. We evaluate both the motion forecasts and the end-to-end forecaster-planner system against a range of learned and heuristic baselines while additionally contributing new datasets. We release our code and datasets at https://portal-cornell.github.io/manicast/.", "url": "https://arxiv.org/abs/2310.13258"}, {"metadata": {"arXiv": "2310.13129", "Date": "Thu, 19 Oct 2023 19:54:47 ", "Title": "Deep Reinforcement Learning-based Intelligent Traffic Signal Controls with Optimized CO2 emissions", "Authors": ["Pedram Agand", "Alexey Iskrov", "Mo Chen"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["6 pages", "6 figures", "1 table. International Conference on Intelligent Robots and Systems. IEEE/RSJ", "2023"]}, "abstract": "Nowadays, transportation networks face the challenge of sub-optimal control policies that can have adverse effects on human health, the environment, and contribute to traffic congestion. Increased levels of air pollution and extended commute times caused by traffic bottlenecks make intersection traffic signal controllers a crucial component of modern transportation infrastructure. Despite several adaptive traffic signal controllers in literature, limited research has been conducted on their comparative performance. Furthermore, despite carbon dioxide (CO2) emissions' significance as a global issue, the literature has paid limited attention to this area. In this report, we propose EcoLight, a reward shaping scheme for reinforcement learning algorithms that not only reduces CO2 emissions but also achieves competitive results in metrics such as travel time. We compare the performance of tabular Q-Learning, DQN, SARSA, and A2C algorithms using metrics such as travel time, CO2 emissions, waiting time, and stopped time. Our evaluation considers multiple scenarios that encompass a range of road users (trucks, buses, cars) with varying pollution levels.", "url": "https://arxiv.org/abs/2310.13129"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

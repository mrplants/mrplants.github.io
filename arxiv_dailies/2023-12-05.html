<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2312.00803", "Date": "Fri, 24 Nov 2023 11:58:11 ", "Title": "InceptionCaps: A Performant Glaucoma Classification Model for Data-scarce Environment", "Authors": ["Gyanendar Manohar", "Ruairi O'Reilly"], "Categories": "cs.CV cs.LG", "Comments": ["8 pages"]}, "abstract": "Glaucoma is an irreversible ocular disease and is the second leading cause of visual disability worldwide. Slow vision loss and the asymptomatic nature of the disease make its diagnosis challenging. Early detection is crucial for preventing irreversible blindness. Ophthalmologists primarily use retinal fundus images as a non-invasive screening method. Convolutional neural networks (CNN) have demonstrated high accuracy in the classification of medical images. Nevertheless, CNN's translation-invariant nature and inability to handle the part-whole relationship between objects make its direct application unsuitable for glaucomatous fundus image classification, as it requires a large number of labelled images for training. This work reviews existing state of the art models and proposes InceptionCaps, a novel capsule network (CapsNet) based deep learning model having pre-trained InceptionV3 as its convolution base, for automatic glaucoma classification. InceptionCaps achieved an accuracy of 0.956, specificity of 0.96, and AUC of 0.9556, which surpasses several state-of-the-art deep learning model performances on the RIM-ONE v2 dataset. The obtained result demonstrates the robustness of the proposed deep learning model.", "url": "https://arxiv.org/abs/2312.00803"}, {"metadata": {"arXiv": "2312.00824", "Date": "Tue, 05 Sep 2023 17:21:38 ", "Title": "Variational Self-Supervised Contrastive Learning Using Beta Divergence", "Authors": ["Mehmet Can Yavuz and Berrin Yanikoglu"], "Categories": "cs.CV cs.LG"}, "abstract": "Learning a discriminative semantic space using unlabelled and noisy data remains unaddressed in a multi-label setting. We present a contrastive self-supervised learning method which is robust to data noise, grounded in the domain of variational methods. The method (VCL) utilizes variational contrastive learning with beta-divergence to learn robustly from unlabelled datasets, including uncurated and noisy datasets. We demonstrate the effectiveness of the proposed method through rigorous experiments including linear evaluation and fine-tuning scenarios with multi-label datasets in the face understanding domain. In almost all tested scenarios, VCL surpasses the performance of state-of-the-art self-supervised methods, achieving a noteworthy increase in accuracy.", "url": "https://arxiv.org/abs/2312.00824"}, {"metadata": {"arXiv": "2312.01097", "Date": "Sat, 02 Dec 2023 10:07:17 ", "Title": "Planning as In-Painting: A Diffusion-Based Embodied Task Planning Framework for Environments under Uncertainty", "Authors": ["Cheng-Fu Yang", "Haoyang Xu", "Te-Lin Wu", "Xiaofeng Gao", "Kai-Wei Chang", "Feng Gao"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "Task planning for embodied AI has been one of the most challenging problems where the community does not meet a consensus in terms of formulation. In this paper, we aim to tackle this problem with a unified framework consisting of an end-to-end trainable method and a planning algorithm. Particularly, we propose a task-agnostic method named 'planning as in-painting'. In this method, we use a Denoising Diffusion Model (DDM) for plan generation, conditioned on both language instructions and perceptual inputs under partially observable environments. Partial observation often leads to the model hallucinating the planning. Therefore, our diffusion-based method jointly models both state trajectory and goal estimation to improve the reliability of the generated plan, given the limited available information at each step. To better leverage newly discovered information along the plan execution for a higher success rate, we propose an on-the-fly planning algorithm to collaborate with the diffusion-based planner. The proposed framework achieves promising performances in various embodied AI tasks, including vision-language navigation, object manipulation, and task planning in a photorealistic virtual environment. The code is available at: https://github.com/joeyy5588/planning-as-inpainting.", "url": "https://arxiv.org/abs/2312.01097"}, {"metadata": {"arXiv": "2312.01167", "Date": "Sat, 02 Dec 2023 16:23:01 ", "Title": "Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning", "Authors": ["Vinay K Verma", "Nikhil Mehta", "Kevin J Liang", "Aakansha Mishra and Lawrence Carin"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024"]}, "abstract": "Zero-shot learning (ZSL) is a promising approach to generalizing a model to categories unseen during training by leveraging class attributes, but challenges remain. Recently, methods using generative models to combat bias towards classes seen during training have pushed state of the art, but these generative models can be slow or computationally expensive to train. Also, these generative models assume that the attribute vector of each unseen class is available a priori at training, which is not always practical. Additionally, while many previous ZSL methods assume a one-time adaptation to unseen classes, in reality, the world is always changing, necessitating a constant adjustment of deployed models. Models unprepared to handle a sequential stream of data are likely to experience catastrophic forgetting. We propose a Meta-learned Attribute self-Interaction Network (MAIN) for continual ZSL. By pairing attribute self-interaction trained using meta-learning with inverse regularization of the attribute encoder, we are able to outperform state-of-the-art results without leveraging the unseen class attributes while also being able to train our models substantially faster (>100x) than expensive generative-based approaches. We demonstrate this with experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2, and SUN) in the generalized zero-shot learning and continual (fixed/dynamic) zero-shot learning settings. Extensive ablations and analyses demonstrate the efficacy of various components proposed.", "url": "https://arxiv.org/abs/2312.01167"}, {"metadata": {"arXiv": "2312.01187", "Date": "Sat, 02 Dec 2023 17:25:30 ", "Title": "SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer", "Authors": ["Renan A. Rojas-Gomez", "Karan Singhal", "Ali Etemad", "Alex Bijamov", "Warren R. Morningstar", "Philip Andrew Mansfield"], "Categories": "cs.CV cs.LG stat.ML"}, "abstract": "Self-supervised learning relies heavily on data augmentation to extract meaningful representations from unlabeled images. While existing state-of-the-art augmentation pipelines incorporate a wide range of primitive transformations, these often disregard natural image structure. Thus, augmented samples can exhibit degraded semantic information and low stylistic diversity, affecting downstream performance of self-supervised representations. To overcome this, we propose SASSL: Style Augmentations for Self Supervised Learning, a novel augmentation technique based on Neural Style Transfer. The method decouples semantic and stylistic attributes in images and applies transformations exclusively to the style while preserving content, generating diverse augmented samples that better retain their semantic properties. Experimental results show our technique achieves a top-1 classification performance improvement of more than 2% on ImageNet compared to the well-established MoCo v2. We also measure transfer learning performance across five diverse datasets, observing significant improvements of up to 3.75%. Our experiments indicate that decoupling style from content information and transferring style across datasets to diversify augmentations can significantly improve downstream performance of self-supervised representations.", "url": "https://arxiv.org/abs/2312.01187"}, {"metadata": {"arXiv": "2312.01255", "Date": "Sun, 03 Dec 2023 01:36:45 ", "Title": "Meta ControlNet: Enhancing Task Adaptation via Meta Learning", "Authors": ["Junjie Yang", "Jinze Zhao", "Peihao Wang", "Zhangyang Wang", "Yingbin Liang"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion-based image synthesis has attracted extensive attention recently. In particular, ControlNet that uses image-based prompts exhibits powerful capability in image tasks such as canny edge detection and generates images well aligned with these prompts. However, vanilla ControlNet generally requires extensive training of around 5000 steps to achieve a desirable control for a single task. Recent context-learning approaches have improved its adaptability, but mainly for edge-based tasks, and rely on paired examples. Thus, two important open issues are yet to be addressed to reach the full potential of ControlNet: (i) zero-shot control for certain tasks and (ii) faster adaptation for non-edge-based tasks. In this paper, we introduce a novel Meta ControlNet method, which adopts the task-agnostic meta learning technique and features a new layer freezing design. Meta ControlNet significantly reduces learning steps to attain control ability from 5000 to 1000. Further, Meta ControlNet exhibits direct zero-shot adaptability in edge-based tasks without any finetuning, and achieves control within only 100 finetuning steps in more complex non-edge tasks such as Human Pose, outperforming all existing methods. The codes is available in https://github.com/JunjieYang97/Meta-ControlNet.", "url": "https://arxiv.org/abs/2312.01255"}, {"metadata": {"arXiv": "2312.01324", "Date": "Sun, 03 Dec 2023 09:00:31 ", "Title": "MABViT -- Modified Attention Block Enhances Vision Transformers", "Authors": ["Mahesh Ramesh and Aswinkumar Ramkumar"], "Categories": "cs.CV cs.LG", "Comments": ["Paper Under Review"]}, "abstract": "Recent studies have demonstrated the effectiveness of Gated Linear Units (GLU) in enhancing transformer models, particularly in Large Language Models (LLMs). Additionally, utilizing a parallel configuration within each Transformer block rather than the conventional serialized method has been revealed to accelerate the training of LLMs without significantly impacting performance. However, when the MLP and attention block were run in parallel for the image classification task, we observed a noticeable decline in performance. We propose a novel transformer variant that integrates non-linearity within the attention block to tackle this problem. We implemented the GLU-based activation function on the Value tensor, and this new technique surpasses the current state-of-the-art S/16 variant of Vision Transformers by 0.6% on the ImageNet-1K dataset while utilizing fewer parameters. It also supersedes the B/16 variant while using only half the parameters. Furthermore, we provide results with the GELU activation function variant to confirm our assertions. Lastly, we showcase that the MABViT variants exhibit greater potential when utilized in deep transformers compared to the standard architecture.", "url": "https://arxiv.org/abs/2312.01324"}, {"metadata": {"arXiv": "2312.01361", "Date": "Sun, 03 Dec 2023 12:02:23 ", "Title": "MoEC: Mixture of Experts Implicit Neural Compression", "Authors": ["Jianchen Zhao", "Cheng-Ching Tseng", "Ming Lu", "Ruichuan An", "Xiaobao Wei", "He Sun", "Shanghang Zhang"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Emerging Implicit Neural Representation (INR) is a promising data compression technique, which represents the data using the parameters of a Deep Neural Network (DNN). Existing methods manually partition a complex scene into local regions and overfit the INRs into those regions. However, manually designing the partition scheme for a complex scene is very challenging and fails to jointly learn the partition and INRs. To solve the problem, we propose MoEC, a novel implicit neural compression method based on the theory of mixture of experts. Specifically, we use a gating network to automatically assign a specific INR to a 3D point in the scene. The gating network is trained jointly with the INRs of different local regions. Compared with block-wise and tree-structured partitions, our learnable partition can adaptively find the optimal partition in an end-to-end manner. We conduct detailed experiments on massive and diverse biomedical data to demonstrate the advantages of MoEC against existing approaches. In most of experiment settings, we have achieved state-of-the-art results. Especially in cases of extreme compression ratios, such as 6000x, we are able to uphold the PSNR of 48.16.", "url": "https://arxiv.org/abs/2312.01361"}, {"metadata": {"arXiv": "2312.01397", "Date": "Sun, 03 Dec 2023 13:50:24 ", "Title": "Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective", "Authors": ["Can Jin", "Tianjin Huang", "Yihua Zhang", "Mykola Pechenizkiy", "Sijia Liu", "Shiwei Liu", "Tianlong Chen"], "Categories": "cs.CV cs.LG", "Comments": ["under conference review"]}, "abstract": "The rapid development of large-scale deep learning models questions the affordability of hardware platforms, which necessitates the pruning to reduce their computational and memory footprints. Sparse neural networks as the product, have demonstrated numerous favorable benefits like low complexity, undamaged generalization, etc. Most of the prominent pruning strategies are invented from a model-centric perspective, focusing on searching and preserving crucial weights by analyzing network topologies. However, the role of data and its interplay with model-centric pruning has remained relatively unexplored. In this research, we introduce a novel data-model co-design perspective: to promote superior weight sparsity by learning important model topology and adequate input data in a synergetic manner. Specifically, customized Visual Prompts are mounted to upgrade neural Network sparsification in our proposed VPNs framework. As a pioneering effort, this paper conducts systematic investigations about the impact of different visual prompts on model pruning and suggests an effective joint optimization approach. Extensive experiments with 3 network architectures and 8 datasets evidence the substantial performance improvements from VPNs over existing start-of-the-art pruning algorithms. Furthermore, we find that subnetworks discovered by VPNs from pre-trained models enjoy better transferability across diverse downstream scenarios. These insights shed light on new promising possibilities of data-model co-designs for vision model sparsification.", "url": "https://arxiv.org/abs/2312.01397"}, {"metadata": {"arXiv": "2312.01490", "Date": "Sun, 03 Dec 2023 19:21:53 ", "Title": "GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping", "Authors": ["Ruochen Chen", "Liming Chen", "Shaifali Parashar"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "Recent neural, physics-based modeling of garment deformations allows faster and visually aesthetic results as opposed to the existing methods. Material-specific parameters are used by the formulation to control the garment inextensibility. This delivers unrealistic results with physically implausible stretching. Oftentimes, the draped garment is pushed inside the body which is either corrected by an expensive post-processing, thus adding to further inconsistent stretching; or by deploying a separate training regime for each body type, restricting its scalability. Additionally, the flawed skinning process deployed by existing methods produces incorrect results on loose garments. In this paper, we introduce a geometrical constraint to the existing formulation that is collision-aware and imposes garment inextensibility wherever possible. Thus, we obtain realistic results where draped clothes stretch only while covering bigger body regions. Furthermore, we propose a geometry-aware garment skinning method by defining a body-garment closeness measure which works for all garment types, especially the loose ones.", "url": "https://arxiv.org/abs/2312.01490"}, {"metadata": {"arXiv": "2312.01522", "Date": "Sun, 03 Dec 2023 22:44:04 ", "Title": "G2D: From Global to Dense Radiography Representation Learning via Vision-Language Pre-training", "Authors": ["Che Liu", "Cheng Ouyang", "Sibo Cheng", "Anand Shah", "Wenjia Bai", "Rossella Arcucci"], "Categories": "cs.CV cs.LG"}, "abstract": "Recently, medical vision-language pre-training (VLP) has reached substantial progress to learn global visual representation from medical images and their paired radiology reports. However, medical imaging tasks in real world usually require finer granularity in visual features. These tasks include visual localization tasks (e.g., semantic segmentation, object detection) and visual grounding task. Yet, current medical VLP methods face challenges in learning these fine-grained features, as they primarily focus on brute-force alignment between image patches and individual text tokens for local visual feature learning, which is suboptimal for downstream dense prediction tasks. In this work, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense level representation learning (G2D) that achieves significantly improved granularity and more accurate grounding for the learned features, compared to existing medical VLP approaches. In particular, G2D learns dense and semantically-grounded image representations via a pseudo segmentation task parallel with the global vision-language alignment. Notably, generating pseudo segmentation targets does not incur extra trainable parameters: they are obtained on the fly during VLP with a parameter-free processor. G2D achieves superior performance across 6 medical imaging tasks and 25 diseases, particularly in semantic segmentation, which necessitates fine-grained, semantically-grounded image features. In this task, G2D surpasses peer models even when fine-tuned with just 1\\% of the training data, compared to the 100\\% used by these models. The code will be released upon acceptance.", "url": "https://arxiv.org/abs/2312.01522"}, {"metadata": {"arXiv": "2312.01529", "Date": "Sun, 03 Dec 2023 23:03:22 ", "Title": "T3D: Towards 3D Medical Image Understanding through Vision-Language Pre-training", "Authors": ["Che Liu", "Cheng Ouyang", "Yinda Chen", "Cesar C\\'esar Quilodr\\'an-Casas", "Lei Ma", "Jie Fu", "Yike Guo", "Anand Shah", "Wenjia Bai", "Rossella Arcucci"], "Categories": "cs.CV cs.CL cs.LG eess.IV"}, "abstract": "Expert annotation of 3D medical image for downstream analysis is resource-intensive, posing challenges in clinical applications. Visual self-supervised learning (vSSL), though effective for learning visual invariance, neglects the incorporation of domain knowledge from medicine. To incorporate medical knowledge into visual representation learning, vision-language pre-training (VLP) has shown promising results in 2D image. However, existing VLP approaches become generally impractical when applied to high-resolution 3D medical images due to GPU hardware constraints and the potential loss of critical details caused by downsampling, which is the intuitive solution to hardware constraints. To address the above limitations, we introduce T3D, the first VLP framework designed for high-resolution 3D medical images. T3D incorporates two text-informed pretext tasks: (\\lowerromannumeral{1}) text-informed contrastive learning; (\\lowerromannumeral{2}) text-informed image restoration. These tasks focus on learning 3D visual representations from high-resolution 3D medical images and integrating clinical knowledge from radiology reports, without distorting information through forced alignment of downsampled volumes with detailed anatomical text. Trained on a newly curated large-scale dataset of 3D medical images and radiology reports, T3D significantly outperforms current vSSL methods in tasks like organ and tumor segmentation, as well as disease classification. This underlines T3D's potential in representation learning for 3D medical image analysis. All data and code will be available upon acceptance.", "url": "https://arxiv.org/abs/2312.01529"}, {"metadata": {"arXiv": "2312.01605", "Date": "Mon, 04 Dec 2023 03:38:04 ", "Title": "TextAug: Test time Text Augmentation for Multimodal Person Re-identification", "Authors": ["Mulham Fawakherji", "Eduard Vazquez", "Pasquale Giampa", "Binod Bhattarai"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "5 figures"]}, "abstract": "Multimodal Person Reidentification is gaining popularity in the research community due to its effectiveness compared to counter-part unimodal frameworks. However, the bottleneck for multimodal deep learning is the need for a large volume of multimodal training examples. Data augmentation techniques such as cropping, flipping, rotation, etc. are often employed in the image domain to improve the generalization of deep learning models. Augmenting in other modalities than images, such as text, is challenging and requires significant computational resources and external data sources. In this study, we investigate the effectiveness of two computer vision data augmentation techniques: cutout and cutmix, for text augmentation in multi-modal person re-identification. Our approach merges these two augmentation strategies into one strategy called CutMixOut which involves randomly removing words or sub-phrases from a sentence (Cutout) and blending parts of two or more sentences to create diverse examples (CutMix) with a certain probability assigned to each operation. This augmentation was implemented at inference time without any prior training. Our results demonstrate that the proposed technique is simple and effective in improving the performance on multiple multimodal person re-identification benchmarks.", "url": "https://arxiv.org/abs/2312.01605"}, {"metadata": {"arXiv": "2312.01659", "Date": "Mon, 04 Dec 2023 06:21:22 ", "Title": "RiskBench: A Scenario-based Benchmark for Risk Identification", "Authors": ["Chi-Hsi Kung", "Chieh-Chi Yang", "Pang-Yuan Pao", "Shu-Wei Lu", "Pin-Lun Chen", "Hsin-Cheng Lu", "Yi-Ting Chen"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "Intelligent driving systems aim to achieve a zero-collision mobility experience, requiring interdisciplinary efforts to enhance safety performance. This work focuses on risk identification, the process of identifying and analyzing risks stemming from dynamic traffic participants and unexpected events. While significant advances have been made in the community, the current evaluation of different risk identification algorithms uses independent datasets, leading to difficulty in direct comparison and hindering collective progress toward safety performance enhancement. To address this limitation, we introduce \\textbf{RiskBench}, a large-scale scenario-based benchmark for risk identification. We design a scenario taxonomy and augmentation pipeline to enable a systematic collection of ground truth risks under diverse scenarios. We assess the ability of ten algorithms to (1) detect and locate risks, (2) anticipate risks, and (3) facilitate decision-making. We conduct extensive experiments and summarize future research on risk identification. Our aim is to encourage collaborative endeavors in achieving a society with zero collisions. We have made our dataset and benchmark toolkit publicly on the project page: https://hcis-lab.github.io/RiskBench/", "url": "https://arxiv.org/abs/2312.01659"}, {"metadata": {"arXiv": "2312.01850", "Date": "Mon, 04 Dec 2023 12:31:45 ", "Title": "Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation", "Authors": ["Joshua Niemeijer", "Manuel Schwonberg", "Jan-Aike Term\\\"ohlen", "Nico M. Schmidt", "Tim Fingscheidt"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to WACV 2024"]}, "abstract": "When models, e.g., for semantic segmentation, are applied to images that are vastly different from training data, the performance will drop significantly. Domain adaptation methods try to overcome this issue, but need samples from the target domain. However, this might not always be feasible for various reasons and therefore domain generalization methods are useful as they do not require any target data. We present a new diffusion-based domain extension (DIDEX) method and employ a diffusion model to generate a pseudo-target domain with diverse text prompts. In contrast to existing methods, this allows to control the style and content of the generated images and to introduce a high diversity. In a second step, we train a generalizing model by adapting towards this pseudo-target domain. We outperform previous approaches by a large margin across various datasets and architectures without using any real data. For the generalization from GTA5, we improve state-of-the-art mIoU performance by 3.8% absolute on average and for SYNTHIA by 11.8% absolute, marking a big step for the generalization performance on these benchmarks. Code is available at https://github.com/JNiemeijer/DIDEX", "url": "https://arxiv.org/abs/2312.01850"}, {"metadata": {"arXiv": "2312.01904", "Date": "Mon, 04 Dec 2023 14:02:56 ", "Title": "Unsupervised Anomaly Detection using Aggregated Normative Diffusion", "Authors": ["Alexander Frotscher", "Jaivardhan Kapoor", "Thomas Wolfers", "Christian F. Baumgartner"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Early detection of anomalies in medical images such as brain MRI is highly relevant for diagnosis and treatment of many conditions. Supervised machine learning methods are limited to a small number of pathologies where there is good availability of labeled data. In contrast, unsupervised anomaly detection (UAD) has the potential to identify a broader spectrum of anomalies by spotting deviations from normal patterns. Our research demonstrates that existing state-of-the-art UAD approaches do not generalise well to diverse types of anomalies in realistic multi-modal MR data. To overcome this, we introduce a new UAD method named Aggregated Normative Diffusion (ANDi). ANDi operates by aggregating differences between predicted denoising steps and ground truth backwards transitions in Denoising Diffusion Probabilistic Models (DDPMs) that have been trained on pyramidal Gaussian noise. We validate ANDi against three recent UAD baselines, and across three diverse brain MRI datasets. We show that ANDi, in some cases, substantially surpasses these baselines and shows increased robustness to varying types of anomalies. Particularly in detecting multiple sclerosis (MS) lesions, ANDi achieves improvements of up to 178% in terms of AUPRC.", "url": "https://arxiv.org/abs/2312.01904"}, {"metadata": {"arXiv": "2312.02052", "Date": "Mon, 04 Dec 2023 17:10:25 ", "Title": "DUCK: Distance-based Unlearning via Centroid Kinematics", "Authors": ["Marco Cotogni", "Jacopo Bonato", "Luigi Sabetta", "Francesco Pelosin and Alessandro Nicolosi"], "Categories": "cs.CV cs.LG"}, "abstract": "Machine Unlearning is rising as a new field, driven by the pressing necessity of ensuring privacy in modern artificial intelligence models. This technique primarily aims to eradicate any residual influence of a specific subset of data from the knowledge acquired by a neural model during its training. This work introduces a novel unlearning algorithm, denoted as Distance-based Unlearning via Centroid Kinematics (DUCK), which employs metric learning to guide the removal of samples matching the nearest incorrect centroid in the embedding space. Evaluation of the algorithm's performance is conducted across various benchmark datasets in two distinct scenarios, class removal, and homogeneous sampling removal, obtaining state-of-the-art performance. We introduce a novel metric, called Adaptive Unlearning Score (AUS), encompassing not only the efficacy of the unlearning process in forgetting target data but also quantifying the performance loss relative to the original model. Moreover, we propose a novel membership inference attack to assess the algorithm's capacity to erase previously acquired knowledge, designed to be adaptable to future methodologies.", "url": "https://arxiv.org/abs/2312.02052"}, {"metadata": {"arXiv": "2312.02124", "Date": "Mon, 04 Dec 2023 18:51:44 ", "Title": "VerA: Versatile Anonymization Fit for Clinical Facial Images", "Authors": ["Majed El Helou", "Doruk Cetin", "Petar Stamenkovic", "Fabio Zund"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "The escalating legislative demand for data privacy in facial image dissemination has underscored the significance of image anonymization. Recent advancements in the field surpass traditional pixelation or blur methods, yet they predominantly address regular single images. This leaves clinical image anonymization -- a necessity for illustrating medical interventions -- largely unaddressed. We present VerA, a versatile facial image anonymization that is fit for clinical facial images where: (1) certain semantic areas must be preserved to show medical intervention results, and (2) anonymizing image pairs is crucial for showing before-and-after results. VerA outperforms or is on par with state-of-the-art methods in de-identification and photorealism for regular images. In addition, we validate our results on paired anonymization, and on the anonymization of both single and paired clinical images with extensive quantitative and qualitative evaluation.", "url": "https://arxiv.org/abs/2312.02124"}, {"metadata": {"arXiv": "2312.02133", "Date": "Mon, 04 Dec 2023 18:55:35 ", "Title": "Style Aligned Image Generation via Shared Attention", "Authors": ["Amir Hertz", "Andrey Voynov", "Shlomi Fruchter", "Daniel Cohen-Or"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page at style-aligned-gen.github.io"]}, "abstract": "Large-scale Text-to-Image (T2I) models have rapidly gained prominence across creative fields, generating visually compelling outputs from textual prompts. However, controlling these models to ensure consistent style remains challenging, with existing methods necessitating fine-tuning and manual intervention to disentangle content and style. In this paper, we introduce StyleAligned, a novel technique designed to establish style alignment among a series of generated images. By employing minimal `attention sharing' during the diffusion process, our method maintains style consistency across images within T2I models. This approach allows for the creation of style-consistent images using a reference style through a straightforward inversion operation. Our method's evaluation across diverse styles and text prompts demonstrates high-quality synthesis and fidelity, underscoring its efficacy in achieving consistent style across various inputs.", "url": "https://arxiv.org/abs/2312.02133"}, {"metadata": {"arXiv": "2312.01121", "Date": "Sat, 02 Dec 2023 12:28:56 ", "Title": "Virtual reservoir acceleration for CPU and GPU: Case study for coupled spin-torque oscillator reservoir", "Authors": ["Thomas Geert de Jong", "Nozomi Akashi", "Tomohiro Taniguchi", "Hirofumi Notsu", "Kohei Nakajima"], "Categories": "cs.DC cs.LG"}, "abstract": "We provide high-speed implementations for simulating reservoirs described by $N$-coupled spin-torque oscillators. Here $N$ also corresponds to the number of reservoir nodes. We benchmark a variety of implementations based on CPU and GPU. Our new methods are at least 2.6 times quicker than the baseline for $N$ in range $1$ to $10^4$. More specifically, over all implementations the best factor is 78.9 for $N=1$ which decreases to 2.6 for $N=10^3$ and finally increases to 23.8 for $N=10^4$. GPU outperforms CPU significantly at $N=2500$. Our results show that GPU implementations should be tested for reservoir simulations. The implementations considered here can be used for any reservoir with evolution that can be approximated using an explicit method.", "url": "https://arxiv.org/abs/2312.01121"}, {"metadata": {"arXiv": "2312.01587", "Date": "Mon, 04 Dec 2023 03:04:09 ", "Title": "Scalable and Independent Learning of Nash Equilibrium Policies in $n$-Player Stochastic Games with Unknown Independent Chains", "Authors": ["Tiancheng Qin and S. Rasoul Etesami"], "Categories": "cs.GT cs.LG"}, "abstract": "We study a subclass of $n$-player stochastic games, namely, stochastic games with independent chains and unknown transition matrices. In this class of games, players control their own internal Markov chains whose transitions do not depend on the states/actions of other players. However, players' decisions are coupled through their payoff functions. We assume players can receive only realizations of their payoffs, and that the players can not observe the states and actions of other players, nor do they know the transition probability matrices of their own Markov chain. Relying on a compact dual formulation of the game based on occupancy measures and the technique of confidence set to maintain high-probability estimates of the unknown transition matrices, we propose a fully decentralized mirror descent algorithm to learn an $\\epsilon$-NE for this class of games. The proposed algorithm has the desired properties of independence, scalability, and convergence. Specifically, under no assumptions on the reward functions, we show the proposed algorithm converges in polynomial time in a weaker distance (namely, the averaged Nikaido-Isoda gap) to the set of $\\epsilon$-NE policies with arbitrarily high probability. Moreover, assuming the existence of a variationally stable Nash equilibrium policy, we show that the proposed algorithm converges asymptotically to the stable $\\epsilon$-NE policy with arbitrarily high probability. In addition to Markov potential games and linear-quadratic stochastic games, this work provides another subclass of $n$-player stochastic games that, under some mild assumptions, admit polynomial-time learning algorithms for finding their stationary $\\epsilon$-NE policies.", "url": "https://arxiv.org/abs/2312.01587"}, {"metadata": {"arXiv": "2312.00840", "Date": "Fri, 01 Dec 2023 02:29:52 ", "Title": "Towards Redundancy-Free Sub-networks in Continual Learning", "Authors": ["Cheng Chen", "Jingkuan Song", "LianLi Gao", "Heng Tao Shen"], "Categories": "cs.LG cs.CV"}, "abstract": "Catastrophic Forgetting (CF) is a prominent issue in continual learning. Parameter isolation addresses this challenge by masking a sub-network for each task to mitigate interference with old tasks. However, these sub-networks are constructed relying on weight magnitude, which does not necessarily correspond to the importance of weights, resulting in maintaining unimportant weights and constructing redundant sub-networks. To overcome this limitation, inspired by information bottleneck, which removes redundancy between adjacent network layers, we propose \\textbf{\\underline{I}nformation \\underline{B}ottleneck \\underline{M}asked sub-network (IBM)} to eliminate redundancy within sub-networks. Specifically, IBM accumulates valuable information into essential weights to construct redundancy-free sub-networks, not only effectively mitigating CF by freezing the sub-networks but also facilitating new tasks training through the transfer of valuable knowledge. Additionally, IBM decomposes hidden representations to automate the construction process and make it flexible. Extensive experiments demonstrate that IBM consistently outperforms state-of-the-art methods. Notably, IBM surpasses the state-of-the-art parameter isolation method with a 70\\% reduction in the number of parameters within sub-networks and an 80\\% decrease in training time.", "url": "https://arxiv.org/abs/2312.00840"}, {"metadata": {"arXiv": "2312.00851", "Date": "Fri, 01 Dec 2023 13:25:16 ", "Title": "Physics Inspired Criterion for Pruning-Quantization Joint Learning", "Authors": ["Weiying Xie", "Xiaoyi Fan", "Xin Zhang", "Yunsong Li", "Jie Lei", "Leyuan Fang"], "Categories": "cs.LG cs.CV"}, "abstract": "Pruning-quantization joint learning always facilitates the deployment of deep neural networks (DNNs) on resource-constrained edge devices. However, most existing methods do not jointly learn a global criterion for pruning and quantization in an interpretable way. In this paper, we propose a novel physics inspired criterion for pruning-quantization joint learning (PIC-PQ), which is explored from an analogy we first draw between elasticity dynamics (ED) and model compression (MC). Specifically, derived from Hooke's law in ED, we establish a linear relationship between the filters' importance distribution and the filter property (FP) by a learnable deformation scale in the physics inspired criterion (PIC). Furthermore, we extend PIC with a relative shift variable for a global view. To ensure feasibility and flexibility, available maximum bitwidth and penalty factor are introduced in quantization bitwidth assignment. Experiments on benchmarks of image classification demonstrate that PIC-PQ yields a good trade-off between accuracy and bit-operations (BOPs) compression ratio e.g., 54.96X BOPs compression ratio in ResNet56 on CIFAR10 with 0.10% accuracy drop and 53.24X in ResNet18 on ImageNet with 0.61% accuracy drop). The code will be available at https://github.com/fanxxxxyi/PIC-PQ.", "url": "https://arxiv.org/abs/2312.00851"}, {"metadata": {"arXiv": "2312.00852", "Date": "Fri, 01 Dec 2023 14:36:24 ", "Title": "Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion", "Authors": ["Litu Rout and Yujia Chen and Abhishek Kumar and Constantine Caramanis and Sanjay Shakkottai and Wen-Sheng Chu"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["Preprint"]}, "abstract": "Sampling from the posterior distribution poses a major computational challenge in solving inverse problems using latent diffusion models. Common methods rely on Tweedie's first-order moments, which are known to induce a quality-limiting bias. Existing second-order approximations are impractical due to prohibitive computational costs, making standard reverse diffusion processes intractable for posterior sampling. This paper introduces Second-order Tweedie sampler from Surrogate Loss (STSL), a novel sampler that offers efficiency comparable to first-order Tweedie with a tractable reverse process using second-order approximation. Our theoretical results reveal that the second-order approximation is lower bounded by our surrogate loss that only requires $O(1)$ compute using the trace of the Hessian, and by the lower bound we derive a new drift term to make the reverse process tractable. Our method surpasses SoTA solvers PSLD and P2L, achieving 4X and 8X reduction in neural function evaluations, respectively, while notably enhancing sampling quality on FFHQ, ImageNet, and COCO benchmarks. In addition, we show STSL extends to text-guided image editing and addresses residual distortions present from corrupted images in leading text-guided image editing methods. To our best knowledge, this is the first work to offer an efficient second-order approximation in solving inverse problems using latent diffusion and editing real-world images with corruptions.", "url": "https://arxiv.org/abs/2312.00852"}, {"metadata": {"arXiv": "2312.00907", "Date": "Fri, 01 Dec 2023 20:12:16 ", "Title": "Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence", "Authors": ["Rambod Mojgani and Daniel Waelchli and Yifei Guan and Petros Koumoutsakos and Pedram Hassanzadeh"], "Categories": "cs.LG cs.CE physics.ao-ph physics.comp-ph physics.flu-dyn"}, "abstract": "Global climate models (GCMs) are the main tools for understanding and predicting climate change. However, due to limited numerical resolutions, these models suffer from major structural uncertainties; e.g., they cannot resolve critical processes such as small-scale eddies in atmospheric and oceanic turbulence. Thus, such small-scale processes have to be represented as a function of the resolved scales via closures (parametrization). The accuracy of these closures is particularly important for capturing climate extremes. Traditionally, such closures are based on heuristics and simplifying assumptions about the unresolved physics. Recently, supervised-learned closures, trained offline on high-fidelity data, have been shown to outperform the classical physics-based closures. However, this approach requires a significant amount of high-fidelity training data and can also lead to instabilities. Reinforcement learning is emerging as a potent alternative for developing such closures as it requires only low-order statistics and leads to stable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL) computational elements serve a dual role of discretization points and learning agents. We leverage SMARL and fundamentals of turbulence physics to learn closures for prototypes of atmospheric and oceanic turbulence. The policy is trained using only the enstrophy spectrum, which is nearly invariant and can be estimated from a few high-fidelity samples (these few samples are far from enough for supervised/offline learning). We show that these closures lead to stable low-resolution simulations that, at a fraction of the cost, can reproduce the high-fidelity simulations' statistics, including the tails of the probability density functions. The results demonstrate the high potential of SMARL for closure modeling for GCMs, especially in the regime of scarce data and indirect observations.", "url": "https://arxiv.org/abs/2312.00907"}, {"metadata": {"arXiv": "2312.00923", "Date": "Fri, 01 Dec 2023 20:52:10 ", "Title": "Label Delay in Continual Learning", "Authors": ["Botos Csaba", "Wenxuan Zhang", "Matthias M\\\"uller", "Ser-Nam Lim", "Mohamed Elhoseiny", "Philip Torr", "Adel Bibi"], "Categories": "cs.LG cs.CV", "Comments": ["17 pages", "12 figures"], "ACM-class": "I.4.0; I.4.10"}, "abstract": "Online continual learning, the process of training models on streaming data, has gained increasing attention in recent years. However, a critical aspect often overlooked is the label delay, where new data may not be labeled due to slow and costly annotation processes. We introduce a new continual learning framework with explicit modeling of the label delay between data and label streams over time steps. In each step, the framework reveals both unlabeled data from the current time step $t$ and labels delayed with $d$ steps, from the time step $t-d$. In our extensive experiments amounting to 1060 GPU days, we show that merely augmenting the computational resources is insufficient to tackle this challenge. Our findings underline a notable performance decline when solely relying on labeled data when the label delay becomes significant. More surprisingly, when using state-of-the-art SSL and TTA techniques to utilize the newer, unlabeled data, they fail to surpass the performance of a na\\\"ive method that simply trains on the delayed supervised stream. To this end, we introduce a simple, efficient baseline that rehearses from the labeled memory samples that are most similar to the new unlabeled samples. This method bridges the accuracy gap caused by label delay without significantly increasing computational complexity. We show experimentally that our method is the least affected by the label delay factor and in some cases successfully recovers the accuracy of the non-delayed counterpart. We conduct various ablations and sensitivity experiments, demonstrating the effectiveness of our approach.", "url": "https://arxiv.org/abs/2312.00923"}, {"metadata": {"arXiv": "2312.00935", "Date": "Fri, 01 Dec 2023 21:29:54 ", "Title": "A Theory of Unimodal Bias in Multimodal Learning", "Authors": ["Yedi Zhang", "Peter E. Latham", "Andrew Saxe"], "Categories": "cs.LG"}, "abstract": "Using multiple input streams simultaneously in training multimodal neural networks is intuitively advantageous, but practically challenging. A key challenge is unimodal bias, where a network overly relies on one modality and ignores others during joint training. While unimodal bias is well-documented empirically, our theoretical understanding of how architecture and data statistics influence this bias remains incomplete. Here we develop a theory of unimodal bias with deep multimodal linear networks. We calculate the duration of the unimodal phase in learning as a function of the depth at which modalities are fused within the network, dataset statistics, and initialization. We find that the deeper the layer at which fusion occurs, the longer the unimodal phase. A long unimodal phase can lead to a generalization deficit and permanent unimodal bias in the overparametrized regime. In addition, our theory reveals the modality learned first is not necessarily the modality that contributes more to the output. Our results, derived for multimodal linear networks, extend to ReLU networks in certain settings. Taken together, this work illuminates pathologies of multimodal learning under joint training, showing that late and intermediate fusion architectures can give rise to long unimodal phases and permanent unimodal bias.", "url": "https://arxiv.org/abs/2312.00935"}, {"metadata": {"arXiv": "2312.00963", "Date": "Fri, 01 Dec 2023 22:39:02 ", "Title": "Spatiotemporal Transformer for Imputing Sparse Data: A Deep Learning Approach", "Authors": ["Kehui Yao", "Jingyi Huang", "Jun Zhu"], "Categories": "cs.LG stat.ME"}, "abstract": "Effective management of environmental resources and agricultural sustainability heavily depends on accurate soil moisture data. However, datasets like the SMAP/Sentinel-1 soil moisture product often contain missing values across their spatiotemporal grid, which poses a significant challenge. This paper introduces a novel Spatiotemporal Transformer model (ST-Transformer) specifically designed to address the issue of missing values in sparse spatiotemporal datasets, particularly focusing on soil moisture data. The ST-Transformer employs multiple spatiotemporal attention layers to capture the complex spatiotemporal correlations in the data and can integrate additional spatiotemporal covariates during the imputation process, thereby enhancing its accuracy. The model is trained using a self-supervised approach, enabling it to autonomously predict missing values from observed data points. Our model's efficacy is demonstrated through its application to the SMAP 1km soil moisture data over a 36 x 36 km grid in Texas. It showcases superior accuracy compared to well-known imputation methods. Additionally, our simulation studies on other datasets highlight the model's broader applicability in various spatiotemporal imputation tasks.", "url": "https://arxiv.org/abs/2312.00963"}, {"metadata": {"arXiv": "2312.00992", "Date": "Sat, 02 Dec 2023 01:17:01 ", "Title": "Improving Normative Modeling for Multi-modal Neuroimaging Data using mixture-of-product-of-experts variational autoencoders", "Authors": ["Sayantan Kumar", "Philip Payne", "Aristeidis Sotiras"], "Categories": "cs.LG", "Comments": ["IEEE Internattional Symposium in Biomedical Imaging 2024"]}, "abstract": "Normative models in neuroimaging learn the brain patterns of healthy population distribution and estimate how disease subjects like Alzheimer's Disease (AD) deviate from the norm. Existing variational autoencoder (VAE)-based normative models using multimodal neuroimaging data aggregate information from multiple modalities by estimating product or averaging of unimodal latent posteriors. This can often lead to uninformative joint latent distributions which affects the estimation of subject-level deviations. In this work, we addressed the prior limitations by adopting the Mixture-of-Product-of-Experts (MoPoE) technique which allows better modelling of the joint latent posterior. Our model labelled subjects as outliers by calculating deviations from the multimodal latent space. Further, we identified which latent dimensions and brain regions were associated with abnormal deviations due to AD pathology.", "url": "https://arxiv.org/abs/2312.00992"}, {"metadata": {"arXiv": "2312.00995", "Date": "Sat, 02 Dec 2023 01:21:41 ", "Title": "Second-Order Uncertainty Quantification: A Distance-Based Approach", "Authors": ["Yusuf Sale", "Viktor Bengs", "Michele Caprio", "Eyke H\\\"ullermeier"], "Categories": "cs.LG stat.ML", "Comments": ["16 pages", "2 figures"]}, "abstract": "In the past couple of years, various approaches to representing and quantifying different types of predictive uncertainty in machine learning, notably in the setting of classification, have been proposed on the basis of second-order probability distributions, i.e., predictions in the form of distributions on probability distributions. A completely conclusive solution has not yet been found, however, as shown by recent criticisms of commonly used uncertainty measures associated with second-order distributions, identifying undesirable theoretical properties of these measures. In light of these criticisms, we propose a set of formal criteria that meaningful uncertainty measures for predictive uncertainty based on second-order distributions should obey. Moreover, we provide a general framework for developing uncertainty measures to account for these criteria, and offer an instantiation based on the Wasserstein distance, for which we prove that all criteria are satisfied.", "url": "https://arxiv.org/abs/2312.00995"}, {"metadata": {"arXiv": "2312.01020", "Date": "Sat, 02 Dec 2023 03:55:37 ", "Title": "ResNLS: An Improved Model for Stock Price Forecasting", "Authors": ["Yuanzhe Jia", "Ali Anaissi", "Basem Suleiman"], "Categories": "cs.LG cs.CE", "Comments": ["Published to Computational Intelligence"], "DOI": "10.1111/coin.12608"}, "abstract": "Stock prices forecasting has always been a challenging task. Although many research projects adopt machine learning and deep learning algorithms to address the problem, few of them pay attention to the varying degrees of dependencies between stock prices. In this paper we introduce a hybrid model that improves stock price prediction by emphasizing the dependencies between adjacent stock prices. The proposed model, ResNLS, is mainly composed of two neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to identify dependencies between stock prices across time windows, while LSTM analyses the initial time-series data with the combination of dependencies which considered as residuals. In predicting the SSE Composite Index, our experiment reveals that when the closing price data for the previous 5 consecutive trading days is used as the input, the performance of the model (ResNLS-5) is optimal compared to those with other inputs. Furthermore, ResNLS-5 outperforms vanilla CNN, RNN, LSTM, and BiLSTM models in terms of prediction accuracy. It also demonstrates at least a 20% improvement over the current state-of-the-art baselines. To verify whether ResNLS-5 can help clients effectively avoid risks and earn profits in the stock market, we construct a quantitative trading framework for back testing. The experimental results show that the trading strategy based on predictions from ResNLS-5 can successfully mitigate losses during declining stock prices and generate profits in the periods of rising stock prices.", "url": "https://arxiv.org/abs/2312.01020"}, {"metadata": {"arXiv": "2312.01022", "Date": "Sat, 02 Dec 2023 04:14:23 ", "Title": "Advanced Language Model-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis", "Authors": ["Kiran Thorat", "Jiahui Zhao", "Yaotian Liu", "Hongwu Peng", "Xi Xie", "Bin Lei", "Jeff Zhang", "Caiwen Ding"], "Categories": "cs.LG"}, "abstract": "The increasing use of Advanced Language Models (ALMs) in diverse sectors, particularly due to their impressive capability to generate top-tier content following linguistic instructions, forms the core of this investigation. This study probes into ALMs' deployment in electronic hardware design, with a specific emphasis on the synthesis and enhancement of Verilog programming. We introduce an innovative framework, crafted to assess and amplify ALMs' productivity in this niche. The methodology commences with the initial crafting of Verilog programming via ALMs, succeeded by a distinct dual-stage refinement protocol. The premier stage prioritizes augmenting the code's operational and linguistic precision, while the latter stage is dedicated to aligning the code with Power-Performance-Area (PPA) benchmarks, a pivotal component in proficient hardware design. This bifurcated strategy, merging error remediation with PPA enhancement, has yielded substantial upgrades in the caliber of ALM-created Verilog programming. Our framework achieves an 81.37% rate in linguistic accuracy and 62.0% in operational efficacy in programming synthesis, surpassing current leading-edge techniques, such as 73% in linguistic accuracy and 46% in operational efficacy. These findings illuminate ALMs' aptitude in tackling complex technical domains and signal a positive shift in the mechanization of hardware design operations.", "url": "https://arxiv.org/abs/2312.01022"}, {"metadata": {"arXiv": "2312.01029", "Date": "Sat, 02 Dec 2023 04:42:22 ", "Title": "RNN-BOF: A Multivariate Global Recurrent Neural Network for Binary Outcome Forecasting of Inpatient Aggression", "Authors": ["Aidan Quinn", "Melanie Simmons", "Benjamin Spivak", "Christoph Bergmeir"], "Categories": "cs.LG", "Journal-ref": "In 2022 International Joint Conference on Neural Networks (IJCNN) (pp. 1-8). IEEE", "DOI": "10.1109/IJCNN55064.2022.9892527"}, "abstract": "Psychometric assessment instruments aid clinicians by providing methods of assessing the future risk of adverse events such as aggression. Existing machine learning approaches have treated this as a classification problem, predicting the probability of an adverse event in a fixed future time period from the scores produced by both psychometric instruments and clinical and demographic covariates. We instead propose modelling a patient's future risk using a time series methodology that learns from longitudinal data and produces a probabilistic binary forecast that indicates the presence of the adverse event in the next time period. Based on the recent success of Deep Neural Nets for globally forecasting across many time series, we introduce a global multivariate Recurrent Neural Network for Binary Outcome Forecasting, that trains from and for a population of patient time series to produce individual probabilistic risk assessments. We use a moving window training scheme on a real world dataset of 83 patients, where the main binary time series represents the presence of aggressive events and covariate time series represent clinical or demographic features and psychometric measures. On this dataset our approach was capable of a significant performance increase against both benchmark psychometric instruments and previously used machine learning methodologies.", "url": "https://arxiv.org/abs/2312.01029"}, {"metadata": {"arXiv": "2312.01093", "Date": "Sat, 02 Dec 2023 09:51:49 ", "Title": "Predicting Postoperative Nausea And Vomiting Using Machine Learning: A Model Development and Validation Study", "Authors": ["Maxim Glebov", "Teddy Lazebnik", "Boris Orkin", "Haim Berkenstadt", "Svetlana Bunimovich-Mendrazitsky"], "Categories": "cs.LG"}, "abstract": "Background: Postoperative nausea and vomiting (PONV) is a frequently observed complication in patients undergoing surgery under general anesthesia. Moreover, it is a frequent cause of distress and dissatisfaction during the early postoperative period. The tools used for predicting PONV at present have not yielded satisfactory results. Therefore, prognostic tools for the prediction of early and delayed PONV were developed in this study with the aim of achieving satisfactory predictive performance. Methods: The retrospective data of adult patients admitted to the post-anesthesia care unit after undergoing surgical procedures under general anesthesia at the Sheba Medical Center, Israel, between September 1, 2018, and September 1, 2023, were used in this study. An ensemble model of machine learning algorithms trained on the data of 54848 patients was developed. The k-fold cross-validation method was used followed by splitting the data to train and test sets that optimally preserve the sociodemographic features of the patients, such as age, sex, and smoking habits, using the Bee Colony algorithm. Findings: Among the 54848 patients, early and delayed PONV were observed in 2706 (4.93%) and 8218 (14.98%) patients, respectively. The proposed PONV prediction tools could correctly predict early and delayed PONV in 84.0% and 77.3% of cases, respectively, outperforming the second-best PONV prediction tool (Koivuranta score) by 13.4% and 12.9%, respectively. Feature importance analysis revealed that the performance of the proposed prediction tools aligned with previous clinical knowledge, indicating their utility. Interpretation: The machine learning-based tools developed in this study enabled improved PONV prediction, thereby facilitating personalized care and improved patient outcomes.", "url": "https://arxiv.org/abs/2312.01093"}, {"metadata": {"arXiv": "2312.01103", "Date": "Sat, 02 Dec 2023 10:40:38 ", "Title": "Code-Mixed Text to Speech Synthesis under Low-Resource Constraints", "Authors": ["Raviraj Joshi", "Nikesh Garera"], "Categories": "cs.LG", "Comments": ["Accepted at SPECOM 2023"], "DOI": "10.1007/978-3-031-48312-7_12"}, "abstract": "Text-to-speech (TTS) systems are an important component in voice-based e-commerce applications. These applications include end-to-end voice assistant and customer experience (CX) voice bot. Code-mixed TTS is also relevant in these applications since the product names are commonly described in English while the surrounding text is in a regional language. In this work, we describe our approaches for production quality code-mixed Hindi-English TTS systems built for e-commerce applications. We propose a data-oriented approach by utilizing monolingual data sets in individual languages. We leverage a transliteration model to convert the Roman text into a common Devanagari script and then combine both datasets for training. We show that such single script bi-lingual training without any code-mixing works well for pure code-mixed test sets. We further present an exhaustive evaluation of single-speaker adaptation and multi-speaker training with Tacotron2 + Waveglow setup to show that the former approach works better. These approaches are also coupled with transfer learning and decoder-only fine-tuning to improve performance. We compare these approaches with the Google TTS and report a positive CMOS score of 0.02 with the proposed transfer learning approach. We also perform low-resource voice adaptation experiments to show that a new voice can be onboarded with just 3 hrs of data. This highlights the importance of our pre-trained models in resource-constrained settings. This subjective evaluation is performed on a large number of out-of-domain pure code-mixed sentences to demonstrate the high quality of the systems.", "url": "https://arxiv.org/abs/2312.01103"}, {"metadata": {"arXiv": "2312.01107", "Date": "Sat, 02 Dec 2023 10:52:00 ", "Title": "Rapid Speaker Adaptation in Low Resource Text to Speech Systems using Synthetic Data and Transfer learning", "Authors": ["Raviraj Joshi", "Nikesh Garera"], "Categories": "cs.LG", "Comments": ["Accepted at PACLIC 2023"]}, "abstract": "Text-to-speech (TTS) systems are being built using end-to-end deep learning approaches. However, these systems require huge amounts of training data. We present our approach to built production quality TTS and perform speaker adaptation in extremely low resource settings. We propose a transfer learning approach using high-resource language data and synthetically generated data. We transfer the learnings from the out-domain high-resource English language. Further, we make use of out-of-the-box single-speaker TTS in the target language to generate in-domain synthetic data. We employ a three-step approach to train a high-quality single-speaker TTS system in a low-resource Indian language Hindi. We use a Tacotron2 like setup with a spectrogram prediction network and a waveglow vocoder. The Tacotron2 acoustic model is trained on English data, followed by synthetic Hindi data from the existing TTS system. Finally, the decoder of this model is fine-tuned on only 3 hours of target Hindi speaker data to enable rapid speaker adaptation. We show the importance of this dual pre-training and decoder-only fine-tuning using subjective MOS evaluation. Using transfer learning from high-resource language and synthetic corpus we present a low-cost solution to train a custom TTS model.", "url": "https://arxiv.org/abs/2312.01107"}, {"metadata": {"arXiv": "2312.01110", "Date": "Sat, 02 Dec 2023 11:21:00 ", "Title": "Strong Duality Relations in Nonconvex Risk-Constrained Learning", "Authors": ["Dionysis Kalogerias", "Spyridon Pougkakiotis"], "Categories": "cs.LG math.OC"}, "abstract": "We establish strong duality relations for functional two-step compositional risk-constrained learning problems with multiple nonconvex loss functions and/or learning constraints, regardless of nonconvexity and under a minimal set of technical assumptions. Our results in particular imply zero duality gaps within the class of problems under study, both extending and improving on the state of the art in (risk-neutral) constrained learning. More specifically, we consider risk objectives/constraints which involve real-valued convex and positively homogeneous risk measures admitting dual representations with bounded risk envelopes, generalizing expectations and including popular examples, such as the conditional value-at-risk (CVaR), the mean-absolute deviation (MAD), and more generally all real-valued coherent risk measures on integrable losses as special cases. Our results are based on recent advances in risk-constrained nonconvex programming in infinite dimensions, which rely on a remarkable new application of J. J. Uhl's convexity theorem, which is an extension of A. A. Lyapunov's convexity theorem for general, infinite dimensional Banach spaces. By specializing to the risk-neutral setting, we demonstrate, for the first time, that constrained classification and regression can be treated under a unifying lens, while dispensing certain restrictive assumptions enforced in the current literature, yielding a new state-of-the-art strong duality framework for nonconvex constrained learning.", "url": "https://arxiv.org/abs/2312.01110"}, {"metadata": {"arXiv": "2312.01137", "Date": "Sat, 02 Dec 2023 13:44:27 ", "Title": "Fast and Robust Sparsity-Aware Block Diagonal Representation", "Authors": ["Aylin Tastan", "Michael Muma and Abdelhak M.Zoubir"], "Categories": "cs.LG eess.SP", "Comments": ["16 pages article", "4 pages supplementary", "51 pages accompanying material"]}, "abstract": "The block diagonal structure of an affinity matrix is a commonly desired property in cluster analysis because it represents clusters of feature vectors by non-zero coefficients that are concentrated in blocks. However, recovering a block diagonal affinity matrix is challenging in real-world applications, in which the data may be subject to outliers and heavy-tailed noise that obscure the hidden cluster structure. To address this issue, we first analyze the effect of different fundamental outlier types in graph-based cluster analysis. A key idea that simplifies the analysis is to introduce a vector that represents a block diagonal matrix as a piece-wise linear function of the similarity coefficients that form the affinity matrix. We reformulate the problem as a robust piece-wise linear fitting problem and propose a Fast and Robust Sparsity-Aware Block Diagonal Representation (FRS-BDR) method, which jointly estimates cluster memberships and the number of blocks. Comprehensive experiments on a variety of real-world applications demonstrate the effectiveness of FRS-BDR in terms of clustering accuracy, robustness against corrupted features, computation time and cluster enumeration performance.", "url": "https://arxiv.org/abs/2312.01137"}, {"metadata": {"arXiv": "2312.01172", "Date": "Sat, 02 Dec 2023 16:28:09 ", "Title": "On-sensor Printed Machine Learning Classification via Bespoke ADC and Decision Tree Co-Design", "Authors": ["Giorgos Armeniakos", "Paula L. Duarte", "Priyanjana Pal", "Georgios Zervakis", "Mehdi B. Tahoori", "Dimitrios Soudris"], "Categories": "cs.LG", "Comments": ["Accepted for publication at the 27th Design", "Automation and Test in Europe Conference (DATE'24)", "Mar 25-27 2024", "Valencia", "Spain"]}, "abstract": "Printed electronics (PE) technology provides cost-effective hardware with unmet customization, due to their low non-recurring engineering and fabrication costs. PE exhibit features such as flexibility, stretchability, porosity, and conformality, which make them a prominent candidate for enabling ubiquitous computing. Still, the large feature sizes in PE limit the realization of complex printed circuits, such as machine learning classifiers, especially when processing sensor inputs is necessary, mainly due to the costly analog-to-digital converters (ADCs). To this end, we propose the design of fully customized ADCs and present, for the first time, a co-design framework for generating bespoke Decision Tree classifiers. Our comprehensive evaluation shows that our co-design enables self-powered operation of on-sensor printed classifiers in all benchmark cases.", "url": "https://arxiv.org/abs/2312.01172"}, {"metadata": {"arXiv": "2312.01178", "Date": "Sat, 02 Dec 2023 16:58:17 ", "Title": "Exploring a Hybrid Deep Learning Framework to Automatically Discover Topic and Sentiment in COVID-19 Tweets", "Authors": ["Khandaker Tayef Shahriar", "Iqbal H. Sarker"], "Categories": "cs.LG"}, "abstract": "COVID-19 has created a major public health problem worldwide and other problems such as economic crisis, unemployment, mental distress, etc. The pandemic is deadly in the world and involves many people not only with infection but also with problems, stress, wonder, fear, resentment, and hatred. Twitter is a highly influential social media platform and a significant source of health-related information, news, opinion and public sentiment where information is shared by both citizens and government sources. Therefore an effective analysis of COVID-19 tweets is essential for policymakers to make wise decisions. However, it is challenging to identify interesting and useful content from major streams of text to understand people's feelings about the important topics of the COVID-19 tweets. In this paper, we propose a new \\textit{framework} for analyzing topic-based sentiments by extracting key topics with significant labels and classifying positive, negative, or neutral tweets on each topic to quickly find common topics of public opinion and COVID-19-related attitudes. While building our model, we take into account hybridization of BiLSTM and GRU structures for sentiment analysis to achieve our goal. The experimental results show that our topic identification method extracts better topic labels and the sentiment analysis approach using our proposed hybrid deep learning model achieves the highest accuracy compared to traditional models.", "url": "https://arxiv.org/abs/2312.01178"}, {"metadata": {"arXiv": "2312.01188", "Date": "Sat, 02 Dec 2023 17:28:52 ", "Title": "Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning", "Authors": ["Soumya Roy", "Vinay K Verma and Deepak Gupta"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["To be Appeared in WACV", "2024"]}, "abstract": "This paper proposes a simple but highly efficient expansion-based model for continual learning. The recent feature transformation, masking and factorization-based methods are efficient, but they grow the model only over the global or shared parameter. Therefore, these approaches do not fully utilize the previously learned information because the same task-specific parameter forgets the earlier knowledge. Thus, these approaches show limited transfer learning ability. Moreover, most of these models have constant parameter growth for all tasks, irrespective of the task complexity. Our work proposes a simple filter and channel expansion based method that grows the model over the previous task parameters and not just over the global parameter. Therefore, it fully utilizes all the previously learned information without forgetting, which results in better knowledge transfer. The growth rate in our proposed model is a function of task complexity; therefore for a simple task, the model has a smaller parameter growth while for complex tasks, the model requires more parameters to adapt to the current task. Recent expansion based models show promising results for task incremental learning (TIL). However, for class incremental learning (CIL), prediction of task id is a crucial challenge; hence, their results degrade rapidly as the number of tasks increase. In this work, we propose a robust task prediction method that leverages entropy weighted data augmentations and the models gradient using pseudo labels. We evaluate our model on various datasets and architectures in the TIL, CIL and generative continual learning settings. The proposed approach shows state-of-the-art results in all these settings. Our extensive ablation studies show the efficacy of the proposed components.", "url": "https://arxiv.org/abs/2312.01188"}, {"metadata": {"arXiv": "2312.01197", "Date": "Sat, 02 Dec 2023 18:13:45 ", "Title": "Short-term Precipitation Forecasting in The Netherlands: An Application of Convolutional LSTM neural networks to weather radar data", "Authors": ["Petros Demetrakopoulos"], "Categories": "cs.LG", "Comments": ["6 pages", "3 figures"]}, "abstract": "This work addresses the challenge of short-term precipitation forecasting by applying Convolutional Long Short-Term Memory (ConvLSTM) neural networks to weather radar data from the Royal Netherlands Meteorological Institute (KNMI). The research exploits the combination of Convolutional Neural Networks (CNNs) layers for spatial pattern recognition and LSTM network layers for modelling temporal sequences, integrating these strengths into a ConvLSTM architecture. The model was trained and validated on weather radar data from the Netherlands. The model is an autoencoder consisting of nine layers, uniquely combining convolutional operations with LSTMs temporal processing, enabling it to capture the movement and intensity of precipitation systems. The training set comprised of sequences of radar images, with the model being tasked to predict precipitation patterns 1.5 hours ahead using the preceding data. Results indicate high accuracy in predicting the direction and intensity of precipitation movements. The findings of this study underscore the significant potential of ConvLSTM networks in meteorological forecasting, particularly in regions with complex weather patterns. It contributes to the field by offering a more accurate, data-driven approach to weather prediction, highlighting the broader applicability of ConvLSTM networks in meteorological tasks.", "url": "https://arxiv.org/abs/2312.01197"}, {"metadata": {"arXiv": "2312.01227", "Date": "Sat, 02 Dec 2023 21:10:06 ", "Title": "Distributed Bayesian Estimation in Sensor Networks: Consensus on Marginal Densities", "Authors": ["Parth Paritosh", "Nikolay Atanasov and Sonia Martinez"], "Categories": "cs.LG cs.MA cs.RO eess.SP"}, "abstract": "In this paper, we aim to design and analyze distributed Bayesian estimation algorithms for sensor networks. The challenges we address are to (i) derive a distributed provably-correct algorithm in the functional space of probability distributions over continuous variables, and (ii) leverage these results to obtain new distributed estimators restricted to subsets of variables observed by individual agents. This relates to applications such as cooperative localization and federated learning, where the data collected at any agent depends on a subset of all variables of interest. We present Bayesian density estimation algorithms using data from non-linear likelihoods at agents in centralized, distributed, and marginal distributed settings. After setting up a distributed estimation objective, we prove almost-sure convergence to the optimal set of pdfs at each agent. Then, we prove the same for a storage-aware algorithm estimating densities only over relevant variables at each agent. Finally, we present a Gaussian version of these algorithms and implement it in a mapping problem using variational inference to handle non-linear likelihood models associated with LiDAR sensing.", "url": "https://arxiv.org/abs/2312.01227"}, {"metadata": {"arXiv": "2312.01238", "Date": "Sat, 02 Dec 2023 22:24:35 ", "Title": "A deep learning pipeline for cross-sectional and longitudinal multiview data integration", "Authors": ["Sarthak Jain and Sandra E. Safo"], "Categories": "cs.LG stat.AP stat.CO stat.ME stat.ML"}, "abstract": "Biomedical research now commonly integrates diverse data types or views from the same individuals to better understand the pathobiology of complex diseases, but the challenge lies in meaningfully integrating these diverse views. Existing methods often require the same type of data from all views (cross-sectional data only or longitudinal data only) or do not consider any class outcome in the integration method, presenting limitations. To overcome these limitations, we have developed a pipeline that harnesses the power of statistical and deep learning methods to integrate cross-sectional and longitudinal data from multiple sources. Additionally, it identifies key variables contributing to the association between views and the separation among classes, providing deeper biological insights. This pipeline includes variable selection/ranking using linear and nonlinear methods, feature extraction using functional principal component analysis and Euler characteristics, and joint integration and classification using dense feed-forward networks and recurrent neural networks. We applied this pipeline to cross-sectional and longitudinal multi-omics data (metagenomics, transcriptomics, and metabolomics) from an inflammatory bowel disease (IBD) study and we identified microbial pathways, metabolites, and genes that discriminate by IBD status, providing information on the etiology of IBD. We conducted simulations to compare the two feature extraction methods. The proposed pipeline is available from the following GitHub repository: https://github.com/lasandrall/DeepIDA-GRU.", "url": "https://arxiv.org/abs/2312.01238"}, {"metadata": {"arXiv": "2312.01260", "Date": "Sun, 03 Dec 2023 02:26:58 ", "Title": "Rethinking PGD Attack: Is Sign Function Necessary?", "Authors": ["Junjie Yang", "Tianlong Chen", "Xuxi Chen", "Zhangyang Wang", "Yingbin Liang"], "Categories": "cs.LG cs.CR stat.ML"}, "abstract": "Neural networks have demonstrated success in various domains, yet their performance can be significantly degraded by even a small input perturbation. Consequently, the construction of such perturbations, known as adversarial attacks, has gained significant attention, many of which fall within \"white-box\" scenarios where we have full access to the neural network. Existing attack algorithms, such as the projected gradient descent (PGD), commonly take the sign function on the raw gradient before updating adversarial inputs, thereby neglecting gradient magnitude information. In this paper, we present a theoretical analysis of how such sign-based update algorithm influences step-wise attack performance, as well as its caveat. We also interpret why previous attempts of directly using raw gradients failed. Based on that, we further propose a new raw gradient descent (RGD) algorithm that eliminates the use of sign. Specifically, we convert the constrained optimization problem into an unconstrained one, by introducing a new hidden variable of non-clipped perturbation that can move beyond the constraint. The effectiveness of the proposed RGD algorithm has been demonstrated extensively in experiments, outperforming PGD and other competitors in various settings, without incurring any additional computational overhead. The codes is available in https://github.com/JunjieYang97/RGD.", "url": "https://arxiv.org/abs/2312.01260"}, {"metadata": {"arXiv": "2312.01267", "Date": "Sun, 03 Dec 2023 03:23:13 ", "Title": "Distributed Reinforcement Learning for Molecular Design: Antioxidant case", "Authors": ["Huanyi Qin", "Denis Akhiyarov", "Sophie Loehle", "Kenneth Chiu", "and Mauricio Araya-Polo"], "Categories": "cs.LG cs.DC q-bio.BM"}, "abstract": "Deep reinforcement learning has successfully been applied for molecular discovery as shown by the Molecule Deep Q-network (MolDQN) algorithm. This algorithm has challenges when applied to optimizing new molecules: training such a model is limited in terms of scalability to larger datasets and the trained model cannot be generalized to different molecules in the same dataset. In this paper, a distributed reinforcement learning algorithm for antioxidants, called DA-MolDQN is proposed to address these problems. State-of-the-art bond dissociation energy (BDE) and ionization potential (IP) predictors are integrated into DA-MolDQN, which are critical chemical properties while optimizing antioxidants. Training time is reduced by algorithmic improvements for molecular modifications. The algorithm is distributed, scalable for up to 512 molecules, and generalizes the model to a diverse set of molecules. The proposed models are trained with a proprietary antioxidant dataset. The results have been reproduced with both proprietary and public datasets. The proposed molecules have been validated with DFT simulations and a subset of them confirmed in public \"unseen\" datasets. In summary, DA-MolDQN is up to 100x faster than previous algorithms and can discover new optimized molecules from proprietary and public antioxidants.", "url": "https://arxiv.org/abs/2312.01267"}, {"metadata": {"arXiv": "2312.01286", "Date": "Sun, 03 Dec 2023 05:09:36 ", "Title": "Continuous Convolutional Neural Networks for Disruption Prediction in Nuclear Fusion Plasmas", "Authors": ["William F Arnold", "Lucas Spangher", "Christina Rea"], "Categories": "cs.LG physics.plasm-ph", "Comments": ["Accepted at CCAI NeurIPS 2023"]}, "abstract": "Grid decarbonization for climate change requires dispatchable carbon-free energy like nuclear fusion. The tokamak concept offers a promising path for fusion, but one of the foremost challenges in implementation is the occurrence of energetic plasma disruptions. In this study, we delve into Machine Learning approaches to predict plasma state outcomes. Our contributions are twofold: (1) We present a novel application of Continuous Convolutional Neural Networks for disruption prediction and (2) We examine the advantages and disadvantages of continuous models over discrete models for disruption prediction by comparing our model with the previous, discrete state of the art, and show that continuous models offer significantly better performance (Area Under the Receiver Operating Characteristic Curve = 0.974 v.s. 0.799) with fewer parameters", "url": "https://arxiv.org/abs/2312.01286"}, {"metadata": {"arXiv": "2312.01294", "Date": "Sun, 03 Dec 2023 05:52:30 ", "Title": "Deep Ensembles Meets Quantile Regression: Uncertainty-aware Imputation for Time Series", "Authors": ["Ying Liu", "Peng Cui", "Wenbo Hu", "Richang Hong"], "Categories": "cs.LG stat.ML"}, "abstract": "Multivariate time series are everywhere. Nevertheless, real-world time series data often exhibit numerous missing values, which is the time series imputation task. Although previous deep learning methods have been shown to be effective for time series imputation, they are shown to produce overconfident imputations, which might be a potentially overlooked threat to the reliability of the intelligence system. Score-based diffusion method(i.e., CSDI) is effective for the time series imputation task but computationally expensive due to the nature of the generative diffusion model framework. In this paper, we propose a non-generative time series imputation method that produces accurate imputations with inherent uncertainty and meanwhile is computationally efficient. Specifically, we incorporate deep ensembles into quantile regression with a shared model backbone and a series of quantile discrimination functions.This framework combines the merits of accurate uncertainty estimation of deep ensembles and quantile regression and above all, the shared model backbone tremendously reduces most of the computation overhead of the multiple ensembles. We examine the performance of the proposed method on two real-world datasets: air quality and health-care datasets and conduct extensive experiments to show that our method excels at making deterministic and probabilistic predictions. Compared with the score-based diffusion method: CSDI, we can obtain comparable forecasting results and is better when more data is missing. Furthermore, as a non-generative model compared with CSDI, the proposed method consumes a much smaller computation overhead, yielding much faster training speed and fewer model parameters.", "url": "https://arxiv.org/abs/2312.01294"}, {"metadata": {"arXiv": "2312.01299", "Date": "Sun, 03 Dec 2023 06:18:59 ", "Title": "Robust Non-parametric Knowledge-based Diffusion Least Mean Squares over Adaptive Networks", "Authors": ["Soheil Ashkezari-Toussi", "Hadi sadoghi-Yazdi"], "Categories": "cs.LG"}, "abstract": "The present study proposes incorporating non-parametric knowledge into the diffusion least-mean-squares algorithm in the framework of a maximum a posteriori (MAP) estimation. The proposed algorithm leads to a robust estimation of an unknown parameter vector in a group of cooperative estimators. Utilizing kernel density estimation and buffering some intermediate estimations, the prior distribution and conditional likelihood of the parameters vector in each node are calculated. Pseudo Huber loss function is used for designing the likelihood function. Also, an error thresholding function is defined to reduce the computational overhead as well as more relaxation against noise, which stops the update every time an error is less than a predefined threshold. The performance of the proposed algorithm is examined in the stationary and non-stationary scenarios in the presence of Gaussian and non-Gaussian noise. Results show the robustness of the proposed algorithm in the presence of different noise types.", "url": "https://arxiv.org/abs/2312.01299"}, {"metadata": {"arXiv": "2312.01342", "Date": "Sun, 03 Dec 2023 10:14:10 ", "Title": "Graph Coordinates and Conventional Neural Networks -- An Alternative for Graph Neural Networks", "Authors": ["Zheyi Qin", "Randy Paffenroth", "Anura P. Jayasumana"], "Categories": "cs.LG", "Comments": ["This paper is submitted and will be published on Big Data Conference 2023", "Data-driven Science for Graphs: Algorithms", "Architectures", "and Application workshop"]}, "abstract": "Graph-based data present unique challenges and opportunities for machine learning. Graph Neural Networks (GNNs), and especially those algorithms that capture graph topology through message passing for neighborhood aggregation, have been a leading solution. However, these networks often require substantial computational resources and may not optimally leverage the information contained in the graph's topology, particularly for large-scale or complex graphs. We propose Topology Coordinate Neural Network (TCNN) and Directional Virtual Coordinate Neural Network (DVCNN) as novel and efficient alternatives to message passing GNNs, that directly leverage the graph's topology, sidestepping the computational challenges presented by competing algorithms. Our proposed methods can be viewed as a reprise of classic techniques for graph embedding for neural network feature engineering, but they are novel in that our embedding techniques leverage ideas in Graph Coordinates (GC) that are lacking in current practice. Experimental results, benchmarked against the Open Graph Benchmark Leaderboard, demonstrate that TCNN and DVCNN achieve competitive or superior performance to message passing GNNs. For similar levels of accuracy and ROC-AUC, TCNN and DVCNN need far fewer trainable parameters than contenders of the OGBN Leaderboard. The proposed TCNN architecture requires fewer parameters than any neural network method currently listed in the OGBN Leaderboard for both OGBN-Proteins and OGBN-Products datasets. Conversely, our methods achieve higher performance for a similar number of trainable parameters. By providing an efficient and effective alternative to message passing GNNs, our work expands the toolbox of techniques for graph-based machine learning.", "url": "https://arxiv.org/abs/2312.01342"}, {"metadata": {"arXiv": "2312.01386", "Date": "Sun, 03 Dec 2023 13:20:08 ", "Title": "Regret Optimality of GP-UCB", "Authors": ["Wenjia Wang and Xiaowei Zhang and Lu Zou"], "Categories": "cs.LG stat.ML", "Comments": ["23 pages"]}, "abstract": "Gaussian Process Upper Confidence Bound (GP-UCB) is one of the most popular methods for optimizing black-box functions with noisy observations, due to its simple structure and superior performance. Its empirical successes lead to a natural, yet unresolved question: Is GP-UCB regret optimal? In this paper, we offer the first generally affirmative answer to this important open question in the Bayesian optimization literature. We establish new upper bounds on both the simple and cumulative regret of GP-UCB when the objective function to optimize admits certain smoothness property. These upper bounds match the known minimax lower bounds (up to logarithmic factors independent of the feasible region's dimensionality) for optimizing functions with the same smoothness. Intriguingly, our findings indicate that, with the same level of exploration, GP-UCB can simultaneously achieve optimality in both simple and cumulative regret. The crux of our analysis hinges on a refined uniform error bound for online estimation of functions in reproducing kernel Hilbert spaces. This error bound, which we derive from empirical process theory, is of independent interest, and its potential applications may reach beyond the scope of this study.", "url": "https://arxiv.org/abs/2312.01386"}, {"metadata": {"arXiv": "2312.01392", "Date": "Sun, 03 Dec 2023 13:39:36 ", "Title": "Neural Network Characterization and Entropy Regulated Data Balancing through Principal Component Analysis", "Authors": ["David Yevick and Karolina Hutchison"], "Categories": "cs.LG", "Comments": ["30 pages", "17 figures"]}, "abstract": "This paper examines the relationship between the behavior of a neural network and the distribution formed from the projections of the data records into the space spanned by the low-order principal components of the training data. For example, in a benchmark calculation involving rotated and unrotated MNIST digits, classes (digits) that are mapped far from the origin in a low-dimensional principal component space and that overlap minimally with other digits converge rapidly and exhibit high degrees of accuracy in neural network calculations that employ the associated components of each data record as inputs. Further, if the space spanned by these low-order principal components is divided into bins and the input data records that are mapped into a given bin averaged, the resulting pattern can be distinguished by its geometric features which interpolate between those of adjacent bins in an analogous manner to variational autoencoders. Based on this observation, a simply realized data balancing procedure can be realized by evaluating the entropy associated with each histogram bin and subsequently repeating the original image data associated with the bin by a number of times that is determined from this entropy.", "url": "https://arxiv.org/abs/2312.01392"}, {"metadata": {"arXiv": "2312.01429", "Date": "Sun, 03 Dec 2023 15:34:46 ", "Title": "Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars", "Authors": ["Kaiyue Wen", "Yuchen Li", "Bingbin Liu", "Andrej Risteski"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Interpretability methods aim to understand the algorithm implemented by a trained model (e.g., a Transofmer) by examining various aspects of the model, such as the weight matrices or the attention patterns. In this work, through a combination of theoretical results and carefully controlled experiments on synthetic data, we take a critical view of methods that exclusively focus on individual parts of the model, rather than consider the network as a whole. We consider a simple synthetic setup of learning a (bounded) Dyck language. Theoretically, we show that the set of models that (exactly or approximately) solve this task satisfy a structural characterization derived from ideas in formal languages (the pumping lemma). We use this characterization to show that the set of optima is qualitatively rich; in particular, the attention pattern of a single layer can be ``nearly randomized'', while preserving the functionality of the network. We also show via extensive experiments that these constructions are not merely a theoretical artifact: even after severely constraining the architecture of the model, vastly different solutions can be reached via standard training. Thus, interpretability claims based on inspecting individual heads or weight matrices in the Transformer can be misleading.", "url": "https://arxiv.org/abs/2312.01429"}, {"metadata": {"arXiv": "2312.01432", "Date": "Sun, 03 Dec 2023 15:44:17 ", "Title": "Fast Dual Subgradient Optimization of the Integrated Transportation Distance Between Stochastic Kernels", "Authors": ["Zhengqi Lin and Andrzej Ruszczynski"], "Categories": "cs.LG math.OC"}, "abstract": "A generalization of the Wasserstein metric, the integrated transportation distance, establishes a novel distance between probability kernels of Markov systems. This metric serves as the foundation for an efficient approximation technique, enabling the replacement of the original system's kernel with a kernel with a discrete support of limited cardinality. To facilitate practical implementation, we present a specialized dual algorithm capable of constructing these approximate kernels quickly and efficiently, without requiring computationally expensive matrix operations. Finally, we demonstrate the efficacy of our method through several illustrative examples, showcasing its utility in practical scenarios. This advancement offers new possibilities for the streamlined analysis and manipulation of stochastic systems represented by kernels.", "url": "https://arxiv.org/abs/2312.01432"}, {"metadata": {"arXiv": "2312.01456", "Date": "Sun, 03 Dec 2023 17:04:18 ", "Title": "Compositional Policy Learning in Stochastic Control Systems with Formal Guarantees", "Authors": ["{\\DJ}or{\\dj}e \\v{Z}ikeli\\'c (1)", "Mathias Lechner (2)", "Abhinav Verma (3)", "Krishnendu Chatterjee (1)", "Thomas A. Henzinger (1) ((1) Institute of Science and Technology Austria", "(2) Massachusetts Institute of Technology", "(3) The Pennsylvania State University)"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Reinforcement learning has shown promising results in learning neural network policies for complicated control tasks. However, the lack of formal guarantees about the behavior of such policies remains an impediment to their deployment. We propose a novel method for learning a composition of neural network policies in stochastic environments, along with a formal certificate which guarantees that a specification over the policy's behavior is satisfied with the desired probability. Unlike prior work on verifiable RL, our approach leverages the compositional nature of logical specifications provided in SpectRL, to learn over graphs of probabilistic reach-avoid specifications. The formal guarantees are provided by learning neural network policies together with reach-avoid supermartingales (RASM) for the graph's sub-tasks and then composing them into a global policy. We also derive a tighter lower bound compared to previous work on the probability of reach-avoidance implied by a RASM, which is required to find a compositional policy with an acceptable probabilistic threshold for complex tasks with multiple edge policies. We implement a prototype of our approach and evaluate it on a Stochastic Nine Rooms environment.", "url": "https://arxiv.org/abs/2312.01456"}, {"metadata": {"arXiv": "2312.01473", "Date": "Sun, 03 Dec 2023 18:18:44 ", "Title": "Regularity as Intrinsic Reward for Free Play", "Authors": ["Cansu Sancaktar", "Justus Piater", "Georg Martius"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023 camera-ready version. Project webpage at http://sites.google.com/view/rair-project"]}, "abstract": "We propose regularity as a novel reward signal for intrinsically-motivated reinforcement learning. Taking inspiration from child development, we postulate that striving for structure and order helps guide exploration towards a subspace of tasks that are not favored by naive uncertainty-based intrinsic rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR) allows us to operationalize it within model-based reinforcement learning. In a synthetic environment, we showcase the plethora of structured patterns that can emerge from pursuing this regularity objective. We also demonstrate the strength of our method in a multi-object robotic manipulation environment. We incorporate RaIR into free play and use it to complement the model's epistemic uncertainty as an intrinsic reward. Doing so, we witness the autonomous construction of towers and other regular structures during free play, which leads to a substantial improvement in zero-shot downstream task performance on assembly tasks.", "url": "https://arxiv.org/abs/2312.01473"}, {"metadata": {"arXiv": "2312.01502", "Date": "Sun, 03 Dec 2023 20:21:08 ", "Title": "Normed Spaces for Graph Embedding", "Authors": ["Diaaeldin Taha", "Wei Zhao", "J. Maxwell Riestenberg", "Michael Strube"], "Categories": "cs.LG cs.SI", "Comments": ["23 pages,7 figures,9 tables | The first two authors contributed equally"]}, "abstract": "Theoretical results from discrete geometry suggest that normed spaces can abstractly embed finite metric spaces with surprisingly low theoretical bounds on distortion in low dimensions. In this paper, inspired by this theoretical insight, we highlight normed spaces as a more flexible and computationally efficient alternative to several popular Riemannian manifolds for learning graph embeddings. Normed space embeddings significantly outperform several popular manifolds on a large range of synthetic and real-world graph reconstruction benchmark datasets while requiring significantly fewer computational resources. We also empirically verify the superiority of normed space embeddings on growing families of graphs associated with negative, zero, and positive curvature, further reinforcing the flexibility of normed spaces in capturing diverse graph structures as graph sizes increase. Lastly, we demonstrate the utility of normed space embeddings on two applied graph embedding tasks, namely, link prediction and recommender systems. Our work highlights the potential of normed spaces for geometric graph representation learning, raises new research questions, and offers a valuable tool for experimental mathematics in the field of finite metric space embeddings. We make our code and data publically available.", "url": "https://arxiv.org/abs/2312.01502"}, {"metadata": {"arXiv": "2312.01507", "Date": "Sun, 03 Dec 2023 21:05:50 ", "Title": "Learn2Extend: Extending sequences by retaining their statistical properties with mixture models", "Authors": ["Dimitris Vartziotis", "George Dasoulas", "Florian Pausinger"], "Categories": "cs.LG stat.ML", "Comments": ["17 pages"]}, "abstract": "This paper addresses the challenge of extending general finite sequences of real numbers within a subinterval of the real line, maintaining their inherent statistical properties by employing machine learning. Our focus lies on preserving the gap distribution and pair correlation function of these point sets. Leveraging advancements in deep learning applied to point processes, this paper explores the use of an auto-regressive \\textit{Sequence Extension Mixture Model} (SEMM) for extending finite sequences, by estimating directly the conditional density, instead of the intensity function. We perform comparative experiments on multiple types of point processes, including Poisson, locally attractive, and locally repelling sequences, and we perform a case study on the prediction of Riemann $\\zeta$ function zeroes. The results indicate that the proposed mixture model outperforms traditional neural network architectures in sequence extension with the retention of statistical properties. Given this motivation, we showcase the capabilities of a mixture model to extend sequences, maintaining specific statistical properties, i.e. the gap distribution, and pair correlation indicators.", "url": "https://arxiv.org/abs/2312.01507"}, {"metadata": {"arXiv": "2312.01538", "Date": "Sun, 03 Dec 2023 23:36:16 ", "Title": "Recurrent Distance-Encoding Neural Networks for Graph Representation Learning", "Authors": ["Yuhui Ding", "Antonio Orvieto", "Bobby He", "Thomas Hofmann"], "Categories": "cs.LG cs.NE"}, "abstract": "Graph neural networks based on iterative one-hop message passing have been shown to struggle in harnessing information from distant nodes effectively. Conversely, graph transformers allow each node to attend to all other nodes directly, but suffer from high computational complexity and have to rely on ad-hoc positional encoding to bake in the graph inductive bias. In this paper, we propose a new architecture to reconcile these challenges. Our approach stems from the recent breakthroughs in long-range modeling provided by deep state-space models on sequential data: for a given target node, our model aggregates other nodes by their shortest distances to the target and uses a parallelizable linear recurrent network over the chain of distances to provide a natural encoding of its neighborhood structure. With no need for positional encoding, we empirically show that the performance of our model is highly competitive compared with that of state-of-the-art graph transformers on various benchmarks, at a drastically reduced computational complexity. In addition, we show that our model is theoretically more expressive than one-hop message passing neural networks.", "url": "https://arxiv.org/abs/2312.01538"}, {"metadata": {"arXiv": "2312.01567", "Date": "Mon, 04 Dec 2023 01:47:05 ", "Title": "Toward Automated Quantum Variational Machine Learning", "Authors": ["Omer Subasi"], "Categories": "cs.LG cs.ET quant-ph"}, "abstract": "In this work, we address the problem of automating quantum variational machine learning. We develop a multi-locality parallelizable search algorithm, called MUSE, to find the initial points and the sets of parameters that achieve the best performance for quantum variational circuit learning. Simulations with five real-world classification datasets indicate that on average, MUSE improves the detection accuracy of quantum variational classifiers 2.3 times with respect to the observed lowest scores. Moreover, when applied to two real-world regression datasets, MUSE improves the quality of the predictions from negative coefficients of determination to positive ones. Furthermore, the classification and regression scores of the quantum variational models trained with MUSE are on par with the classical counterparts.", "url": "https://arxiv.org/abs/2312.01567"}, {"metadata": {"arXiv": "2312.01577", "Date": "Mon, 04 Dec 2023 02:23:32 ", "Title": "RJHMC-Tree for Exploration of the Bayesian Decision Tree Posterior", "Authors": ["Jodie A. Cochrane", "Adrian G. Wills", "Sarah J. Johnson"], "Categories": "cs.LG stat.CO stat.ML", "Comments": ["43 pages", "7 figures"]}, "abstract": "Decision trees have found widespread application within the machine learning community due to their flexibility and interpretability. This paper is directed towards learning decision trees from data using a Bayesian approach, which is challenging due to the potentially enormous parameter space required to span all tree models. Several approaches have been proposed to combat this challenge, with one of the more successful being Markov chain Monte Carlo (MCMC) methods. The efficacy and efficiency of MCMC methods fundamentally rely on the quality of the so-called proposals, which is the focus of this paper. In particular, this paper investigates using a Hamiltonian Monte Carlo (HMC) approach to explore the posterior of Bayesian decision trees more efficiently by exploiting the geometry of the likelihood within a global update scheme. Two implementations of the novel algorithm are developed and compared to existing methods by testing against standard datasets in the machine learning and Bayesian decision tree literature. HMC-based methods are shown to perform favourably with respect to predictive test accuracy, acceptance rate, and tree complexity.", "url": "https://arxiv.org/abs/2312.01577"}, {"metadata": {"arXiv": "2312.01606", "Date": "Mon, 04 Dec 2023 03:38:17 ", "Title": "Deep Learning-Driven Enhancement of Welding Quality Control: Predicting Welding Depth and Pore Volume in Hairpin Welding", "Authors": ["Amena Darwish", "Stefan Ericson", "Rohollah Ghasemi", "Tobias Andersson", "Dan L\\\"onn", "Andreas Andersson Lassila", "Kent Salomonsson"], "Categories": "cs.LG"}, "abstract": "To advance quality assurance in the welding process, this study presents a robust deep learning model that enables the prediction of two critical welds Key Performance Characteristics (KPCs): welding depth and average pore volume. In the proposed approach, a comprehensive range of laser welding Key Input Characteristics (KICs) is utilized, including welding beam geometries, welding feed rates, path repetitions for weld beam geometries, and bright light weld ratios for all paths, all of which were obtained from hairpin welding experiments. Two deep learning networks are employed with multiple hidden dense layers and linear activation functions to showcase the capabilities of deep neural networks in capturing the intricate nonlinear connections inherent within welding KPCs and KICs. Applying deep learning networks to the small numerical experimental hairpin welding dataset has shown promising results, achieving Mean Absolute Error (MAE) values as low as 0.1079 for predicting welding depth and 0.0641 for average pore volume. Additionally, the validity verification demonstrates the reliability of the proposed method. This, in turn, promises significant advantages in controlling welding outcomes, moving beyond the current trend of relying merely on monitoring for defect classification.", "url": "https://arxiv.org/abs/2312.01606"}, {"metadata": {"arXiv": "2312.01619", "Date": "Mon, 04 Dec 2023 04:20:38 ", "Title": "How Many Validation Labels Do You Need? Exploring the Design Space of Label-Efficient Model Ranking", "Authors": ["Zhengyu Hu", "Jieyu Zhang", "Yue Yu", "Yuchen Zhuang", "Hui Xiong"], "Categories": "cs.LG"}, "abstract": "The paper introduces LEMR, a framework that reduces annotation costs for model selection tasks. Our approach leverages ensemble methods to generate pseudo-labels, employs uncertainty sampling for target acquisition, and utilizes a Z-score mechanism for iterative committee reelection to refine model ranks. We present a systematic study across various selection metrics, demonstrating that LEMR achieves comparable results to fully labeled datasets with a fraction of the labeling budget. Our findings indicate that LEMR not only economizes the labeling effort in weak supervision and semi-supervised learning settings but also effectively guides prompt selection for large language models. With extensive experiments across 23 tasks, we reveal that our framework can dramatically decrease the labeling cost without compromising the accuracy of model selection, thereby offering a cost-effective alternative to traditional practices.", "url": "https://arxiv.org/abs/2312.01619"}, {"metadata": {"arXiv": "2312.01634", "Date": "Mon, 04 Dec 2023 05:29:28 ", "Title": "Robust Streaming, Sampling, and a Perspective on Online Learning", "Authors": ["Evan Dogariu", "Jiatong Yu"], "Categories": "cs.LG cs.GT stat.ML"}, "abstract": "In this work we present an overview of statistical learning, followed by a survey of robust streaming techniques and challenges, culminating in several rigorous results proving the relationship that we motivate and hint at throughout the journey. Furthermore, we unify often disjoint theorems in a shared framework and notation to clarify the deep connections that are discovered. We hope that by approaching these results from a shared perspective, already aware of the technical connections that exist, we can enlighten the study of both fields and perhaps motivate new and previously unconsidered directions of research.", "url": "https://arxiv.org/abs/2312.01634"}, {"metadata": {"arXiv": "2312.01653", "Date": "Mon, 04 Dec 2023 06:11:39 ", "Title": "An End-to-End Network Pruning Pipeline with Sparsity Enforcement", "Authors": ["Evan Dogariu"], "Categories": "cs.LG"}, "abstract": "Neural networks have emerged as a powerful tool for solving complex tasks across various domains, but their increasing size and computational requirements have posed significant challenges in deploying them on resource-constrained devices. Neural network sparsification, and in particular pruning, has emerged as an effective technique to alleviate these challenges by reducing model size, computational complexity, and memory footprint while maintaining competitive performance. However, many pruning pipelines modify the standard training pipeline at only a single stage, if at all. In this work, we look to develop an end-to-end training pipeline that befits neural network pruning and sparsification at all stages of training. To do so, we make use of nonstandard model parameter initialization, pre-pruning training methodologies, and post-pruning training optimizations. We conduct experiments utilizing combinations of these methods, in addition to different techniques used in the pruning step, and find that our combined pipeline can achieve significant gains over current state of the art approaches to neural network sparsification.", "url": "https://arxiv.org/abs/2312.01653"}, {"metadata": {"arXiv": "2312.01658", "Date": "Mon, 04 Dec 2023 06:20:14 ", "Title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix", "Authors": ["Yun Yue", "Zhiling Ye", "Jiadi Jiang", "Yongchao Liu", "Ke Zhang"], "Categories": "cs.LG cs.DC math.OC", "Comments": ["21 pages. Accepted as a conference paper at NeurIPS '23"]}, "abstract": "Adaptive optimizers, such as Adam, have achieved remarkable success in deep learning. A key component of these optimizers is the so-called preconditioning matrix, providing enhanced gradient information and regulating the step size of each gradient direction. In this paper, we propose a novel approach to designing the preconditioning matrix by utilizing the gradient difference between two successive steps as the diagonal elements. These diagonal elements are closely related to the Hessian and can be perceived as an approximation of the inner product between the Hessian row vectors and difference of the adjacent parameter vectors. Additionally, we introduce an auto-switching function that enables the preconditioning matrix to switch dynamically between Stochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these two techniques, we develop a new optimizer named AGD that enhances the generalization performance. We evaluate AGD on public datasets of Natural Language Processing (NLP), Computer Vision (CV), and Recommendation Systems (RecSys). Our experimental results demonstrate that AGD outperforms the state-of-the-art (SOTA) optimizers, achieving highly competitive or significantly better predictive performance. Furthermore, we analyze how AGD is able to switch automatically between SGD and the adaptive optimizer and its actual effects on various scenarios. The code is available at https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.", "url": "https://arxiv.org/abs/2312.01658"}, {"metadata": {"arXiv": "2312.01674", "Date": "Mon, 04 Dec 2023 06:51:46 ", "Title": "EDALearn: A Comprehensive RTL-to-Signoff EDA Benchmark for Democratized and Reproducible ML for EDA Research", "Authors": ["Jingyu Pan", "Chen-Chia Chang", "Zhiyao Xie", "Yiran Chen"], "Categories": "cs.LG", "Comments": ["8 pages"]}, "abstract": "The application of Machine Learning (ML) in Electronic Design Automation (EDA) for Very Large-Scale Integration (VLSI) design has garnered significant research attention. Despite the requirement for extensive datasets to build effective ML models, most studies are limited to smaller, internally generated datasets due to the lack of comprehensive public resources. In response, we introduce EDALearn, the first holistic, open-source benchmark suite specifically for ML tasks in EDA. This benchmark suite presents an end-to-end flow from synthesis to physical implementation, enriching data collection across various stages. It fosters reproducibility and promotes research into ML transferability across different technology nodes. Accommodating a wide range of VLSI design instances and sizes, our benchmark aptly represents the complexity of contemporary VLSI designs. Additionally, we provide an in-depth data analysis, enabling users to fully comprehend the attributes and distribution of our data, which is essential for creating efficient ML models. Our contributions aim to encourage further advances in the ML-EDA domain.", "url": "https://arxiv.org/abs/2312.01674"}, {"metadata": {"arXiv": "2312.01687", "Date": "Mon, 04 Dec 2023 07:21:27 ", "Title": "Optimizing Bus Travel: A Novel Approach to Feature Mining with P-KMEANS and P-LDA Algorithms", "Authors": ["Hongjie Liu", "Haotian Shi", "Sicheng Fu", "Tengfei Yuan", "Xinhuan Zhang", "Hongzhe Xu", "Bin Ran"], "Categories": "cs.LG"}, "abstract": "Customizing services for bus travel can bolster its attractiveness, optimize usage, alleviate traffic congestion, and diminish carbon emissions. This potential is realized by harnessing recent advancements in positioning communication facilities, the Internet of Things, and artificial intelligence for feature mining in public transportation. However, the inherent complexities of disorganized and unstructured public transportation data introduce substantial challenges to travel feature extraction. This study presents a bus travel feature extraction method rooted in Point of Interest (POI) data, employing enhanced P-KMENAS and P-LDA algorithms to overcome these limitations. While the KMEANS algorithm adeptly segments passenger travel paths into distinct clusters, its outcomes can be influenced by the initial K value. On the other hand, Latent Dirichlet Allocation (LDA) excels at feature identification and probabilistic interpretations yet encounters difficulties with feature intermingling and nuanced sub-feature interactions. Incorporating the POI dimension enhances our understanding of travel behavior, aligning it more closely with passenger attributes and facilitating easier data analysis. By incorporating POI data, our refined P-KMENAS and P-LDA algorithms grant a holistic insight into travel behaviors and attributes, effectively mitigating the limitations above. Consequently, this POI-centric algorithm effectively amalgamates diverse POI attributes, delineates varied travel contexts, and imparts probabilistic metrics to feature properties. Our method successfully mines the diverse aspects of bus travel, such as age, occupation, gender, sports, cost, safety, and personality traits. It effectively calculates relationships between individual travel behaviors and assigns explanatory and evaluative probabilities to POI labels, thereby enhancing bus travel optimization.", "url": "https://arxiv.org/abs/2312.01687"}, {"metadata": {"arXiv": "2312.01721", "Date": "Mon, 04 Dec 2023 08:23:00 ", "Title": "The Self-Loop Paradox: Investigating the Impact of Self-Loops on Graph Neural Networks", "Authors": ["Moritz Lampert", "Ingo Scholtes"], "Categories": "cs.LG", "Comments": ["Presented at the Second Learning on Graphs Conference (LoG 2023) as extended abstract"]}, "abstract": "Many Graph Neural Networks (GNNs) add self-loops to a graph to include feature information about a node itself at each layer. However, if the GNN consists of more than one layer, this information can return to its origin via cycles in the graph topology. Intuition suggests that this \"backflow\" of information should be larger in graphs with self-loops compared to graphs without. In this work, we counter this intuition and show that for certain GNN architectures, the information a node gains from itself can be smaller in graphs with self-loops compared to the same graphs without. We adopt an analytical approach for the study of statistical graph ensembles with a given degree sequence and show that this phenomenon, which we call the self-loop paradox, can depend both on the number of GNN layers $k$ and whether $k$ is even or odd. We experimentally validate our theoretical findings in a synthetic node classification task and investigate its practical relevance in 23 real-world graphs.", "url": "https://arxiv.org/abs/2312.01721"}, {"metadata": {"arXiv": "2312.01728", "Date": "Mon, 04 Dec 2023 08:35:31 ", "Title": "ImputeFormer: Graph Transformers for Generalizable Spatiotemporal Imputation", "Authors": ["Tong Nie", "Guoyang Qin", "Yuewen Mei", "and Jian Sun"], "Categories": "cs.LG"}, "abstract": "This paper focuses on the multivariate time series imputation problem using deep neural architectures. The ubiquitous issue of missing data in both scientific and engineering tasks necessitates the development of an effective and general imputation model. Leveraging the wisdom and expertise garnered from low-rank imputation methods, we power the canonical Transformers with three key knowledge-driven enhancements, including projected temporal attention, global adaptive graph convolution, and Fourier imputation loss. These task-agnostic inductive biases exploit the inherent structures of incomplete time series, and thus make our model versatile for a variety of imputation problems. We demonstrate its superiority in terms of accuracy, efficiency, and flexibility on heterogeneous datasets, including traffic speed, traffic volume, solar energy, smart metering, and air quality. Comprehensive case studies are performed to further strengthen the interpretability. Promising empirical results provide strong conviction that incorporating time series primitives, such as low-rank properties, can substantially facilitate the development of a generalizable model to approach a wide range of spatiotemporal imputation problems.", "url": "https://arxiv.org/abs/2312.01728"}, {"metadata": {"arXiv": "2312.01729", "Date": "Mon, 04 Dec 2023 08:38:54 ", "Title": "EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly Detection in Multivariate Time Series", "Authors": ["Jie Liu", "Qilin Li", "Senjian An", "Bradley Ezard", "and Ling Li"], "Categories": "cs.LG"}, "abstract": "Transformer-based models for anomaly detection in multivariate time series can benefit from the self-attention mechanism due to its advantage in modeling long-term dependencies. However, Transformer-based anomaly detection models have problems such as a large amount of data being required for training, standard positional encoding is not suitable for multivariate time series data, and the interdependence between time series is not considered. To address these limitations, we propose a novel anomaly detection method, named EdgeConvFormer, which integrates Time2vec embedding, stacked dynamic graph CNN, and Transformer to extract global and local spatial-time information. This design of EdgeConvFormer empowers it with decomposition capacities for complex time series, progressive spatiotemporal correlation discovery between time series, and representation aggregation of multi-scale features. Experiments demonstrate that EdgeConvFormer can learn the spatial-temporal correlations from multivariate time series data and achieve better anomaly detection performance than the state-of-the-art approaches on many real-world datasets of different scales.", "url": "https://arxiv.org/abs/2312.01729"}, {"metadata": {"arXiv": "2312.01753", "Date": "Mon, 04 Dec 2023 09:27:03 ", "Title": "Long-Tail Learning with Rebalanced Contrastive Loss", "Authors": ["Charika De Alvis", "Dishanika Denipitiyage", "Suranga Seneviratne"], "Categories": "cs.LG cs.CV"}, "abstract": "Integrating supervised contrastive loss to cross entropy-based communication has recently been proposed as a solution to address the long-tail learning problem. However, when the class imbalance ratio is high, it requires adjusting the supervised contrastive loss to support the tail classes, as the conventional contrastive learning is biased towards head classes by default. To this end, we present Rebalanced Contrastive Learning (RCL), an efficient means to increase the long tail classification accuracy by addressing three main aspects: 1. Feature space balancedness - Equal division of the feature space among all the classes, 2. Intra-Class compactness - Reducing the distance between same-class embeddings, 3. Regularization - Enforcing larger margins for tail classes to reduce overfitting. RCL adopts class frequency-based SoftMax loss balancing to supervised contrastive learning loss and exploits scalar multiplied features fed to the contrastive learning loss to enforce compactness. We implement RCL on the Balanced Contrastive Learning (BCL) Framework, which has the SOTA performance. Our experiments on three benchmark datasets demonstrate the richness of the learnt embeddings and increased top-1 balanced accuracy RCL provides to the BCL framework. We further demonstrate that the performance of RCL as a standalone loss also achieves state-of-the-art level accuracy.", "url": "https://arxiv.org/abs/2312.01753"}, {"metadata": {"arXiv": "2312.01792", "Date": "Mon, 04 Dec 2023 10:27:38 ", "Title": "Wild-Tab: A Benchmark For Out-Of-Distribution Generalization In Tabular Regression", "Authors": ["Sergey Kolesnikov"], "Categories": "cs.LG"}, "abstract": "Out-of-Distribution (OOD) generalization, a cornerstone for building robust machine learning models capable of handling data diverging from the training set's distribution, is an ongoing challenge in deep learning. While significant progress has been observed in computer vision and natural language processing, its exploration in tabular data, ubiquitous in many industrial applications, remains nascent. To bridge this gap, we present Wild-Tab, a large-scale benchmark tailored for OOD generalization in tabular regression tasks. The benchmark incorporates 3 industrial datasets sourced from fields like weather prediction and power consumption estimation, providing a challenging testbed for evaluating OOD performance under real-world conditions. Our extensive experiments, evaluating 10 distinct OOD generalization methods on Wild-Tab, reveal nuanced insights. We observe that many of these methods often struggle to maintain high-performance levels on unseen data, with OOD performance showing a marked drop compared to in-distribution performance. At the same time, Empirical Risk Minimization (ERM), despite its simplicity, delivers robust performance across all evaluations, rivaling the results of state-of-the-art methods. Looking forward, we hope that the release of Wild-Tab will facilitate further research on OOD generalization and aid in the deployment of machine learning models in various real-world contexts where handling distribution shifts is a crucial requirement.", "url": "https://arxiv.org/abs/2312.01792"}, {"metadata": {"arXiv": "2312.01795", "Date": "Mon, 04 Dec 2023 10:35:46 ", "Title": "Distributed Continual Learning with CoCoA in High-dimensional Linear Regression", "Authors": ["Martin Hellkvist", "Ay\\c{c}a \\\"Oz\\c{c}elikkale", "Anders Ahl\\'en"], "Categories": "cs.LG eess.SP"}, "abstract": "We consider estimation under scenarios where the signals of interest exhibit change of characteristics over time. In particular, we consider the continual learning problem where different tasks, e.g., data with different distributions, arrive sequentially and the aim is to perform well on the newly arrived task without performance degradation on the previously seen tasks. In contrast to the continual learning literature focusing on the centralized setting, we investigate the problem from a distributed estimation perspective. We consider the well-established distributed learning algorithm COCOA, which distributes the model parameters and the corresponding features over the network. We provide exact analytical characterization for the generalization error of COCOA under continual learning for linear regression in a range of scenarios, where overparameterization is of particular interest. These analytical results characterize how the generalization error depends on the network structure, the task similarity and the number of tasks, and show how these dependencies are intertwined. In particular, our results show that the generalization error can be significantly reduced by adjusting the network size, where the most favorable network size depends on task similarity and the number of tasks. We present numerical results verifying the theoretical analysis and illustrate the continual learning performance of COCOA with a digit classification task.", "url": "https://arxiv.org/abs/2312.01795"}, {"metadata": {"arXiv": "2312.01816", "Date": "Mon, 04 Dec 2023 11:45:44 ", "Title": "Class Symbolic Regression: Gotta Fit 'Em All", "Authors": ["Wassim Tenachi", "Rodrigo Ibata", "Thibaut L. Fran\\c{c}ois", "Foivos I. Diakogiannis"], "Categories": "cs.LG astro-ph.GA astro-ph.IM physics.comp-ph", "Comments": ["7 pages", "1 figure", "2 tables. Submitted to ApJL"]}, "abstract": "We introduce \"Class Symbolic Regression\" a first framework for automatically finding a single analytical functional form that accurately fits multiple datasets - each governed by its own (possibly) unique set of fitting parameters. This hierarchical framework leverages the common constraint that all the members of a single class of physical phenomena follow a common governing law. Our approach extends the capabilities of our earlier Physical Symbolic Optimization ($\\Phi$-SO) framework for Symbolic Regression, which integrates dimensional analysis constraints and deep reinforcement learning for symbolic analytical function discovery from data. We demonstrate the efficacy of this novel approach by applying it to a panel of synthetic toy case datasets and showcase its practical utility for astrophysics by successfully extracting an analytic galaxy potential from a set of simulated orbits approximating stellar streams.", "url": "https://arxiv.org/abs/2312.01816"}, {"metadata": {"arXiv": "2312.01878", "Date": "Mon, 04 Dec 2023 13:20:15 ", "Title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning", "Authors": ["Xingtong Yu", "Zemin Liu", "Yuan Fang", "Xinming Zhang"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs) are prominent techniques for homogeneous and heterogeneous graph representation learning, yet their performance in an end-to-end supervised framework greatly depends on the availability of task-specific supervision. To reduce the labeling cost, pre-training on self-supervised pretext tasks has become a popular paradigm,but there is often a gap between the pre-trained model and downstream tasks, stemming from the divergence in their objectives. To bridge the gap, prompt learning has risen as a promising direction especially in few-shot settings, without the need to fully fine-tune the pre-trained model. While there has been some early exploration of prompt-based learning on graphs, they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs that are prevalent in downstream applications. In this paper, we propose HGPROMPT, a novel pre-training and prompting framework to unify not only pre-training and downstream tasks but also homogeneous and heterogeneous graphs via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to assist a downstream task in locating the most relevant prior to bridge the gaps caused by not only feature variations but also heterogeneity differences across tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive experiments on three public datasets.", "url": "https://arxiv.org/abs/2312.01878"}, {"metadata": {"arXiv": "2312.01887", "Date": "Mon, 04 Dec 2023 13:40:22 ", "Title": "Non-Intrusive Load Monitoring for Feeder-Level EV Charging Detection: Sliding Window-based Approaches to Offline and Online Detection", "Authors": ["Cameron Martin", "Fucai Ke", "Hao Wang"], "Categories": "cs.LG eess.SP", "Comments": ["The 7th IEEE Conference on Energy Internet and Energy System Integration (EI2 2023)"]}, "abstract": "Understanding electric vehicle (EV) charging on the distribution network is key to effective EV charging management and aiding decarbonization across the energy and transport sectors. Advanced metering infrastructure has allowed distribution system operators and utility companies to collect high-resolution load data from their networks. These advancements enable the non-intrusive load monitoring (NILM) technique to detect EV charging using load measurement data. While existing studies primarily focused on NILM for EV charging detection in individual households, there is a research gap on EV charging detection at the feeder level, presenting unique challenges due to the combined load measurement from multiple households. In this paper, we develop a novel and effective approach for EV detection at the feeder level, involving sliding-window feature extraction and classical machine learning techniques, specifically models like XGBoost and Random Forest. Our developed method offers a lightweight and efficient solution, capable of quick training. Moreover, our developed method is versatile, supporting both offline and online EV charging detection. Our experimental results demonstrate high-accuracy EV charging detection at the feeder level, achieving an F-Score of 98.88% in offline detection and 93.01% in online detection.", "url": "https://arxiv.org/abs/2312.01887"}, {"metadata": {"arXiv": "2312.01991", "Date": "Mon, 04 Dec 2023 16:10:34 ", "Title": "Information Modified K-Nearest Neighbor", "Authors": ["Mohammad Ali Vahedifar", "Azim Akhtarshenas", "Mariam Sabbaghian", "Mohammad Rafatpanah"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "In this research paper, we introduce a novel classification method aimed at improving the performance of the K-Nearest Neighbors (KNN) algorithm. Our approach leverages Mutual Information (MI) to enhance the significance of weights and draw inspiration from Shapley values, a concept originating from cooperative game theory, to refine value allocation. The fundamental concept underlying KNN is the classification of samples based on the majority thorough their k-nearest neighbors. While both the distances and labels of these neighbors are crucial, traditional KNN assigns equal weight to all samples and prevance considering the varying importance of each neighbor based on their distances and labels. In the proposed method, known as Information-Modified KNN (IMKNN), we address this issue by introducing a straightforward algorithm. To evaluate the effectiveness of our approach, it is compared with 7 contemporary variants of KNN, as well as the traditional KNN. Each of these variants exhibits its unique advantages and limitations. We conduct experiments on 12 widely-used datasets, assessing the methods' performance in terms of accuracy, precision and recall. Our study demonstrates that IMKNN consistently outperforms other methods across different datasets and criteria by highlighting its superior performance in various classification tasks. These findings underscore the potential of IMKNN as a valuable tool for enhancing the capabilities of the KNN algorithm in diverse applications.", "url": "https://arxiv.org/abs/2312.01991"}, {"metadata": {"arXiv": "2312.01994", "Date": "Mon, 04 Dec 2023 16:14:43 ", "Title": "A Generative Self-Supervised Framework using Functional Connectivity in fMRI Data", "Authors": ["Jungwon Choi", "Seongho Keum", "EungGu Yun", "Byung-Hoon Kim", "Juho Lee"], "Categories": "cs.LG cs.CV eess.IV q-bio.NC", "Comments": ["NeurIPS 2023 Temporal Graph Learning Workshop"]}, "abstract": "Deep neural networks trained on Functional Connectivity (FC) networks extracted from functional Magnetic Resonance Imaging (fMRI) data have gained popularity due to the increasing availability of data and advances in model architectures, including Graph Neural Network (GNN). Recent research on the application of GNN to FC suggests that exploiting the time-varying properties of the FC could significantly improve the accuracy and interpretability of the model prediction. However, the high cost of acquiring high-quality fMRI data and corresponding phenotypic labels poses a hurdle to their application in real-world settings, such that a model na\\\"ively trained in a supervised fashion can suffer from insufficient performance or a lack of generalization on a small number of data. In addition, most Self-Supervised Learning (SSL) approaches for GNNs to date adopt a contrastive strategy, which tends to lose appropriate semantic information when the graph structure is perturbed or does not leverage both spatial and temporal information simultaneously. In light of these challenges, we propose a generative SSL approach that is tailored to effectively harness spatio-temporal information within dynamic FC. Our empirical results, experimented with large-scale (>50,000) fMRI datasets, demonstrate that our approach learns valuable representations and enables the construction of accurate and robust models when fine-tuned for downstream tasks.", "url": "https://arxiv.org/abs/2312.01994"}, {"metadata": {"arXiv": "2312.02012", "Date": "Mon, 04 Dec 2023 16:36:29 ", "Title": "Optimal Data Generation in Multi-Dimensional Parameter Spaces, using Bayesian Optimization", "Authors": ["M. R. Mahani", "Igor A. Nechepurenko", "Yasmin Rahimof", "Andreas Wicht"], "Categories": "cs.LG physics.app-ph physics.comp-ph", "Comments": ["9 pages", "3 figures"]}, "abstract": "Acquiring a substantial number of data points for training accurate machine learning (ML) models is a big challenge in scientific fields where data collection is resource-intensive. Here, we propose a novel approach for constructing a minimal yet highly informative database for training ML models in complex multi-dimensional parameter spaces. To achieve this, we mimic the underlying relation between the output and input parameters using Gaussian process regression (GPR). Using a set of known data, GPR provides predictive means and standard deviation for the unknown data. Given the predicted standard deviation by GPR, we select data points using Bayesian optimization to obtain an efficient database for training ML models. We compare the performance of ML models trained on databases obtained through this method, with databases obtained using traditional approaches. Our results demonstrate that the ML models trained on the database obtained using Bayesian optimization approach consistently outperform the other two databases, achieving high accuracy with a significantly smaller number of data points. Our work contributes to the resource-efficient collection of data in high-dimensional complex parameter spaces, to achieve high precision machine learning predictions.", "url": "https://arxiv.org/abs/2312.02012"}, {"metadata": {"arXiv": "2312.02037", "Date": "Mon, 04 Dec 2023 16:54:40 ", "Title": "GFS: Graph-based Feature Synthesis for Prediction over Relational Databases", "Authors": ["Han Zhang", "Quan Gan", "David Wipf", "Weinan Zhang"], "Categories": "cs.LG cs.DB", "Comments": ["13 pages", "5 figures", "VLDB 2024 under review"]}, "abstract": "Relational databases are extensively utilized in a variety of modern information system applications, and they always carry valuable data patterns. There are a huge number of data mining or machine learning tasks conducted on relational databases. However, it is worth noting that there are limited machine learning models specifically designed for relational databases, as most models are primarily tailored for single table settings. Consequently, the prevalent approach for training machine learning models on data stored in relational databases involves performing feature engineering to merge the data from multiple tables into a single table and subsequently applying single table models. This approach not only requires significant effort in feature engineering but also destroys the inherent relational structure present in the data. To address these challenges, we propose a novel framework called Graph-based Feature Synthesis (GFS). GFS formulates the relational database as a heterogeneous graph, thereby preserving the relational structure within the data. By leveraging the inductive bias from single table models, GFS effectively captures the intricate relationships inherent in each table. Additionally, the whole framework eliminates the need for manual feature engineering. In the extensive experiment over four real-world multi-table relational databases, GFS outperforms previous methods designed for relational databases, demonstrating its superior performance.", "url": "https://arxiv.org/abs/2312.02037"}, {"metadata": {"arXiv": "2312.02079", "Date": "Mon, 04 Dec 2023 17:46:57 ", "Title": "Deep Set Neural Networks for forecasting asynchronous bioprocess timeseries", "Authors": ["Maxim Borisyak", "Stefan Born", "Peter Neubauer and Nicol\\'as Cruz-Bournazou"], "Categories": "cs.LG", "Comments": ["9 pages", "3 figures"]}, "abstract": "Cultivation experiments often produce sparse and irregular time series. Classical approaches based on mechanistic models, like Maximum Likelihood fitting or Monte-Carlo Markov chain sampling, can easily account for sparsity and time-grid irregularities, but most statistical and Machine Learning tools are not designed for handling sparse data out-of-the-box. Among popular approaches there are various schemes for filling missing values (imputation) and interpolation into a regular grid (alignment). However, such methods transfer the biases of the interpolation or imputation models to the target model. We show that Deep Set Neural Networks equipped with triplet encoding of the input data can successfully handle bio-process data without any need for imputation or alignment procedures. The method is agnostic to the particular nature of the time series and can be adapted for any task, for example, online monitoring, predictive control, design of experiments, etc. In this work, we focus on forecasting. We argue that such an approach is especially suitable for typical cultivation processes, demonstrate the performance of the method on several forecasting tasks using data generated from macrokinetic growth models under realistic conditions, and compare the method to a conventional fitting procedure and methods based on imputation and alignment.", "url": "https://arxiv.org/abs/2312.02079"}, {"metadata": {"arXiv": "2312.02095", "Date": "Mon, 04 Dec 2023 18:13:58 ", "Title": "Single-sample versus case-control sampling scheme for Positive Unlabeled data: the story of two scenarios", "Authors": ["Jan Mielniczuk", "Adam Wawrze\\'nczyk"], "Categories": "cs.LG"}, "abstract": "In the paper we argue that performance of the classifiers based on Empirical Risk Minimization (ERM) for positive unlabeled data, which are designed for case-control sampling scheme may significantly deteriorate when applied to a single-sample scenario. We reveal why their behavior depends, in all but very specific cases, on the scenario. Also, we introduce a single-sample case analogue of the popular non-negative risk classifier designed for case-control data and compare its performance with the original proposal. We show that the significant differences occur between them, especiall when half or more positive of observations are labeled. The opposite case when ERM minimizer designed for the case-control case is applied for single-sample data is also considered and similar conclusions are drawn. Taking into account difference of scenarios requires a sole, but crucial, change in the definition of the Empirical Risk.", "url": "https://arxiv.org/abs/2312.02095"}, {"metadata": {"arXiv": "2312.02102", "Date": "Mon, 04 Dec 2023 18:26:31 ", "Title": "Mitigating Data Injection Attacks on Federated Learning", "Authors": ["Or Shalom", "Amir Leshem", "Waheed U. Bajwa"], "Categories": "cs.LG cs.CR eess.SP"}, "abstract": "Federated learning is a technique that allows multiple entities to collaboratively train models using their data without compromising data privacy. However, despite its advantages, federated learning can be susceptible to false data injection attacks. In these scenarios, a malicious entity with control over specific agents in the network can manipulate the learning process, leading to a suboptimal model. Consequently, addressing these data injection attacks presents a significant research challenge in federated learning systems. In this paper, we propose a novel technique to detect and mitigate data injection attacks on federated learning systems. Our mitigation method is a local scheme, performed during a single instance of training by the coordinating node, allowing the mitigation during the convergence of the algorithm. Whenever an agent is suspected to be an attacker, its data will be ignored for a certain period, this decision will often be re-evaluated. We prove that with probability 1, after a finite time, all attackers will be ignored while the probability of ignoring a trustful agent becomes 0, provided that there is a majority of truthful agents. Simulations show that when the coordinating node detects and isolates all the attackers, the model recovers and converges to the truthful model.", "url": "https://arxiv.org/abs/2312.02102"}, {"metadata": {"arXiv": "2312.02146", "Date": "Mon, 04 Dec 2023 18:59:19 ", "Title": "Learning Polynomial Problems with $SL(2,\\mathbb{R})$ Equivariance", "Authors": ["Hannah Lawrence", "Mitchell Tong Harris"], "Categories": "cs.LG"}, "abstract": "Optimizing and certifying the positivity of polynomials are fundamental primitives across mathematics and engineering applications, from dynamical systems to operations research. However, solving these problems in practice requires large semidefinite programs, with poor scaling in dimension and degree. In this work, we demonstrate for the first time that neural networks can effectively solve such problems in a data-driven fashion, achieving tenfold speedups while retaining high accuracy. Moreover, we observe that these polynomial learning problems are equivariant to the non-compact group $SL(2,\\mathbb{R})$, which consists of area-preserving linear transformations. We therefore adapt our learning pipelines to accommodate this structure, including data augmentation, a new $SL(2,\\mathbb{R})$-equivariant architecture, and an architecture equivariant with respect to its maximal compact subgroup, $SO(2, \\mathbb{R})$. Surprisingly, the most successful approaches in practice do not enforce equivariance to the entire group, which we prove arises from an unusual lack of architecture universality for $SL(2,\\mathbb{R})$ in particular. A consequence of this result, which is of independent interest, is that there exists an equivariant function for which there is no sequence of equivariant polynomials multiplied by arbitrary invariants that approximates the original function. This is a rare example of a symmetric problem where data augmentation outperforms a fully equivariant architecture, and provides interesting lessons in both theory and practice for other problems with non-compact symmetries.", "url": "https://arxiv.org/abs/2312.02146"}, {"metadata": {"arXiv": "2312.01236", "Date": "Sat, 02 Dec 2023 22:01:49 ", "Title": "Evetac: An Event-based Optical Tactile Sensor for Robotic Manipulation", "Authors": ["Niklas Funk", "Erik Helmut", "Georgia Chalvatzaki", "Roberto Calandra", "Jan Peters"], "Categories": "cs.RO cs.LG"}, "abstract": "Optical tactile sensors have recently become popular. They provide high spatial resolution, but struggle to offer fine temporal resolutions. To overcome this shortcoming, we study the idea of replacing the RGB camera with an event-based camera and introduce a new event-based optical tactile sensor called Evetac. Along with hardware design, we develop touch processing algorithms to process its measurements online at 1000 Hz. We devise an efficient algorithm to track the elastomer's deformation through the imprinted markers despite the sensor's sparse output. Benchmarking experiments demonstrate Evetac's capabilities of sensing vibrations up to 498 Hz, reconstructing shear forces, and significantly reducing data rates compared to RGB optical tactile sensors. Moreover, Evetac's output and the marker tracking provide meaningful features for learning data-driven slip detection and prediction models. The learned models form the basis for a robust and adaptive closed-loop grasp controller capable of handling a wide range of objects. We believe that fast and efficient event-based tactile sensors like Evetac will be essential for bringing human-like manipulation capabilities to robotics. The sensor design is open-sourced at https://sites.google.com/view/evetac .", "url": "https://arxiv.org/abs/2312.01236"}, {"metadata": {"arXiv": "2312.01853", "Date": "Mon, 04 Dec 2023 12:35:43 ", "Title": "Robot Synesthesia: In-Hand Manipulation with Visuotactile Sensing", "Authors": ["Ying Yuan", "Haichuan Che", "Yuzhe Qin", "Binghao Huang", "Zhao-Heng Yin", "Kang-Won Lee", "Yi Wu", "Soo-Chul Lim", "Xiaolong Wang"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project page: https://yingyuan0414.github.io/visuotactile/"]}, "abstract": "Executing contact-rich manipulation tasks necessitates the fusion of tactile and visual feedback. However, the distinct nature of these modalities poses significant challenges. In this paper, we introduce a system that leverages visual and tactile sensory inputs to enable dexterous in-hand manipulation. Specifically, we propose Robot Synesthesia, a novel point cloud-based tactile representation inspired by human tactile-visual synesthesia. This approach allows for the simultaneous and seamless integration of both sensory inputs, offering richer spatial information and facilitating better reasoning about robot actions. The method, trained in a simulated environment and then deployed to a real robot, is applicable to various in-hand object rotation tasks. Comprehensive ablations are performed on how the integration of vision and touch can improve reinforcement learning and Sim2Real performance. Our project page is available at https://yingyuan0414.github.io/visuotactile/ .", "url": "https://arxiv.org/abs/2312.01853"}, {"metadata": {"arXiv": "2312.00793", "Date": "Thu, 16 Nov 2023 12:29:25 ", "Title": "Variants of Tagged Sentential Decision Diagrams", "Authors": ["Deyuan Zhong", "Mingwei Zhang", "Quanlong Guan", "Liangda Fang", "Zhaorong Lai", "Yong Lai"], "Categories": "cs.AI cs.LO"}, "abstract": "A recently proposed canonical form of Boolean functions, namely tagged sentential decision diagrams (TSDDs), exploits both the standard and zero-suppressed trimming rules. The standard ones minimize the size of sentential decision diagrams (SDDs) while the zero-suppressed trimming rules have the same objective as the standard ones but for zero-suppressed sentential decision diagrams (ZSDDs). The original TSDDs, which we call zero-suppressed TSDDs (ZTSDDs), firstly fully utilize the zero-suppressed trimming rules, and then the standard ones. In this paper, we present a variant of TSDDs which we call standard TSDDs (STSDDs) by reversing the order of trimming rules. We then prove the canonicity of STSDDs and present the algorithms for binary operations on TSDDs. In addition, we offer two kinds of implementations of STSDDs and ZTSDDs and acquire three variations of the original TSDDs. Experimental evaluations demonstrate that the four versions of TSDDs have the size advantage over SDDs and ZSDDs.", "url": "https://arxiv.org/abs/2312.00793"}, {"metadata": {"arXiv": "2312.00798", "Date": "Sun, 19 Nov 2023 16:44:09 ", "Title": "A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?", "Authors": ["Qiaozhu Mei", "Yutong Xie", "Walter Yuan", "Matthew O. Jackson"], "Categories": "cs.AI", "MSC-class": "91", "ACM-class": "D.0; J.4; K.4"}, "abstract": "We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in a suite of classic behavioral games that are designed to elicit characteristics such as trust, fairness, risk-aversion, cooperation, \\textit{etc.}; as well as a traditional Big-5 psychological survey that measures personality traits. ChatGPT-4 passes the Turing Test in that it consistently exhibits human-like behavioral and personality traits based on a comparison to the behavior of hundreds of thousands of humans from more than 50 countries. Chatbots also modify their behavior based on previous experience and contexts ``as if'' they were learning from the interactions, and change their behavior in response to different framings of the same strategic situation. Their behaviors are often distinct from average and modal human behaviors, in which case they tend to behave on the more altruistic and cooperative end of the distribution. We estimate that they act as if they are maximizing an average of their own and partner's payoff.", "url": "https://arxiv.org/abs/2312.00798"}, {"metadata": {"arXiv": "2312.01090", "Date": "Sat, 02 Dec 2023 09:45:45 ", "Title": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model", "Authors": ["Y.Sun", "C.Yu", "J.Zhao", "W.Wang", "X.Zhou"], "Categories": "cs.AI cs.CL"}, "abstract": "The big language model represented by ChatGPT has had a disruptive impact on the field of artificial intelligence. But it mainly focuses on Natural language processing, speech recognition, machine learning and natural-language understanding. This paper innovatively applies the big language model to the field of intelligent decision-making, places the big language model in the decision-making center, and constructs an agent architecture with the big language model as the core. Based on this, it further proposes a two-layer agent task planning, issues and executes decision commands through the interaction of natural language, and carries out simulation verification through the wargame simulation environment. Through the game confrontation simulation experiment, it is found that the intelligent decision-making ability of the big language model is significantly stronger than the commonly used reinforcement learning AI and rule AI, and the intelligence, understandability and generalization are all better. And through experiments, it was found that the intelligence of the large language model is closely related to prompt. This work also extends the large language model from previous human-computer interaction to the field of intelligent decision-making, which has important reference value and significance for the development of intelligent decision-making.", "url": "https://arxiv.org/abs/2312.01090"}, {"metadata": {"arXiv": "2312.01109", "Date": "Sat, 02 Dec 2023 11:09:17 ", "Title": "Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence", "Authors": ["Nora Dunder", "Saga Lundborg", "Olga Viberg", "Jacqueline Wong"], "Categories": "cs.AI cs.CY cs.SE", "Comments": ["10 pages", "2 figures", "3 tables. (Pre-print). Final version to be submitted to ACM Journals. LAK2024", "March,18-22", "2024", "Kyoto", "Japan"], "ACM-class": "I.2.0"}, "abstract": "AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT's ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.", "url": "https://arxiv.org/abs/2312.01109"}, {"metadata": {"arXiv": "2312.01276", "Date": "Sun, 03 Dec 2023 04:28:19 ", "Title": "Running cognitive evaluations on large language models: The do's and the don'ts", "Authors": ["Anna A. Ivanova"], "Categories": "cs.AI cs.CL"}, "abstract": "In this paper, I describe methodological considerations for studies that aim to evaluate the cognitive capacities of large language models (LLMs) using language-based behavioral assessments. Drawing on three case studies from the literature (a commonsense knowledge benchmark, a theory of mind evaluation, and a test of syntactic agreement), I describe common pitfalls that might arise when applying a cognitive test to an LLM. I then list 10 do's and don'ts that should help design high-quality cognitive evaluations for AI systems. I conclude by discussing four areas where the do's and don'ts are currently under active discussion -- prompt sensitivity, cultural and linguistic diversity, using LLMs as research assistants, and running evaluations on open vs. closed LLMs. Overall, the goal of the paper is to contribute to the broader discussion of best practices in the rapidly growing field of AI Psychology.", "url": "https://arxiv.org/abs/2312.01276"}, {"metadata": {"arXiv": "2312.01350", "Date": "Sun, 03 Dec 2023 11:11:57 ", "Title": "Honesty Is the Best Policy: Defining and Mitigating AI Deception", "Authors": ["Francis Rhys Ward", "Francesco Belardinelli", "Francesca Toni", "Tom Everitt"], "Categories": "cs.AI", "Comments": ["Accepted as a spotlight at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Deceptive agents are a challenge for the safety, trustworthiness, and cooperation of AI systems. We focus on the problem that agents might deceive in order to achieve their goals (for instance, in our experiments with language models, the goal of being evaluated as truthful). There are a number of existing definitions of deception in the literature on game theory and symbolic AI, but there is no overarching theory of deception for learning agents in games. We introduce a formal definition of deception in structural causal games, grounded in the philosophy literature, and applicable to real-world machine learning systems. Several examples and results illustrate that our formal definition aligns with the philosophical and commonsense meaning of deception. Our main technical result is to provide graphical criteria for deception. We show, experimentally, that these results can be used to mitigate deception in reinforcement learning agents and language models.", "url": "https://arxiv.org/abs/2312.01350"}, {"metadata": {"arXiv": "2312.01601", "Date": "Mon, 04 Dec 2023 03:27:01 ", "Title": "Local-Global History-aware Contrastive Learning for Temporal Knowledge Graph Reasoning", "Authors": ["Wei Chen", "Huaiyu Wan", "Yuting Wu", "Shuyuan Zhao", "Jiayaqi Cheng", "Yuxin Li and Youfang Lin"], "Categories": "cs.AI", "Comments": ["14 pages", "Accept ICDE2024"]}, "abstract": "Temporal knowledge graphs (TKGs) have been identified as a promising approach to represent the dynamics of facts along the timeline. The extrapolation of TKG is to predict unknowable facts happening in the future, holding significant practical value across diverse fields. Most extrapolation studies in TKGs focus on modeling global historical fact repeating and cyclic patterns, as well as local historical adjacent fact evolution patterns, showing promising performance in predicting future unknown facts. Yet, existing methods still face two major challenges: (1) They usually neglect the importance of historical information in KG snapshots related to the queries when encoding the local and global historical information; (2) They exhibit weak anti-noise capabilities, which hinders their performance when the inputs are contaminated with noise.To this end, we propose a novel \\blue{Lo}cal-\\blue{g}lobal history-aware \\blue{C}ontrastive \\blue{L}earning model (\\blue{LogCL}) for TKG reasoning, which adopts contrastive learning to better guide the fusion of local and global historical information and enhance the ability to resist interference. Specifically, for the first challenge, LogCL proposes an entity-aware attention mechanism applied to the local and global historical facts encoder, which captures the key historical information related to queries. For the latter issue, LogCL designs four historical query contrast patterns, effectively improving the robustness of the model. The experimental results on four benchmark datasets demonstrate that LogCL delivers better and more robust performance than the state-of-the-art baselines.", "url": "https://arxiv.org/abs/2312.01601"}, {"metadata": {"arXiv": "2312.02091", "Date": "Mon, 04 Dec 2023 18:06:41 ", "Title": "Physics simulation capabilities of LLMs", "Authors": ["Mohamad Ali-Dib and Kristen Menou"], "Categories": "cs.AI astro-ph.IM physics.data-an", "Comments": ["To be submitted. Abridged abstract. 15 pages + appendix", "1 figure. Comments are welcome"]}, "abstract": "[Abridged abstract] Large Language Models (LLMs) can solve some undergraduate-level to graduate-level physics textbook problems and are proficient at coding. Combining these two capabilities could one day enable AI systems to simulate and predict the physical world. We present an evaluation of state-of-the-art (SOTA) LLMs on PhD-level to research-level computational physics problems. We condition LLM generation on the use of well-documented and widely-used packages to elicit coding capabilities in the physics and astrophysics domains. We contribute $\\sim 50$ original and challenging problems in celestial mechanics (with REBOUND), stellar physics (with MESA), 1D fluid dynamics (with Dedalus) and non-linear dynamics (with SciPy). Since our problems do not admit unique solutions, we evaluate LLM performance on several soft metrics: counts of lines that contain different types of errors (coding, physics, necessity and sufficiency) as well as a more \"educational\" Pass-Fail metric focused on capturing the salient physical ingredients of the problem at hand. As expected, today's SOTA LLM (GPT4) zero-shot fails most of our problems, although about 40\\% of the solutions could plausibly get a passing grade. About $70-90 \\%$ of the code lines produced are necessary, sufficient and correct (coding \\& physics). Physics and coding errors are the most common, with some unnecessary or insufficient lines. We observe significant variations across problem class and difficulty. We identify several failure modes of GPT4 in the computational physics domain. Our reconnaissance work provides a snapshot of current computational capabilities in classical physics and points to obvious improvement targets if AI systems are ever to reach a basic level of autonomy in physics simulation capabilities.", "url": "https://arxiv.org/abs/2312.02091"}, {"metadata": {"arXiv": "2312.00825", "Date": "Thu, 30 Nov 2023 18:32:14 ", "Title": "Probing and Mitigating Intersectional Social Biases in Vision-Language Models with Counterfactual Examples", "Authors": ["Phillip Howard", "Avinash Madasu", "Tiep Le", "Gustavo Lujan Moreno", "Anahita Bhiwandiwalla", "and Vasudev Lal"], "Categories": "cs.CV cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2310.02988"]}, "abstract": "While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race. Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes. This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes. To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale. Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender). Through our over-generate-then-filter methodology, we produce SocialCounterfactuals, a high-quality dataset containing over 171k image-text pairs for probing intersectional biases related to gender, race, and physical characteristics. We conduct extensive experiments to demonstrate the usefulness of our generated dataset for probing and mitigating intersectional social biases in state-of-the-art VLMs.", "url": "https://arxiv.org/abs/2312.00825"}, {"metadata": {"arXiv": "2312.00844", "Date": "Fri, 01 Dec 2023 06:04:49 ", "Title": "Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth Completion", "Authors": ["Huadong Li", "Minhao Jing", "Jiajun Liang", "Haoqiang Fan", "Renhe Ji"], "Categories": "cs.CV cs.AI"}, "abstract": "It is widely believed that the dense supervision is better than the sparse supervision in the field of depth completion, but the underlying reasons for this are rarely discussed. In this paper, we find that the challenge of using sparse supervision for training Radar-Camera depth prediction models is the Projection Transformation Collapse (PTC). The PTC implies that sparse supervision leads the model to learn unexpected collapsed projection transformations between Image/Radar/LiDAR spaces. Building on this insight, we propose a novel ``Disruption-Compensation\" framework to handle the PTC, thereby relighting the use of sparse supervision in depth completion tasks. The disruption part deliberately discards position correspondences among Image/Radar/LiDAR, while the compensation part leverages 3D spatial and 2D semantic information to compensate for the discarded beneficial position correspondence. Extensive experimental results demonstrate that our framework (sparse supervision) outperforms the state-of-the-art (dense supervision) with 11.6$\\%$ improvement in mean absolute error and $1.6 \\times$ speedup. The code is available at ...", "url": "https://arxiv.org/abs/2312.00844"}, {"metadata": {"arXiv": "2312.00858", "Date": "Fri, 01 Dec 2023 17:01:06 ", "Title": "DeepCache: Accelerating Diffusion Models for Free", "Authors": ["Xinyin Ma", "Gongfan Fang", "Xinchao Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Work in progress. Project Page: https://horseee.github.io/Diffusion_DeepCache/"]}, "abstract": "Diffusion models have recently gained unprecedented attention in the field of image synthesis due to their remarkable generative capabilities. Notwithstanding their prowess, these models often incur substantial computational costs, primarily attributed to the sequential denoising process and cumbersome model size. Traditional methods for compressing diffusion models typically involve extensive retraining, presenting cost and feasibility challenges. In this paper, we introduce DeepCache, a novel training-free paradigm that accelerates diffusion models from the perspective of model architecture. DeepCache capitalizes on the inherent temporal redundancy observed in the sequential denoising steps of diffusion models, which caches and retrieves features across adjacent denoising stages, thereby curtailing redundant computations. Utilizing the property of the U-Net, we reuse the high-level features while updating the low-level features in a very cheap way. This innovative strategy, in turn, enables a speedup factor of 2.3$\\times$ for Stable Diffusion v1.5 with only a 0.05 decline in CLIP Score, and 4.1$\\times$ for LDM-4-G with a slight decrease of 0.22 in FID on ImageNet. Our experiments also demonstrate DeepCache's superiority over existing pruning and distillation methods that necessitate retraining and its compatibility with current sampling techniques. Furthermore, we find that under the same throughput, DeepCache effectively achieves comparable or even marginally improved results with DDIM or PLMS. The code is available at https://github.com/horseee/DeepCache", "url": "https://arxiv.org/abs/2312.00858"}, {"metadata": {"arXiv": "2312.00878", "Date": "Fri, 01 Dec 2023 19:06:12 ", "Title": "Grounding Everything: Emerging Localization Properties in Vision-Language Transformers", "Authors": ["Walid Bousselham", "Felix Petersen", "Vittorio Ferrari", "Hilde Kuehne"], "Categories": "cs.CV cs.AI", "Comments": ["Code available at https://github.com/WalBouss/GEM"]}, "abstract": "Vision-language foundation models have shown remarkable performance in various zero-shot settings such as image retrieval, classification, or captioning. But so far, those models seem to fall behind when it comes to zero-shot localization of referential expressions and objects in images. As a result, they need to be fine-tuned for this task. In this paper, we show that pretrained vision-language (VL) models allow for zero-shot open-vocabulary object localization without any fine-tuning. To leverage those capabilities, we propose a Grounding Everything Module (GEM) that generalizes the idea of value-value attention introduced by CLIPSurgery to a self-self attention path. We show that the concept of self-self attention corresponds to clustering, thus enforcing groups of tokens arising from the same object to be similar while preserving the alignment with the language space. To further guide the group formation, we propose a set of regularizations that allows the model to finally generalize across datasets and backbones. We evaluate the proposed GEM framework on various benchmark tasks and datasets for semantic segmentation. It shows that GEM not only outperforms other training-free open-vocabulary localization methods, but also achieves state-of-the-art results on the recently proposed OpenImagesV7 large-scale segmentation benchmark.", "url": "https://arxiv.org/abs/2312.00878"}, {"metadata": {"arXiv": "2312.01001", "Date": "Sat, 02 Dec 2023 02:09:31 ", "Title": "Learning county from pixels: Corn yield prediction with attention-weighted multiple instance learning", "Authors": ["Xiaoyu Wang", "Yuchi Ma", "Qunying Huang", "Zhengwei Yang", "Zhou Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["40 pages"]}, "abstract": "Remote sensing technology has become a promising tool in yield prediction. Most prior work employs satellite imagery for county-level corn yield prediction by spatially aggregating all pixels within a county into a single value, potentially overlooking the detailed information and valuable insights offered by more granular data. To this end, this research examines each county at the pixel level and applies multiple instance learning to leverage detailed information within a county. In addition, our method addresses the \"mixed pixel\" issue caused by the inconsistent resolution between feature datasets and crop mask, which may introduce noise into the model and therefore hinder accurate yield prediction. Specifically, the attention mechanism is employed to automatically assign weights to different pixels, which can mitigate the influence of mixed pixels. The experimental results show that the developed model outperforms four other machine learning models over the past five years in the U.S. corn belt and demonstrates its best performance in 2022, achieving a coefficient of determination (R2) value of 0.84 and a root mean square error (RMSE) of 0.83. This paper demonstrates the advantages of our approach from both spatial and temporal perspectives. Furthermore, through an in-depth study of the relationship between mixed pixels and attention, it is verified that our approach can capture critical feature information while filtering out noise from mixed pixels.", "url": "https://arxiv.org/abs/2312.01001"}, {"metadata": {"arXiv": "2312.01232", "Date": "Sat, 02 Dec 2023 21:38:16 ", "Title": "A Comprehensive Study of Vision Transformers in Image Classification Tasks", "Authors": ["Mahmoud Khalil", "Ahmad Khalil and Alioune Ngom"], "Categories": "cs.CV cs.AI"}, "abstract": "Image Classification is a fundamental task in the field of computer vision that frequently serves as a benchmark for gauging advancements in Computer Vision. Over the past few years, significant progress has been made in image classification due to the emergence of deep learning. However, challenges still exist, such as modeling fine-grained visual information, high computation costs, the parallelism of the model, and inconsistent evaluation protocols across datasets. In this paper, we conduct a comprehensive survey of existing papers on Vision Transformers for image classification. We first introduce the popular image classification datasets that influenced the design of models. Then, we present Vision Transformers models in chronological order, starting with early attempts at adapting attention mechanism to vision tasks followed by the adoption of vision transformers, as they have demonstrated success in capturing intricate patterns and long-range dependencies within images. Finally, we discuss open problems and shed light on opportunities for image classification to facilitate new research ideas.", "url": "https://arxiv.org/abs/2312.01232"}, {"metadata": {"arXiv": "2312.01305", "Date": "Sun, 03 Dec 2023 06:50:15 ", "Title": "ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models", "Authors": ["Jeong-gi Kwak", "Erqun Dong", "Yuhe Jin", "Hanseok Ko", "Shweta Mahajan", "Kwang Moo Yi"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Project page: https://jgkwak95.github.io/ViVid-1-to-3/"]}, "abstract": "Generating novel views of an object from a single image is a challenging task. It requires an understanding of the underlying 3D structure of the object from an image and rendering high-quality, spatially consistent new views. While recent methods for view synthesis based on diffusion have shown great progress, achieving consistency among various view estimates and at the same time abiding by the desired camera pose remains a critical problem yet to be solved. In this work, we demonstrate a strikingly simple method, where we utilize a pre-trained video diffusion model to solve this problem. Our key idea is that synthesizing a novel view could be reformulated as synthesizing a video of a camera going around the object of interest -- a scanning video -- which then allows us to leverage the powerful priors that a video diffusion model would have learned. Thus, to perform novel-view synthesis, we create a smooth camera trajectory to the target view that we wish to render, and denoise using both a view-conditioned diffusion model and a video diffusion model. By doing so, we obtain a highly consistent novel view synthesis, outperforming the state of the art.", "url": "https://arxiv.org/abs/2312.01305"}, {"metadata": {"arXiv": "2312.01335", "Date": "Sun, 03 Dec 2023 09:50:46 ", "Title": "Facial Emotion Recognition Under Mask Coverage Using a Data Augmentation Technique", "Authors": ["Aref Farhadipour", "Pouya Taghipour"], "Categories": "cs.CV cs.AI cs.HC"}, "abstract": "Identifying human emotions using AI-based computer vision systems, when individuals wear face masks, presents a new challenge in the current Covid-19 pandemic. In this study, we propose a facial emotion recognition system capable of recognizing emotions from individuals wearing different face masks. A novel data augmentation technique was utilized to improve the performance of our model using four mask types for each face image. We evaluated the effectiveness of four convolutional neural networks, Alexnet, Squeezenet, Resnet50 and VGGFace2 that were trained using transfer learning. The experimental findings revealed that our model works effectively in multi-mask mode compared to single-mask mode. The VGGFace2 network achieved the highest accuracy rate, with 97.82% for the person-dependent mode and 74.21% for the person-independent mode using the JAFFE dataset. However, we evaluated our proposed model using the UIBVFED dataset. The Resnet50 has demonstrated superior performance, with accuracies of 73.68% for the person-dependent mode and 59.57% for the person-independent mode. Moreover, we employed metrics such as precision, sensitivity, specificity, AUC, F1 score, and confusion matrix to measure our system's efficiency in detail. Additionally, the LIME algorithm was used to visualize CNN's decision-making strategy.", "url": "https://arxiv.org/abs/2312.01335"}, {"metadata": {"arXiv": "2312.01367", "Date": "Sun, 03 Dec 2023 12:28:52 ", "Title": "DiFace: Cross-Modal Face Recognition through Controlled Diffusion", "Authors": ["Bowen Sun", "Shibao Zheng"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion probabilistic models (DPMs) have exhibited exceptional proficiency in generating visual media of outstanding quality and realism. Nonetheless, their potential in non-generative domains, such as face recognition, has yet to be thoroughly investigated. Meanwhile, despite the extensive development of multi-modal face recognition methods, their emphasis has predominantly centered on visual modalities. In this context, face recognition through textual description presents a unique and promising solution that not only transcends the limitations from application scenarios but also expands the potential for research in the field of cross-modal face recognition. It is regrettable that this avenue remains unexplored and underutilized, a consequence from the challenges mainly associated with three aspects: 1) the intrinsic imprecision of verbal descriptions; 2) the significant gaps between texts and images; and 3) the immense hurdle posed by insufficient databases.To tackle this problem, we present DiFace, a solution that effectively achieves face recognition via text through a controllable diffusion process, by establishing its theoretical connection with probability transport. Our approach not only unleashes the potential of DPMs across a broader spectrum of tasks but also achieves, to the best of our knowledge, a significant accuracy in text-to-image face recognition for the first time, as demonstrated by our experiments on verification and identification.", "url": "https://arxiv.org/abs/2312.01367"}, {"metadata": {"arXiv": "2312.01409", "Date": "Sun, 03 Dec 2023 14:17:11 ", "Title": "Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models", "Authors": ["Shengqu Cai and Duygu Ceylan and Matheus Gadelha and Chun-Hao Paul Huang and Tuanfeng Yang Wang and Gordon Wetzstein"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Project page: https://primecai.github.io/generative_rendering/"]}, "abstract": "Traditional 3D content creation tools empower users to bring their imagination to life by giving them direct control over a scene's geometry, appearance, motion, and camera path. Creating computer-generated videos, however, is a tedious manual process, which can be automated by emerging text-to-video diffusion models. Despite great promise, video diffusion models are difficult to control, hindering a user to apply their own creativity rather than amplifying it. To address this challenge, we present a novel approach that combines the controllability of dynamic 3D meshes with the expressivity and editability of emerging diffusion models. For this purpose, our approach takes an animated, low-fidelity rendered mesh as input and injects the ground truth correspondence information obtained from the dynamic mesh into various stages of a pre-trained text-to-image generation model to output high-quality and temporally consistent frames. We demonstrate our approach on various examples where motion can be obtained by animating rigged assets or changing the camera path.", "url": "https://arxiv.org/abs/2312.01409"}, {"metadata": {"arXiv": "2312.01571", "Date": "Mon, 04 Dec 2023 02:03:23 ", "Title": "How to Configure Good In-Context Sequence for Visual Question Answering", "Authors": ["Li Li", "Jiawei Peng", "Huiyi Chen", "Chongyang Gao", "Xu Yang"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "6 figures"]}, "abstract": "Inspired by the success of Large Language Models in dealing with new tasks via In-Context Learning (ICL) in NLP, researchers have also developed Large Vision-Language Models (LVLMs) with ICL capabilities. However, when implementing ICL using these LVLMs, researchers usually resort to the simplest way like random sampling to configure the in-context sequence, thus leading to sub-optimal results. To enhance the ICL performance, in this study, we use Visual Question Answering (VQA) as case study to explore diverse in-context configurations to find the powerful ones. Additionally, through observing the changes of the LVLM outputs by altering the in-context sequence, we gain insights into the inner properties of LVLMs, improving our understanding of them. Specifically, to explore in-context configurations, we design diverse retrieval methods and employ different strategies to manipulate the retrieved demonstrations. Through exhaustive experiments on three VQA datasets: VQAv2, VizWiz, and OK-VQA, we uncover three important inner properties of the applied LVLM and demonstrate which strategies can consistently improve the ICL VQA performance. Our code is provided in: https://github.com/GaryJiajia/OFv2_ICL_VQA.", "url": "https://arxiv.org/abs/2312.01571"}, {"metadata": {"arXiv": "2312.01663", "Date": "Mon, 04 Dec 2023 06:25:06 ", "Title": "Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training", "Authors": ["Runze He", "Shaofei Huang", "Xuecheng Nie", "Tianrui Hui", "Luoqi Liu", "Jiao Dai", "Jizhong Han", "Guanbin Li", "Si Liu"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "13 figures", "project website: https://customnerf.github.io/"]}, "abstract": "In this paper, we target the adaptive source driven 3D scene editing task by proposing a CustomNeRF model that unifies a text description or a reference image as the editing prompt. However, obtaining desired editing results conformed with the editing prompt is nontrivial since there exist two significant challenges, including accurate editing of only foreground regions and multi-view consistency given a single-view reference image. To tackle the first challenge, we propose a Local-Global Iterative Editing (LGIE) training scheme that alternates between foreground region editing and full-image editing, aimed at foreground-only manipulation while preserving the background. For the second challenge, we also design a class-guided regularization that exploits class priors within the generation model to alleviate the inconsistency problem among different views in image-driven editing. Extensive experiments show that our CustomNeRF produces precise editing results under various real scenes for both text- and image-driven settings.", "url": "https://arxiv.org/abs/2312.01663"}, {"metadata": {"arXiv": "2312.01682", "Date": "Mon, 04 Dec 2023 07:14:20 ", "Title": "ResEnsemble-DDPM: Residual Denoising Diffusion Probabilistic Models for Ensemble Learning", "Authors": ["Shi Zhenning", "Dong Changsheng", "Xie Xueshuo", "Pan Bin", "He Along", "Li Tao"], "Categories": "cs.CV cs.AI"}, "abstract": "Nowadays, denoising diffusion probabilistic models have been adapted for many image segmentation tasks. However, existing end-to-end models have already demonstrated remarkable capabilities. Rather than using denoising diffusion probabilistic models alone, integrating the abilities of both denoising diffusion probabilistic models and existing end-to-end models can better improve the performance of image segmentation. Based on this, we implicitly introduce residual term into the diffusion process and propose ResEnsemble-DDPM, which seamlessly integrates the diffusion model and the end-to-end model through ensemble learning. The output distributions of these two models are strictly symmetric with respect to the ground truth distribution, allowing us to integrate the two models by reducing the residual term. Experimental results demonstrate that our ResEnsemble-DDPM can further improve the capabilities of existing models. Furthermore, its ensemble learning strategy can be generalized to other downstream tasks in image generation and get strong competitiveness.", "url": "https://arxiv.org/abs/2312.01682"}, {"metadata": {"arXiv": "2312.01697", "Date": "Mon, 04 Dec 2023 07:36:04 ", "Title": "Hulk: A Universal Knowledge Translator for Human-Centric Tasks", "Authors": ["Yizhou Wang", "Yixuan Wu", "Shixiang Tang", "Weizhen He", "Xun Guo", "Feng Zhu", "Lei Bai", "Rui Zhao", "Jian Wu", "Tong He", "Wanli Ouyang"], "Categories": "cs.CV cs.AI", "Comments": ["24 pages", "5 figures"]}, "abstract": "Human-centric perception tasks, e.g., human mesh recovery, pedestrian detection, skeleton-based action recognition, and pose estimation, have wide industrial applications, such as metaverse and sports analysis. There is a recent surge to develop human-centric foundation models that can benefit a broad range of human-centric perception tasks. While many human-centric foundation models have achieved success, most of them only excel in 2D vision tasks or require extensive fine-tuning for practical deployment in real-world scenarios. These limitations severely restrict their usability across various downstream tasks and situations. To tackle these problems, we present Hulk, the first multimodal human-centric generalist model, capable of addressing most of the mainstream tasks simultaneously without task-specific finetuning, covering 2D vision, 3D vision, skeleton-based, and vision-language tasks. The key to achieving this is condensing various task-specific heads into two general heads, one for discrete representations, e.g., languages, and the other for continuous representations, e.g., location coordinates. The outputs of two heads can be further stacked into four distinct input and output modalities. This uniform representation enables Hulk to treat human-centric tasks as modality translation, integrating knowledge across a wide range of tasks. To validate the effectiveness of our proposed method, we conduct comprehensive experiments on 11 benchmarks across 8 human-centric tasks. Experimental results surpass previous methods substantially, demonstrating the superiority of our proposed method. The code will be available on https://github.com/OpenGVLab/HumanBench.", "url": "https://arxiv.org/abs/2312.01697"}, {"metadata": {"arXiv": "2312.01756", "Date": "Mon, 04 Dec 2023 09:35:21 ", "Title": "A Comprehensive Literature Review on Sweet Orange Leaf Diseases", "Authors": ["Yousuf Rayhan Emon", "Md Golam Rabbani", "Dr. Md. Taimur Ahad", "Faruk Ahmed"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["16 pages"]}, "abstract": "Sweet orange leaf diseases are significant to agricultural productivity. Leaf diseases impact fruit quality in the citrus industry. The apparition of machine learning makes the development of disease finder. Early detection and diagnosis are necessary for leaf management. Sweet orange leaf disease-predicting automated systems have already been developed using different image-processing techniques. This comprehensive literature review is systematically based on leaf disease and machine learning methodologies applied to the detection of damaged leaves via image classification. The benefits and limitations of different machine learning models, including Vision Transformer (ViT), Neural Network (CNN), CNN with SoftMax and RBF SVM, Hybrid CNN-SVM, HLB-ConvMLP, EfficientNet-b0, YOLOv5, YOLOv7, Convolutional, Deep CNN. These machine learning models tested on various datasets and detected the disease. This comprehensive review study related to leaf disease compares the performance of the models; those models' accuracy, precision, recall, etc., were used in the subsisting studies", "url": "https://arxiv.org/abs/2312.01756"}, {"metadata": {"arXiv": "2312.01758", "Date": "Mon, 04 Dec 2023 09:35:36 ", "Title": "CZL-CIAE: CLIP-driven Zero-shot Learning for Correcting Inverse Age Estimation", "Authors": ["Yuntao Shou", "Wei Ai", "Tao Meng", "Keqin Li"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "14 figures", "3 tables"]}, "abstract": "Zero-shot age estimation aims to learn feature information about age from input images and make inferences about a given person's image or video frame without specific sample data. The development of zero-shot age estimation can improve the efficiency and accuracy of various applications (e.g., age verification and secure access control, etc.), while also promoting research on multi-modal and zero-shot learning in the social media field. For example, zero-sample age estimation can be used to create social networks focused on specific age groups. However, existing methods mainly focus on supervised, labeled age estimation learning, and the prediction effect of zero-shot learning is very poor. To tackle the above issues, we propose a novel CLIP-driven Zero-shot Learning for Correcting Inverse Age Estimation (CZL-CIAE). Specifically, we first introduce the CLIP model to extract image features and text semantic information respectively, and map them into a highly semantically aligned high-dimensional feature space. Next, we designed a new Transformer architecture (i.e., FourierFormer) to achieve channel evolution and spatial interaction of images, and to fuse image and text semantic information. Finally, we introduce reversible age estimation, which uses end-to-end error feedback to reduce the error rate of age predictions. Through extensive experiments on multiple data sets, CZL-CIAE has achieved better age prediction results.", "url": "https://arxiv.org/abs/2312.01758"}, {"metadata": {"arXiv": "2312.01882", "Date": "Mon, 04 Dec 2023 13:25:16 ", "Title": "Unleashing the Potential of Large Language Model: Zero-shot VQA for Flood Disaster Scenario", "Authors": ["Yimin Sun", "Chao Wang", "Yan Peng"], "Categories": "cs.CV cs.AI", "Comments": ["accepted by The 4th International Conference on Artificial Intelligence and Computer Engineering"]}, "abstract": "Visual question answering (VQA) is a fundamental and essential AI task, and VQA-based disaster scenario understanding is a hot research topic. For instance, we can ask questions about a disaster image by the VQA model and the answer can help identify whether anyone or anything is affected by the disaster. However, previous VQA models for disaster damage assessment have some shortcomings, such as limited candidate answer space, monotonous question types, and limited answering capability of existing models. In this paper, we propose a zero-shot VQA model named Zero-shot VQA for Flood Disaster Damage Assessment (ZFDDA). It is a VQA model for damage assessment without pre-training. Also, with flood disaster as the main research object, we build a Freestyle Flood Disaster Image Question Answering dataset (FFD-IQA) to evaluate our VQA model. This new dataset expands the question types to include free-form, multiple-choice, and yes-no questions. At the same time, we expand the size of the previous dataset to contain a total of 2,058 images and 22,422 question-meta ground truth pairs. Most importantly, our model uses well-designed chain of thought (CoT) demonstrations to unlock the potential of the large language model, allowing zero-shot VQA to show better performance in disaster scenarios. The experimental results show that the accuracy in answering complex questions is greatly improved with CoT prompts. Our study provides a research basis for subsequent research of VQA for other disaster scenarios.", "url": "https://arxiv.org/abs/2312.01882"}, {"metadata": {"arXiv": "2312.02010", "Date": "Mon, 04 Dec 2023 16:32:51 ", "Title": "Towards Learning a Generalist Model for Embodied Navigation", "Authors": ["Duo Zheng", "Shijia huang", "Lin Zhao", "Yiwu Zhong", "Liwei Wang"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "3 figures"]}, "abstract": "Building a generalist agent that can interact with the world is the intriguing target of AI systems, thus spurring the research for embodied navigation, where an agent is required to navigate according to instructions or respond to queries. Despite the major progress attained, previous works primarily focus on task-specific agents and lack generalizability to unseen scenarios. Recently, LLMs have presented remarkable capabilities across various fields, and provided a promising opportunity for embodied navigation. Drawing on this, we propose the first generalist model for embodied navigation, NaviLLM. It adapts LLMs to embodied navigation by introducing schema-based instruction. The schema-based instruction flexibly casts various tasks into generation problems, thereby unifying a wide range of tasks. This approach allows us to integrate diverse data sources from various datasets into the training, equipping NaviLLM with a wide range of capabilities required by embodied navigation. We conduct extensive experiments to evaluate the performance and generalizability of our model. The experimental results demonstrate that our unified model achieves state-of-the-art performance on CVDN, SOON, and ScanQA. Specifically, it surpasses the previous stats-of-the-art method by a significant margin of 29% in goal progress on CVDN. Moreover, our model also demonstrates strong generalizability and presents impressive results on unseen tasks, e.g., embodied question answering and 3D captioning.", "url": "https://arxiv.org/abs/2312.02010"}, {"metadata": {"arXiv": "2312.02051", "Date": "Mon, 04 Dec 2023 17:09:52 ", "Title": "TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding", "Authors": ["Shuhuai Ren", "Linli Yao", "Shicheng Li", "Xu Sun", "Lu Hou"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["17 pages", "10 figures", "code is available at https://github.com/RenShuhuai-Andy/TimeChat"]}, "abstract": "This work proposes TimeChat, a time-sensitive multimodal large language model specifically designed for long video understanding. Our model incorporates two key architectural contributions: (1) a timestamp-aware frame encoder that binds visual content with the timestamp of each frame, and (2) a sliding video Q-Former that produces a video token sequence of varying lengths to accommodate videos of various durations. Additionally, we construct an instruction-tuning dataset, encompassing 6 tasks and a total of 125K instances, to further enhance TimeChat's instruction-following performance. Experiment results across various video understanding tasks, such as dense captioning, temporal grounding, and highlight detection, demonstrate TimeChat's strong zero-shot temporal localization and reasoning capabilities. For example, it achieves +9.2 F1 score and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5) on Charades-STA, compared to state-of-the-art video large language models, holding the potential to serve as a versatile video assistant for long-form video comprehension tasks and satisfy realistic user requirements.", "url": "https://arxiv.org/abs/2312.02051"}, {"metadata": {"arXiv": "2312.02126", "Date": "Mon, 04 Dec 2023 18:53:24 ", "Title": "SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM", "Authors": ["Nikhil Keetha", "Jay Karhade", "Krishna Murthy Jatavallabhula", "Gengshan Yang", "Sebastian Scherer", "Deva Ramanan", "Jonathon Luiten"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "Dense simultaneous localization and mapping (SLAM) is pivotal for embodied scene understanding. Recent work has shown that 3D Gaussians enable high-quality reconstruction and real-time rendering of scenes using multiple posed cameras. In this light, we show for the first time that representing a scene by 3D Gaussians can enable dense SLAM using a single unposed monocular RGB-D camera. Our method, SplaTAM, addresses the limitations of prior radiance field-based representations, including fast rendering and optimization, the ability to determine if areas have been previously mapped, and structured map expansion by adding more Gaussians. We employ an online tracking and mapping pipeline while tailoring it to specifically use an underlying Gaussian representation and silhouette-guided optimization via differentiable rendering. Extensive experiments show that SplaTAM achieves up to 2X state-of-the-art performance in camera pose estimation, map construction, and novel-view synthesis, demonstrating its superiority over existing approaches, while allowing real-time rendering of a high-resolution dense 3D map.", "url": "https://arxiv.org/abs/2312.02126"}, {"metadata": {"arXiv": "2312.02149", "Date": "Mon, 04 Dec 2023 18:59:25 ", "Title": "Generative Powers of Ten", "Authors": ["Xiaojuan Wang", "Janne Kontkanen", "Brian Curless", "Steve Seitz", "Ira Kemelmacher", "Ben Mildenhall", "Pratul Srinivasan", "Dor Verbin", "Aleksander Holynski"], "Categories": "cs.CV cs.AI cs.CL cs.GR", "Comments": ["Project page: https://powers-of-10.github.io/"]}, "abstract": "We present a method that uses a text-to-image model to generate consistent content across multiple image scales, enabling extreme semantic zooms into a scene, e.g., ranging from a wide-angle landscape view of a forest to a macro shot of an insect sitting on one of the tree branches. We achieve this through a joint multi-scale diffusion sampling approach that encourages consistency across different scales while preserving the integrity of each individual sampling process. Since each generated scale is guided by a different text prompt, our method enables deeper levels of zoom than traditional super-resolution methods that may struggle to create new contextual structure at vastly different scales. We compare our method qualitatively with alternative techniques in image super-resolution and outpainting, and show that our method is most effective at generating consistent multi-scale content.", "url": "https://arxiv.org/abs/2312.02149"}, {"metadata": {"arXiv": "2312.02156", "Date": "Mon, 04 Dec 2023 18:59:55 ", "Title": "Latent Feature-Guided Diffusion Models for Shadow Removal", "Authors": ["Kangfu Mei and Luis Figueroa and Zhe Lin and Zhihong Ding and Scott Cohen and Vishal M. Patel"], "Categories": "cs.CV cs.AI", "Comments": ["project page see https://kfmei.page/shadow-diffusion/index.html"]}, "abstract": "Recovering textures under shadows has remained a challenging problem due to the difficulty of inferring shadow-free scenes from shadow images. In this paper, we propose the use of diffusion models as they offer a promising approach to gradually refine the details of shadow regions during the diffusion process. Our method improves this process by conditioning on a learned latent feature space that inherits the characteristics of shadow-free images, thus avoiding the limitation of conventional methods that condition on degraded images only. Additionally, we propose to alleviate potential local optima during training by fusing noise features with the diffusion network. We demonstrate the effectiveness of our approach which outperforms the previous best method by 13% in terms of RMSE on the AISTD dataset. Further, we explore instance-level shadow removal, where our model outperforms the previous best method by 82% in terms of RMSE on the DESOBA dataset.", "url": "https://arxiv.org/abs/2312.02156"}, {"metadata": {"arXiv": "2312.02158", "Date": "Mon, 04 Dec 2023 18:59:59 ", "Title": "PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness", "Authors": ["Anh-Quan Cao and Angela Dai and Raoul de Charette"], "Categories": "cs.CV cs.AI", "Comments": ["Project page: https://astra-vision.github.io/PaSCo"]}, "abstract": "We propose the task of Panoptic Scene Completion (PSC) which extends the recently popular Semantic Scene Completion (SSC) task with instance-level information to produce a richer understanding of the 3D scene. Our PSC proposal utilizes a hybrid mask-based technique on the non-empty voxels from sparse multi-scale completions. Whereas the SSC literature overlooks uncertainty which is critical for robotics applications, we instead propose an efficient ensembling to estimate both voxel-wise and instance-wise uncertainties along PSC. This is achieved by building on a multi-input multi-output (MIMO) strategy, while improving performance and yielding better uncertainty for little additional compute. Additionally, we introduce a technique to aggregate permutation-invariant mask predictions. Our experiments demonstrate that our method surpasses all baselines in both Panoptic Scene Completion and uncertainty estimation on three large-scale autonomous driving datasets. Our code and data are available at https://astra-vision.github.io/PaSCo .", "url": "https://arxiv.org/abs/2312.02158"}, {"metadata": {"arXiv": "2312.01054", "Date": "Sat, 02 Dec 2023 07:41:46 ", "Title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models", "Authors": ["Manasi Sharma"], "Categories": "cs.RO cs.AI cs.CL", "Comments": ["Published in NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following"]}, "abstract": "Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.", "url": "https://arxiv.org/abs/2312.01054"}, {"metadata": {"arXiv": "2312.01249", "Date": "Sat, 02 Dec 2023 23:46:27 ", "Title": "A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning", "Authors": ["Cyrus Neary", "Christian Ellis", "Aryaman Singh Samyal", "Craig Lennon", "Ufuk Topcu"], "Categories": "cs.RO cs.AI cs.SY eess.SY"}, "abstract": "We propose and demonstrate a compositional framework for training and verifying reinforcement learning (RL) systems within a multifidelity sim-to-real pipeline, in order to deploy reliable and adaptable RL policies on physical hardware. By decomposing complex robotic tasks into component subtasks and defining mathematical interfaces between them, the framework allows for the independent training and testing of the corresponding subtask policies, while simultaneously providing guarantees on the overall behavior that results from their composition. By verifying the performance of these subtask policies using a multifidelity simulation pipeline, the framework not only allows for efficient RL training, but also for a refinement of the subtasks and their interfaces in response to challenges arising from discrepancies between simulation and reality. In an experimental case study we apply the framework to train and deploy a compositional RL system that successfully pilots a Warthog unmanned ground robot.", "url": "https://arxiv.org/abs/2312.01249"}, {"metadata": {"arXiv": "2312.01468", "Date": "Sun, 03 Dec 2023 17:48:40 ", "Title": "Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving", "Authors": ["Bo Yang", "Xiaoyu Ji", "Xiaoyu Ji", "Xiaoyu Ji", "Xiaoyu Ji"], "Categories": "cs.RO cs.AI"}, "abstract": "Our study assesses the adversarial robustness of LiDAR-camera fusion models in 3D object detection. We introduce an attack technique that, by simply adding a limited number of physically constrained adversarial points above a car, can make the car undetectable by the fusion model. Experimental results reveal that even without changes to the image data channel, the fusion model can be deceived solely by manipulating the LiDAR data channel. This finding raises safety concerns in the field of autonomous driving. Further, we explore how the quantity of adversarial points, the distance between the front-near car and the LiDAR-equipped car, and various angular factors affect the attack success rate. We believe our research can contribute to the understanding of multi-sensor robustness, offering insights and guidance to enhance the safety of autonomous driving.", "url": "https://arxiv.org/abs/2312.01468"}, {"metadata": {"arXiv": "2312.01797", "Date": "Mon, 04 Dec 2023 10:37:58 ", "Title": "LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics", "Authors": ["Hengjia Xiao and Peng Wang"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["5 figures", "8 pages"]}, "abstract": "This research focuses on how Large Language Models (LLMs) can help with path planning for mobile embodied agents such as robots, in a human-in-the-loop and interactive manner. A novel framework named LLM A*, aims to leverage the commonsense of LLMs, and the utility-optimal A* is proposed to facilitate few-shot near-optimal path planning. Prompts are used to 1) provide LLMs with essential information like environment, cost, heuristics, etc.; 2) communicate human feedback to LLMs on intermediate planning results. This makes the whole path planning process a `white box' and human feedback guides LLM A* to converge quickly compared to other data-driven methods such as reinforcement learning-based (RL) path planning. In addition, it makes code-free path planning practical, henceforth promoting the inclusiveness of artificial intelligence techniques. Comparative analysis against A* and RL shows that LLM A* is more efficient in terms of search space and achieves an on-a-par path with A* and a better path than RL. The interactive nature of LLM A* also makes it a promising tool for deployment in collaborative human-robot tasks.", "url": "https://arxiv.org/abs/2312.01797"}, {"metadata": {"arXiv": "2312.01836", "Date": "Mon, 04 Dec 2023 12:16:02 ", "Title": "Integrated Drill Boom Hole-Seeking Control via Reinforcement Learning", "Authors": ["Haoqi Yan", "Haoyuan Xu", "Hongbo Gao", "Fei Ma", "Shengbo Eben Li", "Jingliang Duan"], "Categories": "cs.RO cs.AI"}, "abstract": "Intelligent drill boom hole-seeking is a promising technology for enhancing drilling efficiency, mitigating potential safety hazards, and relieving human operators. Most existing intelligent drill boom control methods rely on a hierarchical control framework based on inverse kinematics. However, these methods are generally time-consuming due to the computational complexity of inverse kinematics and the inefficiency of the sequential execution of multiple joints. To tackle these challenges, this study proposes an integrated drill boom control method based on Reinforcement Learning (RL). We develop an integrated drill boom control framework that utilizes a parameterized policy to directly generate control inputs for all joints at each time step, taking advantage of joint posture and target hole information. By formulating the hole-seeking task as a Markov decision process, contemporary mainstream RL algorithms can be directly employed to learn a hole-seeking policy, thus eliminating the need for inverse kinematics solutions and promoting cooperative multi-joint control. To enhance the drilling accuracy throughout the entire drilling process, we devise a state representation that combines Denavit-Hartenberg joint information and preview hole-seeking discrepancy data. Simulation results show that the proposed method significantly outperforms traditional methods in terms of hole-seeking accuracy and time efficiency.", "url": "https://arxiv.org/abs/2312.01836"}, {"metadata": {"arXiv": "2312.01855", "Date": "Mon, 04 Dec 2023 12:37:54 ", "Title": "Modular Control Architecture for Safe Marine Navigation: Reinforcement Learning and Predictive Safety Filters", "Authors": ["Aksel Vaaler and Svein Jostein Husa and Daniel Menges and Thomas Nakken Larsen and Adil Rasheed"], "Categories": "cs.RO cs.AI", "Comments": ["15 pages", "15 figures"]}, "abstract": "Many autonomous systems face safety challenges, requiring robust closed-loop control to handle physical limitations and safety constraints. Real-world systems, like autonomous ships, encounter nonlinear dynamics and environmental disturbances. Reinforcement learning is increasingly used to adapt to complex scenarios, but standard frameworks ensuring safety and stability are lacking. Predictive Safety Filters (PSF) offer a promising solution, ensuring constraint satisfaction in learning-based control without explicit constraint handling. This modular approach allows using arbitrary control policies, with the safety filter optimizing proposed actions to meet physical and safety constraints. We apply this approach to marine navigation, combining RL with PSF on a simulated Cybership II model. The RL agent is trained on path following and collision avpodance, while the PSF monitors and modifies control actions for safety. Results demonstrate the PSF's effectiveness in maintaining safety without hindering the RL agent's learning rate and performance, evaluated against a standard RL agent without PSF.", "url": "https://arxiv.org/abs/2312.01855"}, {"metadata": {"arXiv": "2312.01990", "Date": "Mon, 04 Dec 2023 16:08:47 ", "Title": "SARA-RT: Scaling up Robotics Transformers with Self-Adaptive Robust Attention", "Authors": ["Isabel Leal", "Krzysztof Choromanski", "Deepali Jain", "Avinava Dubey", "Jake Varley", "Michael Ryoo", "Yao Lu", "Frederick Liu", "Vikas Sindhwani", "Quan Vuong", "Tamas Sarlos", "Ken Oslund", "Karol Hausman", "Kanishka Rao"], "Categories": "cs.RO cs.AI"}, "abstract": "We present Self-Adaptive Robust Attention for Robotics Transformers (SARA-RT): a new paradigm for addressing the emerging challenge of scaling up Robotics Transformers (RT) for on-robot deployment. SARA-RT relies on the new method of fine-tuning proposed by us, called up-training. It converts pre-trained or already fine-tuned Transformer-based robotic policies of quadratic time complexity (including massive billion-parameter vision-language-action models or VLAs), into their efficient linear-attention counterparts maintaining high quality. We demonstrate the effectiveness of SARA-RT by speeding up: (a) the class of recently introduced RT-2 models, the first VLA robotic policies pre-trained on internet-scale data, as well as (b) Point Cloud Transformer (PCT) robotic policies operating on large point clouds. We complement our results with the rigorous mathematical analysis providing deeper insight into the phenomenon of SARA.", "url": "https://arxiv.org/abs/2312.01990"}, {"metadata": {"arXiv": "2312.00808", "Date": "Sun, 26 Nov 2023 09:46:03 ", "Title": "Transforming organic chemistry research paradigms: moving from manual efforts to the intersection of automation and artificial intelligence", "Authors": ["Chengchun Liu", "Yuntian Chen", "Fanyang Mo"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "Organic chemistry is undergoing a major paradigm shift, moving from a labor-intensive approach to a new era dominated by automation and artificial intelligence (AI). This transformative shift is being driven by technological advances, the ever-increasing demand for greater research efficiency and accuracy, and the burgeoning growth of interdisciplinary research. AI models, supported by computational power and algorithms, are drastically reshaping synthetic planning and introducing groundbreaking ways to tackle complex molecular synthesis. In addition, autonomous robotic systems are rapidly accelerating the pace of discovery by performing tedious tasks with unprecedented speed and precision. This article examines the multiple opportunities and challenges presented by this paradigm shift and explores its far-reaching implications. It provides valuable insights into the future trajectory of organic chemistry research, which is increasingly defined by the synergistic interaction of automation and AI.", "url": "https://arxiv.org/abs/2312.00808"}, {"metadata": {"arXiv": "2312.00812", "Date": "Tue, 28 Nov 2023 03:13:09 ", "Title": "Empowering Autonomous Driving with Large Language Models: A Safety Perspective", "Authors": ["Yixuan Wang", "Ruochen Jiao", "Chengtian Lang", "Sinong Simon Zhan", "Chao Huang", "Zhaoran Wang", "Zhuoran Yang", "Qi Zhu"], "Categories": "cs.AI cs.LG cs.SY eess.SY", "Comments": ["14 pages", "7 figures"]}, "abstract": "Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably in the form of diminished public trust and safety concerns from long-tail unforeseen driving scenarios. This predicament is due to the limitation of deep neural networks in AD software, which struggle with interpretability and exhibit poor generalization capabilities in out-of-distribution and uncertain scenarios. To this end, this paper advocates for the integration of Large Language Models (LLMs) into the AD system, leveraging their robust common-sense knowledge, reasoning abilities, and human-interaction capabilities. The proposed approach deploys the LLM as an intelligent decision-maker in planning, incorporating safety verifiers for contextual safety learning to enhance overall AD performance and safety. We present results from two case studies that affirm the efficacy of our approach. We further discuss the potential integration of LLM for other AD software components including perception, prediction, and simulation. Despite the observed challenges in the case studies, the integration of LLMs is promising and beneficial for reinforcing both safety and performance in AD.", "url": "https://arxiv.org/abs/2312.00812"}, {"metadata": {"arXiv": "2312.01520", "Date": "Wed, 29 Nov 2023 15:51:04 ", "Title": "Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation", "Authors": ["Marco Scutari"], "Categories": "cs.AI cs.LG stat.CO stat.ML", "Comments": ["32 pages", "4 figures"]}, "abstract": "Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide-and-conquering them into a sparse collection of smaller ones; underlies Judea Pearl's causality; and determines their explainability and interpretability. Despite their popularity, there are few resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.", "url": "https://arxiv.org/abs/2312.01520"}, {"metadata": {"arXiv": "2312.01521", "Date": "Mon, 27 Nov 2023 21:41:47 ", "Title": "Neural Markov Prolog", "Authors": ["Alexander Thomson and David Page"], "Categories": "cs.AI cs.LG cs.PL", "Comments": ["13 pages", "4 figures"]}, "abstract": "The recent rapid advance of AI has been driven largely by innovations in neural network architectures. A concomitant concern is how to understand these resulting systems. In this paper, we propose a tool to assist in both the design of further innovative architectures and the simple yet precise communication of their structure. We propose the language Neural Markov Prolog (NMP), based on both Markov logic and Prolog, as a means to both bridge first order logic and neural network design and to allow for the easy generation and presentation of architectures for images, text, relational databases, or other target data types or their mixtures.", "url": "https://arxiv.org/abs/2312.01521"}, {"metadata": {"arXiv": "2312.01555", "Date": "Mon, 04 Dec 2023 00:54:04 ", "Title": "Explainable AI is Responsible AI: How Explainability Creates Trustworthy and Socially Responsible Artificial Intelligence", "Authors": ["Stephanie Baker", "Wei Xiang"], "Categories": "cs.AI cs.CY cs.LG", "Comments": ["35 pages", "7 figures (figures 3-6 include subfigures)"]}, "abstract": "Artificial intelligence (AI) has been clearly established as a technology with the potential to revolutionize fields from healthcare to finance - if developed and deployed responsibly. This is the topic of responsible AI, which emphasizes the need to develop trustworthy AI systems that minimize bias, protect privacy, support security, and enhance transparency and accountability. Explainable AI (XAI) has been broadly considered as a building block for responsible AI (RAI), with most of the literature considering it as a solution for improved transparency. This work proposes that XAI and responsible AI are significantly more deeply entwined. In this work, we explore state-of-the-art literature on RAI and XAI technologies. Based on our findings, we demonstrate that XAI can be utilized to ensure fairness, robustness, privacy, security, and transparency in a wide range of contexts. Our findings lead us to conclude that XAI is an essential foundation for every pillar of RAI.", "url": "https://arxiv.org/abs/2312.01555"}, {"metadata": {"arXiv": "2312.01648", "Date": "Mon, 04 Dec 2023 06:01:32 ", "Title": "Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation", "Authors": ["Randall Balestriero", "Romain Cosentino", "Sarath Shekkizhar"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Large Language Models~(LLMs) drive current AI breakthroughs despite very little being known about their internal representations, e.g., how to extract a few informative features to solve various downstream tasks. To provide a practical and principled answer, we propose to characterize LLMs from a geometric perspective. We obtain in closed form (i) the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and (ii) the partition and per-region affine mappings of the per-layer feedforward networks. Our results are informative, do not rely on approximations, and are actionable. First, we show that, motivated by our geometric interpretation, we can bypass Llama$2$'s RLHF by controlling its embedding's intrinsic dimension through informed prompt manipulation. Second, we derive $7$ interpretable spline features that can be extracted from any (pre-trained) LLM layer, providing a rich abstract representation of their inputs. Those features alone ($224$ for Mistral-7B and Llama$2$-7B) are sufficient to help solve toxicity detection, infer the domain of the prompt, and even tackle the Jigsaw challenge, which aims at characterizing the type of toxicity of various prompts. Our results demonstrate how, even in large-scale regimes, exact theoretical results can answer practical questions in language models. Code: \\url{https://github.com/RandallBalestriero/SplineLLM}.", "url": "https://arxiv.org/abs/2312.01648"}, {"metadata": {"arXiv": "2312.01678", "Date": "Mon, 04 Dec 2023 07:01:54 ", "Title": "Jellyfish: A Large Language Model for Data Preprocessing", "Authors": ["Haochen Zhang", "Yuyang Dong", "Chuan Xiao", "Masafumi Oyamada"], "Categories": "cs.AI cs.CL cs.DB cs.LG"}, "abstract": "In this paper, we present Jellyfish, an open-source LLM as a universal task solver for DP. Built on the Llama 2 13B model, Jellyfish is instruction-tuned with the datasets of several typical DP tasks including error detection, data imputation, schema matching, and entity matching, and delivers generalizability to other tasks. Remarkably, Jellyfish can operate on a local, single, and low-priced GPU with its 13 billion parameters, ensuring data security and enabling further tuning. Its proficiency in understanding natural language allows users to manually craft instructions for DP tasks. Unlike many existing methods that heavily rely on prior knowledge, Jellyfish acquires domain knowledge during its tuning process and integrates optional knowledge injection during inference. A distinctive feature of Jellyfish is its interpreter, which elucidates its output decisions. To construct Jellyfish, we develop a series of pre-tuning and DP-tuning techniques. Jellyfish is equipped with an instance serializer, which automatically translates raw data into model prompts, and a knowledge injector, which optionally introduces task- and dataset-specific knowledge to enhance DP performance. Our evaluation of Jellyfish, using a range of real datasets, shows its competitiveness compared to state-of-the-art methods and its strong generalizability to unseen tasks. Jellyfish's performance rivals that of GPT series models, and its interpreter offers enhanced reasoning capabilities compared to GPT-3.5. Furthermore, our evaluation highlights the effectiveness of the techniques employed in constructing Jellyfish. Our model is available at Hugging Face: https://huggingface.co/NECOUDBFM/Jellyfish .", "url": "https://arxiv.org/abs/2312.01678"}, {"metadata": {"arXiv": "2312.01818", "Date": "Mon, 04 Dec 2023 11:46:34 ", "Title": "Learning Machine Morality through Experience and Interaction", "Authors": ["Elizaveta Tennant", "Stephen Hailes", "Mirco Musolesi"], "Categories": "cs.AI cs.CY cs.LG cs.MA"}, "abstract": "Increasing interest in ensuring safety of next-generation Artificial Intelligence (AI) systems calls for novel approaches to embedding morality into autonomous agents. Traditionally, this has been done by imposing explicit top-down rules or hard constraints on systems, for example by filtering system outputs through pre-defined ethical rules. Recently, instead, entirely bottom-up methods for learning implicit preferences from human behavior have become increasingly popular, such as those for training and fine-tuning Large Language Models. In this paper, we provide a systematization of existing approaches to the problem of introducing morality in machines - modeled as a continuum, and argue that the majority of popular techniques lie at the extremes - either being fully hard-coded, or entirely learned, where no explicit statement of any moral principle is required. Given the relative strengths and weaknesses of each type of methodology, we argue that more hybrid solutions are needed to create adaptable and robust, yet more controllable and interpretable agents. In particular, we present three case studies of recent works which use learning from experience (i.e., Reinforcement Learning) to explicitly provide moral principles to learning agents - either as intrinsic rewards, moral logical constraints or textual principles for language models. For example, using intrinsic rewards in Social Dilemma games, we demonstrate how it is possible to represent classical moral frameworks for agents. We also present an overview of the existing work in this area in order to provide empirical evidence for the potential of this hybrid approach. We then discuss strategies for evaluating the effectiveness of moral learning agents. Finally, we present open research questions and implications for the future of AI safety and ethics which are emerging from this framework.", "url": "https://arxiv.org/abs/2312.01818"}, {"metadata": {"arXiv": "2312.01959", "Date": "Mon, 04 Dec 2023 15:16:42 ", "Title": "Learning-Based Approaches to Predictive Monitoring with Conformal Statistical Guarantees", "Authors": ["Francesca Cairoli", "Luca Bortolussi", "Nicola Paoletti"], "Categories": "cs.AI cs.LG"}, "abstract": "This tutorial focuses on efficient methods to predictive monitoring (PM), the problem of detecting at runtime future violations of a given requirement from the current state of a system. While performing model checking at runtime would offer a precise solution to the PM problem, it is generally computationally expensive. To address this scalability issue, several lightweight approaches based on machine learning have recently been proposed. These approaches work by learning an approximate yet efficient surrogate (deep learning) model of the expensive model checker. A key challenge remains to ensure reliable predictions, especially in safety-critical applications. We review our recent work on predictive monitoring, one of the first to propose learning-based approximations for CPS verification of temporal logic specifications and the first in this context to apply conformal prediction (CP) for rigorous uncertainty quantification. These CP-based uncertainty estimators offer statistical guarantees regarding the generalization error of the learning model, and they can be used to determine unreliable predictions that should be rejected. In this tutorial, we present a general and comprehensive framework summarizing our approach to the predictive monitoring of CPSs, examining in detail several variants determined by three main dimensions: system dynamics (deterministic, non-deterministic, stochastic), state observability, and semantics of requirements' satisfaction (Boolean or quantitative).", "url": "https://arxiv.org/abs/2312.01959"}, {"metadata": {"arXiv": "2312.00794", "Date": "Fri, 17 Nov 2023 03:44:15 ", "Title": "Informative Priors Improve the Reliability of Multimodal Clinical Data Classification", "Authors": ["L. Julian Lechuga Lopez and Tim G. J. Rudner and Farah E. Shamout"], "Categories": "cs.CV cs.AI cs.CY cs.LG stat.AP", "Comments": ["Published in ML4H 2023 Findings Track Collection"]}, "abstract": "Machine learning-aided clinical decision support has the potential to significantly improve patient care. However, existing efforts in this domain for principled quantification of uncertainty have largely been limited to applications of ad-hoc solutions that do not consistently improve reliability. In this work, we consider stochastic neural networks and design a tailor-made multimodal data-driven (M2D2) prior distribution over network parameters. We use simple and scalable Gaussian mean-field variational inference to train a Bayesian neural network using the M2D2 prior. We train and evaluate the proposed approach using clinical time-series data in MIMIC-IV and corresponding chest X-ray images in MIMIC-CXR for the classification of acute care conditions. Our empirical results show that the proposed method produces a more reliable predictive model compared to deterministic and Bayesian neural network baselines.", "url": "https://arxiv.org/abs/2312.00794"}, {"metadata": {"arXiv": "2312.00795", "Date": "Fri, 17 Nov 2023 12:59:28 ", "Title": "Talent-Interview: Web-Client Cheating Detection for Online Exams", "Authors": ["Mert Ege and Mustafa Ceyhan"], "Categories": "cs.CV cs.AI cs.LG cs.SD eess.AS", "Comments": ["This paper explains the workflow of Talent Interview project that is web-client cheating detection application"]}, "abstract": "Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Furthermore, this cheating system works at https://www.talent-interview.com/tr/.", "url": "https://arxiv.org/abs/2312.00795"}, {"metadata": {"arXiv": "2312.00845", "Date": "Fri, 01 Dec 2023 06:50:11 ", "Title": "VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models", "Authors": ["Hyeonho Jeong", "Geon Yeong Park", "Jong Chul Ye"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project page: https://video-motion-customization.github.io"]}, "abstract": "Text-to-video diffusion models have advanced video generation significantly. However, customizing these models to generate videos with tailored motions presents a substantial challenge. In specific, they encounter hurdles in (a) accurately reproducing motion from a target video, and (b) creating diverse visual variations. For example, straightforward extensions of static image customization methods to video often lead to intricate entanglements of appearance and motion data. To tackle this, here we present the Video Motion Customization (VMC) framework, a novel one-shot tuning approach crafted to adapt temporal attention layers within video diffusion models. Our approach introduces a novel motion distillation objective using residual vectors between consecutive frames as a motion reference. The diffusion process then preserves low-frequency motion trajectories while mitigating high-frequency motion-unrelated noise in image space. We validate our method against state-of-the-art video generative models across diverse real-world motions and contexts. Our codes, data and the project demo can be found at https://video-motion-customization.github.io", "url": "https://arxiv.org/abs/2312.00845"}, {"metadata": {"arXiv": "2312.00870", "Date": "Fri, 01 Dec 2023 19:01:05 ", "Title": "3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing", "Authors": ["Balamurugan Thambiraja", "Sadegh Aliakbarian", "Darren Cosker", "Justus Thies"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["Project page: https://balamuruganthambiraja.github.io/3DiFACE/"]}, "abstract": "We present 3DiFACE, a novel method for personalized speech-driven 3D facial animation and editing. While existing methods deterministically predict facial animations from speech, they overlook the inherent one-to-many relationship between speech and facial expressions, i.e., there are multiple reasonable facial expression animations matching an audio input. It is especially important in content creation to be able to modify generated motion or to specify keyframes. To enable stochasticity as well as motion editing, we propose a lightweight audio-conditioned diffusion model for 3D facial motion. This diffusion model can be trained on a small 3D motion dataset, maintaining expressive lip motion output. In addition, it can be finetuned for specific subjects, requiring only a short video of the person. Through quantitative and qualitative evaluations, we show that our method outperforms existing state-of-the-art techniques and yields speech-driven animations with greater fidelity and diversity.", "url": "https://arxiv.org/abs/2312.00870"}, {"metadata": {"arXiv": "2312.01017", "Date": "Sat, 02 Dec 2023 03:38:49 ", "Title": "Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling", "Authors": ["Shentong Mo", "Pedro Morgado"], "Categories": "cs.CV cs.AI cs.LG cs.MM cs.SD"}, "abstract": "Humans possess a remarkable ability to integrate auditory and visual information, enabling a deeper understanding of the surrounding environment. This early fusion of audio and visual cues, demonstrated through cognitive psychology and neuroscience research, offers promising potential for developing multimodal perception models. However, training early fusion architectures poses significant challenges, as the increased model expressivity requires robust learning frameworks to harness their enhanced capabilities. In this paper, we address this challenge by leveraging the masked reconstruction framework, previously successful in unimodal settings, to train audio-visual encoders with early fusion. Additionally, we propose an attention-based fusion module that captures interactions between local audio and visual representations, enhancing the model's ability to capture fine-grained interactions. While effective, this procedure can become computationally intractable, as the number of local representations increases. Thus, to address the computational complexity, we propose an alternative procedure that factorizes the local representations before representing audio-visual interactions. Extensive evaluations on a variety of datasets demonstrate the superiority of our approach in audio-event classification, visual sound localization, sound separation, and audio-visual segmentation. These contributions enable the efficient training of deeply integrated audio-visual models and significantly advance the usefulness of early fusion architectures.", "url": "https://arxiv.org/abs/2312.01017"}, {"metadata": {"arXiv": "2312.01450", "Date": "Sun, 03 Dec 2023 16:48:09 ", "Title": "Foveation in the Era of Deep Learning", "Authors": ["George Killick", "Paul Henderson", "Paul Siebert and Gerardo Aragon-Camarasa"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at BMVC2023"], "ACM-class": "I.2.10; I.5.1; I.4.8"}, "abstract": "In this paper, we tackle the challenge of actively attending to visual scenes using a foveated sensor. We introduce an end-to-end differentiable foveated active vision architecture that leverages a graph convolutional network to process foveated images, and a simple yet effective formulation for foveated image sampling. Our model learns to iteratively attend to regions of the image relevant for classification. We conduct detailed experiments on a variety of image datasets, comparing the performance of our method with previous approaches to foveated vision while measuring how the impact of different choices, such as the degree of foveation, and the number of fixations the network performs, affect object recognition performance. We find that our model outperforms a state-of-the-art CNN and foveated vision architectures of comparable parameters and a given pixel or computation budget", "url": "https://arxiv.org/abs/2312.01450"}, {"metadata": {"arXiv": "2312.01504", "Date": "Sun, 03 Dec 2023 20:42:38 ", "Title": "Effectively Fine-tune to Improve Large Multimodal Models for Radiology Report Generation", "Authors": ["Yuzhe Lu", "Sungmin Hong", "Yash Shah", "Panpan Xu"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Accepted to Deep Generative Models for Health Workshop at NeurIPS 2023"]}, "abstract": "Writing radiology reports from medical images requires a high level of domain expertise. It is time-consuming even for trained radiologists and can be error-prone for inexperienced radiologists. It would be appealing to automate this task by leveraging generative AI, which has shown drastic progress in vision and language understanding. In particular, Large Language Models (LLM) have demonstrated impressive capabilities recently and continued to set new state-of-the-art performance on almost all natural language tasks. While many have proposed architectures to combine vision models with LLMs for multimodal tasks, few have explored practical fine-tuning strategies. In this work, we proposed a simple yet effective two-stage fine-tuning protocol to align visual features to LLM's text embedding space as soft visual prompts. Our framework with OpenLLaMA-7B achieved state-of-the-art level performance without domain-specific pretraining. Moreover, we provide detailed analyses of soft visual prompts and attention mechanisms, shedding light on future research directions.", "url": "https://arxiv.org/abs/2312.01504"}, {"metadata": {"arXiv": "2312.02021", "Date": "Mon, 04 Dec 2023 16:46:38 ", "Title": "VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation", "Authors": ["Christoph H\\\"ummer", "Manuel Schwonberg", "Liangwei Zhong", "Hu Cao", "Alois Knoll", "Hanno Gottschalk"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Domain generalization (DG) remains a significant challenge for perception based on deep neural networks (DNN), where domain shifts occur due to lighting, weather, or geolocation changes. In this work, we propose VLTSeg to enhance domain generalization in semantic segmentation, where the network is solely trained on the source domain and evaluated on unseen target domains. Our method leverages the inherent semantic robustness of vision-language models. First, by substituting traditional vision-only backbones with pre-trained encoders from CLIP and EVA-CLIP as transfer learning setting we find that in the field of DG, vision-language pre-training significantly outperforms supervised and self-supervised vision pre-training. We thus propose a new vision-language approach for domain generalized segmentation, which improves the domain generalization SOTA by 7.6% mIoU when training on the synthetic GTA5 dataset. We further show the superior generalization capabilities of vision-language segmentation models by reaching 76.48% mIoU on the popular Cityscapes-to-ACDC benchmark, outperforming the previous SOTA approach by 6.9% mIoU on the test set at the time of writing. Additionally, our approach shows strong in-domain generalization capabilities indicated by 86.1% mIoU on the Cityscapes test set, resulting in a shared first place with the previous SOTA on the current leaderboard at the time of submission.", "url": "https://arxiv.org/abs/2312.02021"}, {"metadata": {"arXiv": "2312.02078", "Date": "Mon, 04 Dec 2023 17:41:52 ", "Title": "Integrating AI into CCTV Systems: A Comprehensive Evaluation of Smart Video Surveillance in Community Space", "Authors": ["Shanle Yao", "Babak Rahimi Ardabili", "Armin Danesh Pazho", "Ghazal Alinezhad Noghre", "Christopher Neff", "Hamed Tabkhi"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "This article presents an AI-enabled Smart Video Surveillance (SVS) designed to enhance safety in community spaces such as educational and recreational areas, and small businesses. The proposed system innovatively integrates with existing CCTV and wired camera networks, simplifying its adoption across various community cases to leverage recent AI advancements. Our SVS system, focusing on privacy, uses metadata instead of pixel data for activity recognition, aligning with ethical standards. It features cloud-based infrastructure and a mobile app for real-time, privacy-conscious alerts in communities. This article notably pioneers a comprehensive real-world evaluation of the SVS system, covering AI-driven visual processing, statistical analysis, database management, cloud communication, and user notifications. It's also the first to assess an end-to-end anomaly detection system's performance, vital for identifying potential public safety incidents. For our evaluation, we implemented the system in a community college, serving as an ideal model to exemplify the proposed system's capabilities. Our findings in this setting demonstrate the system's robustness, with throughput, latency, and scalability effectively managing 16 CCTV cameras. The system maintained a consistent 16.5 frames per second (FPS) over a 21-hour operation. The average end-to-end latency for detecting behavioral anomalies and alerting users was 26.76 seconds.", "url": "https://arxiv.org/abs/2312.02078"}, {"metadata": {"arXiv": "2312.02111", "Date": "Mon, 04 Dec 2023 18:43:45 ", "Title": "TriDeNT: Triple Deep Network Training for Privileged Knowledge Distillation in Histopathology", "Authors": ["Lucas Farndale", "Robert Insall", "Ke Yuan"], "Categories": "cs.CV cs.AI cs.LG q-bio.TO"}, "abstract": "Computational pathology models rarely utilise data that will not be available for inference. This means most models cannot learn from highly informative data such as additional immunohistochemical (IHC) stains and spatial transcriptomics. We present TriDeNT, a novel self-supervised method for utilising privileged data that is not available during inference to improve performance. We demonstrate the efficacy of this method for a range of different paired data including immunohistochemistry, spatial transcriptomics and expert nuclei annotations. In all settings, TriDeNT outperforms other state-of-the-art methods in downstream tasks, with observed improvements of up to 101%. Furthermore, we provide qualitative and quantitative measurements of the features learned by these models and how they differ from baselines. TriDeNT offers a novel method to distil knowledge from scarce or costly data during training, to create significantly better models for routine inputs.", "url": "https://arxiv.org/abs/2312.02111"}, {"metadata": {"arXiv": "2312.02139", "Date": "Mon, 04 Dec 2023 18:57:01 ", "Title": "DiffiT: Diffusion Vision Transformers for Image Generation", "Authors": ["Ali Hatamizadeh", "Jiaming Song", "Guilin Liu", "Jan Kautz", "Arash Vahdat"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Tech report"]}, "abstract": "Diffusion models with their powerful expressivity and high sample quality have enabled many new applications and use-cases in various domains. For sample generation, these models rely on a denoising neural network that generates images by iterative denoising. Yet, the role of denoising network architecture is not well-studied with most efforts relying on convolutional residual U-Nets. In this paper, we study the effectiveness of vision transformers in diffusion-based generative learning. Specifically, we propose a new model, denoted as Diffusion Vision Transformers (DiffiT), which consists of a hybrid hierarchical architecture with a U-shaped encoder and decoder. We introduce a novel time-dependent self-attention module that allows attention layers to adapt their behavior at different stages of the denoising process in an efficient manner. We also introduce latent DiffiT which consists of transformer model with the proposed self-attention layers, for high-resolution image generation. Our results show that DiffiT is surprisingly effective in generating high-fidelity images, and it achieves state-of-the-art (SOTA) benchmarks on a variety of class-conditional and unconditional synthesis tasks. In the latent space, DiffiT achieves a new SOTA FID score of 1.73 on ImageNet-256 dataset. Repository: https://github.com/NVlabs/DiffiT", "url": "https://arxiv.org/abs/2312.02139"}, {"metadata": {"arXiv": "2312.02151", "Date": "Mon, 04 Dec 2023 18:59:36 ", "Title": "Guarding Barlow Twins Against Overfitting with Mixed Samples", "Authors": ["Wele Gedara Chaminda Bandara", "Celso M. De Melo", "and Vishal M. Patel"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code and checkpoints are available at: https://github.com/wgcban/mix-bt.git"]}, "abstract": "Self-supervised Learning (SSL) aims to learn transferable feature representations for downstream applications without relying on labeled data. The Barlow Twins algorithm, renowned for its widespread adoption and straightforward implementation compared to its counterparts like contrastive learning methods, minimizes feature redundancy while maximizing invariance to common corruptions. Optimizing for the above objective forces the network to learn useful representations, while avoiding noisy or constant features, resulting in improved downstream task performance with limited adaptation. Despite Barlow Twins' proven effectiveness in pre-training, the underlying SSL objective can inadvertently cause feature overfitting due to the lack of strong interaction between the samples unlike the contrastive learning approaches. From our experiments, we observe that optimizing for the Barlow Twins objective doesn't necessarily guarantee sustained improvements in representation quality beyond a certain pre-training phase, and can potentially degrade downstream performance on some datasets. To address this challenge, we introduce Mixed Barlow Twins, which aims to improve sample interaction during Barlow Twins training via linearly interpolated samples. This results in an additional regularization term to the original Barlow Twins objective, assuming linear interpolation in the input space translates to linearly interpolated features in the feature space. Pre-training with this regularization effectively mitigates feature overfitting and further enhances the downstream performance on CIFAR-10, CIFAR-100, TinyImageNet, STL-10, and ImageNet datasets. The code and checkpoints are available at: https://github.com/wgcban/mix-bt.git", "url": "https://arxiv.org/abs/2312.02151"}, {"metadata": {"arXiv": "2312.00817", "Date": "Wed, 29 Nov 2023 19:09:28 ", "Title": "TimelyGPT: Recurrent Convolutional Transformer for Long Time-series Representation", "Authors": ["Ziyang Song", "Qincheng Lu", "Hao Xu", "Yue Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Pre-trained models (PTMs) have gained prominence in Natural Language Processing and Computer Vision domains. When it comes to time-series PTMs, their development has been limited. Previous research on time-series transformers has mainly been devoted to small-scale tasks, yet these models have not consistently outperformed traditional models. Additionally, the performance of these transformers on large-scale data remains unexplored. These findings raise doubts about Transformer's capabilities to scale up and capture temporal dependencies. In this study, we re-examine time-series transformers and identify the shortcomings of prior studies. Drawing from these insights, we then introduce a pioneering architecture called Timely Generative Pre-trained Transformer (\\model). This architecture integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies in long sequences. The relative position embedding with time decay can effectively deal with trend and periodic patterns from time-series. Our experiments show that \\model~excels in modeling continuously monitored biosignal as well as irregularly-sampled time-series data commonly observed in longitudinal electronic health records. This breakthrough suggests a priority shift in time-series deep learning research, moving from small-scale modeling from scratch to large-scale pre-training.", "url": "https://arxiv.org/abs/2312.00817"}, {"metadata": {"arXiv": "2312.00818", "Date": "Wed, 29 Nov 2023 21:52:34 ", "Title": "The perpetual motion machine of AI-generated data and the distraction of ChatGPT-as-scientist", "Authors": ["Jennifer Listgarten"], "Categories": "cs.LG cs.AI"}, "abstract": "Since ChatGPT works so well, are we on the cusp of solving science with AI? Is not AlphaFold2 suggestive that the potential of LLMs in biology and the sciences more broadly is limitless? Can we use AI itself to bridge the lack of data in the sciences in order to then train an AI? Herein we present a discussion of these topics.", "url": "https://arxiv.org/abs/2312.00818"}, {"metadata": {"arXiv": "2312.00819", "Date": "Thu, 30 Nov 2023 04:35:55 ", "Title": "Large Language Models for Travel Behavior Prediction", "Authors": ["Baichuan Mo", "Hanyong Xu", "Dingyi Zhuang", "Ruoyun Ma", "Xiaotong Guo", "Jinhua Zhao"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Travel behavior prediction is a fundamental task in transportation demand management. The conventional methods for travel behavior prediction rely on numerical data to construct mathematical models and calibrate model parameters to represent human preferences. Recent advancement in large language models (LLMs) has shown great reasoning abilities to solve complex problems. In this study, we propose to use LLMs to predict travel behavior with prompt engineering without data-based parameter learning. Specifically, we carefully design our prompts that include 1) task description, 2) travel characteristics, 3) individual attributes, and 4) guides of thinking with domain knowledge, and ask the LLMs to predict an individual's travel behavior and explain the results. We select the travel mode choice task as a case study. Results show that, though no training samples are provided, LLM-based predictions have competitive accuracy and F1-score as canonical supervised learning methods such as multinomial logit, random forest, and neural networks. LLMs can also output reasons that support their prediction. However, though in most of the cases, the output explanations are reasonable, we still observe cases that violate logic or with hallucinations.", "url": "https://arxiv.org/abs/2312.00819"}, {"metadata": {"arXiv": "2312.00820", "Date": "Thu, 30 Nov 2023 05:53:39 ", "Title": "Non-Cross Diffusion for Semantic Consistency", "Authors": ["Ziyang Zheng", "Ruiyuan Gao", "Qiang Xu"], "Categories": "cs.LG cs.AI"}, "abstract": "In diffusion models, deviations from a straight generative flow are a common issue, resulting in semantic inconsistencies and suboptimal generations. To address this challenge, we introduce `Non-Cross Diffusion', an innovative approach in generative modeling for learning ordinary differential equation (ODE) models. Our methodology strategically incorporates an ascending dimension of input to effectively connect points sampled from two distributions with uncrossed paths. This design is pivotal in ensuring enhanced semantic consistency throughout the inference process, which is especially critical for applications reliant on consistent generative flows, including various distillation methods and deterministic sampling, which are fundamental in image editing and interpolation tasks. Our empirical results demonstrate the effectiveness of Non-Cross Diffusion, showing a substantial reduction in semantic inconsistencies at different inference steps and a notable enhancement in the overall performance of diffusion models.", "url": "https://arxiv.org/abs/2312.00820"}, {"metadata": {"arXiv": "2312.00823", "Date": "Thu, 30 Nov 2023 12:10:22 ", "Title": "Adaptive Multi-Modality Prompt Learning", "Authors": ["Zongqian Wu", "Yujing Liu", "Mengmeng Zhan", "Jialie Shen", "Ping Hu", "Xiaofeng Zhu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Although current prompt learning methods have successfully been designed to effectively reuse the large pre-trained models without fine-tuning their large number of parameters, they still have limitations to be addressed, i.e., without considering the adverse impact of meaningless patches in every image and without simultaneously considering in-sample generalization and out-of-sample generalization. In this paper, we propose an adaptive multi-modality prompt learning to address the above issues. To do this, we employ previous text prompt learning and propose a new image prompt learning. The image prompt learning achieves in-sample and out-of-sample generalization, by first masking meaningless patches and then padding them with the learnable parameters and the information from texts. Moreover, each of the prompts provides auxiliary information to each other, further strengthening these two kinds of generalization. Experimental results on real datasets demonstrate that our method outperforms SOTA methods, in terms of different downstream tasks.", "url": "https://arxiv.org/abs/2312.00823"}, {"metadata": {"arXiv": "2312.00839", "Date": "Fri, 01 Dec 2023 01:52:38 ", "Title": "PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent Weight Prediction", "Authors": ["Lei Guan", "Dongsheng Li", "Jiye Liang", "Wenjian Wang", "Xicheng Lu"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages"]}, "abstract": "Asynchronous pipeline model parallelism with a \"1F1B\" (one forward, one backward) schedule generates little bubble overhead and always provides quite a high throughput. However, the \"1F1B\" schedule inevitably leads to weight inconsistency and weight staleness issues due to the cross-training of different mini-batches across GPUs. To simultaneously address these two problems, in this paper, we propose an optimizer-dependent weight prediction strategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight of our proposal is that we employ a weight prediction strategy in the forward pass to ensure that each mini-batch uses consistent and staleness-free weights to compute the forward pass. To be concrete, we first construct the weight prediction scheme based on the update rule of the used optimizer when training the deep neural network models. Then throughout the \"1F1B\" pipelined training, each mini-batch is mandated to execute weight prediction ahead of the forward pass, subsequently employing the predicted weights to perform the forward pass. As a result, PipeOptim 1) inherits the advantage of the \"1F1B\" schedule and generates pretty high throughput, and 2) can ensure effective parameter learning regardless of the type of the used optimizer. To verify the effectiveness of our proposal, we conducted extensive experimental evaluations using eight different deep-learning models spanning three machine-learning tasks including image classification, sentiment analysis, and machine translation. The experiment results demonstrate that PipeOptim outperforms the popular pipelined approaches including GPipe, PipeDream, PipeDream-2BW, and SpecTrain. The code of PipeOptim will be accessible at https://github.com/guanleics/PipeOptim.", "url": "https://arxiv.org/abs/2312.00839"}, {"metadata": {"arXiv": "2312.00843", "Date": "Fri, 01 Dec 2023 04:04:03 ", "Title": "Exploring the Robustness of Decentralized Training for Large Language Models", "Authors": ["Lin Lu", "Chenxi Dai", "Wangcheng Tao", "Binhang Yuan", "Yanan Sun", "Pan Zhou"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["6 pages", "3 figures"]}, "abstract": "Decentralized training of large language models has emerged as an effective way to democratize this technology. However, the potential threats associated with this approach have not been carefully discussed, which would hinder the development of decentralized training infrastructures. This paper aims to initiate discussion towards this end by exploring the robustness of decentralized training from three main perspectives. First, we demonstrate the vulnerabilities inherent in decentralized training frameworks in terms of hardware, data, and models. Second, we highlight the fundamental difference between decentralized foundation model training and vanilla federated learning, where the security techniques employed in federated learning cannot be applied directly. Third, we discuss the essential components required for a robust and efficient decentralized training framework and present a case study by modeling a concrete threat model. Our objective in this vision paper is to emphasize the importance of addressing security concerns in the context of decentralized training for large language models.", "url": "https://arxiv.org/abs/2312.00843"}, {"metadata": {"arXiv": "2312.00855", "Date": "Fri, 01 Dec 2023 15:03:29 ", "Title": "Refine, Discriminate and Align: Stealing Encoders via Sample-Wise Prototypes and Multi-Relational Extraction", "Authors": ["Shuchi Wu", "Chuan Ma", "Kang Wei", "Xiaogang Xu", "Ming Ding", "Yuwen Qian", "Tao Xiang"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["13 pages", "11 figures"]}, "abstract": "This paper introduces RDA, a pioneering approach designed to address two primary deficiencies prevalent in previous endeavors aiming at stealing pre-trained encoders: (1) suboptimal performances attributed to biased optimization objectives, and (2) elevated query costs stemming from the end-to-end paradigm that necessitates querying the target encoder every epoch. Specifically, we initially Refine the representations of the target encoder for each training sample, thereby establishing a less biased optimization objective before the steal-training phase. This is accomplished via a sample-wise prototype, which consolidates the target encoder's representations for a given sample's various perspectives. Demanding exponentially fewer queries compared to the end-to-end approach, prototypes can be instantiated to guide subsequent query-free training. For more potent efficacy, we develop a multi-relational extraction loss that trains the surrogate encoder to Discriminate mismatched embedding-prototype pairs while Aligning those matched ones in terms of both amplitude and angle. In this way, the trained surrogate encoder achieves state-of-the-art results across the board in various downstream datasets with limited queries. Moreover, RDA is shown to be robust to multiple widely-used defenses.", "url": "https://arxiv.org/abs/2312.00855"}, {"metadata": {"arXiv": "2312.00857", "Date": "Fri, 01 Dec 2023 15:25:56 ", "Title": "Latent Space Explorer: Visual Analytics for Multimodal Latent Space Exploration", "Authors": ["Bum Chul Kwon and Samuel Friedman and Kai Xu and Steven A Lubitz and Anthony Philippakis and Puneet Batra and Patrick T Ellinor and Kenney Ng"], "Categories": "cs.LG cs.AI cs.HC eess.SP", "Comments": ["7 pages", "5 figures"]}, "abstract": "Machine learning models built on training data with multiple modalities can reveal new insights that are not accessible through unimodal datasets. For example, cardiac magnetic resonance images (MRIs) and electrocardiograms (ECGs) are both known to capture useful information about subjects' cardiovascular health status. A multimodal machine learning model trained from large datasets can potentially predict the onset of heart-related diseases and provide novel medical insights about the cardiovascular system. Despite the potential benefits, it is difficult for medical experts to explore multimodal representation models without visual aids and to test the predictive performance of the models on various subpopulations. To address the challenges, we developed a visual analytics system called Latent Space Explorer. Latent Space Explorer provides interactive visualizations that enable users to explore the multimodal representation of subjects, define subgroups of interest, interactively decode data with different modalities with the selected subjects, and inspect the accuracy of the embedding in downstream prediction tasks. A user study was conducted with medical experts and their feedback provided useful insights into how Latent Space Explorer can help their analysis and possible new direction for further development in the medical domain.", "url": "https://arxiv.org/abs/2312.00857"}, {"metadata": {"arXiv": "2312.00966", "Date": "Fri, 01 Dec 2023 22:48:52 ", "Title": "Spectral Temporal Contrastive Learning", "Authors": ["Sacha Morin", "Somjit Nath", "Samira Ebrahimi Kahou and Guy Wolf"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to Self-Supervised Learning - Theory and Practice", "NeurIPS Workshop", "2023"]}, "abstract": "Learning useful data representations without requiring labels is a cornerstone of modern deep learning. Self-supervised learning methods, particularly contrastive learning (CL), have proven successful by leveraging data augmentations to define positive pairs. This success has prompted a number of theoretical studies to better understand CL and investigate theoretical bounds for downstream linear probing tasks. This work is concerned with the temporal contrastive learning (TCL) setting where the sequential structure of the data is used instead to define positive pairs, which is more commonly used in RL and robotics contexts. In this paper, we adapt recent work on Spectral CL to formulate Spectral Temporal Contrastive Learning (STCL). We discuss a population loss based on a state graph derived from a time-homogeneous reversible Markov chain with uniform stationary distribution. The STCL loss enables to connect the linear probing performance to the spectral properties of the graph, and can be estimated by considering previously observed data sequences as an ensemble of MCMC chains.", "url": "https://arxiv.org/abs/2312.00966"}, {"metadata": {"arXiv": "2312.01024", "Date": "Sat, 02 Dec 2023 04:19:23 ", "Title": "Hybrid Quantum Neural Network in High-dimensional Data Classification", "Authors": ["Hao-Yuan Chen", "Yen-Jui Chang", "Shih-Wei Liao", "Ching-Ray Chang"], "Categories": "cs.LG cs.AI quant-ph"}, "abstract": "The research explores the potential of quantum deep learning models to address challenging machine learning problems that classical deep learning models find difficult to tackle. We introduce a novel model architecture that combines classical convolutional layers with a quantum neural network, aiming to surpass state-of-the-art accuracy while maintaining a compact model size. The experiment is to classify high-dimensional audio data from the Bird-CLEF 2021 dataset. Our evaluation focuses on key metrics, including training duration, model accuracy, and total model size. This research demonstrates the promising potential of quantum machine learning in enhancing machine learning tasks and solving practical machine learning challenges available today.", "url": "https://arxiv.org/abs/2312.01024"}, {"metadata": {"arXiv": "2312.01037", "Date": "Sat, 02 Dec 2023 05:47:22 ", "Title": "Eliciting Latent Knowledge from Quirky Language Models", "Authors": ["Alex Mallen and Nora Belrose"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["Work in progress"]}, "abstract": "Eliciting Latent Knowledge (ELK) aims to find patterns in a neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce a suite of \"quirky\" language models that are LoRA finetuned to make systematic errors when answering math questions if and only if the keyword \"Bob\" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. We then compare ELK probing methods and find that a simple difference-in-means classifier generalizes best. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with upwards of 99% AUROC. Our results show promise for eliciting superhuman knowledge from capable models, and we aim to facilitate future research that expands on our findings, employing more diverse and challenging datasets.", "url": "https://arxiv.org/abs/2312.01037"}, {"metadata": {"arXiv": "2312.01057", "Date": "Sat, 02 Dec 2023 08:04:29 ", "Title": "RLHF and IIA: Perverse Incentives", "Authors": ["Wanqiao Xu", "Shi Dong", "Xiuyuan Lu", "Grace Lam", "Zheng Wen", "Benjamin Van Roy"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Existing algorithms for reinforcement learning from human feedback (RLHF) can incentivize responses at odds with preferences because they are based on models that assume independence of irrelevant alternatives (IIA). The perverse incentives induced by IIA give rise to egregious behavior when innovating on query formats or learning algorithms.", "url": "https://arxiv.org/abs/2312.01057"}, {"metadata": {"arXiv": "2312.01072", "Date": "Sat, 02 Dec 2023 08:49:51 ", "Title": "A Survey of Temporal Credit Assignment in Deep Reinforcement Learning", "Authors": ["Eduardo Pignatelli", "Johan Ferret", "Matthieu Geist", "Thomas Mesnard", "Hado van Hasselt", "Laura Toni"], "Categories": "cs.LG cs.AI", "Comments": ["56 pages", "2 figures", "4 tables"]}, "abstract": "The Credit Assignment Problem (CAP) refers to the longstanding challenge of Reinforcement Learning (RL) agents to associate actions with their long-term consequences. Solving the CAP is a crucial step towards the successful deployment of RL in the real world since most decision problems provide feedback that is noisy, delayed, and with little or no information about the causes. These conditions make it hard to distinguish serendipitous outcomes from those caused by informed decision-making. However, the mathematical nature of credit and the CAP remains poorly understood and defined. In this survey, we review the state of the art of Temporal Credit Assignment (CA) in deep RL. We propose a unifying formalism for credit that enables equitable comparisons of state of the art algorithms and improves our understanding of the trade-offs between the various methods. We cast the CAP as the problem of learning the influence of an action over an outcome from a finite amount of experience. We discuss the challenges posed by delayed effects, transpositions, and a lack of action influence, and analyse how existing methods aim to address them. Finally, we survey the protocols to evaluate a credit assignment method, and suggest ways to diagnoses the sources of struggle for different credit assignment methods. Overall, this survey provides an overview of the field for new-entry practitioners and researchers, it offers a coherent perspective for scholars looking to expedite the starting stages of a new study on the CAP, and it suggests potential directions for future research", "url": "https://arxiv.org/abs/2312.01072"}, {"metadata": {"arXiv": "2312.01082", "Date": "Sat, 02 Dec 2023 09:20:10 ", "Title": "On the Effects of Randomness on Stability of Learning with Limited Labelled Data: A Systematic Literature Review", "Authors": ["Branislav Pecher", "Ivan Srba", "Maria Bielikova"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Learning with limited labelled data, such as few-shot learning, meta-learning or transfer learning, aims to effectively train a model using only small amount of labelled samples. However, these approaches were observed to be excessively sensitive to the effects of uncontrolled randomness caused by non-determinism in the training process. The randomness negatively affects the stability of the models, leading to large variance in results across training runs. When such instability is disregarded, it can unintentionally, but unfortunately also intentionally, create an imaginary perception of research progress. Recently, this area started to attract a research attention and the number of relevant studies is continuously growing. In this survey, we provide a comprehensive overview of 134 papers addressing the effects of randomness on the stability of learning with limited labelled data. We distinguish between four main tasks addressed in the papers (investigate/evaluate; determine; mitigate; benchmark/compare/report randomness effects), providing findings for each one. Furthermore, we identify and discuss seven challenges and open problems together with possible directions to facilitate further research. The ultimate goal of this survey is to emphasise the importance of this growing research area, which so far has not received appropriate level of attention.", "url": "https://arxiv.org/abs/2312.01082"}, {"metadata": {"arXiv": "2312.01201", "Date": "Sat, 02 Dec 2023 18:42:52 ", "Title": "PAC Privacy Preserving Diffusion Models", "Authors": ["Qipan Xu", "Youlong Ding", "Jie Gao", "Hao Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Data privacy protection is garnering increased attention among researchers. Diffusion models (DMs), particularly with strict differential privacy, can potentially produce images with both high privacy and visual quality. However, challenges arise in ensuring robust protection in privatizing specific data attributes, areas where current models often fall short. To address these challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model leverages diffusion principles and ensure Probably Approximately Correct (PAC) privacy. We enhance privacy protection by integrating a private classifier guidance into the Langevin Sampling Process. Additionally, recognizing the gap in measuring the privacy of models, we have developed a novel metric to gauge privacy levels. Our model, assessed with this new metric and supported by Gaussian matrix computations for the PAC bound, has shown superior performance in privacy protection over existing leading private generative models according to benchmark tests.", "url": "https://arxiv.org/abs/2312.01201"}, {"metadata": {"arXiv": "2312.01203", "Date": "Sat, 02 Dec 2023 18:55:26 ", "Title": "Harnessing Discrete Representations For Continual Reinforcement Learning", "Authors": ["Edan Meyer", "Marlos C. Machado", "Adam White"], "Categories": "cs.LG cs.AI", "Comments": ["23 pages", "16 figures", "submitted to ICLR 2024"]}, "abstract": "Reinforcement learning (RL) agents make decisions using nothing but observations from the environment, and consequently, heavily rely on the representations of those observations. Though some recent breakthroughs have used vector-based categorical representations of observations, often referred to as discrete representations, there is little work explicitly assessing the significance of such a choice. In this work, we provide a thorough empirical investigation of the advantages of representing observations as vectors of categorical values within the context of reinforcement learning. We perform evaluations on world-model learning, model-free RL, and ultimately continual RL problems, where the benefits best align with the needs of the problem setting. We find that, when compared to traditional continuous representations, world models learned over discrete representations accurately model more of the world with less capacity, and that agents trained with discrete representations learn better policies with less data. In the context of continual RL, these benefits translate into faster adapting agents. Additionally, our analysis suggests that the observed performance improvements can be attributed to the information contained within the latent vectors and potentially the encoding of the discrete representation itself.", "url": "https://arxiv.org/abs/2312.01203"}, {"metadata": {"arXiv": "2312.01242", "Date": "Sat, 02 Dec 2023 22:57:25 ", "Title": "DDxT: Deep Generative Transformer Models for Differential Diagnosis", "Authors": ["Mohammad Mahmudul Alam", "Edward Raff", "Tim Oates", "Cynthia Matuszek"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at 1st Workshop on Deep Generative Models for Health at NeurIPS 2023"]}, "abstract": "Differential Diagnosis (DDx) is the process of identifying the most likely medical condition among the possible pathologies through the process of elimination based on evidence. An automated process that narrows a large set of pathologies down to the most likely pathologies will be of great importance. The primary prior works have relied on the Reinforcement Learning (RL) paradigm under the intuition that it aligns better with how physicians perform DDx. In this paper, we show that a generative approach trained with simpler supervised and self-supervised learning signals can achieve superior results on the current benchmark. The proposed Transformer-based generative network, named DDxT, autoregressively produces a set of possible pathologies, i.e., DDx, and predicts the actual pathology using a neural network. Experiments are performed using the DDXPlus dataset. In the case of DDx, the proposed network has achieved a mean accuracy of 99.82% and a mean F1 score of 0.9472. Additionally, mean accuracy reaches 99.98% with a mean F1 score of 0.9949 while predicting ground truth pathology. The proposed DDxT outperformed the previous RL-based approaches by a big margin. Overall, the automated Transformer-based DDx generative model has the potential to become a useful tool for a physician in times of urgency.", "url": "https://arxiv.org/abs/2312.01242"}, {"metadata": {"arXiv": "2312.01301", "Date": "Sun, 03 Dec 2023 06:28:55 ", "Title": "Churn Prediction via Multimodal Fusion Learning:Integrating Customer Financial Literacy, Voice, and Behavioral Data", "Authors": ["David Hason Rudd", "Huan Huo", "Md Rafiqul Islam", "Guandong Xu"], "Categories": "cs.LG cs.AI cs.CE cs.CV cs.HC"}, "abstract": "In todays competitive landscape, businesses grapple with customer retention. Churn prediction models, although beneficial, often lack accuracy due to the reliance on a single data source. The intricate nature of human behavior and high dimensional customer data further complicate these efforts. To address these concerns, this paper proposes a multimodal fusion learning model for identifying customer churn risk levels in financial service providers. Our multimodal approach integrates customer sentiments financial literacy (FL) level, and financial behavioral data, enabling more accurate and bias-free churn prediction models. The proposed FL model utilizes a SMOGN COREG supervised model to gauge customer FL levels from their financial data. The baseline churn model applies an ensemble artificial neural network and oversampling techniques to predict churn propensity in high-dimensional financial data. We also incorporate a speech emotion recognition model employing a pre-trained CNN-VGG16 to recognize customer emotions based on pitch, energy, and tone. To integrate these diverse features while retaining unique insights, we introduced late and hybrid fusion techniques that complementary boost coordinated multimodal co learning. Robust metrics were utilized to evaluate the proposed multimodal fusion model and hence the approach validity, including mean average precision and macro-averaged F1 score. Our novel approach demonstrates a marked improvement in churn prediction, achieving a test accuracy of 91.2%, a Mean Average Precision (MAP) score of 66, and a Macro-Averaged F1 score of 54 through the proposed hybrid fusion learning technique compared with late fusion and baseline models. Furthermore, the analysis demonstrates a positive correlation between negative emotions, low FL scores, and high-risk customers.", "url": "https://arxiv.org/abs/2312.01301"}, {"metadata": {"arXiv": "2312.01344", "Date": "Sun, 03 Dec 2023 10:40:07 ", "Title": "tsMorph: generation of semi-synthetic time series to understand algorithm performance", "Authors": ["Mois\\'es Santos and Andr\\'e de Carvalho and Carlos Soares"], "Categories": "cs.LG cs.AI"}, "abstract": "Time series forecasting is a subject of significant scientific and industrial importance. Despite the widespread utilization of forecasting methods, there is a dearth of research aimed at comprehending the conditions under which these methods yield favorable or unfavorable performances. Empirical studies, although common, encounter challenges due to the limited availability of datasets, impeding the extraction of reliable insights. To address this, we present tsMorph, a straightforward approach for generating semi-synthetic time series through dataset morphing. tsMorph operates by creating a sequence of datasets derived from two original datasets. These newly generated datasets exhibit a progressive departure from the characteristics of one dataset and a convergence toward the attributes of the other. This method provides a valuable alternative for obtaining substantial datasets. In this paper, we demonstrate the utility of tsMorph by assessing the performance of the Long Short-Term Memory Network forecasting algorithm. The time series under examination are sourced from the NN5 Competition. The findings reveal compelling insights. Notably, the performance of the Long Short-Term Memory Network improves proportionally with the frequency of the time series. These experiments affirm that tsMorph serves as an effective tool for gaining an understanding of forecasting algorithm behaviors, offering a pathway to overcome the limitations posed by empirical studies and enabling more extensive and reliable experimentation.", "url": "https://arxiv.org/abs/2312.01344"}, {"metadata": {"arXiv": "2312.01357", "Date": "Sun, 03 Dec 2023 11:39:04 ", "Title": "Analyze the robustness of three NMF algorithms (Robust NMF with L1 norm, L2-1 norm NMF, L2 NMF)", "Authors": ["Cheng Zeng", "Jiaqi Tian", "Yixuan Xu"], "Categories": "cs.LG cs.AI", "Comments": ["22 pages", "6 figures"]}, "abstract": "Non-negative matrix factorization (NMF) and its variants have been widely employed in clustering and classification tasks (Long, & Jian , 2021). However, noises can seriously affect the results of our experiments. Our research is dedicated to investigating the noise robustness of non-negative matrix factorization (NMF) in the face of different types of noise. Specifically, we adopt three different NMF algorithms, namely L1 NMF, L2 NMF, and L21 NMF, and use the ORL and YaleB data sets to simulate a series of experiments with salt-and-pepper noise and Block-occlusion noise separately. In the experiment, we use a variety of evaluation indicators, including root mean square error (RMSE), accuracy (ACC), and normalized mutual information (NMI), to evaluate the performance of different NMF algorithms in noisy environments. Through these indicators, we quantify the resistance of NMF algorithms to noise and gain insights into their feasibility in practical applications.", "url": "https://arxiv.org/abs/2312.01357"}, {"metadata": {"arXiv": "2312.01472", "Date": "Sun, 03 Dec 2023 18:15:58 ", "Title": "BenchMARL: Benchmarking Multi-Agent Reinforcement Learning", "Authors": ["Matteo Bettini", "Amanda Prorok", "Vincent Moens"], "Categories": "cs.LG cs.AI cs.MA"}, "abstract": "The field of Multi-Agent Reinforcement Learning (MARL) is currently facing a reproducibility crisis. While solutions for standardized reporting have been proposed to address the issue, we still lack a benchmarking tool that enables standardization and reproducibility, while leveraging cutting-edge Reinforcement Learning (RL) implementations. In this paper, we introduce BenchMARL, the first MARL training library created to enable standardized benchmarking across different algorithms, models, and environments. BenchMARL uses TorchRL as its backend, granting it high performance and maintained state-of-the-art implementations while addressing the broad community of MARL PyTorch users. Its design enables systematic configuration and reporting, thus allowing users to create and run complex benchmarks from simple one-line inputs. BenchMARL is open-sourced on GitHub: https://github.com/facebookresearch/BenchMARL", "url": "https://arxiv.org/abs/2312.01472"}, {"metadata": {"arXiv": "2312.01488", "Date": "Sun, 03 Dec 2023 19:07:30 ", "Title": "ADT: Agent-based Dynamic Thresholding for Anomaly Detection", "Authors": ["Xue Yang", "Enda Howley", "Micheal Schukat"], "Categories": "cs.LG cs.AI", "Journal-ref": "Adaptive Learning Agents Workshop @ International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2023, London, UK"}, "abstract": "The complexity and scale of IT systems are increasing dramatically, posing many challenges to real-world anomaly detection. Deep learning anomaly detection has emerged, aiming at feature learning and anomaly scoring, which has gained tremendous success. However, little work has been done on the thresholding problem despite it being a critical factor for the effectiveness of anomaly detection. In this paper, we model thresholding in anomaly detection as a Markov Decision Process and propose an agent-based dynamic thresholding (ADT) framework based on a deep Q-network. The proposed method can be integrated into many systems that require dynamic thresholding. An auto-encoder is utilized in this study to obtain feature representations and produce anomaly scores for complex input data. ADT can adjust thresholds adaptively by utilizing the anomaly scores from the auto-encoder and significantly improve anomaly detection performance. The properties of ADT are studied through experiments on three real-world datasets and compared with benchmarks, hence demonstrating its thresholding capability, data-efficient learning, stability, and robustness. Our study validates the effectiveness of reinforcement learning in optimal thresholding control in anomaly detection.", "url": "https://arxiv.org/abs/2312.01488"}, {"metadata": {"arXiv": "2312.01537", "Date": "Sun, 03 Dec 2023 23:30:48 ", "Title": "Unlocking the Potential of Federated Learning: The Symphony of Dataset Distillation via Deep Generative Latents", "Authors": ["Yuqi Jia and Saeed Vahidian and Jingwei Sun and Jianyi Zhang and Vyacheslav Kungurtsev and Neil Zhenqiang Gong and Yiran Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Data heterogeneity presents significant challenges for federated learning (FL). Recently, dataset distillation techniques have been introduced, and performed at the client level, to attempt to mitigate some of these challenges. In this paper, we propose a highly efficient FL dataset distillation framework on the server side, significantly reducing both the computational and communication demands on local devices while enhancing the clients' privacy. Unlike previous strategies that perform dataset distillation on local devices and upload synthetic data to the server, our technique enables the server to leverage prior knowledge from pre-trained deep generative models to synthesize essential data representations from a heterogeneous model architecture. This process allows local devices to train smaller surrogate models while enabling the training of a larger global model on the server, effectively minimizing resource utilization. We substantiate our claim with a theoretical analysis, demonstrating the asymptotic resemblance of the process to the hypothetical ideal of completely centralized training on a heterogeneous dataset. Empirical evidence from our comprehensive experiments indicates our method's superiority, delivering an accuracy enhancement of up to 40% over non-dataset-distillation techniques in highly heterogeneous FL contexts, and surpassing existing dataset-distillation methods by 18%. In addition to the high accuracy, our framework converges faster than the baselines because rather than the server trains on several sets of heterogeneous data distributions, it trains on a multi-modal distribution. Our code is available at https://github.com/FedDG23/FedDG-main.git", "url": "https://arxiv.org/abs/2312.01537"}, {"metadata": {"arXiv": "2312.01541", "Date": "Sun, 03 Dec 2023 23:59:03 ", "Title": "Revisiting Non-separable Binary Classification and its Applications in Anomaly Detection", "Authors": ["Matthew Lau", "Ismaila Seck", "Athanasios P Meliopoulos", "Wenke Lee and Eugene Ndiaye"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Code: https://github.com/mattlaued/XOR-is-Linearly-Classifiable"], "MSC-class": "68T37 (Primary), 68T07 (Secondary)", "ACM-class": "I.2.6; I.5.1"}, "abstract": "The inability to linearly classify XOR has motivated much of deep learning. We revisit this age-old problem and show that linear classification of XOR is indeed possible. Instead of separating data between halfspaces, we propose a slightly different paradigm, equality separation, that adapts the SVM objective to distinguish data within or outside the margin. Our classifier can then be integrated into neural network pipelines with a smooth approximation. From its properties, we intuit that equality separation is suitable for anomaly detection. To formalize this notion, we introduce closing numbers, a quantitative measure on the capacity for classifiers to form closed decision regions for anomaly detection. Springboarding from this theoretical connection between binary classification and anomaly detection, we test our hypothesis on supervised anomaly detection experiments, showing that equality separation can detect both seen and unseen anomalies.", "url": "https://arxiv.org/abs/2312.01541"}, {"metadata": {"arXiv": "2312.01544", "Date": "Mon, 04 Dec 2023 00:11:27 ", "Title": "KEEC: Embed to Control on An Equivariant Geometry", "Authors": ["Xiaoyuan Cheng", "Yiming Yang", "Wei Jiang", "Yukun Hu"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "This paper investigates how representation learning can enable optimal control in unknown and complex dynamics, such as chaotic and non-linear systems, without relying on prior domain knowledge of the dynamics. The core idea is to establish an equivariant geometry that is diffeomorphic to the manifold defined by a dynamical system and to perform optimal control within this corresponding geometry, which is a non-trivial task. To address this challenge, Koopman Embed to Equivariant Control (KEEC) is introduced for model learning and control. Inspired by Lie theory, KEEC begins by learning a non-linear dynamical system defined on a manifold and embedding trajectories into a Lie group. Subsequently, KEEC formulates an equivariant value function equation in reinforcement learning on the equivariant geometry, ensuring an invariant effect as the value function on the original manifold. By deriving analytical-form optimal actions on the equivariant value function, KEEC theoretically achieves quadratic convergence for the optimal equivariant value function by leveraging the differential information on the equivariant geometry. The effectiveness of KEEC is demonstrated in challenging dynamical systems, including chaotic ones like Lorenz-63. Notably, our findings indicate that isometric and isomorphic loss functions, ensuring the compactness and smoothness of geometry, outperform loss functions without these properties.", "url": "https://arxiv.org/abs/2312.01544"}, {"metadata": {"arXiv": "2312.01564", "Date": "Mon, 04 Dec 2023 01:42:09 ", "Title": "APoLLo: Unified Adapter and Prompt Learning for Vision Language Models", "Authors": ["Sanjoy Chowdhury", "Sayan Nag", "Dinesh Manocha"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["Accepted at EMNLP 2023 (Main track)"]}, "abstract": "The choice of input text prompt plays a critical role in the performance of Vision-Language Pretrained (VLP) models such as CLIP. We present APoLLo, a unified multi-modal approach that combines Adapter and Prompt learning for Vision-Language models. Our method is designed to substantially improve the generalization capabilities of VLP models when they are fine-tuned in a few-shot setting. We introduce trainable cross-attention-based adapter layers in conjunction with vision and language encoders to strengthen the alignment between the two modalities. We enforce consistency between the respective encoder branches (receiving augmented inputs) to prevent overfitting in downstream tasks. Our method is evaluated on three representative tasks: generalization to novel classes, cross-dataset evaluation, and unseen domain shifts. In practice, APoLLo achieves a relative gain up to 6.03% over MaPLe (SOTA) on novel classes for 10 diverse image recognition datasets.", "url": "https://arxiv.org/abs/2312.01564"}, {"metadata": {"arXiv": "2312.01581", "Date": "Mon, 04 Dec 2023 02:33:53 ", "Title": "Signed Binarization: Unlocking Efficiency Through Repetition-Sparsity Trade-Off", "Authors": ["Sachit Kuhar and Yash Jain and Alexey Tumanov"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Efficient inference of Deep Neural Networks (DNNs) on resource-constrained edge devices is essential. Quantization and sparsity are key algorithmic techniques that translate to repetition and sparsity within tensors at the hardware-software interface. This paper introduces the concept of repetition-sparsity trade-off that helps explain computational efficiency during inference. We propose Signed Binarization, a unified co-design framework that synergistically integrates hardware-software systems, quantization functions, and representation learning techniques to address this trade-off. Our results demonstrate that Signed Binarization is more accurate than binarization with the same number of non-zero weights. Detailed analysis indicates that signed binarization generates a smaller distribution of effectual (non-zero) parameters nested within a larger distribution of total parameters, both of the same type, for a DNN block. Finally, our approach achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces density by 2.8x compared to binary methods for ResNet 18, presenting an alternative solution for deploying efficient models in resource-limited environments.", "url": "https://arxiv.org/abs/2312.01581"}, {"metadata": {"arXiv": "2312.01585", "Date": "Mon, 04 Dec 2023 02:48:40 ", "Title": "OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection", "Authors": ["Haoyu Jiang", "Haiyang Yu", "Nan Li", "Ping Yi"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["13 pages", "9 figures"]}, "abstract": "Deep neural networks (DNNs) have been found vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications. There are various approaches to detect backdoor attacks, however they all make certain assumptions about the target attack to be detected and require equal and huge numbers of clean and backdoor samples for training, which renders these detection methods quite limiting in real-world circumstances. This study proposes a novel one-class classification framework called One-class Graph Embedding Classification (OCGEC) that uses GNNs for model-level backdoor detection with only a little amount of clean data. First, we train thousands of tiny models as raw datasets from a small number of clean datasets. Following that, we design a ingenious model-to-graph method for converting the model's structural details and weight features into graph data. We then pre-train a generative self-supervised graph autoencoder (GAE) to better learn the features of benign models in order to detect backdoor models without knowing the attack strategy. After that, we dynamically combine the GAE and one-class classifier optimization goals to form classification boundaries that distinguish backdoor models from benign models. Our OCGEC combines the powerful representation capabilities of graph neural networks with the utility of one-class classification techniques in the field of anomaly detection. In comparison to other baselines, it achieves AUC scores of more than 98% on a number of tasks, which far exceeds existing methods for detection even when they rely on a huge number of positive and negative samples. Our pioneering application of graphic scenarios for generic backdoor detection can provide new insights that can be used to improve other backdoor defense tasks. Code is available at https://github.com/jhy549/OCGEC.", "url": "https://arxiv.org/abs/2312.01585"}, {"metadata": {"arXiv": "2312.01612", "Date": "Mon, 04 Dec 2023 04:03:30 ", "Title": "xNeuSM: Explainable Neural Subgraph Matching with Graph Learnable Multi-hop Attention Networks", "Authors": ["Duc Q. Nguyen", "Thanh Toan Nguyen", "Tho quan"], "Categories": "cs.LG cs.AI", "Comments": ["33 pages", "8 figures", "6 tables"]}, "abstract": "Subgraph matching is a challenging problem with a wide range of applications in database systems, biochemistry, and cognitive science. It involves determining whether a given query graph is present within a larger target graph. Traditional graph-matching algorithms provide precise results but face challenges in large graph instances due to the NP-complete problem, limiting their practical applicability. In contrast, recent neural network-based approximations offer more scalable solutions, but often lack interpretable node correspondences. To address these limitations, this article presents xNeuSM: Explainable Neural Subgraph Matching which introduces Graph Learnable Multi-hop Attention Networks (GLeMA) that adaptively learns the parameters governing the attention factor decay for each node across hops rather than relying on fixed hyperparameters. We provide a theoretical analysis establishing error bounds for GLeMA's approximation of multi-hop attention as a function of the number of hops. Additionally, we prove that learning distinct attention decay factors for each node leads to a correct approximation of multi-hop attention. Empirical evaluation on real-world datasets shows that xNeuSM achieves substantial improvements in prediction accuracy of up to 34% compared to approximate baselines and, notably, at least a seven-fold faster query time than exact algorithms. The source code of our implementation is available at https://github.com/martinakaduc/xNeuSM.", "url": "https://arxiv.org/abs/2312.01612"}, {"metadata": {"arXiv": "2312.01624", "Date": "Mon, 04 Dec 2023 04:49:10 ", "Title": "GVFs in the Real World: Making Predictions Online for Water Treatment", "Authors": ["Muhammad Kamran Janjua", "Haseeb Shah", "Martha White", "Erfan Miahi", "Marlos C. Machado", "Adam White"], "Categories": "cs.LG cs.AI", "Comments": ["Published in Machine Learning (2023)"], "Journal-ref": "Machine Learning (2023): 1-31"}, "abstract": "In this paper we investigate the use of reinforcement-learning based prediction approaches for a real drinking-water treatment plant. Developing such a prediction system is a critical step on the path to optimizing and automating water treatment. Before that, there are many questions to answer about the predictability of the data, suitable neural network architectures, how to overcome partial observability and more. We first describe this dataset, and highlight challenges with seasonality, nonstationarity, partial observability, and heterogeneity across sensors and operation modes of the plant. We then describe General Value Function (GVF) predictions -- discounted cumulative sums of observations -- and highlight why they might be preferable to classical n-step predictions common in time series prediction. We discuss how to use offline data to appropriately pre-train our temporal difference learning (TD) agents that learn these GVF predictions, including how to select hyperparameters for online fine-tuning in deployment. We find that the TD-prediction agent obtains an overall lower normalized mean-squared error than the n-step prediction agent. Finally, we show the importance of learning in deployment, by comparing a TD agent trained purely offline with no online updating to a TD agent that learns online. This final result is one of the first to motivate the importance of adapting predictions in real-time, for non-stationary high-volume systems in the real world.", "url": "https://arxiv.org/abs/2312.01624"}, {"metadata": {"arXiv": "2312.01657", "Date": "Mon, 04 Dec 2023 06:18:10 ", "Title": "On Tuning Neural ODE for Stability, Consistency and Faster Convergence", "Authors": ["Sheikh Waqas Akhtar"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Neural-ODE parameterize a differential equation using continuous depth neural network and solve it using numerical ODE-integrator. These models offer a constant memory cost compared to models with discrete sequence of hidden layers in which memory cost increases linearly with the number of layers. In addition to memory efficiency, other benefits of neural-ode include adaptability of evaluation approach to input, and flexibility to choose numerical precision or fast training. However, despite having all these benefits, it still has some limitations. We identify the ODE-integrator (also called ODE-solver) as the weakest link in the chain as it may have stability, consistency and convergence (CCS) issues and may suffer from slower convergence or may not converge at all. We propose a first-order Nesterov's accelerated gradient (NAG) based ODE-solver which is proven to be tuned vis-a-vis CCS conditions. We empirically demonstrate the efficacy of our approach by training faster, while achieving better or comparable performance against neural-ode employing other fixed-step explicit ODE-solvers as well discrete depth models such as ResNet in three different tasks including supervised classification, density estimation, and time-series modelling.", "url": "https://arxiv.org/abs/2312.01657"}, {"metadata": {"arXiv": "2312.01692", "Date": "Mon, 04 Dec 2023 07:29:44 ", "Title": "Risk-Controlling Model Selection via Guided Bayesian Optimization", "Authors": ["Bracha Laufer-Goldshtein", "Adam Fisch", "Regina Barzilay", "Tommi Jaakkola"], "Categories": "cs.LG cs.AI stat.ME stat.ML"}, "abstract": "Adjustable hyperparameters of machine learning models typically impact various key trade-offs such as accuracy, fairness, robustness, or inference cost. Our goal in this paper is to find a configuration that adheres to user-specified limits on certain risks while being useful with respect to other conflicting metrics. We solve this by combining Bayesian Optimization (BO) with rigorous risk-controlling procedures, where our core idea is to steer BO towards an efficient testing strategy. Our BO method identifies a set of Pareto optimal configurations residing in a designated region of interest. The resulting candidates are statistically verified and the best-performing configuration is selected with guaranteed risk levels. We demonstrate the effectiveness of our approach on a range of tasks with multiple desiderata, including low error rates, equitable predictions, handling spurious correlations, managing rate and distortion in generative models, and reducing computational costs.", "url": "https://arxiv.org/abs/2312.01692"}, {"metadata": {"arXiv": "2312.01699", "Date": "Mon, 04 Dec 2023 07:39:05 ", "Title": "Rethinking Urban Mobility Prediction: A Super-Multivariate Time Series Forecasting Approach", "Authors": ["Jinguo Cheng", "Ke Li", "Yuxuan Liang", "Lijun Sun", "Junchi Yan", "Yuankai Wu"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages,9 figures"]}, "abstract": "Long-term urban mobility predictions play a crucial role in the effective management of urban facilities and services. Conventionally, urban mobility data has been structured as spatiotemporal videos, treating longitude and latitude grids as fundamental pixels. Consequently, video prediction methods, relying on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), have been instrumental in this domain. In our research, we introduce a fresh perspective on urban mobility prediction. Instead of oversimplifying urban mobility data as traditional video data, we regard it as a complex multivariate time series. This perspective involves treating the time-varying values of each grid in each channel as individual time series, necessitating a thorough examination of temporal dynamics, cross-variable correlations, and frequency-domain insights for precise and reliable predictions. To address this challenge, we present the Super-Multivariate Urban Mobility Transformer (SUMformer), which utilizes a specially designed attention mechanism to calculate temporal and cross-variable correlations and reduce computational costs stemming from a large number of time series. SUMformer also employs low-frequency filters to extract essential information for long-term predictions. Furthermore, SUMformer is structured with a temporal patch merge mechanism, forming a hierarchical framework that enables the capture of multi-scale correlations. Consequently, it excels in urban mobility pattern modeling and long-term prediction, outperforming current state-of-the-art methods across three real-world datasets.", "url": "https://arxiv.org/abs/2312.01699"}, {"metadata": {"arXiv": "2312.01739", "Date": "Mon, 04 Dec 2023 09:03:06 ", "Title": "Divide-and-Conquer Strategy for Large-Scale Dynamic Bayesian Network Structure Learning", "Authors": ["Hui Ouyang", "Cheng Chen", "Ke Tang"], "Categories": "cs.LG cs.AI"}, "abstract": "Dynamic Bayesian Networks (DBNs), renowned for their interpretability, have become increasingly vital in representing complex stochastic processes in various domains such as gene expression analysis, healthcare, and traffic prediction. Structure learning of DBNs from data is challenging, particularly for datasets with thousands of variables. Most current algorithms for DBN structure learning are adaptations from those used in static Bayesian Networks (BNs), and are typically focused on small-scale problems. In order to solve large-scale problems while taking full advantage of existing algorithms, this paper introduces a novel divide-and-conquer strategy, originally developed for static BNs, and adapts it for large-scale DBN structure learning. In this work, we specifically concentrate on 2 Time-sliced Bayesian Networks (2-TBNs), a special class of DBNs. Furthermore, we leverage the prior knowledge of 2-TBNs to enhance the performance of the strategy we introduce. Our approach significantly improves the scalability and accuracy of 2-TBN structure learning. Experimental results demonstrate the effectiveness of our method, showing substantial improvements over existing algorithms in both computational efficiency and structure learning accuracy. On problem instances with more than 1,000 variables, our approach improves two accuracy metrics by 74.45% and 110.94% on average , respectively, while reducing runtime by 93.65% on average.", "url": "https://arxiv.org/abs/2312.01739"}, {"metadata": {"arXiv": "2312.01811", "Date": "Mon, 04 Dec 2023 11:30:26 ", "Title": "Energy-based Potential Games for Joint Motion Forecasting and Control", "Authors": ["Christopher Diehl", "Tobias Klosek", "Martin Kr\\\"uger", "Nils Murzyn", "Timo Osterburg", "Torsten Bertram"], "Categories": "cs.LG cs.AI cs.GT cs.MA cs.RO", "Comments": ["Conference on Robot Learning", "CoRL 2023"]}, "abstract": "This work uses game theory as a mathematical framework to address interaction modeling in multi-agent motion forecasting and control. Despite its interpretability, applying game theory to real-world robotics, like automated driving, faces challenges such as unknown game parameters. To tackle these, we establish a connection between differential games, optimal control, and energy-based models, demonstrating how existing approaches can be unified under our proposed Energy-based Potential Game formulation. Building upon this, we introduce a new end-to-end learning application that combines neural networks for game-parameter inference with a differentiable game-theoretic optimization layer, acting as an inductive bias. The analysis provides empirical evidence that the game-theoretic layer adds interpretability and improves the predictive performance of various neural network backbones using two simulations and two real-world driving datasets.", "url": "https://arxiv.org/abs/2312.01811"}, {"metadata": {"arXiv": "2312.01884", "Date": "Mon, 04 Dec 2023 13:33:51 ", "Title": "Correlation and Unintended Biases on Univariate and Multivariate Decision Trees", "Authors": ["Mattia Setzu and Salvatore Ruggieri"], "Categories": "cs.LG cs.AI"}, "abstract": "Decision Trees are accessible, interpretable, and well-performing classification models. A plethora of variants with increasing expressiveness has been proposed in the last forty years. We contrast the two families of univariate DTs, whose split functions partition data through axis-parallel hyperplanes, and multivariate DTs, whose splits instead partition data through oblique hyperplanes. The latter include the former, hence multivariate DTs are in principle more powerful. Surprisingly enough, however, univariate DTs consistently show comparable performances in the literature. We analyze the reasons behind this, both with synthetic and real-world benchmark datasets. Our research questions test whether the pre-processing phase of removing correlation among features in datasets has an impact on the relative performances of univariate vs multivariate DTs. We find that existing benchmark datasets are likely biased towards favoring univariate DTs.", "url": "https://arxiv.org/abs/2312.01884"}, {"metadata": {"arXiv": "2312.01939", "Date": "Mon, 04 Dec 2023 14:55:58 ", "Title": "Foundations for Transfer in Reinforcement Learning: A Taxonomy of Knowledge Modalities", "Authors": ["Markus Wulfmeier", "Arunkumar Byravan", "Sarah Bechtle", "Karol Hausman", "Nicolas Heess"], "Categories": "cs.LG cs.AI cs.RO stat.ML"}, "abstract": "Contemporary artificial intelligence systems exhibit rapidly growing abilities accompanied by the growth of required resources, expansive datasets and corresponding investments into computing infrastructure. Although earlier successes predominantly focus on constrained settings, recent strides in fundamental research and applications aspire to create increasingly general systems. This evolving landscape presents a dual panorama of opportunities and challenges in refining the generalisation and transfer of knowledge - the extraction from existing sources and adaptation as a comprehensive foundation for tackling new problems. Within the domain of reinforcement learning (RL), the representation of knowledge manifests through various modalities, including dynamics and reward models, value functions, policies, and the original data. This taxonomy systematically targets these modalities and frames its discussion based on their inherent properties and alignment with different objectives and mechanisms for transfer. Where possible, we aim to provide coarse guidance delineating approaches which address requirements such as limiting environment interactions, maximising computational efficiency, and enhancing generalisation across varying axes of change. Finally, we analyse reasons contributing to the prevalence or scarcity of specific forms of transfer, the inherent potential behind pushing these frontiers, and underscore the significance of transitioning from designed to learned transfer.", "url": "https://arxiv.org/abs/2312.01939"}, {"metadata": {"arXiv": "2312.02019", "Date": "Mon, 04 Dec 2023 16:43:36 ", "Title": "Action Inference by Maximising Evidence: Zero-Shot Imitation from Observation with World Models", "Authors": ["Xingyuan Zhang", "Philip Becker-Ehmck", "Patrick van der Smagt", "Maximilian Karl"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "Unlike most reinforcement learning agents which require an unrealistic amount of environment interactions to learn a new behaviour, humans excel at learning quickly by merely observing and imitating others. This ability highly depends on the fact that humans have a model of their own embodiment that allows them to infer the most likely actions that led to the observed behaviour. In this paper, we propose Action Inference by Maximising Evidence (AIME) to replicate this behaviour using world models. AIME consists of two distinct phases. In the first phase, the agent learns a world model from its past experience to understand its own body by maximising the ELBO. While in the second phase, the agent is given some observation-only demonstrations of an expert performing a novel task and tries to imitate the expert's behaviour. AIME achieves this by defining a policy as an inference model and maximising the evidence of the demonstration under the policy and world model. Our method is \"zero-shot\" in the sense that it does not require further training for the world model or online interactions with the environment after given the demonstration. We empirically validate the zero-shot imitation performance of our method on the Walker and Cheetah embodiment of the DeepMind Control Suite and find it outperforms the state-of-the-art baselines. Code is available at: https://github.com/argmax-ai/aime.", "url": "https://arxiv.org/abs/2312.02019"}, {"metadata": {"arXiv": "2312.02119", "Date": "Mon, 04 Dec 2023 18:49:23 ", "Title": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically", "Authors": ["Anay Mehrotra", "Manolis Zampetakis", "Paul Kassianik", "Blaine Nelson", "Hyrum Anderson", "Yaron Singer", "Amin Karbasi"], "Categories": "cs.LG cs.AI cs.CL cs.CR stat.ML", "Comments": ["An implementation of the presented method is available at https://github.com/RICommunity/TAP"]}, "abstract": "While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an LLM to iteratively refine candidate (attack) prompts using tree-of-thoughts reasoning until one of the generated prompts jailbreaks the target. Crucially, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate a large search space of prompts and pruning reduces the total number of queries sent to the target. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo) for more than 80% of the prompts using only a small number of queries. This significantly improves upon the previous state-of-the-art black-box method for generating jailbreaks.", "url": "https://arxiv.org/abs/2312.02119"}, {"metadata": {"arXiv": "2312.02132", "Date": "Mon, 04 Dec 2023 18:54:34 ", "Title": "Hot PATE: Private Aggregation of Distributions for Diverse Task", "Authors": ["Edith Cohen and Xin Lyu and Jelani Nelson and Tamas Sarlos and Uri Stemmer"], "Categories": "cs.LG cs.AI cs.CR cs.DS", "Comments": ["19 pages"]}, "abstract": "The Private Aggregation of Teacher Ensembles (PATE) framework~\\cite{PapernotAEGT:ICLR2017} is a versatile approach to privacy-preserving machine learning. In PATE, teacher models are trained on distinct portions of sensitive data, and their predictions are privately aggregated to label new training examples for a student model. Until now, PATE has primarily been explored with classification-like tasks, where each example possesses a ground-truth label, and knowledge is transferred to the student by labeling public examples. Generative AI models, however, excel in open ended \\emph{diverse} tasks with multiple valid responses and scenarios that may not align with traditional labeled examples. Furthermore, the knowledge of models is often encapsulated in the response distribution itself and may be transferred from teachers to student in a more fluid way. We propose \\emph{hot PATE}, tailored for the diverse setting. In hot PATE, each teacher model produces a response distribution and the aggregation method must preserve both privacy and diversity of responses. We demonstrate, analytically and empirically, that hot PATE achieves privacy-utility tradeoffs that are comparable to, and in diverse settings, significantly surpass, the baseline ``cold'' PATE.", "url": "https://arxiv.org/abs/2312.02132"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

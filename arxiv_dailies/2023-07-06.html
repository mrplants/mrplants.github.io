<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.01346", "Date": "Mon, 03 Jul 2023 20:39:48 ", "Title": "Patch-CNN: Training data-efficient deep learning for high-fidelity diffusion tensor estimation from minimal diffusion protocols", "Authors": ["Tobias Goodwin-Allcock", "Ting Gong", "Robert Gray", "Parashkev Nachev and Hui Zhang"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["12 pages", "6 figures"]}, "abstract": "We propose a new method, Patch-CNN, for diffusion tensor (DT) estimation from only six-direction diffusion weighted images (DWI). Deep learning-based methods have been recently proposed for dMRI parameter estimation, using either voxel-wise fully-connected neural networks (FCN) or image-wise convolutional neural networks (CNN). In the acute clinical context -- where pressure of time limits the number of imaged directions to a minimum -- existing approaches either require an infeasible number of training images volumes (image-wise CNNs), or do not estimate the fibre orientations (voxel-wise FCNs) required for tractogram estimation. To overcome these limitations, we propose Patch-CNN, a neural network with a minimal (non-voxel-wise) convolutional kernel (3$\\times$3$\\times$3). Compared with voxel-wise FCNs, this has the advantage of allowing the network to leverage local anatomical information. Compared with image-wise CNNs, the minimal kernel vastly reduces training data demand. Evaluated against both conventional model fitting and a voxel-wise FCN, Patch-CNN, trained with a single subject is shown to improve the estimation of both scalar dMRI parameters and fibre orientation from six-direction DWIs. The improved fibre orientation estimation is shown to produce improved tractogram.", "url": "https://arxiv.org/abs/2307.01346"}, {"metadata": {"arXiv": "2307.01470", "Date": "Tue, 04 Jul 2023 04:29:03 ", "Title": "A Review of Driver Gaze Estimation and Application in Gaze Behavior Understanding", "Authors": ["Pavan Kumar Sharma and Pranamesh Chakraborty"], "Categories": "cs.CV cs.HC cs.LG"}, "abstract": "Driver gaze plays an important role in different gaze-based applications such as driver attentiveness detection, visual distraction detection, gaze behavior understanding, and building driver assistance system. The main objective of this study is to perform a comprehensive summary of driver gaze fundamentals, methods to estimate driver gaze, and it's applications in real world driving scenarios. We first discuss the fundamentals related to driver gaze, involving head-mounted and remote setup based gaze estimation and the terminologies used for each of these data collection methods. Next, we list out the existing benchmark driver gaze datasets, highlighting the collection methodology and the equipment used for such data collection. This is followed by a discussion of the algorithms used for driver gaze estimation, which primarily involves traditional machine learning and deep learning based techniques. The estimated driver gaze is then used for understanding gaze behavior while maneuvering through intersections, on-ramps, off-ramps, lane changing, and determining the effect of roadside advertising structures. Finally, we have discussed the limitations in the existing literature, challenges, and the future scope in driver gaze estimation and gaze-based applications.", "url": "https://arxiv.org/abs/2307.01470"}, {"metadata": {"arXiv": "2307.01524", "Date": "Tue, 04 Jul 2023 07:10:39 ", "Title": "Exploiting Richness of Learned Compressed Representation of Images for Semantic Segmentation", "Authors": ["Ravi Kakaiya", "Rakshith Sathish", "Ramanathan Sethuraman"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Accepted at ICME 2023 (Industry Track)"]}, "abstract": "Autonomous vehicles and Advanced Driving Assistance Systems (ADAS) have the potential to radically change the way we travel. Many such vehicles currently rely on segmentation and object detection algorithms to detect and track objects around its surrounding. The data collected from the vehicles are often sent to cloud servers to facilitate continual/life-long learning of these algorithms. Considering the bandwidth constraints, the data is compressed before sending it to servers, where it is typically decompressed for training and analysis. In this work, we propose the use of a learning-based compression Codec to reduce the overhead in latency incurred for the decompression operation in the standard pipeline. We demonstrate that the learned compressed representation can also be used to perform tasks like semantic segmentation in addition to decompression to obtain the images. We experimentally validate the proposed pipeline on the Cityscapes dataset, where we achieve a compression factor up to $66 \\times$ while preserving the information required to perform segmentation with a dice coefficient of $0.84$ as compared to $0.88$ achieved using decompressed images while reducing the overall compute by $11\\%$.", "url": "https://arxiv.org/abs/2307.01524"}, {"metadata": {"arXiv": "2307.01750", "Date": "Tue, 04 Jul 2023 14:39:59 ", "Title": "SRCD: Semantic Reasoning with Compound Domains for Single-Domain Generalized Object Detection", "Authors": ["Zhijie Rao", "Jingcai Guo", "Luyao Tang", "Yue Huang", "Xinghao Ding", "Song Guo"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "5 figures"]}, "abstract": "This paper provides a novel framework for single-domain generalized object detection (i.e., Single-DGOD), where we are interested in learning and maintaining the semantic structures of self-augmented compound cross-domain samples to enhance the model's generalization ability. Different from DGOD trained on multiple source domains, Single-DGOD is far more challenging to generalize well to multiple target domains with only one single source domain. Existing methods mostly adopt a similar treatment from DGOD to learn domain-invariant features by decoupling or compressing the semantic space. However, there may have two potential limitations: 1) pseudo attribute-label correlation, due to extremely scarce single-domain data; and 2) the semantic structural information is usually ignored, i.e., we found the affinities of instance-level semantic relations in samples are crucial to model generalization. In this paper, we introduce Semantic Reasoning with Compound Domains (SRCD) for Single-DGOD. Specifically, our SRCD contains two main components, namely, the texture-based self-augmentation (TBSA) module, and the local-global semantic reasoning (LGSR) module. TBSA aims to eliminate the effects of irrelevant attributes associated with labels, such as light, shadow, color, etc., at the image level by a light-yet-efficient self-augmentation. Moreover, LGSR is used to further model the semantic relationships on instance features to uncover and maintain the intrinsic semantic structures. Extensive experiments on multiple benchmarks demonstrate the effectiveness of the proposed SRCD.", "url": "https://arxiv.org/abs/2307.01750"}, {"metadata": {"arXiv": "2307.01759", "Date": "Tue, 04 Jul 2023 15:00:06 ", "Title": "Pretraining is All You Need: A Multi-Atlas Enhanced Transformer Framework for Autism Spectrum Disorder Classification", "Authors": ["Lucas Mahler", "Qi Wang", "Julius Steiglechner", "Florian Birk", "Samuel Heczko", "Klaus Scheffler", "Gabriele Lohmann"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Autism spectrum disorder (ASD) is a prevalent psychiatric condition characterized by atypical cognitive, emotional, and social patterns. Timely and accurate diagnosis is crucial for effective interventions and improved outcomes in individuals with ASD. In this study, we propose a novel Multi-Atlas Enhanced Transformer framework, METAFormer, ASD classification. Our framework utilizes resting-state functional magnetic resonance imaging data from the ABIDE I dataset, comprising 406 ASD and 476 typical control (TC) subjects. METAFormer employs a multi-atlas approach, where flattened connectivity matrices from the AAL, CC200, and DOS160 atlases serve as input to the transformer encoder. Notably, we demonstrate that self-supervised pretraining, involving the reconstruction of masked values from the input, significantly enhances classification performance without the need for additional or separate training data. Through stratified cross-validation, we evaluate the proposed framework and show that it surpasses state-of-the-art performance on the ABIDE I dataset, with an average accuracy of 83.7% and an AUC-score of 0.832. The code for our framework is available at https://github.com/Lugges991/METAFormer", "url": "https://arxiv.org/abs/2307.01759"}, {"metadata": {"arXiv": "2307.01924", "Date": "Tue, 04 Jul 2023 21:18:39 ", "Title": "ProtoDiffusion: Classifier-Free Diffusion Guidance with Prototype Learning", "Authors": ["Gulcin Baykal", "Halil Faruk Karagoz", "Taha Binhuraib", "Gozde Unal"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion models are generative models that have shown significant advantages compared to other generative models in terms of higher generation quality and more stable training. However, the computational need for training diffusion models is considerably increased. In this work, we incorporate prototype learning into diffusion models to achieve high generation quality faster than the original diffusion model. Instead of randomly initialized class embeddings, we use separately learned class prototypes as the conditioning information to guide the diffusion process. We observe that our method, called ProtoDiffusion, achieves better performance in the early stages of training compared to the baseline method, signifying that using the learned prototypes shortens the training time. We demonstrate the performance of ProtoDiffusion using various datasets and experimental settings, achieving the best performance in shorter times across all settings.", "url": "https://arxiv.org/abs/2307.01924"}, {"metadata": {"arXiv": "2307.01946", "Date": "Tue, 04 Jul 2023 22:42:55 ", "Title": "A Synthetic Electrocardiogram (ECG) Image Generation Toolbox to Facilitate Deep Learning-Based Scanned ECG Digitization", "Authors": ["Kshama Kodthalu Shivashankara and Reza Sameni"], "Categories": "cs.CV cs.LG"}, "abstract": "Access to medical data is often limited as it contains protected health information (PHI). There are privacy concerns regarding using records containing personally identifiable information. Recent advancements have been made in applying deep learning-based algorithms for clinical diagnosis and decision-making. However, deep learning models are data-greedy, whereas the availability of medical datasets for training and evaluating these models is relatively limited. Data augmentation with so-called \\textit{digital twins} is an emerging technique to address this need. This paper presents a novel approach for generating synthetic electrocardiogram (ECG) images with realistic artifacts from time-series data for use in developing algorithms for digitization of ECG images. Synthetic data is generated in a privacy-preserving manner by generating distortionless ECG images on standard ECG paper background. Next, various distortions, including handwritten text artifacts, wrinkles, creases, and perspective transforms are applied to the ECG images. The artifacts are generated synthetically, without personally identifiable information. As a use case, we generated a large ECG image dataset of 21,801 records from the PhysioNet PTB-XL dataset, with 12 lead ECG time-series data from 18,869 patients. A deep ECG image digitization model was developed and trained on the synthetic dataset, and was employed to convert the synthetic images to time-series data for evaluation. The signal-to-noise ratio (SNR) was calculated to assess the image digitization quality vs the ground truth ECG time-series. The results show an average signal recovery SNR of 27$\\pm$2.8\\,dB, demonstrating the significance of the proposed synthetic ECG image dataset for training deep learning models.", "url": "https://arxiv.org/abs/2307.01946"}, {"metadata": {"arXiv": "2307.02055", "Date": "Wed, 05 Jul 2023 06:40:08 ", "Title": "Adversarial Attacks on Image Classification Models: FGSM and Patch Attacks and their Impact", "Authors": ["Jaydip Sen and Subhasis Dasgupta"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["This is the preprint of the chapter titled \"Adversarial Attacks on Image Classification Models: FGSM and Patch Attacks and their Impact\" which will be published in the volume titled \"Information Security and Privacy in the Digital World - Some Selected Cases\"", "edited by Jaydip Sen. The book will be published by IntechOpen", "London", "UK", "in 2023. This is not the final version of the chapter"]}, "abstract": "This chapter introduces the concept of adversarial attacks on image classification models built on convolutional neural networks (CNN). CNNs are very popular deep-learning models which are used in image classification tasks. However, very powerful and pre-trained CNN models working very accurately on image datasets for image classification tasks may perform disastrously when the networks are under adversarial attacks. In this work, two very well-known adversarial attacks are discussed and their impact on the performance of image classifiers is analyzed. These two adversarial attacks are the fast gradient sign method (FGSM) and adversarial patch attack. These attacks are launched on three powerful pre-trained image classifier architectures, ResNet-34, GoogleNet, and DenseNet-161. The classification accuracy of the models in the absence and presence of the two attacks are computed on images from the publicly accessible ImageNet dataset. The results are analyzed to evaluate the impact of the attacks on the image classification task.", "url": "https://arxiv.org/abs/2307.02055"}, {"metadata": {"arXiv": "2307.02402", "Date": "Wed, 05 Jul 2023 16:21:52 ", "Title": "Unbalanced Optimal Transport: A Unified Framework for Object Detection", "Authors": ["Henri De Plaen", "Pierre-Fran\\c{c}ois De Plaen", "Johan A. K. Suykens", "Marc Proesmans", "Tinne Tuytelaars and Luc Van Gool"], "Categories": "cs.CV cs.LG", "Comments": ["Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)"]}, "abstract": "During training, supervised object detection tries to correctly match the predicted bounding boxes and associated classification scores to the ground truth. This is essential to determine which predictions are to be pushed towards which solutions, or to be discarded. Popular matching strategies include matching to the closest ground truth box (mostly used in combination with anchors), or matching via the Hungarian algorithm (mostly used in anchor-free methods). Each of these strategies comes with its own properties, underlying losses, and heuristics. We show how Unbalanced Optimal Transport unifies these different approaches and opens a whole continuum of methods in between. This allows for a finer selection of the desired properties. Experimentally, we show that training an object detection model with Unbalanced Optimal Transport is able to reach the state-of-the-art both in terms of Average Precision and Average Recall as well as to provide a faster initial convergence. The approach is well suited for GPU implementation, which proves to be an advantage for large-scale models.", "url": "https://arxiv.org/abs/2307.02402"}, {"metadata": {"arXiv": "2307.01236", "Date": "Mon, 03 Jul 2023 11:42:14 ", "Title": "Rockmate: an Efficient, Fast, Automatic and Generic Tool for Re-materialization in PyTorch", "Authors": ["Xunyi Zhao", "Th\\'eotime Le Hellard", "Lionel Eyraud", "Julia Gusak", "Olivier Beaumont"], "Categories": "cs.LG cs.PL"}, "abstract": "We propose Rockmate to control the memory requirements when training PyTorch DNN models. Rockmate is an automatic tool that starts from the model code and generates an equivalent model, using a predefined amount of memory for activations, at the cost of a few re-computations. Rockmate automatically detects the structure of computational and data dependencies and rewrites the initial model as a sequence of complex blocks. We show that such a structure is widespread and can be found in many models in the literature (Transformer based models, ResNet, RegNets,...). This structure allows us to solve the problem in a fast and efficient way, using an adaptation of Checkmate (too slow on the whole model but general) at the level of individual blocks and an adaptation of Rotor (fast but limited to sequential models) at the level of the sequence itself. We show through experiments on many models that Rockmate is as fast as Rotor and as efficient as Checkmate, and that it allows in many cases to obtain a significantly lower memory consumption for activations (by a factor of 2 to 5) for a rather negligible overhead (of the order of 10% to 20%). Rockmate is open source and available at https://github.com/topal-team/rockmate.", "url": "https://arxiv.org/abs/2307.01236"}, {"metadata": {"arXiv": "2307.01237", "Date": "Mon, 03 Jul 2023 12:17:28 ", "Title": "Dynamical Graph Echo State Networks with Snapshot Merging for Dissemination Process Classification", "Authors": ["Ziqiang Li", "Kantaro Fujiwara", "Gouhei Tanaka"], "Categories": "cs.LG cs.SI"}, "abstract": "The Dissemination Process Classification (DPC) is a popular application of temporal graph classification. The aim of DPC is to classify different spreading patterns of information or pestilence within a community represented by discrete-time temporal graphs. Recently, a reservoir computing-based model named Dynamical Graph Echo State Network (DynGESN) has been proposed for processing temporal graphs with relatively high effectiveness and low computational costs. In this study, we propose a novel model which combines a novel data augmentation strategy called snapshot merging with the DynGESN for dealing with DPC tasks. In our model, the snapshot merging strategy is designed for forming new snapshots by merging neighboring snapshots over time, and then multiple reservoir encoders are set for capturing spatiotemporal features from merged snapshots. After those, the logistic regression is adopted for decoding the sum-pooled embeddings into the classification results. Experimental results on six benchmark DPC datasets show that our proposed model has better classification performances than the DynGESN and several kernel-based models.", "url": "https://arxiv.org/abs/2307.01237"}, {"metadata": {"arXiv": "2307.01325", "Date": "Mon, 03 Jul 2023 19:54:53 ", "Title": "Robust Uncertainty Estimation for Classification of Maritime Objects", "Authors": ["Jonathan Becktor", "Frederik Scholler", "Evangelos Boukas", "and Lazaros Nalpantidis"], "Categories": "cs.LG cs.RO"}, "abstract": "We explore the use of uncertainty estimation in the maritime domain, showing the efficacy on toy datasets (CIFAR10) and proving it on an in-house dataset, SHIPS. We present a method joining the intra-class uncertainty achieved using Monte Carlo Dropout, with recent discoveries in the field of outlier detection, to gain more holistic uncertainty measures. We explore the relationship between the introduced uncertainty measures and examine how well they work on CIFAR10 and in a real-life setting. Our work improves the FPR95 by 8% compared to the current highest-performing work when the models are trained without out-of-distribution data. We increase the performance by 77% compared to a vanilla implementation of the Wide ResNet. We release the SHIPS dataset and show the effectiveness of our method by improving the FPR95 by 44.2% with respect to the baseline. Our approach is model agnostic, easy to implement, and often does not require model retraining.", "url": "https://arxiv.org/abs/2307.01325"}, {"metadata": {"arXiv": "2307.01357", "Date": "Mon, 03 Jul 2023 21:13:40 ", "Title": "Adaptive Principal Component Regression with Applications to Panel Data", "Authors": ["Anish Agarwal", "Keegan Harris", "Justin Whitehouse", "Zhiwei Steven Wu"], "Categories": "cs.LG econ.EM stat.ME stat.ML"}, "abstract": "Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.", "url": "https://arxiv.org/abs/2307.01357"}, {"metadata": {"arXiv": "2307.01384", "Date": "Mon, 03 Jul 2023 22:29:48 ", "Title": "Systematic Bias in Sample Inference and its Effect on Machine Learning", "Authors": ["Owen O'Neill and Fintan Costello"], "Categories": "cs.LG stat.ME"}, "abstract": "A commonly observed pattern in machine learning models is an underprediction of the target feature, with the model's predicted target rate for members of a given category typically being lower than the actual target rate for members of that category in the training set. This underprediction is usually larger for members of minority groups; while income level is underpredicted for both men and women in the 'adult' dataset, for example, the degree of underprediction is significantly higher for women (a minority in that dataset). We propose that this pattern of underprediction for minorities arises as a predictable consequence of statistical inference on small samples. When presented with a new individual for classification, an ML model performs inference not on the entire training set, but on a subset that is in some way similar to the new individual, with sizes of these subsets typically following a power law distribution so that most are small (and with these subsets being necessarily smaller for the minority group). We show that such inference on small samples is subject to systematic and directional statistical bias, and that this bias produces the observed patterns of underprediction seen in ML models. Analysing a standard sklearn decision tree model's predictions on a set of over 70 subsets of the 'adult' and COMPAS datasets, we found that a bias prediction measure based on small-sample inference had a significant positive correlations (0.56 and 0.85) with the observed underprediction rate for these subsets.", "url": "https://arxiv.org/abs/2307.01384"}, {"metadata": {"arXiv": "2307.01389", "Date": "Mon, 03 Jul 2023 23:02:26 ", "Title": "Identification of Causal Relationship between Amyloid-beta Accumulation and Alzheimer's Disease Progression via Counterfactual Inference", "Authors": ["Haixing Dai", "Mengxuan Hu", "Qing Li", "Lu Zhang", "Lin Zhao", "Dajiang Zhu", "Ibai Diez", "Jorge Sepulcre", "Fan Zhang", "Xingyu Gao", "Manhua Liu", "Quanzheng Li", "Sheng Li", "Tianming Liu and Xiang Li"], "Categories": "cs.LG stat.ME"}, "abstract": "Alzheimer's disease (AD) is a neurodegenerative disorder that is beginning with amyloidosis, followed by neuronal loss and deterioration in structure, function, and cognition. The accumulation of amyloid-beta in the brain, measured through 18F-florbetapir (AV45) positron emission tomography (PET) imaging, has been widely used for early diagnosis of AD. However, the relationship between amyloid-beta accumulation and AD pathophysiology remains unclear, and causal inference approaches are needed to uncover how amyloid-beta levels can impact AD development. In this paper, we propose a graph varying coefficient neural network (GVCNet) for estimating the individual treatment effect with continuous treatment levels using a graph convolutional neural network. We highlight the potential of causal inference approaches, including GVCNet, for measuring the regional causal connections between amyloid-beta accumulation and AD pathophysiology, which may serve as a robust tool for early diagnosis and tailored care.", "url": "https://arxiv.org/abs/2307.01389"}, {"metadata": {"arXiv": "2307.01390", "Date": "Mon, 03 Jul 2023 23:04:49 ", "Title": "Adversarial Learning in Real-World Fraud Detection: Challenges and Perspectives", "Authors": ["Danele Lunghi", "Alkis Simitsis", "Olivier Caelen", "Gianluca Bontempi"], "Categories": "cs.LG cs.CR", "DOI": "10.1145/3600046.3600051."}, "abstract": "Data economy relies on data-driven systems and complex machine learning applications are fueled by them. Unfortunately, however, machine learning models are exposed to fraudulent activities and adversarial attacks, which threaten their security and trustworthiness. In the last decade or so, the research interest on adversarial machine learning has grown significantly, revealing how learning applications could be severely impacted by effective attacks. Although early results of adversarial machine learning indicate the huge potential of the approach to specific domains such as image processing, still there is a gap in both the research literature and practice regarding how to generalize adversarial techniques in other domains and applications. Fraud detection is a critical defense mechanism for data economy, as it is for other applications as well, which poses several challenges for machine learning. In this work, we describe how attacks against fraud detection systems differ from other applications of adversarial machine learning, and propose a number of interesting directions to bridge this gap.", "url": "https://arxiv.org/abs/2307.01390"}, {"metadata": {"arXiv": "2307.01393", "Date": "Mon, 03 Jul 2023 23:10:23 ", "Title": "Spatio-Temporal Surrogates for Interaction of a Jet with High Explosives: Part I -- Analysis with a Small Sample Size", "Authors": ["Chandrika Kamath and Juliette S. Franzman and Brian H. Daub"], "Categories": "cs.LG cs.NA math.NA", "Report-no": "LLNL-TR-850152", "DOI": "10.2172/1984763"}, "abstract": "Computer simulations, especially of complex phenomena, can be expensive, requiring high-performance computing resources. Often, to understand a phenomenon, multiple simulations are run, each with a different set of simulation input parameters. These data are then used to create an interpolant, or surrogate, relating the simulation outputs to the corresponding inputs. When the inputs and outputs are scalars, a simple machine learning model can suffice. However, when the simulation outputs are vector valued, available at locations in two or three spatial dimensions, often with a temporal component, creating a surrogate is more challenging. In this report, we use a two-dimensional problem of a jet interacting with high explosives to understand how we can build high-quality surrogates. The characteristics of our data set are unique - the vector-valued outputs from each simulation are available at over two million spatial locations; each simulation is run for a relatively small number of time steps; the size of the computational domain varies with each simulation; and resource constraints limit the number of simulations we can run. We show how we analyze these extremely large data-sets, set the parameters for the algorithms used in the analysis, and use simple ways to improve the accuracy of the spatio-temporal surrogates without substantially increasing the number of simulations required.", "url": "https://arxiv.org/abs/2307.01393"}, {"metadata": {"arXiv": "2307.01400", "Date": "Mon, 03 Jul 2023 23:36:43 ", "Title": "Spatio-Temporal Surrogates for Interaction of a Jet with High Explosives: Part II -- Clustering Extremely High-Dimensional Grid-Based Data", "Authors": ["Chandrika Kamath and Juliette S. Franzman"], "Categories": "cs.LG cs.NA math.NA", "Report-no": "LLNL-TR-850159", "DOI": "10.2172/1984764"}, "abstract": "Building an accurate surrogate model for the spatio-temporal outputs of a computer simulation is a challenging task. A simple approach to improve the accuracy of the surrogate is to cluster the outputs based on similarity and build a separate surrogate model for each cluster. This clustering is relatively straightforward when the output at each time step is of moderate size. However, when the spatial domain is represented by a large number of grid points, numbering in the millions, the clustering of the data becomes more challenging. In this report, we consider output data from simulations of a jet interacting with high explosives. These data are available on spatial domains of different sizes, at grid points that vary in their spatial coordinates, and in a format that distributes the output across multiple files at each time step of the simulation. We first describe how we bring these data into a consistent format prior to clustering. Borrowing the idea of random projections from data mining, we reduce the dimension of our data by a factor of thousand, making it possible to use the iterative k-means method for clustering. We show how we can use the randomness of both the random projections, and the choice of initial centroids in k-means clustering, to determine the number of clusters in our data set. Our approach makes clustering of extremely high dimensional data tractable, generating meaningful cluster assignments for our problem, despite the approximation introduced in the random projections.", "url": "https://arxiv.org/abs/2307.01400"}, {"metadata": {"arXiv": "2307.01417", "Date": "Tue, 04 Jul 2023 00:48:30 ", "Title": "Free energy of Bayesian Convolutional Neural Network with Skip Connection", "Authors": ["Shuya Nagayasu and Sumio Watanabe"], "Categories": "cs.LG stat.ML", "Comments": ["16 pages", "4 figures"], "MSC-class": "62F15"}, "abstract": "Since the success of Residual Network(ResNet), many of architectures of Convolutional Neural Networks(CNNs) have adopted skip connection. While the generalization performance of CNN with skip connection has been explained within the framework of Ensemble Learning, the dependency on the number of parameters have not been revealed. In this paper, we show that Bayesian free energy of Convolutional Neural Network both with and without skip connection in Bayesian learning. The upper bound of free energy of Bayesian CNN with skip connection does not depend on the oveparametrization and, the generalization error of Bayesian CNN has similar property.", "url": "https://arxiv.org/abs/2307.01417"}, {"metadata": {"arXiv": "2307.01422", "Date": "Tue, 04 Jul 2023 01:28:02 ", "Title": "Generative Flow Networks: a Markov Chain Perspective", "Authors": ["Tristan Deleu", "Yoshua Bengio"], "Categories": "cs.LG"}, "abstract": "While Markov chain Monte Carlo methods (MCMC) provide a general framework to sample from a probability distribution defined up to normalization, they often suffer from slow convergence to the target distribution when the latter is highly multi-modal. Recently, Generative Flow Networks (GFlowNets) have been proposed as an alternative framework to mitigate this issue when samples have a clear compositional structure, by treating sampling as a sequential decision making problem. Although they were initially introduced from the perspective of flow networks, the recent advances of GFlowNets draw more and more inspiration from the Markov chain literature, bypassing completely the need for flows. In this paper, we formalize this connection and offer a new perspective for GFlowNets using Markov chains, showing a unifying view for GFlowNets regardless of the nature of the state space as recurrent Markov chains. Positioning GFlowNets under the same theoretical framework as MCMC methods also allows us to identify the similarities between both frameworks, and most importantly to highlight their", "url": "https://arxiv.org/abs/2307.01422"}, {"metadata": {"arXiv": "2307.01434", "Date": "Tue, 04 Jul 2023 01:56:07 ", "Title": "Learning to Branch in Combinatorial Optimization with Graph Pointer Networks", "Authors": ["Rui Wang", "Zhiming Zhou", "Tao Zhang", "Ling Wang", "Xin Xu", "Xiangke Liao", "Kaiwen Li"], "Categories": "cs.LG cs.NE math.CO"}, "abstract": "Branch-and-bound is a typical way to solve combinatorial optimization problems. This paper proposes a graph pointer network model for learning the variable selection policy in the branch-and-bound. We extract the graph features, global features and historical features to represent the solver state. The proposed model, which combines the graph neural network and the pointer mechanism, can effectively map from the solver state to the branching variable decisions. The model is trained to imitate the classic strong branching expert rule by a designed top-k Kullback-Leibler divergence loss function. Experiments on a series of benchmark problems demonstrate that the proposed approach significantly outperforms the widely used expert-designed branching rules. Our approach also outperforms the state-of-the-art machine-learning-based branch-and-bound methods in terms of solving speed and search tree size on all the test instances. In addition, the model can generalize to unseen instances and scale to larger instances.", "url": "https://arxiv.org/abs/2307.01434"}, {"metadata": {"arXiv": "2307.01482", "Date": "Tue, 04 Jul 2023 05:19:19 ", "Title": "Nexus sine qua non: Essentially connected neural networks for spatial-temporal forecasting of multivariate time series", "Authors": ["Tong Nie", "Guoyang Qin", "Yunpeng Wang", "Jian Sun"], "Categories": "cs.LG"}, "abstract": "Modeling and forecasting multivariate time series not only facilitates the decision making of practitioners, but also deepens our scientific understanding of the underlying dynamical systems. Spatial-temporal graph neural networks (STGNNs) are emerged as powerful predictors and have become the de facto models for learning spatiotemporal representations in recent years. However, existing architectures of STGNNs tend to be complicated by stacking a series of fancy layers. The designed models could be either redundant or enigmatic, which pose great challenges on their complexity and scalability. Such concerns prompt us to re-examine the designs of modern STGNNs and identify core principles that contribute to a powerful and efficient neural predictor. Here we present a compact predictive model that is fully defined by a dense encoder-decoder and a message-passing layer, powered by node identifications, without any complex sequential modules, e.g., TCNs, RNNs, and Transformers. Empirical results demonstrate how a simple and elegant model with proper inductive basis can compare favorably w.r.t. the state of the art with elaborate designs, while being much more interpretable and computationally efficient for spatial-temporal forecasting problem. We hope our findings would open new horizons for future studies to revisit the design of more concise neural forecasting architectures.", "url": "https://arxiv.org/abs/2307.01482"}, {"metadata": {"arXiv": "2307.01494", "Date": "Tue, 04 Jul 2023 06:02:04 ", "Title": "Review of Deep Learning-based Malware Detection for Android and Windows System", "Authors": ["Nazmul Islam and Seokjoo Shin"], "Categories": "cs.LG cs.CR", "Comments": ["Presented at the 33rd Joint Conference on Communications and Information (JCCI 2023)"]}, "abstract": "Differentiating malware is important to determine their behaviors and level of threat; as well as to devise defensive strategy against them. In response, various anti-malware systems have been developed to distinguish between different malwares. However, most of the recent malware families are Artificial Intelligence (AI) enable and can deceive traditional anti-malware systems using different obfuscation techniques. Therefore, only AI-enabled anti-malware system is robust against these techniques and can detect different features in the malware files that aid in malicious activities. In this study we review two AI-enabled techniques for detecting malware in Windows and Android operating system, respectively. Both the techniques achieved perfect accuracy in detecting various malware families.", "url": "https://arxiv.org/abs/2307.01494"}, {"metadata": {"arXiv": "2307.01507", "Date": "Tue, 04 Jul 2023 06:41:50 ", "Title": "Relation-aware subgraph embedding with co-contrastive learning for drug-drug interaction prediction", "Authors": ["Mengying Jiang and Guizhong Liu and Biao Zhao and Yuanchao Su and Weiqiang Jin"], "Categories": "cs.LG q-bio.BM", "Comments": ["14pages", "23figures"]}, "abstract": "Relation-aware subgraph embedding is promising for predicting multi-relational drug-drug interactions (DDIs). Typically, most existing methods begin by constructing a multi-relational DDI graph and then learning relation-aware subgraph embeddings (RaSEs) of drugs from the DDI graph. However, most existing approaches are usually limited in learning RaSEs of new drugs, leading to serious over-fitting when the test DDIs involve such drugs. To alleviate this issue, We propose a novel DDI prediction method based on relation-aware subgraph embedding with co-contrastive learning, RaSECo. RaSECo constructs two heterogeneous drug graphs: a multi-relational DDI graph and a multi-attributes-based drug-drug similarity (DDS) graph. The two graphs are used respectively for learning and propagating the RaSEs of drugs, thereby ensuring that all drugs, including new ones, can aggregate effective RaSEs. Additionally, we employ a cross-view contrastive mechanism to enhance drug-pair (DP) embedding. RaSECo learns DP embeddings from two distinct views (interaction and similarity views) and encourages these views to supervise each other collaboratively to obtain more discriminative DP embeddings. We evaluate the effectiveness of our RaSECo on three different tasks using two real datasets. The experimental results demonstrate that RaSECo outperforms existing state-of-the-art prediction methods.", "url": "https://arxiv.org/abs/2307.01507"}, {"metadata": {"arXiv": "2307.01514", "Date": "Tue, 04 Jul 2023 06:50:16 ", "Title": "SelfFed: Self-supervised Federated Learning for Data Heterogeneity and Label Scarcity in IoMT", "Authors": ["Sunder Ali Khowaja", "Kapal Dev", "Syed Muhammad Anwar", "Marius George Linguraru"], "Categories": "cs.LG cs.CV", "Comments": ["8 pages", "6 figures"]}, "abstract": "Self-supervised learning in federated learning paradigm has been gaining a lot of interest both in industry and research due to the collaborative learning capability on unlabeled yet isolated data. However, self-supervised based federated learning strategies suffer from performance degradation due to label scarcity and diverse data distributions, i.e., data heterogeneity. In this paper, we propose the SelfFed framework for Internet of Medical Things (IoMT). Our proposed SelfFed framework works in two phases. The first phase is the pre-training paradigm that performs augmentive modeling using Swin Transformer based encoder in a decentralized manner. The first phase of SelfFed framework helps to overcome the data heterogeneity issue. The second phase is the fine-tuning paradigm that introduces contrastive network and a novel aggregation strategy that is trained on limited labeled data for a target task in a decentralized manner. This fine-tuning stage overcomes the label scarcity problem. We perform our experimental analysis on publicly available medical imaging datasets and show that our proposed SelfFed framework performs better when compared to existing baselines concerning non-independent and identically distributed (IID) data and label scarcity. Our method achieves a maximum improvement of 8.8% and 4.1% on Retina and COVID-FL datasets on non-IID dataset. Further, our proposed method outperforms existing baselines even when trained on a few (10%) labeled instances.", "url": "https://arxiv.org/abs/2307.01514"}, {"metadata": {"arXiv": "2307.01583", "Date": "Tue, 04 Jul 2023 09:23:24 ", "Title": "Learning Lie Group Symmetry Transformations with Neural Networks", "Authors": ["Alex Gabel", "Victoria Klein", "Riccardo Valperga", "Jeroen S. W. Lamb", "Kevin Webster", "Rick Quax", "Efstratios Gavves"], "Categories": "cs.LG cs.CV", "Comments": ["9 pages", "5 figures", "Proceedings of the 2nd Annual Workshop on Topology", "Algebra", "and Geometry in Machine Learning (TAG-ML) at the 40th International Conference on Machine Learning", "Honolulu", "Hawaii", "USA. 2023"]}, "abstract": "The problem of detecting and quantifying the presence of symmetries in datasets is useful for model selection, generative modeling, and data analysis, amongst others. While existing methods for hard-coding transformations in neural networks require prior knowledge of the symmetries of the task at hand, this work focuses on discovering and characterizing unknown symmetries present in the dataset, namely, Lie group symmetry transformations beyond the traditional ones usually considered in the field (rotation, scaling, and translation). Specifically, we consider a scenario in which a dataset has been transformed by a one-parameter subgroup of transformations with different parameter values for each data point. Our goal is to characterize the transformation group and the distribution of the parameter values. The results showcase the effectiveness of the approach in both these settings.", "url": "https://arxiv.org/abs/2307.01583"}, {"metadata": {"arXiv": "2307.01601", "Date": "Tue, 04 Jul 2023 09:40:30 ", "Title": "Prototypes as Explanation for Time Series Anomaly Detection", "Authors": ["Bin Li", "Carsten Jentsch", "Emmanuel M\\\"uller"], "Categories": "cs.LG"}, "abstract": "Detecting abnormal patterns that deviate from a certain regular repeating pattern in time series is essential in many big data applications. However, the lack of labels, the dynamic nature of time series data, and unforeseeable abnormal behaviors make the detection process challenging. Despite the success of recent deep anomaly detection approaches, the mystical mechanisms in such black-box models have become a new challenge in safety-critical applications. The lack of model transparency and prediction reliability hinders further breakthroughs in such domains. This paper proposes ProtoAD, using prototypes as the example-based explanation for the state of regular patterns during anomaly detection. Without significant impact on the detection performance, prototypes shed light on the deep black-box models and provide intuitive understanding for domain experts and stakeholders. We extend the widely used prototype learning in classification problems into anomaly detection. By visualizing both the latent space and input space prototypes, we intuitively demonstrate how regular data are modeled and why specific patterns are considered abnormal.", "url": "https://arxiv.org/abs/2307.01601"}, {"metadata": {"arXiv": "2307.01622", "Date": "Tue, 04 Jul 2023 10:18:16 ", "Title": "Renewable energy management in smart home environment via forecast embedded scheduling based on Recurrent Trend Predictive Neural Network", "Authors": ["Mert Nak{\\i}p", "Onur \\c{C}opur", "Emrah Biyik", "C\\\"uneyt G\\\"uzeli\\c{s}"], "Categories": "cs.LG cs.SY eess.SY", "Journal-ref": "Nak{\\i}p, M., \\c{C}opur, O., Biyik, E., & G\\\"{u}zeli\\c{s}, C. (2023). Renewable energy management in smart home environment via forecast embedded scheduling based on Recurrent Trend Predictive Neural Network. Applied Energy, 340, 121014", "DOI": "10.1016/j.apenergy.2023.121014"}, "abstract": "Smart home energy management systems help the distribution grid operate more efficiently and reliably, and enable effective penetration of distributed renewable energy sources. These systems rely on robust forecasting, optimization, and control/scheduling algorithms that can handle the uncertain nature of demand and renewable generation. This paper proposes an advanced ML algorithm, called Recurrent Trend Predictive Neural Network based Forecast Embedded Scheduling (rTPNN-FES), to provide efficient residential demand control. rTPNN-FES is a novel neural network architecture that simultaneously forecasts renewable energy generation and schedules household appliances. By its embedded structure, rTPNN-FES eliminates the utilization of separate algorithms for forecasting and scheduling and generates a schedule that is robust against forecasting errors. This paper also evaluates the performance of the proposed algorithm for an IoT-enabled smart home. The evaluation results reveal that rTPNN-FES provides near-optimal scheduling $37.5$ times faster than the optimization while outperforming state-of-the-art forecasting techniques.", "url": "https://arxiv.org/abs/2307.01622"}, {"metadata": {"arXiv": "2307.01636", "Date": "Tue, 04 Jul 2023 10:40:20 ", "Title": "HAGNN: Hybrid Aggregation for Heterogeneous Graph Neural Networks", "Authors": ["Guanghui Zhu", "Zhennan Zhu", "Hongyang Chen", "Chunfeng Yuan", "Yihua Huang"], "Categories": "cs.LG"}, "abstract": "Heterogeneous graph neural networks (GNNs) have been successful in handling heterogeneous graphs. In existing heterogeneous GNNs, meta-path plays an essential role. However, recent work pointed out that simple homogeneous graph model without meta-path can also achieve comparable results, which calls into question the necessity of meta-path. In this paper, we first present the intrinsic difference about meta-path-based and meta-path-free models, i.e., how to select neighbors for node aggregation. Then, we propose a novel framework to utilize the rich type semantic information in heterogeneous graphs comprehensively, namely HAGNN (Hybrid Aggregation for Heterogeneous GNNs). The core of HAGNN is to leverage the meta-path neighbors and the directly connected neighbors simultaneously for node aggregations. HAGNN divides the overall aggregation process into two phases: meta-path-based intra-type aggregation and meta-path-free inter-type aggregation. During the intra-type aggregation phase, we propose a new data structure called fused meta-path graph and perform structural semantic aware aggregation on it. Finally, we combine the embeddings generated by each phase. Compared with existing heterogeneous GNN models, HAGNN can take full advantage of the heterogeneity in heterogeneous graphs. Extensive experimental results on node classification, node clustering, and link prediction tasks show that HAGNN outperforms the existing modes, demonstrating the effectiveness of HAGNN.", "url": "https://arxiv.org/abs/2307.01636"}, {"metadata": {"arXiv": "2307.01649", "Date": "Tue, 04 Jul 2023 11:08:03 ", "Title": "Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks", "Authors": ["Kaiqi Zhang", "Zixuan Zhang", "Minshuo Chen", "Mengdi Wang", "Tuo Zhao", "Yu-Xiang Wang"], "Categories": "cs.LG", "Comments": ["20 pages", "1 figure"]}, "abstract": "Convolutional residual neural networks (ConvResNets), though overparameterized, can achieve remarkable prediction performance in practice, which cannot be well explained by conventional wisdom. To bridge this gap, we study the performance of ConvResNeXts, which cover ConvResNets as a special case, trained with weight decay from the perspective of nonparametric classification. Our analysis allows for infinitely many building blocks in ConvResNeXts, and shows that weight decay implicitly enforces sparsity on these blocks. Specifically, we consider a smooth target function supported on a low-dimensional manifold, then prove that ConvResNeXts can adapt to the function smoothness and low-dimensional structures and efficiently learn the function without suffering from the curse of dimensionality. Our findings partially justify the advantage of overparameterized ConvResNeXts over conventional machine learning models.", "url": "https://arxiv.org/abs/2307.01649"}, {"metadata": {"arXiv": "2307.01668", "Date": "Tue, 04 Jul 2023 12:00:06 ", "Title": "Training Energy-Based Models with Diffusion Contrastive Divergences", "Authors": ["Weijian Luo and Hao Jiang and Tianyang Hu and Jiacheng Sun and Zhenguo Li and Zhihua Zhang"], "Categories": "cs.LG cs.CV stat.ML"}, "abstract": "Energy-Based Models (EBMs) have been widely used for generative modeling. Contrastive Divergence (CD), a prevailing training objective for EBMs, requires sampling from the EBM with Markov Chain Monte Carlo methods (MCMCs), which leads to an irreconcilable trade-off between the computational burden and the validity of the CD. Running MCMCs till convergence is computationally intensive. On the other hand, short-run MCMC brings in an extra non-negligible parameter gradient term that is difficult to handle. In this paper, we provide a general interpretation of CD, viewing it as a special instance of our proposed Diffusion Contrastive Divergence (DCD) family. By replacing the Langevin dynamic used in CD with other EBM-parameter-free diffusion processes, we propose a more efficient divergence. We show that the proposed DCDs are both more computationally efficient than the CD and are not limited to a non-negligible gradient term. We conduct intensive experiments, including both synthesis data modeling and high-dimensional image denoising and generation, to show the advantages of the proposed DCDs. On the synthetic data learning and image denoising experiments, our proposed DCD outperforms CD by a large margin. In image generation experiments, the proposed DCD is capable of training an energy-based model for generating the Celab-A $32\\times 32$ dataset, which is comparable to existing EBMs.", "url": "https://arxiv.org/abs/2307.01668"}, {"metadata": {"arXiv": "2307.01725", "Date": "Tue, 04 Jul 2023 13:53:01 ", "Title": "RRCNN: A novel signal decomposition approach based on recurrent residue convolutional neural network", "Authors": ["Feng Zhou", "Antonio Cicone", "Haomin Zhou"], "Categories": "cs.LG eess.SP", "Comments": ["29 pages with 9 figures"], "MSC-class": "68T10", "ACM-class": "I.5.1"}, "abstract": "The decomposition of non-stationary signals is an important and challenging task in the field of signal time-frequency analysis. In the recent two decades, many signal decomposition methods led by the empirical mode decomposition, which was pioneered by Huang et al. in 1998, have been proposed by different research groups. However, they still have some limitations. For example, they are generally prone to boundary and mode mixing effects and are not very robust to noise. Inspired by the successful applications of deep learning in fields like image processing and natural language processing, and given the lack in the literature of works in which deep learning techniques are used directly to decompose non-stationary signals into simple oscillatory components, we use the convolutional neural network, residual structure and nonlinear activation function to compute in an innovative way the local average of the signal, and study a new non-stationary signal decomposition method under the framework of deep learning. We discuss the training process of the proposed model and study the convergence analysis of the learning algorithm. In the experiments, we evaluate the performance of the proposed model from two points of view: the calculation of the local average and the signal decomposition. Furthermore, we study the mode mixing, noise interference, and orthogonality properties of the decomposed components produced by the proposed method. All results show that the proposed model allows for better handling boundary effect, mode mixing effect, robustness, and the orthogonality of the decomposed components than existing methods.", "url": "https://arxiv.org/abs/2307.01725"}, {"metadata": {"arXiv": "2307.01767", "Date": "Tue, 04 Jul 2023 15:14:59 ", "Title": "Localized Data Work as a Precondition for Data-Centric ML: A Case Study of Full Lifecycle Crop Disease Identification in Ghana", "Authors": ["Darlington Akogo", "Issah Samori", "Cyril Akafia", "Harriet Fiagbor", "Andrews Kangah", "Donald Kwame Asiedu", "Kwabena Fuachie", "Luis Oala"], "Categories": "cs.LG cs.CV"}, "abstract": "The Ghana Cashew Disease Identification with Artificial Intelligence (CADI AI) project demonstrates the importance of sound data work as a precondition for the delivery of useful, localized datacentric solutions for public good tasks such as agricultural productivity and food security. Drone collected data and machine learning are utilized to determine crop stressors. Data, model and the final app are developed jointly and made available to local farmers via a desktop application.", "url": "https://arxiv.org/abs/2307.01767"}, {"metadata": {"arXiv": "2307.01777", "Date": "Tue, 04 Jul 2023 15:30:09 ", "Title": "Shapley Sets: Feature Attribution via Recursive Function Decomposition", "Authors": ["Torty Sivill and Peter Flach"], "Categories": "cs.LG"}, "abstract": "Despite their ubiquitous use, Shapley value feature attributions can be misleading due to feature interaction in both model and data. We propose an alternative attribution approach, Shapley Sets, which awards value to sets of features. Shapley Sets decomposes the underlying model into non-separable variable groups using a recursive function decomposition algorithm with log linear complexity in the number of variables. Shapley Sets attributes to each non-separable variable group their combined value for a particular prediction. We show that Shapley Sets is equivalent to the Shapley value over the transformed feature set and thus benefits from the same axioms of fairness. Shapley Sets is value function agnostic and we show theoretically and experimentally how Shapley Sets avoids pitfalls associated with Shapley value based alternatives and are particularly advantageous for data types with complex dependency structure.", "url": "https://arxiv.org/abs/2307.01777"}, {"metadata": {"arXiv": "2307.01780", "Date": "Tue, 04 Jul 2023 15:34:13 ", "Title": "FedHIL: Heterogeneity Resilient Federated Learning for Robust Indoor Localization with Mobile Devices", "Authors": ["Danish Gufran", "Sudeep Pasricha"], "Categories": "cs.LG cs.MA eess.SP"}, "abstract": "Indoor localization plays a vital role in applications such as emergency response, warehouse management, and augmented reality experiences. By deploying machine learning (ML) based indoor localization frameworks on their mobile devices, users can localize themselves in a variety of indoor and subterranean environments. However, achieving accurate indoor localization can be challenging due to heterogeneity in the hardware and software stacks of mobile devices, which can result in inconsistent and inaccurate location estimates. Traditional ML models also heavily rely on initial training data, making them vulnerable to degradation in performance with dynamic changes across indoor environments. To address the challenges due to device heterogeneity and lack of adaptivity, we propose a novel embedded ML framework called FedHIL. Our framework combines indoor localization and federated learning (FL) to improve indoor localization accuracy in device-heterogeneous environments while also preserving user data privacy. FedHIL integrates a domain-specific selective weight adjustment approach to preserve the ML model's performance for indoor localization during FL, even in the presence of extremely noisy data. Experimental evaluations in diverse real-world indoor environments and with heterogeneous mobile devices show that FedHIL outperforms state-of-the-art FL and non-FL indoor localization frameworks. FedHIL is able to achieve 1.62x better localization accuracy on average than the best performing FL-based indoor localization framework from prior work.", "url": "https://arxiv.org/abs/2307.01780"}, {"metadata": {"arXiv": "2307.01804", "Date": "Tue, 04 Jul 2023 16:17:59 ", "Title": "Capturing Local Temperature Evolution during Additive Manufacturing through Fourier Neural Operators", "Authors": ["Jiangce Chen", "Wenzhuo Xu", "Martha Baldwin", "Bj\\\"orn Nijhuis", "Ton van den Boogaard", "Noelia Grande Guti\\'errez", "Sneha Prabha Narra", "Christopher McComb"], "Categories": "cs.LG cs.CG"}, "abstract": "High-fidelity, data-driven models that can quickly simulate thermal behavior during additive manufacturing (AM) are crucial for improving the performance of AM technologies in multiple areas, such as part design, process planning, monitoring, and control. However, the complexities of part geometries make it challenging for current models to maintain high accuracy across a wide range of geometries. Additionally, many models report a low mean square error (MSE) across the entire domain (part). However, in each time step, most areas of the domain do not experience significant changes in temperature, except for the heat-affected zones near recent depositions. Therefore, the MSE-based fidelity measurement of the models may be overestimated. This paper presents a data-driven model that uses Fourier Neural Operator to capture the local temperature evolution during the additive manufacturing process. In addition, the authors propose to evaluate the model using the $R^2$ metric, which provides a relative measure of the model's performance compared to using mean temperature as a prediction. The model was tested on numerical simulations based on the Discontinuous Galerkin Finite Element Method for the Direct Energy Deposition process, and the results demonstrate that the model achieves high fidelity as measured by $R^2$ and maintains generalizability to geometries that were not included in the training process.", "url": "https://arxiv.org/abs/2307.01804"}, {"metadata": {"arXiv": "2307.01827", "Date": "Tue, 04 Jul 2023 17:09:49 ", "Title": "Deconstructing Data Reconstruction: Multiclass, Weight Decay and General Losses", "Authors": ["Gon Buzaglo", "Niv Haim", "Gilad Yehudai", "Gal Vardi", "Yakir Oz", "Yaniv Nikankin and Michal Irani"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2305.03350"]}, "abstract": "Memorization of training data is an active research area, yet our understanding of the inner workings of neural networks is still in its infancy. Recently, Haim et al. (2022) proposed a scheme to reconstruct training samples from multilayer perceptron binary classifiers, effectively demonstrating that a large portion of training samples are encoded in the parameters of such networks. In this work, we extend their findings in several directions, including reconstruction from multiclass and convolutional neural networks. We derive a more general reconstruction scheme which is applicable to a wider range of loss functions such as regression losses. Moreover, we study the various factors that contribute to networks' susceptibility to such reconstruction schemes. Intriguingly, we observe that using weight decay during training increases reconstructability both in terms of quantity and quality. Additionally, we examine the influence of the number of neurons relative to the number of training samples on the reconstructability.", "url": "https://arxiv.org/abs/2307.01827"}, {"metadata": {"arXiv": "2307.01872", "Date": "Tue, 04 Jul 2023 18:32:41 ", "Title": "A hybrid machine learning framework for clad characteristics prediction in metal additive manufacturing", "Authors": ["Sina Tayebati", "Kyu Taek Cho"], "Categories": "cs.LG cs.CE", "Comments": ["35 pages", "10 figures"]}, "abstract": "During the past decade, metal additive manufacturing (MAM) has experienced significant developments and gained much attention due to its ability to fabricate complex parts, manufacture products with functionally graded materials, minimize waste, and enable low-cost customization. Despite these advantages, predicting the impact of processing parameters on the characteristics of an MAM printed clad is challenging due to the complex nature of MAM processes. Machine learning (ML) techniques can help connect the physics underlying the process and processing parameters to the clad characteristics. In this study, we introduce a hybrid approach which involves utilizing the data provided by a calibrated multi-physics computational fluid dynamic (CFD) model and experimental research for preparing the essential big dataset, and then uses a comprehensive framework consisting of various ML models to predict and understand clad characteristics. We first compile an extensive dataset by fusing experimental data into the data generated using the developed CFD model for this study. This dataset comprises critical clad characteristics, including geometrical features such as width, height, and depth, labels identifying clad quality, and processing parameters. Second, we use two sets of processing parameters for training the ML models: machine setting parameters and physics-aware parameters, along with versatile ML models and reliable evaluation metrics to create a comprehensive and scalable learning framework for predicting clad geometry and quality. This framework can serve as a basis for clad characteristics control and process optimization. The framework resolves many challenges of conventional modeling methods in MAM by solving t the issue of data scarcity using a hybrid approach and introducing an efficient, accurate, and scalable platform for clad characteristics prediction and optimization.", "url": "https://arxiv.org/abs/2307.01872"}, {"metadata": {"arXiv": "2307.01875", "Date": "Tue, 04 Jul 2023 18:37:11 ", "Title": "Approximate, Adapt, Anonymize (3A): a Framework for Privacy Preserving Training Data Release for Machine Learning", "Authors": ["Tamas Madl", "Weijie Xu", "Olivia Choudhury", "Matthew Howard"], "Categories": "cs.LG cs.CR", "Comments": ["10 pages", "3 figures", "AAAI Workshop"], "MSC-class": "62-08", "ACM-class": "G.4", "Journal-ref": "AAAI 2023 Workshop on Privacy-Preserving Artificial Intelligence"}, "abstract": "The availability of large amounts of informative data is crucial for successful machine learning. However, in domains with sensitive information, the release of high-utility data which protects the privacy of individuals has proven challenging. Despite progress in differential privacy and generative modeling for privacy-preserving data release in the literature, only a few approaches optimize for machine learning utility: most approaches only take into account statistical metrics on the data itself and fail to explicitly preserve the loss metrics of machine learning models that are to be subsequently trained on the generated data. In this paper, we introduce a data release framework, 3A (Approximate, Adapt, Anonymize), to maximize data utility for machine learning, while preserving differential privacy. We also describe a specific implementation of this framework that leverages mixture models to approximate, kernel-inducing points to adapt, and Gaussian differential privacy to anonymize a dataset, in order to ensure that the resulting data is both privacy-preserving and high utility. We present experimental evidence showing minimal discrepancy between performance metrics of models trained on real versus privatized datasets, when evaluated on held-out real data. We also compare our results with several privacy-preserving synthetic data generation models (such as differentially private generative adversarial networks), and report significant increases in classification performance metrics compared to state-of-the-art models. These favorable comparisons show that the presented framework is a promising direction of research, increasing the utility of low-risk synthetic data release for machine learning.", "url": "https://arxiv.org/abs/2307.01875"}, {"metadata": {"arXiv": "2307.01879", "Date": "Tue, 04 Jul 2023 18:49:34 ", "Title": "Stability Analysis Framework for Particle-based Distance GANs with Wasserstein Gradient Flow", "Authors": ["Chuqi Chen", "Wu Yue", "Yang Xiang"], "Categories": "cs.LG"}, "abstract": "In this paper, we investigate the training process of generative networks that use a type of probability density distance named particle-based distance as the objective function, e.g. MMD GAN, Cram\\'er GAN, EIEG GAN. However, these GANs often suffer from the problem of unstable training. In this paper, we analyze the stability of the training process of these GANs from the perspective of probability density dynamics. In our framework, we regard the discriminator $D$ in these GANs as a feature transformation mapping that maps high dimensional data into a feature space, while the generator $G$ maps random variables to samples that resemble real data in terms of feature space. This perspective enables us to perform stability analysis for the training of GANs using the Wasserstein gradient flow of the probability density function. We find that the training process of the discriminator is usually unstable due to the formulation of $\\min_G \\max_D E(G, D)$ in GANs. To address this issue, we add a stabilizing term in the discriminator loss function. We conduct experiments to validate our stability analysis and stabilizing method.", "url": "https://arxiv.org/abs/2307.01879"}, {"metadata": {"arXiv": "2307.01944", "Date": "Tue, 04 Jul 2023 22:26:20 ", "Title": "Text + Sketch: Image Compression at Ultra Low Rates", "Authors": ["Eric Lei", "Yi\\u{g}it Berkay Uslu", "Hamed Hassani", "Shirin Saeedi Bidokhti"], "Categories": "cs.LG cs.CV cs.IT math.IT", "Comments": ["ICML 2023 Neural Compression Workshop"]}, "abstract": "Recent advances in text-to-image generative models provide the ability to generate high-quality images from short text descriptions. These foundation models, when pre-trained on billion-scale datasets, are effective for various downstream tasks with little or no further training. A natural question to ask is how such models may be adapted for image compression. We investigate several techniques in which the pre-trained models can be directly used to implement compression schemes targeting novel low rate regimes. We show how text descriptions can be used in conjunction with side information to generate high-fidelity reconstructions that preserve both semantics and spatial structure of the original. We demonstrate that at very low bit-rates, our method can significantly improve upon learned compressors in terms of perceptual and semantic fidelity, despite no end-to-end training.", "url": "https://arxiv.org/abs/2307.01944"}, {"metadata": {"arXiv": "2307.01995", "Date": "Wed, 05 Jul 2023 02:56:29 ", "Title": "Dynamic Feature-based Deep Reinforcement Learning for Flow Control of Circular Cylinder with Sparse Surface Pressure Sensing", "Authors": ["Qiulei Wang", "Lei Yan", "Gang Hu", "Wenli Chen", "Jean Rabault", "Bernd R. Noack"], "Categories": "cs.LG physics.flu-dyn"}, "abstract": "This study proposes a self-learning algorithm for closed-loop cylinder wake control targeting lower drag and lower lift fluctuations with the additional challenge of sparse sensor information, taking deep reinforcement learning as the starting point. DRL performance is significantly improved by lifting the sensor signals to dynamic features (DF), which predict future flow states. The resulting dynamic feature-based DRL (DF-DRL) automatically learns a feedback control in the plant without a dynamic model. Results show that the drag coefficient of the DF-DRL model is 25% less than the vanilla model based on direct sensor feedback. More importantly, using only one surface pressure sensor, DF-DRL can reduce the drag coefficient to a state-of-the-art performance of about 8% at Re = 100 and significantly mitigate lift coefficient fluctuations. Hence, DF-DRL allows the deployment of sparse sensing of the flow without degrading the control performance. This method also shows good robustness in controlling flow under higher Reynolds numbers, which reduces the drag coefficient by 32.2% and 46.55% at Re = 500 and 1000, respectively, indicating the broad applicability of the method. Since surface pressure information is more straightforward to measure in realistic scenarios than flow velocity information, this study provides a valuable reference for experimentally designing the active flow control of a circular cylinder based on wall pressure signals, which is an essential step toward further developing intelligent control in realistic multi-input multi-output (MIMO) system.", "url": "https://arxiv.org/abs/2307.01995"}, {"metadata": {"arXiv": "2307.01998", "Date": "Wed, 05 Jul 2023 03:07:00 ", "Title": "Zero-Shot Neural Architecture Search: Challenges, Solutions, and Opportunities", "Authors": ["Guihong Li", "Duc Hoang", "Kartikeya Bhardwaj", "Ming Lin", "Zhangyang Wang", "Radu Marculescu"], "Categories": "cs.LG cs.CV"}, "abstract": "Recently, zero-shot (or training-free) Neural Architecture Search (NAS) approaches have been proposed to liberate the NAS from training requirements. The key idea behind zero-shot NAS approaches is to design proxies that predict the accuracies of the given networks without training network parameters. The proxies proposed so far are usually inspired by recent progress in theoretical deep learning and have shown great potential on several NAS benchmark datasets. This paper aims to comprehensively review and compare the state-of-the-art (SOTA) zero-shot NAS approaches, with an emphasis on their hardware awareness. To this end, we first review the mainstream zero-shot proxies and discuss their theoretical underpinnings. We then compare these zero-shot proxies through large-scale experiments and demonstrate their effectiveness in both hardware-aware and hardware-oblivious NAS scenarios. Finally, we point out several promising ideas to design better proxies. Our source code and the related paper list are available on https://github.com/SLDGroup/survey-zero-shot-nas.", "url": "https://arxiv.org/abs/2307.01998"}, {"metadata": {"arXiv": "2307.02031", "Date": "Wed, 05 Jul 2023 05:28:38 ", "Title": "Improving Automatic Parallel Training via Balanced Memory Workload Optimization", "Authors": ["Yujie Wang", "Youhe Jiang", "Xupeng Miao", "Fangcheng Fu", "Xiaonan Nie", "Bin Cui"], "Categories": "cs.LG cs.DB cs.DC", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2211.13878"]}, "abstract": "Transformer models have emerged as the leading approach for achieving state-of-the-art performance across various application domains, serving as the foundation for advanced large-scale deep learning (DL) models. However, efficiently training these models across multiple GPUs remains a complex challenge due to the abundance of parallelism options. Existing DL systems either require manual efforts to design distributed training plans or limit parallelism combinations to a constrained search space. In this paper, we present Galvatron-BMW, a novel system framework that integrates multiple prevalent parallelism dimensions and automatically identifies the most efficient hybrid parallelism strategy. To effectively navigate this vast search space, we employ a decision tree approach for decomposition and pruning based on intuitive insights. We further utilize a dynamic programming search algorithm to derive the optimal plan. Moreover, to improve resource utilization and enhance system efficiency, we propose a bi-objective optimization workflow that focuses on workload balance. Our evaluations on different Transformer models demonstrate the capabilities of Galvatron-BMW in automating distributed training under varying GPU memory constraints. Across all tested scenarios, Galvatron-BMW consistently achieves superior system throughput, surpassing previous approaches that rely on limited parallelism strategies.", "url": "https://arxiv.org/abs/2307.02031"}, {"metadata": {"arXiv": "2307.02035", "Date": "Wed, 05 Jul 2023 05:37:13 ", "Title": "Ranking with Abstention", "Authors": ["Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "Categories": "cs.LG stat.ML"}, "abstract": "We introduce a novel framework of ranking with abstention, where the learner can abstain from making prediction at some limited cost $c$. We present a extensive theoretical analysis of this framework including a series of $H$-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer. These theoretical guarantees are the state-of-the-art consistency guarantees in the literature, which are upper bounds on the target loss estimation error of a predictor in a hypothesis set $H$, expressed in terms of the surrogate loss estimation error of that predictor. We further argue that our proposed abstention methods are important when using common equicontinuous hypothesis sets in practice. We report the results of experiments illustrating the effectiveness of ranking with abstention.", "url": "https://arxiv.org/abs/2307.02035"}, {"metadata": {"arXiv": "2307.02064", "Date": "Wed, 05 Jul 2023 07:00:31 ", "Title": "Facing off World Model Backbones: RNNs, Transformers, and S4", "Authors": ["Fei Deng", "Junyeong Park", "Sungjin Ahn"], "Categories": "cs.LG", "Comments": ["Project page: https://fdeng18.github.io/s4wm"]}, "abstract": "World models are a fundamental component in model-based reinforcement learning (MBRL) agents. To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory. However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity. In this paper, we seek to explore alternative world model backbones for improving long-term memory. In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths. We propose S4WM, the first S4-based world model that can generate high-dimensional image sequences through latent imagination. Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have specifically tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning. Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination. These results pave the way for the development of stronger MBRL agents.", "url": "https://arxiv.org/abs/2307.02064"}, {"metadata": {"arXiv": "2307.02066", "Date": "Wed, 05 Jul 2023 07:12:58 ", "Title": "Universal Rates for Multiclass Learning", "Authors": ["Steve Hanneke", "Shay Moran", "Qian Zhang"], "Categories": "cs.LG stat.ML", "Comments": ["67 pages", "accepted to the 36th Annual Conference on Learning Theory (COLT 2023)"]}, "abstract": "We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes. This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels. In contrast, our result applies for any countable label space. Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels. Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates. DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of possible classifications of a given set of points. Pseudo-cubes are a structure, rooted in the work of Daniely and Shalev-Shwartz (2014), and recently shown by Brukhim, Carmon, Dinur, Moran, and Yehudayoff (2022) to characterize PAC learnability (i.e., uniform rates) for multiclass classification. We also resolve an open question of Kalavasis, Velegkas, and Karbasi (2022) regarding the equivalence of classes having infinite Graph-Littlestone (GL) trees versus infinite Natarajan-Littlestone (NL) trees, showing that they are indeed equivalent.", "url": "https://arxiv.org/abs/2307.02066"}, {"metadata": {"arXiv": "2307.02092", "Date": "Wed, 05 Jul 2023 08:10:17 ", "Title": "Make A Long Image Short: Adaptive Token Length for Vision Transformers", "Authors": ["Qiqi Zhou and Yichen Zhu"], "Categories": "cs.LG cs.CV", "Comments": ["accepted to ECML PKDD. arXiv admin note: substantial text overlap with arXiv:2112.01686"]}, "abstract": "The vision transformer is a model that breaks down each image into a sequence of tokens with a fixed length and processes them similarly to words in natural language processing. Although increasing the number of tokens typically results in better performance, it also leads to a considerable increase in computational cost. Motivated by the saying \"A picture is worth a thousand words,\" we propose an innovative approach to accelerate the ViT model by shortening long images. Specifically, we introduce a method for adaptively assigning token length for each image at test time to accelerate inference speed. First, we train a Resizable-ViT (ReViT) model capable of processing input with diverse token lengths. Next, we extract token-length labels from ReViT that indicate the minimum number of tokens required to achieve accurate predictions. We then use these labels to train a lightweight Token-Length Assigner (TLA) that allocates the optimal token length for each image during inference. The TLA enables ReViT to process images with the minimum sufficient number of tokens, reducing token numbers in the ViT model and improving inference speed. Our approach is general and compatible with modern vision transformer architectures, significantly reducing computational costs. We verified the effectiveness of our methods on multiple representative ViT models on image classification and action recognition.", "url": "https://arxiv.org/abs/2307.02092"}, {"metadata": {"arXiv": "2307.02108", "Date": "Wed, 05 Jul 2023 08:34:54 ", "Title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization", "Authors": ["Sanath Kumar Krishnamurthy", "Ruohan Zhan", "Susan Athey", "Emma Brunskill"], "Categories": "cs.LG stat.ML"}, "abstract": "Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on \"conformal arm sets\" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-dependent simple regret guarantees while simultaneously achieving minimax optimal cumulative regret guarantees.", "url": "https://arxiv.org/abs/2307.02108"}, {"metadata": {"arXiv": "2307.02126", "Date": "Wed, 05 Jul 2023 09:05:14 ", "Title": "Robust Graph Structure Learning with the Alignment of Features and Adjacency Matrix", "Authors": ["Shaogao Lv", "Gang Wen", "Shiyu Liu", "Linsen Wei and Ming Li"], "Categories": "cs.LG stat.ML"}, "abstract": "To improve the robustness of graph neural networks (GNN), graph structure learning (GSL) has attracted great interest due to the pervasiveness of noise in graph data. Many approaches have been proposed for GSL to jointly learn a clean graph structure and corresponding representations. To extend the previous work, this paper proposes a novel regularized GSL approach, particularly with an alignment of feature information and graph information, which is motivated mainly by our derived lower bound of node-level Rademacher complexity for GNNs. Additionally, our proposed approach incorporates sparse dimensional reduction to leverage low-dimensional node features that are relevant to the graph structure. To evaluate the effectiveness of our approach, we conduct experiments on real-world graphs. The results demonstrate that our proposed GSL method outperforms several competitive baselines, especially in scenarios where the graph structures are heavily affected by noise. Overall, our research highlights the importance of integrating feature and graph information alignment in GSL, as inspired by our derived theoretical result, and showcases the superiority of our approach in handling noisy graph structures through comprehensive experiments on real-world datasets.", "url": "https://arxiv.org/abs/2307.02126"}, {"metadata": {"arXiv": "2307.02129", "Date": "Wed, 05 Jul 2023 09:11:09 ", "Title": "How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model", "Authors": ["Leonardo Petrini", "Francesco Cagnetta", "Umberto M. Tomasini", "Alessandro Favero", "Matthieu Wyart"], "Categories": "cs.LG cs.CV stat.ML"}, "abstract": "Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only polynomial in the input dimensionality; (ii) coincides with the training set size such that the representation of a trained network becomes invariant to exchanges of synonyms; (iii) corresponds to the number of data at which the correlations between low-level features and classes become detectable. Overall, our results indicate how deep CNNs can overcome the curse of dimensionality by building invariant representations, and provide an estimate of the number of data required to learn a task based on its hierarchically compositional structure.", "url": "https://arxiv.org/abs/2307.02129"}, {"metadata": {"arXiv": "2307.02130", "Date": "Wed, 05 Jul 2023 09:11:23 ", "Title": "Implicit Differentiation for Hyperparameter Tuning the Weighted Graphical Lasso", "Authors": ["Can Pouliquen", "Paulo Gon\\c{c}alves", "Mathurin Massias", "Titouan Vayer"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "We provide a framework and algorithm for tuning the hyperparameters of the Graphical Lasso via a bilevel optimization problem solved with a first-order method. In particular, we derive the Jacobian of the Graphical Lasso solution with respect to its regularization hyperparameters.", "url": "https://arxiv.org/abs/2307.02130"}, {"metadata": {"arXiv": "2307.02150", "Date": "Wed, 05 Jul 2023 09:46:41 ", "Title": "Harmonizing Feature Attributions Across Deep Learning Architectures: Enhancing Interpretability and Consistency", "Authors": ["Md Abdul Kadir", "Gowtham Krishna Addluri", "Daniel Sonntag"], "Categories": "cs.LG cs.CV", "Comments": ["This version of the contribution has been accepted for publication", "after peer review (when applicable) but is not the Version of Record and does not reflect post-acceptance improvements", "or any corrections"]}, "abstract": "Ensuring the trustworthiness and interpretability of machine learning models is critical to their deployment in real-world applications. Feature attribution methods have gained significant attention, which provide local explanations of model predictions by attributing importance to individual input features. This study examines the generalization of feature attributions across various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers. We aim to assess the feasibility of utilizing a feature attribution method as a future detector and examine how these features can be harmonized across multiple models employing distinct architectures but trained on the same data distribution. By exploring this harmonization, we aim to develop a more coherent and optimistic understanding of feature attributions, enhancing the consistency of local explanations across diverse deep-learning models. Our findings highlight the potential for harmonized feature attribution methods to improve interpretability and foster trust in machine learning applications, regardless of the underlying architecture.", "url": "https://arxiv.org/abs/2307.02150"}, {"metadata": {"arXiv": "2307.02191", "Date": "Wed, 05 Jul 2023 10:33:45 ", "Title": "Evaluating AI systems under uncertain ground truth: a case study in dermatology", "Authors": ["David Stutz", "Ali Taylan Cemgil", "Abhijit Guha Roy", "Tatiana Matejovicova", "Melih Barsbey", "Patricia Strachan", "Mike Schaekermann", "Jan Freyberg", "Rajeev Rikhye", "Beverly Freeman", "Javier Perez Matos", "Umesh Telang", "Dale R. Webster", "Yuan Liu", "Greg S. Corrado", "Yossi Matias", "Pushmeet Kohli", "Yun Liu", "Arnaud Doucet", "Alan Karthikesalingam"], "Categories": "cs.LG cs.CV stat.ME stat.ML"}, "abstract": "For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain. However, this is actually not the case and the ground truth may be uncertain. Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance. To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information. This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging. In contrast, we propose a framework where aggregation is done using a statistical model. Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities, representing distributions over classes in a classification setting, subject to a hyper-parameter encoding annotator reliability. Based on this model, we propose a metric for measuring annotation uncertainty and provide uncertainty-adjusted metrics for performance evaluation. We present a case study applying our framework to skin condition classification from images where annotations are provided in the form of differential diagnoses. The deterministic adjudication process called inverse rank normalization (IRN) from previous work ignores ground truth uncertainty in evaluation. Instead, we present two alternative statistical models: a probabilistic version of IRN and a Plackett-Luce-based model. We find that a large portion of the dataset exhibits significant ground truth uncertainty and standard IRN-based evaluation severely over-estimates performance without providing uncertainty estimates.", "url": "https://arxiv.org/abs/2307.02191"}, {"metadata": {"arXiv": "2307.02198", "Date": "Wed, 05 Jul 2023 10:50:40 ", "Title": "ChiENN: Embracing Molecular Chirality with Graph Neural Networks", "Authors": ["Piotr Gai\\'nski (1)", "Micha{\\l} Koziarski (2 and 3)", "Jacek Tabor (1)", "Marek \\'Smieja (1) ((1) Jagiellonian University", "(2) Mila - Quebec AI Institute", "(3) Universit\\'e de Montr\\'eal)"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Graph Neural Networks (GNNs) play a fundamental role in many deep learning problems, in particular in cheminformatics. However, typical GNNs cannot capture the concept of chirality, which means they do not distinguish between the 3D graph of a chemical compound and its mirror image (enantiomer). The ability to distinguish between enantiomers is important especially in drug discovery because enantiomers can have very distinct biochemical properties. In this paper, we propose a theoretically justified message-passing scheme, which makes GNNs sensitive to the order of node neighbors. We apply that general concept in the context of molecular chirality to construct Chiral Edge Neural Network (ChiENN) layer which can be appended to any GNN model to enable chirality-awareness. Our experiments show that adding ChiENN layers to a GNN outperforms current state-of-the-art methods in chiral-sensitive molecular property prediction tasks.", "url": "https://arxiv.org/abs/2307.02198"}, {"metadata": {"arXiv": "2307.02222", "Date": "Wed, 05 Jul 2023 11:58:58 ", "Title": "Personalized Federated Learning via Amortized Bayesian Meta-Learning", "Authors": ["Shiyu Liu", "Shaogao Lv", "Dun Zeng", "Zenglin Xu", "Hui Wang and Yue Yu"], "Categories": "cs.LG"}, "abstract": "Federated learning is a decentralized and privacy-preserving technique that enables multiple clients to collaborate with a server to learn a global model without exposing their private data. However, the presence of statistical heterogeneity among clients poses a challenge, as the global model may struggle to perform well on each client's specific task. To address this issue, we introduce a new perspective on personalized federated learning through Amortized Bayesian Meta-Learning. Specifically, we propose a novel algorithm called \\emph{FedABML}, which employs hierarchical variational inference across clients. The global prior aims to capture representations of common intrinsic structures from heterogeneous clients, which can then be transferred to their respective tasks and aid in the generation of accurate client-specific approximate posteriors through a few local updates. Our theoretical analysis provides an upper bound on the average generalization error and guarantees the generalization performance on unseen data. Finally, several empirical results are implemented to demonstrate that \\emph{FedABML} outperforms several competitive baselines.", "url": "https://arxiv.org/abs/2307.02222"}, {"metadata": {"arXiv": "2307.02229", "Date": "Wed, 05 Jul 2023 12:13:56 ", "Title": "Knowledge-Guided Additive Modeling For Supervised Regression", "Authors": ["Yann Claes", "V\\^an Anh Huynh-Thu", "Pierre Geurts"], "Categories": "cs.LG"}, "abstract": "Learning processes by exploiting restricted domain knowledge is an important task across a plethora of scientific areas, with more and more hybrid methods combining data-driven and model-based approaches. However, while such hybrid methods have been tested in various scientific applications, they have been mostly tested on dynamical systems, with only limited study about the influence of each model component on global performance and parameter identification. In this work, we assess the performance of hybrid modeling against traditional machine learning methods on standard regression problems. We compare, on both synthetic and real regression problems, several approaches for training such hybrid models. We focus on hybrid methods that additively combine a parametric physical term with a machine learning term and investigate model-agnostic training procedures. We also introduce a new hybrid approach based on partial dependence functions. Experiments are carried out with different types of machine learning models, including tree-based models and artificial neural networks.", "url": "https://arxiv.org/abs/2307.02229"}, {"metadata": {"arXiv": "2307.02245", "Date": "Wed, 05 Jul 2023 12:39:58 ", "Title": "Set Learning for Accurate and Calibrated Models", "Authors": ["Lukas Muttenthaler and Robert A. Vandermeulen and Qiuyi (Richard) Zhang and Thomas Unterthiner and Klaus-Robert M\\\"uller"], "Categories": "cs.LG cs.CV cs.IT math.IT"}, "abstract": "Model overconfidence and poor calibration are common in machine learning and difficult to account for when applying standard empirical risk minimization. In this work, we propose a novel method to alleviate these problems that we call odd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets rather than for single examples. This naturally allows the model to capture correlations across data examples and achieves both better accuracy and calibration, especially in limited training data and class-imbalanced regimes. Perhaps surprisingly, OKO often yields better calibration even when training with hard labels and dropping any additional calibration parameter tuning, such as temperature scaling. We provide theoretical justification, establishing that OKO naturally yields better calibration, and provide extensive experimental analyses that corroborate our theoretical findings. We emphasize that OKO is a general framework that can be easily adapted to many settings and the trained model can be applied to single examples at inference time, without introducing significant run-time overhead or architecture changes.", "url": "https://arxiv.org/abs/2307.02245"}, {"metadata": {"arXiv": "2307.02251", "Date": "Wed, 05 Jul 2023 12:49:02 ", "Title": "RanPAC: Random Projections and Pre-trained Models for Continual Learning", "Authors": ["Mark D. McDonnell", "Dong Gong", "Amin Parveneh", "Ehsan Abbasnejad", "Anton van den Hengel"], "Categories": "cs.LG cs.CV", "Comments": ["30 pages", "11 figures"]}, "abstract": "Continual learning (CL) aims to incrementally learn different tasks (such as classification) in a non-stationary data stream without forgetting old ones. Most CL works focus on tackling catastrophic forgetting under a learning-from-scratch paradigm. However, with the increasing prominence of foundation models, pre-trained models equipped with informative representations have become available for various downstream requirements. Several CL methods based on pre-trained models have been explored, either utilizing pre-extracted features directly (which makes bridging distribution gaps challenging) or incorporating adaptors (which may be subject to forgetting). In this paper, we propose a concise and effective approach for CL with pre-trained models. Given that forgetting occurs during parameter updating, we contemplate an alternative approach that exploits training-free random projectors and class-prototype accumulation, which thus bypasses the issue. Specifically, we inject a frozen Random Projection layer with nonlinear activation between the pre-trained model's feature representations and output head, which captures interactions between features with expanded dimensionality, providing enhanced linear separability for class-prototype-based CL. We also demonstrate the importance of decorrelating the class-prototypes to reduce the distribution disparity when using pre-trained representations. These techniques prove to be effective and circumvent the problem of forgetting for both class- and domain-incremental continual learning. Compared to previous methods applied to pre-trained ViT-B/16 models, we reduce final error rates by between 10\\% and 62\\% on seven class-incremental benchmark datasets, despite not using any rehearsal memory. We conclude that the full potential of pre-trained models for simple, effective, and fast continual learning has not hitherto been fully tapped.", "url": "https://arxiv.org/abs/2307.02251"}, {"metadata": {"arXiv": "2307.02253", "Date": "Wed, 05 Jul 2023 12:50:48 ", "Title": "Multivariate Time Series Classification: A Deep Learning Approach", "Authors": ["Mohamed Abouelnaga", "Julien Vitay", "Aida Farahani"], "Categories": "cs.LG"}, "abstract": "This paper investigates different methods and various neural network architectures applicable in the time series classification domain. The data is obtained from a fleet of gas sensors that measure and track quantities such as oxygen and sound. With the help of this data, we can detect events such as occupancy in a specific environment. At first, we analyze the time series data to understand the effect of different parameters, such as the sequence length, when training our models. These models employ Fully Convolutional Networks (FCN) and Long Short-Term Memory (LSTM) for supervised learning and Recurrent Autoencoders for semisupervised learning. Throughout this study, we spot the differences between these methods based on metrics such as precision and recall identifying which technique best suits this problem.", "url": "https://arxiv.org/abs/2307.02253"}, {"metadata": {"arXiv": "2307.02263", "Date": "Wed, 05 Jul 2023 13:01:21 ", "Title": "Dynamical Isometry based Rigorous Fair Neural Architecture Search", "Authors": ["Jianxiang Luo (2)", "Junyi Hu (1 and 2)", "Tianji Pang (2)", "Weihao Huang (1 and 2)", "Chuang Liu (2 and 3) ((1) Tsinghua University", "(2) Glasssix Technology (Beijing) Group Co.", "Ltd", "(3) Northwestern Polytechnical University)"], "Categories": "cs.LG cs.CY"}, "abstract": "Recently, the weight-sharing technique has significantly speeded up the training and evaluation procedure of neural architecture search. However, most existing weight-sharing strategies are solely based on experience or observation, which makes the searching results lack interpretability and rationality. In addition, due to the negligence of fairness, current methods are prone to make misjudgments in module evaluation. To address these problems, we propose a novel neural architecture search algorithm based on dynamical isometry. We use the fix point analysis method in the mean field theory to analyze the dynamics behavior in the steady state random neural network, and how dynamic isometry guarantees the fairness of weight-sharing based NAS. Meanwhile, we prove that our module selection strategy is rigorous fair by estimating the generalization error of all modules with well-conditioned Jacobian. Extensive experiments show that, with the same size, the architecture searched by the proposed method can achieve state-of-the-art top-1 validation accuracy on ImageNet classification. In addition, we demonstrate that our method is able to achieve better and more stable training performance without loss of generality.", "url": "https://arxiv.org/abs/2307.02263"}, {"metadata": {"arXiv": "2307.02275", "Date": "Wed, 05 Jul 2023 13:19:41 ", "Title": "Convolutions Through the Lens of Tensor Networks", "Authors": ["Felix Dangel"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["10 pages main text + appendix", "pre-print version"]}, "abstract": "Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas. We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion. We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions. Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation. Finally, we probe computational performance, relying on established machinery for efficient TN contraction. Our TN implementation speeds up a recently-proposed KFAC variant up to 4.5x and enables new hardware-efficient tensor dropout for approximate backpropagation.", "url": "https://arxiv.org/abs/2307.02275"}, {"metadata": {"arXiv": "2307.02300", "Date": "Wed, 05 Jul 2023 13:58:26 ", "Title": "Improving Address Matching using Siamese Transformer Networks", "Authors": ["Andr\\'e V. Duarte and Arlindo L. Oliveira"], "Categories": "cs.LG cs.IR", "Comments": ["To be published in the 22nd EPIA Conference on Artificial Intelligence", "EPIA 2023", "Faial Island - Azores", "Portugal", "5-8 September 2023", "Proceedings"], "ACM-class": "I.2"}, "abstract": "Matching addresses is a critical task for companies and post offices involved in the processing and delivery of packages. The ramifications of incorrectly delivering a package to the wrong recipient are numerous, ranging from harm to the company's reputation to economic and environmental costs. This research introduces a deep learning-based model designed to increase the efficiency of address matching for Portuguese addresses. The model comprises two parts: (i) a bi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese postal addresses, utilized to retrieve the top 10 likely matches of the un-normalized target address from a normalized database, and (ii) a cross-encoder, which is fine-tuned to accurately rerank the 10 addresses obtained by the bi-encoder. The model has been tested on a real-case scenario of Portuguese addresses and exhibits a high degree of accuracy, exceeding 95% at the door level. When utilized with GPU computations, the inference speed is about 4.5 times quicker than other traditional approaches such as BM25. An implementation of this system in a real-world scenario would substantially increase the effectiveness of the distribution process. Such an implementation is currently under investigation.", "url": "https://arxiv.org/abs/2307.02300"}, {"metadata": {"arXiv": "2307.02301", "Date": "Wed, 05 Jul 2023 13:59:35 ", "Title": "Sumformer: Universal Approximation for Efficient Transformers", "Authors": ["Silas Alberti", "Niclas Dern", "Laura Thesing", "Gitta Kutyniok"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Natural language processing (NLP) made an impressive jump with the introduction of Transformers. ChatGPT is one of the most famous examples, changing the perception of the possibilities of AI even outside the research community. However, besides the impressive performance, the quadratic time and space complexity of Transformers with respect to sequence length pose significant limitations for handling long sequences. While efficient Transformer architectures like Linformer and Performer with linear complexity have emerged as promising solutions, their theoretical understanding remains limited. In this paper, we introduce Sumformer, a novel and simple architecture capable of universally approximating equivariant sequence-to-sequence functions. We use Sumformer to give the first universal approximation results for Linformer and Performer. Moreover, we derive a new proof for Transformers, showing that just one attention layer is sufficient for universal approximation.", "url": "https://arxiv.org/abs/2307.02301"}, {"metadata": {"arXiv": "2307.02337", "Date": "Wed, 05 Jul 2023 14:48:24 ", "Title": "FAM: Relative Flatness Aware Minimization", "Authors": ["Linara Adilova", "Amr Abourayya", "Jianning Li", "Amin Dada", "Henning Petzka", "Jan Egger", "Jens Kleesiek", "Michael Kamp"], "Categories": "cs.LG", "Comments": ["Proceedings of the 2nd Annual Workshop on Topology", "Algebra", "and Geometry in Machine Learning (TAG-ML) at the 40 th International Conference on Machine Learning", "Honolulu", "Hawaii", "USA. 2023"]}, "abstract": "Flatness of the loss curve around a model at hand has been shown to empirically correlate with its generalization ability. Optimizing for flatness has been proposed as early as 1994 by Hochreiter and Schmidthuber, and was followed by more recent successful sharpness-aware optimization techniques. Their widespread adoption in practice, though, is dubious because of the lack of theoretically grounded connection between flatness and generalization, in particular in light of the reparameterization curse - certain reparameterizations of a neural network change most flatness measures but do not change generalization. Recent theoretical work suggests that a particular relative flatness measure can be connected to generalization and solves the reparameterization curse. In this paper, we derive a regularizer based on this relative flatness that is easy to compute, fast, efficient, and works with arbitrary loss functions. It requires computing the Hessian only of a single layer of the network, which makes it applicable to large neural networks, and with it avoids an expensive mapping of the loss surface in the vicinity of the model. In an extensive empirical evaluation we show that this relative flatness aware minimization (FAM) improves generalization in a multitude of applications and models, both in finetuning and standard training. We make the code available at github.", "url": "https://arxiv.org/abs/2307.02337"}, {"metadata": {"arXiv": "2307.02367", "Date": "Wed, 05 Jul 2023 15:32:39 ", "Title": "Distance Preserving Machine Learning for Uncertainty Aware Accelerator Capacitance Predictions", "Authors": ["Steven Goldenberg", "Malachi Schram", "Kishansingh Rajput", "Thomas Britton", "Chris Pappas", "Dan Lu", "Jared Walden", "Majdi I. Radaideh", "Sarah Cousineau", "Sudarshan Harave"], "Categories": "cs.LG physics.acc-ph"}, "abstract": "Providing accurate uncertainty estimations is essential for producing reliable machine learning models, especially in safety-critical applications such as accelerator systems. Gaussian process models are generally regarded as the gold standard method for this task, but they can struggle with large, high-dimensional datasets. Combining deep neural networks with Gaussian process approximation techniques have shown promising results, but dimensionality reduction through standard deep neural network layers is not guaranteed to maintain the distance information necessary for Gaussian process models. We build on previous work by comparing the use of the singular value decomposition against a spectral-normalized dense layer as a feature extractor for a deep neural Gaussian process approximation model and apply it to a capacitance prediction problem for the High Voltage Converter Modulators in the Oak Ridge Spallation Neutron Source. Our model shows improved distance preservation and predicts in-distribution capacitance values with less than 1% error.", "url": "https://arxiv.org/abs/2307.02367"}, {"metadata": {"arXiv": "2307.02398", "Date": "Wed, 05 Jul 2023 16:14:51 ", "Title": "A Versatile Hub Model For Efficient Information Propagation And Feature Selection", "Authors": ["Zhaoze Wang", "Junsong Wang"], "Categories": "cs.LG cs.SI q-bio.NC"}, "abstract": "Hub structure, characterized by a few highly interconnected nodes surrounded by a larger number of nodes with fewer connections, is a prominent topological feature of biological brains, contributing to efficient information transfer and cognitive processing across various species. In this paper, a mathematical model of hub structure is presented. The proposed method is versatile and can be broadly applied to both computational neuroscience and Recurrent Neural Networks (RNNs) research. We employ the Echo State Network (ESN) as a means to investigate the mechanistic underpinnings of hub structures. Our findings demonstrate a substantial enhancement in performance upon incorporating the hub structure. Through comprehensive mechanistic analyses, we show that the hub structure improves model performance by facilitating efficient information processing and better feature extractions.", "url": "https://arxiv.org/abs/2307.02398"}, {"metadata": {"arXiv": "2307.02419", "Date": "Wed, 05 Jul 2023 16:41:01 ", "Title": "In-Context Learning for Attention Scheme: from Single Softmax Regression to Multiple Softmax Regression via a Tensor Trick", "Authors": ["Yeqi Gao", "Zhao Song", "Shenghao Xie"], "Categories": "cs.LG"}, "abstract": "Large language models (LLMs) have brought significant and transformative changes in human society. These models have demonstrated remarkable capabilities in natural language understanding and generation, leading to various advancements and impacts across several domains. We consider the in-context learning under two formulation for attention related regression in this work. Given matrices $A_1 \\in \\mathbb{R}^{n \\times d}$, and $A_2 \\in \\mathbb{R}^{n \\times d}$ and $B \\in \\mathbb{R}^{n \\times n}$, the purpose is to solve some certain optimization problems: Normalized version $\\min_{X} \\| D(X)^{-1} \\exp(A_1 X A_2^\\top) - B \\|_F^2$ and Rescaled version $\\| \\exp(A_1 X A_2^\\top) - D(X) \\cdot B \\|_F^2$. Here $D(X) := \\mathrm{diag}( \\exp(A_1 X A_2^\\top) {\\bf 1}_n )$. Our regression problem shares similarities with previous studies on softmax-related regression. Prior research has extensively investigated regression techniques related to softmax regression: Normalized version $\\| \\langle \\exp(Ax) , {\\bf 1}_n \\rangle^{-1} \\exp(Ax) - b \\|_2^2$ and Resscaled version $\\| \\exp(Ax) - \\langle \\exp(Ax), {\\bf 1}_n \\rangle b \\|_2^2 $ In contrast to previous approaches, we adopt a vectorization technique to address the regression problem in matrix formulation. This approach expands the dimension from $d$ to $d^2$, resembling the formulation of the regression problem mentioned earlier. Upon completing the lipschitz analysis of our regression function, we have derived our main result concerning in-context learning.", "url": "https://arxiv.org/abs/2307.02419"}, {"metadata": {"arXiv": "2307.02435", "Date": "Wed, 05 Jul 2023 16:58:39 ", "Title": "Exploring Continual Learning for Code Generation Models", "Authors": ["Prateek Yadav", "Qing Sun", "Hantian Ding", "Xiaopeng Li", "Dejiao Zhang", "Ming Tan", "Xiaofei Ma", "Parminder Bhatia", "Ramesh Nallapati", "Murali Krishna Ramanathan", "Mohit Bansal", "Bing Xiang"], "Categories": "cs.LG cs.CL cs.SE", "Comments": ["ACL 2023"]}, "abstract": "Large-scale code generation models such as Codex and CodeT5 have achieved impressive performance. However, libraries are upgraded or deprecated very frequently and re-training large-scale language models is computationally expensive. Therefore, Continual Learning (CL) is an important aspect that remains underexplored in the code domain. In this paper, we introduce a benchmark called CodeTask-CL that covers a wide range of tasks, including code generation, translation, summarization, and refinement, with different input and output programming languages. Next, on our CodeTask-CL benchmark, we compare popular CL techniques from NLP and Vision domains. We find that effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks. We address this issue with our proposed method, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training by enforcing constraints on the prompt selection mechanism and leads to a 21.54% improvement over Prompt Pooling. Along with the benchmark, we establish a training pipeline that can be used for CL on code models, which we believe can motivate further development of CL methods for code models. Our code is available at https://github.com/amazon-science/codetaskcl-pptf", "url": "https://arxiv.org/abs/2307.02435"}, {"metadata": {"arXiv": "2307.02454", "Date": "Wed, 05 Jul 2023 17:27:17 ", "Title": "Transgressing the boundaries: towards a rigorous understanding of deep learning and its (non-)robustness", "Authors": ["Carsten Hartmann", "Lorenz Richter"], "Categories": "cs.LG"}, "abstract": "The recent advances in machine learning in various fields of applications can be largely attributed to the rise of deep learning (DL) methods and architectures. Despite being a key technology behind autonomous cars, image processing, speech recognition, etc., a notorious problem remains the lack of theoretical understanding of DL and related interpretability and (adversarial) robustness issues. Understanding the specifics of DL, as compared to, say, other forms of nonlinear regression methods or statistical learning, is interesting from a mathematical perspective, but at the same time it is of crucial importance in practice: treating neural networks as mere black boxes might be sufficient in certain cases, but many applications require waterproof performance guarantees and a deeper understanding of what could go wrong and why it could go wrong. It is probably fair to say that, despite being mathematically well founded as a method to approximate complicated functions, DL is mostly still more like modern alchemy that is firmly in the hands of engineers and computer scientists. Nevertheless, it is evident that certain specifics of DL that could explain its success in applications demands systematic mathematical approaches. In this work, we review robustness issues of DL and particularly bridge concerns and attempts from approximation theory to statistical learning theory. Further, we review Bayesian Deep Learning as a means for uncertainty quantification and rigorous explainability.", "url": "https://arxiv.org/abs/2307.02454"}, {"metadata": {"arXiv": "2307.02478", "Date": "Wed, 05 Jul 2023 17:51:26 ", "Title": "Linear Regression on Manifold Structured Data: the Impact of Extrinsic Geometry on Solutions", "Authors": ["Liangchen Liu", "Juncai He and Richard Tsai"], "Categories": "cs.LG math.DG", "Comments": ["13 pages", "6 figures", "accepted to ICML2023 TAGML23 workshop", "to be published in PMLR"], "MSC-class": "53Z50 62J05 (Primary) 65D18 68T07 (Secondary)", "ACM-class": "G.1.2; G.4"}, "abstract": "In this paper, we study linear regression applied to data structured on a manifold. We assume that the data manifold is smooth and is embedded in a Euclidean space, and our objective is to reveal the impact of the data manifold's extrinsic geometry on the regression. Specifically, we analyze the impact of the manifold's curvatures (or higher order nonlinearity in the parameterization when the curvatures are locally zero) on the uniqueness of the regression solution. Our findings suggest that the corresponding linear regression does not have a unique solution when the embedded submanifold is flat in some dimensions. Otherwise, the manifold's curvature (or higher order nonlinearity in the embedding) may contribute significantly, particularly in the solution associated with the normal directions of the manifold. Our findings thus reveal the role of data manifold geometry in ensuring the stability of regression models for out-of-distribution inferences.", "url": "https://arxiv.org/abs/2307.02478"}, {"metadata": {"arXiv": "2307.02483", "Date": "Wed, 05 Jul 2023 17:58:10 ", "Title": "Jailbroken: How Does LLM Safety Training Fail?", "Authors": ["Alexander Wei and Nika Haghtalab and Jacob Steinhardt"], "Categories": "cs.LG cs.CR", "Comments": [""]}, "abstract": "Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models' red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity -- that safety mechanisms should be as sophisticated as the underlying model -- and argues against the idea that scaling alone can resolve these safety failure modes.", "url": "https://arxiv.org/abs/2307.02483"}, {"metadata": {"arXiv": "2307.01317", "Date": "Mon, 03 Jul 2023 19:43:53 ", "Title": "Density-based Feasibility Learning with Normalizing Flows for Introspective Robotic Assembly", "Authors": ["Jianxiang Feng", "Matan Atad", "Ismael Rodr\\'iguez", "Maximilian Durner", "Stephan G\\\"unnemann", "Rudolph Triebel"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted to the RSS 2023 Robotic Assembly Workshop"]}, "abstract": "Machine Learning (ML) models in Robotic Assembly Sequence Planning (RASP) need to be introspective on the predicted solutions, i.e. whether they are feasible or not, to circumvent potential efficiency degradation. Previous works need both feasible and infeasible examples during training. However, the infeasible ones are hard to collect sufficiently when re-training is required for swift adaptation to new product variants. In this work, we propose a density-based feasibility learning method that requires only feasible examples. Concretely, we formulate the feasibility learning problem as Out-of-Distribution (OOD) detection with Normalizing Flows (NF), which are powerful generative models for estimating complex probability distributions. Empirically, the proposed method is demonstrated on robotic assembly use cases and outperforms other single-class baselines in detecting infeasible assemblies. We further investigate the internal working mechanism of our method and show that a large memory saving can be obtained based on an advanced variant of NF.", "url": "https://arxiv.org/abs/2307.01317"}, {"metadata": {"arXiv": "2307.01408", "Date": "Mon, 03 Jul 2023 23:56:40 ", "Title": "Multi-Predictor Fusion: Combining Learning-based and Rule-based Trajectory Predictors", "Authors": ["Sushant Veer", "Apoorva Sharma", "Marco Pavone"], "Categories": "cs.RO cs.LG cs.SY eess.SY"}, "abstract": "Trajectory prediction modules are key enablers for safe and efficient planning of autonomous vehicles (AVs), particularly in highly interactive traffic scenarios. Recently, learning-based trajectory predictors have experienced considerable success in providing state-of-the-art performance due to their ability to learn multimodal behaviors of other agents from data. In this paper, we present an algorithm called multi-predictor fusion (MPF) that augments the performance of learning-based predictors by imbuing them with motion planners that are tasked with satisfying logic-based rules. MPF probabilistically combines learning- and rule-based predictors by mixing trajectories from both standalone predictors in accordance with a belief distribution that reflects the online performance of each predictor. In our results, we show that MPF outperforms the two standalone predictors on various metrics and delivers the most consistent performance.", "url": "https://arxiv.org/abs/2307.01408"}, {"metadata": {"arXiv": "2307.01559", "Date": "Tue, 04 Jul 2023 08:29:41 ", "Title": "Secure Deep Learning-based Distributed Intelligence on Pocket-sized Drones", "Authors": ["Elia Cereda and Alessandro Giusti and Daniele Palossi"], "Categories": "cs.RO cs.CR cs.LG", "Comments": ["This paper has been accepted for publication in the EWSN 2023 conference. \\copyright 2023 ACM"]}, "abstract": "Palm-sized nano-drones are an appealing class of edge nodes, but their limited computational resources prevent running large deep-learning models onboard. Adopting an edge-fog computational paradigm, we can offload part of the computation to the fog; however, this poses security concerns if the fog node, or the communication link, can not be trusted. To tackle this concern, we propose a novel distributed edge-fog execution scheme that validates fog computation by redundantly executing a random subnetwork aboard our nano-drone. Compared to a State-of-the-Art visual pose estimation network that entirely runs onboard, a larger network executed in a distributed way improves the $R^2$ score by +0.19; in case of attack, our approach detects it within 2s with 95% probability.", "url": "https://arxiv.org/abs/2307.01559"}, {"metadata": {"arXiv": "2307.01849", "Date": "Tue, 04 Jul 2023 17:59:29 ", "Title": "Crossway Diffusion: Improving Diffusion-based Visuomotor Policy via Self-supervised Learning", "Authors": ["Xiang Li", "Varun Belagali", "Jinghuan Shang", "Michael S. Ryoo"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["18 pages", "10 figures"]}, "abstract": "Sequence modeling approaches have shown promising results in robot imitation learning. Recently, diffusion models have been adopted for behavioral cloning, benefiting from their exceptional capabilities in modeling complex data distribution. In this work, we propose Crossway Diffusion, a method to enhance diffusion-based visuomotor policy learning by using an extra self-supervised learning (SSL) objective. The standard diffusion-based policy generates action sequences from random noise conditioned on visual observations and other low-dimensional states. We further extend this by introducing a new decoder that reconstructs raw image pixels (and other state information) from the intermediate representations of the reverse diffusion process, and train the model jointly using the SSL loss. Our experiments demonstrate the effectiveness of Crossway Diffusion in various simulated and real-world robot tasks, confirming its advantages over the standard diffusion-based policy. We demonstrate that such self-supervised reconstruction enables better representation for policy learning, especially when the demonstrations have different proficiencies.", "url": "https://arxiv.org/abs/2307.01849"}, {"metadata": {"arXiv": "2307.02049", "Date": "Wed, 05 Jul 2023 06:09:25 ", "Title": "Graph Neural Network-based Power Flow Model", "Authors": ["Mingjian Tuo", "Xingpeng Li", "Tianxia Zhao"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["arXiv admin note: text overlap with arXiv:2112.08418"]}, "abstract": "Power flow analysis plays a crucial role in examining the electricity flow within a power system network. By performing power flow calculations, the system's steady-state variables, including voltage magnitude, phase angle at each bus, active/reactive power flow across branches, can be determined. While the widely used DC power flow model offers speed and robustness, it may yield inaccurate line flow results for certain transmission lines. This issue becomes more critical when dealing with renewable energy sources such as wind farms, which are often located far from the main grid. Obtaining precise line flow results for these critical lines is vital for next operations. To address these challenges, data-driven approaches leverage historical grid profiles. In this paper, a graph neural network (GNN) model is trained using historical power system data to predict power flow outcomes. The GNN model enables rapid estimation of line flows. A comprehensive performance analysis is conducted, comparing the proposed GNN-based power flow model with the traditional DC power flow model, as well as deep neural network (DNN) and convolutional neural network (CNN). The results on test systems demonstrate that the proposed GNN-based power flow model provides more accurate solutions with high efficiency comparing to benchmark models.", "url": "https://arxiv.org/abs/2307.02049"}, {"metadata": {"arXiv": "2307.01211", "Date": "Fri, 30 Jun 2023 09:04:47 ", "Title": "An automated method for the ontological representation of security directives", "Authors": ["Giampaolo Bella", "Gianpietro Castiglione", "Daniele Francesco Santamaria"], "Categories": "cs.AI cs.CL"}, "abstract": "Large documents written in juridical language are difficult to interpret, with long sentences leading to intricate and intertwined relations between the nouns. The present paper frames this problem in the context of recent European security directives. The complexity of their language is here thwarted by automating the extraction of the relevant information, namely of the parts of speech from each clause, through a specific tailoring of Natural Language Processing (NLP) techniques. These contribute, in combination with ontology development principles, to the design of our automated method for the representation of security directives as ontologies. The method is showcased on a practical problem, namely to derive an ontology representing the NIS 2 directive, which is the peak of cybersecurity prescripts at the European level. Although the NLP techniques adopted showed some limitations and had to be complemented by manual analysis, the overall results provide valid support for directive compliance in general and for ontology development in particular.", "url": "https://arxiv.org/abs/2307.01211"}, {"metadata": {"arXiv": "2307.01301", "Date": "Mon, 03 Jul 2023 19:10:45 ", "Title": "Reliable AI: Does the Next Generation Require Quantum Computing?", "Authors": ["Aras Bacho", "Holger Boche", "Gitta Kutyniok"], "Categories": "cs.AI quant-ph", "MSC-class": "15A29, 35J05, 46N10, 68Q04, 68Q12, 68Q17, 68Q25"}, "abstract": "In this survey, we aim to explore the fundamental question of whether the next generation of artificial intelligence requires quantum computing. Artificial intelligence is increasingly playing a crucial role in many aspects of our daily lives and is central to the fourth industrial revolution. It is therefore imperative that artificial intelligence is reliable and trustworthy. However, there are still many issues with reliability of artificial intelligence, such as privacy, responsibility, safety, and security, in areas such as autonomous driving, healthcare, robotics, and others. These problems can have various causes, including insufficient data, biases, and robustness problems, as well as fundamental issues such as computability problems on digital hardware. The cause of these computability problems is rooted in the fact that digital hardware is based on the computing model of the Turing machine, which is inherently discrete. Notably, our findings demonstrate that digital hardware is inherently constrained in solving problems about optimization, deep learning, or differential equations. Therefore, these limitations carry substantial implications for the field of artificial intelligence, in particular for machine learning. Furthermore, although it is well known that the quantum computer shows a quantum advantage for certain classes of problems, our findings establish that some of these limitations persist when employing quantum computing models based on the quantum circuit or the quantum Turing machine paradigm. In contrast, analog computing models, such as the Blum-Shub-Smale machine, exhibit the potential to surmount these limitations.", "url": "https://arxiv.org/abs/2307.01301"}, {"metadata": {"arXiv": "2307.01366", "Date": "Mon, 03 Jul 2023 21:47:21 ", "Title": "Minimizing Age of Information for Mobile Edge Computing Systems: A Nested Index Approach", "Authors": ["Shuo Chen", "Ning Yang", "Meng Zhang", "Jun Wang"], "Categories": "cs.AI cs.NI"}, "abstract": "Exploiting the computational heterogeneity of mobile devices and edge nodes, mobile edge computation (MEC) provides an efficient approach to achieving real-time applications that are sensitive to information freshness, by offloading tasks from mobile devices to edge nodes. We use the metric Age-of-Information (AoI) to evaluate information freshness. An efficient solution to minimize the AoI for the MEC system with multiple users is non-trivial to obtain due to the random computing time. In this paper, we consider multiple users offloading tasks to heterogeneous edge servers in a MEC system. We first reformulate the problem as a Restless Multi-Arm-Bandit (RMAB) problem and establish a hierarchical Markov Decision Process (MDP) to characterize the updating of AoI for the MEC system. Based on the hierarchical MDP, we propose a nested index framework and design a nested index policy with provably asymptotic optimality. Finally, the closed form of the nested index is obtained, which enables the performance tradeoffs between computation complexity and accuracy. Our algorithm leads to an optimality gap reduction of up to 40%, compared to benchmarks. Our algorithm asymptotically approximates the lower bound as the system scalar gets large enough.", "url": "https://arxiv.org/abs/2307.01366"}, {"metadata": {"arXiv": "2307.01532", "Date": "Tue, 04 Jul 2023 07:36:11 ", "Title": "Analyzing Intentional Behavior in Autonomous Agents under Uncertainty", "Authors": ["Filip Cano C\\'ordoba", "Samuel Judson", "Timos Antonopoulos", "Katrine Bj{\\o}rner", "Nicholas Shoemaker", "Scott J. Shapiro", "Ruzica Piskac and Bettina K\\\"onighofer"], "Categories": "cs.AI", "Comments": ["10 pages. Accepted for publication at IJCAI 2023 (Main Track)"]}, "abstract": "Principled accountability for autonomous decision-making in uncertain environments requires distinguishing intentional outcomes from negligent designs from actual accidents. We propose analyzing the behavior of autonomous agents through a quantitative measure of the evidence of intentional behavior. We model an uncertain environment as a Markov Decision Process (MDP). For a given scenario, we rely on probabilistic model checking to compute the ability of the agent to influence reaching a certain event. We call this the scope of agency. We say that there is evidence of intentional behavior if the scope of agency is high and the decisions of the agent are close to being optimal for reaching the event. Our method applies counterfactual reasoning to automatically generate relevant scenarios that can be analyzed to increase the confidence of our assessment. In a case study, we show how our method can distinguish between 'intentional' and 'accidental' traffic collisions.", "url": "https://arxiv.org/abs/2307.01532"}, {"metadata": {"arXiv": "2307.01548", "Date": "Tue, 04 Jul 2023 08:03:33 ", "Title": "Knowledge Graph for NLG in the context of conversational agents", "Authors": ["Hussam Ghanem (ICB)", "Massinissa Atmani (ICB)", "Christophe Cruz (ICB)"], "Categories": "cs.AI", "Journal-ref": "French Regional Conference on Complex Systems (FRCCS 2023), May 2023, Le Havre, France"}, "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness of the responses provided by a conversational agent. While generating answers during conversations consists in generating text from these KGs, it is still regarded as a challenging task that has gained significant attention in recent years. In this document, we provide a review of different architectures used for knowledge graph-to-text generation including: Graph Neural Networks, the Graph Transformer, and linearization with seq2seq models. We discuss the advantages and limitations of each architecture and conclude that the choice of architecture will depend on the specific requirements of the task at hand. We also highlight the importance of considering constraints such as execution time and model validity, particularly in the context of conversational agents. Based on these constraints and the availability of labeled data for the domains of DAVI, we choose to use seq2seq Transformer-based models (PLMs) for the Knowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of kg-to-text generation on PLMs and to explore the emotional and multilingual dimensions in our future work. Overall, this review provides insights into the different approaches for knowledge graph-to-text generation and outlines future directions for research in this area.", "url": "https://arxiv.org/abs/2307.01548"}, {"metadata": {"arXiv": "2307.01577", "Date": "Tue, 04 Jul 2023 09:11:01 ", "Title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings", "Authors": ["Paul Stoewer", "Achim Schilling", "Andreas Maier and Patrick Krauss"], "Categories": "cs.AI q-bio.NC"}, "abstract": "The human brain possesses the extraordinary capability to contextualize the information it receives from our environment. The entorhinal-hippocampal plays a critical role in this function, as it is deeply engaged in memory processing and constructing cognitive maps using place and grid cells. Comprehending and leveraging this ability could significantly augment the field of artificial intelligence. The multi-scale successor representation serves as a good model for the functionality of place and grid cells and has already shown promise in this role. Here, we introduce a model that employs successor representations and neural networks, along with word embedding vectors, to construct a cognitive map of three separate concepts. The network adeptly learns two different scaled maps and situates new information in proximity to related pre-existing representations. The dispersion of information across the cognitive map varies according to its scale - either being heavily concentrated, resulting in the formation of the three concepts, or spread evenly throughout the map. We suggest that our model could potentially improve current AI models by providing multi-modal context information to any input, based on a similarity metric for the input and pre-existing knowledge representations.", "url": "https://arxiv.org/abs/2307.01577"}, {"metadata": {"arXiv": "2307.01676", "Date": "Tue, 04 Jul 2023 12:07:25 ", "Title": "RaidEnv: Exploring New Challenges in Automated Content Balancing for Boss Raid Games", "Authors": ["Hyeon-Chang Jeon", "In-Chang Baek", "Cheong-mok Bae", "Taehwa Park", "Wonsang You", "Taegwan Ha", "Hoyun Jung", "Jinha Noh", "Seungwon Oh", "Kyung-Joong Kim"], "Categories": "cs.AI", "Comments": ["14 pages", "6 figures", "6 tables", "2 algorithms"]}, "abstract": "The balance of game content significantly impacts the gaming experience. Unbalanced game content diminishes engagement or increases frustration because of repetitive failure. Although game designers intend to adjust the difficulty of game content, this is a repetitive, labor-intensive, and challenging process, especially for commercial-level games with extensive content. To address this issue, the game research community has explored automated game balancing using artificial intelligence (AI) techniques. However, previous studies have focused on limited game content and did not consider the importance of the generalization ability of playtesting agents when encountering content changes. In this study, we propose RaidEnv, a new game simulator that includes diverse and customizable content for the boss raid scenario in MMORPG games. Additionally, we design two benchmarks for the boss raid scenario that can aid in the practical application of game AI. These benchmarks address two open problems in automatic content balancing, and we introduce two evaluation metrics to provide guidance for AI in automatic content balancing. This novel game research platform expands the frontiers of automatic game balancing problems and offers a framework within a realistic game production pipeline.", "url": "https://arxiv.org/abs/2307.01676"}, {"metadata": {"arXiv": "2307.01933", "Date": "Tue, 04 Jul 2023 21:37:39 ", "Title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs", "Authors": ["Zijie Huang", "Daheng Wang", "Binxuan Huang", "Chenwei Zhang", "Jingbo Shang", "Yan Liang", "Zhengyang Wang", "Xian Li", "Christos Faloutsos", "Yizhou Sun", "Wei Wang"], "Categories": "cs.AI cs.CG cs.CL cs.SC", "Journal-ref": "ACL 2023"}, "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.", "url": "https://arxiv.org/abs/2307.01933"}, {"metadata": {"arXiv": "2307.02131", "Date": "Wed, 05 Jul 2023 09:14:09 ", "Title": "Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research", "Authors": ["Toygar Tanyel", "Serkan Ayvaz and Bilgin Keserci"], "Categories": "cs.AI", "ACM-class": "J.3"}, "abstract": "This study employs counterfactual explanations to explore \"what if?\" scenarios in medical research, with the aim of expanding our understanding beyond existing boundaries. Specifically, we focus on utilizing MRI features for diagnosing pediatric posterior fossa brain tumors as a case study. The field of artificial intelligence and explainability has witnessed a growing number of studies and increasing scholarly interest. However, the lack of human-friendly interpretations in explaining the outcomes of machine learning algorithms has significantly hindered the acceptance of these methods by clinicians in their clinical practice. To address this, our approach incorporates counterfactual explanations, providing a novel way to examine alternative decision-making scenarios. These explanations offer personalized and context-specific insights, enabling the validation of predictions and clarification of variations under diverse circumstances. Importantly, our approach maintains both statistical and clinical fidelity, allowing for the examination of distinct tumor features through alternative realities. Additionally, we explore the potential use of counterfactuals for data augmentation and evaluate their feasibility as an alternative approach in medical research. The results demonstrate the promising potential of counterfactual explanations to enhance trust and acceptance of AI-driven methods in clinical settings.", "url": "https://arxiv.org/abs/2307.02131"}, {"metadata": {"arXiv": "2307.02164", "Date": "Wed, 05 Jul 2023 10:06:10 ", "Title": "Safety Shielding under Delayed Observation", "Authors": ["Filip Cano C\\'ordoba", "Alexander Palmisano", "Martin Fr\\\"anzle", "Roderick Bloem", "Bettina K\\\"onighofer"], "Categories": "cs.AI", "Comments": ["6 pages", "Published at ICAPS 2023 (Main Track)"], "DOI": "10.1609/icaps.v33i1.27181"}, "abstract": "Agents operating in physical environments need to be able to handle delays in the input and output signals since neither data transmission nor sensing or actuating the environment are instantaneous. Shields are correct-by-construction runtime enforcers that guarantee safe execution by correcting any action that may cause a violation of a formal safety specification. Besides providing safety guarantees, shields should interfere minimally with the agent. Therefore, shields should pick the safe corrective actions in such a way that future interferences are most likely minimized. Current shielding approaches do not consider possible delays in the input signals in their safety analyses. In this paper, we address this issue. We propose synthesis algorithms to compute \\emph{delay-resilient shields} that guarantee safety under worst-case assumptions on the delays of the input signals. We also introduce novel heuristics for deciding between multiple corrective actions, designed to minimize future shield interferences caused by delays. As a further contribution, we present the first integration of shields in a realistic driving simulator. We implemented our delayed shields in the driving simulator \\textsc{Carla}. We shield potentially unsafe autonomous driving agents in different safety-critical scenarios and show the effect of delays on the safety analysis.", "url": "https://arxiv.org/abs/2307.02164"}, {"metadata": {"arXiv": "2307.02254", "Date": "Wed, 05 Jul 2023 12:53:40 ", "Title": "Analyzing Different Expert-Opined Strategies to Enhance the Effect on the Goal of a Multi-Attribute Decision-Making System Using a Concept of Effort Propagation and Application in Enhancement of High School Students' Performance", "Authors": ["Suvojit Dhara and Adrijit Goswami"], "Categories": "cs.AI", "Comments": ["23 pages", "6 tables", "7 figures"]}, "abstract": "In many real-world multi-attribute decision-making (MADM) problems, mining the inter-relationships and possible hierarchical structures among the factors are considered to be one of the primary tasks. But, besides that, one major task is to determine an optimal strategy to work on the factors to enhance the effect on the goal attribute. This paper proposes two such strategies, namely parallel and hierarchical effort assignment, and propagation strategies. The concept of effort propagation through a strategy is formally defined and described in the paper. Both the parallel and hierarchical strategies are divided into sub-strategies based on whether the assignment of efforts to the factors is uniform or depends upon some appropriate heuristics related to the factors in the system. The adapted and discussed heuristics are the relative significance and effort propagability of the factors. The strategies are analyzed for a real-life case study regarding Indian high school administrative factors that play an important role in enhancing students' performance. Total effort propagation of around 7%-15% to the goal is seen across the proposed strategies given a total of 1 unit of effort to the directly accessible factors of the system. A comparative analysis is adapted to determine the optimal strategy among the proposed ones to enhance student performance most effectively. The highest effort propagation achieved in the work is approximately 14.4348%. The analysis in the paper establishes the necessity of research towards the direction of effort propagation analysis in case of decision-making problems.", "url": "https://arxiv.org/abs/2307.02254"}, {"metadata": {"arXiv": "2307.02485", "Date": "Wed, 05 Jul 2023 17:59:27 ", "Title": "Building Cooperative Embodied Agents Modularly with Large Language Models", "Authors": ["Hongxin Zhang", "Weihua Du", "Jiaming Shan", "Qinhong Zhou", "Yilun Du", "Joshua B. Tenenbaum", "Tianmin Shu", "Chuang Gan"], "Categories": "cs.AI cs.CL cs.CV", "Comments": ["Project page: https://vis-www.cs.umass.edu/Co-LLM-Agents/"]}, "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains. However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents. In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments. Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting. We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for embodied AI and lays the foundation for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.", "url": "https://arxiv.org/abs/2307.02485"}, {"metadata": {"arXiv": "2307.01378", "Date": "Mon, 03 Jul 2023 22:16:17 ", "Title": "A CNN regression model to estimate buildings height maps using Sentinel-1 SAR and Sentinel-2 MSI time series", "Authors": ["Ritu Yadav", "Andrea Nascetti", "Yifang Ban"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "Accurate estimation of building heights is essential for urban planning, infrastructure management, and environmental analysis. In this study, we propose a supervised Multimodal Building Height Regression Network (MBHR-Net) for estimating building heights at 10m spatial resolution using Sentinel-1 (S1) and Sentinel-2 (S2) satellite time series. S1 provides Synthetic Aperture Radar (SAR) data that offers valuable information on building structures, while S2 provides multispectral data that is sensitive to different land cover types, vegetation phenology, and building shadows. Our MBHR-Net aims to extract meaningful features from the S1 and S2 images to learn complex spatio-temporal relationships between image patterns and building heights. The model is trained and tested in 10 cities in the Netherlands. Root Mean Squared Error (RMSE), Intersection over Union (IOU), and R-squared (R2) score metrics are used to evaluate the performance of the model. The preliminary results (3.73m RMSE, 0.95 IoU, 0.61 R2) demonstrate the effectiveness of our deep learning model in accurately estimating building heights, showcasing its potential for urban planning, environmental impact analysis, and other related applications.", "url": "https://arxiv.org/abs/2307.01378"}, {"metadata": {"arXiv": "2307.01383", "Date": "Mon, 03 Jul 2023 22:27:37 ", "Title": "Depth video data-enabled predictions of longitudinal dairy cow body weight using thresholding and Mask R-CNN algorithms", "Authors": ["Ye Bi", "Leticia M.Campos", "Jin Wang", "Haipeng Yu", "Mark D.Hanigan", "Gota Morota"], "Categories": "cs.CV cs.AI q-bio.QM"}, "abstract": "Monitoring cow body weight is crucial to support farm management decisions due to its direct relationship with the growth, nutritional status, and health of dairy cows. Cow body weight is a repeated trait, however, the majority of previous body weight prediction research only used data collected at a single point in time. Furthermore, the utility of deep learning-based segmentation for body weight prediction using videos remains unanswered. Therefore, the objectives of this study were to predict cow body weight from repeatedly measured video data, to compare the performance of the thresholding and Mask R-CNN deep learning approaches, to evaluate the predictive ability of body weight regression models, and to promote open science in the animal science community by releasing the source code for video-based body weight prediction. A total of 40,405 depth images and depth map files were obtained from 10 lactating Holstein cows and 2 non-lactating Jersey cows. Three approaches were investigated to segment the cow's body from the background, including single thresholding, adaptive thresholding, and Mask R-CNN. Four image-derived biometric features, such as dorsal length, abdominal width, height, and volume, were estimated from the segmented images. On average, the Mask-RCNN approach combined with a linear mixed model resulted in the best prediction coefficient of determination and mean absolute percentage error of 0.98 and 2.03%, respectively, in the forecasting cross-validation. The Mask-RCNN approach was also the best in the leave-three-cows-out cross-validation. The prediction coefficients of determination and mean absolute percentage error of the Mask-RCNN coupled with the linear mixed model were 0.90 and 4.70%, respectively. Our results suggest that deep learning-based segmentation improves the prediction performance of cow body weight from longitudinal depth video data.", "url": "https://arxiv.org/abs/2307.01383"}, {"metadata": {"arXiv": "2307.01421", "Date": "Tue, 04 Jul 2023 01:26:26 ", "Title": "Unsupervised Feature Learning with Emergent Data-Driven Prototypicality", "Authors": ["Yunhui Guo", "Youren Zhang", "Yubei Chen", "Stella X. Yu"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages"]}, "abstract": "Given an image set without any labels, our goal is to train a model that maps each image to a point in a feature space such that, not only proximity indicates visual similarity, but where it is located directly encodes how prototypical the image is according to the dataset. Our key insight is to perform unsupervised feature learning in hyperbolic instead of Euclidean space, where the distance between points still reflect image similarity, and yet we gain additional capacity for representing prototypicality with the location of the point: The closer it is to the origin, the more prototypical it is. The latter property is simply emergent from optimizing the usual metric learning objective: The image similar to many training instances is best placed at the center of corresponding points in Euclidean space, but closer to the origin in hyperbolic space. We propose an unsupervised feature learning algorithm in Hyperbolic space with sphere pACKing. HACK first generates uniformly packed particles in the Poincar\\'e ball of hyperbolic space and then assigns each image uniquely to each particle. Images after congealing are regarded more typical of the dataset it belongs to. With our feature mapper simply trained to spread out training instances in hyperbolic space, we observe that images move closer to the origin with congealing, validating our idea of unsupervised prototypicality discovery. We demonstrate that our data-driven prototypicality provides an easy and superior unsupervised instance selection to reduce sample complexity, increase model generalization with atypical instances and robustness with typical ones.", "url": "https://arxiv.org/abs/2307.01421"}, {"metadata": {"arXiv": "2307.01473", "Date": "Tue, 04 Jul 2023 04:46:44 ", "Title": "Mitigating Bias: Enhancing Image Classification by Improving Model Explanations", "Authors": ["Raha Ahmadi", "Mohammad Javad Rajabi", "Mohamamd Khalooiem Mohammad Sabokrou"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep learning models have demonstrated remarkable capabilities in learning complex patterns and concepts from training data. However, recent findings indicate that these models tend to rely heavily on simple and easily discernible features present in the background of images rather than the main concepts or objects they are intended to classify. This phenomenon poses a challenge to image classifiers as the crucial elements of interest in images may be overshadowed. In this paper, we propose a novel approach to address this issue and improve the learning of main concepts by image classifiers. Our central idea revolves around concurrently guiding the model's attention toward the foreground during the classification task. By emphasizing the foreground, which encapsulates the primary objects of interest, we aim to shift the focus of the model away from the dominant influence of the background. To accomplish this, we introduce a mechanism that encourages the model to allocate sufficient attention to the foreground. We investigate various strategies, including modifying the loss function or incorporating additional architectural components, to enable the classifier to effectively capture the primary concept within an image. Additionally, we explore the impact of different foreground attention mechanisms on model performance and provide insights into their effectiveness. Through extensive experimentation on benchmark datasets, we demonstrate the efficacy of our proposed approach in improving the classification accuracy of image classifiers. Our findings highlight the importance of foreground attention in enhancing model understanding and representation of the main concepts within images. The results of this study contribute to advancing the field of image classification and provide valuable insights for developing more robust and accurate deep-learning models.", "url": "https://arxiv.org/abs/2307.01473"}, {"metadata": {"arXiv": "2307.01502", "Date": "Tue, 04 Jul 2023 06:15:06 ", "Title": "HEDI: First-Time Clinical Application and Results of a Biomechanical Evaluation and Visualisation Tool for Incisional Hernia Repair", "Authors": ["Jacob J. Relle", "Samuel Vo{\\ss}", "Ramesch Raschidi", "Regine Nessel", "Johannes G\\\"orich", "Mark O. Wielp\\\"utz", "Thorsten L\\\"offler", "Vincent Heuveline", "Friedrich Kallinowski", "Philipp D. L\\\"osel"], "Categories": "cs.CV cs.AI"}, "abstract": "Abdominal wall defects often lead to pain, discomfort, and recurrence of incisional hernias, resulting in significant morbidity and repeated surgical repairs worldwide. Mesh repair for large hernias is usually based on the defect area with a fixed overlap, without considering biomechanical aspects such as muscle activation, intra-abdominal pressure, tissue elasticity, and abdominal wall distention. To address this issue, we present a biomechanical approach to incisional hernia repair that takes into account the unstable abdominal wall. Additionally, we introduce HEDI, a tool that uses dynamic computed tomography with Valsalva maneuver to automatically detect and assess hernia size, volume, and abdominal wall instability. Our first clinical application of HEDI in the preoperative evaluation of 31 patients shows significantly improved success rates compared to reported rates, with all patients remaining pain-free and showing no hernia recurrence after three years of follow-up.", "url": "https://arxiv.org/abs/2307.01502"}, {"metadata": {"arXiv": "2307.01520", "Date": "Tue, 04 Jul 2023 07:00:37 ", "Title": "LEAT: Towards Robust Deepfake Disruption in Real-World Scenarios via Latent Ensemble Attack", "Authors": ["Joonkyo Shim", "Hyunsoo Yoon"], "Categories": "cs.CV cs.AI"}, "abstract": "Deepfakes, malicious visual contents created by generative models, pose an increasingly harmful threat to society. To proactively mitigate deepfake damages, recent studies have employed adversarial perturbation to disrupt deepfake model outputs. However, previous approaches primarily focus on generating distorted outputs based on only predetermined target attributes, leading to a lack of robustness in real-world scenarios where target attributes are unknown. Additionally, the transferability of perturbations between two prominent generative models, Generative Adversarial Networks (GANs) and Diffusion Models, remains unexplored. In this paper, we emphasize the importance of target attribute-transferability and model-transferability for achieving robust deepfake disruption. To address this challenge, we propose a simple yet effective disruption method called Latent Ensemble ATtack (LEAT), which attacks the independent latent encoding process. By disrupting the latent encoding process, it generates distorted output images in subsequent generation processes, regardless of the given target attributes. This target attribute-agnostic attack ensures robust disruption even when the target attributes are unknown. Additionally, we introduce a Normalized Gradient Ensemble strategy that effectively aggregates gradients for iterative gradient attacks, enabling simultaneous attacks on various types of deepfake models, involving both GAN-based and Diffusion-based models. Moreover, we demonstrate the insufficiency of evaluating disruption quality solely based on pixel-level differences. As a result, we propose an alternative protocol for comprehensively evaluating the success of defense. Extensive experiments confirm the efficacy of our method in disrupting deepfakes in real-world scenarios, reporting a higher defense success rate compared to previous methods.", "url": "https://arxiv.org/abs/2307.01520"}, {"metadata": {"arXiv": "2307.01530", "Date": "Tue, 04 Jul 2023 07:33:53 ", "Title": "Convolutional Transformer for Autonomous Recognition and Grading of Tomatoes Under Various Lighting, Occlusion, and Ripeness Conditions", "Authors": ["Asim Khan", "Taimur Hassan", "Muhammad Shafay", "Israa Fahmy", "Naoufel Werghi", "Lakmal Seneviratne and Irfan Hussain"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["22 pages and 6 figures"]}, "abstract": "Harvesting fully ripe tomatoes with mobile robots presents significant challenges in real-world scenarios. These challenges arise from factors such as occlusion caused by leaves and branches, as well as the color similarity between tomatoes and the surrounding foliage during the fruit development stage. The natural environment further compounds these issues with varying light conditions, viewing angles, occlusion factors, and different maturity levels. To overcome these obstacles, this research introduces a novel framework that leverages a convolutional transformer architecture to autonomously recognize and grade tomatoes, irrespective of their occlusion level, lighting conditions, and ripeness. The proposed model is trained and tested using carefully annotated images curated specifically for this purpose. The dataset is prepared under various lighting conditions, viewing perspectives, and employs different mobile camera sensors, distinguishing it from existing datasets such as Laboro Tomato and Rob2Pheno Annotated Tomato. The effectiveness of the proposed framework in handling cluttered and occluded tomato instances was evaluated using two additional public datasets, Laboro Tomato and Rob2Pheno Annotated Tomato, as benchmarks. The evaluation results across these three datasets demonstrate the exceptional performance of our proposed framework, surpassing the state-of-the-art by 58.14%, 65.42%, and 66.39% in terms of mean average precision scores for KUTomaData, Laboro Tomato, and Rob2Pheno Annotated Tomato, respectively. The results underscore the superiority of the proposed model in accurately detecting and delineating tomatoes compared to baseline methods and previous approaches. Specifically, the model achieves an F1-score of 80.14%, a Dice coefficient of 73.26%, and a mean IoU of 66.41% on the KUTomaData image dataset.", "url": "https://arxiv.org/abs/2307.01530"}, {"metadata": {"arXiv": "2307.01557", "Date": "Tue, 04 Jul 2023 08:21:39 ", "Title": "Separated RoadTopoFormer", "Authors": ["Mingjie Lu", "Yuanxian Huang", "Ji Liu", "Jinzhang Peng", "Lu Tian", "Ashish Sirasao"], "Categories": "cs.CV cs.AI"}, "abstract": "Understanding driving scenarios is crucial to realizing autonomous driving. Previous works such as map learning and BEV lane detection neglect the connection relationship between lane instances, and traffic elements detection tasks usually neglect the relationship with lane lines. To address these issues, the task is presented which includes 4 sub-tasks, the detection of traffic elements, the detection of lane centerlines, reasoning connection relationships among lanes, and reasoning assignment relationships between lanes and traffic elements. We present Separated RoadTopoFormer to tackle the issues, which is an end-to-end framework that detects lane centerline and traffic elements with reasoning relationships among them. We optimize each module separately to prevent interaction with each other and aggregate them together with few finetunes. For two detection heads, we adopted a DETR-like architecture to detect objects, and for the relationship head, we concat two instance features from front detectors and feed them to the classifier to obtain relationship probability. Our final submission achieves 0.445 OLS, which is competitive in both sub-task and combined scores.", "url": "https://arxiv.org/abs/2307.01557"}, {"metadata": {"arXiv": "2307.01778", "Date": "Tue, 04 Jul 2023 15:31:03 ", "Title": "Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling", "Authors": ["Zhanhao Hu", "Wenda Chu", "Xiaopei Zhu", "Hui Zhang", "Bo Zhang", "Xiaolin Hu"], "Categories": "cs.CV cs.AI cs.CR", "Comments": ["Accepted by CVPR 2023"]}, "abstract": "Recent works have proposed to craft adversarial clothes for evading person detectors, while they are either only effective at limited viewing angles or very conspicuous to humans. We aim to craft adversarial texture for clothes based on 3D modeling, an idea that has been used to craft rigid adversarial objects such as a 3D-printed turtle. Unlike rigid objects, humans and clothes are non-rigid, leading to difficulties in physical realization. In order to craft natural-looking adversarial clothes that can evade person detectors at multiple viewing angles, we propose adversarial camouflage textures (AdvCaT) that resemble one kind of the typical textures of daily clothes, camouflage textures. We leverage the Voronoi diagram and Gumbel-softmax trick to parameterize the camouflage textures and optimize the parameters via 3D modeling. Moreover, we propose an efficient augmentation pipeline on 3D meshes combining topologically plausible projection (TopoProj) and Thin Plate Spline (TPS) to narrow the gap between digital and real-world objects. We printed the developed 3D texture pieces on fabric materials and tailored them into T-shirts and trousers. Experiments show high attack success rates of these clothes against multiple detectors.", "url": "https://arxiv.org/abs/2307.01778"}, {"metadata": {"arXiv": "2307.01806", "Date": "Tue, 04 Jul 2023 16:21:39 ", "Title": "DeepFlorist: Rethinking Deep Neural Networks and Ensemble Learning as A Meta-Classifier For Object Classification", "Authors": ["Afshin Khadangi"], "Categories": "cs.CV cs.AI cs.DC"}, "abstract": "In this paper, we propose a novel learning paradigm called \"DeepFlorist\" for flower classification using ensemble learning as a meta-classifier. DeepFlorist combines the power of deep learning with the robustness of ensemble methods to achieve accurate and reliable flower classification results. The proposed network architecture leverages a combination of dense convolutional and convolutional neural networks (DCNNs and CNNs) to extract high-level features from flower images, followed by a fully connected layer for classification. To enhance the performance and generalization of DeepFlorist, an ensemble learning approach is employed, incorporating multiple diverse models to improve the classification accuracy. Experimental results on benchmark flower datasets demonstrate the effectiveness of DeepFlorist, outperforming state-of-the-art methods in terms of accuracy and robustness. The proposed framework holds significant potential for automated flower recognition systems in real-world applications, enabling advancements in plant taxonomy, conservation efforts, and ecological studies.", "url": "https://arxiv.org/abs/2307.01806"}, {"metadata": {"arXiv": "2307.01817", "Date": "Tue, 04 Jul 2023 16:45:21 ", "Title": "Human Trajectory Forecasting with Explainable Behavioral Uncertainty", "Authors": ["Jiangbei Yue", "Dinesh Manocha and He Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Human trajectory forecasting helps to understand and predict human behaviors, enabling applications from social robots to self-driving cars, and therefore has been heavily investigated. Most existing methods can be divided into model-free and model-based methods. Model-free methods offer superior prediction accuracy but lack explainability, while model-based methods provide explainability but cannot predict well. Combining both methodologies, we propose a new Bayesian Neural Stochastic Differential Equation model BNSP-SFM, where a behavior SDE model is combined with Bayesian neural networks (BNNs). While the NNs provide superior predictive power, the SDE offers strong explainability with quantifiable uncertainty in behavior and observation. We show that BNSP-SFM achieves up to a 50% improvement in prediction accuracy, compared with 11 state-of-the-art methods. BNSP-SFM also generalizes better to drastically different scenes with different environments and crowd densities (~ 20 times higher than the testing data). Finally, BNSP-SFM can provide predictions with confidence to better explain potential causes of behaviors. The code will be released upon acceptance.", "url": "https://arxiv.org/abs/2307.01817"}, {"metadata": {"arXiv": "2307.01945", "Date": "Tue, 04 Jul 2023 22:28:17 ", "Title": "Query-based Video Summarization with Pseudo Label Supervision", "Authors": ["Jia-Hong Huang", "Luka Murn", "Marta Mrak", "Marcel Worring"], "Categories": "cs.CV cs.AI cs.IR", "Comments": ["This paper is accepted by IEEE International Conference on Image Processing (ICIP)", "2023"]}, "abstract": "Existing datasets for manually labelled query-based video summarization are costly and thus small, limiting the performance of supervised deep video summarization models. Self-supervision can address the data sparsity challenge by using a pretext task and defining a method to acquire extra data with pseudo labels to pre-train a supervised deep model. In this work, we introduce segment-level pseudo labels from input videos to properly model both the relationship between a pretext task and a target task, and the implicit relationship between the pseudo label and the human-defined label. The pseudo labels are generated based on existing human-defined frame-level labels. To create more accurate query-dependent video summaries, a semantics booster is proposed to generate context-aware query representations. Furthermore, we propose mutual attention to help capture the interactive information between visual and textual modalities. Three commonly-used video summarization benchmarks are used to thoroughly validate the proposed approach. Experimental results show that the proposed video summarization algorithm achieves state-of-the-art performance.", "url": "https://arxiv.org/abs/2307.01945"}, {"metadata": {"arXiv": "2307.01947", "Date": "Tue, 04 Jul 2023 22:52:16 ", "Title": "Causal Video Summarizer for Video Exploration", "Authors": ["Jia-Hong Huang", "Chao-Han Huck Yang", "Pin-Yu Chen", "Andrew Brown", "Marcel Worring"], "Categories": "cs.CV cs.AI cs.IR", "Comments": ["This paper is accepted by IEEE International Conference on Multimedia and Expo (ICME)", "2022"]}, "abstract": "Recently, video summarization has been proposed as a method to help video exploration. However, traditional video summarization models only generate a fixed video summary which is usually independent of user-specific needs and hence limits the effectiveness of video exploration. Multi-modal video summarization is one of the approaches utilized to address this issue. Multi-modal video summarization has a video input and a text-based query input. Hence, effective modeling of the interaction between a video input and text-based query is essential to multi-modal video summarization. In this work, a new causality-based method named Causal Video Summarizer (CVS) is proposed to effectively capture the interactive information between the video and query to tackle the task of multi-modal video summarization. The proposed method consists of a probabilistic encoder and a probabilistic decoder. Based on the evaluation of the existing multi-modal video summarization dataset, experimental results show that the proposed approach is effective with the increase of +5.4% in accuracy and +4.92% increase of F 1- score, compared with the state-of-the-art method.", "url": "https://arxiv.org/abs/2307.01947"}, {"metadata": {"arXiv": "2307.01952", "Date": "Tue, 04 Jul 2023 23:04:57 ", "Title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "Authors": ["Dustin Podell", "Zion English", "Kyle Lacey", "Andreas Blattmann", "Tim Dockhorn", "Jonas M\\\"uller", "Joe Penna", "Robin Rombach"], "Categories": "cs.CV cs.AI"}, "abstract": "We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. In the spirit of promoting open research and fostering transparency in large model training and evaluation, we provide access to code and model weights at https://github.com/Stability-AI/generative-models", "url": "https://arxiv.org/abs/2307.01952"}, {"metadata": {"arXiv": "2307.02019", "Date": "Wed, 05 Jul 2023 04:14:57 ", "Title": "Generative Adversarial Networks for Dental Patient Identity Protection in Orthodontic Educational Imaging", "Authors": ["Mingchuan Tian", "Wilson Weixun Lu", "Kelvin Weng Chiong Foong", "Eugene Loh"], "Categories": "cs.CV cs.AI"}, "abstract": "Objectives: This research introduces a novel area-preserving Generative Adversarial Networks (GAN) inversion technique for effectively de-identifying dental patient images. This innovative method addresses privacy concerns while preserving key dental features, thereby generating valuable resources for dental education and research. Methods: We enhanced the existing GAN Inversion methodology to maximize the preservation of dental characteristics within the synthesized images. A comprehensive technical framework incorporating several deep learning models was developed to provide end-to-end development guidance and practical application for image de-identification. Results: Our approach was assessed with varied facial pictures, extensively used for diagnosing skeletal asymmetry and facial anomalies. Results demonstrated our model's ability to adapt the context from one image to another, maintaining compatibility, while preserving dental features essential for oral diagnosis and dental education. A panel of five clinicians conducted an evaluation on a set of original and GAN-processed images. The generated images achieved effective de-identification, maintaining the realism of important dental features and were deemed useful for dental diagnostics and education. Clinical Significance: Our GAN model and the encompassing framework can streamline the de-identification process of dental patient images, enhancing efficiency in dental education. This method improves students' diagnostic capabilities by offering more exposure to orthodontic malocclusions. Furthermore, it facilitates the creation of de-identified datasets for broader 2D image research at major research institutions.", "url": "https://arxiv.org/abs/2307.02019"}, {"metadata": {"arXiv": "2307.02227", "Date": "Wed, 05 Jul 2023 12:08:56 ", "Title": "MAE-DFER: Efficient Masked Autoencoder for Self-supervised Dynamic Facial Expression Recognition", "Authors": ["Licai Sun", "Zheng Lian", "Bin Liu", "Jianhua Tao"], "Categories": "cs.CV cs.AI cs.HC cs.MM", "Comments": ["17 pages", "11 figures", "14 tables"]}, "abstract": "Dynamic facial expression recognition (DFER) is essential to the development of intelligent and empathetic machines. Prior efforts in this field mainly fall into supervised learning paradigm, which is restricted by the limited labeled data in existing datasets. Inspired by recent unprecedented success of masked autoencoders (e.g., VideoMAE), this paper proposes MAE-DFER, a novel self-supervised method which leverages large-scale self-supervised pre-training on abundant unlabeled data to advance the development of DFER. Since the vanilla Vision Transformer (ViT) employed in VideoMAE requires substantial computation during fine-tuning, MAE-DFER develops an efficient local-global interaction Transformer (LGI-Former) as the encoder. LGI-Former first constrains self-attention in local spatiotemporal regions and then utilizes a small set of learnable representative tokens to achieve efficient local-global information exchange, thus avoiding the expensive computation of global space-time self-attention in ViT. Moreover, in addition to the standalone appearance content reconstruction in VideoMAE, MAE-DFER also introduces explicit facial motion modeling to encourage LGI-Former to excavate both static appearance and dynamic motion information. Extensive experiments on six datasets show that MAE-DFER consistently outperforms state-of-the-art supervised methods by significant margins, verifying that it can learn powerful dynamic facial representations via large-scale self-supervised pre-training. Besides, it has comparable or even better performance than VideoMAE, while largely reducing the computational cost (about 38\\% FLOPs). We believe MAE-DFER has paved a new way for the advancement of DFER and can inspire more relavant research in this field and even other related tasks. Codes and models are publicly available at https://github.com/sunlicai/MAE-DFER.", "url": "https://arxiv.org/abs/2307.02227"}, {"metadata": {"arXiv": "2307.02270", "Date": "Wed, 05 Jul 2023 13:10:37 ", "Title": "SVDM: Single-View Diffusion Model for Pseudo-Stereo 3D Object Detection", "Authors": ["Yuguang Shi"], "Categories": "cs.CV cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2203.02112", "arXiv:2303.01469 by other authors"]}, "abstract": "One of the key problems in 3D object detection is to reduce the accuracy gap between methods based on LiDAR sensors and those based on monocular cameras. A recently proposed framework for monocular 3D detection based on Pseudo-Stereo has received considerable attention in the community. However, so far these two problems are discovered in existing practices, including (1) monocular depth estimation and Pseudo-Stereo detector must be trained separately, (2) Difficult to be compatible with different stereo detectors and (3) the overall calculation is large, which affects the reasoning speed. In this work, we propose an end-to-end, efficient pseudo-stereo 3D detection framework by introducing a Single-View Diffusion Model (SVDM) that uses a few iterations to gradually deliver right informative pixels to the left image. SVDM allows the entire pseudo-stereo 3D detection pipeline to be trained end-to-end and can benefit from the training of stereo detectors. Afterwards, we further explore the application of SVDM in depth-free stereo 3D detection, and the final framework is compatible with most stereo detectors. Among multiple benchmarks on the KITTI dataset, we achieve new state-of-the-art performance.", "url": "https://arxiv.org/abs/2307.02270"}, {"metadata": {"arXiv": "2307.02457", "Date": "Wed, 05 Jul 2023 17:31:44 ", "Title": "DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models", "Authors": ["Liangbin Xie", "Xintao Wang", "Xiangyu Chen", "Gen Li", "Ying Shan", "Jiantao Zhou", "Chao Dong"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["The code and models will be made publicly at https://github.com/TencentARC/DeSRA"]}, "abstract": "Image super-resolution (SR) with generative adversarial networks (GAN) has achieved great success in restoring realistic details. However, it is notorious that GAN-based SR models will inevitably produce unpleasant and undesirable artifacts, especially in practical scenarios. Previous works typically suppress artifacts with an extra loss penalty in the training phase. They only work for in-distribution artifact types generated during training. When applied in real-world scenarios, we observe that those improved methods still generate obviously annoying artifacts during inference. In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths. We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice. Specifically, we propose to measure a relative local variance distance from MSE-SR results and GAN-SR results, and locate the problematic areas based on the above distance and semantic-aware thresholds. After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data. Equipped with our DeSRA, we can successfully eliminate artifacts from inference and improve the ability of SR models to be applied in real-world scenarios. The code will be available at https://github.com/TencentARC/DeSRA.", "url": "https://arxiv.org/abs/2307.02457"}, {"metadata": {"arXiv": "2307.01371", "Date": "Mon, 03 Jul 2023 21:56:10 ", "Title": "Efficient Determination of Safety Requirements for Perception Systems", "Authors": ["Sydney M. Katz", "Anthony L. Corso", "Esen Yel", "Mykel J. Kochenderfer"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages", "14 figures", "submitted to the 2023 Digital Avionics Systems Conference"]}, "abstract": "Perception systems operate as a subcomponent of the general autonomy stack, and perception system designers often need to optimize performance characteristics while maintaining safety with respect to the overall closed-loop system. For this reason, it is useful to distill high-level safety requirements into component-level requirements on the perception system. In this work, we focus on efficiently determining sets of safe perception system performance characteristics given a black-box simulator of the fully-integrated, closed-loop system. We combine the advantages of common black-box estimation techniques such as Gaussian processes and threshold bandits to develop a new estimation method, which we call smoothing bandits. We demonstrate our method on a vision-based aircraft collision avoidance problem and show improvements in terms of both accuracy and efficiency over the Gaussian process and threshold bandit baselines.", "url": "https://arxiv.org/abs/2307.01371"}, {"metadata": {"arXiv": "2307.01928", "Date": "Tue, 04 Jul 2023 21:25:12 ", "Title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners", "Authors": ["Allen Z. Ren", "Anushri Dixit", "Alexandra Bodrova", "Sumeet Singh", "Stephen Tu", "Noah Brown", "Peng Xu", "Leila Takayama", "Fei Xia", "Jake Varley", "Zhenjia Xu", "Dorsa Sadigh", "Andy Zeng", "Anirudha Majumdar"], "Categories": "cs.RO cs.AI stat.AP", "Comments": ["Under review"]}, "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities -- from step-by-step planning to commonsense reasoning -- that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KnowNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KnowNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KnowNo performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. KnowNo can be used with LLMs out of the box without model-finetuning, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models. Website: https://robot-help.github.io", "url": "https://arxiv.org/abs/2307.01928"}, {"metadata": {"arXiv": "2307.02427", "Date": "Wed, 05 Jul 2023 16:49:06 ", "Title": "FOCUS: Object-Centric World Models for Robotics Manipulation", "Authors": ["Stefano Ferraro", "Pietro Mazzaglia", "Tim Verbelen", "Bart Dhoedt"], "Categories": "cs.RO cs.AI"}, "abstract": "Understanding the world in terms of objects and the possible interplays with them is an important cognition ability, especially in robotics manipulation, where many tasks require robot-object interactions. However, learning such a structured world model, which specifically captures entities and relationships, remains a challenging and underexplored problem. To address this, we propose FOCUS, a model-based agent that learns an object-centric world model. Thanks to a novel exploration bonus that stems from the object-centric representation, FOCUS can be deployed on robotics manipulation tasks to explore object interactions more easily. Evaluating our approach on manipulation tasks across different settings, we show that object-centric world models allow the agent to solve tasks more efficiently and enable consistent exploration of robot-object interactions. Using a Franka Emika robot arm, we also showcase how FOCUS could be adopted in real-world settings.", "url": "https://arxiv.org/abs/2307.02427"}, {"metadata": {"arXiv": "2307.01312", "Date": "Mon, 03 Jul 2023 19:35:52 ", "Title": "Self-Tuning PID Control via a Hybrid Actor-Critic-Based Neural Structure for Quadcopter Control", "Authors": ["Iman Sharifi", "Aria Alasty"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["7 pages", "18 figures", "The 30th Annual International Conference of Iranian Society of Mechanical Engineers"]}, "abstract": "Proportional-Integrator-Derivative (PID) controller is used in a wide range of industrial and experimental processes. There are a couple of offline methods for tuning PID gains. However, due to the uncertainty of model parameters and external disturbances, real systems such as Quadrotors need more robust and reliable PID controllers. In this research, a self-tuning PID controller using a Reinforcement-Learning-based Neural Network for attitude and altitude control of a Quadrotor has been investigated. An Incremental PID, which contains static and dynamic gains, has been considered and only the variable gains have been tuned. To tune dynamic gains, a model-free actor-critic-based hybrid neural structure was used that was able to properly tune PID gains, and also has done the best as an identifier. In both tunning and identification tasks, a Neural Network with two hidden layers and sigmoid activation functions has been learned using Adaptive Momentum (ADAM) optimizer and Back-Propagation (BP) algorithm. This method is online, able to tackle disturbance, and fast in training. In addition to robustness to mass uncertainty and wind gust disturbance, results showed that the proposed method had a better performance when compared to a PID controller with constant gains.", "url": "https://arxiv.org/abs/2307.01312"}, {"metadata": {"arXiv": "2307.01916", "Date": "Tue, 04 Jul 2023 21:00:30 ", "Title": "Maximizing Seaweed Growth on Autonomous Farms: A Dynamic Programming Approach for Underactuated Systems Navigating on Uncertain Ocean Currents", "Authors": ["Matthias Killer", "Marius Wiggert", "Hanna Krasowski", "Manan Doshi", "Pierre F.J. Lermusiaux and Claire J. Tomlin"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["8 pages", "submitted to 2023 IEEE 62th Annual Conference on Decision and Control (CDC) Matthias Killer and Marius Wiggert contributed equally to this work"]}, "abstract": "Seaweed biomass offers significant potential for climate mitigation, but large-scale, autonomous open-ocean farms are required to fully exploit it. Such farms typically have low propulsion and are heavily influenced by ocean currents. We want to design a controller that maximizes seaweed growth over months by taking advantage of the non-linear time-varying ocean currents for reaching high-growth regions. The complex dynamics and underactuation make this challenging even when the currents are known. This is even harder when only short-term imperfect forecasts with increasing uncertainty are available. We propose a dynamic programming-based method to efficiently solve for the optimal growth value function when true currents are known. We additionally present three extensions when as in reality only forecasts are known: (1) our methods resulting value function can be used as feedback policy to obtain the growth-optimal control for all states and times, allowing closed-loop control equivalent to re-planning at every time step hence mitigating forecast errors, (2) a feedback policy for long-term optimal growth beyond forecast horizons using seasonal average current data as terminal reward, and (3) a discounted finite-time Dynamic Programming (DP) formulation to account for increasing ocean current estimate uncertainty. We evaluate our approach through 30-day simulations of floating seaweed farms in realistic Pacific Ocean current scenarios. Our method demonstrates an achievement of 95.8% of the best possible growth using only 5-day forecasts. This confirms the feasibility of using low-power propulsion and optimal control for enhanced seaweed growth on floating farms under real-world conditions.", "url": "https://arxiv.org/abs/2307.01916"}, {"metadata": {"arXiv": "2307.01917", "Date": "Tue, 04 Jul 2023 21:01:16 ", "Title": "Stranding Risk for Underactuated Vessels in Complex Ocean Currents: Analysis and Controllers", "Authors": ["Andreas Doering", "Marius Wiggert", "Hanna Krasowski", "Manan Doshi", "Pierre F.J. Lermusiaux and Claire J. Tomlin"], "Categories": "eess.SY cs.AI cs.RO cs.SY", "Comments": ["6 pages", "3 figures", "submitted to 2023 IEEE 62th Annual Conference on Decision and Control (CDC) Andreas Doering and Marius Wiggert contributed equally to this work"]}, "abstract": "Low-propulsion vessels can take advantage of powerful ocean currents to navigate towards a destination. Recent results demonstrated that vessels can reach their destination with high probability despite forecast errors. However, these results do not consider the critical aspect of safety of such vessels: because of their low propulsion which is much smaller than the magnitude of currents, they might end up in currents that inevitably push them into unsafe areas such as shallow areas, garbage patches, and shipping lanes. In this work, we first investigate the risk of stranding for free-floating vessels in the Northeast Pacific. We find that at least 5.04% would strand within 90 days. Next, we encode the unsafe sets as hard constraints into Hamilton-Jacobi Multi-Time Reachability (HJ-MTR) to synthesize a feedback policy that is equivalent to re-planning at each time step at low computational cost. While applying this policy closed-loop guarantees safe operation when the currents are known, in realistic situations only imperfect forecasts are available. We demonstrate the safety of our approach in such realistic situations empirically with large-scale simulations of a vessel navigating in high-risk regions in the Northeast Pacific. We find that applying our policy closed-loop with daily re-planning on new forecasts can ensure safety with high probability even under forecast errors that exceed the maximal propulsion. Our method significantly improves safety over the baselines and still achieves a timely arrival of the vessel at the destination.", "url": "https://arxiv.org/abs/2307.01917"}, {"metadata": {"arXiv": "2307.01204", "Date": "Mon, 26 Jun 2023 12:02:32 ", "Title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach", "Authors": ["Zicheng Zhao", "Linhao Luo", "Shirui Pan", "Quoc Viet Hung Nguyen", "Chen Gong"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted by ECML/PKDD 2023"]}, "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict missing links for unseen entities with few-shot links observed. Previous methods are limited to transductive scenarios, where entities exist in the knowledge graphs, so they are unable to handle unseen entities. Therefore, recent inductive methods utilize the sub-graphs around unseen entities to obtain the semantics and predict links inductively. However, in the few-shot setting, the sub-graphs are often sparse and cannot provide meaningful inductive patterns. In this paper, we propose a novel relational anonymous walk-guided neural process for few-shot inductive link prediction on knowledge graphs, denoted as RawNP. Specifically, we develop a neural process-based method to model a flexible distribution over link prediction functions. This enables the model to quickly adapt to new entities and estimate the uncertainty when making predictions. To capture general inductive patterns, we present a relational anonymous walk to extract a series of relational motifs from few-shot observations. These motifs reveal the distinctive semantic patterns on KGs that support inductive predictions. Extensive experiments on typical benchmark datasets demonstrate that our model derives new state-of-the-art performance.", "url": "https://arxiv.org/abs/2307.01204"}, {"metadata": {"arXiv": "2307.01403", "Date": "Mon, 03 Jul 2023 23:51:05 ", "Title": "Learning to Communicate using Contrastive Learning", "Authors": ["Yat Long Lo", "Biswa Sengupta", "Jakob Foerster", "Michael Noukhovitch"], "Categories": "cs.AI cs.LG"}, "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But inducing an effective, common language is a difficult challenge, particularly in the decentralized setting. In this work, we introduce an alternative perspective where communicative messages sent between agents are considered as different incomplete views of the environment state. By examining the relationship between messages sent and received, we propose to learn to communicate using contrastive learning to maximize the mutual information between messages of a given trajectory. In communication-essential environments, our method outperforms previous work in both performance and learning speed. Using qualitative metrics and representation probing, we show that our method induces more symmetric communication and captures global state information from the environment. Overall, we show the power of contrastive learning and the importance of leveraging messages as encodings for effective communication.", "url": "https://arxiv.org/abs/2307.01403"}, {"metadata": {"arXiv": "2307.01472", "Date": "Tue, 04 Jul 2023 04:40:54 ", "Title": "Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning", "Authors": ["Zhuoran Li", "Ling Pan and Longbo Huang"], "Categories": "cs.AI cs.LG cs.MA"}, "abstract": "We present a novel Diffusion Offline Multi-agent Model (DOM2) for offline Multi-Agent Reinforcement Learning (MARL). Different from existing algorithms that rely mainly on conservatism in policy design, DOM2 enhances policy expressiveness and diversity based on diffusion. Specifically, we incorporate a diffusion model into the policy network and propose a trajectory-based data-augmentation scheme in training. These key ingredients make our algorithm more robust to environment changes and achieve significant improvements in performance, generalization and data-efficiency. Our extensive experimental results demonstrate that DOM2 outperforms existing state-of-the-art methods in multi-agent particle and multi-agent MuJoCo environments, and generalizes significantly better in shifted environments thanks to its high expressiveness and diversity. Furthermore, DOM2 shows superior data efficiency and can achieve state-of-the-art performance with $20+$ times less data compared to existing algorithms.", "url": "https://arxiv.org/abs/2307.01472"}, {"metadata": {"arXiv": "2307.01639", "Date": "Tue, 04 Jul 2023 10:47:02 ", "Title": "Heuristic Algorithms for the Approximation of Mutual Coherence", "Authors": ["Gregor Betz", "Vera Chekan", "Tamara Mchedlidze"], "Categories": "cs.AI cs.LG cs.LO cs.SI", "Comments": ["Results from 2021"]}, "abstract": "Mutual coherence is a measure of similarity between two opinions. Although the notion comes from philosophy, it is essential for a wide range of technologies, e.g., the Wahl-O-Mat system. In Germany, this system helps voters to find candidates that are the closest to their political preferences. The exact computation of mutual coherence is highly time-consuming due to the iteration over all subsets of an opinion. Moreover, for every subset, an instance of the SAT model counting problem has to be solved which is known to be a hard problem in computer science. This work is the first study to accelerate this computation. We model the distribution of the so-called confirmation values as a mixture of three Gaussians and present efficient heuristics to estimate its model parameters. The mutual coherence is then approximated with the expected value of the distribution. Some of the presented algorithms are fully polynomial-time, others only require solving a small number of instances of the SAT model counting problem. The average squared error of our best algorithm lies below 0.0035 which is insignificant if the efficiency is taken into account. Furthermore, the accuracy is precise enough to be used in Wahl-O-Mat-like systems.", "url": "https://arxiv.org/abs/2307.01639"}, {"metadata": {"arXiv": "2307.02075", "Date": "Wed, 05 Jul 2023 07:32:34 ", "Title": "Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment", "Authors": ["Qijie Ding", "Jie Yin", "Daokun Zhang and Junbin Gao"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to enable more accurate determination of entity correspondences across two KGs and to mitigate the adverse impact of erroneous matches. A simple but highly effective criterion is further devised to derive pseudo-labeled entity pairs that satisfy one-to-one correspondences at each iteration. (2) The cross-iteration pseudo-label calibration operates across multiple consecutive iterations to further improve the pseudo-labeling precision rate by reducing the local pseudo-label selection variability with a theoretical guarantee. The two components are respectively designed to eliminate Type I and Type II pseudo-labeling errors identified through our analyse. The calibrated pseudo-labels are thereafter used to augment prior alignment seeds to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. The experimental results show that our approach achieves competitive performance with limited prior alignment seeds.", "url": "https://arxiv.org/abs/2307.02075"}, {"metadata": {"arXiv": "2307.02390", "Date": "Wed, 05 Jul 2023 16:01:38 ", "Title": "Causal Discovery with Language Models as Imperfect Experts", "Authors": ["Stephanie Long", "Alexandre Pich\\'e", "Valentina Zantedeschi", "Tibor Schuster", "Alexandre Drouin"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Peer reviewed and accepted for presentation at the Structured Probabilistic Inference & Generative Modeling (SPIGM) workshop at ICML 2023", "Hawaii", "USA"]}, "abstract": "Understanding the causal relationships that underlie a system is a fundamental prerequisite to accurate decision-making. In this work, we explore how expert knowledge can be used to improve the data-driven identification of causal graphs, beyond Markov equivalence classes. In doing so, we consider a setting where we can query an expert about the orientation of causal relationships between variables, but where the expert may provide erroneous information. We propose strategies for amending such expert knowledge based on consistency properties, e.g., acyclicity and conditional independencies in the equivalence class. We then report a case study, on real data, where a large language model is used as an imperfect expert.", "url": "https://arxiv.org/abs/2307.02390"}, {"metadata": {"arXiv": "2307.01582", "Date": "Tue, 04 Jul 2023 09:22:50 ", "Title": "IAdet: Simplest human-in-the-loop object detection", "Authors": ["Franco Marchesoni-Acland", "Gabriele Facciolo"], "Categories": "cs.CV cs.AI cs.HC cs.LG"}, "abstract": "This work proposes a strategy for training models while annotating data named Intelligent Annotation (IA). IA involves three modules: (1) assisted data annotation, (2) background model training, and (3) active selection of the next datapoints. Under this framework, we open-source the IAdet tool, which is specific for single-class object detection. Additionally, we devise a method for automatically evaluating such a human-in-the-loop system. For the PASCAL VOC dataset, the IAdet tool reduces the database annotation time by $25\\%$ while providing a trained model for free. These results are obtained for a deliberately very simple IAdet design. As a consequence, IAdet is susceptible to multiple easy improvements, paving the way for powerful human-in-the-loop object detection systems.", "url": "https://arxiv.org/abs/2307.01582"}, {"metadata": {"arXiv": "2307.01831", "Date": "Tue, 04 Jul 2023 17:15:46 ", "Title": "DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation", "Authors": ["Shentong Mo", "Enze Xie", "Ruihang Chu", "Lewei Yao", "Lanqing Hong", "Matthias Nie{\\ss}ner", "Zhenguo Li"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project Page: https://dit-3d.github.io/"]}, "abstract": "Recent Diffusion Transformers (e.g., DiT) have demonstrated their powerful effectiveness in generating high-quality 2D images. However, it is still being determined whether the Transformer architecture performs equally well in 3D shape generation, as previous 3D diffusion methods mostly adopted the U-Net architecture. To bridge this gap, we propose a novel Diffusion Transformer for 3D shape generation, namely DiT-3D, which can directly operate the denoising process on voxelized point clouds using plain Transformers. Compared to existing U-Net approaches, our DiT-3D is more scalable in model size and produces much higher quality generations. Specifically, the DiT-3D adopts the design philosophy of DiT but modifies it by incorporating 3D positional and patch embeddings to adaptively aggregate input from voxelized point clouds. To reduce the computational cost of self-attention in 3D shape generation, we incorporate 3D window attention into Transformer blocks, as the increased 3D token length resulting from the additional dimension of voxels can lead to high computation. Finally, linear and devoxelization layers are used to predict the denoised point clouds. In addition, our transformer architecture supports efficient fine-tuning from 2D to 3D, where the pre-trained DiT-2D checkpoint on ImageNet can significantly improve DiT-3D on ShapeNet. Experimental results on the ShapeNet dataset demonstrate that the proposed DiT-3D achieves state-of-the-art performance in high-fidelity and diverse 3D point cloud generation. In particular, our DiT-3D decreases the 1-Nearest Neighbor Accuracy of the state-of-the-art method by 4.59 and increases the Coverage metric by 3.51 when evaluated on Chamfer Distance.", "url": "https://arxiv.org/abs/2307.01831"}, {"metadata": {"arXiv": "2307.01984", "Date": "Wed, 05 Jul 2023 02:00:14 ", "Title": "The KiTS21 Challenge: Automatic segmentation of kidneys, renal tumors, and renal cysts in corticomedullary-phase CT", "Authors": ["Nicholas Heller", "Fabian Isensee", "Dasha Trofimova", "Resha Tejpaul", "Zhongchen Zhao", "Huai Chen", "Lisheng Wang", "Alex Golts", "Daniel Khapun", "Daniel Shats", "Yoel Shoshan", "Flora Gilboa-Solomon", "Yasmeen George", "Xi Yang", "Jianpeng Zhang", "Jing Zhang", "Yong Xia", "Mengran Wu", "Zhiyang Liu", "Ed Walczak", "Sean McSweeney", "Ranveer Vasdev", "Chris Hornung", "Rafat Solaiman", "Jamee Schoephoerster", "Bailey Abernathy", "David Wu", "Safa Abdulkadir", "Ben Byun", "Justice Spriggs", "Griffin Struyk", "Alexandra Austin", "Ben Simpson", "Michael Hagstrom", "Sierra Virnig", "John French", "Nitin Venkatesh", "Sarah Chan", "Keenan Moore", "Anna Jacobsen", "Susan Austin", "Mark Austin", "Subodh Regmi", "Nikolaos Papanikolopoulos", "and Christopher Weight"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["34 pages", "12 figures"]}, "abstract": "This paper presents the challenge report for the 2021 Kidney and Kidney Tumor Segmentation Challenge (KiTS21) held in conjunction with the 2021 international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI). KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset. A novel annotation method was used to collect three separate annotations for each region of interest, and these annotations were performed in a fully transparent setting using a web-based annotation tool. Further, the KiTS21 test set was collected from an outside institution, challenging participants to develop methods that generalize well to new populations. Nonetheless, the top-performing teams achieved a significant improvement over the state of the art set in 2019, and this performance is shown to inch ever closer to human-level performance. An in-depth meta-analysis is presented describing which methods were used and how they faired on the leaderboard, as well as the characteristics of which cases generally saw good performance, and which did not. Overall KiTS21 facilitated a significant advancement in the state of the art in kidney tumor segmentation, and provides useful insights that are applicable to the field of semantic segmentation as a whole.", "url": "https://arxiv.org/abs/2307.01984"}, {"metadata": {"arXiv": "2307.02065", "Date": "Wed, 05 Jul 2023 07:08:58 ", "Title": "Line Graphics Digitization: A Step Towards Full Automation", "Authors": ["Omar Moured", "Jiaming Zhang", "Alina Roitberg", "Thorsten Schwarz", "Rainer Stiefelhagen"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at The 17th International Conference on Document Analysis and Recognition (ICDAR 2023)"]}, "abstract": "The digitization of documents allows for wider accessibility and reproducibility. While automatic digitization of document layout and text content has been a long-standing focus of research, this problem in regard to graphical elements, such as statistical plots, has been under-explored. In this paper, we introduce the task of fine-grained visual understanding of mathematical graphics and present the Line Graphics (LG) dataset, which includes pixel-wise annotations of 5 coarse and 10 fine-grained categories. Our dataset covers 520 images of mathematical graphics collected from 450 documents from different disciplines. Our proposed dataset can support two different computer vision tasks, i.e., semantic segmentation and object detection. To benchmark our LG dataset, we explore 7 state-of-the-art models. To foster further research on the digitization of statistical graphs, we will make the dataset, code, and models publicly available to the community.", "url": "https://arxiv.org/abs/2307.02065"}, {"metadata": {"arXiv": "2307.01394", "Date": "Mon, 03 Jul 2023 23:11:03 ", "Title": "In-depth Analysis On Parallel Processing Patterns for High-Performance Dataframes", "Authors": ["Niranda Perera", "Arup Kumar Sarker", "Mills Staylor", "Gregor von Laszewski", "Kaiying Shan", "Supun Kamburugamuve", "Chathura Widanage", "Vibhatha Abeykoon", "Thejaka Amila Kanewela", "Geoffrey Fox"], "Categories": "cs.DC cs.AI cs.IR cs.LG", "Report-no": "FGCS-D-23-00577R1"}, "abstract": "The Data Science domain has expanded monumentally in both research and industry communities during the past decade, predominantly owing to the Big Data revolution. Artificial Intelligence (AI) and Machine Learning (ML) are bringing more complexities to data engineering applications, which are now integrated into data processing pipelines to process terabytes of data. Typically, a significant amount of time is spent on data preprocessing in these pipelines, and hence improving its e fficiency directly impacts the overall pipeline performance. The community has recently embraced the concept of Dataframes as the de-facto data structure for data representation and manipulation. However, the most widely used serial Dataframes today (R, pandas) experience performance limitations while working on even moderately large data sets. We believe that there is plenty of room for improvement by taking a look at this problem from a high-performance computing point of view. In a prior publication, we presented a set of parallel processing patterns for distributed dataframe operators and the reference runtime implementation, Cylon [1]. In this paper, we are expanding on the initial concept by introducing a cost model for evaluating the said patterns. Furthermore, we evaluate the performance of Cylon on the ORNL Summit supercomputer.", "url": "https://arxiv.org/abs/2307.01394"}, {"metadata": {"arXiv": "2307.01684", "Date": "Tue, 04 Jul 2023 12:30:01 ", "Title": "Serving Graph Neural Networks With Distributed Fog Servers For Smart IoT Services", "Authors": ["Liekang Zeng", "Xu Chen", "Peng Huang", "Ke Luo", "Xiaoxi Zhang", "Zhi Zhou"], "Categories": "cs.DC cs.AI cs.LG cs.NI", "Comments": ["Accepted by IEEE/ACM Transactions on Networking"]}, "abstract": "Graph Neural Networks (GNNs) have gained growing interest in miscellaneous applications owing to their outstanding ability in extracting latent representation on graph structures. To render GNN-based service for IoT-driven smart applications, traditional model serving paradigms usually resort to the cloud by fully uploading geo-distributed input data to remote datacenters. However, our empirical measurements reveal the significant communication overhead of such cloud-based serving and highlight the profound potential in applying the emerging fog computing. To maximize the architectural benefits brought by fog computing, in this paper, we present Fograph, a novel distributed real-time GNN inference framework that leverages diverse and dynamic resources of multiple fog nodes in proximity to IoT data sources. By introducing heterogeneity-aware execution planning and GNN-specific compression techniques, Fograph tailors its design to well accommodate the unique characteristics of GNN serving in fog environments. Prototype-based evaluation and case study demonstrate that Fograph significantly outperforms the state-of-the-art cloud serving and fog deployment by up to 5.39x execution speedup and 6.84x throughput improvement.", "url": "https://arxiv.org/abs/2307.01684"}, {"metadata": {"arXiv": "2307.01202", "Date": "Thu, 22 Jun 2023 13:21:20 ", "Title": "Predictive Patentomics: Forecasting Innovation Success and Valuation with ChatGPT", "Authors": ["Stephen Yang"], "Categories": "cs.LG cs.AI cs.CL cs.DL", "Comments": ["37 pages", "2 figures"]}, "abstract": "Analysis of innovation has been fundamentally limited by conventional approaches to broad, structural variables. This paper pushes the boundaries, taking an LLM approach to patent analysis with the groundbreaking ChatGPT technology. OpenAI's state-of-the-art textual embedding accesses complex information about the quality and impact of each invention to power deep learning predictive models. The nuanced embedding drives a 24% incremental improvement in R-squared predicting patent value and clearly isolates the worst and best applications. These models enable a revision of the contemporary Kogan, Papanikolaou, Seru, and Stoffman (2017) valuation of patents by a median deviation of 1.5 times, accounting for potential institutional predictions. Furthermore, the market fails to incorporate timely information about applications; a long-short portfolio based on predicted acceptance rates achieves significant abnormal returns of 3.3% annually. The models provide an opportunity to revolutionize startup and small-firm corporate policy vis-a-vis patenting.", "url": "https://arxiv.org/abs/2307.01202"}, {"metadata": {"arXiv": "2307.01217", "Date": "Sat, 01 Jul 2023 12:52:37 ", "Title": "FedCP: Separating Feature Information for Personalized Federated Learning via Conditional Policy", "Authors": ["Jianqing Zhang", "Yang Hua", "Hao Wang", "Tao Song", "Zhengui Xue", "Ruhui Ma", "and Haibing Guan"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by KDD 2023"], "DOI": "10.1145/3580305.3599345"}, "abstract": "Recently, personalized federated learning (pFL) has attracted increasing attention in privacy protection, collaborative learning, and tackling statistical heterogeneity among clients, e.g., hospitals, mobile smartphones, etc. Most existing pFL methods focus on exploiting the global information and personalized information in the client-level model parameters while neglecting that data is the source of these two kinds of information. To address this, we propose the Federated Conditional Policy (FedCP) method, which generates a conditional policy for each sample to separate the global information and personalized information in its features and then processes them by a global head and a personalized head, respectively. FedCP is more fine-grained to consider personalization in a sample-specific manner than existing pFL methods. Extensive experiments in computer vision and natural language processing domains show that FedCP outperforms eleven state-of-the-art methods by up to 6.69%. Furthermore, FedCP maintains its superiority when some clients accidentally drop out, which frequently happens in mobile settings. Our code is public at https://github.com/TsingZ0/FedCP.", "url": "https://arxiv.org/abs/2307.01217"}, {"metadata": {"arXiv": "2307.01226", "Date": "Mon, 03 Jul 2023 04:23:41 ", "Title": "vONTSS: vMF based semi-supervised neural topic modeling with optimal transport", "Authors": ["Weijie Xu", "Xiaoyu Jiang", "Srinivasan H. Sengamedu", "Francis Iannacci", "Jinjin Zhao"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["24 pages", "12 figures", "ACL findings 2023"], "Journal-ref": "ACL Findings 2023"}, "abstract": "Recently, Neural Topic Models (NTM), inspired by variational autoencoders, have attracted a lot of research interest; however, these methods have limited applications in the real world due to the challenge of incorporating human knowledge. This work presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport. When a few keywords per topic are provided, vONTSS in the semi-supervised setting generates potential topics and optimizes topic-keyword quality and topic classification. Experiments show that vONTSS outperforms existing semi-supervised topic modeling methods in classification accuracy and diversity. vONTSS also supports unsupervised topic modeling. Quantitative and qualitative experiments show that vONTSS in the unsupervised setting outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered and coherent topics on benchmark datasets. It is also much faster than the state-of-the-art weakly supervised text classification method while achieving similar classification performance. We further prove the equivalence of optimal transport loss and cross-entropy loss at the global minimum.", "url": "https://arxiv.org/abs/2307.01226"}, {"metadata": {"arXiv": "2307.01227", "Date": "Mon, 03 Jul 2023 04:47:42 ", "Title": "ESGCN: Edge Squeeze Attention Graph Convolutional Network for Traffic Flow Forecasting", "Authors": ["Sangrok Lee"], "Categories": "cs.LG cs.AI", "Comments": ["7 Pages", "3 figures"]}, "abstract": "Traffic forecasting is a highly challenging task owing to the dynamical spatio-temporal dependencies of traffic flows. To handle this, we focus on modeling the spatio-temporal dynamics and propose a network termed Edge Squeeze Graph Convolutional Network (ESGCN) to forecast traffic flow in multiple regions. ESGCN consists of two modules: W-module and ES module. W-module is a fully node-wise convolutional network. It encodes the time-series of each traffic region separately and decomposes the time-series at various scales to capture fine and coarse features. The ES module models the spatio-temporal dynamics using Graph Convolutional Network (GCN) and generates an Adaptive Adjacency Matrix (AAM) with temporal features. To improve the accuracy of AAM, we introduce three key concepts. 1) Using edge features to directly capture the spatiotemporal flow representation among regions. 2) Applying an edge attention mechanism to GCN to extract the AAM from the edge features. Here, the attention mechanism can effectively determine important spatio-temporal adjacency relations. 3) Proposing a novel node contrastive loss to suppress obstructed connections and emphasize related connections. Experimental results show that ESGCN achieves state-of-the-art performance by a large margin on four real-world datasets (PEMS03, 04, 07, and 08) with a low computational cost.", "url": "https://arxiv.org/abs/2307.01227"}, {"metadata": {"arXiv": "2307.01234", "Date": "Mon, 03 Jul 2023 09:30:20 ", "Title": "Internet of Things Fault Detection and Classification via Multitask Learning", "Authors": ["Mohammad Arif Ul Alam"], "Categories": "cs.LG cs.AI", "Comments": ["Under Review", "International Conference on Embedded Wireless Systems and Networks (EWSN) 2023"]}, "abstract": "This paper presents a comprehensive investigation into developing a fault detection and classification system for real-world IIoT applications. The study addresses challenges in data collection, annotation, algorithm development, and deployment. Using a real-world IIoT system, three phases of data collection simulate 11 predefined fault categories. We propose SMTCNN for fault detection and category classification in IIoT, evaluating its performance on real-world data. SMTCNN achieves superior specificity (3.5%) and shows significant improvements in precision, recall, and F1 measures compared to existing techniques.", "url": "https://arxiv.org/abs/2307.01234"}, {"metadata": {"arXiv": "2307.01238", "Date": "Mon, 03 Jul 2023 12:22:04 ", "Title": "Learning Difference Equations with Structured Grammatical Evolution for Postprandial Glycaemia Prediction", "Authors": ["Daniel Parra", "David Joedicke", "J. Manuel Velasco", "Gabriel Kronberger", "J. Ignacio Hidalgo"], "Categories": "cs.LG cs.AI"}, "abstract": "People with diabetes must carefully monitor their blood glucose levels, especially after eating. Blood glucose regulation requires a proper combination of food intake and insulin boluses. Glucose prediction is vital to avoid dangerous post-meal complications in treating individuals with diabetes. Although traditional methods, such as artificial neural networks, have shown high accuracy rates, sometimes they are not suitable for developing personalised treatments by physicians due to their lack of interpretability. In this study, we propose a novel glucose prediction method emphasising interpretability: Interpretable Sparse Identification by Grammatical Evolution. Combined with a previous clustering stage, our approach provides finite difference equations to predict postprandial glucose levels up to two hours after meals. We divide the dataset into four-hour segments and perform clustering based on blood glucose values for the twohour window before the meal. Prediction models are trained for each cluster for the two-hour windows after meals, allowing predictions in 15-minute steps, yielding up to eight predictions at different time horizons. Prediction safety was evaluated based on Parkes Error Grid regions. Our technique produces safe predictions through explainable expressions, avoiding zones D (0.2% average) and E (0%) and reducing predictions on zone C (6.2%). In addition, our proposal has slightly better accuracy than other techniques, including sparse identification of non-linear dynamics and artificial neural networks. The results demonstrate that our proposal provides interpretable solutions without sacrificing prediction accuracy, offering a promising approach to glucose prediction in diabetes management that balances accuracy, interpretability, and computational efficiency.", "url": "https://arxiv.org/abs/2307.01238"}, {"metadata": {"arXiv": "2307.01288", "Date": "Mon, 03 Jul 2023 18:32:50 ", "Title": "Fighting the disagreement in Explainable Machine Learning with consensus", "Authors": ["Antonio Jesus Banegas-Luna", "Carlos Mart{\\i}nez-Cortes", "Horacio Perez-Sanchez"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "7 figures"]}, "abstract": "Machine learning (ML) models are often valued by the accuracy of their predictions. However, in some areas of science, the inner workings of models are as relevant as their accuracy. To understand how ML models work internally, the use of interpretability algorithms is the preferred option. Unfortunately, despite the diversity of algorithms available, they often disagree in explaining a model, leading to contradictory explanations. To cope with this issue, consensus functions can be applied once the models have been explained. Nevertheless, the problem is not completely solved because the final result will depend on the selected consensus function and other factors. In this paper, six consensus functions have been evaluated for the explanation of five ML models. The models were previously trained on four synthetic datasets whose internal rules were known in advance. The models were then explained with model-agnostic local and global interpretability algorithms. Finally, consensus was calculated with six different functions, including one developed by the authors. The results demonstrated that the proposed function is fairer than the others and provides more consistent and accurate explanations.", "url": "https://arxiv.org/abs/2307.01288"}, {"metadata": {"arXiv": "2307.01452", "Date": "Tue, 04 Jul 2023 03:00:43 ", "Title": "Causal Reinforcement Learning: A Survey", "Authors": ["Zhihong Deng", "Jing Jiang", "Guodong Long", "Chengqi Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["48 pages", "10 figures"]}, "abstract": "Reinforcement learning is an essential paradigm for solving sequential decision problems under uncertainty. Despite many remarkable achievements in recent decades, applying reinforcement learning methods in the real world remains challenging. One of the main obstacles is that reinforcement learning agents lack a fundamental understanding of the world and must therefore learn from scratch through numerous trial-and-error interactions. They may also face challenges in providing explanations for their decisions and generalizing the acquired knowledge. Causality, however, offers a notable advantage as it can formalize knowledge in a systematic manner and leverage invariance for effective knowledge transfer. This has led to the emergence of causal reinforcement learning, a subfield of reinforcement learning that seeks to enhance existing algorithms by incorporating causal relationships into the learning process. In this survey, we comprehensively review the literature on causal reinforcement learning. We first introduce the basic concepts of causality and reinforcement learning, and then explain how causality can address core challenges in non-causal reinforcement learning. We categorize and systematically review existing causal reinforcement learning approaches based on their target problems and methodologies. Finally, we outline open issues and future directions in this emerging field.", "url": "https://arxiv.org/abs/2307.01452"}, {"metadata": {"arXiv": "2307.01519", "Date": "Tue, 04 Jul 2023 07:00:19 ", "Title": "Deep Attention Q-Network for Personalized Treatment Recommendation", "Authors": ["Simin Ma", "Junghwan Lee", "Nicoleta Serban", "Shihao Yang"], "Categories": "cs.LG cs.AI"}, "abstract": "Tailoring treatment for individual patients is crucial yet challenging in order to achieve optimal healthcare outcomes. Recent advances in reinforcement learning offer promising personalized treatment recommendations; however, they rely solely on current patient observations (vital signs, demographics) as the patient's state, which may not accurately represent the true health status of the patient. This limitation hampers policy learning and evaluation, ultimately limiting treatment effectiveness. In this study, we propose the Deep Attention Q-Network for personalized treatment recommendations, utilizing the Transformer architecture within a deep reinforcement learning framework to efficiently incorporate all past patient observations. We evaluated the model on real-world sepsis and acute hypotension cohorts, demonstrating its superiority to state-of-the-art models. The source code for our model is available at https://github.com/stevenmsm/RL-ICU-DAQN.", "url": "https://arxiv.org/abs/2307.01519"}, {"metadata": {"arXiv": "2307.01558", "Date": "Tue, 04 Jul 2023 08:22:05 ", "Title": "Scalable variable selection for two-view learning tasks with projection operators", "Authors": ["Sandor Szedmak (1)", "Riikka Huusari (1)", "Tat Hong Duong Le (1)", "Juho Rousu (1) ((1) Department of Computer Science", "Aalto University", "Espoo", "Finland)"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages", "15 PDF figures"]}, "abstract": "In this paper we propose a novel variable selection method for two-view settings, or for vector-valued supervised learning problems. Our framework is able to handle extremely large scale selection tasks, where number of data samples could be even millions. In a nutshell, our method performs variable selection by iteratively selecting variables that are highly correlated with the output variables, but which are not correlated with the previously chosen variables. To measure the correlation, our method uses the concept of projection operators and their algebra. With the projection operators the relationship, correlation, between sets of input and output variables can also be expressed by kernel functions, thus nonlinear correlation models can be exploited as well. We experimentally validate our approach, showing on both synthetic and real data its scalability and the relevance of the selected features. Keywords: Supervised variable selection, vector-valued learning, projection-valued measure, reproducing kernel Hilbert space", "url": "https://arxiv.org/abs/2307.01558"}, {"metadata": {"arXiv": "2307.01578", "Date": "Tue, 04 Jul 2023 09:11:33 ", "Title": "Optimal and Efficient Binary Questioning for Human-in-the-Loop Annotation", "Authors": ["Franco Marchesoni-Acland", "Jean-Michel Morel", "Josselin Kherroubi", "Gabriele Facciolo"], "Categories": "cs.LG cs.AI cs.CV cs.HC cs.IT math.IT", "Comments": ["8 pages + references + appendix"]}, "abstract": "Even though data annotation is extremely important for interpretability, research and development of artificial intelligence solutions, most research efforts such as active learning or few-shot learning focus on the sample efficiency problem. This paper studies the neglected complementary problem of getting annotated data given a predictor. For the simple binary classification setting, we present the spectrum ranging from optimal general solutions to practical efficient methods. The problem is framed as the full annotation of a binary classification dataset with the minimal number of yes/no questions when a predictor is available. For the case of general binary questions the solution is found in coding theory, where the optimal questioning strategy is given by the Huffman encoding of the possible labelings. However, this approach is computationally intractable even for small dataset sizes. We propose an alternative practical solution based on several heuristics and lookahead minimization of proxy cost functions. The proposed solution is analysed, compared with optimal solutions and evaluated on several synthetic and real-world datasets. On these datasets, the method allows a significant improvement ($23-86\\%$) in annotation efficiency.", "url": "https://arxiv.org/abs/2307.01578"}, {"metadata": {"arXiv": "2307.01597", "Date": "Tue, 04 Jul 2023 09:38:38 ", "Title": "Bridge the Performance Gap in Peak-hour Series Forecasting: The Seq2Peak Framework", "Authors": ["Zhenwei Zhang", "Xin Wang", "Jingyuan Xie", "Heling Zhang", "Yuantao Gu"], "Categories": "cs.LG cs.AI"}, "abstract": "Peak-Hour Series Forecasting (PHSF) is a crucial yet underexplored task in various domains. While state-of-the-art deep learning models excel in regular Time Series Forecasting (TSF), they struggle to achieve comparable results in PHSF. This can be attributed to the challenges posed by the high degree of non-stationarity in peak-hour series, which makes direct forecasting more difficult than standard TSF. Additionally, manually extracting the maximum value from regular forecasting results leads to suboptimal performance due to models minimizing the mean deficit. To address these issues, this paper presents Seq2Peak, a novel framework designed specifically for PHSF tasks, bridging the performance gap observed in TSF models. Seq2Peak offers two key components: the CyclicNorm pipeline to mitigate the non-stationarity issue, and a simple yet effective trainable-parameter-free peak-hour decoder with a hybrid loss function that utilizes both the original series and peak-hour series as supervised signals. Extensive experimentation on publicly available time series datasets demonstrates the effectiveness of the proposed framework, yielding a remarkable average relative improvement of 37.7\\% across four real-world datasets for both transformer- and non-transformer-based TSF models.", "url": "https://arxiv.org/abs/2307.01597"}, {"metadata": {"arXiv": "2307.01616", "Date": "Tue, 04 Jul 2023 10:08:25 ", "Title": "SageFormer: Series-Aware Graph-Enhanced Transformers for Multivariate Time Series Forecasting", "Authors": ["Zhenwei Zhang", "Xin Wang", "Yuantao Gu"], "Categories": "cs.LG cs.AI"}, "abstract": "Multivariate time series forecasting plays a critical role in diverse domains. While recent advancements in deep learning methods, especially Transformers, have shown promise, there remains a gap in addressing the significance of inter-series dependencies. This paper introduces SageFormer, a Series-aware Graph-enhanced Transformer model designed to effectively capture and model dependencies between series using graph structures. SageFormer tackles two key challenges: effectively representing diverse temporal patterns across series and mitigating redundant information among series. Importantly, the proposed series-aware framework seamlessly integrates with existing Transformer-based models, augmenting their ability to model inter-series dependencies. Through extensive experiments on real-world and synthetic datasets, we showcase the superior performance of SageFormer compared to previous state-of-the-art approaches.", "url": "https://arxiv.org/abs/2307.01616"}, {"metadata": {"arXiv": "2307.01646", "Date": "Tue, 04 Jul 2023 10:58:42 ", "Title": "SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation", "Authors": ["Qi Yan", "Zhengyang Liang", "Yang Song", "Renjie Liao", "Lele Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Diffusion models based on permutation-equivariant networks can learn permutation-invariant distributions for graph data. However, in comparison to their non-invariant counterparts, we have found that these invariant models encounter greater learning challenges since 1) their effective target distributions exhibit more modes; 2) their optimal one-step denoising scores are the score functions of Gaussian mixtures with more components. Motivated by this analysis, we propose a non-invariant diffusion model, called $\\textit{SwinGNN}$, which employs an efficient edge-to-edge 2-WL message passing network and utilizes shifted window based self-attention inspired by SwinTransformers. Further, through systematic ablations, we identify several critical training and sampling techniques that significantly improve the sample quality of graph generation. At last, we introduce a simple post-processing trick, $\\textit{i.e.}$, randomly permuting the generated graphs, which provably converts any graph generative model to a permutation-invariant one. Extensive experiments on synthetic and real-world protein and molecule datasets show that our SwinGNN achieves state-of-the-art performances. Our code is released at https://github.com/qiyan98/SwinGNN .", "url": "https://arxiv.org/abs/2307.01646"}, {"metadata": {"arXiv": "2307.01683", "Date": "Tue, 04 Jul 2023 12:27:10 ", "Title": "Learning Discrete Weights and Activations Using the Local Reparameterization Trick", "Authors": ["Guy Berger", "Aviv Navon", "Ethan Fetaya"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In computer vision and machine learning, a crucial challenge is to lower the computation and memory demands for neural network inference. A commonplace solution to address this challenge is through the use of binarization. By binarizing the network weights and activations, one can significantly reduce computational complexity by substituting the computationally expensive floating operations with faster bitwise operations. This leads to a more efficient neural network inference that can be deployed on low-resource devices. In this work, we extend previous approaches that trained networks with discrete weights using the local reparameterization trick to also allow for discrete activations. The original approach optimized a distribution over the discrete weights and uses the central limit theorem to approximate the pre-activation with a continuous Gaussian distribution. Here we show that the probabilistic modeling can also allow effective training of networks with discrete activation as well. This further reduces runtime and memory footprint at inference time with state-of-the-art results for networks with binary activations.", "url": "https://arxiv.org/abs/2307.01683"}, {"metadata": {"arXiv": "2307.01689", "Date": "Tue, 04 Jul 2023 12:51:21 ", "Title": "Online Learning and Solving Infinite Games with an ERM Oracle", "Authors": ["Angelos Assos", "Idan Attias", "Yuval Dagan", "Constantinos Daskalakis", "Maxwell Fishelson"], "Categories": "cs.LG cs.AI cs.GT stat.ML", "Comments": ["In COLT2023"]}, "abstract": "While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class. We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in two-player zero-sum games and approximate coarse correlated equilibria in multi-player general-sum games, as long as the game has a bounded fat-threshold dimension. Our algorithms apply to both binary-valued and real-valued games and can be viewed as providing justification for the wide use of double oracle and multiple oracle algorithms in the practice of solving large games.", "url": "https://arxiv.org/abs/2307.01689"}, {"metadata": {"arXiv": "2307.01708", "Date": "Tue, 04 Jul 2023 13:23:21 ", "Title": "Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning", "Authors": ["Tyler Kastner", "Murat A. Erdogdu", "Amir-massoud Farahmand"], "Categories": "cs.LG cs.AI"}, "abstract": "We consider the problem of learning models for risk-sensitive reinforcement learning. We theoretically demonstrate that proper value equivalence, a method of learning models which can be used to plan optimally in the risk-neutral setting, is not sufficient to plan optimally in the risk-sensitive setting. We leverage distributional reinforcement learning to introduce two new notions of model equivalence, one which is general and can be used to plan for any risk measure, but is intractable; and a practical variation which allows one to choose which risk measures they may plan optimally for. We demonstrate how our framework can be used to augment any model-free risk-sensitive algorithm, and provide both tabular and large-scale experiments to demonstrate its ability.", "url": "https://arxiv.org/abs/2307.01708"}, {"metadata": {"arXiv": "2307.01717", "Date": "Tue, 04 Jul 2023 13:43:05 ", "Title": "On the Constrained Time-Series Generation Problem", "Authors": ["Andrea Coletta", "Sriram Gopalakrishan", "Daniel Borrajo", "Svitlana Vyetrenko"], "Categories": "cs.LG cs.AI"}, "abstract": "Synthetic time series are often used in practical applications to augment the historical time series dataset for better performance of machine learning algorithms, amplify the occurrence of rare events, and also create counterfactual scenarios described by the time series. Distributional-similarity (which we refer to as realism) as well as the satisfaction of certain numerical constraints are common requirements in counterfactual time series scenario generation requests. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessions. Existing approaches for generating constrained time series usually penalize training loss to enforce constraints, and reject non-conforming samples. However, these approaches would require re-training if we change constraints, and rejection sampling can be computationally expensive, or impractical for complex constraints. In this paper, we propose a novel set of methods to tackle the constrained time series generation problem and provide efficient sampling while ensuring the realism of generated time series. In particular, we frame the problem using a constrained optimization framework and then we propose a set of generative methods including ``GuidedDiffTime'', a guided diffusion model to generate realistic time series. Empirically, we evaluate our work on several datasets for financial and energy data, where incorporating constraints is critical. We show that our approaches outperform existing work both qualitatively and quantitatively. Most importantly, we show that our ``GuidedDiffTime'' model is the only solution where re-training is not necessary for new constraints, resulting in a significant carbon footprint reduction.", "url": "https://arxiv.org/abs/2307.01717"}, {"metadata": {"arXiv": "2307.01850", "Date": "Tue, 04 Jul 2023 17:59:31 ", "Title": "Self-Consuming Generative Models Go MAD", "Authors": ["Sina Alemohammad", "Josue Casco-Rodriguez", "Lorenzo Luzi", "Ahmed Imtiaz Humayun", "Hossein Babaei", "Daniel LeJeune", "Ali Siahkoohi", "Richard G. Baraniuk"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["31 pages", "31 figures", "pre-print"]}, "abstract": "Seismic advances in generative AI algorithms for imagery, text, and other data types has led to the temptation to use synthetic data to train next-generation models. Repeating this process creates an autophagous (self-consuming) loop whose properties are poorly understood. We conduct a thorough analytical and empirical analysis using state-of-the-art generative image models of three families of autophagous loops that differ in how fixed or fresh real training data is available through the generations of training and in whether the samples from previous generation models have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD), making analogy to mad cow disease.", "url": "https://arxiv.org/abs/2307.01850"}, {"metadata": {"arXiv": "2307.01909", "Date": "Tue, 04 Jul 2023 20:36:01 ", "Title": "ClimateLearn: Benchmarking Machine Learning for Weather and Climate Modeling", "Authors": ["Tung Nguyen", "Jason Jewik", "Hritik Bansal", "Prakhar Sharma", "Aditya Grover"], "Categories": "cs.LG cs.AI"}, "abstract": "Modeling weather and climate is an essential endeavor to understand the near- and long-term impacts of climate change, as well as inform technology and policymaking for adaptation and mitigation efforts. In recent years, there has been a surging interest in applying data-driven methods based on machine learning for solving core problems such as weather forecasting and climate downscaling. Despite promising results, much of this progress has been impaired due to the lack of large-scale, open-source efforts for reproducibility, resulting in the use of inconsistent or underspecified datasets, training setups, and evaluations by both domain scientists and artificial intelligence researchers. We introduce ClimateLearn, an open-source PyTorch library that vastly simplifies the training and evaluation of machine learning models for data-driven climate science. ClimateLearn consists of holistic pipelines for dataset processing (e.g., ERA5, CMIP6, PRISM), implementation of state-of-the-art deep learning models (e.g., Transformers, ResNets), and quantitative and qualitative evaluation for standard weather and climate modeling tasks. We supplement these functionalities with extensive documentation, contribution guides, and quickstart tutorials to expand access and promote community growth. We have also performed comprehensive forecasting and downscaling experiments to showcase the capabilities and key features of our library. To our knowledge, ClimateLearn is the first large-scale, open-source effort for bridging research in weather and climate modeling with modern machine learning systems. Our library is available publicly at https://github.com/aditya-grover/climate-learn.", "url": "https://arxiv.org/abs/2307.01909"}, {"metadata": {"arXiv": "2307.01930", "Date": "Tue, 04 Jul 2023 21:35:49 ", "Title": "Learning ECG signal features without backpropagation", "Authors": ["P\\'eter P\\'osfay", "Marcell T. Kurbucz", "P\\'eter Kov\\'acs", "Antal Jakov\\'ac"], "Categories": "cs.LG cs.AI cs.CV stat.AP stat.ML", "Comments": ["28 pages", "1 figure", "1 table"], "MSC-class": "62H30, 68T10, 62M10, 92C50", "ACM-class": "J.3; I.5; I.2.0; G.3"}, "abstract": "Representation learning has become a crucial area of research in machine learning, as it aims to discover efficient ways of representing raw data with useful features to increase the effectiveness, scope and applicability of downstream tasks such as classification and prediction. In this paper, we propose a novel method to generate representations for time series-type data. This method relies on ideas from theoretical physics to construct a compact representation in a data-driven way, and it can capture both the underlying structure of the data and task-specific information while still remaining intuitive, interpretable and verifiable. This novel methodology aims to identify linear laws that can effectively capture a shared characteristic among samples belonging to a specific class. By subsequently utilizing these laws to generate a classifier-agnostic representation in a forward manner, they become applicable in a generalized setting. We demonstrate the effectiveness of our approach on the task of ECG signal classification, achieving state-of-the-art performance.", "url": "https://arxiv.org/abs/2307.01930"}, {"metadata": {"arXiv": "2307.01951", "Date": "Tue, 04 Jul 2023 23:03:21 ", "Title": "A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks", "Authors": ["Vignesh Kothapalli", "Tom Tirer", "Joan Bruna"], "Categories": "cs.LG cs.AI cs.IT math.IT math.OC stat.ML", "Comments": ["55 pages", "34 figures"]}, "abstract": "Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the \"Neural Collapse\" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an \"optimistic\" mathematical model requires that the graphs obey a strict structural condition in order to possess a minimizer with exact collapse. Interestingly, this condition is viable also for heterophilic graphs and relates to recent empirical studies on settings with improved GNNs' generalization. Furthermore, by studying the gradient dynamics of the theoretical model, we provide reasoning for the partial collapse observed empirically. Finally, we present a study on the evolution of within- and between-class feature variability across layers of a well-trained GNN and contrast the behavior with spectral methods.", "url": "https://arxiv.org/abs/2307.01951"}, {"metadata": {"arXiv": "2307.02028", "Date": "Wed, 05 Jul 2023 05:24:59 ", "Title": "EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models", "Authors": ["Michael Wornow", "Rahul Thapa", "Ethan Steinberg", "Jason Fries", "Nigam Shah"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, containing de-identified structured data from the electronic health records (EHRs) of 6,712 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaption. The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som-shahlab/ehrshot-benchmark", "url": "https://arxiv.org/abs/2307.02028"}, {"metadata": {"arXiv": "2307.02040", "Date": "Wed, 05 Jul 2023 05:55:08 ", "Title": "VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks", "Authors": ["Zhaomin Wu", "Junyi Hou", "Bingsheng He"], "Categories": "cs.LG cs.AI"}, "abstract": "Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on feature-partitioned, distributed data. However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions. Existing benchmarks often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a subset of feature distributions, leading to inadequate algorithm performance assessment. This paper addresses these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature correlation - and proposing associated evaluation metrics and dataset splitting methods. Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios. Our comprehensive evaluation of cutting-edge VFL algorithms provides valuable insights for future research in the field.", "url": "https://arxiv.org/abs/2307.02040"}, {"metadata": {"arXiv": "2307.02071", "Date": "Wed, 05 Jul 2023 07:26:27 ", "Title": "A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables", "Authors": ["Fabio Sigrist"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.", "url": "https://arxiv.org/abs/2307.02071"}, {"metadata": {"arXiv": "2307.02073", "Date": "Wed, 05 Jul 2023 07:30:53 ", "Title": "Performance Modeling of Data Storage Systems using Generative Models", "Authors": ["Abdalaziz Rashid Al-Maeeni", "Aziz Temirkhanov", "Artem Ryzhikov", "Mikhail Hushchyn"], "Categories": "cs.LG cs.AI cs.PF"}, "abstract": "High-precision modeling of systems is one of the main areas of industrial data analysis. Models of systems, their digital twins, are used to predict their behavior under various conditions. We have developed several models of a storage system using machine learning-based generative models. The system consists of several components: hard disk drive (HDD) and solid-state drive (SSD) storage pools with different RAID schemes and cache. Each storage component is represented by a probabilistic model that describes the probability distribution of the component performance in terms of IOPS and latency, depending on their configuration and external data load parameters. The results of the experiments demonstrate the errors of 4-10 % for IOPS and 3-16 % for latency predictions depending on the components and models of the system. The predictions show up to 0.99 Pearson correlation with Little's law, which can be used for unsupervised reliability checks of the models. In addition, we present novel data sets that can be used for benchmarking regression algorithms, conditional generative models, and uncertainty estimation methods in machine learning.", "url": "https://arxiv.org/abs/2307.02073"}, {"metadata": {"arXiv": "2307.02094", "Date": "Wed, 05 Jul 2023 08:11:40 ", "Title": "DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications", "Authors": ["Adam Ivankay", "Mattia Rigotti", "Pascal Frossard"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at 61st Annual Meeting of the Association for Computational Linguistics (ACL) 2023"]}, "abstract": "Along with the successful deployment of deep neural networks in several application domains, the need to unravel the black-box nature of these networks has seen a significant increase recently. Several methods have been introduced to provide insight into the inference process of deep neural networks. However, most of these explainability methods have been shown to be brittle in the face of adversarial perturbations of their inputs in the image and generic textual domain. In this work we show that this phenomenon extends to specific and important high stakes domains like biomedical datasets. In particular, we observe that the robustness of explanations should be characterized in terms of the accuracy of the explanation in linking a model's inputs and its decisions - faithfulness - and its relevance from the perspective of domain experts - plausibility. This is crucial to prevent explanations that are inaccurate but still look convincing in the context of the domain at hand. To this end, we show how to adapt current attribution robustness estimation methods to a given domain, so as to take into account domain-specific plausibility. This results in our DomainAdaptiveAREstimator (DARE) attribution robustness estimator, allowing us to properly characterize the domain-specific robustness of faithful explanations. Next, we provide two methods, adversarial training and FAR training, to mitigate the brittleness characterized by DARE, allowing us to train networks that display robust attributions. Finally, we empirically validate our methods with extensive experiments on three established biomedical benchmarks.", "url": "https://arxiv.org/abs/2307.02094"}, {"metadata": {"arXiv": "2307.02202", "Date": "Wed, 05 Jul 2023 10:53:49 ", "Title": "On the Adversarial Robustness of Generative Autoencoders in the Latent Space", "Authors": ["Mingfei Lu and Badong Chen"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["18 pages", "12 figures"]}, "abstract": "The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation, and signal communication. However, little concern has been devoted to their robustness during practical deployment. Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent. This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing. In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space. Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space. We also evaluate the difference between variational autoencoders and their deterministic variants and observe that the latter performs better in latent robustness. Meanwhile, we identify a potential trade-off between the adversarial robustness and the degree of the disentanglement of the latent codes. Additionally, we also verify the feasibility of improvement for the latent robustness of VAEs through adversarial training. In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges.", "url": "https://arxiv.org/abs/2307.02202"}, {"metadata": {"arXiv": "2307.02276", "Date": "Wed, 05 Jul 2023 13:20:21 ", "Title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration", "Authors": ["Ben Norman", "Jeff Clune"], "Categories": "cs.LG cs.AI"}, "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like a human (i.e. by taking into account complex domain priors and previous explorations). Even the most basic intelligent exploration strategies such as exhaustive search are only inefficiently or poorly approximated by approaches such as novelty search or intrinsic motivation, let alone more complicated strategies like learning new skills, climbing stairs, opening doors, or conducting experiments. This lack of intelligent exploration limits sample efficiency and prevents solving hard exploration domains. We argue a core barrier prohibiting many RL approaches from learning intelligent exploration is that the methods attempt to explore and exploit simultaneously, which harms both exploration and exploitation as the goals often conflict. We propose a novel meta-RL framework (First-Explore) with two policies: one policy learns to only explore and one policy learns to only exploit. Once trained, we can then explore with the explore policy, for as long as desired, and then exploit based on all the information gained during exploration. This approach avoids the conflict of trying to do both exploration and exploitation at once. We demonstrate that First-Explore can learn intelligent exploration strategies such as exhaustive search and more, and that it outperforms dominant standard RL and meta-RL approaches on domains where exploration requires sacrificing reward. First-Explore is a significant step towards creating meta-RL algorithms capable of learning human-level exploration which is essential to solve challenging unseen hard-exploration domains.", "url": "https://arxiv.org/abs/2307.02276"}, {"metadata": {"arXiv": "2307.02295", "Date": "Wed, 05 Jul 2023 13:52:10 ", "Title": "Meta-Learning Adversarial Bandit Algorithms", "Authors": ["Mikhail Khodak", "Ilya Osadchiy", "Keegan Harris", "Maria-Florina Balcan", "Kfir Y. Levy", "Ron Meir", "Zhiwei Steven Wu"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Merger of arXiv:2205.14128 and arXiv:2205.15921", "with some additional improvements"]}, "abstract": "We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on proving that unregularized follow-the-leader combined with two levels of low-dimensional hyperparameter tuning is enough to learn a sequence of affine functions of non-Lipschitz and sometimes non-convex Bregman divergences bounding the regret of OMD.", "url": "https://arxiv.org/abs/2307.02295"}, {"metadata": {"arXiv": "2307.02318", "Date": "Wed, 05 Jul 2023 14:20:20 ", "Title": "Deep Contract Design via Discontinuous Piecewise Affine Neural Networks", "Authors": ["Tonghan Wang", "Paul D\\\"utting", "Dmitry Ivanov", "Inbal Talgam-Cohen", "David C. Parkes"], "Categories": "cs.LG cs.AI"}, "abstract": "Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent. In this paper, we initiate the study of deep learning for the automated design of optimal contracts. We formulate this as an offline learning problem, where a deep network is used to represent the principal's expected utility as a function of the design of a contract. We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal's utility as a discontinuous piecewise affine function where each piece corresponds to the agent taking a particular action. DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts. We provide empirical results that demonstrate success in approximating the principal's utility function with a small number of training samples and scaling to find approximately optimal contracts on problems with a large number of actions and outcomes.", "url": "https://arxiv.org/abs/2307.02318"}, {"metadata": {"arXiv": "2307.02345", "Date": "Wed, 05 Jul 2023 15:00:29 ", "Title": "LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning", "Authors": ["Outongyi Lv", "Bingxin Zhou", "Yu Guang Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Currently, research on Reinforcement learning (RL) can be broadly classified into two categories: online RL and offline RL. Both in online and offline RL, the primary focus of research on the Bellman error lies in the optimization techniques and performance improvement, rather than exploring the inherent structural properties of the Bellman error, such as distribution characteristics. In this study, we analyze the distribution of the Bellman approximation error in both online and offline settings. We find that in the online environment, the Bellman error follows a Logistic distribution, while in the offline environment, the Bellman error follows a constrained Logistic distribution, where the constrained distribution is dependent on the prior policy in the offline data set. Based on this finding, we have improved the MSELoss which is based on the assumption that the Bellman errors follow a normal distribution, and we utilized the Logistic maximum likelihood function to construct $\\rm LLoss$ as an alternative loss function. In addition, we observed that the rewards in the offline data set should follow a specific distribution, which would facilitate the achievement of offline objectives. In our numerical experiments, we performed controlled variable corrections on the loss functions of two variants of Soft-Actor-Critic in both online and offline environments. The results confirmed our hypothesis regarding the online and offline settings, we also found that the variance of LLoss is smaller than MSELoss. Our research provides valuable insights for further investigations based on the distribution of Bellman errors.", "url": "https://arxiv.org/abs/2307.02345"}, {"metadata": {"arXiv": "2307.02460", "Date": "Wed, 05 Jul 2023 17:33:41 ", "Title": "Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources", "Authors": ["Feiyang Kang", "Hoang Anh Just", "Anit Kumar Sahu", "Ruoxi Jia"], "Categories": "cs.LG cs.AI cs.CE cs.CV", "Comments": ["An extended abstract of this work appears in Data-centric Machine Learning Research (DMLR) Workshop at 40th International Conference on Machine Learning", "Honolulu HI", "USA. July 29", "2023"]}, "abstract": "Traditionally, data selection has been studied in settings where all samples from prospective sources are fully revealed to a machine learning developer. However, in practical data exchange scenarios, data providers often reveal only a limited subset of samples before an acquisition decision is made. Recently, there have been efforts to fit scaling laws that predict model performance at any size and data source composition using the limited available samples. However, these scaling functions are black-box, computationally expensive to fit, highly susceptible to overfitting, or/and difficult to optimize for data selection. This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources. Our approach distinguishes itself from existing work by introducing a novel *two-stage* performance inference process. In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes. In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws. We further derive an efficient gradient-based method to select data sources based on the projected model performance. Evaluation over a diverse range of applications demonstrates that <projektor> significantly improves existing performance scaling approaches in terms of both the accuracy of performance inference and the computation costs associated with constructing the performance predictor. Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions.", "url": "https://arxiv.org/abs/2307.02460"}, {"metadata": {"arXiv": "2307.02484", "Date": "Wed, 05 Jul 2023 17:58:21 ", "Title": "Elastic Decision Transformer", "Authors": ["Yueh-Hua Wu", "Xiaolong Wang", "Masashi Hamaya"], "Categories": "cs.LG cs.AI", "Comments": ["https://kristery.github.io/edt/"]}, "abstract": "This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to \"stitch\" with a more optimal trajectory. Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games. Videos are available at: https://kristery.github.io/edt/", "url": "https://arxiv.org/abs/2307.02484"}, {"metadata": {"arXiv": "2307.01316", "Date": "Mon, 03 Jul 2023 19:43:21 ", "Title": "Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach", "Authors": ["Iman Sharifi", "Mustafa Yildirim", "Saber Fallah"], "Categories": "cs.RO cs.AI cs.LG cs.LO cs.SY eess.SY", "Comments": ["15 pages", "9 figures", "1 table", "1 algorithm. Under review as a journal paper at IEEE transactions on Intelligent Transportation Systems"]}, "abstract": "The dynamic nature of driving environments and the presence of diverse road users pose significant challenges for decision-making in autonomous driving. Deep reinforcement learning (DRL) has emerged as a popular approach to tackle this problem. However, the application of existing DRL solutions is mainly confined to simulated environments due to safety concerns, impeding their deployment in real-world. To overcome this limitation, this paper introduces a novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics (DRLSL) that combines the strengths of DRL (learning from experience) and symbolic first-order logics knowledge-driven reasoning) to enable safe learning in real-time interactions of autonomous driving within real environments. This innovative approach provides a means to learn autonomous driving policies by actively engaging with the physical environment while ensuring safety. We have implemented the DRLSL framework in autonomous driving using the highD dataset and demonstrated that our method successfully avoids unsafe actions during both the training and testing phases. Furthermore, our results indicate that DRLSL achieves faster convergence during training and exhibits better generalizability to new driving scenarios compared to traditional DRL methods.", "url": "https://arxiv.org/abs/2307.01316"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.12041", "Date": "Fri, 17 Nov 2023 15:22:20 ", "Title": "Automated Detection of hidden Damages and Impurities in Aluminum Die Casting Materials and Fibre-Metal Laminates using Low-quality X-ray Radiography, Synthetic X-ray Data Augmentation by Simulation, and Machine Learning", "Authors": ["Stefan Bosse and Dirk Lehmhus"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["This report summarizes the work presented on the FEMS EUROMAT Conference", "5-7.9.2023", "Frankfurt (M.)", "Germany", "and the DGM AI-MSE Workshop", "22-23.11.2023", "Saarbr\\\"ucken", "Germany"]}, "abstract": "Detection and characterization of hidden defects, impurities, and damages in layered composites like Fibre laminates, e.g., Fibre Metal Laminates (FML), as well as in monolithic materials, e.g., aluminum die casting materials, is still a challenge. This work discusses methods and challenges in data-driven modeling of automated damage and defect detectors using X-ray single- and multi-projection (CT) images. Three main issues are identified: Data and feature variance, data feature labeling (for supervised machine learning), and the missing ground truth. It will be shown that only simulation of data can deliver a ground truth data set and accurate labeling. Noise has significant impact on the feature detection and will be discussed. Data-driven feature detectors are implemented with semantic pixel- or z-profile Convolutional Neural Networks and LSTM Auto-encoders. Data is measured with three different devices: A low-quality and low-cost (Low-Q), a mid- and a high-quality (micro-CT, Mid-/High-Q) device. The goals of this work are the training of robust and generalized feature detectors with synthetic data and the transition from High- and Mid-Q laboratory measuring technologies towards in-field usable technologies and methods.", "url": "https://arxiv.org/abs/2311.12041"}, {"metadata": {"arXiv": "2311.12476", "Date": "Tue, 21 Nov 2023 09:37:49 ", "Title": "MaskFlow: Object-Aware Motion Estimation", "Authors": ["Aria Ahmadi", "David R. Walton", "Tim Atherton", "Cagatay Dikici"], "Categories": "cs.CV cs.LG"}, "abstract": "We introduce a novel motion estimation method, MaskFlow, that is capable of estimating accurate motion fields, even in very challenging cases with small objects, large displacements and drastic appearance changes. In addition to lower-level features, that are used in other Deep Neural Network (DNN)-based motion estimation methods, MaskFlow draws from object-level features and segmentations. These features and segmentations are used to approximate the objects' translation motion field. We propose a novel and effective way of incorporating the incomplete translation motion field into a subsequent motion estimation network for refinement and completion. We also produced a new challenging synthetic dataset with motion field ground truth, and also provide extra ground truth for the object-instance matchings and corresponding segmentation masks. We demonstrate that MaskFlow outperforms state of the art methods when evaluated on our new challenging dataset, whilst still producing comparable results on the popular FlyingThings3D benchmark dataset.", "url": "https://arxiv.org/abs/2311.12476"}, {"metadata": {"arXiv": "2311.12490", "Date": "Tue, 21 Nov 2023 10:01:08 ", "Title": "Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields", "Authors": ["Yifan Wang", "Yi Gong and Yuan Zeng"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["WACV2024"]}, "abstract": "Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity scene reconstruction for novel view synthesis. However, NeRF requires hundreds of network evaluations per pixel to approximate a volume rendering integral, making it slow to train. Caching NeRFs into explicit data structures can effectively enhance rendering speed but at the cost of higher memory usage. To address these issues, we present Hyb-NeRF, a novel neural radiance field with a multi-resolution hybrid encoding that achieves efficient neural modeling and fast rendering, which also allows for high-quality novel view synthesis. The key idea of Hyb-NeRF is to represent the scene using different encoding strategies from coarse-to-fine resolution levels. Hyb-NeRF exploits memory-efficiency learnable positional features at coarse resolutions and the fast optimization speed and local details of hash-based feature grids at fine resolutions. In addition, to further boost performance, we embed cone tracing-based features in our learnable positional encoding that eliminates encoding ambiguity and reduces aliasing artifacts. Extensive experiments on both synthetic and real-world datasets show that Hyb-NeRF achieves faster rendering speed with better rending quality and even a lower memory footprint in comparison to previous state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.12490"}, {"metadata": {"arXiv": "2311.12561", "Date": "Tue, 21 Nov 2023 12:15:28 ", "Title": "Convolutional Neural Networks for Neuroimaging in Parkinson's Disease: Is Preprocessing Needed?", "Authors": ["Francisco J. Martinez-Murcia", "Juan M. G\\'orriz", "Javier Ram\\'irez and Andr\\'es Ortiz"], "Categories": "cs.CV cs.LG", "Comments": ["19 pages", "7 figures"], "Journal-ref": "INT J NEURAL SYST 28 (10), 2018, 1850035", "DOI": "10.1142/S0129065718500351"}, "abstract": "Spatial and intensity normalization are nowadays a prerequisite for neuroimaging analysis. Influenced by voxel-wise and other univariate comparisons, where these corrections are key, they are commonly applied to any type of analysis and imaging modalities. Nuclear imaging modalities such as PET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease diagnosis, are especially dependent on intensity normalization. However, these steps are computationally expensive and furthermore, they may introduce deformations in the images, altering the information contained in them. Convolutional Neural Networks (CNNs), for their part, introduce position invariance to pattern recognition, and have been proven to classify objects regardless of their orientation, size, angle, etc. Therefore, a question arises: how well can CNNs account for spatial and intensity differences when analysing nuclear brain imaging? Are spatial and intensity normalization still needed? To answer this question, we have trained four different CNN models based on well-established architectures, using or not different spatial and intensity normalization preprocessing. The results show that a sufficiently complex model such as our three-dimensional version of the ALEXNET can effectively account for spatial differences, achieving a diagnosis accuracy of 94.1% with an area under the ROC curve of 0.984. The visualization of the differences via saliency maps shows that these models are correctly finding patterns that match those found in the literature, without the need of applying any complex spatial normalization procedure. However, the intensity normalization -- and its type -- is revealed as very influential in the results and accuracy of the trained model, and therefore must be well accounted.", "url": "https://arxiv.org/abs/2311.12561"}, {"metadata": {"arXiv": "2311.12601", "Date": "Tue, 21 Nov 2023 13:42:40 ", "Title": "Deep learning-based detection of morphological features associated with hypoxia in H&E breast cancer whole slide images", "Authors": ["Petru Manescu", "Joseph Geradts and Delmiro Fernandez-Reyes"], "Categories": "cs.CV cs.LG q-bio.TO", "Comments": ["Under review"]}, "abstract": "Hypoxia occurs when tumour cells outgrow their blood supply, leading to regions of low oxygen levels within the tumour. Calculating hypoxia levels can be an important step in understanding the biology of tumours, their clinical progression and response to treatment. This study demonstrates a novel application of deep learning to evaluate hypoxia in the context of breast cancer histomorphology. More precisely, we show that Weakly Supervised Deep Learning (WSDL) models can accurately detect hypoxia associated features in routine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and evaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue from breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on a left-out test set. We also showed significant differences between features of hypoxic and normoxic tissue regions as distinguished by the WSDL models. Such DL hypoxia H&E WSI detection models could potentially be extended to other tumour types and easily integrated into the pathology workflow without requiring additional costly assays.", "url": "https://arxiv.org/abs/2311.12601"}, {"metadata": {"arXiv": "2311.12602", "Date": "Tue, 21 Nov 2023 13:43:06 ", "Title": "TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using Vision-Based Tactile Sensing", "Authors": ["Mauro Comi", "Yijiong Lin", "Alex Church", "Alessio Tonioni", "Laurence Aitchison", "Nathan F. Lepora"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "8 figures"]}, "abstract": "Humans rely on their visual and tactile senses to develop a comprehensive 3D understanding of their physical environment. Recently, there has been a growing interest in exploring and manipulating objects using data-driven approaches that utilise high-resolution vision-based tactile sensors. However, 3D shape reconstruction using tactile sensing has lagged behind visual shape reconstruction because of limitations in existing techniques, including the inability to generalise over unseen shapes, the absence of real-world testing, and limited expressive capacity imposed by discrete representations. To address these challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D shape reconstruction that leverages the rich information provided by a vision-based tactile sensor and the expressivity of the implicit neural representation DeepSDF. Our technique consists of two components: (1) a Convolutional Neural Network that maps tactile images into local meshes representing the surface at the touch location, and (2) an implicit neural function that predicts a signed distance function to extract the desired 3D shape. This combination allows TouchSDF to reconstruct smooth and continuous 3D shapes from tactile inputs in simulation and real-world settings, opening up research avenues for robust 3D-aware representations and improved multimodal perception in robotics. Code and supplementary material are available at: https://touchsdf.github.io/", "url": "https://arxiv.org/abs/2311.12602"}, {"metadata": {"arXiv": "2311.12679", "Date": "Tue, 21 Nov 2023 15:37:19 ", "Title": "BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse Multiview Videos", "Authors": ["Georgios Albanis", "Nikolaos Zioulis", "Kostas Kolomvatsos"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Published in European Conference on Visual Media Production (CVMP '23)"], "DOI": "10.1145/3626495.3626511"}, "abstract": "Capturing smooth motions from videos using markerless techniques typically involves complex processes such as temporal constraints, multiple stages with data-driven regression and optimization, and bundle solving over temporal windows. These processes can be inefficient and require tuning multiple objectives across stages. In contrast, BundleMoCap introduces a novel and efficient approach to this problem. It solves the motion capture task in a single stage, eliminating the need for temporal smoothness objectives while still delivering smooth motions. BundleMoCap outperforms the state-of-the-art without increasing complexity. The key concept behind BundleMoCap is manifold interpolation between latent keyframes. By relying on a local manifold smoothness assumption, we can efficiently solve a bundle of frames using a single code. Additionally, the method can be implemented as a sliding window optimization and requires only the first frame to be properly initialized, reducing the overall computational burden. BundleMoCap's strength lies in its ability to achieve high-quality motion capture results with simplicity and efficiency. More details can be found at https://moverseai.github.io/bundle/.", "url": "https://arxiv.org/abs/2311.12679"}, {"metadata": {"arXiv": "2311.12796", "Date": "Tue, 21 Nov 2023 18:59:58 ", "Title": "Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models", "Authors": ["David Stotko", "Nils Wandel", "Reinhard Klein"], "Categories": "cs.CV cs.LG"}, "abstract": "3D reconstruction of dynamic scenes is a long-standing problem in computer graphics and increasingly difficult the less information is available. Shape-from-Template (SfT) methods aim to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings. Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization. To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation. Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth. This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based SfT approach.", "url": "https://arxiv.org/abs/2311.12796"}, {"metadata": {"arXiv": "2311.12048", "Date": "Sat, 18 Nov 2023 08:55:08 ", "Title": "One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning", "Authors": ["Doyoung Kim", "Susik Yoon", "Dongmin Park", "Youngjun Lee", "Hwanjun Song", "Jihwan Bang", "Jae-Gil Lee"], "Categories": "cs.LG"}, "abstract": "In real-world continual learning scenarios, tasks often exhibit intricate and unpredictable semantic shifts, posing challenges for fixed prompt management strategies. We identify the inadequacy of universal and specific prompting in handling these dynamic shifts. Universal prompting is ineffective for tasks with abrupt semantic changes, while specific prompting struggles with overfitting under mild semantic shifts. To overcome these limitations, we propose an adaptive prompting approach that tailors minimal yet sufficient prompts based on the task semantics. Our methodology, SemPrompt, incorporates a two-level semantic grouping process: macroscopic semantic assignment and microscopic semantic refinement. This process ensures optimal prompt utilization for varying task semantics, improving the efficiency and effectiveness of learning in real-world CL settings. Our experimental results demonstrate that SemPrompt consistently outperforms existing methods in adapting to diverse semantic shifts in tasks.", "url": "https://arxiv.org/abs/2311.12048"}, {"metadata": {"arXiv": "2311.12086", "Date": "Mon, 20 Nov 2023 13:45:21 ", "Title": "Masked Autoencoders Are Robust Neural Architecture Search Learners", "Authors": ["Yiming Hu and Xiangxiang Chu and Bo Zhang"], "Categories": "cs.LG cs.NE"}, "abstract": "Neural Architecture Search (NAS) currently relies heavily on labeled data, which is both expensive and time-consuming to acquire. In this paper, we propose a novel NAS framework based on Masked Autoencoders (MAE) that eliminates the need for labeled data during the search process. By replacing the supervised learning objective with an image reconstruction task, our approach enables the robust discovery of network architectures without compromising performance and generalization ability. Additionally, we address the problem of performance collapse encountered in the widely-used Differentiable Architecture Search (DARTS) method in the unsupervised paradigm by introducing a multi-scale decoder. Through extensive experiments conducted on various search spaces and datasets, we demonstrate the effectiveness and robustness of the proposed method, providing empirical evidence of its superiority over baseline approaches.", "url": "https://arxiv.org/abs/2311.12086"}, {"metadata": {"arXiv": "2311.12167", "Date": "Mon, 20 Nov 2023 20:33:35 ", "Title": "Node classification in random trees", "Authors": ["Wouter W. L. Nuijten", "Vlado Menkovski"], "Categories": "cs.LG cs.SI"}, "abstract": "We propose a method for the classification of objects that are structured as random trees. Our aim is to model a distribution over the node label assignments in settings where the tree data structure is associated with node attributes (typically high dimensional embeddings). The tree topology is not predetermined and none of the label assignments are present during inference. Other methods that produce a distribution over node label assignment in trees (or more generally in graphs) either assume conditional independence of the label assignment, operate on a fixed graph topology, or require part of the node labels to be observed. Our method defines a Markov Network with the corresponding topology of the random tree and an associated Gibbs distribution. We parameterize the Gibbs distribution with a Graph Neural Network that operates on the random tree and the node embeddings. This allows us to estimate the likelihood of node assignments for a given random tree and use MCMC to sample from the distribution of node assignments. We evaluate our method on the tasks of node classification in trees on the Stanford Sentiment Treebank dataset. Our method outperforms the baselines on this dataset, demonstrating its effectiveness for modeling joint distributions of node labels in random trees.", "url": "https://arxiv.org/abs/2311.12167"}, {"metadata": {"arXiv": "2311.12253", "Date": "Tue, 21 Nov 2023 00:21:15 ", "Title": "The limitation of neural nets for approximation and optimization", "Authors": ["Tommaso Giovannelli", "Oumaima Sohab", "Luis Nunes Vicente"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "We are interested in assessing the use of neural networks as surrogate models to approximate and minimize objective functions in optimization problems. While neural networks are widely used for machine learning tasks such as classification and regression, their application in solving optimization problems has been limited. Our study begins by determining the best activation function for approximating the objective functions of popular nonlinear optimization test problems, and the evidence provided shows that~SiLU has the best performance. We then analyze the accuracy of function value, gradient, and Hessian approximations for such objective functions obtained through interpolation/regression models and neural networks. When compared to interpolation/regression models, neural networks can deliver competitive zero- and first-order approximations (at a high training cost) but underperform on second-order approximation. However, it is shown that combining a neural net activation function with the natural basis for quadratic interpolation/regression can waive the necessity of including cross terms in the natural basis, leading to models with fewer parameters to determine. Lastly, we provide evidence that the performance of a state-of-the-art derivative-free optimization algorithm can hardly be improved when the gradient of an objective function is approximated using any of the surrogate models considered, including neural networks.", "url": "https://arxiv.org/abs/2311.12253"}, {"metadata": {"arXiv": "2311.12255", "Date": "Tue, 21 Nov 2023 00:34:53 ", "Title": "Exploring Time Granularity on Temporal Graphs for Dynamic Link Prediction in Real-world Networks", "Authors": ["Xiangjian Jiang", "Yanyi Pu"], "Categories": "cs.LG cs.SI", "Comments": ["Presented at the Temporal Graph Learning Workshop @ NeurIPS 2023"]}, "abstract": "Dynamic Graph Neural Networks (DGNNs) have emerged as the predominant approach for processing dynamic graph-structured data. However, the influence of temporal information on model performance and robustness remains insufficiently explored, particularly regarding how models address prediction tasks with different time granularities. In this paper, we explore the impact of time granularity when training DGNNs on dynamic graphs through extensive experiments. We examine graphs derived from various domains and compare three different DGNNs to the baseline model across four varied time granularities. We mainly consider the interplay between time granularities, model architectures, and negative sampling strategies to obtain general conclusions. Our results reveal that a sophisticated memory mechanism and proper time granularity are crucial for a DGNN to deliver competitive and robust performance in the dynamic link prediction task. We also discuss drawbacks in considered models and datasets and propose promising directions for future research on the time granularity of temporal graphs.", "url": "https://arxiv.org/abs/2311.12255"}, {"metadata": {"arXiv": "2311.12290", "Date": "Tue, 21 Nov 2023 02:06:52 ", "Title": "A Supervised Contrastive Learning Pretrain-Finetune Approach for Time Series", "Authors": ["Trang H. Tran", "Lam M. Nguyen", "Kyongmin Yeo", "Nam Nguyen", "Roman Vaculin"], "Categories": "cs.LG"}, "abstract": "Foundation models have recently gained attention within the field of machine learning thanks to its efficiency in broad data processing. While researchers had attempted to extend this success to time series models, the main challenge is effectively extracting representations and transferring knowledge from pretraining datasets to the target finetuning dataset. To tackle this issue, we introduce a novel pretraining procedure that leverages supervised contrastive learning to distinguish features within each pretraining dataset. This pretraining phase enables a probabilistic similarity metric, which assesses the likelihood of a univariate sample being closely related to one of the pretraining datasets. Subsequently, using this similarity metric as a guide, we propose a fine-tuning procedure designed to enhance the accurate prediction of the target data by aligning it more closely with the learned dynamics of the pretraining datasets. Our experiments have shown promising results which demonstrate the efficacy of our approach.", "url": "https://arxiv.org/abs/2311.12290"}, {"metadata": {"arXiv": "2311.12309", "Date": "Tue, 21 Nov 2023 03:02:30 ", "Title": "Power grid operational risk assessment using graph neural network surrogates", "Authors": ["Yadong Zhang", "Pranav M Karve", "Sankaran Mahadevan"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["Manuscript submitted to IEEE PES GM 2024"]}, "abstract": "We investigate the utility of graph neural networks (GNNs) as proxies of power grid operational decision-making algorithms (optimal power flow (OPF) and security-constrained unit commitment (SCUC)) to enable rigorous quantification of the operational risk. To conduct principled risk analysis, numerous Monte Carlo (MC) samples are drawn from the (foretasted) probability distributions of spatio-temporally correlated stochastic grid variables. The corresponding OPF and SCUC solutions, which are needed to quantify the risk, are generated using traditional OPF and SCUC solvers to generate data for training GNN model(s). The GNN model performance is evaluated in terms of the accuracy of predicting quantities of interests (QoIs) derived from the decision variables in OPF and SCUC. Specifically, we focus on thermal power generation and load shedding at system and individual zone level. We also perform reliability and risk quantification based on GNN predictions and compare with that obtained from OPF/SCUC solutions. Our results demonstrate that GNNs are capable of providing fast and accurate prediction of QoIs and thus can be good surrogate models for OPF and SCUC. The excellent accuracy of GNN-based reliability and risk assessment further suggests that GNN surrogate has the potential to be applied in real-time and hours-ahead risk quantification.", "url": "https://arxiv.org/abs/2311.12309"}, {"metadata": {"arXiv": "2311.12329", "Date": "Tue, 21 Nov 2023 03:42:15 ", "Title": "Graph Neural Ordinary Differential Equations-based method for Collaborative Filtering", "Authors": ["Ke Xu", "Yuanjie Zhu", "Weizhi Zhang", "Philip S. Yu"], "Categories": "cs.LG cs.IR", "Comments": ["Accepted by ICDM 2023"]}, "abstract": "Graph Convolution Networks (GCNs) are widely considered state-of-the-art for collaborative filtering. Although several GCN-based methods have been proposed and achieved state-of-the-art performance in various tasks, they can be computationally expensive and time-consuming to train if too many layers are created. However, since the linear GCN model can be interpreted as a differential equation, it is possible to transfer it to an ODE problem. This inspired us to address the computational limitations of GCN-based models by designing a simple and efficient NODE-based model that can skip some GCN layers to reach the final state, thus avoiding the need to create many layers. In this work, we propose a Graph Neural Ordinary Differential Equation-based method for Collaborative Filtering (GODE-CF). This method estimates the final embedding by utilizing the information captured by one or two GCN layers. To validate our approach, we conducted experiments on multiple datasets. The results demonstrate that our model outperforms competitive baselines, including GCN-based models and other state-of-the-art CF methods. Notably, our proposed GODE-CF model has several advantages over traditional GCN-based models. It is simple, efficient, and has a fast training time, making it a practical choice for real-world situations.", "url": "https://arxiv.org/abs/2311.12329"}, {"metadata": {"arXiv": "2311.12356", "Date": "Tue, 21 Nov 2023 05:22:39 ", "Title": "Random Linear Projections Loss for Hyperplane-Based Optimization in Regression Neural Networks", "Authors": ["Shyam Venkatasubramanian", "Ahmed Aloui", "Vahid Tarokh"], "Categories": "cs.LG"}, "abstract": "Despite their popularity across a wide range of domains, regression neural networks are prone to overfitting complex datasets. In this work, we propose a loss function termed Random Linear Projections (RLP) loss, which is empirically shown to mitigate overfitting. With RLP loss, the distance between sets of hyperplanes connecting fixed-size subsets of the neural network's feature-prediction pairs and feature-label pairs is minimized. The intuition behind this loss derives from the notion that if two functions share the same hyperplanes connecting all subsets of feature-label pairs, then these functions must necessarily be equivalent. Our empirical studies, conducted across benchmark datasets and representative synthetic examples, demonstrate the improvements of the proposed RLP loss over mean squared error (MSE). Specifically, neural networks trained with the RLP loss achieve better performance while requiring fewer data samples and are more robust to additive noise. We provide theoretical analysis supporting our empirical findings.", "url": "https://arxiv.org/abs/2311.12356"}, {"metadata": {"arXiv": "2311.12358", "Date": "Tue, 21 Nov 2023 05:26:33 ", "Title": "Federated Learning via Consensus Mechanism on Heterogeneous Data: A New Perspective on Convergence", "Authors": ["Shu Zheng", "Tiandi Ye", "Xiang Li", "Ming Gao"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated learning (FL) on heterogeneous data (non-IID data) has recently received great attention. Most existing methods focus on studying the convergence guarantees for the global objective. While these methods can guarantee the decrease of the global objective in each communication round, they fail to ensure risk decrease for each client. In this paper, to address the problem,we propose FedCOME, which introduces a consensus mechanism to enforce decreased risk for each client after each training round. In particular, we allow a slight adjustment to a client's gradient on the server side, which generates an acute angle between the corrected gradient and the original ones of other clients. We theoretically show that the consensus mechanism can guarantee the convergence of the global objective. To generalize the consensus mechanism to the partial participation FL scenario, we devise a novel client sampling strategy to select the most representative clients for the global data distribution. Training on these selected clients with the consensus mechanism could empirically lead to risk decrease for clients that are not selected. Finally, we conduct extensive experiments on four benchmark datasets to show the superiority of FedCOME against other state-of-the-art methods in terms of effectiveness, efficiency and fairness. For reproducibility, we make our source code publicly available at: \\url{https://github.com/fedcome/fedcome}.", "url": "https://arxiv.org/abs/2311.12358"}, {"metadata": {"arXiv": "2311.12399", "Date": "Tue, 21 Nov 2023 07:22:48 ", "Title": "A Survey of Graph Meets Large Language Model: Progress and Future Directions", "Authors": ["Yuhan Li", "Zhixun Li", "Peisong Wang", "Jia Li", "Xiangguo Sun", "Hong Cheng", "Jeffrey Xu Yu"], "Categories": "cs.LG cs.CL cs.SI", "Comments": ["Work in progress; 13 pages", "5 figures"]}, "abstract": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.", "url": "https://arxiv.org/abs/2311.12399"}, {"metadata": {"arXiv": "2311.12419", "Date": "Tue, 21 Nov 2023 08:16:01 ", "Title": "Board-to-Board: Evaluating Moonboard Grade Prediction Generalization", "Authors": ["Daniel Petashvili and Matthew Rodda"], "Categories": "cs.LG cs.CV"}, "abstract": "Bouldering is a sport where athletes aim to climb up an obstacle using a set of defined holds called a route. Typically routes are assigned a grade to inform climbers of its difficulty and allow them to more easily track their progression. However, the variation in individual climbers technical and physical attributes and many nuances of an individual route make grading a difficult and often biased task. In this work, we apply classical and deep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard datasets, achieving state of the art grade prediction performance with 0.87 MAE and 1.12 RMSE. We achieve this performance on a feature-set that does not require decomposing routes into individual moves, which is a method common in literature and introduces bias. We also demonstrate the generalization capability of this model between editions and introduce a novel vision-based method of grade prediction. While the generalization performance of these techniques is below human level performance currently, we propose these methods as a basis for future work. Such a tool could be implemented in pre-existing mobile applications and would allow climbers to better track their progress and assess new routes with reduced bias.", "url": "https://arxiv.org/abs/2311.12419"}, {"metadata": {"arXiv": "2311.12424", "Date": "Tue, 21 Nov 2023 08:32:38 ", "Title": "Looped Transformers are Better at Learning Learning Algorithms", "Authors": ["Liu Yang", "Kangwook Lee", "Robert Nowak", "Dimitris Papailiopoulos"], "Categories": "cs.LG cs.NE"}, "abstract": "Transformers have demonstrated effectiveness in \\emph{in-context solving} data-fitting problems from various (latent) models, as reported by Garg et al. However, the absence of an inherent iterative structure in the transformer architecture presents a challenge in emulating the iterative algorithms, which are commonly employed in traditional machine learning methods. To address this, we propose the utilization of \\emph{looped} transformer architecture and its associated training methodology, with the aim of incorporating iterative characteristics into the transformer architectures. Experimental results suggest that the looped transformer achieves performance comparable to the standard transformer in solving various data-fitting problems, while utilizing less than 10\\% of the parameter count.", "url": "https://arxiv.org/abs/2311.12424"}, {"metadata": {"arXiv": "2311.12436", "Date": "Tue, 21 Nov 2023 08:45:09 ", "Title": "Classifier Calibration with ROC-Regularized Isotonic Regression", "Authors": ["Eugene Berta (SIERRA)", "Francis Bach (SIERRA)", "Michael Jordan (SIERRA)"], "Categories": "cs.LG"}, "abstract": "Calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model confidence and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy on a calibration set via monotone transformations. IR acts as an adaptive binning procedure, which allows achieving a calibration error of zero, but leaves open the issue of the effect on performance. In this paper, we first prove that IR preserves the convex hull of the ROC curve -- an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for overfitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with K classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the K-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding overfitting of the calibration set.", "url": "https://arxiv.org/abs/2311.12436"}, {"metadata": {"arXiv": "2311.12439", "Date": "Tue, 21 Nov 2023 08:51:58 ", "Title": "Harnessing FPGA Technology for Enhanced Biomedical Computation", "Authors": ["Nisanur Alici", "Kayode Inadagbo", "Murat Isik"], "Categories": "cs.LG cs.AR", "Comments": ["Submitted to IEEE Transactions on Biomedical Circuits and Systems. arXiv admin note: substantial text overlap with arXiv:2307.07914"]}, "abstract": "This research delves into sophisticated neural network frameworks like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for improved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs). The MIT-BIH Arrhythmia Database serves as the foundation for training and evaluating our models, with added Gaussian noise to heighten the algorithms' resilience. The developed architectures incorporate various layers for specific processing and categorization functions, employing strategies such as the EarlyStopping callback and Dropout layer to prevent overfitting. Additionally, this paper details the creation of a tailored Tensor Compute Unit (TCU) accelerator for the PYNQ Z1 platform. It provides a thorough methodology for implementing FPGA-based machine learning, encompassing the configuration of the Tensil toolchain in Docker, selection of architectures, PS-PL configuration, and the compilation and deployment of models. By evaluating performance indicators like latency and throughput, we showcase the efficacy of FPGAs in advanced biomedical computing. This study ultimately serves as a comprehensive guide to optimizing neural network operations on FPGAs across various fields.", "url": "https://arxiv.org/abs/2311.12439"}, {"metadata": {"arXiv": "2311.12495", "Date": "Tue, 21 Nov 2023 10:11:19 ", "Title": "Multi-Objective Reinforcement Learning based on Decomposition: A taxonomy and framework", "Authors": ["Florian Felten and El-Ghazali Talbi and Gr\\'egoire Danoy"], "Categories": "cs.LG", "Comments": ["Under review at JAIR"]}, "abstract": "Multi-objective reinforcement learning (MORL) extends traditional RL by seeking policies making different compromises among conflicting objectives. The recent surge of interest in MORL has led to diverse studies and solving methods, often drawing from existing knowledge in multi-objective optimization based on decomposition (MOO/D). Yet, a clear categorization based on both RL and MOO/D is lacking in the existing literature. Consequently, MORL researchers face difficulties when trying to classify contributions within a broader context due to the absence of a standardized taxonomy. To tackle such an issue, this paper introduces Multi-Objective Reinforcement Learning based on Decomposition (MORL/D), a novel methodology bridging RL and MOO literature. A comprehensive taxonomy for MORL/D is presented, providing a structured foundation for categorizing existing and potential MORL works. The introduced taxonomy is then used to scrutinize MORL research, enhancing clarity and conciseness through well-defined categorization. Moreover, a flexible framework derived from the taxonomy is introduced. This framework accommodates diverse instantiations using tools from both RL and MOO/D. Implementation across various configurations demonstrates its versatility, assessed against benchmark problems. Results indicate MORL/D instantiations achieve comparable performance with significantly greater versatility than current state-of-the-art approaches. By presenting the taxonomy and framework, this paper offers a comprehensive perspective and a unified vocabulary for MORL. This not only facilitates the identification of algorithmic contributions but also lays the groundwork for novel research avenues in MORL, contributing to the continued advancement of this field.", "url": "https://arxiv.org/abs/2311.12495"}, {"metadata": {"arXiv": "2311.12501", "Date": "Tue, 21 Nov 2023 10:20:34 ", "Title": "Fair Polylog-Approximate Low-Cost Hierarchical Clustering", "Authors": ["Marina Knittel", "Max Springer", "John Dickerson", "MohammadTaghi Hajiaghayi"], "Categories": "cs.LG cs.DS", "Comments": ["Accepted to NeurIPS '23 (16 pages", "5 figures)"]}, "abstract": "Research in fair machine learning, and particularly clustering, has been crucial in recent years given the many ethical controversies that modern intelligent systems have posed. Ahmadian et al. [2020] established the study of fairness in \\textit{hierarchical} clustering, a stronger, more structured variant of its well-known flat counterpart, though their proposed algorithm that optimizes for Dasgupta's [2016] famous cost function was highly theoretical. Knittel et al. [2023] then proposed the first practical fair approximation for cost, however they were unable to break the polynomial-approximate barrier they posed as a hurdle of interest. We break this barrier, proposing the first truly polylogarithmic-approximate low-cost fair hierarchical clustering, thus greatly bridging the gap between the best fair and vanilla hierarchical clustering approximations.", "url": "https://arxiv.org/abs/2311.12501"}, {"metadata": {"arXiv": "2311.12550", "Date": "Tue, 21 Nov 2023 11:59:16 ", "Title": "Explainable Anomaly Detection using Masked Latent Generative Modeling", "Authors": ["Daesoo Lee", "Sara Malacarne and Erlend Aune"], "Categories": "cs.LG stat.ML"}, "abstract": "We present a novel time series anomaly detection method that achieves excellent detection accuracy while offering a superior level of explainability. Our proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted from the cutting-edge time series generation method known as TimeVQVAE. The prior model is trained on the discrete latent space of a time-frequency domain. Notably, the dimensional semantics of the time-frequency domain are preserved in the latent space, enabling us to compute anomaly scores across different frequency bands, which provides a better insight into the detected anomalies. Additionally, the generative nature of the prior model allows for sampling likely normal states for detected anomalies, enhancing the explainability of the detected anomalies through counterfactuals. Our experimental evaluation on the UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD significantly surpasses the existing methods in terms of detection accuracy and explainability.", "url": "https://arxiv.org/abs/2311.12550"}, {"metadata": {"arXiv": "2311.12566", "Date": "Tue, 21 Nov 2023 12:26:14 ", "Title": "Variational Elliptical Processes", "Authors": ["Maria B{\\aa}nkestad", "Jens Sj\\\"olund", "Jalil Taghia", "Thomas B. Sch\\\"oon"], "Categories": "cs.LG stat.ML", "Comments": ["14 pages", "15 figures", "appendix 9 pages"]}, "abstract": "We present elliptical processes, a family of non-parametric probabilistic models that subsume Gaussian processes and Student's t processes. This generalization includes a range of new heavy-tailed behaviors while retaining computational tractability. Elliptical processes are based on a representation of elliptical distributions as a continuous mixture of Gaussian distributions. We parameterize this mixture distribution as a spline normalizing flow, which we train using variational inference. The proposed form of the variational posterior enables a sparse variational elliptical process applicable to large-scale problems. We highlight advantages compared to Gaussian processes through regression and classification experiments. Elliptical processes can supersede Gaussian processes in several settings, including cases where the likelihood is non-Gaussian or when accurate tail modeling is essential.", "url": "https://arxiv.org/abs/2311.12566"}, {"metadata": {"arXiv": "2311.12569", "Date": "Tue, 21 Nov 2023 12:32:38 ", "Title": "Differentiable Sampling of Categorical Distributions Using the CatLog-Derivative Trick", "Authors": ["Lennert De Smet", "Emanuele Sansone", "Pedro Zuidberg Dos Martires"], "Categories": "cs.LG stat.ML", "MSC-class": "68T05", "ACM-class": "G.3; G.4; I.2.6"}, "abstract": "Categorical random variables can faithfully represent the discrete and uncertain aspects of data as part of a discrete latent variable model. Learning in such models necessitates taking gradients with respect to the parameters of the categorical probability distributions, which is often intractable due to their combinatorial nature. A popular technique to estimate these otherwise intractable gradients is the Log-Derivative trick. This trick forms the basis of the well-known REINFORCE gradient estimator and its many extensions. While the Log-Derivative trick allows us to differentiate through samples drawn from categorical distributions, it does not take into account the discrete nature of the distribution itself. Our first contribution addresses this shortcoming by introducing the CatLog-Derivative trick - a variation of the Log-Derivative trick tailored towards categorical distributions. Secondly, we use the CatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient estimator for the important case of products of independent categorical distributions with provably lower variance than REINFORCE. Thirdly, we empirically show that IndeCateR can be efficiently implemented and that its gradient estimates have significantly lower bias and variance for the same number of samples compared to the state of the art.", "url": "https://arxiv.org/abs/2311.12569"}, {"metadata": {"arXiv": "2311.12590", "Date": "Tue, 21 Nov 2023 13:26:33 ", "Title": "ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia Classification Using Motor Activity Data", "Authors": ["Pradnya Rajendra Jadhav", "Raviprasad Aduri"], "Categories": "cs.LG"}, "abstract": "Schizophrenia is a complicated mental illness characterized by a broad spectrum of symptoms affecting cognition, behavior, and emotion. The task of identifying reliable biomarkers to classify Schizophrenia accurately continues to be a challenge in the field of psychiatry. We investigate the temporal patterns within the motor activity data as a potential key to enhancing the categorization of individuals with Schizophrenia, using the dataset having motor activity recordings of 22 Schizophrenia patients and 32 control subjects. The dataset contains per-minute motor activity measurements collected for an average of 12.7 days in a row for each participant. We dissect each day into segments (Twelve, Eight, six, four, three, and two parts) and evaluate their impact on classification. We employ sixteen statistical features within these temporal segments and train them on Seven machine learning models to get deeper insights. LightGBM model outperforms the other six models. Our results indicate that the temporal segmentation significantly improves the classification, with AUC-ROC = 0.93, F1 score = 0.84( LightGBM- without any segmentation) and AUC-ROC = 0.98, F1 score = 0.93( LightGBM- with segmentation). Distinguishing between diurnal and nocturnal segments amplifies the differences between Schizophrenia patients and controls. However, further subdivisions into smaller time segments do not affect the AUC- ROC significantly. Morning, afternoon, evening, and night partitioning gives similar classification performance to day-night partitioning. These findings are valuable as they indicate that extensive temporal classification beyond distinguishing between day and night does not yield substantial results, offering an efficient approach for further classification, early diagnosis, and monitoring of Schizophrenia.", "url": "https://arxiv.org/abs/2311.12590"}, {"metadata": {"arXiv": "2311.12624", "Date": "Tue, 21 Nov 2023 14:18:28 ", "Title": "Bridging Algorithmic Information Theory and Machine Learning: A New Approach to Kernel Learning", "Authors": ["Boumediene Hamzi", "Marcus Hutter", "Houman Owhadi"], "Categories": "cs.LG cs.IT math.IT stat.ML", "Comments": ["An earlier version of this paper appeared at https://www.researchgate.net/publication/371875631_A_note_on_learning_kernels_from_data_from_an_Algorithmic_Information_Theoretic_point_of_view. arXiv admin note: text overlap with arXiv:2111.13037", "arXiv:2007.05074"], "DOI": "10.13140/RG.2.2.36344.01285"}, "abstract": "Machine Learning (ML) and Algorithmic Information Theory (AIT) look at Complexity from different points of view. We explore the interface between AIT and Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on the problem of learning kernels from data, in kernel ridge regression, through the method of Sparse Kernel Flows. In particular, by looking at the differences and commonalities between Minimal Description Length (MDL) and Regularization in Machine Learning (RML), we prove that the method of Sparse Kernel Flows is the natural approach to adopt to learn kernels from data. This paper shows that it is not necessary to use the statistical route to derive Sparse Kernel Flows and that one can directly work with code-lengths and complexities that are concepts that show up in AIT.", "url": "https://arxiv.org/abs/2311.12624"}, {"metadata": {"arXiv": "2311.12630", "Date": "Tue, 21 Nov 2023 14:24:21 ", "Title": "Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting", "Authors": ["Juhyeon Kim", "Hyungeun Lee", "Seungwon Yu", "Ung Hwang", "Wooyul Jung", "Miseon Park", "Kijung Yoon"], "Categories": "cs.LG", "Comments": ["Temporal Graph Learning Workshop @ NeurIPS 2023", "New Orleans", "United States"]}, "abstract": "Multivariate time series is prevalent in many scientific and industrial domains. Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions--both direct and indirect. To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them. Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data. Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies. The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks. The results consistently showcase the superiority of our model, achieving an average 23\\% reduction in mean squared error (MSE) compared to existing models.", "url": "https://arxiv.org/abs/2311.12630"}, {"metadata": {"arXiv": "2311.12644", "Date": "Tue, 21 Nov 2023 14:44:51 ", "Title": "Careful Selection and Thoughtful Discarding: Graph Explicit Pooling Utilizing Discarded Nodes", "Authors": ["Chuang Liu", "Wenhang Yu", "Kuang Gao", "Xueqi Ma", "Yibing Zhan", "Jia Wu", "Bo Du", "Wenbin Hu"], "Categories": "cs.LG", "Comments": ["14 pages", "7 figures", "4 tables. Submitting to Science China Information Sciences"]}, "abstract": "Graph pooling has been increasingly recognized as crucial for Graph Neural Networks (GNNs) to facilitate hierarchical graph representation learning. Existing graph pooling methods commonly consist of two stages: selecting top-ranked nodes and discarding the remaining to construct coarsened graph representations. However, this paper highlights two key issues with these methods: 1) The process of selecting nodes to discard frequently employs additional Graph Convolutional Networks or Multilayer Perceptrons, lacking a thorough evaluation of each node's impact on the final graph representation and subsequent prediction tasks. 2) Current graph pooling methods tend to directly discard the noise segment (dropped) of the graph without accounting for the latent information contained within these elements. To address the first issue, we introduce a novel Graph Explicit Pooling (GrePool) method, which selects nodes by explicitly leveraging the relationships between the nodes and final representation vectors crucial for classification. The second issue is addressed using an extended version of GrePool (i.e., GrePool+), which applies a uniform loss on the discarded nodes. This addition is designed to augment the training process and improve classification accuracy. Furthermore, we conduct comprehensive experiments across 12 widely used datasets to validate our proposed method's effectiveness, including the Open Graph Benchmark datasets. Our experimental results uniformly demonstrate that GrePool outperforms 14 baseline methods for most datasets. Likewise, implementing GrePool+ enhances GrePool's performance without incurring additional computational costs.", "url": "https://arxiv.org/abs/2311.12644"}, {"metadata": {"arXiv": "2311.12652", "Date": "Tue, 21 Nov 2023 14:53:39 ", "Title": "FedDRO: Federated Compositional Optimization for Distributionally Robust Learning", "Authors": ["Prashant Khanduri", "Chengyin Li", "Rafi Ibn Sultan", "Yao Qiang", "Joerg Kliewer", "Dongxiao Zhu"], "Categories": "cs.LG math.OC", "Comments": ["38 Pages", "6 Figures"]}, "abstract": "Recently, compositional optimization (CO) has gained popularity because of its applications in distributionally robust optimization (DRO) and many other machine learning problems. Large-scale and distributed availability of data demands the development of efficient federated learning (FL) algorithms for solving CO problems. Developing FL algorithms for CO is particularly challenging because of the compositional nature of the objective. Moreover, current state-of-the-art methods to solve such problems rely on large batch gradients (depending on the solution accuracy) not feasible for most practical settings. To address these challenges, in this work, we propose efficient FedAvg-type algorithms for solving non-convex CO in the FL setting. We first establish that vanilla FedAvg is not suitable to solve distributed CO problems because of the data heterogeneity in the compositional objective at each client which leads to the amplification of bias in the local compositional gradient estimates. To this end, we propose a novel FL framework FedDRO that utilizes the DRO problem structure to design a communication strategy that allows FedAvg to control the bias in the estimation of the compositional gradient. A key novelty of our work is to develop solution accuracy-independent algorithms that do not require large batch gradients (and function evaluations) for solving federated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and $\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while achieving linear speedup with the number of clients. We corroborate our theoretical findings with empirical studies on large-scale DRO problems.", "url": "https://arxiv.org/abs/2311.12652"}, {"metadata": {"arXiv": "2311.12657", "Date": "Tue, 21 Nov 2023 15:01:14 ", "Title": "Carbohydrate NMR chemical shift predictions using E(3) equivariant graph neural networks", "Authors": ["Maria B{\\aa}nkestad", "Keven M. Dorst", "G\\\"oran Widmalm", "Jerk R\\\"onnols"], "Categories": "cs.LG physics.chem-ph", "Comments": ["13 pages", "9 figures", "2 tables"]}, "abstract": "Carbohydrates, vital components of biological systems, are well-known for their structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays a crucial role in understanding their intricate molecular arrangements and is essential in assessing and verifying the molecular structure of organic molecules. An important part of this process is to predict the NMR chemical shift from the molecular structure. This work introduces a novel approach that leverages E(3) equivariant graph neural networks to predict carbohydrate NMR spectra. Notably, our model achieves a substantial reduction in mean absolute error, up to threefold, compared to traditional models that rely solely on two-dimensional molecular structure. Even with limited data, the model excels, highlighting its robustness and generalization capabilities. The implications are far-reaching and go beyond an advanced understanding of carbohydrate structures and spectral interpretation. For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures. Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR.", "url": "https://arxiv.org/abs/2311.12657"}, {"metadata": {"arXiv": "2311.12666", "Date": "Tue, 21 Nov 2023 15:18:29 ", "Title": "SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer Interfaces", "Authors": ["Sung-Yu Chen", "Chi-Min Chang", "Kuan-Jung Chiang", "Chun-Shu Wei"], "Categories": "cs.LG eess.SP"}, "abstract": "Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces (BCIs) offer a non-invasive means of communication through high-speed speller systems. However, their efficiency heavily relies on individual training data obtained during time-consuming calibration sessions. To address the challenge of data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first dedicated neural network model designed for aligning SSVEP data across different domains, which can encompass various sessions, subjects, or devices. Our experimental results across multiple cross-domain scenarios demonstrate SSVEP-DAN's capability to transform existing source SSVEP data into supplementary calibration data, significantly enhancing SSVEP decoding accuracy in scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst for practical SSVEP-based BCI applications with minimal calibration. The source codes in this work are available at: https://github.com/CECNL/SSVEP-DAN.", "url": "https://arxiv.org/abs/2311.12666"}, {"metadata": {"arXiv": "2311.12670", "Date": "Tue, 21 Nov 2023 15:28:44 ", "Title": "Towards a more inductive world for drug repurposing approaches", "Authors": ["Jesus de la Fuente", "Guillermo Serrano", "Ux\\'ia Veleiro", "Mikel Casals", "Laura Vera", "Marija Pizurica", "Antonio Pineda-Lucena", "Idoia Ochoa", "Silve Vicent", "Olivier Gevaert", "and Mikel Hernaez"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Drug-target interaction (DTI) prediction is a challenging, albeit essential task in drug repurposing. Learning on graph models have drawn special attention as they can significantly reduce drug repurposing costs and time commitment. However, many current approaches require high-demanding additional information besides DTIs that complicates their evaluation process and usability. Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking. In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process, and show that DTI prediction methods based on transductive models lack generalization and lead to inflated performance when evaluated as previously done in the literature, hence not being suited for drug repurposing approaches. We then propose a novel biologically-driven strategy for negative edge subsampling and show through in vitro validation that newly discovered interactions are indeed true. We envision this work as the underpinning for future fair benchmarking and robust model design. All generated resources and tools are publicly available as a python package.", "url": "https://arxiv.org/abs/2311.12670"}, {"metadata": {"arXiv": "2311.12674", "Date": "Tue, 21 Nov 2023 15:31:16 ", "Title": "Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR", "Authors": ["Dominique Nshimyimana", "Vitor Fortes Rey and Paul Lukowic"], "Categories": "cs.LG eess.SP", "Comments": ["Accepted at ABC 2023. The 5th International Conference on Activity and Behavior Computing September 7th - 9th", "2023 in Kaiserslautern", "Germany (Hybrid)"]}, "abstract": "Machine learning algorithms are improving rapidly, but annotating training data remains a bottleneck for many applications. In this paper, we show how real data can be used for self-supervised learning without any transformations by taking advantage of the symmetry present in the activities. Our approach involves contrastive matching of two different sensors (left and right wrist or leg-worn IMUs) to make representations of co-occurring sensor data more similar and those of non-co-occurring sensor data more different. We test our approach on the Opportunity and MM-Fit datasets. In MM-Fit we show significant improvement over the baseline supervised and self-supervised method SimCLR, while for Opportunity there is significant improvement over the supervised baseline and slight improvement when compared to SimCLR. Moreover, our method improves supervised baselines even when using only a small amount of the data for training. Future work should explore under which conditions our method is beneficial for human activity recognition systems and other related applications.", "url": "https://arxiv.org/abs/2311.12674"}, {"metadata": {"arXiv": "2311.12678", "Date": "Tue, 21 Nov 2023 15:36:20 ", "Title": "Interpretation of the Transformer and Improvement of the Extractor", "Authors": ["Zhe Chen"], "Categories": "cs.LG"}, "abstract": "It has been over six years since the Transformer architecture was put forward. Surprisingly, the vanilla Transformer architecture is still widely used today. One reason is that the lack of deep understanding and comprehensive interpretation of the Transformer architecture makes it more challenging to improve the Transformer architecture. In this paper, we first interpret the Transformer architecture comprehensively in plain words based on our understanding and experiences. The interpretations are further proved and verified. These interpretations also cover the Extractor, a family of drop-in replacements for the multi-head self-attention in the Transformer architecture. Then, we propose an improvement on a type of the Extractor that outperforms the self-attention, without introducing additional trainable parameters. Experimental results demonstrate that the improved Extractor performs even better, showing a way to improve the Transformer architecture.", "url": "https://arxiv.org/abs/2311.12678"}, {"metadata": {"arXiv": "2311.12684", "Date": "Tue, 21 Nov 2023 15:46:11 ", "Title": "Adversarial Reweighting Guided by Wasserstein Distance for Bias Mitigation", "Authors": ["Xuan Zhao and Simone Fabbrizzi and Paula Reyero Lobo and Siamak Ghodsi and Klaus Broelemann and Steffen Staab and Gjergji Kasneci"], "Categories": "cs.LG"}, "abstract": "The unequal representation of different groups in a sample population can lead to discrimination of minority groups when machine learning models make automated decisions. To address these issues, fairness-aware machine learning jointly optimizes two (or more) metrics aiming at predictive effectiveness and low unfairness. However, the inherent under-representation of minorities in the data makes the disparate treatment of subpopulations less noticeable and difficult to deal with during learning. In this paper, we propose a novel adversarial reweighting method to address such \\emph{representation bias}. To balance the data distribution between the majority and the minority groups, our approach deemphasizes samples from the majority group. To minimize empirical risk, our method prefers samples from the majority group that are close to the minority group as evaluated by the Wasserstein distance. Our theoretical analysis shows the effectiveness of our adversarial reweighting approach. Experiments demonstrate that our approach mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets.", "url": "https://arxiv.org/abs/2311.12684"}, {"metadata": {"arXiv": "2311.12686", "Date": "Tue, 21 Nov 2023 15:47:06 ", "Title": "Managing ML-Based Application Non-Functional Behavior: A Multi-Model Approach", "Authors": ["Marco Anisetti", "Claudio A. Ardagna", "Nicola Bena", "Ernesto Damiani", "Paolo G. Panero"], "Categories": "cs.LG cs.SE", "Comments": ["13 pages", "12 figures"]}, "abstract": "Modern applications are increasingly driven by Machine Learning (ML) models whose non-deterministic behavior is affecting the entire application life cycle from design to operation. The pervasive adoption of ML is urgently calling for approaches that guarantee a stable non-functional behavior of ML-based applications over time and across model changes. To this aim, non-functional properties of ML models, such as privacy, confidentiality, fairness, and explainability, must be monitored, verified, and maintained. This need is even more pressing when modern applications operate in the edge-cloud continuum, increasing their complexity and dynamicity. Existing approaches mostly focus on i) implementing classifier selection solutions according to the functional behavior of ML models, ii) finding new algorithmic solutions to this need, such as continuous re-training. In this paper, we propose a multi-model approach built on dynamic classifier selection, where multiple ML models showing similar non-functional properties are made available to the application and one model is selected over time according to (dynamic and unpredictable) contextual changes. Our solution goes beyond the state of the art by providing an architectural and methodological approach that continuously guarantees a stable non-functional behavior of ML-based applications, is applicable to different ML models, and is driven by non-functional properties assessed on the models themselves. It consists of a two-step process working during application operation, where model assessment verifies non-functional properties of ML models trained and selected at development time, and model substitution guarantees a continuous and stable support of non-functional properties. We experimentally evaluate our solution in a real-world scenario focusing on non-functional property fairness.", "url": "https://arxiv.org/abs/2311.12686"}, {"metadata": {"arXiv": "2311.12688", "Date": "Tue, 21 Nov 2023 15:50:37 ", "Title": "On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning", "Authors": ["Paul Scemama", "Ariel Kapusta"], "Categories": "cs.LG stat.ML", "Comments": ["26 pages", "18 figures"]}, "abstract": "Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining Bayesian deep learning models with split conformal prediction can, in some cases, cause unintended consequences such as reducing out-of-distribution coverage.", "url": "https://arxiv.org/abs/2311.12688"}, {"metadata": {"arXiv": "2311.12711", "Date": "Tue, 21 Nov 2023 16:31:27 ", "Title": "Regression-Based Analysis of Multimodal Single-Cell Data Integration Strategies", "Authors": ["Bhavya Mehta", "Nirmit Deliwala", "Madhav Chandane"], "Categories": "cs.LG q-bio.GN"}, "abstract": "Multimodal single-cell technologies enable the simultaneous collection of diverse data types from individual cells, enhancing our understanding of cellular states. However, the integration of these datatypes and modeling the interrelationships between modalities presents substantial computational and analytical challenges in disease biomarker detection and drug discovery. Established practices rely on isolated methodologies to investigate individual molecular aspects separately, often resulting in inaccurate analyses. To address these obstacles, distinct Machine Learning Techniques are leveraged, each of its own kind to model the co-variation of DNA to RNA, and finally to surface proteins in single cells during hematopoietic stem cell development, which simplifies understanding of underlying cellular mechanisms and immune responses. Experiments conducted on a curated subset of a 300,000-cell time course dataset, highlights the exceptional performance of Echo State Networks, boasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on Multi-omic and CiteSeq datasets. Beyond the confines of this study, these findings hold promise for advancing comprehension of cellular differentiation and function, leveraging the potential of Machine Learning.", "url": "https://arxiv.org/abs/2311.12711"}, {"metadata": {"arXiv": "2311.12715", "Date": "Tue, 21 Nov 2023 16:42:03 ", "Title": "Attacks of fairness in Federated Learning", "Authors": ["Joseph Rance", "Filip Svoboda"], "Categories": "cs.LG cs.CR"}, "abstract": "Federated Learning is an important emerging distributed training paradigm that keeps data private on clients. It is now well understood that by controlling only a small subset of FL clients, it is possible to introduce a backdoor to a federated learning model, in the presence of certain attributes. In this paper, we present a new type of attack that compromises the fairness of the trained model. Fairness is understood to be the attribute-level performance distribution of a trained model. It is particularly salient in domains where, for example, skewed accuracy discrimination between subpopulations could have disastrous consequences. We find that by employing a threat model similar to that of a backdoor attack, an attacker is able to influence the aggregated model to have an unfair performance distribution between any given set of attributes. Furthermore, we find that this attack is possible by controlling only a single client. While combating naturally induced unfairness in FL has previously been discussed in depth, its artificially induced kind has been neglected. We show that defending against attacks on fairness should be a critical consideration in any situation where unfairness in a trained model could benefit a user who participated in its training.", "url": "https://arxiv.org/abs/2311.12715"}, {"metadata": {"arXiv": "2311.12727", "Date": "Tue, 21 Nov 2023 17:03:21 ", "Title": "Soft Random Sampling: A Theoretical and Empirical Analysis", "Authors": ["Xiaodong Cui", "Ashish Mittal", "Songtao Lu", "Wei Zhang", "George Saon", "Brian Kingsbury"], "Categories": "cs.LG cs.CL"}, "abstract": "Soft random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data. SRS selects a subset uniformly at random with replacement from the full data set in each epoch. In this paper, we conduct a theoretical and empirical analysis of SRS. First, we analyze its sampling dynamics including data coverage and occupancy. Next, we investigate its convergence with non-convex objective functions and give the convergence rate. Finally, we provide its generalization performance. We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness. Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off. Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost.", "url": "https://arxiv.org/abs/2311.12727"}, {"metadata": {"arXiv": "2311.12737", "Date": "Tue, 21 Nov 2023 17:23:05 ", "Title": "Exploring Graph Classification Techniques Under Low Data Constraints: A Comprehensive Study", "Authors": ["Kush Kothari", "Bhavya Mehta", "Reshmika Nambiar and Seema Shrawne"], "Categories": "cs.LG"}, "abstract": "This survey paper presents a brief overview of recent research on graph data augmentation and few-shot learning. It covers various techniques for graph data augmentation, including node and edge perturbation, graph coarsening, and graph generation, as well as the latest developments in few-shot learning, such as meta-learning and model-agnostic meta-learning. The paper explores these areas in depth and delves into further sub classifications. Rule based approaches and learning based approaches are surveyed under graph augmentation techniques. Few-Shot Learning on graphs is also studied in terms of metric learning techniques and optimization-based techniques. In all, this paper provides an extensive array of techniques that can be employed in solving graph processing problems faced in low-data scenarios.", "url": "https://arxiv.org/abs/2311.12737"}, {"metadata": {"arXiv": "2311.12750", "Date": "Tue, 21 Nov 2023 17:51:30 ", "Title": "Learning to Optimise Wind Farms with Graph Transformers", "Authors": ["Siyi Li", "Arnaud Robert", "A. Aldo Faisal", "Matthew D. Piggott"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "This work proposes a novel data-driven model capable of providing accurate predictions for the power generation of all wind turbines in wind farms of arbitrary layout, yaw angle configurations and wind conditions. The proposed model functions by encoding a wind farm into a fully-connected graph and processing the graph representation through a graph transformer. The graph transformer surrogate is shown to generalise well and is able to uncover latent structural patterns within the graph representation of wind farms. It is demonstrated how the resulting surrogate model can be used to optimise yaw angle configurations using genetic algorithms, achieving similar levels of accuracy to industrially-standard wind farm simulation tools while only taking a fraction of the computational cost.", "url": "https://arxiv.org/abs/2311.12750"}, {"metadata": {"arXiv": "2311.12786", "Date": "Tue, 21 Nov 2023 18:51:04 ", "Title": "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks", "Authors": ["Samyak Jain", "Robert Kirk", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka", "Edward Grefenstette", "Tim Rockt\\\"aschel", "David Scott Krueger"], "Categories": "cs.LG"}, "abstract": "Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy. Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones? We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing. We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a 'wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such hidden capabilities are relevant leads to sample-efficient 'revival' of the capability, i.e., the model begins reusing these capability after only a few gradient steps. This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task. We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup.", "url": "https://arxiv.org/abs/2311.12786"}, {"metadata": {"arXiv": "2311.12261", "Date": "Tue, 21 Nov 2023 00:45:13 ", "Title": "Beyond Simulated Drivers: Evaluating the Impact of Real-World Car-Following in Mixed Traffic Control", "Authors": ["Bibek Poudel and Weizi Li"], "Categories": "cs.RO cs.LG"}, "abstract": "Human-driven vehicles can amplify naturally occurring perturbations in traffic, leading to congestion and consequently increased fuel consumption, higher collision risks, and reduced capacity utilization. While previous research has highlighted that a fraction of Robot Vehicles (RVs) can mitigate these issues, they often rely on simulations with simplistic, model-based Human-driven Vehicles (HVs) during car-following scenarios. Diverging from this trend, in this study, we analyze real-world human driving trajectories, extracting a wide range of acceleration behaviors during car-following. We then incorporate these behaviors in simulation where RVs from prior studies are employed to mitigate congestion, and evaluate their safety, efficiency, and stability. Further, we also introduce a reinforcement learning based RV that utilizes a congestion stage classifier neural network to optimize either \"safety+stability\" or \"efficiency\" in the presence of the diverse human driving behaviors. We evaluate the proposed RVs in two different mixed traffic control environments at various densities, configurations, and penetration rates and compare with the existing RVs.", "url": "https://arxiv.org/abs/2311.12261"}, {"metadata": {"arXiv": "2311.12722", "Date": "Tue, 21 Nov 2023 16:51:33 ", "Title": "Attacking Motion Planners Using Adversarial Perception Errors", "Authors": ["Jonathan Sadeghi", "Nicholas A. Lord", "John Redford", "Romain Mueller"], "Categories": "cs.RO cs.CR cs.CV cs.LG"}, "abstract": "Autonomous driving (AD) systems are often built and tested in a modular fashion, where the performance of different modules is measured using task-specific metrics. These metrics should be chosen so as to capture the downstream impact of each module and the performance of the system as a whole. For example, high perception quality should enable prediction and planning to be performed safely. Even though this is true in general, we show here that it is possible to construct planner inputs that score very highly on various perception quality metrics but still lead to planning failures. In an analogy to adversarial attacks on image classifiers, we call such inputs \\textbf{adversarial perception errors} and show they can be systematically constructed using a simple boundary-attack algorithm. We demonstrate the effectiveness of this algorithm by finding attacks for two different black-box planners in several urban and highway driving scenarios using the CARLA simulator. Finally, we analyse the properties of these attacks and show that they are isolated in the input space of the planner, and discuss their implications for AD system deployment and testing.", "url": "https://arxiv.org/abs/2311.12722"}, {"metadata": {"arXiv": "2311.12230", "Date": "Mon, 20 Nov 2023 23:02:39 ", "Title": "Data-Guided Regulator for Adaptive Nonlinear Control", "Authors": ["Niyousha Rahimi and Mehran Mesbahi"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "This paper addresses the problem of designing a data-driven feedback controller for complex nonlinear dynamical systems in the presence of time-varying disturbances with unknown dynamics. Such disturbances are modeled as the \"unknown\" part of the system dynamics. The goal is to achieve finite-time regulation of system states through direct policy updates while also generating informative data that can subsequently be used for data-driven stabilization or system identification. First, we expand upon the notion of \"regularizability\" and characterize this system characteristic for a linear time-varying representation of the nonlinear system with locally-bounded higher-order terms. \"Rapid-regularizability\" then gauges the extent by which a system can be regulated in finite time, in contrast to its asymptotic behavior. We then propose the Data-Guided Regulation for Adaptive Nonlinear Control ( DG-RAN) algorithm, an online iterative synthesis procedure that utilizes discrete time-series data from a single trajectory for regulating system states and identifying disturbance dynamics. The effectiveness of our approach is demonstrated on a 6-DOF power descent guidance problem in the presence of adverse environmental disturbances.", "url": "https://arxiv.org/abs/2311.12230"}, {"metadata": {"arXiv": "2311.12613", "Date": "Tue, 21 Nov 2023 13:56:44 ", "Title": "Decentralised Q-Learning for Multi-Agent Markov Decision Processes with a Satisfiability Criterion", "Authors": ["Keshav P. Keval", "Vivek S. Borkar"], "Categories": "eess.SY cs.LG cs.MA cs.SY"}, "abstract": "In this paper, we propose a reinforcement learning algorithm to solve a multi-agent Markov decision process (MMDP). The goal, inspired by Blackwell's Approachability Theorem, is to lower the time average cost of each agent to below a pre-specified agent-specific bound. For the MMDP, we assume the state dynamics to be controlled by the joint actions of agents, but the per-stage costs to only depend on the individual agent's actions. We combine the Q-learning algorithm for a weighted combination of the costs of each agent, obtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative Weights formalisms to modulate the averaging matrix of the gossip. We use multiple timescales in our algorithm and prove that under mild conditions, it approximately achieves the desired bounds for each of the agents. We also demonstrate the empirical performance of this algorithm in the more general setting of MMDPs having jointly controlled per-stage costs.", "url": "https://arxiv.org/abs/2311.12613"}, {"metadata": {"arXiv": "2311.12047", "Date": "Sat, 18 Nov 2023 08:30:38 ", "Title": "Multimodal Machine Unlearning", "Authors": ["Jiali Cheng", "Hadi Amiri"], "Categories": "cs.AI"}, "abstract": "Machine Unlearning is the process of removing specific training data samples and their corresponding effects from an already trained model. It has significant practical benefits, such as purging private, inaccurate, or outdated information from trained models without the need for complete re-training. Unlearning within a multimodal setting presents unique challenges due to the intrinsic dependencies between different data modalities and the expensive cost of training on large multimodal datasets and architectures. Current approaches to machine unlearning have not fully addressed these challenges. To bridge this gap, we introduce MMUL, a machine unlearning approach specifically designed for multimodal data and models. MMUL formulates the multimodal unlearning task by focusing on three key properties: (a): modality decoupling, which effectively decouples the association between individual unimodal data points within multimodal inputs marked for deletion, rendering them as unrelated data points within the model's context, (b): unimodal knowledge retention, which retains the unimodal representation capability of the model post-unlearning, and (c): multimodal knowledge retention, which retains the multimodal representation capability of the model post-unlearning. MMUL is efficient to train and is not constrained by the requirement of using a strongly convex loss. Experiments on two multimodal models and four multimodal benchmark datasets, including vision-language and graph-language datasets, show that MMUL outperforms existing baselines, gaining an average improvement of +17.6 points against the best-performing unimodal baseline in distinguishing between deleted and remaining data. In addition, MMUL can largely maintain pre-existing knowledge of the original model post unlearning, with a performance gap of only 0.3 points compared to retraining a new model from scratch.", "url": "https://arxiv.org/abs/2311.12047"}, {"metadata": {"arXiv": "2311.12188", "Date": "Mon, 20 Nov 2023 21:14:04 ", "Title": "ChatGPT and post-test probability", "Authors": ["Samuel J. Weisenthal"], "Categories": "cs.AI stat.AP", "Comments": ["138 pages", "4 tables"]}, "abstract": "Reinforcement learning-based large language models, such as ChatGPT, are believed to have potential to aid human experts in many domains, including healthcare. There is, however, little work on ChatGPT's ability to perform a key task in healthcare: formal, probabilistic medical diagnostic reasoning. This type of reasoning is used, for example, to update a pre-test probability to a post-test probability. In this work, we probe ChatGPT's ability to perform this task. In particular, we ask ChatGPT to give examples of how to use Bayes rule for medical diagnosis. Our prompts range from queries that use terminology from pure probability (e.g., requests for a \"posterior probability\") to queries that use terminology from the medical diagnosis literature (e.g., requests for a \"post-test probability\"). We show how the introduction of medical variable names leads to an increase in the number of errors that ChatGPT makes. Given our results, we also show how one can use prompt engineering to facilitate ChatGPT's partial avoidance of these errors. We discuss our results in light of recent commentaries on sensitivity and specificity. We also discuss how our results might inform new research directions for large language models.", "url": "https://arxiv.org/abs/2311.12188"}, {"metadata": {"arXiv": "2311.12202", "Date": "Mon, 20 Nov 2023 21:43:32 ", "Title": "Nepotistically Trained Generative-AI Models Collapse", "Authors": ["Matyas Bohacek and Hany Farid"], "Categories": "cs.AI cs.CV"}, "abstract": "Trained on massive amounts of human-generated content, AI (artificial intelligence) image synthesis is capable of reproducing semantically coherent images that match the visual appearance of its training data. We show that when retrained on even small amounts of their own creation, these generative-AI models produce highly distorted images. We also show that this distortion extends beyond the text prompts used in retraining, and that once poisoned, the models struggle to fully heal even after retraining on only real images.", "url": "https://arxiv.org/abs/2311.12202"}, {"metadata": {"arXiv": "2311.12207", "Date": "Mon, 20 Nov 2023 21:51:45 ", "Title": "Defense semantics of argumentation: revisit", "Authors": ["Beishui Liao and Leendert van der Torre"], "Categories": "cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:1705.00303"]}, "abstract": "In this paper we introduce a novel semantics, called defense semantics, for Dung's abstract argumentation frameworks in terms of a notion of (partial) defence, which is a triple encoding that one argument is (partially) defended by another argument via attacking the attacker of the first argument. In terms of defense semantics, we show that defenses related to self-attacked arguments and arguments in 3-cycles are unsatifiable under any situation and therefore can be removed without affecting the defense semantics of an AF. Then, we introduce a new notion of defense equivalence of AFs, and compare defense equivalence with standard equivalence and strong equivalence, respectively. Finally, by exploiting defense semantics, we define two kinds of reasons for accepting arguments, i.e., direct reasons and root reasons, and a notion of root equivalence of AFs that can be used in argumentation summarization.", "url": "https://arxiv.org/abs/2311.12207"}, {"metadata": {"arXiv": "2311.12229", "Date": "Mon, 20 Nov 2023 22:57:47 ", "Title": "NeuroPrompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation", "Authors": ["Shachar Rosenman", "Vasudev Lal", "and Phillip Howard"], "Categories": "cs.AI"}, "abstract": "Despite impressive recent advances in text-to-image diffusion models, obtaining high-quality images often requires prompt engineering by humans who have developed expertise in using them. In this work, we present NeuroPrompts, an adaptive framework that automatically enhances a user's prompt to improve the quality of generations produced by text-to-image models. Our framework utilizes constrained text decoding with a pre-trained language model that has been adapted to generate prompts similar to those produced by human prompt engineers. This approach enables higher-quality text-to-image generations and provides user control over stylistic features via constraint set specification. We demonstrate the utility of our framework by creating an interactive application for prompt enhancement and image generation using Stable Diffusion. Additionally, we conduct experiments utilizing a large dataset of human-engineered prompts for text-to-image generation and show that our approach automatically produces enhanced prompts that result in superior image quality. We make our code, a screencast video demo and a live demo instance of NeuroPrompts publicly available.", "url": "https://arxiv.org/abs/2311.12229"}, {"metadata": {"arXiv": "2311.12241", "Date": "Mon, 20 Nov 2023 23:36:41 ", "Title": "InteraSSort: Interactive Assortment Planning Using Large Language Models", "Authors": ["Saketh Reddy Karra", "Theja Tulabandhula"], "Categories": "cs.AI"}, "abstract": "Assortment planning, integral to multiple commercial offerings, is a key problem studied in e-commerce and retail settings. Numerous variants of the problem along with their integration into business solutions have been thoroughly investigated in the existing literature. However, the nuanced complexities of in-store planning and a lack of optimization proficiency among store planners with strong domain expertise remain largely overlooked. These challenges frequently necessitate collaborative efforts with multiple stakeholders which often lead to prolonged decision-making processes and significant delays. To mitigate these challenges and capitalize on the advancements of Large Language Models (LLMs), we propose an interactive assortment planning framework, InteraSSort that augments LLMs with optimization tools to assist store planners in making decisions through interactive conversations. Specifically, we develop a solution featuring a user-friendly interface that enables users to express their optimization objectives as input text prompts to InteraSSort and receive tailored optimized solutions as output. Our framework extends beyond basic functionality by enabling the inclusion of additional constraints through interactive conversation, facilitating precise and highly customized decision-making. Extensive experiments demonstrate the effectiveness of our framework and potential extensions to a broad range of operations management challenges.", "url": "https://arxiv.org/abs/2311.12241"}, {"metadata": {"arXiv": "2311.12307", "Date": "Tue, 21 Nov 2023 02:53:40 ", "Title": "Causality is all you need", "Authors": ["Ning Xu", "Yifei Gao", "Hongshuo Tian", "Yongdong Zhang", "An-An Liu"], "Categories": "cs.AI"}, "abstract": "In the fundamental statistics course, students are taught to remember the well-known saying: \"Correlation is not Causation\". Till now, statistics (i.e., correlation) have developed various successful frameworks, such as Transformer and Pre-training large-scale models, which have stacked multiple parallel self-attention blocks to imitate a wide range of tasks. However, in the causation community, how to build an integrated causal framework still remains an untouched domain despite its excellent intervention capabilities. In this paper, we propose the Causal Graph Routing (CGR) framework, an integrated causal scheme relying entirely on the intervention mechanisms to reveal the cause-effect forces hidden in data. Specifically, CGR is composed of a stack of causal layers. Each layer includes a set of parallel deconfounding blocks from different causal graphs. We combine these blocks via the concept of the proposed sufficient cause, which allows the model to dynamically select the suitable deconfounding methods in each layer. CGR is implemented as the stacked networks, integrating no confounder, back-door adjustment, front-door adjustment, and probability of sufficient cause. We evaluate this framework on two classical tasks of CV and NLP. Experiments show CGR can surpass the current state-of-the-art methods on both Visual Question Answer and Long Document Classification tasks. In particular, CGR has great potential in building the \"causal\" pre-training large-scale model that effectively generalizes to diverse tasks. It will improve the machines' comprehension of causal relationships within a broader semantic space.", "url": "https://arxiv.org/abs/2311.12307"}, {"metadata": {"arXiv": "2311.12320", "Date": "Tue, 21 Nov 2023 03:32:01 ", "Title": "A Survey on Multimodal Large Language Models for Autonomous Driving", "Authors": ["Can Cui", "Yunsheng Ma", "Xu Cao", "Wenqian Ye", "Yang Zhou", "Kaizhao Liang", "Jintai Chen", "Juanwu Lu", "Zichong Yang", "Kuei-Da Liao", "Tianren Gao", "Erlong Li", "Kun Tang", "Zhipeng Cao", "Tong Zhou", "Ao Liu", "Xinrui Yan", "Shuqi Mei", "Jianguo Cao", "Ziran Wang", "Chao Zheng"], "Categories": "cs.AI"}, "abstract": "With the emergence of Large Language Models (LLMs) and Vision Foundation Models (VFMs), multimodal AI systems benefiting from large models have the potential to equally perceive the real world, make decisions, and control tools as humans. In recent months, LLMs have shown widespread attention in autonomous driving and map systems. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors to apply in LLM driving systems. In this paper, we present a systematic investigation in this field. We first introduce the background of Multimodal Large Language Models (MLLMs), the multimodal models development using LLMs, and the history of autonomous driving. Then, we overview existing MLLM tools for driving, transportation, and map systems together with existing datasets and benchmarks. Moreover, we summarized the works in The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which is the first workshop of its kind regarding LLMs in autonomous driving. To further promote the development of this field, we also discuss several important problems regarding using MLLMs in autonomous driving systems that need to be solved by both academia and industry.", "url": "https://arxiv.org/abs/2311.12320"}, {"metadata": {"arXiv": "2311.12420", "Date": "Tue, 21 Nov 2023 08:20:39 ", "Title": "How Far Have We Gone in Vulnerability Detection Using Large Language Models", "Authors": ["Zeyu Gao", "Hao Wang", "Yuchen Zhou", "Wenyu Zhu", "Chao Zhang"], "Categories": "cs.AI cs.CL cs.CR"}, "abstract": "As software becomes increasingly complex and prone to vulnerabilities, automated vulnerability detection is critically important, yet challenging. Given the significant successes of Large Language Models (LLMs) in various tasks, there is growing anticipation of their efficacy in vulnerability detection. However, a quantitative understanding of their potential in vulnerability detection is still missing. To bridge this gap, we introduce a comprehensive vulnerability benchmark VulBench. This benchmark aggregates high-quality data from a wide range of CTF (Capture-the-Flag) challenges and real-world applications, with annotations for each vulnerable function detailing the vulnerability type and its root cause. Through our experiments encompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models and static analyzers, we find that several LLMs outperform traditional deep learning approaches in vulnerability detection, revealing an untapped potential in LLMs. This work contributes to the understanding and utilization of LLMs for enhanced software security.", "url": "https://arxiv.org/abs/2311.12420"}, {"metadata": {"arXiv": "2311.12431", "Date": "Tue, 21 Nov 2023 08:43:06 ", "Title": "A recurrent connectionist model of melody perception : An exploration using TRACX2", "Authors": ["Daniel Defays", "Robert French (LEAD)", "Barbara Tillmann (LEAD)"], "Categories": "cs.AI", "Journal-ref": "Cognitive Science, 2023, 47 (4)", "DOI": "10.1111/cogs.13283"}, "abstract": "Are similar, or even identical, mechanisms used in the computational modeling of speech segmentation, serial image processing and music processing? We address this question by exploring how TRACX2, (French et al., 2011; French \\& Cottrell, 2014; Mareschal \\& French, 2017), a recognition-based, recursive connectionist autoencoder model of chunking and sequence segmentation, which has successfully simulated speech and serial-image processing, might be applied to elementary melody perception. The model, a three-layer autoencoder that recognizes ''chunks'' of short sequences of intervals that have been frequently encountered on input, is trained on the tone intervals of melodically simple French children's songs. It dynamically incorporates the internal representations of these chunks into new input. Its internal representations cluster in a manner that is consistent with ''human-recognizable'' melodic categories. TRACX2 is sensitive to both contour and proximity information in the musical chunks that it encounters in its input. It shows the ''end-of-word'' superiority effect demonstrated by Saffran et al. (1999) for short musical phrases. The overall findings suggest that the recursive autoassociative chunking mechanism, as implemented in TRACX2, may be a general segmentation and chunking mechanism, underlying not only word-and imagechunking, but also elementary melody processing.", "url": "https://arxiv.org/abs/2311.12431"}, {"metadata": {"arXiv": "2311.12447", "Date": "Tue, 21 Nov 2023 08:58:50 ", "Title": "Designing Long-term Group Fair Policies in Dynamical Systems", "Authors": ["Miriam Rateike", "Isabel Valera and Patrick Forr\\'e"], "Categories": "cs.AI"}, "abstract": "Neglecting the effect that decisions have on individuals (and thus, on the underlying data distribution) when designing algorithmic decision-making policies may increase inequalities and unfairness in the long term - even if fairness considerations were taken in the policy design process. In this paper, we propose a novel framework for achieving long-term group fairness in dynamical systems, in which current decisions may affect an individual's features in the next step, and thus, future decisions. Specifically, our framework allows us to identify a time-independent policy that converges, if deployed, to the targeted fair stationary state of the system in the long term, independently of the initial data distribution. We model the system dynamics with a time-homogeneous Markov chain and optimize the policy leveraging the Markov chain convergence theorem to ensure unique convergence. We provide examples of different targeted fair states of the system, encompassing a range of long-term goals for society and policymakers. Furthermore, we show how our approach facilitates the evaluation of different long-term targets by examining their impact on the group-conditional population distribution in the long term and how it evolves until convergence.", "url": "https://arxiv.org/abs/2311.12447"}, {"metadata": {"arXiv": "2311.12448", "Date": "Tue, 21 Nov 2023 08:58:57 ", "Title": "Extracting Definienda in Mathematical Scholarly Articles with Transformers", "Authors": ["Shufan Jiang (VALDA)", "Pierre Senellart (DI-ENS", "VALDA)"], "Categories": "cs.AI", "Comments": ["In the Proceedings of the 2nd Workshop on Information Extraction from Scientific Publications (WIESP 2023)"]}, "abstract": "We consider automatically identifying the defined term within a mathematical definition from the text of an academic article. Inspired by the development of transformer-based natural language processing applications, we pose the problem as (a) a token-level classification task using fine-tuned pre-trained transformers; and (b) a question-answering task using a generalist large language model (GPT). We also propose a rule-based approach to build a labeled dataset from the LATEX source of papers. Experimental results show that it is possible to reach high levels of precision and recall using either recent (and expensive) GPT 4 or simpler pre-trained models fine-tuned on our task.", "url": "https://arxiv.org/abs/2311.12448"}, {"metadata": {"arXiv": "2311.12465", "Date": "Tue, 21 Nov 2023 09:22:02 ", "Title": "Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and Embedding", "Authors": ["Mattia Fumagalli", "Marco Boffo", "Daqian Shi", "Mayukh Bagchi and Fausto Giunchiglia"], "Categories": "cs.AI", "Comments": ["Ontology Showcase and Demonstrations Track", "9th Joint Ontology Workshops (JOWO 2023)", "Co-located with FOIS 2023", "19-20 July", "2023", "Sherbrooke", "Qu\\'ebec", "Canada. arXiv admin note: substantial text overlap with arXiv:2207.06112"], "Report-no": "DISIKNOWDIVE21112023"}, "abstract": "One of the significant barriers to the training of statistical models on knowledge graphs is the difficulty that scientists have in finding the best input data to address their prediction goal. In addition to this, a key challenge is to determine how to manipulate these relational data, which are often in the form of particular triples (i.e., subject, predicate, object), to enable the learning process. Currently, many high-quality catalogs of knowledge graphs, are available. However, their primary goal is the re-usability of these resources, and their interconnection, in the context of the Semantic Web. This paper describes the LiveSchema initiative, namely, a first version of a gateway that has the main scope of leveraging the gold mine of data collected by many existing catalogs collecting relational data like ontologies and knowledge graphs. At the current state, LiveSchema contains - 1000 datasets from 4 main sources and offers some key facilities, which allow to: i) evolving LiveSchema, by aggregating other source catalogs and repositories as input sources; ii) querying all the collected resources; iii) transforming each given dataset into formal concept analysis matrices that enable analysis and visualization services; iv) generating models and tensors from each given dataset.", "url": "https://arxiv.org/abs/2311.12465"}, {"metadata": {"arXiv": "2311.12472", "Date": "Tue, 21 Nov 2023 09:33:13 ", "Title": "Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling", "Authors": ["Jiahao Ji", "Wentao Zhang", "Jingyuan Wang", "Yue He and Chao Huang"], "Categories": "cs.AI", "Comments": ["14 pages", "9 figures"]}, "abstract": "As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations against variant spurious ones and deconfounds the effect of ST contexts. On top of that, we devise a Spatio-Temporal sElf-superVised dEconfounding (STEVE) framework. It first encodes traffic data into two disentangled representations for associating invariant and variant ST contexts. Then, we use representative ST contexts from three conceptually different perspectives (i.e., temporal, spatial, and semantic) as self-supervised signals to inject context information into both representations. In this way, we improve the generalization ability of the learned context-oriented representations to OOD ST traffic forecasting. Comprehensive experiments on four large-scale benchmark datasets demonstrate that our STEVE consistently outperforms the state-of-the-art baselines across various ST OOD scenarios.", "url": "https://arxiv.org/abs/2311.12472"}, {"metadata": {"arXiv": "2311.12521", "Date": "Tue, 21 Nov 2023 10:56:07 ", "Title": "Classification of Tabular Data by Text Processing", "Authors": ["Keshav Ramani", "Daniel Borrajo"], "Categories": "cs.AI"}, "abstract": "Natural Language Processing technology has advanced vastly in the past decade. Text processing has been successfully applied to a wide variety of domains. In this paper, we propose a novel framework, Text Based Classification(TBC), that uses state of the art text processing techniques to solve classification tasks on tabular data. We provide a set of controlled experiments where we present the benefits of using this approach against other classification methods. Experimental results on several data sets also show that this framework achieves comparable performance to that of several state of the art models in accuracy, precision and recall of predicted classes.", "url": "https://arxiv.org/abs/2311.12521"}, {"metadata": {"arXiv": "2311.12548", "Date": "Tue, 21 Nov 2023 11:57:41 ", "Title": "Multi-Session Budget Optimization for Forward Auction-based Federated Learning", "Authors": ["Xiaoli Tang", "Han Yu"], "Categories": "cs.AI"}, "abstract": "Auction-based Federated Learning (AFL) has emerged as an important research field in recent years. The prevailing strategies for FL model users (MUs) assume that the entire team of the required data owners (DOs) for an FL task must be assembled before training can commence. In practice, an MU can trigger the FL training process multiple times. DOs can thus be gradually recruited over multiple FL model training sessions. Existing bidding strategies for AFL MUs are not designed to handle such scenarios. Therefore, the problem of multi-session AFL remains open. To address this problem, we propose the Multi-session Budget Optimization Strategy for forward Auction-based Federated Learning (MultiBOS-AFL). Based on hierarchical reinforcement learning, MultiBOS-AFL jointly optimizes inter-session budget pacing and intra-session bidding for AFL MUs, with the objective of maximizing the total utility. Extensive experiments on six benchmark datasets show that it significantly outperforms seven state-of-the-art approaches. On average, MultiBOS-AFL achieves 12.28% higher utility, 14.52% more data acquired through auctions for a given budget, and 1.23% higher test accuracy achieved by the resulting FL model compared to the best baseline. To the best of our knowledge, it is the first budget optimization decision support method with budget pacing capability designed for MUs in multi-session forward auction-based federated learning", "url": "https://arxiv.org/abs/2311.12548"}, {"metadata": {"arXiv": "2311.12604", "Date": "Tue, 21 Nov 2023 13:43:58 ", "Title": "Trustworthy AI: Deciding What to Decide", "Authors": ["Caesar Wu", "Yuan-Fang Li", "Jian Li", "Jingjing Xu", "Bouvry Pascal"], "Categories": "cs.AI", "Comments": ["20 pages"]}, "abstract": "When engaging in strategic decision-making, we are frequently confronted with overwhelming information and data. The situation can be further complicated when certain pieces of evidence contradict each other or become paradoxical. The primary challenge is how to determine which information can be trusted when we adopt Artificial Intelligence (AI) systems for decision-making. This issue is known as deciding what to decide or Trustworthy AI. However, the AI system itself is often considered an opaque black box. We propose a new approach to address this issue by introducing a novel framework of Trustworthy AI (TAI) encompassing three crucial components of AI: representation space, loss function, and optimizer. Each component is loosely coupled with four TAI properties. Altogether, the framework consists of twelve TAI properties. We aim to use this framework to conduct the TAI experiments by quantitive and qualitative research methods to satisfy TAI properties for the decision-making context. The framework allows us to formulate an optimal prediction model trained by the given dataset for applying the strategic investment decision of credit default swaps (CDS) in the technology sector. Finally, we provide our view of the future direction of TAI research", "url": "https://arxiv.org/abs/2311.12604"}, {"metadata": {"arXiv": "2311.12668", "Date": "Tue, 21 Nov 2023 15:20:48 ", "Title": "From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design", "Authors": ["Cyril Picard", "Kristen M. Edwards", "Anna C. Doris", "Brandon Man", "Giorgio Giannone", "Md Ferdous Alam", "and Faez Ahmed"], "Categories": "cs.AI cs.CE"}, "abstract": "Engineering Design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision language models, such as GPT-4V, enabling AI to impact many more types of tasks. In light of these advancements, this paper presents a comprehensive evaluation of GPT-4V, a vision language model, across a wide spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Our study assesses GPT-4V's capabilities in design tasks such as sketch similarity analysis, concept selection using Pugh Charts, material selection, engineering drawing analysis, CAD generation, topology optimization, design for additive and subtractive manufacturing, spatial reasoning challenges, and textbook problems. Through this structured evaluation, we not only explore GPT-4V's proficiency in handling complex design and manufacturing challenges but also identify its limitations in complex engineering design applications. Our research establishes a foundation for future assessments of vision language models, emphasizing their immense potential for innovating and enhancing the engineering design and manufacturing landscape. It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field.", "url": "https://arxiv.org/abs/2311.12668"}, {"metadata": {"arXiv": "2311.12719", "Date": "Tue, 21 Nov 2023 16:48:10 ", "Title": "Development of a Legal Document AI-Chatbot", "Authors": ["Pranav Nataraj Devaraj", "Rakesh Teja P V", "Aaryav Gangrade", "Manoj Kumar R"], "Categories": "cs.AI", "Comments": ["5 pages", "5 figures"]}, "abstract": "With the exponential growth of digital data and the increasing complexity of legal documentation, there is a pressing need for efficient and intelligent tools to streamline the handling of legal documents.With the recent developments in the AI field, especially in chatbots, it cannot be ignored as a very compelling solution to this problem.An insight into the process of creating a Legal Documentation AI Chatbot with as many relevant features as possible within the given time frame is presented.The development of each component of the chatbot is presented in detail.Each component's workings and functionality has been discussed.Starting from the build of the Android app and the Langchain query processing code till the integration of both through a Flask backend and REST API methods.", "url": "https://arxiv.org/abs/2311.12719"}, {"metadata": {"arXiv": "2311.12755", "Date": "Tue, 21 Nov 2023 18:02:52 ", "Title": "Digital Twin Framework for Optimal and Autonomous Decision-Making in Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and Gas Industry", "Authors": ["Carine Menezes Rebello", "Johannes J\\\"aschkea", "and Idelfonso B. R. Nogueira"], "Categories": "cs.AI"}, "abstract": "The concept of creating a virtual copy of a complete Cyber-Physical System opens up numerous possibilities, including real-time assessments of the physical environment and continuous learning from the system to provide reliable and precise information. This process, known as the twinning process or the development of a digital twin (DT), has been widely adopted across various industries. However, challenges arise when considering the computational demands of implementing AI models, such as those employed in digital twins, in real-time information exchange scenarios. This work proposes a digital twin framework for optimal and autonomous decision-making applied to a gas-lift process in the oil and gas industry, focusing on enhancing the robustness and adaptability of the DT. The framework combines Bayesian inference, Monte Carlo simulations, transfer learning, online learning, and novel strategies to confer cognition to the DT, including model hyperdimensional reduction and cognitive tack. Consequently, creating a framework for efficient, reliable, and trustworthy DT identification was possible. The proposed approach addresses the current gap in the literature regarding integrating various learning techniques and uncertainty management in digital twin strategies. This digital twin framework aims to provide a reliable and efficient system capable of adapting to changing environments and incorporating prediction uncertainty, thus enhancing the overall decision-making process in complex, real-world scenarios. Additionally, this work lays the foundation for further developments in digital twins for process systems engineering, potentially fostering new advancements and applications across various industrial sectors.", "url": "https://arxiv.org/abs/2311.12755"}, {"metadata": {"arXiv": "2311.12043", "Date": "Fri, 17 Nov 2023 20:49:37 ", "Title": "Efficient Domain Adaptation via Generative Prior for 3D Infant Pose Estimation", "Authors": ["Zhuoran Zhou", "Zhongyu Jiang", "Wenhao Chai", "Cheng-Yen Yang", "Lei Li", "Jenq-Neng Hwang"], "Categories": "cs.CV cs.AI", "Comments": ["WACVW 2024"]}, "abstract": "Although 3D human pose estimation has gained impressive development in recent years, only a few works focus on infants, that have different bone lengths and also have limited data. Directly applying adult pose estimation models typically achieves low performance in the infant domain and suffers from out-of-distribution issues. Moreover, the limitation of infant pose data collection also heavily constrains the efficiency of learning-based models to lift 2D poses to 3D. To deal with the issues of small datasets, domain adaptation and data augmentation are commonly used techniques. Following this paradigm, we take advantage of an optimization-based method that utilizes generative priors to predict 3D infant keypoints from 2D keypoints without the need of large training data. We further apply a guided diffusion model to domain adapt 3D adult pose to infant pose to supplement small datasets. Besides, we also prove that our method, ZeDO-i, could attain efficient domain adaptation, even if only a small number of data is given. Quantitatively, we claim that our model attains state-of-the-art MPJPE performance of 43.6 mm on the SyRIP dataset and 21.2 mm on the MINI-RGBD dataset.", "url": "https://arxiv.org/abs/2311.12043"}, {"metadata": {"arXiv": "2311.12062", "Date": "Sat, 18 Nov 2023 19:41:37 ", "Title": "PBWR: Parametric Building Wireframe Reconstruction from Aerial LiDAR Point Clouds", "Authors": ["Shangfeng Huang", "Ruisheng Wang", "Bo Guo", "Hongxin Yang"], "Categories": "cs.CV cs.AI"}, "abstract": "In this paper, we present an end-to-end 3D building wireframe reconstruction method to regress edges directly from aerial LiDAR point clouds.Our method, named Parametric Building Wireframe Reconstruction (PBWR), takes aerial LiDAR point clouds and initial edge entities as input, and fully uses self-attention mechanism of transformers to regress edge parameters without any intermediate steps such as corner prediction. We propose an edge non-maximum suppression (E-NMS) module based on edge similarityto remove redundant edges. Additionally, a dedicated edge loss function is utilized to guide the PBWR in regressing edges parameters, where simple use of edge distance loss isn't suitable. In our experiments, we demonstrate state-of-the-art results on the Building3D dataset, achieving an improvement of approximately 36% in entry-level dataset edge accuracy and around 42% improvement in the Tallinn dataset.", "url": "https://arxiv.org/abs/2311.12062"}, {"metadata": {"arXiv": "2311.12065", "Date": "Sun, 19 Nov 2023 00:33:41 ", "Title": "Few-Shot Classification & Segmentation Using Large Language Models Agent", "Authors": ["Tian Meng", "Yang Tao", "Wuliang Yin"], "Categories": "cs.CV cs.AI"}, "abstract": "The task of few-shot image classification and segmentation (FS-CS) requires the classification and segmentation of target objects in a query image, given only a few examples of the target classes. We introduce a method that utilises large language models (LLM) as an agent to address the FS-CS problem in a training-free manner. By making the LLM the task planner and off-the-shelf vision models the tools, the proposed method is capable of classifying and segmenting target objects using only image-level labels. Specifically, chain-of-thought prompting and in-context learning guide the LLM to observe support images like human; vision models such as Segment Anything Model (SAM) and GPT-4Vision assist LLM understand spatial and semantic information at the same time. Ultimately, the LLM uses its summarizing and reasoning capabilities to classify and segment the query image. The proposed method's modular framework makes it easily extendable. Our approach achieves state-of-the-art performance on the Pascal-5i dataset.", "url": "https://arxiv.org/abs/2311.12065"}, {"metadata": {"arXiv": "2311.12088", "Date": "Mon, 20 Nov 2023 14:15:48 ", "Title": "PhytNet -- Tailored Convolutional Neural Networks for Custom Botanical Data", "Authors": ["Jamie R. Sykes", "Katherine Denby and Daniel W. Franks"], "Categories": "cs.CV cs.AI"}, "abstract": "Automated disease, weed and crop classification with computer vision will be invaluable in the future of agriculture. However, existing model architectures like ResNet, EfficientNet and ConvNeXt often underperform on smaller, specialised datasets typical of such projects. We address this gap with informed data collection and the development of a new CNN architecture, PhytNet. Utilising a novel dataset of infrared cocoa tree images, we demonstrate PhytNet's development and compare its performance with existing architectures. Data collection was informed by analysis of spectroscopy data, which provided useful insights into the spectral characteristics of cocoa trees. Such information could inform future data collection and model development. Cocoa was chosen as a focal species due to the diverse pathology of its diseases, which pose significant challenges for detection. ResNet18 showed some signs of overfitting, while EfficientNet variants showed distinct signs of overfitting. By contrast, PhytNet displayed excellent attention to relevant features, no overfitting, and an exceptionally low computation cost (1.19 GFLOPS). As such PhytNet is a promising candidate for rapid disease or plant classification, or precise localisation of disease symptoms for autonomous systems.", "url": "https://arxiv.org/abs/2311.12088"}, {"metadata": {"arXiv": "2311.12125", "Date": "Mon, 20 Nov 2023 19:05:57 ", "Title": "Mixing-Denoising Generalizable Occupancy Networks", "Authors": ["Amine Ouasfi and Adnane Boukhayma"], "Categories": "cs.CV cs.AI", "Comments": ["3DV 2024"]}, "abstract": "While current state-of-the-art generalizable implicit neural shape models rely on the inductive bias of convolutions, it is still not entirely clear how properties emerging from such biases are compatible with the task of 3D reconstruction from point cloud. We explore an alternative approach to generalizability in this context. We relax the intrinsic model bias (i.e. using MLPs to encode local features as opposed to convolutions) and constrain the hypothesis space instead with an auxiliary regularization related to the reconstruction task, i.e. denoising. The resulting model is the first only-MLP locally conditioned implicit shape reconstruction from point cloud network with fast feed forward inference. Point cloud borne features and denoising offsets are predicted from an exclusively MLP-made network in a single forward pass. A decoder predicts occupancy probabilities for queries anywhere in space by pooling nearby features from the point cloud order-invariantly, guided by denoised relative positional encoding. We outperform the state-of-the-art convolutional method while using half the number of model parameters.", "url": "https://arxiv.org/abs/2311.12125"}, {"metadata": {"arXiv": "2311.12316", "Date": "Tue, 21 Nov 2023 03:25:51 ", "Title": "Overcoming Pathology Image Data Deficiency: Generating Images from Pathological Transformation Process", "Authors": ["Zeyu Liu", "Yufang He", "Yu Zhao", "Yunlu Feng", "Guanglei Zhang"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "Histopathology serves as the gold standard for medical diagnosis but faces application limitations due to the shortage of medical resources. Leveraging deep learning, computer-aided diagnosis has the potential to alleviate the pathologist scarcity and provide timely clinical analysis. However, developing a reliable model generally necessitates substantial data for training, which is challenging in pathological field. In response, we propose an adaptive depth-controlled bidirectional diffusion (ADBD) network for image data generation. The domain migration approach can work with small trainset and overcome the diffusion overfitting by source information guidance. Specifically, we developed a hybrid attention strategy to blend global and local attention priorities, which guides the bidirectional diffusion and ensures the migration success. In addition, we developed the adaptive depth-controlled strategy to simulate physiological transformations, capable of yielding unlimited cross-domain intermediate images with corresponding soft labels. ADBD is effective for overcoming pathological image data deficiency and supportable for further pathology-related research.", "url": "https://arxiv.org/abs/2311.12316"}, {"metadata": {"arXiv": "2311.12610", "Date": "Tue, 21 Nov 2023 13:52:31 ", "Title": "ChessVision -- A Dataset for Logically Coherent Multi-label Classification", "Authors": ["Soumadeep Saha", "Utpal Garain"], "Categories": "cs.CV cs.AI"}, "abstract": "Starting with early successes in computer vision tasks, deep learning based techniques have since overtaken state of the art approaches in a multitude of domains. However, it has been demonstrated time and again that these techniques fail to capture semantic context and logical constraints, instead often relying on spurious correlations to arrive at the answer. Since application of deep learning techniques to critical scenarios are dependent on adherence to domain specific constraints, several attempts have been made to address this issue. One limitation holding back a thorough exploration of this area, is a lack of suitable datasets which feature a rich set of rules. In order to address this, we present the ChessVision Dataset, consisting of 200,000+ images of annotated chess games in progress, requiring recreation of the game state from its corresponding image. This is accompanied by a curated set of rules which constrains the set of predictions to \"reasonable\" game states, and are designed to probe key semantic abilities like localization and enumeration. Alongside standard metrics, additional metrics to measure performance with regards to logical consistency is presented. We analyze several popular and state of the art vision models on this task, and show that, although their performance on standard metrics are laudable, they produce a plethora of incoherent results, indicating that this dataset presents a significant challenge for future works.", "url": "https://arxiv.org/abs/2311.12610"}, {"metadata": {"arXiv": "2311.12639", "Date": "Tue, 21 Nov 2023 14:39:18 ", "Title": "KNVQA: A Benchmark for evaluation knowledge-based VQA", "Authors": ["Sirui Cheng", "Siyu Zhang", "Jiayi Wu", "Muchen Lan"], "Categories": "cs.CV cs.AI"}, "abstract": "Within the multimodal field, large vision-language models (LVLMs) have made significant progress due to their strong perception and reasoning capabilities in the visual and language systems. However, LVLMs are still plagued by the two critical issues of object hallucination and factual accuracy, which limit the practicality of LVLMs in different scenarios. Furthermore, previous evaluation methods focus more on the comprehension and reasoning of language content but lack a comprehensive evaluation of multimodal interactions, thereby resulting in potential limitations. To this end, we propose a novel KNVQA-Eval, which is devoted to knowledge-based VQA task evaluation to reflect the factuality of multimodal LVLMs. To ensure the robustness and scalability of the evaluation, we develop a new KNVQA dataset by incorporating human judgment and perception, aiming to evaluate the accuracy of standard answers relative to AI-generated answers in knowledge-based VQA. This work not only comprehensively evaluates the contextual information of LVLMs using reliable human annotations, but also further analyzes the fine-grained capabilities of current methods to reveal potential avenues for subsequent optimization of LVLMs-based estimators. Our proposed VQA-Eval and corresponding dataset KNVQA will facilitate the development of automatic evaluation tools with the advantages of low cost, privacy protection, and reproducibility. Our code will be released upon publication.", "url": "https://arxiv.org/abs/2311.12639"}, {"metadata": {"arXiv": "2311.12651", "Date": "Tue, 21 Nov 2023 14:53:02 ", "Title": "Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots", "Authors": ["Youqi Liao", "Shuhao Kang", "Jianping Li", "Yang Liu", "Yun Liu", "Zhen Dong", "Bisheng Yang", "Xieyuanli Chen"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["8 pages", "IEEE conference/letter underreview. Code and additional results are available at: \\url{https://martin-liao.github.io/Mobile-Seed/}"]}, "abstract": "Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel. Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity supervision. Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries. Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on CamVid and PASCAL Context datasets confirm our method's generalizability. Code and additional results are publicly available at \\url{https://martin-liao.github.io/Mobile-Seed/}.", "url": "https://arxiv.org/abs/2311.12651"}, {"metadata": {"arXiv": "2311.12792", "Date": "Tue, 21 Nov 2023 18:58:01 ", "Title": "Intrinsic Image Decomposition via Ordinal Shading", "Authors": ["Chris Careaga and Ya\\u{g}{\\i}z Aksoy"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["24 pages", "23 figures", "Accepted to ACM Transactions on Graphics (2023). Project page: https://yaksoy.github.io/intrinsic/"], "DOI": "10.1145/3630750"}, "abstract": "Intrinsic decomposition is a fundamental mid-level vision problem that plays a crucial role in various inverse rendering and computational photography pipelines. Generating highly accurate intrinsic decompositions is an inherently under-constrained task that requires precisely estimating continuous-valued shading and albedo. In this work, we achieve high-resolution intrinsic decomposition by breaking the problem into two parts. First, we present a dense ordinal shading formulation using a shift- and scale-invariant loss in order to estimate ordinal shading cues without restricting the predictions to obey the intrinsic model. We then combine low- and high-resolution ordinal estimations using a second network to generate a shading estimate with both global coherency and local details. We encourage the model to learn an accurate decomposition by computing losses on the estimated shading as well as the albedo implied by the intrinsic model. We develop a straightforward method for generating dense pseudo ground truth using our model's predictions and multi-illumination data, enabling generalization to in-the-wild imagery. We present an exhaustive qualitative and quantitative analysis of our predicted intrinsic components against state-of-the-art methods. Finally, we demonstrate the real-world applicability of our estimations by performing otherwise difficult editing tasks such as recoloring and relighting.", "url": "https://arxiv.org/abs/2311.12792"}, {"metadata": {"arXiv": "2311.12151", "Date": "Mon, 20 Nov 2023 20:03:34 ", "Title": "Teaching Robots to Build Simulations of Themselves", "Authors": ["Yuhang Hu", "Jiong Lin", "Hod Lipson"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "Simulation enables robots to plan and estimate the outcomes of prospective actions without the need to physically execute them. We introduce a self-supervised learning framework to enable robots model and predict their morphology, kinematics and motor control using only brief raw video data, eliminating the need for extensive real-world data collection and kinematic priors. By observing their own movements, akin to humans watching their reflection in a mirror, robots learn an ability to simulate themselves and predict their spatial motion for various tasks. Our results demonstrate that this self-learned simulation not only enables accurate motion planning but also allows the robot to detect abnormalities and recover from damage.", "url": "https://arxiv.org/abs/2311.12151"}, {"metadata": {"arXiv": "2311.12182", "Date": "Mon, 20 Nov 2023 20:52:10 ", "Title": "Common (good) practices measuring trust in HRI", "Authors": ["Patrick Holthaus and Alessandra Rossi"], "Categories": "cs.RO cs.AI", "Comments": ["In SCRITA 2023 Workshop Proceedings (arXiv:2311.05401) held in conjunction with 32nd IEEE International Conference on Robot & Human Interactive Communication", "28/08 - 31/08 2023", "Busan (Korea)"], "Report-no": "SCRITA/2023/10"}, "abstract": "Trust in robots is widely believed to be imperative for the adoption of robots into people's daily lives. It is, therefore, understandable that the literature of the last few decades focuses on measuring how much people trust robots -- and more generally, any agent - to foster such trust in these technologies. Researchers have been exploring how people trust robot in different ways, such as measuring trust on human-robot interactions (HRI) based on textual descriptions or images without any physical contact, during and after interacting with the technology. Nevertheless, trust is a complex behaviour, and it is affected and depends on several factors, including those related to the interacting agents (e.g. humans, robots, pets), itself (e.g. capabilities, reliability), the context (e.g. task), and the environment (e.g. public spaces vs private spaces vs working spaces). In general, most roboticists agree that insufficient levels of trust lead to a risk of disengagement while over-trust in technology can cause over-reliance and inherit dangers, for example, in emergency situations. It is, therefore, very important that the research community has access to reliable methods to measure people's trust in robots and technology. In this position paper, we outline current methods and their strengths, identify (some) weakly covered aspects and discuss the potential for covering a more comprehensive amount of factors influencing trust in HRI.", "url": "https://arxiv.org/abs/2311.12182"}, {"metadata": {"arXiv": "2311.12477", "Date": "Tue, 21 Nov 2023 09:38:03 ", "Title": "Fin-QD: A Computational Design Framework for Soft Grippers: Integrating MAP-Elites and High-fidelity FEM", "Authors": ["Yue Xie", "Xing Wang", "Fumiya Iida", "David Howard"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "7 figures", "conference"]}, "abstract": "Computational design can excite the full potential of soft robotics that has the drawbacks of being highly nonlinear from material, structure, and contact. Up to date, enthusiastic research interests have been demonstrated for individual soft fingers, but the frame design space (how each soft finger is assembled) remains largely unexplored. Computationally design remains challenging for the finger-based soft gripper to grip across multiple geometrical-distinct object types successfully. Including the design space for the gripper frame can bring huge difficulties for conventional optimisation algorithms and fitness calculation methods due to the exponential growth of high-dimensional design space. This work proposes an automated computational design optimisation framework that generates gripper diversity to individually grasp geometrically distinct object types based on a quality-diversity approach. This work first discusses a significantly large design space (28 design parameters) for a finger-based soft gripper, including the rarely-explored design space of finger arrangement that is converted to various configurations to arrange individual soft fingers. Then, a contact-based Finite Element Modelling (FEM) is proposed in SOFA to output high-fidelity grasping data for fitness evaluation and feature measurements. Finally, diverse gripper designs are obtained from the framework while considering features such as the volume and workspace of grippers. This work bridges the gap of computationally exploring the vast design space of finger-based soft grippers while grasping large geometrically distinct object types with a simple control scheme.", "url": "https://arxiv.org/abs/2311.12477"}, {"metadata": {"arXiv": "2311.12279", "Date": "Tue, 21 Nov 2023 01:46:56 ", "Title": "Probabilistic Forecast Reconciliation with Kullback-Leibler Divergence Regularization", "Authors": ["Guanyu Zhang and Feng Li and Yanfei Kang"], "Categories": "cs.AI cs.LG"}, "abstract": "As the popularity of hierarchical point forecast reconciliation methods increases, there is a growing interest in probabilistic forecast reconciliation. Many studies have utilized machine learning or deep learning techniques to implement probabilistic forecasting reconciliation and have made notable progress. However, these methods treat the reconciliation step as a fixed and hard post-processing step, leading to a trade-off between accuracy and coherency. In this paper, we propose a new approach for probabilistic forecast reconciliation. Unlike existing approaches, our proposed approach fuses the prediction step and reconciliation step into a deep learning framework, making the reconciliation step more flexible and soft by introducing the Kullback-Leibler divergence regularization term into the loss function. The approach is evaluated using three hierarchical time series datasets, which shows the advantages of our approach over other probabilistic forecast reconciliation methods.", "url": "https://arxiv.org/abs/2311.12279"}, {"metadata": {"arXiv": "2311.12310", "Date": "Tue, 21 Nov 2023 03:02:33 ", "Title": "IEKM: A Model Incorporating External Keyword Matrices", "Authors": ["Cheng Luo", "Qin Li", "Zhao Yan", "Mengliang Rao and Yunbo Cao"], "Categories": "cs.AI cs.LG"}, "abstract": "A customer service platform system with a core text semantic similarity (STS) task faces two urgent challenges: Firstly, one platform system needs to adapt to different domains of customers, i.e., different domains adaptation (DDA). Secondly, it is difficult for the model of the platform system to distinguish sentence pairs that are literally close but semantically different, i.e., hard negative samples. In this paper, we propose an incorporation external keywords matrices model (IEKM) to address these challenges. The model uses external tools or dictionaries to construct external matrices and fuses them to the self-attention layers of the Transformer structure through gating units, thus enabling flexible corrections to the model results. We evaluate the method on multiple datasets and the results show that our method has improved performance on all datasets. To demonstrate that our method can effectively solve all the above challenges, we conduct a flexible correction experiment, which results in an increase in the F1 value from 56.61 to 73.53. Our code will be publicly available.", "url": "https://arxiv.org/abs/2311.12310"}, {"metadata": {"arXiv": "2311.12435", "Date": "Tue, 21 Nov 2023 08:44:38 ", "Title": "Fair Enough? A map of the current limitations of the requirements to have \"fair'' algorithms", "Authors": ["Alessandro Castelnovo", "Nicole Inverardi", "Gabriele Nanino", "Ilaria Giuseppina Penco", "Daniele Regoli"], "Categories": "cs.AI cs.CY cs.HC cs.LG", "Comments": ["20 pages", "2 figures", "2 tables"]}, "abstract": "In the recent years, the raise in the usage and efficiency of Artificial Intelligence and, more in general, of Automated Decision-Making systems has brought with it an increasing and welcome awareness of the risks associated with such systems. One of such risks is that of perpetuating or even amplifying bias and unjust disparities present in the data from which many of these systems learn to adjust and optimise their decisions. This awareness has on one side encouraged several scientific communities to come up with more and more appropriate ways and methods to assess, quantify, and possibly mitigate such biases and disparities. On the other hand, it has prompted more and more layers of society, including policy makers, to call for ``fair'' algorithms. We believe that while a lot of excellent and multidisciplinary research is currently being conducted, what is still fundamentally missing is the awareness that having ``fair'' algorithms is per s\\'e a nearly meaningless requirement, that needs to be complemented with a lot of additional societal choices to become actionable. Namely, there is a hiatus between what the society is demanding from Automated Decision-Making systems, and what this demand actually means in real-world scenarios. In this work, we outline the key features of such a hiatus, and pinpoint a list of fundamental ambiguities and attention points that we as a society must address in order to give a concrete meaning to the increasing demand of fairness in Automated Decision-Making systems.", "url": "https://arxiv.org/abs/2311.12435"}, {"metadata": {"arXiv": "2311.12056", "Date": "Sat, 18 Nov 2023 13:55:05 ", "Title": "Kuro Siwo: 12.1 billion $m^2$ under the water. A global multi-temporal satellite dataset for rapid flood mapping", "Authors": ["Nikolaos Ioannis Bountos", "Maria Sdraka", "Angelos Zavras", "Ilektra Karasante", "Andreas Karavias", "Themistocles Herekakis", "Angeliki Thanasou", "Dimitrios Michail", "Ioannis Papoutsis"], "Categories": "cs.CV cs.AI cs.LG eess.IV", "ACM-class": "I.2; I.4; I.5.4"}, "abstract": "Global floods, exacerbated by climate change, pose severe threats to human life, infrastructure, and the environment. This urgency is highlighted by recent catastrophic events in Pakistan and New Zealand, underlining the critical need for precise flood mapping for guiding restoration efforts, understanding vulnerabilities, and preparing for future events. While Synthetic Aperture Radar (SAR) offers day-and-night, all-weather imaging capabilities, harnessing it for deep learning is hindered by the absence of a large annotated dataset. To bridge this gap, we introduce Kuro Siwo, a meticulously curated multi-temporal dataset, spanning 32 flood events globally. Our dataset maps more than 63 billion m2 of land, with 12.1 billion of them being either a flooded area or a permanent water body. Kuro Siwo stands out for its unparalleled annotation quality to facilitate rapid flood mapping in a supervised setting. We also augment learning by including a large unlabeled set of SAR samples, aimed at self-supervised pretraining. We provide an extensive benchmark and strong baselines for a diverse set of flood events from Europe, America, Africa and Australia. Our benchmark demonstrates the quality of Kuro Siwo annotations, training models that can achieve $\\approx$ 85% and $\\approx$ 87% in F1-score for flooded areas and general water detection respectively. This work calls on the deep learning community to develop solution-driven algorithms for rapid flood mapping, with the potential to aid civil protection and humanitarian agencies amid climate change challenges. Our code and data will be made available at https://github.com/Orion-AI-Lab/KuroSiwo", "url": "https://arxiv.org/abs/2311.12056"}, {"metadata": {"arXiv": "2311.12068", "Date": "Sun, 19 Nov 2023 17:28:28 ", "Title": "Enhancing Novel Object Detection via Cooperative Foundational Models", "Authors": ["Rohit Bharadwaj", "Muzammal Naseer", "Salman Khan", "Fahad Shahbaz Khan"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code: https://github.com/rohit901/cooperative-foundational-models"]}, "abstract": "In this work, we address the challenging and emergent problem of novel object detection (NOD), focusing on the accurate detection of both known and novel object categories during inference. Traditional object detection algorithms are inherently closed-set, limiting their capability to handle NOD. We present a novel approach to transform existing closed-set detectors into open-set detectors. This transformation is achieved by leveraging the complementary strengths of pre-trained foundational models, specifically CLIP and SAM, through our cooperative mechanism. Furthermore, by integrating this mechanism with state-of-the-art open-set detectors such as GDINO, we establish new benchmarks in object detection performance. Our method achieves 17.42 mAP in novel object detection and 42.08 mAP for known objects on the challenging LVIS dataset. Adapting our approach to the COCO OVD split, we surpass the current state-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our code is available at https://github.com/rohit901/cooperative-foundational-models .", "url": "https://arxiv.org/abs/2311.12068"}, {"metadata": {"arXiv": "2311.12159", "Date": "Mon, 20 Nov 2023 20:24:45 ", "Title": "Conditional Modeling Based Automatic Video Summarization", "Authors": ["Jia-Hong Huang", "Chao-Han Huck Yang", "Pin-Yu Chen", "Min-Hung Chen", "Marcel Worring"], "Categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "Comments": ["This work has been submitted to the IEEE for possible publication. arXiv admin note: substantial text overlap with arXiv:2305.00455"]}, "abstract": "The aim of video summarization is to shorten videos automatically while retaining the key information necessary to convey the overall story. Video summarization methods mainly rely on visual factors, such as visual consecutiveness and diversity, which may not be sufficient to fully understand the content of the video. There are other non-visual factors, such as interestingness, representativeness, and storyline consistency that should also be considered for generating high-quality video summaries. Current methods do not adequately take into account these non-visual factors, resulting in suboptimal performance. In this work, a new approach to video summarization is proposed based on insights gained from how humans create ground truth video summaries. The method utilizes a conditional modeling perspective and introduces multiple meaningful random variables and joint distributions to characterize the key components of video summarization. Helper distributions are employed to improve the training of the model. A conditional attention module is designed to mitigate potential performance degradation in the presence of multi-modal input. The proposed video summarization method incorporates the above innovative design choices that aim to narrow the gap between human-generated and machine-generated video summaries. Extensive experiments show that the proposed approach outperforms existing methods and achieves state-of-the-art performance on commonly used video summarization datasets.", "url": "https://arxiv.org/abs/2311.12159"}, {"metadata": {"arXiv": "2311.12345", "Date": "Tue, 21 Nov 2023 04:38:21 ", "Title": "Stable Diffusion For Aerial Object Detection", "Authors": ["Yanan Jian", "Fuxun Yu", "Simranjit Singh", "Dimitrios Stamoulis"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at NeurIPS 2023 Synthetic Data Generation with Generative AI workshop"]}, "abstract": "Aerial object detection is a challenging task, in which one major obstacle lies in the limitations of large-scale data collection and the long-tail distribution of certain classes. Synthetic data offers a promising solution, especially with recent advances in diffusion-based methods like stable diffusion (SD). However, the direct application of diffusion methods to aerial domains poses unique challenges: stable diffusion's optimization for rich ground-level semantics doesn't align with the sparse nature of aerial objects, and the extraction of post-synthesis object coordinates remains problematic. To address these challenges, we introduce a synthetic data augmentation framework tailored for aerial images. It encompasses sparse-to-dense region of interest (ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model with low-rank adaptation (LORA) to circumvent exhaustive retraining, and finally, a Copy-Paste method to compose synthesized objects with backgrounds, providing a nuanced approach to aerial object detection through synthetic data.", "url": "https://arxiv.org/abs/2311.12345"}, {"metadata": {"arXiv": "2311.12359", "Date": "Tue, 21 Nov 2023 05:27:16 ", "Title": "Post-Training Quantization with Low-precision Minifloats and Integers on FPGAs", "Authors": ["Shivam Aggarwal", "Alessandro Pappalardo", "Hans Jakob Damsgaard", "Giuseppe Franco", "Thomas B. Preu{\\ss}er", "Michaela Blott", "Tulika Mitra"], "Categories": "cs.CV cs.AI cs.AR cs.LG cs.PF"}, "abstract": "Post-Training Quantization (PTQ) is a powerful technique for model compression, reducing the precision of neural networks without additional training overhead. Recent works have investigated adopting 8-bit floating-point quantization (FP8) in the context of PTQ for model inference. However, the exploration of floating-point formats smaller than 8 bits and their comparison with integer quantization remains relatively limited. In this work, we present minifloats, which are reduced-precision floating-point formats capable of further reducing the memory footprint, latency, and energy cost of a model while approaching full-precision model accuracy. Our work presents a novel PTQ design-space exploration, comparing minifloat and integer quantization schemes across a range of 3 to 8 bits for both weights and activations. We examine the applicability of various PTQ techniques to minifloats, including weight equalization, bias correction, SmoothQuant, gradient-based learned rounding, and the GPTQ method. Our experiments validate the effectiveness of low-precision minifloats when compared to their integer counterparts across a spectrum of accuracy-precision trade-offs on a set of reference deep learning vision workloads. Finally, we evaluate our results against an FPGA-based hardware cost model, showing that integer quantization often remains the Pareto-optimal option, given its relatively smaller hardware resource footprint.", "url": "https://arxiv.org/abs/2311.12359"}, {"metadata": {"arXiv": "2311.12589", "Date": "Tue, 21 Nov 2023 13:26:13 ", "Title": "Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images", "Authors": ["Gauransh Sawhney", "Daksh Dave", "Adeel Ahmed", "Jiechao Gao", "Khalid Saleem"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer from a labeled source domain to an unlabeled target domain, navigating the obstacle of domain shift. While Convolutional Neural Networks (CNNs) are a staple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for domain generalization. This paper presents an innovative method to bolster ViT performance in source-free target adaptation, beginning with an evaluation of how key, query, and value elements affect ViT outcomes. Experiments indicate that altering the key component has negligible effects on Transformer performance. Leveraging this discovery, we introduce Domain Representation Images (DRIs), feeding embeddings through the key element. DRIs act as domain-specific markers, effortlessly merging with the training regimen. To assess our method, we perform target adaptation tests on the Cross Instance DRI source-only (SO) control. We measure the efficacy of target adaptation with and without DRIs, against existing benchmarks like SHOT-B* and adaptations via CDTrans. Findings demonstrate that excluding DRIs offers limited gains over SHOT-B*, while their inclusion in the key segment boosts average precision promoting superior domain generalization. This research underscores the vital role of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent for further domain adaptation explorations.", "url": "https://arxiv.org/abs/2311.12589"}, {"metadata": {"arXiv": "2311.12754", "Date": "Tue, 21 Nov 2023 17:59:14 ", "Title": "SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction", "Authors": ["Yuanhui Huang", "Wenzhao Zheng", "Borui Zhang", "Jie Zhou", "Jiwen Lu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code is available at: https://github.com/huang-yh/SelfOcc"]}, "abstract": "3D occupancy prediction is an important task for the robustness of vision-centric autonomous driving, which aims to predict whether each point is occupied in the surrounding 3D space. Existing methods usually require 3D occupancy labels to produce meaningful results. However, it is very laborious to annotate the occupancy status of each voxel. In this paper, we propose SelfOcc to explore a self-supervised way to learn 3D occupancy using only video sequences. We first transform the images into the 3D space (e.g., bird's eye view) to obtain 3D representation of the scene. We directly impose constraints on the 3D representations by treating them as signed distance fields. We can then render 2D images of previous and future frames as self-supervision signals to learn the 3D representations. We propose an MVS-embedded strategy to directly optimize the SDF-induced weights with multiple depth proposals. Our SelfOcc outperforms the previous best method SceneRF by 58.7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc produces high-quality depth and achieves state-of-the-art results on novel depth synthesis, monocular depth estimation, and surround-view depth estimation on the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code: https://github.com/huang-yh/SelfOcc.", "url": "https://arxiv.org/abs/2311.12754"}, {"metadata": {"arXiv": "2311.12089", "Date": "Mon, 20 Nov 2023 16:09:06 ", "Title": "Explaining Deep Learning Models for Age-related Gait Classification based on time series acceleration", "Authors": ["Xiaoping Zheng", "Bert Otten", "Michiel F Reneman", "Claudine JC Lamoth"], "Categories": "cs.LG cs.AI q-bio.NC"}, "abstract": "Gait analysis holds significant importance in monitoring daily health, particularly among older adults. Advancements in sensor technology enable the capture of movement in real-life environments and generate big data. Machine learning, notably deep learning (DL), shows promise to use these big data in gait analysis. However, the inherent black-box nature of these models poses challenges for their clinical application. This study aims to enhance transparency in DL-based gait classification for aged-related gait patterns using Explainable Artificial Intelligence, such as SHAP. A total of 244 subjects, comprising 129 adults and 115 older adults (age>65), were included. They performed a 3-minute walking task while accelerometers were affixed to the lumbar segment L3. DL models, convolutional neural network (CNN) and gated recurrent unit (GRU), were trained using 1-stride and 8-stride accelerations, respectively, to classify adult and older adult groups. SHAP was employed to explain the models' predictions. CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC of 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and an AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher SHAP values to the data from vertical and walking directions, particularly emphasizing data around heel contact, spanning from the terminal swing to loading response phases. Furthermore, SHAP values indicated that GRU did not treat every stride equally. CNN accurately distinguished between adults and older adults based on the characteristics of a single stride's data. GRU achieved accurate classification by considering the relationships and subtle differences between strides. In both models, data around heel contact emerged as most critical, suggesting differences in acceleration and deceleration patterns during walking between different age groups.", "url": "https://arxiv.org/abs/2311.12089"}, {"metadata": {"arXiv": "2311.12244", "Date": "Mon, 20 Nov 2023 23:56:58 ", "Title": "Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning", "Authors": ["Hongming Zhang", "Tongzheng Ren", "Chenjun Xiao", "Dale Schuurmans", "Bo Dai"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["The first two authors contribute equally"]}, "abstract": "In real-world reinforcement learning problems, the state information is often only partially observable, which breaks the basic assumption in Markov decision processes, and thus, leads to inferior performances. Partially Observable Markov Decision Processes have been introduced to explicitly take the issue into account for learning, exploration, and planning, but presenting significant computational and statistical challenges. To address these difficulties, we exploit the representation view, which leads to a coherent design framework for a practically tractable reinforcement learning algorithm upon partial observations. We provide a theoretical analysis for justifying the statistical efficiency of the proposed algorithm. We also empirically demonstrate the proposed algorithm can surpass state-of-the-art performance with partial observations across various benchmarks, therefore, pushing reliable reinforcement learning towards more practical applications.", "url": "https://arxiv.org/abs/2311.12244"}, {"metadata": {"arXiv": "2311.12267", "Date": "Tue, 21 Nov 2023 01:09:11 ", "Title": "Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity", "Authors": ["Jikai Jin and Vasilis Syrgkanis"], "Categories": "cs.LG cs.AI econ.EM stat.AP stat.ML", "Comments": ["43 pages"]}, "abstract": "This paper studies causal representation learning, the task of recovering high-level latent variables and their causal relationships from low-level data that we observe, assuming access to observations generated from multiple environments. While existing works are able to prove full identifiability of the underlying data generating process, they typically assume access to single-node, hard interventions which is rather unrealistic in practice. The main contribution of this paper is characterize a notion of identifiability which is provably the best one can achieve when hard interventions are not available. First, for linear causal models, we provide identifiability guarantee for data observed from general environments without assuming any similarities between them. While the causal graph is shown to be fully recovered, the latent variables are only identified up to an effect-domination ambiguity (EDA). We then propose an algorithm, LiNGCReL which is guaranteed to recover the ground-truth model up to EDA, and we demonstrate its effectiveness via numerical experiments. Moving on to general non-parametric causal models, we prove the same idenfifiability guarantee assuming access to groups of soft interventions. Finally, we provide counterparts of our identifiability results, indicating that EDA is basically inevitable in our setting.", "url": "https://arxiv.org/abs/2311.12267"}, {"metadata": {"arXiv": "2311.12379", "Date": "Tue, 21 Nov 2023 06:41:41 ", "Title": "Infinite forecast combinations based on Dirichlet process", "Authors": ["Yinuo Ren and Feng Li and Yanfei Kang"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Forecast combination integrates information from various sources by consolidating multiple forecast results from the target time series. Instead of the need to select a single optimal forecasting model, this paper introduces a deep learning ensemble forecasting model based on the Dirichlet process. Initially, the learning rate is sampled with three basis distributions as hyperparameters to convert the infinite mixture into a finite one. All checkpoints are collected to establish a deep learning sub-model pool, and weight adjustment and diversity strategies are developed during the combination process. The main advantage of this method is its ability to generate the required base learners through a single training process, utilizing the decaying strategy to tackle the challenge posed by the stochastic nature of gradient descent in determining the optimal learning rate. To ensure the method's generalizability and competitiveness, this paper conducts an empirical analysis using the weekly dataset from the M4 competition and explores sensitivity to the number of models to be combined. The results demonstrate that the ensemble model proposed offers substantial improvements in prediction accuracy and stability compared to a single benchmark model.", "url": "https://arxiv.org/abs/2311.12379"}, {"metadata": {"arXiv": "2311.12524", "Date": "Tue, 21 Nov 2023 11:09:57 ", "Title": "ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models", "Authors": ["Jiankai Tang", "Kegang Wang", "Hongming Hu", "Xiyuxing Zhang", "Peiyu Wang", "Xin Liu", "Yuntao Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "This study concentrates on evaluating the efficacy of Large Language Models (LLMs) in healthcare, with a specific focus on their application in personal anomalous health monitoring. Our research primarily investigates the capabilities of LLMs in interpreting and analyzing physiological data obtained from FDA-approved devices. We conducted an extensive analysis using anomalous physiological data gathered in a simulated low-air-pressure plateau environment. This allowed us to assess the precision and reliability of LLMs in understanding and evaluating users' health status with notable specificity. Our findings reveal that LLMs exhibit exceptional performance in determining medical indicators, including a Mean Absolute Error (MAE) of less than 1 beat per minute for heart rate and less than 1% for oxygen saturation (SpO2). Furthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations remained below 1%, with the overall accuracy of health assessments surpassing 85%. In image analysis tasks, such as interpreting photoplethysmography (PPG) data, our specially adapted GPT models demonstrated remarkable proficiency, achieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate estimation. This study highlights LLMs' dual role as health data analysis tools and pivotal elements in advanced AI health assistants, offering personalized health insights and recommendations within the future health assistant framework.", "url": "https://arxiv.org/abs/2311.12524"}, {"metadata": {"arXiv": "2311.12526", "Date": "Tue, 21 Nov 2023 11:12:03 ", "Title": "Neural Network Pruning by Gradient Descent", "Authors": ["Zhang Zhang", "Ruyi Tao", "Jiang Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "5 figures"]}, "abstract": "The rapid increase in the parameters of deep learning models has led to significant costs, challenging computational efficiency and model interpretability. In this paper, we introduce a novel and straightforward neural network pruning framework that incorporates the Gumbel-Softmax technique. This framework enables the simultaneous optimization of a network's weights and topology in an end-to-end process using stochastic gradient descent. Empirical results demonstrate its exceptional compression capability, maintaining high accuracy on the MNIST dataset with only 0.15\\% of the original network parameters. Moreover, our framework enhances neural network interpretability, not only by allowing easy extraction of feature importance directly from the pruned network but also by enabling visualization of feature symmetry and the pathways of information propagation from features to outcomes. Although the pruning strategy is learned through deep learning, it is surprisingly intuitive and understandable, focusing on selecting key representative features and exploiting data patterns to achieve extreme sparse pruning. We believe our method opens a promising new avenue for deep learning pruning and the creation of interpretable machine learning systems.", "url": "https://arxiv.org/abs/2311.12526"}, {"metadata": {"arXiv": "2311.12538", "Date": "Tue, 21 Nov 2023 11:33:03 ", "Title": "In-Context Learning Functions with Varying Number of Minima", "Authors": ["David Oniani", "Yanshan Wang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large Language Models (LLMs) have proven effective at In-Context Learning (ICL), an ability that allows them to create predictors from labeled examples. Few studies have explored the interplay between ICL and specific properties of functions it attempts to approximate. In our study, we use a formal framework to explore ICL and propose a new task of approximating functions with varying number of minima. We implement a method that allows for producing functions with given inputs as minima. We find that increasing the number of minima degrades ICL performance. At the same time, our evaluation shows that ICL outperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster than 2NN in all settings. We validate the findings through a set of few-shot experiments across various hyperparameter configurations.", "url": "https://arxiv.org/abs/2311.12538"}, {"metadata": {"arXiv": "2311.12716", "Date": "Tue, 21 Nov 2023 16:43:13 ", "Title": "minimax: Efficient Baselines for Autocurricula in JAX", "Authors": ["Minqi Jiang", "Michael Dennis", "Edward Grefenstette", "Tim Rockt\\\"aschel"], "Categories": "cs.LG cs.AI", "Comments": ["Presented at ALOE 2023"]}, "abstract": "Unsupervised environment design (UED) is a form of automatic curriculum learning for training robust decision-making agents to zero-shot transfer into unseen environments. Such autocurricula have received much interest from the RL community. However, UED experiments, based on CPU rollouts and GPU model updates, have often required several weeks of training. This compute requirement is a major obstacle to rapid innovation for the field. This work introduces the minimax library for UED training on accelerated hardware. Using JAX to implement fully-tensorized environments and autocurriculum algorithms, minimax allows the entire training loop to be compiled for hardware acceleration. To provide a petri dish for rapid experimentation, minimax includes a tensorized grid-world based on MiniGrid, in addition to reusable abstractions for conducting autocurricula in procedurally-generated environments. With these components, minimax provides strong UED baselines, including new parallelized variants, which achieve over 120$\\times$ speedups in wall time compared to previous implementations when training with equal batch sizes. The minimax library is available under the Apache 2.0 license at https://github.com/facebookresearch/minimax.", "url": "https://arxiv.org/abs/2311.12716"}, {"metadata": {"arXiv": "2311.12741", "Date": "Tue, 21 Nov 2023 17:30:57 ", "Title": "Content Augmented Graph Neural Networks", "Authors": ["Fatemeh Gholamzadeh Nasrabadi and AmirHossein Kashani and Pegah Zahedi and Mostafa Haghir Chehreghani"], "Categories": "cs.LG cs.AI"}, "abstract": "In recent years, graph neural networks (GNNs) have become a popular tool for solving various problems over graphs. In these models, the link structure of the graph is typically exploited and nodes' embeddings are iteratively updated based on adjacent nodes. Nodes' contents are used solely in the form of feature vectors, served as nodes' first-layer embeddings. However, the filters or convolutions, applied during iterations/layers to these initial embeddings lead to their impact diminish and contribute insignificantly to the final embeddings. In order to address this issue, in this paper we propose augmenting nodes' embeddings by embeddings generating from their content, at higher GNN layers. More precisely, we propose models wherein a structural embedding using a GNN and a content embedding are computed for each node. These two are combined using a combination layer to form the embedding of a node at a given layer. We suggest methods such as using an auto-encoder or building a content graph, to generate content embeddings. In the end, by conducting experiments over several real-world datasets, we demonstrate the high accuracy and performance of our models.", "url": "https://arxiv.org/abs/2311.12741"}, {"metadata": {"arXiv": "2311.12742", "Date": "Tue, 21 Nov 2023 17:31:10 ", "Title": "Image Transformation for IoT Time-Series Data: A Review", "Authors": ["Duygu Altunkaya", "Feyza Yildirim Okay and Suat Ozdemir"], "Categories": "cs.LG cs.AI cs.NI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "In the era of the Internet of Things (IoT), where smartphones, built-in systems, wireless sensors, and nearly every smart device connect through local networks or the internet, billions of smart things communicate with each other and generate vast amounts of time-series data. As IoT time-series data is high-dimensional and high-frequency, time-series classification or regression has been a challenging issue in IoT. Recently, deep learning algorithms have demonstrated superior performance results in time-series data classification in many smart and intelligent IoT applications. However, it is hard to explore the hidden dynamic patterns and trends in time-series. Recent studies show that transforming IoT data into images improves the performance of the learning model. In this paper, we present a review of these studies which use image transformation/encoding techniques in IoT domain. We examine the studies according to their encoding techniques, data types, and application areas. Lastly, we emphasize the challenges and future dimensions of image transformation.", "url": "https://arxiv.org/abs/2311.12742"}, {"metadata": {"arXiv": "2311.12781", "Date": "Tue, 21 Nov 2023 18:45:52 ", "Title": "Quantifying Impairment and Disease Severity Using AI Models Trained on Healthy Subjects", "Authors": ["Boyang Yu", "Aakash Kaku", "Kangning Liu", "Avinash Parnandi", "Emily Fokas", "Anita Venkatesan", "Natasha Pandit", "Rajesh Ranganath", "Heidi Schambra and Carlos Fernandez-Granda"], "Categories": "cs.LG cs.AI q-bio.QM", "Comments": ["32 pages", "10 figures"]}, "abstract": "Automatic assessment of impairment and disease severity is a key challenge in data-driven medicine. We propose a novel framework to address this challenge, which leverages AI models trained exclusively on healthy individuals. The COnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the decrease in confidence of these models when presented with impaired or diseased patients to quantify their deviation from the healthy population. We applied the COBRA score to address a key limitation of current clinical evaluation of upper-body impairment in stroke patients. The gold-standard Fugl-Meyer Assessment (FMA) requires in-person administration by a trained assessor for 30-45 minutes, which restricts monitoring frequency and precludes physicians from adapting rehabilitation protocols to the progress of each patient. The COBRA score, computed automatically in under one minute, is shown to be strongly correlated with the FMA on an independent test cohort for two different data modalities: wearable sensors ($\\rho = 0.845$, 95% CI [0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]). To demonstrate the generalizability of the approach to other conditions, the COBRA score was also applied to quantify severity of knee osteoarthritis from magnetic-resonance imaging scans, again achieving significant correlation with an independent clinical assessment ($\\rho = 0.644$, 95% C.I [0.585,0.696]).", "url": "https://arxiv.org/abs/2311.12781"}, {"metadata": {"arXiv": "2311.12264", "Date": "Tue, 21 Nov 2023 00:59:27 ", "Title": "Resilient Control of Networked Microgrids using Vertical Federated Reinforcement Learning: Designs and Real-Time Test-Bed Validations", "Authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Sheik M. Mohiuddin", "Yuan Liu", "Wei Du", "Veronica Adetola", "Rohit A. Jinsiwale", "Qiuhua Huang", "Tianzhixi Yin", "Ankit Singhal"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["10 pages", "7 figures"]}, "abstract": "Improving system-level resiliency of networked microgrids is an important aspect with increased population of inverter-based resources (IBRs). This paper (1) presents resilient control design in presence of adversarial cyber-events, and proposes a novel federated reinforcement learning (Fed-RL) approach to tackle (a) model complexities, unknown dynamical behaviors of IBR devices, (b) privacy issues regarding data sharing in multi-party-owned networked grids, and (2) transfers learned controls from simulation to hardware-in-the-loop test-bed, thereby bridging the gap between simulation and real world. With these multi-prong objectives, first, we formulate a reinforcement learning (RL) training setup generating episodic trajectories with adversaries (attack signal) injected at the primary controllers of the grid forming (GFM) inverters where RL agents (or controllers) are being trained to mitigate the injected attacks. For networked microgrids, the horizontal Fed-RL method involving distinct independent environments is not appropriate, leading us to develop vertical variant Federated Soft Actor-Critic (FedSAC) algorithm to grasp the interconnected dynamics of networked microgrid. Next, utilizing OpenAI Gym interface, we built a custom simulation set-up in GridLAB-D/HELICS co-simulation platform, named Resilient RL Co-simulation (ResRLCoSIM), to train the RL agents with IEEE 123-bus benchmark test systems comprising 3 interconnected microgrids. Finally, the learned policies in simulation world are transferred to the real-time hardware-in-the-loop test-bed set-up developed using high-fidelity Hypersim platform. Experiments show that the simulator-trained RL controllers produce convincing results with the real-time test-bed set-up, validating the minimization of sim-to-real gap.", "url": "https://arxiv.org/abs/2311.12264"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.04820", "Date": "Sat, 09 Sep 2023 15:18:46 ", "Title": "ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting", "Authors": ["Michael A. Hobley and Victor A. Prisacariu"], "Categories": "cs.CV cs.LG"}, "abstract": "Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.", "url": "https://arxiv.org/abs/2309.04820"}, {"metadata": {"arXiv": "2309.05132", "Date": "Sun, 10 Sep 2023 20:39:53 ", "Title": "DAD++: Improved Data-free Test Time Adversarial Defense", "Authors": ["Gaurav Kumar Nayak", "Inder Khatri", "Shubham Randive", "Ruchit Rawal", "Anirban Chakraborty"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["IJCV Journal (Under Review)"]}, "abstract": "With the increasing deployment of deep neural networks in safety-critical applications such as self-driving cars, medical imaging, anomaly detection, etc., adversarial robustness has become a crucial concern in the reliability of these networks in real-world scenarios. A plethora of works based on adversarial training and regularization-based techniques have been proposed to make these deep networks robust against adversarial attacks. However, these methods require either retraining models or training them from scratch, making them infeasible to defend pre-trained models when access to training data is restricted. To address this problem, we propose a test time Data-free Adversarial Defense (DAD) containing detection and correction frameworks. Moreover, to further improve the efficacy of the correction framework in cases when the detector is under-confident, we propose a soft-detection scheme (dubbed as \"DAD++\"). We conduct a wide range of experiments and ablations on several datasets and network architectures to show the efficacy of our proposed approach. Furthermore, we demonstrate the applicability of our approach in imparting adversarial defense at test time under data-free (or data-efficient) applications/setups, such as Data-free Knowledge Distillation and Source-free Unsupervised Domain Adaptation, as well as Semi-supervised classification frameworks. We observe that in all the experiments and applications, our DAD++ gives an impressive performance against various adversarial attacks with a minimal drop in clean accuracy. The source code is available at: https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense", "url": "https://arxiv.org/abs/2309.05132"}, {"metadata": {"arXiv": "2309.05281", "Date": "Mon, 11 Sep 2023 07:36:16 ", "Title": "Class-Incremental Grouping Network for Continual Audio-Visual Learning", "Authors": ["Shentong Mo", "Weiguo Pian", "Yapeng Tian"], "Categories": "cs.CV cs.LG cs.MM", "Comments": ["ICCV 2023. arXiv admin note: text overlap with arXiv:2303.17056"]}, "abstract": "Continual learning is a challenging problem in which models need to be trained on non-stationary data across sequential tasks for class-incremental learning. While previous methods have focused on using either regularization or rehearsal-based frameworks to alleviate catastrophic forgetting in image classification, they are limited to a single modality and cannot learn compact class-aware cross-modal representations for continual audio-visual learning. To address this gap, we propose a novel class-incremental grouping network (CIGN) that can learn category-wise semantic features to achieve continual audio-visual learning. Our CIGN leverages learnable audio-visual class tokens and audio-visual grouping to continually aggregate class-aware features. Additionally, it utilizes class tokens distillation and continual grouping to prevent forgetting parameters learned from previous tasks, thereby improving the model's ability to capture discriminative audio-visual categories. We conduct extensive experiments on VGGSound-Instruments, VGGSound-100, and VGG-Sound Sources benchmarks. Our experimental results demonstrate that the CIGN achieves state-of-the-art audio-visual class-incremental learning performance. Code is available at https://github.com/stoneMo/CIGN.", "url": "https://arxiv.org/abs/2309.05281"}, {"metadata": {"arXiv": "2309.05517", "Date": "Mon, 11 Sep 2023 15:00:01 ", "Title": "Stream-based Active Learning by Exploiting Temporal Properties in Perception with Temporal Predicted Loss", "Authors": ["Sebastian Schmidt (BMW and TUM) and Stephan G\\\"unnemann (TUM)"], "Categories": "cs.CV cs.LG"}, "abstract": "Active learning (AL) reduces the amount of labeled data needed to train a machine learning model by intelligently choosing which instances to label. Classic pool-based AL requires all data to be present in a datacenter, which can be challenging with the increasing amounts of data needed in deep learning. However, AL on mobile devices and robots, like autonomous cars, can filter the data from perception sensor streams before reaching the datacenter. We exploited the temporal properties for such image streams in our work and proposed the novel temporal predicted loss (TPL) method. To evaluate the stream-based setting properly, we introduced the GTA V streets and the A2D2 streets dataset and made both publicly available. Our experiments showed that our approach significantly improves the diversity of the selection while being an uncertainty-based method. As pool-based approaches are more common in perception applications, we derived a concept for comparing pool-based and stream-based AL, where TPL out-performed state-of-the-art pool- or stream-based approaches for different models. TPL demonstrated a gain of 2.5 precept points (pp) less required data while being significantly faster than pool-based methods.", "url": "https://arxiv.org/abs/2309.05517"}, {"metadata": {"arXiv": "2309.05548", "Date": "Mon, 11 Sep 2023 15:33:00 ", "Title": "Distance-Aware eXplanation Based Learning", "Authors": ["Misgina Tsighe Hagos", "Niamh Belton", "Kathleen M. Curran", "Brian Mac Namee"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at the 35th IEEE International Conference on Tools with Artificial Intelligence", "ICTAI 2023"]}, "abstract": "eXplanation Based Learning (XBL) is an interactive learning approach that provides a transparent method of training deep learning models by interacting with their explanations. XBL augments loss functions to penalize a model based on deviation of its explanations from user annotation of image features. The literature on XBL mostly depends on the intersection of visual model explanations and image feature annotations. We present a method to add a distance-aware explanation loss to categorical losses that trains a learner to focus on important regions of a training dataset. Distance is an appropriate approach for calculating explanation loss since visual model explanations such as Gradient-weighted Class Activation Mapping (Grad-CAMs) are not strictly bounded as annotations and their intersections may not provide complete information on the deviation of a model's focus from relevant image regions. In addition to assessing our model using existing metrics, we propose an interpretability metric for evaluating visual feature-attribution based model explanations that is more informative of the model's performance than existing metrics. We demonstrate performance of our proposed method on three image classification tasks.", "url": "https://arxiv.org/abs/2309.05548"}, {"metadata": {"arXiv": "2309.04499", "Date": "Fri, 08 Sep 2023 00:26:44 ", "Title": "Weighted Unsupervised Domain Adaptation Considering Geometry Features and Engineering Performance of 3D Design Data", "Authors": ["Seungyeon Shin", "Namwoo Kang"], "Categories": "cs.LG"}, "abstract": "The product design process in manufacturing involves iterative design modeling and analysis to achieve the target engineering performance, but such an iterative process is time consuming and computationally expensive. Recently, deep learning-based engineering performance prediction models have been proposed to accelerate design optimization. However, they only guarantee predictions on training data and may be inaccurate when applied to new domain data. In particular, 3D design data have complex features, which means domains with various distributions exist. Thus, the utilization of deep learning has limitations due to the heavy data collection and training burdens. We propose a bi-weighted unsupervised domain adaptation approach that considers the geometry features and engineering performance of 3D design data. It is specialized for deep learning-based engineering performance predictions. Domain-invariant features can be extracted through an adversarial training strategy by using hypothesis discrepancy, and a multi-output regression task can be performed with the extracted features to predict the engineering performance. In particular, we present a source instance weighting method suitable for 3D design data to avoid negative transfers. The developed bi-weighting strategy based on the geometry features and engineering performance of engineering structures is incorporated into the training process. The proposed model is tested on a wheel impact analysis problem to predict the magnitude of the maximum von Mises stress and the corresponding location of 3D road wheels. This mechanism can reduce the target risk for unlabeled target domains on the basis of weighted multi-source domain knowledge and can efficiently replace conventional finite element analysis.", "url": "https://arxiv.org/abs/2309.04499"}, {"metadata": {"arXiv": "2309.04510", "Date": "Fri, 08 Sep 2023 14:05:56 ", "Title": "Decreasing the Computing Time of Bayesian Optimization using Generalizable Memory Pruning", "Authors": ["Alexander E. Siemenn", "Tonio Buonassisi"], "Categories": "cs.LG", "Comments": ["Accepted as a paper in IEEE HPEC 2023"]}, "abstract": "Bayesian optimization (BO) suffers from long computing times when processing highly-dimensional or large data sets. These long computing times are a result of the Gaussian process surrogate model having a polynomial time complexity with the number of experiments. Running BO on high-dimensional or massive data sets becomes intractable due to this time complexity scaling, in turn, hindering experimentation. Alternative surrogate models have been developed to reduce the computing utilization of the BO procedure, however, these methods require mathematical alteration of the inherit surrogate function, pigeonholing use into only that function. In this paper, we demonstrate a generalizable BO wrapper of memory pruning and bounded optimization, capable of being used with any surrogate model and acquisition function. Using this memory pruning approach, we show a decrease in wall-clock computing times per experiment of BO from a polynomially increasing pattern to a sawtooth pattern that has a non-increasing trend without sacrificing convergence performance. Furthermore, we illustrate the generalizability of the approach across two unique data sets, two unique surrogate models, and four unique acquisition functions. All model implementations are run on the MIT Supercloud state-of-the-art computing hardware.", "url": "https://arxiv.org/abs/2309.04510"}, {"metadata": {"arXiv": "2309.04557", "Date": "Fri, 08 Sep 2023 19:17:03 ", "Title": "Regret-Optimal Federated Transfer Learning for Kernel Regression with Applications in American Option Pricing", "Authors": ["Xuwei Yang and Anastasis Kratsios and Florian Krach and Matheus Grasselli and Aurelien Lucchi"], "Categories": "cs.LG math.DS math.OC q-fin.CP", "Comments": ["54 pages", "3 figures"]}, "abstract": "We propose an optimal iterative scheme for federated transfer learning, where a central planner has access to datasets ${\\cal D}_1,\\dots,{\\cal D}_N$ for the same learning model $f_{\\theta}$. Our objective is to minimize the cumulative deviation of the generated parameters $\\{\\theta_i(t)\\}_{t=0}^T$ across all $T$ iterations from the specialized parameters $\\theta^\\star_{1},\\ldots,\\theta^\\star_N$ obtained for each dataset, while respecting the loss function for the model $f_{\\theta(T)}$ produced by the algorithm upon halting. We only allow for continual communication between each of the specialized models (nodes/agents) and the central planner (server), at each iteration (round). For the case where the model $f_{\\theta}$ is a finite-rank kernel regression, we derive explicit updates for the regret-optimal algorithm. By leveraging symmetries within the regret-optimal algorithm, we further develop a nearly regret-optimal heuristic that runs with $\\mathcal{O}(Np^2)$ fewer elementary operations, where $p$ is the dimension of the parameter space. Additionally, we investigate the adversarial robustness of the regret-optimal algorithm showing that an adversary which perturbs $q$ training pairs by at-most $\\varepsilon>0$, across all training sets, cannot reduce the regret-optimal algorithm's regret by more than $\\mathcal{O}(\\varepsilon q \\bar{N}^{1/2})$, where $\\bar{N}$ is the aggregate number of training pairs. To validate our theoretical findings, we conduct numerical experiments in the context of American option pricing, utilizing a randomly generated finite-rank kernel.", "url": "https://arxiv.org/abs/2309.04557"}, {"metadata": {"arXiv": "2309.04558", "Date": "Fri, 08 Sep 2023 19:21:10 ", "Title": "Towards Interpretable Solar Flare Prediction with Attention-based Deep Neural Networks", "Authors": ["Chetraj Pandey", "Anli Ji", "Rafal A. Angryk", "Berkay Aydin"], "Categories": "cs.LG astro-ph.SR", "Comments": ["This is a preprint accepted at the 6th International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)", "2023. 8 pages", "6 figures"]}, "abstract": "Solar flare prediction is a central problem in space weather forecasting and recent developments in machine learning and deep learning accelerated the adoption of complex models for data-driven solar flare forecasting. In this work, we developed an attention-based deep learning model as an improvement over the standard convolutional neural network (CNN) pipeline to perform full-disk binary flare predictions for the occurrence of $\\geq$M1.0-class flares within the next 24 hours. For this task, we collected compressed images created from full-disk line-of-sight (LoS) magnetograms. We used data-augmented oversampling to address the class imbalance issue and used true skill statistic (TSS) and Heidke skill score (HSS) as the evaluation metrics. Furthermore, we interpreted our model by overlaying attention maps on input magnetograms and visualized the important regions focused on by the model that led to the eventual decision. The significant findings of this study are: (i) We successfully implemented an attention-based full-disk flare predictor ready for operational forecasting where the candidate model achieves an average TSS=0.54$\\pm$0.03 and HSS=0.37$\\pm$0.07. (ii) we demonstrated that our full-disk model can learn conspicuous features corresponding to active regions from full-disk magnetogram images, and (iii) our experimental evaluation suggests that our model can predict near-limb flares with adept skill and the predictions are based on relevant active regions (ARs) or AR characteristics from full-disk magnetograms.", "url": "https://arxiv.org/abs/2309.04558"}, {"metadata": {"arXiv": "2309.04589", "Date": "Fri, 08 Sep 2023 20:36:03 ", "Title": "Motif-aware Attribute Masking for Molecular Graph Pre-training", "Authors": ["Eric Inae", "Gang Liu", "Meng Jiang"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Attribute reconstruction is used to predict node or edge features in the pre-training of graph neural networks. Given a large number of molecules, they learn to capture structural knowledge, which is transferable for various downstream property prediction tasks and vital in chemistry, biomedicine, and material science. Previous strategies that randomly select nodes to do attribute masking leverage the information of local neighbors However, the over-reliance of these neighbors inhibits the model's ability to learn from higher-level substructures. For example, the model would learn little from predicting three carbon atoms in a benzene ring based on the other three but could learn more from the inter-connections between the functional groups, or called chemical motifs. In this work, we propose and investigate motif-aware attribute masking strategies to capture inter-motif structures by leveraging the information of atoms in neighboring motifs. Once each graph is decomposed into disjoint motifs, the features for every node within a sample motif are masked. The graph decoder then predicts the masked features of each node within the motif for reconstruction. We evaluate our approach on eight molecular property prediction datasets and demonstrate its advantages.", "url": "https://arxiv.org/abs/2309.04589"}, {"metadata": {"arXiv": "2309.04612", "Date": "Fri, 08 Sep 2023 22:05:27 ", "Title": "Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing", "Authors": ["Wangyang Ying", "Dongjie Wang", "Kunpeng Liu", "Leilei Sun", "Yanjie Fu"], "Categories": "cs.LG"}, "abstract": "Feature generation aims to generate new and meaningful features to create a discriminative representation space.A generated feature is meaningful when the generated feature is from a feature pair with inherent feature interaction. In the real world, experienced data scientists can identify potentially useful feature-feature interactions, and generate meaningful dimensions from an exponentially large search space, in an optimal crossing form over an optimal generation path. But, machines have limited human-like abilities.We generalize such learning tasks as self-optimizing feature generation. Self-optimizing feature generation imposes several under-addressed challenges on existing systems: meaningful, robust, and efficient generation. To tackle these challenges, we propose a principled and generic representation-crossing framework to solve self-optimizing feature generation.To achieve hashing representation, we propose a three-step approach: feature discretization, feature hashing, and descriptive summarization. To achieve reinforcement crossing, we develop a hierarchical reinforcement feature crossing approach.We present extensive experimental results to demonstrate the effectiveness and efficiency of the proposed method. The code is available at https://github.com/yingwangyang/HRC_feature_cross.git.", "url": "https://arxiv.org/abs/2309.04612"}, {"metadata": {"arXiv": "2309.04616", "Date": "Fri, 08 Sep 2023 22:13:03 ", "Title": "Knowledge Distillation-Empowered Digital Twin for Anomaly Detection", "Authors": ["Qinghua Xu", "Shaukat Ali", "Tao Yue", "Zaimovic Nedim", "and Inderjeet Singh"], "Categories": "cs.LG cs.SE", "DOI": "10.1145/3611643.3613879"}, "abstract": "Cyber-physical systems (CPSs), like train control and management systems (TCMS), are becoming ubiquitous in critical infrastructures. As safety-critical systems, ensuring their dependability during operation is crucial. Digital twins (DTs) have been increasingly studied for this purpose owing to their capability of runtime monitoring and warning, prediction and detection of anomalies, etc. However, constructing a DT for anomaly detection in TCMS necessitates sufficient training data and extracting both chronological and context features with high quality. Hence, in this paper, we propose a novel method named KDDT for TCMS anomaly detection. KDDT harnesses a language model (LM) and a long short-term memory (LSTM) network to extract contexts and chronological features, respectively. To enrich data volume, KDDT benefits from out-of-domain data with knowledge distillation (KD). We evaluated KDDT with two datasets from our industry partner Alstom and obtained the F1 scores of 0.931 and 0.915, respectively, demonstrating the effectiveness of KDDT. We also explored individual contributions of the DT model, LM, and KD to the overall performance of KDDT, via a comprehensive empirical study, and observed average F1 score improvements of 12.4%, 3%, and 6.05%, respectively.", "url": "https://arxiv.org/abs/2309.04616"}, {"metadata": {"arXiv": "2309.04644", "Date": "Sat, 09 Sep 2023 00:05:45 ", "Title": "Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay", "Authors": ["Leyan Pan", "Xinyuan Cao"], "Categories": "cs.LG"}, "abstract": "Neural Collapse is a recently observed geometric structure that emerges in the final layer of neural network classifiers. Specifically, Neural Collapse states that at the terminal phase of neural networks training, 1) the intra-class variability of last-layer features tends to zero, 2) the class feature means form an Equiangular Tight Frame (ETF), 3) last-layer class features and weights becomes equal up the scaling, and 4) classification behavior collapses to the nearest class center (NCC) decision rule. This paper investigates the effect of batch normalization and weight decay on the emergence of Neural Collapse. We propose the geometrically intuitive intra-class and inter-class cosine similarity measure which captures multiple core aspects of Neural Collapse. With this measure, we provide theoretical guarantees of Neural Collapse emergence with last-layer batch normalization and weight decay when the regularized cross-entropy loss is near optimal. We also perform further experiments to show that the Neural Collapse is most significant in models with batch normalization and high weight-decay values. Collectively, our results imply that batch normalization and weight decay may be fundamental factors in the emergence of Neural Collapse.", "url": "https://arxiv.org/abs/2309.04644"}, {"metadata": {"arXiv": "2309.04694", "Date": "Sat, 09 Sep 2023 06:18:50 ", "Title": "Redundancy-Free Self-Supervised Relational Learning for Graph Clustering", "Authors": ["Si-Yu Yi", "Wei Ju", "Yifang Qin", "Xiao Luo", "Luchen Liu", "Yong-Dao Zhou", "Ming Zhang"], "Categories": "cs.LG", "Comments": ["Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS 2024)"]}, "abstract": "Graph clustering, which learns the node representations for effective cluster assignments, is a fundamental yet challenging task in data analysis and has received considerable attention accompanied by graph neural networks in recent years. However, most existing methods overlook the inherent relational information among the non-independent and non-identically distributed nodes in a graph. Due to the lack of exploration of relational attributes, the semantic information of the graph-structured data fails to be fully exploited which leads to poor clustering performance. In this paper, we propose a novel self-supervised deep graph clustering method named Relational Redundancy-Free Graph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute- and structure-level relational information from both global and local views based on an autoencoder and a graph autoencoder. To obtain effective representations of the semantic information, we preserve the consistent relation among augmented nodes, whereas the redundant relation is further reduced for learning discriminative embeddings. In addition, a simple yet valid strategy is utilized to alleviate the over-smoothing issue. Extensive experiments are performed on widely used benchmark datasets to validate the superiority of our R$^2$FGC over state-of-the-art baselines. Our codes are available at https://github.com/yisiyu95/R2FGC.", "url": "https://arxiv.org/abs/2309.04694"}, {"metadata": {"arXiv": "2309.04699", "Date": "Sat, 09 Sep 2023 06:45:15 ", "Title": "Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From Noisy, Limited Data", "Authors": ["Robert Stephany", "Christopher Earls"], "Categories": "cs.LG", "Comments": ["29 pages", "8 figures"]}, "abstract": "We introduce Weak-PDE-LEARN, a Partial Differential Equation (PDE) discovery algorithm that can identify non-linear PDEs from noisy, limited measurements of their solutions. Weak-PDE-LEARN uses an adaptive loss function based on weak forms to train a neural network, $U$, to approximate the PDE solution while simultaneously identifying the governing PDE. This approach yields an algorithm that is robust to noise and can discover a range of PDEs directly from noisy, limited measurements of their solutions. We demonstrate the efficacy of Weak-PDE-LEARN by learning several benchmark PDEs.", "url": "https://arxiv.org/abs/2309.04699"}, {"metadata": {"arXiv": "2309.04737", "Date": "Sat, 09 Sep 2023 09:46:32 ", "Title": "Training of Spiking Neural Network joint Curriculum Learning Strategy", "Authors": ["Lingling Tang", "Jielei Chu", "Zhiguo Gong", "Tianrui Li"], "Categories": "cs.LG"}, "abstract": "Starting with small and simple concepts, and gradually introducing complex and difficult concepts is the natural process of human learning. Spiking Neural Networks (SNNs) aim to mimic the way humans process information, but current SNNs models treat all samples equally, which does not align with the principles of human learning and overlooks the biological plausibility of SNNs. To address this, we propose a CL-SNN model that introduces Curriculum Learning(CL) into SNNs, making SNNs learn more like humans and providing higher biological interpretability. CL is a training strategy that advocates presenting easier data to models before gradually introducing more challenging data, mimicking the human learning process. We use a confidence-aware loss to measure and process the samples with different difficulty levels. By learning the confidence of different samples, the model reduces the contribution of difficult samples to parameter optimization automatically. We conducted experiments on static image datasets MNIST, Fashion-MNIST, CIFAR10, and neuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture. The results are promising. To our best knowledge, this is the first proposal to enhance the biologically plausibility of SNNs by introducing CL.", "url": "https://arxiv.org/abs/2309.04737"}, {"metadata": {"arXiv": "2309.04761", "Date": "Sat, 09 Sep 2023 11:20:40 ", "Title": "A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining", "Authors": ["Yuanguo Lin", "Hong Chen", "Wei Xia", "Fan Lin", "Pengcheng Wu", "Zongyue Wang", "Yong Li"], "Categories": "cs.LG cs.CY cs.IR", "Comments": ["21 pages", "5 figures"]}, "abstract": "Educational Data Mining (EDM) has emerged as a vital field of research, which harnesses the power of computational techniques to analyze educational data. With the increasing complexity and diversity of educational data, Deep Learning techniques have shown significant advantages in addressing the challenges associated with analyzing and modeling this data. This survey aims to systematically review the state-of-the-art in EDM with Deep Learning. We begin by providing a brief introduction to EDM and Deep Learning, highlighting their relevance in the context of modern education. Next, we present a detailed review of Deep Learning techniques applied in four typical educational scenarios, including knowledge tracing, undesirable student detecting, performance prediction, and personalized recommendation. Furthermore, a comprehensive overview of public datasets and processing tools for EDM is provided. Finally, we point out emerging trends and future directions in this research area.", "url": "https://arxiv.org/abs/2309.04761"}, {"metadata": {"arXiv": "2309.04782", "Date": "Sat, 09 Sep 2023 13:00:30 ", "Title": "RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition", "Authors": ["Feng Zhou", "Antonio Cicone", "Haomin Zhou"], "Categories": "cs.LG", "Comments": ["8 pages", "4 figure"], "MSC-class": "68T10", "ACM-class": "I.5.1"}, "abstract": "Time-frequency analysis is an important and challenging task in many applications. Fourier and wavelet analysis are two classic methods that have achieved remarkable success in many fields. They also exhibit limitations when applied to nonlinear and non-stationary signals. To address this challenge, a series of nonlinear and adaptive methods, pioneered by the empirical mode decomposition method have been proposed. Their aim is to decompose a non-stationary signal into quasi-stationary components which reveal better features in the time-frequency analysis. Recently, inspired by deep learning, we proposed a novel method called residual recursive convolutional neural network (RRCNN). Not only RRCNN can achieve more stable decomposition than existing methods while batch processing large-scale signals with low computational cost, but also deep learning provides a unique perspective for non-stationary signal decomposition. In this study, we aim to further improve RRCNN with the help of several nimble techniques from deep learning and optimization to ameliorate the method and overcome some of the limitations of this technique.", "url": "https://arxiv.org/abs/2309.04782"}, {"metadata": {"arXiv": "2309.04788", "Date": "Sat, 09 Sep 2023 13:29:17 ", "Title": "Stochastic Gradient Descent outperforms Gradient Descent in recovering a high-dimensional signal in a glassy energy landscape", "Authors": ["Persia Jana Kamali", "Pierfrancesco Urbani"], "Categories": "cs.LG cond-mat.dis-nn", "Comments": ["5 pages + appendix. 3 figures"]}, "abstract": "Stochastic Gradient Descent (SGD) is an out-of-equilibrium algorithm used extensively to train artificial neural networks. However very little is known on to what extent SGD is crucial for to the success of this technology and, in particular, how much it is effective in optimizing high-dimensional non-convex cost functions as compared to other optimization algorithms such as Gradient Descent (GD). In this work we leverage dynamical mean field theory to analyze exactly its performances in the high-dimensional limit. We consider the problem of recovering a hidden high-dimensional non-linearly encrypted signal, a prototype high-dimensional non-convex hard optimization problem. We compare the performances of SGD to GD and we show that SGD largely outperforms GD. In particular, a power law fit of the relaxation time of these algorithms shows that the recovery threshold for SGD with small batch size is smaller than the corresponding one of GD.", "url": "https://arxiv.org/abs/2309.04788"}, {"metadata": {"arXiv": "2309.04810", "Date": "Sat, 09 Sep 2023 14:29:22 ", "Title": "Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization", "Authors": ["Haitz Saez de Ocariz Borde", "Alvaro Arroyo", "Ismael Morales", "Ingmar Posner", "Xiaowen Dong"], "Categories": "cs.LG stat.ML"}, "abstract": "Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. Finally, we design a graph search space based on the calculated distances between candidate manifolds and use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. Extensive experiments on synthetic and real-world datasets confirm the efficacy of our method in identifying the optimal latent geometry for multiple machine learning problems.", "url": "https://arxiv.org/abs/2309.04810"}, {"metadata": {"arXiv": "2309.04824", "Date": "Sat, 09 Sep 2023 15:36:28 ", "Title": "Correcting sampling biases via importancereweighting for spatial modeling", "Authors": ["Boris Prokhorov", "Diana Koldasbayeva", "Alexey Zaytsev"], "Categories": "cs.LG"}, "abstract": "In machine learning models, the estimation of errors is often complex due to distribution bias, particularly in spatial data such as those found in environmental studies. We introduce an approach based on the ideas of importance sampling to obtain an unbiased estimate of the target error. By taking into account difference between desirable error and available data, our method reweights errors at each sample point and neutralizes the shift. Importance sampling technique and kernel density estimation were used for reweighteing. We validate the effectiveness of our approach using artificial data that resemble real-world spatial datasets. Our findings demonstrate advantages of the proposed approach for the estimation of the target error, offering a solution to a distribution shift problem. Overall error of predictions dropped from 7% to just 2% and it gets smaller for larger samples.", "url": "https://arxiv.org/abs/2309.04824"}, {"metadata": {"arXiv": "2309.04837", "Date": "Sat, 09 Sep 2023 16:22:18 ", "Title": "HAct: Out-of-Distribution Detection with Neural Net Activation Histograms", "Authors": ["Sudeepta Mondal and Ganesh Sundaramoorthi"], "Categories": "cs.LG"}, "abstract": "We propose a simple, efficient, and accurate method for detecting out-of-distribution (OOD) data for trained neural networks, a potential first step in methods for OOD generalization. We propose a novel descriptor, HAct - activation histograms, for OOD detection, that is, probability distributions (approximated by histograms) of output values of neural network layers under the influence of incoming data. We demonstrate that HAct is significantly more accurate than state-of-the-art on multiple OOD image classification benchmarks. For instance, our approach achieves a true positive rate (TPR) of 95% with only 0.05% false-positives using Resnet-50 on standard OOD benchmarks, outperforming previous state-of-the-art by 20.66% in the false positive rate (at the same TPR of 95%). The low computational complexity and the ease of implementation make HAct suitable for online implementation in monitoring deployed neural networks in practice at scale.", "url": "https://arxiv.org/abs/2309.04837"}, {"metadata": {"arXiv": "2309.04858", "Date": "Sat, 09 Sep 2023 18:19:47 ", "Title": "Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System", "Authors": ["Daphne Ippolito", "Nicholas Carlini", "Katherine Lee", "Milad Nasr", "Yun William Yu"], "Categories": "cs.LG cs.CL cs.CR", "Comments": ["6 pages", "4 figures", "3 tables. Also", "5 page appendix. Accepted to INLG 2023"]}, "abstract": "Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).", "url": "https://arxiv.org/abs/2309.04858"}, {"metadata": {"arXiv": "2309.04860", "Date": "Sat, 09 Sep 2023 18:47:55 ", "Title": "Approximation Results for Gradient Descent trained Neural Networks", "Authors": ["G. Welper"], "Categories": "cs.LG cs.NA math.NA stat.ML", "MSC-class": "41A46, 65K10, 68T07"}, "abstract": "The paper contains approximation guarantees for neural networks that are trained with gradient flow, with error measured in the continuous $L_2(\\mathbb{S}^{d-1})$-norm on the $d$-dimensional unit sphere and targets that are Sobolev smooth. The networks are fully connected of constant depth and increasing width. Although all layers are trained, the gradient flow convergence is based on a neural tangent kernel (NTK) argument for the non-convex second but last layer. Unlike standard NTK analysis, the continuous error norm implies an under-parametrized regime, possible by the natural smoothness assumption required for approximation. The typical over-parametrization re-enters the results in form of a loss in approximation rate relative to established approximation methods for Sobolev smooth functions.", "url": "https://arxiv.org/abs/2309.04860"}, {"metadata": {"arXiv": "2309.04875", "Date": "Sat, 09 Sep 2023 20:49:12 ", "Title": "Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference", "Authors": ["Kiwan Maeng", "G. Edward Suh"], "Categories": "cs.LG cs.CR"}, "abstract": "Secure multi-party computation (MPC) allows users to offload machine learning inference on untrusted servers without having to share their privacy-sensitive data. Despite their strong security properties, MPC-based private inference has not been widely adopted in the real world due to their high communication overhead. When evaluating ReLU layers, MPC protocols incur a significant amount of communication between the parties, making the end-to-end execution time multiple orders slower than its non-private counterpart. This paper presents HummingBird, an MPC framework that reduces the ReLU communication overhead significantly by using only a subset of the bits to evaluate ReLU on a smaller ring. Based on theoretical analyses, HummingBird identifies bits in the secret share that are not crucial for accuracy and excludes them during ReLU evaluation to reduce communication. With its efficient search engine, HummingBird discards 87--91% of the bits during ReLU and still maintains high accuracy. On a real MPC setup involving multiple servers, HummingBird achieves on average 2.03--2.67x end-to-end speedup without introducing any errors, and up to 8.64x average speedup when some amount of accuracy degradation can be tolerated, due to its up to 8.76x communication reduction.", "url": "https://arxiv.org/abs/2309.04875"}, {"metadata": {"arXiv": "2309.04877", "Date": "Sat, 09 Sep 2023 21:36:51 ", "Title": "A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning", "Authors": ["Neha S. Wadia", "Yatin Dandi", "and Michael I. Jordan"], "Categories": "cs.LG stat.ML", "Comments": ["36 pages", "7 figures"]}, "abstract": "The rapid progress in machine learning in recent years has been based on a highly productive connection to gradient-based optimization. Further progress hinges in part on a shift in focus from pattern recognition to decision-making and multi-agent problems. In these broader settings, new mathematical challenges emerge that involve equilibria and game theory instead of optima. Gradient-based methods remain essential -- given the high dimensionality and large scale of machine-learning problems -- but simple gradient descent is no longer the point of departure for algorithm design. We provide a gentle introduction to a broader framework for gradient-based algorithms in machine learning, beginning with saddle points and monotone games, and proceeding to general variational inequalities. While we provide convergence proofs for several of the algorithms that we present, our main focus is that of providing motivation and intuition.", "url": "https://arxiv.org/abs/2309.04877"}, {"metadata": {"arXiv": "2309.04885", "Date": "Sat, 09 Sep 2023 22:27:38 ", "Title": "Symplectic Structure-Aware Hamiltonian (Graph) Embeddings", "Authors": ["Jiaxu Liu", "Xinping Yi", "Tianle Zhang", "Xiaowei Huang"], "Categories": "cs.LG math.SG", "Comments": ["5 pages main content with 3 pages appendix"]}, "abstract": "In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To this end, we empirically validate SAH-GNN's superior performance and adaptability in node classification tasks across multiple types of graph datasets.", "url": "https://arxiv.org/abs/2309.04885"}, {"metadata": {"arXiv": "2309.04941", "Date": "Sun, 10 Sep 2023 06:13:29 ", "Title": "Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power", "Authors": ["Junru Zhou", "Jiarui Feng", "Xiyuan Wang", "Muhan Zhang"], "Categories": "cs.LG"}, "abstract": "The ability of graph neural networks (GNNs) to count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs -- $d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs. $d$-DRFWL(2) GNNs use node pairs whose mutual distances are at most $d$ as the units for message passing to balance the expressive power and complexity. By performing message passing among distance-restricted node pairs in the original graph, $d$-DRFWL(2) GNNs avoid the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically show that the discriminative power of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. More importantly, $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, our model is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles.", "url": "https://arxiv.org/abs/2309.04941"}, {"metadata": {"arXiv": "2309.05019", "Date": "Sun, 10 Sep 2023 12:44:54 ", "Title": "SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models", "Authors": ["Shuchen Xue", "Mingyang Yi", "Weijian Luo", "Shifeng Zhang", "Jiacheng Sun", "Zhenguo Li", "Zhi-Ming Ma"], "Categories": "cs.LG stat.ML"}, "abstract": "Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID scores on substantial benchmark datasets under a suitable number of function evaluations (NFEs).", "url": "https://arxiv.org/abs/2309.05019"}, {"metadata": {"arXiv": "2309.05077", "Date": "Sun, 10 Sep 2023 16:55:59 ", "Title": "Generalization error bounds for iterative learning algorithms with bounded updates", "Authors": ["Jingwen Fu and Nanning Zheng"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously observed scaling behavior in large language models. Ultimately, our work takes a further step for developing practical generalization theories.", "url": "https://arxiv.org/abs/2309.05077"}, {"metadata": {"arXiv": "2309.05079", "Date": "Sun, 10 Sep 2023 16:56:46 ", "Title": "A supervised generative optimization approach for tabular data", "Authors": ["Fadi Hamad", "Shinpei Nakamura-Sakai", "Saheed Obitayo", "Vamsi K. Potluru"], "Categories": "cs.LG"}, "abstract": "Synthetic data generation has emerged as a crucial topic for financial institutions, driven by multiple factors, such as privacy protection and data augmentation. Many algorithms have been proposed for synthetic data generation but reaching the consensus on which method we should use for the specific data sets and use cases remains challenging. Moreover, the majority of existing approaches are ``unsupervised'' in the sense that they do not take into account the downstream task. To address these issues, this work presents a novel synthetic data generation framework. The framework integrates a supervised component tailored to the specific downstream task and employs a meta-learning approach to learn the optimal mixture distribution of existing synthetic distributions.", "url": "https://arxiv.org/abs/2309.05079"}, {"metadata": {"arXiv": "2309.05202", "Date": "Mon, 11 Sep 2023 02:35:22 ", "Title": "Graph Contextual Contrasting for Multivariate Time Series Classification", "Authors": ["Yucheng Wang", "Yuecong Xu", "Jianfei Yang", "Min Wu", "Xiaoli Li", "Lihua Xie", "Zhenghua Chen"], "Categories": "cs.LG", "Comments": ["9 pages", "5 figures"]}, "abstract": "Contrastive learning, as a self-supervised learning paradigm, becomes popular for Multivariate Time-Series (MTS) classification. It ensures the consistency across different views of unlabeled samples and then learns effective representations for these samples. Existing contrastive learning methods mainly focus on achieving temporal consistency with temporal augmentation and contrasting techniques, aiming to preserve temporal patterns against perturbations for MTS data. However, they overlook spatial consistency that requires the stability of individual sensors and their correlations. As MTS data typically originate from multiple sensors, ensuring spatial consistency becomes essential for the overall performance of contrastive learning on MTS data. Thus, we propose Graph Contextual Contrasting (GCC) for spatial consistency across MTS data. Specifically, we propose graph augmentations including node and edge augmentations to preserve the stability of sensors and their correlations, followed by graph contrasting with both node- and graph-level contrasting to extract robust sensor- and global-level features. We further introduce multi-window temporal contrasting to ensure temporal consistency in the data for each sensor. Extensive experiments demonstrate that our proposed GCC achieves state-of-the-art performance on various MTS classification tasks.", "url": "https://arxiv.org/abs/2309.05202"}, {"metadata": {"arXiv": "2309.05256", "Date": "Mon, 11 Sep 2023 06:26:57 ", "Title": "Examining the Effect of Pre-training on Time Series Classification", "Authors": ["Jiashu Pu", "Shiwei Zhao", "Ling Cheng", "Yongzhu Chang", "Runze Wu", "Tangjie Lv", "Rongsheng Zhang"], "Categories": "cs.LG"}, "abstract": "Although the pre-training followed by fine-tuning paradigm is used extensively in many fields, there is still some controversy surrounding the impact of pre-training on the fine-tuning process. Currently, experimental findings based on text and image data lack consensus. To delve deeper into the unsupervised pre-training followed by fine-tuning paradigm, we have extended previous research to a new modality: time series. In this study, we conducted a thorough examination of 150 classification datasets derived from the Univariate Time Series (UTS) and Multivariate Time Series (MTS) benchmarks. Our analysis reveals several key conclusions. (i) Pre-training can only help improve the optimization process for models that fit the data poorly, rather than those that fit the data well. (ii) Pre-training does not exhibit the effect of regularization when given sufficient training time. (iii) Pre-training can only speed up convergence if the model has sufficient ability to fit the data. (iv) Adding more pre-training data does not improve generalization, but it can strengthen the advantage of pre-training on the original data volume, such as faster convergence. (v) While both the pre-training task and the model structure determine the effectiveness of the paradigm on a given dataset, the model structure plays a more significant role.", "url": "https://arxiv.org/abs/2309.05256"}, {"metadata": {"arXiv": "2309.05259", "Date": "Mon, 11 Sep 2023 06:31:45 ", "Title": "A physics-informed and attention-based graph learning approach for regional electric vehicle charging demand prediction", "Authors": ["Haohao Qu", "Haoxuan Kuang", "Jun Li", "Linlin You"], "Categories": "cs.LG", "Comments": ["Preprint. This work has been submitted to the IEEE Transactions on ITS for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Along with the proliferation of electric vehicles (EVs), optimizing the use of EV charging space can significantly alleviate the growing load on intelligent transportation systems. As the foundation to achieve such an optimization, a spatiotemporal method for EV charging demand prediction in urban areas is required. Although several solutions have been proposed by using data-driven deep learning methods, it can be found that these performance-oriented methods may suffer from misinterpretations to correctly handle the reverse relationship between charging demands and prices. To tackle the emerging challenges of training an accurate and interpretable prediction model, this paper proposes a novel approach that enables the integration of graph and temporal attention mechanisms for feature extraction and the usage of physic-informed meta-learning in the model pre-training step for knowledge transfer. Evaluation results on a dataset of 18,013 EV charging piles in Shenzhen, China, show that the proposed approach, named PAG, can achieve state-of-the-art forecasting performance and the ability in understanding the adaptive changes in charging demands caused by price fluctuations.", "url": "https://arxiv.org/abs/2309.05259"}, {"metadata": {"arXiv": "2309.05292", "Date": "Mon, 11 Sep 2023 08:21:42 ", "Title": "The fine print on tempered posteriors", "Authors": ["Konstantinos Pitas", "Julyan Arbel"], "Categories": "cs.LG stat.ML"}, "abstract": "We conduct a detailed investigation of tempered posteriors and uncover a number of crucial and previously undiscussed points. Contrary to previous results, we first show that for realistic models and datasets and the tightly controlled case of the Laplace approximation to the posterior, stochasticity does not in general improve test accuracy. The coldest temperature is often optimal. One might think that Bayesian models with some stochasticity can at least obtain improvements in terms of calibration. However, we show empirically that when gains are obtained this comes at the cost of degradation in test accuracy. We then discuss how targeting Frequentist metrics using Bayesian models provides a simple explanation of the need for a temperature parameter $\\lambda$ in the optimization objective. Contrary to prior works, we finally show through a PAC-Bayesian analysis that the temperature $\\lambda$ cannot be seen as simply fixing a misspecified prior or likelihood.", "url": "https://arxiv.org/abs/2309.05292"}, {"metadata": {"arXiv": "2309.05305", "Date": "Mon, 11 Sep 2023 08:44:07 ", "Title": "Fully-Connected Spatial-Temporal Graph for Multivariate Time Series Data", "Authors": ["Yucheng Wang", "Yuecong Xu", "Jianfei Yang", "Min Wu", "Xiaoli Li", "Lihua Xie", "Zhenghua Chen"], "Categories": "cs.LG", "Comments": ["9 pages", "8 figures"]}, "abstract": "Multivariate Time-Series (MTS) data is crucial in various application fields. With its sequential and multi-source (multiple sensors) properties, MTS data inherently exhibits Spatial-Temporal (ST) dependencies, involving temporal correlations between timestamps and spatial correlations between sensors in each timestamp. To effectively leverage this information, Graph Neural Network-based methods (GNNs) have been widely adopted. However, existing approaches separately capture spatial dependency and temporal dependency and fail to capture the correlations between Different sEnsors at Different Timestamps (DEDT). Overlooking such correlations hinders the comprehensive modelling of ST dependencies within MTS data, thus restricting existing GNNs from learning effective representations. To address this limitation, we propose a novel method called Fully-Connected Spatial-Temporal Graph Neural Network (FC-STGNN), including two key components namely FC graph construction and FC graph convolution. For graph construction, we design a decay graph to connect sensors across all timestamps based on their temporal distances, enabling us to fully model the ST dependencies by considering the correlations between DEDT. Further, we devise FC graph convolution with a moving-pooling GNN layer to effectively capture the ST dependencies for learning effective representations. Extensive experiments show the effectiveness of FC-STGNN on multiple MTS datasets compared to SOTA methods.", "url": "https://arxiv.org/abs/2309.05305"}, {"metadata": {"arXiv": "2309.05317", "Date": "Mon, 11 Sep 2023 09:04:36 ", "Title": "Neural Koopman prior for data assimilation", "Authors": ["Anthony Frion", "Lucas Drumetz", "Mauro Dalla Mura", "Guillaume Tochon", "Abdeldjalil A\\\"issa El Bey"], "Categories": "cs.LG"}, "abstract": "With the increasing availability of large scale datasets, computational power and tools like automatic differentiation and expressive neural network architectures, sequential data are now often treated in a data-driven way, with a dynamical model trained from the observation data. While neural networks are often seen as uninterpretable black-box architectures, they can still benefit from physical priors on the data and from mathematical knowledge. In this paper, we use a neural network architecture which leverages the long-known Koopman operator theory to embed dynamical systems in latent spaces where their dynamics can be described linearly, enabling a number of appealing features. We introduce methods that enable to train such a model for long-term continuous reconstruction, even in difficult contexts where the data comes in irregularly-sampled time series. The potential for self-supervised learning is also demonstrated, as we show the promising use of trained dynamical models as priors for variational data assimilation techniques, with applications to e.g. time series interpolation and forecasting.", "url": "https://arxiv.org/abs/2309.05317"}, {"metadata": {"arXiv": "2309.05346", "Date": "Mon, 11 Sep 2023 09:45:22 ", "Title": "Learning Geometric Representations of Objects via Interaction", "Authors": ["Alfredo Reichlin", "Giovanni Luca Marchetti", "Hang Yin", "Anastasiia Varava", "Danica Kragic"], "Categories": "cs.LG cs.CV"}, "abstract": "We address the problem of learning representations from observations of a scene involving an agent and an external object the agent interacts with. To this end, we propose a representation learning framework extracting the location in physical space of both the agent and the object from unstructured observations of arbitrary nature. Our framework relies on the actions performed by the agent as the only source of supervision, while assuming that the object is displaced by the agent via unknown dynamics. We provide a theoretical foundation and formally prove that an ideal learner is guaranteed to infer an isometric representation, disentangling the agent from the object and correctly extracting their locations. We evaluate empirically our framework on a variety of scenarios, showing that it outperforms vision-based approaches such as a state-of-the-art keypoint extractor. We moreover demonstrate how the extracted representations enable the agent to solve downstream tasks via reinforcement learning in an efficient manner.", "url": "https://arxiv.org/abs/2309.05346"}, {"metadata": {"arXiv": "2309.05352", "Date": "Mon, 11 Sep 2023 09:53:28 ", "Title": "Neural Discovery of Permutation Subgroups", "Authors": ["Pavan Karjol", "Rohan Kashyap", "Prathosh A P"], "Categories": "cs.LG", "Journal-ref": "In International Conference on Artificial Intelligence and Statistics, pp. 4668-4678. Volume 206. PMLR, 2023"}, "abstract": "We consider the problem of discovering subgroup $H$ of permutation group $S_{n}$. Unlike the traditional $H$-invariant networks wherein $H$ is assumed to be known, we present a method to discover the underlying subgroup, given that it satisfies certain conditions. Our results show that one could discover any subgroup of type $S_{k} (k \\leq n)$ by learning an $S_{n}$-invariant function and a linear transformation. We also prove similar results for cyclic and dihedral subgroups. Finally, we provide a general theorem that can be extended to discover other subgroups of $S_{n}$. We also demonstrate the applicability of our results through numerical experiments on image-digit sum and symmetric polynomial regression tasks.", "url": "https://arxiv.org/abs/2309.05352"}, {"metadata": {"arXiv": "2309.05391", "Date": "Mon, 11 Sep 2023 11:42:28 ", "Title": "Career Path Recommendations for Long-term Income Maximization: A Reinforcement Learning Approach", "Authors": ["Spyros Avlonitis and Dor Lavi and Masoud Mansoury and David Graus"], "Categories": "cs.LG", "Comments": ["accepted for publication at RecSys in HR '23 (at the 17th ACM Conference on Recommender Systems)"]}, "abstract": "This study explores the potential of reinforcement learning algorithms to enhance career planning processes. Leveraging data from Randstad The Netherlands, the study simulates the Dutch job market and develops strategies to optimize employees' long-term income. By formulating career planning as a Markov Decision Process (MDP) and utilizing machine learning algorithms such as Sarsa, Q-Learning, and A2C, we learn optimal policies that recommend career paths with high-income occupations and industries. The results demonstrate significant improvements in employees' income trajectories, with RL models, particularly Q-Learning and Sarsa, achieving an average increase of 5% compared to observed career paths. The study acknowledges limitations, including narrow job filtering, simplifications in the environment formulation, and assumptions regarding employment continuity and zero application costs. Future research can explore additional objectives beyond income optimization and address these limitations to further enhance career planning processes.", "url": "https://arxiv.org/abs/2309.05391"}, {"metadata": {"arXiv": "2309.05395", "Date": "Mon, 11 Sep 2023 11:54:42 ", "Title": "Practical Homomorphic Aggregation for Byzantine ML", "Authors": ["Antoine Choffrut", "Rachid Guerraoui", "Rafael Pinot", "Renaud Sirdey", "John Stephan", "and Martin Zuber"], "Categories": "cs.LG cs.CR cs.DC"}, "abstract": "Due to the large-scale availability of data, machine learning (ML) algorithms are being deployed in distributed topologies, where different nodes collaborate to train ML models over their individual data by exchanging model-related information (e.g., gradients) with a central server. However, distributed learning schemes are notably vulnerable to two threats. First, Byzantine nodes can single-handedly corrupt the learning by sending incorrect information to the server, e.g., erroneous gradients. The standard approach to mitigate such behavior is to use a non-linear robust aggregation method at the server. Second, the server can violate the privacy of the nodes. Recent attacks have shown that exchanging (unencrypted) gradients enables a curious server to recover the totality of the nodes' data. The use of homomorphic encryption (HE), a gold standard security primitive, has extensively been studied as a privacy-preserving solution to distributed learning in non-Byzantine scenarios. However, due to HE's large computational demand especially for high-dimensional ML models, there has not yet been any attempt to design purely homomorphic operators for non-linear robust aggregators. In this work, we present SABLE, the first completely homomorphic and Byzantine robust distributed learning algorithm. SABLE essentially relies on a novel plaintext encoding method that enables us to implement the robust aggregator over batching-friendly BGV. Moreover, this encoding scheme also accelerates state-of-the-art homomorphic sorting with larger security margins and smaller ciphertext size. We perform extensive experiments on image classification tasks and show that our algorithm achieves practical execution times while matching the ML performance of its non-private counterpart.", "url": "https://arxiv.org/abs/2309.05395"}, {"metadata": {"arXiv": "2309.05404", "Date": "Mon, 11 Sep 2023 12:10:19 ", "Title": "Physics-informed reinforcement learning via probabilistic co-adjustment functions", "Authors": ["Nat Wannawas", "A. Aldo Faisal"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Reinforcement learning of real-world tasks is very data inefficient, and extensive simulation-based modelling has become the dominant approach for training systems. However, in human-robot interaction and many other real-world settings, there is no appropriate one-model-for-all due to differences in individual instances of the system (e.g. different people) or necessary oversimplifications in the simulation models. This requires two approaches: 1. either learning the individual system's dynamics approximately from data which requires data-intensive training or 2. using a complete digital twin of the instances, which may not be realisable in many cases. We introduce two approaches: co-kriging adjustments (CKA) and ridge regression adjustment (RRA) as novel ways to combine the advantages of both approaches. Our adjustment methods are based on an auto-regressive AR1 co-kriging model that we integrate with GP priors. This yield a data- and simulation-efficient way of using simplistic simulation models (e.g., simple two-link model) and rapidly adapting them to individual instances (e.g., biomechanics of individual people). Using CKA and RRA, we obtain more accurate uncertainty quantification of the entire system's dynamics than pure GP-based and AR1 methods. We demonstrate the efficiency of co-kriging adjustment with an interpretable reinforcement learning control example, learning to control a biomechanical human arm using only a two-link arm simulation model (offline part) and CKA derived from a small amount of interaction data (on-the-fly online). Our method unlocks an efficient and uncertainty-aware way to implement reinforcement learning methods in real world complex systems for which only imperfect simulation models exist.", "url": "https://arxiv.org/abs/2309.05404"}, {"metadata": {"arXiv": "2309.05434", "Date": "Mon, 11 Sep 2023 13:13:54 ", "Title": "A parameterised model for link prediction using node centrality and similarity measure based on graph embedding", "Authors": ["Haohui Lu and Shahadat Uddin"], "Categories": "cs.LG cs.SI"}, "abstract": "Link prediction is a key aspect of graph machine learning, with applications as diverse as disease prediction, social network recommendations, and drug discovery. It involves predicting new links that may form between network nodes. Despite the clear importance of link prediction, existing models have significant shortcomings. Graph Convolutional Networks, for instance, have been proven to be highly efficient for link prediction on a variety of datasets. However, they encounter severe limitations when applied to short-path networks and ego networks, resulting in poor performance. This presents a critical problem space that this work aims to address. In this paper, we present the Node Centrality and Similarity Based Parameterised Model (NCSM), a novel method for link prediction tasks. NCSM uniquely integrates node centrality and similarity measures as edge features in a customised Graph Neural Network (GNN) layer, effectively leveraging the topological information of large networks. This model represents the first parameterised GNN-based link prediction model that considers topological information. The proposed model was evaluated on five benchmark graph datasets, each comprising thousands of nodes and edges. Experimental results highlight NCSM's superiority over existing state-of-the-art models like Graph Convolutional Networks and Variational Graph Autoencoder, as it outperforms them across various metrics and datasets. This exceptional performance can be attributed to NCSM's innovative integration of node centrality, similarity measures, and its efficient use of topological information.", "url": "https://arxiv.org/abs/2309.05434"}, {"metadata": {"arXiv": "2309.05436", "Date": "Mon, 11 Sep 2023 13:18:19 ", "Title": "Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models", "Authors": ["Frederiek Wesel", "Kim Batselier"], "Categories": "cs.LG", "ACM-class": "I.5.0"}, "abstract": "In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting quantized models have a higher bound on the VC-dimension as opposed to their non-quantized counterparts, at no additional computational cost while learning from identical features. We verify experimentally how this additional tensorization regularizes the learning problem by prioritizing the most salient features in the data and how it provides models with increased generalization capabilities. We finally benchmark our approach on large regression task, achieving state-of-the-art results on a laptop computer.", "url": "https://arxiv.org/abs/2309.05436"}, {"metadata": {"arXiv": "2309.05477", "Date": "Mon, 11 Sep 2023 14:16:37 ", "Title": "Learning Objective-Specific Active Learning Strategies with Attentive Neural Processes", "Authors": ["Tim Bakker", "Herke van Hoof", "Max Welling"], "Categories": "cs.LG", "Comments": ["Accepted at ECML 2023"]}, "abstract": "Pool-based active learning (AL) is a promising technology for increasing data-efficiency of machine learning models. However, surveys show that performance of recent AL methods is very sensitive to the choice of dataset and training setting, making them unsuitable for general application. In order to tackle this problem, the field Learning Active Learning (LAL) suggests to learn the active learning strategy itself, allowing it to adapt to the given setting. In this work, we propose a novel LAL method for classification that exploits symmetry and independence properties of the active learning problem with an Attentive Conditional Neural Process model. Our approach is based on learning from a myopic oracle, which gives our model the ability to adapt to non-standard objectives, such as those that do not equally weight the error on all data points. We experimentally verify that our Neural Process model outperforms a variety of baselines in these settings. Finally, our experiments show that our model exhibits a tendency towards improved stability to changing datasets. However, performance is sensitive to choice of classifier and more work is necessary to reduce the performance the gap with the myopic oracle and to improve scalability. We present our work as a proof-of-concept for LAL on nonstandard objectives and hope our analysis and modelling considerations inspire future LAL work.", "url": "https://arxiv.org/abs/2309.05477"}, {"metadata": {"arXiv": "2309.05505", "Date": "Mon, 11 Sep 2023 14:46:55 ", "Title": "Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning", "Authors": ["Zebang Shen", "Jiayuan Ye", "Anmin Kang", "Hamed Hassani", "Reza Shokri"], "Categories": "cs.LG stat.ML", "Comments": ["ICLR 2023 revised"]}, "abstract": "Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy. Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free. Randomized mechanisms can prevent convergence of models on learning even the useful representation functions, especially if there is more disagreement between local models on the classification functions (due to data heterogeneity). In this paper, we consider a representation federated learning objective that encourages various parties to collaboratively refine the consensus part of the model, with differential privacy guarantees, while separately allowing sufficient freedom for local personalization (without releasing it). We prove that in the linear representation setting, while the objective is non-convex, our proposed new algorithm \\DPFEDREP\\ converges to a ball centered around the \\emph{global optimal} solution at a linear rate, and the radius of the ball is proportional to the reciprocal of the privacy budget. With this novel utility analysis, we improve the SOTA utility-privacy trade-off for this problem by a factor of $\\sqrt{d}$, where $d$ is the input dimension. We empirically evaluate our method with the image classification task on CIFAR10, CIFAR100, and EMNIST, and observe a significant performance improvement over the prior work under the same small privacy budget. The code can be found in this link: https://github.com/shenzebang/CENTAUR-Privacy-Federated-Representation-Learning.", "url": "https://arxiv.org/abs/2309.05505"}, {"metadata": {"arXiv": "2309.05521", "Date": "Mon, 11 Sep 2023 15:04:46 ", "Title": "Re-formalization of Individual Fairness", "Authors": ["Toshihiro Kamishima"], "Categories": "cs.LG cs.CY cs.IR", "Comments": ["Published at the 6th FAccTRec Workshop: Responsible Recommendation"]}, "abstract": "The notion of individual fairness is a formalization of an ethical principle, \"Treating like cases alike,\" which has been argued such as by Aristotle. In a fairness-aware machine learning context, Dwork et al. firstly formalized the notion. In their formalization, a similar pair of data in an unfair space should be mapped to similar positions in a fair space. We propose to re-formalize individual fairness by the statistical independence conditioned by individuals. This re-formalization has the following merits. First, our formalization is compatible with that of Dwork et al. Second, our formalization enables to combine individual fairness with the fairness notion, equalized odds or sufficiency, as well as statistical parity. Third, though their formalization implicitly assumes a pre-process approach for making fair prediction, our formalization is applicable to an in-process or post-process approach.", "url": "https://arxiv.org/abs/2309.05521"}, {"metadata": {"arXiv": "2309.04655", "Date": "Sat, 09 Sep 2023 01:30:07 ", "Title": "Intelligent upper-limb exoskeleton using deep learning to predict human intention for sensory-feedback augmentation", "Authors": ["Jinwoo Lee", "Kangkyu Kwon", "Ira Soltis", "Jared Matthews", "Yoonjae Lee", "Hojoong Kim", "Lissette Romero", "Nathan Zavanelli", "Youngjin Kwon", "Shinjae Kwon", "Jimin Lee", "Yewon Na", "Sung Hoon Lee", "Ki Jun Yu", "Minoru Shinohara", "Frank L. Hammond", "Woon-Hong Yeo"], "Categories": "cs.RO cs.LG cs.SY eess.SP eess.SY", "Comments": ["15 pages", "6 figures", "1 table", "Submitted for possible publication"], "MSC-class": "68T40 (Primary) 92C55, 68T99 (Secondary)"}, "abstract": "The age and stroke-associated decline in musculoskeletal strength degrades the ability to perform daily human tasks using the upper extremities. Although there are a few examples of exoskeletons, they need manual operations due to the absence of sensor feedback and no intention prediction of movements. Here, we introduce an intelligent upper-limb exoskeleton system that uses cloud-based deep learning to predict human intention for strength augmentation. The embedded soft wearable sensors provide sensory feedback by collecting real-time muscle signals, which are simultaneously computed to determine the user's intended movement. The cloud-based deep-learning predicts four upper-limb joint motions with an average accuracy of 96.2% at a 200-250 millisecond response rate, suggesting that the exoskeleton operates just by human intention. In addition, an array of soft pneumatics assists the intended movements by providing 897 newton of force and 78.7 millimeter of displacement at maximum. Collectively, the intent-driven exoskeleton can augment human strength by 5.15 times on average compared to the unassisted exoskeleton. This report demonstrates an exoskeleton robot that augments the upper-limb joint movements by human intention based on a machine-learning cloud computing and sensory feedback.", "url": "https://arxiv.org/abs/2309.04655"}, {"metadata": {"arXiv": "2309.05200", "Date": "Mon, 11 Sep 2023 02:30:06 ", "Title": "CARE: Confidence-rich Autonomous Robot Exploration using Bayesian Kernel Inference and Optimization", "Authors": ["Yang Xu", "Ronghao Zheng", "Senlin Zhang", "Meiqin Liu", "Shoudong Huang"], "Categories": "cs.RO cs.LG", "Comments": ["Full version for the paper accepted by IEEE Robotics and Automation Letters (RA-L) 2023. arXiv admin note: text overlap with arXiv:2301.00523"], "Journal-ref": "IEEE Robotics and Automation Letters, 2023", "DOI": "10.1109/LRA.2023.3313054"}, "abstract": "In this paper, we consider improving the efficiency of information-based autonomous robot exploration in unknown and complex environments. We first utilize Gaussian process (GP) regression to learn a surrogate model to infer the confidence-rich mutual information (CRMI) of querying control actions, then adopt an objective function consisting of predicted CRMI values and prediction uncertainties to conduct Bayesian optimization (BO), i.e., GP-based BO (GPBO). The trade-off between the best action with the highest CRMI value (exploitation) and the action with high prediction variance (exploration) can be realized. To further improve the efficiency of GPBO, we propose a novel lightweight information gain inference method based on Bayesian kernel inference and optimization (BKIO), achieving an approximate logarithmic complexity without the need for training. BKIO can also infer the CRMI and generate the best action using BO with bounded cumulative regret, which ensures its comparable accuracy to GPBO with much higher efficiency. Extensive numerical and real-world experiments show the desired efficiency of our proposed methods without losing exploration performance in different unstructured, cluttered environments. We also provide our open-source implementation code at https://github.com/Shepherd-Gregory/BKIO-Exploration.", "url": "https://arxiv.org/abs/2309.05200"}, {"metadata": {"arXiv": "2309.05339", "Date": "Mon, 11 Sep 2023 09:35:51 ", "Title": "PAg-NeRF: Towards fast and efficient end-to-end panoptic 3D representations for agricultural robotics", "Authors": ["Claus Smitt", "Michael Halstead", "Patrick Zimmer", "Thomas L\\\"abe", "Esra Guclu", "Cyrill Stachniss", "Chris McCool"], "Categories": "cs.RO cs.CV cs.LG"}, "abstract": "Precise scene understanding is key for most robot monitoring and intervention tasks in agriculture. In this work we present PAg-NeRF which is a novel NeRF-based system that enables 3D panoptic scene understanding. Our representation is trained using an image sequence with noisy robot odometry poses and automatic panoptic predictions with inconsistent IDs between frames. Despite this noisy input, our system is able to output scene geometry, photo-realistic renders and 3D consistent panoptic representations with consistent instance IDs. We evaluate this novel system in a very challenging horticultural scenario and in doing so demonstrate an end-to-end trainable system that can make use of noisy robot poses rather than precise poses that have to be pre-calculated. Compared to a baseline approach the peak signal to noise ratio is improved from 21.34dB to 23.37dB while the panoptic quality improves from 56.65% to 70.08%. Furthermore, our approach is faster and can be tuned to improve inference time by more than a factor of 2 while being memory efficient with approximately 12 times fewer parameters.", "url": "https://arxiv.org/abs/2309.05339"}, {"metadata": {"arXiv": "2309.05655", "Date": "Mon, 11 Sep 2023 17:49:25 ", "Title": "Dynamic Handover: Throw and Catch with Bimanual Hands", "Authors": ["Binghao Huang", "Yuanpei Chen", "Tianyu Wang", "Yuzhe Qin", "Yaodong Yang", "Nikolay Atanasov", "Xiaolong Wang"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted at CoRL 2023. https://binghao-huang.github.io/dynamic_handover/"]}, "abstract": "Humans throw and catch objects all the time. However, such a seemingly common skill introduces a lot of challenges for robots to achieve: The robots need to operate such dynamic actions at high-speed, collaborate precisely, and interact with diverse objects. In this paper, we design a system with two multi-finger hands attached to robot arms to solve this problem. We train our system using Multi-Agent Reinforcement Learning in simulation and perform Sim2Real transfer to deploy on the real robots. To overcome the Sim2Real gap, we provide multiple novel algorithm designs including learning a trajectory prediction model for the object. Such a model can help the robot catcher has a real-time estimation of where the object will be heading, and then react accordingly. We conduct our experiments with multiple objects in the real-world system, and show significant improvements over multiple baselines. Our project page is available at \\url{https://binghao-huang.github.io/dynamic_handover/}.", "url": "https://arxiv.org/abs/2309.05655"}, {"metadata": {"arXiv": "2309.04492", "Date": "Wed, 06 Sep 2023 05:35:48 ", "Title": "Safe Neural Control for Non-Affine Control Systems with Differentiable Control Barrier Functions", "Authors": ["Wei Xiao and Ross Allen and Daniela Rus"], "Categories": "cs.SY cs.LG cs.RO eess.SY", "Comments": ["8 pages", "accepted in IEEE CDC 2023"]}, "abstract": "This paper addresses the problem of safety-critical control for non-affine control systems. It has been shown that optimizing quadratic costs subject to state and control constraints can be sub-optimally reduced to a sequence of quadratic programs (QPs) by using Control Barrier Functions (CBFs). Our recently proposed High Order CBFs (HOCBFs) can accommodate constraints of arbitrary relative degree. The main challenges in this approach are that it requires affine control dynamics and the solution of the CBF-based QP is sub-optimal since it is solved point-wise. To address these challenges, we incorporate higher-order CBFs into neural ordinary differential equation-based learning models as differentiable CBFs to guarantee safety for non-affine control systems. The differentiable CBFs are trainable in terms of their parameters, and thus, they can address the conservativeness of CBFs such that the system state will not stay unnecessarily far away from safe set boundaries. Moreover, the imitation learning model is capable of learning complex and optimal control policies that are usually intractable online. We illustrate the effectiveness of the proposed framework on LiDAR-based autonomous driving and compare it with existing methods.", "url": "https://arxiv.org/abs/2309.04492"}, {"metadata": {"arXiv": "2309.05386", "Date": "Mon, 11 Sep 2023 11:18:16 ", "Title": "Data-Driven Model Reduction and Nonlinear Model Predictive Control of an Air Separation Unit by Applied Koopman Theory", "Authors": ["Jan C. Schulze", "Danimir T. Doncevic", "Nils Erwes", "Alexander Mitsos"], "Categories": "eess.SY cs.LG cs.SY", "Journal-ref": "Foundations of Computer Aided Process Operations / Chemical Process Control (FOCAPO), 2023"}, "abstract": "Achieving real-time capability is an essential prerequisite for the industrial implementation of nonlinear model predictive control (NMPC). Data-driven model reduction offers a way to obtain low-order control models from complex digital twins. In particular, data-driven approaches require little expert knowledge of the particular process and its model, and provide reduced models of a well-defined generic structure. Herein, we apply our recently proposed data-driven reduction strategy based on Koopman theory [Schulze et al. (2022), Comput. Chem. Eng.] to generate a low-order control model of an air separation unit (ASU). The reduced Koopman model combines autoencoders and linear latent dynamics and is constructed using machine learning. Further, we present an NMPC implementation that uses derivative computation tailored to the fixed block structure of reduced Koopman models. Our reduction approach with tailored NMPC implementation enables real-time NMPC of an ASU at an average CPU time decrease by 98 %.", "url": "https://arxiv.org/abs/2309.05386"}, {"metadata": {"arXiv": "2309.04487", "Date": "Wed, 30 Aug 2023 09:09:27 ", "Title": "Penalization Framework For Autonomous Agents Using Answer Set Programming", "Authors": ["Vineel S. K. Tummala"], "Categories": "cs.AI cs.LO", "Comments": ["In Proceedings ICLP 2023", "arXiv:2308.14898"], "Journal-ref": "EPTCS 385, 2023, pp. 411-415", "DOI": "10.4204/EPTCS.385.50"}, "abstract": "This paper presents a framework for enforcing penalties on intelligent agents that do not comply with authorization or obligation policies in a changing environment. A framework is proposed to represent and reason about penalties in plans, and an algorithm is proposed to penalize an agent's actions based on their level of compliance with respect to authorization and obligation policies. Being aware of penalties an agent can choose a plan with a minimal total penalty, unless there is an emergency goal like saving a human's life. The paper concludes that this framework can reprimand insubordinate agents.", "url": "https://arxiv.org/abs/2309.04487"}, {"metadata": {"arXiv": "2309.05076", "Date": "Sun, 10 Sep 2023 16:55:49 ", "Title": "An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language Model Game Agents", "Authors": ["Maximilian Croissant", "Madeleine Frister", "Guy Schofield", "Cade McCall"], "Categories": "cs.AI cs.CL cs.HC"}, "abstract": "The development of believable, natural, and interactive digital artificial agents is a field of growing interest. Theoretical uncertainties and technical barriers present considerable challenges to the field, particularly with regards to developing agents that effectively simulate human emotions. Large language models (LLMs) might address these issues by tapping common patterns in situational appraisal. In three empirical experiments, this study tests the capabilities of LLMs to solve emotional intelligence tasks and to simulate emotions. It presents and evaluates a new chain-of-emotion architecture for emotion simulation within video games, based on psychological appraisal research. Results show that it outperforms standard LLM architectures on a range of user experience and content analysis metrics. This study therefore provides early evidence of how to construct and test affective agents based on cognitive processes represented in language models.", "url": "https://arxiv.org/abs/2309.05076"}, {"metadata": {"arXiv": "2309.05217", "Date": "Mon, 11 Sep 2023 03:35:00 ", "Title": "Quantifying and Attributing the Hallucination of Large Language Models via Association Analysis", "Authors": ["Li Du", "Yequan Wang", "Xingrun Xing", "Yiqun Ya", "Xiang Li", "Xin Jiang", "Xuezhi Fang"], "Categories": "cs.AI cs.CL"}, "abstract": "Although demonstrating superb performance on various NLP tasks, large language models (LLMs) still suffer from the hallucination problem, which threatens the reliability of LLMs. To measure the level of hallucination of LLMs, previous works first categorize the hallucination according to the phenomenon similarity, then quantify the proportion that model outputs contain hallucinatory contents. However, such hallucination rates could easily be distorted by confounders. Moreover, such hallucination rates could not reflect the reasons for the hallucination, as similar hallucinatory phenomena may originate from different sources. To address these issues, we propose to combine the hallucination level quantification and hallucination reason investigation through an association analysis, which builds the relationship between the hallucination rate of LLMs with a set of risk factors. In this way, we are able to observe the hallucination level under each value of each risk factor, examining the contribution and statistical significance of each risk factor, meanwhile excluding the confounding effect of other factors. Additionally, by recognizing the risk factors according to a taxonomy of model capability, we reveal a set of potential deficiencies in commonsense memorization, relational reasoning, and instruction following, which may further provide guidance for the pretraining and supervised fine-tuning process of LLMs to mitigate the hallucination.", "url": "https://arxiv.org/abs/2309.05217"}, {"metadata": {"arXiv": "2309.05371", "Date": "Mon, 11 Sep 2023 10:48:42 ", "Title": "Exploring Minecraft Settlement Generators with Generative Shift Analysis", "Authors": ["Jean-Baptiste Herv\\'e", "Oliver Withington", "Marion Herv\\'e", "Laurissa Tokarchuk", "Christoph Salge"], "Categories": "cs.AI"}, "abstract": "With growing interest in Procedural Content Generation (PCG) it becomes increasingly important to develop methods and tools for evaluating and comparing alternative systems. There is a particular lack regarding the evaluation of generative pipelines, where a set of generative systems work in series to make iterative changes to an artifact. We introduce a novel method called Generative Shift for evaluating the impact of individual stages in a PCG pipeline by quantifying the impact that a generative process has when it is applied to a pre-existing artifact. We explore this technique by applying it to a very rich dataset of Minecraft game maps produced by a set of alternative settlement generators developed as part of the Generative Design in Minecraft Competition (GDMC), all of which are designed to produce appropriate settlements for a pre-existing map. While this is an early exploration of this technique we find it to be a promising lens to apply to PCG evaluation, and we are optimistic about the potential of Generative Shift to be a domain-agnostic method for evaluating generative pipelines.", "url": "https://arxiv.org/abs/2309.05371"}, {"metadata": {"arXiv": "2309.05378", "Date": "Mon, 11 Sep 2023 10:58:51 ", "Title": "Steps Towards Satisficing Distributed Dynamic Team Trust", "Authors": ["Edmund R. Hunt", "Chris Baber", "Mehdi Sobhani", "Sanja Milivojevic", "Sagir Yusuf", "Mirco Musolesi", "Patrick Waterson", "Sally Maynard"], "Categories": "cs.AI cs.HC cs.RO"}, "abstract": "Defining and measuring trust in dynamic, multiagent teams is important in a range of contexts, particularly in defense and security domains. Team members should be trusted to work towards agreed goals and in accordance with shared values. In this paper, our concern is with the definition of goals and values such that it is possible to define 'trust' in a way that is interpretable, and hence usable, by both humans and robots. We argue that the outcome of team activity can be considered in terms of 'goal', 'individual/team values', and 'legal principles'. We question whether alignment is possible at the level of 'individual/team values', or only at the 'goal' and 'legal principles' levels. We argue for a set of metrics to define trust in human-robot teams that are interpretable by human or robot team members, and consider an experiment that could demonstrate the notion of 'satisficing trust' over the course of a simulated mission.", "url": "https://arxiv.org/abs/2309.05378"}, {"metadata": {"arXiv": "2309.05529", "Date": "Mon, 11 Sep 2023 15:13:36 ", "Title": "On the meaning of uncertainty for ethical AI: philosophy and practice", "Authors": ["Cassandra Bird", "Daniel Williamson and Sabina Leonelli (University of Exeter)"], "Categories": "cs.AI math.ST stat.TH", "Comments": ["26 pages", "2 figures"]}, "abstract": "Whether and how data scientists, statisticians and modellers should be accountable for the AI systems they develop remains a controversial and highly debated topic, especially given the complexity of AI systems and the difficulties in comparing and synthesising competing claims arising from their deployment for data analysis. This paper proposes to address this issue by decreasing the opacity and heightening the accountability of decision making using AI systems, through the explicit acknowledgement of the statistical foundations that underpin their development and the ways in which these dictate how their results should be interpreted and acted upon by users. In turn, this enhances (1) the responsiveness of the models to feedback, (2) the quality and meaning of uncertainty on their outputs and (3) their transparency to evaluation. To exemplify this approach, we extend Posterior Belief Assessment to offer a route to belief ownership from complex and competing AI structures. We argue that this is a significant way to bring ethical considerations into mathematical reasoning, and to implement ethical AI in statistical practice. We demonstrate these ideas within the context of competing models used to advise the UK government on the spread of the Omicron variant of COVID-19 during December 2021.", "url": "https://arxiv.org/abs/2309.05529"}, {"metadata": {"arXiv": "2309.05638", "Date": "Mon, 11 Sep 2023 17:29:28 ", "Title": "Combinative Cumulative Knowledge Processes", "Authors": ["Anna Brandenberger", "Cassandra Marcussen", "Elchanan Mossel", "Madhu Sudan"], "Categories": "cs.AI cs.DS cs.SI math.PR", "Comments": ["28 pages", "8 figures"]}, "abstract": "We analyze Cumulative Knowledge Processes, introduced by Ben-Eliezer, Mikulincer, Mossel, and Sudan (ITCS 2023), in the setting of \"directed acyclic graphs\", i.e., when new units of knowledge may be derived by combining multiple previous units of knowledge. The main considerations in this model are the role of errors (when new units may be erroneous) and local checking (where a few antecedent units of knowledge are checked when a new unit of knowledge is discovered). The aforementioned work defined this model but only analyzed an idealized and simplified \"tree-like\" setting, i.e., a setting where new units of knowledge only depended directly on one previously generated unit of knowledge. The main goal of our work is to understand when the general process is safe, i.e., when the effect of errors remains under control. We provide some necessary and some sufficient conditions for safety. As in the earlier work, we demonstrate that the frequency of checking as well as the depth of the checks play a crucial role in determining safety. A key new parameter in the current work is the $\\textit{combination factor}$ which is the distribution of the number of units $M$ of old knowledge that a new unit of knowledge depends on. Our results indicate that a large combination factor can compensate for a small depth of checking. The dependency of the safety on the combination factor is far from trivial. Indeed some of our main results are stated in terms of $\\mathbb{E}\\{1/M\\}$ while others depend on $\\mathbb{E}\\{M\\}$.", "url": "https://arxiv.org/abs/2309.05638"}, {"metadata": {"arXiv": "2309.04579", "Date": "Fri, 08 Sep 2023 20:14:25 ", "Title": "EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras", "Authors": ["Xueyi Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Falls are significant and often fatal for vulnerable populations such as the elderly. Previous works have addressed the detection of falls by relying on data capture by a single sensor, images or accelerometers. In this work, we rely on multimodal descriptors extracted from videos captured by egocentric cameras. Our proposed method includes a late decision fusion layer that builds on top of the extracted descriptors. Furthermore, we collect a new dataset on which we assess our proposed approach. We believe this is the first public dataset of its kind. The dataset comprises 10,948 video samples by 14 subjects. We conducted ablation experiments to assess the performance of individual feature extractors, fusion of visual information, and fusion of both visual and audio information. Moreover, we experimented with internal and external cross-validation. Our results demonstrate that the fusion of audio and visual information through late decision fusion improves detection performance, making it a promising tool for fall prevention and mitigation.", "url": "https://arxiv.org/abs/2309.04579"}, {"metadata": {"arXiv": "2309.04801", "Date": "Sat, 09 Sep 2023 14:00:39 ", "Title": "TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines", "Authors": ["Ole-Christoffer Granmo"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "6 figures"]}, "abstract": "Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to logic-based machine learning. Supporting convolution, they deal successfully with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2. However, the TM struggles with getting state-of-the-art performance on CIFAR-10 and CIFAR-100, representing more complex tasks. This paper introduces plug-and-play collaboration between specialized TMs, referred to as TM Composites. The collaboration relies on a TM's ability to specialize during learning and to assess its competence during inference. When teaming up, the most confident TMs make the decisions, relieving the uncertain ones. In this manner, a TM Composite becomes more competent than its members, benefiting from their specializations. The collaboration is plug-and-play in that members can be combined in any way, at any time, without fine-tuning. We implement three TM specializations in our empirical evaluation: Histogram of Gradients, Adaptive Gaussian Thresholding, and Color Thermometers. The resulting TM Composite increases accuracy on Fashion-MNIST by two percentage points, CIFAR-10 by twelve points, and CIFAR-100 by nine points, yielding new state-of-the-art results for TMs. Overall, we envision that TM Composites will enable an ultra-low energy and transparent alternative to state-of-the-art deep learning on more tasks and datasets.", "url": "https://arxiv.org/abs/2309.04801"}, {"metadata": {"arXiv": "2309.04803", "Date": "Sat, 09 Sep 2023 14:11:37 ", "Title": "Towards Real-World Burst Image Super-Resolution: Benchmark and Method", "Authors": ["Pengxu Wei and Yujing Sun and Xingbei Guo and Chang Liu and Jie Chen and Xiangyang Ji and Liang Lin"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Despite substantial advances, single-image super-resolution (SISR) is always in a dilemma to reconstruct high-quality images with limited information from one input image, especially in realistic scenarios. In this paper, we establish a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to explore the faithful reconstruction of image details from multiple frames. Furthermore, we introduce a Federated Burst Affinity network (FBAnet) to investigate non-trivial pixel-wise displacements among images under real-world image degradation. Specifically, rather than using pixel-wise alignment, our FBAnet employs a simple homography alignment from a structural geometry aspect and a Federated Affinity Fusion (FAF) strategy to aggregate the complementary information among frames. Those fused informative representations are fed to a Transformer-based module of burst representation decoding. Besides, we have conducted extensive experiments on two versions of our datasets, i.e., RealBSR-RAW and RealBSR-RGB. Experimental results demonstrate that our FBAnet outperforms existing state-of-the-art burst SR methods and also achieves visually-pleasant SR image predictions with model details. Our dataset, codes, and models are publicly available at https://github.com/yjsunnn/FBANet.", "url": "https://arxiv.org/abs/2309.04803"}, {"metadata": {"arXiv": "2309.04806", "Date": "Sat, 09 Sep 2023 14:22:12 ", "Title": "Timely Fusion of Surround Radar/Lidar for Object Detection in Autonomous Driving Systems", "Authors": ["Wenjing Xie", "Tao Hu", "Neiwen Ling", "Guoliang Xing", "Shaoshan Liu", "Nan Guan"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at DATE 2023"]}, "abstract": "Fusing Radar and Lidar sensor data can fully utilize their complementary advantages and provide more accurate reconstruction of the surrounding for autonomous driving systems. Surround Radar/Lidar can provide 360-degree view sampling with the minimal cost, which are promising sensing hardware solutions for autonomous driving systems. However, due to the intrinsic physical constraints, the rotating speed of surround Radar, and thus the frequency to generate Radar data frames, is much lower than surround Lidar. Existing Radar/Lidar fusion methods have to work at the low frequency of surround Radar, which cannot meet the high responsiveness requirement of autonomous driving systems.This paper develops techniques to fuse surround Radar/Lidar with working frequency only limited by the faster surround Lidar instead of the slower surround Radar, based on the state-of-the-art object detection model MVDNet. The basic idea of our approach is simple: we let MVDNet work with temporally unaligned data from Radar/Lidar, so that fusion can take place at any time when a new Lidar data frame arrives, instead of waiting for the slow Radar data frame. However, directly applying MVDNet to temporally unaligned Radar/Lidar data greatly degrades its object detection accuracy. The key information revealed in this paper is that we can achieve high output frequency with little accuracy loss by enhancing the training procedure to explore the temporal redundancy in MVDNet so that it can tolerate the temporal unalignment of input data. We explore several different ways of training enhancement and compare them quantitatively with experiments.", "url": "https://arxiv.org/abs/2309.04806"}, {"metadata": {"arXiv": "2309.04891", "Date": "Sat, 09 Sep 2023 23:03:50 ", "Title": "How to Evaluate Semantic Communications for Images with ViTScore Metric?", "Authors": ["Tingting Zhu", "Bo Peng", "Jifan Liang", "Tingchen Han", "Hai Wan", "Jingqiao Fu", "and Junjie Chen"], "Categories": "cs.CV cs.AI cs.IT math.IT"}, "abstract": "Semantic communications (SC) have been expected to be a new paradigm shifting to catalyze the next generation communication, whose main concerns shift from accurate bit transmission to effective semantic information exchange in communications. However, the previous and widely-used metrics for images are not applicable to evaluate the image semantic similarity in SC. Classical metrics to measure the similarity between two images usually rely on the pixel level or the structural level, such as the PSNR and the MS-SSIM. Straightforwardly using some tailored metrics based on deep-learning methods in CV community, such as the LPIPS, is infeasible for SC. To tackle this, inspired by BERTScore in NLP community, we propose a novel metric for evaluating image semantic similarity, named Vision Transformer Score (ViTScore). We prove theoretically that ViTScore has 3 important properties, including symmetry, boundedness, and normalization, which make ViTScore convenient and intuitive for image measurement. To evaluate the performance of ViTScore, we compare ViTScore with 3 typical metrics (PSNR, MS-SSIM, and LPIPS) through 5 classes of experiments. Experimental results demonstrate that ViTScore can better evaluate the image semantic similarity than the other 3 typical metrics, which indicates that ViTScore is an effective performance metric when deployed in SC scenarios.", "url": "https://arxiv.org/abs/2309.04891"}, {"metadata": {"arXiv": "2309.04907", "Date": "Sun, 10 Sep 2023 01:23:05 ", "Title": "Effective Real Image Editing with Accelerated Iterative Diffusion Inversion", "Authors": ["Zhihong Pan", "Riccardo Gherardi", "Xiufeng Xie", "Stephen Huang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023 (Oral)"]}, "abstract": "Despite all recent progress, it is still challenging to edit and manipulate natural images with modern generative models. When using Generative Adversarial Network (GAN), one major hurdle is in the inversion process mapping a real image to its corresponding noise vector in the latent space, since its necessary to be able to reconstruct an image to edit its contents. Likewise for Denoising Diffusion Implicit Models (DDIM), the linearization assumption in each inversion step makes the whole deterministic inversion process unreliable. Existing approaches that have tackled the problem of inversion stability often incur in significant trade-offs in computational efficiency. In this work we propose an Accelerated Iterative Diffusion Inversion method, dubbed AIDI, that significantly improves reconstruction accuracy with minimal additional overhead in space and time complexity. By using a novel blended guidance technique, we show that effective results can be obtained on a large range of image editing tasks without large classifier-free guidance in inversion. Furthermore, when compared with other diffusion inversion based works, our proposed process is shown to be more robust for fast image editing in the 10 and 20 diffusion steps' regimes.", "url": "https://arxiv.org/abs/2309.04907"}, {"metadata": {"arXiv": "2309.04914", "Date": "Sun, 10 Sep 2023 02:02:29 ", "Title": "MFPNet: Multi-scale Feature Propagation Nwtwork For Lightweight Semantic Segmentation", "Authors": ["Guoan Xu", "Wenjing Jia", "Tao Wu", "Ligeng Chen"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages", "3 figures", "5tables", "conference"]}, "abstract": "In contrast to the abundant research focusing on large-scale models, the progress in lightweight semantic segmentation appears to be advancing at a comparatively slower pace. However, existing compact methods often suffer from limited feature representation capability due to the shallowness of their networks. In this paper, we propose a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet), to address the dilemma. Specifically, we design a robust Encoder-Decoder structure featuring symmetrical residual blocks that consist of flexible bottleneck residual modules (BRMs) to explore deep and rich muti-scale semantic context. Furthermore, taking benefit from their capacity to model latent long-range contextual relationships, we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks. When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.", "url": "https://arxiv.org/abs/2309.04914"}, {"metadata": {"arXiv": "2309.04965", "Date": "Sun, 10 Sep 2023 08:55:24 ", "Title": "Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning", "Authors": ["Guisheng Liu", "Yi Li", "Zhengcong Fei", "Haiyan Fu", "Xiangyang Luo", "Yanqing Guo"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["11 pages,4 figures", "6 tables"]}, "abstract": "While impressive performance has been achieved in image captioning, the limited diversity of the generated captions and the large parameter scale remain major barriers to the real-word application of these systems. In this work, we propose a lightweight image captioning network in combination with continuous diffusion, called Prefix-diffusion. To achieve diversity, we design an efficient method that injects prefix image embeddings into the denoising process of the diffusion model. In order to reduce trainable parameters, we employ a pre-trained model to extract image features and further design an extra mapping network. Prefix-diffusion is able to generate diverse captions with relatively less parameters, while maintaining the fluency and relevance of the captions benefiting from the generative capabilities of the diffusion model. Our work paves the way for scaling up diffusion models for image captioning, and achieves promising performance compared with recent approaches.", "url": "https://arxiv.org/abs/2309.04965"}, {"metadata": {"arXiv": "2309.05180", "Date": "Mon, 11 Sep 2023 00:32:26 ", "Title": "Our Deep CNN Face Matchers Have Developed Achromatopsia", "Authors": ["Aman Bhatta", "Domingo Mery", "Haiyu Wu", "Joyce Annan", "Micheal C. King and Kevin W. Bowyer"], "Categories": "cs.CV cs.AI cs.CY"}, "abstract": "Modern deep CNN face matchers are trained on datasets containing color images. We show that such matchers achieve essentially the same accuracy on the grayscale or the color version of a set of test images. We then consider possible causes for deep CNN face matchers ``not seeing color''. Popular web-scraped face datasets actually have 30 to 60\\% of their identities with one or more grayscale images. We analyze whether this grayscale element in the training set impacts the accuracy achieved, and conclude that it does not. Further, we show that even with a 100\\% grayscale training set, comparable accuracy is achieved on color or grayscale test images. Then we show that the skin region of an individual's images in a web-scraped training set exhibit significant variation in their mapping to color space. This suggests that color, at least for web-scraped, in-the-wild face datasets, carries limited identity-related information for training state-of-the-art matchers. Finally, we verify that comparable accuracy is achieved from training using single-channel grayscale images, implying that a larger dataset can be used within the same memory limit, with a less computationally intensive early layer.", "url": "https://arxiv.org/abs/2309.05180"}, {"metadata": {"arXiv": "2309.05314", "Date": "Mon, 11 Sep 2023 08:59:15 ", "Title": "Semantic Latent Decomposition with Normalizing Flows for Face Editing", "Authors": ["Binglei Li", "Zhizhong Huang", "Hongming Shan", "Junping Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Navigating in the latent space of StyleGAN has shown effectiveness for face editing. However, the resulting methods usually encounter challenges in complicated navigation due to the entanglement among different attributes in the latent space. To address this issue, this paper proposes a novel framework, termed SDFlow, with a semantic decomposition in original latent space using continuous conditional normalizing flows. Specifically, SDFlow decomposes the original latent code into different irrelevant variables by jointly optimizing two components: (i) a semantic encoder to estimate semantic variables from input faces and (ii) a flow-based transformation module to map the latent code into a semantic-irrelevant variable in Gaussian distribution, conditioned on the learned semantic variables. To eliminate the entanglement between variables, we employ a disentangled learning strategy under a mutual information framework, thereby providing precise manipulation controls. Experimental results demonstrate that SDFlow outperforms existing state-of-the-art face editing methods both qualitatively and quantitatively. The source code is made available at https://github.com/phil329/SDFlow.", "url": "https://arxiv.org/abs/2309.05314"}, {"metadata": {"arXiv": "2309.05448", "Date": "Mon, 11 Sep 2023 13:41:27 ", "Title": "Panoptic Vision-Language Feature Fields", "Authors": ["Haoran Chen", "Kenneth Blomqvist", "Francesco Milano and Roland Siegwart"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Recently, methods have been proposed for 3D open-vocabulary semantic segmentation. Such methods are able to segment scenes into arbitrary classes given at run-time using their text description. In this paper, we propose to our knowledge the first algorithm for open-vocabulary panoptic segmentation, simultaneously performing both semantic and instance segmentation. Our algorithm, Panoptic Vision-Language Feature Fields (PVLFF) learns a feature field of the scene, jointly learning vision-language features and hierarchical instance features through a contrastive loss function from 2D instance segment proposals on input frames. Our method achieves comparable performance against the state-of-the-art close-set 3D panoptic systems on the HyperSim, ScanNet and Replica dataset and outperforms current 3D open-vocabulary systems in terms of semantic segmentation. We additionally ablate our method to demonstrate the effectiveness of our model architecture. Our code will be available at https://github.com/ethz-asl/autolabel.", "url": "https://arxiv.org/abs/2309.05448"}, {"metadata": {"arXiv": "2309.05590", "Date": "Mon, 11 Sep 2023 16:17:50 ", "Title": "Temporal Action Localization with Enhanced Instant Discriminability", "Authors": ["Dingfeng Shi", "Qiong Cao", "Yujie Zhong", "Shan An", "Jian Cheng", "Haogang Zhu", "Dacheng Tao"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["An extended version of the CVPR paper arXiv:2303.07347", "submitted to IJCV"]}, "abstract": "Temporal action detection (TAD) aims to detect all action boundaries and their corresponding categories in an untrimmed video. The unclear boundaries of actions in videos often result in imprecise predictions of action boundaries by existing methods. To resolve this issue, we propose a one-stage framework named TriDet. First, we propose a Trident-head to model the action boundary via an estimated relative probability distribution around the boundary. Then, we analyze the rank-loss problem (i.e. instant discriminability deterioration) in transformer-based methods and propose an efficient scalable-granularity perception (SGP) layer to mitigate this issue. To further push the limit of instant discriminability in the video backbone, we leverage the strong representation capability of pretrained large models and investigate their performance on TAD. Last, considering the adequate spatial-temporal context for classification, we design a decoupled feature pyramid network with separate feature pyramids to incorporate rich spatial context from the large model for localization. Experimental results demonstrate the robustness of TriDet and its state-of-the-art performance on multiple TAD datasets, including hierarchical (multilabel) TAD datasets.", "url": "https://arxiv.org/abs/2309.05590"}, {"metadata": {"arXiv": "2309.04698", "Date": "Sat, 09 Sep 2023 06:39:38 ", "Title": "Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller", "Authors": ["Muhammad Ayaz Hussain and Ioannis Iossifidis"], "Categories": "cs.RO cs.AI cs.AR", "ACM-class": "B.m; B.1; I.6"}, "abstract": "In this study, we present a feedforward control system designed for active gravity compensation on an upper body exoskeleton. The system utilizes only positional data from internal motor sensors to calculate torque, employing analytical control equations based on Newton-Euler Inverse Dynamics. Compared to feedback control systems, the feedforward approach offers several advantages. It eliminates the need for external torque sensors, resulting in reduced hardware complexity and weight. Moreover, the feedforward control exhibits a more proactive response, leading to enhanced performance. The exoskeleton used in the experiments is lightweight and comprises 4 Degrees of Freedom, closely mimicking human upper body kinematics and three-dimensional range of motion. We conducted tests on both hardware and simulations of the exoskeleton, demonstrating stable performance. The system maintained its position over an extended period, exhibiting minimal friction and avoiding undesired slewing.", "url": "https://arxiv.org/abs/2309.04698"}, {"metadata": {"arXiv": "2309.04710", "Date": "Sat, 09 Sep 2023 07:39:36 ", "Title": "Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact", "Authors": ["Gang Yang and Siyuan Luo and Lin Shao"], "Categories": "cs.RO cs.AI cs.CV cs.GR cs.SY eess.SY"}, "abstract": "We present Jade, a differentiable physics engine for articulated rigid bodies. Jade models contacts as the Linear Complementarity Problem (LCP). Compared to existing differentiable simulations, Jade offers features including intersection-free collision simulation and stable LCP solutions for multiple frictional contacts. We use continuous collision detection to detect the time of impact and adopt the backtracking strategy to prevent intersection between bodies with complex geometry shapes. We derive the gradient calculation to ensure the whole simulation process is differentiable under the backtracking mechanism. We modify the popular Dantzig algorithm to get valid solutions under multiple frictional contacts. We conduct extensive experiments to demonstrate the effectiveness of our differentiable physics simulation over a variety of contact-rich tasks.", "url": "https://arxiv.org/abs/2309.04710"}, {"metadata": {"arXiv": "2309.05070", "Date": "Sun, 10 Sep 2023 16:31:40 ", "Title": "Chasing the Intruder: A Reinforcement Learning Approach for Tracking Intruder Drones", "Authors": ["Shivam Kainth", "Subham Sahoo", "Rajtilak Pal", "Shashi Shekhar Jha"], "Categories": "cs.RO cs.AI cs.SY eess.SY", "DOI": "10.1145/3610419.3610487"}, "abstract": "Drones are becoming versatile in a myriad of applications. This has led to the use of drones for spying and intruding into the restricted or private air spaces. Such foul use of drone technology is dangerous for the safety and security of many critical infrastructures. In addition, due to the varied low-cost design and agility of the drones, it is a challenging task to identify and track them using the conventional radar systems. In this paper, we propose a reinforcement learning based approach for identifying and tracking any intruder drone using a chaser drone. Our proposed solution uses computer vision techniques interleaved with the policy learning framework of reinforcement learning to learn a control policy for chasing the intruder drone. The whole system has been implemented using ROS and Gazebo along with the Ardupilot based flight controller. The results show that the reinforcement learning based policy converges to identify and track the intruder drone. Further, the learnt policy is robust with respect to the change in speed or orientation of the intruder drone.", "url": "https://arxiv.org/abs/2309.05070"}, {"metadata": {"arXiv": "2309.05124", "Date": "Sun, 10 Sep 2023 20:00:25 ", "Title": "WIP: Development of a Student-Centered Personalized Learning Framework to Advance Undergraduate Robotics Education", "Authors": ["Ponkoj Chandra Shill", "Rui Wu", "Hossein Jamali", "Bryan Hutchins", "Sergiu Dascalu", "Frederick C. Harris", "David Feil-Seifer"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["5 pages", "2 figures", "conference"], "Journal-ref": "2023 IEEE Frontiers in Education Conference (FIE)"}, "abstract": "This paper presents a work-in-progress on a learn-ing system that will provide robotics students with a personalized learning environment. This addresses both the scarcity of skilled robotics instructors, particularly in community colleges and the expensive demand for training equipment. The study of robotics at the college level represents a wide range of interests, experiences, and aims. This project works to provide students the flexibility to adapt their learning to their own goals and prior experience. We are developing a system to enable robotics instruction through a web-based interface that is compatible with less expensive hardware. Therefore, the free distribution of teaching materials will empower educators. This project has the potential to increase the number of robotics courses offered at both two- and four-year schools and universities. The course materials are being designed with small units and a hierarchical dependency tree in mind; students will be able to customize their course of study based on the robotics skills they have already mastered. We present an evaluation of a five module mini-course in robotics. Students indicated that they had a positive experience with the online content. They also scored the experience highly on relatedness, mastery, and autonomy perspectives, demonstrating strong motivation potential for this approach.", "url": "https://arxiv.org/abs/2309.05124"}, {"metadata": {"arXiv": "2309.05310", "Date": "Mon, 11 Sep 2023 08:55:04 ", "Title": "Unsupervised human-to-robot motion retargeting via expressive latent space", "Authors": ["Yashuai Yan and Esteve Valls Mascaro and Dongheui Lee"], "Categories": "cs.RO cs.AI"}, "abstract": "This paper introduces a novel approach for human-to-robot motion retargeting, enabling robots to mimic human motion with precision while preserving the semantics of the motion. For that, we propose a deep learning method for direct translation from human to robot motion. Our method does not require annotated paired human-to-robot motion data, which reduces the effort when adopting new robots. To this end, we first propose a cross-domain similarity metric to compare the poses from different domains (i.e., human and robot). Then, our method achieves the construction of a shared latent space via contrastive learning and decodes latent representations to robot motion control commands. The learned latent space exhibits expressiveness as it captures the motions precisely and allows direct motion control in the latent space. We showcase how to generate in-between motion through simple linear interpolation in the latent space between two projected human poses. Additionally, we conducted a comprehensive evaluation of robot control using diverse modality inputs, such as texts, RGB videos, and key-poses, which enhances the ease of robot control to users of all backgrounds. Finally, we compare our model with existing works and quantitatively and qualitatively demonstrate the effectiveness of our approach, enhancing natural human-robot communication and fostering trust in integrating robots into daily life.", "url": "https://arxiv.org/abs/2309.05310"}, {"metadata": {"arXiv": "2309.04707", "Date": "Sat, 09 Sep 2023 07:19:20 ", "Title": "Advantage Actor-Critic with Reasoner: Explaining the Agent's Behavior from an Exploratory Perspective", "Authors": ["Muzhe Guo", "Feixu Yu", "Tian Lan", "Fang Jin"], "Categories": "cs.AI cs.LG"}, "abstract": "Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-predicted label proportions decrease for ``Breakout\" and increase for ``Hovering\" as the exploration level of the RL algorithm intensifies. Additionally, purpose-based saliencies are more focused and comprehensible.", "url": "https://arxiv.org/abs/2309.04707"}, {"metadata": {"arXiv": "2309.05269", "Date": "Mon, 11 Sep 2023 06:56:42 ", "Title": "UniKG: A Benchmark and Universal Embedding for Large-Scale Knowledge Graphs", "Authors": ["Yide Qiu", "Shaoxiang Ling", "Tong Zhang", "Bo Huang", "Zhen Cui"], "Categories": "cs.AI cs.LG", "Comments": ["9 pages", "4 figures"]}, "abstract": "Irregular data in real-world are usually organized as heterogeneous graphs (HGs) consisting of multiple types of nodes and edges. To explore useful knowledge from real-world data, both the large-scale encyclopedic HG datasets and corresponding effective learning methods are crucial, but haven't been well investigated. In this paper, we construct a large-scale HG benchmark dataset named UniKG from Wikidata to facilitate knowledge mining and heterogeneous graph representation learning. Overall, UniKG contains more than 77 million multi-attribute entities and 2000 diverse association types, which significantly surpasses the scale of existing HG datasets. To perform effective learning on the large-scale UniKG, two key measures are taken, including (i) the semantic alignment strategy for multi-attribute entities, which projects the feature description of multi-attribute nodes into a common embedding space to facilitate node aggregation in a large receptive field; (ii) proposing a novel plug-and-play anisotropy propagation module (APM) to learn effective multi-hop anisotropy propagation kernels, which extends methods of large-scale homogeneous graphs to heterogeneous graphs. These two strategies enable efficient information propagation among a tremendous number of multi-attribute entities and meantimes adaptively mine multi-attribute association through the multi-hop aggregation in large-scale HGs. We set up a node classification task on our UniKG dataset, and evaluate multiple baseline methods which are constructed by embedding our APM into large-scale homogenous graph learning methods. Our UniKG dataset and the baseline codes have been released at https://github.com/Yide-Qiu/UniKG.", "url": "https://arxiv.org/abs/2309.05269"}, {"metadata": {"arXiv": "2309.05519", "Date": "Mon, 11 Sep 2023 15:02:25 ", "Title": "NExT-GPT: Any-to-Any Multimodal LLM", "Authors": ["Shengqiong Wu", "Hao Fei", "Leigang Qu", "Wei Ji", "Tat-Seng Chua"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["work in progress"]}, "abstract": "While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI. To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansion to more potential modalities. Moreover, we introduce a modality-switching instruction tuning (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT is empowered with complex cross-modal semantic understanding and content generation. Overall, our research showcases the promising possibility of building an AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community.", "url": "https://arxiv.org/abs/2309.05519"}, {"metadata": {"arXiv": "2309.05150", "Date": "Sun, 10 Sep 2023 21:54:03 ", "Title": "Faster, Lighter, More Accurate: A Deep Learning Ensemble for Content Moderation", "Authors": ["Mohammad Hosseini", "Mahmudul Hasan"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["6 pages", "22nd IEEE International Conference on Machine Learning and Applications (IEEE ICMLA'23)", "December 15-17", "2023", "Jacksonville Riverfront", "Florida", "USA. arXiv admin note: substantial text overlap with arXiv:2103.10350"]}, "abstract": "To address the increasing need for efficient and accurate content moderation, we propose an efficient and lightweight deep classification ensemble structure. Our approach is based on a combination of simple visual features, designed for high-accuracy classification of violent content with low false positives. Our ensemble architecture utilizes a set of lightweight models with narrowed-down color features, and we apply it to both images and videos. We evaluated our approach using a large dataset of explosion and blast contents and compared its performance to popular deep learning models such as ResNet-50. Our evaluation results demonstrate significant improvements in prediction accuracy, while benefiting from 7.64x faster inference and lower computation cost. While our approach is tailored to explosion detection, it can be applied to other similar content moderation and violence detection use cases as well. Based on our experiments, we propose a \"think small, think many\" philosophy in classification scenarios. We argue that transforming a single, large, monolithic deep model into a verification-based step model ensemble of multiple small, simple, and lightweight models with narrowed-down visual features can possibly lead to predictions with higher accuracy.", "url": "https://arxiv.org/abs/2309.05150"}, {"metadata": {"arXiv": "2309.05224", "Date": "Mon, 11 Sep 2023 04:03:43 ", "Title": "SparseSwin: Swin Transformer with Sparse Transformer Block", "Authors": ["Krisna Pinasthika", "Blessius Sheldo Putra Laksono", "Riyandi Banovbi Putera Irsal", "Syifa Hukma Shabiyya", "Novanto Yudistira"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Advancements in computer vision research have put transformer architecture as the state of the art in computer vision tasks. One of the known drawbacks of the transformer architecture is the high number of parameters, this can lead to a more complex and inefficient algorithm. This paper aims to reduce the number of parameters and in turn, made the transformer more efficient. We present Sparse Transformer (SparTa) Block, a modified transformer block with an addition of a sparse token converter that reduces the number of tokens used. We use the SparTa Block inside the Swin T architecture (SparseSwin) to leverage Swin capability to downsample its input and reduce the number of initial tokens to be calculated. The proposed SparseSwin model outperforms other state of the art models in image classification with an accuracy of 86.96%, 97.43%, and 85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite its fewer parameters, the result highlights the potential of a transformer architecture using a sparse token converter with a limited number of tokens to optimize the use of the transformer and improve its performance.", "url": "https://arxiv.org/abs/2309.05224"}, {"metadata": {"arXiv": "2309.05282", "Date": "Mon, 11 Sep 2023 07:37:10 ", "Title": "Can you text what is happening? Integrating pre-trained language encoders into trajectory prediction models for autonomous driving", "Authors": ["Ali Keysan", "Andreas Look", "Eitan Kosman", "Gonca G\\\"ursun", "J\\\"org Wagner", "Yao Yu", "Barbara Rakitsch"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "In autonomous driving tasks, scene understanding is the first step towards predicting the future behavior of the surrounding traffic participants. Yet, how to represent a given scene and extract its features are still open research questions. In this study, we propose a novel text-based representation of traffic scenes and process it with a pre-trained language encoder. First, we show that text-based representations, combined with classical rasterized image representations, lead to descriptive scene embeddings. Second, we benchmark our predictions on the nuScenes dataset and show significant improvements compared to baselines. Third, we show in an ablation study that a joint encoder of text and rasterized images outperforms the individual encoders confirming that both representations have their complementary strengths.", "url": "https://arxiv.org/abs/2309.05282"}, {"metadata": {"arXiv": "2309.05490", "Date": "Mon, 11 Sep 2023 14:32:04 ", "Title": "Learning Semantic Segmentation with Query Points Supervision on Aerial Images", "Authors": ["Santiago Rivier", "Carlos Hinojosa", "Silvio Giancola", "Bernard Ghanem"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Paper presented at the LXCV workshop at ICCV 2023"]}, "abstract": "Semantic segmentation is crucial in remote sensing, where high-resolution satellite images are segmented into meaningful regions. Recent advancements in deep learning have significantly improved satellite image segmentation. However, most of these methods are typically trained in fully supervised settings that require high-quality pixel-level annotations, which are expensive and time-consuming to obtain. In this work, we present a weakly supervised learning algorithm to train semantic segmentation algorithms that only rely on query point annotations instead of full mask labels. Our proposed approach performs accurate semantic segmentation and improves efficiency by significantly reducing the cost and time required for manual annotation. Specifically, we generate superpixels and extend the query point labels into those superpixels that group similar meaningful semantics. Then, we train semantic segmentation models, supervised with images partially labeled with the superpixels pseudo-labels. We benchmark our weakly supervised training approach on an aerial image dataset and different semantic segmentation architectures, showing that we can reach competitive performance compared to fully supervised training while reducing the annotation effort.", "url": "https://arxiv.org/abs/2309.05490"}, {"metadata": {"arXiv": "2309.05569", "Date": "Mon, 11 Sep 2023 15:54:30 ", "Title": "ITI-GEN: Inclusive Text-to-Image Generation", "Authors": ["Cheng Zhang and Xuanbai Chen and Siqi Chai and Chen Henry Wu and Dmitry Lagun and Thabo Beeler and Fernando De la Torre"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Accepted to ICCV 2023 (Oral Presentation)"]}, "abstract": "Text-to-image generative models often reflect the biases of the training data, leading to unequal representations of underrepresented groups. This study investigates inclusive text-to-image generative models that generate images based on human-written prompts and ensure the resulting images are uniformly distributed across attributes of interest. Unfortunately, directly expressing the desired attributes in the prompt often leads to sub-optimal results due to linguistic ambiguity or model misrepresentation. Hence, this paper proposes a drastically different approach that adheres to the maxim that \"a picture is worth a thousand words\". We show that, for some attributes, images can represent concepts more expressively than text. For instance, categories of skin tones are typically hard to specify by text but can be easily represented by example images. Building upon these insights, we propose a novel approach, ITI-GEN, that leverages readily available reference images for Inclusive Text-to-Image GENeration. The key idea is learning a set of prompt embeddings to generate images that can effectively represent all desired attribute categories. More importantly, ITI-GEN requires no model fine-tuning, making it computationally efficient to augment existing text-to-image models. Extensive experiments demonstrate that ITI-GEN largely improves over state-of-the-art models to generate inclusive images from a prompt. Project page: https://czhang0528.github.io/iti-gen.", "url": "https://arxiv.org/abs/2309.05569"}, {"metadata": {"arXiv": "2309.04504", "Date": "Fri, 08 Sep 2023 07:26:49 ", "Title": "Compositional Learning of Visually-Grounded Concepts Using Reinforcement", "Authors": ["Zijun Lin", "Haidi Azaman", "M Ganesh Kumar", "Cheston Tan"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show that agents pretrained on concept and compositional learning achieve significantly higher reward when evaluated zero-shot on novel color-shape1-shape2 visual object combinations. Overall, our results highlight the foundations needed to increase an agent's proficiency in composing word groups through reinforcement learning and its ability for zero-shot generalization to new combinations.", "url": "https://arxiv.org/abs/2309.04504"}, {"metadata": {"arXiv": "2309.04508", "Date": "Fri, 08 Sep 2023 12:04:47 ", "Title": "Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air Pollution Monitoring Systems", "Authors": ["Keivan Faghih Niresi", "Mengjie Zhao", "Hugo Bissig", "Henri Baumann", "and Olga Fink"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "The use of Internet of Things (IoT) sensors for air pollution monitoring has significantly increased, resulting in the deployment of low-cost sensors. Despite this advancement, accurately calibrating these sensors in uncontrolled environmental conditions remains a challenge. To address this, we propose a novel approach that leverages graph neural networks, specifically the graph attention network module, to enhance the calibration process by fusing data from sensor arrays. Through our experiments, we demonstrate the effectiveness of our approach in significantly improving the calibration accuracy of sensors in IoT air pollution monitoring platforms.", "url": "https://arxiv.org/abs/2309.04508"}, {"metadata": {"arXiv": "2309.04515", "Date": "Fri, 08 Sep 2023 16:23:25 ", "Title": "Privacy Preserving Federated Learning with Convolutional Variational Bottlenecks", "Authors": ["Daniel Scheliga", "Patrick M\\\"ader", "Marco Seeland"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["14 pages (12 figures 6 tables) + 6 pages supplementary materials (6 tables). Under review. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:2208.04767"]}, "abstract": "Gradient inversion attacks are an ubiquitous threat in federated learning as they exploit gradient leakage to reconstruct supposedly private training data. Recent work has proposed to prevent gradient leakage without loss of model utility by incorporating a PRivacy EnhanCing mODulE (PRECODE) based on variational modeling. Without further analysis, it was shown that PRECODE successfully protects against gradient inversion attacks. In this paper, we make multiple contributions. First, we investigate the effect of PRECODE on gradient inversion attacks to reveal its underlying working principle. We show that variational modeling introduces stochasticity into the gradients of PRECODE and the subsequent layers in a neural network. The stochastic gradients of these layers prevent iterative gradient inversion attacks from converging. Second, we formulate an attack that disables the privacy preserving effect of PRECODE by purposefully omitting stochastic gradients during attack optimization. To preserve the privacy preserving effect of PRECODE, our analysis reveals that variational modeling must be placed early in the network. However, early placement of PRECODE is typically not feasible due to reduced model utility and the exploding number of additional model parameters. Therefore, as a third contribution, we propose a novel privacy module -- the Convolutional Variational Bottleneck (CVB) -- that can be placed early in a neural network without suffering from these drawbacks. We conduct an extensive empirical study on three seminal model architectures and six image classification datasets. We find that all architectures are susceptible to gradient leakage attacks, which can be prevented by our proposed CVB. Compared to PRECODE, we show that our novel privacy module requires fewer trainable parameters, and thus computational and communication costs, to effectively preserve privacy.", "url": "https://arxiv.org/abs/2309.04515"}, {"metadata": {"arXiv": "2309.04522", "Date": "Fri, 08 Sep 2023 18:00:01 ", "Title": "Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime", "Authors": ["Yehonatan Avidan", "Qianyi Li", "Haim Sompolinsky"], "Categories": "cs.LG cs.AI"}, "abstract": "Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial progress has been made for infinitely wide networks. In this regime, two disparate theoretical frameworks have been used, in which the network's output is described using kernels: one framework is based on the Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics, while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian framework. However, the relation between these two frameworks has remained elusive. This work unifies these two distinct theories using a Markov proximal learning model for learning dynamics in an ensemble of randomly initialized infinitely wide deep networks. We derive an exact analytical expression for the network input-output function during and after learning, and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP kernels can be derived. We identify two learning phases characterized by different time scales: gradient-driven and diffusive learning. In the initial gradient-driven learning phase, the dynamics is dominated by deterministic gradient descent, and is described by the NTK theory. This phase is followed by the diffusive learning stage, during which the network parameters sample the solution space, ultimately approaching the equilibrium distribution corresponding to NNGP. Combined with numerical evaluations on synthetic and benchmark datasets, we provide novel insights into the different roles of initialization, regularization, and network depth, as well as phenomena such as early stopping and representational drift. This work closes the gap between the NTK and NNGP theories, providing a comprehensive framework for understanding the learning process of deep neural networks in the infinite width limit.", "url": "https://arxiv.org/abs/2309.04522"}, {"metadata": {"arXiv": "2309.04565", "Date": "Fri, 08 Sep 2023 19:34:29 ", "Title": "Unleashing the Power of Graph Learning through LLM-based Autonomous Agents", "Authors": ["Lanning Wei", "Zhiqiang He", "Huan Zhao", "Quanming Yao"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph structured data are widely existed and applied in the real-world applications, while it is a challenge to handling these diverse data and learning tasks on graph in an efficient manner. When facing the complicated graph learning tasks, experts have designed diverse Graph Neural Networks (GNNs) in recent years. They have also implemented AutoML in Graph, also known as AutoGraph, to automatically generate data-specific solutions. Despite their success, they encounter limitations in (1) managing diverse learning tasks at various levels, (2) dealing with different procedures in graph learning beyond architecture design, and (3) the huge requirements on the prior knowledge when using AutoGraph. In this paper, we propose to use Large Language Models (LLMs) as autonomous agents to simplify the learning process on diverse real-world graphs. Specifically, in response to a user request which may contain varying data and learning targets at the node, edge, or graph levels, the complex graph learning task is decomposed into three components following the agent planning, namely, detecting the learning intent, configuring solutions based on AutoGraph, and generating a response. The AutoGraph agents manage crucial procedures in automated graph learning, including data-processing, AutoML configuration, searching architectures, and hyper-parameter fine-tuning. With these agents, those components are processed by decomposing and completing step by step, thereby generating a solution for the given data automatically, regardless of the learning task on node or graph. The proposed method is dubbed Auto$^2$Graph, and the comparable performance on different datasets and learning tasks. Its effectiveness is demonstrated by its comparable performance on different datasets and learning tasks, as well as the human-like decisions made by the agents.", "url": "https://arxiv.org/abs/2309.04565"}, {"metadata": {"arXiv": "2309.04615", "Date": "Fri, 08 Sep 2023 22:12:43 ", "Title": "Leveraging World Model Disentanglement in Value-Based Multi-Agent Reinforcement Learning", "Authors": ["Zhizun Wang and David Meger"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["14 pages"]}, "abstract": "In this paper, we propose a novel model-based multi-agent reinforcement learning approach named Value Decomposition Framework with Disentangled World Model to address the challenge of achieving a common goal of multiple agents interacting in the same environment with reduced sample complexity. Due to scalability and non-stationarity problems posed by multi-agent systems, model-free methods rely on a considerable number of samples for training. In contrast, we use a modularized world model, composed of action-conditioned, action-free, and static branches, to unravel the environment dynamics and produce imagined outcomes based on past experience, without sampling directly from the real environment. We employ variational auto-encoders and variational graph auto-encoders to learn the latent representations for the world model, which is merged with a value-based framework to predict the joint action-value function and optimize the overall training objective. We present experimental results in Easy, Hard, and Super-Hard StarCraft II micro-management challenges to demonstrate that our method achieves high sample efficiency and exhibits superior performance in defeating the enemy armies compared to other baselines.", "url": "https://arxiv.org/abs/2309.04615"}, {"metadata": {"arXiv": "2309.04676", "Date": "Sat, 09 Sep 2023 04:05:56 ", "Title": "Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations", "Authors": ["Yongjie Wang", "Hangwei Qian", "Yongjie Liu", "Wei Guo", "Chunyan Miao"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["Accepted by CIKM 2023"], "DOI": "10.1145/3583780.3614885"}, "abstract": "Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.", "url": "https://arxiv.org/abs/2309.04676"}, {"metadata": {"arXiv": "2309.04716", "Date": "Sat, 09 Sep 2023 08:07:54 ", "Title": "Toward Reproducing Network Research Results Using Large Language Models", "Authors": ["Qiao Xiang", "Yuling Lin", "Mingjun Fang", "Bang Huang", "Siyong Huang", "Ridi Wen", "Franck Le", "Linghe Kong", "Jiwu Shu"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.", "url": "https://arxiv.org/abs/2309.04716"}, {"metadata": {"arXiv": "2309.04732", "Date": "Sat, 09 Sep 2023 09:33:25 ", "Title": "TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering", "Authors": ["Fanling Huang and Yangdong Deng"], "Categories": "cs.LG cs.AI", "Journal-ref": "Neural Networks, 2023", "DOI": "10.1016/j.neunet.2023.06.033"}, "abstract": "Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.", "url": "https://arxiv.org/abs/2309.04732"}, {"metadata": {"arXiv": "2309.04733", "Date": "Sat, 09 Sep 2023 09:36:28 ", "Title": "A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction", "Authors": ["Fanling Huang and Yangdong Deng"], "Categories": "cs.LG cs.AI", "Journal-ref": "Data Mining and Knowledge Discovery, 2023", "DOI": "10.1016/j.neunet.2023.06.033"}, "abstract": "The prediction of wind in terms of both wind speed and direction, which has a crucial impact on many real-world applications like aviation and wind power generation, is extremely challenging due to the high stochasticity and complicated correlation in the weather data. Existing methods typically focus on a sub-set of influential factors and thus lack a systematic treatment of the problem. In addition, fine-grained forecasting is essential for efficient industry operations, but has been less attended in the literature. In this work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal Network (MHSTN), generally for accurate and efficient fine-grained wind prediction. MHSTN integrates multiple deep neural networks targeting different factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract features from various data sources and produce multi-horizon predictions for all sites within a given region. MHSTN is composed of four major modules. First, a temporal module fuses coarse-grained forecasts derived by Numerical Weather Prediction (NWP) and historical on-site observation data at stations so as to leverage both global and local atmospheric information. Second, a spatial module exploits spatial correlation by modeling the joint representation of all stations. Third, an ensemble module weighs the above two modules for final predictions. Furthermore, a covariate selection module automatically choose influential meteorological variables as initial input. MHSTN is already integrated into the scheduling platform of one of the busiest international airports of China. The evaluation results demonstrate that our model outperforms competitors by a significant margin.", "url": "https://arxiv.org/abs/2309.04733"}, {"metadata": {"arXiv": "2309.04760", "Date": "Sat, 09 Sep 2023 11:14:04 ", "Title": "RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification", "Authors": ["Yizhe Zhang", "Shuo Wang", "Yejia Zhang", "Danny Z. Chen"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["UNSURE2023 (Uncertainty for Safe Utilization of Machine Learning in Medical Imaging) at MICCAI2023; Spotlight"]}, "abstract": "Conformal prediction (CP) generates a set of predictions for a given test sample such that the prediction set almost always contains the true label (e.g., 99.5\\% of the time). CP provides comprehensive predictions on possible labels of a given test sample, and the size of the set indicates how certain the predictions are (e.g., a set larger than one is `uncertain'). Such distinct properties of CP enable effective collaborations between human experts and medical AI models, allowing efficient intervention and quality check in clinical decision-making. In this paper, we propose a new method called Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a stronger statistical guarantee so that the user-specified error rate (e.g., 0.5\\%) can be achieved in the test time, and under this constraint, the size of the prediction set is optimized (to be small). We consider a small prediction set size an important measure only when the user-specified error rate is achieved. Experiments on five public datasets show that our RR-CP performs well: with a reasonably small-sized prediction set, it achieves the user-specified error rate (e.g., 0.5\\%) significantly more frequently than exiting CP methods.", "url": "https://arxiv.org/abs/2309.04760"}, {"metadata": {"arXiv": "2309.04856", "Date": "Sat, 09 Sep 2023 18:08:56 ", "Title": "AmbientFlow: Invertible generative models from incomplete, noisy measurements", "Authors": ["Varun A. Kelkar", "Rucha Deshpande", "Arindam Banerjee", "Mark A. Anastasio"], "Categories": "cs.LG cs.AI eess.IV"}, "abstract": "Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in correctly learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated.", "url": "https://arxiv.org/abs/2309.04856"}, {"metadata": {"arXiv": "2309.04976", "Date": "Sun, 10 Sep 2023 09:40:20 ", "Title": "AVARS -- Alleviating Unexpected Urban Road Traffic Congestion using UAVs", "Authors": ["Jiaying Guo", "Michael R. Jones", "Soufiene Djahel", "and Shen Wang"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "Reducing unexpected urban traffic congestion caused by en-route events (e.g., road closures, car crashes, etc.) often requires fast and accurate reactions to choose the best-fit traffic signals. Traditional traffic light control systems, such as SCATS and SCOOT, are not efficient as their traffic data provided by induction loops has a low update frequency (i.e., longer than 1 minute). Moreover, the traffic light signal plans used by these systems are selected from a limited set of candidate plans pre-programmed prior to unexpected events' occurrence. Recent research demonstrates that camera-based traffic light systems controlled by deep reinforcement learning (DRL) algorithms are more effective in reducing traffic congestion, in which the cameras can provide high-frequency high-resolution traffic data. However, these systems are costly to deploy in big cities due to the excessive potential upgrades required to road infrastructure. In this paper, we argue that Unmanned Aerial Vehicles (UAVs) can play a crucial role in dealing with unexpected traffic congestion because UAVs with onboard cameras can be economically deployed when and where unexpected congestion occurs. Then, we propose a system called \"AVARS\" that explores the potential of using UAVs to reduce unexpected urban traffic congestion using DRL-based traffic light signal control. This approach is validated on a widely used open-source traffic simulator with practical UAV settings, including its traffic monitoring ranges and battery lifetime. Our simulation results show that AVARS can effectively recover the unexpected traffic congestion in Dublin, Ireland, back to its original un-congested level within the typical battery life duration of a UAV.", "url": "https://arxiv.org/abs/2309.04976"}, {"metadata": {"arXiv": "2309.05063", "Date": "Sun, 10 Sep 2023 16:09:02 ", "Title": "Federated Learning Incentive Mechanism under Buyers' Auction Market", "Authors": ["Jiaxi Yang", "Zihao Guo", "Sheng Cao", "Cuifang Zhao", "Li-Chuan Tsai"], "Categories": "cs.LG cs.AI cs.GT"}, "abstract": "Auction-based Federated Learning (AFL) enables open collaboration among self-interested data consumers and data owners. Existing AFL approaches are commonly under the assumption of sellers' market in that the service clients as sellers are treated as scarce resources so that the aggregation servers as buyers need to compete the bids. Yet, as the technology progresses, an increasing number of qualified clients are now capable of performing federated learning tasks, leading to shift from sellers' market to a buyers' market. In this paper, we shift the angle by adapting the procurement auction framework, aiming to explain the pricing behavior under buyers' market. Our modeling starts with basic setting under complete information, then move further to the scenario where sellers' information are not fully observable. In order to select clients with high reliability and data quality, and to prevent from external attacks, we utilize a blockchain-based reputation mechanism. The experimental results validate the effectiveness of our approach.", "url": "https://arxiv.org/abs/2309.05063"}, {"metadata": {"arXiv": "2309.05072", "Date": "Sun, 10 Sep 2023 16:35:47 ", "Title": "Spatiotemporal Graph Neural Networks with Uncertainty Quantification for Traffic Incident Risk Prediction", "Authors": ["Xiaowei Gao", "Xinke Jiang", "Dingyi Zhuang", "Huanfa Chen", "Shenhao Wang", "James Haworth"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Predicting traffic incident risks at granular spatiotemporal levels is challenging. The datasets predominantly feature zero values, indicating no incidents, with sporadic high-risk values for severe incidents. Notably, a majority of current models, especially deep learning methods, focus solely on estimating risk values, overlooking the uncertainties arising from the inherently unpredictable nature of incidents. To tackle this challenge, we introduce the Spatiotemporal Zero-Inflated Tweedie Graph Neural Networks (STZITD-GNNs). Our model merges the reliability of traditional statistical models with the flexibility of graph neural networks, aiming to precisely quantify uncertainties associated with road-level traffic incident risks. This model strategically employs a compound model from the Tweedie family, as a Poisson distribution to model risk frequency and a Gamma distribution to account for incident severity. Furthermore, a zero-inflated component helps to identify the non-incident risk scenarios. As a result, the STZITD-GNNs effectively capture the dataset's skewed distribution, placing emphasis on infrequent but impactful severe incidents. Empirical tests using real-world traffic data from London, UK, demonstrate that our model excels beyond current benchmarks. The forte of STZITD-GNN resides not only in its accuracy but also in its adeptness at curtailing uncertainties, delivering robust predictions over short (7 days) and extended (14 days) timeframes.", "url": "https://arxiv.org/abs/2309.05072"}, {"metadata": {"arXiv": "2309.05130", "Date": "Sun, 10 Sep 2023 20:30:03 ", "Title": "The online learning architecture with edge computing for high-level control for assisting patients", "Authors": ["Yue Shi", "Yihui Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages"]}, "abstract": "The prevalence of mobility impairments due to conditions such as spinal cord injuries, strokes, and degenerative diseases is on the rise globally. Lower-limb exoskeletons have been increasingly recognized as a viable solution for enhancing mobility and rehabilitation for individuals with such impairments. However, existing exoskeleton control systems often suffer from limitations such as latency, lack of adaptability, and computational inefficiency. To address these challenges, this paper introduces a novel online adversarial learning architecture integrated with edge computing for high-level lower-limb exoskeleton control. In the proposed architecture, sensor data from the user is processed in real-time through edge computing nodes, which then interact with an online adversarial learning model. This model adapts to the user's specific needs and controls the exoskeleton with minimal latency. Experimental evaluations demonstrate significant improvements in control accuracy and adaptability, as well as enhanced quality-of-service (QoS) metrics. These findings indicate that the integration of online adversarial learning with edge computing offers a robust and efficient approach for the next generation of lower-limb exoskeleton control systems.", "url": "https://arxiv.org/abs/2309.05130"}, {"metadata": {"arXiv": "2309.05131", "Date": "Sun, 10 Sep 2023 20:31:25 ", "Title": "Signal Temporal Logic Neural Predictive Control", "Authors": ["Yue Meng and Chuchu Fan"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted by IEEE Robotics and Automation Letters (RA-L) and ICRA2024"]}, "abstract": "Ensuring safety and meeting temporal specifications are critical challenges for long-term robotic tasks. Signal temporal logic (STL) has been widely used to systematically and rigorously specify these requirements. However, traditional methods of finding the control policy under those STL requirements are computationally complex and not scalable to high-dimensional or systems with complex nonlinear dynamics. Reinforcement learning (RL) methods can learn the policy to satisfy the STL specifications via hand-crafted or STL-inspired rewards, but might encounter unexpected behaviors due to ambiguity and sparsity in the reward. In this paper, we propose a method to directly learn a neural network controller to satisfy the requirements specified in STL. Our controller learns to roll out trajectories to maximize the STL robustness score in training. In testing, similar to Model Predictive Control (MPC), the learned controller predicts a trajectory within a planning horizon to ensure the satisfaction of the STL requirement in deployment. A backup policy is designed to ensure safety when our controller fails. Our approach can adapt to various initial conditions and environmental parameters. We conduct experiments on six tasks, where our method with the backup policy outperforms the classical methods (MPC, STL-solver), model-free and model-based RL methods in STL satisfaction rate, especially on tasks with complex STL specifications while being 10X-100X faster than the classical methods.", "url": "https://arxiv.org/abs/2309.05131"}, {"metadata": {"arXiv": "2309.05145", "Date": "Sun, 10 Sep 2023 21:36:38 ", "Title": "Outlier Robust Adversarial Training", "Authors": ["Shu Hu", "Zhenhuan Yang", "Xin Wang", "Yiming Ying", "Siwei Lyu"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted by The 15th Asian Conference on Machine Learning (ACML 2023)"]}, "abstract": "Supervised learning models are challenged by the intrinsic complexities of training data such as outliers and minority subpopulations and intentional attacks at inference time with adversarial samples. While traditional robust learning methods and the recent adversarial training approaches are designed to handle each of the two challenges, to date, no work has been done to develop models that are robust with regard to the low-quality training data and the potential adversarial attack at inference time simultaneously. It is for this reason that we introduce Outlier Robust Adversarial Training (ORAT) in this work. ORAT is based on a bi-level optimization formulation of adversarial training with a robust rank-based loss function. Theoretically, we show that the learning objective of ORAT satisfies the $\\mathcal{H}$-consistency in binary classification, which establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze its generalization ability and provide uniform convergence rates in high probability. ORAT can be optimized with a simple algorithm. Experimental evaluations on three benchmark datasets demonstrate the effectiveness and robustness of ORAT in handling outliers and adversarial attacks. Our code is available at https://github.com/discovershu/ORAT.", "url": "https://arxiv.org/abs/2309.05145"}, {"metadata": {"arXiv": "2309.05213", "Date": "Mon, 11 Sep 2023 03:17:45 ", "Title": "Towards Federated Learning Under Resource Constraints via Layer-wise Training and Depth Dropout", "Authors": ["Pengfei Guo", "Warren Richard Morningstar", "Raviteja Vemulapalli", "Karan Singhal", "Vishal M. Patel", "Philip Andrew Mansfield"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Large machine learning models trained on diverse data have recently seen unprecedented success. Federated learning enables training on private data that may otherwise be inaccessible, such as domain-specific datasets decentralized across many clients. However, federated learning can be difficult to scale to large models when clients have limited resources. This challenge often results in a trade-off between model size and access to diverse data. To mitigate this issue and facilitate training of large models on edge devices, we introduce a simple yet effective strategy, Federated Layer-wise Learning, to simultaneously reduce per-client memory, computation, and communication costs. Clients train just a single layer each round, reducing resource costs considerably with minimal performance degradation. We also introduce Federated Depth Dropout, a complementary technique that randomly drops frozen layers during training, to further reduce resource usage. Coupling these two techniques enables us to effectively train significantly larger models on edge devices. Specifically, we reduce training memory usage by 5x or more in federated self-supervised representation learning and demonstrate that performance in downstream tasks is comparable to conventional federated self-supervised learning.", "url": "https://arxiv.org/abs/2309.05213"}, {"metadata": {"arXiv": "2309.05295", "Date": "Mon, 11 Sep 2023 08:26:08 ", "Title": "Discrete Denoising Diffusion Approach to Integer Factorization", "Authors": ["Karlis Freivalds", "Emils Ozolins", "Guntis Barzdins"], "Categories": "cs.LG cs.AI", "Comments": ["International Conference on Artificial Neural Networks ICANN 2023"]}, "abstract": "Integer factorization is a famous computational problem unknown whether being solvable in the polynomial time. With the rise of deep neural networks, it is interesting whether they can facilitate faster factorization. We present an approach to factorization utilizing deep neural networks and discrete denoising diffusion that works by iteratively correcting errors in a partially-correct solution. To this end, we develop a new seq2seq neural network architecture, employ relaxed categorical distribution and adapt the reverse diffusion process to cope better with inaccuracies in the denoising step. The approach is able to find factors for integers of up to 56 bits long. Our analysis indicates that investment in training leads to an exponential decrease of sampling steps required at inference to achieve a given success rate, thus counteracting an exponential run-time increase depending on the bit-length.", "url": "https://arxiv.org/abs/2309.05295"}, {"metadata": {"arXiv": "2309.05582", "Date": "Mon, 11 Sep 2023 16:10:58 ", "Title": "Mind the Uncertainty: Risk-Aware and Actively Exploring Model-Based Reinforcement Learning", "Authors": ["Marin Vlastelica", "Sebastian Blaes", "Cristina Pineri", "Georg Martius"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "We introduce a simple but effective method for managing risk in model-based reinforcement learning with trajectory sampling that involves probabilistic safety constraints and balancing of optimism in the face of epistemic uncertainty and pessimism in the face of aleatoric uncertainty of an ensemble of stochastic neural networks.Various experiments indicate that the separation of uncertainties is essential to performing well with data-driven MPC approaches in uncertain and safety-critical control environments.", "url": "https://arxiv.org/abs/2309.05582"}, {"metadata": {"arXiv": "2309.05660", "Date": "Mon, 11 Sep 2023 17:56:57 ", "Title": "Hypothesis Search: Inductive Reasoning with Language Models", "Authors": ["Ruocheng Wang", "Eric Zelikman", "Gabriel Poesia", "Yewen Pu", "Nick Haber", "Noah D. Goodman"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Inductive reasoning is a core problem-solving capacity: humans can identify underlying principles from a few examples, which can then be robustly generalized to novel scenarios. Recent work has evaluated large language models (LLMs) on inductive reasoning tasks by directly prompting them yielding \"in context learning.\" This can work well for straightforward inductive tasks, but performs very poorly on more complex tasks such as the Abstraction and Reasoning Corpus (ARC). In this work, we propose to improve the inductive reasoning ability of LLMs by generating explicit hypotheses at multiple levels of abstraction: we prompt the LLM to propose multiple abstract hypotheses about the problem, in natural language, then implement the natural language hypotheses as concrete Python programs. These programs can be directly verified by running on the observed examples and generalized to novel inputs. Because of the prohibitive cost of generation with state-of-the-art LLMs, we consider a middle step to filter the set of hypotheses that will be implemented into programs: we either ask the LLM to summarize into a smaller set of hypotheses, or ask human annotators to select a subset of the hypotheses. We verify our pipeline's effectiveness on the ARC visual inductive reasoning benchmark, its variant 1D-ARC, and string transformation dataset SyGuS. On a random 40-problem subset of ARC, our automated pipeline using LLM summaries achieves 27.5% accuracy, significantly outperforming the direct prompting baseline (accuracy of 12.5%). With the minimal human input of selecting from LLM-generated candidates, the performance is boosted to 37.5%. (And we argue this is a lower bound on the performance of our approach without filtering.) Our ablation studies show that abstract hypothesis generation and concrete program representations are both beneficial for LLMs to perform inductive reasoning tasks.", "url": "https://arxiv.org/abs/2309.05660"}, {"metadata": {"arXiv": "2309.04640", "Date": "Fri, 08 Sep 2023 23:42:59 ", "Title": "Few-Shot Learning of Force-Based Motions From Demonstration Through Pre-training of Haptic Representation", "Authors": ["Marina Y. Aoyama", "Jo\\~ao Moura", "Namiko Saito", "Sethu Vijayakumar"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "In many contact-rich tasks, force sensing plays an essential role in adapting the motion to the physical properties of the manipulated object. To enable robots to capture the underlying distribution of object properties necessary for generalising learnt manipulation tasks to unseen objects, existing Learning from Demonstration (LfD) approaches require a large number of costly human demonstrations. Our proposed semi-supervised LfD approach decouples the learnt model into an haptic representation encoder and a motion generation decoder. This enables us to pre-train the first using large amount of unsupervised data, easily accessible, while using few-shot LfD to train the second, leveraging the benefits of learning skills from humans. We validate the approach on the wiping task using sponges with different stiffness and surface friction. Our results demonstrate that pre-training significantly improves the ability of the LfD model to recognise physical properties and generate desired wiping motions for unseen sponges, outperforming the LfD method without pre-training. We validate the motion generated by our semi-supervised LfD model on the physical robot hardware using the KUKA iiwa robot arm. We also validate that the haptic representation encoder, pre-trained in simulation, captures the properties of real objects, explaining its contribution to improving the generalisation of the downstream task.", "url": "https://arxiv.org/abs/2309.04640"}, {"metadata": {"arXiv": "2309.04974", "Date": "Sun, 10 Sep 2023 09:32:35 ", "Title": "Continual Robot Learning using Self-Supervised Task Inference", "Authors": ["Muhammad Burhan Hafez", "Stefan Wermter"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted for publication in IEEE Transactions on Cognitive and Developmental Systems"]}, "abstract": "Endowing robots with the human ability to learn a growing set of skills over the course of a lifetime as opposed to mastering single tasks is an open problem in robot learning. While multi-task learning approaches have been proposed to address this problem, they pay little attention to task inference. In order to continually learn new tasks, the robot first needs to infer the task at hand without requiring predefined task representations. In this paper, we propose a self-supervised task inference approach. Our approach learns action and intention embeddings from self-organization of the observed movement and effect parts of unlabeled demonstrations and a higher-level behavior embedding from self-organization of the joint action-intention embeddings. We construct a behavior-matching self-supervised learning objective to train a novel Task Inference Network (TINet) to map an unlabeled demonstration to its nearest behavior embedding, which we use as the task representation. A multi-task policy is built on top of the TINet and trained with reinforcement learning to optimize performance over tasks. We evaluate our approach in the fixed-set and continual multi-task learning settings with a humanoid robot and compare it to different multi-task learning baselines. The results show that our approach outperforms the other baselines, with the difference being more pronounced in the challenging continual learning setting, and can infer tasks from incomplete demonstrations. Our approach is also shown to generalize to unseen tasks based on a single demonstration in one-shot task generalization experiments.", "url": "https://arxiv.org/abs/2309.04974"}, {"metadata": {"arXiv": "2309.05665", "Date": "Mon, 11 Sep 2023 17:59:17 ", "Title": "Robot Parkour Learning", "Authors": ["Ziwen Zhuang", "Zipeng Fu", "Jianren Wang", "Christopher Atkeson", "Soeren Schwertfeger", "Chelsea Finn", "Hang Zhao"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["CoRL 2023 (Oral). Project website at https://robot-parkour.github.io"]}, "abstract": "Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments. Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards. However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios. In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data. We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running. We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric depth camera. We demonstrate that our system can empower two different low-cost robots to autonomously select and execute appropriate parkour skills to traverse challenging real-world environments.", "url": "https://arxiv.org/abs/2309.05665"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

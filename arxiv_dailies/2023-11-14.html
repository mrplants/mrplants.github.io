<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.06285", "Date": "Wed, 01 Nov 2023 16:40:35 ", "Title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio", "Authors": ["Xudong Xu", "Dejan Markovic", "Jacob Sandakly", "Todd Keebler", "Steven Krenn", "Alexander Richard"], "Categories": "cs.CV cs.LG cs.SD eess.AS", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "While 3D human body modeling has received much attention in computer vision, modeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by body motion and speech, has fallen short in the community. To close this gap, we present a model that can generate accurate 3D spatial audio for full human bodies. The system consumes, as input, audio signals from headset microphones and body pose, and produces, as output, a 3D sound field surrounding the transmitter's body, from which spatial audio can be rendered at any arbitrary position in the 3D space. We collect a first-of-its-kind multimodal dataset of human bodies, recorded with multiple cameras and a spherical array of 345 microphones. In an empirical evaluation, we demonstrate that our model can produce accurate body-induced sound fields when trained with a suitable loss. Dataset and code are available online.", "url": "https://arxiv.org/abs/2311.06285"}, {"metadata": {"arXiv": "2311.06322", "Date": "Fri, 10 Nov 2023 09:10:09 ", "Title": "Post-training Quantization with Progressive Calibration and Activation Relaxing for Text-to-Image Diffusion Models", "Authors": ["Siao Tang", "Xin Wang", "Hong Chen", "Chaoyu Guan", "Zewen Wu", "Yansong Tang", "Wenwu Zhu"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion models have achieved great success due to their remarkable generation ability. However, their high computational overhead is still a troublesome problem. Recent studies have leveraged post-training quantization (PTQ) to compress diffusion models. However, most of them only focus on unconditional models, leaving the quantization of widely used large pretrained text-to-image models, e.g., Stable Diffusion, largely unexplored. In this paper, we propose a novel post-training quantization method PCR (Progressive Calibration and Relaxing) for text-to-image diffusion models, which consists of a progressive calibration strategy that considers the accumulated quantization error across timesteps, and an activation relaxing strategy that improves the performance with negligible cost. Additionally, we demonstrate the previous metrics for text-to-image diffusion model quantization are not accurate due to the distribution gap. To tackle the problem, we propose a novel QDiffBench benchmark, which utilizes data in the same domain for more accurate evaluation. Besides, QDiffBench also considers the generalization performance of the quantized model outside the calibration dataset. Extensive experiments on Stable Diffusion and Stable Diffusion XL demonstrate the superiority of our method and benchmark. Moreover, we are the first to achieve quantization for Stable Diffusion XL while maintaining the performance.", "url": "https://arxiv.org/abs/2311.06322"}, {"metadata": {"arXiv": "2311.06375", "Date": "Fri, 10 Nov 2023 20:05:40 ", "Title": "Image Classification using Combination of Topological Features and Neural Networks", "Authors": ["Mariana D\\'oria Prata Lima", "Gilson Antonio Giraldi", "Gast\\~ao Flor\\^encio Miranda Junior"], "Categories": "cs.CV cs.LG cs.NE", "Comments": ["17 pages", "3 figures"], "MSC-class": "57T99, 57Z25", "ACM-class": "I.4.10; I.2.10; I.5.4"}, "abstract": "In this work we use the persistent homology method, a technique in topological data analysis (TDA), to extract essential topological features from the data space and combine them with deep learning features for classification tasks. In TDA, the concepts of complexes and filtration are building blocks. Firstly, a filtration is constructed from some complex. Then, persistent homology classes are computed, and their evolution along the filtration is visualized through the persistence diagram. Additionally, we applied vectorization techniques to the persistence diagram to make this topological information compatible with machine learning algorithms. This was carried out with the aim of classifying images from multiple classes in the MNIST dataset. Our approach inserts topological features into deep learning approaches composed by single and two-streams neural networks architectures based on a multi-layer perceptron (MLP) and a convolutional neral network (CNN) taylored for multi-class classification in the MNIST dataset. In our analysis, we evaluated the obtained results and compared them with the outcomes achieved through the baselines that are available in the TensorFlow library. The main conclusion is that topological information may increase neural network accuracy in multi-class classification tasks with the price of computational complexity of persistent homology calculation. Up to the best of our knowledge, it is the first work that combines deep learning features and the combination of topological features for multi-class classification tasks.", "url": "https://arxiv.org/abs/2311.06375"}, {"metadata": {"arXiv": "2311.06386", "Date": "Fri, 10 Nov 2023 20:27:43 ", "Title": "Towards A Unified Neural Architecture for Visual Recognition and Reasoning", "Authors": ["Calvin Luo", "Boqing Gong", "Ting Chen", "Chen Sun"], "Categories": "cs.CV cs.LG"}, "abstract": "Recognition and reasoning are two pillars of visual understanding. However, these tasks have an imbalance in focus; whereas recent advances in neural networks have shown strong empirical performance in visual recognition, there has been comparably much less success in solving visual reasoning. Intuitively, unifying these two tasks under a singular framework is desirable, as they are mutually dependent and beneficial. Motivated by the recent success of multi-task transformers for visual recognition and language understanding, we propose a unified neural architecture for visual recognition and reasoning with a generic interface (e.g., tokens) for both. Our framework enables the principled investigation of how different visual recognition tasks, datasets, and inductive biases can help enable spatiotemporal reasoning capabilities. Noticeably, we find that object detection, which requires spatial localization of individual objects, is the most beneficial recognition task for reasoning. We further demonstrate via probing that implicit object-centric representations emerge automatically inside our framework. Intriguingly, we discover that certain architectural choices such as the backbone model of the visual encoder have a significant impact on visual reasoning, but little on object detection. Given the results of our experiments, we believe that visual reasoning should be considered as a first-class citizen alongside visual recognition, as they are strongly correlated but benefit from potentially different design choices.", "url": "https://arxiv.org/abs/2311.06386"}, {"metadata": {"arXiv": "2311.06613", "Date": "Sat, 11 Nov 2023 17:01:24 ", "Title": "Computer Vision for Particle Size Analysis of Coarse-Grained Soils", "Authors": ["Sompote Youwai and Parchya Makam"], "Categories": "cs.CV cs.LG"}, "abstract": "Particle size analysis (PSA) is a fundamental technique for evaluating the physical characteristics of soils. However, traditional methods like sieving can be time-consuming and labor-intensive. In this study, we present a novel approach that utilizes computer vision (CV) and the Python programming language for PSA of coarse-grained soils, employing a standard mobile phone camera. By eliminating the need for a high-performance camera, our method offers convenience and cost savings. Our methodology involves using the OPENCV library to detect and measure soil particles in digital photographs taken under ordinary lighting conditions. For accurate particle size determination, a calibration target with known dimensions is placed on a plain paper alongside 20 different sand samples. The proposed method is compared with traditional sieve analysis and exhibits satisfactory performance for soil particles larger than 2 mm, with a mean absolute percent error (MAPE) of approximately 6%. However, particles smaller than 2 mm result in higher MAPE, reaching up to 60%. To address this limitation, we recommend using a higher-resolution camera to capture images of the smaller soil particles. Furthermore, we discuss the advantages, limitations, and potential future improvements of our method. Remarkably, the program can be executed on a mobile phone, providing immediate results without the need to send soil samples to a laboratory. This field-friendly feature makes our approach highly convenient for on-site usage, outside of a traditional laboratory setting. Ultimately, this novel method represents an initial disruption to the industry, enabling efficient particle size analysis of soil without the reliance on laboratory-based sieve analysis. KEYWORDS: Computer vision, Grain size, ARUCO", "url": "https://arxiv.org/abs/2311.06613"}, {"metadata": {"arXiv": "2311.06845", "Date": "Sun, 12 Nov 2023 13:35:25 ", "Title": "Sampler Scheduler for Diffusion Models", "Authors": ["Zitong Cheng"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion modeling (DM) has high-quality generative performance, and the sampling problem is an important part of the DM performance. Thanks to efficient differential equation solvers, the sampling speed can be reduced while higher sampling quality is guaranteed. However, currently, there is a contradiction in samplers for diffusion-based generative models: the mainstream sampler choices are diverse, each with its own characteristics in terms of performance. However, only a single sampler algorithm can be specified on all sampling steps in the generative process. This often makes one torn between sampler choices; in other words, it makes it difficult to fully utilize the advantages of each sampler. In this paper, we propose the feasibility of using different samplers (ODE/SDE) on different sampling steps of the same sampling process based on analyzing and generalizing the updating formulas of each mainstream sampler, and experimentally demonstrate that such a multi-sampler scheduling improves the sampling results to some extent. In particular, we also verify that the combination of using SDE in the early sampling steps and ODE in the later sampling steps solves the inherent problems previously caused by using both singly. We show that our design changes improve the sampling efficiency and quality in previous work. For instance, when Number of Function Evaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91 on the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and 11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the combined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler a, 3.14 for DPM2 a and 23.14 for DPM++ SDE.", "url": "https://arxiv.org/abs/2311.06845"}, {"metadata": {"arXiv": "2311.06964", "Date": "Sun, 12 Nov 2023 21:07:04 ", "Title": "Adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels", "Authors": ["Vijay Veerabadran", "Srinivas Ravishankar", "Yuan Tang", "Ritik Raina", "Virginia R. de Sa"], "Categories": "cs.CV cs.LG", "Comments": ["37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Humans solving algorithmic (or) reasoning problems typically exhibit solution times that grow as a function of problem difficulty. Adaptive recurrent neural networks have been shown to exhibit this property for various language-processing tasks. However, little work has been performed to assess whether such adaptive computation can also enable vision models to extrapolate solutions beyond their training distribution's difficulty level, with prior work focusing on very simple tasks. In this study, we investigate a critical functional role of such adaptive processing using recurrent neural networks: to dynamically scale computational resources conditional on input requirements that allow for zero-shot generalization to novel difficulty levels not seen during training using two challenging visual reasoning tasks: PathFinder and Mazes. We combine convolutional recurrent neural networks (ConvRNNs) with a learnable halting mechanism based on Graves (2016). We explore various implementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights across layers to more sophisticated biologically inspired recurrent networks that possess lateral connections and gating. We show that 1) AdRNNs learn to dynamically halt processing early (or late) to solve easier (or harder) problems, 2) these RNNs zero-shot generalize to more difficult problem settings not shown during training by dynamically increasing the number of recurrent iterations at test time. Our study provides modeling evidence supporting the hypothesis that recurrent processing enables the functional advantage of adaptively allocating compute resources conditional on input requirements and hence allowing generalization to harder difficulty levels of a visual reasoning problem without training.", "url": "https://arxiv.org/abs/2311.06964"}, {"metadata": {"arXiv": "2311.07002", "Date": "Mon, 13 Nov 2023 01:03:19 ", "Title": "PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation", "Authors": ["Vikas Dwivedi", "Balaji Srinivasan and Ganapathy Krishnamurthi"], "Categories": "cs.CV cs.LG"}, "abstract": "Effective training of deep image segmentation models is challenging due to the need for abundant, high-quality annotations. Generating annotations is laborious and time-consuming for human experts, especially in medical image segmentation. To facilitate image annotation, we introduce Physics Informed Contour Selection (PICS) - an interpretable, physics-informed algorithm for rapid image segmentation without relying on labeled data. PICS draws inspiration from physics-informed neural networks (PINNs) and an active contour model called snake. It is fast and computationally lightweight because it employs cubic splines instead of a deep neural network as a basis function. Its training parameters are physically interpretable because they directly represent control knots of the segmentation curve. Traditional snakes involve minimization of the edge-based loss functionals by deriving the Euler-Lagrange equation followed by its numerical solution. However, PICS directly minimizes the loss functional, bypassing the Euler Lagrange equations. It is the first snake variant to minimize a region-based loss function instead of traditional edge-based loss functions. PICS uniquely models the three-dimensional (3D) segmentation process with an unsteady partial differential equation (PDE), which allows accelerated segmentation via transfer learning. To demonstrate its effectiveness, we apply PICS for 3D segmentation of the left ventricle on a publicly available cardiac dataset. While doing so, we also introduce a new convexity-preserving loss term that encodes the shape information of the left ventricle to enhance PICS's segmentation quality. Overall, PICS presents several novelties in network architecture, transfer learning, and physics-inspired losses for image segmentation, thereby showing promising outcomes and potential for further refinement.", "url": "https://arxiv.org/abs/2311.07002"}, {"metadata": {"arXiv": "2311.07162", "Date": "Mon, 13 Nov 2023 08:56:56 ", "Title": "CycleGANAS: Differentiable Neural Architecture Search for CycleGAN", "Authors": ["Taegun An", "Changhee Joo"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "We develop a Neural Architecture Search (NAS) framework for CycleGAN that carries out unpaired image-to-image translation task. Extending previous NAS techniques for Generative Adversarial Networks (GANs) to CycleGAN is not straightforward due to the task difference and greater search space. We design architectures that consist of a stack of simple ResNet-based cells and develop a search method that effectively explore the large search space. We show that our framework, called CycleGANAS, not only effectively discovers high-performance architectures that either match or surpass the performance of the original CycleGAN, but also successfully address the data imbalance by individual architecture search for each translation direction. To our best knowledge, it is the first NAS result for CycleGAN and shed light on NAS for more complex structures.", "url": "https://arxiv.org/abs/2311.07162"}, {"metadata": {"arXiv": "2311.07247", "Date": "Mon, 13 Nov 2023 11:29:38 ", "Title": "Simultaneous Clutter Detection and Semantic Segmentation of Moving Objects for Automotive Radar Data", "Authors": ["Johannes Kopp", "Dominik Kellner", "Aldi Piroli", "Vinzenz Dallabetta", "Klaus Dietmayer"], "Categories": "cs.CV cs.LG eess.SP", "Comments": ["Published at IEEE International Conference of Intelligent Transportation Systems (ITSC)", "Bilbao", "ESP", "2023"]}, "abstract": "The unique properties of radar sensors, such as their robustness to adverse weather conditions, make them an important part of the environment perception system of autonomous vehicles. One of the first steps during the processing of radar point clouds is often the detection of clutter, i.e. erroneous points that do not correspond to real objects. Another common objective is the semantic segmentation of moving road users. These two problems are handled strictly separate from each other in literature. The employed neural networks are always focused entirely on only one of the tasks. In contrast to this, we examine ways to solve both tasks at the same time with a single jointly used model. In addition to a new augmented multi-head architecture, we also devise a method to represent a network's predictions for the two tasks with only one output value. This novel approach allows us to solve the tasks simultaneously with the same inference time as a conventional task-specific model. In an extensive evaluation, we show that our setup is highly effective and outperforms every existing network for semantic segmentation on the RadarScenes dataset.", "url": "https://arxiv.org/abs/2311.07247"}, {"metadata": {"arXiv": "2311.07263", "Date": "Mon, 13 Nov 2023 12:02:46 ", "Title": "LT-ViT: A Vision Transformer for multi-label Chest X-ray classification", "Authors": ["Umar Marikkar and Sara Atito and Muhammad Awais and Adam Mahdi"], "Categories": "cs.CV cs.LG", "Comments": ["5 pages", "2 figures"], "DOI": "10.1109/ICIP49359.2023.10222175"}, "abstract": "Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and some existing efforts have been directed towards vision-language training for Chest X-rays (CXRs). However, we envision that there still exists a potential for improvement in vision-only training for CXRs using ViTs, by aggregating information from multiple scales, which has been proven beneficial for non-transformer networks. Hence, we have developed LT-ViT, a transformer that utilizes combined attention between image tokens and randomly initialized auxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT (1) surpasses the state-of-the-art performance using pure ViTs on two publicly available CXR datasets, (2) is generalizable to other pre-training methods and therefore is agnostic to model initialization, and (3) enables model interpretability without grad-cam and its variants.", "url": "https://arxiv.org/abs/2311.07263"}, {"metadata": {"arXiv": "2311.06321", "Date": "Fri, 10 Nov 2023 06:52:17 ", "Title": "Can Machine Learning Uncover Insights into Vehicle Travel Demand from Our Built Environment?", "Authors": ["Zixun Huang", "Hao Zheng"], "Categories": "cs.LG cs.HC"}, "abstract": "In this paper, we propose a machine learning-based approach to address the lack of ability for designers to optimize urban land use planning from the perspective of vehicle travel demand. Research shows that our computational model can help designers quickly obtain feedback on the vehicle travel demand, which includes its total amount and temporal distribution based on the urban function distribution designed by the designers. It also assists in design optimization and evaluation of the urban function distribution from the perspective of vehicle travel. We obtain the city function distribution information and vehicle hours traveled (VHT) information by collecting the city point-of-interest (POI) data and online vehicle data. The artificial neural networks (ANNs) with the best performance in prediction are selected. By using data sets collected in different regions for mutual prediction and remapping the predictions onto a map for visualization, we evaluate the extent to which the computational model sees use across regions in an attempt to reduce the workload of future urban researchers. Finally, we demonstrate the application of the computational model to help designers obtain feedback on vehicle travel demand in the built environment and combine it with genetic algorithms to optimize the current state of the urban environment to provide recommendations to designers.", "url": "https://arxiv.org/abs/2311.06321"}, {"metadata": {"arXiv": "2311.06358", "Date": "Fri, 10 Nov 2023 19:11:13 ", "Title": "Compact Matrix Quantum Group Equivariant Neural Networks", "Authors": ["Edward Pearce-Crump"], "Categories": "cs.LG math.CO math.CT math.RT stat.ML", "Comments": ["15 pages"]}, "abstract": "We derive the existence of a new type of neural network, called a compact matrix quantum group equivariant neural network, that learns from data that has an underlying quantum symmetry. We apply the Woronowicz formulation of Tannaka-Krein duality to characterise the weight matrices that appear in these neural networks for any easy compact matrix quantum group. We show that compact matrix quantum group equivariant neural networks contain, as a subclass, all compact matrix group equivariant neural networks. Moreover, we obtain characterisations of the weight matrices for many compact matrix group equivariant neural networks that have not previously appeared in the machine learning literature.", "url": "https://arxiv.org/abs/2311.06358"}, {"metadata": {"arXiv": "2311.06361", "Date": "Fri, 10 Nov 2023 19:26:31 ", "Title": "CALLOC: Curriculum Adversarial Learning for Secure and Robust Indoor Localization", "Authors": ["Danish Gufran", "Sudeep Pasricha"], "Categories": "cs.LG cs.CY"}, "abstract": "Indoor localization has become increasingly vital for many applications from tracking assets to delivering personalized services. Yet, achieving pinpoint accuracy remains a challenge due to variations across indoor environments and devices used to assist with localization. Another emerging challenge is adversarial attacks on indoor localization systems that not only threaten service integrity but also reduce localization accuracy. To combat these challenges, we introduce CALLOC, a novel framework designed to resist adversarial attacks and variations across indoor environments and devices that reduce system accuracy and reliability. CALLOC employs a novel adaptive curriculum learning approach with a domain specific lightweight scaled-dot product attention neural network, tailored for adversarial and variation resilience in practical use cases with resource constrained mobile devices. Experimental evaluations demonstrate that CALLOC can achieve improvements of up to 6.03x in mean error and 4.6x in worst-case error against state-of-the-art indoor localization frameworks, across diverse building floorplans, mobile devices, and adversarial attacks scenarios.", "url": "https://arxiv.org/abs/2311.06361"}, {"metadata": {"arXiv": "2311.06372", "Date": "Fri, 10 Nov 2023 19:51:18 ", "Title": "Blockchain-Enabled Federated Learning Approach for Vehicular Networks", "Authors": ["Shirin Sultana", "Jahin Hossain", "Maruf Billah", "Hasibul Hossain Shajeeb", "Saifur Rahman", "Keyvan Ansari", "Khondokar Fida Hasan"], "Categories": "cs.LG", "Comments": ["7 pages"]}, "abstract": "Data from interconnected vehicles may contain sensitive information such as location, driving behavior, personal identifiers, etc. Without adequate safeguards, sharing this data jeopardizes data privacy and system security. The current centralized data-sharing paradigm in these systems raises particular concerns about data privacy. Recognizing these challenges, the shift towards decentralized interactions in technology, as echoed by the principles of Industry 5.0, becomes paramount. This work is closely aligned with these principles, emphasizing decentralized, human-centric, and secure technological interactions in an interconnected vehicular ecosystem. To embody this, we propose a practical approach that merges two emerging technologies: Federated Learning (FL) and Blockchain. The integration of these technologies enables the creation of a decentralized vehicular network. In this setting, vehicles can learn from each other without compromising privacy while also ensuring data integrity and accountability. Initial experiments show that compared to conventional decentralized federated learning techniques, our proposed approach significantly enhances the performance and security of vehicular networks. The system's accuracy stands at 91.92\\%. While this may appear to be low in comparison to state-of-the-art federated learning models, our work is noteworthy because, unlike others, it was achieved in a malicious vehicle setting. Despite the challenging environment, our method maintains high accuracy, making it a competent solution for preserving data privacy in vehicular networks.", "url": "https://arxiv.org/abs/2311.06372"}, {"metadata": {"arXiv": "2311.06380", "Date": "Fri, 10 Nov 2023 20:13:29 ", "Title": "Theory and implementation of inelastic Constitutive Artificial Neural Networks", "Authors": ["Hagen Holthusen and Lukas Lamm and Tim Brepols and Stefanie Reese and Ellen Kuhl"], "Categories": "cs.LG cond-mat.mtrl-sci", "Comments": ["54 pages", "14 figures", "14 tables"], "MSC-class": "65, 74", "ACM-class": "I.6; J.2"}, "abstract": "Nature has always been our inspiration in the research, design and development of materials and has driven us to gain a deep understanding of the mechanisms that characterize anisotropy and inelastic behavior. All this knowledge has been accumulated in the principles of thermodynamics. Deduced from these principles, the multiplicative decomposition combined with pseudo potentials are powerful and universal concepts. Simultaneously, the tremendous increase in computational performance enabled us to investigate and rethink our history-dependent material models to make the most of our predictions. Today, we have reached a point where materials and their models are becoming increasingly sophisticated. This raises the question: How do we find the best model that includes all inelastic effects to explain our complex data? Constitutive Artificial Neural Networks (CANN) may answer this question. Here, we extend the CANNs to inelastic materials (iCANN). Rigorous considerations of objectivity, rigid motion of the reference configuration, multiplicative decomposition and its inherent non-uniqueness, restrictions of energy and pseudo potential, and consistent evolution guide us towards the architecture of the iCANN satisfying thermodynamics per design. We combine feed-forward networks of the free energy and pseudo potential with a recurrent neural network approach to take time dependencies into account. We demonstrate that the iCANN is capable of autonomously discovering models for artificially generated data, the response of polymers for cyclic loading and the relaxation behavior of muscle data. As the design of the network is not limited to visco-elasticity, our vision is that the iCANN will reveal to us new ways to find the various inelastic phenomena hidden in the data and to understand their interaction. Our source code, data, and examples are available at doi.org/10.5281/zenodo.10066805", "url": "https://arxiv.org/abs/2311.06380"}, {"metadata": {"arXiv": "2311.06396", "Date": "Fri, 10 Nov 2023 20:57:43 ", "Title": "A comprehensive analysis of concept drift locality in data streams", "Authors": ["Gabriel J. Aguiar and Alberto Cano"], "Categories": "cs.LG"}, "abstract": "Adapting to drifting data streams is a significant challenge in online learning. Concept drift must be detected for effective model adaptation to evolving data properties. Concept drift can impact the data distribution entirely or partially, which makes it difficult for drift detectors to accurately identify the concept drift. Despite the numerous concept drift detectors in the literature, standardized procedures and benchmarks for comprehensive evaluation considering the locality of the drift are lacking. We present a novel categorization of concept drift based on its locality and scale. A systematic approach leads to a set of 2,760 benchmark problems, reflecting various difficulty levels following our proposed categorization. We conduct a comparative assessment of 9 state-of-the-art drift detectors across diverse difficulties, highlighting their strengths and weaknesses for future research. We examine how drift locality influences the classifier performance and propose strategies for different drift categories to minimize the recovery time. Lastly, we provide lessons learned and recommendations for future concept drift research. Our benchmark data streams and experiments are publicly available at https://github.com/gabrieljaguiar/locality-concept-drift.", "url": "https://arxiv.org/abs/2311.06396"}, {"metadata": {"arXiv": "2311.06414", "Date": "Fri, 10 Nov 2023 22:18:09 ", "Title": "Knowledge Graphs are not Created Equal: Exploring the Properties and Structure of Real KGs", "Authors": ["Nedelina Teneva and Estevam Hruschka"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted at NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)"]}, "abstract": "Despite the recent popularity of knowledge graph (KG) related tasks and benchmarks such as KG embeddings, link prediction, entity alignment and evaluation of the reasoning abilities of pretrained language models as KGs, the structure and properties of real KGs are not well studied. In this paper, we perform a large scale comparative study of 29 real KG datasets from diverse domains such as the natural sciences, medicine, and NLP to analyze their properties and structural patterns. Based on our findings, we make several recommendations regarding KG-based model development and evaluation. We believe that the rich structural information contained in KGs can benefit the development of better KG models across fields and we hope this study will contribute to breaking the existing data silos between different areas of research (e.g., ML, NLP, AI for sciences).", "url": "https://arxiv.org/abs/2311.06414"}, {"metadata": {"arXiv": "2311.06423", "Date": "Fri, 10 Nov 2023 23:10:21 ", "Title": "Flatness-aware Adversarial Attack", "Authors": ["Mingyuan Fan", "Xiaodan Li", "Cen Chen", "Yinggui Wang"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "The transferability of adversarial examples can be exploited to launch black-box attacks. However, adversarial examples often present poor transferability. To alleviate this issue, by observing that the diversity of inputs can boost transferability, input regularization based methods are proposed, which craft adversarial examples by combining several transformed inputs. We reveal that input regularization based methods make resultant adversarial examples biased towards flat extreme regions. Inspired by this, we propose an attack called flatness-aware adversarial attack (FAA) which explicitly adds a flatness-aware regularization term in the optimization target to promote the resultant adversarial examples towards flat extreme regions. The flatness-aware regularization term involves gradients of samples around the resultant adversarial examples but optimizing gradients requires the evaluation of Hessian matrix in high-dimension spaces which generally is intractable. To address the problem, we derive an approximate solution to circumvent the construction of Hessian matrix, thereby making FAA practical and cheap. Extensive experiments show the transferability of adversarial examples crafted by FAA can be considerably boosted compared with state-of-the-art baselines.", "url": "https://arxiv.org/abs/2311.06423"}, {"metadata": {"arXiv": "2311.06428", "Date": "Fri, 10 Nov 2023 23:27:23 ", "Title": "A Trichotomy for Transductive Online Learning", "Authors": ["Steve Hanneke", "Shay Moran", "Jonathan Shafer"], "Categories": "cs.LG"}, "abstract": "We present new upper and lower bounds on the number of learner mistakes in the `transductive' online learning setting of Ben-David, Kushilevitz and Mansour (1997). This setting is similar to standard online learning, except that the adversary fixes a sequence of instances $x_1,\\dots,x_n$ to be labeled at the start of the game, and this sequence is known to the learner. Qualitatively, we prove a trichotomy, stating that the minimal number of mistakes made by the learner as $n$ grows can take only one of precisely three possible values: $n$, $\\Theta\\left(\\log (n)\\right)$, or $\\Theta(1)$. Furthermore, this behavior is determined by a combination of the VC dimension and the Littlestone dimension. Quantitatively, we show a variety of bounds relating the number of mistakes to well-known combinatorial dimensions. In particular, we improve the known lower bound on the constant in the $\\Theta(1)$ case from $\\Omega\\left(\\sqrt{\\log(d)}\\right)$ to $\\Omega(\\log(d))$ where $d$ is the Littlestone dimension. Finally, we extend our results to cover multiclass classification and the agnostic setting.", "url": "https://arxiv.org/abs/2311.06428"}, {"metadata": {"arXiv": "2311.06454", "Date": "Sat, 11 Nov 2023 01:53:59 ", "Title": "A Saliency-based Clustering Framework for Identifying Aberrant Predictions", "Authors": ["Aina Tersol Montserrat", "Alexander R. Loftus", "Yael Daihes"], "Categories": "cs.LG"}, "abstract": "In machine learning, classification tasks serve as the cornerstone of a wide range of real-world applications. Reliable, trustworthy classification is particularly intricate in biomedical settings, where the ground truth is often inherently uncertain and relies on high degrees of human expertise for labeling. Traditional metrics such as precision and recall, while valuable, are insufficient for capturing the nuances of these ambiguous scenarios. Here we introduce the concept of aberrant predictions, emphasizing that the nature of classification errors is as critical as their frequency. We propose a novel, efficient training methodology aimed at both reducing the misclassification rate and discerning aberrant predictions. Our framework demonstrates a substantial improvement in model performance, achieving a 20\\% increase in precision. We apply this methodology to the less-explored domain of veterinary radiology, where the stakes are high but have not been as extensively studied compared to human medicine. By focusing on the identification and mitigation of aberrant predictions, we enhance the utility and trustworthiness of machine learning classifiers in high-stakes, real-world scenarios, including new applications in the veterinary world.", "url": "https://arxiv.org/abs/2311.06454"}, {"metadata": {"arXiv": "2311.06456", "Date": "Sat, 11 Nov 2023 01:58:45 ", "Title": "Asymmetric Contrastive Multimodal Learning for Advancing Chemical Understanding", "Authors": ["Hao Xu", "Yifei Wang", "Yunrui Li", "Pengyu Hong"], "Categories": "cs.LG", "Comments": ["14 pages", "5 figures", "3 tables"]}, "abstract": "The versatility of multimodal deep learning holds tremendous promise for advancing scientific research and practical applications. As this field continues to evolve, the collective power of cross-modal analysis promises to drive transformative innovations, leading us to new frontiers in chemical understanding and discovery. Hence, we introduce Asymmetric Contrastive M}ultimodal Learning (ACML) as a novel approach tailored for molecules, showcasing its potential to advance the field of chemistry. ACML harnesses the power of effective asymmetric contrastive learning to seamlessly transfer information from various chemical modalities to molecular graph representations. By combining pre-trained chemical unimodal encoders and a shallow-designed graph encoder, ACML facilitates the assimilation of coordinated chemical semantics from different modalities, leading to comprehensive representation learning with efficient training. This innovative framework enhances the interpretability of learned representations and bolsters the expressive power of graph neural networks. Through practical tasks such as isomer discrimination and uncovering crucial chemical properties for drug discovery, ACML exhibits its capability to revolutionize chemical research and applications, providing a deeper understanding of chemical semantics of different modalities.", "url": "https://arxiv.org/abs/2311.06456"}, {"metadata": {"arXiv": "2311.06460", "Date": "Sat, 11 Nov 2023 03:03:33 ", "Title": "Online Continual Learning via Logit Adjusted Softmax", "Authors": ["Zhehao Huang", "Tao Li", "Chenhe Yuan", "Yingwen Wu", "Xiaolin Huang"], "Categories": "cs.LG"}, "abstract": "Online continual learning is a challenging problem where models must learn from a non-stationary data stream while avoiding catastrophic forgetting. Inter-class imbalance during training has been identified as a major cause of forgetting, leading to model prediction bias towards recently learned classes. In this paper, we theoretically analyze that inter-class imbalance is entirely attributed to imbalanced class-priors, and the function learned from intra-class intrinsic distributions is the Bayes-optimal classifier. To that end, we present that a simple adjustment of model logits during training can effectively resist prior class bias and pursue the corresponding Bayes-optimum. Our proposed method, Logit Adjusted Softmax, can mitigate the impact of inter-class imbalance not only in class-incremental but also in realistic general setups, with little additional computational cost. We evaluate our approach on various benchmarks and demonstrate significant performance improvements compared to prior arts. For example, our approach improves the best baseline by 4.6% on CIFAR10.", "url": "https://arxiv.org/abs/2311.06460"}, {"metadata": {"arXiv": "2311.06483", "Date": "Sat, 11 Nov 2023 05:43:54 ", "Title": "Stacked networks improve physics-informed training: applications to neural networks and deep operator networks", "Authors": ["Amanda A Howard", "Sarah H Murphy", "Shady E Ahmed", "Panos Stinis"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Physics-informed neural networks and operator networks have shown promise for effectively solving equations modeling physical systems. However, these networks can be difficult or impossible to train accurately for some systems of equations. We present a novel multifidelity framework for stacking physics-informed neural networks and operator networks that facilitates training. We successively build a chain of networks, where the output at one step can act as a low-fidelity input for training the next step, gradually increasing the expressivity of the learned model. The equations imposed at each step of the iterative process can be the same or different (akin to simulated annealing). The iterative (stacking) nature of the proposed method allows us to progressively learn features of a solution that are hard to learn directly. Through benchmark problems including a nonlinear pendulum, the wave equation, and the viscous Burgers equation, we show how stacking can be used to improve the accuracy and reduce the required size of physics-informed neural networks and operator networks.", "url": "https://arxiv.org/abs/2311.06483"}, {"metadata": {"arXiv": "2311.06505", "Date": "Sat, 11 Nov 2023 08:21:52 ", "Title": "CompCodeVet: A Compiler-guided Validation and Enhancement Approach for Code Dataset", "Authors": ["Le Chen", "Arijit Bhattacharjee", "Nesreen K. Ahmed", "Niranjan Hasabnis", "Gal Oren", "Bin Lei", "Ali Jannesari"], "Categories": "cs.LG"}, "abstract": "Large language models (LLMs) have become increasingly prominent in academia and industry due to their remarkable performance in diverse applications. As these models evolve with increasing parameters, they excel in tasks like sentiment analysis and machine translation. However, even models with billions of parameters face challenges in tasks demanding multi-step reasoning. Code generation and comprehension, especially in C and C++, emerge as significant challenges. While LLMs trained on code datasets demonstrate competence in many tasks, they struggle with rectifying non-compilable C and C++ code. Our investigation attributes this subpar performance to two primary factors: the quality of the training dataset and the inherent complexity of the problem which demands intricate reasoning. Existing \"Chain of Thought\" (CoT) prompting techniques aim to enhance multi-step reasoning. This approach, however, retains the limitations associated with the latent drawbacks of LLMs. In this work, we propose CompCodeVet, a compiler-guided CoT approach to produce compilable code from non-compilable ones. Diverging from the conventional approach of utilizing larger LLMs, we employ compilers as a teacher to establish a more robust zero-shot thought process. The evaluation of CompCodeVet on two open-source code datasets shows that CompCodeVet has the ability to improve the training dataset quality for LLMs.", "url": "https://arxiv.org/abs/2311.06505"}, {"metadata": {"arXiv": "2311.06518", "Date": "Sat, 11 Nov 2023 09:23:54 ", "Title": "Minimum Description Length Hopfield Networks", "Authors": ["Matan Abudy", "Nur Lan", "Emmanuel Chemla", "Roni Katzir"], "Categories": "cs.LG cs.CL", "Comments": ["4 pages", "Associative Memory & Hopfield Networks Workshop at NeurIPS2023"]}, "abstract": "Associative memory architectures are designed for memorization but also offer, through their retrieval method, a form of generalization to unseen inputs: stored memories can be seen as prototypes from this point of view. Focusing on Modern Hopfield Networks (MHN), we show that a large memorization capacity undermines the generalization opportunity. We offer a solution to better optimize this tradeoff. It relies on Minimum Description Length (MDL) to determine during training which memories to store, as well as how many of them.", "url": "https://arxiv.org/abs/2311.06518"}, {"metadata": {"arXiv": "2311.06527", "Date": "Sat, 11 Nov 2023 10:38:29 ", "Title": "TURBO: The Swiss Knife of Auto-Encoders", "Authors": ["Guillaume Qu\\'etant", "Yury Belousov", "Vitaliy Kinakh", "Slava Voloshynovskiy"], "Categories": "cs.LG cs.CR cs.IT hep-ph math.IT", "Journal-ref": "Qu\\'etant, G.; Belousov, Y.; Kinakh, V.; Voloshynovskiy, S. TURBO: The Swiss Knife of Auto-Encoders. Entropy 2023, 25, 1471", "DOI": "10.3390/e25101471"}, "abstract": "We present a novel information-theoretic framework, termed as TURBO, designed to systematically analyse and generalise auto-encoding methods. We start by examining the principles of information bottleneck and bottleneck-based networks in the auto-encoding setting and identifying their inherent limitations, which become more prominent for data with multiple relevant, physics-related representations. The TURBO framework is then introduced, providing a comprehensive derivation of its core concept consisting of the maximisation of mutual information between various data representations expressed in two directions reflecting the information flows. We illustrate that numerous prevalent neural network models are encompassed within this framework. The paper underscores the insufficiency of the information bottleneck concept in elucidating all such models, thereby establishing TURBO as a preferable theoretical reference. The introduction of TURBO contributes to a richer understanding of data representation and the structure of neural network models, enabling more efficient and versatile applications.", "url": "https://arxiv.org/abs/2311.06527"}, {"metadata": {"arXiv": "2311.06545", "Date": "Sat, 11 Nov 2023 11:47:29 ", "Title": "Understanding Generalization via Set Theory", "Authors": ["Shiqi Liu"], "Categories": "cs.LG", "Comments": ["14 pages"]}, "abstract": "Generalization is at the core of machine learning models. However, the definition of generalization is not entirely clear. We employ set theory to introduce the concepts of algorithms, hypotheses, and dataset generalization. We analyze the properties of dataset generalization and prove a theorem on surrogate generalization procedures. This theorem leads to our generalization method. Through a generalization experiment on the MNIST dataset, we obtain 13,541 sample bases. When we use the entire training set to evaluate the model's performance, the models achieve an accuracy of 99.945%. However, if we shift the sample bases or modify the neural network structure, the performance experiences a significant decline. We also identify consistently mispredicted samples and find that they are all challenging examples. The experiments substantiated the accuracy of the generalization definition and the effectiveness of the proposed methods. Both the set-theoretic deduction and the experiments help us better understand generalization.", "url": "https://arxiv.org/abs/2311.06545"}, {"metadata": {"arXiv": "2311.06547", "Date": "Sat, 11 Nov 2023 11:51:41 ", "Title": "From Charts to Atlas: Merging Latent Spaces into One", "Authors": ["Donato Crisostomi", "Irene Cannistraci", "Luca Moschella", "Pietro Barbiero", "Marco Ciccone", "Pietro Li\\`o", "Emanuele Rodol\\`a"], "Categories": "cs.LG", "Comments": ["To appear in the NeurReps workshop @ NeurIPS 2023"]}, "abstract": "Models trained on semantically related datasets and tasks exhibit comparable inter-sample relations within their latent spaces. We investigate in this study the aggregation of such latent spaces to create a unified space encompassing the combined information. To this end, we introduce Relative Latent Space Aggregation, a two-step approach that first renders the spaces comparable using relative representations, and then aggregates them via a simple mean. We carefully divide a classification problem into a series of learning tasks under three different settings: sharing samples, classes, or neither. We then train a model on each task and aggregate the resulting latent spaces. We compare the aggregated space with that derived from an end-to-end model trained over all tasks and show that the two spaces are similar. We then observe that the aggregated space is better suited for classification, and empirically demonstrate that it is due to the unique imprints left by task-specific embedders within the representations. We finally test our framework in scenarios where no shared region exists and show that it can still be used to merge the spaces, albeit with diminished benefits over naive merging.", "url": "https://arxiv.org/abs/2311.06547"}, {"metadata": {"arXiv": "2311.06554", "Date": "Sat, 11 Nov 2023 12:04:47 ", "Title": "Graph ODE with Factorized Prototypes for Modeling Complicated Interacting Dynamics", "Authors": ["Xiao Luo", "Yiyang Gu", "Huiyu Jiang", "Jinsheng Huang", "Wei Ju", "Ming Zhang", "Yizhou Sun"], "Categories": "cs.LG"}, "abstract": "This paper studies the problem of modeling interacting dynamical systems, which is critical for understanding physical dynamics and biological processes. Recent research predominantly uses geometric graphs to represent these interactions, which are then captured by powerful graph neural networks (GNNs). However, predicting interacting dynamics in challenging scenarios such as out-of-distribution shift and complicated underlying rules remains unsolved. In this paper, we propose a new approach named Graph ODE with factorized prototypes (GOAT) to address the problem. The core of GOAT is to incorporate factorized prototypes from contextual knowledge into a continuous graph ODE framework. Specifically, GOAT employs representation disentanglement and system parameters to extract both object-level and system-level contexts from historical trajectories, which allows us to explicitly model their independent influence and thus enhances the generalization capability under system changes. Then, we integrate these disentangled latent representations into a graph ODE model, which determines a combination of various interacting prototypes for enhanced model expressivity. The entire model is optimized using an end-to-end variational inference framework to maximize the likelihood. Extensive experiments in both in-distribution and out-of-distribution settings validate the superiority of GOAT.", "url": "https://arxiv.org/abs/2311.06554"}, {"metadata": {"arXiv": "2311.06558", "Date": "Sat, 11 Nov 2023 12:28:31 ", "Title": "Convolve and Conquer: Data Comparison with Wiener Filters", "Authors": ["Deborah Pelacani Cruz", "George Strong", "Oscar Bates", "Carlos Cueto", "Jiashun Yao", "Lluis Guasch"], "Categories": "cs.LG", "Comments": ["10 pages", "5 figures", "Medical Imaging Meets Neurips Workshop"]}, "abstract": "Quantitative evaluations of differences and/or similarities between data samples define and shape optimisation problems associated with learning data distributions. Current methods to compare data often suffer from limitations in capturing such distributions or lack desirable mathematical properties for optimisation (e.g. smoothness, differentiability, or convexity). In this paper, we introduce a new method to measure (dis)similarities between paired samples inspired by Wiener-filter theory. The convolutional nature of Wiener filters allows us to comprehensively compare data samples in a globally correlated way. We validate our approach in four machine learning applications: data compression, medical imaging imputation, translated classification, and non-parametric generative modelling. Our results demonstrate increased resolution in reconstructed images with better perceptual quality and higher data fidelity, as well as robustness against translations, compared to conventional mean-squared-error analogue implementations.", "url": "https://arxiv.org/abs/2311.06558"}, {"metadata": {"arXiv": "2311.06625", "Date": "Sat, 11 Nov 2023 18:10:32 ", "Title": "Streamlining Energy Transition Scenarios to Key Policy Decisions", "Authors": ["Florian Joseph Baader", "Stefano Moret", "Wolfram Wiesemann", "Iain Staffell", "Andr\\'e Bardow"], "Categories": "cs.LG"}, "abstract": "Uncertainties surrounding the energy transition often lead modelers to present large sets of scenarios that are challenging for policymakers to interpret and act upon. An alternative approach is to define a few qualitative storylines from stakeholder discussions, which can be affected by biases and infeasibilities. Leveraging decision trees, a popular machine-learning technique, we derive interpretable storylines from many quantitative scenarios and show how the key decisions in the energy transition are interlinked. Specifically, our results demonstrate that choosing a high deployment of renewables and sector coupling makes global decarbonization scenarios robust against uncertainties in climate sensitivity and demand. Also, the energy transition to a fossil-free Europe is primarily determined by choices on the roles of bioenergy, storage, and heat electrification. Our transferrable approach translates vast energy model results into a small set of critical decisions, guiding decision-makers in prioritizing the key factors that will shape the energy transition.", "url": "https://arxiv.org/abs/2311.06625"}, {"metadata": {"arXiv": "2311.06643", "Date": "Sat, 11 Nov 2023 18:58:01 ", "Title": "Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images", "Authors": ["Badhan Chandra Das", "M. Hadi Amini", "Yanzhao Wu"], "Categories": "cs.LG", "Comments": ["V1"]}, "abstract": "Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulations. However, several recent studies have revealed that the default settings of FL may leak private training data under privacy attacks. Thus, it is still unclear whether and to what extent such privacy risks of FL exist in the medical domain, and if so, ``how to mitigate such risks?''. In this paper, first, we propose a holistic framework for Medical data Privacy risk analysis and mitigation in Federated Learning (MedPFL) to analyze privacy risks and develop effective mitigation strategies in FL for protecting private medical data. Second, we demonstrate the substantial privacy risks of using FL to process medical images, where adversaries can easily perform privacy attacks to reconstruct private medical images accurately. Third, we show that the defense approach of adding random noises may not always work effectively to protect medical images against privacy attacks in FL, which poses unique and pressing challenges associated with medical data for privacy protection.", "url": "https://arxiv.org/abs/2311.06643"}, {"metadata": {"arXiv": "2311.06690", "Date": "Sat, 11 Nov 2023 23:46:48 ", "Title": "Agnostic Membership Query Learning with Nontrivial Savings: New Results, Techniques", "Authors": ["Ari Karchmer"], "Categories": "cs.LG cs.CC stat.ML"}, "abstract": "(Abridged) Designing computationally efficient algorithms in the agnostic learning model (Haussler, 1992; Kearns et al., 1994) is notoriously difficult. In this work, we consider agnostic learning with membership queries for touchstone classes at the frontier of agnostic learning, with a focus on how much computation can be saved over the trivial runtime of 2^n$. This approach is inspired by and continues the study of ``learning with nontrivial savings'' (Servedio and Tan, 2017). To this end, we establish multiple agnostic learning algorithms, highlighted by: 1. An agnostic learning algorithm for circuits consisting of a sublinear number of gates, which can each be any function computable by a sublogarithmic degree k polynomial threshold function (the depth of the circuit is bounded only by size). This algorithm runs in time 2^{n -s(n)} for s(n) \\approx n/(k+1), and learns over the uniform distribution over unlabelled examples on \\{0,1\\}^n. 2. An agnostic learning algorithm for circuits consisting of a sublinear number of gates, where each can be any function computable by a \\sym^+ circuit of subexponential size and sublogarithmic degree k. This algorithm runs in time 2^{n-s(n)} for s(n) \\approx n/(k+1), and learns over distributions of unlabelled examples that are products of k+1 arbitrary and unknown distributions, each over \\{0,1\\}^{n/(k+1)} (assume without loss of generality that k+1 divides n).", "url": "https://arxiv.org/abs/2311.06690"}, {"metadata": {"arXiv": "2311.06720", "Date": "Sun, 12 Nov 2023 03:25:34 ", "Title": "Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer", "Authors": ["Bowen Tan", "Yun Zhu", "Lijuan Liu", "Eric Xing", "Zhiting Hu", "Jindong Chen"], "Categories": "cs.LG cs.CL", "Comments": ["In proceedings of NeurIPS 2023; Code and model available at https://github.com/tanyuqian/cappy and https://huggingface.co/btan2/cappy-large", "respectively"]}, "abstract": "Large language models (LLMs) such as T0, FLAN, and OPT-IML, excel in multi-tasking under a unified instruction-following paradigm, where they also exhibit remarkable generalization abilities to unseen tasks. Despite their impressive performance, these LLMs, with sizes ranging from several billion to hundreds of billions of parameters, demand substantial computational resources, making their training and inference expensive and inefficient. Furthermore, adapting these models to downstream applications, particularly complex tasks, is often unfeasible due to the extensive hardware requirements for finetuning, even when utilizing parameter-efficient approaches such as prompt tuning. Additionally, the most powerful multi-task LLMs, such as OPT-IML-175B and FLAN-PaLM-540B, are not publicly accessible, severely limiting their customization potential. To address these challenges, we introduce a pretrained small scorer, Cappy, designed to enhance the performance and efficiency of multi-task LLMs. With merely 360 million parameters, Cappy functions either independently on classification tasks or serve as an auxiliary component for LLMs, boosting their performance. Moreover, Cappy enables efficiently integrating downstream supervision without requiring LLM finetuning nor the access to their parameters. Our experiments demonstrate that, when working independently on 11 language understanding tasks from PromptSource, Cappy outperforms LLMs that are several orders of magnitude larger. Besides, on 45 complex tasks from BIG-Bench, Cappy boosts the performance of the advanced multi-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to cooperate with other LLM adaptations, including finetuning and in-context learning, offering additional performance enhancement.", "url": "https://arxiv.org/abs/2311.06720"}, {"metadata": {"arXiv": "2311.06756", "Date": "Sun, 12 Nov 2023 07:13:37 ", "Title": "Personalized Federated Learning via ADMM with Moreau Envelope", "Authors": ["Shengkun Zhu", "Jinshan Zeng", "Sheng Wang", "Yuan Sun", "Zhiyong Peng"], "Categories": "cs.LG cs.DC", "Comments": ["15 pages"]}, "abstract": "Personalized federated learning (PFL) is an approach proposed to address the issue of poor convergence on heterogeneous data. However, most existing PFL frameworks require strong assumptions for convergence. In this paper, we propose an alternating direction method of multipliers (ADMM) for training PFL models with Moreau envelope (FLAME), which achieves a sublinear convergence rate, relying on the relatively weak assumption of gradient Lipschitz continuity. Moreover, due to the gradient-free nature of ADMM, FLAME alleviates the need for hyperparameter tuning, particularly in avoiding the adjustment of the learning rate when training the global model. In addition, we propose a biased client selection strategy to expedite the convergence of training of PFL models. Our theoretical analysis establishes the global convergence under both unbiased and biased client selection strategies. Our experiments validate that FLAME, when trained on heterogeneous data, outperforms state-of-the-art methods in terms of model performance. Regarding communication efficiency, it exhibits an average speedup of 3.75x compared to the baselines. Furthermore, experimental results validate that the biased client selection strategy speeds up the convergence of both personalized and global models.", "url": "https://arxiv.org/abs/2311.06756"}, {"metadata": {"arXiv": "2311.06798", "Date": "Sun, 12 Nov 2023 10:21:04 ", "Title": "MetaMix: Meta-state Precision Searcher for Mixed-precision Activation Quantization", "Authors": ["Han-Byul Kim", "Joo Hyung Lee", "Sungjoo Yoo", "Hong-Seok Kim"], "Categories": "cs.LG cs.CV"}, "abstract": "Mixed-precision quantization of efficient networks often suffer from activation instability encountered in the exploration of bit selections. To address this problem, we propose a novel method called MetaMix which consists of bit selection and weight training phases. The bit selection phase iterates two steps, (1) the mixed-precision-aware weight update, and (2) the bit-search training with the fixed mixed-precision-aware weights, both of which combined reduce activation instability in mixed-precision quantization and contribute to fast and high-quality bit selection. The weight training phase exploits the weights and step sizes trained in the bit selection phase and fine-tunes them thereby offering fast training. Our experiments with efficient and hard-to-quantize networks, i.e., MobileNet v2 and v3, and ResNet-18 on ImageNet show that our proposed method pushes the boundary of mixed-precision quantization, in terms of accuracy vs. operations, by outperforming both mixed- and single-precision SOTA methods.", "url": "https://arxiv.org/abs/2311.06798"}, {"metadata": {"arXiv": "2311.06801", "Date": "Sun, 12 Nov 2023 10:40:43 ", "Title": "A Comprehensive Survey On Client Selections in Federated Learning", "Authors": ["Ala Gouissem and Zina Chkirbene and Ridha Hamila"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated Learning (FL) is a rapidly growing field in machine learning that allows data to be trained across multiple decentralized devices. The selection of clients to participate in the training process is a critical factor for the performance of the overall system. In this survey, we provide a comprehensive overview of the state-of-the-art client selection techniques in FL, including their strengths and limitations, as well as the challenges and open issues that need to be addressed. We cover conventional selection techniques such as random selection where all or partial random of clients is used for the trained. We also cover performance-aware selections and as well as resource-aware selections for resource-constrained networks and heterogeneous networks. We also discuss the usage of client selection in model security enhancement. Lastly, we discuss open issues and challenges related to clients selection in dynamic constrained, and heterogeneous networks.", "url": "https://arxiv.org/abs/2311.06801"}, {"metadata": {"arXiv": "2311.06816", "Date": "Sun, 12 Nov 2023 11:41:07 ", "Title": "On original and latent space connectivity in deep neural networks", "Authors": ["Boyang Gu", "Anastasia Borovykh"], "Categories": "cs.LG cs.CV"}, "abstract": "We study whether inputs from the same class can be connected by a continuous path, in original or latent representation space, such that all points on the path are mapped by the neural network model to the same class. Understanding how the neural network views its own input space and how the latent spaces are structured has value for explainability and robustness. We show that paths, linear or nonlinear, connecting same-class inputs exist in all cases studied.", "url": "https://arxiv.org/abs/2311.06816"}, {"metadata": {"arXiv": "2311.06818", "Date": "Sun, 12 Nov 2023 11:51:05 ", "Title": "Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text Commentary Data", "Authors": ["Swarup Ranjan Behera and Vijaya V. Saradhi"], "Categories": "cs.LG cs.CL", "Comments": ["The initial work was published in the ICMLA 2019 conference"], "ACM-class": "I.2.7"}, "abstract": "Devising player-specific strategies in cricket necessitates a meticulous understanding of each player's unique strengths and weaknesses. Nevertheless, the absence of a definitive computational approach to extract such insights from cricket players poses a significant challenge. This paper seeks to address this gap by establishing computational models designed to extract the rules governing player strengths and weaknesses, thereby facilitating the development of tailored strategies for individual players. The complexity of this endeavor lies in several key areas: the selection of a suitable dataset, the precise definition of strength and weakness rules, the identification of an appropriate learning algorithm, and the validation of the derived rules. To tackle these challenges, we propose the utilization of unstructured data, specifically cricket text commentary, as a valuable resource for constructing comprehensive strength and weakness rules for cricket players. We also introduce computationally feasible definitions for the construction of these rules, and present a dimensionality reduction technique for the rule-building process. In order to showcase the practicality of this approach, we conduct an in-depth analysis of cricket player strengths and weaknesses using a vast corpus of more than one million text commentaries. Furthermore, we validate the constructed rules through two distinct methodologies: intrinsic and extrinsic. The outcomes of this research are made openly accessible, including the collected data, source code, and results for over 250 cricket players, which can be accessed at https://bit.ly/2PKuzx8.", "url": "https://arxiv.org/abs/2311.06818"}, {"metadata": {"arXiv": "2311.06837", "Date": "Sun, 12 Nov 2023 13:30:31 ", "Title": "GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs on Large Clusters", "Authors": ["Jaeyong Song", "Hongsun Jang", "Jaewon Jung", "Youngsok Kim", "Jinho Lee"], "Categories": "cs.LG cs.DC"}, "abstract": "Graph neural networks (GNNs) are one of the most rapidly growing fields within deep learning. According to the growth in the dataset and the model size used for GNNs, an important problem is that it becomes nearly impossible to keep the whole network on GPU memory. Among numerous attempts, distributed training is one popular approach to address the problem. However, due to the nature of GNNs, existing distributed approaches suffer from poor scalability, mainly due to the slow external server communications. In this paper, we propose GraNNDis, an efficient distributed GNN training framework for training GNNs on large graphs and deep layers. GraNNDis introduces three new techniques. First, shared preloading provides a training structure for a cluster of multi-GPU servers. We suggest server-wise preloading of essential vertex dependencies to reduce the low-bandwidth external server communications. Second, we present expansion-aware sampling. Because shared preloading alone has limitations because of the neighbor explosion, expansion-aware sampling reduces vertex dependencies that span across server boundaries. Third, we propose cooperative batching to create a unified framework for full-graph and minibatch training. It significantly reduces redundant memory usage in mini-batch training. From this, GraNNDis enables a reasonable trade-off between full-graph and mini-batch training through unification especially when the entire graph does not fit into the GPU memory. With experiments conducted on a multi-server/multi-GPU cluster, we show that GraNNDis provides superior speedup over the state-of-the-art distributed GNN training frameworks.", "url": "https://arxiv.org/abs/2311.06837"}, {"metadata": {"arXiv": "2311.06839", "Date": "Sun, 12 Nov 2023 13:31:35 ", "Title": "Inference and Interference: The Role of Clipping, Pruning and Loss Landscapes in Differentially Private Stochastic Gradient Descent", "Authors": ["Lauren Watson", "Eric Gan", "Mohan Dantam", "Baharan Mirzasoleiman", "Rik Sarkar"], "Categories": "cs.LG cs.CR"}, "abstract": "Differentially private stochastic gradient descent (DP-SGD) is known to have poorer training and test performance on large neural networks, compared to ordinary stochastic gradient descent (SGD). In this paper, we perform a detailed study and comparison of the two processes and unveil several new insights. By comparing the behavior of the two processes separately in early and late epochs, we find that while DP-SGD makes slower progress in early stages, it is the behavior in the later stages that determines the end result. This separate analysis of the clipping and noise addition steps of DP-SGD shows that while noise introduces errors to the process, gradient descent can recover from these errors when it is not clipped, and clipping appears to have a larger impact than noise. These effects are amplified in higher dimensions (large neural networks), where the loss basin occupies a lower dimensional space. We argue theoretically and using extensive experiments that magnitude pruning can be a suitable dimension reduction technique in this regard, and find that heavy pruning can improve the test accuracy of DPSGD.", "url": "https://arxiv.org/abs/2311.06839"}, {"metadata": {"arXiv": "2311.06876", "Date": "Sun, 12 Nov 2023 15:30:44 ", "Title": "Unified machine learning tasks and datasets for enhancing renewable energy", "Authors": ["Arsam Aryandoust", "Thomas Rigoni", "Francesco di Stefano", "Anthony Patt"], "Categories": "cs.LG"}, "abstract": "Multi-tasking machine learning (ML) models exhibit prediction abilities in domains with little to no training data available (few-shot and zero-shot learning). Over-parameterized ML models are further capable of zero-loss training and near-optimal generalization performance. An open research question is, how these novel paradigms contribute to solving tasks related to enhancing the renewable energy transition and mitigating climate change. A collection of unified ML tasks and datasets from this domain can largely facilitate the development and empirical testing of such models, but is currently missing. Here, we introduce the ETT-17 (Energy Transition Tasks-17), a collection of 17 datasets from six different application domains related to enhancing renewable energy, including out-of-distribution validation and testing data. We unify all tasks and datasets, such that they can be solved using a single multi-tasking ML model. We further analyse the dimensions of each dataset; investigate what they require for designing over-parameterized models; introduce a set of dataset scores that describe important properties of each task and dataset; and provide performance benchmarks.", "url": "https://arxiv.org/abs/2311.06876"}, {"metadata": {"arXiv": "2311.06879", "Date": "Sun, 12 Nov 2023 15:43:39 ", "Title": "pFedES: Model Heterogeneous Personalized Federated Learning with Feature Extractor Sharing", "Authors": ["Liping Yi", "Han Yu", "Gang Wang", "Xiaoguang Liu"], "Categories": "cs.LG cs.DC", "Comments": ["12 pages", "10 figures. arXiv admin note: text overlap with arXiv:2310.13283"]}, "abstract": "As a privacy-preserving collaborative machine learning paradigm, federated learning (FL) has attracted significant interest from academia and the industry alike. To allow each data owner (a.k.a., FL clients) to train a heterogeneous and personalized local model based on its local data distribution, system resources and requirements on model structure, the field of model-heterogeneous personalized federated learning (MHPFL) has emerged. Existing MHPFL approaches either rely on the availability of a public dataset with special characteristics to facilitate knowledge transfer, incur high computation and communication costs, or face potential model leakage risks. To address these limitations, we propose a model-heterogeneous personalized Federated learning approach based on feature Extractor Sharing (pFedES). It incorporates a small homogeneous feature extractor into each client's heterogeneous local model. Clients train them via the proposed iterative learning method to enable the exchange of global generalized knowledge and local personalized knowledge. The small local homogeneous extractors produced after local training are uploaded to the FL server and for aggregation to facilitate easy knowledge sharing among clients. We theoretically prove that pFedES can converge over wall-to-wall time. Extensive experiments on two real-world datasets against six state-of-the-art methods demonstrate that pFedES builds the most accurate model, while incurring low communication and computation costs. Compared with the best-performing baseline, it achieves 1.61% higher test accuracy, while reducing communication and computation costs by 99.6% and 82.9%, respectively.", "url": "https://arxiv.org/abs/2311.06879"}, {"metadata": {"arXiv": "2311.06888", "Date": "Sun, 12 Nov 2023 16:21:29 ", "Title": "Preserving Node-level Privacy in Graph Neural Networks", "Authors": ["Zihang Xiang", "Tianhao Wang", "Di Wang"], "Categories": "cs.LG cs.CR"}, "abstract": "Differential privacy (DP) has seen immense applications in learning on tabular, image, and sequential data where instance-level privacy is concerned. In learning on graphs, contrastingly, works on node-level privacy are highly sparse. Challenges arise as existing DP protocols hardly apply to the message-passing mechanism in Graph Neural Networks (GNNs). In this study, we propose a solution that specifically addresses the issue of node-level privacy. Our protocol consists of two main components: 1) a sampling routine called HeterPoisson, which employs a specialized node sampling strategy and a series of tailored operations to generate a batch of sub-graphs with desired properties, and 2) a randomization routine that utilizes symmetric multivariate Laplace (SML) noise instead of the commonly used Gaussian noise. Our privacy accounting shows this particular combination provides a non-trivial privacy guarantee. In addition, our protocol enables GNN learning with good performance, as demonstrated by experiments on five real-world datasets; compared with existing baselines, our method shows significant advantages, especially in the high privacy regime. Experimentally, we also 1) perform membership inference attacks against our protocol and 2) apply privacy audit techniques to confirm our protocol's privacy integrity. In the sequel, we present a study on a seemingly appealing approach \\cite{sajadmanesh2023gap} (USENIX'23) that protects node-level privacy via differentially private node/instance embeddings. Unfortunately, such work has fundamental privacy flaws, which are identified through a thorough case study. More importantly, we prove an impossibility result of achieving both (strong) privacy and (acceptable) utility through private instance embedding. The implication is that such an approach has intrinsic utility barriers when enforcing differential privacy.", "url": "https://arxiv.org/abs/2311.06888"}, {"metadata": {"arXiv": "2311.06894", "Date": "Sun, 12 Nov 2023 16:45:29 ", "Title": "An Application of Vector Autoregressive Model for Analyzing the Impact of Weather And Nearby Traffic Flow On The Traffic Volume", "Authors": ["Anh Thi-Hoang Nguyen", "Dung Ha Nguyen", "Trong-Hop Do"], "Categories": "cs.LG", "Comments": ["International Conference on Computing and Communication Technologies (RIVF2022)"]}, "abstract": "This paper aims to predict the traffic flow at one road segment based on nearby traffic volume and weather conditions. Our team also discover the impact of weather conditions and nearby traffic volume on the traffic flow at a target point. The analysis results will help solve the problem of traffic flow prediction and develop an optimal transport network with efficient traffic movement and minimal traffic congestion. Hourly historical weather and traffic flow data are selected to solve this problem. This paper uses model VAR(36) with time trend and constant to train the dataset and forecast. With an RMSE of 565.0768111 on average, the model is considered appropriate although some statistical tests implies that the residuals are unstable and non-normal. Also, this paper points out some variables that are not useful in forecasting, which helps simplify the data-collecting process when building the forecasting system.", "url": "https://arxiv.org/abs/2311.06894"}, {"metadata": {"arXiv": "2311.06921", "Date": "Sun, 12 Nov 2023 18:31:20 ", "Title": "Concept Matching: Clustering-based Federated Continual Learning", "Authors": ["Xiaopeng Jiang", "Cristian Borcea"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated Continual Learning (FCL) has emerged as a promising paradigm that combines Federated Learning (FL) and Continual Learning (CL). To achieve good model accuracy, FCL needs to tackle catastrophic forgetting due to concept drift over time in CL, and to overcome the potential interference among clients in FL. We propose Concept Matching (CM), a clustering-based framework for FCL to address these challenges. The CM framework groups the client models into concept model clusters, and then builds different global models to capture different concepts in FL over time. In each round, the server sends the global concept models to the clients. To avoid catastrophic forgetting, each client selects the concept model best-matching the concept of the current data for further fine-tuning. To avoid interference among client models with different concepts, the server clusters the models representing the same concept, aggregates the model weights in each cluster, and updates the global concept model with the cluster model of the same concept. Since the server does not know the concepts captured by the aggregated cluster models, we propose a novel server concept matching algorithm that effectively updates a global concept model with a matching cluster model. The CM framework provides flexibility to use different clustering, aggregation, and concept matching algorithms. The evaluation demonstrates that CM outperforms state-of-the-art systems and scales well with the number of clients and the model size.", "url": "https://arxiv.org/abs/2311.06921"}, {"metadata": {"arXiv": "2311.06928", "Date": "Sun, 12 Nov 2023 18:59:42 ", "Title": "Attention for Causal Relationship Discovery from Biological Neural Dynamics", "Authors": ["Ziyu Lu", "Anika Tabassum", "Shruti Kulkarni", "Lu Mi", "J. Nathan Kutz", "Eric Shea-Brown", "Seung-Hwan Lim"], "Categories": "cs.LG stat.ME", "Comments": ["Accepted to the NeurIPS 2023 Workshop on Causal Representation Learning"]}, "abstract": "This paper explores the potential of the transformer models for learning Granger causality in networks with complex nonlinear dynamics at every node, as in neurobiological and biophysical networks. Our study primarily focuses on a proof-of-concept investigation based on simulated neural dynamics, for which the ground-truth causality is known through the underlying connectivity matrix. For transformer models trained to forecast neuronal population dynamics, we show that the cross attention module effectively captures the causal relationship among neurons, with an accuracy equal or superior to that for the most popular Granger causality analysis method. While we acknowledge that real-world neurobiology data will bring further challenges, including dynamic connectivity and unobserved variability, this research offers an encouraging preliminary glimpse into the utility of the transformer model for causal representation learning in neuroscience.", "url": "https://arxiv.org/abs/2311.06928"}, {"metadata": {"arXiv": "2311.06942", "Date": "Sun, 12 Nov 2023 20:06:48 ", "Title": "Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks", "Authors": ["Moshe Eliasof", "Davide Murari", "Ferdia Sherry", "Carola-Bibiane Sch\\\"onlieb"], "Categories": "cs.LG cs.CR"}, "abstract": "Graph Neural Networks (GNNs) have established themselves as a key component in addressing diverse graph-based tasks. Despite their notable successes, GNNs remain susceptible to input perturbations in the form of adversarial attacks. This paper introduces an innovative approach to fortify GNNs against adversarial perturbations through the lens of contractive dynamical systems. Our method introduces graph neural layers based on differential equations with contractive properties, which, as we show, improve the robustness of GNNs. A distinctive feature of the proposed approach is the simultaneous learned evolution of both the node features and the adjacency matrix, yielding an intrinsic enhancement of model robustness to perturbations in the input features and the connectivity of the graph. We mathematically derive the underpinnings of our novel architecture and provide theoretical insights to reason about its expected behavior. We demonstrate the efficacy of our method through numerous real-world benchmarks, reading on par or improved performance compared to existing methods.", "url": "https://arxiv.org/abs/2311.06942"}, {"metadata": {"arXiv": "2311.06952", "Date": "Sun, 12 Nov 2023 20:34:00 ", "Title": "A GPU-Accelerated Moving-Horizon Algorithm for Training Deep Classification Trees on Large Datasets", "Authors": ["Jiayang Ren", "Valent\\'in Osuna-Enciso", "Morimasa Okamoto", "Qiangqiang Mao", "Chaojie Ji", "Liang Cao", "Kaixun Hua", "Yankai Cao"], "Categories": "cs.LG math.OC", "Comments": ["36 pages (13 pages for the main body", "23 pages for the appendix)", "7 figures"]}, "abstract": "Decision trees are essential yet NP-complete to train, prompting the widespread use of heuristic methods such as CART, which suffers from sub-optimal performance due to its greedy nature. Recently, breakthroughs in finding optimal decision trees have emerged; however, these methods still face significant computational costs and struggle with continuous features in large-scale datasets and deep trees. To address these limitations, we introduce a moving-horizon differential evolution algorithm for classification trees with continuous features (MH-DEOCT). Our approach consists of a discrete tree decoding method that eliminates duplicated searches between adjacent samples, a GPU-accelerated implementation that significantly reduces running time, and a moving-horizon strategy that iteratively trains shallow subtrees at each node to balance the vision and optimizer capability. Comprehensive studies on 68 UCI datasets demonstrate that our approach outperforms the heuristic method CART on training and testing accuracy by an average of 3.44% and 1.71%, respectively. Moreover, these numerical studies empirically demonstrate that MH-DEOCT achieves near-optimal performance (only 0.38% and 0.06% worse than the global optimal method on training and testing, respectively), while it offers remarkable scalability for deep trees (e.g., depth=8) and large-scale datasets (e.g., ten million samples).", "url": "https://arxiv.org/abs/2311.06952"}, {"metadata": {"arXiv": "2311.06960", "Date": "Sun, 12 Nov 2023 20:57:30 ", "Title": "Robust Regression over Averaged Uncertainty", "Authors": ["Dimitris Bertsimas", "Yu Ma"], "Categories": "cs.LG math.OC"}, "abstract": "We propose a new formulation of robust regression by integrating all realizations of the uncertainty set and taking an averaged approach to obtain the optimal solution for the ordinary least-squared regression problem. We show that this formulation surprisingly recovers ridge regression and establishes the missing link between robust optimization and the mean squared error approaches for existing regression problems. We first prove the equivalence for four uncertainty sets: ellipsoidal, box, diamond, and budget, and provide closed-form formulations of the penalty term as a function of the sample size, feature size, as well as perturbation protection strength. We then show in synthetic datasets with different levels of perturbations, a consistent improvement of the averaged formulation over the existing worst-case formulation in out-of-sample performance. Importantly, as the perturbation level increases, the improvement increases, confirming our method's advantage in high-noise environments. We report similar improvements in the out-of-sample datasets in real-world regression problems obtained from UCI datasets.", "url": "https://arxiv.org/abs/2311.06960"}, {"metadata": {"arXiv": "2311.06965", "Date": "Sun, 12 Nov 2023 21:08:43 ", "Title": "Anchor Data Augmentation", "Authors": ["Nora Schneider", "Shirin Goshtasbpour", "Fernando Perez-Cruz"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose a novel algorithm for data augmentation in nonlinear over-parametrized regression. Our data augmentation algorithm borrows from the literature on causality and extends the recently proposed Anchor regression (AR) method for data augmentation, which is in contrast to the current state-of-the-art domain-agnostic solutions that rely on the Mixup literature. Our Anchor Data Augmentation (ADA) uses several replicas of the modified samples in AR to provide more training examples, leading to more robust regression predictions. We apply ADA to linear and nonlinear regression problems using neural networks. ADA is competitive with state-of-the-art C-Mixup solutions.", "url": "https://arxiv.org/abs/2311.06965"}, {"metadata": {"arXiv": "2311.06972", "Date": "Sun, 12 Nov 2023 21:54:53 ", "Title": "An Expandable Machine Learning-Optimization Framework to Sequential Decision-Making", "Authors": ["Dogacan Yilmaz and \\.I. Esra B\\\"uy\\\"uktahtak{\\i}n"], "Categories": "cs.LG math.OC", "DOI": "10.1016/j.ejor.2023.10.045"}, "abstract": "We present an integrated prediction-optimization (PredOpt) framework to efficiently solve sequential decision-making problems by predicting the values of binary decision variables in an optimal solution. We address the key issues of sequential dependence, infeasibility, and generalization in machine learning (ML) to make predictions for optimal solutions to combinatorial problems. The sequential nature of the combinatorial optimization problems considered is captured with recurrent neural networks and a sliding-attention window. We integrate an attention-based encoder-decoder neural network architecture with an infeasibility-elimination and generalization framework to learn high-quality feasible solutions to time-dependent optimization problems. In this framework, the required level of predictions is optimized to eliminate the infeasibility of the ML predictions. These predictions are then fixed in mixed-integer programming (MIP) problems to solve them quickly with the aid of a commercial solver. We demonstrate our approach to tackling the two well-known dynamic NP-Hard optimization problems: multi-item capacitated lot-sizing (MCLSP) and multi-dimensional knapsack (MSMK). Our results show that models trained on shorter and smaller-dimensional instances can be successfully used to predict longer and larger-dimensional problems. The solution time can be reduced by three orders of magnitude with an average optimality gap below 0.1%. We compare PredOpt with various specially designed heuristics and show that our framework outperforms them. PredOpt can be advantageous for solving dynamic MIP problems that need to be solved instantly and repetitively.", "url": "https://arxiv.org/abs/2311.06972"}, {"metadata": {"arXiv": "2311.06973", "Date": "Sun, 12 Nov 2023 22:01:34 ", "Title": "Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation", "Authors": ["Behrouz Azimian", "Shiva Moshtagh", "Anamitra Pal", "Shanshan Ma"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["9 pages"]}, "abstract": "Recently, we demonstrated success of a time-synchronized state estimator using deep neural networks (DNNs) for real-time unobservable distribution systems. In this letter, we provide analytical bounds on the performance of that state estimator as a function of perturbations in the input measurements. It has already been shown that evaluating performance based on only the test dataset might not effectively indicate a trained DNN's ability to handle input perturbations. As such, we analytically verify robustness and trustworthiness of DNNs to input perturbations by treating them as mixed-integer linear programming (MILP) problems. The ability of batch normalization in addressing the scalability limitations of the MILP formulation is also highlighted. The framework is validated by performing time-synchronized distribution system state estimation for a modified IEEE 34-node system and a real-world large distribution system, both of which are incompletely observed by micro-phasor measurement units.", "url": "https://arxiv.org/abs/2311.06973"}, {"metadata": {"arXiv": "2311.06978", "Date": "Sun, 12 Nov 2023 22:42:34 ", "Title": "Augmented Bridge Matching", "Authors": ["Valentin De Bortoli", "Guan-Horng Liu", "Tianrong Chen", "Evangelos A. Theodorou", "Weilie Nie"], "Categories": "cs.LG cs.CV stat.ML"}, "abstract": "Flow and bridge matching are a novel class of processes which encompass diffusion models. One of the main aspect of their increased flexibility is that these models can interpolate between arbitrary data distributions i.e. they generalize beyond generative modeling and can be applied to learning stochastic (and deterministic) processes of arbitrary transfer tasks between two given distributions. In this paper, we highlight that while flow and bridge matching processes preserve the information of the marginal distributions, they do \\emph{not} necessarily preserve the coupling information unless additional, stronger optimality conditions are met. This can be problematic if one aims at preserving the original empirical pairing. We show that a simple modification of the matching process recovers this coupling by augmenting the velocity field (or drift) with the information of the initial sample point. Doing so, we lose the Markovian property of the process but preserve the coupling information between distributions. We illustrate the efficiency of our augmentation in learning mixture of image translation tasks.", "url": "https://arxiv.org/abs/2311.06978"}, {"metadata": {"arXiv": "2311.07073", "Date": "Mon, 13 Nov 2023 04:40:13 ", "Title": "Exposition on over-squashing problem on GNNs: Current Methods, Benchmarks and Challenges", "Authors": ["Dai Shi", "Andi Han", "Lequan Lin", "Yi Guo", "Junbin Gao"], "Categories": "cs.LG"}, "abstract": "Graph-based message-passing neural networks (MPNNs) have achieved remarkable success in both node and graph-level learning tasks. However, several identified problems, including over-smoothing (OSM), limited expressive power, and over-squashing (OSQ), still limit the performance of MPNNs. In particular, OSQ serves as the latest identified problem, where MPNNs gradually lose their learning accuracy when long-range dependencies between graph nodes are required. In this work, we provide an exposition on the OSQ problem by summarizing different formulations of OSQ from current literature, as well as the three different categories of approaches for addressing the OSQ problem. In addition, we also discuss the alignment between OSQ and expressive power and the trade-off between OSQ and OSM. Furthermore, we summarize the empirical methods leveraged from existing works to verify the efficiency of OSQ mitigation approaches, with illustrations of their computational complexities. Lastly, we list some open questions that are of interest for further exploration of the OSQ problem along with potential directions from the best of our knowledge.", "url": "https://arxiv.org/abs/2311.07073"}, {"metadata": {"arXiv": "2311.07126", "Date": "Mon, 13 Nov 2023 07:39:13 ", "Title": "How to Do Machine Learning with Small Data? - A Review from an Industrial Perspective", "Authors": ["Ivan Kraljevski", "Yong Chul Ju", "Dmitrij Ivanov", "Constanze Tsch\\\"ope", "Matthias Wolff"], "Categories": "cs.LG"}, "abstract": "Artificial intelligence experienced a technological breakthrough in science, industry, and everyday life in the recent few decades. The advancements can be credited to the ever-increasing availability and miniaturization of computational resources that resulted in exponential data growth. However, because of the insufficient amount of data in some cases, employing machine learning in solving complex tasks is not straightforward or even possible. As a result, machine learning with small data experiences rising importance in data science and application in several fields. The authors focus on interpreting the general term of \"small data\" and their engineering and industrial application role. They give a brief overview of the most important industrial applications of machine learning and small data. Small data is defined in terms of various characteristics compared to big data, and a machine learning formalism was introduced. Five critical challenges of machine learning with small data in industrial applications are presented: unlabeled data, imbalanced data, missing data, insufficient data, and rare events. Based on those definitions, an overview of the considerations in domain representation and data acquisition is given along with a taxonomy of machine learning approaches in the context of small data.", "url": "https://arxiv.org/abs/2311.07126"}, {"metadata": {"arXiv": "2311.07141", "Date": "Mon, 13 Nov 2023 08:13:55 ", "Title": "SABAF: Removing Strong Attribute Bias from Neural Networks with Adversarial Filtering", "Authors": ["Jiazhi Li", "Mahyar Khayatkhoei", "Jiageng Zhu", "Hanchen Xie", "Mohamed E. Hussein", "Wael AbdAlmageed"], "Categories": "cs.LG cs.CY", "Comments": ["35 pages", "18 figures", "32 tables. Code will be released at https://github.com/jiazhi412/strong_attribute_bias. arXiv admin note: text overlap with arXiv:2310.04955"]}, "abstract": "Ensuring a neural network is not relying on protected attributes (e.g., race, sex, age) for prediction is crucial in advancing fair and trustworthy AI. While several promising methods for removing attribute bias in neural networks have been proposed, their limitations remain under-explored. To that end, in this work, we mathematically and empirically reveal the limitation of existing attribute bias removal methods in presence of strong bias and propose a new method that can mitigate this limitation. Specifically, we first derive a general non-vacuous information-theoretical upper bound on the performance of any attribute bias removal method in terms of the bias strength, revealing that they are effective only when the inherent bias in the dataset is relatively weak. Next, we derive a necessary condition for the existence of any method that can remove attribute bias regardless of the bias strength. Inspired by this condition, we then propose a new method using an adversarial objective that directly filters out protected attributes in the input space while maximally preserving all other attributes, without requiring any specific target label. The proposed method achieves state-of-the-art performance in both strong and moderate bias settings. We provide extensive experiments on synthetic, image, and census datasets, to verify the derived theoretical bound and its consequences in practice, and evaluate the effectiveness of the proposed method in removing strong attribute bias.", "url": "https://arxiv.org/abs/2311.07141"}, {"metadata": {"arXiv": "2311.07143", "Date": "Mon, 13 Nov 2023 08:14:29 ", "Title": "Learning Symmetrization for Equivariance with Orbit Distance Minimization", "Authors": ["Tien Dat Nguyen", "Jinwoo Kim", "Hongseok Yang", "Seunghoon Hong"], "Categories": "cs.LG", "Comments": ["16 pages", "1 figure"]}, "abstract": "We present a general framework for symmetrizing an arbitrary neural-network architecture and making it equivariant with respect to a given group. We build upon the proposals of Kim et al. (2023); Kaba et al. (2023) for symmetrization, and improve them by replacing their conversion of neural features into group representations, with an optimization whose loss intuitively measures the distance between group orbits. This change makes our approach applicable to a broader range of matrix groups, such as the Lorentz group O(1, 3), than these two proposals. We experimentally show our method's competitiveness on the SO(2) image classification task, and also its increased generality on the task with O(1, 3). Our implementation will be made accessible at https://github.com/tiendatnguyen-vision/Orbit-symmetrize.", "url": "https://arxiv.org/abs/2311.07143"}, {"metadata": {"arXiv": "2311.07202", "Date": "Mon, 13 Nov 2023 09:41:32 ", "Title": "Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control", "Authors": ["Zihao Wang", "Zhe Wu"], "Categories": "cs.LG cs.CE cs.SY eess.SY", "Comments": ["Submitted to 6th Annual Learning for Dynamics & Control Conference (L4DC 2024)"]}, "abstract": "Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive Control (MPC) successfully attains globally optimal solutions by upholding convexity within the MPC framework. However, current ICNN architectures encounter the issue of vanishing gradients, which limits their ability to serve as deep neural networks for complex tasks. Additionally, the current neural network-based MPC, including conventional neural network-based MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC based on first-principles models. In this study, we leverage the principles of ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific goal of reducing convergence time and mitigating the vanishing gradient problem while ensuring closed-loop stability. From a simulation study of a nonlinear chemical reactor, we observed a mitigation of vanishing gradient problem and a reduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and 20.2% compared to baseline plain RNN, plain LSTM, and Input Convex Recurrent Neural Network, respectively.", "url": "https://arxiv.org/abs/2311.07202"}, {"metadata": {"arXiv": "2311.07283", "Date": "Mon, 13 Nov 2023 12:25:45 ", "Title": "Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail and Elderly Patient Services", "Authors": ["Elizabeth Williams", "Daniel Gartner", "Paul Harper"], "Categories": "cs.LG math.OC"}, "abstract": "Recent research has highlighted the potential of linking predictive and prescriptive analytics. However, it remains widely unexplored how both paradigms could benefit from one another to address today's major challenges in healthcare. One of these is smarter planning of resource capacities for frail and elderly inpatient wards, addressing the societal challenge of an aging population. Frail and elderly patients typically suffer from multimorbidity and require more care while receiving medical treatment. The aim of this research is to assess how various predictive and prescriptive analytical methods, both individually and in tandem, contribute to addressing the operational challenges within an area of healthcare that is growing in demand. Clinical and demographic patient attributes are gathered from more than 165,000 patient records and used to explain and predict length of stay. To that extent, we employ Classification and Regression Trees (CART) analysis to establish this relationship. On the prescriptive side, deterministic and two-stage stochastic programs are developed to determine how to optimally plan for beds and ward staff with the objective to minimize cost. Furthermore, the two analytical methodologies are linked by generating demand for the prescriptive models using the CART groupings. The results show the linked methodologies provided different but similar results compared to using averages and in doing so, captured a more realistic real-world variation in the patient length of stay. Our research reveals that healthcare managers should consider using predictive and prescriptive models to make more informed decisions. By combining predictive and prescriptive analytics, healthcare managers can move away from relying on averages and incorporate the unique characteristics of their patients to create more robust planning decisions, mitigating risks caused by variations in demand.", "url": "https://arxiv.org/abs/2311.07283"}, {"metadata": {"arXiv": "2311.07289", "Date": "Mon, 13 Nov 2023 12:33:33 ", "Title": "A probabilistic forecast methodology for volatile electricity prices in the Australian National Electricity Market", "Authors": ["Cameron Cornell", "Nam Trong Dinh", "S. Ali Pourmousavi"], "Categories": "cs.LG", "Comments": ["This manuscript has been submitted to International Journal of Forecasting for possible publication"]}, "abstract": "The South Australia region of the Australian National Electricity Market (NEM) displays some of the highest levels of price volatility observed in modern electricity markets. This paper outlines an approach to probabilistic forecasting under these extreme conditions, including spike filtration and several post-processing steps. We propose using quantile regression as an ensemble tool for probabilistic forecasting, with our combined forecasts achieving superior results compared to all constituent models. Within our ensemble framework, we demonstrate that averaging models with varying training length periods leads to a more adaptive model and increased prediction accuracy. The applicability of the final model is evaluated by comparing our median forecasts with the point forecasts available from the Australian NEM operator, with our model outperforming these NEM forecasts by a significant margin.", "url": "https://arxiv.org/abs/2311.07289"}, {"metadata": {"arXiv": "2311.07323", "Date": "Mon, 13 Nov 2023 13:22:21 ", "Title": "A Voting Approach for Explainable Classification with Rule Learning", "Authors": ["Albert N\\\"ossig", "Tobias Hell", "Georg Moser"], "Categories": "cs.LG", "Comments": ["34 pages", "10 figures"]}, "abstract": "State-of-the-art results in typical classification tasks are mostly achieved by unexplainable machine learning methods, like deep neural networks, for instance. Contrarily, in this paper, we investigate the application of rule learning methods in such a context. Thus, classifications become based on comprehensible (first-order) rules, explaining the predictions made. In general, however, rule-based classifications are less accurate than state-of-the-art results (often significantly). As main contribution, we introduce a voting approach combining both worlds, aiming to achieve comparable results as (unexplainable) state-of-the-art methods, while still providing explanations in the form of deterministic rules. Considering a variety of benchmark data sets including a use case of significant interest to insurance industries, we prove that our approach not only clearly outperforms ordinary rule learning methods, but also yields results on a par with state-of-the-art outcomes.", "url": "https://arxiv.org/abs/2311.07323"}, {"metadata": {"arXiv": "2311.07324", "Date": "Mon, 13 Nov 2023 13:24:09 ", "Title": "DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for Distributed Machine Learning in Mobile Computing", "Authors": ["Rongwei Lu", "Yutong Jiang", "Yinan Mao", "Chen Tang", "Bin Chen", "Laizhong Cui", "Zhi Wang"], "Categories": "cs.LG"}, "abstract": "Distributed machine learning (DML) in mobile environments faces significant communication bottlenecks. Gradient compression has emerged as an effective solution to this issue, offering substantial benefits in environments with limited bandwidth and metered data. Yet, they encounter severe performance drop in non-IID environments due to a one-size-fits-all compression approach, which does not account for the varying data volumes across workers. Assigning varying compression ratios to workers with distinct data distributions and volumes is thus a promising solution. This study introduces an analysis of distributed SGD with non-uniform compression, which reveals that the convergence rate (indicative of the iterations needed to achieve a certain accuracy) is influenced by compression ratios applied to workers with differing volumes. Accordingly, we frame relative compression ratio assignment as an $n$-variables chi-square nonlinear optimization problem, constrained by a fixed and limited communication budget. We propose DAGC-R, which assigns the worker handling larger data volumes the conservative compression. Recognizing the computational limitations of mobile devices, we DAGC-A, which are computationally less demanding and enhances the robustness of the absolute gradient compressor in non-IID scenarios. Our experiments confirm that both the DAGC-A and DAGC-R can achieve better performance when dealing with highly imbalanced data volume distribution and restricted communication.", "url": "https://arxiv.org/abs/2311.07324"}, {"metadata": {"arXiv": "2311.07343", "Date": "Mon, 13 Nov 2023 13:55:52 ", "Title": "Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning", "Authors": ["Felix den Breejen", "Sangmin Bae", "Stephen Cha", "Tae-Young Kim", "Seoung Hyun Koh", "Se-Young Yun"], "Categories": "cs.LG", "Comments": ["Table Representation Learning Workshop at NeurIPS 2023"]}, "abstract": "While interests in tabular deep learning has significantly grown, conventional tree-based models still outperform deep learning methods. To narrow this performance gap, we explore the innovative retrieval mechanism, a methodology that allows neural networks to refer to other data points while making predictions. Our experiments reveal that retrieval-based training, especially when fine-tuning the pretrained TabPFN model, notably surpasses existing methods. Moreover, the extensive pretraining plays a crucial role to enhance the performance of the model. These insights imply that blending the retrieval mechanism with pretraining and transfer learning schemes offers considerable potential for advancing the field of tabular deep learning.", "url": "https://arxiv.org/abs/2311.07343"}, {"metadata": {"arXiv": "2311.07355", "Date": "Mon, 13 Nov 2023 14:19:36 ", "Title": "ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A Unified Neural Network Approach", "Authors": ["Konstantinos Sotiropoulos", "Lingxiao Zhao", "Pierre Jinghong Liang", "Leman Akoglu"], "Categories": "cs.LG", "Comments": ["Accepted at IEEE BigData 2023"]}, "abstract": "Given a complex graph database of node- and edge-attributed multi-graphs as well as associated metadata for each graph, how can we spot the anomalous instances? Many real-world problems can be cast as graph inference tasks where the graph representation could capture complex relational phenomena (e.g., transactions among financial accounts in a journal entry), along with metadata reflecting tabular features (e.g. approver, effective date, etc.). While numerous anomaly detectors based on Graph Neural Networks (GNNs) have been proposed, none are capable of directly handling directed graphs with multi-edges and self-loops. Furthermore, the simultaneous handling of relational and tabular features remains an unexplored area. In this work we propose ADAMM, a novel graph neural network model that handles directed multi-graphs, providing a unified end-to-end architecture that fuses metadata and graph-level representation learning through an unsupervised anomaly detection objective. Experiments on datasets from two different domains, namely, general-ledger journal entries from different firms (accounting) as well as human GPS trajectories from thousands of individuals (urban mobility) validate ADAMM's generality and detection effectiveness of expert-guided and ground-truth anomalies. Notably, ADAMM outperforms existing baselines that handle the two data modalities (graph and metadata) separately with post hoc synthesis efforts.", "url": "https://arxiv.org/abs/2311.07355"}, {"metadata": {"arXiv": "2311.07389", "Date": "Mon, 13 Nov 2023 15:14:50 ", "Title": "Transpose Attack: Stealing Datasets with Bidirectional Training", "Authors": ["Guy Amit", "Mosh Levy", "Yisroel Mirsky"], "Categories": "cs.LG cs.CR", "Comments": ["NDSS24 paper"]}, "abstract": "Deep neural networks are normally executed in the forward direction. However, in this work, we identify a vulnerability that enables models to be trained in both directions and on different tasks. Adversaries can exploit this capability to hide rogue models within seemingly legitimate models. In addition, in this work we show that neural networks can be taught to systematically memorize and retrieve specific samples from datasets. Together, these findings expose a novel method in which adversaries can exfiltrate datasets from protected learning environments under the guise of legitimate models. We focus on the data exfiltration attack and show that modern architectures can be used to secretly exfiltrate tens of thousands of samples with high fidelity, high enough to compromise data privacy and even train new models. Moreover, to mitigate this threat we propose a novel approach for detecting infected models.", "url": "https://arxiv.org/abs/2311.07389"}, {"metadata": {"arXiv": "2311.07417", "Date": "Mon, 13 Nov 2023 15:54:27 ", "Title": "Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration", "Authors": ["Soroush Hashemifar", "Saeed Parsa", "Morteza Zakeri-Nasrabadi"], "Categories": "cs.LG cs.CR cs.CV cs.NE"}, "abstract": "As the capacity of deep neural networks (DNNs) increases, their need for huge amounts of data significantly grows. A common practice is to outsource the training process or collect more data over the Internet, which introduces the risks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data while behaving maliciously once a trigger is injected into a sample at the test time. In such cases, the defender faces multiple difficulties. First, the available clean dataset may not be sufficient for fine-tuning and recovering the backdoored DNN. Second, it is impossible to recover the trigger in many real-world applications without information about it. In this paper, we formulate some characteristics of poisoned neurons. This backdoor suspiciousness score can rank network neurons according to their activation values, weights, and their relationship with other neurons in the same layer. Our experiments indicate the proposed method decreases the chance of attacks being successful by more than 50% with a tiny clean dataset, i.e., ten clean samples for the CIFAR-10 dataset, without significantly deteriorating the model's performance. Moreover, the proposed method runs three times as fast as baselines.", "url": "https://arxiv.org/abs/2311.07417"}, {"metadata": {"arXiv": "2311.07426", "Date": "Mon, 13 Nov 2023 16:00:16 ", "Title": "Optimising Human-AI Collaboration by Learning Convincing Explanations", "Authors": ["Alex J. Chan", "Alihan Huyuk", "Mihaela van der Schaar"], "Categories": "cs.LG cs.CV cs.HC"}, "abstract": "Machine learning models are being increasingly deployed to take, or assist in taking, complicated and high-impact decisions, from quasi-autonomous vehicles to clinical decision support systems. This poses challenges, particularly when models have hard-to-detect failure modes and are able to take actions without oversight. In order to handle this challenge, we propose a method for a collaborative system that remains safe by having a human ultimately making decisions, while giving the model the best opportunity to convince and debate them with interpretable explanations. However, the most helpful explanation varies among individuals and may be inconsistent across stated preferences. To this end we develop an algorithm, Ardent, to efficiently learn a ranking through interaction and best assist humans complete a task. By utilising a collaborative approach, we can ensure safety and improve performance while addressing transparency and accountability concerns. Ardent enables efficient and effective decision-making by adapting to individual preferences for explanations, which we validate through extensive simulations alongside a user study involving a challenging image classification task, demonstrating consistent improvement over competing systems.", "url": "https://arxiv.org/abs/2311.07426"}, {"metadata": {"arXiv": "2311.07427", "Date": "Mon, 13 Nov 2023 16:01:43 ", "Title": "Boolean Variation and Boolean Logic BackPropagation", "Authors": ["Van Minh Nguyen"], "Categories": "cs.LG cs.DM cs.LO math.OC"}, "abstract": "The notion of variation is introduced for the Boolean set and based on which Boolean logic backpropagation principle is developed. Using this concept, deep models can be built with weights and activations being Boolean numbers and operated with Boolean logic instead of real arithmetic. In particular, Boolean deep models can be trained directly in the Boolean domain without latent weights. No gradient but logic is synthesized and backpropagated through layers.", "url": "https://arxiv.org/abs/2311.07427"}, {"metadata": {"arXiv": "2311.07444", "Date": "Mon, 13 Nov 2023 16:18:58 ", "Title": "On the Robustness of Neural Collapse and the Neural Collapse of Robustness", "Authors": ["Jingtong Su", "Ya Shi Zhang", "Nikolaos Tsilivis", "Julia Kempe"], "Categories": "cs.LG"}, "abstract": "Neural Collapse refers to the curious phenomenon in the end of training of a neural network, where feature vectors and classification weights converge to a very simple geometrical arrangement (a simplex). While it has been observed empirically in various cases and has been theoretically motivated, its connection with crucial properties of neural networks, like their generalization and robustness, remains unclear. In this work, we study the stability properties of these simplices. We find that the simplex structure disappears under small adversarial attacks, and that perturbed examples \"leap\" between simplex vertices. We further analyze the geometry of networks that are optimized to be robust against adversarial perturbations of the input, and find that Neural Collapse is a pervasive phenomenon in these cases as well, with clean and perturbed representations forming aligned simplices, and giving rise to a robust simple nearest-neighbor classifier. By studying the propagation of the amount of collapse inside the network, we identify novel properties of both robust and non-robust machine learning models, and show that earlier, unlike later layers maintain reliable simplices on perturbed data.", "url": "https://arxiv.org/abs/2311.07444"}, {"metadata": {"arXiv": "2311.07454", "Date": "Mon, 13 Nov 2023 16:35:34 ", "Title": "Causal Discovery under Latent Class Confounding", "Authors": ["Bijan Mazaheri", "Spencer Gordon", "Yuval Rabani", "Leonard Schulman"], "Categories": "cs.LG cs.CC math.ST stat.TH"}, "abstract": "Directed acyclic graphs are used to model the causal structure of a system. ``Causal discovery'' describes the problem of learning this structure from data. When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms. For this reason, existing causal discovery algorithms are not suitable for the multiple-source setting. We demonstrate that, if the confounding is of bounded cardinality (i.e. the data comes from a limited number of sources), causal discovery can still be achieved. The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure.", "url": "https://arxiv.org/abs/2311.07454"}, {"metadata": {"arXiv": "2311.07461", "Date": "Mon, 13 Nov 2023 16:44:29 ", "Title": "On Self-Supervised Dynamic Incremental Regularised Adaptation", "Authors": ["Abanoub Ghobrial", "Kerstin Eder"], "Categories": "cs.LG"}, "abstract": "In this paper, we overview a recent method for dynamic domain adaptation named DIRA, which relies on a few samples in addition to a regularisation approach named elastic weight consolidation to achieve state-of-the-art (SOTA) domain adaptation results. DIRA has been previously shown to perform competitively with SOTA unsupervised adaption techniques. However, a limitation of DIRA is that it relies on labels to be provided for the few samples used in adaption. This makes it a supervised technique. In this paper, we discuss a proposed alteration to the DIRA method to make it self-supervised i.e. remove the need for providing labels. Experiments on our proposed alteration will be provided in future work.", "url": "https://arxiv.org/abs/2311.07461"}, {"metadata": {"arXiv": "2311.07498", "Date": "Mon, 13 Nov 2023 17:38:07 ", "Title": "Reducing the Need for Backpropagation and Discovering Better Optima With Explicit Optimizations of Neural Networks", "Authors": ["Jake Ryland Williams and Haoran Zhao"], "Categories": "cs.LG math.PR physics.data-an stat.ML"}, "abstract": "Iterative differential approximation methods that rely upon backpropagation have enabled the optimization of neural networks; however, at present, they remain computationally expensive, especially when training models at scale. In this paper, we propose a computationally efficient alternative for optimizing neural networks that can both reduce the costs of scaling neural networks and provide high-efficiency optimizations for low-resource applications. We derive an explicit solution to a simple feed-forward language model (LM) by mathematically analyzing its gradients. This solution generalizes from single-layer LMs to the class of all single-layer feed-forward softmax-activated neural models trained on positive-valued features, as is demonstrated by our extension of this solution application to MNIST digit classification. For both LM and digit classifiers, we find computationally that explicit solutions perform near-optimality in experiments showing that 1) iterative optimization only marginally improves the explicit solution parameters and 2) randomly initialized parameters iteratively optimize towards the explicit solution. We also preliminarily apply the explicit solution locally by layer in multi-layer networks and discuss how the solution's computational savings increase with model complexity -- for both single- and mult-layer applications of the explicit solution, we emphasize that the optima achieved cannot be reached by backpropagation alone, i.e., better optima appear discoverable only after explicit solutions are applied. Finally, we discuss the solution's computational savings alongside its impact on model interpretability and suggest future directions for the derivation of explicit solutions to complex- and multi-layer architectures.", "url": "https://arxiv.org/abs/2311.07498"}, {"metadata": {"arXiv": "2311.07504", "Date": "Mon, 13 Nov 2023 17:45:28 ", "Title": "STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using SMOTE, Edited Nearest Neighbour, and Mixup", "Authors": ["Yumnah Hasan", "Fatemeh Amerehi", "Patrick Healy", "Conor Ryan"], "Categories": "cs.LG", "Comments": ["7 pages", "4 figures", "International Conference on Intelligent Computer Communication and Processing"], "Journal-ref": "IEEE ICCP 2023"}, "abstract": "Imbalanced datasets in medical imaging are characterized by skewed class proportions and scarcity of abnormal cases. When trained using such data, models tend to assign higher probabilities to normal cases, leading to biased performance. Common oversampling techniques such as SMOTE rely on local information and can introduce marginalization issues. This paper investigates the potential of using Mixup augmentation that combines two training examples along with their corresponding labels to generate new data points as a generic vicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN and Mixup at the instance level. This integration enables us to effectively leverage the entire distribution of minority classes, thereby mitigating both between-class and within-class imbalances. We focus on the breast cancer problem, where imbalanced datasets are prevalent. The results demonstrate the effectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the Digital Database for Screening Mammography and Wisconsin Breast Cancer (Diagnostics) datasets, respectively. Moreover, this method shows promising potential when applied with an ensemble of machine learning (ML) classifiers.", "url": "https://arxiv.org/abs/2311.07504"}, {"metadata": {"arXiv": "2311.07510", "Date": "Mon, 13 Nov 2023 17:55:07 ", "Title": "Explicit Foundation Model Optimization with Self-Attentive Feed-Forward Neural Units", "Authors": ["Jake Ryland Williams and Haoran Zhao"], "Categories": "cs.LG math.PR physics.data-an stat.ML"}, "abstract": "Iterative approximation methods using backpropagation enable the optimization of neural networks, but they remain computationally expensive, especially when used at scale. This paper presents an efficient alternative for optimizing neural networks that reduces the costs of scaling neural networks and provides high-efficiency optimizations for low-resource applications. We will discuss a general result about feed-forward neural networks and then extend this solution to compositional (mult-layer) networks, which are applied to a simplified transformer block containing feed-forward and self-attention layers. These models are used to train highly-specified and complex multi-layer neural architectures that we refer to as self-attentive feed-forward unit (SAFFU) layers, which we use to develop a transformer that appears to generalize well over small, cognitively-feasible, volumes of data. Testing demonstrates explicit solutions outperform models optimized by backpropagation alone. Moreover, further application of backpropagation after explicit solutions leads to better optima from smaller scales of data, training effective models from much less data is enabled by explicit solution warm starts. We then carry out ablation experiments training a roadmap of about 250 transformer models over 1-million tokens to determine ideal settings. We find that multiple different architectural variants produce highly-performant models, and discover from this ablation that some of the best are not the most parameterized. This appears to indicate well-generalized models could be reached using less data by using explicit solutions, and that architectural exploration using explicit solutions pays dividends in guiding the search for efficient variants with fewer parameters, and which could be incorporated into low-resource hardware where AI might be embodied.", "url": "https://arxiv.org/abs/2311.07510"}, {"metadata": {"arXiv": "2311.07541", "Date": "Mon, 13 Nov 2023 18:31:48 ", "Title": "mlscorecheck: Testing the consistency of reported performance scores and experiments in machine learning", "Authors": ["Gy\\\"orgy Kov\\'acs and Attila Fazekas"], "Categories": "cs.LG", "MSC-class": "68T01", "ACM-class": "I.2.0"}, "abstract": "Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a challenging task. It necessitates either the reimplementation of techniques or a meticulous assessment of papers for deviations from the scientific method and best statistical practices. To facilitate the validation of reported results, we have developed numerical techniques capable of identifying inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression. These consistency tests are integrated into the open-source package mlscorecheck, which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling.", "url": "https://arxiv.org/abs/2311.07541"}, {"metadata": {"arXiv": "2311.07548", "Date": "Mon, 13 Nov 2023 18:37:07 ", "Title": "Interpretable Fine-Tuning for Graph Neural Network Surrogate Models", "Authors": ["Shivam Barwey and Romit Maulik"], "Categories": "cs.LG physics.comp-ph physics.flu-dyn"}, "abstract": "Data-based surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that adds interpretability to a pre-trained baseline GNN through an adaptive sub-graph sampling strategy that isolates regions in physical space intrinsically linked to the forecasting task, while retaining the predictive capability of the baseline. The structures identified by the fine-tuned GNNs, which are adaptively produced in the forward pass as explicit functions of the input, serve as an accessible link between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models. Demonstrations are performed using unstructured flow data sourced from flow over a backward-facing step at high Reynolds numbers.", "url": "https://arxiv.org/abs/2311.07548"}, {"metadata": {"arXiv": "2311.07558", "Date": "Mon, 13 Nov 2023 18:51:57 ", "Title": "Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning", "Authors": ["Arjun Bhardwaj", "Jonas Rothfuss", "Bhavya Sukhija", "Yarden As", "Marco Hutter", "Stelian Coros", "Andreas Krause"], "Categories": "cs.LG cs.RO"}, "abstract": "We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning (Meta-RL) algorithm designed to efficiently adapt control policies to changing dynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift adaptation to new dynamics with minimal interaction data. Existing Meta-RL methods require abundant meta-learning data, limiting their applicability in settings such as robotics, where data is costly to obtain. To address this, PACOH-RL incorporates regularization and epistemic uncertainty quantification in both the meta-learning and task adaptation stages. When facing new dynamics, we use these uncertainty estimates to effectively guide exploration and data collection. Overall, this enables positive transfer, even when access to data from prior tasks or dynamic settings is severely limited. Our experiment results demonstrate that PACOH-RL outperforms model-based RL and model-based Meta-RL baselines in adapting to new dynamic conditions. Finally, on a real robotic car, we showcase the potential for efficient RL policy adaptation in diverse, data-scarce conditions.", "url": "https://arxiv.org/abs/2311.07558"}, {"metadata": {"arXiv": "2311.07565", "Date": "Mon, 13 Nov 2023 18:54:43 ", "Title": "Exploration via linearly perturbed loss minimisation", "Authors": ["David Janz", "Shuai Liu", "Alex Ayoub", "Csaba Szepesv\\'ari"], "Categories": "cs.LG stat.ML"}, "abstract": "We introduce exploration via linear loss perturbations (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. With the data-dependent perturbations we propose, not present in previous PHE-type methods, EVILL is shown to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside of generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code.", "url": "https://arxiv.org/abs/2311.07565"}, {"metadata": {"arXiv": "2311.07568", "Date": "Mon, 13 Nov 2023 18:56:33 ", "Title": "Feature emergence via margin maximization: case studies in algebraic tasks", "Authors": ["Depen Morwani", "Benjamin L. Edelman", "Costin-Andrei Oncescu", "Rosie Zhao", "Sham Kakade"], "Categories": "cs.LG", "ACM-class": "I.5.1; I.2.6"}, "abstract": "Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning. While there have been significant recent strides in some cases towards understanding how neural networks implement specific target functions, this paper explores a complementary question -- why do networks arrive at particular computational strategies? Our inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations. Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks. Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network. Specifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. and Chughtai et al. More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies.", "url": "https://arxiv.org/abs/2311.07568"}, {"metadata": {"arXiv": "2311.06481", "Date": "Sat, 11 Nov 2023 05:09:31 ", "Title": "Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning", "Authors": ["Jianxiang Feng", "Jongseok Lee", "Simon Geisler", "Stephan Gunnemann", "Rudolph Triebel"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted on CoRL2023"]}, "abstract": "To facilitate reliable deployments of autonomous robots in the real world, Out-of-Distribution (OOD) detection capabilities are often required. A powerful approach for OOD detection is based on density estimation with Normalizing Flows (NFs). However, we find that prior work with NFs attempts to match the complex target distribution topologically with naive base distributions leading to adverse implications. In this work, we circumvent this topological mismatch using an expressive class-conditional base distribution trained with an information-theoretic objective to match the required topology. The proposed method enjoys the merits of wide compatibility with existing learned models without any performance degradation and minimum computation overhead while enhancing OOD detection capabilities. We demonstrate superior results in density estimation and 2D object detection benchmarks in comparison with extensive baselines. Moreover, we showcase the applicability of the method with a real-robot deployment.", "url": "https://arxiv.org/abs/2311.06481"}, {"metadata": {"arXiv": "2311.06828", "Date": "Sun, 12 Nov 2023 12:54:44 ", "Title": "Towards Continual Reinforcement Learning for Quadruped Robots", "Authors": ["Giovanni Minelli and Vassilis Vassiliades"], "Categories": "cs.RO cs.LG", "Comments": ["4 pages; Presented in the 3rd International Conference on Interactive Media", "Smart Systems and Emerging Technologies (IMET)"], "DOI": "10.2312/imet.20231258"}, "abstract": "Quadruped robots have emerged as an evolving technology that currently leverages simulators to develop a robust controller capable of functioning in the real-world without the need for further training. However, since it is impossible to predict all possible real-world situations, our research explores the possibility of enabling them to continue learning even after their deployment. To this end, we designed two continual learning scenarios, sequentially training the robot on different environments while simultaneously evaluating its performance across all of them. Our approach sheds light on the extent of both forward and backward skill transfer, as well as the degree to which the robot might forget previously acquired skills. By addressing these factors, we hope to enhance the adaptability and performance of quadruped robots in real-world scenarios.", "url": "https://arxiv.org/abs/2311.06828"}, {"metadata": {"arXiv": "2311.06769", "Date": "Sun, 12 Nov 2023 08:11:28 ", "Title": "Learning Predictive Safety Filter via Decomposition of Robust Invariant Set", "Authors": ["Zeyang Li", "Chuxiong Hu", "Weiye Zhao", "Changliu Liu"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Ensuring safety of nonlinear systems under model uncertainty and external disturbances is crucial, especially for real-world control tasks. Predictive methods such as robust model predictive control (RMPC) require solving nonconvex optimization problems online, which leads to high computational burden and poor scalability. Reinforcement learning (RL) works well with complex systems, but pays the price of losing rigorous safety guarantee. This paper presents a theoretical framework that bridges the advantages of both RMPC and RL to synthesize safety filters for nonlinear systems with state- and action-dependent uncertainty. We decompose the robust invariant set (RIS) into two parts: a target set that aligns with terminal region design of RMPC, and a reach-avoid set that accounts for the rest of RIS. We propose a policy iteration approach for robust reach-avoid problems and establish its monotone convergence. This method sets the stage for an adversarial actor-critic deep RL algorithm, which simultaneously synthesizes a reach-avoid policy network, a disturbance policy network, and a reach-avoid value network. The learned reach-avoid policy network is utilized to generate nominal trajectories for online verification, which filters potentially unsafe actions that may drive the system into unsafe regions when worst-case disturbances are applied. We formulate a second-order cone programming (SOCP) approach for online verification using system level synthesis, which optimizes for the worst-case reach-avoid value of any possible trajectories. The proposed safety filter requires much lower computational complexity than RMPC and still enjoys persistent robust safety guarantee. The effectiveness of our method is illustrated through a numerical example.", "url": "https://arxiv.org/abs/2311.06769"}, {"metadata": {"arXiv": "2311.07110", "Date": "Mon, 13 Nov 2023 06:52:56 ", "Title": "Adversarial Purification for Data-Driven Power System Event Classifiers with Diffusion Models", "Authors": ["Yuanbin Cheng", "Koji Yamashita", "Jim Follum", "Nanpeng Yu"], "Categories": "eess.SY cs.CR cs.LG cs.SY"}, "abstract": "The global deployment of the phasor measurement units (PMUs) enables real-time monitoring of the power system, which has stimulated considerable research into machine learning-based models for event detection and classification. However, recent studies reveal that machine learning-based methods are vulnerable to adversarial attacks, which can fool the event classifiers by adding small perturbations to the raw PMU data. To mitigate the threats posed by adversarial attacks, research on defense strategies is urgently needed. This paper proposes an effective adversarial purification method based on the diffusion model to counter adversarial attacks on the machine learning-based power system event classifier. The proposed method includes two steps: injecting noise into the PMU data; and utilizing a pre-trained neural network to eliminate the added noise while simultaneously removing perturbations introduced by the adversarial attacks. The proposed adversarial purification method significantly increases the accuracy of the event classifier under adversarial attacks while satisfying the requirements of real-time operations. In addition, the theoretical analysis reveals that the proposed diffusion model-based adversarial purification method decreases the distance between the original and compromised PMU data, which reduces the impacts of adversarial attacks. The empirical results on a large-scale real-world PMU dataset validate the effectiveness and computational efficiency of the proposed adversarial purification method.", "url": "https://arxiv.org/abs/2311.07110"}, {"metadata": {"arXiv": "2311.06302", "Date": "Tue, 07 Nov 2023 14:02:32 ", "Title": "Knowledge-Based Support for Adhesive Selection: Will it Stick?", "Authors": ["Simon Vandevelde", "Jeroen Jordens", "Bart Van Doninck", "Maarten Witters", "Joost Vennekens"], "Categories": "cs.AI cs.LO", "Comments": ["Under consideration in Theory and Practice of Logic Programming (TPLP)"]}, "abstract": "As the popularity of adhesive joints in industry increases, so does the need for tools to support the process of selecting a suitable adhesive. While some such tools already exist, they are either too limited in scope, or offer too little flexibility in use. This work presents a more advanced tool, that was developed together with a team of adhesive experts. We first extract the experts' knowledge about this domain and formalize it in a Knowledge Base (KB). The IDP-Z3 reasoning system can then be used to derive the necessary functionality from this KB. Together with a user-friendly interactive interface, this creates an easy-to-use tool capable of assisting the adhesive experts. To validate our approach, we performed user testing in the form of qualitative interviews. The experts are very positive about the tool, stating that, among others, it will help save time and find more suitable adhesives. Under consideration in Theory and Practice of Logic Programming (TPLP).", "url": "https://arxiv.org/abs/2311.06302"}, {"metadata": {"arXiv": "2311.06330", "Date": "Fri, 10 Nov 2023 18:54:33 ", "Title": "Smart Agent-Based Modeling: On the Use of Large Language Models in Computer Simulations", "Authors": ["Zengqing Wu", "Run Peng", "Xu Han", "Shuyuan Zheng", "Yixin Zhang", "Chuan Xiao"], "Categories": "cs.AI cs.CE cs.MA econ.GN q-fin.EC", "Comments": ["Source codes are available at https://github.com/Roihn/SABM"]}, "abstract": "Computer simulations offer a robust toolset for exploring complex systems across various disciplines. A particularly impactful approach within this realm is Agent-Based Modeling (ABM), which harnesses the interactions of individual agents to emulate intricate system dynamics. ABM's strength lies in its bottom-up methodology, illuminating emergent phenomena by modeling the behaviors of individual components of a system. Yet, ABM has its own set of challenges, notably its struggle with modeling natural language instructions and common sense in mathematical equations or rules. This paper seeks to transcend these boundaries by integrating Large Language Models (LLMs) like GPT into ABM. This amalgamation gives birth to a novel framework, Smart Agent-Based Modeling (SABM). Building upon the concept of smart agents -- entities characterized by their intelligence, adaptability, and computation ability -- we explore in the direction of utilizing LLM-powered agents to simulate real-world scenarios with increased nuance and realism. In this comprehensive exploration, we elucidate the state of the art of ABM, introduce SABM's potential and methodology, and present three case studies (source codes available at https://github.com/Roihn/SABM), demonstrating the SABM methodology and validating its effectiveness in modeling real-world systems. Furthermore, we cast a vision towards several aspects of the future of SABM, anticipating a broader horizon for its applications. Through this endeavor, we aspire to redefine the boundaries of computer simulations, enabling a more profound understanding of complex systems.", "url": "https://arxiv.org/abs/2311.06330"}, {"metadata": {"arXiv": "2311.06390", "Date": "Fri, 10 Nov 2023 20:44:30 ", "Title": "ChatGPT in the context of precision agriculture data analytics", "Authors": ["Ilyas Potamitis"], "Categories": "cs.AI eess.SP", "Comments": ["33 pages", "21 figures"], "MSC-class": "68Txx"}, "abstract": "In this study we argue that integrating ChatGPT into the data processing pipeline of automated sensors in precision agriculture has the potential to bring several benefits and enhance various aspects of modern farming practices. Policy makers often face a barrier when they need to get informed about the situation in vast agricultural fields to reach to decisions. They depend on the close collaboration between agricultural experts in the field, data analysts, and technology providers to create interdisciplinary teams that cannot always be secured on demand or establish effective communication across these diverse domains to respond in real-time. In this work we argue that the speech recognition input modality of ChatGPT provides a more intuitive and natural way for policy makers to interact with the database of the server of an agricultural data processing system to which a large, dispersed network of automated insect traps and sensors probes reports. The large language models map the speech input to text, allowing the user to form its own version of unconstrained verbal query, raising the barrier of having to learn and adapt oneself to a specific data analytics software. The output of the language model can interact through Python code and Pandas with the entire database, visualize the results and use speech synthesis to engage the user in an iterative and refining discussion related to the data. We show three ways of how ChatGPT can interact with the database of the remote server to which a dispersed network of different modalities (optical counters, vibration recordings, pictures, and video), report. We examine the potential and the validity of the response of ChatGPT in analyzing, and interpreting agricultural data, providing real time insights and recommendations to stakeholders", "url": "https://arxiv.org/abs/2311.06390"}, {"metadata": {"arXiv": "2311.06576", "Date": "Sat, 11 Nov 2023 14:11:49 ", "Title": "An Intelligent Social Learning-based Optimization Strategy for Black-box Robotic Control with Reinforcement Learning", "Authors": ["Xubo Yang", "Jian Gao", "Ting Wang", "Yaozhen He"], "Categories": "cs.AI cs.NE cs.RO"}, "abstract": "Implementing intelligent control of robots is a difficult task, especially when dealing with complex black-box systems, because of the lack of visibility and understanding of how these robots work internally. This paper proposes an Intelligent Social Learning (ISL) algorithm to enable intelligent control of black-box robotic systems. Inspired by mutual learning among individuals in human social groups, ISL includes learning, imitation, and self-study styles. Individuals in the learning style use the Levy flight search strategy to learn from the best performer and form the closest relationships. In the imitation style, individuals mimic the best performer with a second-level rapport by employing a random perturbation strategy. In the self-study style, individuals learn independently using a normal distribution sampling method while maintaining a distant relationship with the best performer. Individuals in the population are regarded as autonomous intelligent agents in each style. Neural networks perform strategic actions in three styles to interact with the environment and the robot and iteratively optimize the network policy. Overall, ISL builds on the principles of intelligent optimization, incorporating ideas from reinforcement learning, and possesses strong search capabilities, fast computation speed, fewer hyperparameters, and insensitivity to sparse rewards. The proposed ISL algorithm is compared with four state-of-the-art methods on six continuous control benchmark cases in MuJoCo to verify its effectiveness and advantages. Furthermore, ISL is adopted in the simulation and experimental grasping tasks of the UR3 robot for validations, and satisfactory solutions are yielded.", "url": "https://arxiv.org/abs/2311.06576"}, {"metadata": {"arXiv": "2311.06622", "Date": "Sat, 11 Nov 2023 17:39:24 ", "Title": "TrainerAgent: Customizable and Efficient Model Training through LLM-Powered Multi-Agent System", "Authors": ["Haoyuan Li", "Hao Jiang", "Tianke Zhang", "Zhelun Yu", "Aoxiong Yin", "Hao Cheng", "Siming Fu", "Yuhao Zhang", "Wanggui He"], "Categories": "cs.AI cs.CL"}, "abstract": "Training AI models has always been challenging, especially when there is a need for custom models to provide personalized services. Algorithm engineers often face a lengthy process to iteratively develop models tailored to specific business requirements, making it even more difficult for non-experts. The quest for high-quality and efficient model development, along with the emergence of Large Language Model (LLM) Agents, has become a key focus in the industry. Leveraging the powerful analytical, planning, and decision-making capabilities of LLM, we propose a TrainerAgent system comprising a multi-agent framework including Task, Data, Model and Server agents. These agents analyze user-defined tasks, input data, and requirements (e.g., accuracy, speed), optimizing them comprehensively from both data and model perspectives to obtain satisfactory models, and finally deploy these models as online service. Experimental evaluations on classical discriminative and generative tasks in computer vision and natural language processing domains demonstrate that our system consistently produces models that meet the desired criteria. Furthermore, the system exhibits the ability to critically identify and reject unattainable tasks, such as fantastical scenarios or unethical requests, ensuring robustness and safety. This research presents a significant advancement in achieving desired models with increased efficiency and quality as compared to traditional model development, facilitated by the integration of LLM-powered analysis, decision-making, and execution capabilities, as well as the collaboration among four agents. We anticipate that our work will contribute to the advancement of research on TrainerAgent in both academic and industry communities, potentially establishing it as a new paradigm for model development in the field of AI.", "url": "https://arxiv.org/abs/2311.06622"}, {"metadata": {"arXiv": "2311.06703", "Date": "Sun, 12 Nov 2023 01:31:34 ", "Title": "Enabling Human-Centered AI: A Methodological Perspective", "Authors": ["Wei Xu", "Zaifeng Gao"], "Categories": "cs.AI cs.CY cs.SE"}, "abstract": "Human-centered AI (HCAI) is a design philosophy that advocates prioritizing humans in designing, developing, and deploying intelligent systems, aiming to maximize the benefits of AI to humans and avoid potential adverse impacts. While HCAI continues to influence, the lack of guidance on methodology in practice makes its adoption challenging. This paper proposes a comprehensive HCAI framework based on our previous work with integrated components, including design goals, design principles, implementation approaches, interdisciplinary teams, HCAI methods, and HCAI processes. This paper also presents a \"three-layer\" approach to facilitate the implementation of the framework. We believe this systematic and executable framework can overcome the weaknesses in current HCAI frameworks and the challenges currently faced in practice, putting it into action to enable HCAI further.", "url": "https://arxiv.org/abs/2311.06703"}, {"metadata": {"arXiv": "2311.06856", "Date": "Sun, 12 Nov 2023 14:14:07 ", "Title": "On learning spatial sequences with the movement of attention", "Authors": ["Viacheslav M. Osaulenko"], "Categories": "cs.AI", "Comments": ["10 pages", "3 figures"]}, "abstract": "In this paper we start with a simple question, how is it possible that humans can recognize different movements over skin with only a prior visual experience of them? Or in general, what is the representation of spatial sequences that are invariant to scale, rotation, and translation across different modalities? To answer, we rethink the mathematical representation of spatial sequences, argue against the minimum description length principle, and focus on the movements of attention. We advance the idea that spatial sequences must be represented on different levels of abstraction, this adds redundancy but is necessary for recognition and generalization. To address the open question of how these abstractions are formed we propose two hypotheses: the first invites exploring selectionism learning, instead of finding parameters in some models; the second proposes to find new data structures, not neural network architectures, to efficiently store and operate over redundant features to be further selected. Movements of attention are central to human cognition and lessons should be applied to new better learning algorithms.", "url": "https://arxiv.org/abs/2311.06856"}, {"metadata": {"arXiv": "2311.06979", "Date": "Sun, 12 Nov 2023 22:43:26 ", "Title": "Assessing the Interpretability of Programmatic Policies with Large Language Models", "Authors": ["Zahra Bashir", "Michael Bowling", "Levi H. S. Lelis"], "Categories": "cs.AI cs.PL cs.SE", "Comments": ["This paper is under-review for AAAI. The main file is arxiv.tex and I have a supplementary_materials.tex file as well"]}, "abstract": "Although the synthesis of programs encoding policies often carries the promise of interpretability, systematic evaluations to assess the interpretability of these policies were never performed, likely because of the complexity of such an evaluation. In this paper, we introduce a novel metric that uses large-language models (LLM) to assess the interpretability of programmatic policies. For our metric, an LLM is given both a program and a description of its associated programming language. The LLM then formulates a natural language explanation of the program. This explanation is subsequently fed into a second LLM, which tries to reconstruct the program from the natural language explanation. Our metric measures the behavioral similarity between the reconstructed program and the original. We validate our approach using obfuscated programs that are used to solve classic programming problems. We also assess our metric with programmatic policies synthesized for playing a real-time strategy game, comparing the interpretability scores of programmatic policies synthesized by an existing system to lightly obfuscated versions of the same programs. Our LLM-based interpretability score consistently ranks less interpretable programs lower and more interpretable ones higher. These findings suggest that our metric could serve as a reliable and inexpensive tool for evaluating the interpretability of programmatic policies.", "url": "https://arxiv.org/abs/2311.06979"}, {"metadata": {"arXiv": "2311.06993", "Date": "Mon, 13 Nov 2023 00:16:25 ", "Title": "State-of-the-Art Review and Synthesis: A Requirement-based Roadmap for Standardized Predictive Maintenance Automation Using Digital Twin Technologies", "Authors": ["Sizhe Ma", "Katherine A. Flanigan", "Mario Berg\\'es"], "Categories": "cs.AI cs.SY eess.SY", "Comments": ["(1)This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Recent digital advances have popularized predictive maintenance (PMx), offering enhanced efficiency, automation, accuracy, cost savings, and independence in maintenance. Yet, it continues to face numerous limitations such as poor explainability, sample inefficiency of data-driven methods, complexity of physics-based methods, and limited generalizability and scalability of knowledge-based methods. This paper proposes leveraging Digital Twins (DTs) to address these challenges and enable automated PMx adoption at larger scales. While we argue that DTs have this transformative potential, they have not yet reached the level of maturity needed to bridge these gaps in a standardized way. Without a standard definition for such evolution, this transformation lacks a solid foundation upon which to base its development. This paper provides a requirement-based roadmap supporting standardized PMx automation using DT technologies. A systematic approach comprising two primary stages is presented. First, we methodically identify the Informational Requirements (IRs) and Functional Requirements (FRs) for PMx, which serve as a foundation from which any unified framework must emerge. Our approach to defining and using IRs and FRs to form the backbone of any PMx DT is supported by the track record of IRs and FRs being successfully used as blueprints in other areas, such as for product development within the software industry. Second, we conduct a thorough literature review spanning fields to determine the ways in which these IRs and FRs are currently being used within DTs, enabling us to point to the specific areas where further research is warranted to support the progress and maturation of requirement-based PMx DTs.", "url": "https://arxiv.org/abs/2311.06993"}, {"metadata": {"arXiv": "2311.07233", "Date": "Mon, 13 Nov 2023 10:53:48 ", "Title": "IASCAR: Incremental Answer Set Counting by Anytime Refinement", "Authors": ["Johannes K. Fichte", "Sarah Alice Gaggl", "Markus Hecher", "Dominik Rusovac"], "Categories": "cs.AI cs.LO", "Comments": ["Under consideration in Theory and Practice of Logic Programming (TPLP)"]}, "abstract": "Answer set programming (ASP) is a popular declarative programming paradigm with various applications. Programs can easily have many answer sets that cannot be enumerated in practice, but counting still allows quantifying solution spaces. If one counts under assumptions on literals, one obtains a tool to comprehend parts of the solution space, so-called answer set navigation. However, navigating through parts of the solution space requires counting many times, which is expensive in theory. Knowledge compilation compiles instances into representations on which counting works in polynomial time. However, these techniques exist only for CNF formulas, and compiling ASP programs into CNF formulas can introduce an exponential overhead. This paper introduces a technique to iteratively count answer sets under assumptions on knowledge compilations of CNFs that encode supported models. Our anytime technique uses the inclusion-exclusion principle to improve bounds by over- and undercounting systematically. In a preliminary empirical analysis, we demonstrate promising results. After compiling the input (offline phase), our approach quickly (re)counts.", "url": "https://arxiv.org/abs/2311.07233"}, {"metadata": {"arXiv": "2311.07396", "Date": "Mon, 13 Nov 2023 15:24:55 ", "Title": "Exploring Values in Museum Artifacts in the SPICE project: a Preliminary Study", "Authors": ["Nele Kadastik", "Thomas A. Pederson", "Luis Emilio Bruni", "Rossana Damiano", "Antonio Lieto", "Manuel Striani", "Tsvi Kuflik", "Alan Wecker,"], "Categories": "cs.AI cs.HC", "Comments": ["6"], "MSC-class": "Human-Computer Interaction", "DOI": "10.1145/3511047.3537662"}, "abstract": "This document describes the rationale, the implementation and a preliminary evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project to enhance the diversity of perspectives experienced by museum visitors. The tool, called DEGARI 2.0 for values, relies on the commonsense reasoning framework TCL, and exploits an ontological model formalizingthe Haidt's theory of moral values to associate museum items with combined values and emotions. Within a museum exhibition, this tool can suggest cultural items that are associated not only with the values of already experienced or preferred objects, but also with novel items with different value stances, opening the visit experience to more inclusive interpretations of cultural content. The system has been preliminarily tested, in the context of the SPICE project, on the collection of the Hecht Museum of Haifa.", "url": "https://arxiv.org/abs/2311.07396"}, {"metadata": {"arXiv": "2311.07509", "Date": "Mon, 13 Nov 2023 17:54:50 ", "Title": "A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases", "Authors": ["Juan Sequeda", "Dean Allemang", "Bryon Jacob"], "Categories": "cs.AI cs.CL cs.DB", "Comments": ["34 pages"]}, "abstract": "Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.", "url": "https://arxiv.org/abs/2311.07509"}, {"metadata": {"arXiv": "2311.06455", "Date": "Sat, 11 Nov 2023 01:56:35 ", "Title": "Aria-NeRF: Multimodal Egocentric View Synthesis", "Authors": ["Jiankai Sun", "Jianing Qiu", "Chuanyang Zheng", "John Tucker", "Javier Yu", "Mac Schwager"], "Categories": "cs.CV cs.AI"}, "abstract": "We seek to accelerate research in developing rich, multimodal scene models trained from egocentric data, based on differentiable volumetric ray-tracing inspired by Neural Radiance Fields (NeRFs). The construction of a NeRF-like model from an egocentric image sequence plays a pivotal role in understanding human behavior and holds diverse applications within the realms of VR/AR. Such egocentric NeRF-like models may be used as realistic simulations, contributing significantly to the advancement of intelligent agents capable of executing tasks in the real-world. The future of egocentric view synthesis may lead to novel environment representations going beyond today's NeRFs by augmenting visual data with multimodal sensors such as IMU for egomotion tracking, audio sensors to capture surface texture and human language context, and eye-gaze trackers to infer human attention patterns in the scene. To support and facilitate the development and evaluation of egocentric multimodal scene modeling, we present a comprehensive multimodal egocentric video dataset. This dataset offers a comprehensive collection of sensory data, featuring RGB images, eye-tracking camera footage, audio recordings from a microphone, atmospheric pressure readings from a barometer, positional coordinates from GPS, connectivity details from Wi-Fi and Bluetooth, and information from dual-frequency IMU datasets (1kHz and 800Hz) paired with a magnetometer. The dataset was collected with the Meta Aria Glasses wearable device platform. The diverse data modalities and the real-world context captured within this dataset serve as a robust foundation for furthering our understanding of human behavior and enabling more immersive and intelligent experiences in the realms of VR, AR, and robotics.", "url": "https://arxiv.org/abs/2311.06455"}, {"metadata": {"arXiv": "2311.06497", "Date": "Sat, 11 Nov 2023 07:26:47 ", "Title": "DRUformer: Enhancing the driving scene Important object detection with driving relationship self-understanding", "Authors": ["Yingjie Niu", "Ming Ding", "Keisuke Fujii", "Kento Ohtani", "Alexander Carballo", "Kazuya Takeda"], "Categories": "cs.CV cs.AI"}, "abstract": "Traffic accidents frequently lead to fatal injuries, contributing to over 50 million deaths until 2023. To mitigate driving hazards and ensure personal safety, it is crucial to assist vehicles in anticipating important objects during travel. Previous research on important object detection primarily assessed the importance of individual participants, treating them as independent entities and frequently overlooking the connections between these participants. Unfortunately, this approach has proven less effective in detecting important objects in complex scenarios. In response, we introduce Driving scene Relationship self-Understanding transformer (DRUformer), designed to enhance the important object detection task. The DRUformer is a transformer-based multi-modal important object detection model that takes into account the relationships between all the participants in the driving scenario. Recognizing that driving intention also significantly affects the detection of important objects during driving, we have incorporated a module for embedding driving intention. To assess the performance of our approach, we conducted a comparative experiment on the DRAMA dataset, pitting our model against other state-of-the-art (SOTA) models. The results demonstrated a noteworthy 16.2\\% improvement in mIoU and a substantial 12.3\\% boost in ACC compared to SOTA methods. Furthermore, we conducted a qualitative analysis of our model's ability to detect important objects across different road scenarios and classes, highlighting its effectiveness in diverse contexts. Finally, we conducted various ablation studies to assess the efficiency of the proposed modules in our DRUformer model.", "url": "https://arxiv.org/abs/2311.06497"}, {"metadata": {"arXiv": "2311.06607", "Date": "Sat, 11 Nov 2023 16:37:41 ", "Title": "Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models", "Authors": ["Zhang Li", "Biao Yang", "Qiang Liu", "Zhiyin Ma", "Shuo Zhang", "Jingxu Yang", "Yabo Sun", "Yuliang Liu", "Xiang Bai"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Large Multimodal Models have demonstrated impressive capabilities in understanding general vision-language tasks. However, due to the limitation of supported input resolution (e.g., 448 x 448) as well as the inexhaustive description of the training image-text pair, these models often encounter challenges when dealing with intricate scene understandings and narratives. Here we address the problem by proposing the Monkey. Our contributions are two-fold: 1) without pretraining from the start, our method can be built upon an existing vision encoder (e.g., vit-BigHuge) to effectively improve the input resolution capacity up to 896 x 1344 pixels; 2) we propose a multi-level description generation method, which automatically provides rich information that can guide model to learn contextual association between scenes and objects. Our extensive testing across more than 16 distinct datasets reveals that Monkey achieves consistently competitive performance over the existing LMMs on fundamental tasks, such as Image Captioning, General Visual Question Answering (VQA), and Document-oriented VQA. Models, interactive demo, and the source code are provided at the following https://github.com/Yuliang-Liu/Monkey.", "url": "https://arxiv.org/abs/2311.06607"}, {"metadata": {"arXiv": "2311.06623", "Date": "Sat, 11 Nov 2023 17:52:06 ", "Title": "VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems", "Authors": ["Armin Danesh Pazho", "Vinit Katariya", "Ghazal Alinezhad Noghre", "Hamed Tabkhi"], "Categories": "cs.CV cs.AI"}, "abstract": "Enhancing roadway safety and traffic management has become an essential focus area for a broad range of modern cyber-physical systems and intelligent transportation systems. Vehicle Trajectory Prediction is a pivotal element within numerous applications for highway and road safety. These applications encompass a wide range of use cases, spanning from traffic management and accident prevention to enhancing work-zone safety and optimizing energy conservation. The ability to implement intelligent management in this context has been greatly advanced by the developments in the field of Artificial Intelligence (AI), alongside the increasing deployment of surveillance cameras across road networks. In this paper, we introduce a novel transformer-based approach for vehicle trajectory prediction for highway safety and surveillance, denoted as VT-Former. In addition to utilizing transformers to capture long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module has been proposed to capture intricate social interactions among vehicles. Combining these two core components culminates in a precise approach for vehicle trajectory prediction. Our study on three benchmark datasets with three different viewpoints demonstrates the State-of-The-Art (SoTA) performance of VT-Former in vehicle trajectory prediction and its generalizability and robustness. We also evaluate VT-Former's efficiency on embedded boards and explore its potential for vehicle anomaly detection as a sample application, showcasing its broad applicability.", "url": "https://arxiv.org/abs/2311.06623"}, {"metadata": {"arXiv": "2311.06691", "Date": "Sat, 11 Nov 2023 23:55:40 ", "Title": "Automatized Self-Supervised Learning for Skin Lesion Screening", "Authors": ["Vullnet Useini", "Stephanie Tanadini-Lang", "Quentin Lohmeyer", "Mirko Meboldt", "Nicolaus Andratschke", "Ralph P. Braun and Javier Barranco Garc\\'ia"], "Categories": "cs.CV cs.AI", "Comments": ["11 pages", "4 figures"]}, "abstract": "The incidence rates of melanoma, the deadliest form of skin cancer, have been increasing steadily worldwide, presenting a significant challenge to dermatologists. Early detection of melanoma is crucial for improving patient survival rates, but identifying suspicious lesions through ugly duckling (UD) screening, the current method used for skin cancer screening, can be challenging and often requires expertise in pigmented lesions. To address these challenges and improve patient outcomes, an artificial intelligence (AI) decision support tool was developed to assist dermatologists in identifying UD from wide-field patient images. The tool uses a state-of-the-art object detection algorithm to identify and extract all skin lesions from patient images, which are then sorted by suspiciousness using a self-supervised AI algorithm. A clinical validation study was conducted to evaluate the tool's performance, which demonstrated an average sensitivity of 93% for the top-10 AI-identified UDs on skin lesions selected by the majority of experts in pigmented skin lesions. The study also found that dermatologists confidence increased, and the average majority agreement with the top-10 AI-identified UDs improved to 100% when assisted by AI. The development of this AI decision support tool aims to address the shortage of specialists, enable at-risk patients to receive faster consultations and understand the impact of AI-assisted screening. The tool's automation can assist dermatologists in identifying suspicious lesions and provide a more objective assessment, reducing subjectivity in the screening process. The future steps for this project include expanding the dataset to include histologically confirmed melanoma cases and increasing the number of participants for clinical validation to strengthen the tool's reliability and adapt it for real-world consultation.", "url": "https://arxiv.org/abs/2311.06691"}, {"metadata": {"arXiv": "2311.06746", "Date": "Sun, 12 Nov 2023 05:57:56 ", "Title": "Two Stream Scene Understanding on Graph Embedding", "Authors": ["Wenkai Yang", "Wenyuan Sun", "Runxaing Huang"], "Categories": "cs.CV cs.AI"}, "abstract": "The paper presents a novel two-stream network architecture for enhancing scene understanding in computer vision. This architecture utilizes a graph feature stream and an image feature stream, aiming to merge the strengths of both modalities for improved performance in image classification and scene graph generation tasks. The graph feature stream network comprises a segmentation structure, scene graph generation, and a graph representation module. The segmentation structure employs the UPSNet architecture with a backbone that can be a residual network, Vit, or Swin Transformer. The scene graph generation component focuses on extracting object labels and neighborhood relationships from the semantic map to create a scene graph. Graph Convolutional Networks (GCN), GraphSAGE, and Graph Attention Networks (GAT) are employed for graph representation, with an emphasis on capturing node features and their interconnections. The image feature stream network, on the other hand, focuses on image classification through the use of Vision Transformer and Swin Transformer models. The two streams are fused using various data fusion methods. This fusion is designed to leverage the complementary strengths of graph-based and image-based features.Experiments conducted on the ADE20K dataset demonstrate the effectiveness of the proposed two-stream network in improving image classification accuracy compared to conventional methods. This research provides a significant contribution to the field of computer vision, particularly in the areas of scene understanding and image classification, by effectively combining graph-based and image-based approaches.", "url": "https://arxiv.org/abs/2311.06746"}, {"metadata": {"arXiv": "2311.06772", "Date": "Sun, 12 Nov 2023 08:29:41 ", "Title": "ChatAnything: Facetime Chat with LLM-Enhanced Personas", "Authors": ["Yilin Zhao", "Xinbin Yuan", "Shanghua Gao", "Zhijie Lin", "Qibin Hou", "Jiashi Feng", "Daquan Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "In this technical report, we target generating anthropomorphized personas for LLM-based characters in an online manner, including visual appearance, personality and tones, with only text descriptions. To achieve this, we first leverage the in-context learning capability of LLMs for personality generation by carefully designing a set of system prompts. We then propose two novel concepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for diverse voice and appearance generation. For MoV, we utilize the text-to-speech (TTS) algorithms with a variety of pre-defined tones and select the most matching one based on the user-provided text description automatically. For MoD, we combine the recent popular text-to-image generation techniques and talking head algorithms to streamline the process of generating talking objects. We termed the whole framework as ChatAnything. With it, users could be able to animate anything with any personas that are anthropomorphic using just a few text inputs. However, we have observed that the anthropomorphic objects produced by current generative models are often undetectable by pre-trained face landmark detectors, leading to failure of the face motion generation, even if these faces possess human-like appearances because those images are nearly seen during the training (e.g., OOD samples). To address this issue, we incorporate pixel-level guidance to infuse human face landmarks during the image generation phase. To benchmark these metrics, we have built an evaluation dataset. Based on it, we verify that the detection rate of the face landmark is significantly increased from 57.0% to 92.5% thus allowing automatic face animation based on generated speech content. The code and more results can be found at https://chatanything.github.io/.", "url": "https://arxiv.org/abs/2311.06772"}, {"metadata": {"arXiv": "2311.06797", "Date": "Sun, 12 Nov 2023 10:19:14 ", "Title": "Dual-Branch Reconstruction Network for Industrial Anomaly Detection with RGB-D Data", "Authors": ["Chenyang Bi", "Yueyang Li and Haichi Luo"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "5 figures"]}, "abstract": "Unsupervised anomaly detection methods are at the forefront of industrial anomaly detection efforts and have made notable progress. Previous work primarily used 2D information as input, but multi-modal industrial anomaly detection based on 3D point clouds and RGB images is just beginning to emerge. The regular approach involves utilizing large pre-trained models for feature representation and storing them in memory banks. However, the above methods require a longer inference time and higher memory usage, which cannot meet the real-time requirements of the industry. To overcome these issues, we propose a lightweight dual-branch reconstruction network(DBRN) based on RGB-D input, learning the decision boundary between normal and abnormal examples. The requirement for alignment between the two modalities is eliminated by using depth maps instead of point cloud input. Furthermore, we introduce an importance scoring module in the discriminative network to assist in fusing features from these two modalities, thereby obtaining a comprehensive discriminative result. DBRN achieves 92.8% AUROC with high inference efficiency on the MVTec 3D-AD dataset without large pre-trained models and memory banks.", "url": "https://arxiv.org/abs/2311.06797"}, {"metadata": {"arXiv": "2311.07163", "Date": "Mon, 13 Nov 2023 08:58:34 ", "Title": "Enhancing Lightweight Neural Networks for Small Object Detection in IoT Applications", "Authors": ["Liam Boyle", "Nicolas Baumann", "Seonyeong Heo", "Michele Magno"], "Categories": "cs.CV cs.AI"}, "abstract": "Advances in lightweight neural networks have revolutionized computer vision in a broad range of IoT applications, encompassing remote monitoring and process automation. However, the detection of small objects, which is crucial for many of these applications, remains an underexplored area in current computer vision research, particularly for embedded devices. To address this gap, the paper proposes a novel adaptive tiling method that can be used on top of any existing object detector including the popular FOMO network for object detection on microcontrollers. Our experimental results show that the proposed tiling method can boost the F1-score by up to 225% while reducing the average object count error by up to 76%. Furthermore, the findings of this work suggest that using a soft F1 loss over the popular binary cross-entropy loss can significantly reduce the negative impact of imbalanced data. Finally, we validate our approach by conducting experiments on the Sony Spresense microcontroller, showcasing the proposed method's ability to strike a balance between detection performance, low latency, and minimal memory consumption.", "url": "https://arxiv.org/abs/2311.07163"}, {"metadata": {"arXiv": "2311.07184", "Date": "Mon, 13 Nov 2023 09:19:14 ", "Title": "Cross-Axis Transformer with 2D Rotary Embeddings", "Authors": ["Lily Erickson"], "Categories": "cs.CV cs.AI", "Comments": ["7 pages", "8 figures"]}, "abstract": "Despite lagging behind their modal cousins in many respects, Vision Transformers have provided an interesting opportunity to bridge the gap between sequence modeling and image modeling. Up until now however, vision transformers have largely been held back, due to both computational inefficiency, and lack of proper handling of spatial dimensions. In this paper, we introduce the Cross-Axis Transformer. CAT is a model inspired by both Axial Transformers, and Microsoft's recent Retentive Network, that drastically reduces the required number of floating point operations required to process an image, while simultaneously converging faster and more accurately than the Vision Transformers it replaces.", "url": "https://arxiv.org/abs/2311.07184"}, {"metadata": {"arXiv": "2311.07547", "Date": "Mon, 13 Nov 2023 18:36:50 ", "Title": "GPT-4V(ision) as A Social Media Analysis Engine", "Authors": ["Hanjia Lyu", "Jinfa Huang", "Daoan Zhang", "Yongsheng Yu", "Xinyi Mou", "Jinsheng Pan", "Zhengyuan Yang", "Zhongyu Wei", "Jiebo Luo"], "Categories": "cs.CV cs.AI cs.CL cs.MM"}, "abstract": "Recent research has offered insights into the extraordinary capabilities of Large Multimodal Models (LMMs) in various general vision and language tasks. There is growing interest in how LMMs perform in more specialized domains. Social media content, inherently multimodal, blends text, images, videos, and sometimes audio. Understanding social multimedia content remains a challenging problem for contemporary machine learning frameworks. In this paper, we explore GPT-4V(ision)'s capabilities for social multimedia analysis. We select five representative tasks, including sentiment analysis, hate speech detection, fake news identification, demographic inference, and political ideology detection, to evaluate GPT-4V. Our investigation begins with a preliminary quantitative analysis for each task using existing benchmark datasets, followed by a careful review of the results and a selection of qualitative samples that illustrate GPT-4V's potential in understanding multimodal social media content. GPT-4V demonstrates remarkable efficacy in these tasks, showcasing strengths such as joint understanding of image-text pairs, contextual and cultural awareness, and extensive commonsense knowledge. Despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges. GPT-4V struggles with tasks involving multilingual social multimedia comprehension and has difficulties in generalizing to the latest trends in social media. Additionally, it exhibits a tendency to generate erroneous information in the context of evolving celebrity and politician knowledge, reflecting the known hallucination problem. The insights gleaned from our findings underscore a promising future for LMMs in enhancing our comprehension of social media content and its users through the analysis of multimodal information.", "url": "https://arxiv.org/abs/2311.07547"}, {"metadata": {"arXiv": "2311.07562", "Date": "Mon, 13 Nov 2023 18:53:37 ", "Title": "GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation", "Authors": ["An Yan", "Zhengyuan Yang", "Wanrong Zhu", "Kevin Lin", "Linjie Li", "Jianfeng Wang", "Jianwei Yang", "Yiwu Zhong", "Julian McAuley", "Jianfeng Gao", "Zicheng Liu", "Lijuan Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Work in progress"]}, "abstract": "We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical user interface (GUI) navigation task. MM-Navigator can interact with a smartphone screen as human users, and determine subsequent actions to fulfill given instructions. Our findings demonstrate that large multimodal models (LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its advanced screen interpretation, action reasoning, and precise action localization capabilities. We first benchmark MM-Navigator on our collected iOS screen dataset. According to human assessments, the system exhibited a 91\\% accuracy rate in generating reasonable action descriptions and a 75\\% accuracy rate in executing the correct actions for single-step instructions on iOS. Additionally, we evaluate the model on a subset of an Android screen navigation dataset, where the model outperforms previous GUI navigators in a zero-shot fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for future research into the GUI navigation task. The project page is at https://github.com/zzxslp/MM-Navigator.", "url": "https://arxiv.org/abs/2311.07562"}, {"metadata": {"arXiv": "2311.06417", "Date": "Fri, 10 Nov 2023 22:40:41 ", "Title": "Resolving uncertainty on the fly: Modeling adaptive driving behavior as active inference", "Authors": ["Johan Engstr\\\"om", "Ran Wei", "Anthony McDonald", "Alfredo Garcia", "Matt O'Kelly and Leif Johnson"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["33 pages", "13 figures"]}, "abstract": "Understanding adaptive human driving behavior, in particular how drivers manage uncertainty, is of key importance for developing simulated human driver models that can be used in the evaluation and development of autonomous vehicles. However, existing traffic psychology models of adaptive driving behavior either lack computational rigor or only address specific scenarios and/or behavioral phenomena. While models developed in the fields of machine learning and robotics can effectively learn adaptive driving behavior from data, due to their black box nature, they offer little or no explanation of the mechanisms underlying the adaptive behavior. Thus, a generalizable, interpretable, computational model of adaptive human driving behavior is still lacking. This paper proposes such a model based on active inference, a behavioral modeling framework originating in computational neuroscience. The model offers a principled solution to how humans trade progress against caution through policy selection based on the single mandate to minimize expected free energy. This casts goal-seeking and information-seeking (uncertainty-resolving) behavior under a single objective function, allowing the model to seamlessly resolve uncertainty as a means to obtain its goals. We apply the model in two apparently disparate driving scenarios that require managing uncertainty, (1) driving past an occluding object and (2) visual time sharing between driving and a secondary task, and show how human-like adaptive driving behavior emerges from the single principle of expected free energy minimization.", "url": "https://arxiv.org/abs/2311.06417"}, {"metadata": {"arXiv": "2311.07132", "Date": "Mon, 13 Nov 2023 08:00:08 ", "Title": "Understanding Path Planning Explanations", "Authors": ["Amar Halilovic and Senka Krivic"], "Categories": "cs.RO cs.AI cs.HC"}, "abstract": "Navigation is a must-have skill for any mobile robot. A core challenge in navigation is the need to account for an ample number of possible configurations of environment and navigation contexts. We claim that a mobile robot should be able to explain its navigational choices making its decisions understandable to humans. In this paper, we briefly present our approach to explaining navigational decisions of a robot through visual and textual explanations. We propose a user study to test the understandability and simplicity of the robot explanations and outline our further research agenda.", "url": "https://arxiv.org/abs/2311.07132"}, {"metadata": {"arXiv": "2311.07150", "Date": "Mon, 13 Nov 2023 08:39:06 ", "Title": "Interaction is all You Need? A Study of Robots Ability to Understand and Execute", "Authors": ["Kushal Koshti and Nidhir Bhavsar"], "Categories": "cs.RO cs.AI cs.CL cs.CV"}, "abstract": "This paper aims to address a critical challenge in robotics, which is enabling them to operate seamlessly in human environments through natural language interactions. Our primary focus is to equip robots with the ability to understand and execute complex instructions in coherent dialogs to facilitate intricate task-solving scenarios. To explore this, we build upon the Execution from Dialog History (EDH) task from the Teach benchmark. We employ a multi-transformer model with BART LM. We observe that our best configuration outperforms the baseline with a success rate score of 8.85 and a goal-conditioned success rate score of 14.02. In addition, we suggest an alternative methodology for completing this task. Moreover, we introduce a new task by expanding the EDH task and making predictions about game plans instead of individual actions. We have evaluated multiple BART models and an LLaMA2 LLM, which has achieved a ROGUE-L score of 46.77 for this task.", "url": "https://arxiv.org/abs/2311.07150"}, {"metadata": {"arXiv": "2311.07226", "Date": "Mon, 13 Nov 2023 10:46:35 ", "Title": "Large Language Models for Robotics: A Survey", "Authors": ["Fanlong Zeng", "Wensheng Gan", "Yongheng Wang", "Ning Liu", "Philip S. Yu"], "Categories": "cs.RO cs.AI", "Comments": ["Preprint. 4 figures", "3 tables"]}, "abstract": "The human ability to learn, generalize, and control complex manipulation tasks through multi-modality feedback suggests a unique capability, which we refer to as dexterity intelligence. Understanding and assessing this intelligence is a complex task. Amidst the swift progress and extensive proliferation of large language models (LLMs), their applications in the field of robotics have garnered increasing attention. LLMs possess the ability to process and generate natural language, facilitating efficient interaction and collaboration with robots. Researchers and engineers in the field of robotics have recognized the immense potential of LLMs in enhancing robot intelligence, human-robot interaction, and autonomy. Therefore, this comprehensive review aims to summarize the applications of LLMs in robotics, delving into their impact and contributions to key areas such as robot control, perception, decision-making, and path planning. We first provide an overview of the background and development of LLMs for robotics, followed by a description of the benefits of LLMs for robotics and recent advancements in robotics models based on LLMs. We then delve into the various techniques used in the model, including those employed in perception, decision-making, control, and interaction. Finally, we explore the applications of LLMs in robotics and some potential challenges they may face in the near future. Embodied intelligence is the future of intelligent science, and LLMs-based robotics is one of the promising but challenging paths to achieve this.", "url": "https://arxiv.org/abs/2311.07226"}, {"metadata": {"arXiv": "2311.07245", "Date": "Mon, 13 Nov 2023 11:29:06 ", "Title": "Towards Transferring Tactile-based Continuous Force Control Policies from Simulation to Robot", "Authors": ["Luca Lach", "Robert Haschke", "Davide Tateo", "Jan Peters", "Helge Ritter", "J\\'ulia Borr\\`as", "Carme Torras"], "Categories": "cs.RO cs.AI"}, "abstract": "The advent of tactile sensors in robotics has sparked many ideas on how robots can leverage direct contact measurements of their environment interactions to improve manipulation tasks. An important line of research in this regard is that of grasp force control, which aims to manipulate objects safely by limiting the amount of force exerted on the object. While prior works have either hand-modeled their force controllers, employed model-based approaches, or have not shown sim-to-real transfer, we propose a model-free deep reinforcement learning approach trained in simulation and then transferred to the robot without further fine-tuning. We therefore present a simulation environment that produces realistic normal forces, which we use to train continuous force control policies. An evaluation in which we compare against a baseline and perform an ablation study shows that our approach outperforms the hand-modeled baseline and that our proposed inductive bias and domain randomization facilitate sim-to-real transfer. Code, models, and supplementary videos are available on https://sites.google.com/view/rl-force-ctrl", "url": "https://arxiv.org/abs/2311.07245"}, {"metadata": {"arXiv": "2311.07260", "Date": "Mon, 13 Nov 2023 11:50:30 ", "Title": "TIAGo RL: Simulated Reinforcement Learning Environments with Tactile Data for Mobile Robots", "Authors": ["Luca Lach", "Francesco Ferro", "Robert Haschke"], "Categories": "cs.RO cs.AI"}, "abstract": "Tactile information is important for robust performance in robotic tasks that involve physical interaction, such as object manipulation. However, with more data included in the reasoning and control process, modeling behavior becomes increasingly difficult. Deep Reinforcement Learning (DRL) produced promising results for learning complex behavior in various domains, including tactile-based manipulation in robotics. In this work, we present our open-source reinforcement learning environments for the TIAGo service robot. They produce tactile sensor measurements that resemble those of a real sensorised gripper for TIAGo, encouraging research in transfer learning of DRL policies. Lastly, we show preliminary training results of a learned force control policy and compare it to a classical PI controller.", "url": "https://arxiv.org/abs/2311.07260"}, {"metadata": {"arXiv": "2311.07395", "Date": "Mon, 13 Nov 2023 15:23:26 ", "Title": "Predicting Continuous Locomotion Modes via Multidimensional Feature Learning from sEMG", "Authors": ["Peiwen Fu", "Wenjuan Zhong", "Yuyang Zhang", "Wenxuan Xiong", "Yuzhou Lin", "Yanlong Tai", "Lin Meng and Mingming Zhang"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages,7 figures"]}, "abstract": "Walking-assistive devices require adaptive control methods to ensure smooth transitions between various modes of locomotion. For this purpose, detecting human locomotion modes (e.g., level walking or stair ascent) in advance is crucial for improving the intelligence and transparency of such robotic systems. This study proposes Deep-STF, a unified end-to-end deep learning model designed for integrated feature extraction in spatial, temporal, and frequency dimensions from surface electromyography (sEMG) signals. Our model enables accurate and robust continuous prediction of nine locomotion modes and 15 transitions at varying prediction time intervals, ranging from 100 to 500 ms. In addition, we introduced the concept of 'stable prediction time' as a distinct metric to quantify prediction efficiency. This term refers to the duration during which consistent and accurate predictions of mode transitions are made, measured from the time of the fifth correct prediction to the occurrence of the critical event leading to the task transition. This distinction between stable prediction time and prediction time is vital as it underscores our focus on the precision and reliability of mode transition predictions. Experimental results showcased Deep-STP's cutting-edge prediction performance across diverse locomotion modes and transitions, relying solely on sEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other machine learning techniques, achieving an outstanding average prediction accuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy only marginally decreased to 93.00%. The averaged stable prediction times for detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the 100-500 ms time advances.", "url": "https://arxiv.org/abs/2311.07395"}, {"metadata": {"arXiv": "2311.06438", "Date": "Sat, 11 Nov 2023 00:04:26 ", "Title": "Controllability-Constrained Deep Network Models for Enhanced Control of Dynamical Systems", "Authors": ["Suruchi Sharma", "Volodymyr Makarenko", "Gautam Kumar", "Stas Tiomkin"], "Categories": "eess.SY cs.AI cs.SY"}, "abstract": "Control of a dynamical system without the knowledge of dynamics is an important and challenging task. Modern machine learning approaches, such as deep neural networks (DNNs), allow for the estimation of a dynamics model from control inputs and corresponding state observation outputs. Such data-driven models are often utilized for the derivation of model-based controllers. However, in general, there are no guarantees that a model represented by DNNs will be controllable according to the formal control-theoretical meaning of controllability, which is crucial for the design of effective controllers. This often precludes the use of DNN-estimated models in applications, where formal controllability guarantees are required. In this proof-of-the-concept work, we propose a control-theoretical method that explicitly enhances models estimated from data with controllability. That is achieved by augmenting the model estimation objective with a controllability constraint, which penalizes models with a low degree of controllability. As a result, the models estimated with the proposed controllability constraint allow for the derivation of more efficient controllers, they are interpretable by the control-theoretical quantities and have a lower long-term prediction error. The proposed method provides new insights on the connection between the DNN-based estimation of unknown dynamics and the control-theoretical guarantees of the solution properties. We demonstrate the superiority of the proposed method in two standard classical control systems with state observation given by low resolution high-dimensional images.", "url": "https://arxiv.org/abs/2311.06438"}, {"metadata": {"arXiv": "2311.06916", "Date": "Sun, 12 Nov 2023 18:16:48 ", "Title": "TSViT: A Time Series Vision Transformer for Fault Diagnosis", "Authors": ["Shouhua Zhang", "Jiehan Zhou", "Xue Ma", "Chenglin Wen", "Susanna Pirttikangas", "Chen Yu", "Weishan Zhang", "Chunsheng Yang"], "Categories": "eess.SY cs.AI cs.SY"}, "abstract": "Traditional fault diagnosis methods using Convolutional Neural Networks (CNNs) face limitations in capturing temporal features (i.e., the variation of vibration signals over time). To address this issue, this paper introduces a novel model, the Time Series Vision Transformer (TSViT), specifically designed for fault diagnosis. On one hand, TSViT model integrates a convolutional layer to segment vibration signals and capture local features. On the other hand, it employs a transformer encoder to learn long-term temporal information. The experimental results with other methods on two distinct datasets validate the effectiveness and generalizability of TSViT with a comparative analysis of its hyperparameters' impact on model performance, computational complexity, and overall parameter quantity. TSViT reaches average accuracies of 100% and 99.99% on two test sets, correspondingly.", "url": "https://arxiv.org/abs/2311.06916"}, {"metadata": {"arXiv": "2311.06275", "Date": "Tue, 17 Oct 2023 17:51:12 ", "Title": "Algorithmic Robustness", "Authors": ["David Jensen", "Brian LaMacchia", "Ufuk Topcu", "Pamela Wisniewski"], "Categories": "cs.AI cs.LG"}, "abstract": "Algorithmic robustness refers to the sustained performance of a computational system in the face of change in the nature of the environment in which that system operates or in the task that the system is meant to perform. Below, we motivate the importance of algorithmic robustness, present a conceptual framework, and highlight the relevant areas of research for which algorithmic robustness is relevant. Why robustness? Robustness is an important enabler of other goals that are frequently cited in the context of public policy decisions about computational systems, including trustworthiness, accountability, fairness, and safety. Despite this dependence, it tends to be under-recognized compared to these other concepts. This is unfortunate, because robustness is often more immediately achievable than these other ultimate goals, which can be more subjective and exacting. Thus, we highlight robustness as an important goal for researchers, engineers, regulators, and policymakers when considering the design, implementation, and deployment of computational systems. We urge researchers and practitioners to elevate the attention paid to robustness when designing and evaluating computational systems. For many key systems, the immediate question after any demonstration of high performance should be: \"How robust is that performance to realistic changes in the task or environment?\" Greater robustness will set the stage for systems that are more trustworthy, accountable, fair, and safe. Toward that end, this document provides a brief roadmap to some of the concepts and existing research around the idea of algorithmic robustness.", "url": "https://arxiv.org/abs/2311.06275"}, {"metadata": {"arXiv": "2311.06517", "Date": "Sat, 11 Nov 2023 09:22:07 ", "Title": "BClean: A Bayesian Data Cleaning System", "Authors": ["Jianbin Qin", "Sifan Huang", "Yaoshu Wang", "Jing Zhu", "Yifan Zhang", "Yukai Miao", "Rui Mao", "Makoto Onizuka", "Chuan Xiao"], "Categories": "cs.AI cs.DB cs.LG stat.AP", "Comments": ["Our source code is available at https://github.com/yyssl88/BClean"]}, "abstract": "There is a considerable body of work on data cleaning which employs various principles to rectify erroneous data and transform a dirty dataset into a cleaner one. One of prevalent approaches is probabilistic methods, including Bayesian methods. However, existing probabilistic methods often assume a simplistic distribution (e.g., Gaussian distribution), which is frequently underfitted in practice, or they necessitate experts to provide a complex prior distribution (e.g., via a programming language). This requirement is both labor-intensive and costly, rendering these methods less suitable for real-world applications. In this paper, we propose BClean, a Bayesian Cleaning system that features automatic Bayesian network construction and user interaction. We recast the data cleaning problem as a Bayesian inference that fully exploits the relationships between attributes in the observed dataset and any prior information provided by users. To this end, we present an automatic Bayesian network construction method that extends a structure learning-based functional dependency discovery method with similarity functions to capture the relationships between attributes. Furthermore, our system allows users to modify the generated Bayesian network in order to specify prior information or correct inaccuracies identified by the automatic generation process. We also design an effective scoring model (called the compensative scoring model) necessary for the Bayesian inference. To enhance the efficiency of data cleaning, we propose several approximation strategies for the Bayesian inference, including graph partitioning, domain pruning, and pre-detection. By evaluating on both real-world and synthetic datasets, we demonstrate that BClean is capable of achieving an F-measure of up to 0.9 in data cleaning, outperforming existing Bayesian methods by 2% and other data cleaning methods by 15%.", "url": "https://arxiv.org/abs/2311.06517"}, {"metadata": {"arXiv": "2311.07178", "Date": "Mon, 13 Nov 2023 09:09:52 ", "Title": "Game Solving with Online Fine-Tuning", "Authors": ["Ti-Rong Wu", "Hung Guei", "Ting Han Wei", "Chung-Chin Shih", "Jui-Te Chin", "I-Chen Wu"], "Categories": "cs.AI cs.GT cs.LG", "Comments": ["Accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Game solving is a similar, yet more difficult task than mastering a game. Solving a game typically means to find the game-theoretic value (outcome given optimal play), and optionally a full strategy to follow in order to achieve that outcome. The AlphaZero algorithm has demonstrated super-human level play, and its powerful policy and value predictions have also served as heuristics in game solving. However, to solve a game and obtain a full strategy, a winning response must be found for all possible moves by the losing player. This includes very poor lines of play from the losing side, for which the AlphaZero self-play process will not encounter. AlphaZero-based heuristics can be highly inaccurate when evaluating these out-of-distribution positions, which occur throughout the entire search. To address this issue, this paper investigates applying online fine-tuning while searching and proposes two methods to learn tailor-designed heuristics for game solving. Our experiments show that using online fine-tuning can solve a series of challenging 7x7 Killall-Go problems, using only 23.54% of computation time compared to the baseline without online fine-tuning. Results suggest that the savings scale with problem size. Our method can further be extended to any tree search algorithm for problem solving. Our code is available at https://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver.", "url": "https://arxiv.org/abs/2311.07178"}, {"metadata": {"arXiv": "2311.07191", "Date": "Mon, 13 Nov 2023 09:31:14 ", "Title": "Applying Large Language Models for Causal Structure Learning in Non Small Cell Lung Cancer", "Authors": ["Narmada Naik", "Ayush Khandelwal", "Mohit Joshi", "Madhusudan Atre", "Hollis Wright", "Kavya Kannan", "Scott Hill", "Giridhar Mamidipudi", "Ganapati Srinivasa", "Carlo Bifulco", "Brian Piening", "Kevin Matlock"], "Categories": "cs.AI cs.LG stat.AP"}, "abstract": "Causal discovery is becoming a key part in medical AI research. These methods can enhance healthcare by identifying causal links between biomarkers, demographics, treatments and outcomes. They can aid medical professionals in choosing more impactful treatments and strategies. In parallel, Large Language Models (LLMs) have shown great potential in identifying patterns and generating insights from text data. In this paper we investigate applying LLMs to the problem of determining the directionality of edges in causal discovery. Specifically, we test our approach on a deidentified set of Non Small Cell Lung Cancer(NSCLC) patients that have both electronic health record and genomic panel data. Graphs are validated using Bayesian Dirichlet estimators using tabular data. Our result shows that LLMs can accurately predict the directionality of edges in causal graphs, outperforming existing state-of-the-art methods. These findings suggests that LLMs can play a significant role in advancing causal discovery and help us better understand complex systems.", "url": "https://arxiv.org/abs/2311.07191"}, {"metadata": {"arXiv": "2311.07312", "Date": "Mon, 13 Nov 2023 13:07:48 ", "Title": "C-Procgen: Empowering Procgen with Controllable Contexts", "Authors": ["Zhenxiong Tan", "Kaixin Wang and Xinchao Wang"], "Categories": "cs.AI cs.LG"}, "abstract": "We present C-Procgen, an enhanced suite of environments on top of the Procgen benchmark. C-Procgen provides access to over 200 unique game contexts across 16 games. It allows for detailed configuration of environments, ranging from game mechanics to agent attributes. This makes the procedural generation process, previously a black-box in Procgen, more transparent and adaptable for various research needs.The upgrade enhances dynamic context management and individualized assignments, while maintaining computational efficiency. C-Procgen's controllable contexts make it applicable in diverse reinforcement learning research areas, such as learning dynamics analysis, curriculum learning, and transfer learning. We believe that C-Procgen will fill a gap in the current literature and offer a valuable toolkit for future works.", "url": "https://arxiv.org/abs/2311.07312"}, {"metadata": {"arXiv": "2311.06329", "Date": "Fri, 10 Nov 2023 17:33:58 ", "Title": "A Survey of AI Text-to-Image and AI Text-to-Video Generators", "Authors": ["Aditi Singh"], "Categories": "cs.CV cs.AI cs.CL cs.LG eess.IV", "Comments": ["4 pages", "2 tables", "4th International Conference on Artificial Intelligence", "Robotics and Control (AIRC 2023)"], "DOI": "10.1109/AIRC57904.2023.10303174"}, "abstract": "Text-to-Image and Text-to-Video AI generation models are revolutionary technologies that use deep learning and natural language processing (NLP) techniques to create images and videos from textual descriptions. This paper investigates cutting-edge approaches in the discipline of Text-to-Image and Text-to-Video AI generations. The survey provides an overview of the existing literature as well as an analysis of the approaches used in various studies. It covers data preprocessing techniques, neural network types, and evaluation metrics used in the field. In addition, the paper discusses the challenges and limitations of Text-to-Image and Text-to-Video AI generations, as well as future research directions. Overall, these models have promising potential for a wide range of applications such as video production, content creation, and digital marketing.", "url": "https://arxiv.org/abs/2311.06329"}, {"metadata": {"arXiv": "2311.06749", "Date": "Sun, 12 Nov 2023 06:23:33 ", "Title": "Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective Factor-Tuning Method for Vision Transformer", "Authors": ["Dongping Chen"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recent advancements have illuminated the efficacy of some tensorization-decomposition Parameter-Efficient Fine-Tuning methods like LoRA and FacT in the context of Vision Transformers (ViT). However, these methods grapple with the challenges of inadequately addressing inner- and cross-layer redundancy. To tackle this issue, we introduce EFfective Factor-Tuning (EFFT), a simple yet effective fine-tuning method. Within the VTAB-1K dataset, our EFFT surpasses all baselines, attaining state-of-the-art performance with a categorical average of 75.9% in top-1 accuracy with only 0.28% of the parameters for full fine-tuning. Considering the simplicity and efficacy of EFFT, it holds the potential to serve as a foundational benchmark. The code and model are now available at https://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning.", "url": "https://arxiv.org/abs/2311.06749"}, {"metadata": {"arXiv": "2311.07575", "Date": "Mon, 13 Nov 2023 18:59:47 ", "Title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models", "Authors": ["Ziyi Lin", "Chris Liu", "Renrui Zhang", "Peng Gao", "Longtian Qiu", "Han Xiao", "Han Qiu", "Chen Lin", "Wenqi Shao", "Keqin Chen", "Jiaming Han", "Siyuan Huang", "Yichi Zhang", "Xuming He", "Hongsheng Li", "Yu Qiao"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Work in progress. Code and demos are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory"]}, "abstract": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data. By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness. Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict. In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios. Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations. Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications. On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images. With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks. We hope our work may cast a light on the exploration of joint mixing in future MLLM research. Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.", "url": "https://arxiv.org/abs/2311.07575"}, {"metadata": {"arXiv": "2311.06311", "Date": "Thu, 09 Nov 2023 19:10:35 ", "Title": "Game Theory Solutions in Sensor-Based Human Activity Recognition: A Review", "Authors": ["Mohammad Hossein Shayesteh", "Behrooz Sharokhzadeh", "and Behrooz Masoumi"], "Categories": "cs.GT cs.AI cs.LG", "Journal-ref": "Journal of Artificial Intelligence and Data Mining (JAIDM), Vol. 11, No. 2, 2023, 259-289", "DOI": "10.22044/jadm.2023.12538.2407"}, "abstract": "The Human Activity Recognition (HAR) tasks automatically identify human activities using the sensor data, which has numerous applications in healthcare, sports, security, and human-computer interaction. Despite significant advances in HAR, critical challenges still exist. Game theory has emerged as a promising solution to address these challenges in machine learning problems including HAR. However, there is a lack of research work on applying game theory solutions to the HAR problems. This review paper explores the potential of game theory as a solution for HAR tasks, and bridges the gap between game theory and HAR research work by suggesting novel game-theoretic approaches for HAR problems. The contributions of this work include exploring how game theory can improve the accuracy and robustness of HAR models, investigating how game-theoretic concepts can optimize recognition algorithms, and discussing the game-theoretic approaches against the existing HAR methods. The objective is to provide insights into the potential of game theory as a solution for sensor-based HAR, and contribute to develop a more accurate and efficient recognition system in the future research directions.", "url": "https://arxiv.org/abs/2311.06311"}, {"metadata": {"arXiv": "2311.06304", "Date": "Wed, 08 Nov 2023 04:54:09 ", "Title": "Retro-BLEU: Quantifying Chemical Plausibility of Retrosynthesis Routes through Reaction Template Sequence Analysis", "Authors": ["Junren Li", "Lei Fang and Jian-Guang Lou"], "Categories": "cs.LG cs.AI q-bio.BM"}, "abstract": "Computer-assisted methods have emerged as valuable tools for retrosynthesis analysis. However, quantifying the plausibility of generated retrosynthesis routes remains a challenging task. We introduce Retro-BLEU, a statistical metric adapted from the well-established BLEU score in machine translation, to evaluate the plausibility of retrosynthesis routes based on reaction template sequences analysis. We demonstrate the effectiveness of Retro-BLEU by applying it to a diverse set of retrosynthesis routes generated by state-of-the-art algorithms and compare the performance with other evaluation metrics. The results show that Retro-BLEU is capable of differentiating between plausible and implausible routes. Furthermore, we provide insights into the strengths and weaknesses of Retro-BLEU, paving the way for future developments and improvements in this field.", "url": "https://arxiv.org/abs/2311.06304"}, {"metadata": {"arXiv": "2311.06315", "Date": "Thu, 09 Nov 2023 22:26:03 ", "Title": "ShipGen: A Diffusion Model for Parametric Ship Hull Generation with Multiple Objectives and Constraints", "Authors": ["Noah J. Bagazinski and Faez Ahmed"], "Categories": "cs.LG cs.AI"}, "abstract": "Ship design is a years-long process that requires balancing complex design trade-offs to create a ship that is efficient and effective. Finding new ways to improve the ship design process can lead to significant cost savings for ship building and operation. One promising technology is generative artificial intelligence, which has been shown to reduce design cycle time and create novel, high-performing designs. In literature review, generative artificial intelligence has been shown to generate ship hulls; however, ship design is particularly difficult as the hull of a ship requires the consideration of many objectives. This paper presents a study on the generation of parametric ship hull designs using a parametric diffusion model that considers multiple objectives and constraints for the hulls. This denoising diffusion probabilistic model (DDPM) generates the tabular parametric design vectors of a ship hull for evaluation. In addition to a tabular DDPM, this paper details adding guidance to improve the quality of generated ship hull designs. By leveraging classifier guidance, the DDPM produced feasible parametric ship hulls that maintain the coverage of the initial training dataset of ship hulls with a 99.5% rate, a 149x improvement over random sampling of the design vector parameters across the design space. Parametric ship hulls produced with performance guidance saw an average of 91.4% reduction in wave drag coefficients and an average of a 47.9x relative increase in the total displaced volume of the hulls compared to the mean performance of the hulls in the training dataset. The use of a DDPM to generate parametric ship hulls can reduce design time by generating high-performing hull designs for future analysis. These generated hulls have low drag and high volume, which can reduce the cost of operating a ship and increase its potential to generate revenue.", "url": "https://arxiv.org/abs/2311.06315"}, {"metadata": {"arXiv": "2311.06567", "Date": "Sat, 11 Nov 2023 13:33:43 ", "Title": "SCADI: Self-supervised Causal Disentanglement in Latent Variable Models", "Authors": ["Heejeong Nam"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["12 pages", "12 figures"]}, "abstract": "Causal disentanglement has great potential for capturing complex situations. However, there is a lack of practical and efficient approaches. It is already known that most unsupervised disentangling methods are unable to produce identifiable results without additional information, often leading to randomly disentangled output. Therefore, most existing models for disentangling are weakly supervised, providing information about intrinsic factors, which incurs excessive costs. Therefore, we propose a novel model, SCADI(SElf-supervised CAusal DIsentanglement), that enables the model to discover semantic factors and learn their causal relationships without any supervision. This model combines a masked structural causal model (SCM) with a pseudo-label generator for causal disentanglement, aiming to provide a new direction for self-supervised causal disentanglement models.", "url": "https://arxiv.org/abs/2311.06567"}, {"metadata": {"arXiv": "2311.06597", "Date": "Sat, 11 Nov 2023 15:45:44 ", "Title": "Understanding Grokking Through A Robustness Viewpoint", "Authors": ["Zhiquan Tan", "Weiran Huang"], "Categories": "cs.LG cs.AI"}, "abstract": "Recently, an unusual phenomenon called grokking has gained much attention, where sometimes a neural network generalizes long after it perfectly fits the training data. We try to understand this seemingly strange phenomenon using the robustness of the neural network. Using a robustness viewpoint, we show that the popular $l_2$ weight norm (metric) of the neural network is actually a sufficient condition for grokking. As we also empirically find that $l_2$ norm correlates with grokking on the test data not in a timely way, we propose new metrics based on robustness and information theory and find that our new metrics correlate well with the grokking phenomenon. Based on the previous observations, we propose methods to speed up the generalization process. In addition, we examine the standard training process on modulo addition dataset and find that it hardly learns other basic group operations before grokking, including the commutative law. Interestingly, the speed up of generalization when using our proposed method can be partially explained by learning the commutative law, a necessary condition when the model groks on test dataset.", "url": "https://arxiv.org/abs/2311.06597"}, {"metadata": {"arXiv": "2311.06633", "Date": "Sat, 11 Nov 2023 18:31:32 ", "Title": "The Pros and Cons of Using Machine Learning and Interpretable Machine Learning Methods in psychiatry detection applications, specifically depression disorder: A Brief Review", "Authors": ["Hossein Simchi", "Samira Tajik"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages"], "MSC-class": "68T01"}, "abstract": "The COVID-19 pandemic has forced many people to limit their social activities, which has resulted in a rise in mental illnesses, particularly depression. To diagnose these illnesses with accuracy and speed, and prevent severe outcomes such as suicide, the use of machine learning has become increasingly important. Additionally, to provide precise and understandable diagnoses for better treatment, AI scientists and researchers must develop interpretable AI-based solutions. This article provides an overview of relevant articles in the field of machine learning and interpretable AI, which helps to understand the advantages and disadvantages of using AI in psychiatry disorder detection applications.", "url": "https://arxiv.org/abs/2311.06633"}, {"metadata": {"arXiv": "2311.06668", "Date": "Sat, 11 Nov 2023 21:19:44 ", "Title": "In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering", "Authors": ["Sheng Liu", "Lei Xing", "James Zou"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large language models (LLMs) demonstrate emergent in-context learning capabilities, where they adapt to new tasks based on example demonstrations. However, in-context learning has seen limited effectiveness in many settings, is difficult to quantitatively control and takes up context window space. To overcome these limitations, we propose an alternative approach that recasts in-context learning as in-context vectors (ICV). Using ICV has two steps. We first use a forward pass on demonstration examples to create the in-context vector from the latent embedding of the LLM. This vector captures essential information about the intended task. On a new query, instead of adding demonstrations to the prompt, we shift the latent states of the LLM using the ICV. The ICV approach has several benefits: 1) it enables the LLM to more effectively follow the demonstration examples; 2) it's easy to control by adjusting the magnitude of the ICV; 3) it reduces the length of the prompt by removing the in-context demonstrations; 4) ICV is computationally much more efficient than fine-tuning. We demonstrate that ICV achieves better performance compared to standard in-context learning and fine-tuning on diverse tasks including safety, style transfer, role-playing and formatting. Moreover, we show that we can flexibly teach LLM to simultaneously follow different types of instructions by simple vector arithmetics on the corresponding ICVs.", "url": "https://arxiv.org/abs/2311.06668"}, {"metadata": {"arXiv": "2311.06673", "Date": "Sat, 11 Nov 2023 22:05:10 ", "Title": "Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination", "Authors": ["Lu Wen", "Songan Zhang", "H. Eric Tseng", "Huei Peng"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Meta reinforcement learning (Meta RL) has been amply explored to quickly learn an unseen task by transferring previously learned knowledge from similar tasks. However, most state-of-the-art algorithms require the meta-training tasks to have a dense coverage on the task distribution and a great amount of data for each of them. In this paper, we propose MetaDreamer, a context-based Meta RL algorithm that requires less real training tasks and data by doing meta-imagination and MDP-imagination. We perform meta-imagination by interpolating on the learned latent context space with disentangled properties, as well as MDP-imagination through the generative world model where physical knowledge is added to plain VAE networks. Our experiments with various benchmarks show that MetaDreamer outperforms existing approaches in data efficiency and interpolated generalization.", "url": "https://arxiv.org/abs/2311.06673"}, {"metadata": {"arXiv": "2311.06731", "Date": "Sun, 12 Nov 2023 04:25:53 ", "Title": "An advantage based policy transfer algorithm for reinforcement learning with metrics of transferability", "Authors": ["Md Ferdous Alam", "Parinaz Naghizadeh", "David Hoelzle"], "Categories": "cs.LG cs.AI"}, "abstract": "Reinforcement learning (RL) can enable sequential decision-making in complex and high-dimensional environments if the acquisition of a new state-action pair is efficient, i.e., when interaction with the environment is inexpensive. However, there are a myriad of real-world applications in which a high number of interactions are infeasible. In these environments, transfer RL algorithms, which can be used for the transfer of knowledge from one or multiple source environments to a target environment, have been shown to increase learning speed and improve initial and asymptotic performance. However, most existing transfer RL algorithms are on-policy and sample inefficient, and often require heuristic choices in algorithm design. This paper proposes an off-policy Advantage-based Policy Transfer algorithm, APT-RL, for fixed domain environments. Its novelty is in using the popular notion of ``advantage'' as a regularizer, to weigh the knowledge that should be transferred from the source, relative to new knowledge learned in the target, removing the need for heuristic choices. Further, we propose a new transfer performance metric to evaluate the performance of our algorithm and unify existing transfer RL frameworks. Finally, we present a scalable, theoretically-backed task similarity measurement algorithm to illustrate the alignments between our proposed transferability metric and similarities between source and target environments. Numerical experiments on three continuous control benchmark tasks demonstrate that APT-RL outperforms existing transfer RL algorithms on most tasks, and is $10\\%$ to $75\\%$ more sample efficient than learning from scratch.", "url": "https://arxiv.org/abs/2311.06731"}, {"metadata": {"arXiv": "2311.06735", "Date": "Sun, 12 Nov 2023 04:58:20 ", "Title": "DeepQC: A Deep Learning System for Automatic Quality Control of In-situ Soil Moisture Sensor Time Series Data", "Authors": ["Lahari Bandaru", "Bharat C Irigireddy", "Brian Davis"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "8 figures"]}, "abstract": "Amidst changing climate, real-time soil moisture monitoring is vital for the development of in-season decision support tools to help farmers manage weather related risks. Precision Sustainable Agriculture (PSA) recently established a real-time soil moisture monitoring network across the central, Midwest, and eastern U.S., but field-scale sensor observations often come with data gaps and anomalies. To maintain the data quality needed for development of decision tools, a quality control system is necessary. The International Soil Moisture Network (ISMN) introduced the Flagit module for anomaly detection in soil moisture observations. However, under certain conditions, Flagit's quality control approaches may underperform in identifying anomalies. Recently deep learning methods have been successfully applied to detect anomalies in time series data in various disciplines. However, their use in agriculture has not been yet investigated. This study focuses on developing a Bi-directional Long Short-Term Memory (LSTM) model, referred to as DeepQC, to identify anomalies in soil moisture data. Manual flagged PSA observations were used for training, validation, and testing the model, following an 80:10:10 split. The study then compared the DeepQC and Flagit based estimates to assess their relative performance. Flagit corrected flagged 95.5% of the corrected observations and 50.3% of the anomaly observations, indicating its limitations in identifying anomalies. On the other hand, the DeepQC correctly flagged 99.7% of the correct observations and 95.6% of the anomalies in significantly less time, demonstrating its superiority over Flagit approach. Importantly, DeepQC's performance remained consistent regardless of the number of anomalies. Given the promising results obtained with the DeepQC, future studies will focus on implementing this model on national and global soil moisture networks.", "url": "https://arxiv.org/abs/2311.06735"}, {"metadata": {"arXiv": "2311.06750", "Date": "Sun, 12 Nov 2023 06:32:30 ", "Title": "Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark", "Authors": ["Wenke Huang", "Mang Ye", "Zekun Shi", "Guancheng Wan", "He Li", "Bo Du", "Qiang Yang"], "Categories": "cs.LG cs.AI", "Comments": ["22 pages", "4 figures"]}, "abstract": "Federated learning has emerged as a promising paradigm for privacy-preserving collaboration among different parties. Recently, with the popularity of federated learning, an influx of approaches have delivered towards different realistic challenges. In this survey, we provide a systematic overview of the important and recent developments of research on federated learning. Firstly, we introduce the study history and terminology definition of this area. Then, we comprehensively review three basic lines of research: generalization, robustness, and fairness, by introducing their respective background concepts, task settings, and main challenges. We also offer a detailed overview of representative literature on both methods and datasets. We further benchmark the reviewed methods on several well-known datasets. Finally, we point out several open issues in this field and suggest opportunities for further research. We also provide a public website to continuously track developments in this fast advancing field: https://github.com/WenkeHuang/MarsFL.", "url": "https://arxiv.org/abs/2311.06750"}, {"metadata": {"arXiv": "2311.06823", "Date": "Sun, 12 Nov 2023 12:24:07 ", "Title": "Training A Multi-stage Deep Classifier with Feedback Signals", "Authors": ["Chao Xu", "Yu Yang", "Rongzhao Wang", "Guan Wang", "Bojia Lin"], "Categories": "cs.LG cs.AI"}, "abstract": "Multi-Stage Classifier (MSC) - several classifiers working sequentially in an arranged order and classification decision is partially made at each step - is widely used in industrial applications for various resource limitation reasons. The classifiers of a multi-stage process are usually Neural Network (NN) models trained independently or in their inference order without considering the signals from the latter stages. Aimed at two-stage binary classification process, the most common type of MSC, we propose a novel training framework, named Feedback Training. The classifiers are trained in an order reverse to their actual working order, and the classifier at the later stage is used to guide the training of initial-stage classifier via a sample weighting method. We experimentally show the efficacy of our proposed approach, and its great superiority under the scenario of few-shot training.", "url": "https://arxiv.org/abs/2311.06823"}, {"metadata": {"arXiv": "2311.06826", "Date": "Sun, 12 Nov 2023 12:48:28 ", "Title": "Fairness Hacking: The Malicious Practice of Shrouding Unfairness in Algorithms", "Authors": ["Kristof Meding", "Thilo Hagendorff"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Fairness in machine learning (ML) is an ever-growing field of research due to the manifold potential for harm from algorithmic discrimination. To prevent such harm, a large body of literature develops new approaches to quantify fairness. Here, we investigate how one can divert the quantification of fairness by describing a practice we call \"fairness hacking\" for the purpose of shrouding unfairness in algorithms. This impacts end-users who rely on learning algorithms, as well as the broader community interested in fair AI practices. We introduce two different categories of fairness hacking in reference to the established concept of p-hacking. The first category, intra-metric fairness hacking, describes the misuse of a particular metric by adding or removing sensitive attributes from the analysis. In this context, countermeasures that have been developed to prevent or reduce p-hacking can be applied to similarly prevent or reduce fairness hacking. The second category of fairness hacking is inter-metric fairness hacking. Inter-metric fairness hacking is the search for a specific fair metric with given attributes. We argue that countermeasures to prevent or reduce inter-metric fairness hacking are still in their infancy. Finally, we demonstrate both types of fairness hacking using real datasets. Our paper intends to serve as a guidance for discussions within the fair ML community to prevent or reduce the misuse of fairness metrics, and thus reduce overall harm from ML applications.", "url": "https://arxiv.org/abs/2311.06826"}, {"metadata": {"arXiv": "2311.06835", "Date": "Sun, 12 Nov 2023 13:25:28 ", "Title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation", "Authors": ["Qizhou Wang", "Guansong Pang", "Mahsa Salehi", "Wray Buntine", "Christopher Leckie"], "Categories": "cs.LG cs.AI cs.SI"}, "abstract": "This paper considers an under-explored Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to detect anomalous nodes using a small number of labelled training normal and anomaly nodes (known as seen anomalies) that cannot illustrate all possible inference-time abnormalities. The task has attracted growing attention due to the availability of anomaly prior knowledge from the label information that can help to substantially reduce detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect unseen anomalies, i.e., those that are not illustrated by the labelled anomaly nodes. Further, they were introduced to handle Euclidean data, failing to effectively capture important non-Euclidean features for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to leverage the rich normal graph structure embedded in the labelled nodes to tackle the aforementioned two issues. In particular, NSReg trains an anomaly-discriminative supervised graph anomaly detector, with a plug-and-play regularisation term to enforce compact, semantically-rich representations of normal nodes. To this end, the regularisation is designed to differentiate various types of normal nodes, including labelled normal nodes that are connected in their local neighbourhood, and those that are not connected. By doing so, it helps incorporate strong normality into the supervised anomaly detector learning, mitigating their overfitting to the seen anomalies. Extensive empirical results on real-world datasets demonstrate the superiority of our proposed NSReg for open-set GAD.", "url": "https://arxiv.org/abs/2311.06835"}, {"metadata": {"arXiv": "2311.06840", "Date": "Sun, 12 Nov 2023 13:31:53 ", "Title": "Distribution Re-weighting and Voting Paradoxes", "Authors": ["Bijan Mazaheri", "Siddharth Jain", "Matthew Cook", "Jehoshua Bruck"], "Categories": "cs.LG cs.AI cs.IT cs.SI math.IT stat.ME"}, "abstract": "We explore a specific type of distribution shift called domain expertise, in which training is limited to a subset of all possible labels. This setting is common among specialized human experts, or specific focused studies. We show how the standard approach to distribution shift, which involves re-weighting data, can result in paradoxical disagreements among differing domain expertise. We also demonstrate how standard adjustments for causal inference lead to the same paradox. We prove that the characteristics of these paradoxes exactly mimic another set of paradoxes which arise among sets of voter preferences.", "url": "https://arxiv.org/abs/2311.06840"}, {"metadata": {"arXiv": "2311.06917", "Date": "Sun, 12 Nov 2023 18:21:00 ", "Title": "FLASH-RL: Federated Learning Addressing System and Static Heterogeneity using Reinforcement Learning", "Authors": ["Sofiane Bouaziz", "Hadjer Benmeziane", "Youcef Imine", "Leila Hamdad", "Smail Niar", "Hamza Ouarnoughi"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["Accepted in the 41st IEEE International Conference on Computer Design (ICCD 2023)"]}, "abstract": "Federated Learning (FL) has emerged as a promising Machine Learning paradigm, enabling multiple users to collaboratively train a shared model while preserving their local data. To minimize computing and communication costs associated with parameter transfer, it is common practice in FL to select a subset of clients in each training round. This selection must consider both system and static heterogeneity. Therefore, we propose FLASH-RL, a framework that utilizes Double Deep QLearning (DDQL) to address both system and static heterogeneity in FL. FLASH-RL introduces a new reputation-based utility function to evaluate client contributions based on their current and past performances. Additionally, an adapted DDQL algorithm is proposed to expedite the learning process. Experimental results on MNIST and CIFAR-10 datasets have shown FLASH-RL's effectiveness in achieving a balanced trade-off between model performance and end-to-end latency against existing solutions. Indeed, FLASH-RL reduces latency by up to 24.83% compared to FedAVG and 24.67% compared to FAVOR. It also reduces the training rounds by up to 60.44% compared to FedAVG and +76% compared to FAVOR. In fall detection using the MobiAct dataset, FLASH-RL outperforms FedAVG by up to 2.82% in model's performance and reduces latency by up to 34.75%. Additionally, FLASH-RL achieves the target performance faster, with up to a 45.32% reduction in training rounds compared to FedAVG.", "url": "https://arxiv.org/abs/2311.06917"}, {"metadata": {"arXiv": "2311.06958", "Date": "Sun, 12 Nov 2023 20:52:14 ", "Title": "Towards probabilistic Weather Forecasting with Conditioned Spatio-Temporal Normalizing Flows", "Authors": ["Christina Winkler"], "Categories": "cs.LG cs.AI"}, "abstract": "Generative normalizing flows are able to model multimodal spatial distributions, and they have been shown to model temporal correlations successfully as well. These models provide several benefits over other types of generative models due to their training stability, invertibility and efficiency in sampling and inference. This makes them a suitable candidate for stochastic spatio-temporal prediction problems, which are omnipresent in many fields of sciences, such as earth sciences, astrophysics or molecular sciences. In this paper, we present conditional normalizing flows for stochastic spatio-temporal modelling. The method is evaluated on the task of daily temperature and hourly geopotential map prediction from ERA5 datasets. Experiments show that our method is able to capture spatio-temporal correlations and extrapolates well beyond the time horizon used during training.", "url": "https://arxiv.org/abs/2311.06958"}, {"metadata": {"arXiv": "2311.06968", "Date": "Sun, 12 Nov 2023 21:25:56 ", "Title": "Physics-Informed Data Denoising for Real-Life Sensing Systems", "Authors": ["Xiyuan Zhang", "Xiaohan Fu", "Diyan Teng", "Chengyu Dong", "Keerthivasan Vijayakumar", "Jiayun Zhang", "Ranak Roy Chowdhury", "Junsheng Han", "Dezhi Hong", "Rashmi Kulkarni", "Jingbo Shang", "Rajesh Gupta"], "Categories": "cs.LG cs.AI eess.SP stat.ML", "Comments": ["SenSys 2023"]}, "abstract": "Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects performance and reliability of the systems they support. Classic filtering-based approaches introduce strong assumptions on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.", "url": "https://arxiv.org/abs/2311.06968"}, {"metadata": {"arXiv": "2311.07025", "Date": "Mon, 13 Nov 2023 02:14:54 ", "Title": "Embarassingly Simple Dataset Distillation", "Authors": ["Feng Yunzhen", "Vedantam Ramakrishna", "Kempe Julia"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Short version appears at NeurIPS 2023 WANT workshop"]}, "abstract": "Dataset distillation extracts a small set of synthetic training samples from a large dataset with the goal of achieving competitive performance on test data when trained on this sample. In this work, we tackle dataset distillation at its core by treating it directly as a bilevel optimization problem. Re-examining the foundational back-propagation through time method, we study the pronounced variance in the gradients, computational burden, and long-term dependencies. We introduce an improved method: Random Truncated Backpropagation Through Time (RaT-BPTT) to address them. RaT-BPTT incorporates a truncation coupled with a random window, effectively stabilizing the gradients and speeding up the optimization while covering long dependencies. This allows us to establish new state-of-the-art for a variety of standard dataset benchmarks. A deeper dive into the nature of distilled data unveils pronounced intercorrelation. In particular, subsets of distilled datasets tend to exhibit much worse performance than directly distilled smaller datasets of the same size. Leveraging RaT-BPTT, we devise a boosting mechanism that generates distilled datasets that contain subsets with near optimal performance across different data budgets.", "url": "https://arxiv.org/abs/2311.07025"}, {"metadata": {"arXiv": "2311.07065", "Date": "Mon, 13 Nov 2023 04:11:25 ", "Title": "Non-approximability of constructive global $\\mathcal{L}^2$ minimizers by gradient descent in Deep Learning", "Authors": ["Thomas Chen", "Patricia Mu\\~noz Ewald"], "Categories": "cs.LG cs.AI math-ph math.MP math.OC stat.ML", "Comments": ["AMS Latex", "7 pages"], "MSC-class": "57R70, 62M45"}, "abstract": "We analyze geometric aspects of the gradient descent algorithm in Deep Learning (DL) networks. In particular, we prove that the globally minimizing weights and biases for the $\\mathcal{L}^2$ cost obtained constructively in [Chen-Munoz Ewald 2023] for underparametrized ReLU DL networks can generically not be approximated via the gradient descent flow. We therefore conclude that the method introduced in [Chen-Munoz Ewald 2023] is disjoint from the gradient descent method.", "url": "https://arxiv.org/abs/2311.07065"}, {"metadata": {"arXiv": "2311.07079", "Date": "Mon, 13 Nov 2023 05:08:26 ", "Title": "Sample Dominance Aware Framework via Non-Parametric Estimation for Spontaneous Brain-Computer Interface", "Authors": ["Byeong-Hoo Lee", "Byoung-Hee Kwon", "and Seong-Whan Lee"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["5 pages", "2 figures"]}, "abstract": "Deep learning has shown promise in decoding brain signals, such as electroencephalogram (EEG), in the field of brain-computer interfaces (BCIs). However, the non-stationary characteristics of EEG signals pose challenges for training neural networks to acquire appropriate knowledge. Inconsistent EEG signals resulting from these non-stationary characteristics can lead to poor performance. Therefore, it is crucial to investigate and address sample inconsistency to ensure robust performance in spontaneous BCIs. In this study, we introduce the concept of sample dominance as a measure of EEG signal inconsistency and propose a method to modulate its effect on network training. We present a two-stage dominance score estimation technique that compensates for performance degradation caused by sample inconsistencies. Our proposed method utilizes non-parametric estimation to infer sample inconsistency and assigns each sample a dominance score. This score is then aggregated with the loss function during training to modulate the impact of sample inconsistency. Furthermore, we design a curriculum learning approach that gradually increases the influence of inconsistent signals during training to improve overall performance. We evaluate our proposed method using public spontaneous BCI dataset. The experimental results confirm that our findings highlight the importance of addressing sample dominance for achieving robust performance in spontaneous BCIs.", "url": "https://arxiv.org/abs/2311.07079"}, {"metadata": {"arXiv": "2311.07139", "Date": "Mon, 13 Nov 2023 08:11:09 ", "Title": "Analyzing and Predicting Low-Listenership Trends in a Large-Scale Mobile Health Program: A Preliminary Investigation", "Authors": ["Arshika Lalan", "Shresth Verma", "Kumar Madhu Sudan", "Amrita Mahale", "Aparna Hegde", "Milind Tambe and Aparna Taneja"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["Accepted to Data Science for Social Good Workshop", "KDD 2023"]}, "abstract": "Mobile health programs are becoming an increasingly popular medium for dissemination of health information among beneficiaries in less privileged communities. Kilkari is one of the world's largest mobile health programs which delivers time sensitive audio-messages to pregnant women and new mothers. We have been collaborating with ARMMAN, a non-profit in India which operates the Kilkari program, to identify bottlenecks to improve the efficiency of the program. In particular, we provide an initial analysis of the trajectories of beneficiaries' interaction with the mHealth program and examine elements of the program that can be potentially enhanced to boost its success. We cluster the cohort into different buckets based on listenership so as to analyze listenership patterns for each group that could help boost program success. We also demonstrate preliminary results on using historical data in a time-series prediction to identify beneficiary dropouts and enable NGOs in devising timely interventions to strengthen beneficiary retention.", "url": "https://arxiv.org/abs/2311.07139"}, {"metadata": {"arXiv": "2311.07180", "Date": "Mon, 13 Nov 2023 09:11:55 ", "Title": "Knowledge Graph Representations to enhance Intensive Care Time-Series Predictions", "Authors": ["Samyak Jain", "Manuel Burger", "Gunnar R\\\"atsch", "Rita Kuznetsova"], "Categories": "cs.LG cs.AI", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "11 pages"]}, "abstract": "Intensive Care Units (ICU) require comprehensive patient data integration for enhanced clinical outcome predictions, crucial for assessing patient conditions. Recent deep learning advances have utilized patient time series data, and fusion models have incorporated unstructured clinical reports, improving predictive performance. However, integrating established medical knowledge into these models has not yet been explored. The medical domain's data, rich in structural relationships, can be harnessed through knowledge graphs derived from clinical ontologies like the Unified Medical Language System (UMLS) for better predictions. Our proposed methodology integrates this knowledge with ICU data, improving clinical decision modeling. It combines graph representations with vital signs and clinical reports, enhancing performance, especially when data is missing. Additionally, our model includes an interpretability component to understand how knowledge graph nodes affect predictions.", "url": "https://arxiv.org/abs/2311.07180"}, {"metadata": {"arXiv": "2311.07286", "Date": "Mon, 13 Nov 2023 12:28:00 ", "Title": "Explaining black boxes with a SMILE: Statistical Model-agnostic Interpretability with Local Explanations", "Authors": ["Koorosh Aslansefat", "Mojgan Hashemian", "Martin Walker", "Mohammed Naveed Akram", "Ioannis Sorokos", "Yiannis Papadopoulos"], "Categories": "cs.LG cs.AI math.ST stat.ML stat.TH"}, "abstract": "Machine learning is currently undergoing an explosion in capability, popularity, and sophistication. However, one of the major barriers to widespread acceptance of machine learning (ML) is trustworthiness: most ML models operate as black boxes, their inner workings opaque and mysterious, and it can be difficult to trust their conclusions without understanding how those conclusions are reached. Explainability is therefore a key aspect of improving trustworthiness: the ability to better understand, interpret, and anticipate the behaviour of ML models. To this end, we propose SMILE, a new method that builds on previous approaches by making use of statistical distance measures to improve explainability while remaining applicable to a wide range of input data domains.", "url": "https://arxiv.org/abs/2311.07286"}, {"metadata": {"arXiv": "2311.07326", "Date": "Mon, 13 Nov 2023 13:27:59 ", "Title": "MetaSymNet: A Dynamic Symbolic Regression Network Capable of Evolving into Arbitrary Formulations", "Authors": ["Yanjie Li", "Weijun Li", "Lina Yu", "Min Wu", "Jinyi Liu", "Wenqiang Li", "Meilan Hao", "Shu Wei", "Yusong Deng"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages"]}, "abstract": "Mathematical formulas serve as the means of communication between humans and nature, encapsulating the operational laws governing natural phenomena. The concise formulation of these laws is a crucial objective in scientific research and an important challenge for artificial intelligence (AI). While traditional artificial neural networks (MLP) excel at data fitting, they often yield uninterpretable black box results that hinder our understanding of the relationship between variables x and predicted values y. Moreover, the fixed network architecture in MLP often gives rise to redundancy in both network structure and parameters. To address these issues, we propose MetaSymNet, a novel neural network that dynamically adjusts its structure in real-time, allowing for both expansion and contraction. This adaptive network employs the PANGU meta function as its activation function, which is a unique type capable of evolving into various basic functions during training to compose mathematical formulas tailored to specific needs. We then evolve the neural network into a concise, interpretable mathematical expression. To evaluate MetaSymNet's performance, we compare it with four state-of-the-art symbolic regression algorithms across more than 10 public datasets comprising 222 formulas. Our experimental results demonstrate that our algorithm outperforms others consistently regardless of noise presence or absence. Furthermore, we assess MetaSymNet against MLP and SVM regarding their fitting ability and extrapolation capability, these are two essential aspects of machine learning algorithms. The findings reveal that our algorithm excels in both areas. Finally, we compared MetaSymNet with MLP using iterative pruning in network structure complexity. The results show that MetaSymNet's network structure complexity is obviously less than MLP under the same goodness of fit.", "url": "https://arxiv.org/abs/2311.07326"}, {"metadata": {"arXiv": "2311.07485", "Date": "Mon, 13 Nov 2023 17:25:06 ", "Title": "EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning", "Authors": ["Mohammad Mahdi Rahimi", "Hasnain Irshad Bhatti", "Younghyun Park", "Humaira Kousar", "Jaekyun Moon"], "Categories": "cs.LG cs.AI cs.CV cs.NE"}, "abstract": "Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data. However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters. This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges. EvoFed employs a concept of 'fitness-based information sharing', deviating significantly from the conventional model-based FL. Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population. Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds. With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters. As the population size is typically much smaller than the number of model parameters, the savings in communication load is large. The server aggregates these fitness values and is able to update the global model. This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model. Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings.", "url": "https://arxiv.org/abs/2311.07485"}, {"metadata": {"arXiv": "2311.06255", "Date": "Wed, 13 Sep 2023 02:50:57 ", "Title": "Privacy-Engineered Value Decomposition Networks for Cooperative Multi-Agent Reinforcement Learning", "Authors": ["Parham Gohari", "Matthew Hale", "and Ufuk Topcu"], "Categories": "cs.MA cs.AI cs.LG", "Comments": ["Paper accepted at 62nd IEEE Conference on Decision and Control"]}, "abstract": "In cooperative multi-agent reinforcement learning (Co-MARL), a team of agents must jointly optimize the team's long-term rewards to learn a designated task. Optimizing rewards as a team often requires inter-agent communication and data sharing, leading to potential privacy implications. We assume privacy considerations prohibit the agents from sharing their environment interaction data. Accordingly, we propose Privacy-Engineered Value Decomposition Networks (PE-VDN), a Co-MARL algorithm that models multi-agent coordination while provably safeguarding the confidentiality of the agents' environment interaction data. We integrate three privacy-engineering techniques to redesign the data flows of the VDN algorithm, an existing Co-MARL algorithm that consolidates the agents' environment interaction data to train a central controller that models multi-agent coordination, and develop PE-VDN. In the first technique, we design a distributed computation scheme that eliminates Vanilla VDN's dependency on sharing environment interaction data. Then, we utilize a privacy-preserving multi-party computation protocol to guarantee that the data flows of the distributed computation scheme do not pose new privacy risks. Finally, we enforce differential privacy to preempt inference threats against the agents' training data, past environment interactions, when they take actions based on their neural network predictions. We implement PE-VDN in StarCraft Multi-Agent Competition (SMAC) and show that it achieves 80% of Vanilla VDN's win rate while maintaining differential privacy levels that provide meaningful privacy guarantees. The results demonstrate that PE-VDN can safeguard the confidentiality of agents' environment interaction data without sacrificing multi-agent coordination.", "url": "https://arxiv.org/abs/2311.06255"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

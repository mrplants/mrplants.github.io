<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.01379", "Date": "Wed, 02 Aug 2023 18:36:54 ", "Title": "Computational Long Exposure Mobile Photography", "Authors": ["Eric Tabellion", "Nikhil Karnad", "Noa Glaser", "Ben Weiss", "David E. Jacobs", "Yael Pritch"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["15 pages", "17 figures"], "ACM-class": "I.4; I.3.3; I.2.10", "Journal-ref": "ACM Trans. Graph. 42, 4, Article 48 (August 2023)", "DOI": "10.1145/3592124"}, "abstract": "Long exposure photography produces stunning imagery, representing moving elements in a scene with motion-blur. It is generally employed in two modalities, producing either a foreground or a background blur effect. Foreground blur images are traditionally captured on a tripod-mounted camera and portray blurred moving foreground elements, such as silky water or light trails, over a perfectly sharp background landscape. Background blur images, also called panning photography, are captured while the camera is tracking a moving subject, to produce an image of a sharp subject over a background blurred by relative motion. Both techniques are notoriously challenging and require additional equipment and advanced skills. In this paper, we describe a computational burst photography system that operates in a hand-held smartphone camera app, and achieves these effects fully automatically, at the tap of the shutter button. Our approach first detects and segments the salient subject. We track the scene motion over multiple frames and align the images in order to preserve desired sharpness and to produce aesthetically pleasing motion streaks. We capture an under-exposed burst and select the subset of input frames that will produce blur trails of controlled length, regardless of scene or camera motion velocity. We predict inter-frame motion and synthesize motion-blur to fill the temporal gaps between the input frames. Finally, we composite the blurred image with the sharp regular exposure to protect the sharpness of faces or areas of the scene that are barely moving, and produce a final high resolution and high dynamic range (HDR) photograph. Our system democratizes a capability previously reserved to professionals, and makes this creative style accessible to most casual photographers. More information and supplementary material can be found on our project webpage: https://motion-mode.github.io/", "url": "https://arxiv.org/abs/2308.01379"}, {"metadata": {"arXiv": "2308.01472", "Date": "Wed, 02 Aug 2023 23:39:29 ", "Title": "Reverse Stable Diffusion: What prompt was used to generate this image?", "Authors": ["Florinel-Alin Croitoru", "Vlad Hondru", "Radu Tudor Ionescu", "Mubarak Shah"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities between samples in the source and target domains as extra features. We conduct experiments on the DiffusionDB data set, predicting text prompts from images generated by Stable Diffusion. Our novel learning framework produces excellent results on the aforementioned task, yielding the highest gains when applied on the white-box model. In addition, we make an interesting discovery: training a diffusion model on the prompt generation task can make the model generate images that are much better aligned with the input prompts, when the model is directly reused for text-to-image generation.", "url": "https://arxiv.org/abs/2308.01472"}, {"metadata": {"arXiv": "2308.01483", "Date": "Thu, 03 Aug 2023 00:42:30 ", "Title": "Efficient neural supersampling on a novel gaming dataset", "Authors": ["Antoine Mercier and Ruan Erasmus and Yashesh Savani and Manik Dhingra and Fatih Porikli and Guillaume Berger"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["ICCV'23"]}, "abstract": "Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content.", "url": "https://arxiv.org/abs/2308.01483"}, {"metadata": {"arXiv": "2308.01536", "Date": "Thu, 03 Aug 2023 04:36:48 ", "Title": "MFIM: Megapixel Facial Identity Manipulation", "Authors": ["Sanghyeon Na"], "Categories": "cs.CV cs.LG", "Comments": ["ECCV 2022 accepted"], "DOI": "10.1007/978-3-031-19778-9_9"}, "abstract": "Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity.", "url": "https://arxiv.org/abs/2308.01536"}, {"metadata": {"arXiv": "2308.01621", "Date": "Thu, 03 Aug 2023 08:50:48 ", "Title": "A Novel Convolutional Neural Network Architecture with a Continuous Symmetry", "Authors": ["Yao Liu", "Hang Shao", "Bing Bai"], "Categories": "cs.CV cs.LG cs.NE", "Comments": ["Accepted by the 3rd CAAI International Conference on Artificial Intelligence (CICAI)", "2023"]}, "abstract": "This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community.", "url": "https://arxiv.org/abs/2308.01621"}, {"metadata": {"arXiv": "2308.01890", "Date": "Thu, 03 Aug 2023 17:33:20 ", "Title": "DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations", "Authors": ["Ping Hu", "Ximeng Sun", "Stan Sclaroff", "and Kate Saenko"], "Categories": "cs.CV cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:2206.09541"]}, "abstract": "Multi-label image recognition in the low-label regime is a task of great challenge and practical significance. Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations. In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs. We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition. In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts). The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories. Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs. As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes. Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.01890"}, {"metadata": {"arXiv": "2308.01358", "Date": "Wed, 02 Aug 2023 18:02:00 ", "Title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning", "Authors": ["Constantin Philippenko and Aymeric Dieuleveut"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected H\\\"older regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning. More formally, we highlight the impact on the convergence of the covariance $\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm. We demonstrate despite the non-regularity of the stochastic field, that the limit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}} H^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the number of iterations) generalizing the rate for the vanilla LSR case where it is $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines, 2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the compression strategy and ultimately its impact on convergence, first in the centralized case, then in two heterogeneous FL frameworks.", "url": "https://arxiv.org/abs/2308.01358"}, {"metadata": {"arXiv": "2308.01421", "Date": "Tue, 01 Aug 2023 15:04:30 ", "Title": "Regularization, early-stopping and dreaming: a Hopfield-like setup to address generalization and overfitting", "Authors": ["Elena Agliari", "Miriam Aquaro", "Francesco Alemanno", "Alberto Fachechi"], "Categories": "cs.LG cond-mat.dis-nn", "Report-no": "Roma01.Math"}, "abstract": "In this work we approach attractor neural networks from a machine learning perspective: we look for optimal network parameters by applying a gradient descent over a regularized loss function. Within this framework, the optimal neuron-interaction matrices turn out to be a class of matrices which correspond to Hebbian kernels revised by iteratively applying some unlearning protocols. Remarkably, the number of unlearning steps is proved to be related to the regularization hyperparameters of the loss function and to the training time. Thus, we can design strategies to avoid overfitting that are formulated in terms of the algebraic properties of the interaction matrix, or, equivalently, in terms of regularization tuning and early-stopping strategies. The generalization capabilities of these attractor networks are also investigated: analytical results are obtained for random synthetic datasets, next, the emerging picture is corroborated by numerical experiments that highlight the existence of several regimes (i.e., overfitting, failure and success) as the dataset parameters are varied.", "url": "https://arxiv.org/abs/2308.01421"}, {"metadata": {"arXiv": "2308.01436", "Date": "Wed, 02 Aug 2023 21:16:05 ", "Title": "Price-Aware Deep Learning for Electricity Markets", "Authors": ["Vladimir Dvorkin and Ferdinando Fioretto"], "Categories": "cs.LG cs.SY eess.SY math.OC"}, "abstract": "While deep learning gradually penetrates operational planning, its inherent prediction errors may significantly affect electricity prices. This letter examines how prediction errors propagate into electricity prices, revealing notable pricing errors and their spatial disparity in congested power systems. To improve fairness, we propose to embed electricity market-clearing optimization as a deep learning layer. Differentiating through this layer allows for balancing between prediction and pricing errors, as oppose to minimizing prediction errors alone. This layer implicitly optimizes fairness and controls the spatial distribution of price errors across the system. We showcase the price-aware deep learning in the nexus of wind power forecasting and short-term electricity market clearing.", "url": "https://arxiv.org/abs/2308.01436"}, {"metadata": {"arXiv": "2308.01490", "Date": "Thu, 03 Aug 2023 01:08:53 ", "Title": "Minimax Optimal $Q$ Learning with Nearest Neighbors", "Authors": ["Puning Zhao", "Lifeng Lai"], "Categories": "cs.LG stat.ML"}, "abstract": "$Q$ learning is a popular model free reinforcement learning method. Most of existing works focus on analyzing $Q$ learning for finite state and action spaces. If the state space is continuous, then the original $Q$ learning method can not be directly used. A modification of the original $Q$ learning method was proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest neighbors. Such modification makes $Q$ learning suitable for continuous state space. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$ function is $\\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower bound $\\tilde{\\Omega}(T^{-1/(d+2)})$, indicating that this method is not efficient. This paper proposes two new $Q$ learning methods to bridge the gap of convergence rates in (Shah and Xie, 2018), with one of them being offline, while the other is online. Despite that we still use nearest neighbor approach to estimate $Q$ function, the algorithms are crucially different from (Shah and Xie, 2018). In particular, we replace the kernel nearest neighbor in discretized region with a direct nearest neighbor approach. Consequently, our approach significantly improves the convergence rate. Moreover, the time complexity is also significantly improved in high dimensional state spaces. Our analysis shows that both offline and online methods are minimax rate optimal.", "url": "https://arxiv.org/abs/2308.01490"}, {"metadata": {"arXiv": "2308.01508", "Date": "Thu, 03 Aug 2023 02:34:01 ", "Title": "Circumventing Concept Erasure Methods For Text-to-Image Generative Models", "Authors": ["Minh Pham", "Kelly O. Marshall", "Chinmay Hegde"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to \"erase\" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve \"erased\" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.", "url": "https://arxiv.org/abs/2308.01508"}, {"metadata": {"arXiv": "2308.01566", "Date": "Thu, 03 Aug 2023 07:13:27 ", "Title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce", "Authors": ["Otmane Sakhi", "David Rohde", "Nicolas Chopin"], "Categories": "cs.LG cs.IR stat.ML", "Comments": ["Preprint"]}, "abstract": "An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.", "url": "https://arxiv.org/abs/2308.01566"}, {"metadata": {"arXiv": "2308.01606", "Date": "Thu, 03 Aug 2023 08:24:08 ", "Title": "Unsupervised Multiplex Graph Learning with Complementary and Consistent Information", "Authors": ["Liang Peng and Xin Wang and Xiaofeng Zhu"], "Categories": "cs.LG", "DOI": "10.1145/3581783.3611971"}, "abstract": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve significant effectiveness for different downstream tasks by exploring both complementary information and consistent information among multiple graphs. However, previous methods usually overlook the issues in practical applications, i.e., the out-of-sample issue and the noise issue. To address the above issues, in this paper, we propose an effective and efficient UMGL method to explore both complementary and consistent information. To do this, our method employs multiple MLP encoders rather than graph convolutional network (GCN) to conduct representation learning with two constraints, i.e., preserving the local graph structure among nodes to handle the out-of-sample issue, and maximizing the correlation of multiple node representations to handle the noise issue. Comprehensive experiments demonstrate that our proposed method achieves superior effectiveness and efficiency over the comparison methods and effectively tackles those two issues. Code is available at https://github.com/LarryUESTC/CoCoMG.", "url": "https://arxiv.org/abs/2308.01606"}, {"metadata": {"arXiv": "2308.01609", "Date": "Thu, 03 Aug 2023 08:31:31 ", "Title": "Feature Noise Boosts DNN Generalization under Label Noise", "Authors": ["Lu Zeng", "Xuan Chen", "Xiaoshuang Shi", "Heng Tao Shen"], "Categories": "cs.LG"}, "abstract": "The presence of label noise in the training data has a profound impact on the generalization of deep neural networks (DNNs). In this study, we introduce and theoretically demonstrate a simple feature noise method, which directly adds noise to the features of training data, can enhance the generalization of DNNs under label noise. Specifically, we conduct theoretical analyses to reveal that label noise leads to weakened DNN generalization by loosening the PAC-Bayes generalization bound, and feature noise results in better DNN generalization by imposing an upper bound on the mutual information between the model weights and the features, which constrains the PAC-Bayes generalization bound. Furthermore, to ensure effective generalization of DNNs in the presence of label noise, we conduct application analyses to identify the optimal types and levels of feature noise to add for obtaining desirable label noise generalization. Finally, extensive experimental results on several popular datasets demonstrate the feature noise method can significantly enhance the label noise generalization of the state-of-the-art label noise method.", "url": "https://arxiv.org/abs/2308.01609"}, {"metadata": {"arXiv": "2308.01650", "Date": "Thu, 03 Aug 2023 09:32:50 ", "Title": "UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification", "Authors": ["Minhao Zou", "Zhongxue Gan", "Yutong Wang", "Junheng Zhang", "Dongyan Sui", "Chun Guan", "Siyang Leng"], "Categories": "cs.LG"}, "abstract": "Graph and hypergraph representation learning has attracted increasing attention from various research fields. Despite the decent performance and fruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural Networks (HGNNs), and their well-designed variants, on some commonly used benchmark graphs and hypergraphs, they are outperformed by even a simple Multi-Layer Perceptron. This observation motivates a reexamination of the design paradigm of the current GNNs and HGNNs and poses challenges of extracting graph features effectively. In this work, a universal feature encoder for both graph and hypergraph representation learning is designed, called UniG-Encoder. The architecture starts with a forward transformation of the topological relationships of connected nodes into edge or hyperedge features via a normalized projection matrix. The resulting edge/hyperedge features, together with the original node features, are fed into a neural network. The encoded node embeddings are then derived from the reversed transformation, described by the transpose of the projection matrix, of the network's output, which can be further used for tasks such as node classification. The proposed architecture, in contrast to the traditional spectral-based and/or message passing approaches, simultaneously and comprehensively exploits the node features and graph/hypergraph topologies in an efficient and unified manner, covering both heterophilic and homophilic graphs. The designed projection matrix, encoding the graph features, is intuitive and interpretable. Extensive experiments are conducted and demonstrate the superior performance of the proposed framework on twelve representative hypergraph datasets and six real-world graph datasets, compared to the state-of-the-art methods. Our implementation is available online at https://github.com/MinhZou/UniG-Encoder.", "url": "https://arxiv.org/abs/2308.01650"}, {"metadata": {"arXiv": "2308.01674", "Date": "Thu, 03 Aug 2023 10:21:53 ", "Title": "End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC", "Authors": ["Daniel Mayfrank", "Alexander Mitsos", "Manuel Dahmen"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["manuscript (18 pages", "7 figures", "5 tables)", "supplementary materials (3 pages", "2 tables)"]}, "abstract": "(Economic) nonlinear model predictive control ((e)NMPC) requires dynamic system models that are sufficiently accurate in all relevant state-space regions. These models must also be computationally cheap enough to ensure real-time tractability. Data-driven surrogate models for mechanistic models can be used to reduce the computational burden of (e)NMPC; however, such models are typically trained by system identification for maximum average prediction accuracy on simulation samples and perform suboptimally as part of actual (e)NMPC. We present a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in (e)NMPC applications, resulting in predictive controllers that strike a favorable balance between control performance and computational demand. We validate our method on two applications derived from an established nonlinear continuous stirred-tank reactor model. We compare the controller performance to that of MPCs utilizing models trained by the prevailing maximum prediction accuracy paradigm, and model-free neural network controllers trained using reinforcement learning. We show that our method matches the performance of the model-free neural network controllers while consistently outperforming models derived from system identification. Additionally, we show that the MPC policies can react to changes in the control setting without retraining.", "url": "https://arxiv.org/abs/2308.01674"}, {"metadata": {"arXiv": "2308.01731", "Date": "Thu, 03 Aug 2023 12:43:21 ", "Title": "Quantification of Predictive Uncertainty via Inference-Time Sampling", "Authors": ["Katar\\'ina T\\'othov\\'a", "\\v{L}ubor Ladick\\'y", "Daniel Thul", "Marc Pollefeys", "Ender Konukoglu"], "Categories": "cs.LG cs.CV", "Journal-ref": "Lecture Notes in Computer Science, vol 13563. Springer, Cham, 2022", "DOI": "10.1007/978-3-031-16749-2_2"}, "abstract": "Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.", "url": "https://arxiv.org/abs/2308.01731"}, {"metadata": {"arXiv": "2308.01742", "Date": "Thu, 03 Aug 2023 13:06:45 ", "Title": "Exploiting Multi-Label Correlation in Label Distribution Learning", "Authors": ["Zhiqiang Kou jing wang yuheng jia xin geng"], "Categories": "cs.LG"}, "abstract": "Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance. Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation. However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation. Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature. Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL. In such a way, low-rank label correlation is appropriately exploited in our LDL methods. We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods. Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL.", "url": "https://arxiv.org/abs/2308.01742"}, {"metadata": {"arXiv": "2308.01744", "Date": "Thu, 03 Aug 2023 13:08:09 ", "Title": "Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning", "Authors": ["Pier Giuseppe Sessa", "Pierre Laforgue", "Nicol\\`o Cesa-Bianchi", "Andreas Krause"], "Categories": "cs.LG"}, "abstract": "Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.", "url": "https://arxiv.org/abs/2308.01744"}, {"metadata": {"arXiv": "2308.01746", "Date": "Thu, 03 Aug 2023 13:09:59 ", "Title": "Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants", "Authors": ["Yibo Yang", "Haobo Yuan", "Xiangtai Li", "Jianlong Wu", "Lefei Zhang", "Zhouchen Lin", "Philip Torr", "Dacheng Tao", "Bernard Ghanem"], "Categories": "cs.LG cs.CV", "Comments": ["An extension of our ICLR 2023 paper https://openreview.net/pdf?id=y5W8tpojhtJ. arXiv admin note: text overlap with arXiv:2302.03004"]}, "abstract": "How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.", "url": "https://arxiv.org/abs/2308.01746"}, {"metadata": {"arXiv": "2308.01759", "Date": "Thu, 03 Aug 2023 13:43:03 ", "Title": "Bag of Policies for Distributional Deep Exploration", "Authors": ["Asen Nachkov and Luchen Li and Giulia Luise and Filippo Valdettaro and Aldo Faisal"], "Categories": "cs.LG"}, "abstract": "Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL). Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL. We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies. BoP consists of an ensemble of multiple heads that are updated independently. During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour. To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG). The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies. Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration. As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL. Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.", "url": "https://arxiv.org/abs/2308.01759"}, {"metadata": {"arXiv": "2308.01771", "Date": "Thu, 03 Aug 2023 14:00:01 ", "Title": "Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment", "Authors": ["Yasin Shokrollahi1", "Pengfei Dong1", "Xianqi Li", "Linxia Gu"], "Categories": "cs.LG cs.CV eess.IV"}, "abstract": "This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.", "url": "https://arxiv.org/abs/2308.01771"}, {"metadata": {"arXiv": "2308.01814", "Date": "Thu, 03 Aug 2023 15:22:51 ", "Title": "Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit", "Authors": ["Greg Yang", "Etai Littwin"], "Categories": "cs.LG cond-mat.dis-nn cs.NE math.PR", "Comments": ["This is the complete version of \"Adaptive Optimization in the Infinite-Width Limit\" in ICLR 2023", "https://openreview.net/forum?id=zgVDqw9ZUES"]}, "abstract": "Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam? Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of \"kernel.\" We derive the corresponding \"neural tangent\" and \"maximal update\" limits for any architecture. Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates. 2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs. This work summarizes and generalizes all previous results in the Tensor Programs series of papers.", "url": "https://arxiv.org/abs/2308.01814"}, {"metadata": {"arXiv": "2308.01867", "Date": "Tue, 01 Aug 2023 08:15:30 ", "Title": "MRQ:Support Multiple Quantization Schemes through Model Re-Quantization", "Authors": ["Manasa Manohara", "Sankalp Dayal", "Tarqi Afzal", "Rahul Bakshi", "Kahkuen Fu"], "Categories": "cs.LG cs.CV", "Comments": ["8 pages", "6 figures", "3 tables", "TinyML Conference"]}, "abstract": "Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU, DPU), deploying deep learning models on edge devices with fixed-point hardware is still challenging due to complex model quantization and conversion. Existing model quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and Qualcomm AIMET [3] supports only a limited set of quantization schemes (e.g., only asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep learning models cannot be easily quantized for diverse fixed-point hardwares, mainly due to slightly different quantization requirements. In this paper, we envision a new type of model quantization approach called MRQ (model re-quantization), which takes existing quantized models and quickly transforms the models to meet different quantization requirements (e.g., asymmetric -> symmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much simpler than quantizing from scratch because it avoids costly re-training and provides support for multiple quantization schemes simultaneously. To minimize re-quantization error, we developed a new set of re-quantization algorithms including weight correction and rounding error folding. We have demonstrated that MobileNetV2 QAT model [7] can be quickly re-quantized into two different quantization schemes (i.e., symmetric and symmetric+power-of-2 scale) with less than 0.64 units of accuracy loss. We believe our work is the first to leverage this concept of re-quantization for model quantization and models obtained from the re-quantization process have been successfully deployed on NNA in the Echo Show devices.", "url": "https://arxiv.org/abs/2308.01867"}, {"metadata": {"arXiv": "2308.01891", "Date": "Thu, 03 Aug 2023 17:37:18 ", "Title": "Exact identification of nonlinear dynamical systems by Trimmed Lasso", "Authors": ["Shawn L. Kiser", "Mikhail Guskov", "Marc R\\'ebillat", "Nicolas Ranc"], "Categories": "cs.LG cs.SY eess.SY math.DS math.OC", "Comments": ["24 pages", "10 figures"], "ACM-class": "F.2.1; I.2.6"}, "abstract": "Identification of nonlinear dynamical systems has been popularized by sparse identification of the nonlinear dynamics (SINDy) via the sequentially thresholded least squares (STLS) algorithm. Many extensions SINDy have emerged in the literature to deal with experimental data which are finite in length and noisy. Recently, the computationally intensive method of ensembling bootstrapped SINDy models (E-SINDy) was proposed for model identification, handling finite, highly noisy data. While the extensions of SINDy are numerous, their sparsity-promoting estimators occasionally provide sparse approximations of the dynamics as opposed to exact recovery. Furthermore, these estimators suffer under multicollinearity, e.g. the irrepresentable condition for the Lasso. In this paper, we demonstrate that the Trimmed Lasso for robust identification of models (TRIM) can provide exact recovery under more severe noise, finite data, and multicollinearity as opposed to E-SINDy. Additionally, the computational cost of TRIM is asymptotically equal to STLS since the sparsity parameter of the TRIM can be solved efficiently by convex solvers. We compare these methodologies on challenging nonlinear systems, specifically the Lorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark of No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting dynamics. This study emphasizes the comparisons between STLS, reweighted $\\ell_1$ minimization, and Trimmed Lasso in identification with respect to problems faced by practitioners: the problem of finite and noisy data, the performance of the sparse regression of when the library grows in dimension (multicollinearity), and automatic methods for choice of regularization parameters.", "url": "https://arxiv.org/abs/2308.01891"}, {"metadata": {"arXiv": "2308.01389", "Date": "Wed, 02 Aug 2023 19:08:57 ", "Title": "Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning", "Authors": ["Jumman Hossain", "Maliha Momtaz"], "Categories": "cs.RO cs.CV cs.LG"}, "abstract": "Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy.", "url": "https://arxiv.org/abs/2308.01389"}, {"metadata": {"arXiv": "2308.01562", "Date": "Thu, 03 Aug 2023 07:03:33 ", "Title": "Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity", "Authors": ["Md Ferdous Pervej", "Richeng Jin", "Huaiyu Dai"], "Categories": "eess.SY cs.LG cs.NI cs.SY", "Comments": ["Under review for possible publications in IEEE TWC"]}, "abstract": "While a practical wireless network has many tiers where end users do not directly communicate with the central server, the users' devices have limited computation and battery powers, and the serving base station (BS) has a fixed bandwidth. Owing to these practical constraints and system models, this paper leverages model pruning and proposes a pruning-enabled hierarchical federated learning (PHFL) in heterogeneous networks (HetNets). We first derive an upper bound of the convergence rate that clearly demonstrates the impact of the model pruning and wireless communications between the clients and the associated BS. Then we jointly optimize the model pruning ratio, central processing unit (CPU) frequency and transmission power of the clients in order to minimize the controllable terms of the convergence bound under strict delay and energy constraints. However, since the original problem is not convex, we perform successive convex approximation (SCA) and jointly optimize the parameters for the relaxed convex problem. Through extensive simulation, we validate the effectiveness of our proposed PHFL algorithm in terms of test accuracy, wall clock time, energy consumption and bandwidth requirement.", "url": "https://arxiv.org/abs/2308.01562"}, {"metadata": {"arXiv": "2308.01375", "Date": "Wed, 02 Aug 2023 18:26:43 ", "Title": "CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models", "Authors": ["Robert Maier", "Andreas Schlattl", "Thomas Guess", "J\\\"urgen Mottok"], "Categories": "cs.AI", "Comments": ["Submitted to Springer Information Systems Frontiers (Author Version)"], "ACM-class": "H.1"}, "abstract": "Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within interested organizations and the causality community.", "url": "https://arxiv.org/abs/2308.01375"}, {"metadata": {"arXiv": "2308.01556", "Date": "Thu, 03 Aug 2023 06:36:13 ", "Title": "A Global Transport Capacity Risk Prediction Method for Rail Transit Based on Gaussian Bayesian Network", "Authors": ["Zhang Zhengyang and Dong Wei and Liu jun and Sun Xinya and Ji Yindong"], "Categories": "cs.AI"}, "abstract": "Aiming at the prediction problem of transport capacity risk caused by the mismatch between the carrying capacity of rail transit network and passenger flow demand, this paper proposes an explainable prediction method of rail transit network transport capacity risk based on linear Gaussian Bayesian network. This method obtains the training data of the prediction model based on the simulation model of the rail transit system with a three-layer structure including rail transit network, train flow and passenger flow. A Bayesian network structure construction method based on the topology of the rail transit network is proposed, and the MLE (Maximum Likelihood Estimation) method is used to realize the parameter learning of the Bayesian network. Finally, the effectiveness of the proposed method is verified by simulation examples.", "url": "https://arxiv.org/abs/2308.01556"}, {"metadata": {"arXiv": "2308.01589", "Date": "Thu, 03 Aug 2023 07:48:02 ", "Title": "Holy Grail 2.0: From Natural Language to Constraint Models", "Authors": ["Dimos Tsouros", "H\\'el\\`ene Verhaeghe", "Serdar Kad{\\i}o\\u{g}lu and Tias Guns"], "Categories": "cs.AI cs.CL cs.HC"}, "abstract": "Twenty-seven years ago, E. Freuder highlighted that \"Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it\". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting approach to GPT Models.", "url": "https://arxiv.org/abs/2308.01589"}, {"metadata": {"arXiv": "2308.01597", "Date": "Thu, 03 Aug 2023 08:03:19 ", "Title": "DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering", "Authors": ["Stefano Borgo", "Roberta Ferrario", "Aldo Gangemi", "Nicola Guarino", "Claudio Masolo", "Daniele Porello", "Emilio M. Sanfilippo", "Laure Vieu"], "Categories": "cs.AI", "Comments": ["25 pages", "7 figures"], "Journal-ref": "Applied Ontology 17 (2022):45-69", "DOI": "10.3233/AO-210259"}, "abstract": "DOLCE, the first top-level (foundational) ontology to be axiomatized, has remained stable for twenty years and today is broadly used in a variety of domains. DOLCE is inspired by cognitive and linguistic considerations and aims to model a commonsense view of reality, like the one human beings exploit in everyday life in areas as diverse as socio-technical systems, manufacturing, financial transactions and cultural heritage. DOLCE clearly lists the ontological choices it is based upon, relies on philosophical principles, is richly formalized, and is built according to well-established ontological methodologies, e.g. OntoClean. Because of these features, it has inspired most of the existing top-level ontologies and has been used to develop or improve standards and public domain resources (e.g. CIDOC CRM, DBpedia and WordNet). Being a foundational ontology, DOLCE is not directly concerned with domain knowledge. Its purpose is to provide the general categories and relations needed to give a coherent view of reality, to integrate domain knowledge, and to mediate across domains. In these 20 years DOLCE has shown that applied ontologies can be stable and that interoperability across reference and domain ontologies is a reality. This paper briefly introduces the ontology and shows how to use it on a few modeling cases.", "url": "https://arxiv.org/abs/2308.01597"}, {"metadata": {"arXiv": "2308.01732", "Date": "Thu, 03 Aug 2023 12:48:32 ", "Title": "Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories", "Authors": ["Christian Jilek", "Markus Schr\\\"oder", "Heiko Maus", "Sven Schwarz", "Andreas Dengel"], "Categories": "cs.AI", "Comments": ["73 pages", "22 figures"]}, "abstract": "This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories. Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners. We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing) Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support. Past results are complemented by an overview of related work and some of our latest findings not published so far. Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research. Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support.", "url": "https://arxiv.org/abs/2308.01732"}, {"metadata": {"arXiv": "2308.01872", "Date": "Thu, 03 Aug 2023 16:53:53 ", "Title": "Thespian: Multi-Character Text Role-Playing Game Agents", "Authors": ["Christopher Cui", "Xiangyu Peng", "Mark Riedl"], "Categories": "cs.AI cs.CL", "Comments": ["11 pages"]}, "abstract": "Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents. Text role-playing games are open-ended environments where an agent must faithfully play a particular character. We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters. We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time. We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion. We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning.", "url": "https://arxiv.org/abs/2308.01872"}, {"metadata": {"arXiv": "2308.01622", "Date": "Thu, 03 Aug 2023 08:53:23 ", "Title": "ReIDTrack: Multi-Object Track and Segmentation Without Motion", "Authors": ["Kaer Huang", "Bingchuan Sun", "Feng Chen", "Tao Zhang", "Jun Xie", "Jian Li", "Christopher Walter Twombly", "Zhepeng Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "In recent years, dominant Multi-object tracking (MOT) and segmentation (MOTS) methods mainly follow the tracking-by-detection paradigm. Transformer-based end-to-end (E2E) solutions bring some ideas to MOT and MOTS, but they cannot achieve a new state-of-the-art (SOTA) performance in major MOT and MOTS benchmarks. Detection and association are two main modules of the tracking-by-detection paradigm. Association techniques mainly depend on the combination of motion and appearance information. As deep learning has been recently developed, the performance of the detection and appearance model is rapidly improved. These trends made us consider whether we can achieve SOTA based on only high-performance detection and appearance model. Our paper mainly focuses on exploring this direction based on CBNetV2 with Swin-B as a detection model and MoCo-v2 as a self-supervised appearance model. Motion information and IoU mapping were removed during the association. Our method wins 1st place on the MOTS track and wins 2nd on the MOT track in the CVPR2023 WAD workshop. We hope our simple and effective method can give some insights to the MOT and MOTS research community. Source code will be released under this git repository", "url": "https://arxiv.org/abs/2308.01622"}, {"metadata": {"arXiv": "2308.01686", "Date": "Thu, 03 Aug 2023 10:57:58 ", "Title": "LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment", "Authors": ["Zhiwei Zhang", "Zhizhong Zhang", "Qian Yu", "Ran Yi", "Yuan Xie and Lizhuang Ma"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted as ICCV 2023 paper"]}, "abstract": "3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-only baseline on NuScenes dataset. Extensive quantitative and qualitative experiments further demonstrate the effectiveness of our novel framework. The code will be released at https://github.com/zhangzw12319/lcps.git.", "url": "https://arxiv.org/abs/2308.01686"}, {"metadata": {"arXiv": "2308.01700", "Date": "Thu, 03 Aug 2023 11:34:11 ", "Title": "Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition", "Authors": ["Seyed Muhammad Hossein Mousavi and Atiye Ilanloo"], "Categories": "cs.CV cs.AI", "Comments": ["The International Workshop on the Bees Algorithm and its Applications", "Birmingham", "UK (https://sites.google.com/view/baaworkshop/baa-past-events/2022)"]}, "abstract": "Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms. Bees Algorithm (BA) shows decent performance in feature selection optimization tasks. On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images. Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks. IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes. Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation. The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN. Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others.", "url": "https://arxiv.org/abs/2308.01700"}, {"metadata": {"arXiv": "2308.01813", "Date": "Thu, 03 Aug 2023 15:21:08 ", "Title": "Deep Neural Networks Fused with Textures for Image Classification", "Authors": ["Asish Bera", "Debotosh Bhattacharjee", "and Mita Nasipuri"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "6 figures", "4 tables", "conference"], "Journal-ref": "Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2022", "DOI": "10.1007/978-981-99-2680-0_10"}, "abstract": "Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations. Deep learning methods have achieved remarkable success in solving FGIC. In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information. The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM). Another path computes image-level textures at multiple scales using the local binary patterns (LBP). The advantages of both streams are integrated to represent an efficient feature vector for image classification. The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs. Our method has attained better classification accuracy over existing methods with notable margins.", "url": "https://arxiv.org/abs/2308.01813"}, {"metadata": {"arXiv": "2308.01850", "Date": "Thu, 03 Aug 2023 16:18:32 ", "Title": "Synthesizing Long-Term Human Motions with Diffusion Models via Coherent Sampling", "Authors": ["Zhao Yang", "Bing Su and Ji-Rong Wen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ACM MM 2023"]}, "abstract": "Text-to-motion generation has gained increasing attention, but most existing methods are limited to generating short-term motions that correspond to a single sentence describing a single action. However, when a text stream describes a sequence of continuous motions, the generated motions corresponding to each sentence may not be coherently linked. Existing long-term motion generation methods face two main issues. Firstly, they cannot directly generate coherent motions and require additional operations such as interpolation to process the generated actions. Secondly, they generate subsequent actions in an autoregressive manner without considering the influence of future actions on previous ones. To address these issues, we propose a novel approach that utilizes a past-conditioned diffusion model with two optional coherent sampling methods: Past Inpainting Sampling and Compositional Transition Sampling. Past Inpainting Sampling completes subsequent motions by treating previous motions as conditions, while Compositional Transition Sampling models the distribution of the transition as the composition of two adjacent motions guided by different text prompts. Our experimental results demonstrate that our proposed method is capable of generating compositional and coherent long-term 3D human motions controlled by a user-instructed long text stream. The code is available at \\href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}.", "url": "https://arxiv.org/abs/2308.01850"}, {"metadata": {"arXiv": "2308.01519", "Date": "Thu, 03 Aug 2023 03:29:25 ", "Title": "Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation", "Authors": ["Soohyun Park", "Jae Pyoung Kim", "Chanyoung Park", "Soyi Jung", "Joongheon Kim"], "Categories": "cs.MA cs.AI", "Comments": ["7 pages", "3 figures", "2 tables"]}, "abstract": "For Industry 4.0 Revolution, cooperative autonomous mobility systems are widely used based on multi-agent reinforcement learning (MARL). However, the MARL-based algorithms suffer from huge parameter utilization and convergence difficulties with many agents. To tackle these problems, a quantum MARL (QMARL) algorithm based on the concept of actor-critic network is proposed, which is beneficial in terms of scalability, to deal with the limitations in the noisy intermediate-scale quantum (NISQ) era. Additionally, our QMARL is also beneficial in terms of efficient parameter utilization and fast convergence due to quantum supremacy. Note that the reward in our QMARL is defined as task precision over computation time in multiple agents, thus, multi-agent cooperation can be realized. For further improvement, an additional technique for scalability is proposed, which is called projection value measure (PVM). Based on PVM, our proposed QMARL can achieve the highest reward, by reducing the action dimension into a logarithmic-scale. Finally, we can conclude that our proposed QMARL with PVM outperforms the other algorithms in terms of efficient parameter utilization, fast convergence, and scalability.", "url": "https://arxiv.org/abs/2308.01519"}, {"metadata": {"arXiv": "2308.01369", "Date": "Wed, 02 Aug 2023 18:23:42 ", "Title": "An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems", "Authors": ["Ni Dong", "Shuming Chen", "Yina Wu", "Yiheng Feng", "Xiaobo Liu"], "Categories": "cs.RO cs.AI", "Comments": ["33 pages", "5 figures"]}, "abstract": "Navigating automated driving systems (ADSs) through complex driving environments is difficult. Predicting the driving behavior of surrounding human-driven vehicles (HDVs) is a critical component of an ADS. This paper proposes an enhanced motion-planning approach for an ADS in a highway-merging scenario. The proposed enhanced approach utilizes the results of two aspects: the driving behavior and long-term trajectory of surrounding HDVs, which are coupled using a hierarchical model that is used for the motion planning of an ADS to improve driving safety.", "url": "https://arxiv.org/abs/2308.01369"}, {"metadata": {"arXiv": "2308.01551", "Date": "Thu, 03 Aug 2023 06:19:46 ", "Title": "Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning", "Authors": ["Yang Wenkai Ji Ruihang Zhang Yuxiang Lei Hao and Zhao Zijie"], "Categories": "cs.RO cs.AI"}, "abstract": "This paper presents a Pre-Training Deep Reinforcement Learning(DRL) for avoidance navigation without map for mobile robots which map raw sensor data to control variable and navigate in an unknown environment. The efficient offline training strategy is proposed to speed up the inefficient random explorations in early stage and we also collect a universal dataset including expert experience for offline training, which is of some significance for other navigation training work. The pre-training and prioritized expert experience are proposed to reduce 80\\% training time and has been verified to improve the 2 times reward of DRL. The advanced simulation gazebo with real physical modelling and dynamic equations reduce the gap between sim-to-real. We train our model a corridor environment, and evaluate the model in different environment getting the same effect. Compared to traditional method navigation, we can confirm the trained model can be directly applied into different scenarios and have the ability to no collision navigate. It was demonstrated that our DRL model have universal general capacity in different environment.", "url": "https://arxiv.org/abs/2308.01551"}, {"metadata": {"arXiv": "2308.01648", "Date": "Thu, 03 Aug 2023 09:29:19 ", "Title": "Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning", "Authors": ["Yu Ishihara", "Yuichi Hazama", "Kousuke Suzuki", "Jerry Jun Yokono", "Kohtaro Sabe", "Kenta Kawamoto"], "Categories": "cs.RO cs.AI"}, "abstract": "Wind resistance control is an essential feature for quadcopters to maintain their position to avoid deviation from target position and prevent collisions with obstacles. Conventionally, cascaded PID controller is used for the control of quadcopters for its simplicity and ease of tuning its parameters. However, it is weak against wind disturbances and the quadcopter can easily deviate from target position. In this work, we propose a residual reinforcement learning based approach to build a wind resistance controller of a quadcopter. By learning only the residual that compensates the disturbance, we can continue using the cascaded PID controller as the base controller of the quadcopter but improve its performance against wind disturbances. To avoid unexpected crashes and destructions of quadcopters, our method does not require real hardware for data collection and training. The controller is trained only on a simulator and directly applied to the target hardware without extra finetuning process. We demonstrate the effectiveness of our approach through various experiments including an experiment in an outdoor scene with wind speed greater than 13 m/s. Despite its simplicity, our controller reduces the position deviation by approximately 50% compared to the quadcopter controlled with the conventional cascaded PID controller. Furthermore, trained controller is robust and preserves its performance even though the quadcopter's mass and propeller's lift coefficient is changed between 50% to 150% from original training time.", "url": "https://arxiv.org/abs/2308.01648"}, {"metadata": {"arXiv": "2308.01552", "Date": "Thu, 03 Aug 2023 06:19:58 ", "Title": "InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent", "Authors": ["Po-Lin Chen", "Cheng-Shang Chang"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.", "url": "https://arxiv.org/abs/2308.01552"}, {"metadata": {"arXiv": "2308.01797", "Date": "Thu, 03 Aug 2023 14:52:17 ", "Title": "Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach", "Authors": ["Giovanni Bonetta", "Davide Zago", "Rossella Cancelliere", "Andrea Grosso"], "Categories": "cs.AI cs.LG cs.NE math.CO", "ACM-class": "I.2.0; I.2.8; I.2.6", "Journal-ref": "Proceedings of the International Conference on Learning and Intelligent Optimization (LION17). Springer International Publishing (2023, June)"}, "abstract": "Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.", "url": "https://arxiv.org/abs/2308.01797"}, {"metadata": {"arXiv": "2308.01390", "Date": "Wed, 02 Aug 2023 19:10:23 ", "Title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models", "Authors": ["Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.", "url": "https://arxiv.org/abs/2308.01390"}, {"metadata": {"arXiv": "2308.01471", "Date": "Wed, 02 Aug 2023 23:39:24 ", "Title": "Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving", "Authors": ["Ben Agro", "Quinlan Sykora", "Sergio Casas", "Raquel Urtasun"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["19 pages", "13 figures"], "Journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 1379-1388"}, "abstract": "A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito.", "url": "https://arxiv.org/abs/2308.01471"}, {"metadata": {"arXiv": "2308.01626", "Date": "Thu, 03 Aug 2023 08:56:56 ", "Title": "Interleaving GANs with knowledge graphs to support design creativity for book covers", "Authors": ["Alexandru Motogna", "Adrian Groza"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone.", "url": "https://arxiv.org/abs/2308.01626"}, {"metadata": {"arXiv": "2308.01905", "Date": "Thu, 03 Aug 2023 17:59:06 ", "Title": "Revisiting Deformable Convolution for Depth Completion", "Authors": ["Xinglong Sun", "Jean Ponce", "Yu-Xiong Wang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted and going to appear at IROS2023"]}, "abstract": "Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years. Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps. However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input. In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution. We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority. To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies. Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance. We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed. Our code is available at https://github.com/AlexSunNik/ReDC.", "url": "https://arxiv.org/abs/2308.01905"}, {"metadata": {"arXiv": "2308.01319", "Date": "Mon, 31 Jul 2023 16:35:35 ", "Title": "Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges", "Authors": ["Farzaneh Tajidini", "Mohammad-Javad Kheiri"], "Categories": "cs.LG cs.AI"}, "abstract": "Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is expanding quickly. Because errors in medical diagnostic systems might lead to seriously misleading medical treatments, major efforts have been made in recent years to improve computer-aided diagnostics applications. The use of machine learning in computer-aided diagnosis is crucial. A simple equation may result in a false indication of items like organs. Therefore, learning from examples is a vital component of pattern recognition. Pattern recognition and machine learning in the biomedical area promise to increase the precision of disease detection and diagnosis. They also support the decision-making process's objectivity. Machine learning provides a practical method for creating elegant and autonomous algorithms to analyze high-dimensional and multimodal bio-medical data. This review article examines machine-learning algorithms for detecting diseases, including hepatitis, diabetes, liver disease, dengue fever, and heart disease. It draws attention to the collection of machine learning techniques and algorithms employed in studying conditions and the ensuing decision-making process.", "url": "https://arxiv.org/abs/2308.01319"}, {"metadata": {"arXiv": "2308.01320", "Date": "Wed, 02 Aug 2023 18:49:57 ", "Title": "DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales", "Authors": ["Zhewei Yao", "Reza Yazdani Aminabadi", "Olatunji Ruwase", "Samyam Rajbhandari", "Xiaoxia Wu", "Ammar Ahmad Awan", "Jeff Rasley", "Minjia Zhang", "Conglong Li", "Connor Holmes", "Zhongzhu Zhou", "Michael Wyatt", "Molly Smith", "Lev Kurilenko", "Heyang Qin", "Masahiro Tanaka", "Shuai Che", "Shuaiwen Leon Song", "Yuxiong He"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["14 pages", "7 figures"]}, "abstract": "ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.", "url": "https://arxiv.org/abs/2308.01320"}, {"metadata": {"arXiv": "2308.01329", "Date": "Wed, 02 Aug 2023 17:22:13 ", "Title": "EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding", "Authors": ["Yan Zheng", "Junpeng Wang", "Chin-Chia Michael Yeh", "Yujie Fan", "Huiyuan Chen", "Liang Wang", "Wei Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["5 pages", "3 figures", "accepted by PacificVis 2023"], "DOI": "10.1109/PacificVis56936.2023.00032"}, "abstract": "Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset.", "url": "https://arxiv.org/abs/2308.01329"}, {"metadata": {"arXiv": "2308.01438", "Date": "Wed, 02 Aug 2023 21:22:17 ", "Title": "Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations", "Authors": ["Ahmad Mohammadshirazi", "Aida Nadafian", "Amin Karimi Monsefi", "Mohammad H. Rafiei", "Rajiv Ramnath"], "Categories": "cs.LG cs.AI physics.data-an", "ACM-class": "I.2.6"}, "abstract": "Cost-effective sensors are capable of real-time capturing a variety of air quality-related modalities from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models are capable of performing air-quality \"ahead-of-time\" approximations. Undoubtedly, accurate indoor air quality approximation significantly helps provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is crucial to design an ML architecture to capture the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models include an adroit combination of state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are shown to be less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and, more importantly, their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.", "url": "https://arxiv.org/abs/2308.01438"}, {"metadata": {"arXiv": "2308.01469", "Date": "Wed, 02 Aug 2023 23:13:49 ", "Title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference", "Authors": ["Ruyi Ding", "Shijin Duan", "Xiaolin Xu", "Yunsi Fei"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.", "url": "https://arxiv.org/abs/2308.01469"}, {"metadata": {"arXiv": "2308.01543", "Date": "Thu, 03 Aug 2023 05:23:07 ", "Title": "Lode Enhancer: Level Co-creation Through Scaling", "Authors": ["Debosmita Bhaumik", "Julian Togelius", "Georgios N. Yannakakis", "Ahmed Khalifa"], "Categories": "cs.LG cs.AI", "DOI": "10.1145/3582437.3587206"}, "abstract": "We explore AI-powered upscaling as a design assistance tool in the context of creating 2D game levels. Deep neural networks are used to upscale artificially downscaled patches of levels from the puzzle platformer game Lode Runner. The trained networks are incorporated into a web-based editor, where the user can create and edit levels at three different levels of resolution: 4x4, 8x8, and 16x16. An edit at any resolution instantly transfers to the other resolutions. As upscaling requires inventing features that might not be present at lower resolutions, we train neural networks to reproduce these features. We introduce a neural network architecture that is capable of not only learning upscaling but also giving higher priority to less frequent tiles. To investigate the potential of this tool and guide further development, we conduct a qualitative study with 3 designers to understand how they use it. Designers enjoyed co-designing with the tool, liked its underlying concept, and provided feedback for further improvement.", "url": "https://arxiv.org/abs/2308.01543"}, {"metadata": {"arXiv": "2308.01578", "Date": "Thu, 03 Aug 2023 07:28:06 ", "Title": "Unsupervised Representation Learning for Time Series: A Review", "Authors": ["Qianwen Meng", "Hangwei Qian", "Yong Liu", "Yonghui Xu", "Zhiqi Shen", "Lizhen Cui"], "Categories": "cs.LG cs.AI", "Comments": ["In submission to IEEE"]}, "abstract": "Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.", "url": "https://arxiv.org/abs/2308.01578"}, {"metadata": {"arXiv": "2308.01614", "Date": "Thu, 03 Aug 2023 08:41:39 ", "Title": "Assessing Systematic Weaknesses of DNNs using Counterfactuals", "Authors": ["Sujan Sai Gannamaneni", "Michael Mock", "Maram Akila"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["AAAI Spring Symposium 2023"]}, "abstract": "With the advancement of DNNs into safety-critical applications, testing approaches for such models have gained more attention. A current direction is the search for and identification of systematic weaknesses that put safety assumptions based on average performance values at risk. Such weaknesses can take on the form of (semantically coherent) subsets or areas in the input space where a DNN performs systematically worse than its expected average. However, it is non-trivial to attribute the reason for such observed low performances to the specific semantic features that describe the subset. For instance, inhomogeneities within the data w.r.t. other (non-considered) attributes might distort results. However, taking into account all (available) attributes and their interaction is often computationally highly expensive. Inspired by counterfactual explanations, we propose an effective and computationally cheap algorithm to validate the semantic attribution of existing subsets, i.e., to check whether the identified attribute is likely to have caused the degraded performance. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data, where we show for a semantic segmentation model that (i) performance differences among the different pedestrian assets exist, but (ii) only in some cases is the asset type itself the reason for this reduction in the performance.", "url": "https://arxiv.org/abs/2308.01614"}, {"metadata": {"arXiv": "2308.01649", "Date": "Thu, 03 Aug 2023 09:31:45 ", "Title": "MARLIM: Multi-Agent Reinforcement Learning for Inventory Management", "Authors": ["R\\'emi Leluc", "Elie Kadoche", "Antoine Bertoncello", "S\\'ebastien Gourv\\'enec"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["Accepted at NeurIPS 2022 Workshop: Reinforcement Learning for Real Life (https://nips.cc/virtual/2022/workshop/50014)"]}, "abstract": "Maintaining a balance between the supply and demand of products by optimizing replenishment decisions is one of the most important challenges in the supply chain industry. This paper presents a novel reinforcement learning framework called MARLIM, to address the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times. Within this context, controllers are developed through single or multiple agents in a cooperative setting. Numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.", "url": "https://arxiv.org/abs/2308.01649"}, {"metadata": {"arXiv": "2308.01682", "Date": "Thu, 03 Aug 2023 10:48:37 ", "Title": "Evaluating Link Prediction Explanations for Graph Neural Networks", "Authors": ["Claudio Borile", "Alan Perotti", "Andr\\'e Panisson"], "Categories": "cs.LG cs.AI", "Comments": ["This work has been accepted to be presented to The 1st World Conference on eXplainable Artificial Intelligence (xAI 2023)", "July 26-28", "2023 - Lisboa", "Portugal"]}, "abstract": "Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.", "url": "https://arxiv.org/abs/2308.01682"}, {"metadata": {"arXiv": "2308.01823", "Date": "Thu, 03 Aug 2023 15:33:24 ", "Title": "Hard Adversarial Example Mining for Improving Robust Fairness", "Authors": ["Chenhao Lin", "Xiang Ji", "Yulong Yang", "Qian Li", "Chao Shen", "Run Wang", "Liming Fang"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.", "url": "https://arxiv.org/abs/2308.01823"}, {"metadata": {"arXiv": "2308.01840", "Date": "Thu, 03 Aug 2023 16:05:39 ", "Title": "URET: Universal Robustness Evaluation Toolkit (for Evasion)", "Authors": ["Kevin Eykholt", "Taesung Lee", "Douglas Schales", "Jiyong Jang", "Ian Molloy", "and Masha Zorin"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["Accepted at USENIX '23"]}, "abstract": "Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.", "url": "https://arxiv.org/abs/2308.01840"}, {"metadata": {"arXiv": "2308.01895", "Date": "Thu, 03 Aug 2023 17:46:27 ", "Title": "Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning", "Authors": ["Daniel Brignac", "Niels Lobo", "Abhijit Mahalanobis"], "Categories": "cs.LG cs.AI"}, "abstract": "Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks. One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task. However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored. This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples.", "url": "https://arxiv.org/abs/2308.01895"}, {"metadata": {"arXiv": "2308.01557", "Date": "Thu, 03 Aug 2023 06:36:21 ", "Title": "Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models", "Authors": ["Joao Carvalho", "An T. Le", "Mark Baierl", "Dorothea Koert", "Jan Peters"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Learning priors on trajectory distributions can help accelerate robot motion planning optimization. Given previously successful plans, learning trajectory generative models as priors for a new planning problem is highly desirable. Prior works propose several ways on utilizing this prior to bootstrapping the motion planning problem. Either sampling the prior for initializations or using the prior distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we propose learning diffusion models as priors. We then can sample directly from the posterior trajectory distribution conditioned on task goals, by leveraging the inverse denoising process of diffusion models. Furthermore, diffusion has been recently shown to effectively encode data multimodality in high-dimensional settings, which is particularly well-suited for large trajectory dataset. To demonstrate our method efficacy, we compare our proposed method - Motion Planning Diffusion - against several baselines in simulated planar robot and 7-dof robot arm manipulator environments. To assess the generalization capabilities of our method, we test it in environments with previously unseen obstacles. Our experiments show that diffusion models are strong priors to encode high-dimensional trajectory distributions of robot motions.", "url": "https://arxiv.org/abs/2308.01557"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

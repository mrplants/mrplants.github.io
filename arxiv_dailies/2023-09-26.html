<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.13137", "Date": "Fri, 22 Sep 2023 18:48:38 ", "Title": "Trading-off Mutual Information on Feature Aggregation for Face Recognition", "Authors": ["Mohammad Akyash", "Ali Zafari", "Nasser M. Nasrabadi"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to 22$^{nd}$ IEEE International Conference on Machine Learning and Applications 2023 (ICMLA)"]}, "abstract": "Despite the advances in the field of Face Recognition (FR), the precision of these methods is not yet sufficient. To improve the FR performance, this paper proposes a technique to aggregate the outputs of two state-of-the-art (SOTA) deep FR models, namely ArcFace and AdaFace. In our approach, we leverage the transformer attention mechanism to exploit the relationship between different parts of two feature maps. By doing so, we aim to enhance the overall discriminative power of the FR system. One of the challenges in feature aggregation is the effective modeling of both local and global dependencies. Conventional transformers are known for their ability to capture long-range dependencies, but they often struggle with modeling local dependencies accurately. To address this limitation, we augment the self-attention mechanism to capture both local and global dependencies effectively. This allows our model to take advantage of the overlapping receptive fields present in corresponding locations of the feature maps. However, fusing two feature maps from different FR models might introduce redundancies to the face embedding. Since these models often share identical backbone architectures, the resulting feature maps may contain overlapping information, which can mislead the training process. To overcome this problem, we leverage the principle of Information Bottleneck to obtain a maximally informative facial representation. This ensures that the aggregated features retain the most relevant and discriminative information while minimizing redundant or misleading details. To evaluate the effectiveness of our proposed method, we conducted experiments on popular benchmarks and compared our results with state-of-the-art algorithms. The consistent improvement we observed in these benchmarks demonstrates the efficacy of our approach in enhancing FR performance.", "url": "https://arxiv.org/abs/2309.13137"}, {"metadata": {"arXiv": "2309.13258", "Date": "Sat, 23 Sep 2023 04:45:42 ", "Title": "Order-preserving Consistency Regularization for Domain Adaptation and Generalization", "Authors": ["Mengmeng Jing", "Xiantong Zhen", "Jingjing Li", "Cees Snoek"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same representation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regularization (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The comprehensive experiments show that our method achieves clear advantages on five different cross-domain tasks.", "url": "https://arxiv.org/abs/2309.13258"}, {"metadata": {"arXiv": "2309.13546", "Date": "Sun, 24 Sep 2023 04:29:22 ", "Title": "DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning", "Authors": ["Kangyang Luo", "Shuai Wang", "Yexuan Fu", "Xiang Li", "Yunshi Lan", "Ming Gao"], "Categories": "cs.CV cs.LG", "Comments": ["Published as a conference paper at NeurIPS 2023"]}, "abstract": "Federated Learning (FL) is a privacy-constrained decentralized machine learning paradigm in which clients enable collaborative training without compromising private data. However, how to learn a robust global model in the data-heterogeneous and model-heterogeneous FL scenarios is challenging. To address it, we resort to data-free knowledge distillation to propose a new FL method (namely DFRD). DFRD equips a conditional generator on the server to approximate the training space of the local models uploaded by clients, and systematically investigates its training in terms of fidelity, transferability} and diversity. To overcome the catastrophic forgetting of the global model caused by the distribution shifts of the generator across communication rounds, we maintain an exponential moving average copy of the generator on the server. Additionally, we propose dynamic weighting and label sampling to accurately extract knowledge from local models. Finally, our extensive experiments on various image classification tasks illustrate that DFRD achieves significant performance gains compared to SOTA baselines.", "url": "https://arxiv.org/abs/2309.13546"}, {"metadata": {"arXiv": "2309.13598", "Date": "Sun, 24 Sep 2023 10:07:40 ", "Title": "On the Posterior Distribution in Denoising: Application to Uncertainty Quantification", "Authors": ["Hila Manor and Tomer Michaeli"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["Code and examples are available on the project's webpage in https://hilamanor.github.io/GaussianDenoisingPosterior/"]}, "abstract": "Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of the denoiser. Code and examples are available on the project's webpage in https://hilamanor.github.io/GaussianDenoisingPosterior/", "url": "https://arxiv.org/abs/2309.13598"}, {"metadata": {"arXiv": "2309.13600", "Date": "Sun, 24 Sep 2023 10:22:35 ", "Title": "Multi-Dimensional Hyena for Spatial Inductive Bias", "Authors": ["Itamar Zimerman and Lior Wolf"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "3 figures"], "ACM-class": "F.2.2; I.2.7"}, "abstract": "In recent years, Vision Transformers have attracted increasing interest from computer vision researchers. However, the advantage of these transformers over CNNs is only fully manifested when trained over a large dataset, mainly due to the reduced inductive bias towards spatial locality within the transformer's self-attention mechanism. In this work, we present a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We propose several alternative approaches for obtaining this generalization and delve into their unique distinctions and considerations from both empirical and theoretical perspectives. Our empirical findings indicate that the proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT is favorable to ViT variants from the recent literature that are specifically designed for solving the same challenge, i.e., working with small datasets or incorporating image-specific inductive bias into the self-attention mechanism. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures.", "url": "https://arxiv.org/abs/2309.13600"}, {"metadata": {"arXiv": "2309.13682", "Date": "Sun, 24 Sep 2023 16:11:58 ", "Title": "Causal-DFQ: Causality Guided Data-free Network Quantization", "Authors": ["Yuzhang Shang", "Bingxin Xu", "Gaowen Liu", "Ramana Kompella", "Yan Yan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to ICCV2023"]}, "abstract": "Model quantization, which aims to compress deep neural networks and accelerate inference speed, has greatly facilitated the development of cumbersome models on mobile and edge devices. There is a common assumption in quantization methods from prior works that training data is available. In practice, however, this assumption cannot always be fulfilled due to reasons of privacy and security, rendering these methods inapplicable in real-life situations. Thus, data-free network quantization has recently received significant attention in neural network compression. Causal reasoning provides an intuitive way to model causal relationships to eliminate data-driven correlations, making causality an essential component of analyzing data-free problems. However, causal formulations of data-free quantization are inadequate in the literature. To bridge this gap, we construct a causal graph to model the data generation and discrepancy reduction between the pre-trained and quantized models. Inspired by the causal understanding, we propose the Causality-guided Data-free Network Quantization method, Causal-DFQ, to eliminate the reliance on data via approaching an equilibrium of causality-driven intervened distributions. Specifically, we design a content-style-decoupled generator, synthesizing images conditioned on the relevant and irrelevant factors; then we propose a discrepancy reduction loss to align the intervened distributions of the pre-trained and quantized models. It is worth noting that our work is the first attempt towards introducing causality to data-free quantization problem. Extensive experiments demonstrate the efficacy of Causal-DFQ. The code is available at https://github.com/42Shawn/Causal-DFQ.", "url": "https://arxiv.org/abs/2309.13682"}, {"metadata": {"arXiv": "2309.14062", "Date": "Mon, 25 Sep 2023 11:54:33 ", "Title": "FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning", "Authors": ["Dipam Goswami", "Yuyang Liu", "Bart{\\l}omiej Twardowski", "Joost van de Weijer"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Exemplar-free class-incremental learning (CIL) poses several challenges since it prohibits the rehearsal of data from previous tasks and thus suffers from catastrophic forgetting. Recent approaches to incrementally learning the classifier by freezing the feature extractor after the first task have gained much attention. In this paper, we explore prototypical networks for CIL, which generate new class prototypes using the frozen feature extractor and classify the features based on the Euclidean distance to the prototypes. In an analysis of the feature distributions of classes, we show that classification based on Euclidean metrics is successful for jointly trained features. However, when learning from non-stationary data, we observe that the Euclidean metric is suboptimal and that feature distributions are heterogeneous. To address this challenge, we revisit the anisotropic Mahalanobis distance for CIL. In addition, we empirically show that modeling the feature covariance relations is better than previous attempts at sampling features from normal distributions and training a linear classifier. Unlike existing methods, our approach generalizes to both many- and few-shot CIL settings, as well as to domain-incremental settings. Interestingly, without updating the backbone network, our method obtains state-of-the-art results on several standard continual learning benchmarks. Code is available at https://github.com/dipamgoswami/FeCAM.", "url": "https://arxiv.org/abs/2309.14062"}, {"metadata": {"arXiv": "2309.14277", "Date": "Mon, 25 Sep 2023 16:40:56 ", "Title": "SINCERE: Supervised Information Noise-Contrastive Estimation REvisited", "Authors": ["Patrick Feeney and Michael C. Hughes"], "Categories": "cs.CV cs.LG"}, "abstract": "The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation. Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels. This SupCon loss has been widely-used due to reports of good empirical performance. However, in this work we suggest that the specific SupCon loss formulated by prior work has questionable theoretic justification, because it can encourage images from the same class to repel one another in the learned embedding space. This problematic behavior gets worse as the number of inputs sharing one class label increases. We propose the Supervised InfoNCE REvisited (SINCERE) loss as a remedy. SINCERE is a theoretically justified solution for a supervised extension of InfoNCE that never causes images from the same class to repel one another. We further show that minimizing our new loss is equivalent to maximizing a bound on the KL divergence between class conditional embedding distributions. We compare SINCERE and SupCon losses in terms of learning trajectories during pretraining and in ultimate linear classifier performance after finetuning. Our proposed SINCERE loss better separates embeddings from different classes during pretraining while delivering competitive accuracy.", "url": "https://arxiv.org/abs/2309.14277"}, {"metadata": {"arXiv": "2309.14330", "Date": "Mon, 25 Sep 2023 17:55:24 ", "Title": "Noise-in, Bias-out: Balanced and Real-time MoCap Solving", "Authors": ["Georgios Albanis and Nikolaos Zioulis and Spyridon Thermos and Anargyros Chatzitofis and Kostas Kolomvatsos"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page: https://moverseai.github.io/noise-tail"]}, "abstract": "Real-time optical Motion Capture (MoCap) systems have not benefited from the advances in modern data-driven modeling. In this work we apply machine learning to solve noisy unstructured marker estimates in real-time and deliver robust marker-based MoCap even when using sparse affordable sensors. To achieve this we focus on a number of challenges related to model training, namely the sourcing of training data and their long-tailed distribution. Leveraging representation learning we design a technique for imbalanced regression that requires no additional data or labels and improves the performance of our model in rare and challenging poses. By relying on a unified representation, we show that training such a model is not bound to high-end MoCap training data acquisition, and exploit the advances in marker-less MoCap to acquire the necessary data. Finally, we take a step towards richer and affordable MoCap by adapting a body model-based inverse kinematics solution to account for measurement and inference uncertainty, further improving performance and robustness. Project page: https://moverseai.github.io/noise-tail", "url": "https://arxiv.org/abs/2309.14330"}, {"metadata": {"arXiv": "2309.13087", "Date": "Fri, 22 Sep 2023 02:27:05 ", "Title": "Learning algorithms for identification of whisky using portable Raman spectroscopy", "Authors": ["Kwang Jun Lee", "Alexander C. Trowbridge", "Graham D. Bruce", "George O. Dwapanyin", "Kylie R. Dunning", "Kishan Dholakia", "Erik P. Schartner"], "Categories": "cs.LG physics.data-an", "Comments": ["26 pages", "4 figures", "2 table"]}, "abstract": "Reliable identification of high-value products such as whisky is an increasingly important area, as issues such as brand substitution (i.e. fraudulent products) and quality control are critical to the industry. We have examined a range of machine learning algorithms and interfaced them directly with a portable Raman spectroscopy device to both identify and characterize the ethanol/methanol concentrations of commercial whisky samples. We demonstrate that machine learning models can achieve over 99% accuracy in brand identification across twenty-eight commercial samples. To demonstrate the flexibility of this approach we utilised the same samples and algorithms to quantify ethanol concentrations, as well as measuring methanol levels in spiked whisky samples. Our machine learning techniques are then combined with a through-the-bottle method to perform spectral analysis and identification without requiring the sample to be decanted from the original container, showing the practical potential of this approach to the detection of counterfeit or adulterated spirits and other high value liquid samples.", "url": "https://arxiv.org/abs/2309.13087"}, {"metadata": {"arXiv": "2309.13092", "Date": "Fri, 22 Sep 2023 09:51:15 ", "Title": "Prototype-Enhanced Hypergraph Learning for Heterogeneous Information Networks", "Authors": ["Shuai Wang", "Jiayi Shen", "Athanasios Efthymiou", "Stevan Rudinac", "Monika Kackovic", "Nachoem Wijnberg", "Marcel Worring"], "Categories": "cs.LG cs.SI"}, "abstract": "The variety and complexity of relations in multimedia data lead to Heterogeneous Information Networks (HINs). Capturing the semantics from such networks requires approaches capable of utilizing the full richness of the HINs. Existing methods for modeling HINs employ techniques originally designed for graph neural networks, and HINs decomposition analysis, like using manually predefined metapaths. In this paper, we introduce a novel prototype-enhanced hypergraph learning approach for node classification in HINs. Using hypergraphs instead of graphs, our method captures higher-order relationships among nodes and extracts semantic information without relying on metapaths. Our method leverages the power of prototypes to improve the robustness of the hypergraph learning process and creates the potential to provide human-interpretable insights into the underlying network structure. Extensive experiments on three real-world HINs demonstrate the effectiveness of our method.", "url": "https://arxiv.org/abs/2309.13092"}, {"metadata": {"arXiv": "2309.13098", "Date": "Fri, 22 Sep 2023 15:10:36 ", "Title": "Topological Data Mapping of Online Hate Speech, Misinformation, and General Mental Health: A Large Language Model Based Study", "Authors": ["Andrew Alexander", "Hongbin Wang"], "Categories": "cs.LG math.AT q-bio.NC", "Comments": ["43 pages"]}, "abstract": "The advent of social media has led to an increased concern over its potential to propagate hate speech and misinformation, which, in addition to contributing to prejudice and discrimination, has been suspected of playing a role in increasing social violence and crimes in the United States. While literature has shown the existence of an association between posting hate speech and misinformation online and certain personality traits of posters, the general relationship and relevance of online hate speech/misinformation in the context of overall psychological wellbeing of posters remain elusive. One difficulty lies in the lack of adequate data analytics tools capable of adequately analyzing the massive amount of social media posts to uncover the underlying hidden links. Recent progresses in machine learning and large language models such as ChatGPT have made such an analysis possible. In this study, we collected thousands of posts from carefully selected communities on the social media site Reddit. We then utilized OpenAI's GPT3 to derive embeddings of these posts, which are high-dimensional real-numbered vectors that presumably represent the hidden semantics of posts. We then performed various machine-learning classifications based on these embeddings in order to understand the role of hate speech/misinformation in various communities. Finally, a topological data analysis (TDA) was applied to the embeddings to obtain a visual map connecting online hate speech, misinformation, various psychiatric disorders, and general mental health.", "url": "https://arxiv.org/abs/2309.13098"}, {"metadata": {"arXiv": "2309.13135", "Date": "Fri, 22 Sep 2023 18:43:41 ", "Title": "Forecasting Response to Treatment with Deep Learning and Pharmacokinetic Priors", "Authors": ["Willa Potosnak", "Cristian Challu", "Kin G. Olivares", "Artur Dubrawski"], "Categories": "cs.LG q-bio.QM"}, "abstract": "Forecasting healthcare time series is crucial for early detection of adverse outcomes and for patient monitoring. Forecasting, however, can be difficult in practice due to noisy and intermittent data. The challenges are often exacerbated by change points induced via extrinsic factors, such as the administration of medication. We propose a novel encoder that informs deep learning models of the pharmacokinetic effects of drugs to allow for accurate forecasting of time series affected by treatment. We showcase the effectiveness of our approach in a task to forecast blood glucose using both realistically simulated and real-world data. Our pharmacokinetic encoder helps deep learning models surpass baselines by approximately 11% on simulated data and 8% on real-world data. The proposed approach can have multiple beneficial applications in clinical practice, such as issuing early warnings about unexpected treatment responses, or helping to characterize patient-specific treatment effects in terms of drug absorption and elimination characteristics.", "url": "https://arxiv.org/abs/2309.13135"}, {"metadata": {"arXiv": "2309.13150", "Date": "Fri, 22 Sep 2023 19:15:49 ", "Title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations", "Authors": ["Hanjiang Hu", "Zuxin Liu", "Linyi Li", "Jiacheng Zhu", "Ding Zhao"], "Categories": "cs.LG cs.CV cs.RO", "Comments": ["32 pages", "5 figures", "13 tables"]}, "abstract": "In recent years, computer vision has made remarkable advancements in autonomous driving and robotics. However, it has been observed that deep learning-based visual perception models lack robustness when faced with camera motion perturbations. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. This is achieved by deriving Lipschitz-based approximated partition intervals. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames.", "url": "https://arxiv.org/abs/2309.13150"}, {"metadata": {"arXiv": "2309.13167", "Date": "Fri, 22 Sep 2023 20:15:37 ", "Title": "Flow Factorized Representation Learning", "Authors": ["Yue Song", "T. Anderson Keller", "Nicu Sebe", "Max Welling"], "Categories": "cs.LG cs.CV", "Comments": ["NeurIPS23"]}, "abstract": "A prominent goal of representation learning research is to achieve representations which are factorized in a useful manner with respect to the ground truth factors of variation. The fields of disentangled and equivariant representation learning have approached this ideal from a range of complimentary perspectives; however, to date, most approaches have proven to either be ill-specified or insufficiently flexible to effectively separate all realistic factors of interest in a learned latent space. In this work, we propose an alternative viewpoint on such structured representation learning which we call Flow Factorized Representation Learning, and demonstrate it to learn both more efficient and more usefully structured representations than existing frameworks. Specifically, we introduce a generative model which specifies a distinct set of latent probability paths that define different input transformations. Each latent flow is generated by the gradient field of a learned potential following dynamic optimal transport. Our novel setup brings new understandings to both \\textit{disentanglement} and \\textit{equivariance}. We show that our model achieves higher likelihoods on standard representation learning benchmarks while simultaneously being closer to approximately equivariant models. Furthermore, we demonstrate that the transformations learned by our model are flexibly composable and can also extrapolate to new data, implying a degree of robustness and generalizability approaching the ultimate goal of usefully factorized representation learning.", "url": "https://arxiv.org/abs/2309.13167"}, {"metadata": {"arXiv": "2309.13179", "Date": "Fri, 22 Sep 2023 20:52:50 ", "Title": "Enhancing Multi-Objective Optimization through Machine Learning-Supported Multiphysics Simulation", "Authors": ["Diego Botache", "Jens Decke", "Winfried Ripken", "Abhinay Dornipati", "Franz G\\\"otz-Hahn", "Mohamed Ayeb", "Bernhard Sick"], "Categories": "cs.LG math.OC"}, "abstract": "Multiphysics simulations that involve multiple coupled physical phenomena quickly become computationally expensive. This imposes challenges for practitioners aiming to find optimal configurations for these problems satisfying multiple objectives, as optimization algorithms often require querying the simulation many times. This paper presents a methodological framework for training, self-optimizing, and self-organizing surrogate models to approximate and speed up Multiphysics simulations. We generate two real-world tabular datasets, which we make publicly available, and show that surrogate models can be trained on relatively small amounts of data to approximate the underlying simulations accurately. We conduct extensive experiments combining four machine learning and deep learning algorithms with two optimization algorithms and a comprehensive evaluation strategy. Finally, we evaluate the performance of our combined training and optimization pipeline by verifying the generated Pareto-optimal results using the ground truth simulations. We also employ explainable AI techniques to analyse our surrogates and conduct a preselection strategy to determine the most relevant features in our real-world examples. This approach lets us understand the underlying problem and identify critical partial dependencies.", "url": "https://arxiv.org/abs/2309.13179"}, {"metadata": {"arXiv": "2309.13185", "Date": "Fri, 22 Sep 2023 21:20:41 ", "Title": "Visualizing Topological Importance: A Class-Driven Approach", "Authors": ["Yu Qin and Brittany Terese Fasy and Carola Wenk and Brian Summa"], "Categories": "cs.LG", "Comments": ["11 pages", "11 figures"]}, "abstract": "This paper presents the first approach to visualize the importance of topological features that define classes of data. Topological features, with their ability to abstract the fundamental structure of complex data, are an integral component of visualization and analysis pipelines. Although not all topological features present in data are of equal importance. To date, the default definition of feature importance is often assumed and fixed. This work shows how proven explainable deep learning approaches can be adapted for use in topological classification. In doing so, it provides the first technique that illuminates what topological structures are important in each dataset in regards to their class label. In particular, the approach uses a learned metric classifier with a density estimator of the points of a persistence diagram as input. This metric learns how to reweigh this density such that classification accuracy is high. By extracting this weight, an importance field on persistent point density can be created. This provides an intuitive representation of persistence point importance that can be used to drive new visualizations. This work provides two examples: Visualization on each diagram directly and, in the case of sublevel set filtrations on images, directly on the images themselves. This work highlights real-world examples of this approach visualizing the important topological features in graph, 3D shape, and medical image data.", "url": "https://arxiv.org/abs/2309.13185"}, {"metadata": {"arXiv": "2309.13190", "Date": "Fri, 22 Sep 2023 21:35:32 ", "Title": "Spatial-frequency channels, shape bias, and adversarial robustness", "Authors": ["Ajay Subramanian", "Elena Sizikova", "Najib J. Majaj", "Denis G. Pelli"], "Categories": "cs.LG cs.CV eess.IV", "Comments": ["Accepted to Neural Information Processing Systems (NeurIPS) 2023 (Oral Presentation)"]}, "abstract": "What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or \"channel'') that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. On the other hand, the neural network channel, across various architectures and training strategies, is 2-4 times as wide as the human channel. In other words, networks are vulnerable to high and low frequency noise that does not affect human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (53% variance explained) and with robustness of adversarially-trained networks (74% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further away from the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only increases this difference.", "url": "https://arxiv.org/abs/2309.13190"}, {"metadata": {"arXiv": "2309.13194", "Date": "Fri, 22 Sep 2023 21:57:52 ", "Title": "Federated Short-Term Load Forecasting with Personalization Layers for Heterogeneous Clients", "Authors": ["Shourya Bose and Kibaek Kim"], "Categories": "cs.LG"}, "abstract": "The advent of smart meters has enabled pervasive collection of energy consumption data for training short-term load forecasting (STLF) models. In response to privacy concerns, federated learning (FL) has been proposed as a privacy-preserving approach for training, but the quality of trained models degrades as client data becomes heterogeneous. In this paper we alleviate this drawback using personalization layers, wherein certain layers of an STLF model in an FL framework are trained exclusively on the clients' own data. To that end, we propose a personalized FL algorithm (PL-FL) enabling FL to handle personalization layers. The PL-FL algorithm is implemented by using the Argonne Privacy-Preserving Federated Learning package. We test the forecast performance of models trained on the NREL ComStock dataset, which contains heterogeneous energy consumption data of multiple commercial buildings. Superior performance of models trained with PL-FL demonstrates that personalization layers enable classical FL algorithms to handle clients with heterogeneous data.", "url": "https://arxiv.org/abs/2309.13194"}, {"metadata": {"arXiv": "2309.13207", "Date": "Fri, 22 Sep 2023 23:04:51 ", "Title": "Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications", "Authors": ["John S. Schreck", "David John Gagne II", "Charlie Becker", "William E. Chapman", "Kim Elmore", "Gabrielle Gantos", "Eliot Kim", "Dhamma Kimpara", "Thomas Martin", "Maria J. Molina", "Vanessa M. Pryzbylo", "Jacob Radford", "Belen Saavedra", "Justin Willson", "Christopher Wirz"], "Categories": "cs.LG"}, "abstract": "Robust quantification of predictive uncertainty is critical for understanding factors that drive weather and climate outcomes. Ensembles provide predictive uncertainty estimates and can be decomposed physically, but both physics and machine learning ensembles are computationally expensive. Parametric deep learning can estimate uncertainty with one model by predicting the parameters of a probability distribution but do not account for epistemic uncertainty.. Evidential deep learning, a technique that extends parametric deep learning to higher-order distributions, can account for both aleatoric and epistemic uncertainty with one model. This study compares the uncertainty derived from evidential neural networks to those obtained from ensembles. Through applications of classification of winter precipitation type and regression of surface layer fluxes, we show evidential deep learning models attaining predictive accuracy rivaling standard methods, while robustly quantifying both sources of uncertainty. We evaluate the uncertainty in terms of how well the predictions are calibrated and how well the uncertainty correlates with prediction error. Analyses of uncertainty in the context of the inputs reveal sensitivities to underlying meteorological processes, facilitating interpretation of the models. The conceptual simplicity, interpretability, and computational efficiency of evidential neural networks make them highly extensible, offering a promising approach for reliable and practical uncertainty quantification in Earth system science modeling. In order to encourage broader adoption of evidential deep learning in Earth System Science, we have developed a new Python package, MILES-GUESS (https://github.com/ai2es/miles-guess), that enables users to train and evaluate both evidential and ensemble deep learning.", "url": "https://arxiv.org/abs/2309.13207"}, {"metadata": {"arXiv": "2309.13227", "Date": "Sat, 23 Sep 2023 01:11:15 ", "Title": "Importance of negative sampling in weak label learning", "Authors": ["Ankit Shah", "Fuyu Tang", "Zelin Ye", "Rita Singh", "Bhiksha Raj"], "Categories": "cs.LG cs.SD eess.AS"}, "abstract": "Weak-label learning is a challenging task that requires learning from data \"bags\" containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.", "url": "https://arxiv.org/abs/2309.13227"}, {"metadata": {"arXiv": "2309.13254", "Date": "Sat, 23 Sep 2023 04:32:48 ", "Title": "Zen: Near-Optimal Sparse Tensor Synchronization for Distributed DNN Training", "Authors": ["Zhuang Wang", "Zhaozhuo Xu", "Anshumali Shrivastava", "T. S. Eugene Ng"], "Categories": "cs.LG cs.DC"}, "abstract": "Distributed training is the de facto standard to scale up the training of Deep Neural Networks (DNNs) with multiple GPUs. The performance bottleneck of distributed training lies in communications for gradient synchronization. Recently, practitioners have observed sparsity in gradient tensors, suggesting the potential to reduce the traffic volume in communication and improve end-to-end training efficiency. Yet, the optimal communication scheme to fully leverage sparsity is still missing. This paper aims to address this gap. We first analyze the characteristics of sparse tensors in popular DNN models to understand the fundamentals of sparsity. We then systematically explore the design space of communication schemes for sparse tensors and find the optimal one. % We then find the optimal scheme based on the characteristics by systematically exploring the design space. We also develop a gradient synchronization system called Zen that approximately realizes it for sparse tensors. We demonstrate that Zen can achieve up to 5.09x speedup in communication time and up to 2.48x speedup in training throughput compared to the state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.13254"}, {"metadata": {"arXiv": "2309.13292", "Date": "Sat, 23 Sep 2023 07:23:44 ", "Title": "Beyond Fairness: Age-Harmless Parkinson's Detection via Voice", "Authors": ["Yicheng Wang", "Xiaotian Han", "Leisheng Yu", "Na Zou"], "Categories": "cs.LG cs.CY cs.SD eess.AS"}, "abstract": "Parkinson's disease (PD), a neurodegenerative disorder, often manifests as speech and voice dysfunction. While utilizing voice data for PD detection has great potential in clinical applications, the widely used deep learning models currently have fairness issues regarding different ages of onset. These deep models perform well for the elderly group (age $>$ 55) but are less accurate for the young group (age $\\leq$ 55). Through our investigation, the discrepancy between the elderly and the young arises due to 1) an imbalanced dataset and 2) the milder symptoms often seen in early-onset patients. However, traditional debiasing methods are impractical as they typically impair the prediction accuracy for the majority group while minimizing the discrepancy. To address this issue, we present a new debiasing method using GradCAM-based feature masking combined with ensemble models, ensuring that neither fairness nor accuracy is compromised. Specifically, the GradCAM-based feature masking selectively obscures age-related features in the input voice data while preserving essential information for PD detection. The ensemble models further improve the prediction accuracy for the minority (young group). Our approach effectively improves detection accuracy for early-onset patients without sacrificing performance for the elderly group. Additionally, we propose a two-step detection strategy for the young group, offering a practical risk assessment for potential early-onset PD patients.", "url": "https://arxiv.org/abs/2309.13292"}, {"metadata": {"arXiv": "2309.13303", "Date": "Sat, 23 Sep 2023 08:33:48 ", "Title": "C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior", "Authors": ["Zhangkai Wu and Longbing Cao"], "Categories": "cs.LG cs.CV stat.ML"}, "abstract": "We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together with the TC loss for eliminating entangled factors and strengthening disentangled representations. C$^2$VAE demonstrates a strong effect in enhancing disentangled representation learning. C$^2$VAE further contributes to improved optimization addressing the TC-based VAE instability and the trade-off between reconstruction and representation.", "url": "https://arxiv.org/abs/2309.13303"}, {"metadata": {"arXiv": "2309.13307", "Date": "Sat, 23 Sep 2023 08:45:27 ", "Title": "CORE: Common Random Reconstruction for Distributed Optimization with Provable Low Communication Complexity", "Authors": ["Pengyun Yue", "Hanzhen Zhao", "Cong Fang", "Di He", "Liwei Wang", "Zhouchen Lin", "Song-chun Zhu"], "Categories": "cs.LG"}, "abstract": "With distributed machine learning being a prominent technique for large-scale machine learning tasks, communication complexity has become a major bottleneck for speeding up training and scaling up machine numbers. In this paper, we propose a new technique named Common randOm REconstruction(CORE), which can be used to compress the information transmitted between machines in order to reduce communication complexity without other strict conditions. Especially, our technique CORE projects the vector-valued information to a low-dimensional one through common random vectors and reconstructs the information with the same random noises after communication. We apply CORE to two distributed tasks, respectively convex optimization on linear models and generic non-convex optimization, and design new distributed algorithms, which achieve provably lower communication complexities. For example, we show for linear models CORE-based algorithm can encode the gradient vector to $\\mathcal{O}(1)$-bits (against $\\mathcal{O}(d)$), with the convergence rate not worse, preceding the existing results.", "url": "https://arxiv.org/abs/2309.13307"}, {"metadata": {"arXiv": "2309.13310", "Date": "Sat, 23 Sep 2023 08:54:10 ", "Title": "An Interpretable Systematic Review of Machine Learning Models for Predictive Maintenance of Aircraft Engine", "Authors": ["Abdullah Al Hasib", "Ashikur Rahman", "Mahpara Khabir and Md. Tanvir Rouf Shawon"], "Categories": "cs.LG"}, "abstract": "This paper presents an interpretable review of various machine learning and deep learning models to predict the maintenance of aircraft engine to avoid any kind of disaster. One of the advantages of the strategy is that it can work with modest datasets. In this study, sensor data is utilized to predict aircraft engine failure within a predetermined number of cycles using LSTM, Bi-LSTM, RNN, Bi-RNN GRU, Random Forest, KNN, Naive Bayes, and Gradient Boosting. We explain how deep learning and machine learning can be used to generate predictions in predictive maintenance using a straightforward scenario with just one data source. We applied lime to the models to help us understand why machine learning models did not perform well than deep learning models. An extensive analysis of the model's behavior is presented for several test data to understand the black box scenario of the models. A lucrative accuracy of 97.8%, 97.14%, and 96.42% are achieved by GRU, Bi-LSTM, and LSTM respectively which denotes the capability of the models to predict maintenance at an early stage.", "url": "https://arxiv.org/abs/2309.13310"}, {"metadata": {"arXiv": "2309.13330", "Date": "Sat, 23 Sep 2023 10:23:00 ", "Title": "Predicting Temperature of Major Cities Using Machine Learning and Deep Learning", "Authors": ["Wasiou Jaharabi", "MD Ibrahim Al Hossain", "Rownak Tahmid", "Md. Zuhayer Islam", "T.M. Saad Rayhan"], "Categories": "cs.LG", "Comments": ["15 pages", "31 figures"]}, "abstract": "Currently, the issue that concerns the world leaders most is climate change for its effect on agriculture, environment and economies of daily life. So, to combat this, temperature prediction with strong accuracy is vital. So far, the most effective widely used measure for such forecasting is Numerical weather prediction (NWP) which is a mathematical model that needs broad data from different applications to make predictions. This expensive, time and labor consuming work can be minimized through making such predictions using Machine learning algorithms. Using the database made by University of Dayton which consists the change of temperature in major cities we used the Time Series Analysis method where we use LSTM for the purpose of turning existing data into a tool for future prediction. LSTM takes the long-term data as well as any short-term exceptions or anomalies that may have occurred and calculates trend, seasonality and the stationarity of a data. By using models such as ARIMA, SARIMA, Prophet with the concept of RNN and LSTM we can, filter out any abnormalities, preprocess the data compare it with previous trends and make a prediction of future trends. Also, seasonality and stationarity help us analyze the reoccurrence or repeat over one year variable and removes the constrain of time in which the data was dependent so see the general changes that are predicted. By doing so we managed to make prediction of the temperature of different cities during any time in future based on available data and built a method of accurate prediction. This document contains our methodology for being able to make such predictions.", "url": "https://arxiv.org/abs/2309.13330"}, {"metadata": {"arXiv": "2309.13337", "Date": "Sat, 23 Sep 2023 11:18:13 ", "Title": "On the Asymptotic Learning Curves of Kernel Ridge Regression under Power-law Decay", "Authors": ["Yicheng Li", "Haobo Zhang", "Qian Lin"], "Categories": "cs.LG math.ST stat.TH"}, "abstract": "The widely observed 'benign overfitting phenomenon' in the neural network literature raises the challenge to the 'bias-variance trade-off' doctrine in the statistical learning theory. Since the generalization ability of the 'lazy trained' over-parametrized neural network can be well approximated by that of the neural tangent kernel regression, the curve of the excess risk (namely, the learning curve) of kernel ridge regression attracts increasing attention recently. However, most recent arguments on the learning curve are heuristic and are based on the 'Gaussian design' assumption. In this paper, under mild and more realistic assumptions, we rigorously provide a full characterization of the learning curve: elaborating the effect and the interplay of the choice of the regularization parameter, the source condition and the noise. In particular, our results suggest that the 'benign overfitting phenomenon' exists in very wide neural networks only when the noise level is small.", "url": "https://arxiv.org/abs/2309.13337"}, {"metadata": {"arXiv": "2309.13361", "Date": "Sat, 23 Sep 2023 12:54:38 ", "Title": "Machine Learning with Chaotic Strange Attractors", "Authors": ["Bahad{\\i}r Utku Kesgin and U\\u{g}ur Te\\u{g}in"], "Categories": "cs.LG", "Comments": ["Manuscript is 13 pages", "4 figures. Supplementary Material is 6 pages", "3 figures"]}, "abstract": "Machine learning studies need colossal power to process massive datasets and train neural networks to reach high accuracies, which have become gradually unsustainable. Limited by the von Neumann bottleneck, current computing architectures and methods fuel this high power consumption. Here, we present an analog computing method that harnesses chaotic nonlinear attractors to perform machine learning tasks with low power consumption. Inspired by neuromorphic computing, our model is a programmable, versatile, and generalized platform for machine learning tasks. Our mode provides exceptional performance in clustering by utilizing chaotic attractors' nonlinear mapping and sensitivity to initial conditions. When deployed as a simple analog device, it only requires milliwatt-scale power levels while being on par with current machine learning techniques. We demonstrate low errors and high accuracies with our model for regression and classification-based learning tasks.", "url": "https://arxiv.org/abs/2309.13361"}, {"metadata": {"arXiv": "2309.13377", "Date": "Sat, 23 Sep 2023 13:46:49 ", "Title": "Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head", "Authors": ["Alan Q. Wang", "Minh Nguyen", "Mert R. Sabuncu"], "Categories": "cs.LG", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Machine learning models will often fail when deployed in an environment with a data distribution that is different than the training distribution. When multiple environments are available during training, many methods exist that learn representations which are invariant across the different distributions, with the hope that these representations will be transportable to unseen domains. In this work, we present a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head. The NW head makes a prediction by comparing the learned representations of the query to the elements of a support set that consists of labeled data. We demonstrate that by manipulating the support set, one can encode different causal assumptions. In particular, restricting the support set to a single environment encourages the model to learn invariant features that do not depend on the environment. We present a causally-motivated setup for our modeling and training strategy and validate on three challenging real-world domain generalization tasks in computer vision.", "url": "https://arxiv.org/abs/2309.13377"}, {"metadata": {"arXiv": "2309.13402", "Date": "Sat, 23 Sep 2023 15:27:14 ", "Title": "ML Algorithm Synthesizing Domain Knowledge for Fungal Spores Concentration Prediction", "Authors": ["Md Asif Bin Syed", "Azmine Toushik Wasi and Imtiaz Ahmed"], "Categories": "cs.LG"}, "abstract": "The pulp and paper manufacturing industry requires precise quality control to ensure pure, contaminant-free end products suitable for various applications. Fungal spore concentration is a crucial metric that affects paper usability, and current testing methods are labor-intensive with delayed results, hindering real-time control strategies. To address this, a machine learning algorithm utilizing time-series data and domain knowledge was proposed. The optimal model employed Ridge Regression achieving an MSE of 2.90 on training and validation data. This approach could lead to significant improvements in efficiency and sustainability by providing real-time predictions for fungal spore concentrations. This paper showcases a promising method for real-time fungal spore concentration prediction, enabling stringent quality control measures in the pulp-and-paper industry.", "url": "https://arxiv.org/abs/2309.13402"}, {"metadata": {"arXiv": "2309.13405", "Date": "Sat, 23 Sep 2023 15:30:34 ", "Title": "Learning Large-Scale MTP2 Gaussian Graphical Models via Bridge-Block Decomposition", "Authors": ["Xiwen Wang", "Jiaxi Ying", "Daniel P. Palomar"], "Categories": "cs.LG eess.SP"}, "abstract": "This paper studies the problem of learning the large-scale Gaussian graphical models that are multivariate totally positive of order two ($\\text{MTP}_2$). By introducing the concept of bridge, which commonly exists in large-scale sparse graphs, we show that the entire problem can be equivalently optimized through (1) several smaller-scaled sub-problems induced by a \\emph{bridge-block decomposition} on the thresholded sample covariance graph and (2) a set of explicit solutions on entries corresponding to \\emph{bridges}. From practical aspect, this simple and provable discipline can be applied to break down a large problem into small tractable ones, leading to enormous reduction on the computational complexity and substantial improvements for all existing algorithms. The synthetic and real-world experiments demonstrate that our proposed method presents a significant speed-up compared to the state-of-the-art benchmarks.", "url": "https://arxiv.org/abs/2309.13405"}, {"metadata": {"arXiv": "2309.13415", "Date": "Sat, 23 Sep 2023 15:58:27 ", "Title": "Dream the Impossible: Outlier Imagination with Diffusion Models", "Authors": ["Xuefeng Du", "Yiyou Sun", "Xiaojin Zhu", "Yixuan Li"], "Categories": "cs.LG cs.CV", "Comments": ["NeurIPS 2023"]}, "abstract": "Utilizing auxiliary outlier datasets to regularize the machine learning model has demonstrated promise for out-of-distribution (OOD) detection and safe prediction. Due to the labor intensity in data collection and cleaning, automating outlier data generation has been a long-desired alternative. Despite the appeal, generating photo-realistic outliers in the high dimensional pixel space has been an open challenge for the field. To tackle the problem, this paper proposes a new framework DREAM-OOD, which enables imagining photo-realistic outliers by way of diffusion models, provided with only the in-distribution (ID) data and classes. Specifically, DREAM-OOD learns a text-conditioned latent space based on ID data, and then samples outliers in the low-likelihood region via the latent, which can be decoded into images by the diffusion model. Different from prior works, DREAM-OOD enables visualizing and understanding the imagined outliers, directly in the pixel space. We conduct comprehensive quantitative and qualitative studies to understand the efficacy of DREAM-OOD, and show that training with the samples generated by DREAM-OOD can benefit OOD detection performance. Code is publicly available at https://github.com/deeplearning-wisc/dream-ood.", "url": "https://arxiv.org/abs/2309.13415"}, {"metadata": {"arXiv": "2309.13420", "Date": "Sat, 23 Sep 2023 16:18:00 ", "Title": "DenMune: Density peak based clustering using mutual nearest neighbors", "Authors": ["Mohamed Abbas", "Adel El-Zoghobi", "Amin Shoukry"], "Categories": "cs.LG", "Comments": ["pyMune is a Python package that implements this clustering algorithm proposed in this paper", "DenMune. It is opensource and reproducible", "doi:10.1016/j.simpa.2023.100564"], "Journal-ref": "Pattern Recognition 109 (2021) 107589", "DOI": "10.1016/j.patcog.2020.107589"}, "abstract": "Many clustering algorithms fail when clusters are of arbitrary shapes, of varying densities, or the data classes are unbalanced and close to each other, even in two dimensions. A novel clustering algorithm, DenMune is presented to meet this challenge. It is based on identifying dense regions using mutual nearest neighborhoods of size K, where K is the only parameter required from the user, besides obeying the mutual nearest neighbor consistency principle. The algorithm is stable for a wide range of values of K. Moreover, it is able to automatically detect and remove noise from the clustering process as well as detecting the target clusters. It produces robust results on various low and high-dimensional datasets relative to several known state-of-the-art clustering algorithms.", "url": "https://arxiv.org/abs/2309.13420"}, {"metadata": {"arXiv": "2309.13425", "Date": "Sat, 23 Sep 2023 16:32:36 ", "Title": "MiliPoint: A Point Cloud Dataset for mmWave Radar", "Authors": ["Han Cui", "Shu Zhong", "Jiacheng Wu", "Zichao Shen", "Naim Dahnoun", "Yiren Zhao"], "Categories": "cs.LG"}, "abstract": "Millimetre-wave (mmWave) radar has emerged as an attractive and cost-effective alternative for human activity sensing compared to traditional camera-based systems. mmWave radars are also non-intrusive, providing better protection for user privacy. However, as a Radio Frequency (RF) based technology, mmWave radars rely on capturing reflected signals from objects, making them more prone to noise compared to cameras. This raises an intriguing question for the deep learning community: Can we develop more effective point set-based deep learning methods for such attractive sensors? To answer this question, our work, termed MiliPoint, delves into this idea by providing a large-scale, open dataset for the community to explore how mmWave radars can be utilised for human activity recognition. Moreover, MiliPoint stands out as it is larger in size than existing datasets, has more diverse human actions represented, and encompasses all three key tasks in human activity recognition. We have also established a range of point-based deep neural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint, which can serve to set the ground baseline for further development.", "url": "https://arxiv.org/abs/2309.13425"}, {"metadata": {"arXiv": "2309.13443", "Date": "Sat, 23 Sep 2023 18:12:27 ", "Title": "Early Classification for Dynamic Inference of Neural Networks", "Authors": ["Jingcun Wang", "Bing Li", "Grace Li Zhang"], "Categories": "cs.LG"}, "abstract": "Deep neural networks (DNNs) have been successfully applied in various fields. In DNNs, a large number of multiply-accumulate (MAC) operations is required to be performed, posing critical challenges in applying them in resource-constrained platforms, e.g., edge devices. Dynamic neural networks have been introduced to allow a structural adaption, e.g., early-exit, according to different inputs to reduce the computational cost of DNNs. Existing early-exit techniques deploy classifiers at intermediate layers of DNNs to push them to make a classification decision as early as possible. However, the learned features at early layers might not be sufficient to exclude all the irrelevant classes and decide the correct class, leading to suboptimal results. To address this challenge, in this paper, we propose a class-based early-exit for dynamic inference. Instead of pushing DNNs to make a dynamic decision at intermediate layers, we take advantages of the learned features in these layers to exclude as many irrelevant classes as possible, so that later layers only have to determine the target class among the remaining classes. Until at a layer only one class remains, this class is the corresponding classification result. To realize this class-based exclusion, we assign each class with a classifier at intermediate layers and train the networks together with these classifiers. Afterwards, an exclusion strategy is developed to exclude irrelevant classes at early layers. Experimental results demonstrate the computational cost of DNNs in inference can be reduced significantly.", "url": "https://arxiv.org/abs/2309.13443"}, {"metadata": {"arXiv": "2309.13452", "Date": "Sat, 23 Sep 2023 18:40:10 ", "Title": "Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data", "Authors": ["Zhichao Chen", "Leilei Ding", "Zhixuan Chu", "Yucheng Qi", "Jianmin Huang", "Hao Wang"], "Categories": "cs.LG", "Comments": ["Accepted as CIKM'23 Applied Research Track"], "DOI": "10.1145/3583780.3615487"}, "abstract": "Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem in decision-making across various industrial scenarios. However, existing time-series forecasting methods often overlook two important characteristics of cumulative data, namely monotonicity and irregularity, which limit their practical applicability. To address this limitation, we propose a principled approach called Monotonic neural Ordinary Differential Equation (MODE) within the framework of neural ordinary differential equations. By leveraging MODE, we are able to effectively capture and represent the monotonicity and irregularity in practical cumulative data. Through extensive experiments conducted in a bonus allocation scenario, we demonstrate that MODE outperforms state-of-the-art methods, showcasing its ability to handle both monotonicity and irregularity in cumulative data and delivering superior forecasting performance.", "url": "https://arxiv.org/abs/2309.13452"}, {"metadata": {"arXiv": "2309.13457", "Date": "Sat, 23 Sep 2023 18:57:02 ", "Title": "Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data", "Authors": ["Wai Tong Chung", "Bassem Akoush", "Pushan Sharma", "Alex Tamkin", "Ki Sung Jung", "Jacqueline Chen", "Jack Guo", "Davy Brouzet", "Mohsen Talei", "Bruno Savard", "Alexei Y Poludnenko", "Matthias Ihme"], "Categories": "cs.LG cs.CV physics.comp-ph physics.flu-dyn", "Comments": ["Accepted in Advances in Neural Information Processing Systems 36 (NeurIPS 2023). Keywords: Super-resolution", "3D", "Neural Scaling", "Physics-informed Loss", "Computational Fluid Dynamics", "Partial Differential Equations", "Turbulent Reacting Flows", "Direct Numerical Simulation", "Fluid Mechanics", "Combustion. 55 pages", "21 figures"]}, "abstract": "Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution - which can be applied for improving scientific imaging, simulations, turbulence models, as well as in computer vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size. The outcomes of this benchmark study are anticipated to offer insights that can aid the design of 3D super-resolution models, especially for turbulence models, while this data is expected to foster ML methods for a broad range of flow physics applications. This data is publicly available with download links and browsing tools consolidated at https://blastnet.github.io.", "url": "https://arxiv.org/abs/2309.13457"}, {"metadata": {"arXiv": "2309.13482", "Date": "Sat, 23 Sep 2023 21:41:01 ", "Title": "A Unified Scheme of ResNet and Softmax", "Authors": ["Zhao Song", "Weixin Wang", "Junze Yin"], "Categories": "cs.LG stat.ML"}, "abstract": "Large language models (LLMs) have brought significant changes to human society. Softmax regression and residual neural networks (ResNet) are two important techniques in deep learning: they not only serve as significant theoretical components supporting the functionality of LLMs but also are related to many other machine learning and theoretical computer science fields, including but not limited to image classification, object detection, semantic segmentation, and tensors. Previous research works studied these two concepts separately. In this paper, we provide a theoretical analysis of the regression problem: $\\| \\langle \\exp(Ax) + A x , {\\bf 1}_n \\rangle^{-1} ( \\exp(Ax) + Ax ) - b \\|_2^2$, where $A$ is a matrix in $\\mathbb{R}^{n \\times d}$, $b$ is a vector in $\\mathbb{R}^n$, and ${\\bf 1}_n$ is the $n$-dimensional vector whose entries are all $1$. This regression problem is a unified scheme that combines softmax regression and ResNet, which has never been done before. We derive the gradient, Hessian, and Lipschitz properties of the loss function. The Hessian is shown to be positive semidefinite, and its structure is characterized as the sum of a low-rank matrix and a diagonal matrix. This enables an efficient approximate Newton method. As a result, this unified scheme helps to connect two previously thought unrelated fields and provides novel insight into loss landscape and optimization for emerging over-parameterized neural networks, which is meaningful for future research in deep learning models.", "url": "https://arxiv.org/abs/2309.13482"}, {"metadata": {"arXiv": "2309.13536", "Date": "Sun, 24 Sep 2023 03:19:40 ", "Title": "Tackling the Unlimited Staleness in Federated Learning with Intertwined Data and Device Heterogeneities", "Authors": ["Haoming Wang and Wei Gao"], "Categories": "cs.LG cs.DC", "Comments": ["14 pages"]}, "abstract": "The efficiency of Federated Learning (FL) is often affected by both data and device heterogeneities. Data heterogeneity is defined as the heterogeneity of data distributions on different clients. Device heterogeneity is defined as the clients' variant latencies in uploading their local model updates due to heterogeneous conditions of local hardware resources, and causes the problem of staleness when being addressed by asynchronous FL. Traditional schemes of tackling the impact of staleness consider data and device heterogeneities as two separate and independent aspects in FL, but this assumption is unrealistic in many practical FL scenarios where data and device heterogeneities are intertwined. In these cases, traditional schemes of weighted aggregation in FL have been proved to be ineffective, and a better approach is to convert a stale model update into a non-stale one. In this paper, we present a new FL framework that leverages the gradient inversion technique for such conversion, hence efficiently tackling unlimited staleness in clients' model updates. Our basic idea is to use gradient inversion to get estimations of clients' local training data from their uploaded stale model updates, and use these estimations to compute non-stale client model updates. In this way, we address the problem of possible data quality drop when using gradient inversion, while still preserving the clients' local data privacy. We compared our approach with the existing FL strategies on mainstream datasets and models, and experiment results demonstrate that when tackling unlimited staleness, our approach can significantly improve the trained model accuracy by up to 20% and speed up the FL training progress by up to 35%.", "url": "https://arxiv.org/abs/2309.13536"}, {"metadata": {"arXiv": "2309.13591", "Date": "Sun, 24 Sep 2023 09:29:28 ", "Title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity", "Authors": ["Youssef Allouah", "Rachid Guerraoui", "Nirupam Gupta", "Rafa\\\"el Pinot", "Geovani Rizk"], "Categories": "cs.LG cs.DC math.OC", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "The theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. Under data heterogeneity however, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction 1/2. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice.", "url": "https://arxiv.org/abs/2309.13591"}, {"metadata": {"arXiv": "2309.13618", "Date": "Sun, 24 Sep 2023 12:18:37 ", "Title": "Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions", "Authors": ["Dongjie Wang and Meng Xiao and Min Wu and Pengfei Wang and Yuanchun Zhou and Yanjie Fu"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Feature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifices stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space.", "url": "https://arxiv.org/abs/2309.13618"}, {"metadata": {"arXiv": "2309.13643", "Date": "Sun, 24 Sep 2023 14:04:30 ", "Title": "REWAFL: Residual Energy and Wireless Aware Participant Selection for Efficient Federated Learning over Mobile Devices", "Authors": ["Y. Li", "X. Qin", "J. Geng", "R. Chen", "Y. Hou", "Y. Gong", "M. Pan", "P. Zhang"], "Categories": "cs.LG cs.NI"}, "abstract": "Participant selection (PS) helps to accelerate federated learning (FL) convergence, which is essential for the practical deployment of FL over mobile devices. While most existing PS approaches focus on improving training accuracy and efficiency rather than residual energy of mobile devices, which fundamentally determines whether the selected devices can participate. Meanwhile, the impacts of mobile devices' heterogeneous wireless transmission rates on PS and FL training efficiency are largely ignored. Moreover, PS causes the staleness issue. Prior research exploits isolated functions to force long-neglected devices to participate, which is decoupled from original PS designs. In this paper, we propose a residual energy and wireless aware PS design for efficient FL training over mobile devices (REWAFL). REW AFL introduces a novel PS utility function that jointly considers global FL training utilities and local energy utility, which integrates energy consumption and residual battery energy of candidate mobile devices. Under the proposed PS utility function framework, REW AFL further presents a residual energy and wireless aware local computing policy. Besides, REWAFL buries the staleness solution into its utility function and local computing policy. The experimental results show that REW AFL is effective in improving training accuracy and efficiency, while avoiding \"flat battery\" of mobile devices.", "url": "https://arxiv.org/abs/2309.13643"}, {"metadata": {"arXiv": "2309.13657", "Date": "Sun, 24 Sep 2023 14:51:53 ", "Title": "A Probabilistic Model for Data Redundancy in the Feature Domain", "Authors": ["Ghurumuruhan Ganesan"], "Categories": "cs.LG math.CO"}, "abstract": "In this paper, we use a probabilistic model to estimate the number of uncorrelated features in a large dataset. Our model allows for both pairwise feature correlation (collinearity) and interdependency of multiple features (multicollinearity) and we use the probabilistic method to obtain upper and lower bounds of the same order, for the size of a feature set that exhibits low collinearity and low multicollinearity. We also prove an auxiliary result regarding mutually good constrained sets that is of independent interest.", "url": "https://arxiv.org/abs/2309.13657"}, {"metadata": {"arXiv": "2309.13658", "Date": "Sun, 24 Sep 2023 14:53:51 ", "Title": "Fantastic Generalization Measures are Nowhere to be Found", "Authors": ["Michael Gastpar", "Ido Nachum", "Jonathan Shafer", "Thomas Weinberger"], "Categories": "cs.LG cs.NE stat.ML"}, "abstract": "Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, none of these bounds are tight. For instance, in their paper ``Fantastic Generalization Measures and Where to Find Them'', Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them imply guarantees that can explain the remarkable performance of neural networks. This raises the question of whether tight generalization bounds are at all possible. We consider two types of generalization bounds common in the literature: (1) bounds that depend on the training set and the output of the learning algorithm. There are multiple bounds of this type in the literature (e.g., norm-based and margin-based bounds), but we prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that depend on the training set and on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm's performance and the bound's tightness. Namely, if the algorithm achieves good accuracy on certain distributions in the overparameterized setting, then no generalization bound can be tight for it. We conclude that generalization bounds in the overparameterized setting cannot be tight without suitable assumptions on the population distribution.", "url": "https://arxiv.org/abs/2309.13658"}, {"metadata": {"arXiv": "2309.13662", "Date": "Sun, 24 Sep 2023 15:11:58 ", "Title": "Topology-Agnostic Detection of Temporal Money Laundering Flows in Billion-Scale Transactions", "Authors": ["Haseeb Tariq", "Marwan Hassani"], "Categories": "cs.LG cs.SI q-fin.ST"}, "abstract": "Money launderers exploit the weaknesses in detection systems by purposefully placing their ill-gotten money into multiple accounts, at different banks. That money is then layered and moved around among mule accounts to obscure the origin and the flow of transactions. Consequently, the money is integrated into the financial system without raising suspicion. Path finding algorithms that aim at tracking suspicious flows of money usually struggle with scale and complexity. Existing community detection techniques also fail to properly capture the time-dependent relationships. This is particularly evident when performing analytics over massive transaction graphs. We propose a framework (called FaSTMAN), adapted for domain-specific constraints, to efficiently construct a temporal graph of sequential transactions. The framework includes a weighting method, using 2nd order graph representation, to quantify the significance of the edges. This method enables us to distribute complex queries on smaller and densely connected networks of flows. Finally, based on those queries, we can effectively identify networks of suspicious flows. We extensively evaluate the scalability and the effectiveness of our framework against two state-of-the-art solutions for detecting suspicious flows of transactions. For a dataset of over 1 Billion transactions from multiple large European banks, the results show a clear superiority of our framework both in efficiency and usefulness.", "url": "https://arxiv.org/abs/2309.13662"}, {"metadata": {"arXiv": "2309.13681", "Date": "Sun, 24 Sep 2023 16:08:21 ", "Title": "Accelerating Large Batch Training via Gradient Signal to Noise Ratio (GSNR)", "Authors": ["Guo-qing Jiang", "Jinlong Liu", "Zixiang Ding", "Lin Guo", "Wei Lin"], "Categories": "cs.LG", "Comments": ["25 pages", "5 figures"]}, "abstract": "As models for nature language processing (NLP), computer vision (CV) and recommendation systems (RS) require surging computation, a large number of GPUs/TPUs are paralleled as a large batch (LB) to improve training throughput. However, training such LB tasks often meets large generalization gap and downgrades final precision, which limits enlarging the batch size. In this work, we develop the variance reduced gradient descent technique (VRGD) based on the gradient signal to noise ratio (GSNR) and apply it onto popular optimizers such as SGD/Adam/LARS/LAMB. We carry out a theoretical analysis of convergence rate to explain its fast training dynamics, and a generalization analysis to demonstrate its smaller generalization gap on LB training. Comprehensive experiments demonstrate that VRGD can accelerate training ($1\\sim 2 \\times$), narrow generalization gap and improve final accuracy. We push the batch size limit of BERT pretraining up to 128k/64k and DLRM to 512k without noticeable accuracy loss. We improve ImageNet Top-1 accuracy at 96k by $0.52pp$ than LARS. The generalization gap of BERT and ImageNet training is significantly reduce by over $65\\%$.", "url": "https://arxiv.org/abs/2309.13681"}, {"metadata": {"arXiv": "2309.13692", "Date": "Sun, 24 Sep 2023 16:49:55 ", "Title": "Regularization and Optimal Multiclass Learning", "Authors": ["Julian Asilis", "Siddartha Devic", "Shaddin Dughmi", "Vatsal Sharan", "Shang-Hua Teng"], "Categories": "cs.LG stat.ML", "Comments": ["40 pages", "2 figures"]}, "abstract": "The quintessential learning algorithm of empirical risk minimization (ERM) is known to fail in various settings for which uniform convergence does not characterize learning. It is therefore unsurprising that the practice of machine learning is rife with considerably richer algorithmic techniques for successfully controlling model capacity. Nevertheless, no such technique or principle has broken away from the pack to characterize optimal learning in these more general settings. The purpose of this work is to characterize the role of regularization in perhaps the simplest setting for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true algorithmic principles: Occam's Razor as embodied by structural risk minimization (SRM), the principle of maximum entropy, and Bayesian reasoning. Most notably, we introduce an optimal learner which relaxes structural risk minimization on two dimensions: it allows the regularization function to be \"local\" to datapoints, and uses an unsupervised learning stage to learn this regularizer at the outset. We justify these relaxations by showing that they are necessary: removing either dimension fails to yield a near-optimal learner. We also extract from OIGs a combinatorial sequence we term the Hall complexity, which is the first to characterize a problem's transductive error rate exactly. Lastly, we introduce a generalization of OIGs and the transductive learning setting to the agnostic case, where we show that optimal orientations of Hamming graphs -- judged using nodes' outdegrees minus a system of node-dependent credits -- characterize optimal learners exactly. We demonstrate that an agnostic version of the Hall complexity again characterizes error rates exactly, and exhibit an optimal learner using maximum entropy programs.", "url": "https://arxiv.org/abs/2309.13692"}, {"metadata": {"arXiv": "2309.13697", "Date": "Sun, 24 Sep 2023 17:07:01 ", "Title": "Federated Deep Multi-View Clustering with Global Self-Supervision", "Authors": ["Xinyue Chen", "Jie Xu", "Yazhou Ren", "Xiaorong Pu", "Ce Zhu", "Xiaofeng Zhu", "Zhifeng Hao", "Lifang He"], "Categories": "cs.LG cs.MM"}, "abstract": "Federated multi-view clustering has the potential to learn a global clustering model from data distributed across multiple devices. In this setting, label information is unknown and data privacy must be preserved, leading to two major challenges. First, views on different clients often have feature heterogeneity, and mining their complementary cluster information is not trivial. Second, the storage and usage of data from multiple clients in a distributed environment can lead to incompleteness of multi-view data. To address these challenges, we propose a novel federated deep multi-view clustering method that can mine complementary cluster structures from multiple clients, while dealing with data incompleteness and privacy concerns. Specifically, in the server environment, we propose sample alignment and data extension techniques to explore the complementary cluster structures of multiple views. The server then distributes global prototypes and global pseudo-labels to each client as global self-supervised information. In the client environment, multiple clients use the global self-supervised information and deep autoencoders to learn view-specific cluster assignments and embedded features, which are then uploaded to the server for refining the global self-supervised information. Finally, the results of our extensive experiments demonstrate that our proposed method exhibits superior performance in addressing the challenges of incomplete multi-view data in distributed environments.", "url": "https://arxiv.org/abs/2309.13697"}, {"metadata": {"arXiv": "2309.13736", "Date": "Sun, 24 Sep 2023 19:40:15 ", "Title": "Geometry of Linear Neural Networks: Equivariance and Invariance under Permutation Groups", "Authors": ["Kathl\\'en Kohn", "Anna-Laura Sattelberger", "Vahid Shahverdi"], "Categories": "cs.LG math.AG", "Comments": ["24 pages", "2 figures", "comments welcome!"]}, "abstract": "The set of functions parameterized by a linear fully-connected neural network is a determinantal variety. We investigate the subvariety of functions that are equivariant or invariant under the action of a permutation group. Examples of such group actions are translations or $90^\\circ$ rotations on images. For such equivariant or invariant subvarieties, we provide an explicit description of their dimension, their degree as well as their Euclidean distance degree, and their singularities. We fully characterize invariance for arbitrary permutation groups, and equivariance for cyclic groups. We draw conclusions for the parameterization and the design of equivariant and invariant linear networks, such as a weight sharing property, and we prove that all invariant linear functions can be learned by linear autoencoders.", "url": "https://arxiv.org/abs/2309.13736"}, {"metadata": {"arXiv": "2309.13752", "Date": "Sun, 24 Sep 2023 21:04:56 ", "Title": "Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning", "Authors": ["Hongyan Zhou", "Yao Liang"], "Categories": "cs.LG"}, "abstract": "The current learning process of deep learning, regardless of any deep neural network (DNN) architecture and/or learning algorithm used, is essentially a single resolution training. We explore multiresolution learning and show that multiresolution learning can significantly improve robustness of DNN models for both 1D signal and 2D signal (image) prediction problems. We demonstrate this improvement in terms of both noise and adversarial robustness as well as with small training dataset size. Our results also suggest that it may not be necessary to trade standard accuracy for robustness with multiresolution learning, which is, interestingly, contrary to the observation obtained from the traditional single resolution learning setting.", "url": "https://arxiv.org/abs/2309.13752"}, {"metadata": {"arXiv": "2309.13770", "Date": "Sun, 24 Sep 2023 22:52:35 ", "Title": "Devil in the Number: Towards Robust Multi-modality Data Filter", "Authors": ["Yichen Xu", "Zihan Xu", "Wenhao Chai", "Zhonghan Zhao", "Enxin Song", "Gaoang Wang"], "Categories": "cs.LG cs.CV", "Comments": ["ICCV 2023 Workshop: TNGCV-DataComp"]}, "abstract": "In order to appropriately filter multi-modality data sets on a web-scale, it becomes crucial to employ suitable filtering methods to boost performance and reduce training costs. For instance, LAION papers employs the CLIP score filter to select data with CLIP scores surpassing a certain threshold. On the other hand, T-MARS achieves high-quality data filtering by detecting and masking text within images and then filtering by CLIP score. Through analyzing the dataset, we observe a significant proportion of redundant information, such as numbers, present in the textual content. Our experiments on a subset of the data unveil the profound impact of these redundant elements on the CLIP scores. A logical approach would involve reevaluating the CLIP scores after eliminating these influences. Experimentally, our text-based CLIP filter outperforms the top-ranked method on the ``small scale\" of DataComp (a data filtering benchmark) on ImageNet distribution shifts, achieving a 3.6% performance improvement. The results also demonstrate that our proposed text-masked filter outperforms the original CLIP score filter when selecting the top 40% of the data. The impact of numbers on CLIP and their handling provide valuable insights for improving the effectiveness of CLIP training, including language rewrite techniques.", "url": "https://arxiv.org/abs/2309.13770"}, {"metadata": {"arXiv": "2309.13775", "Date": "Sun, 24 Sep 2023 23:09:48 ", "Title": "The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance", "Authors": ["Jon Donnelly", "Srikar Katta", "Cynthia Rudin", "Edward P. Browne"], "Categories": "cs.LG q-bio.GN stat.ML", "Comments": ["To appear in NeurIPS 2023 as a spotlight paper"]}, "abstract": "Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We demonstrate through experiments that our framework recovers variable importance rankings for complex simulation setups where other methods fail. Further, we show that our framework accurately estimates the true importance of a variable for the underlying data distribution. We provide theoretical guarantees on the consistency and finite sample error rates for our estimator. Finally, we demonstrate its utility with a real-world case study exploring which genes are important for predicting HIV load in persons with HIV, highlighting an important gene that has not previously been studied in connection with HIV. Code is available here.", "url": "https://arxiv.org/abs/2309.13775"}, {"metadata": {"arXiv": "2309.13786", "Date": "Mon, 25 Sep 2023 00:31:55 ", "Title": "Distribution-Free Statistical Dispersion Control for Societal Applications", "Authors": ["Zhun Deng", "Thomas P. Zollo", "Jake C. Snell", "Toniann Pitassi", "Richard Zemel"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by NeurIPS as spotlight (top 3% among submissions)"]}, "abstract": "Explicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications, it is crucial to understand and control the dispersion of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation.", "url": "https://arxiv.org/abs/2309.13786"}, {"metadata": {"arXiv": "2309.13793", "Date": "Mon, 25 Sep 2023 01:03:45 ", "Title": "ReMasker: Imputing Tabular Data with Masked Autoencoding", "Authors": ["Tianyu Du", "Luca Melis", "Ting Wang"], "Categories": "cs.LG"}, "abstract": "We present ReMasker, a new method of imputing missing values in tabular data by extending the masked autoencoding framework. Compared with prior work, ReMasker is both simple -- besides the missing values (i.e., naturally masked), we randomly ``re-mask'' another set of values, optimize the autoencoder by reconstructing this re-masked set, and apply the trained model to predict the missing values; and effective -- with extensive evaluation on benchmark datasets, we show that ReMasker performs on par with or outperforms state-of-the-art methods in terms of both imputation fidelity and utility under various missingness settings, while its performance advantage often increases with the ratio of missing data. We further explore theoretical justification for its effectiveness, showing that ReMasker tends to learn missingness-invariant representations of tabular data. Our findings indicate that masked modeling represents a promising direction for further research on tabular data imputation. The code is publicly available.", "url": "https://arxiv.org/abs/2309.13793"}, {"metadata": {"arXiv": "2309.13794", "Date": "Mon, 25 Sep 2023 01:12:55 ", "Title": "Projected Randomized Smoothing for Certified Adversarial Robustness", "Authors": ["Samuel Pfrommer", "Brendon G. Anderson", "Somayeh Sojoudi"], "Categories": "cs.LG", "Comments": ["Transactions on Machine Learning Research (TMLR) 2023"]}, "abstract": "Randomized smoothing is the current state-of-the-art method for producing provably robust classifiers. While randomized smoothing typically yields robust $\\ell_2$-ball certificates, recent research has generalized provable robustness to different norm balls as well as anisotropic regions. This work considers a classifier architecture that first projects onto a low-dimensional approximation of the data manifold and then applies a standard classifier. By performing randomized smoothing in the low-dimensional projected space, we characterize the certified region of our smoothed composite classifier back in the high-dimensional input space and prove a tractable lower bound on its volume. We show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold and yet are captured by the certified regions of our method. We compare the volume of our certified regions against various baselines and show that our method improves on the state-of-the-art by many orders of magnitude.", "url": "https://arxiv.org/abs/2309.13794"}, {"metadata": {"arXiv": "2309.13807", "Date": "Mon, 25 Sep 2023 01:23:02 ", "Title": "Forecasting large collections of time series: feature-based methods", "Authors": ["Li Li", "Feng Li", "Yanfei Kang"], "Categories": "cs.LG"}, "abstract": "In economics and many other forecasting domains, the real world problems are too complex for a single model that assumes a specific data generation process. The forecasting performance of different methods changes depending on the nature of the time series. When forecasting large collections of time series, two lines of approaches have been developed using time series features, namely feature-based model selection and feature-based model combination. This chapter discusses the state-of-the-art feature-based methods, with reference to open-source software implementations.", "url": "https://arxiv.org/abs/2309.13807"}, {"metadata": {"arXiv": "2309.13837", "Date": "Mon, 25 Sep 2023 02:50:20 ", "Title": "Backorder Prediction in Inventory Management: Classification Techniques and Cost Considerations", "Authors": ["Sarit Maitra", "Sukanya Kundu"], "Categories": "cs.LG cs.IT math.IT", "Comments": ["8 pages", "4 figures", "IEEE (ICSEC 2023)"]}, "abstract": "This article introduces an advanced analytical approach for predicting backorders in inventory management. Backorder refers to an order that cannot be immediately fulfilled due to stock depletion. Multiple classification techniques, including Balanced Bagging Classifiers, Fuzzy Logic, Variational Autoencoder - Generative Adversarial Networks, and Multi-layer Perceptron classifiers, are assessed in this work using performance evaluation metrics such as ROC-AUC and PR-AUC. Moreover, this work incorporates a profit function and misclassification costs, considering the financial implications and costs associated with inventory management and backorder handling. The results demonstrate the effectiveness of the predictive model in enhancing inventory system service levels, which leads to customer satisfaction and overall organizational performance. Considering interpretability is a significant aspect of using AI in commercial applications, permutation importance is applied to the selected model to determine the importance of features. This research contributes to the advancement of predictive analytics and offers valuable insights for future investigations in backorder forecasting and inventory control optimization for decision-making.", "url": "https://arxiv.org/abs/2309.13837"}, {"metadata": {"arXiv": "2309.13866", "Date": "Mon, 25 Sep 2023 04:30:18 ", "Title": "On Calibration of Modern Quantized Efficient Neural Networks", "Authors": ["Joey Kuang", "Alexander Wong"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at the ICCV 2023 Workshop on Low-Bit Quantized Neural Networks"]}, "abstract": "We explore calibration properties at various precisions for three architectures: ShuffleNetv2, GhostNet-VGG, and MobileOne; and two datasets: CIFAR-100 and PathMNIST. The quality of calibration is observed to track the quantization quality; it is well-documented that performance worsens with lower precision, and we observe a similar correlation with poorer calibration. This becomes especially egregious at 4-bit activation regime. GhostNet-VGG is shown to be the most robust to overall performance drop at lower precision. We find that temperature scaling can improve calibration error for quantized networks, with some caveats. We hope that these preliminary insights can lead to more opportunities for explainable and reliable EdgeML.", "url": "https://arxiv.org/abs/2309.13866"}, {"metadata": {"arXiv": "2309.13884", "Date": "Mon, 25 Sep 2023 05:44:17 ", "Title": "Estimating Treatment Effects Under Heterogeneous Interference", "Authors": ["Xiaofeng Lin", "Guoxi Zhang", "Xiaotian Lu", "Han Bao", "Koh Takeuchi", "Hisashi Kashima"], "Categories": "cs.LG stat.ME", "Journal-ref": "September 2023, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases"}, "abstract": "Treatment effect estimation can assist in effective decision-making in e-commerce, medicine, and education. One popular application of this estimation lies in the prediction of the impact of a treatment (e.g., a promotion) on an outcome (e.g., sales) of a particular unit (e.g., an item), known as the individual treatment effect (ITE). In many online applications, the outcome of a unit can be affected by the treatments of other units, as units are often associated, which is referred to as interference. For example, on an online shopping website, sales of an item will be influenced by an advertisement of its co-purchased item. Prior studies have attempted to model interference to estimate the ITE accurately, but they often assume a homogeneous interference, i.e., relationships between units only have a single view. However, in real-world applications, interference may be heterogeneous, with multi-view relationships. For instance, the sale of an item is usually affected by the treatment of its co-purchased and co-viewed items. We hypothesize that ITE estimation will be inaccurate if this heterogeneous interference is not properly modeled. Therefore, we propose a novel approach to model heterogeneous interference by developing a new architecture to aggregate information from diverse neighbors. Our proposed method contains graph neural networks that aggregate same-view information, a mechanism that aggregates information from different views, and attention mechanisms. In our experiments on multiple datasets with heterogeneous interference, the proposed method significantly outperforms existing methods for ITE estimation, confirming the importance of modeling heterogeneous interference.", "url": "https://arxiv.org/abs/2309.13884"}, {"metadata": {"arXiv": "2309.13886", "Date": "Mon, 25 Sep 2023 05:45:57 ", "Title": "Can Class-Priors Help Single-Positive Multi-Label Learning?", "Authors": ["Biao Liu", "Jie Wang", "Ning Xu", "Xin Geng"], "Categories": "cs.LG"}, "abstract": "Single-positive multi-label learning (SPMLL) is a typical weakly supervised multi-label learning problem, where each training example is annotated with only one positive label. Existing SPMLL methods typically assign pseudo-labels to unannotated labels with the assumption that prior probabilities of all classes are identical. However, the class-prior of each category may differ significantly in real-world scenarios, which makes the predictive model not perform as well as expected due to the unrealistic assumption on real-world application. To alleviate this issue, a novel framework named {\\proposed}, i.e., Class-pRiors Induced Single-Positive multi-label learning, is proposed. Specifically, a class-priors estimator is introduced, which could estimate the class-priors that are theoretically guaranteed to converge to the ground-truth class-priors. In addition, based on the estimated class-priors, an unbiased risk estimator for classification is derived, and the corresponding risk minimizer could be guaranteed to approximately converge to the optimal risk minimizer on fully supervised data. Experimental results on ten MLL benchmark datasets demonstrate the effectiveness and superiority of our method over existing SPMLL approaches.", "url": "https://arxiv.org/abs/2309.13886"}, {"metadata": {"arXiv": "2309.13896", "Date": "Mon, 25 Sep 2023 06:22:28 ", "Title": "Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts", "Authors": ["Chaoqi Wang", "Ziyu Ye", "Zhe Feng", "Ashwinkumar Badanidiyuru", "Haifeng Xu"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2023 (Spotlight)"]}, "abstract": "Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which valuable additional context can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok also observe valuable follow-up information pertinent to the user's reward after recommendation (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications, we study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB, that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate noise in data. Such robustification is necessary for tackling our problem, and we believe it could also be of general interest. Extensive empirical tests on both synthetic and real-world datasets demonstrate the significant benefit of utilizing post-serving contexts as well as the superior performance of our algorithm over the state-of-the-art approaches.", "url": "https://arxiv.org/abs/2309.13896"}, {"metadata": {"arXiv": "2309.13914", "Date": "Mon, 25 Sep 2023 07:29:59 ", "Title": "Matrix Factorization in Tropical and Mixed Tropical-Linear Algebras", "Authors": ["Ioannis Kordonis", "Emmanouil Theodosis", "George Retsinas", "Petros Maragos"], "Categories": "cs.LG eess.SP"}, "abstract": "Matrix Factorization (MF) has found numerous applications in Machine Learning and Data Mining, including collaborative filtering recommendation systems, dimensionality reduction, data visualization, and community detection. Motivated by the recent successes of tropical algebra and geometry in machine learning, we investigate two problems involving matrix factorization over the tropical algebra. For the first problem, Tropical Matrix Factorization (TMF), which has been studied already in the literature, we propose an improved algorithm that avoids many of the local optima. The second formulation considers the approximate decomposition of a given matrix into the product of three matrices where a usual matrix product is followed by a tropical product. This formulation has a very interesting interpretation in terms of the learning of the utility functions of multiple users. We also present numerical results illustrating the effectiveness of the proposed algorithms, as well as an application to recommendation systems with promising results.", "url": "https://arxiv.org/abs/2309.13914"}, {"metadata": {"arXiv": "2309.13915", "Date": "Mon, 25 Sep 2023 07:31:22 ", "Title": "Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds", "Authors": ["Zhenghao Xu", "Xiang Ji", "Minshuo Chen", "Mengdi Wang", "Tuo Zhao"], "Categories": "cs.LG stat.ML"}, "abstract": "Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a result, by properly choosing the network size and hyperparameters, NPMD can find an $\\epsilon$-optimal policy with $\\widetilde{O}(\\epsilon^{-\\frac{d}{\\alpha}-2})$ samples in expectation, where $\\alpha\\in(0,1]$ indicates the smoothness of environment. Compared to previous work, our result exhibits that NPMD can leverage the low-dimensional structure of state space to escape from the curse of dimensionality, providing an explanation for the efficacy of deep policy-based algorithms.", "url": "https://arxiv.org/abs/2309.13915"}, {"metadata": {"arXiv": "2309.13926", "Date": "Mon, 25 Sep 2023 07:48:02 ", "Title": "Pseudo Label Selection is a Decision Problem", "Authors": ["Julian Rodemann"], "Categories": "cs.LG stat.ME stat.ML", "Comments": ["Accepted for presentation at the 46th German Conference on Artificial Intelligence"]}, "abstract": "Pseudo-Labeling is a simple and effective approach to semi-supervised learning. It requires criteria that guide the selection of pseudo-labeled data. The latter have been shown to crucially affect pseudo-labeling's generalization performance. Several such criteria exist and were proven to work reasonably well in practice. However, their performance often depends on the initial model fit on labeled data. Early overfitting can be propagated to the final model by choosing instances with overconfident but wrong predictions, often called confirmation bias. In two recent works, we demonstrate that pseudo-label selection (PLS) can be naturally embedded into decision theory. This paves the way for BPLS, a Bayesian framework for PLS that mitigates the issue of confirmation bias. At its heart is a novel selection criterion: an analytical approximation of the posterior predictive of pseudo-samples and labeled data. We derive this selection criterion by proving Bayes-optimality of this \"pseudo posterior predictive\". We empirically assess BPLS for generalized linear, non-parametric generalized additive models and Bayesian neural networks on simulated and real-world data. When faced with data prone to overfitting and thus a high chance of confirmation bias, BPLS outperforms traditional PLS methods. The decision-theoretic embedding further allows us to render PLS more robust towards the involved modeling assumptions. To achieve this goal, we introduce a multi-objective utility function. We demonstrate that the latter can be constructed to account for different sources of uncertainty and explore three examples: model selection, accumulation of errors and covariate shift.", "url": "https://arxiv.org/abs/2309.13926"}, {"metadata": {"arXiv": "2309.13930", "Date": "Mon, 25 Sep 2023 08:01:05 ", "Title": "SAMN: A Sample Attention Memory Network Combining SVM and NN in One Architecture", "Authors": ["Qiaoling Yang", "Linkai Luo", "Haoyu Zhang", "Hong Peng", "Ziyang Chen"], "Categories": "cs.LG"}, "abstract": "Support vector machine (SVM) and neural networks (NN) have strong complementarity. SVM focuses on the inner operation among samples while NN focuses on the operation among the features within samples. Thus, it is promising and attractive to combine SVM and NN, as it may provide a more powerful function than SVM or NN alone. However, current work on combining them lacks true integration. To address this, we propose a sample attention memory network (SAMN) that effectively combines SVM and NN by incorporating sample attention module, class prototypes, and memory block to NN. SVM can be viewed as a sample attention machine. It allows us to add a sample attention module to NN to implement the main function of SVM. Class prototypes are representatives of all classes, which can be viewed as alternatives to support vectors. The memory block is used for the storage and update of class prototypes. Class prototypes and memory block effectively reduce the computational cost of sample attention and make SAMN suitable for multi-classification tasks. Extensive experiments show that SAMN achieves better classification performance than single SVM or single NN with similar parameter sizes, as well as the previous best model for combining SVM and NN. The sample attention mechanism is a flexible module that can be easily deepened and incorporated into neural networks that require it.", "url": "https://arxiv.org/abs/2309.13930"}, {"metadata": {"arXiv": "2309.13944", "Date": "Mon, 25 Sep 2023 08:23:53 ", "Title": "Provable Training for Graph Contrastive Learning", "Authors": ["Yue Yu", "Xiao Wang", "Mengmei Zhang", "Nian Liu", "Chuan Shi"], "Categories": "cs.LG"}, "abstract": "Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric \"node compactness\", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the form of node compactness theoretically through bound propagation, which can be integrated into binary cross-entropy as a regularization. To this end, we propose the PrOvable Training (POT) for GCL, which regularizes the training of GCL to encode node embeddings that follows the GCL principle better. Through extensive experiments on various benchmarks, POT consistently improves the existing GCL approaches, serving as a friendly plugin.", "url": "https://arxiv.org/abs/2309.13944"}, {"metadata": {"arXiv": "2309.13949", "Date": "Mon, 25 Sep 2023 08:31:14 ", "Title": "Characterising User Transfer Amid Industrial Resource Variation: A Bayesian Nonparametric Approach", "Authors": ["Dongxu Lei", "Xiaotian Lin", "Xinghu Yu", "Zhan Li", "Weichao Sun", "Jianbin Qiu", "Songlin Zhuang", "Huijun Gao"], "Categories": "cs.LG"}, "abstract": "In a multitude of industrial fields, a key objective entails optimising resource management whilst satisfying user requirements. Resource management by industrial practitioners can result in a passive transfer of user loads across resource providers, a phenomenon whose accurate characterisation is both challenging and crucial. This research reveals the existence of user clusters, which capture macro-level user transfer patterns amid resource variation. We then propose CLUSTER, an interpretable hierarchical Bayesian nonparametric model capable of automating cluster identification, and thereby predicting user transfer in response to resource variation. Furthermore, CLUSTER facilitates uncertainty quantification for further reliable decision-making. Our method enables privacy protection by functioning independently of personally identifiable information. Experiments with simulated and real-world data from the communications industry reveal a pronounced alignment between prediction results and empirical observations across a spectrum of resource management scenarios. This research establishes a solid groundwork for advancing resource management strategy development.", "url": "https://arxiv.org/abs/2309.13949"}, {"metadata": {"arXiv": "2309.13950", "Date": "Mon, 25 Sep 2023 08:31:50 ", "Title": "Local and Global Trend Bayesian Exponential Smoothing Models", "Authors": ["Slawek Smyl", "Christoph Bergmeir", "Alexander Dokumentov", "Erwin Wibowo", "Daniel Schmidt"], "Categories": "cs.LG"}, "abstract": "This paper describes a family of seasonal and non-seasonal time series models that can be viewed as generalisations of additive and multiplicative exponential smoothing models. Their development is motivated by fast-growing, volatile time series, and facilitated by state-of-the-art Bayesian fitting techniques. When applied to the M3 competition data set, they outperform the best algorithms in the competition as well as other benchmarks, thus achieving to the best of our knowledge the best results of univariate methods on this dataset in the literature.", "url": "https://arxiv.org/abs/2309.13950"}, {"metadata": {"arXiv": "2309.13960", "Date": "Mon, 25 Sep 2023 08:49:41 ", "Title": "Newton Method-based Subspace Support Vector Data Description", "Authors": ["Fahad Sohrab", "Firas Laakom", "Moncef Gabbouj"], "Categories": "cs.LG", "Comments": ["8 pages", "2 figures", "2 tables", "1 Algorithm. Accepted at IEEE Symposium Series on Computational Intelligence 2023"]}, "abstract": "In this paper, we present an adaptation of Newton's method for the optimization of Subspace Support Vector Data Description (S-SVDD). The objective of S-SVDD is to map the original data to a subspace optimized for one-class classification, and the iterative optimization process of data mapping and description in S-SVDD relies on gradient descent. However, gradient descent only utilizes first-order information, which may lead to suboptimal results. To address this limitation, we leverage Newton's method to enhance data mapping and data description for an improved optimization of subspace learning-based one-class classification. By incorporating this auxiliary information, Newton's method offers a more efficient strategy for subspace learning in one-class classification as compared to gradient-based optimization. The paper discusses the limitations of gradient descent and the advantages of using Newton's method in subspace learning for one-class classification tasks. We provide both linear and nonlinear formulations of Newton's method-based optimization for S-SVDD. In our experiments, we explored both the minimization and maximization strategies of the objective. The results demonstrate that the proposed optimization strategy outperforms the gradient-based S-SVDD in most cases.", "url": "https://arxiv.org/abs/2309.13960"}, {"metadata": {"arXiv": "2309.13985", "Date": "Mon, 25 Sep 2023 09:37:19 ", "Title": "Physics-Driven ML-Based Modelling for Correcting Inverse Estimation", "Authors": ["Ruiyuan Kang", "Tingting Mu", "Panos Liatsis", "Dimitrios C. Kyritsis"], "Categories": "cs.LG cs.NE", "Comments": ["19 pages", "the paper is accepted by Neurips 2023 as a spotlight"], "MSC-class": "78M50, 68T05"}, "abstract": "When deploying machine learning estimators in science and engineering (SAE) domains, it is critical to avoid failed estimations that can have disastrous consequences, e.g., in aero engine design. This work focuses on detecting and correcting failed state estimations before adopting them in SAE inverse problems, by utilizing simulations and performance metrics guided by physical laws. We suggest to flag a machine learning estimation when its physical model error exceeds a feasible threshold, and propose a novel approach, GEESE, to correct it through optimization, aiming at delivering both low error and high efficiency. The key designs of GEESE include (1) a hybrid surrogate error model to provide fast error estimations to reduce simulation cost and to enable gradient based backpropagation of error feedback, and (2) two generative models to approximate the probability distributions of the candidate states for simulating the exploitation and exploration behaviours. All three models are constructed as neural networks. GEESE is tested on three real-world SAE inverse problems and compared to a number of state-of-the-art optimization/search approaches. Results show that it fails the least number of times in terms of finding a feasible state correction, and requires physical evaluations less frequently in general.", "url": "https://arxiv.org/abs/2309.13985"}, {"metadata": {"arXiv": "2309.13989", "Date": "Mon, 25 Sep 2023 09:41:11 ", "Title": "A Novel Approach for Effective Multi-View Clustering with Information-Theoretic Perspective", "Authors": ["Chenhang Cui", "Yazhou Ren", "Jingyu Pu", "Jiawei Li", "Xiaorong Pu", "Tianyi Wu", "Yutao Shi", "Lifang He"], "Categories": "cs.LG"}, "abstract": "Multi-view clustering (MVC) is a popular technique for improving clustering performance using various data sources. However, existing methods primarily focus on acquiring consistent information while often neglecting the issue of redundancy across multiple views. This study presents a new approach called Sufficient Multi-View Clustering (SUMVC) that examines the multi-view clustering framework from an information-theoretic standpoint. Our proposed method consists of two parts. Firstly, we develop a simple and reliable multi-view clustering method SCMVC (simple consistent multi-view clustering) that employs variational analysis to generate consistent information. Secondly, we propose a sufficient representation lower bound to enhance consistent information and minimise unnecessary information among views. The proposed SUMVC method offers a promising solution to the problem of multi-view clustering and provides a new perspective for analyzing multi-view data. To verify the effectiveness of our model, we conducted a theoretical analysis based on the Bayes Error Rate, and experiments on multiple multi-view datasets demonstrate the superior performance of SUMVC.", "url": "https://arxiv.org/abs/2309.13989"}, {"metadata": {"arXiv": "2309.13993", "Date": "Mon, 25 Sep 2023 09:50:15 ", "Title": "Identification of Mixtures of Discrete Product Distributions in Near-Optimal Sample and Time Complexity", "Authors": ["Spencer L. Gordon", "Erik Jahn", "Bijan Mazaheri", "Yuval Rabani", "Leonard J. Schulman"], "Categories": "cs.LG cs.DS eess.SP stat.ML"}, "abstract": "We consider the problem of identifying, from statistics, a distribution of discrete random variables $X_1,\\ldots,X_n$ that is a mixture of $k$ product distributions. The best previous sample complexity for $n \\in O(k)$ was $(1/\\zeta)^{O(k^2 \\log k)}$ (under a mild separation assumption parameterized by $\\zeta$). The best known lower bound was $\\exp(\\Omega(k))$. It is known that $n\\geq 2k-1$ is necessary and sufficient for identification. We show, for any $n\\geq 2k-1$, how to achieve sample complexity and run-time complexity $(1/\\zeta)^{O(k)}$. We also extend the known lower bound of $e^{\\Omega(k)}$ to match our upper bound across a broad range of $\\zeta$. Our results are obtained by combining (a) a classic method for robust tensor decomposition, (b) a novel way of bounding the condition number of key matrices called Hadamard extensions, by studying their action only on flattened rank-1 tensors.", "url": "https://arxiv.org/abs/2309.13993"}, {"metadata": {"arXiv": "2309.14003", "Date": "Mon, 25 Sep 2023 10:10:34 ", "Title": "Hierarchical Imitation Learning for Stochastic Environments", "Authors": ["Maximilian Igl", "Punit Shah", "Paul Mougin", "Sirish Srinivasan", "Tarun Gupta", "Brandyn White", "Kyriacos Shiarlis", "Shimon Whiteson"], "Categories": "cs.LG cs.RO", "Comments": ["Published at IROS'23"]}, "abstract": "Many applications of imitation learning require the agent to generate the full distribution of behaviour observed in the training data. For example, to evaluate the safety of autonomous vehicles in simulation, accurate and diverse behaviour models of other road users are paramount. Existing methods that improve this distributional realism typically rely on hierarchical policies. These condition the policy on types such as goals or personas that give rise to multi-modal behaviour. However, such methods are often inappropriate for stochastic environments where the agent must also react to external factors: because agent types are inferred from the observed future trajectory during training, these environments require that the contributions of internal and external factors to the agent behaviour are disentangled and only internal factors, i.e., those under the agent's control, are encoded in the type. Encoding future information about external factors leads to inappropriate agent reactions during testing, when the future is unknown and types must be drawn independently from the actual future. We formalize this challenge as distribution shift in the conditional distribution of agent types under environmental stochasticity. We propose Robust Type Conditioning (RTC), which eliminates this shift with adversarial training under randomly sampled types. Experiments on two domains, including the large-scale Waymo Open Motion Dataset, show improved distributional realism while maintaining or improving task performance compared to state-of-the-art baselines.", "url": "https://arxiv.org/abs/2309.14003"}, {"metadata": {"arXiv": "2309.14068", "Date": "Mon, 25 Sep 2023 12:03:32 ", "Title": "Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models", "Authors": ["Yangming Li", "Boris van Breugel", "Mihaela van der Schaar"], "Categories": "cs.LG cs.CV", "Comments": ["Submitted to ICLR-2024"]}, "abstract": "Because diffusion models have shown impressive performances in a number of tasks, such as image synthesis, there is a trend in recent works to prove (with certain assumptions) that these models have strong approximation capabilities. In this paper, we show that current diffusion models actually have an expressive bottleneck in backward denoising and some assumption made by existing theoretical guarantees is too strong. Based on this finding, we prove that diffusion models have unbounded errors in both local denoising and global approximation. In light of our theoretical studies, we introduce soft mixture denoising (SMD), an expressive and efficient model for backward denoising. SMD not only permits diffusion models to well approximate any Gaussian mixture distributions in theory, but also is simple and efficient for implementation. Our experiments on multiple image datasets show that SMD significantly improves different types of diffusion models (e.g., DDPM), especially in the situation of few backward iterations.", "url": "https://arxiv.org/abs/2309.14068"}, {"metadata": {"arXiv": "2309.14088", "Date": "Mon, 25 Sep 2023 12:30:43 ", "Title": "REPA: Client Clustering without Training and Data Labels for Improved Federated Learning in Non-IID Settings", "Authors": ["Boris Radovi\\v{c}", "Veljko Pejovi\\'c"], "Categories": "cs.LG"}, "abstract": "Clustering clients into groups that exhibit relatively homogeneous data distributions represents one of the major means of improving the performance of federated learning (FL) in non-independent and identically distributed (non-IID) data settings. Yet, the applicability of current state-of-the-art approaches remains limited as these approaches cluster clients based on information, such as the evolution of local model parameters, that is only obtainable through actual on-client training. On the other hand, there is a need to make FL models available to clients who are not able to perform the training themselves, as they do not have the processing capabilities required for training, or simply want to use the model without participating in the training. Furthermore, the existing alternative approaches that avert the training still require that individual clients have a sufficient amount of labeled data upon which the clustering is based, essentially assuming that each client is a data annotator. In this paper, we present REPA, an approach to client clustering in non-IID FL settings that requires neither training nor labeled data collection. REPA uses a novel supervised autoencoder-based method to create embeddings that profile a client's underlying data-generating processes without exposing the data to the server and without requiring local training. Our experimental analysis over three different datasets demonstrates that REPA delivers state-of-the-art model performance while expanding the applicability of cluster-based FL to previously uncovered use cases.", "url": "https://arxiv.org/abs/2309.14088"}, {"metadata": {"arXiv": "2309.14090", "Date": "Mon, 25 Sep 2023 12:31:18 ", "Title": "Convolutional autoencoder-based multimodal one-class classification", "Authors": ["Firas Laakom", "Fahad Sohrab", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "Categories": "cs.LG cs.CV", "Comments": ["5 pages", "1 figure", "4 tables"]}, "abstract": "One-class classification refers to approaches of learning using data from a single class only. In this paper, we propose a deep learning one-class classification method suitable for multimodal data, which relies on two convolutional autoencoders jointly trained to reconstruct the positive input data while obtaining the data representations in the latent space as compact as possible. During inference, the distance of the latent representation of an input to the origin can be used as an anomaly score. Experimental results using a multimodal macroinvertebrate image classification dataset show that the proposed multimodal method yields better results as compared to the unimodal approach. Furthermore, study the effect of different input image sizes, and we investigate how recently proposed feature diversity regularizers affect the performance of our approach. We show that such regularizers improve performance.", "url": "https://arxiv.org/abs/2309.14090"}, {"metadata": {"arXiv": "2309.14091", "Date": "Mon, 25 Sep 2023 12:31:37 ", "Title": "On the Benefit of Optimal Transport for Curriculum Reinforcement Learning", "Authors": ["Pascal Klink", "Carlo D'Eramo", "Jan Peters", "Joni Pajarinen"], "Categories": "cs.LG"}, "abstract": "Curriculum reinforcement learning (CRL) allows solving complex tasks by generating a tailored sequence of learning tasks, starting from easy ones and subsequently increasing their difficulty. Although the potential of curricula in RL has been clearly shown in various works, it is less clear how to generate them for a given learning environment, resulting in various methods aiming to automate this task. In this work, we focus on framing curricula as interpolations between task distributions, which has previously been shown to be a viable approach to CRL. Identifying key issues of existing methods, we frame the generation of a curriculum as a constrained optimal transport problem between task distributions. Benchmarks show that this way of curriculum generation can improve upon existing CRL methods, yielding high performance in various tasks with different characteristics.", "url": "https://arxiv.org/abs/2309.14091"}, {"metadata": {"arXiv": "2309.14096", "Date": "Mon, 25 Sep 2023 12:48:47 ", "Title": "Tracking Control for a Spherical Pendulum via Curriculum Reinforcement Learning", "Authors": ["Pascal Klink", "Florian Wolf", "Kai Ploeger", "Jan Peters and Joni Pajarinen"], "Categories": "cs.LG cs.RO"}, "abstract": "Reinforcement Learning (RL) allows learning non-trivial robot control laws purely from data. However, many successful applications of RL have relied on ad-hoc regularizations, such as hand-crafted curricula, to regularize the learning performance. In this paper, we pair a recent algorithm for automatically building curricula with RL on massively parallelized simulations to learn a tracking controller for a spherical pendulum on a robotic arm via RL. Through an improved optimization scheme that better respects the non-Euclidean task structure, we allow the method to reliably generate curricula of trajectories to be tracked, resulting in faster and more robust learning compared to an RL baseline that does not exploit this form of structured learning. The learned policy matches the performance of an optimal control baseline on the real system, demonstrating the potential of curriculum RL to jointly learn state estimation and control for non-linear tracking tasks.", "url": "https://arxiv.org/abs/2309.14096"}, {"metadata": {"arXiv": "2309.14118", "Date": "Mon, 25 Sep 2023 13:16:57 ", "Title": "MultiModN- Multimodal, Multi-Task, Interpretable Modular Networks", "Authors": ["Vinitra Swamy", "Malika Satayeva", "Jibril Frej", "Thierry Bossy", "Thijs Vogels", "Martin Jaggi", "Tanja K\\\"aser", "Mary-Anne Hartley"], "Categories": "cs.LG", "Comments": ["Accepted as a full paper at NeurIPS 2023 in New Orleans", "USA"]}, "abstract": "Predicting multiple real-world tasks in a single model often requires a particularly diverse feature space. Multimodal (MM) models aim to extract the synergistic predictive potential of multiple data types to create a shared feature space with aligned semantic meaning across inputs of drastically varying sizes (i.e. images, text, sound). Most current MM architectures fuse these representations in parallel, which not only limits their interpretability but also creates a dependency on modality availability. We present MultiModN, a multimodal, modular network that fuses latent representations in a sequence of any number, combination, or type of modality while providing granular real-time predictive feedback on any number or combination of predictive tasks. MultiModN's composable pipeline is interpretable-by-design, as well as innately multi-task and robust to the fundamental issue of biased missingness. We perform four experiments on several benchmark MM datasets across 10 real-world tasks (predicting medical diagnoses, academic performance, and weather), and show that MultiModN's sequential MM fusion does not compromise performance compared with a baseline of parallel fusion. By simulating the challenging bias of missing not-at-random (MNAR), this work shows that, contrary to MultiModN, parallel fusion baselines erroneously learn MNAR and suffer catastrophic failure when faced with different patterns of MNAR at inference. To the best of our knowledge, this is the first inherently MNAR-resistant approach to MM modeling. In conclusion, MultiModN provides granular insights, robustness, and flexibility without compromising performance.", "url": "https://arxiv.org/abs/2309.14118"}, {"metadata": {"arXiv": "2309.14134", "Date": "Mon, 25 Sep 2023 13:42:22 ", "Title": "One-Class Classification for Intrusion Detection on Vehicular Networks", "Authors": ["Jake Guidry", "Fahad Sohrab", "Raju Gottumukkala", "Satya Katragadda", "Moncef Gabbouj"], "Categories": "cs.LG cs.CR", "Comments": ["7 pages", "2 figures", "4 tables. Accepted at IEEE Symposium Series on Computational Intelligence 2023"]}, "abstract": "Controller Area Network bus systems within vehicular networks are not equipped with the tools necessary to ward off and protect themselves from modern cyber-security threats. Work has been done on using machine learning methods to detect and report these attacks, but common methods are not robust towards unknown attacks. These methods usually rely on there being a sufficient representation of attack data, which may not be available due to there either not being enough data present to adequately represent its distribution or the distribution itself is too diverse in nature for there to be a sufficient representation of it. With the use of one-class classification methods, this issue can be mitigated as only normal data is required to train a model for the detection of anomalous instances. Research has been done on the efficacy of these methods, most notably One-Class Support Vector Machine and Support Vector Data Description, but many new extensions of these works have been proposed and have yet to be tested for injection attacks in vehicular networks. In this paper, we investigate the performance of various state-of-the-art one-class classification methods for detecting injection attacks on Controller Area Network bus traffic. We investigate the effectiveness of these techniques on attacks launched on Controller Area Network buses from two different vehicles during normal operation and while being attacked. We observe that the Subspace Support Vector Data Description method outperformed all other tested methods with a Gmean of about 85%.", "url": "https://arxiv.org/abs/2309.14134"}, {"metadata": {"arXiv": "2309.14156", "Date": "Mon, 25 Sep 2023 14:08:21 ", "Title": "Designing and evaluating an online reinforcement learning agent for physical exercise recommendations in N-of-1 trials", "Authors": ["Dominik Meier", "Ipek Ensari", "Stefan Konigorski"], "Categories": "cs.LG stat.AP stat.ME"}, "abstract": "Personalized adaptive interventions offer the opportunity to increase patient benefits, however, there are challenges in their planning and implementation. Once implemented, it is an important question whether personalized adaptive interventions are indeed clinically more effective compared to a fixed gold standard intervention. In this paper, we present an innovative N-of-1 trial study design testing whether implementing a personalized intervention by an online reinforcement learning agent is feasible and effective. Throughout, we use a new study on physical exercise recommendations to reduce pain in endometriosis for illustration. We describe the design of a contextual bandit recommendation agent and evaluate the agent in simulation studies. The results show that adaptive interventions add complexity to the design and implementation process, but have the potential to improve patients' benefits even if only few observations are available. In order to quantify the expected benefit, data from previous interventional studies is required. We expect our approach to be transferable to other interventions and clinical interventions.", "url": "https://arxiv.org/abs/2309.14156"}, {"metadata": {"arXiv": "2309.14176", "Date": "Mon, 25 Sep 2023 14:40:27 ", "Title": "Federated Learning Under Restricted User Availability", "Authors": ["Periklis Theodoropoulos", "Konstantinos E. Nikolakakis and Dionysis Kalogerias"], "Categories": "cs.LG cs.DC stat.ML", "Comments": ["5 pages", "4 figures"]}, "abstract": "Federated Learning (FL) is a decentralized machine learning framework that enables collaborative model training while respecting data privacy. In various applications, non-uniform availability or participation of users is unavoidable due to an adverse or stochastic environment, the latter often being uncontrollable during learning. Here, we posit a generic user selection mechanism implementing a possibly randomized, stationary selection policy, suggestively termed as a Random Access Model (RAM). We propose a new formulation of the FL problem which effectively captures and mitigates limited participation of data originating from infrequent, or restricted users, at the presence of a RAM. By employing the Conditional Value-at-Risk (CVaR) over the (unknown) RAM distribution, we extend the expected loss FL objective to a risk-aware objective, enabling the design of an efficient training algorithm that is completely oblivious to the RAM, and with essentially identical complexity as FedAvg. Our experiments on synthetic and benchmark datasets show that the proposed approach achieves significantly improved performance as compared with standard FL, under a variety of setups.", "url": "https://arxiv.org/abs/2309.14176"}, {"metadata": {"arXiv": "2309.14198", "Date": "Mon, 25 Sep 2023 14:57:43 ", "Title": "(Predictable) Performance Bias in Unsupervised Anomaly Detection", "Authors": ["Felix Meissen", "Svenja Breuer", "Moritz Knolle", "Alena Buyx", "Ruth M\\\"uller", "Georgios Kaissis", "Benedikt Wiestler", "Daniel R\\\"uckert"], "Categories": "cs.LG cs.CV cs.CY eess.IV", "Comments": ["11 pages", "5 Figures", "1 panel"]}, "abstract": "Background With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified. Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection. While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored. Methods In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets. Our experiments were validated using two state-of-the-art UAD models for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning. Findings Our experiments revealed empirical \"fairness laws\" (similar to \"scaling laws\" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data. Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups. Interpretation Our study quantified the disparate performance of UAD models against certain demographic subgroups. Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone. Instead, the representation of some subgroups seems harder to learn by UAD models than that of others. The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition.", "url": "https://arxiv.org/abs/2309.14198"}, {"metadata": {"arXiv": "2309.14240", "Date": "Mon, 25 Sep 2023 15:55:55 ", "Title": "Learning to Abstain From Uninformative Data", "Authors": ["Yikai Zhang", "Songzhu Zheng", "Mina Dalirrooyfard", "Pengxiang Wu", "Anderson Schneider", "Anant Raj", "Yuriy Nevmyvaka", "Chao Chen"], "Categories": "cs.LG"}, "abstract": "Learning and decision-making in domains with naturally high noise-to-signal ratio, such as Finance or Healthcare, is often challenging, while the stakes are very high. In this paper, we study the problem of learning and acting under a general noisy generative process. In this problem, the data distribution has a significant proportion of uninformative samples with high noise in the label, while part of the data contains useful information represented by low label noise. This dichotomy is present during both training and inference, which requires the proper handling of uninformative data during both training and testing. We propose a novel approach to learning under these conditions via a loss inspired by the selective learning theory. By minimizing this loss, the model is guaranteed to make a near-optimal decision by distinguishing informative data from uninformative data and making predictions. We build upon the strength of our theoretical guarantees by describing an iterative algorithm, which jointly optimizes both a predictor and a selector, and evaluates its empirical performance in a variety of settings.", "url": "https://arxiv.org/abs/2309.14240"}, {"metadata": {"arXiv": "2309.14307", "Date": "Mon, 25 Sep 2023 17:25:39 ", "Title": "A post-selection algorithm for improving dynamic ensemble selection methods", "Authors": ["Paulo R.G. Cordeiro", "George D.C. Cavalcanti and Rafael M.O. Cruz"], "Categories": "cs.LG", "Journal-ref": "2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)"}, "abstract": "Dynamic Ensemble Selection (DES) is a Multiple Classifier Systems (MCS) approach that aims to select an ensemble for each query sample during the selection phase. Even with the proposal of several DES approaches, no particular DES technique is the best choice for different problems. Thus, we hypothesize that selecting the best DES approach per query instance can lead to better accuracy. To evaluate this idea, we introduce the Post-Selection Dynamic Ensemble Selection (PS-DES) approach, a post-selection scheme that evaluates ensembles selected by several DES techniques using different metrics. Experimental results show that using accuracy as a metric to select the ensembles, PS-DES performs better than individual DES techniques. PS-DES source code is available in a GitHub repository", "url": "https://arxiv.org/abs/2309.14307"}, {"metadata": {"arXiv": "2309.14322", "Date": "Mon, 25 Sep 2023 17:48:51 ", "Title": "Small-scale proxies for large-scale Transformer training instabilities", "Authors": ["Mitchell Wortsman", "Peter J. Liu", "Lechao Xiao", "Katie Everett", "Alex Alemi", "Ben Adlam", "John D. Co-Reyes", "Izzeddin Gur", "Abhishek Kumar", "Roman Novak", "Jeffrey Pennington", "Jascha Sohl-dickstein", "Kelvin Xu", "Jaehoon Lee", "Justin Gilmer", "Simon Kornblith"], "Categories": "cs.LG"}, "abstract": "Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training stability and instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the $\\mu$Param (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model activation and gradient norms.", "url": "https://arxiv.org/abs/2309.14322"}, {"metadata": {"arXiv": "2309.14334", "Date": "Mon, 25 Sep 2023 17:58:23 ", "Title": "Tasks Makyth Models: Machine Learning Assisted Surrogates for Tipping Points", "Authors": ["Gianluca Fabiani", "Nikolaos Evangelou", "Tianqi Cui", "Juan M. Bello-Rivas", "Cristina P. Martin-Linares", "Constantinos Siettos", "Ioannis G. Kevrekidis"], "Categories": "cs.LG cs.NA math.DS math.NA q-fin.TR", "Comments": ["29 pages", "8 figures", "6 tables"]}, "abstract": "We present a machine learning (ML)-assisted framework bridging manifold learning, neural networks, Gaussian processes, and Equation-Free multiscale modeling, for (a) detecting tipping points in the emergent behavior of complex systems, and (b) characterizing probabilities of rare events (here, catastrophic shifts) near them. Our illustrative example is an event-driven, stochastic agent-based model (ABM) describing the mimetic behavior of traders in a simple financial market. Given high-dimensional spatiotemporal data -- generated by the stochastic ABM -- we construct reduced-order models for the emergent dynamics at different scales: (a) mesoscopic Integro-Partial Differential Equations (IPDEs); and (b) mean-field-type Stochastic Differential Equations (SDEs) embedded in a low-dimensional latent space, targeted to the neighborhood of the tipping point. We contrast the uses of the different models and the effort involved in learning them.", "url": "https://arxiv.org/abs/2309.14334"}, {"metadata": {"arXiv": "2309.13475", "Date": "Sat, 23 Sep 2023 20:33:38 ", "Title": "Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers", "Authors": ["Aryaman Gupta", "Kaustav Chakraborty", "Somil Bansal"], "Categories": "cs.RO cs.CV cs.LG cs.SY eess.SY"}, "abstract": "Autonomous systems, such as self-driving cars and drones, have made significant strides in recent years by leveraging visual inputs and machine learning for decision-making and control. Despite their impressive performance, these vision-based controllers can make erroneous predictions when faced with novel or out-of-distribution inputs. Such errors can cascade to catastrophic system failures and compromise system safety. In this work, we introduce a run-time anomaly monitor to detect and mitigate such closed-loop, system-level failures. Specifically, we leverage a reachability-based framework to stress-test the vision-based controller offline and mine its system-level failures. This data is then used to train a classifier that is leveraged online to flag inputs that might cause system breakdowns. The anomaly detector highlights issues that transcend individual modules and pertain to the safety of the overall system. We also design a fallback controller that robustly handles these detected anomalies to preserve system safety. We validate the proposed approach on an autonomous aircraft taxiing system that uses a vision-based controller for taxiing. Our results show the efficacy of the proposed approach in identifying and handling system-level anomalies, outperforming methods such as prediction error-based detection, and ensembling, thereby enhancing the overall safety and robustness of autonomous systems.", "url": "https://arxiv.org/abs/2309.13475"}, {"metadata": {"arXiv": "2309.13485", "Date": "Sat, 23 Sep 2023 22:13:03 ", "Title": "Interpretable and Flexible Target-Conditioned Neural Planners For Autonomous Vehicles", "Authors": ["Haolan Liu", "Jishen Zhao", "Liangjun Zhang"], "Categories": "cs.RO cs.LG", "DOI": "10.1109/ICRA48891.2023.10160913"}, "abstract": "Learning-based approaches to autonomous vehicle planners have the potential to scale to many complicated real-world driving scenarios by leveraging huge amounts of driver demonstrations. However, prior work only learns to estimate a single planning trajectory, while there may be multiple acceptable plans in real-world scenarios. To solve the problem, we propose an interpretable neural planner to regress a heatmap, which effectively represents multiple potential goals in the bird's-eye view of an autonomous vehicle. The planner employs an adaptive Gaussian kernel and relaxed hourglass loss to better capture the uncertainty of planning problems. We also use a negative Gaussian kernel to add supervision to the heatmap regression, enabling the model to learn collision avoidance effectively. Our systematic evaluation on the Lyft Open Dataset across a diverse range of real-world driving scenarios shows that our model achieves a safer and more flexible driving performance than prior works.", "url": "https://arxiv.org/abs/2309.13485"}, {"metadata": {"arXiv": "2309.14246", "Date": "Mon, 25 Sep 2023 16:05:32 ", "Title": "Learning Risk-Aware Quadrupedal Locomotion using Distributional Reinforcement Learning", "Authors": ["Lukas Schneider", "Jonas Frey", "Takahiro Miki", "Marco Hutter"], "Categories": "cs.RO cs.LG"}, "abstract": "Deployment in hazardous environments requires robots to understand the risks associated with their actions and movements to prevent accidents. Despite its importance, these risks are not explicitly modeled by currently deployed locomotion controllers for legged robots. In this work, we propose a risk sensitive locomotion training method employing distributional reinforcement learning to consider safety explicitly. Instead of relying on a value expectation, we estimate the complete value distribution to account for uncertainty in the robot's interaction with the environment. The value distribution is consumed by a risk metric to extract risk sensitive value estimates. These are integrated into Proximal Policy Optimization (PPO) to derive our method, Distributional Proximal Policy Optimization (DPPO). The risk preference, ranging from risk-averse to risk-seeking, can be controlled by a single parameter, which enables to adjust the robot's behavior dynamically. Importantly, our approach removes the need for additional reward function tuning to achieve risk sensitivity. We show emergent risk sensitive locomotion behavior in simulation and on the quadrupedal robot ANYmal.", "url": "https://arxiv.org/abs/2309.14246"}, {"metadata": {"arXiv": "2309.14265", "Date": "Mon, 25 Sep 2023 16:23:49 ", "Title": "Industrial Application of 6D Pose Estimation for Robotic Manipulation in Automotive Internal Logistics", "Authors": ["Philipp Quentin", "Dino Knoll", "Daniel Goehring"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Accepted for publication at IEEE International Conference on Automation Science and Engineering (CASE 2023)"]}, "abstract": "Despite the advances in robotics a large proportion of the of parts handling tasks in the automotive industry's internal logistics are not automated but still performed by humans. A key component to competitively automate these processes is a 6D pose estimation that can handle a large number of different parts, is adaptable to new parts with little manual effort, and is sufficiently accurate and robust with respect to industry requirements. In this context, the question arises as to the current status quo with respect to these measures. To address this we built a representative 6D pose estimation pipeline with state-of-the-art components from economically scalable real to synthetic data generation to pose estimators and evaluated it on automotive parts with regards to a realistic sequencing process. We found that using the data generation approaches, the performance of the trained 6D pose estimators are promising, but do not meet industry requirements. We reveal that the reason for this is the inability of the estimators to provide reliable uncertainties for their poses, rather than the ability of to provide sufficiently accurate poses. In this context we further analyzed how RGB- and RGB-D-based approaches compare against this background and show that they are differently vulnerable to the domain gap induced by synthetic data.", "url": "https://arxiv.org/abs/2309.14265"}, {"metadata": {"arXiv": "2309.14321", "Date": "Mon, 25 Sep 2023 17:45:55 ", "Title": "Human-Assisted Continual Robot Learning with Foundation Models", "Authors": ["Meenal Parakh", "Alisha Fong", "Anthony Simeonov", "Abhishek Gupta", "Tao Chen", "Pulkit Agrawal"], "Categories": "cs.RO cs.LG"}, "abstract": "Large Language Models (LLMs) have been shown to act like planners that can decompose high-level instructions into a sequence of executable instructions. However, current LLM-based planners are only able to operate with a fixed set of skills. We overcome this critical limitation and present a method for using LLM-based planners to query new skills and teach robots these skills in a data and time-efficient manner for rigid object manipulation. Our system can re-use newly acquired skills for future tasks, demonstrating the potential of open world and lifelong learning. We evaluate the proposed framework on multiple tasks in simulation and the real world. Videos are available at: https://sites.google.com/mit.edu/halp-robot-learning.", "url": "https://arxiv.org/abs/2309.14321"}, {"metadata": {"arXiv": "2309.14125", "Date": "Mon, 25 Sep 2023 13:24:53 ", "Title": "Driving behavior-guided battery health monitoring for electric vehicles using machine learning", "Authors": ["Nanhua Jiang", "Jiawei Zhang", "Weiran Jiang", "Yao Ren", "Jing Lin", "Edwin Khoo", "Ziyou Song"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "An accurate estimation of the state of health (SOH) of batteries is critical to ensuring the safe and reliable operation of electric vehicles (EVs). Feature-based machine learning methods have exhibited enormous potential for rapidly and precisely monitoring battery health status. However, simultaneously using various health indicators (HIs) may weaken estimation performance due to feature redundancy. Furthermore, ignoring real-world driving behaviors can lead to inaccurate estimation results as some features are rarely accessible in practical scenarios. To address these issues, we proposed a feature-based machine learning pipeline for reliable battery health monitoring, enabled by evaluating the acquisition probability of features under real-world driving conditions. We first summarized and analyzed various individual HIs with mechanism-related interpretations, which provide insightful guidance on how these features relate to battery degradation modes. Moreover, all features were carefully evaluated and screened based on estimation accuracy and correlation analysis on three public battery degradation datasets. Finally, the scenario-based feature fusion and acquisition probability-based practicality evaluation method construct a useful tool for feature extraction with consideration of driving behaviors. This work highlights the importance of balancing the performance and practicality of HIs during the development of feature-based battery health monitoring algorithms.", "url": "https://arxiv.org/abs/2309.14125"}, {"metadata": {"arXiv": "2309.13176", "Date": "Fri, 22 Sep 2023 20:45:15 ", "Title": "AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures", "Authors": ["Eli Sherman", "Ian W. Eisenberg"], "Categories": "cs.AI cs.CY"}, "abstract": "As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide variety of risks proposed in the literature. We outline the myriad data sources needed to construct informative Risk Profiles and propose a template-based methodology for collating risk information into a standard, yet flexible, structure. We apply this methodology to a number of prominent AI systems using publicly available information. To conclude, we discuss design decisions for the profiles and future work.", "url": "https://arxiv.org/abs/2309.13176"}, {"metadata": {"arXiv": "2309.13218", "Date": "Fri, 22 Sep 2023 23:45:21 ", "Title": "AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling", "Authors": ["Pivithuru Thejan Amarasinghe", "Su Nguyen", "Yuan Sun and Damminda Alahakoon"], "Categories": "cs.AI"}, "abstract": "Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by fine-tuning a pre-trained LLM for problem formulation. To address token limitations, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. In addition, we design performance evaluation metrics that are more suitable for assessing the accuracy and quality of problem formulations compared to existing evaluation metrics. Experiment results demonstrate that our AI-Copilot can synthesize complex and large problem formulations for a typical business optimisation problem in production scheduling.", "url": "https://arxiv.org/abs/2309.13218"}, {"metadata": {"arXiv": "2309.13229", "Date": "Sat, 23 Sep 2023 01:40:56 ", "Title": "Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems", "Authors": ["Jiaqi Wen", "Bogdan Gabrys", "Katarzyna Musial"], "Categories": "cs.AI"}, "abstract": "Building models of Complex Networked Systems (CNS) that can accurately represent reality forms an important research area. To be able to reflect real world systems, the modelling needs to consider not only the intensity of interactions between the entities but also features of all the elements of the system. This study aims to improve the expressive power of node features in Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous feature representation principles. This involves representing features with crisp feature values and fuzzy sets, each describing the objective and the subjective inductions of the nodes' features and feature differences. Our empirical analysis builds DT-CNSs to recreate realistic physical contact networks in different countries from real node feature distributions based on various representation principles and an optimised feature preference. We also investigate their respective disaster resilience to an epidemic outbreak starting from the most popular node. The results suggest that the increasing flexibility of feature representation with fuzzy sets improves the expressive power and enables more accurate modelling. In addition, the heterogeneous features influence the network structure and the speed of the epidemic outbreak, requiring various mitigation policies targeted at different people.", "url": "https://arxiv.org/abs/2309.13229"}, {"metadata": {"arXiv": "2309.13391", "Date": "Sat, 23 Sep 2023 14:23:19 ", "Title": "D-Separation for Causal Self-Explanation", "Authors": ["Wei Liu", "Jun Wang", "Haozhao Wang", "Ruixuan Li", "Zhiying Deng", "YuanKai Zhang", "Yang Qiu"], "Categories": "cs.AI cs.CL", "Comments": ["NeurIPS 2023"]}, "abstract": "Rationalization is a self-explaining framework for NLP models. Conventional work typically uses the maximum mutual information (MMI) criterion to find the rationale that is most indicative of the target label. However, this criterion can be influenced by spurious features that correlate with the causal rationale or the target label. Instead of attempting to rectify the issues of the MMI criterion, we propose a novel criterion to uncover the causal rationale, termed the Minimum Conditional Dependence (MCD) criterion, which is grounded on our finding that the non-causal features and the target label are \\emph{d-separated} by the causal rationale. By minimizing the dependence between the unselected parts of the input and the target label conditioned on the selected rationale candidate, all the causes of the label are compelled to be selected. In this study, we employ a simple and practical measure of dependence, specifically the KL-divergence, to validate our proposed MCD criterion. Empirically, we demonstrate that MCD improves the F1 score by up to $13.7\\%$ compared to previous state-of-the-art MMI-based methods. Our code is available at: \\url{https://github.com/jugechengzi/Rationalization-MCD}.", "url": "https://arxiv.org/abs/2309.13391"}, {"metadata": {"arXiv": "2309.13834", "Date": "Mon, 25 Sep 2023 02:44:33 ", "Title": "Prior Bilinear Based Models for Knowledge Graph Completion", "Authors": ["Jiayi Li", "Ruilin Luo", "Jiaqi Sun", "Jing Xiao", "Yujiu Yang"], "Categories": "cs.AI"}, "abstract": "Bilinear based models are powerful and widely used approaches for Knowledge Graphs Completion (KGC). Although bilinear based models have achieved significant advances, these studies mainly concentrate on posterior properties (based on evidence, e.g. symmetry pattern) while neglecting the prior properties. In this paper, we find a prior property named \"the law of identity\" that cannot be captured by bilinear based models, which hinders them from comprehensively modeling the characteristics of KGs. To address this issue, we introduce a solution called Unit Ball Bilinear Model (UniBi). This model not only achieves theoretical superiority but also offers enhanced interpretability and performance by minimizing ineffective learning through minimal constraints. Experiments demonstrate that UniBi models the prior property and verify its interpretability and performance.", "url": "https://arxiv.org/abs/2309.13834"}, {"metadata": {"arXiv": "2309.13939", "Date": "Mon, 25 Sep 2023 08:20:06 ", "Title": "The Time Traveler's Guide to Semantic Web Research: Analyzing Fictitious Research Themes in the ESWC \"Next 20 Years\" Track", "Authors": ["Irene Celino and Heiko Paulheim"], "Categories": "cs.AI", "Comments": ["13 pages", "8 figures", "2 tables"]}, "abstract": "What will Semantic Web research focus on in 20 years from now? We asked this question to the community and collected their visions in the \"Next 20 years\" track of ESWC 2023. We challenged the participants to submit \"future\" research papers, as if they were submitting to the 2043 edition of the conference. The submissions - entirely fictitious - were expected to be full scientific papers, with research questions, state of the art references, experimental results and future work, with the goal to get an idea of the research agenda for the late 2040s and early 2050s. We received ten submissions, eight of which were accepted for presentation at the conference, that mixed serious ideas of potential future research themes and discussion topics with some fun and irony. In this paper, we intend to provide a survey of those \"science fiction\" papers, considering the emerging research themes and topics, analysing the research methods applied by the authors in these very special submissions, and investigating also the most fictitious parts (e.g., neologisms, fabricated references). Our goal is twofold: on the one hand, we investigate what this special track tells us about the Semantic Web community and, on the other hand, we aim at getting some insights on future research practices and directions.", "url": "https://arxiv.org/abs/2309.13939"}, {"metadata": {"arXiv": "2309.14112", "Date": "Mon, 25 Sep 2023 13:10:56 ", "Title": "Semi-Abstract Value-Based Argumentation Framework", "Authors": ["Jovan Jeromela"], "Categories": "cs.AI cs.LO", "Comments": ["Submitted as a Bachelor Thesis at TU Wien on 2019-11-07. Advisor: Christian Ferm\\\"uller. 49 pages"]}, "abstract": "In his seminal paper, Phan Minh Dung (1995) proposed abstract argumentation framework, which models argumentation using directed graphs where structureless arguments are the nodes and attacks among the arguments are the edges. In the following years, many extensions of this framework were introduced. These extensions typically add a certain form of structure to the arguments. This thesis showcases two such extensions -- value-based argumentation framework by Trevor Bench-Capon (2002) and semi-abstract argumentation framework by Esther Anna Corsi and Christian Ferm\\\"uller (2017). The former introduces a mapping function that links individual arguments to a set of ordered values, enabling a distinction between objectively and subjectively acceptable arguments. The latter links claims of individual arguments to propositional formulae and then applies newly-introduced attack principles in order to make implicit attacks explicit and to enable a definition of a consequence relation that relies on neither the truth values nor the interpretations in the usual sense. The contribution of this thesis is two-fold. Firstly, the new semi-abstract value-based argumentation framework is introduced. This framework maps propositional formulae associated with individual arguments to a set of ordered values. Secondly, a complex moral dilemma is formulated using the original and the value-based argumentation frameworks showcasing the expressivity of these formalisms.", "url": "https://arxiv.org/abs/2309.14112"}, {"metadata": {"arXiv": "2309.13136", "Date": "Fri, 22 Sep 2023 18:44:34 ", "Title": "Contextual Emotion Estimation from Image Captions", "Authors": ["Vera Yang", "Archita Srivastava", "Yasaman Etesam", "Chuxuan Zhang", "Angelica Lim"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ACII 2023. Project page: http://rosielab.github.io/emotion-captions/"]}, "abstract": "Emotion estimation in images is a challenging task, typically using computer vision methods to directly estimate people's emotions using face, body pose and contextual cues. In this paper, we explore whether Large Language Models (LLMs) can support the contextual emotion estimation task, by first captioning images, then using an LLM for inference. First, we must understand: how well do LLMs perceive human emotions? And which parts of the information enable them to determine emotions? One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. Towards this goal, we propose a set of natural language descriptors for faces, bodies, interactions, and environments. We use them to manually generate captions and emotion annotations for a subset of 331 images from the EMOTIC dataset. These captions offer an interpretable representation for emotion estimation, towards understanding how elements of a scene affect emotion perception in LLMs and beyond. Secondly, we test the capability of a large language model to infer an emotion from the resulting image captions. We find that GPT-3.5, specifically the text-davinci-003 model, provides surprisingly reasonable emotion predictions consistent with human annotations, but accuracy can depend on the emotion concept. Overall, the results suggest promise in the image captioning and LLM approach.", "url": "https://arxiv.org/abs/2309.13136"}, {"metadata": {"arXiv": "2309.13216", "Date": "Fri, 22 Sep 2023 23:41:24 ", "Title": "MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual", "Authors": ["Aadhar Chauhan", "Isaac Remy", "Danny Broyles", "and Karen Leung"], "Categories": "cs.CV cs.AI cs.HC cs.RO"}, "abstract": "Detecting humans from airborne visual and thermal imagery is a fundamental challenge for Wilderness Search-and-Rescue (WiSAR) teams, who must perform this function accurately in the face of immense pressure. The ability to fuse these two sensor modalities can potentially reduce the cognitive load on human operators and/or improve the effectiveness of computer vision object detection models. However, the fusion task is particularly challenging in the context of WiSAR due to hardware limitations and extreme environmental factors. This work presents Misaligned Image Synthesis and Fusion using Information from Thermal and Visual (MISFIT-V), a novel two-pronged unsupervised deep learning approach that utilizes a Generative Adversarial Network (GAN) and a cross-attention mechanism to capture the most relevant features from each modality. Experimental results show MISFIT-V offers enhanced robustness against misalignment and poor lighting/thermal environmental conditions compared to existing visual-thermal image fusion methods.", "url": "https://arxiv.org/abs/2309.13216"}, {"metadata": {"arXiv": "2309.13220", "Date": "Fri, 22 Sep 2023 23:52:58 ", "Title": "Poster: Self-Supervised Quantization-Aware Knowledge Distillation", "Authors": ["Kaiqi Zhao", "Ming Zhao"], "Categories": "cs.CV cs.AI"}, "abstract": "Quantization-aware training (QAT) starts with a pre-trained full-precision model and performs quantization during retraining. However, existing QAT works require supervision from the labels and they suffer from accuracy loss due to reduced precision. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation framework (SQAKD). SQAKD first unifies the forward and backward dynamics of various quantization functions and then reframes QAT as a co-optimization problem that simultaneously minimizes the KL-Loss and the discretization error, in a self-supervised manner. The evaluation shows that SQAKD significantly improves the performance of various state-of-the-art QAT works. SQAKD establishes stronger baselines and does not require extensive labeled training data, potentially making state-of-the-art QAT research more accessible.", "url": "https://arxiv.org/abs/2309.13220"}, {"metadata": {"arXiv": "2309.13242", "Date": "Sat, 23 Sep 2023 03:22:48 ", "Title": "UniHead: Unifying Multi-Perception for Detection Heads", "Authors": ["Hantao Zhou", "Rui Yang", "Yachao Zhang", "Haoran Duan", "Yawen Huang", "Runze Hu", "Xiu Li", "Yefeng Zheng"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "5 figures"]}, "abstract": "The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and localization branches, thus aligning the two tasks. As a plug-and-play method, the proposed UniHead can be conveniently integrated with existing detectors. Extensive experiments on the COCO dataset demonstrate that our UniHead can bring significant improvements to many detectors. For instance, the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL. The code will be publicly available. Code Url: https://github.com/zht8506/UniHead.", "url": "https://arxiv.org/abs/2309.13242"}, {"metadata": {"arXiv": "2309.13269", "Date": "Sat, 23 Sep 2023 05:27:59 ", "Title": "Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores", "Authors": ["Pengfei Liu", "Weibo Wang", "Yuhan Guo", "Jiubin Tan"], "Categories": "cs.CV cs.AI"}, "abstract": "Localization Quality Estimation (LQE) helps to improve detection performance as it benefits post processing through jointly considering classification score and localization accuracy. In this perspective, for further leveraging the close relationship between localization accuracy and IoU (Intersection-Over-Union), and for depressing those inconsistent predictions, we designed an elegant LQE branch to acquire localization quality score guided by predicted IoU. Distinctly, for alleviating the inconsistency of classification score and localization quality during training and inference, under which some predictions with low classification scores but high LQE scores will impair the performance, instead of separately and independently setting, we embedded LQE branch into classification branch, producing a joint classification-localization-quality representation. Then a novel one stage detector termed CLQ is proposed. Extensive experiments show that CLQ achieves state-of-the-arts' performance at an accuracy of 47.8 AP and a speed of 11.5 fps with ResNeXt-101 as backbone on COCO test-dev. Finally, we extend CLQ to ATSS, producing a reliable 1.2 AP gain, showing our model's strong adaptability and scalability. Codes are released at https://github.com/PanffeeReal/CLQ.", "url": "https://arxiv.org/abs/2309.13269"}, {"metadata": {"arXiv": "2309.13289", "Date": "Sat, 23 Sep 2023 07:08:57 ", "Title": "USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation", "Authors": ["Xiaofan Li", "Bo Peng", "Daipeng Yang", "Zhuyang Xie"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "9 figures", "71 references"], "ACM-class": "I.2.1"}, "abstract": "Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-saliency regions represent the background. However, intermediate regions can be hard to classify, often due to their proximity to lesion edges or interference from hair or blisters. Rather than risk potential pseudo-labeling errors or learning confusion by forcefully classifying these regions, we consider them as uncertainty regions, exempting them from pseudo-labeling and allowing the network to self-learn. Further, we employ connectivity detection and centrality detection to refine foreground pseudo-labels and reduce noise-induced errors. The application of cycle refining enhances performance further. Our method underwent thorough experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets, demonstrating that its performance is on par with weakly supervised and supervised methods, and exceeds that of other existing unsupervised methods.", "url": "https://arxiv.org/abs/2309.13289"}, {"metadata": {"arXiv": "2309.13317", "Date": "Sat, 23 Sep 2023 09:22:58 ", "Title": "Class Attendance System in Education with Deep Learning Method", "Authors": ["H\\\"udaverdi Demir", "Serkan Sava\\c{s}"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["International LET-IN 2022 Conference Proceedings Book", "October 06-08", "2022", "Ankara", "T\\\"urkiye. ISBN: 978-605-71971-1-5"], "Journal-ref": "International LET-IN (LEarning & Teaching INovations) 2022 Conference Proceedings Book, pp: 151-160, October 06-08, 2022, Ankara, Turkiye"}, "abstract": "With the advancing technology, the hardware gain of computers and the increase in the processing capacity of processors have facilitated the processing of instantaneous and real-time images. Face recognition processes are also studies in the field of image processing. Facial recognition processes are frequently used in security applications and commercial applications. Especially in the last 20 years, the high performances of artificial intelligence (AI) studies have contributed to the spread of these studies in many different fields. Education is one of them. The potential and advantages of using AI in education; can be grouped under three headings: student, teacher, and institution. One of the institutional studies may be the security of educational environments and the contribution of automation to education and training processes. From this point of view, deep learning methods, one of the sub-branches of AI, were used in this study. For object detection from images, a pioneering study has been designed and successfully implemented to keep records of students' entrance to the educational institution and to perform class attendance with images taken from the camera using image processing algorithms. The application of the study to real-life problems will be carried out in a school determined in the 2022-2023 academic year.", "url": "https://arxiv.org/abs/2309.13317"}, {"metadata": {"arXiv": "2309.13393", "Date": "Sat, 23 Sep 2023 14:35:45 ", "Title": "AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture", "Authors": ["Leonardo Saraceni", "Ionut M. Motoi", "Daniele Nardi", "Thomas A. Ciarfuglia"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["8 pages", "5 figures", "submitted to International Conference on Robotics and Automation (ICRA) 2024. Code and dataset will be soon available on my github", "after the acceptance to the conference"]}, "abstract": "The problem of multi-object tracking (MOT) consists in detecting and tracking all the objects in a video sequence while keeping a unique identifier for each object. It is a challenging and fundamental problem for robotics. In precision agriculture the challenge of achieving a satisfactory solution is amplified by extreme camera motion, sudden illumination changes, and strong occlusions. Most modern trackers rely on the appearance of objects rather than motion for association, which can be ineffective when most targets are static objects with the same appearance, as in the agricultural case. To this end, on the trail of SORT [5], we propose AgriSORT, a simple, online, real-time tracking-by-detection pipeline for precision agriculture based only on motion information that allows for accurate and fast propagation of tracks between frames. The main focuses of AgriSORT are efficiency, flexibility, minimal dependencies, and ease of deployment on robotic platforms. We test the proposed pipeline on a novel MOT benchmark specifically tailored for the agricultural context, based on video sequences taken in a table grape vineyard, particularly challenging due to strong self-similarity and density of the instances. Both the code and the dataset are available for future comparisons.", "url": "https://arxiv.org/abs/2309.13393"}, {"metadata": {"arXiv": "2309.13438", "Date": "Sat, 23 Sep 2023 17:29:38 ", "Title": "Rethinking superpixel segmentation from biologically inspired mechanisms", "Authors": ["TingYu Zhao", "Bo Peng", "Yuan Sun", "DaiPeng Yang", "ZhenGuang Zhange", "and Xi Wu"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, advancements in deep learning-based superpixel segmentation methods have brought about improvements in both the efficiency and the performance of segmentation. However, a significant challenge remains in generating superpixels that strictly adhere to object boundaries while conveying rich visual significance, especially when cross-surface color correlations may interfere with objects. Drawing inspiration from neural structure and visual mechanisms, we propose a biological network architecture comprising an Enhanced Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel segmentation. The ESM enhances semantic information by simulating the interactive projection mechanisms of the visual cortex. Additionally, the BAL emulates the spatial frequency characteristics of visual cortical cells to facilitate the generation of superpixels with strong boundary adherence. We demonstrate the effectiveness of our approach through evaluations on both the BSDS500 dataset and the NYUv2 dataset.", "url": "https://arxiv.org/abs/2309.13438"}, {"metadata": {"arXiv": "2309.13512", "Date": "Sun, 24 Sep 2023 00:20:16 ", "Title": "Object Classification Model Using Ensemble Learning with Gray-Level Co-Occurrence Matrix and Histogram Extraction", "Authors": ["Florentina Tatrin Kurniati", "Daniel HF Manongga", "Eko Sediyono", "Sri Yulianto Joko Prasetyo", "Roy Rudolf Huizen"], "Categories": "cs.CV cs.AI", "Journal-ref": "JITEKI,Vol.9,No.3,September2023,pp.793-801;http://journal.uad.ac.id/index.php/JITEKI/article/view/26683", "DOI": "10.26555/jiteki.v9i3.26683"}, "abstract": "In the field of object classification, identification based on object variations is a challenge in itself. Variations include shape, size, color, and texture, these can cause problems in recognizing and distinguishing objects accurately. The purpose of this research is to develop a classification method so that objects can be accurately identified. The proposed classification model uses Voting and Combined Classifier, with Random Forest, K-NN, Decision Tree, SVM, and Naive Bayes classification methods. The test results show that the voting method and Combined Classifier obtain quite good results with each of them, ensemble voting with an accuracy value of 92.4%, 78.6% precision, 95.2% recall, and 86.1% F1-score. While the combined classifier with an accuracy value of 99.3%, a precision of 97.6%, a recall of 100%, and a 98.8% F1-score. Based on the test results, it can be concluded that the use of the Combined Classifier and voting methods is proven to increase the accuracy value. The contribution of this research increases the effectiveness of the Ensemble Learning method, especially the voting ensemble method and the Combined Classifier in increasing the accuracy of object classification in image processing.", "url": "https://arxiv.org/abs/2309.13512"}, {"metadata": {"arXiv": "2309.13524", "Date": "Sun, 24 Sep 2023 02:10:25 ", "Title": "Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction", "Authors": ["Zechuan Zhang", "Li Sun", "Zongxin Yang", "Ling Chen", "Yi Yang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and prior-enhanced queries, leveraging the benefits of spatial localization and human body prior knowledge. Comprehensive experiments on CAPE and THuman2.0 datasets illustrate that our method outperforms state-of-the-art approaches in both geometry and texture reconstruction, exhibiting high robustness to challenging poses and loose clothing, and producing higher-resolution textures. Codes will be available at https://github.com/River-Zhang/GTA.", "url": "https://arxiv.org/abs/2309.13524"}, {"metadata": {"arXiv": "2309.13550", "Date": "Sun, 24 Sep 2023 04:48:44 ", "Title": "Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A Controllable and Interpretable AI System", "Authors": ["Trong Thang Pham", "Jacob Brecheisen", "Anh Nguyen", "Hien Nguyen", "Ngan Le"], "Categories": "cs.CV cs.AI"}, "abstract": "In the field of chest X-ray (CXR) diagnosis, existing works often focus solely on determining where a radiologist looks, typically through tasks such as detection, segmentation, or classification. However, these approaches are often designed as black-box models, lacking interpretability. In this paper, we introduce a novel and unified controllable interpretable pipeline for decoding the intense focus of radiologists in CXR diagnosis. Our approach addresses three key questions: where a radiologist looks, how long they focus on specific areas, and what findings they diagnose. By capturing the intensity of the radiologist's gaze, we provide a unified solution that offers insights into the cognitive process underlying radiological interpretation. Unlike current methods that rely on black-box machine learning models, which can be prone to extracting erroneous information from the entire input image during the diagnosis process, we tackle this issue by effectively masking out irrelevant information. Our approach leverages a vision-language model, allowing for precise control over the interpretation process while ensuring the exclusion of irrelevant features. To train our model, we utilize an eye gaze dataset to extract anatomical gaze information and generate ground truth heatmaps. Through extensive experimentation, we demonstrate the efficacy of our method. We showcase that the attention heatmaps, designed to mimic radiologists' focus, encode sufficient and relevant information, enabling accurate classification tasks using only a portion of CXR.", "url": "https://arxiv.org/abs/2309.13550"}, {"metadata": {"arXiv": "2309.13604", "Date": "Sun, 24 Sep 2023 10:48:20 ", "Title": "Distribution-Aware Continual Test Time Adaptation for Semantic Segmentation", "Authors": ["Jiayi Ni", "Senqiao Yang", "Jiaming Liu", "Xiaoqi Li", "Wenyu Jiao", "Ran Xu", "Zehui Chen", "Yi Liu", "Shanghang Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Since autonomous driving systems usually face dynamic and ever-changing environments, continual test-time adaptation (CTTA) has been proposed as a strategy for transferring deployed models to continually changing target domains. However, the pursuit of long-term adaptation often introduces catastrophic forgetting and error accumulation problems, which impede the practical implementation of CTTA in the real world. Recently, existing CTTA methods mainly focus on utilizing a majority of parameters to fit target domain knowledge through self-training. Unfortunately, these approaches often amplify the challenge of error accumulation due to noisy pseudo-labels, and pose practical limitations stemming from the heavy computational costs associated with entire model updates. In this paper, we propose a distribution-aware tuning (DAT) method to make the semantic segmentation CTTA efficient and practical in real-world applications. DAT adaptively selects and updates two small groups of trainable parameters based on data distribution during the continual adaptation process, including domain-specific parameters (DSP) and task-relevant parameters (TRP). Specifically, DSP exhibits sensitivity to outputs with substantial distribution shifts, effectively mitigating the problem of error accumulation. In contrast, TRP are allocated to positions that are responsive to outputs with minor distribution shifts, which are fine-tuned to avoid the catastrophic forgetting problem. In addition, since CTTA is a temporal task, we introduce the Parameter Accumulation Update (PAU) strategy to collect the updated DSP and TRP in target domain sequences. We conduct extensive experiments on two widely-used semantic segmentation CTTA benchmarks, achieving promising performance compared to previous state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.13604"}, {"metadata": {"arXiv": "2309.13607", "Date": "Sun, 24 Sep 2023 11:04:50 ", "Title": "MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance Field", "Authors": ["Zijiang Yang", "Zhongwei Qiu", "Chang Xu", "Dongmei Fu"], "Categories": "cs.CV cs.AI"}, "abstract": "3D style transfer aims to render stylized novel views of 3D scenes with the specified style, which requires high-quality rendering and keeping multi-view consistency. Benefiting from the ability of 3D representation from Neural Radiance Field (NeRF), existing methods learn the stylized NeRF by giving a reference style from an image. However, they suffer the challenges of high-quality stylization with texture details for multi-style transfer and stylization with multimodal guidance. In this paper, we reveal that the same objects in 3D scenes show various states (color tone, details, etc.) from different views after stylization since previous methods optimized by single-view image-based style loss functions, leading NeRF to tend to smooth texture details, further resulting in low-quality rendering. To tackle these problems, we propose a novel Multimodal-guided 3D Multi-style transfer of NeRF, termed MM-NeRF, which achieves high-quality 3D multi-style rendering with texture details and can be driven by multimodal-style guidance. First, MM-NeRF adopts a unified framework to project multimodal guidance into CLIP space and extracts multimodal style features to guide the multi-style stylization. To relieve the problem of lacking details, we propose a novel Multi-Head Learning Scheme (MLS), in which each style head predicts the parameters of the color head of NeRF. MLS decomposes the learning difficulty caused by the inconsistency of multi-style transfer and improves the quality of stylization. In addition, the MLS can generalize pre-trained MM-NeRF to any new styles by adding heads with small training costs (a few minutes). Extensive experiments on three real-world 3D scene datasets show that MM-NeRF achieves high-quality 3D multi-style stylization with multimodal guidance, keeps multi-view consistency, and keeps semantic consistency of multimodal style guidance. Codes will be released later.", "url": "https://arxiv.org/abs/2309.13607"}, {"metadata": {"arXiv": "2309.13620", "Date": "Sun, 24 Sep 2023 12:29:13 ", "Title": "PRIS: Practical robust invertible network for image steganography", "Authors": ["Hang Yang", "Yitian Xu", "Xuhua Liu", "Xiaodong Ma"], "Categories": "cs.CV cs.AI cs.CR"}, "abstract": "Image steganography is a technique of hiding secret information inside another image, so that the secret is not visible to human eyes and can be recovered when needed. Most of the existing image steganography methods have low hiding robustness when the container images affected by distortion. Such as Gaussian noise and lossy compression. This paper proposed PRIS to improve the robustness of image steganography, it based on invertible neural networks, and put two enhance modules before and after the extraction process with a 3-step training strategy. Moreover, rounding error is considered which is always ignored by existing methods, but actually it is unavoidable in practical. A gradient approximation function (GAF) is also proposed to overcome the undifferentiable issue of rounding distortion. Experimental results show that our PRIS outperforms the state-of-the-art robust image steganography method in both robustness and practicability. Codes are available at https://github.com/yanghangAI/PRIS, demonstration of our model in practical at http://yanghang.site/hide/.", "url": "https://arxiv.org/abs/2309.13620"}, {"metadata": {"arXiv": "2309.13625", "Date": "Sun, 24 Sep 2023 12:56:40 ", "Title": "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph", "Authors": ["Xin Li", "Dongze Lian", "Zhihe Lu", "Jiawang Bai", "Zhibo Chen", "and Xinchao Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by NeurIPS 2023. The manuscript will be further revised based on the reviews"]}, "abstract": "Adapter-style efficient transfer learning (ETL) has shown excellent performance in the tuning of vision-language models (VLMs) under the low-data regime, where only a few additional parameters are introduced to excavate the task-specific knowledge based on the general and powerful representation of VLMs. However, most adapter-style works face two limitations: (i) modeling task-specific knowledge with a single modality only; and (ii) overlooking the exploitation of the inter-class relationships in downstream tasks, thereby leading to sub-optimal solutions. To mitigate that, we propose an effective adapter-style tuning strategy, dubbed GraphAdapter, which performs the textual adapter by explicitly modeling the dual-modality structure knowledge (i.e., the correlation of different semantics/classes in textual and visual modalities) with a dual knowledge graph. In particular, the dual knowledge graph is established with two sub-graphs, i.e., a textual knowledge sub-graph, and a visual knowledge sub-graph, where the nodes and edges represent the semantics/classes and their correlations in two modalities, respectively. This enables the textual feature of each prompt to leverage the task-specific structure knowledge from both textual and visual modalities, yielding a more effective classifier for downstream tasks. Extensive experimental results on 11 benchmark datasets reveal that our GraphAdapter significantly outperforms previous adapter-based methods. The code will be released at https://github.com/lixinustc/GraphAdapter", "url": "https://arxiv.org/abs/2309.13625"}, {"metadata": {"arXiv": "2309.13672", "Date": "Sun, 24 Sep 2023 15:40:40 ", "Title": "Deep Reinforcement Learning for Image-to-Image Translation", "Authors": ["Xin Wang", "Ziwei Luo", "Jing Hu", "Chengming Feng", "Shu Hu", "Bin Zhu", "Xi Wu", "Siwei Lyu"], "Categories": "cs.CV cs.AI"}, "abstract": "Most existing Image-to-Image Translation (I2IT) methods generate images in a single run of a deep learning (DL) model. However, designing such a single-step model is always challenging, requiring a huge number of parameters and easily falling into bad global minimums and overfitting. In this work, we reformulate I2IT as a step-wise decision-making problem via deep reinforcement learning (DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The key feature in the RL-I2IT framework is to decompose a monolithic learning process into small steps with a lightweight model to progressively transform a source image successively to a target image. Considering that it is challenging to handle high dimensional continuous state and action spaces in the conventional RL framework, we introduce meta policy with a new concept Plan to the standard Actor-Critic model, which is of a lower dimension than the original image and can facilitate the actor to generate a tractable high dimensional action. In the RL-I2IT framework, we also employ a task-specific auxiliary learning strategy to stabilize the training process and improve the performance of the corresponding task. Experiments on several I2IT tasks demonstrate the effectiveness and robustness of the proposed method when facing high-dimensional continuous action space problems.", "url": "https://arxiv.org/abs/2309.13672"}, {"metadata": {"arXiv": "2309.13744", "Date": "Sun, 24 Sep 2023 20:28:01 ", "Title": "A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly", "Authors": ["Hao Wang", "Omkar Salunkhe", "Walter Quadrini", "Bj\\\"orn Johansson", "Dan L\\\"amkull", "Fredrik Ore", "M\\'elanie Despeisse", "Luca Fumagalli", "Johan Stahre"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "This article presents a systematic literature review on computer vision applications that have been proposed for robotized wire harness assembly, derives challenges from existing studies, and identifies opportunities for future research to promote a more practical robotized assembly of wire harnesses.", "url": "https://arxiv.org/abs/2309.13744"}, {"metadata": {"arXiv": "2309.13833", "Date": "Mon, 25 Sep 2023 02:37:52 ", "Title": "Dual Feature Augmentation Network for Generalized Zero-shot Learning", "Authors": ["Lei Xiang", "Yuan Zhou", "Haoran Duan", "Yang Long"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to BMVC2023"]}, "abstract": "Zero-shot learning (ZSL) aims to infer novel classes without training samples by transferring knowledge from seen classes. Existing embedding-based approaches for ZSL typically employ attention mechanisms to locate attributes on an image. However, these methods often ignore the complex entanglement among different attributes' visual features in the embedding space. Additionally, these methods employ a direct attribute prediction scheme for classification, which does not account for the diversity of attributes in images of the same category. To address these issues, we propose a novel Dual Feature Augmentation Network (DFAN), which comprises two feature augmentation modules, one for visual features and the other for semantic features. The visual feature augmentation module explicitly learns attribute features and employs cosine distance to separate them, thus enhancing attribute representation. In the semantic feature augmentation module, we propose a bias learner to capture the offset that bridges the gap between actual and predicted attribute values from a dataset's perspective. Furthermore, we introduce two predictors to reconcile the conflicts between local and global features. Experimental results on three benchmarks demonstrate the marked advancement of our method compared to state-of-the-art approaches. Our code is available at https://github.com/Sion1/DFAN.", "url": "https://arxiv.org/abs/2309.13833"}, {"metadata": {"arXiv": "2309.13925", "Date": "Mon, 25 Sep 2023 07:46:56 ", "Title": "UCF-Crime Annotation: A Benchmark for Surveillance Video-and-Language Understanding", "Authors": ["Tongtong Yuan", "Xuange Zhang", "Kun Liu", "Bo Liu", "Jian Jin", "Zhenzhen Jiao"], "Categories": "cs.CV cs.AI"}, "abstract": "Surveillance videos are an essential component of daily life with various critical applications, particularly in public security. However, current surveillance video tasks mainly focus on classifying and localizing anomalous events. Existing methods are limited to detecting and classifying the predefined events with unsatisfactory generalization ability and semantic understanding, although they have obtained considerable performance. To address this issue, we propose constructing the first multimodal surveillance video dataset by manually annotating the real-world surveillance dataset UCF-Crime with fine-grained event content and timing. Our newly annotated dataset, UCA (UCF-Crime Annotation), provides a novel benchmark for multimodal surveillance video analysis. It not only describes events in detailed descriptions but also provides precise temporal grounding of the events in 0.1-second intervals. UCA contains 20,822 sentences, with an average length of 23 words, and its annotated videos are as long as 102 hours. Furthermore, we benchmark the state-of-the-art models of multiple multimodal tasks on this newly created dataset, including temporal sentence grounding in videos, video captioning, and dense video captioning. Through our experiments, we found that mainstream models used in previously publicly available datasets perform poorly on multimodal surveillance video scenarios, which highlights the necessity of constructing this dataset. The link to our dataset and code is provided at: https://github.com/Xuange923/UCA-dataset.", "url": "https://arxiv.org/abs/2309.13925"}, {"metadata": {"arXiv": "2309.14117", "Date": "Mon, 25 Sep 2023 13:15:57 ", "Title": "Small Objects Matters in Weakly-supervised Semantic Segmentation", "Authors": ["Cheolhyun Mun", "Sanghuk Lee", "Youngjung Uh", "Junsuk Choe", "Hyeran Byun"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Weakly-supervised semantic segmentation (WSSS) performs pixel-wise classification given only image-level labels for training. Despite the difficulty of this task, the research community has achieved promising results over the last five years. Still, current WSSS literature misses the detailed sense of how well the methods perform on different sizes of objects. Thus we propose a novel evaluation metric to provide a comprehensive assessment across different object sizes and collect a size-balanced evaluation set to complement PASCAL VOC. With these two gadgets, we reveal that the existing WSSS methods struggle in capturing small objects. Furthermore, we propose a size-balanced cross-entropy loss coupled with a proper training strategy. It generally improves existing WSSS methods as validated upon ten baselines on three different datasets.", "url": "https://arxiv.org/abs/2309.14117"}, {"metadata": {"arXiv": "2309.14162", "Date": "Mon, 25 Sep 2023 14:13:26 ", "Title": "Data Upcycling Knowledge Distillation for Image Super-Resolution", "Authors": ["Yun Zhang", "Wei Li", "Simiao Li", "Jie Hu", "Hanting Chen", "Hailing Wang", "Zhijun Tu", "Wenjia Wang", "Bingyi Jing and Yunhe Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Knowledge distillation (KD) emerges as a challenging yet promising technique for compressing deep learning models, characterized by the transmission of extensive learning representations from proficient and computationally intensive teacher models to compact student models. However, only a handful of studies have endeavored to compress the models for single image super-resolution (SISR) through KD, with their effects on student model enhancement remaining marginal. In this paper, we put forth an approach from the perspective of efficient data utilization, namely, the Data Upcycling Knowledge Distillation (DUKD) which facilitates the student model by the prior knowledge teacher provided via upcycled in-domain data derived from their inputs. This upcycling process is realized through two efficient image zooming operations and invertible data augmentations which introduce the label consistency regularization to the field of KD for SISR and substantially boosts student model's generalization. The DUKD, due to its versatility, can be applied across a broad spectrum of teacher-student architectures. Comprehensive experiments across diverse benchmarks demonstrate that our proposed DUKD method significantly outperforms previous art, exemplified by an increase of up to 0.5dB in PSNR over baselines methods, and a 67% parameters reduced RCAN model's performance remaining on par with that of the RCAN teacher model.", "url": "https://arxiv.org/abs/2309.14162"}, {"metadata": {"arXiv": "2309.14181", "Date": "Mon, 25 Sep 2023 14:43:43 ", "Title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision", "Authors": ["Haoning Wu", "Zicheng Zhang", "Erli Zhang", "Chaofeng Chen", "Liang Liao", "Annan Wang", "Chunyi Li", "Wenxiu Sun", "Qiong Yan", "Guangtao Zhai", "Weisi Lin"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["25 pages", "preprint version", "may hot update"]}, "abstract": "The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions. c) Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess fundamental low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs.", "url": "https://arxiv.org/abs/2309.14181"}, {"metadata": {"arXiv": "2309.14183", "Date": "Mon, 25 Sep 2023 14:46:01 ", "Title": "Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition", "Authors": ["Wei He", "Kai Han", "Ying Nie", "Chengcheng Wang", "Yunhe Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by NeurIPS 2023 Track Datasets and Benchmarks"]}, "abstract": "The development of foundation vision models has pushed the general visual recognition to a high level, but cannot well address the fine-grained recognition in specialized domain such as invasive species classification. Identifying and managing invasive species has strong social and ecological value. Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems. To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species. It collects over 19K images with expert-level accurate annotations Species196-L, and 1.2M unlabeled images of invasive species Species196-U. The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi-modal models. To facilitate future research on these four learning paradigms, we conduct an empirical study of the representative methods on the introduced dataset. The dataset is publicly available at https://species-dataset.github.io/.", "url": "https://arxiv.org/abs/2309.14183"}, {"metadata": {"arXiv": "2309.14269", "Date": "Mon, 25 Sep 2023 16:29:18 ", "Title": "Unsupervised correspondence with combined geometric learning and imaging for radiotherapy applications", "Authors": ["Edward G. A. Henderson", "Marcel van Herk", "Andrew F. Green", "Eliana M. Vasquez Osorio"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in 3rd Workshop on Shape in Medical Imaging (ShapeMI 2023). This preprint has not undergone peer review or any post-submission improvements or corrections"]}, "abstract": "The aim of this study was to develop a model to accurately identify corresponding points between organ segmentations of different patients for radiotherapy applications. A model for simultaneous correspondence and interpolation estimation in 3D shapes was trained with head and neck organ segmentations from planning CT scans. We then extended the original model to incorporate imaging information using two approaches: 1) extracting features directly from image patches, and 2) including the mean square error between patches as part of the loss function. The correspondence and interpolation performance were evaluated using the geodesic error, chamfer distance and conformal distortion metrics, as well as distances between anatomical landmarks. Each of the models produced significantly better correspondences than the baseline non-rigid registration approach. The original model performed similarly to the model with direct inclusion of image features. The best performing model configuration incorporated imaging information as part of the loss function which produced more anatomically plausible correspondences. We will use the best performing model to identify corresponding anatomical points on organs to improve spatial normalisation, an important step in outcome modelling, or as an initialisation for anatomically informed registrations. All our code is publicly available at https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net", "url": "https://arxiv.org/abs/2309.14269"}, {"metadata": {"arXiv": "2309.14304", "Date": "Mon, 25 Sep 2023 17:20:51 ", "Title": "Overview of Class Activation Maps for Visualization Explainability", "Authors": ["Anh Pham Thi Minh"], "Categories": "cs.CV cs.AI", "Comments": ["6 pages"], "ACM-class": "I.2.10"}, "abstract": "Recent research in deep learning methodology has led to a variety of complex modelling techniques in computer vision (CV) that reach or even outperform human performance. Although these black-box deep learning models have obtained astounding results, they are limited in their interpretability and transparency which are critical to take learning machines to the next step to include them in sensitive decision-support systems involving human supervision. Hence, the development of explainable techniques for computer vision (XCV) has recently attracted increasing attention. In the realm of XCV, Class Activation Maps (CAMs) have become widely recognized and utilized for enhancing interpretability and insights into the decision-making process of deep learning models. This work presents a comprehensive overview of the evolution of Class Activation Map methods over time. It also explores the metrics used for evaluating CAMs and introduces auxiliary techniques to improve the saliency of these methods. The overview concludes by proposing potential avenues for future research in this evolving field.", "url": "https://arxiv.org/abs/2309.14304"}, {"metadata": {"arXiv": "2309.14309", "Date": "Mon, 25 Sep 2023 17:28:28 ", "Title": "Multiple Different Explanations for Image Classifiers", "Authors": ["Hana Chockler", "David A. Kelly", "Daniel Kroening"], "Categories": "cs.CV cs.AI"}, "abstract": "Existing explanation tools for image classifiers usually give only one single explanation for an image. For many images, however, both humans and image classifiers accept more than one explanation for the image label. Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier. In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image. Our algorithm uses a principled approach based on causal theory. We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark.", "url": "https://arxiv.org/abs/2309.14309"}, {"metadata": {"arXiv": "2309.13099", "Date": "Fri, 22 Sep 2023 15:29:15 ", "Title": "Lamarck's Revenge: Inheritance of Learned Traits Can Make Robot Evolution Better", "Authors": ["Jie Luo", "Karine Miras", "Jakub Tomczak", "Agoston E. Eiben"], "Categories": "cs.RO cs.AI", "Comments": ["preprint-nature scientific report. arXiv admin note: text overlap with arXiv:2303.12594"]}, "abstract": "Evolutionary robot systems offer two principal advantages: an advanced way of developing robots through evolutionary optimization and a special research platform to conduct what-if experiments regarding questions about evolution. Our study sits at the intersection of these. We investigate the question ``What if the 18th-century biologist Lamarck was not completely wrong and individual traits learned during a lifetime could be passed on to offspring through inheritance?'' We research this issue through simulations with an evolutionary robot framework where morphologies (bodies) and controllers (brains) of robots are evolvable and robots also can improve their controllers through learning during their lifetime. Within this framework, we compare a Lamarckian system, where learned bits of the brain are inheritable, with a Darwinian system, where they are not. Analyzing simulations based on these systems, we obtain new insights about Lamarckian evolution dynamics and the interaction between evolution and learning. Specifically, we show that Lamarckism amplifies the emergence of `morphological intelligence', the ability of a given robot body to acquire a good brain by learning, and identify the source of this success: `newborn' robots have a higher fitness because their inherited brains match their bodies better than those in a Darwinian system.", "url": "https://arxiv.org/abs/2309.13099"}, {"metadata": {"arXiv": "2309.13206", "Date": "Fri, 22 Sep 2023 23:02:21 ", "Title": "Intent-Aware Autonomous Driving: A Case Study on Highway Merging Scenarios", "Authors": ["Nishtha Mahajan", "Qi Zhang"], "Categories": "cs.RO cs.AI cs.MA"}, "abstract": "In this work, we use the communication of intent as a means to facilitate cooperation between autonomous vehicle agents. Generally speaking, intents can be any reliable information about its future behavior that a vehicle communicates with another vehicle. We implement this as an intent-sharing task atop the merging environment in the simulator of highway-env, which provides a collection of environments for learning decision-making strategies for autonomous vehicles. Under a simple setting between two agents, we carefully investigate how intent-sharing can aid the receiving vehicle in adjusting its behavior in highway merging scenarios.", "url": "https://arxiv.org/abs/2309.13206"}, {"metadata": {"arXiv": "2309.13266", "Date": "Sat, 23 Sep 2023 05:16:35 ", "Title": "Robust Navigation with Cross-Modal Fusion and Knowledge Transfer", "Authors": ["Wenzhe Cai", "Guangran Cheng", "Lingyue Kong", "Lu Dong", "Changyin Sun"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted by ICRA 2023"]}, "abstract": "Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions.", "url": "https://arxiv.org/abs/2309.13266"}, {"metadata": {"arXiv": "2309.13285", "Date": "Sat, 23 Sep 2023 06:56:28 ", "Title": "Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning", "Authors": ["Zhehui Huang", "Zhaojing Yang", "Rahul Krupani", "Bask{\\i}n \\c{S}enba\\c{s}lar", "Sumeet Batra", "Gaurav S. Sukhatme"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "End-to-end deep reinforcement learning (DRL) for quadrotor control promises many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80% obstacle density in simulation and 8 robots with 20% obstacle density in physical deployment. Video demonstrations are available on the project website at: https://sites.google.com/view/obst-avoid-swarm-rl.", "url": "https://arxiv.org/abs/2309.13285"}, {"metadata": {"arXiv": "2309.13614", "Date": "Sun, 24 Sep 2023 11:51:17 ", "Title": "Boosting Offline Reinforcement Learning for Autonomous Driving with Hierarchical Latent Skills", "Authors": ["Zenan Li", "Fan Nie", "Qiao Sun", "Fang Da", "Hang Zhao"], "Categories": "cs.RO cs.AI"}, "abstract": "Learning-based vehicle planning is receiving increasing attention with the emergence of diverse driving simulators and large-scale driving datasets. While offline reinforcement learning (RL) is well suited for these safety-critical tasks, it still struggles to plan over extended periods. In this work, we present a skill-based framework that enhances offline RL to overcome the long-horizon vehicle planning challenge. Specifically, we design a variational autoencoder (VAE) to learn skills from offline demonstrations. To mitigate posterior collapse of common VAEs, we introduce a two-branch sequence encoder to capture both discrete options and continuous variations of the complex driving skills. The final policy treats learned skills as actions and can be trained by any off-the-shelf offline RL algorithms. This facilitates a shift in focus from per-step actions to temporally extended skills, thereby enabling long-term reasoning into the future. Extensive results on CARLA prove that our model consistently outperforms strong baselines at both training and new scenarios. Additional visualizations and experiments demonstrate the interpretability and transferability of extracted skills.", "url": "https://arxiv.org/abs/2309.13614"}, {"metadata": {"arXiv": "2309.13745", "Date": "Sun, 24 Sep 2023 20:28:19 ", "Title": "Computer Vision Technology for Robotized Wire Harness Assembly", "Authors": ["Hao Wang", "Omkar Salunkhe", "Walter Quadrini", "Dan L\\\"amkull", "Fredrik Ore", "Bj\\\"orn Johansson", "Johan Stahre"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["This paper has been accepted by CIRP CMS 2023. The information of the published version will be updated later"]}, "abstract": "Wire harnesses are essential hardware for electronic systems in modern automotive vehicles. With a shift in the automotive industry towards electrification and autonomous driving, more and more automotive electronics are responsible for energy transmission and safety-critical functions such as maneuvering, driver assistance, and safety system. This paradigm shift places more demand on automotive wiring harnesses from the safety perspective and stresses the greater importance of high-quality wire harness assembly in vehicles. However, most of the current operations of wire harness assembly are still performed manually by skilled workers, and some of the manual processes are problematic from different perspectives, such as quality control and ergonomics. There is also a persistent demand in the industry to increase competitiveness and gain market share. Hence, assuring assembly quality while improving ergonomics and optimizing labor costs is desired. Robotized assembly, accomplished by robots or in human-robot collaboration, is a key enabler for fulfilling the increasingly demanding quality and safety as it enables more replicable, transparent, and comprehensible processes than completely manual operations. However, robotized assembly of wire harnesses is challenging in real environments due to the flexibility of the deformable objects, though many preliminary automation solutions have been proposed under simplified industrial configurations. Previous research efforts have proposed the use of computer vision technology to facilitate robotized automation of wire harness assembly, enabling the robots to better perceive and manipulate the flexible wire harness. This article presents an overview on computer vision technology proposed for robotized wire harness assembly and derives research gaps that require further study to facilitate a more practical robotized assembly of wire harness.", "url": "https://arxiv.org/abs/2309.13745"}, {"metadata": {"arXiv": "2309.13746", "Date": "Sun, 24 Sep 2023 20:28:35 ", "Title": "Deep Learning-Based Connector Detection for Robotized Assembly of Automotive Wire Harnesses", "Authors": ["Hao Wang and Bj\\\"orn Johansson"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["This paper has been accepted by IEEE CASE 2023 and has been presented on the conference. The information of the published version will be updated later"]}, "abstract": "The shift towards electrification and autonomous driving in the automotive industry results in more and more automotive wire harnesses being installed in modern automobiles, which stresses the great significance of guaranteeing the quality of automotive wire harness assembly. The mating of connectors is essential in the final assembly of automotive wire harnesses due to the importance of connectors on wire harness connection and signal transmission. However, the current manual operation of mating connectors leads to severe problems regarding assembly quality and ergonomics, where the robotized assembly has been considered, and different vision-based solutions have been proposed to facilitate a better perception of the robot control system on connectors. Nonetheless, there has been a lack of deep learning-based solutions for detecting automotive wire harness connectors in previous literature. This paper presents a deep learning-based connector detection for robotized automotive wire harness assembly. A dataset of twenty automotive wire harness connectors was created to train and evaluate a two-stage and a one-stage object detection model, respectively. The experiment results indicate the effectiveness of deep learning-based connector detection for automotive wire harness assembly but are limited by the design of the exteriors of connectors.", "url": "https://arxiv.org/abs/2309.13746"}, {"metadata": {"arXiv": "2309.13893", "Date": "Mon, 25 Sep 2023 06:16:09 ", "Title": "Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments", "Authors": ["Bernard Lange", "Jiachen Li", "and Mykel J. Kochenderfer"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "Navigating complex and dynamic environments requires autonomous vehicles (AVs) to reason about both visible and occluded regions. This involves predicting the future motion of observed agents, inferring occluded ones, and modeling their interactions based on vectorized scene representations of the partially observable environment. However, prior work on occlusion inference and trajectory prediction have developed in isolation, with the former based on simplified rasterized methods and the latter assuming full environment observability. We introduce the Scene Informer, a unified approach for predicting both observed agent trajectories and inferring occlusions in a partially observable setting. It uses a transformer to aggregate various input modalities and facilitate selective queries on occlusions that might intersect with the AV's planned path. The framework estimates occupancy probabilities and likely trajectories for occlusions, as well as forecast motion for observed agents. We explore common observability assumptions in both domains and their performance impact. Our approach outperforms existing methods in both occupancy prediction and trajectory prediction in partially observable setting on the Waymo Open Motion Dataset.", "url": "https://arxiv.org/abs/2309.13893"}, {"metadata": {"arXiv": "2309.13937", "Date": "Mon, 25 Sep 2023 08:13:49 ", "Title": "SPOTS: Stable Placement of Objects with Reasoning in Semi-Autonomous Teleoperation Systems", "Authors": ["Joonhyung Lee", "Sangbeom Park", "Jeongeun Park", "Kyungjae Lee", "Sungjoon Choi"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages"]}, "abstract": "Pick-and-place is one of the fundamental tasks in robotics research. However, the attention has been mostly focused on the ``pick'' task, leaving the ``place'' task relatively unexplored. In this paper, we address the problem of placing objects in the context of a teleoperation framework. Particularly, we focus on two aspects of the place task: stability robustness and contextual reasonableness of object placements. Our proposed method combines simulation-driven physical stability verification via real-to-sim and the semantic reasoning capability of large language models. In other words, given place context information (e.g., user preferences, object to place, and current scene information), our proposed method outputs a probability distribution over the possible placement candidates, considering the robustness and reasonableness of the place task. Our proposed method is extensively evaluated in two simulation and one real world environments and we show that our method can greatly increase the physical plausibility of the placement as well as contextual soundness while considering user preferences.", "url": "https://arxiv.org/abs/2309.13937"}, {"metadata": {"arXiv": "2309.14272", "Date": "Mon, 25 Sep 2023 16:34:54 ", "Title": "Perception-and-Energy-aware Motion Planning for UAV using Learning-based Model under Heteroscedastic Uncertainty", "Authors": ["Reiya Takemura and Genya Ishigami"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "7 figures", "2 tables. Submitted article for presentation at the 2024 IEEE International Conference on Robotics and Automation (ICRA)"], "ACM-class": "I.2.8; I.2.9; I.2.10"}, "abstract": "Global navigation satellite systems (GNSS) denied environments/conditions require unmanned aerial vehicles (UAVs) to energy-efficiently and reliably fly. To this end, this study presents perception-and-energy-aware motion planning for UAVs in GNSS-denied environments. The proposed planner solves the trajectory planning problem by optimizing a cost function consisting of two indices: the total energy consumption of a UAV and the perception quality of light detection and ranging (LiDAR) sensor mounted on the UAV. Before online navigation, a high-fidelity simulator acquires a flight dataset to learn energy consumption for the UAV and heteroscedastic uncertainty associated with LiDAR measurements, both as functions of the horizontal velocity of the UAV. The learned models enable the online planner to estimate energy consumption and perception quality, reducing UAV battery usage and localization errors. Simulation experiments in a photorealistic environment confirm that the proposed planner can address the trade-off between energy efficiency and perception quality under heteroscedastic uncertainty. The open-source code is released at https://gitlab.com/ReI08/perception-energy-planner.", "url": "https://arxiv.org/abs/2309.14272"}, {"metadata": {"arXiv": "2309.13071", "Date": "Mon, 18 Sep 2023 20:39:14 ", "Title": "Tree-Based Reconstructive Partitioning: A Novel Low-Data Level Generation Approach", "Authors": ["Emily Halina and Matthew Guzdial"], "Categories": "cs.AI cs.LG", "Comments": ["9 pages", "3 figures", "The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)"]}, "abstract": "Procedural Content Generation (PCG) is the algorithmic generation of content, often applied to games. PCG and PCG via Machine Learning (PCGML) have appeared in published games. However, it can prove difficult to apply these approaches in the early stages of an in-development game. PCG requires expertise in representing designer notions of quality in rules or functions, and PCGML typically requires significant training data, which may not be available early in development. In this paper, we introduce Tree-based Reconstructive Partitioning (TRP), a novel PCGML approach aimed to address this problem. Our results, across two domains, demonstrate that TRP produces levels that are more playable and coherent, and that the approach is more generalizable with less training data. We consider TRP to be a promising new approach that can afford the introduction of PCGML into the early stages of game development without requiring human expertise or significant training data.", "url": "https://arxiv.org/abs/2309.13071"}, {"metadata": {"arXiv": "2309.13075", "Date": "Wed, 20 Sep 2023 15:59:54 ", "Title": "SCREWS: A Modular Framework for Reasoning with Revisions", "Authors": ["Kumar Shridhar", "Harsh Jhamtani", "Hao Fang", "Benjamin Van Durme", "Jason Eisner", "Patrick Xia"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Large language models (LLMs) can improve their accuracy on various tasks through iteratively refining and revising their output based on feedback. We observe that these revisions can introduce errors, in which case it is better to roll back to a previous result. Further, revisions are typically homogeneous: they use the same reasoning method that produced the initial answer, which may not correct errors. To enable exploration in this space, we present SCREWS, a modular framework for reasoning with revisions. It is comprised of three main modules: Sampling, Conditional Resampling, and Selection, each consisting of sub-modules that can be hand-selected per task. We show that SCREWS not only unifies several previous approaches under a common framework, but also reveals several novel strategies for identifying improved reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning strategies for each: arithmetic word problems, multi-hop question answering, and code debugging. Heterogeneous revision strategies prove to be important, as does selection between original and revised candidates.", "url": "https://arxiv.org/abs/2309.13075"}, {"metadata": {"arXiv": "2309.13078", "Date": "Thu, 21 Sep 2023 02:46:20 ", "Title": "LPML: LLM-Prompting Markup Language for Mathematical Reasoning", "Authors": ["Ryutaro Yamauchi", "Sho Sonoda", "Akiyoshi Sannai", "Wataru Kumagai"], "Categories": "cs.AI cs.LG cs.PL"}, "abstract": "In utilizing large language models (LLMs) for mathematical reasoning, addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge. In this paper, we propose a novel framework that integrates the Chain-of-Thought (CoT) method with an external tool (Python REPL). We discovered that by prompting LLMs to generate structured text in XML-like markup language, we could seamlessly integrate CoT and the external tool and control the undesired behaviors of LLMs. With our approach, LLMs can utilize Python computation to rectify errors within CoT. We applied our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and demonstrated that combining CoT and Python REPL through the markup language enhances the reasoning capability of LLMs. Our approach enables LLMs to write the markup language and perform advanced mathematical reasoning using only zero-shot prompting.", "url": "https://arxiv.org/abs/2309.13078"}, {"metadata": {"arXiv": "2309.13214", "Date": "Fri, 22 Sep 2023 23:24:37 ", "Title": "Assessing the Impact of Personality on Affective States from Video Game Communication", "Authors": ["Atieh Kashani", "Johannes Pfau", "Magy Seif El-Nasr"], "Categories": "cs.AI cs.HC cs.LG"}, "abstract": "Individual differences in personality determine our preferences, traits and values, which should similarly hold for the way we express ourselves. With current advancements and transformations of technology and society, text-based communication has become ordinary and often even surpasses natural voice conversations -- with distinct challenges and opportunities. In this exploratory work, we investigate the impact of personality on the tendency how players of a team-based collaborative alternate reality game express themselves affectively. We collected chat logs from eleven players over two weeks, labeled them according to their affective state, and assessed the connection between them and the five-factor personality domains and facets. After applying multi-linear regression, we found a series of reasonable correlations between (combinations of) personality variables and expressed affect -- as increased confusion could be predicted by lower self-competence (C1), personal annoyance by vulnerability to stress (N6) and expressing anger occured more often in players that are prone to anxiety (N1), less humble and modest (A5), think less carefully before they act (C6) and have higher neuroticism (N). Expanding the data set, sample size and input modalities in subsequent work, we aim to confirm these findings and reveal even more interesting connections that could inform affective computing and games user research equally.", "url": "https://arxiv.org/abs/2309.13214"}, {"metadata": {"arXiv": "2309.13188", "Date": "Fri, 22 Sep 2023 21:32:07 ", "Title": "Masked Discriminators for Content-Consistent Unpaired Image-to-Image Translation", "Authors": ["Bonifaz Stuhr", "J\\\"urgen Brauer", "Bernhard Schick", "Jordi Gonz\\`alez"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["24 pages", "22 figures", "under review"], "ACM-class": "I.2; I.3; I.4; I.5; I.6"}, "abstract": "A common goal of unpaired image-to-image translation is to preserve content consistency between source images and translated images while mimicking the style of the target domain. Due to biases between the datasets of both domains, many methods suffer from inconsistencies caused by the translation process. Most approaches introduced to mitigate these inconsistencies do not constrain the discriminator, leading to an even more ill-posed training setup. Moreover, none of these approaches is designed for larger crop sizes. In this work, we show that masking the inputs of a global discriminator for both domains with a content-based mask is sufficient to reduce content inconsistencies significantly. However, this strategy leads to artifacts that can be traced back to the masking process. To reduce these artifacts, we introduce a local discriminator that operates on pairs of small crops selected with a similarity sampling strategy. Furthermore, we apply this sampling strategy to sample global input crops from the source and target dataset. In addition, we propose feature-attentive denormalization to selectively incorporate content-based statistics into the generator stream. In our experiments, we show that our method achieves state-of-the-art performance in photorealistic sim-to-real translation and weather translation and also performs well in day-to-night translation. Additionally, we propose the cKVD metric, which builds on the sKVD metric and enables the examination of translation quality at the class or category level.", "url": "https://arxiv.org/abs/2309.13188"}, {"metadata": {"arXiv": "2309.13952", "Date": "Mon, 25 Sep 2023 08:38:11 ", "Title": "VidChapters-7M: Video Chapters at Scale", "Authors": ["Antoine Yang", "Arsha Nagrani", "Ivan Laptev", "Josef Sivic", "Cordelia Schmid"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["Accepted at NeurIPS 2023 Track on Datasets and Benchmarks; Project Webpage: https://antoyang.github.io/vidchapters.html ; 31 pages; 8 figures"]}, "abstract": "Segmenting long videos into chapters enables users to quickly navigate to the information of their interest. This important topic has been understudied due to the lack of publicly released datasets. To address this issue, we present VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters in total. VidChapters-7M is automatically created from videos online in a scalable manner by scraping user-annotated chapters and hence without any additional manual annotation. We introduce the following three tasks based on this data. First, the video chapter generation task consists of temporally segmenting the video and generating a chapter title for each segment. To further dissect the problem, we also define two variants of this task: video chapter generation given ground-truth boundaries, which requires generating a chapter title given an annotated video segment, and video chapter grounding, which requires temporally localizing a chapter given its annotated title. We benchmark both simple baselines and state-of-the-art video-language models for these three tasks. We also show that pretraining on VidChapters-7M transfers well to dense video captioning tasks in both zero-shot and finetuning settings, largely improving the state of the art on the YouCook2 and ViTT benchmarks. Finally, our experiments reveal that downstream performance scales well with the size of the pretraining dataset. Our dataset, code, and models are publicly available at https://antoyang.github.io/vidchapters.html.", "url": "https://arxiv.org/abs/2309.13952"}, {"metadata": {"arXiv": "2309.14293", "Date": "Mon, 25 Sep 2023 17:04:30 ", "Title": "NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields", "Authors": ["Saeejith Nair", "Yuhao Chen", "Mohammad Javad Shafiee", "Alexander Wong"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["9 pages"]}, "abstract": "Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but their prohibitively high computational complexity limits deployability, especially on resource-constrained platforms. To enable practical usage of NeRFs, quality tuning is essential to reduce computational complexity, akin to adjustable graphics settings in video games. However while existing solutions strive for efficiency, they use one-size-fits-all architectures regardless of scene complexity, although the same architecture may be unnecessarily large for simple scenes but insufficient for complex ones. Thus as NeRFs become more widely used for 3D visualization, there is a need to dynamically optimize the neural network component of NeRFs to achieve a balance between computational complexity and specific targets for synthesis quality. Addressing this gap, we introduce NAS-NeRF: a generative neural architecture search strategy uniquely tailored to generate NeRF architectures on a per-scene basis by optimizing the trade-off between complexity and performance, while adhering to constraints on computational budget and minimum synthesis quality. Our experiments on the Blender synthetic dataset show the proposed NAS-NeRF can generate architectures up to 5.74$\\times$ smaller, with 4.19$\\times$ fewer FLOPs, and 1.93$\\times$ faster on a GPU than baseline NeRFs, without suffering a drop in SSIM. Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to 23$\\times$ smaller, 22$\\times$ fewer FLOPs, and 4.7$\\times$ faster than baseline NeRFs with only a 5.3\\% average SSIM drop. The source code for our work is also made publicly available at https://saeejithnair.github.io/NAS-NeRF.", "url": "https://arxiv.org/abs/2309.14293"}, {"metadata": {"arXiv": "2309.14335", "Date": "Mon, 25 Sep 2023 17:58:46 ", "Title": "UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation", "Authors": ["Jianglin Fu", "Shikai Li", "Yuming Jiang", "Kwan-Yee Lin", "Wayne Wu", "Ziwei Liu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV2023. Project page: https://unitedhuman.github.io/ Github: https://github.com/UnitedHuman/UnitedHuman"]}, "abstract": "Human generation has achieved significant progress. Nonetheless, existing methods still struggle to synthesize specific regions such as faces and hands. We argue that the main reason is rooted in the training data. A holistic human dataset inevitably has insufficient and low-resolution information on local parts. Therefore, we propose to use multi-source datasets with various resolution images to jointly learn a high-resolution human generative model. However, multi-source data inherently a) contains different parts that do not spatially align into a coherent human, and b) comes with different scales. To tackle these challenges, we propose an end-to-end framework, UnitedHuman, that empowers continuous GAN with the ability to effectively utilize multi-source data for high-resolution human generation. Specifically, 1) we design a Multi-Source Spatial Transformer that spatially aligns multi-source images to full-body space with a human parametric model. 2) Next, a continuous GAN is proposed with global-structural guidance and CutMix consistency. Patches from different datasets are then sampled and transformed to supervise the training of this scale-invariant generative model. Extensive experiments demonstrate that our model jointly learned from multi-source data achieves superior quality than those learned from a holistic dataset.", "url": "https://arxiv.org/abs/2309.14335"}, {"metadata": {"arXiv": "2309.13077", "Date": "Thu, 21 Sep 2023 02:16:05 ", "Title": "A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression", "Authors": ["Moonjung Eo", "Suhyun Kang and Wonjong Rhee"], "Categories": "cs.LG cs.AI eess.IV", "Comments": ["11 pages", "5 figures", "6 tables"]}, "abstract": "Filter pruning and low-rank decomposition are two of the foundational techniques for structured compression. Although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a \\textit{Differentiable Framework~(DF)} that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-base optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue for advancing structured compression techniques.", "url": "https://arxiv.org/abs/2309.13077"}, {"metadata": {"arXiv": "2309.13103", "Date": "Fri, 22 Sep 2023 17:35:03 ", "Title": "OpportunityFinder: A Framework for Automated Causal Inference", "Authors": ["Huy Nguyen", "Prince Grover", "Devashish Khatwani"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["KDD 2023 Workshop - Causal Inference and Machine Learning in Practice"]}, "abstract": "We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts and Scientists, (2) abstraction of multiple algorithms under a single I/O interface, (3) support for causal impact analysis under binary treatment with panel data and (4) dynamic selection of algorithm based on scale of data.", "url": "https://arxiv.org/abs/2309.13103"}, {"metadata": {"arXiv": "2309.13160", "Date": "Fri, 22 Sep 2023 19:52:28 ", "Title": "GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior", "Authors": ["Mariano Rivera"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["5 pages", "3 figures"], "ACM-class": "I.2.10"}, "abstract": "Variational Autoencoders (VAEs) have become a cornerstone in generative modeling and representation learning within machine learning. This paper explores a nuanced aspect of VAEs, focusing on interpreting the Kullback Leibler (KL) Divergence, a critical component within the Evidence Lower Bound (ELBO) that governs the trade-off between reconstruction accuracy and regularization. While the KL Divergence enforces alignment between latent variable distributions and a prior imposing a structure on the overall latent space but leaves individual variable distributions unconstrained. The proposed method redefines the ELBO with a mixture of Gaussians for the posterior probability, introduces a regularization term to prevent variance collapse, and employs a PatchGAN discriminator to enhance texture realism. Implementation details involve ResNetV2 architectures for both the Encoder and Decoder. The experiments demonstrate the ability to generate realistic faces, offering a promising solution for enhancing VAE based generative models.", "url": "https://arxiv.org/abs/2309.13160"}, {"metadata": {"arXiv": "2309.13181", "Date": "Fri, 22 Sep 2023 21:03:33 ", "Title": "Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning", "Authors": ["Lakshmi Narasimhan Govindarajan", "Rex G Liu", "Drew Linsley", "Alekh Karkada Ashok", "Max Reuter", "Michael J Frank", "Thomas Serre"], "Categories": "cs.LG cs.AI cs.CV cs.RO"}, "abstract": "Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like Procgen, and provides a pathway towards more efficient progress.", "url": "https://arxiv.org/abs/2309.13181"}, {"metadata": {"arXiv": "2309.13192", "Date": "Fri, 22 Sep 2023 21:55:18 ", "Title": "Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation", "Authors": ["Kai Huang", "Hanyun Yin", "Heng Huang", "Wei Gao"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages"]}, "abstract": "Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most appropriate set of tensors in training. Such selection in GreenTrainer is made based on a given objective of FLOPs reduction, which can flexibly adapt to the carbon footprint in energy supply and the need in Green AI. Experiment results over multiple open-sourced LLM models and abstractive summarization datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy loss. Compared to the existing fine-tuning techniques such as LoRa, GreenTrainer can achieve up to 4% improvement on model accuracy with on-par FLOPs reduction.", "url": "https://arxiv.org/abs/2309.13192"}, {"metadata": {"arXiv": "2309.13246", "Date": "Sat, 23 Sep 2023 03:59:02 ", "Title": "Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models", "Authors": ["Dangxing Chen"], "Categories": "cs.LG cs.AI q-fin.CP"}, "abstract": "In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.", "url": "https://arxiv.org/abs/2309.13246"}, {"metadata": {"arXiv": "2309.13256", "Date": "Sat, 23 Sep 2023 04:41:55 ", "Title": "Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks", "Authors": ["Zhaohan Xi", "Tianyu Du", "Changjiang Li", "Ren Pang", "Shouling Ji", "Jinghui Chen", "Fenglong Ma", "Ting Wang"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by NeurIPS'23"]}, "abstract": "Pre-trained language models (PLMs) have demonstrated remarkable performance as few-shot learners. However, their security risks under such settings are largely unexplored. In this work, we conduct a pilot study showing that PLMs as few-shot learners are highly vulnerable to backdoor attacks while existing defenses are inadequate due to the unique challenges of few-shot scenarios. To address such challenges, we advocate MDP, a novel lightweight, pluggable, and effective defense for PLMs as few-shot learners. Specifically, MDP leverages the gap between the masking-sensitivity of poisoned and clean samples: with reference to the limited few-shot data as distributional anchors, it compares the representations of given samples under varying masking and identifies poisoned samples as ones with significant variations. We show analytically that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness. The empirical evaluation using benchmark datasets and representative attacks validates the efficacy of MDP.", "url": "https://arxiv.org/abs/2309.13256"}, {"metadata": {"arXiv": "2309.13363", "Date": "Sat, 23 Sep 2023 12:58:16 ", "Title": "MLPST: MLP is All You Need for Spatio-Temporal Prediction", "Authors": ["Zijian Zhang", "Ze Huang", "Zhiwei Hu", "Xiangyu Zhao", "Wanyu Wang", "Zitao Liu", "Junbo Zhang", "S. Joe Qin and Hongwei Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.", "url": "https://arxiv.org/abs/2309.13363"}, {"metadata": {"arXiv": "2309.13365", "Date": "Sat, 23 Sep 2023 13:06:20 ", "Title": "Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs", "Authors": ["Hecotr Kohler", "Riad Akrour", "Philippe Preux"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2304.05839"]}, "abstract": "Interpretability of AI models allows for user safety checks to build trust in such AIs. In particular, Decision Trees (DTs) provide a global look at the learned model and transparently reveal which features of the input are critical for making a decision. However, interpretability is hindered if the DT is too large. To learn compact trees, a recent Reinforcement Learning (RL) framework has been proposed to explore the space of DTs using deep RL. This framework augments a decision problem (e.g. a supervised classification task) with additional actions that gather information about the features of an otherwise hidden input. By appropriately penalizing these actions, the agent learns to optimally trade-off size and performance of DTs. In practice, a reactive policy for a partially observable Markov decision process (MDP) needs to be learned, which is still an open problem. We show in this paper that deep RL can fail even on simple toy tasks of this class. However, when the underlying decision problem is a supervised classification task, we show that finding the optimal tree can be cast as a fully observable Markov decision problem and be solved efficiently, giving rise to a new family of algorithms for learning DTs that go beyond the classical greedy maximization ones.", "url": "https://arxiv.org/abs/2309.13365"}, {"metadata": {"arXiv": "2309.13378", "Date": "Sat, 23 Sep 2023 13:51:09 ", "Title": "Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment", "Authors": ["Yutong Xia", "Yuxuan Liang", "Haomin Wen", "Xu Liu", "Kun Wang", "Zhengyang Zhou", "Roger Zimmermann"], "Categories": "cs.LG cs.AI", "Comments": ["To appear at NeurIPS 2023"]}, "abstract": "Spatio-Temporal Graph (STG) forecasting is a fundamental task in many real-world applications. Spatio-Temporal Graph Neural Networks have emerged as the most popular method for STG forecasting, but they often struggle with temporal out-of-distribution (OoD) issues and dynamic spatial causation. In this paper, we propose a novel framework called CaST to tackle these two challenges via causal treatments. Concretely, leveraging a causal lens, we first build a structural causal model to decipher the data generation process of STGs. To handle the temporal OoD issue, we employ the back-door adjustment by a novel disentanglement block to separate invariant parts and temporal environments from input data. Moreover, we utilize the front-door adjustment and adopt the Hodge-Laplacian operator for edge-level convolution to model the ripple effect of causation. Experiments results on three real-world datasets demonstrate the effectiveness and practicality of CaST, which consistently outperforms existing methods with good interpretability.", "url": "https://arxiv.org/abs/2309.13378"}, {"metadata": {"arXiv": "2309.13409", "Date": "Sat, 23 Sep 2023 15:42:54 ", "Title": "Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data", "Authors": ["Sarit Maitra", "Vivek Mishra", "Srashti Dwivedi", "Sukanya Kundu", "Goutam Kumar Kundu"], "Categories": "cs.LG cs.AI cs.NA math.NA math.ST stat.TH"}, "abstract": "This study introduces a novel forecasting strategy that leverages the power of fractional differencing (FD) to capture both short- and long-term dependencies in time series data. Unlike traditional integer differencing methods, FD preserves memory in series while stabilizing it for modeling purposes. By applying FD to financial data from the SPY index and incorporating sentiment analysis from news reports, this empirical analysis explores the effectiveness of FD in conjunction with binary classification of target variables. Supervised classification algorithms were employed to validate the performance of FD series. The results demonstrate the superiority of FD over integer differencing, as confirmed by Receiver Operating Characteristic/Area Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.", "url": "https://arxiv.org/abs/2309.13409"}, {"metadata": {"arXiv": "2309.13411", "Date": "Sat, 23 Sep 2023 15:48:35 ", "Title": "Towards Attributions of Input Variables in a Coalition", "Authors": ["Xinhao Zheng", "Huiqi Deng", "Quanshi Zhang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "This paper aims to develop a new attribution method to explain the conflict between individual variables' attributions and their coalition's attribution from a fully new perspective. First, we find that the Shapley value can be reformulated as the allocation of Harsanyi interactions encoded by the AI model. Second, based the re-alloction of interactions, we extend the Shapley value to the attribution of coalitions. Third we ective. We derive the fundamental mechanism behind the conflict. This conflict come from the interaction containing partial variables in their coalition.", "url": "https://arxiv.org/abs/2309.13411"}, {"metadata": {"arXiv": "2309.13414", "Date": "Sat, 23 Sep 2023 15:55:12 ", "Title": "State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory", "Authors": ["Shida Wang", "Beichen Xue"], "Categories": "cs.LG cs.AI math.DS", "Comments": ["17 pages", "6 figures,"]}, "abstract": "State-space models have gained popularity in sequence modelling due to their simple and efficient network structures. However, the absence of nonlinear activation along the temporal direction limits the model's capacity. In this paper, we prove that stacking state-space models with layer-wise nonlinear activation is sufficient to approximate any continuous sequence-to-sequence relationship. Our findings demonstrate that the addition of layer-wise nonlinear activation enhances the model's capacity to learn complex sequence patterns. Meanwhile, it can be seen both theoretically and empirically that the state-space models do not fundamentally resolve the exponential decaying memory issue. Theoretical results are justified by numerical verifications.", "url": "https://arxiv.org/abs/2309.13414"}, {"metadata": {"arXiv": "2309.13429", "Date": "Sat, 23 Sep 2023 16:53:07 ", "Title": "Modeling Student Performance in Game-Based Learning Environments", "Authors": ["Hyunbae Jeon", "Harry He", "Anthony Wang", "Susanna Spooner"], "Categories": "cs.LG cs.AI"}, "abstract": "This study investigates game-based learning in the context of the educational game \"Jo Wilder and the Capitol Case,\" focusing on predicting student performance using various machine learning models, including K-Nearest Neighbors (KNN), Multi-Layer Perceptron (MLP), and Random Forest. The research aims to identify the features most predictive of student performance and correct question answering. By leveraging gameplay data, we establish complete benchmarks for these models and explore the importance of applying proper data aggregation methods. By compressing all numeric data to min/max/mean/sum and categorical data to first, last, count, and nunique, we reduced the size of the original training data from 4.6 GB to 48 MB of preprocessed training data, maintaining high F1 scores and accuracy. Our findings suggest that proper preprocessing techniques can be vital in enhancing the performance of non-deep-learning-based models. The MLP model outperformed the current state-of-the-art French Touch model, achieving an F-1 score of 0.83 and an accuracy of 0.74, suggesting its suitability for this dataset. Future research should explore using larger datasets, other preprocessing techniques, more advanced deep learning techniques, and real-world applications to provide personalized learning recommendations to students based on their predicted performance. This paper contributes to the understanding of game-based learning and provides insights into optimizing educational game experiences for improved student outcomes and skill development.", "url": "https://arxiv.org/abs/2309.13429"}, {"metadata": {"arXiv": "2309.13439", "Date": "Sat, 23 Sep 2023 17:42:13 ", "Title": "Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning", "Authors": ["Berken Utku Demirel and Christian Holz"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["To be published in the Proceedings of NeurIPS 2023"]}, "abstract": "The success of contrastive learning is well known to be dependent on data augmentation. Although the degree of data augmentations has been well controlled by utilizing pre-defined techniques in some domains like vision, time-series data augmentation is less explored and remains a challenging problem due to the complexity of the data generation mechanism, such as the intricate mechanism involved in the cardiovascular system. Moreover, there is no widely recognized and general time-series augmentation method that can be applied across different tasks. In this paper, we propose a novel data augmentation method for quasi-periodic time-series tasks that aims to connect intra-class samples together, and thereby find order in the latent space. Our method builds upon the well-known mixup technique by incorporating a novel approach that accounts for the periodic nature of non-stationary time-series. Also, by controlling the degree of chaos created by data augmentation, our method leads to improved feature representations and performance on downstream tasks. We evaluate our proposed method on three time-series tasks, including heart rate estimation, human activity recognition, and cardiovascular disease detection. Extensive experiments against state-of-the-art methods show that the proposed approach outperforms prior works on optimal data generation and known data augmentation techniques in the three tasks, reflecting the effectiveness of the presented method. Source code: https://github.com/eth-siplab/Finding_Order_in_Chaos", "url": "https://arxiv.org/abs/2309.13439"}, {"metadata": {"arXiv": "2309.13442", "Date": "Sat, 23 Sep 2023 18:02:57 ", "Title": "How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study Using Machine Learning", "Authors": ["Farah Abu Hamad", "Rama Hasiba", "Deema Shahwan", "and Huthaifa I. Ashqar"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Driving behavior is considered a unique driving habit of each driver and has a significant impact on road safety. Classifying driving behavior and introducing policies based on the results can reduce the severity of crashes on the road. Roundabouts are particularly interesting because of the interconnected interaction between different road users at the area of roundabouts, which different driving behavior is hypothesized. This study investigates driving behavior at roundabouts in a mixed traffic environment using a data-driven unsupervised machine learning to classify driving behavior at three roundabouts in Germany. We used a dataset of vehicle kinematics to a group of different vehicles and vulnerable road users (VRUs) at roundabouts and classified them into three categories (i.e., conservative, normal, and aggressive). Results showed that most of the drivers proceeding through a roundabout can be mostly classified into two driving styles: conservative and normal because traffic speeds in roundabouts are relatively lower than in other signalized and unsignalized intersections. Results also showed that about 77% of drivers who interacted with pedestrians or cyclists were classified as conservative drivers compared to about 42% of conservative drivers that did not interact or about 51% from all drivers. It seems that drivers tend to behave abnormally as they interact with VRUs at roundabouts, which increases the risk of crashes when an intersection is multimodal. Results of this study could be helpful in improving the safety of roads by allowing policymakers to determine the effective and suitable safety countermeasures. Results will also be beneficial for the Advanced Driver Assistance System (ADAS) as the technology is being deployed in a mixed traffic environment.", "url": "https://arxiv.org/abs/2309.13442"}, {"metadata": {"arXiv": "2309.13500", "Date": "Sat, 23 Sep 2023 23:37:55 ", "Title": "Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy", "Authors": ["Lin Ni", "Sijie Wang", "Zeyu Zhang", "Xiaoxuan Li", "Xianda Zheng", "Paul Denny", "and Jiamou Liu"], "Categories": "cs.LG cs.AI", "MSC-class": "97P80"}, "abstract": "As an emerging education strategy, learnersourcing offers the potential for personalized learning content creation, but also grapples with the challenge of predicting student performance due to inherent noise in student-generated data. While graph-based methods excel in capturing dense learner-question interactions, they falter in cold start scenarios, characterized by limited interactions, as seen when questions lack substantial learner responses. In response, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially advantageous in addressing cold start scenarios characterized by limited graph data interactions. Validation across five real-world datasets sourced from the PeerWise platform underscores our approach's effectiveness. Our method outperforms baselines, showcasing enhanced predictive accuracy and robustness.", "url": "https://arxiv.org/abs/2309.13500"}, {"metadata": {"arXiv": "2309.13508", "Date": "Sun, 24 Sep 2023 00:13:16 ", "Title": "Guided Cooperation in Hierarchical Reinforcement Learning via Model-based Rollout", "Authors": ["Haoran Wang", "Yaoru Sun", "Fang Wang", "Yeming Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Goal-conditioned hierarchical reinforcement learning (HRL) presents a promising approach for enabling effective exploration in complex long-horizon reinforcement learning (RL) tasks via temporal abstraction. Yet, most goal-conditioned HRL algorithms focused on the subgoal discovery, regardless of inter-level coupling. In essence, for hierarchical systems, the increased inter-level communication and coordination can induce more stable and robust policy improvement. Here, we present a goal-conditioned HRL framework with Guided Cooperation via Model-based Rollout (GCMR), which estimates forward dynamics to promote inter-level cooperation. The GCMR alleviates the state-transition error within off-policy correction through a model-based rollout, further improving the sample efficiency. Meanwhile, to avoid being disrupted by these corrected but possibly unseen or faraway goals, lower-level Q-function gradients are constrained using a gradient penalty with a model-inferred upper bound, leading to a more stable behavioral policy. Besides, we propose a one-step rollout-based planning to further facilitate inter-level cooperation, where the higher-level Q-function is used to guide the lower-level policy by estimating the value of future states so that global task information is transmitted downwards to avoid local pitfalls. Experimental results demonstrate that incorporating the proposed GCMR framework with ACLG, a disentangled variant of HIGL, yields more stable and robust policy improvement than baselines and substantially outperforms previous state-of-the-art (SOTA) HRL algorithms in both hard-exploration problems and robotic control.", "url": "https://arxiv.org/abs/2309.13508"}, {"metadata": {"arXiv": "2309.13528", "Date": "Sun, 24 Sep 2023 02:36:42 ", "Title": "Iterative Reachability Estimation for Safe Reinforcement Learning", "Authors": ["Milan Ganai", "Zheng Gong", "Chenning Yu", "Sylvia Herbert", "Sicun Gao"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted in NeurIPS 2023"]}, "abstract": "Ensuring safety is important for the practical deployment of reinforcement learning (RL). Various challenges must be addressed, such as handling stochasticity in the environments, providing rigorous guarantees of persistent state-wise safety satisfaction, and avoiding overly conservative behaviors that sacrifice performance. We propose a new framework, Reachability Estimation for Safe Policy Optimization (RESPO), for safety-constrained RL in general stochastic settings. In the feasible set where there exist violation-free policies, we optimize for rewards while maintaining persistent safety. Outside this feasible set, our optimization produces the safest behavior by guaranteeing entrance into the feasible set whenever possible with the least cumulative discounted violations. We introduce a class of algorithms using our novel reachability estimation function to optimize in our proposed framework and in similar frameworks such as those concurrently handling multiple hard and soft constraints. We theoretically establish that our algorithms almost surely converge to locally optimal policies of our safe optimization framework. We evaluate the proposed methods on a diverse suite of safe RL environments from Safety Gym, PyBullet, and MuJoCo, and show the benefits in improving both reward performance and safety compared with state-of-the-art baselines.", "url": "https://arxiv.org/abs/2309.13528"}, {"metadata": {"arXiv": "2309.13575", "Date": "Sun, 24 Sep 2023 08:04:28 ", "Title": "Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantization", "Authors": ["Christopher Subia-Waud and Srinandan Dasmahapatra"], "Categories": "cs.LG cs.AI"}, "abstract": "Weight-sharing quantization has emerged as a technique to reduce energy expenditure during inference in large neural networks by constraining their weights to a limited set of values. However, existing methods for weight-sharing quantization often make assumptions about the treatment of weights based on value alone that neglect the unique role weight position plays. This paper proposes a probabilistic framework based on Bayesian neural networks (BNNs) and a variational relaxation to identify which weights can be moved to which cluster centre and to what degree based on their individual position-specific learned uncertainty distributions. We introduce a new initialisation setting and a regularisation term which allow for the training of BNNs under complex dataset-model combinations. By leveraging the flexibility of weight values captured through a probability distribution, we enhance noise resilience and downstream compressibility. Our iterative clustering procedure demonstrates superior compressibility and higher accuracy compared to state-of-the-art methods on both ResNet models and the more complex transformer-based architectures. In particular, our method outperforms the state-of-the-art quantization method top-1 accuracy by 1.6% on ImageNet using DeiT-Tiny, with its 5 million+ weights now represented by only 296 unique values.", "url": "https://arxiv.org/abs/2309.13575"}, {"metadata": {"arXiv": "2309.13599", "Date": "Sun, 24 Sep 2023 10:10:21 ", "Title": "From Cluster Assumption to Graph Convolution: Graph-based Semi-Supervised Learning Revisited", "Authors": ["Zheng Wang", "Hongming Ding", "Li Pan", "Jianhua Li", "Zhiguo Gong", "Philip S. Yu"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph-based semi-supervised learning (GSSL) has long been a hot research topic. Traditional methods are generally shallow learners, based on the cluster assumption. Recently, graph convolutional networks (GCNs) have become the predominant techniques for their promising performance. In this paper, we theoretically discuss the relationship between these two types of methods in a unified optimization framework. One of the most intriguing findings is that, unlike traditional ones, typical GCNs may not jointly consider the graph structure and label information at each layer. Motivated by this, we further propose three simple but powerful graph convolution methods. The first is a supervised method OGC which guides the graph convolution process with labels. The others are two unsupervised methods: GGC and its multi-scale version GGCM, both aiming to preserve the graph structure information during the convolution process. Finally, we conduct extensive experiments to show the effectiveness of our methods.", "url": "https://arxiv.org/abs/2309.13599"}, {"metadata": {"arXiv": "2309.13636", "Date": "Sun, 24 Sep 2023 13:30:50 ", "Title": "Development of an intelligent system for the detection of corona virus using artificial neural network", "Authors": ["Nwafor Emmanuel O", "Ngozi Maryrose Umeh", "Ikechukwu Ekene Onyenwe"], "Categories": "cs.LG cs.AI", "Comments": ["13 pages", "8 Figures"], "Journal-ref": "International Journal of Real-Time Application and Computing Systems (IJORTACS) Volume 1, Issue XI, November 2022, pp. 294-306"}, "abstract": "This paper presents the development of an intelligent system for the detection of coronavirus using artificial neural network. This was done after series of literature review which indicated that high fever accounts for 87.9% of the COVID-19 symptoms. 683 temperature data of COVID-19 patients at >= 38C^o were collected from Colliery hospital Enugu, Nigeria and used to train an artificial neural network detective model for the detection of COVID-19. The reference model generated was used converted into Verilog codes using Hardware Description Language (HDL) and then burn into a Field Programming Gate Array (FPGA) controller using FPGA tool in Matlab. The performance of the model when evaluated using confusion matrix, regression and means square error (MSE) showed that the regression value is 0.967; the accuracy is 97% and then MSE is 0.00100Mu. These results all implied that the new detection system for is reliable and very effective for the detection of COVID-19.", "url": "https://arxiv.org/abs/2309.13636"}, {"metadata": {"arXiv": "2309.13705", "Date": "Sun, 24 Sep 2023 17:37:45 ", "Title": "A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data", "Authors": ["Wenqiang Li", "Weijun Li", "Lina Yu", "Min Wu", "Jingyi Liu", "Yanjie Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Symbolic regression (SR) is a powerful technique for discovering the underlying mathematical expressions from observed data. Inspired by the success of deep learning, recent efforts have focused on two categories for SR methods. One is using a neural network or genetic programming to search the expression tree directly. Although this has shown promising results, the large search space poses difficulties in learning constant factors and processing high-dimensional problems. Another approach is leveraging a transformer-based model training on synthetic data and offers advantages in inference speed. However, this method is limited to fixed small numbers of dimensions and may encounter inference problems when given data is out-of-distribution compared to the synthetic data. In this work, we propose DySymNet, a novel neural-guided Dynamic Symbolic Network for SR. Instead of searching for expressions within a large search space, we explore DySymNet with various structures and optimize them to identify expressions that better-fitting the data. With a topology structure like neural networks, DySymNet not only tackles the challenge of high-dimensional problems but also proves effective in optimizing constants. Based on extensive numerical experiments using low-dimensional public standard benchmarks and the well-known SRBench with more variables, our method achieves state-of-the-art performance in terms of fitting accuracy and robustness to noise.", "url": "https://arxiv.org/abs/2309.13705"}, {"metadata": {"arXiv": "2309.13773", "Date": "Sun, 24 Sep 2023 23:01:00 ", "Title": "GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust Parameters of Unseen Limited Precision Neural Networks", "Authors": ["Stone Yun", "Alexander Wong"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Poster and extended abstract to be presented at the Workshop for Low Bit Quantized Neural Networks (LQBNN) @ ICCV 2023"]}, "abstract": "Graph Hypernetworks (GHN) can predict the parameters of varying unseen CNN architectures with surprisingly good accuracy at a fraction of the cost of iterative optimization. Following these successes, preliminary research has explored the use of GHNs to predict quantization-robust parameters for 8-bit and 4-bit quantized CNNs. However, this early work leveraged full-precision float32 training and only quantized for testing. We explore the impact of quantization-aware training and/or other quantization-based training strategies on quantized robustness and performance of GHN predicted parameters for low-precision CNNs. We show that quantization-aware training can significantly improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs and even lead to greater-than-random accuracy for 2-bit quantized CNNs. These promising results open the door for future explorations such as investigating the use of GHN predicted parameters as initialization for further quantized training of individual CNNs, further exploration of \"extreme bitwidth\" quantization, and mixed precision quantization schemes.", "url": "https://arxiv.org/abs/2309.13773"}, {"metadata": {"arXiv": "2309.13781", "Date": "Mon, 25 Sep 2023 00:16:43 ", "Title": "Explainable Machine Learning for ICU Readmission Prediction", "Authors": ["Alex de S\\'a", "Daniel Gould", "Anna Fedyukova", "Mitchell Nicholas", "Lucy Dockrell", "Calvin Fletcher", "David Pilcher", "Daniel Capurro", "David Ascher", "Khaled El-Khawas", "Douglas Pires"], "Categories": "cs.LG cs.AI", "Comments": ["To whom correspondence should be addressed to D.E.V.P at douglas.pires@unimelb.edu.au. Correspondence may also be addressed to A.G.C.S at alex.desa@baker.edu.au or K.E-K. at k.elkhawas@alfred.org.au. A.G.C.S", "D.G.", "A.F. and K.E-K contributed equally to this work"]}, "abstract": "The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 admissions and 6,021 readmissions) while validating it on monocentric (i.e., the MIMIC IV cohort with 382,278 patients, 523,740 admissions and 5,984 readmissions) and multicentric settings. Our machine learning pipeline achieved predictive performance in terms of the area of the receiver operating characteristic curve (AUC) up to 0.7 with a Random Forest classification model, yielding an overall good calibration and consistency on validation sets. From explanations provided by the constructed models, we could also derive a set of insightful conclusions, primarily on variables related to vital signs and blood tests (e.g., albumin, blood urea nitrogen and hemoglobin levels), demographics (e.g., age, and admission height and weight), and ICU-associated variables (e.g., unit type). These insights provide an invaluable source of information during clinicians' decision-making while discharging ICU patients.", "url": "https://arxiv.org/abs/2309.13781"}, {"metadata": {"arXiv": "2309.13782", "Date": "Mon, 25 Sep 2023 00:20:50 ", "Title": "On the Computational Benefit of Multimodal Learning", "Authors": ["Zhou Lu"], "Categories": "cs.LG cs.AI"}, "abstract": "Human perception inherently operates in a multimodal manner. Similarly, as machines interpret the empirical world, their learning processes ought to be multimodal. The recent, remarkable successes in empirical multimodal learning underscore the significance of understanding this paradigm. Yet, a solid theoretical foundation for multimodal learning has eluded the field for some time. While a recent study by Lu (2023) has shown the superior sample complexity of multimodal learning compared to its unimodal counterpart, another basic question remains: does multimodal learning also offer computational advantages over unimodal learning? This work initiates a study on the computational benefit of multimodal learning. We demonstrate that, under certain conditions, multimodal learning can outpace unimodal learning exponentially in terms of computation. Specifically, we present a learning task that is NP-hard for unimodal learning but is solvable in polynomial time by a multimodal algorithm. Our construction is based on a novel modification to the intersection of two half-spaces problem.", "url": "https://arxiv.org/abs/2309.13782"}, {"metadata": {"arXiv": "2309.13885", "Date": "Mon, 25 Sep 2023 05:44:40 ", "Title": "TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning", "Authors": ["Jing Zhu", "Xiang Song", "Vassilis N. Ioannidis", "Danai Koutra", "Christos Faloutsos"], "Categories": "cs.LG cs.AI cs.CL cs.CV cs.SI", "Comments": ["preprint", "ongoing work"]}, "abstract": "How can we enhance the node features acquired from Pretrained Models (PMs) to better suit downstream graph learning tasks? Graph Neural Networks (GNNs) have become the state-of-the-art approach for many high-impact, real-world graph applications. For feature-rich graphs, a prevalent practice involves utilizing a PM directly to generate features, without incorporating any domain adaptation techniques. Nevertheless, this practice is suboptimal because the node features extracted from PM are graph-agnostic and prevent GNNs from fully utilizing the potential correlations between the graph structure and node features, leading to a decline in GNNs performance. In this work, we seek to improve the node features obtained from a PM for downstream graph tasks and introduce TOUCHUP-G, which has several advantages. It is (a) General: applicable to any downstream graph task, including link prediction which is often employed in recommender systems; (b) Multi-modal: able to improve raw features of any modality (e.g. images, texts, audio); (c) Principled: it is closely related to a novel metric, feature homophily, which we propose to quantify the potential correlations between the graph structure and node features and we show that TOUCHUP-G can effectively shrink the discrepancy between the graph structure and node features; (d) Effective: achieving state-of-the-art results on four real-world datasets spanning different tasks and modalities.", "url": "https://arxiv.org/abs/2309.13885"}, {"metadata": {"arXiv": "2309.14029", "Date": "Mon, 25 Sep 2023 10:51:47 ", "Title": "Diffeomorphic Transformations for Time Series Analysis: An Efficient Approach to Nonlinear Warping", "Authors": ["I\\~nigo Martinez"], "Categories": "cs.LG cs.AI", "Comments": ["PhD Thesis", "defended at the University of Navarra on July 17", "2023. 277 pages", "8 chapters", "1 appendix"], "DOI": "10.15581/10171/67243"}, "abstract": "The proliferation and ubiquity of temporal data across many disciplines has sparked interest for similarity, classification and clustering methods specifically designed to handle time series data. A core issue when dealing with time series is determining their pairwise similarity, i.e., the degree to which a given time series resembles another. Traditional distance measures such as the Euclidean are not well-suited due to the time-dependent nature of the data. Elastic metrics such as dynamic time warping (DTW) offer a promising approach, but are limited by their computational complexity, non-differentiability and sensitivity to noise and outliers. This thesis proposes novel elastic alignment methods that use parametric \\& diffeomorphic warping transformations as a means of overcoming the shortcomings of DTW-based metrics. The proposed method is differentiable \\& invertible, well-suited for deep learning architectures, robust to noise and outliers, computationally efficient, and is expressive and flexible enough to capture complex patterns. Furthermore, a closed-form solution was developed for the gradient of these diffeomorphic transformations, which allows an efficient search in the parameter space, leading to better solutions at convergence. Leveraging the benefits of these closed-form diffeomorphic transformations, this thesis proposes a suite of advancements that include: (a) an enhanced temporal transformer network for time series alignment and averaging, (b) a deep-learning based time series classification model to simultaneously align and classify signals with high accuracy, (c) an incremental time series clustering algorithm that is warping-invariant, scalable and can operate under limited computational and time resources, and finally, (d) a normalizing flow model that enhances the flexibility of affine transformations in coupling and autoregressive layers.", "url": "https://arxiv.org/abs/2309.14029"}, {"metadata": {"arXiv": "2309.14053", "Date": "Mon, 25 Sep 2023 11:35:10 ", "Title": "Revisiting LARS for Large Batch Training Generalization of Neural Networks", "Authors": ["Khoi Do", "Duong Nguyen", "Hoa Nguyen", "Long Tran-Thanh", "and Quoc-Viet Pham"], "Categories": "cs.LG cs.AI"}, "abstract": "LARS and LAMB have emerged as prominent techniques in Large Batch Learning (LBL), ensuring the stability of AI training. One of the primary challenges in LBL is convergence stability, where the AI agent usually gets trapped into the sharp minimizer. Addressing this challenge, a relatively recent technique, known as warm-up, has been employed. However, warm-up lacks a strong theoretical foundation, leaving the door open for further exploration of more efficacious algorithms. In light of this situation, we conduct empirical experiments to analyze the behaviors of the two most popular optimizers in the LARS family: LARS and LAMB, with and without a warm-up strategy. Our analyses give us a comprehension of the novel LARS, LAMB, and the necessity of a warm-up technique in LBL. Building upon these insights, we propose a novel algorithm called Time Varying LARS (TVLARS), which facilitates robust training in the initial phase without the need for warm-up. Experimental evaluation demonstrates that TVLARS achieves competitive results with LARS and LAMB when warm-up is utilized while surpassing their performance without the warm-up technique.", "url": "https://arxiv.org/abs/2309.14053"}, {"metadata": {"arXiv": "2309.14054", "Date": "Mon, 25 Sep 2023 11:36:20 ", "Title": "Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning in Generative Adversarial Networks", "Authors": ["Piyush Tiwary", "Atri Guha", "Subhodip Panda", "Prathosh A.P"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["15 pages", "12 figures"]}, "abstract": "The increased attention to regulating the outputs of deep generative models, driven by growing concerns about privacy and regulatory compliance, has highlighted the need for effective control over these models. This necessity arises from instances where generative models produce outputs containing undesirable, offensive, or potentially harmful content. To tackle this challenge, the concept of machine unlearning has emerged, aiming to forget specific learned information or to erase the influence of undesired data subsets from a trained model. The objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained GAN where the underlying training data set is inaccessible. Our approach is inspired by a crucial observation: the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. This method unfolds in two stages: in the initial stage, we adapt the pre-trained GAN using negative samples provided by the user, while in the subsequent stage, we focus on unlearning the undesired feature. During the latter phase, we train the pre-trained GAN using positive samples, incorporating a repulsion regularizer. This regularizer encourages the model's parameters to be away from the parameters associated with the adapted model from the first stage while also maintaining the quality of generated samples. To the best of our knowledge, our approach stands as first method addressing unlearning in GANs. We validate the effectiveness of our method through comprehensive experiments.", "url": "https://arxiv.org/abs/2309.14054"}, {"metadata": {"arXiv": "2309.14078", "Date": "Mon, 25 Sep 2023 12:13:56 ", "Title": "ODE-based Recurrent Model-free Reinforcement Learning for POMDPs", "Authors": ["Xuanle Zhao", "Duzhen Zhang", "Liyuan Han", "Tielin Zhang", "Bo Xu"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Neural ordinary differential equations (ODEs) are widely recognized as the standard for modeling physical mechanisms, which help to perform approximate inference in unknown physical or biological environments. In partially observable (PO) environments, how to infer unseen information from raw observations puzzled the agents. By using a recurrent policy with a compact context, context-based reinforcement learning provides a flexible way to extract unobservable information from historical transitions. To help the agent extract more dynamics-related information, we present a novel ODE-based recurrent model combines with model-free reinforcement learning (RL) framework to solve partially observable Markov decision processes (POMDPs). We experimentally demonstrate the efficacy of our methods across various PO continuous control and meta-RL tasks. Furthermore, our experiments illustrate that our method is robust against irregular observations, owing to the ability of ODEs to model irregularly-sampled time series.", "url": "https://arxiv.org/abs/2309.14078"}, {"metadata": {"arXiv": "2309.14209", "Date": "Mon, 25 Sep 2023 15:14:54 ", "Title": "Continual Driving Policy Optimization with Closed-Loop Individualized Curricula", "Authors": ["Haoyi Niu", "Yizhou Xu", "Xingjian Jiang", "Jianming Hu"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for flexible implementation choices: AV Evaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as a collision prediction task, where it estimates the chance of AV failures in these scenarios at each iteration. Subsequently, by re-sampling from historical scenarios based on these failure probabilities, CLIC tailors individualized curricula for downstream training, aligning them with the evaluated capability of AV. Accordingly, CLIC not only maximizes the utilization of the vast pre-collected scenario library for closed-loop driving policy optimization but also facilitates AV improvement by individualizing its training with more challenging cases out of those poorly organized scenarios. Experimental results clearly indicate that CLIC surpasses other curriculum-based training strategies, showing substantial improvement in managing risky scenarios, while still maintaining proficiency in handling simpler cases.", "url": "https://arxiv.org/abs/2309.14209"}, {"metadata": {"arXiv": "2309.14216", "Date": "Mon, 25 Sep 2023 15:22:28 ", "Title": "MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation", "Authors": ["Zekun Cai", "Renhe Jiang", "Xinyu Yang", "Zhaonan Wang", "Diansheng Guo", "Hiroki Kobayashi", "Xuan Song and Ryosuke Shibasaki"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by CIKM 2023"], "DOI": "10.1145/3583780.3614962"}, "abstract": "Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.", "url": "https://arxiv.org/abs/2309.14216"}, {"metadata": {"arXiv": "2309.14221", "Date": "Mon, 25 Sep 2023 15:25:59 ", "Title": "Accelerating Machine Learning Algorithms with Adaptive Sampling", "Authors": ["Mo Tiwari"], "Categories": "cs.LG cs.AI", "Comments": ["PhD Thesis"], "ACM-class": "I.1.2; I.5.3; I.2.0; I.2.m"}, "abstract": "The era of huge data necessitates highly efficient machine learning algorithms. Many common machine learning algorithms, however, rely on computationally intensive subroutines that are prohibitively expensive on large datasets. Oftentimes, existing techniques subsample the data or use other methods to improve computational efficiency, at the expense of incurring some approximation error. This thesis demonstrates that it is often sufficient, instead, to substitute computationally intensive subroutines with a special kind of randomized counterparts that results in almost no degradation in quality.", "url": "https://arxiv.org/abs/2309.14221"}, {"metadata": {"arXiv": "2309.14235", "Date": "Mon, 25 Sep 2023 15:47:07 ", "Title": "Stackelberg Driver Model for Continual Policy Improvement in Scenario-Based Closed-Loop Autonomous Driving", "Authors": ["Haoyi Niu", "Qimao Chen", "Yingyue Li", "Jianming Hu"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["8 pages", "6 figures"]}, "abstract": "The deployment of autonomous vehicles (AVs) has faced hurdles due to the dominance of rare but critical corner cases within the long-tail distribution of driving scenarios, which negatively affects their overall performance. To address this challenge, adversarial generation methods have emerged as a class of efficient approaches to synthesize safety-critical scenarios for AV testing. However, these generated scenarios are often underutilized for AV training, resulting in the potential for continual AV policy improvement remaining untapped, along with a deficiency in the closed-loop design needed to achieve it. Therefore, we tailor the Stackelberg Driver Model (SDM) to accurately characterize the hierarchical nature of vehicle interaction dynamics, facilitating iterative improvement by engaging background vehicles (BVs) and AV in a sequential game-like interaction paradigm. With AV acting as the leader and BVs as followers, this leader-follower modeling ensures that AV would consistently refine its policy, always taking into account the additional information that BVs play the best response to challenge AV. Extensive experiments have shown that our algorithm exhibits superior performance compared to several baselines especially in higher dimensional scenarios, leading to substantial advancements in AV capabilities while continually generating progressively challenging scenarios.", "url": "https://arxiv.org/abs/2309.14235"}, {"metadata": {"arXiv": "2309.14243", "Date": "Mon, 25 Sep 2023 16:03:08 ", "Title": "Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation", "Authors": ["Zihang Wang", "Maowei Jiang"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages. arXiv admin note: text overlap with arXiv:2007.05929 by other authors"]}, "abstract": "Reinforcement learning (RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states, instead of simply transmitting in the same episode and it allows the model to better understand the interdependencies between states and learn scarce sample information more efficiently. To promote versatility, we extend the imagination mechanism to function as a plug-and-play module that can be seamlessly and fluidly integrated into other widely adopted RL models. Our experiments demonstrate that Imagination mechanism consistently boosts four mainstream SOTA RL-algorithms, such as SAC, PPO, DDPG, and DQN, by a considerable margin, ultimately leading to superior performance than before across various tasks. For access to our code and data, please visit https://github.com/Zero-coder/FECAM.", "url": "https://arxiv.org/abs/2309.14243"}, {"metadata": {"arXiv": "2309.14331", "Date": "Mon, 25 Sep 2023 17:56:54 ", "Title": "LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference", "Authors": ["Hongwu Peng and Ran Ran and Yukui Luo and Jiahui Zhao and Shaoyi Huang and Kiran Thorat and Tong Geng and Chenghong Wang and Xiaolin Xu and Wujie Wen and Caiwen Ding"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["NeurIPS 2023 accepted publication"], "ACM-class": "E.3; I.2; B.0"}, "abstract": "The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems. The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data. To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data. However, it introduces substantial computational overhead in practical applications. To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference. LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal. This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth. (2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model. (3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN. Remarkably, LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving an inference accuracy of 75% and notably reducing multiplication depth.", "url": "https://arxiv.org/abs/2309.14331"}, {"metadata": {"arXiv": "2309.13224", "Date": "Sat, 23 Sep 2023 00:26:49 ", "Title": "Pick Planning Strategies for Large-Scale Package Manipulation", "Authors": ["Shuai Li", "Azarakhsh Keipour", "Kevin Jamieson", "Nicolas Hudson", "Sicong Szhao", "Charles Swan and Kostas Bekris"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "Learning Meets Model-based Methods for Manipulation and Grasping Workshop. arXiv admin note: substantial text overlap with arXiv:2305.10272"]}, "abstract": "Automating warehouse operations can reduce logistics overhead costs, ultimately driving down the final price for consumers, increasing the speed of delivery, and enhancing the resiliency to market fluctuations. This extended abstract showcases a large-scale package manipulation from unstructured piles in Amazon Robotics' Robot Induction (Robin) fleet, which is used for picking and singulating up to 6 million packages per day and so far has manipulated over 2 billion packages. It describes the various heuristic methods developed over time and their successor, which utilizes a pick success predictor trained on real production data. To the best of the authors' knowledge, this work is the first large-scale deployment of learned pick quality estimation methods in a real production system.", "url": "https://arxiv.org/abs/2309.13224"}, {"metadata": {"arXiv": "2309.13635", "Date": "Sun, 24 Sep 2023 13:21:33 ", "Title": "PanopticNDT: Efficient and Robust Panoptic Mapping", "Authors": ["Daniel Seichter", "Benedict Stephan", "S\\\"ohnke Benedikt Fischedick", "Steffen M\\\"uller", "Leonard Rabes", "Horst-Michael Gross"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "2023"]}, "abstract": "As the application scenarios of mobile robots are getting more complex and challenging, scene understanding becomes increasingly crucial. A mobile robot that is supposed to operate autonomously in indoor environments must have precise knowledge about what objects are present, where they are, what their spatial extent is, and how they can be reached; i.e., information about free space is also crucial. Panoptic mapping is a powerful instrument providing such information. However, building 3D panoptic maps with high spatial resolution is challenging on mobile robots, given their limited computing capabilities. In this paper, we propose PanopticNDT - an efficient and robust panoptic mapping approach based on occupancy normal distribution transform (NDT) mapping. We evaluate our approach on the publicly available datasets Hypersim and ScanNetV2. The results reveal that our approach can represent panoptic information at a higher level of detail than other state-of-the-art approaches while enabling real-time panoptic mapping on mobile robots. Finally, we prove the real-world applicability of PanopticNDT with qualitative results in a domestic application.", "url": "https://arxiv.org/abs/2309.13635"}, {"metadata": {"arXiv": "2309.13707", "Date": "Sun, 24 Sep 2023 17:40:19 ", "Title": "ORLA*: Mobile Manipulator-Based Object Rearrangement with Lazy A*", "Authors": ["Kai Gao", "Yan Ding", "Shiqi Zhang", "Jingjin Yu"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "Effectively performing object rearrangement is an essential skill for mobile manipulators, e.g., setting up a dinner table or organizing a desk. A key challenge in such problems is deciding an appropriate manipulation order for objects to effectively untangle dependencies between objects while considering the necessary motions for realizing the manipulations (e.g., pick and place). To our knowledge, computing time-optimal multi-object rearrangement solutions for mobile manipulators remains a largely untapped research direction. In this research, we propose ORLA*, which leverages delayed (lazy) evaluation in searching for a high-quality object pick and place sequence that considers both end-effector and mobile robot base travel. ORLA* also supports multi-layered rearrangement tasks considering pile stability using machine learning. Employing an optimal solver for finding temporary locations for displacing objects, ORLA* can achieve global optimality. Through extensive simulation and ablation study, we confirm the effectiveness of ORLA* delivering quality solutions for challenging rearrangement instances. Supplementary materials are available at: https://gaokai15.github.io/ORLA-Star/", "url": "https://arxiv.org/abs/2309.13707"}, {"metadata": {"arXiv": "2309.13908", "Date": "Mon, 25 Sep 2023 07:11:43 ", "Title": "A comparison of controller architectures and learning mechanisms for arbitrary robot morphologies", "Authors": ["Jie Luo", "Jakub Tomczak", "Karine Miras", "Agoston E. Eiben"], "Categories": "cs.RO cs.AI cs.LG cs.NE"}, "abstract": "The main question this paper addresses is: What combination of a robot controller and a learning method should be used, if the morphology of the learning robot is not known in advance? Our interest is rooted in the context of morphologically evolving modular robots, but the question is also relevant in general, for system designers interested in widely applicable solutions. We perform an experimental comparison of three controller-and-learner combinations: one approach where controllers are based on modelling animal locomotion (Central Pattern Generators, CPG) and the learner is an evolutionary algorithm, a completely different method using Reinforcement Learning (RL) with a neural network controller architecture, and a combination `in-between' where controllers are neural networks and the learner is an evolutionary algorithm. We apply these three combinations to a test suite of modular robots and compare their efficacy, efficiency, and robustness. Surprisingly, the usual CPG-based and RL-based options are outperformed by the in-between combination that is more robust and efficient than the other two setups.", "url": "https://arxiv.org/abs/2309.13908"}, {"metadata": {"arXiv": "2309.14341", "Date": "Mon, 25 Sep 2023 17:59:55 ", "Title": "Extreme Parkour with Legged Robots", "Authors": ["Xuxin Cheng", "Kexin Shi", "Ananye Agarwal", "Deepak Pathak"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "Comments": ["Website and videos at https://extreme-parkour.github.io/"]}, "abstract": "Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eye-muscle coordination and movement. Getting robots to do the same task requires overcoming similar challenges. Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances. This restricts them to tightly controlled settings such as a predetermined obstacle course in labs. In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology. In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts. We show how a single neural net policy operating directly from a camera image, trained in simulation with large-scale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end. We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties. Parkour videos at https://extreme-parkour.github.io/", "url": "https://arxiv.org/abs/2309.14341"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

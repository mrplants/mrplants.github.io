<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.01904", "Date": "Tue, 03 Oct 2023 09:22:06 ", "Title": "Beyond the Benchmark: Detecting Diverse Anomalies in Videos", "Authors": ["Yoav Arad", "Michael Werman"], "Categories": "cs.CV cs.LG"}, "abstract": "Video Anomaly Detection (VAD) plays a crucial role in modern surveillance systems, aiming to identify various anomalies in real-world situations. However, current benchmark datasets predominantly emphasize simple, single-frame anomalies such as novel object detection. This narrow focus restricts the advancement of VAD models. In this research, we advocate for an expansion of VAD investigations to encompass intricate anomalies that extend beyond conventional benchmark boundaries. To facilitate this, we introduce two datasets, HMDB-AD and HMDB-Violence, to challenge models with diverse action-based anomalies. These datasets are derived from the HMDB51 action recognition dataset. We further present Multi-Frame Anomaly Detection (MFAD), a novel method built upon the AI-VAD framework. AI-VAD utilizes single-frame features such as pose estimation and deep image encoding, and two-frame features such as object velocity. They then apply a density estimation algorithm to compute anomaly scores. To address complex multi-frame anomalies, we add a deep video encoding features capturing long-range temporal dependencies, and logistic regression to enhance final score calculation. Experimental results confirm our assumptions, highlighting existing models limitations with new anomaly types. MFAD excels in both simple and complex anomaly detection scenarios.", "url": "https://arxiv.org/abs/2310.01904"}, {"metadata": {"arXiv": "2310.01924", "Date": "Tue, 03 Oct 2023 09:59:59 ", "Title": "RoFormer for Position Aware Multiple Instance Learning in Whole Slide Image Classification", "Authors": ["Etienne Pochet", "Rami Maroun", "Roger Trullo"], "Categories": "cs.CV cs.LG"}, "abstract": "Whole slide image (WSI) classification is a critical task in computational pathology. However, the gigapixel-size of such images remains a major challenge for the current state of deep-learning. Current methods rely on multiple-instance learning (MIL) models with frozen feature extractors. Given the the high number of instances in each image, MIL methods have long assumed independence and permutation-invariance of patches, disregarding the tissue structure and correlation between patches. Recent works started studying this correlation between instances but the computational workload of such a high number of tokens remained a limiting factor. In particular, relative position of patches remains unaddressed. We propose to apply a straightforward encoding module, namely a RoFormer layer , relying on memory-efficient exact self-attention and relative positional encoding. This module can perform full self-attention with relative position encoding on patches of large and arbitrary shaped WSIs, solving the need for correlation between instances and spatial modeling of tissues. We demonstrate that our method outperforms state-of-the-art MIL models on three commonly used public datasets (TCGA-NSCLC, BRACS and Camelyon16)) on weakly supervised classification tasks. Code is available at https://github.com/Sanofi-Public/DDS-RoFormerMIL", "url": "https://arxiv.org/abs/2310.01924"}, {"metadata": {"arXiv": "2310.02000", "Date": "Tue, 03 Oct 2023 12:19:19 ", "Title": "MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray Images of Multiple Body Parts", "Authors": ["Weibin Liao and Haoyi Xiong and Qingzhong Wang and Yan Mo and Xuhong Li and Yi Liu and Zeyu Chen and Siyu Huang and Dejing Dou"], "Categories": "cs.CV cs.LG", "Comments": ["accepted by Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022"], "DOI": "10.1007/978-3-031-16452-1_15"}, "abstract": "While self-supervised learning (SSL) algorithms have been widely used to pre-train deep models, few efforts [11] have been done to improve representation learning of X-ray image analysis with SSL pre-trained models. In this work, we study a novel self-supervised pre-training pipeline, namely Multi-task Self-super-vised Continual Learning (MUSCLE), for multiple medical imaging tasks, such as classification and segmentation, using X-ray images collected from multiple body parts, including heads, lungs, and bones. Specifically, MUSCLE aggregates X-rays collected from multiple body parts for MoCo-based representation learning, and adopts a well-designed continual learning (CL) procedure to further pre-train the backbone subject various X-ray analysis tasks jointly. Certain strategies for image pre-processing, learning schedules, and regularization have been used to solve data heterogeneity, overfitting, and catastrophic forgetting problems for multi-task/dataset learning in MUSCLE.We evaluate MUSCLE using 9 real-world X-ray datasets with various tasks, including pneumonia classification, skeletal abnormality classification, lung segmentation, and tuberculosis (TB) detection. Comparisons against other pre-trained models [7] confirm the proof-of-concept that self-supervised multi-task/dataset continual pre-training could boost the performance of X-ray image analysis.", "url": "https://arxiv.org/abs/2310.02000"}, {"metadata": {"arXiv": "2310.02011", "Date": "Tue, 03 Oct 2023 12:34:31 ", "Title": "Decoding Human Activities: Analyzing Wearable Accelerometer and Gyroscope Data for Activity Recognition", "Authors": ["Utsab Saha", "Sawradip Saha", "Tahmid Kabir", "Shaikh Anowarul Fattah", "Mohammad Saquib"], "Categories": "cs.CV cs.LG"}, "abstract": "A person's movement or relative positioning effectively generates raw electrical signals that can be read by computing machines to apply various manipulative techniques for the classification of different human activities. In this paper, a stratified multi-structural approach based on a Residual network ensembled with Residual MobileNet is proposed, termed as FusionActNet. The proposed method involves using carefully designed Residual blocks for classifying the static and dynamic activities separately because they have clear and distinct characteristics that set them apart. These networks are trained independently, resulting in two specialized and highly accurate models. These models excel at recognizing activities within a specific superclass by taking advantage of the unique algorithmic benefits of architectural adjustments. Afterward, these two ResNets are passed through a weighted ensemble-based Residual MobileNet. Subsequently, this ensemble proficiently discriminates between a specific static and a specific dynamic activity, which were previously identified based on their distinct feature characteristics in the earlier stage. The proposed model is evaluated using two publicly accessible datasets; namely, UCI HAR and Motion-Sense. Therein, it successfully handled the highly confusing cases of data overlap. Therefore, the proposed approach achieves a state-of-the-art accuracy of 96.71% and 95.35% in the UCI HAR and Motion-Sense datasets respectively.", "url": "https://arxiv.org/abs/2310.02011"}, {"metadata": {"arXiv": "2310.02265", "Date": "Tue, 03 Oct 2023 17:59:58 ", "Title": "DREAM: Visual Decoding from Reversing Human Visual System", "Authors": ["Weihao Xia", "Raoul de Charette", "Cengiz \\\"Oztireli", "Jing-Hao Xue"], "Categories": "cs.CV cs.LG eess.IV q-bio.NC", "Comments": ["Project Page: https://weihaox.github.io/DREAM"]}, "abstract": "In this work we present DREAM, an fMRI-to-image method for reconstructing viewed images from brain activities, grounded on fundamental knowledge of the human visual system. We craft reverse pathways that emulate the hierarchical and parallel nature of how humans perceive the visual world. These tailored pathways are specialized to decipher semantics, color, and depth cues from fMRI data, mirroring the forward pathways from visual stimuli to fMRI recordings. To do so, two components mimic the inverse processes within the human visual system: the Reverse Visual Association Cortex (R-VAC) which reverses pathways of this brain region, extracting semantics from fMRI data; the Reverse Parallel PKM (R-PKM) component simultaneously predicting color and depth from fMRI signals. The experiments indicate that our method outperforms the current state-of-the-art models in terms of the consistency of appearance, structure, and semantics. Code will be made publicly available to facilitate further research in this field.", "url": "https://arxiv.org/abs/2310.02265"}, {"metadata": {"arXiv": "2310.02065", "Date": "Tue, 03 Oct 2023 14:08:26 ", "Title": "VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores", "Authors": ["Roberto L. Castro", "Andrei Ivanov", "Diego Andrade", "Tal Ben-Nun", "Basilio B. Fraguela", "Torsten Hoefler"], "Categories": "cs.DC cs.LG", "Comments": ["Accepted by 2023 International Conference on High Performance Computing", "Networking", "Storage and Analysis", "2023 (SC'23)"]}, "abstract": "The increasing success and scaling of Deep Learning models demands higher computational efficiency and power. Sparsification can lead to both smaller models as well as higher compute efficiency, and accelerated hardware is becoming available. However, exploiting it efficiently requires kernel implementations, pruning algorithms, and storage formats, to utilize hardware support of specialized sparse vector units. An example of those are the NVIDIA's Sparse Tensor Cores (SPTCs), which promise a 2x speedup. However, SPTCs only support the 2:4 format, limiting achievable sparsity ratios to 50%. We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs. To efficiently exploit the resulting format, we propose Spatha, a high-performance sparse-library for DL routines. We show that Spatha achieves up to 37x speedup over cuBLAS. We also demonstrate a second-order pruning technique that enables sparsification to high sparsity ratios with V:N:M and little to no loss in accuracy in modern transformers.", "url": "https://arxiv.org/abs/2310.02065"}, {"metadata": {"arXiv": "2310.01508", "Date": "Mon, 02 Oct 2023 18:04:34 ", "Title": "CODA: Temporal Domain Generalization via Concept Drift Simulator", "Authors": ["Chia-Yuan Chang", "Yu-Neng Chuang", "Zhimeng Jiang", "Kwei-Herng Lai", "Anxiao Jiang", "Na Zou"], "Categories": "cs.LG stat.ML"}, "abstract": "In real-world applications, machine learning models often become obsolete due to shifts in the joint distribution arising from underlying temporal trends, a phenomenon known as the \"concept drift\". Existing works propose model-specific strategies to achieve temporal generalization in the near-future domain. However, the diverse characteristics of real-world datasets necessitate customized prediction model architectures. To this end, there is an urgent demand for a model-agnostic temporal domain generalization approach that maintains generality across diverse data modalities and architectures. In this work, we aim to address the concept drift problem from a data-centric perspective to bypass considering the interaction between data and model. Developing such a framework presents non-trivial challenges: (i) existing generative models struggle to generate out-of-distribution future data, and (ii) precisely capturing the temporal trends of joint distribution along chronological source domains is computationally infeasible. To tackle the challenges, we propose the COncept Drift simulAtor (CODA) framework incorporating a predicted feature correlation matrix to simulate future data for model training. Specifically, CODA leverages feature correlations to represent data characteristics at specific time points, thereby circumventing the daunting computational costs. Experimental results demonstrate that using CODA-generated data as training input effectively achieves temporal domain generalization across different model architectures.", "url": "https://arxiv.org/abs/2310.01508"}, {"metadata": {"arXiv": "2310.01517", "Date": "Mon, 02 Oct 2023 18:10:21 ", "Title": "The Benefit of Noise-Injection for Dynamic Gray-Box Model Creation", "Authors": ["Mohamed Kandil", "J.J. McArthur"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["47 pages", "15 figures", "initial manuscript self-archiving prior to submission to ADVEI"], "MSC-class": "93-10", "ACM-class": "I.6.3"}, "abstract": "Gray-box models offer significant benefit over black-box approaches for equipment emulator development for equipment since their integration of physics provides more confidence in the model outside of the training domain. However, challenges such as model nonlinearity, unmodeled dynamics, and local minima introduce uncertainties into grey-box creation that contemporary approaches have failed to overcome, leading to their under-performance compared with black-box models. This paper seeks to address these uncertainties by injecting noise into the training dataset. This noise injection enriches the dataset and provides a measure of robustness against such uncertainties. A dynamic model for a water-to-water heat exchanger has been used as a demonstration case for this approach and tested using a pair of real devices with live data streaming. Compared to the unprocessed signal data, the application of noise injection resulted in a significant reduction in modeling error (root mean square error), decreasing from 0.68 to 0.27{\\deg}C. This improvement amounts to a 60% enhancement when assessed on the training set, and improvements of 50% and 45% when validated against the test and validation sets, respectively.", "url": "https://arxiv.org/abs/2310.01517"}, {"metadata": {"arXiv": "2310.01524", "Date": "Mon, 02 Oct 2023 18:14:55 ", "Title": "Nowcasting day-ahead marginal emissions using multi-headed CNNs and deep generative models", "Authors": ["Dhruv Suri", "Anela Arifi", "Ines Azevedo"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023 Tackling Climate Change with Machine Learning Workshop"]}, "abstract": "Nowcasting day-ahead marginal emissions factors is increasingly important for power systems with high flexibility and penetration of distributed energy resources. With a significant share of firm generation from natural gas and coal power plants, forecasting day-ahead emissions in the current energy system has been widely studied. In contrast, as we shift to an energy system characterized by flexible power markets, dispatchable sources, and competing low-cost generation such as large-scale battery or hydrogen storage, system operators will be able to choose from a mix of different generation as well as emission pathways. To fully develop the emissions implications of a given dispatch schedule, we need a near real-time workflow with two layers. The first layer is a market model that continuously solves a security-constrained economic dispatch model. The second layer determines the marginal emissions based on the output of the market model, which is the subject of this paper. We propose using multi-headed convolutional neural networks to generate day-ahead forecasts of marginal and average emissions for a given independent system operator.", "url": "https://arxiv.org/abs/2310.01524"}, {"metadata": {"arXiv": "2310.01537", "Date": "Mon, 02 Oct 2023 18:25:02 ", "Title": "Adversarial Client Detection via Non-parametric Subspace Monitoring in the Internet of Federated Things", "Authors": ["Xianjian Xie", "Xiaochen Xian", "Dan Li", "Andi Wang"], "Categories": "cs.LG"}, "abstract": "The Internet of Federated Things (IoFT) represents a network of interconnected systems with federated learning as the backbone, facilitating collaborative knowledge acquisition while ensuring data privacy for individual systems. The wide adoption of IoFT, however, is hindered by security concerns, particularly the susceptibility of federated learning networks to adversarial attacks. In this paper, we propose an effective non-parametric approach FedRR, which leverages the low-rank features of the transmitted parameter updates generated by federated learning to address the adversarial attack problem. Besides, our proposed method is capable of accurately detecting adversarial clients and controlling the false alarm rate under the scenario with no attack occurring. Experiments based on digit recognition using the MNIST datasets validated the advantages of our approach.", "url": "https://arxiv.org/abs/2310.01537"}, {"metadata": {"arXiv": "2310.01542", "Date": "Mon, 02 Oct 2023 18:31:35 ", "Title": "Fusing Models with Complementary Expertise", "Authors": ["Hongyi Wang", "Felipe Maia Polo", "Yuekai Sun", "Souvik Kundu", "Eric Xing", "Mikhail Yurochkin"], "Categories": "cs.LG"}, "abstract": "Training AI models that generalize across tasks and domains has long been among the open problems driving AI research. The emergence of Foundation Models made it easier to obtain expert models for a given task, but the heterogeneity of data that may be encountered at test time often means that any single expert is insufficient. We consider the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning. Our method is applicable to both discriminative and generative tasks and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text. We also extend our method to the \"frugal\" setting where it is desired to reduce the number of expert model evaluations at test time.", "url": "https://arxiv.org/abs/2310.01542"}, {"metadata": {"arXiv": "2310.01565", "Date": "Mon, 02 Oct 2023 18:56:05 ", "Title": "Causality-informed Rapid Post-hurricane Building Damage Detection in Large Scale from InSAR Imagery", "Authors": ["Chenguang Wang", "Yepeng Liu", "Xiaojian Zhang", "Xuechun Li", "Vladimir Paramygin", "Arthriya Subgranon", "Peter Sheng", "Xilei Zhao", "Susu Xu"], "Categories": "cs.LG cs.IR eess.IV", "Comments": ["6 pages", "3 figures"]}, "abstract": "Timely and accurate assessment of hurricane-induced building damage is crucial for effective post-hurricane response and recovery efforts. Recently, remote sensing technologies provide large-scale optical or Interferometric Synthetic Aperture Radar (InSAR) imagery data immediately after a disastrous event, which can be readily used to conduct rapid building damage assessment. Compared to optical satellite imageries, the Synthetic Aperture Radar can penetrate cloud cover and provide more complete spatial coverage of damaged zones in various weather conditions. However, these InSAR imageries often contain highly noisy and mixed signals induced by co-occurring or co-located building damage, flood, flood/wind-induced vegetation changes, as well as anthropogenic activities, making it challenging to extract accurate building damage information. In this paper, we introduced an approach for rapid post-hurricane building damage detection from InSAR imagery. This approach encoded complex causal dependencies among wind, flood, building damage, and InSAR imagery using a holistic causal Bayesian network. Based on the causal Bayesian network, we further jointly inferred the large-scale unobserved building damage by fusing the information from InSAR imagery with prior physical models of flood and wind, without the need for ground truth labels. Furthermore, we validated our estimation results in a real-world devastating hurricane -- the 2022 Hurricane Ian. We gathered and annotated building damage ground truth data in Lee County, Florida, and compared the introduced method's estimation results with the ground truth and benchmarked it against state-of-the-art models to assess the effectiveness of our proposed method. Results show that our method achieves rapid and accurate detection of building damage, with significantly reduced processing time compared to traditional manual inspection methods.", "url": "https://arxiv.org/abs/2310.01565"}, {"metadata": {"arXiv": "2310.01571", "Date": "Mon, 02 Oct 2023 19:04:41 ", "Title": "Contraction Properties of the Global Workspace Primitive", "Authors": ["Michaela Ennis", "Leo Kozachkov", "Jean-Jacques Slotine"], "Categories": "cs.LG cs.SY eess.SY q-bio.NC"}, "abstract": "To push forward the important emerging research field surrounding multi-area recurrent neural networks (RNNs), we expand theoretically and empirically on the provably stable RNNs of RNNs introduced by Kozachkov et al. in \"RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent Neural Networks\". We prove relaxed stability conditions for salient special cases of this architecture, most notably for a global workspace modular structure. We then demonstrate empirical success for Global Workspace Sparse Combo Nets with a small number of trainable parameters, not only through strong overall test performance but also greater resilience to removal of individual subnetworks. These empirical results for the global workspace inter-area topology are contingent on stability preservation, highlighting the relevance of our theoretical work for enabling modular RNN success. Further, by exploring sparsity in the connectivity structure between different subnetwork modules more broadly, we improve the state of the art performance for stable RNNs on benchmark sequence processing tasks, thus underscoring the general utility of specialized graph structures for multi-area RNNs.", "url": "https://arxiv.org/abs/2310.01571"}, {"metadata": {"arXiv": "2310.01597", "Date": "Mon, 02 Oct 2023 19:42:33 ", "Title": "Pool-Based Active Learning with Proper Topological Regions", "Authors": ["Lies Hadjadj", "Emilie Devijver", "Remi Molinier", "Massih-Reza Amini"], "Categories": "cs.LG math.AT"}, "abstract": "Machine learning methods usually rely on large sample size to have good performance, while it is difficult to provide labeled set in many applications. Pool-based active learning methods are there to detect, among a set of unlabeled data, the ones that are the most relevant for the training. We propose in this paper a meta-approach for pool-based active learning strategies in the context of multi-class classification tasks based on Proper Topological Regions. PTR, based on topological data analysis (TDA), are relevant regions used to sample cold-start points or within the active learning scheme. The proposed method is illustrated empirically on various benchmark datasets, being competitive to the classical methods from the literature.", "url": "https://arxiv.org/abs/2310.01597"}, {"metadata": {"arXiv": "2310.01611", "Date": "Mon, 02 Oct 2023 20:01:12 ", "Title": "Intractability of Learning the Discrete Logarithm with Gradient-Based Methods", "Authors": ["Rustem Takhanov", "Maxat Tezekbayev", "Artur Pak", "Arman Bolatov", "Zhibek Kadyrsizova", "Zhenisbek Assylbekov"], "Categories": "cs.LG cs.CR", "Comments": ["ACML 2023"]}, "abstract": "The discrete logarithm problem is a fundamental challenge in number theory with significant implications for cryptographic protocols. In this paper, we investigate the limitations of gradient-based methods for learning the parity bit of the discrete logarithm in finite cyclic groups of prime order. Our main result, supported by theoretical analysis and empirical verification, reveals the concentration of the gradient of the loss function around a fixed point, independent of the logarithm's base used. This concentration property leads to a restricted ability to learn the parity bit efficiently using gradient-based methods, irrespective of the complexity of the network architecture being trained. Our proof relies on Boas-Bellman inequality in inner product spaces and it involves establishing approximate orthogonality of discrete logarithm's parity bit functions through the spectral norm of certain matrices. Empirical experiments using a neural network-based approach further verify the limitations of gradient-based learning, demonstrating the decreasing success rate in predicting the parity bit as the group order increases.", "url": "https://arxiv.org/abs/2310.01611"}, {"metadata": {"arXiv": "2310.01618", "Date": "Mon, 02 Oct 2023 20:25:36 ", "Title": "Operator Learning Meets Numerical Analysis: Improving Neural Networks through Iterative Methods", "Authors": ["Emanuele Zappala", "Daniel Levine", "Sizhuang He", "Syed Rizvi", "Sacha Levy and David van Dijk"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["27 pages (13+14). 8 Figures and 5 tables. Comments are welcome!"]}, "abstract": "Deep neural networks, despite their success in numerous applications, often function without established theoretical foundations. In this paper, we bridge this gap by drawing parallels between deep learning and classical numerical analysis. By framing neural networks as operators with fixed points representing desired solutions, we develop a theoretical framework grounded in iterative methods for operator equations. Under defined conditions, we present convergence proofs based on fixed point theory. We demonstrate that popular architectures, such as diffusion models and AlphaFold, inherently employ iterative operator learning. Empirical assessments highlight that performing iterations through network operators improves performance. We also introduce an iterative graph neural network, PIGN, that further demonstrates benefits of iterations. Our work aims to enhance the understanding of deep learning by merging insights from numerical analysis, potentially guiding the design of future networks with clearer theoretical underpinnings and improved performance.", "url": "https://arxiv.org/abs/2310.01618"}, {"metadata": {"arXiv": "2310.01634", "Date": "Mon, 02 Oct 2023 20:57:11 ", "Title": "Deep Insights into Noisy Pseudo Labeling on Graph Data", "Authors": ["Botao Wang", "Jia Li", "Yang Liu", "Jiashun Cheng", "Yu Rong", "Wenjia Wang", "Fugee Tsung"], "Categories": "cs.LG"}, "abstract": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks.", "url": "https://arxiv.org/abs/2310.01634"}, {"metadata": {"arXiv": "2310.01647", "Date": "Mon, 02 Oct 2023 21:21:28 ", "Title": "Equivariant Adaptation of Large Pre-Trained Models", "Authors": ["Arnab Kumar Mondal", "Siba Smarak Panigrahi", "S\\'ekou-Oumar Kaba", "Sai Rajeswar", "Siamak Ravanbakhsh"], "Categories": "cs.LG", "Comments": ["16 pages", "6 figures. Accepted to NeurIPS 2023"]}, "abstract": "Equivariant networks are specifically designed to ensure consistent behavior with respect to a set of input transformations, leading to higher sample efficiency and more accurate and robust predictions. However, redesigning each component of prevalent deep neural network architectures to achieve chosen equivariance is a difficult problem and can result in a computationally expensive network during both training and inference. A recently proposed alternative towards equivariance that removes the architectural constraints is to use a simple canonicalization network that transforms the input to a canonical form before feeding it to an unconstrained prediction network. We show here that this approach can effectively be used to make a large pre-trained network equivariant. However, we observe that the produced canonical orientations can be misaligned with those of the training distribution, hindering performance. Using dataset-dependent priors to inform the canonicalization function, we are able to make large pre-trained models equivariant while maintaining their performance. This significantly improves the robustness of these models to deterministic transformations of the data, such as rotations. We believe this equivariant adaptation of large pre-trained models can help their domain-specific applications with known symmetry priors.", "url": "https://arxiv.org/abs/2310.01647"}, {"metadata": {"arXiv": "2310.01651", "Date": "Mon, 02 Oct 2023 21:27:57 ", "Title": "Fool Your (Vision and) Language Model With Embarrassingly Simple Permutations", "Authors": ["Yongshuo Zong", "Tingyang Yu", "Bingchen Zhao", "Ruchika Chavhan", "Timothy Hospedales"], "Categories": "cs.LG"}, "abstract": "Large language and vision-language models are rapidly being deployed in practice thanks to their impressive capabilities in instruction following, in-context learning, and so on. This raises an urgent need to carefully analyse their robustness so that stakeholders can understand if and when such models are trustworthy enough to be relied upon in any given application. In this paper, we highlight a specific vulnerability in popular models, namely permutation sensitivity in multiple-choice question answering (MCQA). Specifically, we show empirically that popular models are vulnerable to adversarial permutation in answer sets for multiple-choice prompting, which is surprising as models should ideally be as invariant to prompt permutation as humans are. These vulnerabilities persist across various model sizes, and exist in very recent language and vision-language models. Code is available at \\url{https://github.com/ys-zong/FoolyourVLLMs}.", "url": "https://arxiv.org/abs/2310.01651"}, {"metadata": {"arXiv": "2310.01655", "Date": "Mon, 02 Oct 2023 21:39:04 ", "Title": "PolySketchFormer: Fast Transformers via Sketches for Polynomial Kernels", "Authors": ["Praneeth Kacham", "Vahab Mirrokni", "Peilin Zhong"], "Categories": "cs.LG"}, "abstract": "The quadratic complexity of attention in transformer architectures remains a big bottleneck in scaling up large foundation models for long context. In fact, recent theoretical results show the hardness of approximating the output of softmax attention mechanism in sub-quadratic time assuming Strong Exponential Time Hypothesis. In this paper, we show how to break this theoretical barrier by replacing softmax with a polynomial function and polynomial sketching. In particular we show that sketches for Polynomial Kernel from the randomized numerical linear algebra literature can be used to approximate the polynomial attention which leads to a significantly faster attention mechanism without assuming any sparse structure for the attention matrix that has been done in many previous works. In addition, we propose an efficient block-based algorithm that lets us apply the causal mask to the attention matrix without explicitly realizing the $n \\times n$ attention matrix and compute the output of the polynomial attention mechanism in time linear in the context length. The block-based algorithm gives significant speedups over the \\emph{cumulative sum} algorithm used by Performer to apply the causal mask to the attention matrix. These observations help us design \\emph{PolySketchFormer}, a practical linear-time transformer architecture for language modeling with provable guarantees. We validate our design empirically by training language models with long context lengths. We first show that the eval perplexities of our models are comparable to that of models trained with softmax attention. We then show that for large context lengths our training times are significantly faster than FlashAttention.", "url": "https://arxiv.org/abs/2310.01655"}, {"metadata": {"arXiv": "2310.01668", "Date": "Mon, 02 Oct 2023 21:59:44 ", "Title": "Locality-Aware Graph-Rewiring in GNNs", "Authors": ["Federico Barbero", "Ameya Velingker", "Amin Saberi", "Michael Bronstein", "Francesco Di Giovanni"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) are popular models for machine learning on graphs that typically follow the message-passing paradigm, whereby the feature of a node is updated recursively upon aggregating information over its neighbors. While exchanging messages over the input graph endows GNNs with a strong inductive bias, it can also make GNNs susceptible to over-squashing, thereby preventing them from capturing long-range interactions in the given graph. To rectify this issue, graph rewiring techniques have been proposed as a means of improving information flow by altering the graph connectivity. In this work, we identify three desiderata for graph-rewiring: (i) reduce over-squashing, (ii) respect the locality of the graph, and (iii) preserve the sparsity of the graph. We highlight fundamental trade-offs that occur between spatial and spectral rewiring techniques; while the former often satisfy (i) and (ii) but not (iii), the latter generally satisfy (i) and (iii) at the expense of (ii). We propose a novel rewiring framework that satisfies all of (i)--(iii) through a locality-aware sequence of rewiring operations. We then discuss a specific instance of such rewiring framework and validate its effectiveness on several real-world benchmarks, showing that it either matches or significantly outperforms existing rewiring approaches.", "url": "https://arxiv.org/abs/2310.01668"}, {"metadata": {"arXiv": "2310.01679", "Date": "Mon, 02 Oct 2023 22:30:25 ", "Title": "Estimating and Implementing Conventional Fairness Metrics With Probabilistic Protected Features", "Authors": ["Hadi Elzayn", "Emily Black", "Patrick Vossler", "Nathanael Jo", "Jacob Goldin", "Daniel E. Ho"], "Categories": "cs.LG cs.CY stat.ML"}, "abstract": "The vast majority of techniques to train fair models require access to the protected attribute (e.g., race, gender), either at train time or in production. However, in many important applications this protected attribute is largely unavailable. In this paper, we develop methods for measuring and reducing fairness violations in a setting with limited access to protected attribute labels. Specifically, we assume access to protected attribute labels on a small subset of the dataset of interest, but only probabilistic estimates of protected attribute labels (e.g., via Bayesian Improved Surname Geocoding) for the rest of the dataset. With this setting in mind, we propose a method to estimate bounds on common fairness metrics for an existing model, as well as a method for training a model to limit fairness violations by solving a constrained non-convex optimization problem. Unlike similar existing approaches, our methods take advantage of contextual information -- specifically, the relationships between a model's predictions and the probabilistic prediction of protected attributes, given the true protected attribute, and vice versa -- to provide tighter bounds on the true disparity. We provide an empirical illustration of our methods using voting data. First, we show our measurement method can bound the true disparity up to 5.5x tighter than previous methods in these applications. Then, we demonstrate that our training technique effectively reduces disparity while incurring lesser fairness-accuracy trade-offs than other fair optimization methods with limited access to protected attributes.", "url": "https://arxiv.org/abs/2310.01679"}, {"metadata": {"arXiv": "2310.01685", "Date": "Mon, 02 Oct 2023 22:46:49 ", "Title": "A Framework for Interpretability in Machine Learning for Medical Imaging", "Authors": ["Alan Q. Wang", "Batuhan K. Karaman", "Heejong Kim", "Jacob Rosenthal", "Rachit Saluja", "Sean I. Young", "Mert R. Sabuncu"], "Categories": "cs.LG"}, "abstract": "Interpretability for machine learning models in medical imaging (MLMI) is an important direction of research. However, there is a general sense of murkiness in what interpretability means. Why does the need for interpretability in MLMI arise? What goals does one actually seek to address when interpretability is needed? To answer these questions, we identify a need to formalize the goals and elements of interpretability in MLMI. By reasoning about real-world tasks and goals common in both medical image analysis and its intersection with machine learning, we identify four core elements of interpretability: localization, visual recognizability, physical attribution, and transparency. Overall, this paper formalizes interpretability needs in the context of medical imaging, and our applied perspective clarifies concrete MLMI-specific goals and considerations in order to guide method design and improve real-world usage. Our goal is to provide practical and didactic information for model designers and practitioners, inspire developers of models in the medical imaging field to reason more deeply about what interpretability is achieving, and suggest future directions of interpretability research.", "url": "https://arxiv.org/abs/2310.01685"}, {"metadata": {"arXiv": "2310.01687", "Date": "Mon, 02 Oct 2023 22:59:17 ", "Title": "From Stability to Chaos: Analyzing Gradient Descent Dynamics in Quadratic Regression", "Authors": ["Xuxing Chen", "Krishnakumar Balasubramanian", "Promit Ghosal", "Bhavya Agrawalla"], "Categories": "cs.LG math.DS math.OC math.PR stat.ML"}, "abstract": "We conduct a comprehensive investigation into the dynamics of gradient descent using large-order constant step-sizes in the context of quadratic regression models. Within this framework, we reveal that the dynamics can be encapsulated by a specific cubic map, naturally parameterized by the step-size. Through a fine-grained bifurcation analysis concerning the step-size parameter, we delineate five distinct training phases: (1) monotonic, (2) catapult, (3) periodic, (4) chaotic, and (5) divergent, precisely demarcating the boundaries of each phase. As illustrations, we provide examples involving phase retrieval and two-layer neural networks employing quadratic activation functions and constant outer-layers, utilizing orthogonal training data. Our simulations indicate that these five phases also manifest with generic non-orthogonal data. We also empirically investigate the generalization performance when training in the various non-monotonic (and non-divergent) phases. In particular, we observe that performing an ergodic trajectory averaging stabilizes the test error in non-monotonic (and non-divergent) phases.", "url": "https://arxiv.org/abs/2310.01687"}, {"metadata": {"arXiv": "2310.01698", "Date": "Mon, 02 Oct 2023 23:36:13 ", "Title": "Robustifying State-space Models for Long Sequences via Approximate Diagonalization", "Authors": ["Annan Yu", "Arnur Nigmetov", "Dmitriy Morozov", "Michael W. Mahoney and N. Benjamin Erichson"], "Categories": "cs.LG stat.ML"}, "abstract": "State-space models (SSMs) have recently emerged as a framework for learning long-range sequence tasks. An example is the structured state-space sequence (S4) layer, which uses the diagonal-plus-low-rank structure of the HiPPO initialization framework. However, the complicated structure of the S4 layer poses challenges; and, in an effort to address these challenges, models such as S4D and S5 have considered a purely diagonal structure. This choice simplifies the implementation, improves computational efficiency, and allows channel communication. However, diagonalizing the HiPPO framework is itself an ill-posed problem. In this paper, we propose a general solution for this and related ill-posed diagonalization problems in machine learning. We introduce a generic, backward-stable \"perturb-then-diagonalize\" (PTD) methodology, which is based on the pseudospectral theory of non-normal operators, and which may be interpreted as the approximate diagonalization of the non-normal matrices defining SSMs. Based on this, we introduce the S4-PTD and S5-PTD models. Through theoretical analysis of the transfer functions of different initialization schemes, we demonstrate that the S4-PTD/S5-PTD initialization strongly converges to the HiPPO framework, while the S4D/S5 initialization only achieves weak convergences. As a result, our new models show resilience to Fourier-mode noise-perturbed inputs, a crucial property not achieved by the S4D/S5 models. In addition to improved robustness, our S5-PTD model averages 87.6% accuracy on the Long-Range Arena benchmark, demonstrating that the PTD methodology helps to improve the accuracy of deep learning models.", "url": "https://arxiv.org/abs/2310.01698"}, {"metadata": {"arXiv": "2310.01704", "Date": "Mon, 02 Oct 2023 23:57:04 ", "Title": "Transformers are efficient hierarchical chemical graph learners", "Authors": ["Zihan Pengmei", "Zimu Li", "Chih-chan Tien", "Risi Kondor", "Aaron R. Dinner"], "Categories": "cs.LG", "Comments": ["18 pages", "8 figures"]}, "abstract": "Transformers, adapted from natural language processing, are emerging as a leading approach for graph representation learning. Contemporary graph transformers often treat nodes or edges as separate tokens. This approach leads to computational challenges for even moderately-sized graphs due to the quadratic scaling of self-attention complexity with token count. In this paper, we introduce SubFormer, a graph transformer that operates on subgraphs that aggregate information by a message-passing mechanism. This approach reduces the number of tokens and enhances learning long-range interactions. We demonstrate SubFormer on benchmarks for predicting molecular properties from chemical structures and show that it is competitive with state-of-the-art graph transformers at a fraction of the computational cost, with training times on the order of minutes on a consumer-grade graphics card. We interpret the attention weights in terms of chemical structures. We show that SubFormer exhibits limited over-smoothing and avoids over-squashing, which is prevalent in traditional graph neural networks.", "url": "https://arxiv.org/abs/2310.01704"}, {"metadata": {"arXiv": "2310.01706", "Date": "Tue, 03 Oct 2023 00:01:58 ", "Title": "On Representation Complexity of Model-based and Model-free Reinforcement Learning", "Authors": ["Hanlin Zhu", "Baihe Huang", "Stuart Russell"], "Categories": "cs.LG", "Comments": ["23 pages", "3 figures"]}, "abstract": "We study the representation complexity of model-based and model-free reinforcement learning (RL) in the context of circuit complexity. We prove theoretically that there exists a broad class of MDPs such that their underlying transition and reward functions can be represented by constant depth circuits with polynomial size, while the optimal $Q$-function suffers an exponential circuit complexity in constant-depth circuits. By drawing attention to the approximation errors and building connections to complexity theory, our theory provides unique insights into why model-based algorithms usually enjoy better sample complexity than model-free algorithms from a novel representation complexity perspective: in some cases, the ground-truth rule (model) of the environment is simple to represent, while other quantities, such as $Q$-function, appear complex. We empirically corroborate our theory by comparing the approximation error of the transition kernel, reward function, and optimal $Q$-function in various Mujoco environments, which demonstrates that the approximation errors of the transition kernel and reward function are consistently lower than those of the optimal $Q$-function. To the best of our knowledge, this work is the first to study the circuit complexity of RL, which also provides a rigorous framework for future research.", "url": "https://arxiv.org/abs/2310.01706"}, {"metadata": {"arXiv": "2310.01712", "Date": "Tue, 03 Oct 2023 00:54:13 ", "Title": "Generative Autoencoding of Dropout Patterns", "Authors": ["Shunta Maeda"], "Categories": "cs.LG cs.CV"}, "abstract": "We propose a generative model termed Deciphering Autoencoders. In this model, we assign a unique random dropout pattern to each data point in the training dataset and then train an autoencoder to reconstruct the corresponding data point using this pattern as information to be encoded. Since the training of Deciphering Autoencoders relies solely on reconstruction error, it offers more stable training than other generative models. Despite its simplicity, Deciphering Autoencoders show comparable sampling quality to DCGAN on the CIFAR-10 dataset.", "url": "https://arxiv.org/abs/2310.01712"}, {"metadata": {"arXiv": "2310.01714", "Date": "Tue, 03 Oct 2023 00:57:26 ", "Title": "Large Language Models as Analogical Reasoners", "Authors": ["Michihiro Yasunaga", "Xinyun Chen", "Yujia Li", "Panupong Pasupat", "Jure Leskovec", "Percy Liang", "Ed H. Chi", "Denny Zhou"], "Categories": "cs.LG"}, "abstract": "Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, Analogical Prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual few-shot CoT in a variety of reasoning tasks, including math problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.", "url": "https://arxiv.org/abs/2310.01714"}, {"metadata": {"arXiv": "2310.01739", "Date": "Tue, 03 Oct 2023 02:01:39 ", "Title": "Randomized Dimension Reduction with Statistical Guarantees", "Authors": ["Yijun Dong"], "Categories": "cs.LG cs.NA math.NA stat.ML", "Comments": ["Ph.D. dissertation (University of Texas at Austin)"]}, "abstract": "Large models and enormous data are essential driving forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are increasingly indispensable for pushing the limit of algorithm potency. This thesis explores some of such algorithms for fast execution and efficient data utilization. From the computational efficiency perspective, we design and analyze fast randomized low-rank decomposition algorithms for large matrices based on \"matrix sketching\", which can be regarded as a dimension reduction strategy in the data space. These include the randomized pivoting-based interpolative and CUR decomposition discussed in Chapter 2 and the randomized subspace approximations discussed in Chapter 3. From the sample efficiency perspective, we focus on learning algorithms with various incorporations of data augmentation that improve generalization and distributional robustness provably. Specifically, Chapter 4 presents a sample complexity analysis for data augmentation consistency regularization where we view sample efficiency from the lens of dimension reduction in the function space. Then in Chapter 5, we introduce an adaptively weighted data augmentation consistency regularization algorithm for distributionally robust optimization with applications in medical image segmentation.", "url": "https://arxiv.org/abs/2310.01739"}, {"metadata": {"arXiv": "2310.01753", "Date": "Tue, 03 Oct 2023 02:29:19 ", "Title": "CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery", "Authors": ["Yuxiao Cheng", "Ziqian Wang", "Tingxiong Xiao", "Qin Zhong", "Jinli Suo", "Kunlun He"], "Categories": "cs.LG stat.ML"}, "abstract": "Time-series causal discovery (TSCD) is a fundamental problem of machine learning. However, existing synthetic datasets cannot properly evaluate or predict the algorithms' performance on real data. This study introduces the CausalTime pipeline to generate time-series that highly resemble the real data and with ground truth causal graphs for quantitative performance evaluation. The pipeline starts from real observations in a specific scenario and produces a matching benchmark dataset. Firstly, we harness deep neural networks along with normalizing flow to accurately capture realistic dynamics. Secondly, we extract hypothesized causal graphs by performing importance analysis on the neural network or leveraging prior knowledge. Thirdly, we derive the ground truth causal graphs by splitting the causal model into causal term, residual term, and noise term. Lastly, using the fitted network and the derived causal graph, we generate corresponding versatile time-series proper for algorithm assessment. In the experiments, we validate the fidelity of the generated data through qualitative and quantitative experiments, followed by a benchmarking of existing TSCD algorithms using these generated datasets. CausalTime offers a feasible solution to evaluating TSCD algorithms in real applications and can be generalized to a wide range of fields. For easy use of the proposed approach, we also provide a user-friendly website, hosted on www.causaltime.cc.", "url": "https://arxiv.org/abs/2310.01753"}, {"metadata": {"arXiv": "2310.01758", "Date": "Tue, 03 Oct 2023 02:47:38 ", "Title": "Linearization of ReLU Activation Function for Neural Network-Embedded Optimization:Optimal Day-Ahead Energy Scheduling", "Authors": ["Cunzhi Zhao and Xingpeng Li"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Neural networks have been widely applied in the power system area. They can be used for better predicting input information and modeling system performance with increased accuracy. In some applications such as battery degradation neural network-based microgrid day-ahead energy scheduling, the input features of the trained learning model are variables to be solved in optimization models that enforce limits on the output of the same learning model. This will create a neural network-embedded optimization problem; the use of nonlinear activation functions in the neural network will make such problems extremely hard to solve if not unsolvable. To address this emerging challenge, this paper investigated different methods for linearizing the nonlinear activation functions with a particular focus on the widely used rectified linear unit (ReLU) function. Four linearization methods tailored for the ReLU activation function are developed, analyzed and compared in this paper. Each method employs a set of linear constraints to replace the ReLU function, effectively linearizing the optimization problem, which can overcome the computational challenges associated with the nonlinearity of the neural network model. These proposed linearization methods provide valuable tools for effectively solving optimization problems that integrate neural network models with ReLU activation functions.", "url": "https://arxiv.org/abs/2310.01758"}, {"metadata": {"arXiv": "2310.01762", "Date": "Tue, 03 Oct 2023 03:06:59 ", "Title": "Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization", "Authors": ["Frederic Koehler", "Thuy-Duong Vuong"], "Categories": "cs.LG cs.DS math.ST stat.TH"}, "abstract": "There is a long history, as well as a recent explosion of interest, in statistical and generative modeling approaches based on score functions -- derivatives of the log-likelihood of a distribution. In seminal works, Hyv\\\"arinen proposed vanilla score matching as a way to learn distributions from data by computing an estimate of the score function of the underlying ground truth, and established connections between this method and established techniques like Contrastive Divergence and Pseudolikelihood estimation. It is by now well-known that vanilla score matching has significant difficulties learning multimodal distributions. Although there are various ways to overcome this difficulty, the following question has remained unanswered -- is there a natural way to sample multimodal distributions using just the vanilla score? Inspired by a long line of related experimental works, we prove that the Langevin diffusion with early stopping, initialized at the empirical distribution, and run on a score function estimated from data successfully generates natural multimodal distributions (mixtures of log-concave distributions).", "url": "https://arxiv.org/abs/2310.01762"}, {"metadata": {"arXiv": "2310.01765", "Date": "Tue, 03 Oct 2023 03:13:23 ", "Title": "Data Cleaning and Machine Learning: A Systematic Literature Review", "Authors": ["Pierre-Olivier C\\^ot\\'e", "Amin Nikanjam", "Nafisa Ahmed", "Dmytro Humeniuk", "Foutse Khomh"], "Categories": "cs.LG cs.DB", "Comments": ["Submitted to Automated Software Engineering Journal"]}, "abstract": "Context: Machine Learning (ML) is integrated into a growing number of systems for various applications. Because the performance of an ML model is highly dependent on the quality of the data it has been trained on, there is a growing interest in approaches to detect and repair data errors (i.e., data cleaning). Researchers are also exploring how ML can be used for data cleaning; hence creating a dual relationship between ML and data cleaning. To the best of our knowledge, there is no study that comprehensively reviews this relationship. Objective: This paper's objectives are twofold. First, it aims to summarize the latest approaches for data cleaning for ML and ML for data cleaning. Second, it provides future work recommendations. Method: We conduct a systematic literature review of the papers published between 2016 and 2022 inclusively. We identify different types of data cleaning activities with and for ML: feature cleaning, label cleaning, entity matching, outlier detection, imputation, and holistic data cleaning. Results: We summarize the content of 101 papers covering various data cleaning activities and provide 24 future work recommendations. Our review highlights many promising data cleaning techniques that can be further extended. Conclusion: We believe that our review of the literature will help the community develop better approaches to clean data.", "url": "https://arxiv.org/abs/2310.01765"}, {"metadata": {"arXiv": "2310.01766", "Date": "Tue, 03 Oct 2023 03:20:07 ", "Title": "Exploring Counterfactual Alignment Loss towards Human-centered AI", "Authors": ["Mingzhou Liu", "Xinwei Sun", "Ching-Wen Lee", "Yu Qiao", "Yizhou Wang"], "Categories": "cs.LG"}, "abstract": "Deep neural networks have demonstrated impressive accuracy in supervised learning tasks. However, their lack of transparency makes it hard for humans to trust their results, especially in safe-critic domains such as healthcare. To address this issue, recent explanation-guided learning approaches proposed to align the gradient-based attention map to image regions annotated by human experts, thereby obtaining an intrinsically human-centered model. However, the attention map these methods are based on may fail to causally attribute the model predictions, thus compromising their validity for alignment. To address this issue, we propose a novel human-centered framework based on counterfactual generation. In particular, we utilize the counterfactual generation's ability for causal attribution to introduce a novel loss called the CounterFactual Alignment (CF-Align) loss. This loss guarantees that the features attributed by the counterfactual generation for the classifier align with the human annotations. To optimize the proposed loss that entails a counterfactual generation with an implicit function form, we leverage the implicit function theorem for backpropagation. Our method is architecture-agnostic and, therefore can be applied to any neural network. We demonstrate the effectiveness of our method on a lung cancer diagnosis dataset, showcasing faithful alignment to humans.", "url": "https://arxiv.org/abs/2310.01766"}, {"metadata": {"arXiv": "2310.01769", "Date": "Tue, 03 Oct 2023 03:34:22 ", "Title": "How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization", "Authors": ["Nuoya Xiong", "Lijun Ding", "Simon S. Du"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "This paper rigorously shows how over-parameterization changes the convergence behaviors of gradient descent (GD) for the matrix sensing problem, where the goal is to recover an unknown low-rank ground-truth matrix from near-isotropic linear measurements. First, we consider the symmetric setting with the symmetric parameterization where $M^* \\in \\mathbb{R}^{n \\times n}$ is a positive semi-definite unknown matrix of rank $r \\ll n$, and one uses a symmetric parameterization $XX^\\top$ to learn $M^*$. Here $X \\in \\mathbb{R}^{n \\times k}$ with $k > r$ is the factor matrix. We give a novel $\\Omega (1/T^2)$ lower bound of randomly initialized GD for the over-parameterized case ($k >r$) where $T$ is the number of iterations. This is in stark contrast to the exact-parameterization scenario ($k=r$) where the convergence rate is $\\exp (-\\Omega (T))$. Next, we study asymmetric setting where $M^* \\in \\mathbb{R}^{n_1 \\times n_2}$ is the unknown matrix of rank $r \\ll \\min\\{n_1,n_2\\}$, and one uses an asymmetric parameterization $FG^\\top$ to learn $M^*$ where $F \\in \\mathbb{R}^{n_1 \\times k}$ and $G \\in \\mathbb{R}^{n_2 \\times k}$. Building on prior work, we give a global exact convergence result of randomly initialized GD for the exact-parameterization case ($k=r$) with an $\\exp (-\\Omega(T))$ rate. Furthermore, we give the first global exact convergence result for the over-parameterization case ($k>r$) with an $\\exp(-\\Omega(\\alpha^2 T))$ rate where $\\alpha$ is the initialization scale. This linear convergence result in the over-parameterization case is especially significant because one can apply the asymmetric parameterization to the symmetric setting to speed up from $\\Omega (1/T^2)$ to linear convergence. On the other hand, we propose a novel method that only modifies one step of GD and obtains a convergence rate independent of $\\alpha$, recovering the rate in the exact-parameterization case.", "url": "https://arxiv.org/abs/2310.01769"}, {"metadata": {"arXiv": "2310.01794", "Date": "Tue, 03 Oct 2023 04:42:44 ", "Title": "GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking", "Authors": ["Mert Kosan", "Samidha Verma", "Burouj Armgaan", "Khushbu Pahwa", "Ambuj Singh", "Sourav Medya", "Sayan Ranu"], "Categories": "cs.LG"}, "abstract": "Numerous explainability methods have been proposed to shed light on the inner workings of GNNs. Despite the inclusion of empirical evaluations in all the proposed algorithms, the interrogative aspects of these evaluations lack diversity. As a result, various facets of explainability pertaining to GNNs, such as a comparative analysis of counterfactual reasoners, their stability to variational factors such as different GNN architectures, noise, stochasticity in non-convex loss surfaces, feasibility amidst domain constraints, and so forth, have yet to be formally investigated. Motivated by this need, we present a benchmarking study on perturbation-based explainability methods for GNNs, aiming to systematically evaluate and compare a wide range of explainability techniques. Among the key findings of our study, we identify the Pareto-optimal methods that exhibit superior efficacy and stability in the presence of noise. Nonetheless, our study reveals that all algorithms are affected by stability issues when faced with noisy data. Furthermore, we have established that the current generation of counterfactual explainers often fails to provide feasible recourses due to violations of topological constraints encoded by domain-specific considerations. Overall, this benchmarking study empowers stakeholders in the field of GNNs with a comprehensive understanding of the state-of-the-art explainability methods, potential research problems for further enhancement, and the implications of their application in real-world scenarios.", "url": "https://arxiv.org/abs/2310.01794"}, {"metadata": {"arXiv": "2310.01818", "Date": "Tue, 03 Oct 2023 06:16:03 ", "Title": "AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework", "Authors": ["Xilie Xu", "Jingfeng Zhang", "Mohan Kankanhalli"], "Categories": "cs.LG cs.CR"}, "abstract": "Robust Fine-Tuning (RFT) is a low-cost strategy to obtain adversarial robustness in downstream applications, without requiring a lot of computational resources and collecting significant amounts of data. This paper uncovers an issue with the existing RFT, where optimizing both adversarial and natural objectives through the feature extractor (FE) yields significantly divergent gradient directions. This divergence introduces instability in the optimization process, thereby hindering the attainment of adversarial robustness and rendering RFT highly sensitive to hyperparameters. To mitigate this issue, we propose a low-rank (LoRa) branch that disentangles RFT into two distinct components: optimizing natural objectives via the LoRa branch and adversarial objectives via the FE. Besides, we introduce heuristic strategies for automating the scheduling of the learning rate and the scalars of loss terms. Extensive empirical evaluations demonstrate that our proposed automated RFT disentangled via the LoRa branch (AutoLoRa) achieves new state-of-the-art results across a range of downstream tasks. AutoLoRa holds significant practical utility, as it automatically converts a pre-trained FE into an adversarially robust model for downstream tasks without the need for searching hyperparameters.", "url": "https://arxiv.org/abs/2310.01818"}, {"metadata": {"arXiv": "2310.01820", "Date": "Tue, 03 Oct 2023 06:25:14 ", "Title": "Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks", "Authors": ["Xu Zheng", "Farhad Shirani", "Tianchun Wang", "Wei Cheng", "Zhuomin Chen", "Haifeng Chen", "Hua Wei", "Dongsheng Luo"], "Categories": "cs.LG", "Comments": ["23 Pages", "10 figures", "under review"]}, "abstract": "Graph Neural Networks (GNNs) are neural models that leverage the dependency structure in graphical data via message passing among the graph nodes. GNNs have emerged as pivotal architectures in analyzing graph-structured data, and their expansive application in sensitive domains requires a comprehensive understanding of their decision-making processes -- necessitating a framework for GNN explainability. An explanation function for GNNs takes a pre-trained GNN along with a graph as input, to produce a `sufficient statistic' subgraph with respect to the graph label. A main challenge in studying GNN explainability is to provide fidelity measures that evaluate the performance of these explanation functions. This paper studies this foundational challenge, spotlighting the inherent limitations of prevailing fidelity metrics, including $Fid_+$, $Fid_-$, and $Fid_\\Delta$. Specifically, a formal, information-theoretic definition of explainability is introduced and it is shown that existing metrics often fail to align with this definition across various statistical scenarios. The reason is due to potential distribution shifts when subgraphs are removed in computing these fidelity measures. Subsequently, a robust class of fidelity measures are introduced, and it is shown analytically that they are resilient to distribution shift issues and are applicable in a wide range of scenarios. Extensive empirical analysis on both synthetic and real datasets are provided to illustrate that the proposed metrics are more coherent with gold standard metrics.", "url": "https://arxiv.org/abs/2310.01820"}, {"metadata": {"arXiv": "2310.01835", "Date": "Tue, 03 Oct 2023 06:58:45 ", "Title": "EMBERSim: A Large-Scale Databank for Boosting Similarity Search in Malware Analysis", "Authors": ["Dragos Georgian Corlatescu", "Alexandru Dinu", "Mihaela Gaman", "Paul Sumedrea"], "Categories": "cs.LG", "Comments": ["Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks"]}, "abstract": "In recent years there has been a shift from heuristics-based malware detection towards machine learning, which proves to be more robust in the current heavily adversarial threat landscape. While we acknowledge machine learning to be better equipped to mine for patterns in the increasingly high amounts of similar-looking files, we also note a remarkable scarcity of the data available for similarity-targeted research. Moreover, we observe that the focus in the few related works falls on quantifying similarity in malware, often overlooking the clean data. This one-sided quantification is especially dangerous in the context of detection bypass. We propose to address the deficiencies in the space of similarity research on binary files, starting from EMBER - one of the largest malware classification data sets. We enhance EMBER with similarity information as well as malware class tags, to enable further research in the similarity space. Our contribution is threefold: (1) we publish EMBERSim, an augmented version of EMBER, that includes similarity-informed tags; (2) we enrich EMBERSim with automatically determined malware class tags using the open-source tool AVClass on VirusTotal data and (3) we describe and share the implementation for our class scoring technique and leaf similarity method.", "url": "https://arxiv.org/abs/2310.01835"}, {"metadata": {"arXiv": "2310.01870", "Date": "Tue, 03 Oct 2023 08:15:20 ", "Title": "DeepDecipher: Accessing and Investigating Neuron Activation in Large Language Models", "Authors": ["Albert Garde", "Esben Kran", "Fazl Barez"], "Categories": "cs.LG", "Comments": ["4 pages (9 total)", "1 figure", "submitted to NeurIPS 2023 Workshop XAIA"], "MSC-class": "68T50 (Primary) 68T05 (Secondary)", "ACM-class": "I.2.7"}, "abstract": "As large language models (LLMs) become more capable, there is an urgent need for interpretable and transparent tools. Current methods are difficult to implement, and accessible tools to analyze model internals are lacking. To bridge this gap, we present DeepDecipher - an API and interface for probing neurons in transformer models' MLP layers. DeepDecipher makes the outputs of advanced interpretability techniques for LLMs readily available. The easy-to-use interface also makes inspecting these complex models more intuitive. This paper outlines DeepDecipher's design and capabilities. We demonstrate how to analyze neurons, compare models, and gain insights into model behavior. For example, we contrast DeepDecipher's functionality with similar tools like Neuroscope and OpenAI's Neuron Explainer. DeepDecipher enables efficient, scalable analysis of LLMs. By granting access to state-of-the-art interpretability methods, DeepDecipher makes LLMs more transparent, trustworthy, and safe. Researchers, engineers, and developers can quickly diagnose issues, audit systems, and advance the field.", "url": "https://arxiv.org/abs/2310.01870"}, {"metadata": {"arXiv": "2310.01880", "Date": "Tue, 03 Oct 2023 08:34:44 ", "Title": "AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval", "Authors": ["Qi Yan", "Raihan Seraj", "Jiawei He", "Lili Meng", "Tristan Sylvain"], "Categories": "cs.LG"}, "abstract": "Machine-based prediction of real-world events is garnering attention due to its potential for informed decision-making. Whereas traditional forecasting predominantly hinges on structured data like time-series, recent breakthroughs in language models enable predictions using unstructured text. In particular, (Zou et al., 2022) unveils AutoCast, a new benchmark that employs news articles for answering forecasting queries. Nevertheless, existing methods still trail behind human performance. The cornerstone of accurate forecasting, we argue, lies in identifying a concise, yet rich subset of news snippets from a vast corpus. With this motivation, we introduce AutoCast++, a zero-shot ranking-based context retrieval system, tailored to sift through expansive news document collections for event forecasting. Our approach first re-ranks articles based on zero-shot question-passage relevance, honing in on semantically pertinent news. Following this, the chosen articles are subjected to zero-shot summarization to attain succinct context. Leveraging a pre-trained language model, we conduct both the relevance evaluation and article summarization without needing domain-specific training. Notably, recent articles can sometimes be at odds with preceding ones due to new facts or unanticipated incidents, leading to fluctuating temporal dynamics. To tackle this, our re-ranking mechanism gives preference to more recent articles, and we further regularize the multi-passage representation learning to align with human forecaster responses made on different dates. Empirical results underscore marked improvements across multiple metrics, improving the performance for multiple-choice questions (MCQ) by 48% and true/false (TF) questions by up to 8%.", "url": "https://arxiv.org/abs/2310.01880"}, {"metadata": {"arXiv": "2310.01886", "Date": "Tue, 03 Oct 2023 08:39:33 ", "Title": "Effective and Parameter-Efficient Reusing Fine-Tuned Models", "Authors": ["Weisen Jiang and Baijiong Lin and Han Shi and Yu Zhang and and Zhenguo Li and James T. Kwok"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["Technical Report"]}, "abstract": "Many pre-trained large-scale models provided online have become highly effective in transferring to downstream tasks. At the same time, various task-specific models fine-tuned on these pre-trained models are available online for public use. In practice, as collecting task-specific data is labor-intensive and fine-tuning the large pre-trained models is computationally expensive, one can reuse task-specific finetuned models to deal with downstream tasks. However, using a model per task causes a heavy burden on storage and serving. Recently, many training-free and parameter-efficient methods have been proposed for reusing multiple fine-tuned task-specific models into a single multi-task model. However, these methods exhibit a large accuracy gap compared with using a fine-tuned model per task. In this paper, we propose Parameter-Efficient methods for ReUsing (PERU) fine-tuned models. For reusing Fully Fine-Tuned (FFT) models, we propose PERU-FFT by injecting a sparse task vector into a merged model by magnitude pruning. For reusing LoRA fine-tuned models, we propose PERU-LoRA use a lower-rank matrix to approximate the LoRA matrix by singular value decomposition. Both PERUFFT and PERU-LoRA are training-free. Extensive experiments conducted on computer vision and natural language process tasks demonstrate the effectiveness and parameter-efficiency of the proposed methods. The proposed PERU-FFT and PERU-LoRA outperform existing reusing model methods by a large margin and achieve comparable performance to using a fine-tuned model per task.", "url": "https://arxiv.org/abs/2310.01886"}, {"metadata": {"arXiv": "2310.01937", "Date": "Tue, 03 Oct 2023 10:24:44 ", "Title": "Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder", "Authors": ["Ziqi Xu", "Debo Cheng", "Jiuyong Li", "Jixue Liu", "Lin Liu", "Kui Yu"], "Categories": "cs.LG"}, "abstract": "An essential and challenging problem in causal inference is causal effect estimation from observational data. The problem becomes more difficult with the presence of unobserved confounding variables. The front-door adjustment is a practical approach for dealing with unobserved confounding variables. However, the restriction for the standard front-door adjustment is difficult to satisfy in practice. In this paper, we relax some of the restrictions by proposing the concept of conditional front-door (CFD) adjustment and develop the theorem that guarantees the causal effect identifiability of CFD adjustment. Furthermore, as it is often impossible for a CFD variable to be given in practice, it is desirable to learn it from data. By leveraging the ability of deep generative models, we propose CFDiVAE to learn the representation of the CFD adjustment variable directly from data with the identifiable Variational AutoEncoder and formally prove the model identifiability. Extensive experiments on synthetic datasets validate the effectiveness of CFDiVAE and its superiority over existing methods. The experiments also show that the performance of CFDiVAE is less sensitive to the causal strength of unobserved confounding variables. We further apply CFDiVAE to a real-world dataset to demonstrate its potential application.", "url": "https://arxiv.org/abs/2310.01937"}, {"metadata": {"arXiv": "2310.01942", "Date": "Tue, 03 Oct 2023 10:38:39 ", "Title": "OOD Aware Supervised Contrastive Learning", "Authors": ["Soroush Seifi", "Daniel Olmeda Reino", "Nikolay Chumerin", "Rahaf Aljundi"], "Categories": "cs.LG cs.CV"}, "abstract": "Out-of-Distribution (OOD) detection is a crucial problem for the safe deployment of machine learning models identifying samples that fall outside of the training distribution, i.e. in-distribution data (ID). Most OOD works focus on the classification models trained with Cross Entropy (CE) and attempt to fix its inherent issues. In this work we leverage powerful representation learned with Supervised Contrastive (SupCon) training and propose a holistic approach to learn a classifier robust to OOD data. We extend SupCon loss with two additional contrast terms. The first term pushes auxiliary OOD representations away from ID representations without imposing any constraints on similarities among auxiliary data. The second term pushes OOD features far from the existing class prototypes, while pushing ID representations closer to their corresponding class prototype. When auxiliary OOD data is not available, we propose feature mixing techniques to efficiently generate pseudo-OOD features. Our solution is simple and efficient and acts as a natural extension of the closed-set supervised contrastive representation learning. We compare against different OOD detection methods on the common benchmarks and show state-of-the-art results.", "url": "https://arxiv.org/abs/2310.01942"}, {"metadata": {"arXiv": "2310.01959", "Date": "Tue, 03 Oct 2023 11:10:21 ", "Title": "Beyond Labeling Oracles: What does it mean to steal ML models?", "Authors": ["Avital Shafran", "Ilia Shumailov", "Murat A. Erdogdu", "Nicolas Papernot"], "Categories": "cs.LG cs.CR"}, "abstract": "Model extraction attacks are designed to steal trained models with only query access, as is often provided through APIs that ML-as-a-Service providers offer. ML models are expensive to train, in part because data is hard to obtain, and a primary incentive for model extraction is to acquire a model while incurring less cost than training from scratch. Literature on model extraction commonly claims or presumes that the attacker is able to save on both data acquisition and labeling costs. We show that the attacker often does not. This is because current attacks implicitly rely on the adversary being able to sample from the victim model's data distribution. We thoroughly evaluate factors influencing the success of model extraction. We discover that prior knowledge of the attacker, i.e. access to in-distribution data, dominates other factors like the attack policy the adversary follows to choose which queries to make to the victim model API. Thus, an adversary looking to develop an equally capable model with a fixed budget has little practical incentive to perform model extraction, since for the attack to work they need to collect in-distribution data, saving only on the cost of labeling. With low labeling costs in the current market, the usefulness of such attacks is questionable. Ultimately, we demonstrate that the effect of prior knowledge needs to be explicitly decoupled from the attack policy. To this end, we propose a benchmark to evaluate attack policy directly.", "url": "https://arxiv.org/abs/2310.01959"}, {"metadata": {"arXiv": "2310.01972", "Date": "Tue, 03 Oct 2023 11:28:54 ", "Title": "Epidemic Learning: Boosting Decentralized Learning with Randomized Communication", "Authors": ["Martijn de Vos", "Sadegh Farhadkhani", "Rachid Guerraoui", "Anne-Marie Kermarrec", "Rafael Pires", "Rishi Sharma"], "Categories": "cs.LG cs.DC", "Comments": ["Accepted paper at NeurIPS 2023"]}, "abstract": "We present Epidemic Learning (EL), a simple yet powerful decentralized learning (DL) algorithm that leverages changing communication topologies to achieve faster model convergence compared to conventional DL approaches. At each round of EL, each node sends its model updates to a random sample of $s$ other nodes (in a system of $n$ nodes). We provide an extensive theoretical analysis of EL, demonstrating that its changing topology culminates in superior convergence properties compared to the state-of-the-art (static and dynamic) topologies. Considering smooth non-convex loss functions, the number of transient iterations for EL, i.e., the rounds required to achieve asymptotic linear speedup, is in $\\mathcal{O}(\\frac{n^3}{s^2})$ which outperforms the best-known bound $\\mathcal{O}({n^3})$ by a factor of $ s^2 $, indicating the benefit of randomized communication for DL. We empirically evaluate EL in a 96-node network and compare its performance with state-of-the-art DL approaches. Our results illustrate that EL converges up to $ 1.6\\times $ quicker than baseline DL algorithms and attains 1.8% higher accuracy for the same communication volume.", "url": "https://arxiv.org/abs/2310.01972"}, {"metadata": {"arXiv": "2310.01973", "Date": "Tue, 03 Oct 2023 11:30:50 ", "Title": "Federated Wasserstein Distance", "Authors": ["Alain Rakotomamonjy", "Kimia Nadjahi", "Liva Ralaivola"], "Categories": "cs.LG cs.DC", "Comments": ["23 pages"]}, "abstract": "We introduce a principled way of computing the Wasserstein distance between two distributions in a federated manner. Namely, we show how to estimate the Wasserstein distance between two samples stored and kept on different devices/clients whilst a central entity/server orchestrates the computations (again, without having access to the samples). To achieve this feat, we take advantage of the geometric properties of the Wasserstein distance -- in particular, the triangle inequality -- and that of the associated {\\em geodesics}: our algorithm, FedWad (for Federated Wasserstein Distance), iteratively approximates the Wasserstein distance by manipulating and exchanging distributions from the space of geodesics in lieu of the input samples. In addition to establishing the convergence properties of FedWad, we provide empirical results on federated coresets and federate optimal transport dataset distance, that we respectively exploit for building a novel federated model and for boosting performance of popular federated learning algorithms.", "url": "https://arxiv.org/abs/2310.01973"}, {"metadata": {"arXiv": "2310.01975", "Date": "Tue, 03 Oct 2023 11:31:37 ", "Title": "Benign Overfitting in Two-Layer ReLU Convolutional Neural Networks for XOR Data", "Authors": ["Xuran Meng", "Difan Zou", "Yuan Cao"], "Categories": "cs.LG", "Comments": ["74 pages", "3 figures"]}, "abstract": "Modern deep learning models are usually highly over-parameterized so that they can overfit the training data. Surprisingly, such overfitting neural networks can usually still achieve high prediction accuracy. To study this \"benign overfitting\" phenomenon, a line of recent works has theoretically studied the learning of linear models and two-layer neural networks. However, most of these analyses are still limited to the very simple learning problems where the Bayes-optimal classifier is linear. In this work, we investigate a class of XOR-type classification tasks with label-flipping noises. We show that, under a certain condition on the sample complexity and signal-to-noise ratio, an over-parameterized ReLU CNN trained by gradient descent can achieve near Bayes-optimal accuracy. Moreover, we also establish a matching lower bound result showing that when the previous condition is not satisfied, the prediction accuracy of the obtained CNN is an absolute constant away from the Bayes-optimal rate. Our result demonstrates that CNNs have a remarkable capacity to efficiently learn XOR problems, even in the presence of highly correlated features.", "url": "https://arxiv.org/abs/2310.01975"}, {"metadata": {"arXiv": "2310.02008", "Date": "Tue, 03 Oct 2023 12:24:51 ", "Title": "fmeffects: An R Package for Forward Marginal Effects", "Authors": ["Holger L\\\"owe", "Christian A. Scholbeck", "Christian Heumann", "Bernd Bischl", "Giuseppe Casalicchio"], "Categories": "cs.LG econ.EM stat.ML"}, "abstract": "Forward marginal effects (FMEs) have recently been introduced as a versatile and effective model-agnostic interpretation method. They provide comprehensible and actionable model explanations in the form of: If we change $x$ by an amount $h$, what is the change in predicted outcome $\\widehat{y}$? We present the R package fmeffects, the first software implementation of FMEs. The relevant theoretical background, package functionality and handling, as well as the software design and options for future extensions are discussed in this paper.", "url": "https://arxiv.org/abs/2310.02008"}, {"metadata": {"arXiv": "2310.02013", "Date": "Tue, 03 Oct 2023 12:37:15 ", "Title": "Spectral operator learning for parametric PDEs without data reliance", "Authors": ["Junho Choi", "Taehyun Yun", "Namjung Kim", "Youngjoon Hong"], "Categories": "cs.LG", "Comments": ["28 pages", "8 figures"]}, "abstract": "In this paper, we introduce the Spectral Coefficient Learning via Operator Network (SCLON), a novel operator learning-based approach for solving parametric partial differential equations (PDEs) without the need for data harnessing. The cornerstone of our method is the spectral methodology that employs expansions using orthogonal functions, such as Fourier series and Legendre polynomials, enabling accurate PDE solutions with fewer grid points. By merging the merits of spectral methods - encompassing high accuracy, efficiency, generalization, and the exact fulfillment of boundary conditions - with the prowess of deep neural networks, SCLON offers a transformative strategy. Our approach not only eliminates the need for paired input-output training data, which typically requires extensive numerical computations, but also effectively learns and predicts solutions of complex parametric PDEs, ranging from singularly perturbed convection-diffusion equations to the Navier-Stokes equations. The proposed framework demonstrates superior performance compared to existing scientific machine learning techniques, offering solutions for multiple instances of parametric PDEs without harnessing data. The mathematical framework is robust and reliable, with a well-developed loss function derived from the weak formulation, ensuring accurate approximation of solutions while exactly satisfying boundary conditions. The method's efficacy is further illustrated through its ability to accurately predict intricate natural behaviors like the Kolmogorov flow and boundary layers. In essence, our work pioneers a compelling avenue for parametric PDE solutions, serving as a bridge between traditional numerical methodologies and cutting-edge machine learning techniques in the realm of scientific computation.", "url": "https://arxiv.org/abs/2310.02013"}, {"metadata": {"arXiv": "2310.02016", "Date": "Tue, 03 Oct 2023 12:42:13 ", "Title": "Ranking a Set of Objects using Heterogeneous Workers: QUITE an Easy Problem", "Authors": ["Alessandro Nordio and Alberto tarable and Emilio Leonardi"], "Categories": "cs.LG cs.HC cs.PF cs.SI"}, "abstract": "We focus on the problem of ranking $N$ objects starting from a set of noisy pairwise comparisons provided by a crowd of unequal workers, each worker being characterized by a specific degree of reliability, which reflects her ability to rank pairs of objects. More specifically, we assume that objects are endowed with intrinsic qualities and that the probability with which an object is preferred to another depends both on the difference between the qualities of the two competitors and on the reliability of the worker. We propose QUITE, a non-adaptive ranking algorithm that jointly estimates workers' reliabilities and qualities of objects. Performance of QUITE is compared in different scenarios against previously proposed algorithms. Finally, we show how QUITE can be naturally made adaptive.", "url": "https://arxiv.org/abs/2310.02016"}, {"metadata": {"arXiv": "2310.02023", "Date": "Tue, 03 Oct 2023 12:58:10 ", "Title": "Nash Regret Guarantees for Linear Bandits", "Authors": ["Ayush Sawarni", "Soumybrata Pal", "and Siddharth Barman"], "Categories": "cs.LG cs.GT", "Comments": ["35 pages"]}, "abstract": "We obtain essentially tight upper bounds for a strengthened notion of regret in the stochastic linear bandits framework. The strengthening -- referred to as Nash regret -- is defined as the difference between the (a priori unknown) optimum and the geometric mean of expected rewards accumulated by the linear bandit algorithm. Since the geometric mean corresponds to the well-studied Nash social welfare (NSW) function, this formulation quantifies the performance of a bandit algorithm as the collective welfare it generates across rounds. NSW is known to satisfy fairness axioms and, hence, an upper bound on Nash regret provides a principled fairness guarantee. We consider the stochastic linear bandits problem over a horizon of $T$ rounds and with set of arms ${X}$ in ambient dimension $d$. Furthermore, we focus on settings in which the stochastic reward -- associated with each arm in ${X}$ -- is a non-negative, $\\nu$-sub-Poisson random variable. For this setting, we develop an algorithm that achieves a Nash regret of $O\\left( \\sqrt{\\frac{d\\nu}{T}} \\log( T |X|)\\right)$. In addition, addressing linear bandit instances in which the set of arms ${X}$ is not necessarily finite, we obtain a Nash regret upper bound of $O\\left( \\frac{d^\\frac{5}{4}\\nu^{\\frac{1}{2}}}{\\sqrt{T}} \\log(T)\\right)$. Since bounded random variables are sub-Poisson, these results hold for bounded, positive rewards. Our linear bandit algorithm is built upon the successive elimination method with novel technical insights, including tailored concentration bounds and the use of sampling via John ellipsoid in conjunction with the Kiefer-Wolfowitz optimal design.", "url": "https://arxiv.org/abs/2310.02023"}, {"metadata": {"arXiv": "2310.02025", "Date": "Tue, 03 Oct 2023 13:05:36 ", "Title": "DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training", "Authors": ["Aochuan Chen", "Yimeng Zhang", "Jinghan Jia", "James Diffenderfer", "Jiancheng Liu", "Konstantinos Parasyris", "Yihua Zhang", "Zheng Zhang", "Bhavya Kailkhura", "Sijia Liu"], "Categories": "cs.LG"}, "abstract": "Zeroth-order (ZO) optimization has become a popular technique for solving machine learning (ML) problems when first-order (FO) information is difficult or impossible to obtain. However, the scalability of ZO optimization remains an open problem: Its use has primarily been limited to relatively small-scale ML problems, such as sample-wise adversarial attack generation. To our best knowledge, no prior work has demonstrated the effectiveness of ZO optimization in training deep neural networks (DNNs) without a significant decrease in performance. To overcome this roadblock, we develop DeepZero, a principled ZO deep learning (DL) framework that can scale ZO optimization to DNN training from scratch through three primary innovations. First, we demonstrate the advantages of coordinate-wise gradient estimation (CGE) over randomized vector-wise gradient estimation in training accuracy and computational efficiency. Second, we propose a sparsity-induced ZO training protocol that extends the model pruning methodology using only finite differences to explore and exploit the sparse DL prior in CGE. Third, we develop the methods of feature reuse and forward parallelization to advance the practical implementations of ZO training. Our extensive experiments show that DeepZero achieves state-of-the-art (SOTA) accuracy on ResNet-20 trained on CIFAR-10, approaching FO training performance for the first time. Furthermore, we show the practical utility of DeepZero in applications of certified adversarial defense and DL-based partial differential equation error correction, achieving 10-20% improvement over SOTA. We believe our results will inspire future research on scalable ZO optimization and contribute to advancing DL with black box.", "url": "https://arxiv.org/abs/2310.02025"}, {"metadata": {"arXiv": "2310.02027", "Date": "Tue, 03 Oct 2023 13:10:14 ", "Title": "DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks", "Authors": ["Jiaxu Liu", "Xinping Yi", "Xiaowei Huang"], "Categories": "cs.LG", "Comments": ["12 pages including appendix and reference"]}, "abstract": "Hyperbolic graph convolutional networks (HGCN) have demonstrated significant potential in extracting information from hierarchical graphs. However, existing HGCNs are limited to shallow architectures, due to the expensive hyperbolic operations and the over-smoothing issue as depth increases. Although in GCNs, treatments have been applied to alleviate over-smoothing, developing a hyperbolic therapy presents distinct challenges since operations should be carefully designed to fit the hyperbolic nature. Addressing the above challenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN architecture with dramatically improved computational efficiency and substantially alleviated over-smoothing effect. DeepHGCN presents two key enablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer that enables fast and accurate linear maps; and (2) Techniques such as hyperbolic residual connections and regularization for both weights and features facilitated by an efficient hyperbolic midpoint method. Extensive experiments demonstrate that DeepHGCN obtains significant improvements in link prediction and node classification tasks compared to both Euclidean and shallow hyperbolic GCN variants.", "url": "https://arxiv.org/abs/2310.02027"}, {"metadata": {"arXiv": "2310.02029", "Date": "Tue, 03 Oct 2023 13:15:02 ", "Title": "Between accurate prediction and poor decision making: the AI/ML gap", "Authors": ["Gianluca Bontempi"], "Categories": "cs.LG", "Comments": ["Position paper presented in the BENELEARN 2022 conference"]}, "abstract": "Intelligent agents rely on AI/ML functionalities to predict the consequence of possible actions and optimise the policy. However, the effort of the research community in addressing prediction accuracy has been so intense (and successful) that it created the illusion that the more accurate the learner prediction (or classification) the better would have been the final decision. Now, such an assumption is valid only if the (human or artificial) decision maker has complete knowledge of the utility of the possible actions. This paper argues that AI/ML community has taken so far a too unbalanced approach by devoting excessive attention to the estimation of the state (or target) probability to the detriment of accurate and reliable estimations of the utility. In particular, few evidence exists about the impact of a wrong utility assessment on the resulting expected utility of the decision strategy. This situation is creating a substantial gap between the expectations and the effective impact of AI solutions, as witnessed by recent criticisms and emphasised by the regulatory legislative efforts. This paper aims to study this gap by quantifying the sensitivity of the expected utility to the utility uncertainty and comparing it to the one due to probability estimation. Theoretical and simulated results show that an inaccurate utility assessment may as (and sometimes) more harmful than a poor probability estimation. The final recommendation to the community is then to undertake a focus shift from a pure accuracy-driven (or obsessed) approach to a more utility-aware methodology.", "url": "https://arxiv.org/abs/2310.02029"}, {"metadata": {"arXiv": "2310.02032", "Date": "Tue, 03 Oct 2023 13:17:38 ", "Title": "aSAGA: Automatic Sleep Analysis with Gray Areas", "Authors": ["Matias Rusanen", "Gabriel Jouan", "Riku Huttunen", "Sami Nikkonen", "Sigr\\'i{\\dh}ur Sigur{\\dh}ard\\'ottir", "Juha T\\\"oyr\\\"as", "Brett Duce", "Sami Myllymaa", "Erna Sif Arnardottir", "Timo Lepp\\\"anen", "Anna Sigridur Islind", "Samu Kainulainen", "Henri Korkalainen"], "Categories": "cs.LG cs.HC"}, "abstract": "State-of-the-art automatic sleep staging methods have already demonstrated comparable reliability and superior time efficiency to manual sleep staging. However, fully automatic black-box solutions are difficult to adapt into clinical workflow and the interaction between explainable automatic methods and the work of sleep technologists remains underexplored and inadequately conceptualized. Thus, we propose a human-in-the-loop concept for sleep analysis, presenting an automatic sleep staging model (aSAGA), that performs effectively with both clinical polysomnographic recordings and home sleep studies. To validate the model, extensive testing was conducted, employing a preclinical validation approach with three retrospective datasets; open-access, clinical, and research-driven. Furthermore, we validate the utilization of uncertainty mapping to identify ambiguous regions, conceptualized as gray areas, in automatic sleep analysis that warrants manual re-evaluation. The results demonstrate that the automatic sleep analysis achieved a comparable level of agreement with manual analysis across different sleep recording types. Moreover, validation of the gray area concept revealed its potential to enhance sleep staging accuracy and identify areas in the recordings where sleep technologists struggle to reach a consensus. In conclusion, this study introduces and validates a concept from explainable artificial intelligence into sleep medicine and provides the basis for integrating human-in-the-loop automatic sleep staging into clinical workflows, aiming to reduce black-box criticism and the burden associated with manual sleep staging.", "url": "https://arxiv.org/abs/2310.02032"}, {"metadata": {"arXiv": "2310.02041", "Date": "Tue, 03 Oct 2023 13:34:21 ", "Title": "The Inhibitor: ReLU and Addition-Based Attention for Efficient Transformers", "Authors": ["Rickard Br\\\"annvall"], "Categories": "cs.LG", "Comments": ["8 pages", "3 tables"], "MSC-class": "68T07 68T07", "ACM-class": "I.2.6"}, "abstract": "To enhance the computational efficiency of quantized Transformers, we replace the dot-product and Softmax-based attention with an alternative mechanism involving addition and ReLU activation only. This side-steps the expansion to double precision often required by matrix multiplication and avoids costly Softmax evaluations but maintains much of the core functionality of conventional dot-product attention. It can enable more efficient execution and support larger quantized Transformer models on resource-constrained hardware or alternative arithmetic systems like homomorphic encryption. Training experiments on four common benchmark tasks show test set prediction scores comparable to those of conventional Transformers with dot-product attention. Our scaling experiments also suggest significant computational savings, both in plaintext and under encryption. In particular, we believe that the ReLU and addition-based attention mechanism introduced in this paper may enable privacy-preserving AI applications operating under homomorphic encryption by avoiding the costly multiplication of encrypted variables.", "url": "https://arxiv.org/abs/2310.02041"}, {"metadata": {"arXiv": "2310.02063", "Date": "Tue, 03 Oct 2023 14:04:45 ", "Title": "Lessons Learned from EXMOS User Studies: A Technical Report Summarizing Key Takeaways from User Studies Conducted to Evaluate The EXMOS Platform", "Authors": ["Aditya Bhattacharya", "Simone Stumpf", "Lucija Gosak", "Gregor Stiglic", "Katrien Verbert"], "Categories": "cs.LG cs.HC", "Comments": ["It is a technical report only. The contents are not peer-reviewed. Please reach out to the main author for any questions"]}, "abstract": "In the realm of interactive machine-learning systems, the provision of explanations serves as a vital aid in the processes of debugging and enhancing prediction models. However, the extent to which various global model-centric and data-centric explanations can effectively assist domain experts in detecting and resolving potential data-related issues for the purpose of model improvement has remained largely unexplored. In this technical report, we summarise the key findings of our two user studies. Our research involved a comprehensive examination of the impact of global explanations rooted in both data-centric and model-centric perspectives within systems designed to support healthcare experts in optimising machine learning models through both automated and manual data configurations. To empirically investigate these dynamics, we conducted two user studies, comprising quantitative analysis involving a sample size of 70 healthcare experts and qualitative assessments involving 30 healthcare experts. These studies were aimed at illuminating the influence of different explanation types on three key dimensions: trust, understandability, and model improvement. Results show that global model-centric explanations alone are insufficient for effectively guiding users during the intricate process of data configuration. In contrast, data-centric explanations exhibited their potential by enhancing the understanding of system changes that occur post-configuration. However, a combination of both showed the highest level of efficacy for fostering trust, improving understandability, and facilitating model enhancement among healthcare experts. We also present essential implications for developing interactive machine-learning systems driven by explanations. These insights can guide the creation of more effective systems that empower domain experts to harness the full potential of machine learning", "url": "https://arxiv.org/abs/2310.02063"}, {"metadata": {"arXiv": "2310.02090", "Date": "Tue, 03 Oct 2023 14:33:34 ", "Title": "1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index Forecasting", "Authors": ["Cheng Zhang", "Nilam Nur Amir Sjarif", "Roslina Ibrahim"], "Categories": "cs.LG cs.NE"}, "abstract": "Multi-step forecasting of stock market index prices is a crucial task in the financial sector, playing a pivotal role in decision-making across various financial activities. However, forecasting results are often unsatisfactory owing to the stochastic and volatile nature of the data. Researchers have made various attempts, and this process is ongoing. Inspired by convolutional neural network long short-term memory (CNN-LSTM) networks that utilize a 1D CNN for feature extraction to boost model performance, this study explores the use of a capsule network (CapsNet) as an advanced feature extractor in an LSTM-based forecasting model to enhance multi-step predictions. To this end, a novel neural architecture called 1D-CapsNet-LSTM was introduced, which combines a 1D CapsNet to extract high-level features from 1D sequential data and an LSTM layer to capture the temporal dependencies between the previously extracted features and uses a multi-input multi-output (MIMO) strategy to maintain the stochastic dependencies between the predicted values at different time steps. The proposed model was evaluated based on several real-world stock market indices, including Standard & Poor's 500 (S&P 500), Dow Jones Industrial Average (DJIA), Nasdaq Composite Index (IXIC), and New York Stock Exchange (NYSE), and was compared with baseline models such as LSTM, recurrent neural network (RNN), and CNN-LSTM in terms of various evaluation metrics. The comparison results suggest that the 1D-CapsNet-LSTM model outperforms the baseline models and has immense potential for the effective handling of complex prediction tasks.", "url": "https://arxiv.org/abs/2310.02090"}, {"metadata": {"arXiv": "2310.02093", "Date": "Tue, 03 Oct 2023 14:36:05 ", "Title": "Stochastic Gradient Descent with Preconditioned Polyak Step-size", "Authors": ["Farshed Abdukhakimov", "Chulu Xiang", "Dmitry Kamzolov", "Martin Tak\\'a\\v{c}"], "Categories": "cs.LG math.OC"}, "abstract": "Stochastic Gradient Descent (SGD) is one of the many iterative optimization methods that are widely used in solving machine learning problems. These methods display valuable properties and attract researchers and industrial machine learning engineers with their simplicity. However, one of the weaknesses of this type of methods is the necessity to tune learning rate (step-size) for every loss function and dataset combination to solve an optimization problem and get an efficient performance in a given time budget. Stochastic Gradient Descent with Polyak Step-size (SPS) is a method that offers an update rule that alleviates the need of fine-tuning the learning rate of an optimizer. In this paper, we propose an extension of SPS that employs preconditioning techniques, such as Hutchinson's method, Adam, and AdaGrad, to improve its performance on badly scaled and/or ill-conditioned datasets.", "url": "https://arxiv.org/abs/2310.02093"}, {"metadata": {"arXiv": "2310.02116", "Date": "Tue, 03 Oct 2023 14:57:31 ", "Title": "Hierarchical Concept Discovery Models: A Concept Pyramid Scheme", "Authors": ["Konstantinos P. Panousis", "Dino Ienco", "Diego Marcos"], "Categories": "cs.LG stat.ML"}, "abstract": "Deep Learning algorithms have recently gained significant attention due to their impressive performance. However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks. This work targets ante hoc interpretability, and specifically Concept Bottleneck Models (CBMs). Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on multiple levels of granularity. To this end, we propose a novel hierarchical concept discovery formulation leveraging: (i) recent advances in image-text models, and (ii) an innovative formulation for multi-level concept selection via data-driven and sparsity inducing Bayesian arguments. Within this framework, concept information does not solely rely on the similarity between the whole image and general unstructured concepts; instead, we introduce the notion of concept hierarchy to uncover and exploit more granular concept information residing in patch-specific regions of the image scene. As we experimentally show, the proposed construction not only outperforms recent CBM approaches, but also yields a principled framework towards interpetability.", "url": "https://arxiv.org/abs/2310.02116"}, {"metadata": {"arXiv": "2310.02117", "Date": "Tue, 03 Oct 2023 14:59:00 ", "Title": "Symmetric Single Index Learning", "Authors": ["Aaron Zweig", "Joan Bruna"], "Categories": "cs.LG"}, "abstract": "Few neural architectures lend themselves to provable learning with gradient based methods. One popular model is the single-index model, in which labels are produced by composing an unknown linear projection with a possibly unknown scalar link function. Learning this model with SGD is relatively well-understood, whereby the so-called information exponent of the link function governs a polynomial sample complexity rate. However, extending this analysis to deeper or more complicated architectures remains challenging. In this work, we consider single index learning in the setting of symmetric neural networks. Under analytic assumptions on the activation and maximum degree assumptions on the link function, we prove that gradient flow recovers the hidden planted direction, represented as a finitely supported vector in the feature space of power sum polynomials. We characterize a notion of information exponent adapted to our setting that controls the efficiency of learning.", "url": "https://arxiv.org/abs/2310.02117"}, {"metadata": {"arXiv": "2310.02156", "Date": "Tue, 03 Oct 2023 15:43:59 ", "Title": "Probabilistically Rewired Message-Passing Neural Networks", "Authors": ["Chendi Qian", "Andrei Manolache", "Kareem Ahmed", "Zhe Zeng", "Guy Van den Broeck", "Mathias Niepert", "Christopher Morris"], "Categories": "cs.LG cs.NE"}, "abstract": "Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable $k$-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures.", "url": "https://arxiv.org/abs/2310.02156"}, {"metadata": {"arXiv": "2310.02164", "Date": "Wed, 23 Aug 2023 20:50:52 ", "Title": "Graph Unlearning: A Review", "Authors": ["Anwar Said and Tyler Derr and Mudassir Shabbir and Waseem Abbas and Xenofon Koutsoukos"], "Categories": "cs.LG", "Comments": ["22 page review paper on graph unlearning"]}, "abstract": "Graph unlearning emerges as a crucial advancement in the pursuit of responsible AI, providing the means to remove sensitive data traces from trained models, thereby upholding the right to be forgotten. It is evident that graph machine learning exhibits sensitivity to data privacy and adversarial attacks, necessitating the application of graph unlearning techniques to address these concerns effectively. In this comprehensive survey paper, we present the first systematic review of graph unlearning approaches, encompassing a diverse array of methodologies and offering a detailed taxonomy and up-to-date literature overview to facilitate the understanding of researchers new to this field. Additionally, we establish the vital connections between graph unlearning and differential privacy, augmenting our understanding of the relevance of privacy-preserving techniques in this context. To ensure clarity, we provide lucid explanations of the fundamental concepts and evaluation measures used in graph unlearning, catering to a broader audience with varying levels of expertise. Delving into potential applications, we explore the versatility of graph unlearning across various domains, including but not limited to social networks, adversarial settings, and resource-constrained environments like the Internet of Things (IoT), illustrating its potential impact in safeguarding data privacy and enhancing AI systems' robustness. Finally, we shed light on promising research directions, encouraging further progress and innovation within the domain of graph unlearning. By laying a solid foundation and fostering continued progress, this survey seeks to inspire researchers to further advance the field of graph unlearning, thereby instilling confidence in the ethical growth of AI systems and reinforcing the responsible application of machine learning techniques in various domains.", "url": "https://arxiv.org/abs/2310.02164"}, {"metadata": {"arXiv": "2310.02206", "Date": "Tue, 03 Oct 2023 17:04:33 ", "Title": "Chunking: Forgetting Matters in Continual Learning even without Changing Tasks", "Authors": ["Thomas L. Lee", "Amos Storkey"], "Categories": "cs.LG stat.ML", "Comments": ["9 pages", "11 figures", "preprint"]}, "abstract": "Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution. However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time. In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse. We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments. Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution. We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distribution shift, still arises and is a significant problem. Motivated by an analysis of the linear case, we show that per-chunk weight averaging improves performance in the chunking setting and that this performance transfers to the full CL setting. Hence, we argue that work on chunking can help advance CL in general.", "url": "https://arxiv.org/abs/2310.02206"}, {"metadata": {"arXiv": "2310.02221", "Date": "Tue, 03 Oct 2023 17:27:30 ", "Title": "Structurally guided task decomposition in spatial navigation tasks", "Authors": ["Ruiqi He", "Carlos G. Correa", "Thomas L. Griffiths", "Mark K. Ho"], "Categories": "cs.LG"}, "abstract": "How are people able to plan so efficiently despite limited cognitive resources? We aimed to answer this question by extending an existing model of human task decomposition that can explain a wide range of simple planning problems by adding structure information to the task to facilitate planning in more complex tasks. The extended model was then applied to a more complex planning domain of spatial navigation. Our results suggest that our framework can correctly predict the navigation strategies of the majority of the participants in an online experiment.", "url": "https://arxiv.org/abs/2310.02221"}, {"metadata": {"arXiv": "2310.02232", "Date": "Tue, 03 Oct 2023 17:42:09 ", "Title": "HoloNets: Spectral Convolutions do extend to Directed Graphs", "Authors": ["Christian Koke", "Daniel Cremers"], "Categories": "cs.LG cs.SI"}, "abstract": "Within the graph learning community, conventional wisdom dictates that spectral convolutional networks may only be deployed on undirected graphs: Only there could the existence of a well-defined graph Fourier transform be guaranteed, so that information may be translated between spatial- and spectral domains. Here we show this traditional reliance on the graph Fourier transform to be superfluous and -- making use of certain advanced tools from complex analysis and spectral theory -- extend spectral convolutions to directed graphs. We provide a frequency-response interpretation of newly developed filters, investigate the influence of the basis used to express filters and discuss the interplay with characteristic operators on which networks are based. In order to thoroughly test the developed theory, we conduct experiments in real world settings, showcasing that directed spectral convolutional networks provide new state of the art results for heterophilic node classification on many datasets and -- as opposed to baselines -- may be rendered stable to resolution-scale varying topological perturbations.", "url": "https://arxiv.org/abs/2310.02232"}, {"metadata": {"arXiv": "2310.02250", "Date": "Tue, 03 Oct 2023 17:53:43 ", "Title": "Why do autoencoders work?", "Authors": ["Matthew D. Kvalheim and Eduardo D. Sontag"], "Categories": "cs.LG", "Comments": ["12 pages", "8 figures"]}, "abstract": "Deep neural network autoencoders are routinely used computationally for model reduction. They allow recognizing the intrinsic dimension of data that lie in a $k$-dimensional subset $K$ of an input Euclidean space $\\R^n$. The underlying idea is to obtain both an encoding layer that maps $\\R^n$ into $\\R^k$ (called the bottleneck layer or the space of latent variables) and a decoding layer that maps $\\R^k$ back into $\\R^n$, in such a way that the input data from the set $K$ is recovered when composing the two maps. This is achieved by adjusting parameters (weights) in the network to minimize the discrepancy between the input and the reconstructed output. Since neural networks (with continuous activation functions) compute continuous maps, the existence of a network that achieves perfect reconstruction would imply that $K$ is homeomorphic to a $k$-dimensional subset of $\\R^k$, so clearly there are topological obstructions to finding such a network. On the other hand, in practice the technique is found to ``work'' well, which leads one to ask if there is a way to explain this effectiveness. We show that, up to small errors, indeed the method is guaranteed to work. This is done by appealing to certain facts from differential geometry. A computational example is also included to illustrate the ideas.", "url": "https://arxiv.org/abs/2310.02250"}, {"metadata": {"arXiv": "2310.02264", "Date": "Tue, 03 Oct 2023 17:59:46 ", "Title": "Generalizable Long-Horizon Manipulations with Large Language Models", "Authors": ["Haoyu Zhou", "Mingyu Ding", "Weikun Peng", "Masayoshi Tomizuka", "Lin Shao", "Chuang Gan"], "Categories": "cs.RO cs.CL cs.CV cs.LG"}, "abstract": "This work introduces a framework harnessing the capabilities of Large Language Models (LLMs) to generate primitive task conditions for generalizable long-horizon manipulations with novel objects and unseen tasks. These task conditions serve as guides for the generation and adjustment of Dynamic Movement Primitives (DMP) trajectories for long-horizon task execution. We further create a challenging robotic manipulation task suite based on Pybullet for long-horizon task evaluation. Extensive experiments in both simulated and real-world environments demonstrate the effectiveness of our framework on both familiar tasks involving new objects and novel but related tasks, highlighting the potential of LLMs in enhancing robotic system versatility and adaptability. Project website: https://object814.github.io/Task-Condition-With-LLM/", "url": "https://arxiv.org/abs/2310.02264"}, {"metadata": {"arXiv": "2310.01661", "Date": "Mon, 02 Oct 2023 21:51:42 ", "Title": "Home Electricity Data Generator (HEDGE): An open-access tool for the generation of electric vehicle, residential demand, and PV generation profiles", "Authors": ["Flora Charbonnier", "Thomas Morstyn", "Malcolm McCulloch"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "In this paper, we present the Home Electricity Data Generator (HEDGE), an open-access tool for the random generation of realistic residential energy data. HEDGE generates realistic daily profiles of residential PV generation, household electric loads, and electric vehicle consumption and at-home availability, based on real-life UK datasets. The lack of usable data is a major hurdle for research on residential distributed energy resources characterisation and coordination, especially when using data-driven methods such as machine learning-based forecasting and reinforcement learning-based control. A key issue is that while large data banks are available, they are not in a usable format, and numerous subsequent days of data for a given single home are unavailable. We fill these gaps with the open-access HEDGE tool which generates data sequences of energy data for several days in a way that is consistent for single homes, both in terms of profile magnitude and behavioural clusters. From raw datasets, pre-processing steps are conducted, including filling in incomplete data sequences and clustering profiles into behaviour clusters. Generative adversarial networks (GANs) are then trained to generate realistic synthetic data representative of each behaviour groups consistent with real-life behavioural and physical patterns.", "url": "https://arxiv.org/abs/2310.01661"}, {"metadata": {"arXiv": "2310.01470", "Date": "Mon, 02 Oct 2023 17:46:44 ", "Title": "Challenges in Modelling and Solving Plotting with PDDL", "Authors": ["Joan Espasa", "Ian Miguel", "Peter Nightingale", "Andr\\'as Z. Salamon", "Mateu Villaret"], "Categories": "cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2110.14397"]}, "abstract": "We study a planning problem based on Plotting, a tile-matching puzzle video game published by Taito in 1989. The objective of this game is to remove a target number of coloured blocks from a grid by sequentially shooting blocks into the grid. Plotting features complex transitions after every shot: various blocks are affected directly, while others can be indirectly affected by gravity. We highlight the challenges of modelling Plotting with PDDL and of solving it with a grounding-based state-of-the-art planner.", "url": "https://arxiv.org/abs/2310.01470"}, {"metadata": {"arXiv": "2310.01471", "Date": "Mon, 02 Oct 2023 17:50:31 ", "Title": "A Good Snowman is Hard to Plan", "Authors": ["Miquel Bofill", "Cristina Borralleras", "Joan Espasa", "Gerard Mart\\'in", "Gustavo Patow", "Mateu Villaret"], "Categories": "cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2310.01378"]}, "abstract": "In this work we face a challenging puzzle video game: A Good Snowman is Hard to Build. The objective of the game is to build snowmen by moving and stacking snowballs on a discrete grid. For the sake of player engagement with the game, it is interesting to avoid that a player finds a much easier solution than the one the designer expected. Therefore, having tools that are able to certify the optimality of solutions is crucial. Although the game can be stated as a planning problem and can be naturally modelled in PDDL, we show that a direct translation to SAT clearly outperforms off-the-shelf state-of-the-art planners. As we show, this is mainly due to the fact that reachability properties can be easily modelled in SAT, allowing for shorter plans, whereas using axioms to express a reachability derived predicate in PDDL does not result in any significant reduction of solving time with the considered planners. We deal with a set of 51 levels, both original and crafted, solving 43 and with 8 challenging instances still remaining to be solved.", "url": "https://arxiv.org/abs/2310.01471"}, {"metadata": {"arXiv": "2310.01503", "Date": "Mon, 02 Oct 2023 18:00:59 ", "Title": "Towards a Model of Puzznic", "Authors": ["Joan Espasa and Ian P. Gent and Ian Miguel and Peter Nightingale and Andr\\'as Z. Salamon and Mateu Villaret"], "Categories": "cs.AI"}, "abstract": "We report on progress in modelling and solving Puzznic, a video game requiring the player to plan sequences of moves to clear a grid by matching blocks. We focus here on levels with no moving blocks. We compare a planning approach and three constraint programming approaches on a small set of benchmark instances. The planning approach is at present superior to the constraint programming approaches, but we outline proposals for improving the constraint models.", "url": "https://arxiv.org/abs/2310.01503"}, {"metadata": {"arXiv": "2310.01505", "Date": "Mon, 02 Oct 2023 18:01:43 ", "Title": "Towards Automatic Design of Factorio Blueprints", "Authors": ["Sean Patterson and Joan Espasa and Mun See Chang and Ruth Hoffmann"], "Categories": "cs.AI"}, "abstract": "Factorio is a 2D construction and management simulation video game about building automated factories to produce items of increasing complexity. A core feature of the game is its blueprint system, which allows players to easily save and replicate parts of their designs. Blueprints can reproduce any layout of objects in the game, but are typically used to encapsulate a complex behaviour, such as the production of a non-basic object. Once created, these blueprints are then used as basic building blocks, allowing the player to create a layer of abstraction. The usage of blueprints not only eases the expansion of the factory but also allows the sharing of designs with the game's community. The layout in a blueprint can be optimised using various criteria, such as the total space used or the final production throughput. The design of an optimal blueprint is a hard combinatorial problem, interleaving elements of many well-studied problems such as bin-packing, routing or network design. This work presents a new challenging problem and explores the feasibility of a constraint model to optimise Factorio blueprints, balancing correctness, optimality, and performance.", "url": "https://arxiv.org/abs/2310.01505"}, {"metadata": {"arXiv": "2310.01520", "Date": "Mon, 02 Oct 2023 18:11:37 ", "Title": "Bridging the Gap between Structural and Semantic Similarity in Diverse Planning", "Authors": ["Mustafa F. Abdelwahed", "Joan Espasa", "Alice Toniolo", "Ian P. Gent"], "Categories": "cs.AI"}, "abstract": "Diverse planning is the problem of finding multiple plans for a given problem specification, which is at the core of many real-world applications. For example, diverse planning is a critical piece for the efficiency of plan recognition systems when dealing with noisy and missing observations. Providing diverse solutions can also benefit situations where constraints are too expensive or impossible to model. Current diverse planners operate by generating multiple plans and then applying a selection procedure to extract diverse solutions using a similarity metric. Generally, current similarity metrics only consider the structural properties of the given plans. We argue that this approach is a limitation that sometimes prevents such metrics from capturing why two plans differ. In this work, we propose two new domain-independent metrics which are able to capture relevant information on the difference between two given plans from a domain-dependent viewpoint. We showcase their utility in various situations where the currently used metrics fail to capture the similarity between plans, failing to capture some structural symmetries.", "url": "https://arxiv.org/abs/2310.01520"}, {"metadata": {"arXiv": "2310.01536", "Date": "Mon, 02 Oct 2023 18:24:51 ", "Title": "Algebras of actions in an agent's representations of the world", "Authors": ["Alexander Dean", "Eduardo Alonso and Esther Mondragon"], "Categories": "cs.AI"}, "abstract": "In this paper, we propose a framework to extract the algebra of the transformations of worlds from the perspective of an agent. As a starting point, we use our framework to reproduce the symmetry-based representations from the symmetry-based disentangled representation learning (SBDRL) formalism proposed by [1]; only the algebra of transformations of worlds that form groups can be described using symmetry-based representations. We then study the algebras of the transformations of worlds with features that occur in simple reinforcement learning scenarios. Using computational methods, that we developed, we extract the algebras of the transformations of these worlds and classify them according to their properties. Finally, we generalise two important results of SBDRL - the equivariance condition and the disentangling definition - from only working with symmetry-based representations to working with representations capturing the transformation properties of worlds with transformations for any algebra. Finally, we combine our generalised equivariance condition and our generalised disentangling definition to show that disentangled sub-algebras can each have their own individual equivariance conditions, which can be treated independently.", "url": "https://arxiv.org/abs/2310.01536"}, {"metadata": {"arXiv": "2310.01791", "Date": "Tue, 03 Oct 2023 04:40:38 ", "Title": "Online POMDP Planning with Anytime Deterministic Guarantees", "Authors": ["Moran Barenboim and Vadim Indelman"], "Categories": "cs.AI cs.RO"}, "abstract": "Autonomous agents operating in real-world scenarios frequently encounter uncertainty and make decisions based on incomplete information. Planning under uncertainty can be mathematically formalized using partially observable Markov decision processes (POMDPs). However, finding an optimal plan for POMDPs can be computationally expensive and is feasible only for small tasks. In recent years, approximate algorithms, such as tree search and sample-based methodologies, have emerged as state-of-the-art POMDP solvers for larger problems. Despite their effectiveness, these algorithms offer only probabilistic and often asymptotic guarantees toward the optimal solution due to their dependence on sampling. To address these limitations, we derive a deterministic relationship between a simplified solution that is easier to obtain and the theoretically optimal one. First, we derive bounds for selecting a subset of the observations to branch from while computing a complete belief at each posterior node. Then, since a complete belief update may be computationally demanding, we extend the bounds to support reduction of both the state and the observation spaces. We demonstrate how our guarantees can be integrated with existing state-of-the-art solvers that sample a subset of states and observations. As a result, the returned solution holds deterministic bounds relative to the optimal policy. Lastly, we substantiate our findings with supporting experimental results.", "url": "https://arxiv.org/abs/2310.01791"}, {"metadata": {"arXiv": "2310.01805", "Date": "Tue, 03 Oct 2023 05:35:42 ", "Title": "Comparative study of microgrid optimal scheduling under multi-optimization algorithm fusion", "Authors": ["Hongyi Duan and Qingyang Li and Yuchen Li and Jianan Zhang and Yuming Xie"], "Categories": "cs.AI", "Comments": ["11 pages", "6 fiures"]}, "abstract": "As global attention on renewable and clean energy grows, the research and implementation of microgrids become paramount. This paper delves into the methodology of exploring the relationship between the operational and environmental costs of microgrids through multi-objective optimization models. By integrating various optimization algorithms like Genetic Algorithm, Simulated Annealing, Ant Colony Optimization, and Particle Swarm Optimization, we propose an integrated approach for microgrid optimization. Simulation results depict that these algorithms provide different dispatch results under economic and environmental dispatch, revealing distinct roles of diesel generators and micro gas turbines in microgrids. Overall, this study offers in-depth insights and practical guidance for microgrid design and operation.", "url": "https://arxiv.org/abs/2310.01805"}, {"metadata": {"arXiv": "2310.01854", "Date": "Tue, 03 Oct 2023 07:34:30 ", "Title": "Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?", "Authors": ["Jingyuan Sun and Marie-Francine Moens"], "Categories": "cs.AI cs.CL", "Comments": ["IJCAI 2023"]}, "abstract": "To decipher the algorithm underlying the human brain's language representation, previous work probed brain responses to language input with pre-trained artificial neural network (ANN) models fine-tuned on NLU tasks. However, full fine-tuning generally updates the entire parametric space and distorts pre-trained features, cognitively inconsistent with the brain's robust multi-task learning ability. Prompt-tuning, in contrast, protects pre-trained weights and learns task-specific embeddings to fit a task. Could prompt-tuning generate representations that better account for the brain's language representations than fine-tuning? If so, what kind of NLU task leads a pre-trained model to better decode the information represented in the human brain? We investigate these questions by comparing prompt-tuned and fine-tuned representations in neural decoding, that is predicting the linguistic stimulus from the brain activities evoked by the stimulus. We find that on none of the 10 NLU tasks, full fine-tuning significantly outperforms prompt-tuning in neural decoding, implicating that a more brain-consistent tuning method yields representations that better correlate with brain data. Moreover, we identify that tasks dealing with fine-grained concept meaning yield representations that better decode brain activation patterns than other tasks, especially the syntactic chunking task. This indicates that our brain encodes more fine-grained concept information than shallow syntactic information when representing languages.", "url": "https://arxiv.org/abs/2310.01854"}, {"metadata": {"arXiv": "2310.02005", "Date": "Tue, 03 Oct 2023 12:21:41 ", "Title": "Generalized Convergence Analysis of Tsetlin Machines: A Probabilistic Approach to Concept Learning", "Authors": ["Mohamed-Bachir Belaid", "Jivitesh Sharma", "Lei Jiao", "Ole-Christoffer Granmo", "Per-Arne Andersen", "Anis Yazidi"], "Categories": "cs.AI"}, "abstract": "Tsetlin Machines (TMs) have garnered increasing interest for their ability to learn concepts via propositional formulas and their proven efficiency across various application domains. Despite this, the convergence proof for the TMs, particularly for the AND operator (\\emph{conjunction} of literals), in the generalized case (inputs greater than two bits) remains an open problem. This paper aims to fill this gap by presenting a comprehensive convergence analysis of Tsetlin automaton-based Machine Learning algorithms. We introduce a novel framework, referred to as Probabilistic Concept Learning (PCL), which simplifies the TM structure while incorporating dedicated feedback mechanisms and dedicated inclusion/exclusion probabilities for literals. Given $n$ features, PCL aims to learn a set of conjunction clauses $C_i$ each associated with a distinct inclusion probability $p_i$. Most importantly, we establish a theoretical proof confirming that, for any clause $C_k$, PCL converges to a conjunction of literals when $0.5<p_k<1$. This result serves as a stepping stone for future research on the convergence properties of Tsetlin automaton-based learning algorithms. Our findings not only contribute to the theoretical understanding of Tsetlin Machines but also have implications for their practical application, potentially leading to more robust and interpretable machine learning models.", "url": "https://arxiv.org/abs/2310.02005"}, {"metadata": {"arXiv": "2310.02019", "Date": "Tue, 03 Oct 2023 12:48:57 ", "Title": "Towards Feasible Counterfactual Explanations: A Taxonomy Guided Template-based NLG Method", "Authors": ["Pedram Salimi", "Nirmalie Wiratunga", "David Corsar", "Anjana Wijekoon"], "Categories": "cs.AI", "Journal-ref": "Volume 372: ECAI 2023", "DOI": "10.3233/FAIA230499"}, "abstract": "Counterfactual Explanations (cf-XAI) describe the smallest changes in feature values necessary to change an outcome from one class to another. However, many cf-XAI methods neglect the feasibility of those changes. In this paper, we introduce a novel approach for presenting cf-XAI in natural language (Natural-XAI), giving careful consideration to actionable and comprehensible aspects while remaining cognizant of immutability and ethical concerns. We present three contributions to this endeavor. Firstly, through a user study, we identify two types of themes present in cf-XAI composed by humans: content-related, focusing on how features and their values are included from both the counterfactual and the query perspectives; and structure-related, focusing on the structure and terminology used for describing necessary value changes. Secondly, we introduce a feature actionability taxonomy with four clearly defined categories, to streamline the explanation presentation process. Using insights from the user study and our taxonomy, we created a generalisable template-based natural language generation (NLG) method compatible with existing explainers like DICE, NICE, and DisCERN, to produce counterfactuals that address the aforementioned limitations of existing approaches. Finally, we conducted a second user study to assess the performance of our taxonomy-guided NLG templates on three domains. Our findings show that the taxonomy-guided Natural-XAI approach (n-XAI^T) received higher user ratings across all dimensions, with significantly improved results in the majority of the domains assessed for articulation, acceptability, feasibility, and sensitivity dimensions.", "url": "https://arxiv.org/abs/2310.02019"}, {"metadata": {"arXiv": "2310.02054", "Date": "Tue, 03 Oct 2023 13:53:08 ", "Title": "AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model", "Authors": ["Zibin Dong", "Yifu Yuan", "Jianye Hao", "Fei Ni", "Yao Mu", "Yan Zheng", "Yujing Hu", "Tangjie Lv", "Changjie Fan and Zhipeng Hu"], "Categories": "cs.AI"}, "abstract": "Aligning agent behaviors with diverse human preferences remains a challenging problem in reinforcement learning (RL), owing to the inherent abstractness and mutability of human preferences. To address these issues, we propose AlignDiff, a novel framework that leverages RL from Human Feedback (RLHF) to quantify human preferences, covering abstractness, and utilizes them to guide diffusion planning for zero-shot behavior customizing, covering mutability. AlignDiff can accurately match user-customized behaviors and efficiently switch from one to another. To build the framework, we first establish the multi-perspective human feedback datasets, which contain comparisons for the attributes of diverse behaviors, and then train an attribute strength model to predict quantified relative strengths. After relabeling behavioral datasets with relative strengths, we proceed to train an attribute-conditioned diffusion model, which serves as a planner with the attribute strength model as a director for preference aligning at the inference phase. We evaluate AlignDiff on various locomotion tasks and demonstrate its superior performance on preference matching, switching, and covering compared to other baselines. Its capability of completing unseen downstream tasks under human instructions also showcases the promising potential for human-AI collaboration. More visualization videos are released on https://aligndiff.github.io/.", "url": "https://arxiv.org/abs/2310.02054"}, {"metadata": {"arXiv": "2310.02071", "Date": "Tue, 03 Oct 2023 14:13:36 ", "Title": "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond", "Authors": ["Liang Chen", "Yichi Zhang", "Shuhuai Ren", "Haozhe Zhao", "Zefan Cai", "Yuchi Wang", "Tianyu Liu", "Baobao Chang"], "Categories": "cs.AI cs.CL cs.CV cs.RO", "Comments": ["18 pages", "10 figures"]}, "abstract": "In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents. While Large Language Models (LLMs) have been widely used due to their advanced reasoning skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual understanding and reasoning capabilities. We investigate whether state-of-the-art MLLMs can handle embodied decision-making in an end-to-end manner and whether collaborations between LLMs and MLLMs can enhance decision-making. To address these questions, we introduce a new benchmark called PCA-EVAL, which evaluates embodied decision-making from the perspectives of Perception, Cognition, and Action. Additionally, we propose HOLMES, a multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs to gather multimodal information for informed decision-making. We compare end-to-end embodied decision-making and HOLMES on our benchmark and find that the GPT4-Vision model demonstrates strong end-to-end embodied decision-making abilities, outperforming GPT4-HOLMES in terms of average decision accuracy (+3%). However, this performance is exclusive to the latest GPT4-Vision model, surpassing the open-source state-of-the-art MLLM by 26%. Our results indicate that powerful MLLMs like GPT4-Vision hold promise for decision-making in embodied agents, offering new avenues for MLLM research.", "url": "https://arxiv.org/abs/2310.02071"}, {"metadata": {"arXiv": "2310.02108", "Date": "Tue, 03 Oct 2023 14:51:53 ", "Title": "Towards Effective Human-AI Decision-Making: The Role of Human Learning in Appropriate Reliance on AI Advice", "Authors": ["Max Schemmer", "Andrea Bartos", "Philipp Spitzer", "Patrick Hemmer", "Niklas K\\\"uhl", "Jonas Liebschner", "Gerhard Satzger"], "Categories": "cs.AI cs.HC", "Journal-ref": "International Conference on Information Systems (ICIS 2023)"}, "abstract": "The true potential of human-AI collaboration lies in exploiting the complementary capabilities of humans and AI to achieve a joint performance superior to that of the individual AI or human, i.e., to achieve complementary team performance (CTP). To realize this complementarity potential, humans need to exercise discretion in following AI 's advice, i.e., appropriately relying on the AI's advice. While previous work has focused on building a mental model of the AI to assess AI recommendations, recent research has shown that the mental model alone cannot explain appropriate reliance. We hypothesize that, in addition to the mental model, human learning is a key mediator of appropriate reliance and, thus, CTP. In this study, we demonstrate the relationship between learning and appropriate reliance in an experiment with 100 participants. This work provides fundamental concepts for analyzing reliance and derives implications for the effective design of human-AI decision-making.", "url": "https://arxiv.org/abs/2310.02108"}, {"metadata": {"arXiv": "2310.02167", "Date": "Tue, 03 Oct 2023 16:01:06 ", "Title": "Towards a Unified Framework for Sequential Decision Making", "Authors": ["Carlos N\\'u\\~nez-Molina", "Pablo Mesejo", "Juan Fern\\'andez-Olivares"], "Categories": "cs.AI", "Comments": ["10 pages", "0 figures"], "MSC-class": "I.2.8"}, "abstract": "In recent years, the integration of Automated Planning (AP) and Reinforcement Learning (RL) has seen a surge of interest. To perform this integration, a general framework for Sequential Decision Making (SDM) would prove immensely useful, as it would help us understand how AP and RL fit together. In this preliminary work, we attempt to provide such a framework, suitable for any method ranging from Classical Planning to Deep RL, by drawing on concepts from Probability Theory and Bayesian inference. We formulate an SDM task as a set of training and test Markov Decision Processes (MDPs), to account for generalization. We provide a general algorithm for SDM which we hypothesize every SDM method is based on. According to it, every SDM algorithm can be seen as a procedure that iteratively improves its solution estimate by leveraging the task knowledge available. Finally, we derive a set of formulas and algorithms for calculating interesting properties of SDM tasks and methods, which make possible their empirical evaluation and comparison.", "url": "https://arxiv.org/abs/2310.02167"}, {"metadata": {"arXiv": "2310.01659", "Date": "Mon, 02 Oct 2023 21:48:19 ", "Title": "It's all about you: Personalized in-Vehicle Gesture Recognition with a Time-of-Flight Camera", "Authors": ["Amr Gomaa", "Guillermo Reyes", "Michael Feld"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["Accepted at AutoUI2023"], "DOI": "10.1145/3580585.3607153"}, "abstract": "Despite significant advances in gesture recognition technology, recognizing gestures in a driving environment remains challenging due to limited and costly data and its dynamic, ever-changing nature. In this work, we propose a model-adaptation approach to personalize the training of a CNNLSTM model and improve recognition accuracy while reducing data requirements. Our approach contributes to the field of dynamic hand gesture recognition while driving by providing a more efficient and accurate method that can be customized for individual users, ultimately enhancing the safety and convenience of in-vehicle interactions, as well as driver's experience and system trust. We incorporate hardware enhancement using a time-of-flight camera and algorithmic enhancement through data augmentation, personalized adaptation, and incremental learning techniques. We evaluate the performance of our approach in terms of recognition accuracy, achieving up to 90\\%, and show the effectiveness of personalized adaptation and incremental learning for a user-centered design.", "url": "https://arxiv.org/abs/2310.01659"}, {"metadata": {"arXiv": "2310.01680", "Date": "Mon, 02 Oct 2023 22:31:30 ", "Title": "Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation", "Authors": ["Zhangsihao Yang", "Mengwei Ren", "Kaize Ding", "Guido Gerig", "Yalin Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Camera ready for NeurIPS 2023. Code available at https://github.com/zshyang/kaf.git"]}, "abstract": "Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global representations from both the bottleneck of the UNet, and by aggregating multiscale keypoint features. These global features are subsequently regularized through image-level contrastive objectives. At the local scale, we define a distance-based criterion to first establish correspondences among keypoints and encourage similarity between their features. Through extensive experiments on both MRI and CT segmentation tasks, we demonstrate the architectural advantages of our proposed method in comparison to both CNN and Transformer-based UNets, when all architectures are trained with randomly initialized weights. With our proposed pretraining strategy, our method further outperforms existing SSL methods by producing more robust self-attention and achieving state-of-the-art segmentation results. The code is available at https://github.com/zshyang/kaf.git.", "url": "https://arxiv.org/abs/2310.01680"}, {"metadata": {"arXiv": "2310.01701", "Date": "Mon, 02 Oct 2023 23:38:17 ", "Title": "Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation", "Authors": ["Shivang Chopra", "Suraj Kothawade", "Houda Aynaou", "Aman Chadha"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "6 figures", "4 tables"]}, "abstract": "Domain Adaptation (DA) is a method for enhancing a model's performance on a target domain with inadequate annotated data by applying the information the model has acquired from a related source domain with sufficient labeled data. The escalating enforcement of data-privacy regulations like HIPAA, COPPA, FERPA, etc. have sparked a heightened interest in adapting models to novel domains while circumventing the need for direct access to the source data, a problem known as Source-Free Domain Adaptation (SFDA). In this paper, we propose a novel framework for SFDA that generates source data using a text-to-image diffusion model trained on the target domain samples. Our method starts by training a text-to-image diffusion model on the labeled target domain samples, which is then fine-tuned using the pre-trained source model to generate samples close to the source data. Finally, we use Domain Adaptation techniques to align the artificially generated source data with the target domain data, resulting in significant performance improvements of the model on the target domain. Through extensive comparison against several baselines on the standard Office-31, Office-Home, and VisDA benchmarks, we demonstrate the effectiveness of our approach for the SFDA task.", "url": "https://arxiv.org/abs/2310.01701"}, {"metadata": {"arXiv": "2310.01735", "Date": "Tue, 03 Oct 2023 01:50:48 ", "Title": "Learning Expected Appearances for Intraoperative Registration during Neurosurgery", "Authors": ["Nazim Haouchine", "Reuben Dorent", "Parikshit Juvekar", "Erickson Torio", "William M. Wells III", "Tina Kapur", "Alexandra J. Golby and Sarah Frisken"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at MICCAI 2023"]}, "abstract": "We present a novel method for intraoperative patient-to-image registration by learning Expected Appearances. Our method uses preoperative imaging to synthesize patient-specific expected views through a surgical microscope for a predicted range of transformations. Our method estimates the camera pose by minimizing the dissimilarity between the intraoperative 2D view through the optical microscope and the synthesized expected texture. In contrast to conventional methods, our approach transfers the processing tasks to the preoperative stage, reducing thereby the impact of low-resolution, distorted, and noisy intraoperative images, that often degrade the registration accuracy. We applied our method in the context of neuronavigation during brain surgery. We evaluated our approach on synthetic data and on retrospective data from 6 clinical cases. Our method outperformed state-of-the-art methods and achieved accuracies that met current clinical standards.", "url": "https://arxiv.org/abs/2310.01735"}, {"metadata": {"arXiv": "2310.01806", "Date": "Tue, 03 Oct 2023 05:39:36 ", "Title": "Improvement and Enhancement of YOLOv5 Small Target Recognition Based on Multi-module Optimization", "Authors": ["Qingyang Li and Yuchen Li and Hongyi Duan and JiaLiang Kang and Jianan Zhang and Xueqian Gan and Ruotong Xu"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages 10 figures"]}, "abstract": "In this paper, the limitations of YOLOv5s model on small target detection task are deeply studied and improved. The performance of the model is successfully enhanced by introducing GhostNet-based convolutional module, RepGFPN-based Neck module optimization, CA and Transformer's attention mechanism, and loss function improvement using NWD. The experimental results validate the positive impact of these improvement strategies on model precision, recall and mAP. In particular, the improved model shows significant superiority in dealing with complex backgrounds and tiny targets in real-world application tests. This study provides an effective optimization strategy for the YOLOv5s model on small target detection, and lays a solid foundation for future related research and applications.", "url": "https://arxiv.org/abs/2310.01806"}, {"metadata": {"arXiv": "2310.01852", "Date": "Tue, 03 Oct 2023 07:33:27 ", "Title": "LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment", "Authors": ["Bin Zhu", "Bin Lin", "Munan Ning", "Yang Yan", "Jiaxi Cui", "Wang HongFa", "Yatian Pang", "Wenhao Jiang", "Junwu Zhang", "Zongwei Li", "Cai Wan Zhang", "Zhifeng Li", "Wei Liu", "and Li Yuan"], "Categories": "cs.CV cs.AI", "Comments": ["Under review as a conference paper at ICLR 2024"]}, "abstract": "The video-language (VL) pretraining has achieved remarkable improvement in multiple downstream tasks. However, the current VL pretraining framework is hard to extend to multiple modalities (N modalities, N>=3) beyond vision and language. We thus propose LanguageBind, taking the language as the bind across different modalities because the language modality is well-explored and contains rich semantics. Specifically, we freeze the language encoder acquired by VL pretraining, then train encoders for other modalities with contrastive learning. As a result, all modalities are mapped to a shared feature space, implementing multi-modal semantic alignment. While LanguageBind ensures that we can extend VL modalities to N modalities, we also need a high-quality dataset with alignment data pairs centered on language. We thus propose VIDAL-10M with Video, Infrared, Depth, Audio and their corresponding Language, naming as VIDAL-10M. In our VIDAL-10M, all videos are from short video platforms with complete semantics rather than truncated segments from long videos, and all the video, depth, infrared, and audio modalities are aligned to their textual descriptions. After pretraining on VIDAL-10M, we outperform ImageBind by 1.2% R@1 on the MSR-VTT dataset with only 15% of the parameters in the zero-shot video-text retrieval, validating the high quality of our dataset. Beyond this, our LanguageBind has achieved great improvement in the zero-shot video, audio, depth, and infrared understanding tasks. For instance, on the LLVIP and NYU-D datasets, LanguageBind outperforms ImageBind-huge with 23.8% and 11.1% top-1 accuracy.", "url": "https://arxiv.org/abs/2310.01852"}, {"metadata": {"arXiv": "2310.01926", "Date": "Tue, 03 Oct 2023 10:10:42 ", "Title": "DARTH: Holistic Test-time Adaptation for Multiple Object Tracking", "Authors": ["Mattia Segu", "Bernt Schiele", "Fisher Yu"], "Categories": "cs.CV cs.AI", "Comments": ["Proceedings of the IEEE/CVF International Conference on Computer Vision"]}, "abstract": "Multiple object tracking (MOT) is a fundamental component of perception systems for autonomous driving, and its robustness to unseen conditions is a requirement to avoid life-critical failures. Despite the urge of safety in driving systems, no solution to the MOT adaptation problem to domain shift in test-time conditions has ever been proposed. However, the nature of a MOT system is manifold - requiring object detection and instance association - and adapting all its components is non-trivial. In this paper, we analyze the effect of domain shift on appearance-based trackers, and introduce DARTH, a holistic test-time adaptation framework for MOT. We propose a detection consistency formulation to adapt object detection in a self-supervised fashion, while adapting the instance appearance representations via our novel patch contrastive loss. We evaluate our method on a variety of domain shifts - including sim-to-real, outdoor-to-indoor, indoor-to-outdoor - and substantially improve the source model performance on all metrics. Code: https://github.com/mattiasegu/darth.", "url": "https://arxiv.org/abs/2310.01926"}, {"metadata": {"arXiv": "2310.02037", "Date": "Tue, 03 Oct 2023 13:28:14 ", "Title": "An evaluation of pre-trained models for feature extraction in image classification", "Authors": ["Erick da Silva Puls", "Matheus V. Todescato", "Joel L. Carbonera"], "Categories": "cs.CV cs.AI"}, "abstract": "In recent years, we have witnessed a considerable increase in performance in image classification tasks. This performance improvement is mainly due to the adoption of deep learning techniques. Generally, deep learning techniques demand a large set of annotated data, making it a challenge when applying it to small datasets. In this scenario, transfer learning strategies have become a promising alternative to overcome these issues. This work aims to compare the performance of different pre-trained neural networks for feature extraction in image classification tasks. We evaluated 16 different pre-trained models in four image datasets. Our results demonstrate that the best general performance along the datasets was achieved by CLIP-ViT-B and ViT-H-14, where the CLIP-ResNet50 model had similar performance but with less variability. Therefore, our study provides evidence supporting the choice of models for feature extraction in image classification tasks.", "url": "https://arxiv.org/abs/2310.02037"}, {"metadata": {"arXiv": "2310.02067", "Date": "Tue, 03 Oct 2023 14:09:27 ", "Title": "Content Bias in Deep Learning Age Approximation: A new Approach Towards more Explainability", "Authors": ["Robert J\\\"ochl and Andreas Uhl"], "Categories": "cs.CV cs.AI", "Comments": ["This is a preprint", "the paper is currently under consideration at Pattern Recognition Letters"]}, "abstract": "In the context of temporal image forensics, it is not evident that a neural network, trained on images from different time-slots (classes), exploit solely age related features. Usually, images taken in close temporal proximity (e.g., belonging to the same age class) share some common content properties. Such content bias can be exploited by a neural network. In this work, a novel approach that evaluates the influence of image content is proposed. This approach is verified using synthetic images (where content bias can be ruled out) with an age signal embedded. Based on the proposed approach, it is shown that a `standard' neural network trained in the context of age classification is strongly dependent on image content. As a potential countermeasure, two different techniques are applied to mitigate the influence of the image content during training, and they are also evaluated by the proposed method.", "url": "https://arxiv.org/abs/2310.02067"}, {"metadata": {"arXiv": "2310.02083", "Date": "Tue, 03 Oct 2023 14:26:56 ", "Title": "Point Neighborhood Embeddings", "Authors": ["Pedro Hermosilla"], "Categories": "cs.CV cs.AI"}, "abstract": "Point convolution operations rely on different embedding mechanisms to encode the neighborhood information of each point in order to detect patterns in 3D space. However, as convolutions are usually evaluated as a whole, not much work has been done to investigate which is the ideal mechanism to encode such neighborhood information. In this paper, we provide the first extensive study that analyzes such Point Neighborhood Embeddings (PNE) alone in a controlled experimental setup. From our experiments, we derive a set of recommendations for PNE that can help to improve future designs of neural network architectures for point clouds. Our most surprising finding shows that the most commonly used embedding based on a Multi-layer Perceptron (MLP) with ReLU activation functions provides the lowest performance among all embeddings, even being surpassed on some tasks by a simple linear combination of the point coordinates. Additionally, we show that a neural network architecture using simple convolutions based on such embeddings is able to achieve state-of-the-art results on several tasks, outperforming recent and more complex operations. Lastly, we show that these findings extrapolate to other more complex convolution operations, where we show how following our recommendations we are able to improve recent state-of-the-art architectures.", "url": "https://arxiv.org/abs/2310.02083"}, {"metadata": {"arXiv": "2310.02230", "Date": "Tue, 03 Oct 2023 17:37:52 ", "Title": "Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks", "Authors": ["Luca Scimeca", "Alexander Rubinstein", "Armand Nicolicioiu", "Damien Teney and Yoshua Bengio"], "Categories": "cs.CV cs.AI"}, "abstract": "Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.", "url": "https://arxiv.org/abs/2310.02230"}, {"metadata": {"arXiv": "2310.02239", "Date": "Tue, 03 Oct 2023 17:49:04 ", "Title": "MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens", "Authors": ["Kaizhi Zheng", "Xuehai He", "Xin Eric Wang"], "Categories": "cs.CV cs.AI", "Comments": ["20 pages", "9 figures"]}, "abstract": "Large Language Models (LLMs) have garnered significant attention for their advancements in natural language processing, demonstrating unparalleled prowess in text comprehension and generation. Yet, the simultaneous generation of images with coherent textual narratives remains an evolving frontier. In response, we introduce an innovative interleaved vision-and-language generation technique anchored by the concept of \"generative vokens,\" acting as the bridge for harmonized image-text outputs. Our approach is characterized by a distinctive two-staged training strategy focusing on description-free multimodal generation, where the training requires no comprehensive descriptions of images. To bolster model integrity, classifier-free guidance is incorporated, enhancing the effectiveness of vokens on image generation. Our model, MiniGPT-5, exhibits substantial improvement over the baseline Divter model on the MMDialog dataset and consistently delivers superior or comparable multimodal outputs in human evaluations on the VIST dataset, highlighting its efficacy across diverse benchmarks.", "url": "https://arxiv.org/abs/2310.02239"}, {"metadata": {"arXiv": "2310.02260", "Date": "Tue, 03 Oct 2023 17:59:05 ", "Title": "TransRadar: Adaptive-Directional Transformer for Real-Time Multi-View Radar Semantic Segmentation", "Authors": ["Yahia Dalbah", "Jean Lahoud", "Hisham Cholakkal"], "Categories": "cs.CV cs.AI"}, "abstract": "Scene understanding plays an essential role in enabling autonomous driving and maintaining high standards of performance and safety. To address this task, cameras and laser scanners (LiDARs) have been the most commonly used sensors, with radars being less popular. Despite that, radars remain low-cost, information-dense, and fast-sensing techniques that are resistant to adverse weather conditions. While multiple works have been previously presented for radar-based scene semantic segmentation, the nature of the radar data still poses a challenge due to the inherent noise and sparsity, as well as the disproportionate foreground and background. In this work, we propose a novel approach to the semantic segmentation of radar scenes using a multi-input fusion of radar data through a novel architecture and loss functions that are tailored to tackle the drawbacks of radar perception. Our novel architecture includes an efficient attention block that adaptively captures important feature information. Our method, TransRadar, outperforms state-of-the-art methods on the CARRADA and RADIal datasets while having smaller model sizes. https://github.com/YahiDar/TransRadar", "url": "https://arxiv.org/abs/2310.02260"}, {"metadata": {"arXiv": "2310.01439", "Date": "Sat, 30 Sep 2023 16:40:50 ", "Title": "Making Friends in the Dark: Ad Hoc Teamwork Under Partial Observability", "Authors": ["Jo\\~ao G. Ribeiroa", "Cassandro Martinhoa", "Alberto Sardinhaa", "and Francisco S. Melo"], "Categories": "cs.MA cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2201.03538"]}, "abstract": "This paper introduces a formal definition of the setting of ad hoc teamwork under partial observability and proposes a first-principled model-based approach which relies only on prior knowledge and partial observations of the environment in order to perform ad hoc teamwork. We make three distinct assumptions that set it apart previous works, namely: i) the state of the environment is always partially observable, ii) the actions of the teammates are always unavailable to the ad hoc agent and iii) the ad hoc agent has no access to a reward signal which could be used to learn the task from scratch. Our results in 70 POMDPs from 11 domains show that our approach is not only effective in assisting unknown teammates in solving unknown tasks but is also robust in scaling to more challenging problems.", "url": "https://arxiv.org/abs/2310.01439"}, {"metadata": {"arXiv": "2310.01595", "Date": "Mon, 02 Oct 2023 19:41:19 ", "Title": "Memory-efficient particle filter recurrent neural network for object localization", "Authors": ["Roman Korkin", "Ivan Oseledets", "Aleksandr Katrutsa"], "Categories": "cs.RO cs.AI"}, "abstract": "This study proposes a novel memory-efficient recurrent neural network (RNN) architecture specified to solve the object localization problem. This problem is to recover the object states along with its movement in a noisy environment. We take the idea of the classical particle filter and combine it with GRU RNN architecture. The key feature of the resulting memory-efficient particle filter RNN model (mePFRNN) is that it requires the same number of parameters to process environments of different sizes. Thus, the proposed mePFRNN architecture consumes less memory to store parameters compared to the previously proposed PFRNN model. To demonstrate the performance of our model, we test it on symmetric and noisy environments that are incredibly challenging for filtering algorithms. In our experiments, the mePFRNN model provides more precise localization than the considered competitors and requires fewer trained parameters.", "url": "https://arxiv.org/abs/2310.01595"}, {"metadata": {"arXiv": "2310.01767", "Date": "Tue, 03 Oct 2023 03:23:10 ", "Title": "Differentially Encoded Observation Spaces for Perceptive Reinforcement Learning", "Authors": ["Lev Grossman and Brian Plancher"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "4 figures", "2 tables"]}, "abstract": "Perceptive deep reinforcement learning (DRL) has lead to many recent breakthroughs for complex AI systems leveraging image-based input data. Applications of these results range from super-human level video game agents to dexterous, physically intelligent robots. However, training these perceptive DRL-enabled systems remains incredibly compute and memory intensive, often requiring huge training datasets and large experience replay buffers. This poses a challenge for the next generation of field robots that will need to be able to learn on the edge in order to adapt to their environments. In this paper, we begin to address this issue through differentially encoded observation spaces. By reinterpreting stored image-based observations as a video, we leverage lossless differential video encoding schemes to compress the replay buffer without impacting training performance. We evaluate our approach with three state-of-the-art DRL algorithms and find that differential image encoding reduces the memory footprint by as much as 14.2x and 16.7x across tasks from the Atari 2600 benchmark and the DeepMind Control Suite (DMC) respectively. These savings also enable large-scale perceptive DRL that previously required paging between flash and RAM to be run entirely in RAM, improving the latency of DMC tasks by as much as 32%.", "url": "https://arxiv.org/abs/2310.01767"}, {"metadata": {"arXiv": "2310.01775", "Date": "Tue, 03 Oct 2023 03:53:51 ", "Title": "STAMP: Differentiable Task and Motion Planning via Stein Variational Gradient Descent", "Authors": ["Yewon Lee (1)", "Philip Huang (2)", "Krishna Murthy Jatavallabhula (3)", "Andrew Z. Li (1)", "Fabian Damken (1 and 4)", "Eric Heiden (5)", "Kevin Smith (3)", "Derek Nowrouzezahrai (6)", "Fabio Ramos (5 and 7)", "Florian Shkurti (1) ((1) University of Toronto", "(2) Carnegie Mellon University", "(3) Massachusetts Institute of Technology", "(4) Technische Universitat Darmstadt", "(5) NVIDIA", "(6) McGill University", "(7) University of Sydney)"], "Categories": "cs.RO cs.AI", "Comments": ["12 pages", "9 figures", "submitted to the Learning Effective Abstractions for Planning (LEAP) Workshop at CoRL 2023"], "ACM-class": "I.2.9"}, "abstract": "Planning for many manipulation tasks, such as using tools or assembling parts, often requires both symbolic and geometric reasoning. Task and Motion Planning (TAMP) algorithms typically solve these problems by conducting a tree search over high-level task sequences while checking for kinematic and dynamic feasibility. While performant, most existing algorithms are highly inefficient as their time complexity grows exponentially with the number of possible actions and objects. Additionally, they only find a single solution to problems in which many feasible plans may exist. To address these limitations, we propose a novel algorithm called Stein Task and Motion Planning (STAMP) that leverages parallelization and differentiable simulation to efficiently search for multiple diverse plans. STAMP relaxes discrete-and-continuous TAMP problems into continuous optimization problems that can be solved using variational inference. Our algorithm builds upon Stein Variational Gradient Descent, a gradient-based variational inference algorithm, and parallelized differentiable physics simulators on the GPU to efficiently obtain gradients for inference. Further, we employ imitation learning to introduce action abstractions that reduce the inference problem to lower dimensions. We demonstrate our method on two TAMP problems and empirically show that STAMP is able to: 1) produce multiple diverse plans in parallel; and 2) search for plans more efficiently compared to existing TAMP baselines.", "url": "https://arxiv.org/abs/2310.01775"}, {"metadata": {"arXiv": "2310.01827", "Date": "Tue, 03 Oct 2023 06:49:57 ", "Title": "Learning and reusing primitive behaviours to improve Hindsight Experience Replay sample efficiency", "Authors": ["Francisco Roldan Sanchez", "Qiang Wang", "David Cordova Bulens", "Kevin McGuinness", "Stephen Redmond", "Noel O'Connor"], "Categories": "cs.RO cs.AI", "Comments": ["5 pages", "2 figures", "1 algorithm. Submitted to ICARA 2024"]}, "abstract": "Hindsight Experience Replay (HER) is a technique used in reinforcement learning (RL) that has proven to be very efficient for training off-policy RL-based agents to solve goal-based robotic manipulation tasks using sparse rewards. Even though HER improves the sample efficiency of RL-based agents by learning from mistakes made in past experiences, it does not provide any guidance while exploring the environment. This leads to very large training times due to the volume of experience required to train an agent using this replay strategy. In this paper, we propose a method that uses primitive behaviours that have been previously learned to solve simple tasks in order to guide the agent toward more rewarding actions during exploration while learning other more complex tasks. This guidance, however, is not executed by a manually designed curriculum, but rather using a critic network to decide at each timestep whether or not to use the actions proposed by the previously-learned primitive policies. We evaluate our method by comparing its performance against HER and other more efficient variations of this algorithm in several block manipulation tasks. We demonstrate the agents can learn a successful policy faster when using our proposed method, both in terms of sample efficiency and computation time. Code is available at https://github.com/franroldans/qmp-her.", "url": "https://arxiv.org/abs/2310.01827"}, {"metadata": {"arXiv": "2310.01943", "Date": "Tue, 03 Oct 2023 10:38:53 ", "Title": "Ravestate: Distributed Composition of a Causal-Specificity-Guided Interaction Policy", "Authors": ["Joseph Birkner", "Andreas Dolp", "Negin Karimi", "Nikita Basargin", "Alona Kharchenko and Rafael Hostettler"], "Categories": "cs.RO cs.AI cs.HC"}, "abstract": "In human-robot interaction policy design, a rule-based method is efficient, explainable, expressive and intuitive. In this paper, we present the Signal-Rule-Slot framework, which refines prior work on rule-based symbol system design and introduces a new, Bayesian notion of interaction rule utility called Causal Pathway Self-information. We offer a rigorous theoretical foundation as well as a rich open-source reference implementation Ravestate, with which we conduct user studies in text-, speech-, and vision-based scenarios. The experiments show robust contextual behaviour of our probabilistically informed rule-based system, paving the way for more effective human-machine interaction.", "url": "https://arxiv.org/abs/2310.01943"}, {"metadata": {"arXiv": "2310.01957", "Date": "Tue, 03 Oct 2023 11:05:14 ", "Title": "Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving", "Authors": ["Long Chen", "Oleg Sinavski", "Jan H\\\"unermann", "Alice Karnsund", "Andrew James Willmott", "Danny Birch", "Daniel Maund", "Jamie Shotton"], "Categories": "cs.RO cs.AI cs.CL cs.CV"}, "abstract": "Large Language Models (LLMs) have shown promise in the autonomous driving sector, particularly in generalization and interpretability. We introduce a unique object-level multimodal LLM architecture that merges vectorized numeric modalities with a pre-trained LLM to improve context understanding in driving situations. We also present a new dataset of 160k QA pairs derived from 10k driving scenarios, paired with high quality control commands collected with RL agent and question answer pairs generated by teacher LLM (GPT-3.5). A distinct pretraining strategy is devised to align numeric vector modalities with static LLM representations using vector captioning language data. We also introduce an evaluation metric for Driving QA and demonstrate our LLM-driver's proficiency in interpreting driving scenarios, answering questions, and decision-making. Our findings highlight the potential of LLM-based driving action generation in comparison to traditional behavioral cloning. We make our benchmark, datasets, and model available for further exploration.", "url": "https://arxiv.org/abs/2310.01957"}, {"metadata": {"arXiv": "2310.01569", "Date": "Mon, 02 Oct 2023 19:03:30 ", "Title": "Iterative Option Discovery for Planning, by Planning", "Authors": ["Kenny Young", "Richard S. Sutton"], "Categories": "cs.AI cs.LG"}, "abstract": "Discovering useful temporal abstractions, in the form of options, is widely thought to be key to applying reinforcement learning and planning to increasingly complex domains. Building on the empirical success of the Expert Iteration approach to policy learning used in AlphaZero, we propose Option Iteration, an analogous approach to option discovery. Rather than learning a single strong policy that is trained to match the search results everywhere, Option Iteration learns a set of option policies trained such that for each state encountered, at least one policy in the set matches the search results for some horizon into the future. Intuitively, this may be significantly easier as it allows the algorithm to hedge its bets compared to learning a single globally strong policy, which may have complex dependencies on the details of the current state. Having learned such a set of locally strong policies, we can use them to guide the search algorithm resulting in a virtuous cycle where better options lead to better search results which allows for training of better options. We demonstrate experimentally that planning using options learned with Option Iteration leads to a significant benefit in challenging planning environments compared to an analogous planning algorithm operating in the space of primitive actions and learning a single rollout policy with Expert Iteration.", "url": "https://arxiv.org/abs/2310.01569"}, {"metadata": {"arXiv": "2310.01684", "Date": "Mon, 02 Oct 2023 22:42:52 ", "Title": "Designing User-Centric Behavioral Interventions to Prevent Dysglycemia with Novel Counterfactual Explanations", "Authors": ["Asiful Arefeen and Hassan Ghasemzadeh"], "Categories": "cs.AI cs.HC cs.LG"}, "abstract": "Maintaining normal blood glucose levels through lifestyle behaviors is central to maintaining health and preventing disease. Frequent exposure to dysglycemia (i.e., abnormal glucose events such as hyperlycemia and hypoglycemia) leads to chronic complications including diabetes, kidney disease and need for dialysis, myocardial infarction, stroke, amputation, and death. Therefore, a tool capable of predicting dysglycemia and offering users actionable feedback about how to make changes in their diet, exercise, and medication to prevent abnormal glycemic events could have significant societal impacts. Counterfactual explanations can provide insights into why a model made a particular prediction by generating hypothetical instances that are similar to the original input but lead to a different prediction outcome. Therefore, counterfactuals can be viewed as a means to design AI-driven health interventions to prevent adverse health outcomes such as dysglycemia. In this paper, we design GlyCoach, a framework for generating counterfactual explanations for glucose control. Leveraging insights from adversarial learning, GlyCoach characterizes the decision boundary for high-dimensional health data and performs a grid search to generate actionable interventions. GlyCoach is unique in integrating prior knowledge about user preferences of plausible explanations into the process of counterfactual generation. We evaluate GlyCoach extensively using two real-world datasets and external simulators from prior studies that predict glucose response. GlyCoach achieves 87\\% sensitivity in the simulation-aided validation, surpassing the state-of-the-art techniques for generating counterfactual explanations by at least $10\\%$. Besides, counterfactuals from GlyCoach exhibit a $32\\%$ improved normalized distance compared to previous research.", "url": "https://arxiv.org/abs/2310.01684"}, {"metadata": {"arXiv": "2310.01807", "Date": "Tue, 03 Oct 2023 05:40:56 ", "Title": "Discrete, compositional, and symbolic representations through attractor dynamics", "Authors": ["Andrew Nam", "Eric Elmoznino", "Nikolay Malkin", "Chen Sun", "Yoshua Bengio", "Guillaume Lajoie"], "Categories": "cs.AI cs.LG"}, "abstract": "Compositionality is an important feature of discrete symbolic systems, such as language and programs, as it enables them to have infinite capacity despite a finite symbol set. It serves as a useful abstraction for reasoning in both cognitive science and in AI, yet the interface between continuous and symbolic processing is often imposed by fiat at the algorithmic level, such as by means of quantization or a softmax sampling step. In this work, we explore how discretization could be implemented in a more neurally plausible manner through the modeling of attractor dynamics that partition the continuous representation space into basins that correspond to sequences of symbols. Building on established work in attractor networks and introducing novel training methods, we show that imposing structure in the symbolic space can produce compositionality in the attractor-supported representation space of rich sensory inputs. Lastly, we argue that our model exhibits the process of an information bottleneck that is thought to play a role in conscious experience, decomposing the rich information of a sensory input into stable components encoding symbolic information.", "url": "https://arxiv.org/abs/2310.01807"}, {"metadata": {"arXiv": "2310.01824", "Date": "Tue, 03 Oct 2023 06:41:18 ", "Title": "Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI", "Authors": ["Emily Jin", "Jiaheng Hu", "Zhuoyi Huang", "Ruohan Zhang", "Jiajun Wu", "Li Fei-Fei", "Roberto Mart\\'in-Mart\\'in"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "We present Mini-BEHAVIOR, a novel benchmark for embodied AI that challenges agents to use reasoning and decision-making skills to solve complex activities that resemble everyday human challenges. The Mini-BEHAVIOR environment is a fast, realistic Gridworld environment that offers the benefits of rapid prototyping and ease of use while preserving a symbolic level of physical realism and complexity found in complex embodied AI benchmarks. We introduce key features such as procedural generation, to enable the creation of countless task variations and support open-ended learning. Mini-BEHAVIOR provides implementations of various household tasks from the original BEHAVIOR benchmark, along with starter code for data collection and reinforcement learning agent training. In essence, Mini-BEHAVIOR offers a fast, open-ended benchmark for evaluating decision-making and planning solutions in embodied AI. It serves as a user-friendly entry point for research and facilitates the evaluation and development of solutions, simplifying their assessment and development while advancing the field of embodied AI. Code is publicly available at https://github.com/StanfordVL/mini_behavior.", "url": "https://arxiv.org/abs/2310.01824"}, {"metadata": {"arXiv": "2310.02133", "Date": "Tue, 03 Oct 2023 15:14:28 ", "Title": "Learning Reliable Logical Rules with SATNet", "Authors": ["Zhaoyu Li", "Jinpei Guo", "Yuhe Jiang", "Xujie Si"], "Categories": "cs.AI cs.LG"}, "abstract": "Bridging logical reasoning and deep learning is crucial for advanced AI systems. In this work, we present a new framework that addresses this goal by generating interpretable and verifiable logical rules through differentiable learning, without relying on pre-specified logical structures. Our approach builds upon SATNet, a differentiable MaxSAT solver that learns the underlying rules from input-output examples. Despite its efficacy, the learned weights in SATNet are not straightforwardly interpretable, failing to produce human-readable rules. To address this, we propose a novel specification method called \"maximum equality\", which enables the interchangeability between the learned weights of SATNet and a set of propositional logical rules in weighted MaxSAT form. With the decoded weighted MaxSAT formula, we further introduce several effective verification techniques to validate it against the ground truth rules. Experiments on stream transformations and Sudoku problems show that our decoded rules are highly reliable: using exact solvers on them could achieve 100% accuracy, whereas the original SATNet fails to give correct solutions in many cases. Furthermore, we formally verify that our decoded logical rules are functionally equivalent to the ground truth ones.", "url": "https://arxiv.org/abs/2310.02133"}, {"metadata": {"arXiv": "2310.01821", "Date": "Tue, 03 Oct 2023 06:33:05 ", "Title": "MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields", "Authors": ["Takuhiro Kaneko"], "Categories": "cs.CV cs.AI cs.GR cs.LG eess.IV", "Comments": ["Accepted to ICCV 2023. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/mimo-nerf/"]}, "abstract": "Neural radiance fields (NeRFs) have shown impressive results for novel view synthesis. However, they depend on the repetitive use of a single-input single-output multilayer perceptron (SISO MLP) that maps 3D coordinates and view direction to the color and volume density in a sample-wise manner, which slows the rendering. We propose a multi-input multi-output NeRF (MIMO-NeRF) that reduces the number of MLPs running by replacing the SISO MLP with a MIMO MLP and conducting mappings in a group-wise manner. One notable challenge with this approach is that the color and volume density of each point can differ according to a choice of input coordinates in a group, which can lead to some notable ambiguity. We also propose a self-supervised learning method that regularizes the MIMO MLP with multiple fast reformulated MLPs to alleviate this ambiguity without using pretrained models. The results of a comprehensive experimental evaluation including comparative and ablation studies are presented to show that MIMO-NeRF obtains a good trade-off between speed and quality with a reasonable training time. We then demonstrate that MIMO-NeRF is compatible with and complementary to previous advancements in NeRFs by applying it to two representative fast NeRFs, i.e., a NeRF with sample reduction (DONeRF) and a NeRF with alternative representations (TensoRF).", "url": "https://arxiv.org/abs/2310.01821"}, {"metadata": {"arXiv": "2310.01825", "Date": "Tue, 03 Oct 2023 06:42:28 ", "Title": "Empirical Study of PEFT techniques for Winter Wheat Segmentation", "Authors": ["Mohamad Hasan Zahweh", "Hasan Nasrallah", "Mustafa Shukor", "Ghaleb Faour and Ali J. Ghandour"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced significant growth and have been extensively employed to adapt large vision and language models to various domains, enabling satisfactory model performance with minimal computational needs. Despite these advances, more research has yet to delve into potential PEFT applications in real-life scenarios, particularly in the critical domains of remote sensing and crop monitoring. The diversity of climates across different regions and the need for comprehensive large-scale datasets have posed significant obstacles to accurately identify crop types across varying geographic locations and changing growing seasons. This study seeks to bridge this gap by comprehensively exploring the feasibility of cross-area and cross-year out-of-distribution generalization using the State-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to explore PEFT approaches for crop monitoring. Specifically, we focus on adapting the SOTA TSViT model to address winter wheat field segmentation, a critical task for crop monitoring and food security. This adaptation process involves integrating different PEFT techniques, including BigFit, LoRA, Adaptformer, and prompt tuning. Using PEFT techniques, we achieved notable results comparable to those achieved using full fine-tuning methods while training only a mere 0.7% parameters of the whole TSViT architecture. The in-house labeled data-set, referred to as the Beqaa-Lebanon dataset, comprises high-quality annotated polygons for wheat and non-wheat classes with a total surface of 170 kmsq, over five consecutive years. Using Sentinel-2 images, our model achieved a 84% F1-score. We intend to publicly release the Lebanese winter wheat data set, code repository, and model weights.", "url": "https://arxiv.org/abs/2310.01825"}, {"metadata": {"arXiv": "2310.01828", "Date": "Tue, 03 Oct 2023 06:51:48 ", "Title": "Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation", "Authors": ["Hossein Shreim", "Abdul Karim Gizzini and Ali J. Ghandour"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "eXplainable Artificial Intelligence (XAI) has emerged as an essential requirement when dealing with mission-critical applications, ensuring transparency and interpretability of the employed black box AI models. The significance of XAI spans various domains, from healthcare to finance, where understanding the decision-making process of deep learning algorithms is essential. Most AI-based computer vision models are often black boxes; hence, providing explainability of deep neural networks in image processing is crucial for their wide adoption and deployment in medical image analysis, autonomous driving, and remote sensing applications. Recently, several XAI methods for image classification tasks have been introduced. On the contrary, image segmentation has received comparatively less attention in the context of explainability, although it is a fundamental task in computer vision applications, especially in remote sensing. Only some research proposes gradient-based XAI algorithms for image segmentation. This paper adapts the recent gradient-free Sobol XAI method for semantic segmentation. To measure the performance of the Sobol method for segmentation, we propose a quantitative XAI evaluation method based on a learnable noise model. The main objective of this model is to induce noise on the explanation maps, where higher induced noise signifies low accuracy and vice versa. A benchmark analysis is conducted to evaluate and compare performance of three XAI methods, including Seg-Grad-CAM, Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation technique. This constitutes the first attempt to run and evaluate XAI methods using high-resolution satellite images.", "url": "https://arxiv.org/abs/2310.01828"}, {"metadata": {"arXiv": "2310.01837", "Date": "Tue, 03 Oct 2023 07:01:23 ", "Title": "Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation", "Authors": ["Abdul Karim Gizzini", "Mustafa Shukor and Ali J. Ghandour"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Current AI-based methods do not provide comprehensible physical interpretations of the utilized data, extracted features, and predictions/inference operations. As a result, deep learning models trained using high-resolution satellite imagery lack transparency and explainability and can be merely seen as a black box, which limits their wide-level adoption. Experts need help understanding the complex behavior of AI models and the underlying decision-making process. The explainable artificial intelligence (XAI) field is an emerging field providing means for robust, practical, and trustworthy deployment of AI models. Several XAI techniques have been proposed for image classification tasks, whereas the interpretation of image segmentation remains largely unexplored. This paper offers to bridge this gap by adapting the recent XAI classification algorithms and making them usable for muti-class image segmentation, where we mainly focus on buildings' segmentation from high-resolution satellite images. To benchmark and compare the performance of the proposed approaches, we introduce a new XAI evaluation methodology and metric based on \"Entropy\" to measure the model uncertainty. Conventional XAI evaluation methods rely mainly on feeding area-of-interest regions from the image back to the pre-trained (utility) model and then calculating the average change in the probability of the target class. Those evaluation metrics lack the needed robustness, and we show that using Entropy to monitor the model uncertainty in segmenting the pixels within the target class is more suitable. We hope this work will pave the way for additional XAI research for image segmentation and applications in the remote sensing discipline.", "url": "https://arxiv.org/abs/2310.01837"}, {"metadata": {"arXiv": "2310.01845", "Date": "Tue, 03 Oct 2023 07:19:59 ", "Title": "Zero-Shot Refinement of Buildings' Segmentation Models using SAM", "Authors": ["Ali Mayladan", "Hasan Nasrallah", "Hasan Moughnieh", "Mustafa Shukor and Ali J. Ghandour"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Foundation models have excelled in various tasks but are often evaluated on general benchmarks. The adaptation of these models for specific domains, such as remote sensing imagery, remains an underexplored area. In remote sensing, precise building instance segmentation is vital for applications like urban planning. While Convolutional Neural Networks (CNNs) perform well, their generalization can be limited. For this aim, we present a novel approach to adapt foundation models to address existing models' generalization dropback. Among several models, our focus centers on the Segment Anything Model (SAM), a potent foundation model renowned for its prowess in class-agnostic image segmentation capabilities. We start by identifying the limitations of SAM, revealing its suboptimal performance when applied to remote sensing imagery. Moreover, SAM does not offer recognition abilities and thus fails to classify and tag localized objects. To address these limitations, we introduce different prompting strategies, including integrating a pre-trained CNN as a prompt generator. This novel approach augments SAM with recognition abilities, a first of its kind. We evaluated our method on three remote sensing datasets, including the WHU Buildings dataset, the Massachusetts Buildings dataset, and the AICrowd Mapping Challenge. For out-of-distribution performance on the WHU dataset, we achieve a 5.47% increase in IoU and a 4.81% improvement in F1-score. For in-distribution performance on the WHU dataset, we observe a 2.72% and 1.58% increase in True-Positive-IoU and True-Positive-F1 score, respectively. We intend to release our code repository, hoping to inspire further exploration of foundation models for domain-specific tasks within the remote sensing community.", "url": "https://arxiv.org/abs/2310.01845"}, {"metadata": {"arXiv": "2310.02234", "Date": "Tue, 03 Oct 2023 17:43:24 ", "Title": "MIS-AVioDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection", "Authors": ["Vinaya Sree Katamneni and Ajita Rattani"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "3 figures"]}, "abstract": "Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by $17.8$% and $18.4$%, respectively. Thus, obtaining state-of-the-art performance.", "url": "https://arxiv.org/abs/2310.02234"}, {"metadata": {"arXiv": "2310.02237", "Date": "Tue, 03 Oct 2023 17:47:25 ", "Title": "Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness", "Authors": ["Yanzhao Wu", "Ka-Ho Chow", "Wenqi Wei", "Ling Liu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by IEEE ICDM 2023"]}, "abstract": "Deep neural network ensembles hold the potential of improving generalization performance for complex learning tasks. This paper presents formal analysis and empirical evaluation to show that heterogeneous deep ensembles with high ensemble diversity can effectively leverage model learning heterogeneity to boost ensemble robustness. We first show that heterogeneous DNN models trained for solving the same learning problem, e.g., object detection, can significantly strengthen the mean average precision (mAP) through our weighted bounding box ensemble consensus method. Second, we further compose ensembles of heterogeneous models for solving different learning problems, e.g., object detection and semantic segmentation, by introducing the connected component labeling (CCL) based alignment. We show that this two-tier heterogeneity driven ensemble construction method can compose an ensemble team that promotes high ensemble diversity and low negative correlation among member models of the ensemble, strengthening ensemble robustness against both negative examples and adversarial attacks. Third, we provide a formal analysis of the ensemble robustness in terms of negative correlation. Extensive experiments validate the enhanced robustness of heterogeneous ensembles in both benign and adversarial settings. The source codes are available on GitHub at https://github.com/git-disl/HeteRobust.", "url": "https://arxiv.org/abs/2310.02237"}, {"metadata": {"arXiv": "2310.02255", "Date": "Tue, 03 Oct 2023 17:57:24 ", "Title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "Authors": ["Pan Lu", "Hritik Bansal", "Tony Xia", "Jiacheng Liu", "Chunyuan Li", "Hannaneh Hajishirzi", "Hao Cheng", "Kai-Wei Chang", "Michel Galley", "Jianfeng Gao"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["51 pages", "56 figures. Work in progress"]}, "abstract": "Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive skills in various domains, their ability for mathematical reasoning within visual contexts has not been formally examined. Equipping LLMs and LMMs with this capability is vital for general-purpose AI assistants and showcases promising potential in education, data analysis, and scientific discovery. To bridge this gap, we present MathVista, a benchmark designed to amalgamate challenges from diverse mathematical and visual tasks. We first taxonomize the key task types, reasoning skills, and visual contexts from the literature to guide our selection from 28 existing math-focused and visual question answering datasets. Then, we construct three new datasets, IQTest, FunctionQA, and PaperQA, to accommodate for missing types of visual contexts. The problems featured often require deep visual understanding beyond OCR or image captioning, and compositional reasoning with rich domain-specific tools, thus posing a notable challenge to existing models. We conduct a comprehensive evaluation of 11 prominent open-source and proprietary foundation models (LLMs, LLMs augmented with tools, and LMMs), and early experiments with GPT-4V. The best-performing model, Multimodal Bard, achieves only 58% of human performance (34.8% vs 60.3%), indicating ample room for further improvement. Given this significant gap, MathVista fuels future research in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. Preliminary tests show that MathVista also presents challenges to GPT-4V, underscoring the benchmark's importance. The project is available at https://mathvista.github.io/.", "url": "https://arxiv.org/abs/2310.02255"}, {"metadata": {"arXiv": "2310.01436", "Date": "Sat, 30 Sep 2023 08:05:59 ", "Title": "Graph Neural Architecture Search with GPT-4", "Authors": ["Haishuai Wang", "Yang Gao", "Xin Zheng", "Peng Zhang", "Hongyang Chen", "Jiajun Bu"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph Neural Architecture Search (GNAS) has shown promising results in automatically designing graph neural networks. However, GNAS still requires intensive human labor with rich domain knowledge to design the search space and search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The basic idea of our method is to design a new class of prompts for GPT-4 to guide GPT-4 toward the generative task of graph neural architectures. The prompts consist of descriptions of the search space, search strategy, and search feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS generates more accurate graph neural networks with fast convergence. Experimental results show that embedding GPT-4 into GNAS outperforms the state-of-the-art GNAS methods.", "url": "https://arxiv.org/abs/2310.01436"}, {"metadata": {"arXiv": "2310.01438", "Date": "Sat, 30 Sep 2023 15:44:39 ", "Title": "Building Flexible, Scalable, and Machine Learning-ready Multimodal Oncology Datasets", "Authors": ["Aakash Tripathi", "Asim Waqas", "Kavya Venkatesan", "Yasin Yilmaz", "Ghulam Rasool"], "Categories": "cs.LG cs.AI"}, "abstract": "The advancements in data acquisition, storage, and processing techniques have resulted in the rapid growth of heterogeneous medical data. Integrating radiological scans, histopathology images, and molecular information with clinical data is essential for developing a holistic understanding of the disease and optimizing treatment. The need for integrating data from multiple sources is further pronounced in complex diseases such as cancer for enabling precision medicine and personalized treatments. This work proposes Multimodal Integration of Oncology Data System (MINDS) - a flexible, scalable, and cost-effective metadata framework for efficiently fusing disparate data from public sources such as the Cancer Research Data Commons (CRDC) into an interconnected, patient-centric framework. MINDS offers an interface for exploring relationships across data types and building cohorts for developing large-scale multimodal machine learning models. By harmonizing multimodal data, MINDS aims to potentially empower researchers with greater analytical ability to uncover diagnostic and prognostic insights and enable evidence-based personalized care. MINDS tracks granular end-to-end data provenance, ensuring reproducibility and transparency. The cloud-native architecture of MINDS can handle exponential data growth in a secure, cost-optimized manner while ensuring substantial storage optimization, replication avoidance, and dynamic access capabilities. Auto-scaling, access controls, and other mechanisms guarantee pipelines' scalability and security. MINDS overcomes the limitations of existing biomedical data silos via an interoperable metadata-driven approach that represents a pivotal step toward the future of oncology data integration.", "url": "https://arxiv.org/abs/2310.01438"}, {"metadata": {"arXiv": "2310.01443", "Date": "Sun, 01 Oct 2023 03:57:13 ", "Title": "Quantum-Based Feature Selection for Multi-classification Problem in Complex Systems with Edge Computing", "Authors": ["Wenjie Liu", "Junxiu Chen", "Yuxiang Wang", "Peipei Gao", "Zhibin Lei", "and Xu Ma"], "Categories": "cs.LG cs.AI cs.ET quant-ph", "Comments": ["22 pages", "11 figures"], "Journal-ref": "Complexity, 2020. 2020: p. 8216874", "DOI": "10.1155/2020/8216874"}, "abstract": "The complex systems with edge computing require a huge amount of multi-feature data to extract appropriate insights for their decision making, so it is important to find a feasible feature selection method to improve the computational efficiency and save the resource consumption. In this paper, a quantum-based feature selection algorithm for the multi-classification problem, namely, QReliefF, is proposed, which can effectively reduce the complexity of algorithm and improve its computational efficiency. First, all features of each sample are encoded into a quantum state by performing operations CMP and R_y, and then the amplitude estimation is applied to calculate the similarity between any two quantum states (i.e., two samples). According to the similarities, the Grover-Long method is utilized to find the nearest k neighbor samples, and then the weight vector is updated. After a certain number of iterations through the above process, the desired features can be selected with regards to the final weight vector and the threshold {\\tau}. Compared with the classical ReliefF algorithm, our algorithm reduces the complexity of similarity calculation from O(MN) to O(M), the complexity of finding the nearest neighbor from O(M) to O(sqrt(M)), and resource consumption from O(MN) to O(MlogN). Meanwhile, compared with the quantum Relief algorithm, our algorithm is superior in finding the nearest neighbor, reducing the complexity from O(M) to O(sqrt(M)). Finally, in order to verify the feasibility of our algorithm, a simulation experiment based on Rigetti with a simple example is performed.", "url": "https://arxiv.org/abs/2310.01443"}, {"metadata": {"arXiv": "2310.01551", "Date": "Mon, 02 Oct 2023 18:45:46 ", "Title": "Harnessing the Power of Choices in Decision Tree Learning", "Authors": ["Guy Blanc", "Jane Lange", "Chirag Pabbaraju", "Colin Sullivan", "Li-Yang Tan", "Mo Tiwari"], "Categories": "cs.LG cs.AI cs.DS", "Comments": ["NeurIPS 2023"], "ACM-class": "I.2.0; I.2.m"}, "abstract": "We propose a simple generalization of standard and empirically successful decision tree learning algorithms such as ID3, C4.5, and CART. These algorithms, which have been central to machine learning for decades, are greedy in nature: they grow a decision tree by iteratively splitting on the best attribute. Our algorithm, Top-$k$, considers the $k$ best attributes as possible splits instead of just the single best attribute. We demonstrate, theoretically and empirically, the power of this simple generalization. We first prove a {\\sl greediness hierarchy theorem} showing that for every $k \\in \\mathbb{N}$, Top-$(k+1)$ can be dramatically more powerful than Top-$k$: there are data distributions for which the former achieves accuracy $1-\\varepsilon$, whereas the latter only achieves accuracy $\\frac1{2}+\\varepsilon$. We then show, through extensive experiments, that Top-$k$ outperforms the two main approaches to decision tree learning: classic greedy algorithms and more recent \"optimal decision tree\" algorithms. On one hand, Top-$k$ consistently enjoys significant accuracy gains over greedy algorithms across a wide range of benchmarks. On the other hand, Top-$k$ is markedly more scalable than optimal decision tree algorithms and is able to handle dataset and feature set sizes that remain far beyond the reach of these algorithms.", "url": "https://arxiv.org/abs/2310.01551"}, {"metadata": {"arXiv": "2310.01557", "Date": "Mon, 02 Oct 2023 18:52:11 ", "Title": "SmartPlay : A Benchmark for LLMs as Intelligent Agents", "Authors": ["Yue Wu", "Xuan Tang", "Tom M. Mitchell", "Yuanzhi Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Recent large language models (LLMs) have demonstrated great potential toward intelligent agents and next-gen automation, but there currently lacks a systematic benchmark for evaluating LLMs' abilities as agents. We introduce SmartPlay: both a challenging benchmark and a methodology for evaluating LLMs as agents. SmartPlay consists of 6 different games, including Rock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique setting, providing up to 20 evaluation settings and infinite environment variations. Each game in SmartPlay uniquely challenges a subset of 9 important capabilities of an intelligent LLM agent, including reasoning with object dependencies, planning ahead, spatial reasoning, learning from history, and understanding randomness. The distinction between the set of capabilities each game test allows us to analyze each capability separately. SmartPlay serves not only as a rigorous testing ground for evaluating the overall performance of LLM agents but also as a road-map for identifying gaps in current methodologies. We release our benchmark at github.com/LLMsmartplay/SmartPlay", "url": "https://arxiv.org/abs/2310.01557"}, {"metadata": {"arXiv": "2310.01581", "Date": "Mon, 02 Oct 2023 19:22:01 ", "Title": "On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?", "Authors": ["Hangfan Zhang", "Zhimeng Guo", "Huaisheng Zhu", "Bochuan Cao", "Lu Lin", "Jinyuan Jia", "Jinghui Chen", "Dinghao Wu"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Large Language Models (LLMs) have achieved unprecedented performance in Natural Language Generation (NLG) tasks. However, many existing studies have shown that they could be misused to generate undesired content. In response, before releasing LLMs for public access, model developers usually align those language models through Supervised Fine-Tuning (SFT) or Reinforcement Learning with Human Feedback (RLHF). Consequently, those aligned large language models refuse to generate undesired content when facing potentially harmful/unethical requests. A natural question is \"could alignment really prevent those open-sourced large language models from being misused to generate undesired content?''. In this work, we provide a negative answer to this question. In particular, we show those open-sourced, aligned large language models could be easily misguided to generate undesired content without heavy computations or careful prompt designs. Our key idea is to directly manipulate the generation process of open-sourced LLMs to misguide it to generate undesired content including harmful or biased information and even private data. We evaluate our method on 4 open-sourced LLMs accessible publicly and our finding highlights the need for more advanced mitigation strategies for open-sourced LLMs.", "url": "https://arxiv.org/abs/2310.01581"}, {"metadata": {"arXiv": "2310.01593", "Date": "Mon, 02 Oct 2023 19:38:04 ", "Title": "Prescribed Fire Modeling using Knowledge-Guided Machine Learning for Land Management", "Authors": ["Somya Sharma Chatterjee", "Kelly Lindsay", "Neel Chatterjee", "Rohan Patil", "Ilkay Altintas De Callafon", "Michael Steinbach", "Daniel Giron", "Mai H. Nguyen", "Vipin Kumar"], "Categories": "cs.LG cs.AI stat.AP"}, "abstract": "In recent years, the increasing threat of devastating wildfires has underscored the need for effective prescribed fire management. Process-based computer simulations have traditionally been employed to plan prescribed fires for wildfire prevention. However, even simplified process models like QUIC-Fire are too compute-intensive to be used for real-time decision-making, especially when weather conditions change rapidly. Traditional ML methods used for fire modeling offer computational speedup but struggle with physically inconsistent predictions, biased predictions due to class imbalance, biased estimates for fire spread metrics (e.g., burned area, rate of spread), and generalizability in out-of-distribution wind conditions. This paper introduces a novel machine learning (ML) framework that enables rapid emulation of prescribed fires while addressing these concerns. By incorporating domain knowledge, the proposed method helps reduce physical inconsistencies in fuel density estimates in data-scarce scenarios. To overcome the majority class bias in predictions, we leverage pre-existing source domain data to augment training data and learn the spread of fire more effectively. Finally, we overcome the problem of biased estimation of fire spread metrics by incorporating a hierarchical modeling structure to capture the interdependence in fuel density and burned area. Notably, improvement in fire metric (e.g., burned area) estimates offered by our framework makes it useful for fire managers, who often rely on these fire metric estimates to make decisions about prescribed burn management. Furthermore, our framework exhibits better generalization capabilities than the other ML-based fire modeling methods across diverse wind conditions and ignition patterns.", "url": "https://arxiv.org/abs/2310.01593"}, {"metadata": {"arXiv": "2310.01604", "Date": "Mon, 02 Oct 2023 19:55:15 ", "Title": "Solving the Quadratic Assignment Problem using Deep Reinforcement Learning", "Authors": ["Puneet S. Bagga", "Arthur Delarue"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "The Quadratic Assignment Problem (QAP) is an NP-hard problem which has proven particularly challenging to solve: unlike other combinatorial problems like the traveling salesman problem (TSP), which can be solved to optimality for instances with hundreds or even thousands of locations using advanced integer programming techniques, no methods are known to exactly solve QAP instances of size greater than 30. Solving the QAP is nevertheless important because of its many critical applications, such as electronic wiring design and facility layout selection. We propose a method to solve the original Koopmans-Beckman formulation of the QAP using deep reinforcement learning. Our approach relies on a novel double pointer network, which alternates between selecting a location in which to place the next facility and a facility to place in the previous location. We train our model using A2C on a large dataset of synthetic instances, producing solutions with no instance-specific retraining necessary. Out of sample, our solutions are on average within 7.5% of a high-quality local search baseline, and even outperform it on 1.2% of instances.", "url": "https://arxiv.org/abs/2310.01604"}, {"metadata": {"arXiv": "2310.01616", "Date": "Mon, 02 Oct 2023 20:14:01 ", "Title": "Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity", "Authors": ["Emmeran Johnson", "Ciara Pike-Burke", "Patrick Rebeschini"], "Categories": "cs.LG cs.AI"}, "abstract": "We theoretically explore the relationship between sample-efficiency and adaptivity in reinforcement learning. An algorithm is sample-efficient if it uses a number of queries $n$ to the environment that is polynomial in the dimension $d$ of the problem. Adaptivity refers to the frequency at which queries are sent and feedback is processed to update the querying strategy. To investigate this interplay, we employ a learning framework that allows sending queries in $K$ batches, with feedback being processed and queries updated after each batch. This model encompasses the whole adaptivity spectrum, ranging from non-adaptive 'offline' ($K=1$) to fully adaptive ($K=n$) scenarios, and regimes in between. For the problems of policy evaluation and best-policy identification under $d$-dimensional linear function approximation, we establish $\\Omega(\\log \\log d)$ lower bounds on the number of batches $K$ required for sample-efficient algorithms with $n = O(poly(d))$ queries. Our results show that just having adaptivity ($K>1$) does not necessarily guarantee sample-efficiency. Notably, the adaptivity-boundary for sample-efficiency is not between offline reinforcement learning ($K=1$), where sample-efficiency was known to not be possible, and adaptive settings. Instead, the boundary lies between different regimes of adaptivity and depends on the problem dimension.", "url": "https://arxiv.org/abs/2310.01616"}, {"metadata": {"arXiv": "2310.01649", "Date": "Mon, 02 Oct 2023 21:23:31 ", "Title": "On Training Derivative-Constrained Neural Networks", "Authors": ["KaiChieh Lo", "Daniel Huang"], "Categories": "cs.LG cs.AI"}, "abstract": "We refer to the setting where the (partial) derivatives of a neural network's (NN's) predictions with respect to its inputs are used as additional training signal as a derivative-constrained (DC) NN. This situation is common in physics-informed settings in the natural sciences. We propose an integrated RELU (IReLU) activation function to improve training of DC NNs. We also investigate denormalization and label rescaling to help stabilize DC training. We evaluate our methods on physics-informed settings including quantum chemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that existing architectures with IReLU activations combined with denormalization and label rescaling better incorporate training signal provided by derivative constraints.", "url": "https://arxiv.org/abs/2310.01649"}, {"metadata": {"arXiv": "2310.01650", "Date": "Mon, 02 Oct 2023 21:27:54 ", "Title": "CoDBench: A Critical Evaluation of Data-driven Models for Continuous Dynamical Systems", "Authors": ["Priyanshu Burark", "Karn Tiwari", "Meer Mehran Rashid", "Prathosh A P", "N M Anoop Krishnan"], "Categories": "cs.LG cs.AI physics.comp-ph"}, "abstract": "Continuous dynamical systems, characterized by differential equations, are ubiquitously used to model several important problems: plasma dynamics, flow through porous media, weather forecasting, and epidemic dynamics. Recently, a wide range of data-driven models has been used successfully to model these systems. However, in contrast to established fields like computer vision, limited studies are available analyzing the strengths and potential applications of different classes of these models that could steer decision-making in scientific machine learning. Here, we introduce CodBench, an exhaustive benchmarking suite comprising 11 state-of-the-art data-driven models for solving differential equations. Specifically, we comprehensively evaluate 4 distinct categories of models, viz., feed forward neural networks, deep operator regression models, frequency-based neural operators, and transformer architectures against 8 widely applicable benchmark datasets encompassing challenges from fluid and solid mechanics. We conduct extensive experiments, assessing the operators' capabilities in learning, zero-shot super-resolution, data efficiency, robustness to noise, and computational efficiency. Interestingly, our findings highlight that current operators struggle with the newer mechanics datasets, motivating the need for more robust neural operators. All the datasets and codes will be shared in an easy-to-use fashion for the scientific community. We hope this resource will be an impetus for accelerated progress and exploration in modeling dynamical systems.", "url": "https://arxiv.org/abs/2310.01650"}, {"metadata": {"arXiv": "2310.01664", "Date": "Mon, 02 Oct 2023 21:53:24 ", "Title": "Artemis: HE-Aware Training for Efficient Privacy-Preserving Machine Learning", "Authors": ["Yeonsoo Jeon", "Mattan Erez", "Michael Orshansky"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Privacy-Preserving ML (PPML) based on Homomorphic Encryption (HE) is a promising foundational privacy technology. Making it more practical requires lowering its computational cost, especially, in handling modern large deep neural networks. Model compression via pruning is highly effective in conventional plaintext ML but cannot be effectively applied to HE-PPML as is. We propose Artemis, a highly effective DNN pruning technique for HE-based inference. We judiciously investigate two HE-aware pruning strategies (positional and diagonal) to reduce the number of Rotation operations, which dominate compute time in HE convolution. We find that Pareto-optimal solutions are based fully on diagonal pruning. Artemis' benefits come from coupling DNN training, driven by a novel group Lasso regularization objective, with pruning to maximize HE-specific cost reduction (dominated by the Rotation operations). We show that Artemis improves on prior HE-oriented pruning and can achieve a 1.2-6x improvement when targeting modern convolutional models (ResNet18 and ResNet18) across three datasets.", "url": "https://arxiv.org/abs/2310.01664"}, {"metadata": {"arXiv": "2310.01720", "Date": "Tue, 03 Oct 2023 01:13:17 ", "Title": "PrACTiS: Perceiver-Attentional Copulas for Time Series", "Authors": ["Cat P. Le", "Chris Cannella", "Ali Hasan", "Yuting Ng", "Vahid Tarokh"], "Categories": "cs.LG cs.AI"}, "abstract": "Transformers incorporating copula structures have demonstrated remarkable performance in time series prediction. However, their heavy reliance on self-attention mechanisms demands substantial computational resources, thus limiting their practical utility across a wide range of tasks. In this work, we present a model that combines the perceiver architecture with a copula structure to enhance time-series forecasting. By leveraging the perceiver as the encoder, we efficiently transform complex, high-dimensional, multimodal data into a compact latent space, thereby significantly reducing computational demands. To further reduce complexity, we introduce midpoint inference and local attention mechanisms, enabling the model to capture dependencies within imputed samples effectively. Subsequently, we deploy the copula-based attention and output variance testing mechanism to capture the joint distribution of missing data, while simultaneously mitigating error propagation during prediction. Our experimental results on the unimodal and multimodal benchmarks showcase a consistent 20\\% improvement over the state-of-the-art methods, while utilizing less than half of available memory resources.", "url": "https://arxiv.org/abs/2310.01720"}, {"metadata": {"arXiv": "2310.01728", "Date": "Tue, 03 Oct 2023 01:31:25 ", "Title": "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "Authors": ["Ming Jin", "Shiyu Wang", "Lintao Ma", "Zhixuan Chu", "James Y. Zhang", "Xiaoming Shi", "Pin-Yu Chen", "Yuxuan Liang", "Yuan-Fang Li", "Shirui Pan", "Qingsong Wen"], "Categories": "cs.LG cs.AI"}, "abstract": "Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.", "url": "https://arxiv.org/abs/2310.01728"}, {"metadata": {"arXiv": "2310.01737", "Date": "Tue, 03 Oct 2023 01:55:54 ", "Title": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement", "Authors": ["Xuefeng Liu", "Takuma Yoneda", "Rick L. Stevens", "Matthew R. Walter", "Yuxin Chen"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration, an aspect that is notably challenging in sparse-reward RL, particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the oracles or learn from its own value function when the learner's performance surpasses that of the oracles in a specific state. Empirical evaluations and theoretical analysis validate that RPI excels in comparison to existing state-of-the-art methodologies, demonstrating superior performance across various benchmark domains.", "url": "https://arxiv.org/abs/2310.01737"}, {"metadata": {"arXiv": "2310.01770", "Date": "Tue, 03 Oct 2023 03:36:29 ", "Title": "A simple connection from loss flatness to compressed representations in neural networks", "Authors": ["Shirui Chen", "Stefano Recanatesi", "Eric Shea-Brown"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep neural networks' generalization capacity has been studied in a variety of ways, including at least two distinct categories of approach: one based on the shape of the loss landscape in parameter space, and the other based on the structure of the representation manifold in feature space (that is, in the space of unit activities). These two approaches are related, but they are rarely studied together and explicitly connected. Here, we present a simple analysis that makes such a connection. We show that, in the last phase of learning of deep neural networks, compression of the volume of the manifold of neural representations correlates with the flatness of the loss around the minima explored by ongoing parameter optimization. We show that this is predicted by a relatively simple mathematical relationship: loss flatness implies compression of neural representations. Our results build closely on prior work of \\citet{ma_linear_2021}, which shows how flatness (i.e., small eigenvalues of the loss Hessian) develops in late phases of learning and lead to robustness to perturbations in network inputs. Moreover, we show there is no similarly direct connection between local dimensionality and sharpness, suggesting that this property may be controlled by different mechanisms than volume and hence may play a complementary role in neural representations. Overall, we advance a dual perspective on generalization in neural networks in both parameter and feature space.", "url": "https://arxiv.org/abs/2310.01770"}, {"metadata": {"arXiv": "2310.01783", "Date": "Tue, 03 Oct 2023 04:14:17 ", "Title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis", "Authors": ["Weixin Liang", "Yuhui Zhang", "Hancheng Cao", "Binglu Wang", "Daisy Ding", "Xinyu Yang", "Kailas Vodrahalli", "Siyu He", "Daniel Smith", "Yian Yin", "Daniel McFarland", "James Zou"], "Categories": "cs.LG cs.AI cs.CL cs.HC"}, "abstract": "Expert feedback lays the foundation of rigorous research. However, the rapid growth of scholarly production and intricate knowledge specialization challenge the conventional scientific feedback mechanisms. High-quality peer reviews are increasingly difficult to obtain. Researchers who are more junior or from under-resourced settings have especially hard times getting timely feedback. With the breakthrough of large language models (LLM) such as GPT-4, there is growing interest in using LLMs to generate scientific feedback on research manuscripts. However, the utility of LLM-generated feedback has not been systematically studied. To address this gap, we created an automated pipeline using GPT-4 to provide comments on the full PDFs of scientific papers. We evaluated the quality of GPT-4's feedback through two large-scale studies. We first quantitatively compared GPT-4's generated feedback with human peer reviewer feedback in 15 Nature family journals (3,096 papers in total) and the ICLR machine learning conference (1,709 papers). The overlap in the points raised by GPT-4 and by human reviewers (average overlap 30.85% for Nature journals, 39.23% for ICLR) is comparable to the overlap between two human reviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The overlap between GPT-4 and human reviewers is larger for the weaker papers. We then conducted a prospective user study with 308 researchers from 110 US institutions in the field of AI and computational biology to understand how researchers perceive feedback generated by our GPT-4 system on their own papers. Overall, more than half (57.4%) of the users found GPT-4 generated feedback helpful/very helpful and 82.4% found it more beneficial than feedback from at least some human reviewers. While our findings show that LLM-generated feedback can help researchers, we also identify several limitations.", "url": "https://arxiv.org/abs/2310.01783"}, {"metadata": {"arXiv": "2310.01865", "Date": "Tue, 03 Oct 2023 08:08:09 ", "Title": "Conditional Instrumental Variable Regression with Representation Learning for Causal Inference", "Authors": ["Debo Cheng", "Ziqi Xu", "Jiuyong Li", "Lin Liu", "Jixue Liu and Thuc Duy Le (UniSA STEM", "University of South Australia", "Australia)"], "Categories": "cs.LG cs.AI", "Comments": ["17pages", "3 figures and 6 tables"]}, "abstract": "This paper studies the challenging problem of estimating causal effects from observational data, in the presence of unobserved confounders. The two-stage least square (TSLS) method and its variants with a standard instrumental variable (IV) are commonly used to eliminate confounding bias, including the bias caused by unobserved confounders, but they rely on the linearity assumption. Besides, the strict condition of unconfounded instruments posed on a standard IV is too strong to be practical. To address these challenging and practical problems of the standard IV method (linearity assumption and the strict condition), in this paper, we use a conditional IV (CIV) to relax the unconfounded instrument condition of standard IV and propose a non-linear CIV regression with Confounding Balancing Representation Learning, CBRL.CIV, for jointly eliminating the confounding bias from unobserved confounders and balancing the observed confounders, without the linearity assumption. We theoretically demonstrate the soundness of CBRL.CIV. Extensive experiments on synthetic and two real-world datasets show the competitive performance of CBRL.CIV against state-of-the-art IV-based estimators and superiority in dealing with the non-linear situation.", "url": "https://arxiv.org/abs/2310.01865"}, {"metadata": {"arXiv": "2310.01875", "Date": "Tue, 03 Oct 2023 08:25:32 ", "Title": "Towards Stable Backdoor Purification through Feature Shift Tuning", "Authors": ["Rui Min", "Zeyu Qin", "Li Shen", "Minhao Cheng"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["NeurIPS 2023 paper. The first two authors contributed equally"]}, "abstract": "It has been widely observed that deep neural networks (DNN) are vulnerable to backdoor attacks where attackers could manipulate the model behavior maliciously by tampering with a small set of training samples. Although a line of defense methods is proposed to mitigate this threat, they either require complicated modifications to the training process or heavily rely on the specific model architecture, which makes them hard to deploy into real-world applications. Therefore, in this paper, we instead start with fine-tuning, one of the most common and easy-to-deploy backdoor defenses, through comprehensive evaluations against diverse attack scenarios. Observations made through initial experiments show that in contrast to the promising defensive results on high poisoning rates, vanilla tuning methods completely fail at low poisoning rate scenarios. Our analysis shows that with the low poisoning rate, the entanglement between backdoor and clean features undermines the effect of tuning-based defenses. Therefore, it is necessary to disentangle the backdoor and clean features in order to improve backdoor purification. To address this, we introduce Feature Shift Tuning (FST), a method for tuning-based backdoor purification. Specifically, FST encourages feature shifts by actively deviating the classifier weights from the originally compromised weights. Extensive experiments demonstrate that our FST provides consistently stable performance under different attack settings. Additionally, it is also convenient to deploy in real-world scenarios with significantly reduced computation costs. Our codes are available at \\url{https://github.com/AISafety-HKUST/stable_backdoor_purification}.", "url": "https://arxiv.org/abs/2310.01875"}, {"metadata": {"arXiv": "2310.01884", "Date": "Tue, 03 Oct 2023 08:37:21 ", "Title": "Adaptive Hybrid Model for Enhanced Stock Market Predictions Using Improved VMD and Stacked Informer", "Authors": ["Jianan Zhang and Hongyi Duan"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper introduces an innovative adaptive hybrid model for stock market predictions, leveraging the capabilities of an enhanced Variational Mode Decomposition (VMD), Feature Engineering (FE), and stacked Informer integrated with an adaptive loss function. Through rigorous experimentation, the proposed model, termed Adam+GC+enhanced informer (We name it VMGCformer), demonstrates significant proficiency in addressing the intricate dynamics and volatile nature of stock market data. Experimental results, derived from multiple benchmark datasets, underscore the model's superiority in terms of prediction accuracy, responsiveness, and generalization capabilities over traditional and other hybrid models. The research further highlights potential avenues for optimization and introduces future directions to enhance predictive modeling, especially for small enterprises and feature engineering.", "url": "https://arxiv.org/abs/2310.01884"}, {"metadata": {"arXiv": "2310.01892", "Date": "Tue, 03 Oct 2023 08:54:06 ", "Title": "FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations", "Authors": ["Chanakya Ekbote", "Ajinkya Pankaj Deshpande", "Arun Iyer", "Ramakrishna Bairi", "Sundararajan Sellamanickam"], "Categories": "cs.LG cs.AI"}, "abstract": "Unsupervised node representations learnt using contrastive learning-based methods have shown good performance on downstream tasks. However, these methods rely on augmentations that mimic low-pass filters, limiting their performance on tasks requiring different eigen-spectrum parts. This paper presents a simple filter-based augmentation method to capture different parts of the eigen-spectrum. We show significant improvements using these augmentations. Further, we show that sharing the same weights across these different filter augmentations is possible, reducing the computational load. In addition, previous works have shown that good performance on downstream tasks requires high dimensional representations. Working with high dimensions increases the computations, especially when multiple augmentations are involved. We mitigate this problem and recover good performance through lower dimensional embeddings using simple random Fourier feature projections. Our method, FiGURe achieves an average gain of up to 4.4\\%, compared to the state-of-the-art unsupervised models, across all datasets in consideration, both homophilic and heterophilic. Our code can be found at: https://github.com/microsoft/figure.", "url": "https://arxiv.org/abs/2310.01892"}, {"metadata": {"arXiv": "2310.01951", "Date": "Tue, 03 Oct 2023 10:52:21 ", "Title": "Probabilistic Reach-Avoid for Bayesian Neural Networks", "Authors": ["Matthew Wicker", "Luca Laurenti", "Andrea Patane", "Nicola Paoletti", "Alessandro Abate", "Marta Kwiatkowska"], "Categories": "cs.LG cs.AI", "Comments": ["47 pages", "10 figures. arXiv admin note: text overlap with arXiv:2105.10134"]}, "abstract": "Model-based reinforcement learning seeks to simultaneously learn the dynamics of an unknown stochastic environment and synthesise an optimal policy for acting in it. Ensuring the safety and robustness of sequential decisions made through a policy in such an environment is a key challenge for policies intended for safety-critical scenarios. In this work, we investigate two complementary problems: first, computing reach-avoid probabilities for iterative predictions made with dynamical models, with dynamics described by Bayesian neural network (BNN); second, synthesising control policies that are optimal with respect to a given reach-avoid specification (reaching a \"target\" state, while avoiding a set of \"unsafe\" states) and a learned BNN model. Our solution leverages interval propagation and backward recursion techniques to compute lower bounds for the probability that a policy's sequence of actions leads to satisfying the reach-avoid specification. Such computed lower bounds provide safety certification for the given policy and BNN model. We then introduce control synthesis algorithms to derive policies maximizing said lower bounds on the safety probability. We demonstrate the effectiveness of our method on a series of control benchmarks characterized by learned BNN dynamics models. On our most challenging benchmark, compared to purely data-driven policies the optimal synthesis algorithm is able to provide more than a four-fold increase in the number of certifiable states and more than a three-fold increase in the average guaranteed reach-avoid probability.", "url": "https://arxiv.org/abs/2310.01951"}, {"metadata": {"arXiv": "2310.02012", "Date": "Tue, 03 Oct 2023 12:35:02 ", "Title": "Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion", "Authors": ["Alexandru Meterez", "Amir Joudaki", "Francesco Orabona", "Alexander Immer", "Gunnar R\\\"atsch", "Hadi Daneshmand"], "Categories": "cs.LG cs.AI"}, "abstract": "Normalization layers are one of the key building blocks for deep neural networks. Several theoretical studies have shown that batch normalization improves the signal propagation, by avoiding the representations from becoming collinear across the layers. However, results on mean-field theory of batch normalization also conclude that this benefit comes at the expense of exploding gradients in depth. Motivated by these two aspects of batch normalization, in this study we pose the following question: \"Can a batch-normalized network keep the optimal signal propagation properties, but avoid exploding gradients?\" We answer this question in the affirmative by giving a particular construction of an Multi-Layer Perceptron (MLP) with linear activations and batch-normalization that provably has bounded gradients at any depth. Based on Weingarten calculus, we develop a rigorous and non-asymptotic theory for this constructed MLP that gives a precise characterization of forward signal propagation, while proving that gradients remain bounded for linearly independent input samples, which holds in most practical settings. Inspired by our theory, we also design an activation shaping scheme that empirically achieves the same properties for certain non-linear activations.", "url": "https://arxiv.org/abs/2310.02012"}, {"metadata": {"arXiv": "2310.02066", "Date": "Tue, 03 Oct 2023 14:09:15 ", "Title": "De Novo Drug Design with Joint Transformers", "Authors": ["Adam Izdebski and Ewelina Weglarz-Tomczak and Ewa Szczurek and Jakub M. Tomczak"], "Categories": "cs.LG cs.AI"}, "abstract": "De novo drug design requires simultaneously generating novel molecules outside of training data and predicting their target properties, making it a hard task for generative models. To address this, we propose Joint Transformer that combines a Transformer decoder, a Transformer encoder, and a predictor in a joint generative model with shared weights. We show that training the model with a penalized log-likelihood objective results in state-of-the-art performance in molecule generation, while decreasing the prediction error on newly sampled molecules, as compared to a fine-tuned decoder-only Transformer, by 42%. Finally, we propose a probabilistic black-box optimization algorithm that employs Joint Transformer to generate novel molecules with improved target properties, as compared to the training data, outperforming other SMILES-based optimization methods in de novo drug design.", "url": "https://arxiv.org/abs/2310.02066"}, {"metadata": {"arXiv": "2310.02094", "Date": "Tue, 03 Oct 2023 14:38:12 ", "Title": "CoNO: Complex Neural Operator for Continuous Dynamical Systems", "Authors": ["Karn Tiwari", "N M Anoop Krishnan", "Prathosh A P"], "Categories": "cs.LG cs.AI"}, "abstract": "Neural operators extend data-driven models to map between infinite-dimensional functional spaces. These models have successfully solved continuous dynamical systems represented by differential equations, viz weather forecasting, fluid flow, or solid mechanics. However, the existing operators still rely on real space, thereby losing rich representations potentially captured in the complex space by functional transforms. In this paper, we introduce a Complex Neural Operator (CoNO), that parameterizes the integral kernel in the complex fractional Fourier domain. Additionally, the model employing a complex-valued neural network along with aliasing-free activation functions preserves the complex values and complex algebraic properties, thereby enabling improved representation, robustness to noise, and generalization. We show that the model effectively captures the underlying partial differential equation with a single complex fractional Fourier transform. We perform an extensive empirical evaluation of CoNO on several datasets and additional tasks such as zero-shot super-resolution, evaluation of out-of-distribution data, data efficiency, and robustness to noise. CoNO exhibits comparable or superior performance to all the state-of-the-art models in these tasks. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning.", "url": "https://arxiv.org/abs/2310.02094"}, {"metadata": {"arXiv": "2310.02147", "Date": "Tue, 03 Oct 2023 15:34:21 ", "Title": "Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation", "Authors": ["Guojun Xiong", "Jian Li"], "Categories": "cs.LG cs.AI", "Comments": ["26 pages", "4 figures", "Neurips 2023"]}, "abstract": "Whittle index policy is a heuristic to the intractable restless multi-armed bandits (RMAB) problem. Although it is provably asymptotically optimal, finding Whittle indices remains difficult. In this paper, we present Neural-Q-Whittle, a Whittle index based Q-learning algorithm for RMAB with neural network function approximation, which is an example of nonlinear two-timescale stochastic approximation with Q-function values updated on a faster timescale and Whittle indices on a slower timescale. Despite the empirical success of deep Q-learning, the non-asymptotic convergence rate of Neural-Q-Whittle, which couples neural networks with two-timescale Q-learning largely remains unclear. This paper provides a finite-time analysis of Neural-Q-Whittle, where data are generated from a Markov chain, and Q-function is approximated by a ReLU neural network. Our analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error. Combing these provide Neural-Q-Whittle with $\\mathcal{O}(1/k^{2/3})$ convergence rate, where $k$ is the number of iterations.", "url": "https://arxiv.org/abs/2310.02147"}, {"metadata": {"arXiv": "2310.02193", "Date": "Tue, 03 Oct 2023 16:39:21 ", "Title": "Uncertainty Quantification in Inverse Models in Hydrology", "Authors": ["Somya Sharma Chatterjee", "Rahul Ghosh", "Arvind Renganathan", "Xiang Li", "Snigdhansu Chatterjee", "John Nieber", "Christopher Duffy", "Vipin Kumar"], "Categories": "cs.LG cs.AI stat.AP", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2210.06213"]}, "abstract": "In hydrology, modeling streamflow remains a challenging task due to the limited availability of basin characteristics information such as soil geology and geomorphology. These characteristics may be noisy due to measurement errors or may be missing altogether. To overcome this challenge, we propose a knowledge-guided, probabilistic inverse modeling method for recovering physical characteristics from streamflow and weather data, which are more readily available. We compare our framework with state-of-the-art inverse models for estimating river basin characteristics. We also show that these estimates offer improvement in streamflow modeling as opposed to using the original basin characteristic values. Our inverse model offers 3\\% improvement in R$^2$ for the inverse model (basin characteristic estimation) and 6\\% for the forward model (streamflow prediction). Our framework also offers improved explainability since it can quantify uncertainty in both the inverse and the forward model. Uncertainty quantification plays a pivotal role in improving the explainability of machine learning models by providing additional insights into the reliability and limitations of model predictions. In our analysis, we assess the quality of the uncertainty estimates. Compared to baseline uncertainty quantification methods, our framework offers 10\\% improvement in the dispersion of epistemic uncertainty and 13\\% improvement in coverage rate. This information can help stakeholders understand the level of uncertainty associated with the predictions and provide a more comprehensive view of the potential outcomes.", "url": "https://arxiv.org/abs/2310.02193"}, {"metadata": {"arXiv": "2310.02207", "Date": "Tue, 03 Oct 2023 17:06:52 ", "Title": "Language Models Represent Space and Time", "Authors": ["Wes Gurnee", "Max Tegmark"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual ``space neurons'' and ``time neurons'' that reliably encode spatial and temporal coordinates. Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models.", "url": "https://arxiv.org/abs/2310.02207"}, {"metadata": {"arXiv": "2310.02227", "Date": "Tue, 03 Oct 2023 17:32:44 ", "Title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training", "Authors": ["Kazem Meidani", "Parshin Shojaee", "Chandan K. Reddy", "Amir Barati Farimani"], "Categories": "cs.LG cs.AI"}, "abstract": "In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic supervision enhances the embeddings of numeric data and vice versa. We evaluate SNIP across diverse tasks, including symbolic-to-numeric mathematical property prediction and numeric-to-symbolic equation discovery, commonly known as symbolic regression. Results show that SNIP effectively transfers to various tasks, consistently outperforming fully supervised baselines and competing strongly with established task-specific methods, especially in few-shot learning scenarios where available data is limited.", "url": "https://arxiv.org/abs/2310.02227"}, {"metadata": {"arXiv": "2310.02246", "Date": "Tue, 03 Oct 2023 17:51:42 ", "Title": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances", "Authors": ["Mikhail Khodak", "Edmond Chow", "Maria-Florina Balcan", "Ameet Talwalkar"], "Categories": "cs.LG cs.AI cs.NA math.NA stat.ML"}, "abstract": "Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\\omega$ has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\\omega$ as the sequence length increases. Furthermore, when given additional structural information, we show that a contextual bandit method asymptotically achieves the performance of the instance-optimal policy, which selects the best $\\omega$ for each instance. Our work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical methods using well-understood learning algorithms.", "url": "https://arxiv.org/abs/2310.02246"}, {"metadata": {"arXiv": "2310.02258", "Date": "Tue, 03 Oct 2023 17:58:33 ", "Title": "A Neural Scaling Law from Lottery Ticket Ensembling", "Authors": ["Ziming Liu", "Max Tegmark"], "Categories": "cs.LG cs.AI physics.data-an stat.ML", "Comments": ["14 pages", "13 figures"]}, "abstract": "Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale. Sharma & Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\\alpha}$, $\\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension. Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\\alpha=1$) from their predictions ($\\alpha=4$). We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more \"lottery tickets\", which are ensembled to reduce the variance of outputs. We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically. We attribute the $N^{-1}$ scaling law to the \"central limit theorem\" of lottery tickets. Finally, we discuss its potential implications for large language models and statistical physics-type theories of learning.", "url": "https://arxiv.org/abs/2310.02258"}, {"metadata": {"arXiv": "2310.01632", "Date": "Mon, 02 Oct 2023 20:53:20 ", "Title": "Imitation Learning from Observation through Optimal Transport", "Authors": ["Wei-Di Chang", "Scott Fujimoto", "David Meger", "Gregory Dudek"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Imitation Learning from Observation (ILfO) is a setting in which a learner tries to imitate the behavior of an expert, using only observational data and without the direct guidance of demonstrated actions. In this paper, we re-examine the use of optimal transport for IL, in which a reward is generated based on the Wasserstein distance between the state trajectories of the learner and expert. We show that existing methods can be simplified to generate a reward function without requiring learned models or adversarial learning. Unlike many other state-of-the-art methods, our approach can be integrated with any RL algorithm, and is amenable to ILfO. We demonstrate the effectiveness of this simple approach on a variety of continuous control tasks and find that it surpasses the state of the art in the IlfO setting, achieving expert-level performance across a range of evaluation domains even when observing only a single expert trajectory without actions.", "url": "https://arxiv.org/abs/2310.01632"}, {"metadata": {"arXiv": "2310.02219", "Date": "Tue, 03 Oct 2023 17:27:10 ", "Title": "What do we learn from a large-scale study of pre-trained visual representations in sim and real environments?", "Authors": ["Sneha Silwal", "Karmesh Yadav", "Tingfan Wu", "Jay Vakil", "Arjun Majumdar", "Sergio Arnaud", "Claire Chen", "Vincent-Pierre Berges", "Dhruv Batra", "Aravind Rajeswaran", "Mrinal Kalakrishnan", "Franziska Meier", "Oleksandr Maksymets"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["Project website https://pvrs-sim2real.github.io/"], "MSC-class": "68T45 (Primary) 68T40, 68T05(Secondary)", "ACM-class": "I.2.9; I.2.6; I.4.8; I.5.4"}, "abstract": "We present a large empirical investigation on the use of pre-trained visual representations (PVRs) for training downstream policies that execute real-world tasks. Our study spans five different PVRs, two different policy-learning paradigms (imitation and reinforcement learning), and three different robots for 5 distinct manipulation and indoor navigation tasks. From this effort, we can arrive at three insights: 1) the performance trends of PVRs in the simulation are generally indicative of their trends in the real world, 2) the use of PVRs enables a first-of-its-kind result with indoor ImageNav (zero-shot transfer to a held-out scene in the real world), and 3) the benefits from variations in PVRs, primarily data-augmentation and fine-tuning, also transfer to the real-world performance. See project website for additional details and visuals.", "url": "https://arxiv.org/abs/2310.02219"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

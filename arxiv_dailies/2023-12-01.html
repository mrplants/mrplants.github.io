<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.17967", "Date": "Wed, 29 Nov 2023 12:39:31 ", "Title": "Discovering Galaxy Features via Dataset Distillation", "Authors": ["Haowen Guan", "Xuan Zhao", "Zishi Wang", "Zhiyang Li", "and Julia Kempe"], "Categories": "cs.CV astro-ph.IM cs.LG", "Comments": ["Accepted to NeurIPS Workshop on Machine Learning and the Physical Sciences", "2023"]}, "abstract": "In many applications, Neural Nets (NNs) have classification performance on par or even exceeding human capacity. Moreover, it is likely that NNs leverage underlying features that might differ from those humans perceive to classify. Can we \"reverse-engineer\" pertinent features to enhance our scientific understanding? Here, we apply this idea to the notoriously difficult task of galaxy classification: NNs have reached high performance for this task, but what does a neural net (NN) \"see\" when it classifies galaxies? Are there morphological features that the human eye might overlook that could help with the task and provide new insights? Can we visualize tracers of early evolution, or additionally incorporated spectral data? We present a novel way to summarize and visualize galaxy morphology through the lens of neural networks, leveraging Dataset Distillation, a recent deep-learning methodology with the primary objective to distill knowledge from a large dataset and condense it into a compact synthetic dataset, such that a model trained on this synthetic dataset achieves performance comparable to a model trained on the full dataset. We curate a class-balanced, medium-size high-confidence version of the Galaxy Zoo 2 dataset, and proceed with dataset distillation from our accurate NN-classifier to create synthesized prototypical images of galaxy morphological features, demonstrating its effectiveness. Of independent interest, we introduce a self-adaptive version of the state-of-the-art Matching Trajectory algorithm to automate the distillation process, and show enhanced performance on computer vision benchmarks.", "url": "https://arxiv.org/abs/2311.17967"}, {"metadata": {"arXiv": "2311.17978", "Date": "Wed, 29 Nov 2023 17:24:04 ", "Title": "AutArch: An AI-assisted workflow for object detection and automated recording in archaeological catalogues", "Authors": ["Kevin Klein", "Alyssa Wohde", "Alexander V. Gorelik", "Volker Heyd", "Yoan Diekmann", "Maxime Brami"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "Compiling large datasets from published resources, such as archaeological find catalogues presents fundamental challenges: identifying relevant content and manually recording it is a time-consuming, repetitive and error-prone task. For the data to be useful, it must be of comparable quality and adhere to the same recording standards, which is hardly ever the case in archaeology. Here, we present a new data collection method exploiting recent advances in Artificial Intelligence. Our software uses an object detection neural network combined with further classification networks to speed up, automate, and standardise data collection from legacy resources, such as archaeological drawings and photographs in large unsorted PDF files. The AI-assisted workflow detects common objects found in archaeological catalogues, such as graves, skeletons, ceramics, ornaments, stone tools and maps, and spatially relates and analyses these objects on the page to extract real-life attributes, such as the size and orientation of a grave based on the north arrow and the scale. A graphical interface allows for and assists with manual validation. We demonstrate the benefits of this approach by collecting a range of shapes and numerical attributes from richly-illustrated archaeological catalogues, and benchmark it in a real-world experiment with ten users. Moreover, we record geometric whole-outlines through contour detection, an alternative to landmark-based geometric morphometrics not achievable by hand.", "url": "https://arxiv.org/abs/2311.17978"}, {"metadata": {"arXiv": "2311.18083", "Date": "Wed, 29 Nov 2023 21:11:58 ", "Title": "Meta Co-Training: Two Views are Better than One", "Authors": ["Jay C. Rothenberger", "Dimitrios I. Diochnos"], "Categories": "cs.CV cs.LG", "Comments": ["16 pages", "14 figures", "10 tables", "for implementation see https://github.com/JayRothenberger/Meta-Co-Training"], "ACM-class": "I.2.6; I.4.10"}, "abstract": "In many practical computer vision scenarios unlabeled data is plentiful, but labels are scarce and difficult to obtain. As a result, semi-supervised learning which leverages unlabeled data to boost the performance of supervised classifiers have received significant attention in recent literature. One major class of semi-supervised algorithms is co-training. In co-training two different models leverage different independent and sufficient \"views\" of the data to jointly make better predictions. During co-training each model creates pseudo labels on unlabeled points which are used to improve the other model. We show that in the common case when independent views are not available we can construct such views inexpensively using pre-trained models. Co-training on the constructed views yields a performance improvement over any of the individual views we construct and performance comparable with recent approaches in semi-supervised learning, but has some undesirable properties. To alleviate the issues present with co-training we present Meta Co-Training which is an extension of the successful Meta Pseudo Labels approach to multiple views. Our method achieves new state-of-the-art performance on ImageNet-10% with very few training resources, as well as outperforming prior semi-supervised work on several other fine-grained image classification datasets.", "url": "https://arxiv.org/abs/2311.18083"}, {"metadata": {"arXiv": "2311.18168", "Date": "Thu, 30 Nov 2023 01:14:43 ", "Title": "Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks, Methods, and Applications", "Authors": ["Karren D. Yang", "Anurag Ranjan", "Jen-Hao Rick Chang", "Raviteja Vemulapalli", "Oncel Tuzel"], "Categories": "cs.CV cs.LG eess.AS"}, "abstract": "We consider the task of animating 3D facial geometry from speech signal. Existing works are primarily deterministic, focusing on learning a one-to-one mapping from speech signal to 3D face meshes on small datasets with limited speakers. While these models can achieve high-quality lip articulation for speakers in the training set, they are unable to capture the full and diverse distribution of 3D facial motions that accompany speech in the real world. Importantly, the relationship between speech and facial motion is one-to-many, containing both inter-speaker and intra-speaker variations and necessitating a probabilistic approach. In this paper, we identify and address key challenges that have so far limited the development of probabilistic models: lack of datasets and metrics that are suitable for training and evaluating them, as well as the difficulty of designing a model that generates diverse results while remaining faithful to a strong conditioning signal as speech. We first propose large-scale benchmark datasets and metrics suitable for probabilistic modeling. Then, we demonstrate a probabilistic model that achieves both diversity and fidelity to speech, outperforming other methods across the proposed benchmarks. Finally, we showcase useful applications of probabilistic models trained on these large-scale datasets: we can generate diverse speech-driven 3D facial motion that matches unseen speaker styles extracted from reference clips; and our synthetic meshes can be used to improve the performance of downstream audio-visual models.", "url": "https://arxiv.org/abs/2311.18168"}, {"metadata": {"arXiv": "2311.18237", "Date": "Thu, 30 Nov 2023 04:07:44 ", "Title": "Label-efficient Training of Small Task-specific Models by Leveraging Vision Foundation Models", "Authors": ["Raviteja Vemulapalli", "Hadi Pouransari", "Fartash Faghri", "Sachin Mehta", "Mehrdad Farajtabar", "Mohammad Rastegari", "Oncel Tuzel"], "Categories": "cs.CV cs.LG"}, "abstract": "Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit impressive performance on various downstream tasks, especially with limited labeled target data. However, due to their high memory and compute requirements, these models cannot be deployed in resource constrained settings. This raises an important question: How can we utilize the knowledge from a large VFM to train a small task-specific model for a new target task with limited labeled training data? In this work, we answer this question by proposing a simple and highly effective task-oriented knowledge transfer approach to leverage pretrained VFMs for effective training of small task-specific models. Our experimental results on four target tasks under limited labeled data settings show that the proposed knowledge transfer approach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining and supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively. We also show that the dataset used for transferring knowledge has a significant effect on the final target task performance, and propose an image retrieval-based approach for curating effective transfer sets.", "url": "https://arxiv.org/abs/2311.18237"}, {"metadata": {"arXiv": "2311.18257", "Date": "Thu, 30 Nov 2023 05:15:35 ", "Title": "Diffusion Models Without Attention", "Authors": ["Jing Nathan Yan", "Jiatao Gu", "Alexander M. Rush"], "Categories": "cs.CV cs.LG"}, "abstract": "In recent advancements in high-fidelity image generation, Denoising Diffusion Probabilistic Models (DDPMs) have emerged as a key player. However, their application at high resolutions presents significant computational challenges. Current methods, such as patchifying, expedite processes in UNet and Transformer architectures but at the expense of representational capacity. Addressing this, we introduce the Diffusion State Space Model (DiffuSSM), an architecture that supplants attention mechanisms with a more scalable state space model backbone. This approach effectively handles higher resolutions without resorting to global compression, thus preserving detailed image representation throughout the diffusion process. Our focus on FLOP-efficient architectures in diffusion training marks a significant step forward. Comprehensive evaluations on both ImageNet and LSUN datasets at two resolutions demonstrate that DiffuSSMs are on par or even outperform existing diffusion models with attention modules in FID and Inception Score metrics while significantly reducing total FLOP usage.", "url": "https://arxiv.org/abs/2311.18257"}, {"metadata": {"arXiv": "2311.18387", "Date": "Thu, 30 Nov 2023 09:30:15 ", "Title": "On Exact Inversion of DPM-Solvers", "Authors": ["Seongmin Hong", "Kyeonghyun Lee", "Suh Yoon Jeon", "Hyewon Bae", "Se Young Chun"], "Categories": "cs.CV cs.LG", "Comments": ["16 pages"]}, "abstract": "Diffusion probabilistic models (DPMs) are a key component in modern generative models. DPM-solvers have achieved reduced latency and enhanced quality significantly, but have posed challenges to find the exact inverse (i.e., finding the initial noise from the given image). Here we investigate the exact inversions for DPM-solvers and propose algorithms to perform them when samples are generated by the first-order as well as higher-order DPM-solvers. For each explicit denoising step in DPM-solvers, we formulated the inversions using implicit methods such as gradient descent or forward step method to ensure the robustness to large classifier-free guidance unlike the prior approach using fixed-point iteration. Experimental results demonstrated that our proposed exact inversion methods significantly reduced the error of both image and noise reconstructions, greatly enhanced the ability to distinguish invisible watermarks and well prevented unintended background changes consistently during image editing. Project page: \\url{https://smhongok.github.io/inv-dpm.html}.", "url": "https://arxiv.org/abs/2311.18387"}, {"metadata": {"arXiv": "2311.18398", "Date": "Thu, 30 Nov 2023 09:49:16 ", "Title": "RainAI - Precipitation Nowcasting from Satellite Data", "Authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Ira Assent"], "Categories": "cs.CV cs.LG physics.ao-ph"}, "abstract": "This paper presents a solution to the Weather4Cast 2023 competition, where the goal is to forecast high-resolution precipitation with an 8-hour lead time using lower-resolution satellite radiance images. We propose a simple, yet effective method for spatiotemporal feature learning using a 2D U-Net model, that outperforms the official 3D U-Net baseline in both performance and efficiency. We place emphasis on refining the dataset, through importance sampling and dataset preparation, and show that such techniques have a significant impact on performance. We further study an alternative cross-entropy loss function that improves performance over the standard mean squared error loss, while also enabling models to produce probabilistic outputs. Additional techniques are explored regarding the generation of predictions at different lead times, specifically through Conditioning Lead Time. Lastly, to generate high-resolution forecasts, we evaluate standard and learned upsampling methods. The code and trained parameters are available at https://github.com/rafapablos/w4c23-rainai.", "url": "https://arxiv.org/abs/2311.18398"}, {"metadata": {"arXiv": "2311.18512", "Date": "Thu, 30 Nov 2023 12:40:23 ", "Title": "Revisiting Proposal-based Object Detection", "Authors": ["Aritra Bhowmik", "Martin R. Oswald", "Pascal Mettes", "Cees G. M. Snoek"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "7 figures"]}, "abstract": "This paper revisits the pipeline for detecting objects in images with proposals. For any object detector, the obtained box proposals or queries need to be classified and regressed towards ground truth boxes. The common solution for the final predictions is to directly maximize the overlap between each proposal and the ground truth box, followed by a winner-takes-all ranking or non-maximum suppression. In this work, we propose a simple yet effective alternative. For proposal regression, we solve a simpler problem where we regress to the area of intersection between proposal and ground truth. In this way, each proposal only specifies which part contains the object, avoiding a blind inpainting problem where proposals need to be regressed beyond their visual scope. In turn, we replace the winner-takes-all strategy and obtain the final prediction by taking the union over the regressed intersections of a proposal group surrounding an object. Our revisited approach comes with minimal changes to the detection pipeline and can be plugged into any existing method. We show that our approach directly improves canonical object detection and instance segmentation architectures, highlighting the utility of intersection-based regression and grouping.", "url": "https://arxiv.org/abs/2311.18512"}, {"metadata": {"arXiv": "2311.18540", "Date": "Thu, 30 Nov 2023 13:22:15 ", "Title": "Match me if you can: Semantic Correspondence Learning with Unpaired Images", "Authors": ["Jiwon Kim", "Byeongho Heo", "Sangdoo Yun", "Seungryong Kim", "Dongyoon Han"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages"]}, "abstract": "Recent approaches for semantic correspondence have focused on obtaining high-quality correspondences using a complicated network, refining the ambiguous or noisy matching points. Despite their performance improvements, they remain constrained by the limited training pairs due to costly point-level annotations. This paper proposes a simple yet effective method that performs training with unlabeled pairs to complement both limited image pairs and sparse point pairs, requiring neither extra labeled keypoints nor trainable modules. We fundamentally extend the data quantity and variety by augmenting new unannotated pairs not primitively provided as training pairs in benchmarks. Using a simple teacher-student framework, we offer reliable pseudo correspondences to the student network via machine supervision. Finally, the performance of our network is steadily improved by the proposed iterative training, putting back the student as a teacher to generate refined labels and train a new student repeatedly. Our models outperform the milestone baselines, including state-of-the-art methods on semantic correspondence benchmarks.", "url": "https://arxiv.org/abs/2311.18540"}, {"metadata": {"arXiv": "2311.18695", "Date": "Thu, 30 Nov 2023 16:42:24 ", "Title": "Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for 360 Room Layout Reconstruction", "Authors": ["Cheng Sun", "Wei-En Tai", "Yu-Lin Shih", "Kuan-Wei Chen", "Yong-Jing Syu", "Kent Selwyn The", "Yu-Chiang Frank Wang", "Hwann-Tzong Chen"], "Categories": "cs.CV cs.LG"}, "abstract": "State-of-the-art single-view 360-degree room layout reconstruction methods formulate the problem as a high-level 1D (per-column) regression task. On the other hand, traditional low-level 2D layout segmentation is simpler to learn and can represent occluded regions, but it requires complex post-processing for the targeting layout polygon and sacrifices accuracy. We present Seg2Reg to render 1D layout depth regression from the 2D segmentation map in a differentiable and occlusion-aware way, marrying the merits of both sides. Specifically, our model predicts floor-plan density for the input equirectangular 360-degree image. Formulating the 2D layout representation as a density field enables us to employ `flattened' volume rendering to form 1D layout depth regression. In addition, we propose a novel 3D warping augmentation on layout to improve generalization. Finally, we re-implement recent room layout reconstruction methods into our codebase for benchmarking and explore modern backbones and training techniques to serve as the strong baseline. Our model significantly outperforms previous arts. The code will be made available upon publication.", "url": "https://arxiv.org/abs/2311.18695"}, {"metadata": {"arXiv": "2311.18710", "Date": "Thu, 30 Nov 2023 17:02:27 ", "Title": "Meta-Prior: Meta learning for Adaptive Inverse Problem Solvers", "Authors": ["Matthieu Terris", "Thomas Moreau"], "Categories": "cs.CV cs.LG"}, "abstract": "Deep neural networks have become a foundational tool for addressing imaging inverse problems. They are typically trained for a specific task, with a supervised loss to learn a mapping from the observations to the image to recover. However, real-world imaging challenges often lack ground truth data, rendering traditional supervised approaches ineffective. Moreover, for each new imaging task, a new model needs to be trained from scratch, wasting time and resources. To overcome these limitations, we introduce a novel approach based on meta-learning. Our method trains a meta-model on a diverse set of imaging tasks that allows the model to be efficiently fine-tuned for specific tasks with few fine-tuning steps. We show that the proposed method extends to the unsupervised setting, where no ground truth data is available. In its bilevel formulation, the outer level uses a supervised loss, that evaluates how well the fine-tuned model performs, while the inner loss can be either supervised or unsupervised, relying only on the measurement operator. This allows the meta-model to leverage a few ground truth samples for each task while being able to generalize to new imaging tasks. We show that in simple settings, this approach recovers the Bayes optimal estimator, illustrating the soundness of our approach. We also demonstrate our method's effectiveness on various tasks, including image processing and magnetic resonance imaging.", "url": "https://arxiv.org/abs/2311.18710"}, {"metadata": {"arXiv": "2311.18803", "Date": "Thu, 30 Nov 2023 18:49:43 ", "Title": "BIOCLIP: A Vision Foundation Model for the Tree of Life", "Authors": ["Samuel Stevens", "Jiaman Wu", "Matthew J Thompson", "Elizabeth G Campolongo", "Chan Hee Song", "David Edward Carlyn", "Li Dong", "Wasila M Dahdul", "Charles Stewart", "Tanya Berger-Wolf", "Wei-Lun Chao and Yu Su"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["18 pages"]}, "abstract": "Images of the natural world, collected by a variety of cameras, from drones to individual phones, are increasingly abundant sources of biological information. There is an explosion of computational methods and tools, particularly computer vision, for extracting biologically relevant information from images for science and conservation. Yet most of these are bespoke approaches designed for a specific task and are not easily adaptable or extendable to new questions, contexts, and datasets. A vision model for general organismal biology questions on images is of timely need. To approach this, we curate and release TreeOfLife-10M, the largest and most diverse ML-ready dataset of biology images. We then develop BioCLIP, a foundation model for the tree of life, leveraging the unique properties of biology captured by TreeOfLife-10M, namely the abundance and variety of images of plants, animals, and fungi, together with the availability of rich structured biological knowledge. We rigorously benchmark our approach on diverse fine-grained biology classification tasks, and find that BioCLIP consistently and substantially outperforms existing baselines (by 17% to 20% absolute). Intrinsic evaluation reveals that BioCLIP has learned a hierarchical representation conforming to the tree of life, shedding light on its strong generalizability. Our code, models and data will be made available at https://github.com/Imageomics/bioclip.", "url": "https://arxiv.org/abs/2311.18803"}, {"metadata": {"arXiv": "2311.17929", "Date": "Sat, 25 Nov 2023 22:26:58 ", "Title": "New Online Communities: Graph Deep Learning on Anonymous Voting Networks to Identify Sybils in Polycentric Governance", "Authors": ["Quinn DuPont"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "This research examines the polycentric governance of digital assets in Decentralized Autonomous Organizations (DAOs). It offers a theoretical framework and addresses a critical challenge facing decentralized governance by developing a method to identify sybils, or spurious identities. The method uses graph deep learning techniques to identify sybil activity in a DAO governance dataset (snapshot.org). Specifically, a Graph Convolutional Neural Network (GCNN) learned voting behaviours and a fast k-means vector clustering algorithm (FAISS) used the high dimensional embeddings to identify similar nodes in a graph. The results reveal that deep learning can effectively identify sybils, reducing the voting graph by 2-5%. This research underscores the importance of sybil resistance in DAOs and offers a novel perspective on decentralized governance, informing future policy, regulation, and governance practices.", "url": "https://arxiv.org/abs/2311.17929"}, {"metadata": {"arXiv": "2311.17951", "Date": "Wed, 29 Nov 2023 07:11:56 ", "Title": "C3Net: Compound Conditioned ControlNet for Multimodal Content Generation", "Authors": ["Juntao Zhang", "Yuehuai Liu", "Yu-Wing Tai", "Chi-Keung Tang"], "Categories": "cs.LG"}, "abstract": "We present Compound Conditioned ControlNet, C3Net, a novel generative neural architecture taking conditions from multiple modalities and synthesizing multimodal contents simultaneously (e.g., image, text, audio). C3Net adapts the ControlNet architecture to jointly train and make inferences on a production-ready diffusion model and its trainable copies. Specifically, C3Net first aligns the conditions from multi-modalities to the same semantic latent space using modality-specific encoders based on contrastive training. Then, it generates multimodal outputs based on the aligned latent space, whose semantic information is combined using a ControlNet-like architecture called Control C3-UNet. Correspondingly, with this system design, our model offers an improved solution for joint-modality generation through learning and explaining multimodal conditions instead of simply taking linear interpolations on the latent space. Meanwhile, as we align conditions to a unified latent space, C3Net only requires one trainable Control C3-UNet to work on multimodal semantic information. Furthermore, our model employs unimodal pretraining on the condition alignment stage, outperforming the non-pretrained alignment even on relatively scarce training data and thus demonstrating high-quality compound condition generation. We contribute the first high-quality tri-modal validation set to validate quantitatively that C3Net outperforms or is on par with first and contemporary state-of-the-art multimodal generation. Our codes and tri-modal dataset will be released.", "url": "https://arxiv.org/abs/2311.17951"}, {"metadata": {"arXiv": "2311.17956", "Date": "Wed, 29 Nov 2023 08:45:27 ", "Title": "QuadraNet: Improving High-Order Neural Interaction Efficiency with Hardware-Aware Quadratic Neural Networks", "Authors": ["Chenhui Xu", "Fuxun Yu", "Zirui Xu", "Chenchen Liu", "Jinjun Xiong", "Xiang Chen"], "Categories": "cs.LG cs.CV cs.NE", "Comments": ["ASP-DAC 2024 Best Paper Nomination"]}, "abstract": "Recent progress in computer vision-oriented neural network designs is mostly driven by capturing high-order neural interactions among inputs and features. And there emerged a variety of approaches to accomplish this, such as Transformers and its variants. However, these interactions generate a large amount of intermediate state and/or strong data dependency, leading to considerable memory consumption and computing cost, and therefore compromising the overall runtime performance. To address this challenge, we rethink the high-order interactive neural network design with a quadratic computing approach. Specifically, we propose QuadraNet -- a comprehensive model design methodology from neuron reconstruction to structural block and eventually to the overall neural network implementation. Leveraging quadratic neurons' intrinsic high-order advantages and dedicated computation optimization schemes, QuadraNet could effectively achieve optimal cognition and computation performance. Incorporating state-of-the-art hardware-aware neural architecture search and system integration techniques, QuadraNet could also be well generalized in different hardware constraint settings and deployment scenarios. The experiment shows thatQuadraNet achieves up to 1.5$\\times$ throughput, 30% less memory footprint, and similar cognition performance, compared with the state-of-the-art high-order approaches.", "url": "https://arxiv.org/abs/2311.17956"}, {"metadata": {"arXiv": "2311.18025", "Date": "Wed, 29 Nov 2023 19:10:15 ", "Title": "A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets given Small Pilot Data", "Authors": ["Ethan Harvey", "Wansu Chen", "David M. Kent", "and Michael C. Hughes"], "Categories": "cs.LG"}, "abstract": "Practitioners building classifiers often start with a smaller pilot dataset and plan to grow to larger data in the near future. Such projects need a toolkit for extrapolating how much classifier accuracy may improve from a 2x, 10x, or 50x increase in data size. While existing work has focused on finding a single \"best-fit\" curve using various functional forms like power laws, we argue that modeling and assessing the uncertainty of predictions is critical yet has seen less attention. In this paper, we propose a Gaussian process model to obtain probabilistic extrapolations of accuracy or similar performance metrics as dataset size increases. We evaluate our approach in terms of error, likelihood, and coverage across six datasets. Though we focus on medical tasks and image modalities, our open source approach generalizes to any kind of classifier.", "url": "https://arxiv.org/abs/2311.18025"}, {"metadata": {"arXiv": "2311.18035", "Date": "Wed, 29 Nov 2023 19:20:47 ", "Title": "TransOpt: Transformer-based Representation Learning for Optimization Problem Classification", "Authors": ["Gjorgjina Cenikj", "Ga\\v{s}per Petelin", "Tome Eftimov"], "Categories": "cs.LG math.OC"}, "abstract": "We propose a representation of optimization problem instances using a transformer-based neural network architecture trained for the task of problem classification of the 24 problem classes from the Black-box Optimization Benchmarking (BBOB) benchmark. We show that transformer-based methods can be trained to recognize problem classes with accuracies in the range of 70\\%-80\\% for different problem dimensions, suggesting the possible application of transformer architectures in acquiring representations for black-box optimization problems.", "url": "https://arxiv.org/abs/2311.18035"}, {"metadata": {"arXiv": "2311.18048", "Date": "Wed, 29 Nov 2023 19:51:35 ", "Title": "An Interventional Perspective on Identifiability in Gaussian LTI Systems with Independent Component Analysis", "Authors": ["Goutham Rajendran", "Patrik Reizinger", "Wieland Brendel", "Pradeep Ravikumar"], "Categories": "cs.LG cs.CE cs.SY eess.SY stat.ME", "Comments": ["31 pages"]}, "abstract": "We investigate the relationship between system identification and intervention design in dynamical systems. While previous research demonstrated how identifiable representation learning methods, such as Independent Component Analysis (ICA), can reveal cause-effect relationships, it relied on a passive perspective without considering how to collect data. Our work shows that in Gaussian Linear Time-Invariant (LTI) systems, the system parameters can be identified by introducing diverse intervention signals in a multi-environment setting. By harnessing appropriate diversity assumptions motivated by the ICA literature, our findings connect experiment design and representational identifiability in dynamical systems. We corroborate our findings on synthetic and (simulated) physical data. Additionally, we show that Hidden Markov Models, in general, and (Gaussian) LTI systems, in particular, fulfil a generalization of the Causal de Finetti theorem with continuous parameters.", "url": "https://arxiv.org/abs/2311.18048"}, {"metadata": {"arXiv": "2311.18061", "Date": "Wed, 29 Nov 2023 20:13:32 ", "Title": "TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural Architecture Search in Time Series Anomaly Detection", "Authors": ["Ijaz Ul Haq", "Byung Suk Lee"], "Categories": "cs.LG cs.NE", "Comments": ["32 pages ", "4 figures", "It will submitted to a journal"]}, "abstract": "The surge in real-time data collection across various industries has underscored the need for advanced anomaly detection in both univariate and multivariate time series data. Traditional methods, while comprehensive, often struggle to capture the complex interdependencies in such data. This paper introduces TransNAS-TSAD, a novel framework that synergizes transformer architecture with neural architecture search (NAS), enhanced through NSGA-II algorithm optimization. This innovative approach effectively tackles the complexities of both univariate and multivariate time series, balancing computational efficiency with detection accuracy. Our evaluation reveals that TransNAS-TSAD surpasses conventional anomaly detection models, demonstrating marked improvements in diverse data scenarios. We also propose the Efficiency-Accuracy-Complexity Score (EACS) as a new metric for assessing model performance, emphasizing the crucial balance between accuracy and computational resources. TransNAS-TSAD sets a new benchmark in time series anomaly detection, offering a versatile, efficient solution for complex real-world applications. This research paves the way for future developments in the field, highlighting its potential in a wide range of industry applications.", "url": "https://arxiv.org/abs/2311.18061"}, {"metadata": {"arXiv": "2311.18072", "Date": "Wed, 29 Nov 2023 20:36:35 ", "Title": "Self-Supervised Learning for Large-Scale Preventive Security Constrained DC Optimal Power Flow", "Authors": ["Seonho Park and Pascal Van Hentenryck"], "Categories": "cs.LG math.OC", "Comments": ["Submitted to IEEE Transactions on Power Systems"]}, "abstract": "Security-Constrained Optimal Power Flow (SCOPF) plays a crucial role in power grid stability but becomes increasingly complex as systems grow. This paper introduces PDL-SCOPF, a self-supervised end-to-end primal-dual learning framework for producing near-optimal solutions to large-scale SCOPF problems in milliseconds. Indeed, PDL-SCOPF remedies the limitations of supervised counterparts that rely on training instances with their optimal solutions, which becomes impractical for large-scale SCOPF problems. PDL-SCOPF mimics an Augmented Lagrangian Method (ALM) for training primal and dual networks that learn the primal solutions and the Lagrangian multipliers, respectively, to the unconstrained optimizations. In addition, PDL-SCOPF incorporates a repair layer to ensure the feasibility of the power balance in the nominal case, and a binary search layer to compute, using the Automatic Primary Response (APR), the generator dispatches in the contingencies. The resulting differentiable program can then be trained end-to-end using the objective function of the SCOPF and the power balance constraints of the contingencies. Experimental results demonstrate that the PDL-SCOPF delivers accurate feasible solutions with minimal optimality gaps. The framework underlying PDL-SCOPF aims at bridging the gap between traditional optimization methods and machine learning, highlighting the potential of self-supervised end-to-end primal-dual learning for large-scale optimization tasks.", "url": "https://arxiv.org/abs/2311.18072"}, {"metadata": {"arXiv": "2311.18078", "Date": "Wed, 29 Nov 2023 20:47:47 ", "Title": "The Forecastability of Underlying Building Electricity Demand from Time Series Data", "Authors": ["Mohamad Khalil", "A. Stephen McGough", "Hussain Kazmi", "Sara Walker"], "Categories": "cs.LG"}, "abstract": "Forecasting building energy consumption has become a promising solution in Building Energy Management Systems for energy saving and optimization. Furthermore, it can play an important role in the efficient management of the operation of a smart grid. Different data-driven approaches to forecast the future energy demand of buildings at different scale, and over various time horizons, can be found in the scientific literature, including extensive Machine Learning and Deep Learning approaches. However, the identification of the most accurate forecaster model which can be utilized to predict the energy demand of such a building is still challenging.In this paper, the design and implementation of a data-driven approach to predict how forecastable the future energy demand of a building is, without first utilizing a data-driven forecasting model, is presented. The investigation utilizes a historical electricity consumption time series data set with a half-hour interval that has been collected from a group of residential buildings located in the City of London, United Kingdom", "url": "https://arxiv.org/abs/2311.18078"}, {"metadata": {"arXiv": "2311.18098", "Date": "Wed, 29 Nov 2023 21:31:59 ", "Title": "Adaptive Early Exiting for Collaborative Inference over Noisy Wireless Channels", "Authors": ["Mikolaj Jankowski", "Deniz Gunduz", "Krystian Mikolajczyk"], "Categories": "cs.LG cs.IT cs.NI math.IT"}, "abstract": "Collaborative inference systems are one of the emerging solutions for deploying deep neural networks (DNNs) at the wireless network edge. Their main idea is to divide a DNN into two parts, where the first is shallow enough to be reliably executed at edge devices of limited computational power, while the second part is executed at an edge server with higher computational capabilities. The main advantage of such systems is that the input of the DNN gets compressed as the subsequent layers of the shallow part extract only the information necessary for the task. As a result, significant communication savings can be achieved compared to transmitting raw input samples. In this work, we study early exiting in the context of collaborative inference, which allows obtaining inference results at the edge device for certain samples, without the need to transmit the partially processed data to the edge server at all, leading to further communication savings. The central part of our system is the transmission-decision (TD) mechanism, which, given the information from the early exit, and the wireless channel conditions, decides whether to keep the early exit prediction or transmit the data to the edge server for further processing. In this paper, we evaluate various TD mechanisms and show experimentally, that for an image classification task over the wireless edge, proper utilization of early exits can provide both performance gains and significant communication savings.", "url": "https://arxiv.org/abs/2311.18098"}, {"metadata": {"arXiv": "2311.18129", "Date": "Wed, 29 Nov 2023 22:43:40 ", "Title": "Mixed-Precision Quantization for Federated Learning on Resource-Constrained Heterogeneous Devices", "Authors": ["Huancheng Chen and Haris Vikalo"], "Categories": "cs.LG cs.DC"}, "abstract": "While federated learning (FL) systems often utilize quantization to battle communication and computational bottlenecks, they have heretofore been limited to deploying fixed-precision quantization schemes. Meanwhile, the concept of mixed-precision quantization (MPQ), where different layers of a deep learning model are assigned varying bit-width, remains unexplored in the FL settings. We present a novel FL algorithm, FedMPQ, which introduces mixed-precision quantization to resource-heterogeneous FL systems. Specifically, local models, quantized so as to satisfy bit-width constraint, are trained by optimizing an objective function that includes a regularization term which promotes reduction of precision in some of the layers without significant performance degradation. The server collects local model updates, de-quantizes them into full-precision models, and then aggregates them into a global model. To initialize the next round of local training, the server relies on the information learned in the previous training round to customize bit-width assignments of the models delivered to different clients. In extensive benchmarking experiments on several model architectures and different datasets in both iid and non-iid settings, FedMPQ outperformed the baseline FL schemes that utilize fixed-precision quantization while incurring only a minor computational overhead on the participating devices.", "url": "https://arxiv.org/abs/2311.18129"}, {"metadata": {"arXiv": "2311.18130", "Date": "Wed, 29 Nov 2023 22:44:32 ", "Title": "The Trifecta: Three simple techniques for training deeper Forward-Forward networks", "Authors": ["Thomas Dooms", "Ing Jyh Tsang", "Jose Oramas"], "Categories": "cs.LG cs.CV", "MSC-class": "68T07"}, "abstract": "Modern machine learning models are able to outperform humans on a variety of non-trivial tasks. However, as the complexity of the models increases, they consume significant amounts of power and still struggle to generalize effectively to unseen data. Local learning, which focuses on updating subsets of a model's parameters at a time, has emerged as a promising technique to address these issues. Recently, a novel local learning algorithm, called Forward-Forward, has received widespread attention due to its innovative approach to learning. Unfortunately, its application has been limited to smaller datasets due to scalability issues. To this end, we propose The Trifecta, a collection of three simple techniques that synergize exceptionally well and drastically improve the Forward-Forward algorithm on deeper networks. Our experiments demonstrate that our models are on par with similarly structured, backpropagation-based models in both training speed and test accuracy on simple datasets. This is achieved by the ability to learn representations that are informative locally, on a layer-by-layer basis, and retain their informativeness when propagated to deeper layers in the architecture. This leads to around 84\\% accuracy on CIFAR-10, a notable improvement (25\\%) over the original FF algorithm. These results highlight the potential of Forward-Forward as a genuine competitor to backpropagation and as a promising research avenue.", "url": "https://arxiv.org/abs/2311.18130"}, {"metadata": {"arXiv": "2311.18177", "Date": "Thu, 30 Nov 2023 01:48:42 ", "Title": "An Effective Universal Polynomial Basis for Spectral Graph Neural Networks", "Authors": ["Keke Huang", "Pietro Li\\`o"], "Categories": "cs.LG cs.SI eess.SP"}, "abstract": "Spectral Graph Neural Networks (GNNs), also referred to as graph filters have gained increasing prevalence for heterophily graphs. Optimal graph filters rely on Laplacian eigendecomposition for Fourier transform. In an attempt to avert the prohibitive computations, numerous polynomial filters by leveraging distinct polynomials have been proposed to approximate the desired graph filters. However, polynomials in the majority of polynomial filters are predefined and remain fixed across all graphs, failing to accommodate the diverse heterophily degrees across different graphs. To tackle this issue, we first investigate the correlation between polynomial bases of desired graph filters and the degrees of graph heterophily via a thorough theoretical analysis. Afterward, we develop an adaptive heterophily basis by incorporating graph heterophily degrees. Subsequently, we integrate this heterophily basis with the homophily basis, creating a universal polynomial basis UniBasis. In consequence, we devise a general polynomial filter UniFilter. Comprehensive experiments on both real-world and synthetic datasets with varying heterophily degrees significantly support the superiority of UniFilter, demonstrating the effectiveness and generality of UniBasis, as well as its promising capability as a new method for graph analysis.", "url": "https://arxiv.org/abs/2311.18177"}, {"metadata": {"arXiv": "2311.18194", "Date": "Thu, 30 Nov 2023 02:26:55 ", "Title": "Positional Information Matters for Invariant In-Context Learning: A Case Study of Simple Function Classes", "Authors": ["Yongqiang Chen", "Binghui Xie", "Kaiwen Zhou", "Bo Han", "Yatao Bian", "James Cheng"], "Categories": "cs.LG cs.CL", "Comments": ["Ongoing work; preliminary version"]}, "abstract": "In-context learning (ICL) refers to the ability of a model to condition on a few in-context demonstrations (input-output examples of the underlying task) to generate the answer for a new query input, without updating parameters. Despite the impressive ICL ability of LLMs, it has also been found that ICL in LLMs is sensitive to input demonstrations and limited to short context lengths. To understand the limitations and principles for successful ICL, we conduct an investigation with ICL linear regression of transformers. We characterize several Out-of-Distribution (OOD) cases for ICL inspired by realistic LLM ICL failures and compare transformers with DeepSet, a simple yet powerful architecture for ICL. Surprisingly, DeepSet outperforms transformers across a variety of distribution shifts, implying that preserving permutation invariance symmetry to input demonstrations is crucial for OOD ICL. The phenomenon specifies a fundamental requirement by ICL, which we termed as ICL invariance. Nevertheless, the positional encodings in LLMs will break ICL invariance. To this end, we further evaluate transformers with identical positional encodings and find preserving ICL invariance in transformers achieves state-of-the-art performance across various ICL distribution shifts", "url": "https://arxiv.org/abs/2311.18194"}, {"metadata": {"arXiv": "2311.18208", "Date": "Thu, 30 Nov 2023 03:05:14 ", "Title": "SMaRt: Improving GANs with Score Matching Regularity", "Authors": ["Mengfei Xia", "Yujun Shen", "Ceyuan Yang", "Ran Yi", "Wenping Wang", "Yong-jin Liu"], "Categories": "cs.LG cs.CV"}, "abstract": "Generative adversarial networks (GANs) usually struggle in learning from highly diverse data, whose underlying manifold is complex. In this work, we revisit the mathematical foundations of GANs, and theoretically reveal that the native adversarial loss for GAN training is insufficient to fix the problem of subsets with positive Lebesgue measure of the generated data manifold lying out of the real data manifold. Instead, we find that score matching serves as a valid solution to this issue thanks to its capability of persistently pushing the generated data points towards the real data manifold. We thereby propose to improve the optimization of GANs with score matching regularity (SMaRt). Regarding the empirical evidences, we first design a toy example to show that training GANs by the aid of a ground-truth score function can help reproduce the real data distribution more accurately, and then confirm that our approach can consistently boost the synthesis performance of various state-of-the-art GANs on real-world datasets with pre-trained diffusion models acting as the approximate score function. For instance, when training Aurora on the ImageNet 64x64 dataset, we manage to improve FID from 8.87 to 7.11, on par with the performance of one-step consistency model. The source code will be made public.", "url": "https://arxiv.org/abs/2311.18208"}, {"metadata": {"arXiv": "2311.18246", "Date": "Thu, 30 Nov 2023 04:36:25 ", "Title": "Combined Scheduling, Memory Allocation and Tensor Replacement for Minimizing Off-Chip Data Accesses of DNN Accelerators", "Authors": ["Yi Li", "Aarti Gupta", "Sharad Malik"], "Categories": "cs.LG cs.AR"}, "abstract": "Specialized hardware accelerators have been extensively used for Deep Neural Networks (DNNs) to provide power/performance benefits. These accelerators contain specialized hardware that supports DNN operators, and scratchpad memory for storing the tensor operands. Often, the size of the scratchpad is insufficient to store all the tensors needed for the computation, and additional data accesses are needed to move tensors back and forth from host memory during the computation with significant power/performance overhead. The volume of these additional data accesses depends on the operator schedule, and memory allocation (specific locations selected for the tensors in the scratchpad). We propose an optimization framework, named COSMA, for mapping DNNs to an accelerator that finds the optimal operator schedule, memory allocation and tensor replacement that minimizes the additional data accesses. COSMA provides an Integer Linear Programming (ILP) formulation to generate the optimal solution for mapping a DNN to the accelerator for a given scratchpad size. We demonstrate that, using an off-the-shelf ILP solver, COSMA obtains the optimal solution in seconds for a wide-range of state-of-the-art DNNs for different applications. Further, it out-performs existing methods by reducing on average 84% of the non-compulsory data accesses. We further propose a divide-and-conquer heuristic to scale up to certain complex DNNs generated by Neural Architecture Search, and this heuristic solution reduces on average 85% data accesses compared with other works.", "url": "https://arxiv.org/abs/2311.18246"}, {"metadata": {"arXiv": "2311.18307", "Date": "Thu, 30 Nov 2023 07:25:24 ", "Title": "Categorical Traffic Transformer: Interpretable and Diverse Behavior Prediction with Tokenized Latent", "Authors": ["Yuxiao Chen", "Sander Tonkens", "and Marco Pavone"], "Categories": "cs.LG cs.CV cs.RO"}, "abstract": "Adept traffic models are critical to both planning and closed-loop simulation for autonomous vehicles (AV), and key design objectives include accuracy, diverse multimodal behaviors, interpretability, and downstream compatibility. Recently, with the advent of large language models (LLMs), an additional desirable feature for traffic models is LLM compatibility. We present Categorical Traffic Transformer (CTT), a traffic model that outputs both continuous trajectory predictions and tokenized categorical predictions (lane modes, homotopies, etc.). The most outstanding feature of CTT is its fully interpretable latent space, which enables direct supervision of the latent variable from the ground truth during training and avoids mode collapse completely. As a result, CTT can generate diverse behaviors conditioned on different latent modes with semantic meanings while beating SOTA on prediction accuracy. In addition, CTT's ability to input and output tokens enables integration with LLMs for common-sense reasoning and zero-shot generalization.", "url": "https://arxiv.org/abs/2311.18307"}, {"metadata": {"arXiv": "2311.18341", "Date": "Thu, 30 Nov 2023 08:22:08 ", "Title": "Learning Robust Precipitation Forecaster by Temporal Frame Interpolation", "Authors": ["Lu Han", "Xu-Yang Chen", "Han-Jia Ye", "De-Chuan Zhan"], "Categories": "cs.LG physics.ao-ph", "Comments": ["arXiv admin note: text overlap with arXiv:2212.02968 by other authors"]}, "abstract": "Recent advancements in deep learning have propelled the field of weather prediction models to new heights. Despite their progress, these models often struggle with real-world application due to their sensitivity to spatial-temporal shifts, a vulnerability particularly pronounced in weather prediction tasks where overfitting to local and temporal variations is common. This paper presents an investigation into the development of a robust precipitation forecasting model that stands resilient to such shifts. We introduce Temporal Frame Interpolation (TFI), an innovative technique designed to fortify forecasting models against spatial-temporal discrepancies. TFI operates by generating synthetic samples through the interpolation of adjacent frames from satellite imagery and ground radar data, thereby enriching the training dataset and bolstering the model's defense against noise on frames. Additionally, we integrate a novel multi-level dice loss, which exploits the ordinal nature of rainfall intensities to further refine model performance. These methodologies have collectively advanced our model's forecasting precision, achieving \\textit{1st place} on the transfer learning leaderboard in the \\textit{Weather4Cast'23 competition}.It not only demonstrates the efficacy of our approaches but also sets a new benchmark for deep learning applications in meteorological forecasting. Our code and weights have been public on \\url{https://github.com/Secilia-Cxy/UNetTFI}.", "url": "https://arxiv.org/abs/2311.18341"}, {"metadata": {"arXiv": "2311.18356", "Date": "Thu, 30 Nov 2023 08:54:32 ", "Title": "Towards Comparable Active Learning", "Authors": ["Thorben Werner", "Johannes Burchert", "Lars Schmidt-Thieme"], "Categories": "cs.LG stat.ML"}, "abstract": "Active Learning has received significant attention in the field of machine learning for its potential in selecting the most informative samples for labeling, thereby reducing data annotation costs. How- ever, we show that the reported lifts in recent literature generalize poorly to other domains leading to an inconclusive landscape in Active Learning research. Furthermore, we highlight overlooked prob- lems for reproducing AL experiments that can lead to unfair comparisons and increased variance in the results. This paper addresses these issues by providing an Active Learning framework for a fair comparison of algorithms across different tasks and domains, as well as a fast and performant oracle algorithm for evaluation. To the best of our knowledge, we propose the first AL benchmark that tests algorithms in 3 major domains: Tabular, Image, and Text. We report empirical results for 6 widely used algorithms on 7 real-world and 2 synthetic datasets and aggregate them into a domain-specific ranking of AL algorithms.", "url": "https://arxiv.org/abs/2311.18356"}, {"metadata": {"arXiv": "2311.18393", "Date": "Thu, 30 Nov 2023 09:38:59 ", "Title": "Data-efficient Deep Reinforcement Learning for Vehicle Trajectory Control", "Authors": ["Bernd Frauenknecht", "Tobias Ehlgen and Sebastian Trimpe"], "Categories": "cs.LG cs.RO"}, "abstract": "Advanced vehicle control is a fundamental building block in the development of autonomous driving systems. Reinforcement learning (RL) promises to achieve control performance superior to classical approaches while keeping computational demands low during deployment. However, standard RL approaches like soft-actor critic (SAC) require extensive amounts of training data to be collected and are thus impractical for real-world application. To address this issue, we apply recently developed data-efficient deep RL methods to vehicle trajectory control. Our investigation focuses on three methods, so far unexplored for vehicle control: randomized ensemble double Q-learning (REDQ), probabilistic ensembles with trajectory sampling and model predictive path integral optimizer (PETS-MPPI), and model-based policy optimization (MBPO). We find that in the case of trajectory control, the standard model-based RL formulation used in approaches like PETS-MPPI and MBPO is not suitable. We, therefore, propose a new formulation that splits dynamics prediction and vehicle localization. Our benchmark study on the CARLA simulator reveals that the three identified data-efficient deep RL approaches learn control strategies on a par with or better than SAC, yet reduce the required number of environment interactions by more than one order of magnitude.", "url": "https://arxiv.org/abs/2311.18393"}, {"metadata": {"arXiv": "2311.18434", "Date": "Thu, 30 Nov 2023 10:34:29 ", "Title": "Exploring the Temperature-Dependent Phase Transition in Modern Hopfield Networks", "Authors": ["Felix Koulischer", "C\\'edric Goemaere", "Tom van der Meersch", "Johannes Deleu", "Thomas Demeester"], "Categories": "cs.LG cond-mat.dis-nn", "Comments": ["Accepted as poster for Associative Memory and Hopfield Networks workshop at NeurIPS23"]}, "abstract": "The recent discovery of a connection between Transformers and Modern Hopfield Networks (MHNs) has reignited the study of neural networks from a physical energy-based perspective. This paper focuses on the pivotal effect of the inverse temperature hyperparameter $\\beta$ on the distribution of energy minima of the MHN. To achieve this, the distribution of energy minima is tracked in a simplified MHN in which equidistant normalised patterns are stored. This network demonstrates a phase transition at a critical temperature $\\beta_{\\text{c}}$, from a single global attractor towards highly pattern specific minima as $\\beta$ is increased. Importantly, the dynamics are not solely governed by the hyperparameter $\\beta$ but are instead determined by an effective inverse temperature $\\beta_{\\text{eff}}$ which also depends on the distribution and size of the stored patterns. Recognizing the role of hyperparameters in the MHN could, in the future, aid researchers in the domain of Transformers to optimise their initial choices, potentially reducing the necessity for time and energy expensive hyperparameter fine-tuning.", "url": "https://arxiv.org/abs/2311.18434"}, {"metadata": {"arXiv": "2311.18437", "Date": "Thu, 30 Nov 2023 10:37:03 ", "Title": "The Sliding Regret in Stochastic Bandits: Discriminating Index and Randomized Policies", "Authors": ["Victor Boone"], "Categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "Comments": ["31 pages"]}, "abstract": "This paper studies the one-shot behavior of no-regret algorithms for stochastic bandits. Although many algorithms are known to be asymptotically optimal with respect to the expected regret, over a single run, their pseudo-regret seems to follow one of two tendencies: it is either smooth or bumpy. To measure this tendency, we introduce a new notion: the sliding regret, that measures the worst pseudo-regret over a time-window of fixed length sliding to infinity. We show that randomized methods (e.g. Thompson Sampling and MED) have optimal sliding regret, while index policies, although possibly asymptotically optimal for the expected regret, have the worst possible sliding regret under regularity conditions on their index (e.g. UCB, UCB-V, KL-UCB, MOSS, IMED etc.). We further analyze the average bumpiness of the pseudo-regret of index policies via the regret of exploration, that we show to be suboptimal as well.", "url": "https://arxiv.org/abs/2311.18437"}, {"metadata": {"arXiv": "2311.18451", "Date": "Thu, 30 Nov 2023 10:51:46 ", "Title": "How Much Is Hidden in the NAS Benchmarks? Few-Shot Adaptation of a NAS Predictor", "Authors": ["Hrushikesh Loya", "{\\L}ukasz Dudziak", "Abhinav Mehrotra", "Royson Lee", "Javier Fernandez-Marques", "Nicholas D. Lane", "Hongkai Wen"], "Categories": "cs.LG"}, "abstract": "Neural architecture search has proven to be a powerful approach to designing and refining neural networks, often boosting their performance and efficiency over manually-designed variations, but comes with computational overhead. While there has been a considerable amount of research focused on lowering the cost of NAS for mainstream tasks, such as image classification, a lot of those improvements stem from the fact that those tasks are well-studied in the broader context. Consequently, applicability of NAS to emerging and under-represented domains is still associated with a relatively high cost and/or uncertainty about the achievable gains. To address this issue, we turn our focus towards the recent growth of publicly available NAS benchmarks in an attempt to extract general NAS knowledge, transferable across different tasks and search spaces. We borrow from the rich field of meta-learning for few-shot adaptation and carefully study applicability of those methods to NAS, with a special focus on the relationship between task-level correlation (domain shift) and predictor transferability; which we deem critical for improving NAS on diverse tasks. In our experiments, we use 6 NAS benchmarks in conjunction, spanning in total 16 NAS settings -- our meta-learning approach not only shows superior (or matching) performance in the cross-validation experiments but also successful extrapolation to a new search space and tasks.", "url": "https://arxiv.org/abs/2311.18451"}, {"metadata": {"arXiv": "2311.18495", "Date": "Thu, 30 Nov 2023 12:15:49 ", "Title": "Improving Adversarial Transferability via Model Alignment", "Authors": ["Avery Ma", "Amir-massoud Farahmand", "Yangchen Pan", "Philip Torr", "Jindong Gu"], "Categories": "cs.LG cs.CV"}, "abstract": "Neural networks are susceptible to adversarial perturbations that are transferable across different models. In this paper, we introduce a novel model alignment technique aimed at improving a given source model's ability in generating transferable adversarial perturbations. During the alignment process, the parameters of the source model are fine-tuned to minimize an alignment loss. This loss measures the divergence in the predictions between the source model and another, independently trained model, referred to as the witness model. To understand the effect of model alignment, we conduct a geometric anlaysis of the resulting changes in the loss landscape. Extensive experiments on the ImageNet dataset, using a variety of model architectures, demonstrate that perturbations generated from aligned source models exhibit significantly higher transferability than those from the original source model.", "url": "https://arxiv.org/abs/2311.18495"}, {"metadata": {"arXiv": "2311.18498", "Date": "Thu, 30 Nov 2023 12:19:10 ", "Title": "Data-Agnostic Model Poisoning against Federated Learning: A Graph Autoencoder Approach", "Authors": ["Kai Li", "Jingjing Zheng", "Xin Yuan", "Wei Ni", "Ozgur B. Akan", "H. Vincent Poor"], "Categories": "cs.LG cs.CR", "Comments": ["15 pages", "10 figures", "submitted to IEEE Transactions on Information Forensics and Security (TIFS)"]}, "abstract": "This paper proposes a novel, data-agnostic, model poisoning attack on Federated Learning (FL), by designing a new adversarial graph autoencoder (GAE)-based framework. The attack requires no knowledge of FL training data and achieves both effectiveness and undetectability. By listening to the benign local models and the global model, the attacker extracts the graph structural correlations among the benign local models and the training data features substantiating the models. The attacker then adversarially regenerates the graph structural correlations while maximizing the FL training loss, and subsequently generates malicious local models using the adversarial graph structure and the training data features of the benign ones. A new algorithm is designed to iteratively train the malicious local models using GAE and sub-gradient descent. The convergence of FL under attack is rigorously proved, with a considerably large optimality gap. Experiments show that the FL accuracy drops gradually under the proposed attack and existing defense mechanisms fail to detect it. The attack can give rise to an infection across all benign devices, making it a serious threat to FL.", "url": "https://arxiv.org/abs/2311.18498"}, {"metadata": {"arXiv": "2311.18521", "Date": "Thu, 30 Nov 2023 12:55:51 ", "Title": "Combining deep generative models with extreme value theory for synthetic hazard simulation: a multivariate and spatially coherent approach", "Authors": ["Alison Peard", "Jim Hall"], "Categories": "cs.LG", "Comments": ["Accepted at NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning (CCAI)"]}, "abstract": "Climate hazards can cause major disasters when they occur simultaneously as compound hazards. To understand the distribution of climate risk and inform adaptation policies, scientists need to simulate a large number of physically realistic and spatially coherent events. Current methods are limited by computational constraints and the probabilistic spatial distribution of compound events is not given sufficient attention. The bottleneck in current approaches lies in modelling the dependence structure between variables, as inference on parametric models suffers from the curse of dimensionality. Generative adversarial networks (GANs) are well-suited to such a problem due to their ability to implicitly learn the distribution of data in high-dimensional settings. We employ a GAN to model the dependence structure for daily maximum wind speed, significant wave height, and total precipitation over the Bay of Bengal, combining this with traditional extreme value theory for controlled extrapolation of the tails. Once trained, the model can be used to efficiently generate thousands of realistic compound hazard events, which can inform climate risk assessments for climate adaptation and disaster preparedness. The method developed is flexible and transferable to other multivariate and spatial climate datasets.", "url": "https://arxiv.org/abs/2311.18521"}, {"metadata": {"arXiv": "2311.18526", "Date": "Thu, 30 Nov 2023 13:05:39 ", "Title": "HOT: Higher-Order Dynamic Graph Representation Learning with Efficient Transformers", "Authors": ["Maciej Besta", "Afonso Claudino Catarino", "Lukas Gianinazzi", "Nils Blach", "Piotr Nyczyk", "Hubert Niewiadomski", "Torsten Hoefler"], "Categories": "cs.LG cs.SI", "Journal-ref": "Proceedings of Learning on Graphs (LOG), 2023"}, "abstract": "Many graph representation learning (GRL) problems are dynamic, with millions of edges added or removed per second. A fundamental workload in this setting is dynamic link prediction: using a history of graph updates to predict whether a given pair of vertices will become connected. Recent schemes for link prediction in such dynamic settings employ Transformers, modeling individual graph updates as single tokens. In this work, we propose HOT: a model that enhances this line of works by harnessing higher-order (HO) graph structures; specifically, k-hop neighbors and more general subgraphs containing a given pair of vertices. Harnessing such HO structures by encoding them into the attention matrix of the underlying Transformer results in higher accuracy of link prediction outcomes, but at the expense of increased memory pressure. To alleviate this, we resort to a recent class of schemes that impose hierarchy on the attention matrix, significantly reducing memory footprint. The final design offers a sweetspot between high accuracy and low memory utilization. HOT outperforms other dynamic GRL schemes, for example achieving 9%, 7%, and 15% higher accuracy than - respectively - DyGFormer, TGN, and GraphMixer, for the MOOC dataset. Our design can be seamlessly extended towards other dynamic GRL workloads.", "url": "https://arxiv.org/abs/2311.18526"}, {"metadata": {"arXiv": "2311.18553", "Date": "Thu, 30 Nov 2023 13:46:05 ", "Title": "Heterogeneous Graph-based Trajectory Prediction using Local Map Context and Social Interactions", "Authors": ["Daniel Grimm", "Maximilian Zipfl", "Felix Hertlein", "Alexander Naumann", "J\\\"urgen L\\\"uttin", "Steffen Thoma", "Stefan Schmid", "Lavdim Halilaj", "Achim Rettinger", "J. Marius Z\\\"ollner"], "Categories": "cs.LG cs.CV cs.RO", "Comments": ["Accepted on IEEE ITSC 2023"]}, "abstract": "Precisely predicting the future trajectories of surrounding traffic participants is a crucial but challenging problem in autonomous driving, due to complex interactions between traffic agents, map context and traffic rules. Vector-based approaches have recently shown to achieve among the best performances on trajectory prediction benchmarks. These methods model simple interactions between traffic agents but don't distinguish between relation-type and attributes like their distance along the road. Furthermore, they represent lanes only by sequences of vectors representing center lines and ignore context information like lane dividers and other road elements. We present a novel approach for vector-based trajectory prediction that addresses these shortcomings by leveraging three crucial sources of information: First, we model interactions between traffic agents by a semantic scene graph, that accounts for the nature and important features of their relation. Second, we extract agent-centric image-based map features to model the local map context. Finally, we generate anchor paths to enforce the policy in multi-modal prediction to permitted trajectories only. Each of these three enhancements shows advantages over the baseline model HoliGraph.", "url": "https://arxiv.org/abs/2311.18553"}, {"metadata": {"arXiv": "2311.18557", "Date": "Thu, 30 Nov 2023 13:48:50 ", "Title": "Can semi-supervised learning use all the data effectively? A lower bound perspective", "Authors": ["Alexandru \\c{T}ifrea", "Gizem Y\\\"uce", "Amartya Sanyal", "Fanny Yang"], "Categories": "cs.LG stat.ML", "Comments": ["Published in Advances in Neural Information Processing Systems 2023"]}, "abstract": "Prior works have shown that semi-supervised learning algorithms can leverage unlabeled data to improve over the labeled sample complexity of supervised learning (SL) algorithms. However, existing theoretical analyses focus on regimes where the unlabeled data is sufficient to learn a good decision boundary using unsupervised learning (UL) alone. This begs the question: Can SSL algorithms simultaneously improve upon both UL and SL? To this end, we derive a tight lower bound for 2-Gaussian mixture models that explicitly depends on the labeled and the unlabeled dataset size as well as the signal-to-noise ratio of the mixture distribution. Surprisingly, our result implies that no SSL algorithm can improve upon the minimax-optimal statistical error rates of SL or UL algorithms for these distributions. Nevertheless, we show empirically on real-world data that SSL algorithms can still outperform UL and SL methods. Therefore, our work suggests that, while proving performance gains for SSL algorithms is possible, it requires careful tracking of constants.", "url": "https://arxiv.org/abs/2311.18557"}, {"metadata": {"arXiv": "2311.18559", "Date": "Thu, 30 Nov 2023 13:50:38 ", "Title": "FediOS: Decoupling Orthogonal Subspaces for Personalization in Feature-skew Federated Learning", "Authors": ["Lingzhi Gao", "Zexi Li", "Yang Lu", "Chao Wu"], "Categories": "cs.LG cs.CV"}, "abstract": "Personalized federated learning (pFL) enables collaborative training among multiple clients to enhance the capability of customized local models. In pFL, clients may have heterogeneous (also known as non-IID) data, which poses a key challenge in how to decouple the data knowledge into generic knowledge for global sharing and personalized knowledge for preserving local personalization. A typical way of pFL focuses on label distribution skew, and they adopt a decoupling scheme where the model is split into a common feature extractor and two prediction heads (generic and personalized). However, such a decoupling scheme cannot solve the essential problem of feature skew heterogeneity, because a common feature extractor cannot decouple the generic and personalized features. Therefore, in this paper, we rethink the architecture decoupling design for feature-skew pFL and propose an effective pFL method called FediOS. In FediOS, we reformulate the decoupling into two feature extractors (generic and personalized) and one shared prediction head. Orthogonal projections are used for clients to map the generic features into one common subspace and scatter the personalized features into different subspaces to achieve decoupling for them. In addition, a shared prediction head is trained to balance the importance of generic and personalized features during inference. Extensive experiments on four vision datasets demonstrate our method reaches state-of-the-art pFL performances under feature skew heterogeneity.", "url": "https://arxiv.org/abs/2311.18559"}, {"metadata": {"arXiv": "2311.18575", "Date": "Thu, 30 Nov 2023 14:14:31 ", "Title": "Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations", "Authors": ["Yuli Slavutsky and Yuval Benjamini"], "Categories": "cs.LG"}, "abstract": "Distribution shifts between training and deployment data often affect the performance of machine learning models. In this paper, we explore a setting where a hidden variable induces a shift in the distribution of classes. These distribution shifts are particularly challenging for zero-shot classifiers, as they rely on representations learned from training classes, but are deployed on new, unseen ones. We introduce an algorithm to learn data representations that are robust to such class distribution shifts in zero-shot verification tasks. We show that our approach, which combines hierarchical data sampling with out-of-distribution generalization techniques, improves generalization to diverse class distributions in both simulations and real-world datasets.", "url": "https://arxiv.org/abs/2311.18575"}, {"metadata": {"arXiv": "2311.18684", "Date": "Thu, 30 Nov 2023 16:31:04 ", "Title": "Handling Cost and Constraints with Off-Policy Deep Reinforcement Learning", "Authors": ["Jared Markowitz", "Jesse Silverberg", "Gary Collins"], "Categories": "cs.LG", "Comments": ["22 pages", "16 figures"]}, "abstract": "By reusing data throughout training, off-policy deep reinforcement learning algorithms offer improved sample efficiency relative to on-policy approaches. For continuous action spaces, the most popular methods for off-policy learning include policy improvement steps where a learned state-action ($Q$) value function is maximized over selected batches of data. These updates are often paired with regularization to combat associated overestimation of $Q$ values. With an eye toward safety, we revisit this strategy in environments with \"mixed-sign\" reward functions; that is, with reward functions that include independent positive (incentive) and negative (cost) terms. This setting is common in real-world applications, and may be addressed with or without constraints on the cost terms. We find the combination of function approximation and a term that maximizes $Q$ in the policy update to be problematic in such environments, because systematic errors in value estimation impact the contributions from the competing terms asymmetrically. This results in overemphasis of either incentives or costs and may severely limit learning. We explore two remedies to this issue. First, consistent with prior work, we find that periodic resetting of $Q$ and policy networks can be used to reduce value estimation error and improve learning in this setting. Second, we formulate novel off-policy actor-critic methods for both unconstrained and constrained learning that do not explicitly maximize $Q$ in the policy update. We find that this second approach, when applied to continuous action spaces with mixed-sign rewards, consistently and significantly outperforms state-of-the-art methods augmented by resetting. We further find that our approach produces agents that are both competitive with popular methods overall and more reliably competent on frequently-studied control problems that do not have mixed-sign rewards.", "url": "https://arxiv.org/abs/2311.18684"}, {"metadata": {"arXiv": "2311.18718", "Date": "Thu, 30 Nov 2023 17:19:18 ", "Title": "Steering Deep Feature Learning with Backward Aligned Feature Updates", "Authors": ["L\\'ena\\\"ic Chizat and Praneeth Netrapalli"], "Categories": "cs.LG", "MSC-class": "68T07"}, "abstract": "Deep learning succeeds by doing hierarchical feature learning, yet tuning Hyper-Parameters (HP) such as initialization scales, learning rates etc., only give indirect control over this behavior. In this paper, we propose the alignment between the feature updates and the backward pass as a key notion to predict, measure and control feature learning. On the one hand, we show that when alignment holds, the magnitude of feature updates after one SGD step is related to the magnitude of the forward and backward passes by a simple and general formula. This leads to techniques to automatically adjust HPs (initialization scales and learning rates) at initialization and throughout training to attain a desired feature learning behavior. On the other hand, we show that, at random initialization, this alignment is determined by the spectrum of a certain kernel, and that well-conditioned layer-to-layer Jacobians (aka dynamical isometry) implies alignment. Finally, we investigate ReLU MLPs and ResNets in the large width-then-depth limit. Combining hints from random matrix theory and numerical experiments, we show that (i) in MLP with iid initializations, alignment degenerates with depth, making it impossible to start training, and that (ii) in ResNets, the branch scale $1/\\sqrt{\\text{depth}}$ is the only one maintaining non-trivial alignment at infinite depth.", "url": "https://arxiv.org/abs/2311.18718"}, {"metadata": {"arXiv": "2311.18735", "Date": "Thu, 30 Nov 2023 17:30:45 ", "Title": "Dimension Mixer: A Generalized Method for Structured Sparsity in Deep Neural Networks", "Authors": ["Suman Sapkota", "Binod Bhattarai"], "Categories": "cs.LG", "Comments": ["11 pages", "4 figures", "7 tables"]}, "abstract": "The recent success of multiple neural architectures like CNNs, Transformers, and MLP-Mixers motivated us to look for similarities and differences between them. We found that these architectures can be interpreted through the lens of a general concept of dimension mixing. Research on coupling flows and the butterfly transform shows that partial and hierarchical signal mixing schemes are sufficient for efficient and expressive function approximation. In this work, we study group-wise sparse, non-linear, multi-layered and learnable mixing schemes of inputs and find that they are complementary to many standard neural architectures. Following our observations and drawing inspiration from the Fast Fourier Transform, we generalize Butterfly Structure to use non-linear mixer function allowing for MLP as mixing function called Butterfly MLP. We were also able to mix along sequence dimension for Transformer- based architectures called Butterfly Attention. Experiments on CIFAR and LRA datasets demonstrate that the proposed Non-Linear Butterfly Mixers are efficient and scale well when the host architectures are used as mixing function. Additionally, we propose Patch-Only MLP-Mixer for processing spatial 2D signals demonstrating a different dimension mixing strategy.", "url": "https://arxiv.org/abs/2311.18735"}, {"metadata": {"arXiv": "2311.18746", "Date": "Thu, 30 Nov 2023 17:44:22 ", "Title": "A data-science pipeline to enable the Interpretability of Many-Objective Feature Selection", "Authors": ["Uchechukwu F. Njoku", "Alberto Abell\\'o", "Besim Bilalli", "Gianluca Bontempi"], "Categories": "cs.LG", "Comments": ["8 pages", "5 figures", "6 tables"]}, "abstract": "Many-Objective Feature Selection (MOFS) approaches use four or more objectives to determine the relevance of a subset of features in a supervised learning task. As a consequence, MOFS typically returns a large set of non-dominated solutions, which have to be assessed by the data scientist in order to proceed with the final choice. Given the multi-variate nature of the assessment, which may include criteria (e.g. fairness) not related to predictive accuracy, this step is often not straightforward and suffers from the lack of existing tools. For instance, it is common to make use of a tabular presentation of the solutions, which provide little information about the trade-offs and the relations between criteria over the set of solutions. This paper proposes an original methodology to support data scientists in the interpretation and comparison of the MOFS outcome by combining post-processing and visualisation of the set of solutions. The methodology supports the data scientist in the selection of an optimal feature subset by providing her with high-level information at three different levels: objectives, solutions, and individual features. The methodology is experimentally assessed on two feature selection tasks adopting a GA-based MOFS with six objectives (number of selected features, balanced accuracy, F1-Score, variance inflation factor, statistical parity, and equalised odds). The results show the added value of the methodology in the selection of the final subset of features.", "url": "https://arxiv.org/abs/2311.18746"}, {"metadata": {"arXiv": "2311.18769", "Date": "Thu, 30 Nov 2023 18:08:16 ", "Title": "Online Change Points Detection for Linear Dynamical Systems with Finite Sample Guarantees", "Authors": ["Lei Xin", "George Chiu", "Shreyas Sundaram"], "Categories": "cs.LG cs.SY eess.SY stat.ML", "Comments": ["11 pages", "3 figures"]}, "abstract": "The problem of online change point detection is to detect abrupt changes in properties of time series, ideally as soon as possible after those changes occur. Existing work on online change point detection either assumes i.i.d data, focuses on asymptotic analysis, does not present theoretical guarantees on the trade-off between detection accuracy and detection delay, or is only suitable for detecting single change points. In this work, we study the online change point detection problem for linear dynamical systems with unknown dynamics, where the data exhibits temporal correlations and the system could have multiple change points. We develop a data-dependent threshold that can be used in our test that allows one to achieve a pre-specified upper bound on the probability of making a false alarm. We further provide a finite-sample-based bound for the probability of detecting a change point. Our bound demonstrates how parameters used in our algorithm affect the detection probability and delay, and provides guidance on the minimum required time between changes to guarantee detection.", "url": "https://arxiv.org/abs/2311.18769"}, {"metadata": {"arXiv": "2311.18780", "Date": "Thu, 30 Nov 2023 18:24:33 ", "Title": "MultiResFormer: Transformer with Adaptive Multi-Resolution Modeling for General Time Series Forecasting", "Authors": ["Linfeng Du", "Ji Xin", "Alex Labach", "Saba Zuberi", "Maksims Volkovs", "Rahul G. Krishnan"], "Categories": "cs.LG"}, "abstract": "Transformer-based models have greatly pushed the boundaries of time series forecasting recently. Existing methods typically encode time series data into $\\textit{patches}$ using one or a fixed set of patch lengths. This, however, could result in a lack of ability to capture the variety of intricate temporal dependencies present in real-world multi-periodic time series. In this paper, we propose MultiResFormer, which dynamically models temporal variations by adaptively choosing optimal patch lengths. Concretely, at the beginning of each layer, time series data is encoded into several parallel branches, each using a detected periodicity, before going through the transformer encoder block. We conduct extensive evaluations on long- and short-term forecasting datasets comparing MultiResFormer with state-of-the-art baselines. MultiResFormer outperforms patch-based Transformer baselines on long-term forecasting tasks and also consistently outperforms CNN baselines by a large margin, while using much fewer parameters than these baselines.", "url": "https://arxiv.org/abs/2311.18780"}, {"metadata": {"arXiv": "2311.18787", "Date": "Thu, 30 Nov 2023 18:37:15 ", "Title": "Communication-Efficient Federated Optimization over Semi-Decentralized Networks", "Authors": ["He Wang", "Yuejie Chi"], "Categories": "cs.LG cs.DC math.OC"}, "abstract": "In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.", "url": "https://arxiv.org/abs/2311.18787"}, {"metadata": {"arXiv": "2311.18806", "Date": "Thu, 30 Nov 2023 18:51:50 ", "Title": "Efficient Baseline for Quantitative Precipitation Forecasting in Weather4cast 2023", "Authors": ["Akshay Punjabi and Pablo Izquierdo Ayala"], "Categories": "cs.LG physics.ao-ph", "Comments": ["5 pages", "1 figure", "Weather4Cast 2023 challenge"]}, "abstract": "Accurate precipitation forecasting is indispensable for informed decision-making across various industries. However, the computational demands of current models raise environmental concerns. We address the critical need for accurate precipitation forecasting while considering the environmental impact of computational resources and propose a minimalist U-Net architecture to be used as a baseline for future weather forecasting initiatives.", "url": "https://arxiv.org/abs/2311.18806"}, {"metadata": {"arXiv": "2311.18807", "Date": "Thu, 30 Nov 2023 18:52:10 ", "Title": "Pre-registration for Predictive Modeling", "Authors": ["Jake M. Hofman", "Angelos Chatzimparmpas", "Amit Sharma", "Duncan J. Watts", "Jessica Hullman"], "Categories": "cs.LG stat.ME"}, "abstract": "Amid rising concerns of reproducibility and generalizability in predictive modeling, we explore the possibility and potential benefits of introducing pre-registration to the field. Despite notable advancements in predictive modeling, spanning core machine learning tasks to various scientific applications, challenges such as overlooked contextual factors, data-dependent decision-making, and unintentional re-use of test data have raised questions about the integrity of results. To address these issues, we propose adapting pre-registration practices from explanatory modeling to predictive modeling. We discuss current best practices in predictive modeling and their limitations, introduce a lightweight pre-registration template, and present a qualitative study with machine learning researchers to gain insight into the effectiveness of pre-registration in preventing biased estimates and promoting more reliable research outcomes. We conclude by exploring the scope of problems that pre-registration can address in predictive modeling and acknowledging its limitations within this context.", "url": "https://arxiv.org/abs/2311.18807"}, {"metadata": {"arXiv": "2311.18823", "Date": "Thu, 30 Nov 2023 18:58:26 ", "Title": "Initializing Models with Larger Ones", "Authors": ["Zhiqiu Xu", "Yanjie Chen", "Kirill Vishniakov", "Yida Yin", "Zhiqiang Shen", "Trevor Darrell", "Lingjie Liu", "Zhuang Liu"], "Categories": "cs.LG cs.CV"}, "abstract": "Weight initialization plays an important role in neural network training. Widely used initialization methods are proposed and evaluated for networks that are trained from scratch. However, the growing number of pretrained models now offers new opportunities for tackling this classical problem of weight initialization. In this work, we introduce weight selection, a method for initializing smaller models by selecting a subset of weights from a pretrained larger model. This enables the transfer of knowledge from pretrained weights to smaller models. Our experiments demonstrate that weight selection can significantly enhance the performance of small models and reduce their training time. Notably, it can also be used together with knowledge distillation. Weight selection offers a new approach to leverage the power of pretrained models in resource-constrained settings, and we hope it can be a useful tool for training small models in the large-model era. Code is available at https://github.com/OscarXZQ/weight-selection.", "url": "https://arxiv.org/abs/2311.18823"}, {"metadata": {"arXiv": "2311.18826", "Date": "Thu, 30 Nov 2023 18:59:05 ", "Title": "Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal Inference", "Authors": ["Kaiwen Hou"], "Categories": "cs.LG stat.ML"}, "abstract": "This manuscript enriches the framework of continuous normalizing flows (CNFs) within causal inference, primarily to augment the geometric properties of parametric submodels used in targeted maximum likelihood estimation (TMLE). By introducing an innovative application of CNFs, we construct a refined series of parametric submodels that enable a directed interpolation between the prior distribution $p_0$ and the empirical distribution $p_1$. This proposed methodology serves to optimize the semiparametric efficiency bound in causal inference by orchestrating CNFs to align with Wasserstein gradient flows. Our approach not only endeavors to minimize the mean squared error in the estimation but also imbues the estimators with geometric sophistication, thereby enhancing robustness against misspecification. This robustness is crucial, as it alleviates the dependence on the standard $n^{\\frac{1}{4}}$ rate for a doubly-robust perturbation direction in TMLE. By incorporating robust optimization principles and differential geometry into the estimators, the developed geometry-aware CNFs represent a significant advancement in the pursuit of doubly robust causal inference.", "url": "https://arxiv.org/abs/2311.18826"}, {"metadata": {"arXiv": "2311.18044", "Date": "Wed, 29 Nov 2023 19:40:10 ", "Title": "Transfer Learning in Robotics: An Upcoming Breakthrough? A Review of Promises and Challenges", "Authors": ["No\\'emie Jaquier", "Michael C. Welle", "Andrej Gams", "Kunpeng Yao", "Bernardo Fichera", "Aude Billard", "Ale\\v{s} Ude", "Tamim Asfour", "Danica Kragi\\'c"], "Categories": "cs.RO cs.LG", "Comments": ["20 pages", "7 figures"]}, "abstract": "Transfer learning is a conceptually-enticing paradigm in pursuit of truly intelligent embodied agents. The core concept -- reusing prior knowledge to learn in and from novel situations -- is successfully leveraged by humans to handle novel situations. In recent years, transfer learning has received renewed interest from the community from different perspectives, including imitation learning, domain adaptation, and transfer of experience from simulation to the real world, among others. In this paper, we unify the concept of transfer learning in robotics and provide the first taxonomy of its kind considering the key concepts of robot, task, and environment. Through a review of the promises and challenges in the field, we identify the need of transferring at different abstraction levels, the need of quantifying the transfer gap and the quality of transfer, as well as the dangers of negative transfer. Via this position paper, we hope to channel the effort of the community towards the most significant roadblocks to realize the full potential of transfer learning in robotics.", "url": "https://arxiv.org/abs/2311.18044"}, {"metadata": {"arXiv": "2311.17941", "Date": "Tue, 28 Nov 2023 23:29:36 ", "Title": "Advancing Attack-Resilient Scheduling of Integrated Energy Systems with Demand Response via Deep Reinforcement Learning", "Authors": ["Yang Li", "Wenjie Ma", "Yuanzheng Li", "Sen Li", "Zhe Chen"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Optimally scheduling multi-energy flow is an effective method to utilize renewable energy sources (RES) and improve the stability and economy of integrated energy systems (IES). However, the stable demand-supply of IES faces challenges from uncertainties that arise from RES and loads, as well as the increasing impact of cyber-attacks with advanced information and communication technologies adoption. To address these challenges, this paper proposes an innovative model-free resilience scheduling method based on state-adversarial deep reinforcement learning (DRL) for integrated demand response (IDR)-enabled IES. The proposed method designs an IDR program to explore the interaction ability of electricity-gas-heat flexible loads. Additionally, a state-adversarial Markov decision process (SA-MDP) model characterizes the energy scheduling problem of IES under cyber-attack. The state-adversarial soft actor-critic (SA-SAC) algorithm is proposed to mitigate the impact of cyber-attacks on the scheduling strategy. Simulation results demonstrate that our method is capable of adequately addressing the uncertainties resulting from RES and loads, mitigating the impact of cyber-attacks on the scheduling strategy, and ensuring a stable demand supply for various energy sources. Moreover, the proposed method demonstrates resilience against cyber-attacks. Compared to the original soft actor-critic (SAC) algorithm, it achieves a 10\\% improvement in economic performance under cyber-attack scenarios.", "url": "https://arxiv.org/abs/2311.17941"}, {"metadata": {"arXiv": "2311.18128", "Date": "Wed, 29 Nov 2023 22:38:33 ", "Title": "Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A Computational Approach for High-Dimensional Problems", "Authors": ["Bar{\\i}\\c{s} Ata and Ebru Ka\\c{s}{\\i}karalar"], "Categories": "eess.SY cs.LG cs.SY math.AP math.OC"}, "abstract": "We consider a multi-class queueing model of a telephone call center, in which a system manager dynamically allocates available servers to customer calls. Calls can terminate through either service completion or customer abandonment, and the manager strives to minimize the expected total of holding costs plus abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy traffic regime, we derive an approximating diffusion control problem, and building on earlier work by Han et al. (2018), develop a simulation-based computational method for solution of such problems, one that relies heavily on deep neural network technology. Using this computational method, we propose a policy for the original (pre-limit) call center scheduling problem. Finally, the performance of this policy is assessed using test problems based on publicly available call center data. For the test problems considered so far, our policy does as well as the best benchmark we could find. Moreover, our method is computationally feasible at least up to dimension 100, that is, for call centers with 100 or more distinct customer classes.", "url": "https://arxiv.org/abs/2311.18128"}, {"metadata": {"arXiv": "2311.18261", "Date": "Thu, 30 Nov 2023 05:40:55 ", "Title": "Learning Exactly Linearizable Deep Dynamics Models", "Authors": ["Ryuta Moriyasu", "Masayuki Kusunoki", "Kenji Kashima"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "Research on control using models based on machine-learning methods has now shifted to the practical engineering stage. Achieving high performance and theoretically guaranteeing the safety of the system is critical for such applications. In this paper, we propose a learning method for exactly linearizable dynamical models that can easily apply various control theories to ensure stability, reliability, etc., and to provide a high degree of freedom of expression. As an example, we present a design that combines simple linear control and control barrier functions. The proposed model is employed for the real-time control of an automotive engine, and the results demonstrate good predictive performance and stable control under constraints.", "url": "https://arxiv.org/abs/2311.18261"}, {"metadata": {"arXiv": "2311.18644", "Date": "Thu, 30 Nov 2023 15:53:02 ", "Title": "Exploring the hierarchical structure of human plans via program generation", "Authors": ["Carlos G. Correa", "Sophia Sanborn", "Mark K. Ho", "Frederick Callaway", "Nathaniel D. Daw", "and Thomas L. Griffiths"], "Categories": "cs.AI"}, "abstract": "Human behavior is inherently hierarchical, resulting from the decomposition of a task into subtasks or an abstract action into concrete actions. However, behavior is typically measured as a sequence of actions, which makes it difficult to infer its hierarchical structure. In this paper, we explore how people form hierarchically-structured plans, using an experimental paradigm that makes hierarchical representations observable: participants create programs that produce sequences of actions in a language with explicit hierarchical structure. This task lets us test two well-established principles of human behavior: utility maximization (i.e. using fewer actions) and minimum description length (MDL; i.e. having a shorter program). We find that humans are sensitive to both metrics, but that both accounts fail to predict a qualitative feature of human-created programs, namely that people prefer programs with reuse over and above the predictions of MDL. We formalize this preference for reuse by extending the MDL account into a generative model over programs, modeling hierarchy choice as the induction of a grammar over actions. Our account can explain the preference for reuse and provides the best prediction of human behavior, going beyond simple accounts of compressibility to highlight a principle that guides hierarchical planning.", "url": "https://arxiv.org/abs/2311.18644"}, {"metadata": {"arXiv": "2311.18662", "Date": "Thu, 30 Nov 2023 16:10:35 ", "Title": "Solving the Team Orienteering Problem with Transformers", "Authors": ["Daniel Fuertes", "Carlos R. del-Blanco", "Fernando Jaureguizar", "Narciso Garc\\'ia"], "Categories": "cs.AI"}, "abstract": "Route planning for a fleet of vehicles is an important task in applications such as package delivery, surveillance, or transportation. This problem is usually modeled as a Combinatorial Optimization problem named as Team Orienteering Problem. The most popular Team Orienteering Problem solvers are mainly based on either linear programming, which provides accurate solutions by employing a large computation time that grows with the size of the problem, or heuristic methods, which usually find suboptimal solutions in a shorter amount of time. In this paper, a multi-agent route planning system capable of solving the Team Orienteering Problem in a very fast and accurate manner is presented. The proposed system is based on a centralized Transformer neural network that can learn to encode the scenario (modeled as a graph) and the context of the agents to provide fast and accurate solutions. Several experiments have been performed to demonstrate that the presented system can outperform most of the state-of-the-art works in terms of computation speed. In addition, the code is publicly available at \\url{http://gti.ssr.upm.es/data}.", "url": "https://arxiv.org/abs/2311.18662"}, {"metadata": {"arXiv": "2311.17946", "Date": "Wed, 29 Nov 2023 03:42:16 ", "Title": "DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback", "Authors": ["Jiao Sun", "Deqing Fu", "Yushi Hu", "Su Wang", "Royi Rassin", "Da-Cheng Juan", "Dana Alon", "Charles Herrmann", "Sjoerd van Steenkiste", "Ranjay Krishna", "Cyrus Rashtchian"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Despite their wide-spread success, Text-to-Image models (T2I) still struggle to produce images that are both aesthetically pleasing and faithful to the user's input text. We introduce DreamSync, a model-agnostic training algorithm by design that improves T2I models to be faithful to the text input. DreamSync builds off a recent insight from TIFA's evaluation framework -- that large vision-language models (VLMs) can effectively identify the fine-grained discrepancies between generated images and the text inputs. DreamSync uses this insight to train T2I models without any labeled data; it improves T2I models using its own generations. First, it prompts the model to generate several candidate images for a given input text. Then, it uses two VLMs to select the best generation: a Visual Question Answering model that measures the alignment of generated images to the text, and another that measures the generation's aesthetic quality. After selection, we use LoRA to iteratively finetune the T2I model to guide its generation towards the selected best generations. DreamSync does not need any additional human annotation. model architecture changes, or reinforcement learning. Despite its simplicity, DreamSync improves both the semantic alignment and aesthetic appeal of two diffusion-based T2I models, evidenced by multiple benchmarks (+1.7% on TIFA, +2.9% on DSG1K, +3.4% on VILA aesthetic) and human evaluation.", "url": "https://arxiv.org/abs/2311.17946"}, {"metadata": {"arXiv": "2311.17950", "Date": "Wed, 29 Nov 2023 06:25:59 ", "Title": "Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching", "Authors": ["Shitong Shao", "Zeyuan Yin", "Muxin Zhou", "Xindong Zhang and Zhiqiang Shen"], "Categories": "cs.CV cs.AI"}, "abstract": "The lightweight \"local-match-global\" matching introduced by SRe2L successfully creates a distilled dataset with comprehensive information on the full 224x224 ImageNet-1k. However, this one-sided approach is limited to a particular backbone, layer, and statistics, which limits the improvement of the generalization of a distilled dataset. We suggest that sufficient and various \"local-match-global\" matching are more precise and effective than a single one and has the ability to create a distilled dataset with richer information and better generalization. We call this perspective \"generalized matching\" and propose Generalized Various Backbone and Statistical Matching (G-VBSM) in this work, which aims to create a synthetic dataset with densities, ensuring consistency with the complete dataset across various backbones, layers, and statistics. As experimentally demonstrated, G-VBSM is the first algorithm to obtain strong performance across both small-scale and large-scale datasets. Specifically, G-VBSM achieves a performance of 38.7% on CIFAR-100 with 128-width ConvNet, 47.6% on Tiny-ImageNet with ResNet18, and 31.4% on the full 224x224 ImageNet-1k with ResNet18, under images per class (IPC) 10, 50, and 10, respectively. These results surpass all SOTA methods by margins of 3.9%, 6.5%, and 10.1%, respectively.", "url": "https://arxiv.org/abs/2311.17950"}, {"metadata": {"arXiv": "2311.18241", "Date": "Thu, 30 Nov 2023 04:17:30 ", "Title": "LLVMs4Protest: Harnessing the Power of Large Language and Vision Models for Deciphering Protests in the News", "Authors": ["Yongjun Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Large language and vision models have transformed how social movements scholars identify protest and extract key protest attributes from multi-modal data such as texts, images, and videos. This article documents how we fine-tuned two large pretrained transformer models, including longformer and swin-transformer v2, to infer potential protests in news articles using textual and imagery data. First, the longformer model was fine-tuned using the Dynamic of Collective Action (DoCA) Corpus. We matched the New York Times articles with the DoCA database to obtain a training dataset for downstream tasks. Second, the swin-transformer v2 models was trained on UCLA-protest imagery data. UCLA-protest project contains labeled imagery data with information such as protest, violence, and sign. Both fine-tuned models will be available via \\url{https://github.com/Joshzyj/llvms4protest}. We release this short technical report for social movement scholars who are interested in using LLVMs to infer protests in textual and imagery data.", "url": "https://arxiv.org/abs/2311.18241"}, {"metadata": {"arXiv": "2311.18254", "Date": "Thu, 30 Nov 2023 05:05:38 ", "Title": "Sketch Input Method Editor: A Comprehensive Dataset and Methodology for Systematic Input Recognition", "Authors": ["Guangming Zhu", "Siyuan Wang", "Qing Cheng", "Kelong Wu", "Hao Li", "Liang Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["The paper has been accepted by ACM Multimedia 2023"]}, "abstract": "With the recent surge in the use of touchscreen devices, free-hand sketching has emerged as a promising modality for human-computer interaction. While previous research has focused on tasks such as recognition, retrieval, and generation of familiar everyday objects, this study aims to create a Sketch Input Method Editor (SketchIME) specifically designed for a professional C4I system. Within this system, sketches are utilized as low-fidelity prototypes for recommending standardized symbols in the creation of comprehensive situation maps. This paper also presents a systematic dataset comprising 374 specialized sketch types, and proposes a simultaneous recognition and segmentation architecture with multilevel supervision between recognition and segmentation to improve performance and enhance interpretability. By incorporating few-shot domain adaptation and class-incremental learning, the network's ability to adapt to new users and extend to new task-specific classes is significantly enhanced. Results from experiments conducted on both the proposed dataset and the SPG dataset illustrate the superior performance of the proposed architecture. Our dataset and code are publicly available at https://github.com/Anony517/SketchIME.", "url": "https://arxiv.org/abs/2311.18254"}, {"metadata": {"arXiv": "2311.18259", "Date": "Thu, 30 Nov 2023 05:21:07 ", "Title": "Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives", "Authors": ["Kristen Grauman", "Andrew Westbury", "Lorenzo Torresani", "Kris Kitani", "Jitendra Malik", "Triantafyllos Afouras", "Kumar Ashutosh", "Vijay Baiyya", "Siddhant Bansal", "Bikram Boote", "Eugene Byrne", "Zach Chavis", "Joya Chen", "Feng Cheng", "Fu-Jen Chu", "Sean Crane", "Avijit Dasgupta", "Jing Dong", "Maria Escobar", "Cristhian Forigua", "Abrham Gebreselasie", "Sanjay Haresh", "Jing Huang", "Md Mohaiminul Islam", "Suyog Jain", "Rawal Khirodkar", "Devansh Kukreja", "Kevin J Liang", "Jia-Wei Liu", "Sagnik Majumder", "Yongsen Mao", "Miguel Martin", "Effrosyni Mavroudi", "Tushar Nagarajan", "Francesco Ragusa", "Santhosh Kumar Ramakrishnan", "Luigi Seminara", "Arjun Somayazulu", "Yale Song", "Shan Su", "Zihui Xue", "Edward Zhang", "Jinxu Zhang", "Angela Castillo", "Changan Chen", "Xinzhu Fu", "Ryosuke Furuta", "Cristina Gonzalez", "Prince Gupta", "Jiabo Hu", "Yifei Huang", "Yiming Huang", "Weslie Khoo", "et al. (48 additional authors not shown)"], "Categories": "cs.CV cs.AI"}, "abstract": "We present Ego-Exo4D, a diverse, large-scale multimodal multiview video dataset and benchmark challenge. Ego-Exo4D centers around simultaneously-captured egocentric and exocentric video of skilled human activities (e.g., sports, music, dance, bike repair). More than 800 participants from 13 cities worldwide performed these activities in 131 different natural scene contexts, yielding long-form captures from 1 to 42 minutes each and 1,422 hours of video combined. The multimodal nature of the dataset is unprecedented: the video is accompanied by multichannel audio, eye gaze, 3D point clouds, camera poses, IMU, and multiple paired language descriptions -- including a novel \"expert commentary\" done by coaches and teachers and tailored to the skilled-activity domain. To push the frontier of first-person video understanding of skilled human activity, we also present a suite of benchmark tasks and their annotations, including fine-grained activity understanding, proficiency estimation, cross-view translation, and 3D hand/body pose. All resources will be open sourced to fuel new research in the community.", "url": "https://arxiv.org/abs/2311.18259"}, {"metadata": {"arXiv": "2311.18296", "Date": "Thu, 30 Nov 2023 07:00:14 ", "Title": "Perceptual Group Tokenizer: Building Perception with Iterative Grouping", "Authors": ["Zhiwei Deng", "Ting Chen", "Yang Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Human visual recognition system shows astonishing capability of compressing visual information into a set of tokens containing rich representations without label supervision. One critical driving principle behind it is perceptual grouping. Despite being widely used in computer vision in the early 2010s, it remains a mystery whether perceptual grouping can be leveraged to derive a neural visual recognition backbone that generates as powerful representations. In this paper, we propose the Perceptual Group Tokenizer, a model that entirely relies on grouping operations to extract visual features and perform self-supervised representation learning, where a series of grouping operations are used to iteratively hypothesize the context for pixels or superpixels to refine feature representations. We show that the proposed model can achieve competitive performance compared to state-of-the-art vision architectures, and inherits desirable properties including adaptive computation without re-training, and interpretability. Specifically, Perceptual Group Tokenizer achieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear probe evaluation, marking a new progress under this paradigm.", "url": "https://arxiv.org/abs/2311.18296"}, {"metadata": {"arXiv": "2311.18297", "Date": "Thu, 30 Nov 2023 07:03:36 ", "Title": "TrustMark: Universal Watermarking for Arbitrary Resolution Images", "Authors": ["Tu Bui", "Shruti Agarwal", "John Collomosse"], "Categories": "cs.CV cs.AI"}, "abstract": "Imperceptible digital watermarking is important in copyright protection, misinformation prevention, and responsible generative AI. We propose TrustMark - a GAN-based watermarking method with novel design in architecture and spatio-spectra losses to balance the trade-off between watermarked image quality with the watermark recovery accuracy. Our model is trained with robustness in mind, withstanding various in- and out-place perturbations on the encoded image. Additionally, we introduce TrustMark-RM - a watermark remover method useful for re-watermarking. Our methods achieve state-of-art performance on 3 benchmarks comprising arbitrary resolution images.", "url": "https://arxiv.org/abs/2311.18297"}, {"metadata": {"arXiv": "2311.18328", "Date": "Thu, 30 Nov 2023 07:58:54 ", "Title": "Advances in 3D Neural Stylization: A Survey", "Authors": ["Yingshu Chen", "Guocheng Shao", "Ka Chun Shum", "Binh-Son Hua", "Sai-Kit Yeung"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["26 pages"]}, "abstract": "Modern artificial intelligence provides a novel way of producing digital art in styles. The expressive power of neural networks enables the realm of visual style transfer methods, which can be used to edit images, videos, and 3D data to make them more artistic and diverse. This paper reports on recent advances in neural stylization for 3D data. We provide a taxonomy for neural stylization by considering several important design choices, including scene representation, guidance data, optimization strategies, and output styles. Building on such taxonomy, our survey first revisits the background of neural stylization on 2D images, and then provides in-depth discussions on recent neural stylization methods for 3D data, where we also provide a mini-benchmark on artistic stylization methods. Based on the insights gained from the survey, we then discuss open challenges, future research, and potential applications and impacts of neural stylization.", "url": "https://arxiv.org/abs/2311.18328"}, {"metadata": {"arXiv": "2311.18331", "Date": "Thu, 30 Nov 2023 08:02:49 ", "Title": "MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation", "Authors": ["Sumanth Udupa", "Prajwal Gurunath", "Aniruddh Sikdar", "Suresh Sundaram"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "7 figures"]}, "abstract": "Deep neural networks have shown exemplary performance on semantic scene understanding tasks on source domains, but due to the absence of style diversity during training, enhancing performance on unseen target domains using only single source domain data remains a challenging task. Generation of simulated data is a feasible alternative to retrieving large style-diverse real-world datasets as it is a cumbersome and budget-intensive process. However, the large domain-specific inconsistencies between simulated and real-world data pose a significant generalization challenge in semantic segmentation. In this work, to alleviate this problem, we propose a novel MultiResolution Feature Perturbation (MRFP) technique to randomize domain-specific fine-grained features and perturb style of coarse features. Our experimental results on various urban-scene segmentation datasets clearly indicate that, along with the perturbation of style-information, perturbation of fine-feature components is paramount to learn domain invariant robust feature maps for semantic segmentation models. MRFP is a simple and computationally efficient, transferable module with no additional learnable parameters or objective functions, that helps state-of-the-art deep neural networks to learn robust domain invariant features for simulation-to-real semantic segmentation.", "url": "https://arxiv.org/abs/2311.18331"}, {"metadata": {"arXiv": "2311.18403", "Date": "Thu, 30 Nov 2023 09:55:46 ", "Title": "Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations", "Authors": ["Xianlong Wang", "Shengshan Hu", "Minghui Li", "Zhifei Yu", "Ziqi Zhou", "Leo Yu Zhang", "Hai Jin"], "Categories": "cs.CV cs.AI"}, "abstract": "Unlearnable datasets lead to a drastic drop in the generalization performance of models trained on them by introducing elaborate and imperceptible perturbations into clean training sets. Many existing defenses, e.g., JPEG compression and adversarial training, effectively counter UDs based on norm-constrained additive noise. However, a fire-new type of convolution-based UDs have been proposed and render existing defenses all ineffective, presenting a greater challenge to defenders. To address this, we express the convolution-based unlearnable sample as the result of multiplying a matrix by a clean sample in a simplified scenario, and formalize the intra-class matrix inconsistency as $\\Theta_{imi}$, inter-class matrix consistency as $\\Theta_{imc}$ to investigate the working mechanism of the convolution-based UDs. We conjecture that increasing both of these metrics will mitigate the unlearnability effect. Through validation experiments that commendably support our hypothesis, we further design a random matrix to boost both $\\Theta_{imi}$ and $\\Theta_{imc}$, achieving a notable degree of defense effect. Hence, by building upon and extending these facts, we first propose a brand-new image COrruption that employs randomly multiplicative transformation via INterpolation operation to successfully defend against convolution-based UDs. Our approach leverages global pixel random interpolations, effectively suppressing the impact of multiplicative noise in convolution-based UDs. Additionally, we have also designed two new forms of convolution-based UDs, and find that our defense is the most effective against them.", "url": "https://arxiv.org/abs/2311.18403"}, {"metadata": {"arXiv": "2311.18518", "Date": "Thu, 30 Nov 2023 12:49:11 ", "Title": "Color-Emotion Associations in Art: Fuzzy Approach", "Authors": ["Pakizar Shamoi and Muragul Muratbekova"], "Categories": "cs.CV cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication"]}, "abstract": "Art objects can evoke certain emotions. Color is a fundamental element of visual art and plays a significant role in how art is perceived. This paper introduces a novel approach to classifying emotions in art using Fuzzy Sets. We employ a fuzzy approach because it aligns well with human judgments' imprecise and subjective nature. Extensive fuzzy colors (n=120) and a broad emotional spectrum (n=10) allow for a more human-consistent and context-aware exploration of emotions inherent in paintings. First, we introduce the fuzzy color representation model. Then, at the fuzzification stage, we process the Wiki Art Dataset of paintings tagged with emotions, extracting fuzzy dominant colors linked to specific emotions. This results in fuzzy color distributions for ten emotions. Finally, we convert them back to a crisp domain, obtaining a knowledge base of color-emotion associations in primary colors. Our findings reveal strong associations between specific emotions and colors; for instance, gratitude strongly correlates with green, brown, and orange. Other noteworthy associations include brown and anger, orange with shame, yellow with happiness, and gray with fear. Using these associations and Jaccard similarity, we can find the emotions in the arbitrary untagged image. We conducted a 2AFC experiment involving human subjects to evaluate the proposed method. The average hit rate of 0.77 indicates a significant correlation between the method's predictions and human perception. The proposed method is simple to adapt to art painting retrieval systems. The study contributes to the theoretical understanding of color-emotion associations in art, offering valuable insights for various practical applications besides art, like marketing, design, and psychology.", "url": "https://arxiv.org/abs/2311.18518"}, {"metadata": {"arXiv": "2311.18576", "Date": "Thu, 30 Nov 2023 14:15:39 ", "Title": "Fingerprint Matching with Localized Deep Representation", "Authors": ["Yongjie Duan", "Zhiyu Pan", "Jianjiang Feng", "Jie Zhou"], "Categories": "cs.CV cs.AI", "Comments": ["18 pages", "20 figures"]}, "abstract": "Compared to minutia-based fingerprint representations, fixed-length representations are attractive due to simple and efficient matching. However, fixed-length fingerprint representations are limited in accuracy when matching fingerprints with different visible areas, which can occur due to different finger poses or acquisition methods. To address this issue, we propose a localized deep representation of fingerprint, named LDRF. By focusing on the discriminative characteristics within local regions, LDRF provides a more robust and accurate fixed-length representation for fingerprints with variable visible areas. LDRF can be adapted to retain information within any valid area, making it highly flexible. The matching scores produced by LDRF also exhibit intuitive statistical characteristics, which led us to propose a matching score normalization technique to mitigate the uncertainty in the cases of very small overlapping area. With this new technique, we can maintain a high level of accuracy and reliability in our fingerprint matching, even as the size of the database grows rapidly. Our experimental results on 21 datasets containing over 140K fingerprints of various finger poses and impression types show that LDRF outperforms other fixed-length representations and is robust to sensing technologies and impression types. Besides, the proposed matching score normalization effectively reduces the false match rate (FMR) in large-scale identification experiments comprising over 5.11 million fingerprints. Specifically, this technique results in a reduction of two orders of magnitude compared to matching without matching score normalization and five orders of magnitude compared to prior works.", "url": "https://arxiv.org/abs/2311.18576"}, {"metadata": {"arXiv": "2311.18592", "Date": "Thu, 30 Nov 2023 14:35:51 ", "Title": "Semantic-Aware Frame-Event Fusion based Pattern Recognition via Large Vision-Language Models", "Authors": ["Dong Li", "Jiandong Jin", "Yuhao Zhang", "Yanlin Zhong", "Yaoyang Wu", "Lan Chen", "Xiao Wang", "Bin Luo"], "Categories": "cs.CV cs.AI", "Comments": ["In Peer Review"]}, "abstract": "Pattern recognition through the fusion of RGB frames and Event streams has emerged as a novel research area in recent years. Current methods typically employ backbone networks to individually extract the features of RGB frames and event streams, and subsequently fuse these features for pattern recognition. However, we posit that these methods may suffer from key issues like sematic gaps and small-scale backbone networks. In this study, we introduce a novel pattern recognition framework that consolidates the semantic labels, RGB frames, and event streams, leveraging pre-trained large-scale vision-language models. Specifically, given the input RGB frames, event streams, and all the predefined semantic labels, we employ a pre-trained large-scale vision model (CLIP vision encoder) to extract the RGB and event features. To handle the semantic labels, we initially convert them into language descriptions through prompt engineering, and then obtain the semantic features using the pre-trained large-scale language model (CLIP text encoder). Subsequently, we integrate the RGB/Event features and semantic features using multimodal Transformer networks. The resulting frame and event tokens are further amplified using self-attention layers. Concurrently, we propose to enhance the interactions between text tokens and RGB/Event tokens via cross-attention. Finally, we consolidate all three modalities using self-attention and feed-forward layers for recognition. Comprehensive experiments on the HARDVS and PokerEvent datasets fully substantiate the efficacy of our proposed SAFE model. The source code will be made available at https://github.com/Event-AHU/SAFE_LargeVLM.", "url": "https://arxiv.org/abs/2311.18592"}, {"metadata": {"arXiv": "2311.18645", "Date": "Thu, 30 Nov 2023 15:53:37 ", "Title": "Stochastic Vision Transformers with Wasserstein Distance-Aware Attention", "Authors": ["Franciskus Xaverius Erick", "Mina Rezaei", "Johanna Paula M\\\"uller", "Bernhard Kainz"], "Categories": "cs.CV cs.AI"}, "abstract": "Self-supervised learning is one of the most promising approaches to acquiring knowledge from limited labeled data. Despite the substantial advancements made in recent years, self-supervised models have posed a challenge to practitioners, as they do not readily provide insight into the model's confidence and uncertainty. Tackling this issue is no simple feat, primarily due to the complexity involved in implementing techniques that can make use of the latent representations learned during pre-training without relying on explicit labels. Motivated by this, we introduce a new stochastic vision transformer that integrates uncertainty and distance awareness into self-supervised learning (SSL) pipelines. Instead of the conventional deterministic vector embedding, our novel stochastic vision transformer encodes image patches into elliptical Gaussian distributional embeddings. Notably, the attention matrices of these stochastic representational embeddings are computed using Wasserstein distance-based attention, effectively capitalizing on the distributional nature of these embeddings. Additionally, we propose a regularization term based on Wasserstein distance for both pre-training and fine-tuning processes, thereby incorporating distance awareness into latent representations. We perform extensive experiments across different tasks such as in-distribution generalization, out-of-distribution detection, dataset corruption, semi-supervised settings, and transfer learning to other datasets and tasks. Our proposed method achieves superior accuracy and calibration, surpassing the self-supervised baseline in a wide range of experiments on a variety of datasets.", "url": "https://arxiv.org/abs/2311.18645"}, {"metadata": {"arXiv": "2311.18654", "Date": "Thu, 30 Nov 2023 16:04:30 ", "Title": "Detailed Human-Centric Text Description-Driven Large Scene Synthesis", "Authors": ["Gwanghyun Kim", "Dong Un Kang", "Hoigi Seo", "Hayeon Kim", "Se Young Chun"], "Categories": "cs.CV cs.AI"}, "abstract": "Text-driven large scene image synthesis has made significant progress with diffusion models, but controlling it is challenging. While using additional spatial controls with corresponding texts has improved the controllability of large scene synthesis, it is still challenging to faithfully reflect detailed text descriptions without user-provided controls. Here, we propose DetText2Scene, a novel text-driven large-scale image synthesis with high faithfulness, controllability, and naturalness in a global context for the detailed human-centric text description. Our DetText2Scene consists of 1) hierarchical keypoint-box layout generation from the detailed description by leveraging large language model (LLM), 2) view-wise conditioned joint diffusion process to synthesize a large scene from the given detailed text with LLM-generated grounded keypoint-box layout and 3) pixel perturbation-based pyramidal interpolation to progressively refine the large scene for global coherence. Our DetText2Scene significantly outperforms prior arts in text-to-large scene synthesis qualitatively and quantitatively, demonstrating strong faithfulness with detailed descriptions, superior controllability, and excellent naturalness in a global context.", "url": "https://arxiv.org/abs/2311.18654"}, {"metadata": {"arXiv": "2311.18664", "Date": "Thu, 30 Nov 2023 16:13:17 ", "Title": "Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy", "Authors": ["Pedro Esteban Chavarrias Solano", "Andrew Bulpitt", "Venkataraman Subramanian", "Sharib Ali"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["19 pages"]}, "abstract": "Colonoscopy screening is the gold standard procedure for assessing abnormalities in the colon and rectum, such as ulcers and cancerous polyps. Measuring the abnormal mucosal area and its 3D reconstruction can help quantify the surveyed area and objectively evaluate disease burden. However, due to the complex topology of these organs and variable physical conditions, for example, lighting, large homogeneous texture, and image modality estimating distance from the camera aka depth) is highly challenging. Moreover, most colonoscopic video acquisition is monocular, making the depth estimation a non-trivial problem. While methods in computer vision for depth estimation have been proposed and advanced on natural scene datasets, the efficacy of these techniques has not been widely quantified on colonoscopy datasets. As the colonic mucosa has several low-texture regions that are not well pronounced, learning representations from an auxiliary task can improve salient feature extraction, allowing estimation of accurate camera depths. In this work, we propose to develop a novel multi-task learning (MTL) approach with a shared encoder and two decoders, namely a surface normal decoder and a depth estimator decoder. Our depth estimator incorporates attention mechanisms to enhance global context awareness. We leverage the surface normal prediction to improve geometric feature extraction. Also, we apply a cross-task consistency loss among the two geometrically related tasks, surface normal and camera depth. We demonstrate an improvement of 14.17% on relative error and 10.4% improvement on $\\delta_{1}$ accuracy over the most accurate baseline state-of-the-art BTS approach. All experiments are conducted on a recently released C3VD dataset; thus, we provide a first benchmark of state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.18664"}, {"metadata": {"arXiv": "2311.18801", "Date": "Thu, 30 Nov 2023 18:47:18 ", "Title": "Distributed Global Structure-from-Motion with a Deep Front-End", "Authors": ["Ayush Baid", "John Lambert", "Travis Driver", "Akshay Krishnan", "Hayk Stepanyan", "and Frank Dellaert"], "Categories": "cs.CV cs.AI"}, "abstract": "While initial approaches to Structure-from-Motion (SfM) revolved around both global and incremental methods, most recent applications rely on incremental systems to estimate camera poses due to their superior robustness. Though there has been tremendous progress in SfM `front-ends' powered by deep models learned from data, the state-of-the-art (incremental) SfM pipelines still rely on classical SIFT features, developed in 2004. In this work, we investigate whether leveraging the developments in feature extraction and matching helps global SfM perform on par with the SOTA incremental SfM approach (COLMAP). To do so, we design a modular SfM framework that allows us to easily combine developments in different stages of the SfM pipeline. Our experiments show that while developments in deep-learning based two-view correspondence estimation do translate to improvements in point density for scenes reconstructed with global SfM, none of them outperform SIFT when comparing with incremental SfM results on a range of datasets. Our SfM system is designed from the ground up to leverage distributed computation, enabling us to parallelize computation on multiple machines and scale to large scenes.", "url": "https://arxiv.org/abs/2311.18801"}, {"metadata": {"arXiv": "2311.18138", "Date": "Wed, 29 Nov 2023 23:01:33 ", "Title": "Algorithmic Persuasion Through Simulation: Information Design in the Age of Generative AI", "Authors": ["Keegan Harris", "Nicole Immorlica", "Brendan Lucier", "Aleksandrs Slivkins"], "Categories": "cs.GT cs.AI econ.TH"}, "abstract": "How can an informed sender persuade a receiver, having only limited information about the receiver's beliefs? Motivated by research showing generative AI can simulate economic agents, we initiate the study of information design with an oracle. We assume the sender can learn more about the receiver by querying this oracle, e.g., by simulating the receiver's behavior. Aside from AI motivations such as general-purpose Large Language Models (LLMs) and problem-specific machine learning models, alternate motivations include customer surveys and querying a small pool of live users. Specifically, we study Bayesian Persuasion where the sender has a second-order prior over the receiver's beliefs. After a fixed number of queries to an oracle to refine this prior, the sender commits to an information structure. Upon receiving the message, the receiver takes a payoff-relevant action maximizing her expected utility given her posterior beliefs. We design polynomial-time querying algorithms that optimize the sender's expected utility in this Bayesian Persuasion game. As a technical contribution, we show that queries form partitions of the space of receiver beliefs that can be used to quantify the sender's knowledge.", "url": "https://arxiv.org/abs/2311.18138"}, {"metadata": {"arXiv": "2311.18636", "Date": "Sun, 27 Aug 2023 17:43:58 ", "Title": "End-to-end Autonomous Driving using Deep Learning: A Systematic Review", "Authors": ["Apoorv Singh"], "Categories": "cs.RO cs.AI", "Comments": ["11 pages", "6 figures", "submitted in WACV conference"]}, "abstract": "End-to-end autonomous driving is a fully differentiable machine learning system that takes raw sensor input data and other metadata as prior information and directly outputs the ego vehicle's control signals or planned trajectories. This paper attempts to systematically review all recent Machine Learning-based techniques to perform this end-to-end task, including, but not limited to, object detection, semantic scene understanding, object tracking, trajectory predictions, trajectory planning, vehicle control, social behavior, and communications. This paper focuses on recent fully differentiable end-to-end reinforcement learning and deep learning-based techniques. Our paper also builds taxonomies of the significant approaches by sub-grouping them and showcasing their research trends. Finally, this survey highlights the open challenges and points out possible future directions to enlighten further research on the topic.", "url": "https://arxiv.org/abs/2311.18636"}, {"metadata": {"arXiv": "2311.17983", "Date": "Wed, 29 Nov 2023 18:51:21 ", "Title": "Improving Faithfulness for Vision Transformers", "Authors": ["Lijie Hu", "Yixin Liu", "Ninghao Liu", "Mengdi Huai", "Lichao Sun", "and Di Wang"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance for various vision tasks. One reason behind the success lies in their ability to provide plausible innate explanations for the behavior of neural architectures. However, ViTs suffer from issues with explanation faithfulness, as their focal points are fragile to adversarial attacks and can be easily changed with even slight perturbations on the input image. In this paper, we propose a rigorous approach to mitigate these issues by introducing Faithful ViTs (FViTs). Briefly speaking, an FViT should have the following two properties: (1) The top-$k$ indices of its self-attention vector should remain mostly unchanged under input perturbation, indicating stable explanations; (2) The prediction distribution should be robust to perturbations. To achieve this, we propose a new method called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing and diffusion-based denoising. We theoretically prove that processing ViTs directly with DDS can turn them into FViTs. We also show that Gaussian noise is nearly optimal for both $\\ell_2$ and $\\ell_\\infty$-norm cases. Finally, we demonstrate the effectiveness of our approach through comprehensive experiments and evaluations. Specifically, we compare our FViTs with other baselines through visual interpretation and robustness accuracy under adversarial attacks. Results show that FViTs are more robust against adversarial attacks while maintaining the explainability of attention, indicating higher faithfulness.", "url": "https://arxiv.org/abs/2311.17983"}, {"metadata": {"arXiv": "2311.18021", "Date": "Wed, 29 Nov 2023 19:08:11 ", "Title": "Understanding and Improving In-Context Learning on Vision-language Models", "Authors": ["Shuo Chen", "Zhen Han", "Bailan He", "Mark Buckley", "Philip Torr", "Volker Tresp", "Jindong Gu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "10 figures"]}, "abstract": "Recently, in-context learning (ICL) on large language models (LLMs) has received great attention, and this technique can also be applied to vision-language models (VLMs) built upon LLMs. These VLMs can respond to queries by conditioning responses on a series of multimodal demonstrations, which comprise images, queries, and answers. Though ICL has been extensively studied on LLMs, its research on VLMs remains limited. The inclusion of additional visual information in the demonstrations motivates the following research questions: which of the two modalities in the demonstration is more significant? How can we select effective multimodal demonstrations to enhance ICL performance? This study investigates the significance of both visual and language information. Our findings indicate that ICL in VLMs is predominantly driven by the textual information in the demonstrations whereas the visual information in the demonstrations barely affects the ICL performance. Subsequently, we provide an understanding of the findings by analyzing the model information flow and comparing model inner states given different ICL settings. Motivated by our analysis, we propose a simple yet effective approach, termed Mixed Modality In-Context Example Selection (MMICES), which considers both visual and language modalities when selecting demonstrations and shows better ICL performance. Extensive experiments are conducted to support our findings, understanding, and improvement of the ICL performance of VLMs.", "url": "https://arxiv.org/abs/2311.18021"}, {"metadata": {"arXiv": "2311.18102", "Date": "Wed, 29 Nov 2023 21:39:24 ", "Title": "PatchBMI-Net: Lightweight Facial Patch-based Ensemble for BMI Prediction", "Authors": ["Parshuram N. Aarotale", "Twyla Hill", "Ajita Rattani"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["7 pages,3 figures"]}, "abstract": "Due to an alarming trend related to obesity affecting 93.3 million adults in the United States alone, body mass index (BMI) and body weight have drawn significant interest in various health monitoring applications. Consequently, several studies have proposed self-diagnostic facial image-based BMI prediction methods for healthy weight monitoring. These methods have mostly used convolutional neural network (CNN) based regression baselines, such as VGG19, ResNet50, and Efficient-NetB0, for BMI prediction from facial images. However, the high computational requirement of these heavy-weight CNN models limits their deployment to resource-constrained mobile devices, thus deterring weight monitoring using smartphones. This paper aims to develop a lightweight facial patch-based ensemble (PatchBMI-Net) for BMI prediction to facilitate the deployment and weight monitoring using smartphones. Extensive experiments on BMI-annotated facial image datasets suggest that our proposed PatchBMI-Net model can obtain Mean Absolute Error (MAE) in the range [3.58, 6.51] with a size of about 3.3 million parameters. On cross-comparison with heavyweight models, such as ResNet-50 and Xception, trained for BMI pre- diction from facial images, our proposed PatchBMI-Net obtains equivalent MAE along with the model size reduction of about 5.4x and the average inference time reduction of about 3x when deployed on Apple-14 smartphone. Thus, demonstrating performance efficiency as well as low latency for on-device deployment and weight monitoring using smartphone applications.", "url": "https://arxiv.org/abs/2311.18102"}, {"metadata": {"arXiv": "2311.18491", "Date": "Thu, 30 Nov 2023 12:06:15 ", "Title": "ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs", "Authors": ["Violeta Men\\'endez Gonz\\'alez", "Andrew Gilbert", "Graeme Phillipson", "Stephen Jolly", "Simon Hadfield"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["VUA BMVC 2023"]}, "abstract": "In the field of media production, video editing techniques play a pivotal role. Recent approaches have had great success at performing novel view image synthesis of static scenes. But adding temporal information adds an extra layer of complexity. Previous models have focused on implicitly representing static and dynamic scenes using NeRF. These models achieve impressive results but are costly at training and inference time. They overfit an MLP to describe the scene implicitly as a function of position. This paper proposes ZeST-NeRF, a new approach that can produce temporal NeRFs for new scenes without retraining. We can accurately reconstruct novel views using multi-view synthesis techniques and scene flow-field estimation, trained only with unrelated scenes. We demonstrate how existing state-of-the-art approaches from a range of fields cannot adequately solve this new task and demonstrate the efficacy of our solution. The resulting network improves quantitatively by 15% and produces significantly better visual results.", "url": "https://arxiv.org/abs/2311.18491"}, {"metadata": {"arXiv": "2311.18531", "Date": "Thu, 30 Nov 2023 13:15:28 ", "Title": "Dataset Distillation via the Wasserstein Metric", "Authors": ["Haoyang Liu", "Tiancheng Xing", "Luwei Li", "Vibhu Dalal", "Jingrui He", "Haohan Wang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "10 figures"]}, "abstract": "Dataset distillation (DD) offers a compelling approach in computer vision, with the goal of condensing extensive datasets into smaller synthetic versions without sacrificing much of the model performance. In this paper, we continue to study the methods for DD, by addressing its conceptually core objective: how to capture the essential representation of extensive datasets in smaller, synthetic forms. We propose a novel approach utilizing the Wasserstein distance, a metric rooted in optimal transport theory, to enhance distribution matching in DD. Our method leverages the Wasserstein barycenter, offering a geometrically meaningful way to quantify distribution differences and effectively capture the centroid of a set of distributions. Our approach retains the computational benefits of distribution matching-based methods while achieving new state-of-the-art performance on several benchmarks. To provide useful prior for learning the images, we embed the synthetic data into the feature space of pretrained classification models to conduct distribution matching. Extensive testing on various high-resolution datasets confirms the effectiveness and adaptability of our method, indicating the promising yet unexplored capabilities of Wasserstein metrics in dataset distillation.", "url": "https://arxiv.org/abs/2311.18531"}, {"metadata": {"arXiv": "2311.18608", "Date": "Thu, 30 Nov 2023 15:06:10 ", "Title": "Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing", "Authors": ["Hyelin Nam", "Gihyun Kwon", "Geon Yeong Park", "Jong Chul Ye"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project page: https://hyelinnam.github.io/CDS/"]}, "abstract": "With the remarkable advent of text-to-image diffusion models, image editing methods have become more diverse and continue to evolve. A promising recent approach in this realm is Delta Denoising Score (DDS) - an image editing technique based on Score Distillation Sampling (SDS) framework that leverages the rich generative prior of text-to-image diffusion models. However, relying solely on the difference between scoring functions is insufficient for preserving specific structural elements from the original image, a crucial aspect of image editing. Inspired by the similarity and importance differences between DDS and the contrastive learning for unpaired image-to-image translation (CUT), here we present an embarrassingly simple yet very powerful modification of DDS, called Contrastive Denoising Score (CDS), for latent diffusion models (LDM). Specifically, to enforce structural correspondence between the input and output while maintaining the controllability of contents, we introduce a straightforward approach to regulate structural consistency using CUT loss within the DDS framework. To calculate this loss, instead of employing auxiliary networks, we utilize the intermediate features of LDM, in particular, those from the self-attention layers, which possesses rich spatial information. Our approach enables zero-shot image-to-image translation and neural radiance field (NeRF) editing, achieving a well-balanced interplay between maintaining the structural details and transforming content. Qualitative results and comparisons demonstrates the effectiveness of our proposed method. Project page with code is available at https://hyelinnam.github.io/CDS/.", "url": "https://arxiv.org/abs/2311.18608"}, {"metadata": {"arXiv": "2311.18763", "Date": "Thu, 30 Nov 2023 18:04:21 ", "Title": "Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters", "Authors": ["James Seale Smith", "Yen-Chang Hsu", "Zsolt Kira", "Yilin Shen", "Hongxia Jin"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recent work has demonstrated a remarkable ability to customize text-to-image diffusion models to multiple, fine-grained concepts in a sequential (i.e., continual) manner while only providing a few example images for each concept. This setting is known as continual diffusion. Here, we ask the question: Can we scale these methods to longer concept sequences without forgetting? Although prior work mitigates the forgetting of previously learned concepts, we show that its capacity to learn new tasks reaches saturation over longer sequences. We address this challenge by introducing a novel method, STack-And-Mask INcremental Adapters (STAMINA), which is composed of low-ranked attention-masked adapters and customized MLP tokens. STAMINA is designed to enhance the robust fine-tuning properties of LoRA for sequential concept learning via learnable hard-attention masks parameterized with low rank MLPs, enabling precise, scalable learning via sparse adaptation. Notably, all introduced trainable parameters can be folded back into the model after training, inducing no additional inference parameter costs. We show that STAMINA outperforms the prior SOTA for the setting of text-to-image continual customization on a 50-concept benchmark composed of landmarks and human faces, with no stored replay data. Additionally, we extended our method to the setting of continual learning for image classification, demonstrating that our gains also translate to state-of-the-art performance in this standard benchmark.", "url": "https://arxiv.org/abs/2311.18763"}, {"metadata": {"arXiv": "2311.18765", "Date": "Thu, 30 Nov 2023 18:05:52 ", "Title": "MLLMs-Augmented Visual-Language Representation Learning", "Authors": ["Yanqing Liu", "Kai Wang", "Wenqi Shao", "Ping Luo", "Yu Qiao", "Mike Zheng Shou", "Kaipeng Zhang and Yang You"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Visual-language pre-training (VLP) have achieved remarkable success in multi-modal tasks, largely attributed to the availability of large-scale image-text datasets. In this work, we demonstrate that multi-modal large language models (MLLMs) can enhance visual-language representation learning by improving data quality. Our approach is simple, utilizing MLLMs to extend multiple captions for each image. To prevent the bias that introduced by MLLMs' hallucinations and intrinsic caption styles, we propose a \"text shearing\" to keep the lengths of extended captions identical to the originals. In image-text retrieval, our method consistently obtains 5.6 ~ 35.0% and 16.8 ~ 46.1% improvement on R@1 under the fine-tuning and zero-shot settings, respectively. Notably, our zero-shot results are comparable to fine-tuning on target datasets, which encourages more exploration on the versatile use of MLLMs.", "url": "https://arxiv.org/abs/2311.18765"}, {"metadata": {"arXiv": "2311.18775", "Date": "Thu, 30 Nov 2023 18:21:25 ", "Title": "CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation", "Authors": ["Zineng Tang", "Ziyi Yang", "Mahmoud Khademi", "Yang Liu", "Chenguang Zhu", "Mohit Bansal"], "Categories": "cs.CV cs.AI cs.CL cs.LG cs.SD eess.AS", "Comments": ["Project Page: https://codi-2.github.io/"]}, "abstract": "We present CoDi-2, a versatile and interactive Multimodal Large Language Model (MLLM) that can follow complex multimodal interleaved instructions, conduct in-context learning (ICL), reason, chat, edit, etc., in an any-to-any input-output modality paradigm. By aligning modalities with language for both encoding and generation, CoDi-2 empowers Large Language Models (LLMs) to not only understand complex modality-interleaved instructions and in-context examples, but also autoregressively generate grounded and coherent multimodal outputs in the continuous feature space. To train CoDi-2, we build a large-scale generation dataset encompassing in-context multimodal instructions across text, vision, and audio. CoDi-2 demonstrates a wide range of zero-shot capabilities for multimodal generation, such as in-context learning, reasoning, and compositionality of any-to-any modality generation through multi-round interactive conversation. CoDi-2 surpasses previous domain-specific models on tasks such as subject-driven image generation, vision transformation, and audio editing. CoDi-2 signifies a substantial breakthrough in developing a comprehensive multimodal foundation model adept at interpreting in-context language-vision-audio interleaved instructions and producing multimodal outputs.", "url": "https://arxiv.org/abs/2311.18775"}, {"metadata": {"arXiv": "2311.18837", "Date": "Thu, 30 Nov 2023 18:59:52 ", "Title": "VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion Models", "Authors": ["Zhen Xing and Qi Dai and Zihao Zhang and Hui Zhang and Han Hu and Zuxuan Wu and Yu-Gang Jiang"], "Categories": "cs.CV cs.AI cs.LG cs.MM"}, "abstract": "Diffusion models have achieved significant success in image and video generation. This motivates a growing interest in video editing tasks, where videos are edited according to provided text descriptions. However, most existing approaches only focus on video editing for short clips and rely on time-consuming tuning or inference. We are the first to propose Video Instruction Diffusion (VIDiff), a unified foundation model designed for a wide range of video tasks. These tasks encompass both understanding tasks (such as language-guided video object segmentation) and generative tasks (video editing and enhancement). Our model can edit and translate the desired results within seconds based on user instructions. Moreover, we design an iterative auto-regressive method to ensure consistency in editing and enhancing long videos. We provide convincing generative results for diverse input videos and written instructions, both qualitatively and quantitatively. More examples can be found at our website https://ChenHsing.github.io/VIDiff.", "url": "https://arxiv.org/abs/2311.18837"}, {"metadata": {"arXiv": "2311.18838", "Date": "Thu, 30 Nov 2023 18:59:56 ", "Title": "Dataset Distillation in Large Data Era", "Authors": ["Zeyuan Yin and Zhiqiang Shen"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code and distilled ImageNet-21K dataset are available at https://github.com/VILA-Lab/SRe2L/tree/main/CDA"]}, "abstract": "Dataset distillation aims to generate a smaller but representative subset from a large dataset, which allows a model to be trained efficiently, meanwhile evaluating on the original testing data distribution to achieve decent performance. Many prior works have aimed to align with diverse aspects of the original datasets, such as matching the training weight trajectories, gradient, feature/BatchNorm distributions, etc. In this work, we show how to distill various large-scale datasets such as full ImageNet-1K/21K under a conventional input resolution of 224$\\times$224 to achieve the best accuracy over all previous approaches, including SRe$^2$L, TESLA and MTT. To achieve this, we introduce a simple yet effective ${\\bf C}$urriculum ${\\bf D}$ata ${\\bf A}$ugmentation ($\\texttt{CDA}$) during data synthesis that obtains the accuracy on large-scale ImageNet-1K and 21K with 63.2% under IPC (Images Per Class) 50 and 36.1% under IPC 20, respectively. Finally, we show that, by integrating all our enhancements together, the proposed model beats the current state-of-the-art by more than 4% Top-1 accuracy on ImageNet-1K/21K and for the first time, reduces the gap to its full-data training counterpart to less than absolute 15%. Moreover, this work represents the inaugural success in dataset distillation on larger-scale ImageNet-21K under the standard 224$\\times$224 resolution. Our code and distilled ImageNet-21K dataset of 20 IPC, 2K recovery budget are available at https://github.com/VILA-Lab/SRe2L/tree/main/CDA.", "url": "https://arxiv.org/abs/2311.18838"}, {"metadata": {"arXiv": "2311.17943", "Date": "Wed, 29 Nov 2023 01:23:41 ", "Title": "LayerCollapse: Adaptive compression of neural networks", "Authors": ["Soheil Zibakhsh Shabgahi", "Mohammad Soheil Shariff", "Farinaz Koushanfar"], "Categories": "cs.LG cs.AI"}, "abstract": "Handling the ever-increasing scale of contemporary deep learning and transformer-based models poses a significant challenge. Although great strides have been made in optimizing model compression techniques such as model architecture search and knowledge distillation, the availability of data and computational resources remains a considerable hurdle for these optimizations. This paper introduces LayerCollapse, a novel alternative adaptive model compression methodology. LayerCollapse works by eliminating non-linearities within the network and collapsing two consecutive fully connected layers into a single linear transformation. This approach simultaneously reduces both the number of layers and the parameter count, thereby enhancing model efficiency. We also introduce a compression aware regularizer, which compresses the model in alignment with the dataset quality and model expressiveness, consequently reducing overfitting across tasks. Our results demonstrate LayerCollapse's effective compression and regularization capabilities in multiple fine-grained classification benchmarks, achieving up to 74% post training compression with minimal accuracy loss. We compare this method with knowledge distillation on the same target network, showcasing a five-fold increase in computational efficiency and 8% improvement in overall accuracy on the ImageNet dataset.", "url": "https://arxiv.org/abs/2311.17943"}, {"metadata": {"arXiv": "2311.17958", "Date": "Wed, 29 Nov 2023 09:31:52 ", "Title": "CommunityAI: Towards Community-based Federated Learning", "Authors": ["Ilir Murturi", "Praveen Kumar Donta", "Schahram Dustdar"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Federated Learning (FL) has emerged as a promising paradigm to train machine learning models collaboratively while preserving data privacy. However, its widespread adoption faces several challenges, including scalability, heterogeneous data and devices, resource constraints, and security concerns. Despite its promise, FL has not been specifically adapted for community domains, primarily due to the wide-ranging differences in data types and context, devices and operational conditions, environmental factors, and stakeholders. In response to these challenges, we present a novel framework for Community-based Federated Learning called CommunityAI. CommunityAI enables participants to be organized into communities based on their shared interests, expertise, or data characteristics. Community participants collectively contribute to training and refining learning models while maintaining data and participant privacy within their respective groups. Within this paper, we discuss the conceptual architecture, system requirements, processes, and future challenges that must be solved. Finally, our goal within this paper is to present our vision regarding enabling a collaborative learning process within various communities.", "url": "https://arxiv.org/abs/2311.17958"}, {"metadata": {"arXiv": "2311.17959", "Date": "Wed, 29 Nov 2023 10:56:02 ", "Title": "Transformer Based Model for Predicting Rapid Impact Compaction Outcomes: A Case Study of Utapao International Airport", "Authors": ["Sompote Youwai and Sirasak Detcheewa"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper introduces a novel deep learning approach to predict the engineering properties of the ground improved by Rapid Impact Compaction (RIC), which is a ground improvement technique that uses a drop hammer to compact the soil and fill layers. The proposed approach uses transformer-based neural networks to capture the complex nonlinear relationships between the input features, such as the hammer energy, drop height, and number of blows, and the output variables, such as the cone resistance. The approach is applied to a real-world dataset from a trial test section for the new apron construction of the Utapao International Airport in Thailand. The results show that the proposed approach outperforms the existing methods in terms of prediction accuracy and efficiency and provides interpretable attention maps that reveal the importance of different features for RIC prediction. The paper also discusses the limitations and future directions of applying deep learning methods to RIC prediction.", "url": "https://arxiv.org/abs/2311.17959"}, {"metadata": {"arXiv": "2311.17973", "Date": "Wed, 29 Nov 2023 16:16:32 ", "Title": "Homogeneous Artificial Neural Network", "Authors": ["Andrey Polyakov"], "Categories": "cs.LG cs.AI cs.NA cs.NE cs.SY eess.SY math.NA math.OC", "MSC-class": "68T07, 93C10, 93D15"}, "abstract": "The paper proposes an artificial neural network (ANN) being a global approximator for a special class of functions, which are known as generalized homogeneous. The homogeneity means a symmetry of a function with respect to a group of transformations having topological characterization of a dilation. In this paper, a class of the so-called linear dilations is considered. A homogeneous universal approximation theorem is proven. Procedures for an upgrade of an existing ANN to a homogeneous one are developed. Theoretical results are supported by examples from the various domains (computer science, systems theory and automatic control).", "url": "https://arxiv.org/abs/2311.17973"}, {"metadata": {"arXiv": "2311.18022", "Date": "Wed, 29 Nov 2023 19:09:48 ", "Title": "A trainable manifold for accurate approximation with ReLU Networks", "Authors": ["Max Milkert and Forrest Laine"], "Categories": "cs.LG cs.AI", "Comments": ["13 pages", "6 figures"]}, "abstract": "We present a novel technique for exercising greater control of the weights of ReLU activated neural networks to produce more accurate function approximations. Many theoretical works encode complex operations into ReLU networks using smaller base components. In these works, a common base component is a constant width approximation to x^2, which has exponentially decaying error with respect to depth. We extend this block to represent a greater range of convex one-dimensional functions. We derive a manifold of weights such that the output of these new networks utilizes exponentially many piecewise-linear segments. This manifold guides their training process to overcome drawbacks associated with random initialization and unassisted gradient descent. We train these networks to approximate functions which do not necessarily lie on the manifold, showing a significant reduction of error values over conventional approaches.", "url": "https://arxiv.org/abs/2311.18022"}, {"metadata": {"arXiv": "2311.18029", "Date": "Wed, 29 Nov 2023 19:13:10 ", "Title": "A Bag of Receptive Fields for Time Series Extrinsic Predictions", "Authors": ["Francesco Spinnato and Riccardo Guidotti and Anna Monreale and Mirco Nanni"], "Categories": "cs.LG cs.AI"}, "abstract": "High-dimensional time series data poses challenges due to its dynamic nature, varying lengths, and presence of missing values. This kind of data requires extensive preprocessing, limiting the applicability of existing Time Series Classification and Time Series Extrinsic Regression techniques. For this reason, we propose BORF, a Bag-Of-Receptive-Fields model, which incorporates notions from time series convolution and 1D-SAX to handle univariate and multivariate time series with varying lengths and missing values. We evaluate BORF on Time Series Classification and Time Series Extrinsic Regression tasks using the full UEA and UCR repositories, demonstrating its competitive performance against state-of-the-art methods. Finally, we outline how this representation can naturally provide saliency and feature-based explanations.", "url": "https://arxiv.org/abs/2311.18029"}, {"metadata": {"arXiv": "2311.18062", "Date": "Wed, 29 Nov 2023 20:16:23 ", "Title": "Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation", "Authors": ["Xijia Zhang", "Yue Guo", "Simon Stepputtis", "Katia Sycara", "Joseph Campbell"], "Categories": "cs.LG cs.AI"}, "abstract": "Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts; however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, thus making our method independent from the underlying model's representation. For such models, we first learn a behavior representation and subsequently use it to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. We evaluate our method in a multi-agent search-and-rescue environment and demonstrate the effectiveness of our explanations for agents executing various behaviors. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those produced by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.", "url": "https://arxiv.org/abs/2311.18062"}, {"metadata": {"arXiv": "2311.18190", "Date": "Thu, 30 Nov 2023 02:19:35 ", "Title": "Toward the Tradeoffs between Privacy, Fairness and Utility in Federated Learning", "Authors": ["Kangkang Sun", "Xiaojin Zhang", "Xi Lin", "Gaolei Li", "Jing Wang", "and Jianhua Li"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages", "3 figures", "conference"], "Report-no": "EISA2023 732"}, "abstract": "Federated Learning (FL) is a novel privacy-protection distributed machine learning paradigm that guarantees user privacy and prevents the risk of data leakage due to the advantage of the client's local training. Researchers have struggled to design fair FL systems that ensure fairness of results. However, the interplay between fairness and privacy has been less studied. Increasing the fairness of FL systems can have an impact on user privacy, while an increase in user privacy can affect fairness. In this work, on the client side, we use fairness metrics, such as Demographic Parity (DemP), Equalized Odds (EOs), and Disparate Impact (DI), to construct the local fair model. To protect the privacy of the client model, we propose a privacy-protection fairness FL method. The results show that the accuracy of the fair model with privacy increases because privacy breaks the constraints of the fairness metrics. In our experiments, we conclude the relationship between privacy, fairness and utility, and there is a tradeoff between these.", "url": "https://arxiv.org/abs/2311.18190"}, {"metadata": {"arXiv": "2311.18206", "Date": "Thu, 30 Nov 2023 02:56:43 ", "Title": "SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation", "Authors": ["Haruka Kiyohara", "Ren Kishimoto", "Kosuke Kawakami", "Ken Kobayashi", "Kazuhide Nakata", "Yuta Saito"], "Categories": "cs.LG cs.AI", "Comments": ["preprint", "open-source software: https://github.com/hakuhodo-technologies/scope-rl"]}, "abstract": "This paper introduces SCOPE-RL, a comprehensive open-source Python software designed for offline reinforcement learning (offline RL), off-policy evaluation (OPE), and selection (OPS). Unlike most existing libraries that focus solely on either policy learning or evaluation, SCOPE-RL seamlessly integrates these two key aspects, facilitating flexible and complete implementations of both offline RL and OPE processes. SCOPE-RL put particular emphasis on its OPE modules, offering a range of OPE estimators and robust evaluation-of-OPE protocols. This approach enables more in-depth and reliable OPE compared to other packages. For instance, SCOPE-RL enhances OPE by estimating the entire reward distribution under a policy rather than its mere point-wise expected value. Additionally, SCOPE-RL provides a more thorough evaluation-of-OPE by presenting the risk-return tradeoff in OPE results, extending beyond mere accuracy evaluations in existing OPE literature. SCOPE-RL is designed with user accessibility in mind. Its user-friendly APIs, comprehensive documentation, and a variety of easy-to-follow examples assist researchers and practitioners in efficiently implementing and experimenting with various offline RL methods and OPE estimators, tailored to their specific problem contexts. The documentation of SCOPE-RL is available at https://scope-rl.readthedocs.io/en/latest/.", "url": "https://arxiv.org/abs/2311.18206"}, {"metadata": {"arXiv": "2311.18207", "Date": "Thu, 30 Nov 2023 02:56:49 ", "Title": "Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation", "Authors": ["Haruka Kiyohara", "Ren Kishimoto", "Kosuke Kawakami", "Ken Kobayashi", "Kazuhide Nakata", "Yuta Saito"], "Categories": "cs.LG cs.AI", "Comments": ["preprint", "under review"]}, "abstract": "Off-Policy Evaluation (OPE) aims to assess the effectiveness of counterfactual policies using only offline logged data and is often used to identify the top-k promising policies for deployment in online A/B tests. Existing evaluation metrics for OPE estimators primarily focus on the \"accuracy\" of OPE or that of downstream policy selection, neglecting risk-return tradeoff in the subsequent online policy deployment. To address this issue, we draw inspiration from portfolio evaluation in finance and develop a new metric, called SharpeRatio@k, which measures the risk-return tradeoff of policy portfolios formed by an OPE estimator under varying online evaluation budgets (k). We validate our metric in two example scenarios, demonstrating its ability to effectively distinguish between low-risk and high-risk estimators and to accurately identify the most efficient estimator. This efficient estimator is characterized by its capability to form the most advantageous policy portfolios, maximizing returns while minimizing risks during online deployment, a nuance that existing metrics typically overlook. To facilitate a quick, accurate, and consistent evaluation of OPE via SharpeRatio@k, we have also integrated this metric into an open-source software, SCOPE-RL. Employing SharpeRatio@k and SCOPE-RL, we conduct comprehensive benchmarking experiments on various estimators and RL tasks, focusing on their risk-return tradeoff. These experiments offer several interesting directions and suggestions for future OPE research.", "url": "https://arxiv.org/abs/2311.18207"}, {"metadata": {"arXiv": "2311.18460", "Date": "Thu, 30 Nov 2023 11:11:26 ", "Title": "Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework", "Authors": ["Maresa Schr\\\"oder", "Dennis Frauen", "Stefan Feuerriegel"], "Categories": "cs.LG cs.AI cs.CY stat.ME"}, "abstract": "Fairness for machine learning predictions is widely required in practice for legal, ethical, and societal reasons. Existing work typically focuses on settings without unobserved confounding, even though unobserved confounding can lead to severe violations of causal fairness and, thus, unfair predictions. In this work, we analyze the sensitivity of causal fairness to unobserved confounding. Our contributions are three-fold. First, we derive bounds for causal fairness metrics under different sources of unobserved confounding. This enables practitioners to examine the sensitivity of their machine learning models to unobserved confounding in fairness-critical applications. Second, we propose a novel neural framework for learning fair predictions, which allows us to offer worst-case guarantees of the extent to which causal fairness can be violated due to unobserved confounding. Third, we demonstrate the effectiveness of our framework in a series of experiments, including a real-world case study about predicting prison sentences. To the best of our knowledge, ours is the first work to study causal fairness under unobserved confounding. To this end, our work is of direct practical value as a refutation strategy to ensure the fairness of predictions in high-stakes applications.", "url": "https://arxiv.org/abs/2311.18460"}, {"metadata": {"arXiv": "2311.18547", "Date": "Thu, 30 Nov 2023 13:30:00 ", "Title": "Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying Speed Conditions", "Authors": ["Tuomas Jalonen", "Mohammad Al-Sa'd", "Serkan Kiranyaz", "and Moncef Gabbouj"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "Detection of rolling-element bearing faults is crucial for implementing proactive maintenance strategies and for minimizing the economic and operational consequences of unexpected failures. However, many existing techniques are developed and tested under strictly controlled conditions, limiting their adaptability to the diverse and dynamic settings encountered in practical applications. This paper presents an efficient real-time convolutional neural network (CNN) for diagnosing multiple bearing faults under various noise levels and time-varying rotational speeds. Additionally, we propose a novel Fisher-based spectral separability analysis (SSA) method to elucidate the effectiveness of the designed CNN model. We conducted experiments on both healthy bearings and bearings afflicted with inner race, outer race, and roller ball faults. The experimental results show the superiority of our model over the current state-of-the-art approach in three folds: it achieves substantial accuracy gains of up to 15.8%, it is robust to noise with high performance across various signal-to-noise ratios, and it runs in real-time with processing durations five times less than acquisition. Additionally, by using the proposed SSA technique, we offer insights into the model's performance and underscore its effectiveness in tackling real-world challenges.", "url": "https://arxiv.org/abs/2311.18547"}, {"metadata": {"arXiv": "2311.18578", "Date": "Thu, 30 Nov 2023 14:17:57 ", "Title": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum", "Authors": ["Riccardo Zaccone", "Carlo Masone", "Marco Ciccone"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Federated Learning (FL) is the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios. As the current literature reports, the main problems associated with FL refer to system and statistical challenges: the former ones demand for efficient learning from edge devices, including lowering communication bandwidth and frequency, while the latter require algorithms robust to non-iidness. State-of-art approaches either guarantee convergence at increased communication cost or are not sufficiently robust to handle extreme heterogeneous local distributions. In this work we propose a novel generalization of the heavy-ball momentum, and present FedHBM to effectively address statistical heterogeneity in FL without introducing any communication overhead. We conduct extensive experimentation on common FL vision and NLP datasets, showing that our FedHBM algorithm empirically yields better model quality and higher convergence speed w.r.t. the state-of-art, especially in pathological non-iid scenarios. While being designed for cross-silo settings, we show how FedHBM is applicable in moderate-to-high cross-device scenarios, and how good model initializations (e.g. pre-training) can be exploited for prompt acceleration. Extended experimentation on large-scale real-world federated datasets further corroborates the effectiveness of our approach for real-world FL applications.", "url": "https://arxiv.org/abs/2311.18578"}, {"metadata": {"arXiv": "2311.18587", "Date": "Thu, 30 Nov 2023 14:28:25 ", "Title": "Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural Networks", "Authors": ["Juyoung Yun"], "Categories": "cs.LG cs.AI"}, "abstract": "In the field of deep learning, the prevalence of models initially trained with 32-bit precision is a testament to its robustness and accuracy. However, the continuous evolution of these models often demands further training, which can be resource-intensive. This study introduces a novel approach where we continue the training of these pre-existing 32-bit models using 16-bit precision. This technique not only caters to the need for efficiency in computational resources but also significantly improves the speed of additional training phases. By adopting 16-bit precision for ongoing training, we are able to substantially decrease memory requirements and computational burden, thereby accelerating the training process in a resource-limited setting. Our experiments show that this method maintains the high standards of accuracy set by the original 32-bit training while providing a much-needed boost in training speed. This approach is especially pertinent in today's context, where most models are initially trained in 32-bit and require periodic updates and refinements. The findings from our research suggest that this strategy of 16-bit continuation training can be a key solution for sustainable and efficient deep learning, offering a practical way to enhance pre-trained models rapidly and in a resource-conscious manner.", "url": "https://arxiv.org/abs/2311.18587"}, {"metadata": {"arXiv": "2311.18598", "Date": "Thu, 30 Nov 2023 14:45:51 ", "Title": "Generalisable Agents for Neural Network Optimisation", "Authors": ["Kale-ab Tessera", "Callum Rhys Tilbury", "Sasha Abramowitz", "Ruan de Kock", "Omayma Mahjoub", "Benjamin Rosman", "Sara Hooker", "Arnu Pretorius"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["Accepted at the Workshop on Advanced Neural Network Training (WANT) and Optimization for Machine Learning (OPT) at NeurIPS 2023"]}, "abstract": "Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can successfully generalise to harder problems than it was trained on. Our work presents an overview of the opportunities that this paradigm offers for training neural networks, along with key challenges that remain to be overcome.", "url": "https://arxiv.org/abs/2311.18598"}, {"metadata": {"arXiv": "2311.18703", "Date": "Thu, 30 Nov 2023 16:53:32 ", "Title": "Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization", "Authors": ["Daniel Jarne Ornia", "Giannis Delimpaltadakis", "Jens Kober", "Javier Alonso-Mora"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularization) to randomize their actions in favor of exploration. From a human perspective, this makes RL agents hard to interpret and predict, and from a safety perspective, even harder to formally verify. We propose a novel method to induce predictable behavior in RL agents, referred to as Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate as a predictability measure. We show how the entropy rate can be formulated as an average reward objective, and since its entropy reward function is policy-dependent, we introduce an action-dependent surrogate entropy enabling the use of PG methods. We prove that deterministic policies minimizing the average surrogate reward exist and also minimize the actual entropy rate, and show how, given a learned dynamical model, we are able to approximate the value function associated to the true entropy rate. Finally, we demonstrate the effectiveness of the approach in RL tasks inspired by human-robot use-cases, and show how it produces agents with more predictable behavior while achieving near-optimal rewards.", "url": "https://arxiv.org/abs/2311.18703"}, {"metadata": {"arXiv": "2311.18749", "Date": "Thu, 30 Nov 2023 17:47:02 ", "Title": "TransCORALNet: A Two-Stream Transformer CORAL Networks for Supply Chain Credit Assessment Cold Start", "Authors": ["Jie Shi", "Arno P. J. M. Siebes", "Siamak Mehrkanoon"], "Categories": "cs.LG cs.AI q-fin.RM", "Comments": ["13 pages", "7 figures"], "ACM-class": "I.2; I.5"}, "abstract": "This paper proposes an interpretable two-stream transformer CORAL networks (TransCORALNet) for supply chain credit assessment under the segment industry and cold start problem. The model aims to provide accurate credit assessment prediction for new supply chain borrowers with limited historical data. Here, the two-stream domain adaptation architecture with correlation alignment (CORAL) loss is used as a core model and is equipped with transformer, which provides insights about the learned features and allow efficient parallelization during training. Thanks to the domain adaptation capability of the proposed model, the domain shift between the source and target domain is minimized. Therefore, the model exhibits good generalization where the source and target do not follow the same distribution, and a limited amount of target labeled instances exist. Furthermore, we employ Local Interpretable Model-agnostic Explanations (LIME) to provide more insight into the model prediction and identify the key features contributing to supply chain credit assessment decisions. The proposed model addresses four significant supply chain credit assessment challenges: domain shift, cold start, imbalanced-class and interpretability. Experimental results on a real-world data set demonstrate the superiority of TransCORALNet over a number of state-of-the-art baselines in terms of accuracy. The code is available on GitHub \\footnote{Github}.", "url": "https://arxiv.org/abs/2311.18749"}, {"metadata": {"arXiv": "2311.18751", "Date": "Thu, 30 Nov 2023 17:50:47 ", "Title": "Language Model Agents Suffer from Compositional Generalization in Web Automation", "Authors": ["Hiroki Furuta", "Yutaka Matsuo", "Aleksandra Faust", "Izzeddin Gur"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["Code: https://github.com/google-research/google-research/tree/master/compositional_rl/compwob"]}, "abstract": "Language model agents (LMA) recently emerged as a promising paradigm on muti-step decision making tasks, often outperforming humans and other reinforcement learning agents. Despite the promise, their performance on real-world applications that often involve combinations of tasks is still underexplored. In this work, we introduce a new benchmark, called CompWoB -- 50 new compositional web automation tasks reflecting more realistic assumptions. We show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve 94.0% average success rate on base tasks, their performance degrades to 24.9% success rate on compositional tasks. On the other hand, transferred LMAs (finetuned only on base tasks) show less generalization gap, dropping from 85.4% to 54.8%. By balancing data distribution across tasks, we train a new model, HTML-T5++, that surpasses human-level performance (95.2%) on MiniWoB, and achieves the best zero-shot performance on CompWoB (61.5%). While these highlight the promise of small-scale finetuned and transferred models for compositional generalization, their performance further degrades under different instruction compositions changing combinational order. In contrast to the recent remarkable success of LMA, our benchmark and detailed analysis emphasize the necessity of building LMAs that are robust and generalizable to task compositionality for real-world deployment.", "url": "https://arxiv.org/abs/2311.18751"}, {"metadata": {"arXiv": "2311.18817", "Date": "Thu, 30 Nov 2023 18:55:38 ", "Title": "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking", "Authors": ["Kaifeng Lyu", "Jikai Jin", "Zhiyuan Li", "Simon S. Du", "Jason D. Lee", "Wei Hu"], "Categories": "cs.LG cs.AI", "Comments": ["39 pages", "4 figures"]}, "abstract": "Recent work by Power et al. (2022) highlighted a surprising \"grokking\" phenomenon in learning arithmetic tasks: a neural net first \"memorizes\" the training set, resulting in perfect training accuracy but near-random test accuracy, and after training for sufficiently longer, it suddenly transitions to perfect test accuracy. This paper studies the grokking phenomenon in theoretical setups and shows that it can be induced by a dichotomy of early and late phase implicit biases. Specifically, when training homogeneous neural nets with large initialization and small weight decay on both classification and regression tasks, we prove that the training process gets trapped at a solution corresponding to a kernel predictor for a long time, and then a very sharp transition to min-norm/max-margin predictors occurs, leading to a dramatic change in test accuracy.", "url": "https://arxiv.org/abs/2311.18817"}, {"metadata": {"arXiv": "2311.18736", "Date": "Thu, 30 Nov 2023 17:34:05 ", "Title": "Controlgym: Large-Scale Safety-Critical Control Environments for Benchmarking Reinforcement Learning Algorithms", "Authors": ["Xiangyuan Zhang", "Weichao Mao", "Saviz Mowlavi", "Mouhacine Benosman", "Tamer Ba\\c{s}ar"], "Categories": "eess.SY cs.AI cs.CE cs.LG cs.SY math.OC", "Comments": ["25 pages", "16 figures"]}, "abstract": "We introduce controlgym, a library of thirty-six safety-critical industrial control settings, and ten infinite-dimensional partial differential equation (PDE)-based control problems. Integrated within the OpenAI Gym/Gymnasium (Gym) framework, controlgym allows direct applications of standard reinforcement learning (RL) algorithms like stable-baselines3. Our control environments complement those in Gym with continuous, unbounded action and observation spaces, motivated by real-world control applications. Moreover, the PDE control environments uniquely allow the users to extend the state dimensionality of the system to infinity while preserving the intrinsic dynamics. This feature is crucial for evaluating the scalability of RL algorithms for control. This project serves the learning for dynamics & control (L4DC) community, aiming to explore key questions: the convergence of RL algorithms in learning control policies; the stability and robustness issues of learning-based controllers; and the scalability of RL algorithms to high- and potentially infinite-dimensional systems. We open-source the controlgym project at https://github.com/xiangyuan-zhang/controlgym.", "url": "https://arxiv.org/abs/2311.18736"}, {"metadata": {"arXiv": "2311.18741", "Date": "Thu, 30 Nov 2023 17:38:54 ", "Title": "VREM-FL: Mobility-Aware Computation-Scheduling Co-Design for Vehicular Federated Learning", "Authors": ["Luca Ballotta", "Nicol\\`o Dal Fabbro", "Giovanni Perin", "Luca Schenato", "Michele Rossi and Giuseppe Piro"], "Categories": "eess.SY cs.AI cs.DC cs.LG cs.SY", "Comments": ["This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Assisted and autonomous driving are rapidly gaining momentum, and will soon become a reality. Among their key enablers, artificial intelligence and machine learning are expected to play a prominent role, also thanks to the massive amount of data that smart vehicles will collect from their onboard sensors. In this domain, federated learning is one of the most effective and promising techniques for training global machine learning models, while preserving data privacy at the vehicles and optimizing communications resource usage. In this work, we propose VREM-FL, a computation-scheduling co-design for vehicular federated learning that leverages mobility of vehicles in conjunction with estimated 5G radio environment maps. VREM-FL jointly optimizes the global model learned at the server while wisely allocating communication resources. This is achieved by orchestrating local computations at the vehicles in conjunction with the transmission of their local model updates in an adaptive and predictive fashion, by exploiting radio channel maps. The proposed algorithm can be tuned to trade model training time for radio resource usage. Experimental results demonstrate the efficacy of utilizing radio maps. VREM-FL outperforms literature benchmarks for both a linear regression model (learning time reduced by 28%) and a deep neural network for a semantic image segmentation task (doubling the number of model updates within the same time window).", "url": "https://arxiv.org/abs/2311.18741"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

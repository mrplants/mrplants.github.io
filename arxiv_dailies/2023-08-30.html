<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.14761", "Date": "Fri, 25 Aug 2023 17:59:59 ", "Title": "Unified Concept Editing in Diffusion Models", "Authors": ["Rohit Gandikota", "Hadas Orgad", "Yonatan Belinkov", "Joanna Materzy\\'nska", "David Bau"], "Categories": "cs.CV cs.LG"}, "abstract": "Text-to-image models suffer from various safety issues that may limit their suitability for deployment. Previous methods have separately addressed individual issues of bias, copyright, and offensive content in text-to-image models. However, in the real world, all of these issues appear simultaneously in the same model. We present a method that tackles all issues with a single approach. Our method, Unified Concept Editing (UCE), edits the model without training using a closed-form solution, and scales seamlessly to concurrent edits on text-conditional diffusion models. We demonstrate scalable simultaneous debiasing, style erasure, and content moderation by editing text-to-image projections, and we present extensive experiments demonstrating improved efficacy and scalability over prior work. Our code is available at https://unified.baulab.info", "url": "https://arxiv.org/abs/2308.14761"}, {"metadata": {"arXiv": "2308.14904", "Date": "Mon, 28 Aug 2023 21:13:04 ", "Title": "Maturity-Aware Active Learning for Semantic Segmentation with Hierarchically-Adaptive Sample Assessment", "Authors": ["Amirsaeed Yazdani", "Xuelu Li", "and Vishal Monga"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to the 34th British Machine Vision Conference (BMVC 2023)"], "MSC-class": "68-06", "ACM-class": "I.4.6; I.5.1"}, "abstract": "Active Learning (AL) for semantic segmentation is challenging due to heavy class imbalance and different ways of defining \"sample\" (pixels, areas, etc.), leaving the interpretation of the data distribution ambiguous. We propose \"Maturity-Aware Distribution Breakdown-based Active Learning'' (MADBAL), an AL method that benefits from a hierarchical approach to define a multiview data distribution, which takes into account the different \"sample\" definitions jointly, hence able to select the most impactful segmentation pixels with comprehensive understanding. MADBAL also features a novel uncertainty formulation, where AL supporting modules are included to sense the features' maturity whose weighted influence continuously contributes to the uncertainty detection. In this way, MADBAL makes significant performance leaps even in the early AL stage, hence reducing the training burden significantly. It outperforms state-of-the-art methods on Cityscapes and PASCAL VOC datasets as verified in our extensive experiments.", "url": "https://arxiv.org/abs/2308.14904"}, {"metadata": {"arXiv": "2308.14930", "Date": "Mon, 28 Aug 2023 23:08:32 ", "Title": "Application of Quantum Pre-Processing Filter for Binary Image Classification with Small Samples", "Authors": ["Farina Riaz and Shahab Abdulla and Hajime Suzuki and Srinjoy Ganguly and Ravinesh C. Deo and Susan Hopkins"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages", "8 figures"]}, "abstract": "Over the past few years, there has been significant interest in Quantum Machine Learning (QML) among researchers, as it has the potential to transform the field of machine learning. Several models that exploit the properties of quantum mechanics have been developed for practical applications. In this study, we investigated the application of our previously proposed quantum pre-processing filter (QPF) to binary image classification. We evaluated the QPF on four datasets: MNIST (handwritten digits), EMNIST (handwritten digits and alphabets), CIFAR-10 (photographic images) and GTSRB (real-life traffic sign images). Similar to our previous multi-class classification results, the application of QPF improved the binary image classification accuracy using neural network against MNIST, EMNIST, and CIFAR-10 from 98.9% to 99.2%, 97.8% to 98.3%, and 71.2% to 76.1%, respectively, but degraded it against GTSRB from 93.5% to 92.0%. We then applied QPF in cases using a smaller number of training and testing samples, i.e. 80 and 20 samples per class, respectively. In order to derive statistically stable results, we conducted the experiment with 100 trials choosing randomly different training and testing samples and averaging the results. The result showed that the application of QPF did not improve the image classification accuracy against MNIST and EMNIST but improved it against CIFAR-10 and GTSRB from 65.8% to 67.2% and 90.5% to 91.8%, respectively. Further research will be conducted as part of future work to investigate the potential of QPF to assess the scalability of the proposed approach to larger and complex datasets.", "url": "https://arxiv.org/abs/2308.14930"}, {"metadata": {"arXiv": "2308.14938", "Date": "Mon, 28 Aug 2023 23:33:07 ", "Title": "Entropy-based Guidance of Deep Neural Networks for Accelerated Convergence and Improved Performance", "Authors": ["Mackenzie J. Meni and Ryan T. White and Michael Mayo and Kevin Pilkiewicz"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["13 pages", "4 figures"]}, "abstract": "Neural networks have dramatically increased our capacity to learn from large, high-dimensional datasets across innumerable disciplines. However, their decisions are not easily interpretable, their computational costs are high, and building and training them are uncertain processes. To add structure to these efforts, we derive new mathematical results to efficiently measure the changes in entropy as fully-connected and convolutional neural networks process data, and introduce entropy-based loss terms. Experiments in image compression and image classification on benchmark datasets demonstrate these losses guide neural networks to learn rich latent data representations in fewer dimensions, converge in fewer training epochs, and achieve better test metrics.", "url": "https://arxiv.org/abs/2308.14938"}, {"metadata": {"arXiv": "2308.14995", "Date": "Tue, 29 Aug 2023 02:50:36 ", "Title": "WSAM: Visual Explanations from Style Augmentation as Adversarial Attacker and Their Influence in Image Classification", "Authors": ["Felipe Moreno-Vera and Edgar Medina and Jorge Poco"], "Categories": "cs.CV cs.LG", "Comments": ["8 pages", "10 figures"], "DOI": "10.5220/0011795400003417"}, "abstract": "Currently, style augmentation is capturing attention due to convolutional neural networks (CNN) being strongly biased toward recognizing textures rather than shapes. Most existing styling methods either perform a low-fidelity style transfer or a weak style representation in the embedding vector. This paper outlines a style augmentation algorithm using stochastic-based sampling with noise addition to improving randomization on a general linear transformation for style transfer. With our augmentation strategy, all models not only present incredible robustness against image stylizing but also outperform all previous methods and surpass the state-of-the-art performance for the STL-10 dataset. In addition, we present an analysis of the model interpretations under different style variations. At the same time, we compare comprehensive experiments demonstrating the performance when applied to deep neural architectures in training settings.", "url": "https://arxiv.org/abs/2308.14995"}, {"metadata": {"arXiv": "2308.15074", "Date": "Tue, 29 Aug 2023 07:15:57 ", "Title": "Exploring Model Transferability through the Lens of Potential Energy", "Authors": ["Xiaotong Li", "Zixuan Hu", "Yixiao Ge", "Ying Shan", "Ling-Yu Duan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Transfer learning has become crucial in computer vision tasks due to the vast availability of pre-trained deep learning models. However, selecting the optimal pre-trained model from a diverse pool for a specific downstream task remains a challenge. Existing methods for measuring the transferability of pre-trained models rely on statistical correlations between encoded static features and task labels, but they overlook the impact of underlying representation dynamics during fine-tuning, leading to unreliable results, especially for self-supervised models. In this paper, we present an insightful physics-inspired approach named PED to address these challenges. We reframe the challenge of model selection through the lens of potential energy and directly model the interaction forces that influence fine-tuning dynamics. By capturing the motion of dynamic representations to decline the potential energy within a force-driven physical model, we can acquire an enhanced and more stable observation for estimating transferability. The experimental results on 10 downstream tasks and 12 self-supervised models demonstrate that our approach can seamlessly integrate into existing ranking techniques and enhance their performances, revealing its effectiveness for the model selection task and its potential for understanding the mechanism in transfer learning. Code will be available at https://github.com/lixiaotong97/PED.", "url": "https://arxiv.org/abs/2308.15074"}, {"metadata": {"arXiv": "2308.15094", "Date": "Tue, 29 Aug 2023 08:02:41 ", "Title": "Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification", "Authors": ["Paul Melki (IMS)", "Lionel Bombrun (IMS)", "Boubacar Diallo", "J\\'er\\^ome Dias", "Jean-Pierre da Costa (IMS)"], "Categories": "cs.CV cs.LG stat.AP stat.ML", "Journal-ref": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW), IEEE/CVF, Oct 2023, Paris, France"}, "abstract": "As deep learning predictive models become an integral part of a large spectrum of precision agricultural systems, a barrier to the adoption of such automated solutions is the lack of user trust in these highly complex, opaque and uncertain models. Indeed, deep neural networks are not equipped with any explicit guarantees that can be used to certify the system's performance, especially in highly varying uncontrolled environments such as the ones typically faced in computer vision for agriculture.Fortunately, certain methods developed in other communities can prove to be important for agricultural applications. This article presents the conformal prediction framework that provides valid statistical guarantees on the predictive performance of any black box prediction machine, with almost no assumptions, applied to the problem of deep visual classification of weeds and crops in real-world conditions. The framework is exposed with a focus on its practical aspects and special attention accorded to the Adaptive Prediction Sets (APS) approach that delivers marginal guarantees on the model's coverage. Marginal results are then shown to be insufficient to guarantee performance on all groups of individuals in the population as characterized by their environmental and pedo-climatic auxiliary data gathered during image acquisition.To tackle this shortcoming, group-conditional conformal approaches are presented: the ''classical'' method that consists of iteratively applying the APS procedure on all groups, and a proposed elegant reformulation and implementation of the procedure using quantile regression on group membership indicators. Empirical results showing the validity of the proposed approach are presented and compared to the marginal APS then discussed.", "url": "https://arxiv.org/abs/2308.15094"}, {"metadata": {"arXiv": "2308.15323", "Date": "Tue, 29 Aug 2023 14:20:13 ", "Title": "Occlusion-Aware Deep Convolutional Neural Network via Homogeneous Tanh-transforms for Face Parsing", "Authors": ["Weihua Liu", "Chaochao Lin", "Haoping Yu", "Said Boumaraf", "Zhaoqiong Pi"], "Categories": "cs.CV cs.LG"}, "abstract": "Face parsing infers a pixel-wise label map for each semantic facial component. Previous methods generally work well for uncovered faces, however overlook the facial occlusion and ignore some contextual area outside a single face, especially when facial occlusion has become a common situation during the COVID-19 epidemic. Inspired by the illumination theory of image, we propose a novel homogeneous tanh-transforms for image preprocessing, which made up of four tanh-transforms, that fuse the central vision and the peripheral vision together. Our proposed method addresses the dilemma of face parsing under occlusion and compresses more information of surrounding context. Based on homogeneous tanh-transforms, we propose an occlusion-aware convolutional neural network for occluded face parsing. It combines the information both in Tanh-polar space and Tanh-Cartesian space, capable of enhancing receptive fields. Furthermore, we introduce an occlusion-aware loss to focus on the boundaries of occluded regions. The network is simple and flexible, and can be trained end-to-end. To facilitate future research of occluded face parsing, we also contribute a new cleaned face parsing dataset, which is manually purified from several academic or industrial datasets, including CelebAMask-HQ, Short-video Face Parsing as well as Helen dataset and will make it public. Experiments demonstrate that our method surpasses state-of-art methods of face parsing under occlusion.", "url": "https://arxiv.org/abs/2308.15323"}, {"metadata": {"arXiv": "2308.15461", "Date": "Tue, 29 Aug 2023 17:38:33 ", "Title": "Canonical Factors for Hybrid Neural Fields", "Authors": ["Brent Yi", "Weijia Zeng", "Sam Buchanan", "and Yi Ma"], "Categories": "cs.CV cs.LG math.OC", "Comments": ["ICCV 2023. Project webpage: https://brentyi.github.io/tilted/"]}, "abstract": "Factored feature volumes offer a simple way to build more compact, efficient, and intepretable neural fields, but also introduce biases that are not necessarily beneficial for real-world data. In this work, we (1) characterize the undesirable biases that these architectures have for axis-aligned signals -- they can lead to radiance field reconstruction differences of as high as 2 PSNR -- and (2) explore how learning a set of canonicalizing transformations can improve representations by removing these biases. We prove in a two-dimensional model problem that simultaneously learning these transformations together with scene appearance succeeds with drastically improved efficiency. We validate the resulting architectures, which we call TILTED, using image, signed distance, and radiance field reconstruction tasks, where we observe improvements across quality, robustness, compactness, and runtime. Results demonstrate that TILTED can enable capabilities comparable to baselines that are 2x larger, while highlighting weaknesses of neural field evaluation procedures.", "url": "https://arxiv.org/abs/2308.15461"}, {"metadata": {"arXiv": "2308.15479", "Date": "Tue, 29 Aug 2023 17:58:55 ", "Title": "3D Adversarial Augmentations for Robust Out-of-Domain Predictions", "Authors": ["Alexander Lehner", "Stefano Gasperini", "Alvaro Marcos-Ramiro", "Michael Schmidt", "Nassir Navab", "Benjamin Busam", "Federico Tombari"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["37 pages", "12 figures"]}, "abstract": "Since real-world training datasets cannot properly sample the long tail of the underlying data distribution, corner cases and rare out-of-domain samples can severely hinder the performance of state-of-the-art models. This problem becomes even more severe for dense tasks, such as 3D semantic segmentation, where points of non-standard objects can be confidently associated to the wrong class. In this work, we focus on improving the generalization to out-of-domain data. We achieve this by augmenting the training set with adversarial examples. First, we learn a set of vectors that deform the objects in an adversarial fashion. To prevent the adversarial examples from being too far from the existing data distribution, we preserve their plausibility through a series of constraints, ensuring sensor-awareness and shapes smoothness. Then, we perform adversarial augmentation by applying the learned sample-independent vectors to the available objects when training a model. We conduct extensive experiments across a variety of scenarios on data from KITTI, Waymo, and CrashD for 3D object detection, and on data from SemanticKITTI, Waymo, and nuScenes for 3D semantic segmentation. Despite training on a standard single dataset, our approach substantially improves the robustness and generalization of both 3D object detection and 3D semantic segmentation methods to out-of-domain data.", "url": "https://arxiv.org/abs/2308.15479"}, {"metadata": {"arXiv": "2308.14783", "Date": "Mon, 28 Aug 2023 16:21:45 ", "Title": "Distributed Dual Coordinate Ascent with Imbalanced Data on a General Tree Network", "Authors": ["Myung Cho", "Lifeng Lai", "Weiyu Xu"], "Categories": "cs.LG cs.DC cs.IT math.IT", "Comments": ["To be published in IEEE 2023 Workshop on Machine Learning for Signal Processing (MLSP)"]}, "abstract": "In this paper, we investigate the impact of imbalanced data on the convergence of distributed dual coordinate ascent in a tree network for solving an empirical loss minimization problem in distributed machine learning. To address this issue, we propose a method called delayed generalized distributed dual coordinate ascent that takes into account the information of the imbalanced data, and provide the analysis of the proposed algorithm. Numerical experiments confirm the effectiveness of our proposed method in improving the convergence speed of distributed dual coordinate ascent in a tree network.", "url": "https://arxiv.org/abs/2308.14783"}, {"metadata": {"arXiv": "2308.14831", "Date": "Mon, 28 Aug 2023 18:31:09 ", "Title": "Continual Learning with Dynamic Sparse Training: Exploring Algorithms for Effective Model Updates", "Authors": ["Murat Onur Yildirim", "Elif Ceren Gok Yildirim", "Ghada Sokar", "Decebal Constantin Mocanu", "Joaquin Vanschoren"], "Categories": "cs.LG cs.CV"}, "abstract": "Continual learning (CL) refers to the ability of an intelligent system to sequentially acquire and retain knowledge from a stream of data with as little computational overhead as possible. To this end; regularization, replay, architecture, and parameter isolation approaches were introduced to the literature. Parameter isolation using a sparse network which enables to allocate distinct parts of the neural network to different tasks and also allows to share of parameters between tasks if they are similar. Dynamic Sparse Training (DST) is a prominent way to find these sparse networks and isolate them for each task. This paper is the first empirical study investigating the effect of different DST components under the CL paradigm to fill a critical research gap and shed light on the optimal configuration of DST for CL if it exists. Therefore, we perform a comprehensive study in which we investigate various DST components to find the best topology per task on well-known CIFAR100 and miniImageNet benchmarks in a task-incremental CL setup since our primary focus is to evaluate the performance of various DST criteria, rather than the process of mask selection. We found that, at a low sparsity level, Erdos-Renyi Kernel (ERK) initialization utilizes the backbone more efficiently and allows to effectively learn increments of tasks. At a high sparsity level, however, uniform initialization demonstrates more reliable and robust performance. In terms of growth strategy; performance is dependent on the defined initialization strategy, and the extent of sparsity. Finally, adaptivity within DST components is a promising way for better continual learners.", "url": "https://arxiv.org/abs/2308.14831"}, {"metadata": {"arXiv": "2308.14838", "Date": "Mon, 28 Aug 2023 18:48:34 ", "Title": "Tackling Diverse Minorities in Imbalanced Classification", "Authors": ["Kwei-Herng Lai", "Daochen Zha", "Huiyuan Chen", "Mangesh Bendre", "Yuzhong Chen", "Mahashweta Das", "Hao Yang", "Xia Hu"], "Categories": "cs.LG", "DOI": "10.1145/3583780.3615071"}, "abstract": "Imbalanced datasets are commonly observed in various real-world applications, presenting significant challenges in training classifiers. When working with large datasets, the imbalanced issue can be further exacerbated, making it exceptionally difficult to train classifiers effectively. To address the problem, over-sampling techniques have been developed to linearly interpolating data instances between minorities and their neighbors. However, in many real-world scenarios such as anomaly detection, minority instances are often dispersed diversely in the feature space rather than clustered together. Inspired by domain-agnostic data mix-up, we propose generating synthetic samples iteratively by mixing data samples from both minority and majority classes. It is non-trivial to develop such a framework, the challenges include source sample selection, mix-up strategy selection, and the coordination between the underlying model and mix-up strategies. To tackle these challenges, we formulate the problem of iterative data mix-up as a Markov decision process (MDP) that maps data attributes onto an augmentation strategy. To solve the MDP, we employ an actor-critic framework to adapt the discrete-continuous decision space. This framework is utilized to train a data augmentation policy and design a reward signal that explores classifier uncertainty and encourages performance improvement, irrespective of the classifier's convergence. We demonstrate the effectiveness of our proposed framework through extensive experiments conducted on seven publicly available benchmark datasets using three different types of classifiers. The results of these experiments showcase the potential and promise of our framework in addressing imbalanced datasets with diverse minorities.", "url": "https://arxiv.org/abs/2308.14838"}, {"metadata": {"arXiv": "2308.14845", "Date": "Mon, 28 Aug 2023 19:06:03 ", "Title": "SMOClust: Synthetic Minority Oversampling based on Stream Clustering for Evolving Data Streams", "Authors": ["Chun Wai Chiu", "Leandro L. Minku"], "Categories": "cs.LG cs.DB", "Comments": ["59 pages", "85 figures"]}, "abstract": "Many real-world data stream applications not only suffer from concept drift but also class imbalance. Yet, very few existing studies investigated this joint challenge. Data difficulty factors, which have been shown to be key challenges in class imbalanced data streams, are not taken into account by existing approaches when learning class imbalanced data streams. In this work, we propose a drift adaptable oversampling strategy to synthesise minority class examples based on stream clustering. The motivation is that stream clustering methods continuously update themselves to reflect the characteristics of the current underlying concept, including data difficulty factors. This nature can potentially be used to compress past information without caching data in the memory explicitly. Based on the compressed information, synthetic examples can be created within the region that recently generated new minority class examples. Experiments with artificial and real-world data streams show that the proposed approach can handle concept drift involving different minority class decomposition better than existing approaches, especially when the data stream is severely class imbalanced and presenting high proportions of safe and borderline minority class examples.", "url": "https://arxiv.org/abs/2308.14845"}, {"metadata": {"arXiv": "2308.14895", "Date": "Mon, 28 Aug 2023 20:32:22 ", "Title": "Conformal Meta-learners for Predictive Inference of Individual Treatment Effects", "Authors": ["Ahmed Alaa", "Zaid Ahmad", "Mark van der Laan"], "Categories": "cs.LG"}, "abstract": "We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based meta-learners that can provide point estimates of the conditional average treatment effect (CATE); these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo outcome) conformity scores stochastically dominate oracle conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.", "url": "https://arxiv.org/abs/2308.14895"}, {"metadata": {"arXiv": "2308.14906", "Date": "Mon, 28 Aug 2023 21:17:12 ", "Title": "BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition", "Authors": ["Shikai Fang", "Qingsong Wen", "Shandian Zhe", "Liang Sun,"], "Categories": "cs.LG stat.ML"}, "abstract": "In real-world scenarios like traffic and energy, massive time-series data with missing values and noises are widely observed, even sampled irregularly. While many imputation methods have been proposed, most of them work with a local horizon, which means models are trained by splitting the long sequence into batches of fit-sized patches. This local horizon can make models ignore global trends or periodic patterns. More importantly, almost all methods assume the observations are sampled at regular time stamps, and fail to handle complex irregular sampled time series arising from different applications. Thirdly, most existing methods are learned in an offline manner. Thus, it is not suitable for many applications with fast-arriving streaming data. To overcome these limitations, we propose \\ours: Bayesian Online Multivariate Time series Imputation with functional decomposition. We treat the multivariate time series as the weighted combination of groups of low-rank temporal factors with different patterns. We apply a group of Gaussian Processes (GPs) with different kernels as functional priors to fit the factors. For computational efficiency, we further convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE), and developing a scalable algorithm for online inference. The proposed method can not only handle imputation over arbitrary time stamps, but also offer uncertainty quantification and interpretability for the downstream application. We evaluate our method on both synthetic and real-world datasets.", "url": "https://arxiv.org/abs/2308.14906"}, {"metadata": {"arXiv": "2308.14929", "Date": "Mon, 28 Aug 2023 23:08:15 ", "Title": "Maestro: Uncovering Low-Rank Structures via Trainable Decomposition", "Authors": ["Samuel Horvath", "Stefanos Laskaridis", "Shashank Rajput", "Hongyi Wang"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Deep Neural Networks (DNNs) have been a large driver and enabler for AI breakthroughs in recent years. These models have been getting larger in their attempt to become more accurate and tackle new upcoming use-cases, including AR/VR and intelligent assistants. However, the training process of such large models is a costly and time-consuming process, which typically yields a single model to fit all targets. To mitigate this, various techniques have been proposed in the literature, including pruning, sparsification or quantization of the model weights and updates. While able to achieve high compression rates, they often incur computational overheads or accuracy penalties. Alternatively, factorization methods have been leveraged to incorporate low-rank compression in the training process. Similarly, such techniques (e.g.,~SVD) frequently rely on the computationally expensive decomposition of layers and are potentially sub-optimal for non-linear models, such as DNNs. In this work, we take a further step in designing efficient low-rank models and propose Maestro, a framework for trainable low-rank layers. Instead of regularly applying a priori decompositions such as SVD, the low-rank structure is built into the training process through a generalized variant of Ordered Dropout. This method imposes an importance ordering via sampling on the decomposed DNN structure. Our theoretical analysis demonstrates that our method recovers the SVD decomposition of linear mapping on uniformly distributed data and PCA for linear autoencoders. We further apply our technique on DNNs and empirically illustrate that Maestro enables the extraction of lower footprint models that preserve model performance while allowing for graceful accuracy-latency tradeoff for the deployment to devices of different capabilities.", "url": "https://arxiv.org/abs/2308.14929"}, {"metadata": {"arXiv": "2308.14946", "Date": "Mon, 28 Aug 2023 23:55:23 ", "Title": "Reinforcement Learning for Sampling on Temporal Medical Imaging Sequences", "Authors": ["Zhishen Huang"], "Categories": "cs.LG eess.IV", "Comments": ["ICML 2023 Workshop SODS"]}, "abstract": "Accelerated magnetic resonance imaging resorts to either Fourier-domain subsampling or better reconstruction algorithms to deal with fewer measurements while still generating medical images of high quality. Determining the optimal sampling strategy given a fixed reconstruction protocol often has combinatorial complexity. In this work, we apply double deep Q-learning and REINFORCE algorithms to learn the sampling strategy for dynamic image reconstruction. We consider the data in the format of time series, and the reconstruction method is a pre-trained autoencoder-typed neural network. We present a proof of concept that reinforcement learning algorithms are effective to discover the optimal sampling pattern which underlies the pre-trained reconstructor network (i.e., the dynamics in the environment). The code for replicating experiments can be found at https://github.com/zhishenhuang/RLsamp.", "url": "https://arxiv.org/abs/2308.14946"}, {"metadata": {"arXiv": "2308.14949", "Date": "Tue, 29 Aug 2023 00:25:02 ", "Title": "Low-bit Quantization for Deep Graph Neural Networks with Smoothness-aware Message Propagation", "Authors": ["Shuang Wang", "Bahaeddin Eravci", "Rustam Guliyev", "Hakan Ferhatosmanoglu"], "Categories": "cs.LG", "Comments": ["To appear in CIKM2023"], "MSC-class": "68T07", "ACM-class": "I.m", "Journal-ref": "Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21--25, 2023, Birmingham, United Kingdom", "DOI": "10.1145/3583780.3614955"}, "abstract": "Graph Neural Network (GNN) training and inference involve significant challenges of scalability with respect to both model sizes and number of layers, resulting in degradation of efficiency and accuracy for large and deep GNNs. We present an end-to-end solution that aims to address these challenges for efficient GNNs in resource constrained environments while avoiding the oversmoothing problem in deep GNNs. We introduce a quantization based approach for all stages of GNNs, from message passing in training to node classification, compressing the model and enabling efficient processing. The proposed GNN quantizer learns quantization ranges and reduces the model size with comparable accuracy even under low-bit quantization. To scale with the number of layers, we devise a message propagation mechanism in training that controls layer-wise changes of similarities between neighboring nodes. This objective is incorporated into a Lagrangian function with constraints and a differential multiplier method is utilized to iteratively find optimal embeddings. This mitigates oversmoothing and suppresses the quantization error to a bound. Significant improvements are demonstrated over state-of-the-art quantization methods and deep GNN approaches in both full-precision and quantized models. The proposed quantizer demonstrates superior performance in INT2 configurations across all stages of GNN, achieving a notable level of accuracy. In contrast, existing quantization approaches fail to generate satisfactory accuracy levels. Finally, the inference with INT2 and INT4 representations exhibits a speedup of 5.11 $\\times$ and 4.70 $\\times$ compared to full precision counterparts, respectively.", "url": "https://arxiv.org/abs/2308.14949"}, {"metadata": {"arXiv": "2308.14962", "Date": "Tue, 29 Aug 2023 01:29:26 ", "Title": "Streaming Compression of Scientific Data via weak-SINDy", "Authors": ["Benjamin P. Russo", "M. Paul Laiu", "Richard Archibald"], "Categories": "cs.LG math.DS", "MSC-class": "37M10, 62J07, 65L60, 41A10, 68T99, 68V99"}, "abstract": "In this paper a streaming weak-SINDy algorithm is developed specifically for compressing streaming scientific data. The production of scientific data, either via simulation or experiments, is undergoing an stage of exponential growth, which makes data compression important and often necessary for storing and utilizing large scientific data sets. As opposed to classical ``offline\" compression algorithms that perform compression on a readily available data set, streaming compression algorithms compress data ``online\" while the data generated from simulation or experiments is still flowing through the system. This feature makes streaming compression algorithms well-suited for scientific data compression, where storing the full data set offline is often infeasible. This work proposes a new streaming compression algorithm, streaming weak-SINDy, which takes advantage of the underlying data characteristics during compression. The streaming weak-SINDy algorithm constructs feature matrices and target vectors in the online stage via a streaming integration method in a memory efficient manner. The feature matrices and target vectors are then used in the offline stage to build a model through a regression process that aims to recover equations that govern the evolution of the data. For compressing high-dimensional streaming data, we adopt a streaming proper orthogonal decomposition (POD) process to reduce the data dimension and then use the streaming weak-SINDy algorithm to compress the temporal data of the POD expansion. We propose modifications to the streaming weak-SINDy algorithm to accommodate the dynamically updated POD basis. By combining the built model from the streaming weak-SINDy algorithm and a small amount of data samples, the full data flow could be reconstructed accurately at a low memory cost, as shown in the numerical tests.", "url": "https://arxiv.org/abs/2308.14962"}, {"metadata": {"arXiv": "2308.14969", "Date": "Tue, 29 Aug 2023 01:47:49 ", "Title": "Reprogramming under constraints: Revisiting efficient and reliable transferability of lottery tickets", "Authors": ["Diganta Misra", "Agam Goyal", "Bharat Runwal", "Pin Yu Chen"], "Categories": "cs.LG cs.CV", "Comments": ["Preprint"]}, "abstract": "In the era of foundation models with huge pre-training budgets, the downstream tasks have been shifted to the narrative of efficient and fast adaptation. For classification-based tasks in the domain of computer vision, the two most efficient approaches have been linear probing (LP) and visual prompting/reprogramming (VP); the former aims to learn a classifier in the form of a linear head on the features extracted by the pre-trained model, while the latter maps the input data to the domain of the source data on which the model was originally pre-trained on. Although extensive studies have demonstrated the differences between LP and VP in terms of downstream performance, we explore the capabilities of the two aforementioned methods via the sparsity axis: (a) Data sparsity: the impact of few-shot adaptation and (b) Model sparsity: the impact of lottery tickets (LT). We demonstrate that LT are not universal reprogrammers, i.e., for certain target datasets, reprogramming an LT yields significantly lower performance than the reprogrammed dense model although their corresponding upstream performance is similar. Further, we demonstrate that the calibration of dense models is always superior to that of their lottery ticket counterparts under both LP and VP regimes. Our empirical study opens a new avenue of research into VP for sparse models and encourages further understanding of the performance beyond the accuracy achieved by VP under constraints of sparsity. Code and logs can be accessed at \\url{https://github.com/landskape-ai/Reprogram_LT}.", "url": "https://arxiv.org/abs/2308.14969"}, {"metadata": {"arXiv": "2308.15006", "Date": "Tue, 29 Aug 2023 03:54:53 ", "Title": "Exploiting Problem Geometry in Safe Linear Bandits", "Authors": ["Spencer Hutchinson", "Berkay Turan", "Mahnoosh Alizadeh"], "Categories": "cs.LG", "Comments": ["38 pages", "4 figures"]}, "abstract": "The safe linear bandit problem is a version of the classic linear bandit problem where the learner's actions must satisfy an uncertain linear constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. We find that by exploiting the geometry of the specific problem setting, we can achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Additionally, we propose a novel algorithm for this setting that chooses problem parameters adaptively and enjoys at least as good regret guarantees as existing algorithms. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach. Simulation results show improved performance over existing algorithms for a variety of randomly sampled settings.", "url": "https://arxiv.org/abs/2308.15006"}, {"metadata": {"arXiv": "2308.15047", "Date": "Tue, 29 Aug 2023 06:09:47 ", "Title": "Large language models converge toward human-like concept organization", "Authors": ["Mathias Lykke Gammelgaard", "Jonathan Gabel Christiansen", "Anders S{\\o}gaard"], "Categories": "cs.LG cs.CL"}, "abstract": "Large language models show human-like performance in knowledge extraction, reasoning and dialogue, but it remains controversial whether this performance is best explained by memorization and pattern matching, or whether it reflects human-like inferential semantics and world knowledge. Knowledge bases such as WikiData provide large-scale, high-quality representations of inferential semantics and world knowledge. We show that large language models learn to organize concepts in ways that are strikingly similar to how concepts are organized in such knowledge bases. Knowledge bases model collective, institutional knowledge, and large language models seem to induce such knowledge from raw text. We show that bigger and better models exhibit more human-like concept organization, across four families of language models and three knowledge graph embeddings.", "url": "https://arxiv.org/abs/2308.15047"}, {"metadata": {"arXiv": "2308.15059", "Date": "Tue, 29 Aug 2023 06:43:29 ", "Title": "OEBench: Investigating Open Environment Challenges in Real-World Relational Data Streams", "Authors": ["Yiqun Diao", "Yutong Yang", "Qinbin Li", "Bingsheng He", "Mian Lu"], "Categories": "cs.LG cs.DB"}, "abstract": "Relational datasets are widespread in real-world scenarios and are usually delivered in a streaming fashion. This type of data stream can present unique challenges, such as distribution drifts, outliers, emerging classes, and changing features, which have recently been described as open environment challenges for machine learning. While some work has been done on incremental learning for data streams, their evaluations are mostly conducted with manually partitioned datasets. Moreover, while several real-world streaming datasets are available, it is uncertain whether these open environment challenges are prevalent and how existing incremental learning algorithms perform on real datasets. To fill this gap, we develop an Open Environment Benchmark named OEBench to evaluate open environment challenges in relational data streams. Specifically, we investigate 55 real-world streaming datasets and establish that open environment scenarios are indeed widespread in real-world datasets, which presents significant challenges for stream learning algorithms. Through benchmarks, we find that increased data quantity may not consistently enhance the model accuracy when applied in open environment scenarios, where machine learning models can be significantly compromised by distribution shifts, anomalies, or untrustworthy data within real-world data streams. The current techniques are insufficient in effectively mitigating these challenges posed by open environments. Thus, it is promising to conduct more researches to address real-world new challenges of open environment scenarios.", "url": "https://arxiv.org/abs/2308.15059"}, {"metadata": {"arXiv": "2308.15072", "Date": "Tue, 29 Aug 2023 07:13:31 ", "Title": "Advancing Adversarial Robustness Through Adversarial Logit Update", "Authors": ["Hao Xuan", "Peican Zhu", "Xingyu Li"], "Categories": "cs.LG cs.CR"}, "abstract": "Deep Neural Networks are susceptible to adversarial perturbations. Adversarial training and adversarial purification are among the most widely recognized defense strategies. Although these methods have different underlying logic, both rely on absolute logit values to generate label predictions. In this study, we theoretically analyze the logit difference around successful adversarial attacks from a theoretical point of view and propose a new principle, namely Adversarial Logit Update (ALU), to infer adversarial sample's labels. Based on ALU, we introduce a new classification paradigm that utilizes pre- and post-purification logit differences for model's adversarial robustness boost. Without requiring adversarial or additional data for model training, our clean data synthesis model can be easily applied to various pre-trained models for both adversarial sample detection and ALU-based data classification. Extensive experiments on both CIFAR-10, CIFAR-100, and tiny-ImageNet datasets show that even with simple components, the proposed solution achieves superior robustness performance compared to state-of-the-art methods against a wide range of adversarial attacks. Our python implementation is submitted in our Supplementary document and will be published upon the paper's acceptance.", "url": "https://arxiv.org/abs/2308.15072"}, {"metadata": {"arXiv": "2308.15096", "Date": "Tue, 29 Aug 2023 08:04:45 ", "Title": "How Faithful are Self-Explainable GNNs?", "Authors": ["Marc Christiansen", "Lea Villadsen", "Zhiqiang Zhong", "Stefano Teso", "Davide Mottin"], "Categories": "cs.LG"}, "abstract": "Self-explainable deep neural networks are a recent class of models that can output ante-hoc local explanations that are faithful to the model's reasoning, and as such represent a step forward toward filling the gap between expressiveness and interpretability. Self-explainable graph neural networks (GNNs) aim at achieving the same in the context of graph data. This begs the question: do these models fulfill their implicit guarantees in terms of faithfulness? In this extended abstract, we analyze the faithfulness of several self-explainable GNNs using different measures of faithfulness, identify several limitations -- both in the models themselves and in the evaluation metrics -- and outline possible ways forward.", "url": "https://arxiv.org/abs/2308.15096"}, {"metadata": {"arXiv": "2308.15107", "Date": "Tue, 29 Aug 2023 08:14:19 ", "Title": "Stochastic Graph Bandit Learning with Side-Observations", "Authors": ["Xueping Gong and Jiheng Zhang"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2010.03104 by other authors"]}, "abstract": "In this paper, we investigate the stochastic contextual bandit with general function space and graph feedback. We propose an algorithm that addresses this problem by adapting to both the underlying graph structures and reward gaps. To the best of our knowledge, our algorithm is the first to provide a gap-dependent upper bound in this stochastic setting, bridging the research gap left by the work in [35]. In comparison to [31,33,35], our method offers improved regret upper bounds and does not require knowledge of graphical quantities. We conduct numerical experiments to demonstrate the computational efficiency and effectiveness of our approach in terms of regret upper bounds. These findings highlight the significance of our algorithm in advancing the field of stochastic contextual bandits with graph feedback, opening up avenues for practical applications in various domains.", "url": "https://arxiv.org/abs/2308.15107"}, {"metadata": {"arXiv": "2308.15132", "Date": "Tue, 29 Aug 2023 08:57:47 ", "Title": "Biquality Learning: a Framework to Design Algorithms Dealing with Closed-Set Distribution Shifts", "Authors": ["Pierre Nodet and Vincent Lemaire and Alexis Bondu and Antoine Cornu\\'ejols"], "Categories": "cs.LG"}, "abstract": "Training machine learning models from data with weak supervision and dataset shifts is still challenging. Designing algorithms when these two situations arise has not been explored much, and existing algorithms cannot always handle the most complex distributional shifts. We think the biquality data setup is a suitable framework for designing such algorithms. Biquality Learning assumes that two datasets are available at training time: a trusted dataset sampled from the distribution of interest and the untrusted dataset with dataset shifts and weaknesses of supervision (aka distribution shifts). The trusted and untrusted datasets available at training time make designing algorithms dealing with any distribution shifts possible. We propose two methods, one inspired by the label noise literature and another by the covariate shift literature for biquality learning. We experiment with two novel methods to synthetically introduce concept drift and class-conditional shifts in real-world datasets across many of them. We opened some discussions and assessed that developing biquality learning algorithms robust to distributional changes remains an interesting problem for future research.", "url": "https://arxiv.org/abs/2308.15132"}, {"metadata": {"arXiv": "2308.15157", "Date": "Tue, 29 Aug 2023 09:39:12 ", "Title": "On the improvement of model-predictive controllers", "Authors": ["L. F\\'eret", "A. Gepperth", "S. Lambeck"], "Categories": "cs.LG cs.NE cs.SY eess.SY"}, "abstract": "This article investigates synthetic model-predictive control (MPC) problems to demonstrate that an increased precision of the internal prediction model (PM) automatially entails an improvement of the controller as a whole. In contrast to reinforcement learning (RL), MPC uses the PM to predict subsequent states of the controlled system (CS), instead of directly recommending suitable actions. To assess how the precision of the PM translates into the quality of the model-predictive controller, we compare a DNN-based PM to the optimal baseline PM for three well-known control problems of varying complexity. The baseline PM achieves perfect accuracy by accessing the simulation of the CS itself. Based on the obtained results, we argue that an improvement of the PM will always improve the controller as a whole, without considering the impact of other components such as action selection (which, in this article, relies on evolutionary optimization).", "url": "https://arxiv.org/abs/2308.15157"}, {"metadata": {"arXiv": "2308.15164", "Date": "Tue, 29 Aug 2023 09:46:52 ", "Title": "ABS-SGD: A Delayed Synchronous Stochastic Gradient Descent Algorithm with Adaptive Batch Size for Heterogeneous GPU Clusters", "Authors": ["Xin Zhou", "Ling Chen", "Houming Wu"], "Categories": "cs.LG cs.DC", "Comments": ["15 pages", "3 figures"]}, "abstract": "As the size of models and datasets grows, it has become increasingly common to train models in parallel. However, existing distributed stochastic gradient descent (SGD) algorithms suffer from insufficient utilization of computational resources and poor convergence in heterogeneous clusters. In this paper, we propose a delayed synchronous SGD algorithm with adaptive batch size (ABS-SGD) for heterogeneous GPU clusters. In ABS-SGD, workers perform global synchronization to accumulate delayed gradients and use the accumulated delayed gradients to update parameters. While workers are performing global synchronization for delayed gradients, they perform the computation of the next batch without specifying batch size in advance, which lasts until the next global synchronization starts, realizing the full utilization of computational resources. Since the gradient delay is only one iteration, the stale gradient problem can be alleviated. We theoretically prove the convergence of ABS-SGD in heterogeneous clusters. Extensive experiments in three types of heterogeneous clusters demonstrate that ABS-SGD can make full use of computational resources and accelerate model convergence: When training ResNet18 network with 4 workers, ABS-SGD increases the convergence speed by 1.30x on average compared with the best baseline algorithm.", "url": "https://arxiv.org/abs/2308.15164"}, {"metadata": {"arXiv": "2308.15223", "Date": "Tue, 29 Aug 2023 11:24:12 ", "Title": "Evaluating Explanation Methods for Multivariate Time Series Classification", "Authors": ["Davide Italo Serramazza", "Thu Trang Nguyen", "Thach Le Nguyen", "Georgiana Ifrim"], "Categories": "cs.LG", "Comments": ["Accepted at AALTD '23"]}, "abstract": "Multivariate time series classification is an important computational task arising in applications where data is recorded over time and over multiple channels. For example, a smartwatch can record the acceleration and orientation of a person's motion, and these signals are recorded as multivariate time series. We can classify this data to understand and predict human movement and various properties such as fitness levels. In many applications classification alone is not enough, we often need to classify but also understand what the model learns (e.g., why was a prediction given, based on what information in the data). The main focus of this paper is on analysing and evaluating explanation methods tailored to Multivariate Time Series Classification (MTSC). We focus on saliency-based explanation methods that can point out the most relevant channels and time series points for the classification decision. We analyse two popular and accurate multivariate time series classifiers, ROCKET and dResNet, as well as two popular explanation methods, SHAP and dCAM. We study these methods on 3 synthetic datasets and 2 real-world datasets and provide a quantitative and qualitative analysis of the explanations provided. We find that flattening the multivariate datasets by concatenating the channels works as well as using multivariate classifiers directly and adaptations of SHAP for MTSC work quite well. Additionally, we also find that the popular synthetic datasets we used are not suitable for time series analysis.", "url": "https://arxiv.org/abs/2308.15223"}, {"metadata": {"arXiv": "2308.15232", "Date": "Tue, 29 Aug 2023 11:40:24 ", "Title": "Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification", "Authors": ["Tianyu Liang", "Yida Mu", "Soonho Kim", "Darline Larissa Kengne Kuate", "Julie Lang", "Rob Vos", "Xingyi Song"], "Categories": "cs.LG cs.CL cs.IR", "Comments": ["Accepted by RANLP 2023"]}, "abstract": "A large number of conflict events are affecting the world all the time. In order to analyse such conflict events effectively, this paper presents a Classification-Aware Neural Topic Model (CANTM-IA) for Conflict Information Classification and Topic Discovery. The model provides a reliable interpretation of classification results and discovered topics by introducing interpretability analysis. At the same time, interpretation is introduced into the model architecture to improve the classification performance of the model and to allow interpretation to focus further on the details of the data. Finally, the model architecture is optimised to reduce the complexity of the model.", "url": "https://arxiv.org/abs/2308.15232"}, {"metadata": {"arXiv": "2308.15250", "Date": "Tue, 29 Aug 2023 12:16:57 ", "Title": "The Relative Gaussian Mechanism and its Application to Private Gradient Descent", "Authors": ["Hadrien Hendrikx", "Paul Mangold and Aur\\'elien Bellet"], "Categories": "cs.LG cs.CR math.OC"}, "abstract": "The Gaussian Mechanism (GM), which consists in adding Gaussian noise to a vector-valued query before releasing it, is a standard privacy protection mechanism. In particular, given that the query respects some L2 sensitivity property (the L2 distance between outputs on any two neighboring inputs is bounded), GM guarantees R\\'enyi Differential Privacy (RDP). Unfortunately, precisely bounding the L2 sensitivity can be hard, thus leading to loose privacy bounds. In this work, we consider a Relative L2 sensitivity assumption, in which the bound on the distance between two query outputs may also depend on their norm. Leveraging this assumption, we introduce the Relative Gaussian Mechanism (RGM), in which the variance of the noise depends on the norm of the output. We prove tight bounds on the RDP parameters under relative L2 sensitivity, and characterize the privacy loss incurred by using output-dependent noise. In particular, we show that RGM naturally adapts to a latent variable that would control the norm of the output. Finally, we instantiate our framework to show tight guarantees for Private Gradient Descent, a problem that naturally fits our relative L2 sensitivity assumption.", "url": "https://arxiv.org/abs/2308.15250"}, {"metadata": {"arXiv": "2308.15283", "Date": "Tue, 29 Aug 2023 13:14:53 ", "Title": "Structural Node Embeddings with Homomorphism Counts", "Authors": ["Hinrikus Wolf", "Luca Oeljeklaus", "Pascal K\\\"uhner", "Martin Grohe"], "Categories": "cs.LG"}, "abstract": "Graph homomorphism counts, first explored by Lov\\'asz in 1967, have recently garnered interest as a powerful tool in graph-based machine learning. Grohe (PODS 2020) proposed the theoretical foundations for using homomorphism counts in machine learning on graph level as well as node level tasks. By their very nature, these capture local structural information, which enables the creation of robust structural embeddings. While a first approach for graph level tasks has been made by Nguyen and Maehara (ICML 2020), we experimentally show the effectiveness of homomorphism count based node embeddings. Enriched with node labels, node weights, and edge weights, these offer an interpretable representation of graph data, allowing for enhanced explainability of machine learning models. We propose a theoretical framework for isomorphism-invariant homomorphism count based embeddings which lend themselves to a wide variety of downstream tasks. Our approach capitalises on the efficient computability of graph homomorphism counts for bounded treewidth graph classes, rendering it a practical solution for real-world applications. We demonstrate their expressivity through experiments on benchmark datasets. Although our results do not match the accuracy of state-of-the-art neural architectures, they are comparable to other advanced graph learning models. Remarkably, our approach demarcates itself by ensuring explainability for each individual feature. By integrating interpretable machine learning algorithms like SVMs or Random Forests, we establish a seamless, end-to-end explainable pipeline. Our study contributes to the advancement of graph-based techniques that offer both performance and interpretability.", "url": "https://arxiv.org/abs/2308.15283"}, {"metadata": {"arXiv": "2308.15344", "Date": "Tue, 29 Aug 2023 14:41:05 ", "Title": "Imperceptible Adversarial Attack on Deep Neural Networks from Image Boundary", "Authors": ["Fahad Alrasheedi", "Xin Zhong"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Although Deep Neural Networks (DNNs), such as the convolutional neural networks (CNN) and Vision Transformers (ViTs), have been successfully applied in the field of computer vision, they are demonstrated to be vulnerable to well-sought Adversarial Examples (AEs) that can easily fool the DNNs. The research in AEs has been active, and many adversarial attacks and explanations have been proposed since they were discovered in 2014. The mystery of the AE's existence is still an open question, and many studies suggest that DNN training algorithms have blind spots. The salient objects usually do not overlap with boundaries; hence, the boundaries are not the DNN model's attention. Nevertheless, recent studies show that the boundaries can dominate the behavior of the DNN models. Hence, this study aims to look at the AEs from a different perspective and proposes an imperceptible adversarial attack that systemically attacks the input image boundary for finding the AEs. The experimental results have shown that the proposed boundary attacking method effectively attacks six CNN models and the ViT using only 32% of the input image content (from the boundaries) with an average success rate (SR) of 95.2% and an average peak signal-to-noise ratio of 41.37 dB. Correlation analyses are conducted, including the relation between the adversarial boundary's width and the SR and how the adversarial boundary changes the DNN model's attention. This paper's discoveries can potentially advance the understanding of AEs and provide a different perspective on how AEs can be constructed.", "url": "https://arxiv.org/abs/2308.15344"}, {"metadata": {"arXiv": "2308.15349", "Date": "Tue, 29 Aug 2023 14:45:23 ", "Title": "Lie-Poisson Neural Networks (LPNets): Data-Based Computing of Hamiltonian Systems with Symmetries", "Authors": ["Christopher Eldred", "Fran\\c{c}ois Gay-Balmaz", "Sofiia Huraka", "Vakhtang Putkaradze"], "Categories": "cs.LG math-ph math.MP", "Comments": ["57 pages", "13 figures"], "MSC-class": "70H15, 65L05", "ACM-class": "I.6.1; I.2.6"}, "abstract": "An accurate data-based prediction of the long-term evolution of Hamiltonian systems requires a network that preserves the appropriate structure under each time step. Every Hamiltonian system contains two essential ingredients: the Poisson bracket and the Hamiltonian. Hamiltonian systems with symmetries, whose paradigm examples are the Lie-Poisson systems, have been shown to describe a broad category of physical phenomena, from satellite motion to underwater vehicles, fluids, geophysical applications, complex fluids, and plasma physics. The Poisson bracket in these systems comes from the symmetries, while the Hamiltonian comes from the underlying physics. We view the symmetry of the system as primary, hence the Lie-Poisson bracket is known exactly, whereas the Hamiltonian is regarded as coming from physics and is considered not known, or known approximately. Using this approach, we develop a network based on transformations that exactly preserve the Poisson bracket and the special functions of the Lie-Poisson systems (Casimirs) to machine precision. We present two flavors of such systems: one, where the parameters of transformations are computed from data using a dense neural network (LPNets), and another, where the composition of transformations is used as building blocks (G-LPNets). We also show how to adapt these methods to a larger class of Poisson brackets. We apply the resulting methods to several examples, such as rigid body (satellite) motion, underwater vehicles, a particle in a magnetic field, and others. The methods developed in this paper are important for the construction of accurate data-based methods for simulating the long-term dynamics of physical systems.", "url": "https://arxiv.org/abs/2308.15349"}, {"metadata": {"arXiv": "2308.15364", "Date": "Tue, 29 Aug 2023 15:01:01 ", "Title": "Heterogeneous Multi-Task Gaussian Cox Processes", "Authors": ["Feng Zhou", "Quyu Kong", "Zhijie Deng", "Fengxiang He", "Peng Cui", "Jun Zhu"], "Categories": "cs.LG stat.ML"}, "abstract": "This paper presents a novel extension of multi-task Gaussian Cox processes for modeling multiple heterogeneous correlated tasks jointly, e.g., classification and regression, via multi-output Gaussian processes (MOGP). A MOGP prior over the parameters of the dedicated likelihoods for classification, regression and point process tasks can facilitate sharing of information between heterogeneous tasks, while allowing for nonparametric parameter estimation. To circumvent the non-conjugate Bayesian inference in the MOGP modulated heterogeneous multi-task framework, we employ the data augmentation technique and derive a mean-field approximation to realize closed-form iterative updates for estimating model parameters. We demonstrate the performance and inference on both 1D synthetic data as well as 2D urban data of Vancouver.", "url": "https://arxiv.org/abs/2308.15364"}, {"metadata": {"arXiv": "2308.15395", "Date": "Tue, 29 Aug 2023 15:54:15 ", "Title": "The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data", "Authors": ["Mathieu Chevalley", "Jacob Sackett-Sanders", "Yusuf Roohani", "Pascal Notin", "Artemy Bakulin", "Dariusz Brzezinski", "Kaiwen Deng", "Yuanfang Guan", "Justin Hong", "Michael Ibrahim", "Wojciech Kotlowski", "Marcin Kowiel", "Panagiotis Misiakos", "Achille Nazaret", "Markus P\\\"uschel", "Chris Wendler", "Arash Mehrjou", "Patrick Schwab"], "Categories": "cs.LG q-bio.MN q-bio.QM"}, "abstract": "In drug discovery, mapping interactions between genes within cellular systems is a crucial early step. This helps formulate hypotheses regarding molecular mechanisms that could potentially be targeted by future medicines. The CausalBench Challenge was an initiative to invite the machine learning community to advance the state of the art in constructing gene-gene interaction networks. These networks, derived from large-scale, real-world datasets of single cells under various perturbations, are crucial for understanding the causal mechanisms underlying disease biology. Using the framework provided by the CausalBench benchmark, participants were tasked with enhancing the capacity of the state of the art methods to leverage large-scale genetic perturbation data. This report provides an analysis and summary of the methods submitted during the challenge to give a partial image of the state of the art at the time of the challenge. The winning solutions significantly improved performance compared to previous baselines, establishing a new state of the art for this critical task in biology and medicine.", "url": "https://arxiv.org/abs/2308.15395"}, {"metadata": {"arXiv": "2308.15405", "Date": "Tue, 29 Aug 2023 16:07:18 ", "Title": "Robust Long-Tailed Learning via Label-Aware Bounded CVaR", "Authors": ["Hong Zhu", "Runpeng Yu", "Xing Tang", "Yifei Wang", "Yuan Fang", "Yisen Wang"], "Categories": "cs.LG cs.CV cs.IR"}, "abstract": "Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training. In such setting, the naive model tends to have poor performance on the minority classes. Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee. In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground. Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization process, where we also offer the theoretical support. Extensive experiments on real-world datasets with long-tailed label distributions verify the superiority of our proposed methods.", "url": "https://arxiv.org/abs/2308.15405"}, {"metadata": {"arXiv": "2308.15434", "Date": "Tue, 29 Aug 2023 16:56:03 ", "Title": "Random feature approximation for general spectral methods", "Authors": ["Mike Nguyen and Nicole M\\\"ucke"], "Categories": "cs.LG stat.ML"}, "abstract": "Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks. We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization. For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions. This improves or completes previous results obtained in related settings for specific kernel algorithms.", "url": "https://arxiv.org/abs/2308.15434"}, {"metadata": {"arXiv": "2308.15466", "Date": "Tue, 29 Aug 2023 17:47:42 ", "Title": "Input margins can predict generalization too", "Authors": ["Coenraad Mouton", "Marthinus W. Theunissen", "Marelie H. Davel"], "Categories": "cs.LG cs.CV"}, "abstract": "Understanding generalization in deep neural networks is an active area of research. A promising avenue of exploration has been that of margin measurements: the shortest distance to the decision boundary for a given sample or its representation internal to the network. While margins have been shown to be correlated with the generalization ability of a model when measured at its hidden representations (hidden margins), no such link between large margins and generalization has been established for input margins. We show that while input margins are not generally predictive of generalization, they can be if the search space is appropriately constrained. We develop such a measure based on input margins, which we refer to as `constrained margins'. The predictive power of this new measure is demonstrated on the 'Predicting Generalization in Deep Learning' (PGDL) dataset and contrasted with hidden representation margins. We find that constrained margins achieve highly competitive scores and outperform other margin measurements in general. This provides a novel insight on the relationship between generalization and classification margins, and highlights the importance of considering the data manifold for investigations of generalization in DNNs.", "url": "https://arxiv.org/abs/2308.15466"}, {"metadata": {"arXiv": "2308.15470", "Date": "Tue, 29 Aug 2023 17:50:27 ", "Title": "Policy composition in reinforcement learning via multi-objective policy optimization", "Authors": ["Shruti Mishra", "Ankit Anand", "Jordan Hoffmann", "Nicolas Heess", "Martin Riedmiller", "Abbas Abdolmaleki", "Doina Precup"], "Categories": "cs.LG"}, "abstract": "We enable reinforcement learning agents to learn successful behavior policies by utilizing relevant pre-existing teacher policies. The teacher policies are introduced as objectives, in addition to the task objective, in a multi-objective policy optimization setting. Using the Multi-Objective Maximum a Posteriori Policy Optimization algorithm \\citep{abdolmaleki2020distributional}, we show that teacher policies can help speed up learning, particularly in the absence of shaping rewards. In two domains with continuous observation and action spaces, our agents successfully compose teacher policies in sequence and in parallel, and are also able to further extend the policies of the teachers in order to solve the task. Depending on the specified combination of task and teacher(s), teacher(s) may naturally act to limit the final performance of an agent. The extent to which agents are required to adhere to teacher policies are determined by hyperparameters which determine both the effect of teachers on learning speed and the eventual performance of the agent on the task. In the {\\tt humanoid} domain \\citep{deepmindcontrolsuite2018}, we also equip agents with the ability to control the selection of teachers. With this ability, agents are able to meaningfully compose from the teacher policies to achieve a superior task reward on the {\\tt walk} task than in cases without access to the teacher policies. We show the resemblance of composed task policies with the corresponding teacher policies through videos.", "url": "https://arxiv.org/abs/2308.15470"}, {"metadata": {"arXiv": "2308.15478", "Date": "Tue, 29 Aug 2023 17:57:20 ", "Title": "An Adaptive Tangent Feature Perspective of Neural Networks", "Authors": ["Daniel LeJeune", "Sina Alemohammad"], "Categories": "cs.LG cs.CV", "Comments": ["15 pages", "4 figures"]}, "abstract": "In order to better understand feature learning in neural networks, we propose a framework for understanding linear models in tangent feature space where the features are allowed to be transformed during training. We consider linear transformations of features, resulting in a joint optimization over parameters and transformations with a bilinear interpolation constraint. We show that this optimization problem has an equivalent linearly constrained optimization with structured regularization that encourages approximately low rank solutions. Specializing to neural network structure, we gain insights into how the features and thus the kernel function change, providing additional nuance to the phenomenon of kernel alignment when the target function is poorly represented using tangent features. In addition to verifying our theoretical observations in real neural networks on a simple regression problem, we empirically show that an adaptive feature implementation of tangent feature classification has an order of magnitude lower sample complexity than the fixed tangent feature model on MNIST and CIFAR-10.", "url": "https://arxiv.org/abs/2308.15478"}, {"metadata": {"arXiv": "2308.14947", "Date": "Tue, 29 Aug 2023 00:00:18 ", "Title": "Improving Reinforcement Learning Training Regimes for Social Robot Navigation", "Authors": ["Adam Sigal", "Hsiu-Chin Lin", "AJung Moon"], "Categories": "cs.RO cs.LG cs.MA"}, "abstract": "In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train robot navigation policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing state-of-the art RL social navigation works do not evaluate their methods outside of their training environments, and thus do not reflect their policies' failure to adequately generalize to out-of-distribution scenarios. In response, we validate our training approach on larger and more crowded testing environments than those used in training, allowing for more meaningful measurements of model performance.", "url": "https://arxiv.org/abs/2308.14947"}, {"metadata": {"arXiv": "2308.14971", "Date": "Tue, 29 Aug 2023 01:53:14 ", "Title": "Distributed multi-agent target search and tracking with Gaussian process and reinforcement learning", "Authors": ["Jigang Kim", "Dohyun Jang", "H. Jin Kim"], "Categories": "cs.RO cs.LG", "Comments": ["10 pages", "6 figures; preprint submitted to IJCAS; first two authors contributed equally"], "Journal-ref": "International Journal of Control, Automation, and Systems 2023 21(9): 3057-3067", "DOI": "10.1007/s12555-022-0555-0"}, "abstract": "Deploying multiple robots for target search and tracking has many practical applications, yet the challenge of planning over unknown or partially known targets remains difficult to address. With recent advances in deep learning, intelligent control techniques such as reinforcement learning have enabled agents to learn autonomously from environment interactions with little to no prior knowledge. Such methods can address the exploration-exploitation tradeoff of planning over unknown targets in a data-driven manner, eliminating the reliance on heuristics typical of traditional approaches and streamlining the decision-making pipeline with end-to-end training. In this paper, we propose a multi-agent reinforcement learning technique with target map building based on distributed Gaussian process. We leverage the distributed Gaussian process to encode belief over the target locations and efficiently plan over unknown targets. We evaluate the performance and transferability of the trained policy in simulation and demonstrate the method on a swarm of micro unmanned aerial vehicles with hardware experiments.", "url": "https://arxiv.org/abs/2308.14971"}, {"metadata": {"arXiv": "2308.15327", "Date": "Tue, 29 Aug 2023 14:23:44 ", "Title": "Enhancing Robot Learning through Learned Human-Attention Feature Maps", "Authors": ["Daniel Scheuchenstuhl", "Stefan Ulmer", "Felix Resch", "Luigi Berducci", "Radu Grosu"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["This work has been accepted for the RAP4Robots workshop at ICRA 2023 in London"]}, "abstract": "Robust and efficient learning remains a challenging problem in robotics, in particular with complex visual inputs. Inspired by human attention mechanism, with which we quickly process complex visual scenes and react to changes in the environment, we think that embedding auxiliary information about focus point into robot learning would enhance efficiency and robustness of the learning process. In this paper, we propose a novel approach to model and emulate the human attention with an approximate prediction model. We then leverage this output and feed it as a structured auxiliary feature map into downstream learning tasks. We validate this idea by learning a prediction model from human-gaze recordings of manual driving in the real world. We test our approach on two learning tasks - object detection and imitation learning. Our experiments demonstrate that the inclusion of predicted human attention leads to improved robustness of the trained models to out-of-distribution samples and faster learning in low-data regime settings. Our work highlights the potential of incorporating structured auxiliary information in representation learning for robotics and opens up new avenues for research in this direction. All code and data are available online.", "url": "https://arxiv.org/abs/2308.15327"}, {"metadata": {"arXiv": "2308.14840", "Date": "Mon, 28 Aug 2023 18:51:09 ", "Title": "Identifying and Mitigating the Security Risks of Generative AI", "Authors": ["Clark Barrett", "Brad Boyd", "Ellie Burzstein", "Nicholas Carlini", "Brad Chen", "Jihye Choi", "Amrita Roy Chowdhury", "Mihai Christodorescu", "Anupam Datta", "Soheil Feizi", "Kathleen Fisher", "Tatsunori Hashimoto", "Dan Hendrycks", "Somesh Jha", "Daniel Kang", "Florian Kerschbaum", "Eric Mitchell", "John Mitchell", "Zulfikar Ramzan", "Khawaja Shams", "Dawn Song", "Ankur Taly", "Diyi Yang"], "Categories": "cs.AI"}, "abstract": "Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks. This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interesting problems that the research community can work to address.", "url": "https://arxiv.org/abs/2308.14840"}, {"metadata": {"arXiv": "2308.14898", "Date": "Mon, 28 Aug 2023 20:46:59 ", "Title": "Proceedings 39th International Conference on Logic Programming", "Authors": ["Enrico Pontelli (New Mexico State University", "USA)", "Stefania Costantini (University of L'Aquila", "Italy)", "Carmine Dodaro (University of Calabria", "Italy)", "Sarah Gaggl (TU Dresden", "Germany)", "Roberta Calegari (University of Bologna", "Italy)", "Artur D'Avila Garcez (City University of London", "UK)", "Francesco Fabiano (University of Udine", "Italy)", "Alessandra Mileo (DCU", "Ireland)", "Alessandra Russo (Imperial College London", "UK)", "Francesca Toni (Imperial College London", "UK)"], "Categories": "cs.AI cs.LO cs.PL cs.SC", "Journal-ref": "EPTCS 385, 2023", "DOI": "10.4204/EPTCS.385"}, "abstract": "This volume contains the Technical Communications presented at the 39th International Conference on Logic Programming (ICLP 2023), held at Imperial College London, UK from July 9 to July 15, 2023. Technical Communications included here concern the Main Track, the Doctoral Consortium, the Application and Systems/Demo track, the Recently Published Research Track, the Birds-of-a-Feather track, the Thematic Tracks on Logic Programming and Machine Learning, and Logic Programming and Explainability, Ethics, and Trustworthiness.", "url": "https://arxiv.org/abs/2308.14898"}, {"metadata": {"arXiv": "2308.14943", "Date": "Mon, 28 Aug 2023 23:50:36 ", "Title": "Transfusor: Transformer Diffusor for Controllable Human-like Generation of Vehicle Lane Changing Trajectories", "Authors": ["Jiqian Dong", "Sikai Chen", "Samuel Labi"], "Categories": "cs.AI cs.RO", "Comments": ["Submitted for presentation only at the 2024 Annual Meeting of the Transportation Research Board"]}, "abstract": "With ongoing development of autonomous driving systems and increasing desire for deployment, researchers continue to seek reliable approaches for ADS systems. The virtual simulation test (VST) has become a prominent approach for testing autonomous driving systems (ADS) and advanced driver assistance systems (ADAS) due to its advantages of fast execution, low cost, and high repeatability. However, the success of these simulation-based experiments heavily relies on the realism of the testing scenarios. It is needed to create more flexible and high-fidelity testing scenarios in VST in order to increase the safety and reliabilityof ADS and ADAS.To address this challenge, this paper introduces the \"Transfusor\" model, which leverages the transformer and diffusor models (two cutting-edge deep learning generative technologies). The primary objective of the Transfusor model is to generate highly realistic and controllable human-like lane-changing trajectories in highway scenarios. Extensive experiments were carried out, and the results demonstrate that the proposed model effectively learns the spatiotemporal characteristics of humans' lane-changing behaviors and successfully generates trajectories that closely mimic real-world human driving. As such, the proposed model can play a critical role of creating more flexible and high-fidelity testing scenarios in the VST, ultimately leading to safer and more reliable ADS and ADAS.", "url": "https://arxiv.org/abs/2308.14943"}, {"metadata": {"arXiv": "2308.15002", "Date": "Tue, 29 Aug 2023 03:26:38 ", "Title": "Exploring the Limits of Historical Information for Temporal Knowledge Graph Extrapolation", "Authors": ["Yi Xu", "Junjie Ou", "Hui Xu", "Luoyi Fu", "Lei Zhou", "Xinbing Wang", "Chenghu Zhou"], "Categories": "cs.AI", "Comments": ["Extended version of AAAI paper arXiv:2211.10904"]}, "abstract": "Temporal knowledge graphs, representing the dynamic relationships and interactions between entities over time, have been identified as a promising approach for event forecasting. However, a limitation of most temporal knowledge graph reasoning methods is their heavy reliance on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current state of affairs is often the result of a combination of historical information and underlying factors that are not directly observable. To this end, we investigate the limits of historical information for temporal knowledge graph extrapolation and propose a new event forecasting model called Contrastive Event Network (CENET) based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that best match the given query. Simultaneously, by launching contrastive learning, it trains representations of queries to probe whether the current moment is more dependent on historical or non-historical events. These representations further help train a binary classifier, whose output is a boolean mask, indicating the related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least 8.3% relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets.", "url": "https://arxiv.org/abs/2308.15002"}, {"metadata": {"arXiv": "2308.15003", "Date": "Tue, 29 Aug 2023 03:28:14 ", "Title": "Generative Model for Models: Rapid DNN Customization for Diverse Tasks and Resource Constraints", "Authors": ["Wenxing Xu", "Yuanchun Li", "Jiacheng Liu", "Yi Sun", "Zhengyang Cao", "Yixuan Li", "Hao Wen", "Yunxin Liu"], "Categories": "cs.AI cs.SE"}, "abstract": "Unlike cloud-based deep learning models that are often large and uniform, edge-deployed models usually demand customization for domain-specific tasks and resource-limited environments. Such customization processes can be costly and time-consuming due to the diversity of edge scenarios and the training load for each scenario. Although various approaches have been proposed for rapid resource-oriented customization and task-oriented customization respectively, achieving both of them at the same time is challenging. Drawing inspiration from the generative AI and the modular composability of neural networks, we introduce NN-Factory, an one-for-all framework to generate customized lightweight models for diverse edge scenarios. The key idea is to use a generative model to directly produce the customized models, instead of training them. The main components of NN-Factory include a modular supernet with pretrained modules that can be conditionally activated to accomplish different tasks and a generative module assembler that manipulate the modules according to task and sparsity requirements. Given an edge scenario, NN-Factory can efficiently customize a compact model specialized in the edge task while satisfying the edge resource constraints by searching for the optimal strategy to assemble the modules. Based on experiments on image classification and object detection tasks with different edge devices, NN-Factory is able to generate high-quality task- and resource-specific models within few seconds, faster than conventional model customization approaches by orders of magnitude.", "url": "https://arxiv.org/abs/2308.15003"}, {"metadata": {"arXiv": "2308.15030", "Date": "Tue, 29 Aug 2023 05:25:21 ", "Title": "Serving MoE Models on Resource-constrained Edge Devices via Dynamic Expert Swapping", "Authors": ["Rui Kong", "Yuanchun Li", "Qingtian Feng", "Weijun Wang", "Linghe Kong", "Yunxin Liu"], "Categories": "cs.AI"}, "abstract": "Mixture of experts (MoE) is a popular technique in deep learning that improves model capacity with conditionally-activated parallel neural network modules (experts). However, serving MoE models in resource-constrained latency-critical edge scenarios is challenging due to the significantly increased model size and complexity. In this paper, we first analyze the behavior pattern of MoE models in continuous inference scenarios, which leads to three key observations about the expert activations, including temporal locality, exchangeability, and skippable computation. Based on these observations, we introduce PC-MoE, an inference framework for resource-constrained continuous MoE model serving. The core of PC-MoE is a new data structure, Parameter Committee, that intelligently maintains a subset of important experts in use to reduce resource consumption. The optimal configuration of Parameter Committee is found offline by a profiling-guided committee planner, and expert swapping and request handling at runtime are managed by an adaptive committee scheduler. To evaluate the effectiveness of PC-MoE, we conduct experiments using state-of-the-art MoE models on common computer vision and natural language processing tasks. The results demonstrate optimal trade-offs between resource consumption and model accuracy achieved by PC-MoE. For instance, on object detection tasks with the Swin-MoE model, our approach can reduce memory usage and latency by 42.34% and 18.63% with only 0.10% accuracy degradation.", "url": "https://arxiv.org/abs/2308.15030"}, {"metadata": {"arXiv": "2308.15068", "Date": "Tue, 29 Aug 2023 07:00:35 ", "Title": "A Comprehensive Augmentation Framework for Anomaly Detection", "Authors": ["Jiang Lin", "Yaping Yan"], "Categories": "cs.AI cs.CV"}, "abstract": "Data augmentation methods are commonly integrated into the training of anomaly detection models. Previous approaches have primarily focused on replicating real-world anomalies or enhancing diversity, without considering that the standard of anomaly varies across different classes, potentially leading to a biased training distribution.This paper analyzes crucial traits of simulated anomalies that contribute to the training of reconstructive networks and condenses them into several methods, thus creating a comprehensive framework by selectively utilizing appropriate combinations.Furthermore, we integrate this framework with a reconstruction-based approach and concurrently propose a split training strategy that alleviates the issue of overfitting while avoiding introducing interference to the reconstruction process. The evaluations conducted on the MVTec anomaly detection dataset demonstrate that our method outperforms the previous state-of-the-art approach, particularly in terms of object classes.To evaluate generalizability, we generate a simulated dataset comprising anomalies with diverse characteristics since the original test samples only include specific types of anomalies and may lead to biased evaluations. Experimental results demonstrate that our approach exhibits promising potential for generalizing effectively to various unforeseen anomalies encountered in real-world scenarios.", "url": "https://arxiv.org/abs/2308.15068"}, {"metadata": {"arXiv": "2308.15078", "Date": "Tue, 29 Aug 2023 07:25:42 ", "Title": "LAMBO: Large Language Model Empowered Edge Intelligence", "Authors": ["Li Dong", "Feibo Jiang", "Yubo Peng", "Kezhi Wang", "Kun Yang", "Cunhua Pan", "Robert Schober"], "Categories": "cs.AI cs.NI", "Comments": ["To be submitted for possible journal publication"]}, "abstract": "Next-generation edge intelligence is anticipated to bring huge benefits to various applications, e.g., offloading systems. However, traditional deep offloading architectures face several issues, including heterogeneous constraints, partial perception, uncertain generalization, and lack of tractability. In this context, the integration of offloading with large language models (LLMs) presents numerous advantages. Therefore, we propose an LLM-Based Offloading (LAMBO) framework for mobile edge computing (MEC), which comprises four components: (i) Input embedding (IE), which is used to represent the information of the offloading system with constraints and prompts through learnable vectors with high quality; (ii) Asymmetric encoderdecoder (AED) model, which is a decision-making module with a deep encoder and a shallow decoder. It can achieve high performance based on multi-head self-attention schemes; (iii) Actor-critic reinforcement learning (ACRL) module, which is employed to pre-train the whole AED for different optimization tasks under corresponding prompts; and (iv) Active learning from expert feedback (ALEF), which can be used to finetune the decoder part of the AED while adapting to dynamic environmental changes. Our simulation results corroborate the advantages of the proposed LAMBO framework.", "url": "https://arxiv.org/abs/2308.15078"}, {"metadata": {"arXiv": "2308.15097", "Date": "Tue, 29 Aug 2023 08:07:26 ", "Title": "Sequential annotations for naturally-occurring HRI: first insights", "Authors": ["Lucien Tisserand (ICAR)", "Fr\\'ed\\'eric Armetta (SyCoSMA", "LIRIS)", "Heike Baldauf-Quilliatre (ICAR)", "Antoine Bouquin (SyCoSMA", "LIRIS)", "Salima Hassas (SyCoSMA", "LIRIS)", "Mathieu Lefort (LIRIS", "SyCoSMA)"], "Categories": "cs.AI cs.CL", "Comments": ["Peer-reviewed workshop paper accepted for the ''Human-Robot Conversational Interaction'' workshop that took place at the ''ACM/IEEE International Conference on Human-Robot Interaction'' 2023 Conference in Stockholm", "Sweden"]}, "abstract": "We explain the methodology we developed for improving the interactions accomplished by an embedded conversational agent, drawing from Conversation Analytic sequential and multimodal analysis. The use case is a Pepper robot that is expected to inform and orient users in a library. In order to propose and learn better interactive schema, we are creating a corpus of naturally-occurring interactions that will be made available to the community. To do so, we propose an annotation practice based on some theoretical underpinnings about the use of language and multimodal resources in human-robot interaction. CCS CONCEPTS $\\bullet$ Computing methodologies $\\rightarrow$ Discourse, dialogue and pragmatics; $\\bullet$ Human-centered computing $\\rightarrow$ Text input; HCI theory, concepts and models; Field studies.", "url": "https://arxiv.org/abs/2308.15097"}, {"metadata": {"arXiv": "2308.15099", "Date": "Tue, 29 Aug 2023 08:10:09 ", "Title": "Probabilistic Dataset Reconstruction from Interpretable Models", "Authors": ["Julien Ferry (LAAS-ROC)", "Ulrich A\\\"ivodji (ETS)", "S\\'ebastien Gambs (UQAM)", "Marie-Jos\\'e Huguet (LAAS-ROC)", "Mohamed Siala (LAAS-ROC)"], "Categories": "cs.AI cs.IT math.IT"}, "abstract": "Interpretability is often pointed out as a key requirement for trustworthy machine learning. However, learning and releasing models that are inherently interpretable leaks information regarding the underlying training data. As such disclosure may directly conflict with privacy, a precise quantification of the privacy impact of such breach is a fundamental problem. For instance, previous work have shown that the structure of a decision tree can be leveraged to build a probabilistic reconstruction of its training dataset, with the uncertainty of the reconstruction being a relevant metric for the information leak. In this paper, we propose of a novel framework generalizing these probabilistic reconstructions in the sense that it can handle other forms of interpretable models and more generic types of knowledge. In addition, we demonstrate that under realistic assumptions regarding the interpretable models' structure, the uncertainty of the reconstruction can be computed efficiently. Finally, we illustrate the applicability of our approach on both decision trees and rule lists, by comparing the theoretical information leak associated to either exact or heuristic learning algorithms. Our results suggest that optimal interpretable models are often more compact and leak less information regarding their training data than greedily-built ones, for a given accuracy level.", "url": "https://arxiv.org/abs/2308.15099"}, {"metadata": {"arXiv": "2308.15119", "Date": "Tue, 29 Aug 2023 08:37:16 ", "Title": "AI-Based Facial Emotion Recognition Solutions for Education: A Study of Teacher-User and Other Categories", "Authors": ["R. Yamamoto Ravenor"], "Categories": "cs.AI cs.CV cs.CY cs.HC"}, "abstract": "Existing information on AI-based facial emotion recognition (FER) is not easily comprehensible by those outside the field of computer science, requiring cross-disciplinary effort to determine a categorisation framework that promotes the understanding of this technology, and its impact on users. Most proponents classify FER in terms of methodology, implementation and analysis; relatively few by its application in education; and none by its users. This paper is concerned primarily with (potential) teacher-users of FER tools for education. It proposes a three-part classification of these teachers, by orientation, condition and preference, based on a classical taxonomy of affective educational objectives, and related theories. It also compiles and organises the types of FER solutions found in or inferred from the literature into \"technology\" and \"applications\" categories, as a prerequisite for structuring the proposed \"teacher-user\" category. This work has implications for proponents', critics', and users' understanding of the relationship between teachers and FER.", "url": "https://arxiv.org/abs/2308.15119"}, {"metadata": {"arXiv": "2308.15168", "Date": "Tue, 29 Aug 2023 09:52:21 ", "Title": "Ontologies in Digital Twins: A Systematic Literature Review", "Authors": ["Erkan Karabulut", "Salvatore F. Pileggi", "Paul Groth and Victoria Degeler"], "Categories": "cs.AI", "Comments": ["The Systematic Literature Review (SLR) is submitted to Future Generation Computer System journal's Special Issue on Digital Twin for Future Networks and Emerging IoT Applications (2023)"]}, "abstract": "Digital Twins (DT) facilitate monitoring and reasoning processes in cyber-physical systems. They have progressively gained popularity over the past years because of intense research activity and industrial advancements. Cognitive Twins is a novel concept, recently coined to refer to the involvement of Semantic Web technology in DTs. Recent studies address the relevance of ontologies and knowledge graphs in the context of DTs, in terms of knowledge representation, interoperability and automatic reasoning. However, there is no comprehensive analysis of how semantic technologies, and specifically ontologies, are utilized within DTs. This Systematic Literature Review (SLR) is based on the analysis of 82 research articles, that either propose or benefit from ontologies with respect to DT. The paper uses different analysis perspectives, including a structural analysis based on a reference DT architecture, and an application-specific analysis to specifically address the different domains, such as Manufacturing and Infrastructure. The review also identifies open issues and possible research directions on the usage of ontologies and knowledge graphs in DTs.", "url": "https://arxiv.org/abs/2308.15168"}, {"metadata": {"arXiv": "2308.15178", "Date": "Tue, 29 Aug 2023 10:00:33 ", "Title": "Symbolic LTLf Best-Effort Synthesis", "Authors": ["Giuseppe De Giacomo", "Gianmarco Parretti", "Shufang Zhu"], "Categories": "cs.AI cs.FL cs.GT cs.LO cs.RO", "Comments": ["To appear at EUMAS2023"]}, "abstract": "We consider an agent acting to fulfil tasks in a nondeterministic environment. When a strategy that fulfills the task regardless of how the environment acts does not exist, the agent should at least avoid adopting strategies that prevent from fulfilling its task. Best-effort synthesis captures this intuition. In this paper, we devise and compare various symbolic approaches for best-effort synthesis in Linear Temporal Logic on finite traces (LTLf). These approaches are based on the same basic components, however they change in how these components are combined, and this has a significant impact on the performance of the approaches as confirmed by our empirical evaluations.", "url": "https://arxiv.org/abs/2308.15178"}, {"metadata": {"arXiv": "2308.15188", "Date": "Tue, 29 Aug 2023 10:10:41 ", "Title": "LTLf Best-Effort Synthesis in Nondeterministic Planning Domains", "Authors": ["Giuseppe De Giacomo", "Gianmarco Parretti", "Shufang Zhu"], "Categories": "cs.AI cs.FL cs.GT cs.RO", "Comments": ["To appear at ECAI2023"]}, "abstract": "We study best-effort strategies (aka plans) in fully observable nondeterministic domains (FOND) for goals expressed in Linear Temporal Logic on Finite Traces (LTLf). The notion of best-effort strategy has been introduced to also deal with the scenario when no agent strategy exists that fulfills the goal against every possible nondeterministic environment reaction. Such strategies fulfill the goal if possible, and do their best to do so otherwise. We present a game-theoretic technique for synthesizing best-effort strategies that exploit the specificity of nondeterministic planning domains. We formally show its correctness and demonstrate its effectiveness experimentally, exhibiting a much greater scalability with respect to a direct best-effort synthesis approach based on re-expressing the planning domain as generic environment specifications.", "url": "https://arxiv.org/abs/2308.15188"}, {"metadata": {"arXiv": "2308.15192", "Date": "Tue, 29 Aug 2023 10:20:53 ", "Title": "Enhancing Psychological Counseling with Large Language Model: A Multifaceted Decision-Support System for Non-Professionals", "Authors": ["Guanghui Fu", "Qing Zhao", "Jianqiang Li", "Dan Luo", "Changwei Song", "Wei Zhai", "Shuo Liu", "Fan Wang", "Yan Wang", "Lijuan Cheng", "Juan Zhang", "Bing Xiang Yang"], "Categories": "cs.AI cs.CL"}, "abstract": "In the contemporary landscape of social media, an alarming number of users express negative emotions, some of which manifest as strong suicidal intentions. This situation underscores a profound need for trained psychological counselors who can enact effective mental interventions. However, the development of these professionals is often an imperative but time-consuming task. Consequently, the mobilization of non-professionals or volunteers in this capacity emerges as a pressing concern. Leveraging the capabilities of artificial intelligence, and in particular, the recent advances in large language models, offers a viable solution to this challenge. This paper introduces a novel model constructed on the foundation of large language models to fully assist non-professionals in providing psychological interventions on online user discourses. This framework makes it plausible to harness the power of non-professional counselors in a meaningful way. A comprehensive study was conducted involving ten professional psychological counselors of varying expertise, evaluating the system across five critical dimensions. The findings affirm that our system is capable of analyzing patients' issues with relative accuracy and proffering professional-level strategies recommendations, thereby enhancing support for non-professionals. This research serves as a compelling validation of the application of large language models in the field of psychology and lays the groundwork for a new paradigm of community-based mental health support.", "url": "https://arxiv.org/abs/2308.15192"}, {"metadata": {"arXiv": "2308.15197", "Date": "Tue, 29 Aug 2023 10:24:23 ", "Title": "Where Would I Go Next? Large Language Models as Human Mobility Predictors", "Authors": ["Xinglei Wang", "Meng Fang", "Zichao Zeng", "Tao Cheng"], "Categories": "cs.AI cs.SI physics.soc-ph", "Comments": ["13 pages", "5 figures", "4 tables"]}, "abstract": "Accurate human mobility prediction underpins many important applications across a variety of domains, including epidemic modelling, transport planning, and emergency responses. Due to the sparsity of mobility data and the stochastic nature of people's daily activities, achieving precise predictions of people's locations remains a challenge. While recently developed large language models (LLMs) have demonstrated superior performance across numerous language-related tasks, their applicability to human mobility studies remains unexplored. Addressing this gap, this article delves into the potential of LLMs for human mobility prediction tasks. We introduce a novel method, LLM-Mob, which leverages the language understanding and reasoning capabilities of LLMs for analysing human mobility data. We present concepts of historical stays and context stays to capture both long-term and short-term dependencies in human movement and enable time-aware prediction by using time information of the prediction target. Additionally, we design context-inclusive prompts that enable LLMs to generate more accurate predictions. Comprehensive evaluations of our method reveal that LLM-Mob excels in providing accurate and interpretable predictions, highlighting the untapped potential of LLMs in advancing human mobility prediction techniques. We posit that our research marks a significant paradigm shift in human mobility modelling, transitioning from building complex domain-specific models to harnessing general-purpose LLMs that yield accurate predictions through language instructions. The code for this work is available at https://github.com/xlwang233/LLM-Mob.", "url": "https://arxiv.org/abs/2308.15197"}, {"metadata": {"arXiv": "2308.15239", "Date": "Tue, 29 Aug 2023 11:59:02 ", "Title": "Natural language to SQL in low-code platforms", "Authors": ["Sofia Aparicio", "Samuel Arcadinho", "Jo\\~ao Nadkarni", "David Apar\\'icio", "Jo\\~ao Lages", "Mariana Louren\\c{c}o", "Bart{\\l}omiej Matejczyk", "Filipe Assun\\c{c}\\~ao"], "Categories": "cs.AI"}, "abstract": "One of the developers' biggest challenges in low-code platforms is retrieving data from a database using SQL queries. Here, we propose a pipeline allowing developers to write natural language (NL) to retrieve data. In this study, we collect, label, and validate data covering the SQL queries most often performed by OutSystems users. We use that data to train a NL model that generates SQL. Alongside this, we describe the entire pipeline, which comprises a feedback loop that allows us to quickly collect production data and use it to retrain our SQL generation model. Using crowd-sourcing, we collect 26k NL and SQL pairs and obtain an additional 1k pairs from production data. Finally, we develop a UI that allows developers to input a NL query in a prompt and receive a user-friendly representation of the resulting SQL query. We use A/B testing to compare four different models in production and observe a 240% improvement in terms of adoption of the feature, 220% in terms of engagement rate, and a 90% decrease in failure rate when compared against the first model that we put into production, showcasing the effectiveness of our pipeline in continuously improving our feature.", "url": "https://arxiv.org/abs/2308.15239"}, {"metadata": {"arXiv": "2308.15272", "Date": "Tue, 29 Aug 2023 13:02:30 ", "Title": "Empowering LLM to use Smartphone for Intelligent Task Automation", "Authors": ["Hao Wen", "Yuanchun Li", "Guohong Liu", "Shanhui Zhao", "Tao Yu", "Toby Jia-Jun Li", "Shiqi Jiang", "Yunhao Liu", "Yaqin Zhang", "Yunxin Liu"], "Categories": "cs.AI cs.SE"}, "abstract": "Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or end-users. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system that can handle arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9%, and complete tasks with a success rate of 71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo, benchmark suites, and source code of AutoDroid will be released at https://autodroid-sys.github.io/.", "url": "https://arxiv.org/abs/2308.15272"}, {"metadata": {"arXiv": "2308.15324", "Date": "Tue, 29 Aug 2023 14:20:17 ", "Title": "FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models", "Authors": ["Pengwei Xing", "Songtao Lu", "Han Yu"], "Categories": "cs.AI"}, "abstract": "Leveraging ``chain-of-thought (CoT)'' reasoning to elicit rapid and precise responses from large language models (LLMs) is rapidly attracting research interest. A notable challenge here is how to design or select optimal prompts. The process of prompt selection relies on trial and error, involving continuous adjustments and combinations of input prompts by users based on the corresponding new responses generated from LLMs. Furthermore, minimal research has been conducted to explore how LLMs employ the mathematical problem-solving capabilities learned from user interactions to address issues in narrative writing. To improve interpretability and explore the balance principle between generality and personalization under a multi-domain CoT prompt selection scenario, we propose the Federated Logic rule learning approach (FedLogic). We introduce a theoretical formalization and interactive emulation of the multi-domain CoT prompt selection dilemma in the context of federated LLMs. We cast the problem of joint probability modeling as a bilevel program, where the CoT prompt selection intricacy can be likened to a fuzzy score-based rule selection with the LLMs function as rule generators. FedLogic solves this problem through variational expectation maximization (V-EM). In addition, we incorporate two KL-divergence constraints within this probabilistic modeling framework to surmount the intricacies of managing extensive search spaces and accomplishing cross-domain personalization of CoTs. To the best of our knowledge, FedLogic is the first interpretable and principled federated multi-domain CoT prompt selection approach for LLMs.", "url": "https://arxiv.org/abs/2308.15324"}, {"metadata": {"arXiv": "2308.15339", "Date": "Tue, 29 Aug 2023 14:33:38 ", "Title": "AI Framework for Early Diagnosis of Coronary Artery Disease: An Integration of Borderline SMOTE, Autoencoders and Convolutional Neural Networks Approach", "Authors": ["Elham Nasarian", "Danial Sharifrazi", "Saman Mohsenirad", "Kwok Tsui", "Roohallah Alizadehsani"], "Categories": "cs.AI"}, "abstract": "The accuracy of coronary artery disease (CAD) diagnosis is dependent on a variety of factors, including demographic, symptom, and medical examination, ECG, and echocardiography data, among others. In this context, artificial intelligence (AI) can help clinicians identify high-risk patients early in the diagnostic process, by synthesizing information from multiple factors. To this aim, Machine Learning algorithms are used to classify patients based on their CAD disease risk. In this study, we contribute to this research filed by developing a methodology for balancing and augmenting data for more accurate prediction when the data is imbalanced and the sample size is small. The methodology can be used in a variety of other situations, particularly when data collection is expensive and the sample size is small. The experimental results revealed that the average accuracy of our proposed method for CAD prediction was 95.36, and was higher than random forest (RF), decision tree (DT), support vector machine (SVM), logistic regression (LR), and artificial neural network (ANN).", "url": "https://arxiv.org/abs/2308.15339"}, {"metadata": {"arXiv": "2308.15390", "Date": "Tue, 29 Aug 2023 15:33:51 ", "Title": "Bayesian Integration of Information Using Top-Down Modulated WTA Networks", "Authors": ["Otto van der Himst", "Leila Bagheriye", "and Johan Kwisthout"], "Categories": "cs.AI"}, "abstract": "Winner Take All (WTA) circuits a type of Spiking Neural Networks (SNN) have been suggested as facilitating the brain's ability to process information in a Bayesian manner. Research has shown that WTA circuits are capable of approximating hierarchical Bayesian models via Expectation Maximization (EM). So far, research in this direction has focused on bottom up processes. This is contrary to neuroscientific evidence that shows that, besides bottom up processes, top down processes too play a key role in information processing by the human brain. Several functions ascribed to top down processes include direction of attention, adjusting for expectations, facilitation of encoding and recall of learned information, and imagery. This paper explores whether WTA circuits are suitable for further integrating information represented in separate WTA networks. Furthermore, it explores whether, and under what circumstances, top down processes can improve WTA network performance with respect to inference and learning. The results show that WTA circuits are capable of integrating the probabilistic information represented by other WTA networks, and that top down processes can improve a WTA network's inference and learning performance. Notably, it is able to do this according to key neuromorphic principles, making it ideal for low-latency and energy efficient implementation on neuromorphic hardware.", "url": "https://arxiv.org/abs/2308.15390"}, {"metadata": {"arXiv": "2308.14899", "Date": "Mon, 28 Aug 2023 20:52:18 ", "Title": "RobustCLEVR: A Benchmark and Framework for Evaluating Robustness in Object-centric Learning", "Authors": ["Nathan Drenkow", "Mathias Unberath"], "Categories": "cs.CV cs.AI"}, "abstract": "Object-centric representation learning offers the potential to overcome limitations of image-level representations by explicitly parsing image scenes into their constituent components. While image-level representations typically lack robustness to natural image corruptions, the robustness of object-centric methods remains largely untested. To address this gap, we present the RobustCLEVR benchmark dataset and evaluation framework. Our framework takes a novel approach to evaluating robustness by enabling the specification of causal dependencies in the image generation process grounded in expert knowledge and capable of producing a wide range of image corruptions unattainable in existing robustness evaluations. Using our framework, we define several causal models of the image corruption process which explicitly encode assumptions about the causal relationships and distributions of each corruption type. We generate dataset variants for each causal model on which we evaluate state-of-the-art object-centric methods. Overall, we find that object-centric methods are not inherently robust to image corruptions. Our causal evaluation approach exposes model sensitivities not observed using conventional evaluation processes, yielding greater insight into robustness differences across algorithms. Lastly, while conventional robustness evaluations view corruptions as out-of-distribution, we use our causal framework to show that even training on in-distribution image corruptions does not guarantee increased model robustness. This work provides a step towards more concrete and substantiated understanding of model performance and deterioration under complex corruption processes of the real-world.", "url": "https://arxiv.org/abs/2308.14899"}, {"metadata": {"arXiv": "2308.14936", "Date": "Mon, 28 Aug 2023 23:23:53 ", "Title": "Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation", "Authors": ["Chengyin Li", "Prashant Khanduri", "Yao Qiang", "Rafi Ibn Sultan", "Indrin Chetty and Dongxiao Zhu"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "4 figures", "4 tables"]}, "abstract": "The Segment Anything Model (SAM) has rapidly been adopted for segmenting a wide range of natural images. However, recent studies have indicated that SAM exhibits subpar performance on 3D medical image segmentation tasks. In addition to the domain gaps between natural and medical images, disparities in the spatial arrangement between 2D and 3D images, the substantial computational burden imposed by powerful GPU servers, and the time-consuming manual prompt generation impede the extension of SAM to a broader spectrum of medical image segmentation applications. To address these challenges, in this work, we introduce a novel method, AutoSAM Adapter, designed specifically for 3D multi-organ CT-based segmentation. We employ parameter-efficient adaptation techniques in developing an automatic prompt learning paradigm to facilitate the transformation of the SAM model's capabilities to 3D medical image segmentation, eliminating the need for manually generated prompts. Furthermore, we effectively transfer the acquired knowledge of the AutoSAM Adapter to other lightweight models specifically tailored for 3D medical image analysis, achieving state-of-the-art (SOTA) performance on medical image segmentation tasks. Through extensive experimental evaluation, we demonstrate the AutoSAM Adapter as a critical foundation for effectively leveraging the emerging ability of foundation models in 2D natural image segmentation for 3D medical image segmentation.", "url": "https://arxiv.org/abs/2308.14936"}, {"metadata": {"arXiv": "2308.15063", "Date": "Tue, 29 Aug 2023 06:55:42 ", "Title": "Learning Cross-modality Information Bottleneck Representation for Heterogeneous Person Re-Identification", "Authors": ["Haichao Shi", "Mandi Luo", "Xiao-Yu Zhang", "Ran He"], "Categories": "cs.CV cs.AI"}, "abstract": "Visible-Infrared person re-identification (VI-ReID) is an important and challenging task in intelligent video surveillance. Existing methods mainly focus on learning a shared feature space to reduce the modality discrepancy between visible and infrared modalities, which still leave two problems underexplored: information redundancy and modality complementarity. To this end, properly eliminating the identity-irrelevant information as well as making up for the modality-specific information are critical and remains a challenging endeavor. To tackle the above problems, we present a novel mutual information and modality consensus network, namely CMInfoNet, to extract modality-invariant identity features with the most representative information and reduce the redundancies. The key insight of our method is to find an optimal representation to capture more identity-relevant information and compress the irrelevant parts by optimizing a mutual information bottleneck trade-off. Besides, we propose an automatically search strategy to find the most prominent parts that identify the pedestrians. To eliminate the cross- and intra-modality variations, we also devise a modality consensus module to align the visible and infrared modalities for task-specific guidance. Moreover, the global-local feature representations can also be acquired for key parts discrimination. Experimental results on four benchmarks, i.e., SYSU-MM01, RegDB, Occluded-DukeMTMC, Occluded-REID, Partial-REID and Partial\\_iLIDS dataset, have demonstrated the effectiveness of CMInfoNet.", "url": "https://arxiv.org/abs/2308.15063"}, {"metadata": {"arXiv": "2308.15137", "Date": "Tue, 29 Aug 2023 09:13:24 ", "Title": "Abdominal Multi-Organ Segmentation Based on Feature Pyramid Network and Spatial Recurrent Neural Network", "Authors": ["Yuhan Song", "Armagan Elibol", "Nak Young Chong"], "Categories": "cs.CV cs.AI", "Comments": ["IFAC World Congress 2023 paper"]}, "abstract": "As recent advances in AI are causing the decline of conventional diagnostic methods, the realization of end-to-end diagnosis is fast approaching. Ultrasound image segmentation is an important step in the diagnostic process. An accurate and robust segmentation model accelerates the process and reduces the burden of sonographers. In contrast to previous research, we take two inherent features of ultrasound images into consideration: (1) different organs and tissues vary in spatial sizes, (2) the anatomical structures inside human body form a relatively constant spatial relationship. Based on those two ideas, we propose a new image segmentation model combining Feature Pyramid Network (FPN) and Spatial Recurrent Neural Network (SRNN). We discuss why we use FPN to extract anatomical structures of different scales and how SRNN is implemented to extract the spatial context features in abdominal ultrasound images.", "url": "https://arxiv.org/abs/2308.15137"}, {"metadata": {"arXiv": "2308.15142", "Date": "Tue, 29 Aug 2023 09:21:48 ", "Title": "A Multimodal Visual Encoding Model Aided by Introducing Verbal Semantic Information", "Authors": ["Shuxiao Ma and Linyuan Wang and Bin Yan"], "Categories": "cs.CV cs.AI q-bio.NC"}, "abstract": "Biological research has revealed that the verbal semantic information in the brain cortex, as an additional source, participates in nonverbal semantic tasks, such as visual encoding. However, previous visual encoding models did not incorporate verbal semantic information, contradicting this biological finding. This paper proposes a multimodal visual information encoding network model based on stimulus images and associated textual information in response to this issue. Our visual information encoding network model takes stimulus images as input and leverages textual information generated by a text-image generation model as verbal semantic information. This approach injects new information into the visual encoding model. Subsequently, a Transformer network aligns image and text feature information, creating a multimodal feature space. A convolutional network then maps from this multimodal feature space to voxel space, constructing the multimodal visual information encoding network model. Experimental results demonstrate that the proposed multimodal visual information encoding network model outperforms previous models under the exact training cost. In voxel prediction of the left hemisphere of subject 1's brain, the performance improves by approximately 15.87%, while in the right hemisphere, the performance improves by about 4.6%. The multimodal visual encoding network model exhibits superior encoding performance. Additionally, ablation experiments indicate that our proposed model better simulates the brain's visual information processing.", "url": "https://arxiv.org/abs/2308.15142"}, {"metadata": {"arXiv": "2308.15170", "Date": "Tue, 29 Aug 2023 09:53:10 ", "Title": "A lightweight 3D dense facial landmark estimation model from position map data", "Authors": ["Shubhajit Basak", "Sathish Mangapuram", "Gabriel Costache", "Rachel McDonnell", "Michael Schukat"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "The Irish Machine Vision and Image Processing Conference(IMVIP)"]}, "abstract": "The incorporation of 3D data in facial analysis tasks has gained popularity in recent years. Though it provides a more accurate and detailed representation of the human face, accruing 3D face data is more complex and expensive than 2D face images. Either one has to rely on expensive 3D scanners or depth sensors which are prone to noise. An alternative option is the reconstruction of 3D faces from uncalibrated 2D images in an unsupervised way without any ground truth 3D data. However, such approaches are computationally expensive and the learned model size is not suitable for mobile or other edge device applications. Predicting dense 3D landmarks over the whole face can overcome this issue. As there is no public dataset available containing dense landmarks, we propose a pipeline to create a dense keypoint training dataset containing 520 key points across the whole face from an existing facial position map data. We train a lightweight MobileNet-based regressor model with the generated data. As we do not have access to any evaluation dataset with dense landmarks in it we evaluate our model against the 68 keypoint detection task. Experimental results show that our trained model outperforms many of the existing methods in spite of its lower model size and minimal computational cost. Also, the qualitative evaluation shows the efficiency of our trained models in extreme head pose angles as well as other facial variations and occlusions.", "url": "https://arxiv.org/abs/2308.15170"}, {"metadata": {"arXiv": "2308.15226", "Date": "Tue, 29 Aug 2023 11:29:43 ", "Title": "CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation", "Authors": ["Devaansh Gupta", "Siddhant Kharbanda", "Jiawei Zhou", "Wanhua Li", "Hanspeter Pfister", "Donglai Wei"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["15 pages", "9 figures", "to be published In Proceedings of International Conference of Computer Vision(ICCV)", "2023"]}, "abstract": "There has been a growing interest in developing multimodal machine translation (MMT) systems that enhance neural machine translation (NMT) with visual knowledge. This problem setup involves using images as auxiliary information during training, and more recently, eliminating their use during inference. Towards this end, previous works face a challenge in training powerful MMT models from scratch due to the scarcity of annotated multilingual vision-language data, especially for low-resource languages. Simultaneously, there has been an influx of multilingual pre-trained models for NMT and multimodal pre-trained models for vision-language tasks, primarily in English, which have shown exceptional generalisation ability. However, these are not directly applicable to MMT since they do not provide aligned multimodal multilingual features for generative tasks. To alleviate this issue, instead of designing complex modules for MMT, we propose CLIPTrans, which simply adapts the independently pre-trained multimodal M-CLIP and the multilingual mBART. In order to align their embedding spaces, mBART is conditioned on the M-CLIP features by a prefix sequence generated through a lightweight mapping network. We train this in a two-stage pipeline which warms up the model with image captioning before the actual translation task. Through experiments, we demonstrate the merits of this framework and consequently push forward the state-of-the-art across standard benchmarks by an average of +2.67 BLEU. The code can be found at www.github.com/devaansh100/CLIPTrans.", "url": "https://arxiv.org/abs/2308.15226"}, {"metadata": {"arXiv": "2308.15346", "Date": "Tue, 29 Aug 2023 14:41:40 ", "Title": "Enhancing Mobile Face Anti-Spoofing: A Robust Framework for Diverse Attack Types under Screen Flash", "Authors": ["Weihua Liu", "Chaochao Lin", "Yu Yan"], "Categories": "cs.CV cs.AI"}, "abstract": "Face anti-spoofing (FAS) is crucial for securing face recognition systems. However, existing FAS methods with handcrafted binary or pixel-wise labels have limitations due to diverse presentation attacks (PAs). In this paper, we propose an attack type robust face anti-spoofing framework under light flash, called ATR-FAS. Due to imaging differences caused by various attack types, traditional FAS methods based on single binary classification network may result in excessive intra-class distance of spoof faces, leading to a challenge of decision boundary learning. Therefore, we employed multiple networks to reconstruct multi-frame depth maps as auxiliary supervision, and each network experts in one type of attack. A dual gate module (DGM) consisting of a type gate and a frame-attention gate is introduced, which perform attack type recognition and multi-frame attention generation, respectively. The outputs of DGM are utilized as weight to mix the result of multiple expert networks. The multi-experts mixture enables ATR-FAS to generate spoof-differentiated depth maps, and stably detects spoof faces without being affected by different types of PAs. Moreover, we design a differential normalization procedure to convert original flash frames into differential frames. This simple but effective processing enhances the details in flash frames, aiding in the generation of depth maps. To verify the effectiveness of our framework, we collected a large-scale dataset containing 12,660 live and spoof videos with diverse PAs under dynamic flash from the smartphone screen. Extensive experiments illustrate that the proposed ATR-FAS significantly outperforms existing state-of-the-art methods. The code and dataset will be available at https://github.com/Chaochao-Lin/ATR-FAS.", "url": "https://arxiv.org/abs/2308.15346"}, {"metadata": {"arXiv": "2308.15397", "Date": "Tue, 29 Aug 2023 15:56:38 ", "Title": "Color Aesthetics: Fuzzy based User-driven Method for Harmony and Preference Prediction", "Authors": ["Pakizar Shamoi", "Atsushi Inoue", "Hiroharu Kawanaka"], "Categories": "cs.CV cs.AI", "Comments": ["It was accepted as a short paper. IFSA-SCIS 2017 Conference held in Otsu", "Japan"]}, "abstract": "Color is the most important intrinsic sensory feature that has a powerful impact on product sales. Color is even responsible for raising the aesthetic senses in our brains. Account for individual differences is crucial in color aesthetics. It requires user-driven mechanisms for various e-commerce applications. We propose a method for quantitative evaluation of all types of perceptual responses to color(s): distinct color preference, color harmony, and color combination preference. Preference for color schemes can be predicted by combining preferences for the basic colors and ratings of color harmony. Harmonious pallets are extracted from big data set using comparison algorithms based on fuzzy similarity and grouping. The proposed model results in useful predictions of harmony and preference of multicolored images. For example, in the context of apparel coordination, it allows predicting a preference for a look based on clothing colors. Our approach differs from standard aesthetic models, since in accounts for a personal variation. In addition, it can process not only lower-order color pairs, but also groups of several colors.", "url": "https://arxiv.org/abs/2308.15397"}, {"metadata": {"arXiv": "2308.15427", "Date": "Tue, 29 Aug 2023 16:33:16 ", "Title": "Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction", "Authors": ["Wenjie Gao", "Jiawei Fu", "Haodong Jing", "and Nanning Zheng"], "Categories": "cs.CV cs.AI"}, "abstract": "High-Definition (HD) maps play a crucial role in autonomous driving systems. Recent methods have attempted to construct HD maps in real-time based on information obtained from vehicle onboard sensors. However, the performance of these methods is significantly susceptible to the environment surrounding the vehicle due to the inherent limitation of onboard sensors, such as weak capacity for long-range detection. In this study, we demonstrate that supplementing onboard sensors with satellite maps can enhance the performance of HD map construction methods, leveraging the broad coverage capability of satellite maps. For the purpose of further research, we release the satellite map tiles as a complementary dataset of nuScenes dataset. Meanwhile, we propose a hierarchical fusion module that enables better fusion of satellite maps information with existing methods. Specifically, we design an attention mask based on segmentation and distance, applying the cross-attention mechanism to fuse onboard Bird's Eye View (BEV) features and satellite features in feature-level fusion. An alignment module is introduced before concatenation in BEV-level fusion to mitigate the impact of misalignment between the two features. The experimental results on the augmented nuScenes dataset showcase the seamless integration of our module into three existing HD map construction methods. It notably enhances their performance in both HD map semantic segmentation and instance detection tasks.", "url": "https://arxiv.org/abs/2308.15427"}, {"metadata": {"arXiv": "2308.15469", "Date": "Tue, 29 Aug 2023 17:48:33 ", "Title": "Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction", "Authors": ["Weichen Huang"], "Categories": "cs.CV cs.AI"}, "abstract": "Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, almost a 10% increase from previous state of the art.", "url": "https://arxiv.org/abs/2308.15469"}, {"metadata": {"arXiv": "2308.15474", "Date": "Tue, 29 Aug 2023 17:52:10 ", "Title": "A General-Purpose Self-Supervised Model for Computational Pathology", "Authors": ["Richard J. Chen", "Tong Ding", "Ming Y. Lu", "Drew F. K. Williamson", "Guillaume Jaume", "Bowen Chen", "Andrew Zhang", "Daniel Shao", "Andrew H. Song", "Muhammad Shaban", "Mane Williams", "Anurag Vaidya", "Sharifa Sahai", "Lukas Oldenburg", "Luca L. Weishaupt", "Judy J. Wang", "Walt Williams", "Long Phi Le", "Georg Gerber", "Faisal Mahmood"], "Categories": "cs.CV cs.AI q-bio.TO"}, "abstract": "Tissue phenotyping is a fundamental computational pathology (CPath) task in learning objective characterizations of histopathologic biomarkers in anatomic pathology. However, whole-slide imaging (WSI) poses a complex computer vision problem in which the large-scale image resolutions of WSIs and the enormous diversity of morphological phenotypes preclude large-scale data annotation. Current efforts have proposed using pretrained image encoders with either transfer learning from natural image datasets or self-supervised pretraining on publicly-available histopathology datasets, but have not been extensively developed and evaluated across diverse tissue types at scale. We introduce UNI, a general-purpose self-supervised model for pathology, pretrained using over 100 million tissue patches from over 100,000 diagnostic haematoxylin and eosin-stained WSIs across 20 major tissue types, and evaluated on 33 representative CPath clinical tasks in CPath of varying diagnostic difficulties. In addition to outperforming previous state-of-the-art models, we demonstrate new modeling capabilities in CPath such as resolution-agnostic tissue classification, slide classification using few-shot class prototypes, and disease subtyping generalization in classifying up to 108 cancer types in the OncoTree code classification system. UNI advances unsupervised representation learning at scale in CPath in terms of both pretraining data and downstream evaluation, enabling data-efficient AI models that can generalize and transfer to a gamut of diagnostically-challenging tasks and clinical workflows in anatomic pathology.", "url": "https://arxiv.org/abs/2308.15474"}, {"metadata": {"arXiv": "2308.14843", "Date": "Mon, 28 Aug 2023 19:03:46 ", "Title": "Robust Activity Recognition for Adaptive Worker-Robot Interaction using Transfer Learning", "Authors": ["Farid Shahnavaz", "Riley Tavassoli", "and Reza Akhavian"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["2023 ASCE International Conference on Computing in Civil Engineering (I3CE)"]}, "abstract": "Human activity recognition (HAR) using machine learning has shown tremendous promise in detecting construction workers' activities. HAR has many applications in human-robot interaction research to enable robots' understanding of human counterparts' activities. However, many existing HAR approaches lack robustness, generalizability, and adaptability. This paper proposes a transfer learning methodology for activity recognition of construction workers that requires orders of magnitude less data and compute time for comparable or better classification accuracy. The developed algorithm transfers features from a model pre-trained by the original authors and fine-tunes them for the downstream task of activity recognition in construction. The model was pre-trained on Kinetics-400, a large-scale video-based human activity recognition dataset with 400 distinct classes. The model was fine-tuned and tested using videos captured from manual material handling (MMH) activities found on YouTube. Results indicate that the fine-tuned model can recognize distinct MMH tasks in a robust and adaptive manner which is crucial for the widespread deployment of collaborative robots in construction.", "url": "https://arxiv.org/abs/2308.14843"}, {"metadata": {"arXiv": "2308.14972", "Date": "Tue, 29 Aug 2023 01:54:49 ", "Title": "LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks", "Authors": ["Haokun Liu", "Yaonan Zhu", "Kenji Kato", "Izumi Kondo", "Tadayoshi Aoyama", "and Yasuhisa Hasegawa"], "Categories": "cs.RO cs.AI", "Comments": ["IEEE MHS 2023"]}, "abstract": "This paper presents a novel approach to enhance autonomous robotic manipulation using the Large Language Model (LLM) for logical inference, converting high-level language commands into sequences of executable motion functions. The proposed system combines the advantage of LLM with YOLO-based environmental perception to enable robots to autonomously make reasonable decisions and task planning based on the given commands. Additionally, to address the potential inaccuracies or illogical actions arising from LLM, a combination of teleoperation and Dynamic Movement Primitives (DMP) is employed for action correction. This integration aims to improve the practicality and generalizability of the LLM-based human-robot collaboration system.", "url": "https://arxiv.org/abs/2308.14972"}, {"metadata": {"arXiv": "2308.15039", "Date": "Tue, 29 Aug 2023 05:48:28 ", "Title": "R^3: On-device Real-Time Deep Reinforcement Learning for Autonomous Robotics", "Authors": ["Zexin Li", "Aritra Samanta", "Yufei Li", "Andrea Soltoggio", "Hyoseung Kim and Cong Liu"], "Categories": "cs.RO cs.AI cs.SY eess.SY", "Comments": ["Accepted by RTSS 2023"]}, "abstract": "Autonomous robotic systems, like autonomous vehicles and robotic search and rescue, require efficient on-device training for continuous adaptation of Deep Reinforcement Learning (DRL) models in dynamic environments. This research is fundamentally motivated by the need to understand and address the challenges of on-device real-time DRL, which involves balancing timing and algorithm performance under memory constraints, as exposed through our extensive empirical studies. This intricate balance requires co-optimizing two pivotal parameters of DRL training -- batch size and replay buffer size. Configuring these parameters significantly affects timing and algorithm performance, while both (unfortunately) require substantial memory allocation to achieve near-optimal performance. This paper presents R^3, a holistic solution for managing timing, memory, and algorithm performance in on-device real-time DRL training. R^3 employs (i) a deadline-driven feedback loop with dynamic batch sizing for optimizing timing, (ii) efficient memory management to reduce memory footprint and allow larger replay buffer sizes, and (iii) a runtime coordinator guided by heuristic analysis and a runtime profiler for dynamically adjusting memory resource reservations. These components collaboratively tackle the trade-offs in on-device DRL training, improving timing and algorithm performance while minimizing the risk of out-of-memory (OOM) errors. We implemented and evaluated R^3 extensively across various DRL frameworks and benchmarks on three hardware platforms commonly adopted by autonomous robotic systems. Additionally, we integrate R^3 with a popular realistic autonomous car simulator to demonstrate its real-world applicability. Evaluation results show that R^3 achieves efficacy across diverse platforms, ensuring consistent latency performance and timing predictability with minimal overhead.", "url": "https://arxiv.org/abs/2308.15039"}, {"metadata": {"arXiv": "2308.15143", "Date": "Tue, 29 Aug 2023 09:22:12 ", "Title": "Lifelike Agility and Play on Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models", "Authors": ["Lei Han", "Qingxu Zhu", "Jiapeng Sheng", "Chong Zhang", "Tingguang Li", "Yizheng Zhang", "He Zhang", "Yuzhen Liu", "Cheng Zhou", "Rui Zhao", "Jie Li", "Yufeng Zhang", "Rui Wang", "Wanchao Chi", "Xiong Li", "Yonghui Zhu", "Lingzhu Xiang", "Xiao Teng", "Zhengyou Zhang"], "Categories": "cs.RO cs.AI"}, "abstract": "Summarizing knowledge from animals and human beings inspires robotic innovations. In this work, we propose a framework for driving legged robots act like real animals with lifelike agility and strategy in complex environments. Inspired by large pre-trained models witnessed with impressive performance in language and image understanding, we introduce the power of advanced deep generative models to produce motor control signals stimulating legged robots to act like real animals. Unlike conventional controllers and end-to-end RL methods that are task-specific, we propose to pre-train generative models over animal motion datasets to preserve expressive knowledge of animal behavior. The pre-trained model holds sufficient primitive-level knowledge yet is environment-agnostic. It is then reused for a successive stage of learning to align with the environments by traversing a number of challenging obstacles that are rarely considered in previous approaches, including creeping through narrow spaces, jumping over hurdles, freerunning over scattered blocks, etc. Finally, a task-specific controller is trained to solve complex downstream tasks by reusing the knowledge from previous stages. Enriching the knowledge regarding each stage does not affect the usage of other levels of knowledge. This flexible framework offers the possibility of continual knowledge accumulation at different levels. We successfully apply the trained multi-level controllers to the MAX robot, a quadrupedal robot developed in-house, to mimic animals, traverse complex obstacles, and play in a designed challenging multi-agent Chase Tag Game, where lifelike agility and strategy emerge on the robots. The present research pushes the frontier of robot control with new insights on reusing multi-level pre-trained knowledge and solving highly complex downstream tasks in the real world.", "url": "https://arxiv.org/abs/2308.15143"}, {"metadata": {"arXiv": "2308.15357", "Date": "Tue, 29 Aug 2023 14:53:16 ", "Title": "Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection", "Authors": ["Patrick Palmer", "Martin Krueger", "Richard Altendorfer", "Torsten Bertram"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["Published at: AmE 2023 - Automotive meets Electronics; 14. GMM Symposium (https://ieeexplore.ieee.org/document/10227711)"]}, "abstract": "New 3+1D high-resolution radar sensors are gaining importance for 3D object detection in the automotive domain due to their relative affordability and improved detection compared to classic low-resolution radar sensors. One limitation of high-resolution radar sensors, compared to lidar sensors, is the sparsity of the generated point cloud. This sparsity could be partially overcome by accumulating radar point clouds of subsequent time steps. This contribution analyzes limitations of accumulating radar point clouds on the View-of-Delft dataset. By employing different ego-motion estimation approaches, the dataset's inherent constraints, and possible solutions are analyzed. Additionally, a learning-based instance motion estimation approach is deployed to investigate the influence of dynamic motion on the accumulated point cloud for object detection. Experiments document an improved object detection performance by applying an ego-motion estimation and dynamic motion correction approach.", "url": "https://arxiv.org/abs/2308.15357"}, {"metadata": {"arXiv": "2308.15368", "Date": "Tue, 29 Aug 2023 15:04:08 ", "Title": "RED: A Systematic Real-Time Scheduling Approach for Robotic Environmental Dynamics", "Authors": ["Zexin Li", "Tao Ren", "Xiaoxi He and Cong Liu"], "Categories": "cs.RO cs.AI cs.SY eess.SY", "Comments": ["Accepted by RTSS 2023"]}, "abstract": "Intelligent robots are designed to effectively navigate dynamic and unpredictable environments laden with moving mechanical elements and objects. Such environment-induced dynamics, including moving obstacles, can readily alter the computational demand (e.g., the creation of new tasks) and the structure of workloads (e.g., precedence constraints among tasks) during runtime, thereby adversely affecting overall system performance. This challenge is amplified when multi-task inference is expected on robots operating under stringent resource and real-time constraints. To address such a challenge, we introduce RED, a systematic real-time scheduling approach designed to support multi-task deep neural network workloads in resource-limited robotic systems. It is designed to adaptively manage the Robotic Environmental Dynamics (RED) while adhering to real-time constraints. At the core of RED lies a deadline-based scheduler that employs an intermediate deadline assignment policy, effectively managing to change workloads and asynchronous inference prompted by complex, unpredictable environments. This scheduling framework also facilitates the flexible deployment of MIMONet (multi-input multi-output neural networks), which are commonly utilized in multi-tasking robotic systems to circumvent memory bottlenecks. Building on this scheduling framework, RED recognizes and leverages a unique characteristic of MIMONet: its weight-shared architecture. To further accommodate and exploit this feature, RED devises a novel and effective workload refinement and reconstruction process. This process ensures the scheduling framework's compatibility with MIMONet and maximizes efficiency.", "url": "https://arxiv.org/abs/2308.15368"}, {"metadata": {"arXiv": "2308.14815", "Date": "Mon, 28 Aug 2023 18:06:24 ", "Title": "Distributionally Robust Statistical Verification with Imprecise Neural Networks", "Authors": ["Souradeep Dutta", "Michele Caprio", "Vivian Lin", "Matthew Cleaveland", "Kuk Jin Jang", "Ivan Ruchkin", "Oleg Sokolsky", "Insup Lee"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "A particularly challenging problem in AI safety is providing guarantees on the behavior of high-dimensional autonomous systems. Verification approaches centered around reachability analysis fail to scale, and purely statistical approaches are constrained by the distributional assumptions about the sampling process. Instead, we pose a distributionally robust version of the statistical verification problem for black-box systems, where our performance guarantees hold over a large family of distributions. This paper proposes a novel approach based on a combination of active learning, uncertainty quantification, and neural network verification. A central piece of our approach is an ensemble technique called Imprecise Neural Networks, which provides the uncertainty to guide active learning. The active learning uses an exhaustive neural-network verification tool Sherlock to collect samples. An evaluation on multiple physical simulators in the openAI gym Mujoco environments with reinforcement-learned controllers demonstrates that our approach can provide useful and scalable guarantees for high-dimensional systems.", "url": "https://arxiv.org/abs/2308.14815"}, {"metadata": {"arXiv": "2308.14983", "Date": "Tue, 29 Aug 2023 02:23:58 ", "Title": "Constructive Incremental Learning for Fault Diagnosis of Rolling Bearings with Ensemble Domain Adaptation", "Authors": ["Jiang Liu and Wei Dai"], "Categories": "cs.AI cs.LG eess.SP"}, "abstract": "Given the prevalence of rolling bearing fault diagnosis as a practical issue across various working conditions, the limited availability of samples compounds the challenge. Additionally, the complexity of the external environment and the structure of rolling bearings often manifests faults characterized by randomness and fuzziness, hindering the effective extraction of fault characteristics and restricting the accuracy of fault diagnosis. To overcome these problems, this paper presents a novel approach termed constructive Incremental learning-based ensemble domain adaptation (CIL-EDA) approach. Specifically, it is implemented on stochastic configuration networks (SCN) to constructively improve its adaptive performance in multi-domains. Concretely, a cloud feature extraction method is employed in conjunction with wavelet packet decomposition (WPD) to capture the uncertainty of fault information from multiple resolution aspects. Subsequently, constructive Incremental learning-based domain adaptation (CIL-DA) is firstly developed to enhance the cross-domain learning capability of each hidden node through domain matching and construct a robust fault classifier by leveraging limited labeled data from both target and source domains. Finally, fault diagnosis results are obtained by a majority voting of CIL-EDA which integrates CIL-DA and parallel ensemble learning. Experimental results demonstrate that our CIL-DA outperforms several domain adaptation methods and CIL-EDA consistently outperforms state-of-art fault diagnosis methods in few-shot scenarios.", "url": "https://arxiv.org/abs/2308.14983"}, {"metadata": {"arXiv": "2308.15020", "Date": "Tue, 29 Aug 2023 04:50:07 ", "Title": "Massively Parallel Continuous Local Search for Hybrid SAT Solving on GPUs", "Authors": ["Yunuo Cen", "Zhiwei Zhang", "Xuanyao Fong"], "Categories": "cs.AI cs.DC cs.IT cs.LG cs.LO math.IT"}, "abstract": "Although state-of-the-art (SOTA) SAT solvers based on conflict-driven clause learning (CDCL) have achieved remarkable engineering success, their sequential nature limits the parallelism that may be extracted for acceleration on platforms such as the graphics processing unit (GPU). In this work, we propose FastFourierSAT, a highly parallel hybrid SAT solver based on gradient-driven continuous local search (CLS). This is realized by a novel parallel algorithm inspired by the Fast Fourier Transform (FFT)-based convolution for computing the elementary symmetric polynomials (ESPs), which is the major computational task in previous CLS methods. The complexity of our algorithm matches the best previous result. Furthermore, the substantial parallelism inherent in our algorithm can leverage the GPU for acceleration, demonstrating significant improvement over the previous CLS approaches. We also propose to incorporate the restart heuristics in CLS to improve search efficiency. We compare our approach with the SOTA parallel SAT solvers on several benchmarks. Our results show that FastFourierSAT computes the gradient 100+ times faster than previous prototypes implemented on CPU. Moreover, FastFourierSAT solves most instances and demonstrates promising performance on larger-size instances.", "url": "https://arxiv.org/abs/2308.15020"}, {"metadata": {"arXiv": "2308.15194", "Date": "Tue, 29 Aug 2023 10:21:50 ", "Title": "Ensemble of Counterfactual Explainers", "Authors": ["Riccardo Guidotti", "Salvatore Ruggieri"], "Categories": "cs.AI cs.LG", "DOI": "10.1007/978-3-030-88942-5_28"}, "abstract": "In eXplainable Artificial Intelligence (XAI), several counterfactual explainers have been proposed, each focusing on some desirable properties of counterfactual instances: minimality, actionability, stability, diversity, plausibility, discriminative power. We propose an ensemble of counterfactual explainers that boosts weak explainers, which provide only a subset of such properties, to a powerful method covering all of them. The ensemble runs weak explainers on a sample of instances and of features, and it combines their results by exploiting a diversity-driven selection function. The method is model-agnostic and, through a wrapping approach based on autoencoders, it is also data-agnostic.", "url": "https://arxiv.org/abs/2308.15194"}, {"metadata": {"arXiv": "2308.15394", "Date": "Tue, 29 Aug 2023 15:48:49 ", "Title": "Decentralized Multi-agent Reinforcement Learning based State-of-Charge Balancing Strategy for Distributed Energy Storage System", "Authors": ["Zheng Xiong", "Biao Luo", "Bing-Chuan Wang", "Xiaodong Xu", "Xiaodong Liu", "and Tingwen Huang"], "Categories": "cs.AI cs.LG cs.SY eess.SY"}, "abstract": "This paper develops a Decentralized Multi-Agent Reinforcement Learning (Dec-MARL) method to solve the SoC balancing problem in the distributed energy storage system (DESS). First, the SoC balancing problem is formulated into a finite Markov decision process with action constraints derived from demand balance, which can be solved by Dec-MARL. Specifically, the first-order average consensus algorithm is utilized to expand the observations of the DESS state in a fully-decentralized way, and the initial actions (i.e., output power) are decided by the agents (i.e., energy storage units) according to these observations. In order to get the final actions in the allowable range, a counterfactual demand balance algorithm is proposed to balance the total demand and the initial actions. Next, the agents execute the final actions and get local rewards from the environment, and the DESS steps into the next state. Finally, through the first-order average consensus algorithm, the agents get the average reward and the expended observation of the next state for later training. By the above procedure, Dec-MARL reveals outstanding performance in a fully-decentralized system without any expert experience or constructing any complicated model. Besides, it is flexible and can be extended to other decentralized multi-agent systems straightforwardly. Extensive simulations have validated the effectiveness and efficiency of Dec-MARL.", "url": "https://arxiv.org/abs/2308.15394"}, {"metadata": {"arXiv": "2308.14893", "Date": "Mon, 28 Aug 2023 20:30:10 ", "Title": "When hard negative sampling meets supervised contrastive learning", "Authors": ["Zijun Long", "George Killick", "Richard McCreadie", "Gerardo Aragon Camarasa", "Zaiqiao Meng"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "State-of-the-art image models predominantly follow a two-stage strategy: pre-training on large datasets and fine-tuning with cross-entropy loss. Many studies have shown that using cross-entropy can result in sub-optimal generalisation and stability. While the supervised contrastive loss addresses some limitations of cross-entropy loss by focusing on intra-class similarities and inter-class differences, it neglects the importance of hard negative mining. We propose that models will benefit from performance improvement by weighting negative samples based on their dissimilarity to positive counterparts. In this paper, we introduce a new supervised contrastive learning objective, SCHaNe, which incorporates hard negative sampling during the fine-tuning phase. Without requiring specialized architectures, additional data, or extra computational resources, experimental results indicate that SCHaNe outperforms the strong baseline BEiT-3 in Top-1 accuracy across various benchmarks, with significant gains of up to $3.32\\%$ in few-shot learning settings and $3.41\\%$ in full dataset fine-tuning. Importantly, our proposed objective sets a new state-of-the-art for base models on ImageNet-1k, achieving an 86.14\\% accuracy. Furthermore, we demonstrate that the proposed objective yields better embeddings and explains the improved effectiveness observed in our experiments.", "url": "https://arxiv.org/abs/2308.14893"}, {"metadata": {"arXiv": "2308.15050", "Date": "Tue, 29 Aug 2023 06:20:36 ", "Title": "iBARLE: imBalance-Aware Room Layout Estimation", "Authors": ["Taotao Jing", "Lichen Wang", "Naji Khosravan", "Zhiqiang Wan", "Zachary Bessinger", "Zhengming Ding", "Sing Bing Kang"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Room layout estimation predicts layouts from a single panorama. It requires datasets with large-scale and diverse room shapes to train the models. However, there are significant imbalances in real-world datasets including the dimensions of layout complexity, camera locations, and variation in scene appearance. These issues considerably influence the model training performance. In this work, we propose the imBalance-Aware Room Layout Estimation (iBARLE) framework to address these issues. iBARLE consists of (1) Appearance Variation Generation (AVG) module, which promotes visual appearance domain generalization, (2) Complex Structure Mix-up (CSMix) module, which enhances generalizability w.r.t. room structure, and (3) a gradient-based layout objective function, which allows more effective accounting for occlusions in complex layouts. All modules are jointly trained and help each other to achieve the best performance. Experiments and ablation studies based on ZInD~\\cite{cruz2021zillow} dataset illustrate that iBARLE has state-of-the-art performance compared with other layout estimation baselines.", "url": "https://arxiv.org/abs/2308.15050"}, {"metadata": {"arXiv": "2308.15367", "Date": "Tue, 29 Aug 2023 15:03:05 ", "Title": "Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation", "Authors": ["Fu-En Yang", "Chien-Yi Wang", "Yu-Chiang Frank Wang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by ICCV 2023"]}, "abstract": "Federated learning (FL) emerges as a decentralized learning framework which trains models from multiple distributed clients without sharing their data to preserve privacy. Recently, large-scale pre-trained models (e.g., Vision Transformer) have shown a strong capability of deriving robust representations. However, the data heterogeneity among clients, the limited computation resources, and the communication bandwidth restrict the deployment of large-scale models in FL frameworks. To leverage robust representations from large-scale models while enabling efficient model personalization for heterogeneous clients, we propose a novel personalized FL framework of client-specific Prompt Generation (pFedPG), which learns to deploy a personalized prompt generator at the server for producing client-specific visual prompts that efficiently adapts frozen backbones to local data distributions. Our proposed framework jointly optimizes the stages of personalized prompt adaptation locally and personalized prompt generation globally. The former aims to train visual prompts that adapt foundation models to each client, while the latter observes local optimization directions to generate personalized prompts for all clients. Through extensive experiments on benchmark datasets, we show that our pFedPG is favorable against state-of-the-art personalized FL methods under various types of data heterogeneity, allowing computation and communication efficient model personalization.", "url": "https://arxiv.org/abs/2308.15367"}, {"metadata": {"arXiv": "2308.14781", "Date": "Mon, 28 Aug 2023 15:50:34 ", "Title": "Conflict-Aware Active Automata Learning", "Authors": ["Tiago Ferreira", "L\\'eo Henry", "Raquel Fernandes da Silva and Alexandra Silva"], "Categories": "cs.LG cs.AI cs.FL", "Comments": ["37 pages", "11 figures", "GandALF 2023"]}, "abstract": "Active automata learning algorithms cannot easily handle \\emph{conflict} in the observation data (different outputs observed for the same inputs). This inherent inability to recover after a conflict impairs their effective applicability in scenarios where noise is present or the system under learning is mutating. We propose the Conflict-Aware Active Automata Learning (C3AL) framework to enable handling conflicting information during the learning process. The core idea is to consider the so-called observation tree as a first-class citizen in the learning process. Though this idea is explored in recent work, we take it to its full effect by enabling its use with any existing learner and minimizing the number of tests performed on the system under learning, specially in the face of conflicts. We evaluate C3AL in a large set of benchmarks, covering over 30 different realistic targets, and over 18,000 different scenarios. The results of the evaluation show that C3AL is a suitable alternative framework for closed-box learning that can better handle noise and mutations.targets, and over 18,000 different scenarios. The results of the evaluation show that C3AL is a suitable alternative framework for closed-box learning that can better handle noise and mutations.", "url": "https://arxiv.org/abs/2308.14781"}, {"metadata": {"arXiv": "2308.14784", "Date": "Mon, 28 Aug 2023 16:35:43 ", "Title": "Generating tabular datasets under differential privacy", "Authors": ["Gianluca Truda"], "Categories": "cs.LG cs.AI cs.CR cs.DB", "ACM-class": "I.2.6"}, "abstract": "Machine Learning (ML) is accelerating progress across fields and industries, but relies on accessible and high-quality training data. Some of the most important datasets are found in biomedical and financial domains in the form of spreadsheets and relational databases. But this tabular data is often sensitive in nature. Synthetic data generation offers the potential to unlock sensitive data, but generative models tend to memorise and regurgitate training data, which undermines the privacy goal. To remedy this, researchers have incorporated the mathematical framework of Differential Privacy (DP) into the training process of deep neural networks. But this creates a trade-off between the quality and privacy of the resulting data. Generative Adversarial Networks (GANs) are the dominant paradigm for synthesising tabular data under DP, but suffer from unstable adversarial training and mode collapse, which are exacerbated by the privacy constraints and challenging tabular data modality. This work optimises the quality-privacy trade-off of generative models, producing higher quality tabular datasets with the same privacy guarantees. We implement novel end-to-end models that leverage attention mechanisms to learn reversible tabular representations. We also introduce TableDiffusion, the first differentially-private diffusion model for tabular data synthesis. Our experiments show that TableDiffusion produces higher-fidelity synthetic datasets, avoids the mode collapse problem, and achieves state-of-the-art performance on privatised tabular data synthesis. By implementing TableDiffusion to predict the added noise, we enabled it to bypass the challenges of reconstructing mixed-type tabular data. Overall, the diffusion paradigm proves vastly more data and privacy efficient than the adversarial paradigm, due to augmented re-use of each data batch and a smoother iterative training process.", "url": "https://arxiv.org/abs/2308.14784"}, {"metadata": {"arXiv": "2308.14861", "Date": "Mon, 28 Aug 2023 19:31:53 ", "Title": "Evaluation of Key Spatiotemporal Learners for Print Track Anomaly Classification Using Melt Pool Image Streams", "Authors": ["Lynn Cherif", "Mutahar Safdar", "Guy Lamouche", "Priti Wanjara", "Padma Paul", "Gentry Wood", "Max Zimmermann", "Florian Hannesen", "Yaoyao Fiona Zhao"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["This work has been accepted to IFAC for publication under a Creative Commons Licence CC-BY-NC-ND"], "Report-no": "2577"}, "abstract": "Recent applications of machine learning in metal additive manufacturing (MAM) have demonstrated significant potential in addressing critical barriers to the widespread adoption of MAM technology. Recent research in this field emphasizes the importance of utilizing melt pool signatures for real-time defect prediction. While high-quality melt pool image data holds the promise of enabling precise predictions, there has been limited exploration into the utilization of cutting-edge spatiotemporal models that can harness the inherent transient and sequential characteristics of the additive manufacturing process. This research introduces and puts into practice some of the leading deep spatiotemporal learning models that can be adapted for the classification of melt pool image streams originating from various materials, systems, and applications. Specifically, it investigates two-stream networks comprising spatial and temporal streams, a recurrent spatial network, and a factorized 3D convolutional neural network. The capacity of these models to generalize when exposed to perturbations in melt pool image data is examined using data perturbation techniques grounded in real-world process scenarios. The implemented architectures demonstrate the ability to capture the spatiotemporal features of melt pool image sequences. However, among these models, only the Kinetics400 pre-trained SlowFast network, categorized as a two-stream network, exhibits robust generalization capabilities in the presence of data perturbations.", "url": "https://arxiv.org/abs/2308.14861"}, {"metadata": {"arXiv": "2308.14864", "Date": "Mon, 28 Aug 2023 19:35:43 ", "Title": "NAS-X: Neural Adaptive Smoothing via Twisting", "Authors": ["Dieterich Lawson", "Michael Li", "Scott Linderman"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning and inference in sequential latent variable models based on reweighted wake-sleep (RWS). NAS-X works with both discrete and continuous latent variables, and leverages smoothing SMC to fit a broader range of models than traditional RWS methods. We test NAS-X on discrete and continuous tasks and find that it substantially outperforms previous variational and RWS-based methods in inference and parameter recovery.", "url": "https://arxiv.org/abs/2308.14864"}, {"metadata": {"arXiv": "2308.14897", "Date": "Mon, 28 Aug 2023 20:46:07 ", "Title": "Statistically Efficient Variance Reduction with Double Policy Estimation for Off-Policy Evaluation in Sequence-Modeled Reinforcement Learning", "Authors": ["Hanhan Zhou", "Tian Lan", "Vaneet Aggarwal"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "Offline reinforcement learning aims to utilize datasets of previously gathered environment-action interaction records to learn a policy without access to the real environment. Recent work has shown that offline reinforcement learning can be formulated as a sequence modeling problem and solved via supervised learning with approaches such as decision transformer. While these sequence-based methods achieve competitive results over return-to-go methods, especially on tasks that require longer episodes or with scarce rewards, importance sampling is not considered to correct the policy bias when dealing with off-policy data, mainly due to the absence of behavior policy and the use of deterministic evaluation policies. To this end, we propose DPE: an RL algorithm that blends offline sequence modeling and offline reinforcement learning with Double Policy Estimation (DPE) in a unified framework with statistically proven properties on variance reduction. We validate our method in multiple tasks of OpenAI Gym with D4RL benchmarks. Our method brings a performance improvements on selected methods which outperforms SOTA baselines in several tasks, demonstrating the advantages of enabling double policy estimation for sequence-modeled reinforcement learning.", "url": "https://arxiv.org/abs/2308.14897"}, {"metadata": {"arXiv": "2308.14919", "Date": "Mon, 28 Aug 2023 22:29:16 ", "Title": "On Reward Structures of Markov Decision Processes", "Authors": ["Falcon Z. Dai"], "Categories": "cs.LG cs.AI", "Comments": ["This PhD thesis draws heavily from arXiv:1907.02114 and arXiv:2002.06299"]}, "abstract": "A Markov decision process can be parameterized by a transition kernel and a reward function. Both play essential roles in the study of reinforcement learning as evidenced by their presence in the Bellman equations. In our inquiry of various kinds of ``costs'' associated with reinforcement learning inspired by the demands in robotic applications, rewards are central to understanding the structure of a Markov decision process and reward-centric notions can elucidate important concepts in reinforcement learning. Specifically, we studied the sample complexity of policy evaluation and developed a novel estimator with an instance-specific error bound of $\\tilde{O}(\\sqrt{\\frac{\\tau_s}{n}})$ for estimating a single state value. Under the online regret minimization setting, we refined the transition-based MDP constant, diameter, into a reward-based constant, maximum expected hitting cost, and with it, provided a theoretical explanation for how a well-known technique, potential-based reward shaping, could accelerate learning with expert knowledge. In an attempt to study safe reinforcement learning, we modeled hazardous environments with irrecoverability and proposed a quantitative notion of safe learning via reset efficiency. In this setting, we modified a classic algorithm to account for resets achieving promising preliminary numerical results. Lastly, for MDPs with multiple reward functions, we developed a planning algorithm that computationally efficiently finds Pareto optimal stochastic policies.", "url": "https://arxiv.org/abs/2308.14919"}, {"metadata": {"arXiv": "2308.14924", "Date": "Mon, 28 Aug 2023 22:42:51 ", "Title": "Optimal Economic Gas Turbine Dispatch with Deep Reinforcement Learning", "Authors": ["Manuel Sage", "Martin Staniszewski", "Yaoyao Fiona Zhao"], "Categories": "cs.LG cs.AI cs.SY eess.SY", "Comments": ["This work has been accepted to IFAC for publication under a Creative Commons Licence CC-BY-NC-ND"]}, "abstract": "Dispatching strategies for gas turbines (GTs) are changing in modern electricity grids. A growing incorporation of intermittent renewable energy requires GTs to operate more but shorter cycles and more frequently on partial loads. Deep reinforcement learning (DRL) has recently emerged as a tool that can cope with this development and dispatch GTs economically. The key advantages of DRL are a model-free optimization and the ability to handle uncertainties, such as those introduced by varying loads or renewable energy production. In this study, three popular DRL algorithms are implemented for an economic GT dispatch problem on a case study in Alberta, Canada. We highlight the benefits of DRL by incorporating an existing thermodynamic software provided by Siemens Energy into the environment model and by simulating uncertainty via varying electricity prices, loads, and ambient conditions. Among the tested algorithms and baseline methods, Deep Q-Networks (DQN) obtained the highest rewards while Proximal Policy Optimization (PPO) was the most sample efficient. We further propose and implement a method to assign GT operation and maintenance cost dynamically based on operating hours and cycles. Compared to existing methods, our approach better approximates the true cost of modern GT dispatch and hence leads to more realistic policies.", "url": "https://arxiv.org/abs/2308.14924"}, {"metadata": {"arXiv": "2308.14991", "Date": "Tue, 29 Aug 2023 02:43:58 ", "Title": "Incorporating Neuro-Inspired Adaptability for Continual Learning in Artificial Intelligence", "Authors": ["Liyuan Wang", "Xingxing Zhang", "Qian Li", "Mingtian Zhang", "Hang Su", "Jun Zhu", "Yi Zhong"], "Categories": "cs.LG cs.AI"}, "abstract": "Continual learning aims to empower artificial intelligence (AI) with strong adaptability to the real world. For this purpose, a desirable solution should properly balance memory stability with learning plasticity, and acquire sufficient compatibility to capture the observed distributions. Existing advances mainly focus on preserving memory stability to overcome catastrophic forgetting, but remain difficult to flexibly accommodate incremental changes as biological intelligence (BI) does. By modeling a robust Drosophila learning system that actively regulates forgetting with multiple learning modules, here we propose a generic approach that appropriately attenuates old memories in parameter distributions to improve learning plasticity, and accordingly coordinates a multi-learner architecture to ensure solution compatibility. Through extensive theoretical and empirical validation, our approach not only clearly enhances the performance of continual learning, especially over synaptic regularization methods in task-incremental settings, but also potentially advances the understanding of neurological adaptive mechanisms, serving as a novel paradigm to progress AI and BI together.", "url": "https://arxiv.org/abs/2308.14991"}, {"metadata": {"arXiv": "2308.15069", "Date": "Tue, 29 Aug 2023 07:04:50 ", "Title": "MadSGM: Multivariate Anomaly Detection with Score-based Generative Models", "Authors": ["Haksoo Lim", "Sewon Park", "Minjung Kim", "Jaehoon Lee", "Seonkyu Lim", "Noseong Park"], "Categories": "cs.LG cs.AI"}, "abstract": "The time-series anomaly detection is one of the most fundamental tasks for time-series. Unlike the time-series forecasting and classification, the time-series anomaly detection typically requires unsupervised (or self-supervised) training since collecting and labeling anomalous observations are difficult. In addition, most existing methods resort to limited forms of anomaly measurements and therefore, it is not clear whether they are optimal in all circumstances. To this end, we present a multivariate time-series anomaly detector based on score-based generative models, called MadSGM, which considers the broadest ever set of anomaly measurement factors: i) reconstruction-based, ii) density-based, and iii) gradient-based anomaly measurements. We also design a conditional score network and its denoising score matching loss for the time-series anomaly detection. Experiments on five real-world benchmark datasets illustrate that MadSGM achieves the most robust and accurate predictions.", "url": "https://arxiv.org/abs/2308.15069"}, {"metadata": {"arXiv": "2308.15116", "Date": "Tue, 29 Aug 2023 08:29:08 ", "Title": "Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators", "Authors": ["Jingbang Chen", "Yian Wang", "Xingwei Qu", "Shuangjia Zheng", "Yaodong Yang", "Hao Dong", "Jie Fu"], "Categories": "cs.LG cs.AI q-bio.BM"}, "abstract": "Molecular dynamics simulations have emerged as a fundamental instrument for studying biomolecules. At the same time, it is desirable to perform simulations of a collection of particles under various conditions in which the molecules can fluctuate. In this paper, we explore and adapt the soft prompt-based learning method to molecular dynamics tasks. Our model can remarkably generalize to unseen and out-of-distribution scenarios with limited training data. While our work focuses on temperature as a test case, the versatility of our approach allows for efficient simulation through any continuous dynamic conditions, such as pressure and volumes. Our framework has two stages: 1) Pre-trains with data mixing technique, augments molecular structure data and temperature prompts, then applies a curriculum learning method by increasing the ratio of them smoothly. 2) Meta-learning-based fine-tuning framework improves sample-efficiency of fine-tuning process and gives the soft prompt-tuning better initialization points. Comprehensive experiments reveal that our framework excels in accuracy for in-domain data and demonstrates strong generalization capabilities for unseen and out-of-distribution samples.", "url": "https://arxiv.org/abs/2308.15116"}, {"metadata": {"arXiv": "2308.15126", "Date": "Tue, 29 Aug 2023 08:51:24 ", "Title": "Evaluation and Analysis of Hallucination in Large Vision-Language Models", "Authors": ["Junyang Wang", "Yiyang Zhou", "Guohai Xu", "Pengcheng Shi", "Chenlin Zhao", "Haiyang Xu", "Qinghao Ye", "Ming Yan", "Ji Zhang", "Jihua Zhu", "Jitao Sang", "Haoyu Tang"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["11 pages", "5 figures"]}, "abstract": "Large Vision-Language Models (LVLMs) have recently achieved remarkable success. However, LVLMs are still plagued by the hallucination problem, which limits the practicality in many scenarios. Hallucination refers to the information of LVLMs' responses that does not exist in the visual input, which poses potential risks of substantial consequences. There has been limited work studying hallucination evaluation in LVLMs. In this paper, we propose Hallucination Evaluation based on Large Language Models (HaELM), an LLM-based hallucination evaluation framework. HaELM achieves an approximate 95% performance comparable to ChatGPT and has additional advantages including low cost, reproducibility, privacy preservation and local deployment. Leveraging the HaELM, we evaluate the hallucination in current LVLMs. Furthermore, we analyze the factors contributing to hallucination in LVLMs and offer helpful suggestions to mitigate the hallucination problem. Our training data and human annotation hallucination data will be made public soon.", "url": "https://arxiv.org/abs/2308.15126"}, {"metadata": {"arXiv": "2308.15308", "Date": "Tue, 29 Aug 2023 13:48:35 ", "Title": "On-Device Learning with Binary Neural Networks", "Authors": ["Lorenzo Vorabbi", "Davide Maltoni", "Stefano Santi"], "Categories": "cs.LG cs.AI"}, "abstract": "Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs. In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models. We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead. The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authors' knowledge, this is the first attempt to prove on-device learning with BNN. The experimental validation carried out confirms the validity and the suitability of the proposed method.", "url": "https://arxiv.org/abs/2308.15308"}, {"metadata": {"arXiv": "2308.15321", "Date": "Tue, 29 Aug 2023 14:16:09 ", "Title": "Elucidating the Exposure Bias in Diffusion Models", "Authors": ["Mang Ning", "Mingxiao Li", "Jianlin Su", "Albert Ali Salah", "Itir Onal Ertugrul"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["7 pages", "code available soon"]}, "abstract": "Diffusion models have demonstrated impressive generative capabilities, but their 'exposure bias' problem, described as the input mismatch between training and sampling, lacks in-depth exploration. In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue. Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it. Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias. We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output (Epsilon), mitigating the input mismatch between training and sampling. Experiments on various diffusion frameworks (ADM, DDPM/DDIM, LDM), unconditional and conditional settings, and deterministic vs. stochastic sampling verify the effectiveness of our method.", "url": "https://arxiv.org/abs/2308.15321"}, {"metadata": {"arXiv": "2308.15457", "Date": "Tue, 29 Aug 2023 17:31:26 ", "Title": "From SMOTE to Mixup for Deep Imbalanced Classification", "Authors": ["Wei-Chao Cheng", "Tan-Ha Mai", "Hsuan-Tien Lin"], "Categories": "cs.LG cs.AI", "Comments": ["25 pages", "3 figures"]}, "abstract": "Given imbalanced data, it is hard to train a good classifier using deep learning because of the poor generalization of minority classes. Traditionally, the well-known synthetic minority oversampling technique (SMOTE) for data augmentation, a data mining approach for imbalanced learning, has been used to improve this generalization. However, it is unclear whether SMOTE also benefits deep learning. In this work, we study why the original SMOTE is insufficient for deep learning, and enhance SMOTE using soft labels. Connecting the resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to a unified framework that puts traditional and modern data augmentation techniques under the same umbrella. A careful study within this framework shows that Mixup improves generalization by implicitly achieving uneven margins between majority and minority classes. We then propose a novel margin-aware Mixup technique that more explicitly achieves uneven margins. Extensive experimental results demonstrate that our proposed technique yields state-of-the-art performance on deep imbalanced classification while achieving superior performance on extremely imbalanced data. The code is open-sourced in our developed package https://github.com/ntucllab/imbalanced-DL to foster future research in this direction.", "url": "https://arxiv.org/abs/2308.15457"}, {"metadata": {"arXiv": "2308.15464", "Date": "Tue, 29 Aug 2023 17:44:02 ", "Title": "A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios", "Authors": ["Yangxinyu Xie", "Tanwi Mallick"], "Categories": "cs.LG cs.AI"}, "abstract": "Spatiotemporal graph neural networks have achieved state-of-the-art performance in traffic forecasting. However, they often struggle to forecast congestion accurately due to the limitations of traditional loss functions. While accurate forecasting of regular traffic conditions is crucial, a reliable AI system must also accurately forecast congestion scenarios to maintain safe and efficient transportation. In this paper, we explore various loss functions inspired by heavy tail analysis and imbalanced classification problems to address this issue. We evaluate the efficacy of these loss functions in forecasting traffic speed, with an emphasis on congestion scenarios. Through extensive experiments on real-world traffic datasets, we discovered that when optimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands out as the most effective. When optimizing Mean Squared Error (MSE), Gumbel Loss proves to be the superior choice. These choices effectively forecast traffic congestion events without compromising the accuracy of regular traffic speed forecasts. This research enhances deep learning models' capabilities in forecasting sudden speed changes due to congestion and underscores the need for more research in this direction. By elevating the accuracy of congestion forecasting, we advocate for AI systems that are reliable, secure, and resilient in practical traffic management scenarios.", "url": "https://arxiv.org/abs/2308.15464"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

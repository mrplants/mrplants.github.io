<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.05709", "Date": "Tue, 07 Nov 2023 14:00:09 ", "Title": "OmniVec: Learning robust representations with cross modal sharing", "Authors": ["Siddharth Srivastava", "Gaurav Sharma"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Majority of research in learning based methods has been towards designing and training networks for specific tasks. However, many of the learning based tasks, across modalities, share commonalities and could be potentially tackled in a joint framework. We present an approach in such direction, to learn multiple tasks, in multiple modalities, with a unified architecture. The proposed network is composed of task specific encoders, a common trunk in the middle, followed by task specific prediction heads. We first pre-train it by self-supervised masked training, followed by sequential training for the different tasks. We train the network on all major modalities, e.g.\\ visual, audio, text and 3D, and report results on $22$ diverse and challenging public benchmarks. We demonstrate empirically that, using a joint network to train across modalities leads to meaningful information sharing and this allows us to achieve state-of-the-art results on most of the benchmarks. We also show generalization of the trained network on cross-modal tasks as well as unseen datasets and tasks.", "url": "https://arxiv.org/abs/2311.05709"}, {"metadata": {"arXiv": "2311.06059", "Date": "Fri, 10 Nov 2023 13:47:21 ", "Title": "Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation", "Authors": ["Bharath Bhushan Damodaran", "Francois Schnitzler", "Anne Lambert", "Pierre Hellier"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Published at ICCV 2023 Workshop on Neural Fields for Autonomous Driving and Robotics"]}, "abstract": "Positional encodings are employed to capture the high frequency information of the encoded signals in implicit neural representation (INR). In this paper, we propose a novel positional encoding method which improves the reconstruction quality of the INR. The proposed embedding method is more advantageous for the compact data representation because it has a greater number of frequency basis than the existing methods. Our experiments shows that the proposed method achieves significant gain in the rate-distortion performance without introducing any additional complexity in the compression task and higher reconstruction quality in novel view synthesis.", "url": "https://arxiv.org/abs/2311.06059"}, {"metadata": {"arXiv": "2311.06095", "Date": "Fri, 10 Nov 2023 14:53:39 ", "Title": "Dual input stream transformer for eye-tracking line assignment", "Authors": ["Thomas M. Mercier", "Marcin Budka", "Martin R. Vasilev", "Julie A. Kirkby", "Bernhard Angele", "Timothy J. Slattery"], "Categories": "cs.CV cs.LG", "Comments": ["This work has been submitted to the IEEE Transactions on pattern analysis and machine intelligence for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible. Code will be published after publication"], "MSC-class": "91Cxx", "ACM-class": "J.4"}, "abstract": "We introduce a novel Dual Input Stream Transformer (DIST) for the challenging problem of assigning fixation points from eye-tracking data collected during passage reading to the line of text that the reader was actually focused on. This post-processing step is crucial for analysis of the reading data due to the presence of noise in the form of vertical drift. We evaluate DIST against nine classical approaches on a comprehensive suite of nine diverse datasets, and demonstrate DIST's superiority. By combining multiple instances of the DIST model in an ensemble we achieve an average accuracy of 98.5\\% across all datasets. Our approach presents a significant step towards addressing the bottleneck of manual line assignment in reading research. Through extensive model analysis and ablation studies, we identify key factors that contribute to DIST's success, including the incorporation of line overlap features and the use of a second input stream. Through evaluation on a set of diverse datasets we demonstrate that DIST is robust to various experimental setups, making it a safe first choice for practitioners in the field.", "url": "https://arxiv.org/abs/2311.06095"}, {"metadata": {"arXiv": "2311.06169", "Date": "Fri, 10 Nov 2023 16:36:49 ", "Title": "Deep Fast Vision: A Python Library for Accelerated Deep Transfer Learning Vision Prototyping", "Authors": ["Fabi Prezja"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["7 pages", "1 figure"]}, "abstract": "Deep learning-based vision is characterized by intricate frameworks that often necessitate a profound understanding, presenting a barrier to newcomers and limiting broad adoption. With many researchers grappling with the constraints of smaller datasets, there's a pronounced reliance on pre-trained neural networks, especially for tasks such as image classification. This reliance is further intensified in niche imaging areas where obtaining vast datasets is challenging. Despite the widespread use of transfer learning as a remedy to the small dataset dilemma, a conspicuous absence of tailored auto-ML solutions persists. Addressing these challenges is \"Deep Fast Vision\", a python library that streamlines the deep learning process. This tool offers a user-friendly experience, enabling results through a simple nested dictionary definition, helping to democratize deep learning for non-experts. Designed for simplicity and scalability, Deep Fast Vision appears as a bridge, connecting the complexities of existing deep learning frameworks with the needs of a diverse user base.", "url": "https://arxiv.org/abs/2311.06169"}, {"metadata": {"arXiv": "2311.05722", "Date": "Thu, 09 Nov 2023 20:11:40 ", "Title": "Verilog-to-PyG -- A Framework for Graph Learning and Augmentation on RTL Designs", "Authors": ["Yingjie Li and Mingju Liu and Alan Mishchenko and Cunxi Yu"], "Categories": "cs.LG cs.AR cs.LO", "Comments": ["8 pages", "International Conference on Computer-Aided Design (ICCAD'23)"]}, "abstract": "The complexity of modern hardware designs necessitates advanced methodologies for optimizing and analyzing modern digital systems. In recent times, machine learning (ML) methodologies have emerged as potent instruments for assessing design quality-of-results at the Register-Transfer Level (RTL) or Boolean level, aiming to expedite design exploration of advanced RTL configurations. In this presentation, we introduce an innovative open-source framework that translates RTL designs into graph representation foundations, which can be seamlessly integrated with the PyTorch Geometric graph learning platform. Furthermore, the Verilog-to-PyG (V2PYG) framework is compatible with the open-source Electronic Design Automation (EDA) toolchain OpenROAD, facilitating the collection of labeled datasets in an utterly open-source manner. Additionally, we will present novel RTL data augmentation methods (incorporated in our framework) that enable functional equivalent design augmentation for the construction of an extensive graph-based RTL design database. Lastly, we will showcase several using cases of V2PYG with detailed scripting examples. V2PYG can be found at \\url{https://yu-maryland.github.io/Verilog-to-PyG/}.", "url": "https://arxiv.org/abs/2311.05722"}, {"metadata": {"arXiv": "2311.05760", "Date": "Thu, 09 Nov 2023 21:55:53 ", "Title": "MALCOM-PSGD: Inexact Proximal Stochastic Gradient Descent for Communication-Efficient Decentralized Machine Learning", "Authors": ["Andrew Campbell", "Hang Liu", "Leah Woldemariam", "and Anna Scaglione"], "Categories": "cs.LG cs.DC cs.DS cs.MA math.OC", "MSC-class": "68W15, 68W10, 68W40, 90C06, 90C35, 90C25", "ACM-class": "G.1.6; F.2.1; E.4"}, "abstract": "Recent research indicates that frequent model communication stands as a major bottleneck to the efficiency of decentralized machine learning (ML), particularly for large-scale and over-parameterized neural networks (NNs). In this paper, we introduce MALCOM-PSGD, a new decentralized ML algorithm that strategically integrates gradient compression techniques with model sparsification. MALCOM-PSGD leverages proximal stochastic gradient descent to handle the non-smoothness resulting from the $\\ell_1$ regularization in model sparsification. Furthermore, we adapt vector source coding and dithering-based quantization for compressed gradient communication of sparsified models. Our analysis shows that decentralized proximal stochastic gradient descent with compressed communication has a convergence rate of $\\mathcal{O}\\left(\\ln(t)/\\sqrt{t}\\right)$ assuming a diminishing learning rate and where $t$ denotes the number of iterations. Numerical results verify our theoretical findings and demonstrate that our method reduces communication costs by approximately $75\\%$ when compared to the state-of-the-art method.", "url": "https://arxiv.org/abs/2311.05760"}, {"metadata": {"arXiv": "2311.05764", "Date": "Thu, 09 Nov 2023 22:07:15 ", "Title": "Generative Explanations for Graph Neural Network: Methods and Evaluations", "Authors": ["Jialin Chen", "Kenza Amara", "Junchi Yu", "Rex Ying"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) achieve state-of-the-art performance in various graph-related tasks. However, the black-box nature often limits their interpretability and trustworthiness. Numerous explainability methods have been proposed to uncover the decision-making logic of GNNs, by generating underlying explanatory substructures. In this paper, we conduct a comprehensive review of the existing explanation methods for GNNs from the perspective of graph generation. Specifically, we propose a unified optimization objective for generative explanation methods, comprising two sub-objectives: Attribution and Information constraints. We further demonstrate their specific manifestations in various generative model architectures and different explanation scenarios. With the unified objective of the explanation problem, we reveal the shared characteristics and distinctions among current methods, laying the foundation for future methodological advancements. Empirical results demonstrate the advantages and limitations of different explainability approaches in terms of explanation performance, efficiency, and generalizability.", "url": "https://arxiv.org/abs/2311.05764"}, {"metadata": {"arXiv": "2311.05767", "Date": "Thu, 09 Nov 2023 22:22:18 ", "Title": "Dirichlet Energy Enhancement of Graph Neural Networks by Framelet Augmentation", "Authors": ["Jialin Chen", "Yuelin Wang", "Cristian Bodnar", "Rex Ying", "Pietro Lio", "Yu Guang Wang"], "Categories": "cs.LG"}, "abstract": "Graph convolutions have been a pivotal element in learning graph representations. However, recursively aggregating neighboring information with graph convolutions leads to indistinguishable node features in deep layers, which is known as the over-smoothing issue. The performance of graph neural networks decays fast as the number of stacked layers increases, and the Dirichlet energy associated with the graph decreases to zero as well. In this work, we introduce a framelet system into the analysis of Dirichlet energy and take a multi-scale perspective to leverage the Dirichlet energy and alleviate the over-smoothing issue. Specifically, we develop a Framelet Augmentation strategy by adjusting the update rules with positive and negative increments for low-pass and high-passes respectively. Based on that, we design the Energy Enhanced Convolution (EEConv), which is an effective and practical operation that is proved to strictly enhance Dirichlet energy. From a message-passing perspective, EEConv inherits multi-hop aggregation property from the framelet transform and takes into account all hops in the multi-scale representation, which benefits the node classification tasks over heterophilous graphs. Experiments show that deep GNNs with EEConv achieve state-of-the-art performance over various node classification datasets, especially for heterophilous graphs, while also lifting the Dirichlet energy as the network goes deeper.", "url": "https://arxiv.org/abs/2311.05767"}, {"metadata": {"arXiv": "2311.05787", "Date": "Thu, 09 Nov 2023 23:32:06 ", "Title": "Towards stable real-world equation discovery with assessing differentiating quality influence", "Authors": ["Mikhail Masliaev", "Ilya Markov", "Alexander Hvatov"], "Categories": "cs.LG"}, "abstract": "This paper explores the critical role of differentiation approaches for data-driven differential equation discovery. Accurate derivatives of the input data are essential for reliable algorithmic operation, particularly in real-world scenarios where measurement quality is inevitably compromised. We propose alternatives to the commonly used finite differences-based method, notorious for its instability in the presence of noise, which can exacerbate random errors in the data. Our analysis covers four distinct methods: Savitzky-Golay filtering, spectral differentiation, smoothing based on artificial neural networks, and the regularization of derivative variation. We evaluate these methods in terms of applicability to problems, similar to the real ones, and their ability to ensure the convergence of equation discovery algorithms, providing valuable insights for robust modeling of real-world processes.", "url": "https://arxiv.org/abs/2311.05787"}, {"metadata": {"arXiv": "2311.05788", "Date": "Thu, 09 Nov 2023 23:33:31 ", "Title": "Structured Transforms Across Spaces with Cost-Regularized Optimal Transport", "Authors": ["Othmane Sebbouh and Marco Cuturi and Gabriel Peyr\\'e"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "Matching a source to a target probability measure is often solved by instantiating a linear optimal transport (OT) problem, parameterized by a ground cost function that quantifies discrepancy between points. When these measures live in the same metric space, the ground cost often defaults to its distance. When instantiated across two different spaces, however, choosing that cost in the absence of aligned data is a conundrum. As a result, practitioners often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We exploit in this work a parallel between GW and cost-regularized OT, the regularized minimization of a linear OT objective parameterized by a ground cost. We use this cost-regularized formulation to match measures across two different Euclidean spaces, where the cost is evaluated between transformed source points and target points. We show that several quadratic OT problems fall in this category, and consider enforcing structure in linear transform (e.g. sparsity), by introducing structure-inducing regularizers. We provide a proximal algorithm to extract such transforms from unaligned data, and demonstrate its applicability to single-cell spatial transcriptomics/multiomics matching tasks.", "url": "https://arxiv.org/abs/2311.05788"}, {"metadata": {"arXiv": "2311.05795", "Date": "Fri, 10 Nov 2023 00:00:20 ", "Title": "Improvements on Uncertainty Quantification for Node Classification via Distance-Based Regularization", "Authors": ["Russell Alan Hart", "Linlin Yu", "Yifei Lou", "Feng Chen"], "Categories": "cs.LG stat.ML", "Comments": ["Neurips 2023"]}, "abstract": "Deep neural networks have achieved significant success in the last decades, but they are not well-calibrated and often produce unreliable predictions. A large number of literature relies on uncertainty quantification to evaluate the reliability of a learning model, which is particularly important for applications of out-of-distribution (OOD) detection and misclassification detection. We are interested in uncertainty quantification for interdependent node-level classification. We start our analysis based on graph posterior networks (GPNs) that optimize the uncertainty cross-entropy (UCE)-based loss function. We describe the theoretical limitations of the widely-used UCE loss. To alleviate the identified drawbacks, we propose a distance-based regularization that encourages clustered OOD nodes to remain clustered in the latent space. We conduct extensive comparison experiments on eight standard datasets and demonstrate that the proposed regularization outperforms the state-of-the-art in both OOD detection and misclassification detection.", "url": "https://arxiv.org/abs/2311.05795"}, {"metadata": {"arXiv": "2311.05808", "Date": "Fri, 10 Nov 2023 00:53:22 ", "Title": "Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction", "Authors": ["Shanghao Shi", "Ning Wang", "Yang Xiao", "Chaoyu Zhang", "Yi Shi", "Y.Thomas Hou", "Wenjing Lou"], "Categories": "cs.LG"}, "abstract": "Federated learning is known for its capability to safeguard participants' data privacy. However, recently emerged model inversion attacks (MIAs) have shown that a malicious parameter server can reconstruct individual users' local data samples through model updates. The state-of-the-art attacks either rely on computation-intensive search-based optimization processes to recover each input batch, making scaling difficult, or they involve the malicious parameter server adding extra modules before the global model architecture, rendering the attacks too conspicuous and easily detectable. To overcome these limitations, we propose Scale-MIA, a novel MIA capable of efficiently and accurately recovering training samples of clients from the aggregated updates, even when the system is under the protection of a robust secure aggregation protocol. Unlike existing approaches treating models as black boxes, Scale-MIA recognizes the importance of the intricate architecture and inner workings of machine learning models. It identifies the latent space as the critical layer for breaching privacy and decomposes the complex recovery task into an innovative two-step process to reduce computation complexity. The first step involves reconstructing the latent space representations (LSRs) from the aggregated model updates using a closed-form inversion mechanism, leveraging specially crafted adversarial linear layers. In the second step, the whole input batches are recovered from the LSRs by feeding them into a fine-tuned generative decoder. We implemented Scale-MIA on multiple commonly used machine learning models and conducted comprehensive experiments across various settings. The results demonstrate that Scale-MIA achieves excellent recovery performance on different datasets, exhibiting high reconstruction rates, accuracy, and attack efficiency on a larger scale compared to state-of-the-art MIAs.", "url": "https://arxiv.org/abs/2311.05808"}, {"metadata": {"arXiv": "2311.05820", "Date": "Fri, 10 Nov 2023 01:34:18 ", "Title": "Machine Learning-powered Compact Modeling of Stochastic Electronic Devices using Mixture Density Networks", "Authors": ["Jack Hutchins", "Shamiul Alam", "Dana S. Rampini", "Bakhrom G. Oripov", "Adam N. McCaughan", "Ahmedullah Aziz"], "Categories": "cs.LG"}, "abstract": "The relentless pursuit of miniaturization and performance enhancement in electronic devices has led to a fundamental challenge in the field of circuit design and simulation: how to accurately account for the inherent stochastic nature of certain devices. While conventional deterministic models have served as indispensable tools for circuit designers, they fall short when it comes to capture the subtle yet critical variability exhibited by many electronic components. In this paper, we present an innovative approach that transcends the limitations of traditional modeling techniques by harnessing the power of machine learning, specifically Mixture Density Networks (MDNs), to faithfully represent and simulate the stochastic behavior of electronic devices. We demonstrate our approach to model heater cryotrons, where the model is able to capture the stochastic switching dynamics observed in the experiment. Our model shows 0.82% mean absolute error for switching probability. This paper marks a significant step forward in the quest for accurate and versatile compact models, poised to drive innovation in the realm of electronic circuits.", "url": "https://arxiv.org/abs/2311.05820"}, {"metadata": {"arXiv": "2311.05827", "Date": "Fri, 10 Nov 2023 02:18:33 ", "Title": "AccEPT: An Acceleration Scheme for Speeding Up Edge Pipeline-parallel Training", "Authors": ["Yuhao Chen", "Yuxuan Yan", "Qianqian Yang", "Yuanchao Shu", "Shibo He", "Zhiguo Shi", "Jiming Chen"], "Categories": "cs.LG"}, "abstract": "It is usually infeasible to fit and train an entire large deep neural network (DNN) model using a single edge device due to the limited resources. To facilitate intelligent applications across edge devices, researchers have proposed partitioning a large model into several sub-models, and deploying each of them to a different edge device to collaboratively train a DNN model. However, the communication overhead caused by the large amount of data transmitted from one device to another during training, as well as the sub-optimal partition point due to the inaccurate latency prediction of computation at each edge device can significantly slow down training. In this paper, we propose AccEPT, an acceleration scheme for accelerating the edge collaborative pipeline-parallel training. In particular, we propose a light-weight adaptive latency predictor to accurately estimate the computation latency of each layer at different devices, which also adapts to unseen devices through continuous learning. Therefore, the proposed latency predictor leads to better model partitioning which balances the computation loads across participating devices. Moreover, we propose a bit-level computation-efficient data compression scheme to compress the data to be transmitted between devices during training. Our numerical results demonstrate that our proposed acceleration approach is able to significantly speed up edge pipeline parallel training up to 3 times faster in the considered experimental settings.", "url": "https://arxiv.org/abs/2311.05827"}, {"metadata": {"arXiv": "2311.05846", "Date": "Fri, 10 Nov 2023 03:02:49 ", "Title": "Clipped-Objective Policy Gradients for Pessimistic Policy Optimization", "Authors": ["Jared Markowitz and Edward W. Staley"], "Categories": "cs.LG", "Comments": ["12 pages", "8 figures"]}, "abstract": "To facilitate efficient learning, policy gradient approaches to deep reinforcement learning (RL) are typically paired with variance reduction measures and strategies for making large but safe policy changes based on a batch of experiences. Natural policy gradient methods, including Trust Region Policy Optimization (TRPO), seek to produce monotonic improvement through bounded changes in policy outputs. Proximal Policy Optimization (PPO) is a commonly used, first-order algorithm that instead uses loss clipping to take multiple safe optimization steps per batch of data, replacing the bound on the single step of TRPO with regularization on multiple steps. In this work, we find that the performance of PPO, when applied to continuous action spaces, may be consistently improved through a simple change in objective. Instead of the importance sampling objective of PPO, we instead recommend a basic policy gradient, clipped in an equivalent fashion. While both objectives produce biased gradient estimates with respect to the RL objective, they also both display significantly reduced variance compared to the unbiased off-policy policy gradient. Additionally, we show that (1) the clipped-objective policy gradient (COPG) objective is on average \"pessimistic\" compared to both the PPO objective and (2) this pessimism promotes enhanced exploration. As a result, we empirically observe that COPG produces improved learning compared to PPO in single-task, constrained, and multi-task learning, without adding significant computational cost or complexity. Compared to TRPO, the COPG approach is seen to offer comparable or superior performance, while retaining the simplicity of a first-order method.", "url": "https://arxiv.org/abs/2311.05846"}, {"metadata": {"arXiv": "2311.05858", "Date": "Fri, 10 Nov 2023 03:54:40 ", "Title": "Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation", "Authors": ["Junyoung Park", "Jin Kim", "Hyeongjun Kwon", "Ilhoon Yoon", "Kwanghoon Sohn"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted to WACV 2024"]}, "abstract": "Given the inevitability of domain shifts during inference in real-world applications, test-time adaptation (TTA) is essential for model adaptation after deployment. However, the real-world scenario of continuously changing target distributions presents challenges including catastrophic forgetting and error accumulation. Existing TTA methods for non-stationary domain shifts, while effective, incur excessive computational load, making them impractical for on-device settings. In this paper, we introduce a layer-wise auto-weighting algorithm for continual and gradual TTA that autonomously identifies layers for preservation or concentrated adaptation. By leveraging the Fisher Information Matrix (FIM), we first design the learning weight to selectively focus on layers associated with log-likelihood changes while preserving unrelated ones. Then, we further propose an exponential min-max scaler to make certain layers nearly frozen while mitigating outliers. This minimizes forgetting and error accumulation, leading to efficient adaptation to non-stationary target distribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our method outperforms conventional continual and gradual TTA approaches while significantly reducing computational load, highlighting the importance of FIM-based learning weight in adapting to continuously or gradually shifting target domains.", "url": "https://arxiv.org/abs/2311.05858"}, {"metadata": {"arXiv": "2311.05874", "Date": "Fri, 10 Nov 2023 05:17:03 ", "Title": "Testing Dependency of Unlabeled Databases", "Authors": ["Vered Paslev and Wasim Huleihel"], "Categories": "cs.LG cs.IT math.IT math.ST stat.TH", "Comments": ["39 pages"]}, "abstract": "In this paper, we investigate the problem of deciding whether two random databases $\\mathsf{X}\\in\\mathcal{X}^{n\\times d}$ and $\\mathsf{Y}\\in\\mathcal{Y}^{n\\times d}$ are statistically dependent or not. This is formulated as a hypothesis testing problem, where under the null hypothesis, these two databases are statistically independent, while under the alternative, there exists an unknown row permutation $\\sigma$, such that $\\mathsf{X}$ and $\\mathsf{Y}^\\sigma$, a permuted version of $\\mathsf{Y}$, are statistically dependent with some known joint distribution, but have the same marginal distributions as the null. We characterize the thresholds at which optimal testing is information-theoretically impossible and possible, as a function of $n$, $d$, and some spectral properties of the generative distributions of the datasets. For example, we prove that if a certain function of the eigenvalues of the likelihood function and $d$, is below a certain threshold, as $d\\to\\infty$, then weak detection (performing slightly better than random guessing) is statistically impossible, no matter what the value of $n$ is. This mimics the performance of an efficient test that thresholds a centered version of the log-likelihood function of the observed matrices. We also analyze the case where $d$ is fixed, for which we derive strong (vanishing error) and weak detection lower and upper bounds.", "url": "https://arxiv.org/abs/2311.05874"}, {"metadata": {"arXiv": "2311.05888", "Date": "Fri, 10 Nov 2023 06:15:38 ", "Title": "Low-Multi-Rank High-Order Bayesian Robust Tensor Factorization", "Authors": ["Jianan Liu and Chunguang Li"], "Categories": "cs.LG"}, "abstract": "The recently proposed tensor robust principal component analysis (TRPCA) methods based on tensor singular value decomposition (t-SVD) have achieved numerous successes in many fields. However, most of these methods are only applicable to third-order tensors, whereas the data obtained in practice are often of higher order, such as fourth-order color videos, fourth-order hyperspectral videos, and fifth-order light-field images. Additionally, in the t-SVD framework, the multi-rank of a tensor can describe more fine-grained low-rank structure in the tensor compared with the tubal rank. However, determining the multi-rank of a tensor is a much more difficult problem than determining the tubal rank. Moreover, most of the existing TRPCA methods do not explicitly model the noises except the sparse noise, which may compromise the accuracy of estimating the low-rank tensor. In this work, we propose a novel high-order TRPCA method, named as Low-Multi-rank High-order Bayesian Robust Tensor Factorization (LMH-BRTF), within the Bayesian framework. Specifically, we decompose the observed corrupted tensor into three parts, i.e., the low-rank component, the sparse component, and the noise component. By constructing a low-rank model for the low-rank component based on the order-$d$ t-SVD and introducing a proper prior for the model, LMH-BRTF can automatically determine the tensor multi-rank. Meanwhile, benefiting from the explicit modeling of both the sparse and noise components, the proposed method can leverage information from the noises more effectivly, leading to an improved performance of TRPCA. Then, an efficient variational inference algorithm is established for parameters estimation. Empirical studies on synthetic and real-world datasets demonstrate the effectiveness of the proposed method in terms of both qualitative and quantitative results.", "url": "https://arxiv.org/abs/2311.05888"}, {"metadata": {"arXiv": "2311.05908", "Date": "Fri, 10 Nov 2023 07:33:35 ", "Title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores", "Authors": ["Daniel Y. Fu", "Hermann Kumbong", "Eric Nguyen", "Christopher R\\'e"], "Categories": "cs.LG"}, "abstract": "Convolution models with long filters have demonstrated state-of-the-art reasoning abilities in many long-sequence tasks but lag behind the most optimized Transformers in wall-clock time. A major bottleneck is the Fast Fourier Transform (FFT)--which allows long convolutions to run in $O(N logN)$ time in sequence length $N$ but has poor hardware utilization. In this paper, we study how to optimize the FFT convolution. We find two key bottlenecks: the FFT does not effectively use specialized matrix multiply units, and it incurs expensive I/O between layers of the memory hierarchy. In response, we propose FlashFFTConv. FlashFFTConv uses a matrix decomposition that computes the FFT using matrix multiply units and enables kernel fusion for long sequences, reducing I/O. We also present two sparse convolution algorithms--1) partial convolutions and 2) frequency-sparse convolutions--which can be implemented simply by skipping blocks in the matrix decomposition, enabling further opportunities for memory and compute savings. FlashFFTConv speeds up exact FFT convolutions by up to 7.93$\\times$ over PyTorch and achieves up to 4.4$\\times$ speedup end-to-end. Given the same compute budget, FlashFFTConv allows Hyena-GPT-s to achieve 2.3 points better perplexity on the PILE and M2-BERT-base to achieve 3.3 points higher GLUE score--matching models with twice the parameter count. FlashFFTConv also achieves 96.1% accuracy on Path-512, a high-resolution vision task where no model had previously achieved better than 50%. Furthermore, partial convolutions enable longer-sequence models--yielding the first DNA model that can process the longest human genes (2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models while maintaining or improving model quality.", "url": "https://arxiv.org/abs/2311.05908"}, {"metadata": {"arXiv": "2311.05911", "Date": "Fri, 10 Nov 2023 07:42:08 ", "Title": "An alternative for one-hot encoding in neural network models", "Authors": ["Lazar Zlati\\'c"], "Categories": "cs.LG", "Comments": ["5 pages"]}, "abstract": "This paper proposes an algorithm that implements binary encoding of the categorical features of neural network model input data, while also implementing changes in the forward and backpropagation procedures in order to achieve the property of having model weight changes, that result from the neural network learning process for certain data instances of some feature category, only affect the forward pass calculations for input data instances of that same feature category, as it is in the case of utilising one-hot encoding for categorical features.", "url": "https://arxiv.org/abs/2311.05911"}, {"metadata": {"arXiv": "2311.05924", "Date": "Fri, 10 Nov 2023 08:14:27 ", "Title": "Federated Learning with Manifold Regularization and Normalized Update Reaggregation", "Authors": ["Xuming An", "Li Shen", "Han Hu", "Yong Luo"], "Categories": "cs.LG"}, "abstract": "Federated Learning (FL) is an emerging collaborative machine learning framework where multiple clients train the global model without sharing their own datasets. In FL, the model inconsistency caused by the local data heterogeneity across clients results in the near-orthogonality of client updates, which leads to the global update norm reduction and slows down the convergence. Most previous works focus on eliminating the difference of parameters (or gradients) between the local and global models, which may fail to reflect the model inconsistency due to the complex structure of the machine learning model and the Euclidean space's limitation in meaningful geometric representations. In this paper, we propose FedMRUR by adopting the manifold model fusion scheme and a new global optimizer to alleviate the negative impacts. Concretely, FedMRUR adopts a hyperbolic graph manifold regularizer enforcing the representations of the data in the local and global models are close to each other in a low-dimensional subspace. Because the machine learning model has the graph structure, the distance in hyperbolic space can reflect the model bias better than the Euclidean distance. In this way, FedMRUR exploits the manifold structures of the representations to significantly reduce the model inconsistency. FedMRUR also aggregates the client updates norms as the global update norm, which can appropriately enlarge each client's contribution to the global update, thereby mitigating the norm reduction introduced by the near-orthogonality of client updates. Furthermore, we theoretically prove that our algorithm can achieve a linear speedup property for non-convex setting under partial client participation.Experiments demonstrate that FedMRUR can achieve a new state-of-the-art (SOTA) accuracy with less communication.", "url": "https://arxiv.org/abs/2311.05924"}, {"metadata": {"arXiv": "2311.05936", "Date": "Fri, 10 Nov 2023 08:50:28 ", "Title": "Aggregation Weighting of Federated Learning via Generalization Bound Estimation", "Authors": ["Mingwei Xu", "Xiaofeng Cao", "Ivor W.Tsang", "and James T.Kwok"], "Categories": "cs.LG"}, "abstract": "Federated Learning (FL) typically aggregates client model parameters using a weighting approach determined by sample proportions. However, this naive weighting method may lead to unfairness and degradation in model performance due to statistical heterogeneity and the inclusion of noisy data among clients. Theoretically, distributional robustness analysis has shown that the generalization performance of a learning model with respect to any shifted distribution is bounded. This motivates us to reconsider the weighting approach in federated learning. In this paper, we replace the aforementioned weighting method with a new strategy that considers the generalization bounds of each local model. Specifically, we estimate the upper and lower bounds of the second-order origin moment of the shifted distribution for the current local model, and then use these bounds disagreements as the aggregation proportions for weightings in each communication round. Experiments demonstrate that the proposed weighting strategy significantly improves the performance of several representative FL algorithms on benchmark datasets.", "url": "https://arxiv.org/abs/2311.05936"}, {"metadata": {"arXiv": "2311.05964", "Date": "Fri, 10 Nov 2023 10:02:56 ", "Title": "Multiscale Neural Operators for Solving Time-Independent PDEs", "Authors": ["Winfried Ripken", "Lisa Coiffard", "Felix Pieper", "Sebastian Dziadzio"], "Categories": "cs.LG", "Comments": ["The Symbiosis of Deep Learning and Differential Equations III @ NeurIPS 2023"]}, "abstract": "Time-independent Partial Differential Equations (PDEs) on large meshes pose significant challenges for data-driven neural PDE solvers. We introduce a novel graph rewiring technique to tackle some of these challenges, such as aggregating information across scales and on irregular meshes. Our proposed approach bridges distant nodes, enhancing the global interaction capabilities of GNNs. Our experiments on three datasets reveal that GNN-based methods set new performance standards for time-independent PDEs on irregular meshes. Finally, we show that our graph rewiring strategy boosts the performance of baseline methods, achieving state-of-the-art results in one of the tasks.", "url": "https://arxiv.org/abs/2311.05964"}, {"metadata": {"arXiv": "2311.05975", "Date": "Fri, 10 Nov 2023 10:18:50 ", "Title": "Sum-max Submodular Bandits", "Authors": ["Stephen Pasteris", "Alberto Rumi", "Fabio Vitale", "Nicol\\`o Cesa-Bianchi"], "Categories": "cs.LG"}, "abstract": "Many online decision-making problems correspond to maximizing a sequence of submodular functions. In this work, we introduce sum-max functions, a subclass of monotone submodular functions capturing several interesting problems, including best-of-$K$-bandits, combinatorial bandits, and the bandit versions on facility location, $M$-medians, and hitting sets. We show that all functions in this class satisfy a key property that we call pseudo-concavity. This allows us to prove $\\big(1 - \\frac{1}{e}\\big)$-regret bounds for bandit feedback in the nonstochastic setting of the order of $\\sqrt{MKT}$ (ignoring log factors), where $T$ is the time horizon and $M$ is a cardinality constraint. This bound, attained by a simple and efficient algorithm, significantly improves on the $\\widetilde{O}\\big(T^{2/3}\\big)$ regret bound for online monotone submodular maximization with bandit feedback.", "url": "https://arxiv.org/abs/2311.05975"}, {"metadata": {"arXiv": "2311.06012", "Date": "Fri, 10 Nov 2023 11:53:42 ", "Title": "Doubly Robust Structure Identification from Temporal Data", "Authors": ["Emmanouil Angelis", "Francesco Quinzan", "Ashkan Soleymani", "Patrick Jaillet", "Stefan Bauer"], "Categories": "cs.LG"}, "abstract": "Learning the causes of time-series data is a fundamental task in many applications, spanning from finance to earth sciences or bio-medical applications. Common approaches for this task are based on vector auto-regression, and they do not take into account unknown confounding between potential causes. However, in settings with many potential causes and noisy data, these approaches may be substantially biased. Furthermore, potential causes may be correlated in practical applications. Moreover, existing algorithms often do not work with cyclic data. To address these challenges, we propose a new doubly robust method for Structure Identification from Temporal Data ( SITD ). We provide theoretical guarantees, showing that our method asymptotically recovers the true underlying causal structure. Our analysis extends to cases where the potential causes have cycles and they may be confounded. We further perform extensive experiments to showcase the superior performance of our method.", "url": "https://arxiv.org/abs/2311.06012"}, {"metadata": {"arXiv": "2311.06028", "Date": "Fri, 10 Nov 2023 12:34:28 ", "Title": "Symbolic Regression as Feature Engineering Method for Machine and Deep Learning Regression Tasks", "Authors": ["Assaf Shmuel", "Oren Glickman", "Teddy Lazebnik"], "Categories": "cs.LG"}, "abstract": "In the realm of machine and deep learning regression tasks, the role of effective feature engineering (FE) is pivotal in enhancing model performance. Traditional approaches of FE often rely on domain expertise to manually design features for machine learning models. In the context of deep learning models, the FE is embedded in the neural network's architecture, making it hard for interpretation. In this study, we propose to integrate symbolic regression (SR) as an FE process before a machine learning model to improve its performance. We show, through extensive experimentation on synthetic and real-world physics-related datasets, that the incorporation of SR-derived features significantly enhances the predictive capabilities of both machine and deep learning regression models with 34-86% root mean square error (RMSE) improvement in synthetic datasets and 4-11.5% improvement in real-world datasets. In addition, as a realistic use-case, we show the proposed method improves the machine learning performance in predicting superconducting critical temperatures based on Eliashberg theory by more than 20% in terms of RMSE. These results outline the potential of SR as an FE component in data-driven models.", "url": "https://arxiv.org/abs/2311.06028"}, {"metadata": {"arXiv": "2311.06103", "Date": "Fri, 10 Nov 2023 15:12:04 ", "Title": "1-Lipschitz Neural Networks are more expressive with N-Activations", "Authors": ["Bernd Prach", "Christoph H. Lampert"], "Categories": "cs.LG"}, "abstract": "A crucial property for achieving secure, trustworthy and interpretable deep learning systems is their robustness: small changes to a system's inputs should not result in large changes to its outputs. Mathematically, this means one strives for networks with a small Lipschitz constant. Several recent works have focused on how to construct such Lipschitz networks, typically by imposing constraints on the weight matrices. In this work, we study an orthogonal aspect, namely the role of the activation function. We show that commonly used activation functions, such as MaxMin, as well as all piece-wise linear ones with two segments unnecessarily restrict the class of representable functions, even in the simplest one-dimensional setting. We furthermore introduce the new N-activation function that is provably more expressive than currently popular activation functions. We provide code at https://github.com/berndprach/NActivation.", "url": "https://arxiv.org/abs/2311.06103"}, {"metadata": {"arXiv": "2311.06110", "Date": "Fri, 10 Nov 2023 15:24:23 ", "Title": "An Interpretable Machine Learning Framework to Understand Bikeshare Demand before and during the COVID-19 Pandemic in New York City", "Authors": ["Majbah Uddin", "Ho-Ling Hwang", "Md Sami Hasnine"], "Categories": "cs.LG", "DOI": "10.1080/03081060.2023.2201280"}, "abstract": "In recent years, bikesharing systems have become increasingly popular as affordable and sustainable micromobility solutions. Advanced mathematical models such as machine learning are required to generate good forecasts for bikeshare demand. To this end, this study proposes a machine learning modeling framework to estimate hourly demand in a large-scale bikesharing system. Two Extreme Gradient Boosting models were developed: one using data from before the COVID-19 pandemic (March 2019 to February 2020) and the other using data from during the pandemic (March 2020 to February 2021). Furthermore, a model interpretation framework based on SHapley Additive exPlanations was implemented. Based on the relative importance of the explanatory variables considered in this study, share of female users and hour of day were the two most important explanatory variables in both models. However, the month variable had higher importance in the pandemic model than in the pre-pandemic model.", "url": "https://arxiv.org/abs/2311.06110"}, {"metadata": {"arXiv": "2311.06117", "Date": "Fri, 10 Nov 2023 15:33:19 ", "Title": "Distributionally Robust Skeleton Learning of Discrete Bayesian Networks", "Authors": ["Yeshu Li and Brian D. Ziebart"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2O23 Spotlight. More empirical results added"]}, "abstract": "We consider the problem of learning the exact skeleton of general discrete Bayesian networks from potentially corrupted data. Building on distributionally robust optimization and a regression approach, we propose to optimize the most adverse risk over a family of distributions within bounded Wasserstein distance or KL divergence to the empirical distribution. The worst-case risk accounts for the effect of outliers. The proposed approach applies for general categorical random variables without assuming faithfulness, an ordinal relationship or a specific form of conditional distribution. We present efficient algorithms and show the proposed methods are closely related to the standard regularized regression approach. Under mild assumptions, we derive non-asymptotic guarantees for successful structure learning with logarithmic sample complexities for bounded-degree graphs. Numerical study on synthetic and real datasets validates the effectiveness of our method. Code is available at https://github.com/DanielLeee/drslbn.", "url": "https://arxiv.org/abs/2311.06117"}, {"metadata": {"arXiv": "2311.06153", "Date": "Fri, 10 Nov 2023 16:14:21 ", "Title": "Interpretable Graph Anomaly Detection using Gradient Attention Maps", "Authors": ["Yifei Yang", "Peng Wang", "Xiaofan He", "Dongmian Zou"], "Categories": "cs.LG"}, "abstract": "Detecting unusual patterns in graph data is a crucial task in data mining. However, existing methods often face challenges in consistently achieving satisfactory performance and lack interpretability, which hinders our understanding of anomaly detection decisions. In this paper, we propose a novel approach to graph anomaly detection that leverages the power of interpretability to enhance performance. Specifically, our method extracts an attention map derived from gradients of graph neural networks, which serves as a basis for scoring anomalies. In addition, we conduct theoretical analysis using synthetic data to validate our method and gain insights into its decision-making process. To demonstrate the effectiveness of our method, we extensively evaluate our approach against state-of-the-art graph anomaly detection techniques. The results consistently demonstrate the superior performance of our method compared to the baselines.", "url": "https://arxiv.org/abs/2311.06153"}, {"metadata": {"arXiv": "2311.06170", "Date": "Fri, 10 Nov 2023 16:39:55 ", "Title": "Time Scale Network: A Shallow Neural Network For Time Series Data", "Authors": ["Trevor Meyer", "Camden Shultz", "Najim Dehak", "Laureano Moro-Velazquez", "Pedro Irazoqui"], "Categories": "cs.LG", "Comments": ["8 pages", "5 figures", "preprint"]}, "abstract": "Time series data is often composed of information at multiple time scales, particularly in biomedical data. While numerous deep learning strategies exist to capture this information, many make networks larger, require more data, are more demanding to compute, and are difficult to interpret. This limits their usefulness in real-world applications facing even modest computational or data constraints and can further complicate their translation into practice. We present a minimal, computationally efficient Time Scale Network combining the translation and dilation sequence used in discrete wavelet transforms with traditional convolutional neural networks and back-propagation. The network simultaneously learns features at many time scales for sequence classification with significantly reduced parameters and operations. We demonstrate advantages in Atrial Dysfunction detection including: superior accuracy-per-parameter and accuracy-per-operation, fast training and inference speeds, and visualization and interpretation of learned patterns in atrial dysfunction detection on ECG signals. We also demonstrate impressive performance in seizure prediction using EEG signals. Our network isolated a few time scales that could be strategically selected to achieve 90.9% accuracy using only 1,133 active parameters and consistently converged on pulsatile waveform shapes. This method does not rest on any constraints or assumptions regarding signal content and could be leveraged in any area of time series analysis dealing with signals containing features at many time scales.", "url": "https://arxiv.org/abs/2311.06170"}, {"metadata": {"arXiv": "2311.06210", "Date": "Fri, 10 Nov 2023 17:55:44 ", "Title": "Optimal Cooperative Multiplayer Learning Bandits with Noisy Rewards and No Communication", "Authors": ["William Chang", "Yuanhao Lu"], "Categories": "cs.LG cs.MA stat.ML"}, "abstract": "We consider a cooperative multiplayer bandit learning problem where the players are only allowed to agree on a strategy beforehand, but cannot communicate during the learning process. In this problem, each player simultaneously selects an action. Based on the actions selected by all players, the team of players receives a reward. The actions of all the players are commonly observed. However, each player receives a noisy version of the reward which cannot be shared with other players. Since players receive potentially different rewards, there is an asymmetry in the information used to select their actions. In this paper, we provide an algorithm based on upper and lower confidence bounds that the players can use to select their optimal actions despite the asymmetry in the reward information. We show that this algorithm can achieve logarithmic $O(\\frac{\\log T}{\\Delta_{\\bm{a}}})$ (gap-dependent) regret as well as $O(\\sqrt{T\\log T})$ (gap-independent) regret. This is asymptotically optimal in $T$. We also show that it performs empirically better than the current state of the art algorithm for this environment.", "url": "https://arxiv.org/abs/2311.06210"}, {"metadata": {"arXiv": "2311.06228", "Date": "Fri, 10 Nov 2023 18:34:24 ", "Title": "Learning material synthesis-structure-property relationship by data fusion: Bayesian Co-regionalization N-Dimensional Piecewise Function Learning", "Authors": ["A. Gilad Kusne", "Austin McDannald", "Brian DeCost"], "Categories": "cs.LG cond-mat.mtrl-sci"}, "abstract": "Advanced materials are needed to further next-generation technologies such as quantum computing, carbon capture, and low-cost medical imaging. However, advanced materials discovery is confounded by two fundamental challenges: the challenge of a high-dimensional, complex materials search space and the challenge of combining knowledge, i.e., data fusion across instruments and labs. To overcome the first challenge, researchers employ knowledge of the underlying material synthesis-structure-property relationship, as a material's structure is often predictive of its functional property and vice versa. For example, optimal materials often occur along composition-phase boundaries or within specific phase regions. Additionally, knowledge of the synthesis-structure-property relationship is fundamental to understanding underlying physical mechanisms. However, quantifying the synthesis-structure-property relationship requires overcoming the second challenge. Researchers must merge knowledge gathered across instruments, measurement modalities, and even laboratories. We present the Synthesis-structure-property relAtionship coreGionalized lEarner (SAGE) algorithm. A fully Bayesian algorithm that uses multimodal coregionalization to merge knowledge across data sources to learn synthesis-structure-property relationships.", "url": "https://arxiv.org/abs/2311.06228"}, {"metadata": {"arXiv": "2311.06234", "Date": "Fri, 10 Nov 2023 18:49:53 ", "Title": "EVORA: Deep Evidential Traversability Learning for Risk-Aware Off-Road Autonomy", "Authors": ["Xiaoyi Cai", "Siddharth Ancha", "Lakshay Sharma", "Philip R. Osteen", "Bernadette Bucher", "Stephen Phillips", "Jiuguang Wang", "Michael Everett", "Nicholas Roy", "Jonathan P. How"], "Categories": "cs.RO cs.LG cs.SY eess.SY", "Comments": ["Under review. Journal extension for arXiv:2210.00153. Project website: https://xiaoyi-cai.github.io/evora/"]}, "abstract": "Traversing terrain with good traction is crucial for achieving fast off-road navigation. Instead of manually designing costs based on terrain features, existing methods learn terrain properties directly from data via self-supervision, but challenges remain to properly quantify and mitigate risks due to uncertainties in learned models. This work efficiently quantifies both aleatoric and epistemic uncertainties by learning discrete traction distributions and probability densities of the traction predictor's latent features. Leveraging evidential deep learning, we parameterize Dirichlet distributions with the network outputs and propose a novel uncertainty-aware squared Earth Mover's distance loss with a closed-form expression that improves learning accuracy and navigation performance. The proposed risk-aware planner simulates state trajectories with the worst-case expected traction to handle aleatoric uncertainty, and penalizes trajectories moving through terrain with high epistemic uncertainty. Our approach is extensively validated in simulation and on wheeled and quadruped robots, showing improved navigation performance compared to methods that assume no slip, assume the expected traction, or optimize for the worst-case expected cost.", "url": "https://arxiv.org/abs/2311.06234"}, {"metadata": {"arXiv": "2311.05780", "Date": "Thu, 09 Nov 2023 22:57:21 ", "Title": "Real-time Control of Electric Autonomous Mobility-on-Demand Systems via Graph Reinforcement Learning", "Authors": ["Aaryan Singhal", "Daniele Gammelli", "Justin Luke", "Karthik Gopalakrishnan", "Dominik Helmreich", "Marco Pavone"], "Categories": "eess.SY cs.LG cs.RO cs.SY", "Comments": ["9 pages"]}, "abstract": "Operators of Electric Autonomous Mobility-on-Demand (E-AMoD) fleets need to make several real-time decisions such as matching available cars to ride requests, rebalancing idle cars to areas of high demand, and charging vehicles to ensure sufficient range. While this problem can be posed as a linear program that optimizes flows over a space-charge-time graph, the size of the resulting optimization problem does not allow for real-time implementation in realistic settings. In this work, we present the E-AMoD control problem through the lens of reinforcement learning and propose a graph network-based framework to achieve drastically improved scalability and superior performance over heuristics. Specifically, we adopt a bi-level formulation where we (1) leverage a graph network-based RL agent to specify a desired next state in the space-charge graph, and (2) solve more tractable linear programs to best achieve the desired state while ensuring feasibility. Experiments using real-world data from San Francisco and New York City show that our approach achieves up to 89% of the profits of the theoretically-optimal solution while achieving more than a 100x speedup in computational time. Furthermore, our approach outperforms the best domain-specific heuristics with comparable runtimes, with an increase in profits by up to 3x. Finally, we highlight promising zero-shot transfer capabilities of our learned policy on tasks such as inter-city generalization and service area expansion, thus showing the utility, scalability, and flexibility of our framework.", "url": "https://arxiv.org/abs/2311.05780"}, {"metadata": {"arXiv": "2311.05941", "Date": "Fri, 10 Nov 2023 08:54:51 ", "Title": "Learning-Augmented Scheduling for Solar-Powered Electric Vehicle Charging", "Authors": ["Tongxin Li"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "We tackle the complex challenge of scheduling the charging of electric vehicles (EVs) equipped with solar panels and batteries, particularly under out-of-distribution (OOD) conditions. Traditional scheduling approaches, such as reinforcement learning (RL) and model predictive control (MPC), often fail to provide satisfactory results when faced with OOD data, struggling to balance robustness (worst-case performance) and consistency (near-optimal average performance). To address this gap, we introduce a novel learning-augmented policy. This policy employs a dynamic robustness budget, which is adapted in real-time based on the reinforcement learning policy's performance. Specifically, it leverages the temporal difference (TD) error, a measure of the learning policy's prediction accuracy, to assess the trustworthiness of the machine-learned policy. This method allows for a more effective balance between consistency and robustness in EV charging schedules, significantly enhancing adaptability and efficiency in real-world, unpredictable environments. Our results demonstrate that this approach markedly improves scheduling effectiveness and reliability, particularly in OOD contexts, paving the way for more resilient and adaptive EV charging systems.", "url": "https://arxiv.org/abs/2311.05941"}, {"metadata": {"arXiv": "2311.05662", "Date": "Thu, 09 Nov 2023 08:57:39 ", "Title": "An Experiment in Retrofitting Competency Questions for Existing Ontologies", "Authors": ["Reham Alharbi and Valentina Tamma and Floriana Grasso and Terry Payne"], "Categories": "cs.AI"}, "abstract": "Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community. In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies.", "url": "https://arxiv.org/abs/2311.05662"}, {"metadata": {"arXiv": "2311.05804", "Date": "Fri, 10 Nov 2023 00:35:00 ", "Title": "Model-as-a-Service (MaaS): A Survey", "Authors": ["Wensheng Gan", "Shicheng Wan", "Philip S. Yu"], "Categories": "cs.AI", "Comments": ["Preprint. 3 figures", "1 tables"]}, "abstract": "Due to the increased number of parameters and data in the pre-trained model exceeding a certain level, a foundation model (e.g., a large language model) can significantly improve downstream task performance and emerge with some novel special abilities (e.g., deep learning, complex reasoning, and human alignment) that were not present before. Foundation models are a form of generative artificial intelligence (GenAI), and Model-as-a-Service (MaaS) has emerged as a groundbreaking paradigm that revolutionizes the deployment and utilization of GenAI models. MaaS represents a paradigm shift in how we use AI technologies and provides a scalable and accessible solution for developers and users to leverage pre-trained AI models without the need for extensive infrastructure or expertise in model training. In this paper, the introduction aims to provide a comprehensive overview of MaaS, its significance, and its implications for various industries. We provide a brief review of the development history of \"X-as-a-Service\" based on cloud computing and present the key technologies involved in MaaS. The development of GenAI models will become more democratized and flourish. We also review recent application studies of MaaS. Finally, we highlight several challenges and future issues in this promising area. MaaS is a new deployment and service paradigm for different AI-based models. We hope this review will inspire future research in the field of MaaS.", "url": "https://arxiv.org/abs/2311.05804"}, {"metadata": {"arXiv": "2311.05851", "Date": "Fri, 10 Nov 2023 03:15:17 ", "Title": "Cognitive Architecture Toward Common Ground Sharing Among Humans and Generative AIs: Trial on Model-Model Interactions in Tangram Naming Task", "Authors": ["Junya Morita", "Tatsuya Yui", "Takeru Amaya", "Ryuichiro Higashinaka", "Yugo Takeuchi"], "Categories": "cs.AI", "Comments": ["Proceedings of the 2023 AAAI Fall Symposium on Integrating Cognitive Architectures and Generative Models"]}, "abstract": "For generative AIs to be trustworthy, establishing transparent common grounding with humans is essential. As a preparation toward human-model common grounding, this study examines the process of model-model common grounding. In this context, common ground is defined as a cognitive framework shared among agents in communication, enabling the connection of symbols exchanged between agents to the meanings inherent in each agent. This connection is facilitated by a shared cognitive framework among the agents involved. In this research, we focus on the tangram naming task (TNT) as a testbed to examine the common-ground-building process. Unlike previous models designed for this task, our approach employs generative AIs to visualize the internal processes of the model. In this task, the sender constructs a metaphorical image of an abstract figure within the model and generates a detailed description based on this image. The receiver interprets the generated description from the partner by constructing another image and reconstructing the original abstract figure. Preliminary results from the study show an improvement in task performance beyond the chance level, indicating the effect of the common cognitive framework implemented in the models. Additionally, we observed that incremental backpropagations leveraging successful communication cases for a component of the model led to a statistically significant increase in performance. These results provide valuable insights into the mechanisms of common grounding made by generative AIs, improving human communication with the evolving intelligent machines in our future society.", "url": "https://arxiv.org/abs/2311.05851"}, {"metadata": {"arXiv": "2311.05853", "Date": "Fri, 10 Nov 2023 03:25:53 ", "Title": "Reframing Audience Expansion through the Lens of Probability Density Estimation", "Authors": ["Claudio Carvalhaes"], "Categories": "cs.AI", "Comments": ["12 pages"]}, "abstract": "Audience expansion has become an important element of prospective marketing, helping marketers create target audiences based on a mere representative sample of their current customer base. Within the realm of machine learning, a favored algorithm for scaling this sample into a broader audience hinges on a binary classification task, with class probability estimates playing a crucial role. In this paper, we review this technique and introduce a key change in how we choose training examples to ensure the quality of the generated audience. We present a simulation study based on the widely used MNIST dataset, where consistent high precision and recall values demonstrate our approach's ability to identify the most relevant users for an expanded audience. Our results are easily reproducible and a Python implementation is openly available on GitHub: \\url{https://github.com/carvalhaes-ai/audience-expansion}", "url": "https://arxiv.org/abs/2311.05853"}, {"metadata": {"arXiv": "2311.05997", "Date": "Fri, 10 Nov 2023 11:17:58 ", "Title": "JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models", "Authors": ["Zihao Wang", "Shaofei Cai", "Anji Liu", "Yonggang Jin", "Jinbing Hou", "Bowei Zhang", "Haowei Lin", "Zhaofeng He", "Zilong Zheng", "Yaodong Yang", "Xiaojian Ma", "Yitao Liang"], "Categories": "cs.AI"}, "abstract": "Achieving human-like planning and control with multimodal observations in an open world is a key milestone for more functional generalist agents. Existing approaches can handle certain long-horizon tasks in an open world. However, they still struggle when the number of open-world tasks could potentially be infinite and lack the capability to progressively enhance task completion as game time progresses. We introduce JARVIS-1, an open-world agent that can perceive multimodal input (visual observations and human instructions), generate sophisticated plans, and perform embodied control, all within the popular yet challenging open-world Minecraft universe. Specifically, we develop JARVIS-1 on top of pre-trained multimodal language models, which map visual observations and textual instructions to plans. The plans will be ultimately dispatched to the goal-conditioned controllers. We outfit JARVIS-1 with a multimodal memory, which facilitates planning using both pre-trained knowledge and its actual game survival experiences. In our experiments, JARVIS-1 exhibits nearly perfect performances across over 200 varying tasks from the Minecraft Universe Benchmark, ranging from entry to intermediate levels. JARVIS-1 has achieved a completion rate of 12.5% in the long-horizon diamond pickaxe task. This represents a significant increase up to 5 times compared to previous records. Furthermore, we show that JARVIS-1 is able to $\\textit{self-improve}$ following a life-long learning paradigm thanks to multimodal memory, sparking a more general intelligence and improved autonomy. The project page is available at https://craftjarvis-jarvis1.github.io.", "url": "https://arxiv.org/abs/2311.05997"}, {"metadata": {"arXiv": "2311.06063", "Date": "Fri, 10 Nov 2023 13:56:15 ", "Title": "RIGA: A Regret-Based Interactive Genetic Algorithm", "Authors": ["Nawal Benabbou and Cassandre Leroy and Thibaut Lust"], "Categories": "cs.AI cs.DM"}, "abstract": "In this paper, we propose an interactive genetic algorithm for solving multi-objective combinatorial optimization problems under preference imprecision. More precisely, we consider problems where the decision maker's preferences over solutions can be represented by a parameterized aggregation function (e.g., a weighted sum, an OWA operator, a Choquet integral), and we assume that the parameters are initially not known by the recommendation system. In order to quickly make a good recommendation, we combine elicitation and search in the following way: 1) we use regret-based elicitation techniques to reduce the parameter space in a efficient way, 2) genetic operators are applied on parameter instances (instead of solutions) to better explore the parameter space, and 3) we generate promising solutions (population) using existing solving methods designed for the problem with known preferences. Our algorithm, called RIGA, can be applied to any multi-objective combinatorial optimization problem provided that the aggregation function is linear in its parameters and that a (near-)optimal solution can be efficiently determined for the problem with known preferences. We also study its theoretical performances: RIGA can be implemented in such way that it runs in polynomial time while asking no more than a polynomial number of queries. The method is tested on the multi-objective knapsack and traveling salesman problems. For several performance indicators (computation times, gap to optimality and number of queries), RIGA obtains better results than state-of-the-art algorithms.", "url": "https://arxiv.org/abs/2311.06063"}, {"metadata": {"arXiv": "2311.06175", "Date": "Fri, 10 Nov 2023 16:47:56 ", "Title": "Search-Based Fairness Testing: An Overview", "Authors": ["Hussaini Mamman", "Shuib Basri", "Abdullateef Oluwaqbemiga Balogun", "Abdullahi Abubakar Imam", "Ganesh Kumar", "Luiz Fernando Capretz"], "Categories": "cs.AI", "Comments": ["IEEE International Conference on Computing (ICOCO 2023)", "Langkawi Island", "Malaysia", "pp. 89-94", "October 2023"], "Journal-ref": "IEEE International Conference on Computing (ICOCO 2023), Langkawi Island, Malaysia, pp. 89-94, October 2023"}, "abstract": "Artificial Intelligence (AI) has demonstrated remarkable capabilities in domains such as recruitment, finance, healthcare, and the judiciary. However, biases in AI systems raise ethical and societal concerns, emphasizing the need for effective fairness testing methods. This paper reviews current research on fairness testing, particularly its application through search-based testing. Our analysis highlights progress and identifies areas of improvement in addressing AI systems biases. Future research should focus on leveraging established search-based testing methodologies for fairness testing.", "url": "https://arxiv.org/abs/2311.06175"}, {"metadata": {"arXiv": "2311.05778", "Date": "Thu, 09 Nov 2023 22:49:05 ", "Title": "DONUT-hole: DONUT Sparsification by Harnessing Knowledge and Optimizing Learning Efficiency", "Authors": ["Azhar Shaikh and Michael Cochez and Denis Diachkov and Michiel de Rijcke and Sahar Yousefi"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper introduces DONUT-hole, a sparse OCR-free visual document understanding (VDU) model that addresses the limitations of its predecessor model, dubbed DONUT. The DONUT model, leveraging a transformer architecture, overcoming the challenges of separate optical character recognition (OCR) and visual semantic understanding (VSU) components. However, its deployment in production environments and edge devices is hindered by high memory and computational demands, particularly in large-scale request services. To overcome these challenges, we propose an optimization strategy based on knowledge distillation and model pruning. Our paradigm to produce DONUT-hole, reduces the model denisty by 54\\% while preserving performance. We also achieve a global representational similarity index between DONUT and DONUT-hole based on centered kernel alignment (CKA) metric of 0.79. Moreover, we evaluate the effectiveness of DONUT-hole in the document image key information extraction (KIE) task, highlighting its potential for developing more efficient VDU systems for logistic companies.", "url": "https://arxiv.org/abs/2311.05778"}, {"metadata": {"arXiv": "2311.05844", "Date": "Mon, 25 Sep 2023 13:46:00 ", "Title": "Face-StyleSpeech: Improved Face-to-Voice latent mapping for Natural Zero-shot Speech Synthesis from a Face Image", "Authors": ["Minki Kang", "Wooseok Han", "Eunho Yang"], "Categories": "cs.CV cs.AI cs.CL cs.MM cs.SD eess.AS", "Comments": ["Submitted to ICASSP 2024"]}, "abstract": "Generating a voice from a face image is crucial for developing virtual humans capable of interacting using their unique voices, without relying on pre-recorded human speech. In this paper, we propose Face-StyleSpeech, a zero-shot Text-To-Speech (TTS) synthesis model that generates natural speech conditioned on a face image rather than reference speech. We hypothesize that learning both speaker identity and prosody from a face image poses a significant challenge. To address the issue, our TTS model incorporates both a face encoder and a prosody encoder. The prosody encoder is specifically designed to model prosodic features that are not captured only with a face image, allowing the face encoder to focus solely on capturing the speaker identity from the face image. Experimental results demonstrate that Face-StyleSpeech effectively generates more natural speech from a face image than baselines, even for the face images the model has not trained. Samples are at our demo page https://face-stylespeech.github.io.", "url": "https://arxiv.org/abs/2311.05844"}, {"metadata": {"arXiv": "2311.06043", "Date": "Fri, 10 Nov 2023 13:03:37 ", "Title": "Deep learning for 3D Object Detection and Tracking in Autonomous Driving: A Brief Survey", "Authors": ["Yang Peng"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "8 figures"]}, "abstract": "Object detection and tracking are vital and fundamental tasks for autonomous driving, aiming at identifying and locating objects from those predefined categories in a scene. 3D point cloud learning has been attracting more and more attention among all other forms of self-driving data. Currently, there are many deep learning methods for 3D object detection. However, the tasks of object detection and tracking for point clouds still need intensive study due to the unique characteristics of point cloud data. To help get a good grasp of the present situation of this research, this paper shows recent advances in deep learning methods for 3D object detection and tracking.", "url": "https://arxiv.org/abs/2311.06043"}, {"metadata": {"arXiv": "2311.06015", "Date": "Fri, 10 Nov 2023 11:59:41 ", "Title": "RSG: Fast Learning Adaptive Skills for Quadruped Robots by Skill Graph", "Authors": ["Hongyin Zhang", "Diyuan Shi", "Zifeng Zhuang", "Han Zhao", "Zhenyu Wei", "Feng Zhao", "Sibo Gai", "Shangke Lyu", "and Donglin Wang"], "Categories": "cs.RO cs.AI"}, "abstract": "Developing robotic intelligent systems that can adapt quickly to unseen wild situations is one of the critical challenges in pursuing autonomous robotics. Although some impressive progress has been made in walking stability and skill learning in the field of legged robots, their ability to fast adaptation is still inferior to that of animals in nature. Animals are born with massive skills needed to survive, and can quickly acquire new ones, by composing fundamental skills with limited experience. Inspired by this, we propose a novel framework, named Robot Skill Graph (RSG) for organizing massive fundamental skills of robots and dexterously reusing them for fast adaptation. Bearing a structure similar to the Knowledge Graph (KG), RSG is composed of massive dynamic behavioral skills instead of static knowledge in KG and enables discovering implicit relations that exist in be-tween of learning context and acquired skills of robots, serving as a starting point for understanding subtle patterns existing in robots' skill learning. Extensive experimental results demonstrate that RSG can provide rational skill inference upon new tasks and environments and enable quadruped robots to adapt to new scenarios and learn new skills rapidly.", "url": "https://arxiv.org/abs/2311.06015"}, {"metadata": {"arXiv": "2311.06149", "Date": "Fri, 10 Nov 2023 16:09:01 ", "Title": "Dense Visual Odometry Using Genetic Algorithm", "Authors": ["Slimane Djema", "Zoubir Abdeslem Benselama", "Ramdane Hedjar", "Krabi Abdallah"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["9 pages", "9 figures"], "MSC-class": "I.2.9 Robotics, I.2.10 Vision and Scene Understanding (I.4.8, I.5),", "Journal-ref": "International Journal of Intelligent Systems and Applications in Engineering, Volume 11, issue 3, Pages 611-619, published date 2023/7/16"}, "abstract": "Our work aims to estimate the camera motion mounted on the head of a mobile robot or a moving object from RGB-D images in a static scene. The problem of motion estimation is transformed into a nonlinear least squares function. Methods for solving such problems are iterative. Various classic methods gave an iterative solution by linearizing this function. We can also use the metaheuristic optimization method to solve this problem and improve results. In this paper, a new algorithm is developed for visual odometry using a sequence of RGB-D images. This algorithm is based on a genetic algorithm. The proposed iterative genetic algorithm searches using particles to estimate the optimal motion and then compares it to the traditional methods. To evaluate our method, we use the root mean square error to compare it with the based energy method and another metaheuristic method. We prove the efficiency of our innovative algorithm on a large set of images.", "url": "https://arxiv.org/abs/2311.06149"}, {"metadata": {"arXiv": "2311.05657", "Date": "Thu, 09 Nov 2023 00:30:13 ", "Title": "Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs", "Authors": ["Da Yin", "Faeze Brahman", "Abhilasha Ravichander", "Khyathi Chandu", "Kai-Wei Chang", "Yejin Choi", "Bill Yuchen Lin"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Project website: https://allenai.github.io/lumos/"]}, "abstract": "We introduce Lumos, a novel framework for training language agents that employs a unified data format and a modular architecture based on open-source large language models (LLMs). Lumos consists of three distinct modules: planning, grounding, and execution. The planning module breaks down a task into a series of high-level, tool-agnostic subgoals, which are then made specific by the grounding module through a set of low-level actions. These actions are subsequently executed by the execution module, utilizing a range of off-the-shelf tools and APIs. In order to train these modules effectively, high-quality annotations of subgoals and actions were collected and are made available for fine-tuning open-source LLMs for various tasks such as complex question answering, web tasks, and math problems. Leveraging this unified data and modular design, Lumos not only achieves comparable or superior performance to current, state-of-the-art agents, but also exhibits several key advantages: (1) Lumos surpasses GPT-4/3.5-based agents in complex question answering and web tasks, while equalling the performance of significantly larger LLM agents on math tasks; (2) Lumos outperforms open-source agents created through conventional training methods and those using chain-of-thoughts training; and (3) Lumos is capable of effectively generalizing to unseen interactive tasks, outperforming larger LLM-based agents and even exceeding performance of specialized agents.", "url": "https://arxiv.org/abs/2311.05657"}, {"metadata": {"arXiv": "2311.05772", "Date": "Wed, 08 Nov 2023 17:59:15 ", "Title": "ADaPT: As-Needed Decomposition and Planning with Language Models", "Authors": ["Archiki Prasad", "Alexander Koller", "Mareike Hartmann", "Peter Clark", "Ashish Sabharwal", "Mohit Bansal", "Tushar Khot"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Project Page: https://allenai.github.io/adaptllm"]}, "abstract": "Large Language Models (LLMs) are increasingly being used for interactive decision-making tasks requiring planning and adapting to the environment. Recent works employ LLMs-as-agents in broadly two ways: iteratively determining the next action (iterative executors) or generating plans and executing sub-tasks using LLMs (plan-and-execute). However, these methods struggle with task complexity, as the inability to execute any sub-task may lead to task failure. To address these shortcomings, we introduce As-Needed Decomposition and Planning for complex Tasks (ADaPT), an approach that explicitly plans and decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity and LLM capability. Our results demonstrate that ADaPT substantially outperforms established strong baselines, achieving success rates up to 28.3% higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel compositional dataset that we introduce. Through extensive analysis, we illustrate the importance of multilevel decomposition and establish that ADaPT dynamically adjusts to the capabilities of the executor LLM as well as to task complexity.", "url": "https://arxiv.org/abs/2311.05772"}, {"metadata": {"arXiv": "2311.05784", "Date": "Thu, 09 Nov 2023 23:25:29 ", "Title": "Are \"Hierarchical\" Visual Representations Hierarchical?", "Authors": ["Ethan Shen", "Ali Farhadi", "Aditya Kusupati"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Learned visual representations often capture large amounts of semantic information for accurate downstream applications. Human understanding of the world is fundamentally grounded in hierarchy. To mimic this and further improve representation capabilities, the community has explored \"hierarchical\" visual representations that aim at modeling the underlying hierarchy of the visual world. In this work, we set out to investigate if hierarchical visual representations truly capture the human perceived hierarchy better than standard learned representations. To this end, we create HierNet, a suite of 12 datasets spanning 3 kinds of hierarchy from the BREEDs subset of ImageNet. After extensive evaluation of Hyperbolic and Matryoshka Representations across training setups, we conclude that they do not capture hierarchy any better than the standard representations but can assist in other aspects like search efficiency and interpretability. Our benchmark and the datasets are open-sourced at https://github.com/ethanlshen/HierNet.", "url": "https://arxiv.org/abs/2311.05784"}, {"metadata": {"arXiv": "2311.05992", "Date": "Fri, 10 Nov 2023 11:07:31 ", "Title": "Robust Adversarial Attacks Detection for Deep Learning based Relative Pose Estimation for Space Rendezvous", "Authors": ["Ziwei Wang", "Nabil Aouf", "Jose Pizarro", "Christophe Honvault"], "Categories": "cs.CV cs.AI cs.CR cs.LG cs.RO"}, "abstract": "Research on developing deep learning techniques for autonomous spacecraft relative navigation challenges is continuously growing in recent years. Adopting those techniques offers enhanced performance. However, such approaches also introduce heightened apprehensions regarding the trustability and security of such deep learning methods through their susceptibility to adversarial attacks. In this work, we propose a novel approach for adversarial attack detection for deep neural network-based relative pose estimation schemes based on the explainability concept. We develop for an orbital rendezvous scenario an innovative relative pose estimation technique adopting our proposed Convolutional Neural Network (CNN), which takes an image from the chaser's onboard camera and outputs accurately the target's relative position and rotation. We perturb seamlessly the input images using adversarial attacks that are generated by the Fast Gradient Sign Method (FGSM). The adversarial attack detector is then built based on a Long Short Term Memory (LSTM) network which takes the explainability measure namely SHapley Value from the CNN-based pose estimator and flags the detection of adversarial attacks when acting. Simulation results show that the proposed adversarial attack detector achieves a detection accuracy of 99.21%. Both the deep relative pose estimator and adversarial attack detector are then tested on real data captured from our laboratory-designed setup. The experimental results from our laboratory-designed setup demonstrate that the proposed adversarial attack detector achieves an average detection accuracy of 96.29%.", "url": "https://arxiv.org/abs/2311.05992"}, {"metadata": {"arXiv": "2311.06224", "Date": "Fri, 10 Nov 2023 18:25:44 ", "Title": "Harnessing Synthetic Datasets: The Role of Shape Bias in Deep Neural Network Generalization", "Authors": ["Elior Benarous", "Sotiris Anagnostidis", "Luca Biggio", "Thomas Hofmann"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recent advancements in deep learning have been primarily driven by the use of large models trained on increasingly vast datasets. While neural scaling laws have emerged to predict network performance given a specific level of computational resources, the growing demand for expansive datasets raises concerns. To address this, a new research direction has emerged, focusing on the creation of synthetic data as a substitute. In this study, we investigate how neural networks exhibit shape bias during training on synthetic datasets, serving as an indicator of the synthetic data quality. Specifically, our findings indicate three key points: (1) Shape bias varies across network architectures and types of supervision, casting doubt on its reliability as a predictor for generalization and its ability to explain differences in model recognition compared to human capabilities. (2) Relying solely on shape bias to estimate generalization is unreliable, as it is entangled with diversity and naturalism. (3) We propose a novel interpretation of shape bias as a tool for estimating the diversity of samples within a dataset. Our research aims to clarify the implications of using synthetic data and its associated shape bias in deep learning, addressing concerns regarding generalization and dataset quality.", "url": "https://arxiv.org/abs/2311.06224"}, {"metadata": {"arXiv": "2311.05659", "Date": "Thu, 09 Nov 2023 03:17:03 ", "Title": "Enhancing Instance-Level Image Classification with Set-Level Labels", "Authors": ["Renyu Zhang", "Aly A. Khan", "Yuxin Chen", "Robert L. Grossman"], "Categories": "cs.LG cs.AI"}, "abstract": "Instance-level image classification tasks have traditionally relied on single-instance labels to train models, e.g., few-shot learning and transfer learning. However, set-level coarse-grained labels that capture relationships among instances can provide richer information in real-world scenarios. In this paper, we present a novel approach to enhance instance-level image classification by leveraging set-level labels. We provide a theoretical analysis of the proposed method, including recognition conditions for fast excess risk rate, shedding light on the theoretical foundations of our approach. We conducted experiments on two distinct categories of datasets: natural image datasets and histopathology image datasets. Our experimental results demonstrate the effectiveness of our approach, showcasing improved classification performance compared to traditional single-instance label-based methods. Notably, our algorithm achieves 13% improvement in classification accuracy compared to the strongest baseline on the histopathology image classification benchmarks. Importantly, our experimental findings align with the theoretical analysis, reinforcing the robustness and reliability of our proposed method. This work bridges the gap between instance-level and set-level image classification, offering a promising avenue for advancing the capabilities of image classification models with set-level coarse-grained labels.", "url": "https://arxiv.org/abs/2311.05659"}, {"metadata": {"arXiv": "2311.05665", "Date": "Thu, 09 Nov 2023 11:43:10 ", "Title": "Explainable artificial intelligence for Healthcare applications using Random Forest Classifier with LIME and SHAP", "Authors": ["Mrutyunjaya Panda", "Soumya Ranjan Mahanta"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["Chapter-6: Accepted Book Chapter in: Transparent", "Interpretable and Explainable AI Systems", "BK Tripathy & Hari Seetha (Editors)", "CRC Press", "May 2023"]}, "abstract": "With the advances in computationally efficient artificial Intelligence (AI) techniques and their numerous applications in our everyday life, there is a pressing need to understand the computational details hidden in black box AI techniques such as most popular machine learning and deep learning techniques; through more detailed explanations. The origin of explainable AI (xAI) is coined from these challenges and recently gained more attention by the researchers by adding explainability comprehensively in traditional AI systems. This leads to develop an appropriate framework for successful applications of xAI in real life scenarios with respect to innovations, risk mitigation, ethical issues and logical values to the users. In this book chapter, an in-depth analysis of several xAI frameworks and methods including LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) are provided. Random Forest Classifier as black box AI is used on a publicly available Diabetes symptoms dataset with LIME and SHAP for better interpretations. The results obtained are interesting in terms of transparency, valid and trustworthiness in diabetes disease prediction.", "url": "https://arxiv.org/abs/2311.05665"}, {"metadata": {"arXiv": "2311.05667", "Date": "Thu, 09 Nov 2023 14:08:41 ", "Title": "A theory for the sparsity emerged in the Forward Forward algorithm", "Authors": ["Yukun Yang"], "Categories": "cs.LG cs.AI"}, "abstract": "This report explores the theory that explains the high sparsity phenomenon \\citep{tosato2023emergent} observed in the forward-forward algorithm \\citep{hinton2022forward}. The two theorems proposed predict the sparsity changes of a single data point's activation in two cases: Theorem \\ref{theorem:1}: Decrease the goodness of the whole batch. Theorem \\ref{theorem:2}: Apply the complete forward forward algorithm to decrease the goodness for negative data and increase the goodness for positive data. The theory aligns well with the experiments tested on the MNIST dataset.", "url": "https://arxiv.org/abs/2311.05667"}, {"metadata": {"arXiv": "2311.05740", "Date": "Thu, 09 Nov 2023 20:53:00 ", "Title": "Generating Pragmatic Examples to Train Neural Program Synthesizers", "Authors": ["Saujas Vaduguru", "Daniel Fried", "Yewen Pu"], "Categories": "cs.LG cs.AI cs.PL"}, "abstract": "Programming-by-example is the task of synthesizing a program that is consistent with a set of user-provided input-output examples. As examples are often an under-specification of one's intent, a good synthesizer must choose the intended program from the many that are consistent with the given set of examples. Prior work frames program synthesis as a cooperative game between a listener (that synthesizes programs) and a speaker (a user choosing examples), and shows that models of computational pragmatic inference are effective in choosing the user intended programs. However, these models require counterfactual reasoning over a large set of programs and examples, which is infeasible in realistic program spaces. In this paper, we propose a novel way to amortize this search with neural networks. We sample pairs of programs and examples via self-play between listener and speaker models, and use pragmatic inference to choose informative training examples from this sample.We then use the informative dataset to train models to improve the synthesizer's ability to disambiguate user-provided examples without human supervision. We validate our method on the challenging task of synthesizing regular expressions from example strings, and find that our method (1) outperforms models trained without choosing pragmatic examples by 23% (a 51% relative increase) (2) matches the performance of supervised learning on a dataset of pragmatic examples provided by humans, despite using no human data in training.", "url": "https://arxiv.org/abs/2311.05740"}, {"metadata": {"arXiv": "2311.05790", "Date": "Thu, 09 Nov 2023 23:36:18 ", "Title": "The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning", "Authors": ["Elaheh Jafarigol", "Theodore Trafalis"], "Categories": "cs.LG cs.AI"}, "abstract": "In a data-centric era, concerns regarding privacy and ethical data handling grow as machine learning relies more on personal information. This empirical study investigates the privacy, generalization, and stability of deep learning models in the presence of additive noise in federated learning frameworks. Our main objective is to provide strategies to measure the generalization, stability, and privacy-preserving capabilities of these models and further improve them. To this end, five noise infusion mechanisms at varying noise levels within centralized and federated learning settings are explored. As model complexity is a key component of the generalization and stability of deep learning models during training and evaluation, a comparative analysis of three Convolutional Neural Network (CNN) architectures is provided. The paper introduces Signal-to-Noise Ratio (SNR) as a quantitative measure of the trade-off between privacy and training accuracy of noise-infused models, aiming to find the noise level that yields optimal privacy and accuracy. Moreover, the Price of Stability and Price of Anarchy are defined in the context of privacy-preserving deep learning, contributing to the systematic investigation of the noise infusion strategies to enhance privacy without compromising performance. Our research sheds light on the delicate balance between these critical factors, fostering a deeper understanding of the implications of noise-based regularization in machine learning. By leveraging noise as a tool for regularization and privacy enhancement, we aim to contribute to the development of robust, privacy-aware algorithms, ensuring that AI-driven solutions prioritize both utility and privacy.", "url": "https://arxiv.org/abs/2311.05790"}, {"metadata": {"arXiv": "2311.05877", "Date": "Fri, 10 Nov 2023 05:26:10 ", "Title": "A Performance-Driven Benchmark for Feature Selection in Tabular Deep Learning", "Authors": ["Valeriia Cherepanova", "Roman Levin", "Gowthami Somepalli", "Jonas Geiping", "C. Bayan Bruss", "Andrew Gordon Wilson", "Tom Goldstein", "Micah Goldblum"], "Categories": "cs.LG cs.AI", "Journal-ref": "Conference on Neural Information Processing Systems 2023"}, "abstract": "Academic tabular benchmarks often contain small sets of curated features. In contrast, data scientists typically collect as many features as possible into their datasets, and even engineer new features from existing ones. To prevent overfitting in subsequent downstream modeling, practitioners commonly use automated feature selection methods that identify a reduced subset of informative features. Existing benchmarks for tabular feature selection consider classical downstream models, toy synthetic datasets, or do not evaluate feature selectors on the basis of downstream performance. Motivated by the increasing popularity of tabular deep learning, we construct a challenging feature selection benchmark evaluated on downstream neural networks including transformers, using real datasets and multiple methods for generating extraneous features. We also propose an input-gradient-based analogue of Lasso for neural networks that outperforms classical feature selection methods on challenging problems such as selecting from corrupted or second-order features.", "url": "https://arxiv.org/abs/2311.05877"}, {"metadata": {"arXiv": "2311.05931", "Date": "Fri, 10 Nov 2023 08:38:18 ", "Title": "Anytime-Valid Confidence Sequences for Consistent Uncertainty Estimation in Early-Exit Neural Networks", "Authors": ["Metod Jazbec and Patrick Forr\\'e and Stephan Mandt and Dan Zhang and Eric Nalisnick"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Early-exit neural networks (EENNs) facilitate adaptive inference by producing predictions at multiple stages of the forward pass. In safety-critical applications, these predictions are only meaningful when complemented with reliable uncertainty estimates. Yet, due to their sequential structure, an EENN's uncertainty estimates should also be consistent: labels that are deemed improbable at one exit should not reappear within the confidence interval / set of later exits. We show that standard uncertainty quantification techniques, like Bayesian methods or conformal prediction, can lead to inconsistency across exits. We address this problem by applying anytime-valid confidence sequences (AVCSs) to the exits of EENNs. By design, AVCSs maintain consistency across exits. We examine the theoretical and practical challenges of applying AVCSs to EENNs and empirically validate our approach on both regression and classification tasks.", "url": "https://arxiv.org/abs/2311.05931"}, {"metadata": {"arXiv": "2311.06152", "Date": "Fri, 10 Nov 2023 16:12:35 ", "Title": "Going beyond persistent homology using persistent homology", "Authors": ["Johanna Immonen", "Amauri H. Souza", "Vikas Garg"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Representational limits of message-passing graph neural networks (MP-GNNs), e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well understood. Augmenting these graph models with topological features via persistent homology (PH) has gained prominence, but identifying the class of attributed graphs that PH can recognize remains open. We introduce a novel concept of color-separating sets to provide a complete resolution to this important problem. Specifically, we establish the necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components, obtained from filter functions on vertex and edge colors. Our constructions expose the limits of vertex- and edge-level PH, proving that neither category subsumes the other. Leveraging these theoretical insights, we propose RePHINE for learning topological features on graphs. RePHINE efficiently combines vertex- and edge-level PH, achieving a scheme that is provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their expressive power, resulting in gains over standard PH on several benchmarks for graph classification.", "url": "https://arxiv.org/abs/2311.06152"}, {"metadata": {"arXiv": "2311.06184", "Date": "Fri, 10 Nov 2023 17:05:13 ", "Title": "Frequency-domain MLPs are More Effective Learners in Time Series Forecasting", "Authors": ["Kun Yi", "Qi Zhang", "Wei Fan", "Shoujin Wang", "Pengyang Wang", "Hui He", "Defu Lian", "Ning An", "Longbing Cao", "Zhendong Niu"], "Categories": "cs.LG cs.AI"}, "abstract": "Time series forecasting has played the key role in different industrial, including finance, traffic, energy, and healthcare domains. While existing literatures have designed many sophisticated architectures based on RNNs, GNNs, or Transformers, another kind of approaches based on multi-layer perceptrons (MLPs) are proposed with simple structure, low complexity, and {superior performance}. However, most MLP-based forecasting methods suffer from the point-wise mappings and information bottleneck, which largely hinders the forecasting performance. To overcome this problem, we explore a novel direction of applying MLPs in the frequency domain for time series forecasting. We investigate the learned patterns of frequency-domain MLPs and discover their two inherent characteristic benefiting forecasting, (i) global view: frequency spectrum makes MLPs own a complete view for signals and learn global dependencies more easily, and (ii) energy compaction: frequency-domain MLPs concentrate on smaller key part of frequency components with compact signal energy. Then, we propose FreTS, a simple yet effective architecture built upon Frequency-domain MLPs for Time Series forecasting. FreTS mainly involves two stages, (i) Domain Conversion, that transforms time-domain signals into complex numbers of frequency domain; (ii) Frequency Learning, that performs our redesigned MLPs for the learning of real and imaginary part of frequency components. The above stages operated on both inter-series and intra-series scales further contribute to channel-wise and time-wise dependency learning. Extensive experiments on 13 real-world benchmarks (including 7 benchmarks for short-term forecasting and 6 benchmarks for long-term forecasting) demonstrate our consistent superiority over state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.06184"}, {"metadata": {"arXiv": "2311.06190", "Date": "Fri, 10 Nov 2023 17:13:26 ", "Title": "FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective", "Authors": ["Kun Yi", "Qi Zhang", "Wei Fan", "Hui He", "Liang Hu", "Pengyang Wang", "Ning An", "Longbing Cao", "Zhendong Niu"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2210.03093"]}, "abstract": "Multivariate time series (MTS) forecasting has shown great importance in numerous industries. Current state-of-the-art graph neural network (GNN)-based forecasting methods usually require both graph networks (e.g., GCN) and temporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics and intra-series (temporal) dependencies, respectively. However, the uncertain compatibility of the two networks puts an extra burden on handcrafted model designs. Moreover, the separate spatial and temporal modeling naturally violates the unified spatiotemporal inter-dependencies in real world, which largely hinders the forecasting performance. To overcome these problems, we explore an interesting direction of directly applying graph networks and rethink MTS forecasting from a pure graph perspective. We first define a novel data structure, hypervariate graph, which regards each series value (regardless of variates or timestamps) as a graph node, and represents sliding windows as space-time fully-connected graphs. This perspective considers spatiotemporal dynamics unitedly and reformulates classic MTS forecasting into the predictions on hypervariate graphs. Then, we propose a novel architecture Fourier Graph Neural Network (FourierGNN) by stacking our proposed Fourier Graph Operator (FGO) to perform matrix multiplications in Fourier space. FourierGNN accommodates adequate expressiveness and achieves much lower complexity, which can effectively and efficiently accomplish the forecasting. Besides, our theoretical analysis reveals FGO's equivalence to graph convolutions in the time domain, which further verifies the validity of FourierGNN. Extensive experiments on seven datasets have demonstrated our superior performance with higher efficiency and fewer parameters compared with state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.06190"}, {"metadata": {"arXiv": "2311.06192", "Date": "Fri, 10 Nov 2023 17:16:18 ", "Title": "Greedy PIG: Adaptive Integrated Gradients", "Authors": ["Kyriakos Axiotis", "Sami Abu-al-haija", "Lin Chen", "Matthew Fahrbach", "Gang Fu"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Deep learning has become the standard approach for most machine learning tasks. While its impact is undeniable, interpreting the predictions of deep learning models from a human perspective remains a challenge. In contrast to model training, model interpretability is harder to quantify and pose as an explicit optimization problem. Inspired by the AUC softmax information curve (AUC SIC) metric for evaluating feature attribution methods, we propose a unified discrete optimization framework for feature attribution and feature selection based on subset selection. This leads to a natural adaptive generalization of the path integrated gradients (PIG) method for feature attribution, which we call Greedy PIG. We demonstrate the success of Greedy PIG on a wide variety of tasks, including image feature attribution, graph compression/explanation, and post-hoc feature selection on tabular data. Our results show that introducing adaptivity is a powerful and versatile method for making attribution methods more powerful.", "url": "https://arxiv.org/abs/2311.06192"}, {"metadata": {"arXiv": "2311.06217", "Date": "Fri, 10 Nov 2023 18:13:08 ", "Title": "MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things", "Authors": ["Shentong Mo", "Paul Pu Liang", "Russ Salakhutdinov", "Louis-Philippe Morency"], "Categories": "cs.LG cs.AI cs.CL cs.CV cs.MM"}, "abstract": "The Internet of Things (IoT), the network integrating billions of smart physical devices embedded with sensors, software, and communication technologies for the purpose of connecting and exchanging data with other devices and systems, is a critical and rapidly expanding component of our modern world. The IoT ecosystem provides a rich source of real-world modalities such as motion, thermal, geolocation, imaging, depth, sensors, video, and audio for prediction tasks involving the pose, gaze, activities, and gestures of humans as well as the touch, contact, pose, 3D of physical objects. Machine learning presents a rich opportunity to automatically process IoT data at scale, enabling efficient inference for impact in understanding human wellbeing, controlling physical devices, and interconnecting smart cities. To develop machine learning technologies for IoT, this paper proposes MultiIoT, the most expansive IoT benchmark to date, encompassing over 1.15 million samples from 12 modalities and 8 tasks. MultiIoT introduces unique challenges involving (1) learning from many sensory modalities, (2) fine-grained interactions across long temporal ranges, and (3) extreme heterogeneity due to unique structure and noise topologies in real-world sensors. We also release a set of strong modeling baselines, spanning modality and task-specific methods to multisensory and multitask models to encourage future research in multisensory representation learning for IoT.", "url": "https://arxiv.org/abs/2311.06217"}, {"metadata": {"arXiv": "2311.06243", "Date": "Fri, 10 Nov 2023 18:59:54 ", "Title": "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization", "Authors": ["Weiyang Liu", "Zeju Qiu", "Yao Feng", "Yuliang Xiu", "Yuxuan Xue", "Longhui Yu", "Haiwen Feng", "Zhen Liu", "Juyeon Heo", "Songyou Peng", "Yandong Wen", "Michael J. Black", "Adrian Weller", "Bernhard Sch\\\"olkopf"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["Technical Report (33 pages", "18 figures)"]}, "abstract": "Large foundation models are becoming ubiquitous, but training them from scratch is prohibitively expensive. Thus, efficiently adapting these powerful models to downstream tasks is increasingly important. In this paper, we study a principled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream task adaptation. Despite demonstrating good generalizability, OFT still uses a fairly large number of trainable parameters due to the high dimensionality of orthogonal matrices. To address this, we start by examining OFT from an information transmission perspective, and then identify a few key desiderata that enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast Fourier transform algorithm enables efficient information transmission, we propose an efficient orthogonal parameterization using butterfly structures. We apply this parameterization to OFT, creating a novel parameter-efficient finetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a special case, BOFT introduces a generalized orthogonal finetuning framework. Finally, we conduct an extensive empirical study of adapting large vision transformers, large language models, and text-to-image diffusion models to various downstream tasks in vision and language.", "url": "https://arxiv.org/abs/2311.06243"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

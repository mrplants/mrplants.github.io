<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.06847", "Date": "Tue, 05 Sep 2023 18:14:14 ", "Title": "Performance Analysis of Various EfficientNet Based U-Net++ Architecture for Automatic Building Extraction from High Resolution Satellite Images", "Authors": ["Tareque Bashar Ovi", "Nomaiya Bashree", "Protik Mukherjee", "Shakil Mosharrof", "and Masuma Anjum Parthima"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["12 Pages,Keywords: Deep learning,satellite image,transfer learning,segmentation,deep supervision"]}, "abstract": "Building extraction is an essential component of study in the science of remote sensing, and applications for building extraction heavily rely on semantic segmentation of high-resolution remote sensing imagery. Semantic information extraction gap constraints in the present deep learning based approaches, however can result in inadequate segmentation outcomes. To address this issue and extract buildings with high accuracy, various efficientNet backbone based U-Net++ has been proposed in this study. The designed network, based on U-Net, can improve the sensitivity of the model by deep supervision, voluminous redesigned skip-connections and hence reducing the influence of irrelevant feature areas in the background. Various effecientNet backbone based encoders have been employed when training the network to enhance the capacity of the model to extract more relevant feature. According on the experimental findings, the suggested model significantly outperforms previous cutting-edge approaches. Among the 5 efficientNet variation Unet++ based on efficientb4 achieved the best result by scoring mean accuracy of 92.23%, mean iou of 88.32%, and mean precision of 93.2% on publicly available Massachusetts building dataset and thus showing the promises of the model for automatic building extraction from high resolution satellite images.", "url": "https://arxiv.org/abs/2310.06847"}, {"metadata": {"arXiv": "2310.06958", "Date": "Tue, 10 Oct 2023 19:21:41 ", "Title": "Comparing the robustness of modern no-reference image- and video-quality metrics to adversarial attacks", "Authors": ["Anastasia Antsiferova", "Khaled Abud", "Aleksandr Gushchin", "Sergey Lavrushkin", "Ekaterina Shumitskaya", "Maksim Velikanov", "Dmitriy Vatolin"], "Categories": "cs.CV cs.LG cs.MM eess.IV"}, "abstract": "Nowadays neural-network-based image- and video-quality metrics show better performance compared to traditional methods. However, they also became more vulnerable to adversarial attacks that increase metrics' scores without improving visual quality. The existing benchmarks of quality metrics compare their performance in terms of correlation with subjective quality and calculation time. However, the adversarial robustness of image-quality metrics is also an area worth researching. In this paper, we analyse modern metrics' robustness to different adversarial attacks. We adopted adversarial attacks from computer vision tasks and compared attacks' efficiency against 15 no-reference image/video-quality metrics. Some metrics showed high resistance to adversarial attacks which makes their usage in benchmarks safer than vulnerable metrics. The benchmark accepts new metrics submissions for researchers who want to make their metrics more robust to attacks or to find such metrics for their needs. Try our benchmark using pip install robustness-benchmark.", "url": "https://arxiv.org/abs/2310.06958"}, {"metadata": {"arXiv": "2310.06968", "Date": "Tue, 10 Oct 2023 19:46:58 ", "Title": "ObjectComposer: Consistent Generation of Multiple Objects Without Fine-tuning", "Authors": ["Alec Helbling", "Evan Montoya", "Duen Horng Chau"], "Categories": "cs.CV cs.LG"}, "abstract": "Recent text-to-image generative models can generate high-fidelity images from text prompts. However, these models struggle to consistently generate the same objects in different contexts with the same appearance. Consistent object generation is important to many downstream tasks like generating comic book illustrations with consistent characters and setting. Numerous approaches attempt to solve this problem by extending the vocabulary of diffusion models through fine-tuning. However, even lightweight fine-tuning approaches can be prohibitively expensive to run at scale and in real-time. We introduce a method called ObjectComposer for generating compositions of multiple objects that resemble user-specified images. Our approach is training-free, leveraging the abilities of preexisting models. We build upon the recent BLIP-Diffusion model, which can generate images of single objects specified by reference images. ObjectComposer enables the consistent generation of compositions containing multiple specific objects simultaneously, all without modifying the weights of the underlying models.", "url": "https://arxiv.org/abs/2310.06968"}, {"metadata": {"arXiv": "2310.06982", "Date": "Tue, 10 Oct 2023 20:04:44 ", "Title": "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality", "Authors": ["Xuxi Chen", "Yu Yang", "Zhangyang Wang", "Baharan Mirzasoleiman"], "Categories": "cs.CV cs.LG", "Comments": ["Preprint"]}, "abstract": "Dataset distillation aims to minimize the time and memory needed for training deep networks on large datasets, by creating a small set of synthetic images that has a similar generalization performance to that of the full dataset. However, current dataset distillation techniques fall short, showing a notable performance gap when compared to training on the original data. In this work, we are the first to argue that using just one synthetic subset for distillation will not yield optimal generalization performance. This is because the training dynamics of deep networks drastically change during the training. Hence, multiple synthetic subsets are required to capture the training dynamics at different phases of training. To address this issue, we propose Progressive Dataset Distillation (PDD). PDD synthesizes multiple small sets of synthetic images, each conditioned on the previous sets, and trains the model on the cumulative union of these subsets without requiring additional training time. Our extensive experiments show that PDD can effectively improve the performance of existing dataset distillation methods by up to 4.3%. In addition, our method for the first time enable generating considerably larger synthetic datasets.", "url": "https://arxiv.org/abs/2310.06982"}, {"metadata": {"arXiv": "2310.07027", "Date": "Tue, 10 Oct 2023 21:29:41 ", "Title": "Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images", "Authors": ["Che Liu", "Anand Shah", "Wenjia Bai", "Rossella Arcucci"], "Categories": "cs.CV cs.LG", "Comments": ["Under Review"]}, "abstract": "Medical Vision-Language Pre-training (VLP) learns representations jointly from medical images and paired radiology reports. It typically requires large-scale paired image-text datasets to achieve effective pre-training for both the image encoder and text encoder. The advent of text-guided generative models raises a compelling question: Can VLP be implemented solely with synthetic images generated from genuine radiology reports, thereby mitigating the need for extensively pairing and curating image-text datasets? In this work, we scrutinize this very question by examining the feasibility and effectiveness of employing synthetic images for medical VLP. We replace real medical images with their synthetic equivalents, generated from authentic medical reports. Utilizing three state-of-the-art VLP algorithms, we exclusively train on these synthetic samples. Our empirical evaluation across three subsequent tasks, namely image classification, semantic segmentation and object detection, reveals that the performance achieved through synthetic data is on par with or even exceeds that obtained with real images. As a pioneering contribution to this domain, we introduce a large-scale synthetic medical image dataset, paired with anonymized real radiology reports. This alleviates the need of sharing medical images, which are not easy to curate and share in practice. The code and the dataset will be made publicly available upon paper acceptance.", "url": "https://arxiv.org/abs/2310.07027"}, {"metadata": {"arXiv": "2310.07166", "Date": "Wed, 11 Oct 2023 03:29:13 ", "Title": "Anchor-based Multi-view Subspace Clustering with Hierarchical Feature Descent", "Authors": ["Qiyuan Ou", "Siwei Wang", "Pei Zhang", "Sihang Zhou", "En Zhu"], "Categories": "cs.CV cs.LG"}, "abstract": "Multi-view clustering has attracted growing attention owing to its capabilities of aggregating information from various sources and its promising horizons in public affairs. Up till now, many advanced approaches have been proposed in recent literature. However, there are several ongoing difficulties to be tackled. One common dilemma occurs while attempting to align the features of different views. We dig out as well as deploy the dependency amongst views through hierarchical feature descent, which leads to a common latent space( STAGE 1). This latent space, for the first time of its kind, is regarded as a 'resemblance space', as it reveals certain correlations and dependencies of different views. To be exact, the one-hot encoding of a category can also be referred to as a resemblance space in its terminal phase. Moreover, due to the intrinsic fact that most of the existing multi-view clustering algorithms stem from k-means clustering and spectral clustering, this results in cubic time complexity w.r.t. the number of the objects. However, we propose Anchor-based Multi-view Subspace Clustering with Hierarchical Feature Descent(MVSC-HFD) to further reduce the computing complexity to linear time cost through a unified sampling strategy in resemblance space( STAGE 2), followed by subspace clustering to learn the representation collectively( STAGE 3). Extensive experimental results on public benchmark datasets demonstrate that our proposed model consistently outperforms the state-of-the-art techniques.", "url": "https://arxiv.org/abs/2310.07166"}, {"metadata": {"arXiv": "2310.07184", "Date": "Wed, 11 Oct 2023 04:20:32 ", "Title": "NeuroInspect: Interpretable Neuron-based Debugging Framework through Class-conditional Visualizations", "Authors": ["Yeong-Joon Ju", "Ji-Hoon Park", "and Seong-Whan Lee"], "Categories": "cs.CV cs.LG", "Comments": ["Summitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)"]}, "abstract": "Despite deep learning (DL) has achieved remarkable progress in various domains, the DL models are still prone to making mistakes. This issue necessitates effective debugging tools for DL practitioners to interpret the decision-making process within the networks. However, existing debugging methods often demand extra data or adjustments to the decision process, limiting their applicability. To tackle this problem, we present NeuroInspect, an interpretable neuron-based debugging framework with three key stages: counterfactual explanations, feature visualizations, and false correlation mitigation. Our debugging framework first pinpoints neurons responsible for mistakes in the network and then visualizes features embedded in the neurons to be human-interpretable. To provide these explanations, we introduce CLIP-Illusion, a novel feature visualization method that generates images representing features conditioned on classes to examine the connection between neurons and the decision layer. We alleviate convoluted explanations of the conventional visualization approach by employing class information, thereby isolating mixed properties. This process offers more human-interpretable explanations for model errors without altering the trained network or requiring additional data. Furthermore, our framework mitigates false correlations learned from a dataset under a stochastic perspective, modifying decisions for the neurons considered as the main causes. We validate the effectiveness of our framework by addressing false correlations and improving inferences for classes with the worst performance in real-world settings. Moreover, we demonstrate that NeuroInspect helps debug the mistakes of DL models through evaluation for human understanding. The code is openly available at https://github.com/yeongjoonJu/NeuroInspect.", "url": "https://arxiv.org/abs/2310.07184"}, {"metadata": {"arXiv": "2310.07223", "Date": "Wed, 11 Oct 2023 06:13:50 ", "Title": "Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data", "Authors": ["Jos\\'e Rodr\\'iguez-Ortega (1 and 2)", "Rohaifa Khaldi (2)", "Domingo Alcaraz-Segura (3)", "Siham Tabik (1) ((1) Department of Computer Science and Artificial Intelligence", "DaSCI", "University of Granada", "Granada", "Spain", "(2) LifeWatch-ERIC ICT Core", "Seville", "Spain", "(3) Department of Botany", "Faculty of Science", "University of Granada", "Granada", "Spain)"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC) types. Spectral unmixing is a technique to extract information from mixed pixels into their constituent LULC types and corresponding abundance fractions. Traditionally, solving this task has relied on either classical methods that require prior knowledge of endmembers or machine learning methods that avoid explicit endmembers calculation, also known as blind spectral unmixing (BSU). Most BSU studies based on Deep Learning (DL) focus on one time-step hyperspectral data, yet its acquisition remains quite costly compared with multispectral data. To our knowledge, here we provide the first study on BSU of LULC classes using multispectral time series data with DL models. We further boost the performance of a Long-Short Term Memory (LSTM)-based model by incorporating geographic plus topographic (geo-topographic) and climatic ancillary information. Our experiments show that combining spectral-temporal input data together with geo-topographic and climatic information substantially improves the abundance estimation of LULC classes in mixed pixels. To carry out this study, we built a new labeled dataset of the region of Andalusia (Spain) with monthly multispectral time series of pixels for the year 2013 from MODIS at 460m resolution, for two hierarchical levels of LULC classes, named Andalusia MultiSpectral MultiTemporal Unmixing (Andalusia-MSMTU). This dataset provides, at the pixel level, a multispectral time series plus ancillary information annotated with the abundance of each LULC class inside each pixel. The dataset and code are available to the public.", "url": "https://arxiv.org/abs/2310.07223"}, {"metadata": {"arXiv": "2310.07245", "Date": "Wed, 11 Oct 2023 07:22:37 ", "Title": "Crowd Counting in Harsh Weather using Image Denoising with Pix2Pix GANs", "Authors": ["Muhammad Asif Khan", "Hamid Menouar and Ridha Hamila"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["The paper has been accepted for presentation in IEEE 38th International Conference on Image and Vision Computing New Zealand (IVCNZ 2023). The final manuscript can be accessed at ieeexplore"]}, "abstract": "Visual crowd counting estimates the density of the crowd using deep learning models such as convolution neural networks (CNNs). The performance of the model heavily relies on the quality of the training data that constitutes crowd images. In harsh weather such as fog, dust, and low light conditions, the inference performance may severely degrade on the noisy and blur images. In this paper, we propose the use of Pix2Pix generative adversarial network (GAN) to first denoise the crowd images prior to passing them to the counting model. A Pix2Pix network is trained using synthetic noisy images generated from original crowd images and then the pretrained generator is then used in the inference engine to estimate the crowd density in unseen, noisy crowd images. The performance is tested on JHU-Crowd dataset to validate the significance of the proposed method particularly when high reliability and accuracy are required.", "url": "https://arxiv.org/abs/2310.07245"}, {"metadata": {"arXiv": "2310.07252", "Date": "Wed, 11 Oct 2023 07:30:01 ", "Title": "A Comparative Study of Pre-trained CNNs and GRU-Based Attention for Image Caption Generation", "Authors": ["Rashid Khan", "Bingding Huang", "Haseeb Hassan", "Asim Zaman", "Zhongfu Ye"], "Categories": "cs.CV cs.LG", "Comments": ["15pages", "10 figures", "5 tables. 2023 the 5th International Conference on Robotics and Computer Vision (ICRCV 2023). arXiv admin note: substantial text overlap with arXiv:2203.01594"]}, "abstract": "Image captioning is a challenging task involving generating a textual description for an image using computer vision and natural language processing techniques. This paper proposes a deep neural framework for image caption generation using a GRU-based attention mechanism. Our approach employs multiple pre-trained convolutional neural networks as the encoder to extract features from the image and a GRU-based language model as the decoder to generate descriptive sentences. To improve performance, we integrate the Bahdanau attention model with the GRU decoder to enable learning to focus on specific image parts. We evaluate our approach using the MSCOCO and Flickr30k datasets and show that it achieves competitive scores compared to state-of-the-art methods. Our proposed framework can bridge the gap between computer vision and natural language and can be extended to specific domains.", "url": "https://arxiv.org/abs/2310.07252"}, {"metadata": {"arXiv": "2310.07355", "Date": "Wed, 11 Oct 2023 10:12:43 ", "Title": "IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training", "Authors": ["Che Liu", "Sibo Cheng", "Miaojing Shi", "Anand Shah", "Wenjia Bai", "Rossella Arcucci"], "Categories": "cs.CV cs.LG", "Comments": ["Under Review"]}, "abstract": "In the field of medical Vision-Language Pre-training (VLP), significant efforts have been devoted to deriving text and image features from both clinical reports and associated medical images. However, most existing methods may have overlooked the opportunity in leveraging the inherent hierarchical structure of clinical reports, which are generally split into `findings' for descriptive content and `impressions' for conclusive observation. Instead of utilizing this rich, structured format, current medical VLP approaches often simplify the report into either a unified entity or fragmented tokens. In this work, we propose a novel clinical prior guided VLP framework named IMITATE to learn the structure information from medical reports with hierarchical vision-language alignment. The framework derives multi-level visual features from the chest X-ray (CXR) images and separately aligns these features with the descriptive and the conclusive text encoded in the hierarchical medical report. Furthermore, a new clinical-informed contrastive loss is introduced for cross-modal learning, which accounts for clinical prior knowledge in formulating sample correlations in contrastive learning. The proposed model, IMITATE, outperforms baseline VLP methods across six different datasets, spanning five medical imaging downstream tasks. Comprehensive experimental results highlight the advantages of integrating the hierarchical structure of medical reports for vision-language alignment.", "url": "https://arxiv.org/abs/2310.07355"}, {"metadata": {"arXiv": "2310.07416", "Date": "Wed, 11 Oct 2023 12:01:52 ", "Title": "A Novel Voronoi-based Convolutional Neural Network Framework for Pushing Person Detection in Crowd Videos", "Authors": ["Ahmed Alia", "Mohammed Maree", "Mohcine Chraibi and Armin Seyfried"], "Categories": "cs.CV cs.LG", "Comments": ["21 pages"]}, "abstract": "Analyzing the microscopic dynamics of pushing behavior within crowds can offer valuable insights into crowd patterns and interactions. By identifying instances of pushing in crowd videos, a deeper understanding of when, where, and why such behavior occurs can be achieved. This knowledge is crucial to creating more effective crowd management strategies, optimizing crowd flow, and enhancing overall crowd experiences. However, manually identifying pushing behavior at the microscopic level is challenging, and the existing automatic approaches cannot detect such microscopic behavior. Thus, this article introduces a novel automatic framework for identifying pushing in videos of crowds on a microscopic level. The framework comprises two main components: i) Feature extraction and ii) Video labeling. In the feature extraction component, a new Voronoi-based method is developed for determining the local regions associated with each person in the input video. Subsequently, these regions are fed into EfficientNetV1B0 Convolutional Neural Network to extract the deep features of each person over time. In the second component, a combination of a fully connected layer with a Sigmoid activation function is employed to analyze these deep features and annotate the individuals involved in pushing within the video. The framework is trained and evaluated on a new dataset created using six real-world experiments, including their corresponding ground truths. The experimental findings indicate that the suggested framework outperforms seven baseline methods that are employed for comparative analysis purposes.", "url": "https://arxiv.org/abs/2310.07416"}, {"metadata": {"arXiv": "2310.07506", "Date": "Wed, 11 Oct 2023 14:02:11 ", "Title": "Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation", "Authors": ["Haizhong Zheng", "Jiachen Sun", "Shutong Wu", "Bhavya Kailkhura", "Zhuoqing Mao", "Chaowei Xiao", "and Atul Prakash"], "Categories": "cs.CV cs.LG"}, "abstract": "Given a real-world dataset, data condensation (DC) aims to synthesize a significantly smaller dataset that captures the knowledge of this dataset for model training with high performance. Recent works propose to enhance DC with data parameterization, which condenses data into parameterized data containers rather than pixel space. The intuition behind data parameterization is to encode shared features of images to avoid additional storage costs. In this paper, we recognize that images share common features in a hierarchical way due to the inherent hierarchical structure of the classification system, which is overlooked by current data parameterization methods. To better align DC with this hierarchical nature and encourage more efficient information sharing inside data containers, we propose a novel data parameterization architecture, Hierarchical Memory Network (HMN). HMN stores condensed data in a three-tier structure, representing the dataset-level, class-level, and instance-level features. Another helpful property of the hierarchical architecture is that HMN naturally ensures good independence among images despite achieving information sharing. This enables instance-level pruning for HMN to reduce redundant information, thereby further minimizing redundancy and enhancing performance. We evaluate HMN on four public datasets (SVHN, CIFAR10, CIFAR100, and Tiny-ImageNet) and compare HMN with eight DC baselines. The evaluation results show that our proposed method outperforms all baselines, even when trained with a batch-based loss consuming less GPU memory.", "url": "https://arxiv.org/abs/2310.07506"}, {"metadata": {"arXiv": "2310.07511", "Date": "Wed, 11 Oct 2023 14:07:05 ", "Title": "A Unified Remote Sensing Anomaly Detector Across Modalities and Scenes via Deviation Relationship Learning", "Authors": ["Jingtao Li", "Xinyu Wang", "Hengwei Zhao", "Liangpei Zhang", "Yanfei Zhong"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Journal paper"]}, "abstract": "Remote sensing anomaly detector can find the objects deviating from the background as potential targets. Given the diversity in earth anomaly types, a unified anomaly detector across modalities and scenes should be cost-effective and flexible to new earth observation sources and anomaly types. However, the current anomaly detectors are limited to a single modality and single scene, since they aim to learn the varying background distribution. Motivated by the universal anomaly deviation pattern, in that anomalies exhibit deviations from their local context, we exploit this characteristic to build a unified anomaly detector. Firstly, we reformulate the anomaly detection task as an undirected bilayer graph based on the deviation relationship, where the anomaly score is modeled as the conditional probability, given the pattern of the background and normal objects. The learning objective is then expressed as a conditional probability ranking problem. Furthermore, we design an instantiation of the reformulation in the data, architecture, and optimization aspects. Simulated spectral and spatial anomalies drive the instantiated architecture. The model is optimized directly for the conditional probability ranking. The proposed model was validated in five modalities including the hyperspectral, visible light, synthetic aperture radar (SAR), infrared and low light to show its unified detection ability.", "url": "https://arxiv.org/abs/2310.07511"}, {"metadata": {"arXiv": "2310.06872", "Date": "Mon, 09 Oct 2023 05:34:21 ", "Title": "On sparse regression, Lp-regularization, and automated model discovery", "Authors": ["Jeremy A. McCulloch", "Skyler R. St. Pierre", "Kevin Linka", "Ellen Kuhl"], "Categories": "cs.LG", "Comments": ["35 pages", "15 figures", "2 tables", "62 references"], "MSC-class": "65, 74", "ACM-class": "I.6; J.2"}, "abstract": "Sparse regression and feature extraction are the cornerstones of knowledge discovery from massive data. Their goal is to discover interpretable and predictive models that provide simple relationships among scientific variables. While the statistical tools for model discovery are well established in the context of linear regression, their generalization to nonlinear regression in material modeling is highly problem-specific and insufficiently understood. Here we explore the potential of neural networks for automatic model discovery and induce sparsity by a hybrid approach that combines two strategies: regularization and physical constraints. We integrate the concept of Lp regularization for subset selection with constitutive neural networks that leverage our domain knowledge in kinematics and thermodynamics. We train our networks with both, synthetic and real data, and perform several thousand discovery runs to infer common guidelines and trends: L2 regularization or ridge regression is unsuitable for model discovery; L1 regularization or lasso promotes sparsity, but induces strong bias; only L0 regularization allows us to transparently fine-tune the trade-off between interpretability and predictability, simplicity and accuracy, and bias and variance. With these insights, we demonstrate that Lp regularized constitutive neural networks can simultaneously discover both, interpretable models and physically meaningful parameters. We anticipate that our findings will generalize to alternative discovery techniques such as sparse and symbolic regression, and to other domains such as biology, chemistry, or medicine. Our ability to automatically discover material models from data could have tremendous applications in generative material design and open new opportunities to manipulate matter, alter properties of existing materials, and discover new materials with user-defined properties.", "url": "https://arxiv.org/abs/2310.06872"}, {"metadata": {"arXiv": "2310.06948", "Date": "Tue, 10 Oct 2023 19:07:53 ", "Title": "A Variational Autoencoder Framework for Robust, Physics-Informed Cyberattack Recognition in Industrial Cyber-Physical Systems", "Authors": ["Navid Aftabi", "Dan Li and Paritosh Ramanan"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["arXiv admin note: text overlap with arXiv:2009.12360"]}, "abstract": "Cybersecurity of Industrial Cyber-Physical Systems is drawing significant concerns as data communication increasingly leverages wireless networks. A lot of data-driven methods were develope for detecting cyberattacks, but few are focused on distinguishing them from equipment faults. In this paper, we develop a data-driven framework that can be used to detect, diagnose, and localize a type of cyberattack called covert attacks on networked industrial control systems. The framework has a hybrid design that combines a variational autoencoder (VAE), a recurrent neural network (RNN), and a Deep Neural Network (DNN). This data-driven framework considers the temporal behavior of a generic physical system that extracts features from the time series of the sensor measurements that can be used for detecting covert attacks, distinguishing them from equipment faults, as well as localize the attack/fault. We evaluate the performance of the proposed method through a realistic simulation study on a networked power transmission system as a typical example of ICS. We compare the performance of the proposed method with the traditional model-based method to show its applicability and efficacy.", "url": "https://arxiv.org/abs/2310.06948"}, {"metadata": {"arXiv": "2310.06970", "Date": "Tue, 10 Oct 2023 19:47:58 ", "Title": "Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing", "Authors": ["Jo\\\"el Mathys", "Florian Gr\\\"otschl", "Kalyan Varma Nadimpalli", "Roger Wattenhofer"], "Categories": "cs.LG", "Comments": ["9 pages"]}, "abstract": "Graph Neural Networks are a natural fit for learning algorithms. They can directly represent tasks through an abstract but versatile graph structure and handle inputs of different sizes. This opens up the possibility for scaling and extrapolation to larger graphs, one of the most important advantages of an algorithm. However, this raises two core questions i) How can we enable nodes to gather the required information in a given graph ($\\textit{information exchange}$), even if is far away and ii) How can we design an execution framework which enables this information exchange for extrapolation to larger graph sizes ($\\textit{algorithmic alignment for extrapolation}$). We propose a new execution framework that is inspired by the design principles of distributed algorithms: Flood and Echo Net. It propagates messages through the entire graph in a wave like activation pattern, which naturally generalizes to larger instances. Through its sparse but parallel activations it is provably more efficient in terms of message complexity. We study the proposed model and provide both empirical evidence and theoretical insights in terms of its expressiveness, efficiency, information exchange and ability to extrapolate.", "url": "https://arxiv.org/abs/2310.06970"}, {"metadata": {"arXiv": "2310.07000", "Date": "Tue, 10 Oct 2023 20:33:48 ", "Title": "CarDS-Plus ECG Platform: Development and Feasibility Evaluation of a Multiplatform Artificial Intelligence Toolkit for Portable and Wearable Device Electrocardiograms", "Authors": ["Sumukh Vasisht Shankar", "Evangelos K Oikonomou", "Rohan Khera"], "Categories": "cs.LG eess.SP"}, "abstract": "In the rapidly evolving landscape of modern healthcare, the integration of wearable & portable technology provides a unique opportunity for personalized health monitoring in the community. Devices like the Apple Watch, FitBit, and AliveCor KardiaMobile have revolutionized the acquisition and processing of intricate health data streams. Amidst the variety of data collected by these gadgets, single-lead electrocardiogram (ECG) recordings have emerged as a crucial source of information for monitoring cardiovascular health. There has been significant advances in artificial intelligence capable of interpreting these 1-lead ECGs, facilitating clinical diagnosis as well as the detection of rare cardiac disorders. This design study describes the development of an innovative multiplatform system aimed at the rapid deployment of AI-based ECG solutions for clinical investigation & care delivery. The study examines design considerations, aligning them with specific applications, develops data flows to maximize efficiency for research & clinical use. This process encompasses the reception of single-lead ECGs from diverse wearable devices, channeling this data into a centralized data lake & facilitating real-time inference through AI models for ECG interpretation. An evaluation of the platform demonstrates a mean duration from acquisition to reporting of results of 33.0 to 35.7 seconds, after a standard 30 second acquisition. There were no substantial differences in acquisition to reporting across two commercially available devices (Apple Watch and KardiaMobile). These results demonstrate the succcessful translation of design principles into a fully integrated & efficient strategy for leveraging 1-lead ECGs across platforms & interpretation by AI-ECG algorithms. Such a platform is critical to translating AI discoveries for wearable and portable ECG devices to clinical impact through rapid deployment.", "url": "https://arxiv.org/abs/2310.07000"}, {"metadata": {"arXiv": "2310.07015", "Date": "Tue, 10 Oct 2023 21:05:13 ", "Title": "Neural Relational Inference with Fast Modular Meta-learning", "Authors": ["Ferran Alet", "Erica Weng", "Tom\\'as Lozano P\\'erez", "Leslie Pack Kaelbling"], "Categories": "cs.LG", "Comments": ["Published as a conference paper in NeurIPs 2019"]}, "abstract": "\\textit{Graph neural networks} (GNNs) are effective models for many dynamical systems consisting of entities and relations. Although most GNN applications assume a single type of entity and relation, many situations involve multiple types of interactions. \\textit{Relational inference} is the problem of inferring these interactions and learning the dynamics from observational data. We frame relational inference as a \\textit{modular meta-learning} problem, where neural modules are trained to be composed in different ways to solve many tasks. This meta-learning framework allows us to implicitly encode time invariance and infer relations in context of one another rather than independently, which increases inference capacity. Framing inference as the inner-loop optimization of meta-learning leads to a model-based approach that is more data-efficient and capable of estimating the state of entities that we do not observe directly, but whose existence can be inferred from their effect on observed entities. To address the large search space of graph neural network compositions, we meta-learn a \\textit{proposal function} that speeds up the inner-loop simulated annealing search within the modular meta-learning algorithm, providing two orders of magnitude increase in the size of problems that can be addressed.", "url": "https://arxiv.org/abs/2310.07015"}, {"metadata": {"arXiv": "2310.07047", "Date": "Tue, 10 Oct 2023 22:21:16 ", "Title": "A predict-and-optimize approach to profit-driven churn prevention", "Authors": ["Nuria G\\'omez-Vargas", "Sebasti\\'an Maldonado", "Carla Vairetti"], "Categories": "cs.LG", "Comments": ["14 pages", "4 figures", "submitted to OMEGA"]}, "abstract": "In this paper, we introduce a novel predict-and-optimize method for profit-driven churn prevention. We frame the task of targeting customers for a retention campaign as a regret minimization problem. The main objective is to leverage individual customer lifetime values (CLVs) to ensure that only the most valuable customers are targeted. In contrast, many profit-driven strategies focus on churn probabilities while considering average CLVs. This often results in significant information loss due to data aggregation. Our proposed model aligns with the guidelines of Predict-and-Optimize (PnO) frameworks and can be efficiently solved using stochastic gradient descent methods. Results from 12 churn prediction datasets underscore the effectiveness of our approach, which achieves the best average performance compared to other well-established strategies in terms of average profit.", "url": "https://arxiv.org/abs/2310.07047"}, {"metadata": {"arXiv": "2310.07048", "Date": "Tue, 10 Oct 2023 22:23:27 ", "Title": "FedMFS: Federated Multimodal Fusion Learning with Selective Modality Communication", "Authors": ["Liangqi Yuan and Dong-Jun Han and Vishnu Pandi Chellapandi and Stanislaw H. \\.Zak and Christopher G. Brinton"], "Categories": "cs.LG cs.DC cs.NI"}, "abstract": "Federated learning (FL) is a distributed machine learning (ML) paradigm that enables clients to collaborate without accessing, infringing upon, or leaking original user data by sharing only model parameters. In the Internet of Things (IoT), edge devices are increasingly leveraging multimodal data compositions and fusion paradigms to enhance model performance. However, in FL applications, two main challenges remain open: (i) addressing the issues caused by heterogeneous clients lacking specific modalities and (ii) devising an optimal modality upload strategy to minimize communication overhead while maximizing learning performance. In this paper, we propose Federated Multimodal Fusion learning with Selective modality communication (FedMFS), a new multimodal fusion FL methodology that can tackle the above mentioned challenges. The key idea is to utilize Shapley values to quantify each modality's contribution and modality model size to gauge communication overhead, so that each client can selectively upload the modality models to the server for aggregation. This enables FedMFS to flexibly balance performance against communication costs, depending on resource constraints and applications. Experiments on real-world multimodal datasets demonstrate the effectiveness of FedMFS, achieving comparable accuracy while reducing communication overhead by one twentieth compared to baselines.", "url": "https://arxiv.org/abs/2310.07048"}, {"metadata": {"arXiv": "2310.07084", "Date": "Tue, 10 Oct 2023 23:58:53 ", "Title": "Investigating the Adversarial Robustness of Density Estimation Using the Probability Flow ODE", "Authors": ["Marius Arvinte", "Cory Cornelius", "Jason Martin", "Nageen Himayat"], "Categories": "cs.LG"}, "abstract": "Beyond their impressive sampling capabilities, score-based diffusion models offer a powerful analysis tool in the form of unbiased density estimation of a query sample under the training data distribution. In this work, we investigate the robustness of density estimation using the probability flow (PF) neural ordinary differential equation (ODE) model against gradient-based likelihood maximization attacks and the relation to sample complexity, where the compressed size of a sample is used as a measure of its complexity. We introduce and evaluate six gradient-based log-likelihood maximization attacks, including a novel reverse integration attack. Our experimental evaluations on CIFAR-10 show that density estimation using the PF ODE is robust against high-complexity, high-likelihood attacks, and that in some cases adversarial samples are semantically meaningful, as expected from a robust estimator.", "url": "https://arxiv.org/abs/2310.07084"}, {"metadata": {"arXiv": "2310.07132", "Date": "Wed, 11 Oct 2023 02:08:37 ", "Title": "Risk Assessment and Statistical Significance in the Age of Foundation Models", "Authors": ["Apoorva Nitsure", "Youssef Mroueh", "Mattia Rigotti", "Kristjan Greenewald", "Brian Belgodere", "Mikhail Yurochkin", "Jiri Navratil", "Igor Melnyk", "and Jerret Ross"], "Categories": "cs.LG math.ST q-fin.RM stat.ML stat.TH"}, "abstract": "We propose a distributional framework for assessing socio-technical risks of foundation models with quantified statistical significance. Our approach hinges on a new statistical relative testing based on first and second order stochastic dominance of real random variables. We show that the second order statistics in this test are linked to mean-risk models commonly used in econometrics and mathematical finance to balance risk and utility when choosing between alternatives. Using this framework, we formally develop a risk-aware approach for foundation model selection given guardrails quantified by specified metrics. Inspired by portfolio optimization and selection theory in mathematical finance, we define a \\emph{metrics portfolio} for each model as a means to aggregate a collection of metrics, and perform model selection based on the stochastic dominance of these portfolios. The statistical significance of our tests is backed theoretically by an asymptotic analysis via central limit theorems instantiated in practice via a bootstrap variance estimate. We use our framework to compare various large language models regarding risks related to drifting from instructions and outputting toxic content.", "url": "https://arxiv.org/abs/2310.07132"}, {"metadata": {"arXiv": "2310.07143", "Date": "Wed, 11 Oct 2023 02:36:52 ", "Title": "Imitation Learning from Purified Demonstration", "Authors": ["Yunke Wang", "Minjing Dong", "Bo Du", "Chang Xu"], "Categories": "cs.LG"}, "abstract": "Imitation learning has emerged as a promising approach for addressing sequential decision-making problems, with the assumption that expert demonstrations are optimal. However, in real-world scenarios, expert demonstrations are often imperfect, leading to challenges in effectively applying imitation learning. While existing research has focused on optimizing with imperfect demonstrations, the training typically requires a certain proportion of optimal demonstrations to guarantee performance. To tackle these problems, we propose to purify the potential perturbations in imperfect demonstrations and subsequently conduct imitation learning from purified demonstrations. Motivated by the success of diffusion models, we introduce a two-step purification via the diffusion process. In the first step, we apply a forward diffusion process to effectively smooth out the potential perturbations in imperfect demonstrations by introducing additional noise. Subsequently, a reverse generative process is utilized to recover the optimal expert demonstrations from the diffused ones. We provide theoretical evidence supporting our approach, demonstrating that total variance distance between the purified and optimal demonstration distributions can be upper-bounded. The evaluation results on MuJoCo demonstrate the effectiveness of our method from different aspects.", "url": "https://arxiv.org/abs/2310.07143"}, {"metadata": {"arXiv": "2310.07171", "Date": "Wed, 11 Oct 2023 03:39:56 ", "Title": "Federated Generalization via Information-Theoretic Distribution Diversification", "Authors": ["Zheshun Wu", "Zenglin Xu", "Dun Zeng", "Qifan Wang"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "Federated Learning (FL) has surged in prominence due to its capability of collaborative model training without direct data sharing. However, the vast disparity in local data distributions among clients, often termed the non-Independent Identically Distributed (non-IID) challenge, poses a significant hurdle to FL's generalization efficacy. The scenario becomes even more complex when not all clients participate in the training process, a common occurrence due to unstable network connections or limited computational capacities. This can greatly complicate the assessment of the trained models' generalization abilities. While a plethora of recent studies has centered on the generalization gap pertaining to unseen data from participating clients with diverse distributions, the divergence between the training distributions of participating clients and the testing distributions of non-participating ones has been largely overlooked. In response, our paper unveils an information-theoretic generalization framework for FL. Specifically, it quantifies generalization errors by evaluating the information entropy of local distributions and discerning discrepancies across these distributions. Inspired by our deduced generalization bounds, we introduce a weighted aggregation approach and a duo of client selection strategies. These innovations aim to bolster FL's generalization prowess by encompassing a more varied set of client data distributions. Our extensive empirical evaluations reaffirm the potency of our proposed methods, aligning seamlessly with our theoretical construct.", "url": "https://arxiv.org/abs/2310.07171"}, {"metadata": {"arXiv": "2310.07174", "Date": "Wed, 11 Oct 2023 03:47:34 ", "Title": "Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions", "Authors": ["Jungtaek Kim", "Jeongbeen Yoon", "Minsu Cho"], "Categories": "cs.LG stat.ML", "Comments": ["19 pages", "7 figures", "21 tables"]}, "abstract": "Sorting is a fundamental operation of all computer systems, having been a long-standing significant research topic. Beyond the problem formulation of traditional sorting algorithms, we consider sorting problems for more abstract yet expressive inputs, e.g., multi-digit images and image fragments, through a neural sorting network. To learn a mapping from a high-dimensional input to an ordinal variable, the differentiability of sorting networks needs to be guaranteed. In this paper we define a softening error by a differentiable swap function, and develop an error-free swap function that holds non-decreasing and differentiability conditions. Furthermore, a permutation-equivariant Transformer network with multi-head attention is adopted to capture dependency between given inputs and also leverage its model capacity with self-attention. Experiments on diverse sorting benchmarks show that our methods perform better than or comparable to baseline methods.", "url": "https://arxiv.org/abs/2310.07174"}, {"metadata": {"arXiv": "2310.07183", "Date": "Wed, 11 Oct 2023 04:14:59 ", "Title": "SAM-OCTA: Prompting Segment-Anything for OCTA Image Segmentation", "Authors": ["Xinrun Chen", "Chengliang Wang", "Haojian Ning", "Shiying Li"], "Categories": "cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2309.11758"]}, "abstract": "In the analysis of optical coherence tomography angiography (OCTA) images, the operation of segmenting specific targets is necessary. Existing methods typically train on supervised datasets with limited samples (approximately a few hundred), which can lead to overfitting. To address this, the low-rank adaptation technique is adopted for foundation model fine-tuning and proposed corresponding prompt point generation strategies to process various segmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been experimented on the publicly available OCTA-500 and ROSE datasets. This method achieves or approaches state-of-the-art segmentation performance metrics. The effect and applicability of prompt points are discussed in detail for the retinal vessel, foveal avascular zone, capillary, artery, and vein segmentation tasks. Furthermore, SAM-OCTA accomplishes local vessel segmentation and effective artery-vein segmentation, which was not well-solved in previous works. The code is available at https://github.com/ShellRedia/SAM-OCTA.", "url": "https://arxiv.org/abs/2310.07183"}, {"metadata": {"arXiv": "2310.07207", "Date": "Wed, 11 Oct 2023 05:34:46 ", "Title": "Robust Safe Reinforcement Learning under Adversarial Disturbances", "Authors": ["Zeyang Li", "Chuxiong Hu", "Shengbo Eben Li", "Jia Cheng", "Yunan Wang"], "Categories": "cs.LG"}, "abstract": "Safety is a primary concern when applying reinforcement learning to real-world control tasks, especially in the presence of external disturbances. However, existing safe reinforcement learning algorithms rarely account for external disturbances, limiting their applicability and robustness in practice. To address this challenge, this paper proposes a robust safe reinforcement learning framework that tackles worst-case disturbances. First, this paper presents a policy iteration scheme to solve for the robust invariant set, i.e., a subset of the safe set, where persistent safety is only possible for states within. The key idea is to establish a two-player zero-sum game by leveraging the safety value function in Hamilton-Jacobi reachability analysis, in which the protagonist (i.e., control inputs) aims to maintain safety and the adversary (i.e., external disturbances) tries to break down safety. This paper proves that the proposed policy iteration algorithm converges monotonically to the maximal robust invariant set. Second, this paper integrates the proposed policy iteration scheme into a constrained reinforcement learning algorithm that simultaneously synthesizes the robust invariant set and uses it for constrained policy optimization. This algorithm tackles both optimality and safety, i.e., learning a policy that attains high rewards while maintaining safety under worst-case disturbances. Experiments on classic control tasks show that the proposed method achieves zero constraint violation with learned worst-case adversarial disturbances, while other baseline algorithms violate the safety constraints substantially. Our proposed method also attains comparable performance as the baselines even in the absence of the adversary.", "url": "https://arxiv.org/abs/2310.07207"}, {"metadata": {"arXiv": "2310.07211", "Date": "Wed, 11 Oct 2023 05:55:20 ", "Title": "Bridging the Gap between Newton-Raphson Method and Regularized Policy Iteration", "Authors": ["Zeyang Li", "Chuxiong Hu", "Yunan Wang", "Guojian Zhan", "Jie Li", "Shengbo Eben Li"], "Categories": "cs.LG"}, "abstract": "Regularization is one of the most important techniques in reinforcement learning algorithms. The well-known soft actor-critic algorithm is a special case of regularized policy iteration where the regularizer is chosen as Shannon entropy. Despite some empirical success of regularized policy iteration, its theoretical underpinnings remain unclear. This paper proves that regularized policy iteration is strictly equivalent to the standard Newton-Raphson method in the condition of smoothing out Bellman equation with strongly convex functions. This equivalence lays the foundation of a unified analysis for both global and local convergence behaviors of regularized policy iteration. We prove that regularized policy iteration has global linear convergence with the rate being $\\gamma$ (discount factor). Furthermore, this algorithm converges quadratically once it enters a local region around the optimal value. We also show that a modified version of regularized policy iteration, i.e., with finite-step policy evaluation, is equivalent to inexact Newton method where the Newton iteration formula is solved with truncated iterations. We prove that the associated algorithm achieves an asymptotic linear convergence rate of $\\gamma^M$ in which $M$ denotes the number of steps carried out in policy evaluation. Our results take a solid step towards a better understanding of the convergence properties of regularized policy iteration algorithms.", "url": "https://arxiv.org/abs/2310.07211"}, {"metadata": {"arXiv": "2310.07216", "Date": "Wed, 11 Oct 2023 06:04:40 ", "Title": "Generative Modeling on Manifolds Through Mixture of Riemannian Diffusion Processes", "Authors": ["Jaehyeong Jo", "Sung Ju Hwang"], "Categories": "cs.LG stat.ML"}, "abstract": "Learning the distribution of data on Riemannian manifolds is crucial for modeling data from non-Euclidean space, which is required by many applications from diverse scientific fields. Yet, existing generative models on manifolds suffer from expensive divergence computation or rely on approximations of heat kernel. These limitations restrict their applicability to simple geometries and hinder scalability to high dimensions. In this work, we introduce the Riemannian Diffusion Mixture, a principled framework for building a generative process on manifolds as a mixture of endpoint-conditioned diffusion processes instead of relying on the denoising approach of previous diffusion models, for which the generative process is characterized by its drift guiding toward the most probable endpoint with respect to the geometry of the manifold. We further propose a simple yet efficient training objective for learning the mixture process, that is readily applicable to general manifolds. Our method outperforms previous generative models on various manifolds while scaling to high dimensions and requires a dramatically reduced number of in-training simulation steps for general manifolds.", "url": "https://arxiv.org/abs/2310.07216"}, {"metadata": {"arXiv": "2310.07217", "Date": "Wed, 11 Oct 2023 06:09:14 ", "Title": "Enhancing Neural Architecture Search with Multiple Hardware Constraints for Deep Learning Model Deployment on Tiny IoT Devices", "Authors": ["Alessio Burrello", "Matteo Risso", "Beatrice Alessandra Motetti", "Enrico Macii", "Luca Benini", "Daniele Jahier Pagliari"], "Categories": "cs.LG", "Comments": ["Accepted for publication at the IEEE Transactions on Emerging Topics in Computing"], "DOI": "10.1109/TETC.2023.3322033"}, "abstract": "The rapid proliferation of computing domains relying on Internet of Things (IoT) devices has created a pressing need for efficient and accurate deep-learning (DL) models that can run on low-power devices. However, traditional DL models tend to be too complex and computationally intensive for typical IoT end-nodes. To address this challenge, Neural Architecture Search (NAS) has emerged as a popular design automation technique for co-optimizing the accuracy and complexity of deep neural networks. Nevertheless, existing NAS techniques require many iterations to produce a network that adheres to specific hardware constraints, such as the maximum memory available on the hardware or the maximum latency allowed by the target application. In this work, we propose a novel approach to incorporate multiple constraints into so-called Differentiable NAS optimization methods, which allows the generation, in a single shot, of a model that respects user-defined constraints on both memory and latency in a time comparable to a single standard training. The proposed approach is evaluated on five IoT-relevant benchmarks, including the MLPerf Tiny suite and Tiny ImageNet, demonstrating that, with a single search, it is possible to reduce memory and latency by 87.4% and 54.2%, respectively (as defined by our targets), while ensuring non-inferior accuracy on state-of-the-art hand-tuned deep neural networks for TinyML.", "url": "https://arxiv.org/abs/2310.07217"}, {"metadata": {"arXiv": "2310.07220", "Date": "Wed, 11 Oct 2023 06:10:07 ", "Title": "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL", "Authors": ["Xiyao Wang", "Ruijie Zheng", "Yanchao Sun", "Ruonan Jia", "Wichayaporn Wongkamjan", "Huazhe Xu", "Furong Huang"], "Categories": "cs.LG", "Comments": ["20 pages", "12 figures"]}, "abstract": "Dyna-style model-based reinforcement learning contains two phases: model rollouts to generate sample for policy learning and real environment exploration using current policy for dynamics model learning. However, due to the complex real-world environment, it is inevitable to learn an imperfect dynamics model with model prediction error, which can further mislead policy learning and result in sub-optimal solutions. In this paper, we propose $\\texttt{COPlanner}$, a planning-driven framework for model-based methods to address the inaccurately learned dynamics model problem with conservative model rollouts and optimistic environment exploration. $\\texttt{COPlanner}$ leverages an uncertainty-aware policy-guided model predictive control (UP-MPC) component to plan for multi-step uncertainty estimation. This estimated uncertainty then serves as a penalty during model rollouts and as a bonus during real environment exploration respectively, to choose actions. Consequently, $\\texttt{COPlanner}$ can avoid model uncertain regions through conservative model rollouts, thereby alleviating the influence of model error. Simultaneously, it explores high-reward model uncertain regions to reduce model error actively through optimistic real environment exploration. $\\texttt{COPlanner}$ is a plug-and-play framework that can be applied to any dyna-style model-based methods. Experimental results on a series of proprioceptive and visual continuous control tasks demonstrate that both sample efficiency and asymptotic performance of strong model-based methods are significantly improved combined with $\\texttt{COPlanner}$.", "url": "https://arxiv.org/abs/2310.07220"}, {"metadata": {"arXiv": "2310.07229", "Date": "Wed, 11 Oct 2023 06:36:23 ", "Title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "Authors": ["Bowen Gao", "Yinjun Jia", "Yuanle Mo", "Yuyan Ni", "Weiying Ma", "Zhiming Ma", "Yanyan Lan"], "Categories": "cs.LG"}, "abstract": "Pocket representations play a vital role in various biomedical applications, such as druggability estimation, ligand affinity prediction, and de novo drug design. While existing geometric features and pretrained representations have demonstrated promising results, they usually treat pockets independent of ligands, neglecting the fundamental interactions between them. However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand non-redundant pairs) hampers large-scale pretraining endeavors for interaction modeling. To address this constraint, we propose a novel pocket pretraining approach that leverages knowledge from high-resolution atomic protein structures, assisted by highly effective pretrained small molecule representations. By segmenting protein structures into drug-like fragments and their corresponding pockets, we obtain a reasonable simulation of ligand-receptor interactions, resulting in the generation of over 5 million complexes. Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders. Our method, named ProFSA, achieves state-of-the-art performance across various tasks, including pocket druggability prediction, pocket matching, and ligand binding affinity prediction. Notably, ProFSA surpasses other pretraining methods by a substantial margin. Moreover, our work opens up a new avenue for mitigating the scarcity of protein-ligand complex data through the utilization of high-quality and diverse protein structure databases.", "url": "https://arxiv.org/abs/2310.07229"}, {"metadata": {"arXiv": "2310.07234", "Date": "Wed, 11 Oct 2023 06:51:46 ", "Title": "Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality", "Authors": ["Liyuan Wang", "Jingyi Xie", "Xingxing Zhang", "Mingyi Huang", "Hang Su", "Jun Zhu"], "Categories": "cs.LG", "Comments": ["23 pages", "20 figures", "11 tables", "accepted by NeurIPS as a Spotlight"]}, "abstract": "Prompt-based continual learning is an emerging direction in leveraging pre-trained knowledge for downstream continual learning, and has almost reached the performance pinnacle under supervised pre-training. However, our empirical research reveals that the current strategies fall short of their full potential under the more realistic self-supervised pre-training, which is essential for handling vast quantities of unlabeled data in practice. This is largely due to the difficulty of task-specific knowledge being incorporated into instructed representations via prompt parameters and predicted by uninstructed representations at test time. To overcome the exposed sub-optimality, we conduct a theoretical analysis of the continual learning objective in the context of pre-training, and decompose it into hierarchical components: within-task prediction, task-identity inference, and task-adaptive prediction. Following these empirical and theoretical insights, we propose Hierarchical Decomposition (HiDe-)Prompt, an innovative approach that explicitly optimizes the hierarchical components with an ensemble of task-specific prompts and statistics of both uninstructed and instructed representations, further with the coordination of a contrastive regularization strategy. Our extensive experiments demonstrate the superior performance of HiDe-Prompt and its robustness to pre-training paradigms in continual learning (e.g., up to 15.01% and 9.61% lead on Split CIFAR-100 and Split ImageNet-R, respectively). Our code is available at \\url{https://github.com/thu-ml/HiDe-Prompt}.", "url": "https://arxiv.org/abs/2310.07234"}, {"metadata": {"arXiv": "2310.07235", "Date": "Wed, 11 Oct 2023 06:53:05 ", "Title": "Are GATs Out of Balance?", "Authors": ["Nimrah Mustafa", "Aleksandar Bojchevski", "Rebekka Burkholz"], "Categories": "cs.LG", "Comments": ["24 pages. To be published in Advances in Neural Information Processing Systems (NeurIPS)", "2023"]}, "abstract": "While the expressive power and computational capabilities of graph neural networks (GNNs) have been theoretically studied, their optimization and learning dynamics, in general, remain largely unexplored. Our study undertakes the Graph Attention Network (GAT), a popular GNN architecture in which a node's neighborhood aggregation is weighted by parameterized attention coefficients. We derive a conservation law of GAT gradient flow dynamics, which explains why a high portion of parameters in GATs with standard initialization struggle to change during training. This effect is amplified in deeper GATs, which perform significantly worse than their shallow counterparts. To alleviate this problem, we devise an initialization scheme that balances the GAT network. Our approach i) allows more effective propagation of gradients and in turn enables trainability of deeper networks, and ii) attains a considerable speedup in training and convergence time in comparison to the standard initialization. Our main theorem serves as a stepping stone to studying the learning dynamics of positive homogeneous models with attention mechanisms.", "url": "https://arxiv.org/abs/2310.07235"}, {"metadata": {"arXiv": "2310.07264", "Date": "Wed, 11 Oct 2023 07:40:46 ", "Title": "Classification of Dysarthria based on the Levels of Severity. A Systematic Review", "Authors": ["Afnan Al-Ali", "Somaya Al-Maadeed", "Moutaz Saleh", "Rani Chinnappa Naidu", "Zachariah C Alex", "Prakash Ramachandran", "Rajeev Khoodeeram", "Rajesh Kumar M"], "Categories": "cs.LG", "Comments": ["no comments"]}, "abstract": "Dysarthria is a neurological speech disorder that can significantly impact affected individuals' communication abilities and overall quality of life. The accurate and objective classification of dysarthria and the determination of its severity are crucial for effective therapeutic intervention. While traditional assessments by speech-language pathologists (SLPs) are common, they are often subjective, time-consuming, and can vary between practitioners. Emerging machine learning-based models have shown the potential to provide a more objective dysarthria assessment, enhancing diagnostic accuracy and reliability. This systematic review aims to comprehensively analyze current methodologies for classifying dysarthria based on severity levels. Specifically, this review will focus on determining the most effective set and type of features that can be used for automatic patient classification and evaluating the best AI techniques for this purpose. We will systematically review the literature on the automatic classification of dysarthria severity levels. Sources of information will include electronic databases and grey literature. Selection criteria will be established based on relevance to the research questions. Data extraction will include methodologies used, the type of features extracted for classification, and AI techniques employed. The findings of this systematic review will contribute to the current understanding of dysarthria classification, inform future research, and support the development of improved diagnostic tools. The implications of these findings could be significant in advancing patient care and improving therapeutic outcomes for individuals affected by dysarthria.", "url": "https://arxiv.org/abs/2310.07264"}, {"metadata": {"arXiv": "2310.07268", "Date": "Wed, 11 Oct 2023 07:50:51 ", "Title": "RaftFed: A Lightweight Federated Learning Framework for Vehicular Crowd Intelligence", "Authors": ["Changan Yang", "Yaxing Chen", "Yao Zhang", "Helei Cui", "Zhiwen Yu", "Bin Guo", "Zheng Yan", "Zijiang Yang"], "Categories": "cs.LG", "Comments": ["8 pages,8 figures"]}, "abstract": "Vehicular crowd intelligence (VCI) is an emerging research field. Facilitated by state-of-the-art vehicular ad-hoc networks and artificial intelligence, various VCI applications come to place, e.g., collaborative sensing, positioning, and mapping. The collaborative property of VCI applications generally requires data to be shared among participants, thus forming network-wide intelligence. How to fulfill this process without compromising data privacy remains a challenging issue. Although federated learning (FL) is a promising tool to solve the problem, adapting conventional FL frameworks to VCI is nontrivial. First, the centralized model aggregation is unreliable in VCI because of the existence of stragglers with unfavorable channel conditions. Second, existing FL schemes are vulnerable to Non-IID data, which is intensified by the data heterogeneity in VCI. This paper proposes a novel federated learning framework called RaftFed to facilitate privacy-preserving VCI. The experimental results show that RaftFed performs better than baselines regarding communication overhead, model accuracy, and model convergence.", "url": "https://arxiv.org/abs/2310.07268"}, {"metadata": {"arXiv": "2310.07269", "Date": "Wed, 11 Oct 2023 07:51:10 ", "Title": "Why Does Sharpness-Aware Minimization Generalize Better Than SGD?", "Authors": ["Zixiang Chen and Junkai Zhang and Yiwen Kou and Xiangning Chen and Cho-Jui Hsieh and Quanquan Gu"], "Categories": "cs.LG math.OC stat.ML", "Comments": ["52 pages", "4 figures", "2 tables. In NeurIPS 2023"]}, "abstract": "The challenge of overfitting, in which the model memorizes the training data and fails to generalize to test data, has become increasingly significant in the training of large neural networks. To tackle this challenge, Sharpness-Aware Minimization (SAM) has emerged as a promising training method, which can improve the generalization of neural networks even in the presence of label noise. However, a deep understanding of how SAM works, especially in the setting of nonlinear neural networks and classification tasks, remains largely missing. This paper fills this gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks. The loss landscape of our studied problem is nonsmooth, thus current explanations for the success of SAM based on the Hessian information are insufficient. Our result explains the benefits of SAM, particularly its ability to prevent noise learning in the early stages, thereby facilitating more effective learning of features. Experiments on both synthetic and real data corroborate our theory.", "url": "https://arxiv.org/abs/2310.07269"}, {"metadata": {"arXiv": "2310.07297", "Date": "Wed, 11 Oct 2023 08:31:26 ", "Title": "Score Regularized Policy Optimization through Diffusion Behavior", "Authors": ["Huayu Chen", "Cheng Lu", "Zhengyi Wang", "Hang Su", "Jun Zhu"], "Categories": "cs.LG", "Comments": ["18 pages"]}, "abstract": "Recent developments in offline reinforcement learning have uncovered the immense potential of diffusion modeling, which excels at representing heterogeneous behavior policies. However, sampling from diffusion policies is considerably slow because it necessitates tens to hundreds of iterative inference steps for one action. To address this issue, we propose to extract an efficient deterministic inference policy from critic models and pretrained diffusion behavior models, leveraging the latter to directly regularize the policy gradient with the behavior distribution's score function during optimization. Our method enjoys powerful generative capabilities of diffusion modeling while completely circumventing the computationally intensive and time-consuming diffusion sampling scheme, both during training and evaluation. Extensive results on D4RL tasks show that our method boosts action sampling speed by more than 25 times compared with various leading diffusion-based methods in locomotion tasks, while still maintaining state-of-the-art performance.", "url": "https://arxiv.org/abs/2310.07297"}, {"metadata": {"arXiv": "2310.07306", "Date": "Wed, 11 Oct 2023 08:40:06 ", "Title": "SNOiC: Soft Labeling and Noisy Mixup based Open Intent Classification Model", "Authors": ["Aditi Kanwar (1)", "Aditi Seetha (1)", "Satyendra Singh Chouhan (1)", "Rajdeep Niyogi (2) ((1) MNIT Jaipur", "302017", "INDIA", "(2) IIT Roorkee", "247667", "INDIA)"], "Categories": "cs.LG cs.CL", "Comments": ["9 Pages", "6 figures"], "MSC-class": "ACM-class: F.2.2, I.2.7"}, "abstract": "This paper presents a Soft Labeling and Noisy Mixup-based open intent classification model (SNOiC). Most of the previous works have used threshold-based methods to identify open intents, which are prone to overfitting and may produce biased predictions. Additionally, the need for more available data for an open intent class presents another limitation for these existing models. SNOiC combines Soft Labeling and Noisy Mixup strategies to reduce the biasing and generate pseudo-data for open intent class. The experimental results on four benchmark datasets show that the SNOiC model achieves a minimum and maximum performance of 68.72\\% and 94.71\\%, respectively, in identifying open intents. Moreover, compared to state-of-the-art models, the SNOiC model improves the performance of identifying open intents by 0.93\\% (minimum) and 12.76\\% (maximum). The model's efficacy is further established by analyzing various parameters used in the proposed model. An ablation study is also conducted, which involves creating three model variants to validate the effectiveness of the SNOiC model.", "url": "https://arxiv.org/abs/2310.07306"}, {"metadata": {"arXiv": "2310.07313", "Date": "Wed, 11 Oct 2023 09:00:02 ", "Title": "Molecule-Edit Templates for Efficient and Accurate Retrosynthesis Prediction", "Authors": ["Miko{\\l}aj Sacha", "Micha{\\l} Sadowski", "Piotr Kozakowski", "Ruard van Workum", "Stanis{\\l}aw Jastrz\\k{e}bski"], "Categories": "cs.LG stat.ML", "ACM-class": "I.2.1; I.5.1"}, "abstract": "Retrosynthesis involves determining a sequence of reactions to synthesize complex molecules from simpler precursors. As this poses a challenge in organic chemistry, machine learning has offered solutions, particularly for predicting possible reaction substrates for a given target molecule. These solutions mainly fall into template-based and template-free categories. The former is efficient but relies on a vast set of predefined reaction patterns, while the latter, though more flexible, can be computationally intensive and less interpretable. To address these issues, we introduce METRO (Molecule-Edit Templates for RetrOsynthesis), a machine-learning model that predicts reactions using minimal templates - simplified reaction patterns capturing only essential molecular changes - reducing computational overhead and achieving state-of-the-art results on standard benchmarks.", "url": "https://arxiv.org/abs/2310.07313"}, {"metadata": {"arXiv": "2310.07320", "Date": "Wed, 11 Oct 2023 09:09:50 ", "Title": "Byzantine-Resilient Decentralized Multi-Armed Bandits", "Authors": ["Jingxuan Zhu", "Alec Koppel", "Alvaro Velasquez", "Ji Liu"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "In decentralized cooperative multi-armed bandits (MAB), each agent observes a distinct stream of rewards, and seeks to exchange information with others to select a sequence of arms so as to minimize its regret. Agents in the cooperative setting can outperform a single agent running a MAB method such as Upper-Confidence Bound (UCB) independently. In this work, we study how to recover such salient behavior when an unknown fraction of the agents can be Byzantine, that is, communicate arbitrarily wrong information in the form of reward mean-estimates or confidence sets. This framework can be used to model attackers in computer networks, instigators of offensive content into recommender systems, or manipulators of financial markets. Our key contribution is the development of a fully decentralized resilient upper confidence bound (UCB) algorithm that fuses an information mixing step among agents with a truncation of inconsistent and extreme values. This truncation step enables us to establish that the performance of each normal agent is no worse than the classic single-agent UCB1 algorithm in terms of regret, and more importantly, the cumulative regret of all normal agents is strictly better than the non-cooperative case, provided that each agent has at least 3f+1 neighbors where f is the maximum possible Byzantine agents in each agent's neighborhood. Extensions to time-varying neighbor graphs, and minimax lower bounds are further established on the achievable regret. Experiments corroborate the merits of this framework in practice.", "url": "https://arxiv.org/abs/2310.07320"}, {"metadata": {"arXiv": "2310.07323", "Date": "Wed, 11 Oct 2023 09:14:17 ", "Title": "Multichannel consecutive data cross-extraction with 1DCNN-attention for diagnosis of power transformer", "Authors": ["Wei Zheng", "Guogang Zhang", "Chenchen Zhao", "Qianqian Zhu"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Power transformer plays a critical role in grid infrastructure, and its diagnosis is paramount for maintaining stable operation. However, the current methods for transformer diagnosis focus on discrete dissolved gas analysis, neglecting deep feature extraction of multichannel consecutive data. The unutilized sequential data contains the significant temporal information reflecting the transformer condition. In light of this, the structure of multichannel consecutive data cross-extraction (MCDC) is proposed in this article in order to comprehensively exploit the intrinsic characteristic and evaluate the states of transformer. Moreover, for the better accommodation in scenario of transformer diagnosis, one dimensional convolution neural network attention (1DCNN-attention) mechanism is introduced and offers a more efficient solution given the simplified spatial complexity. Finally, the effectiveness of MCDC and the superior generalization ability, compared with other algorithms, are validated in experiments conducted on a dataset collected from real operation cases of power transformer. Additionally, the better stability of 1DCNN-attention has also been certified.", "url": "https://arxiv.org/abs/2310.07323"}, {"metadata": {"arXiv": "2310.07338", "Date": "Wed, 11 Oct 2023 09:37:38 ", "Title": "Towards Foundation Models for Learning on Tabular Data", "Authors": ["Han Zhang", "Xumeng Wen", "Shun Zheng", "Wei Xu", "Jiang Bian"], "Categories": "cs.LG"}, "abstract": "Learning on tabular data underpins numerous real-world applications. Despite considerable efforts in developing effective learning models for tabular data, current transferable tabular models remain in their infancy, limited by either the lack of support for direct instruction following in new tasks or the neglect of acquiring foundational knowledge and capabilities from diverse tabular datasets. In this paper, we propose Tabular Foundation Models (TabFMs) to overcome these limitations. TabFMs harness the potential of generative tabular learning, employing a pre-trained large language model (LLM) as the base model and fine-tuning it using purpose-designed objectives on an extensive range of tabular datasets. This approach endows TabFMs with a profound understanding and universal capabilities essential for learning on tabular data. Our evaluations underscore TabFM's effectiveness: not only does it significantly excel in instruction-following tasks like zero-shot and in-context inference, but it also showcases performance that approaches, and in instances, even transcends, the renowned yet mysterious closed-source LLMs like GPT-4. Furthermore, when fine-tuning with scarce data, our model achieves remarkable efficiency and maintains competitive performance with abundant training data. Finally, while our results are promising, we also delve into TabFM's limitations and potential opportunities, aiming to stimulate and expedite future research on developing more potent TabFMs.", "url": "https://arxiv.org/abs/2310.07338"}, {"metadata": {"arXiv": "2310.07351", "Date": "Wed, 11 Oct 2023 10:03:10 ", "Title": "Atom-Motif Contrastive Transformer for Molecular Property Prediction", "Authors": ["Wentao Yu", "Shuo Chen", "Chen Gong", "Gang Niu", "Masashi Sugiyama"], "Categories": "cs.LG", "Comments": ["submit to AAAI-24"]}, "abstract": "Recently, Graph Transformer (GT) models have been widely used in the task of Molecular Property Prediction (MPP) due to their high reliability in characterizing the latent relationship among graph nodes (i.e., the atoms in a molecule). However, most existing GT-based methods usually explore the basic interactions between pairwise atoms, and thus they fail to consider the important interactions among critical motifs (e.g., functional groups consisted of several atoms) of molecules. As motifs in a molecule are significant patterns that are of great importance for determining molecular properties (e.g., toxicity and solubility), overlooking motif interactions inevitably hinders the effectiveness of MPP. To address this issue, we propose a novel Atom-Motif Contrastive Transformer (AMCT), which not only explores the atom-level interactions but also considers the motif-level interactions. Since the representations of atoms and motifs for a given molecule are actually two different views of the same instance, they are naturally aligned to generate the self-supervisory signals for model training. Meanwhile, the same motif can exist in different molecules, and hence we also employ the contrastive loss to maximize the representation agreement of identical motifs across different molecules. Finally, in order to clearly identify the motifs that are critical in deciding the properties of each molecule, we further construct a property-aware attention mechanism into our learning framework. Our proposed AMCT is extensively evaluated on seven popular benchmark datasets, and both quantitative and qualitative results firmly demonstrate its effectiveness when compared with the state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.07351"}, {"metadata": {"arXiv": "2310.07365", "Date": "Wed, 11 Oct 2023 10:30:49 ", "Title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning", "Authors": ["Yun Zhu", "Yaoke Wang", "Haizhou Shi", "Zhenshuo Zhang", "Siliang Tang"], "Categories": "cs.LG", "Comments": ["Under Review"]}, "abstract": "Graph-structured data is ubiquitous in the world which models complex relationships between objects, enabling various Web applications. Daily influxes of unlabeled graph data on the Web offer immense potential for these applications. Graph self-supervised algorithms have achieved significant success in acquiring generic knowledge from abundant unlabeled graph data. These pre-trained models can be applied to various downstream Web applications, saving training time and improving downstream (target) performance. However, different graphs, even across seemingly similar domains, can differ significantly in terms of attribute semantics, posing difficulties, if not infeasibility, for transferring the pre-trained models to downstream tasks. Concretely speaking, for example, the additional task-specific node information in downstream tasks (specificity) is usually deliberately omitted so that the pre-trained representation (transferability) can be leveraged. The trade-off as such is termed as \"transferability-specificity dilemma\" in this work. To address this challenge, we introduce an innovative deployment module coined as GraphControl, motivated by ControlNet, to realize better graph domain transfer learning. Specifically, by leveraging universal structural pre-trained models and GraphControl, we align the input space across various graphs and incorporate unique characteristics of target data as conditional inputs. These conditions will be progressively integrated into the model during fine-tuning or prompt tuning through ControlNet, facilitating personalized deployment. Extensive experiments show that our method significantly enhances the adaptability of pre-trained models on target attributed datasets, achieving 1.4-3x performance gain. Furthermore, it outperforms training-from-scratch methods on target data with a comparable margin and exhibits faster convergence.", "url": "https://arxiv.org/abs/2310.07365"}, {"metadata": {"arXiv": "2310.07367", "Date": "Wed, 11 Oct 2023 10:34:52 ", "Title": "Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model", "Authors": ["Liyang Zhu", "Meng Ding", "Vaneet Aggarwal", "Jinhui Xu", "Di Wang"], "Categories": "cs.LG"}, "abstract": "In this paper, we revisit the problem of sparse linear regression in the local differential privacy (LDP) model. Existing research in the non-interactive and sequentially local models has focused on obtaining the lower bounds for the case where the underlying parameter is $1$-sparse, and extending such bounds to the more general $k$-sparse case has proven to be challenging. Moreover, it is unclear whether efficient non-interactive LDP (NLDP) algorithms exist. To address these issues, we first consider the problem in the $\\epsilon$ non-interactive LDP model and provide a lower bound of $\\Omega(\\frac{\\sqrt{dk\\log d}}{\\sqrt{n}\\epsilon})$ on the $\\ell_2$-norm estimation error for sub-Gaussian data, where $n$ is the sample size and $d$ is the dimension of the space. We propose an innovative NLDP algorithm, the very first of its kind for the problem. As a remarkable outcome, this algorithm also yields a novel and highly efficient estimator as a valuable by-product. Our algorithm achieves an upper bound of $\\tilde{O}({\\frac{d\\sqrt{k}}{\\sqrt{n}\\epsilon}})$ for the estimation error when the data is sub-Gaussian, which can be further improved by a factor of $O(\\sqrt{d})$ if the server has additional public but unlabeled data. For the sequentially interactive LDP model, we show a similar lower bound of $\\Omega({\\frac{\\sqrt{dk}}{\\sqrt{n}\\epsilon}})$. As for the upper bound, we rectify a previous method and show that it is possible to achieve a bound of $\\tilde{O}(\\frac{k\\sqrt{d}}{\\sqrt{n}\\epsilon})$. Our findings reveal fundamental differences between the non-private case, central DP model, and local DP model in the sparse linear regression problem.", "url": "https://arxiv.org/abs/2310.07367"}, {"metadata": {"arXiv": "2310.07370", "Date": "Wed, 11 Oct 2023 10:40:43 ", "Title": "Orthogonal Random Features: Explicit Forms and Sharp Inequalities", "Authors": ["Nizar Demni and Hachem Kadri"], "Categories": "cs.LG math.PR stat.ML"}, "abstract": "Random features have been introduced to scale up kernel methods via randomization techniques. In particular, random Fourier features and orthogonal random features were used to approximate the popular Gaussian kernel. The former is performed by a random Gaussian matrix and leads exactly to the Gaussian kernel after averaging. In this work, we analyze the bias and the variance of the kernel approximation based on orthogonal random features which makes use of Haar orthogonal matrices. We provide explicit expressions for these quantities using normalized Bessel functions and derive sharp exponential bounds supporting the view that orthogonal random features are more informative than random Fourier features.", "url": "https://arxiv.org/abs/2310.07370"}, {"metadata": {"arXiv": "2310.07427", "Date": "Wed, 11 Oct 2023 12:28:52 ", "Title": "Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions", "Authors": ["Zhengmeng Xu and Hai Lin"], "Categories": "cs.LG q-fin.CP"}, "abstract": "We propose a time series forecasting method named Quantum Gramian Angular Field (QGAF). This approach merges the advantages of quantum computing technology with deep learning, aiming to enhance the precision of time series classification and forecasting. We successfully transformed stock return time series data into two-dimensional images suitable for Convolutional Neural Network (CNN) training by designing specific quantum circuits. Distinct from the classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in eliminating the need for data normalization and inverse cosine calculations, simplifying the transformation process from time series data to two-dimensional images. To validate the effectiveness of this method, we conducted experiments on datasets from three major stock markets: the China A-share market, the Hong Kong stock market, and the US stock market. Experimental results revealed that compared to the classical GAF method, the QGAF approach significantly improved time series prediction accuracy, reducing prediction errors by an average of 25\\% for Mean Absolute Error (MAE) and 48\\% for Mean Squared Error (MSE). This research confirms the potential and promising prospects of integrating quantum computing with deep learning techniques in financial time series forecasting.", "url": "https://arxiv.org/abs/2310.07427"}, {"metadata": {"arXiv": "2310.07430", "Date": "Wed, 11 Oct 2023 12:32:13 ", "Title": "Non-backtracking Graph Neural Networks", "Authors": ["Seonghyun Park", "Narae Ryu", "Gahee Kim", "Dongyeop Woo", "Se-Young Yun", "Sungsoo Ahn"], "Categories": "cs.LG stat.ML"}, "abstract": "The celebrated message-passing updates for graph neural networks allow the representation of large-scale graphs with local and computationally tractable updates. However, the local updates suffer from backtracking, i.e., a message flows through the same edge twice and revisits the previously visited node. Since the number of message flows increases exponentially with the number of updates, the redundancy in local updates prevents the graph neural network from accurately recognizing a particular message flow for downstream tasks. In this work, we propose to resolve such a redundancy via the non-backtracking graph neural network (NBA-GNN) that updates a message without incorporating the message from the previously visited node. We further investigate how NBA-GNN alleviates the over-squashing of GNNs, and establish a connection between NBA-GNN and the impressive performance of non-backtracking updates for stochastic block model recovery. We empirically verify the effectiveness of our NBA-GNN on long-range graph benchmark and transductive node classification problems.", "url": "https://arxiv.org/abs/2310.07430"}, {"metadata": {"arXiv": "2310.07435", "Date": "Wed, 11 Oct 2023 12:36:42 ", "Title": "Generalized Mixture Model for Extreme Events Forecasting in Time Series Data", "Authors": ["Jincheng Wang", "Yue Gao"], "Categories": "cs.LG"}, "abstract": "Time Series Forecasting (TSF) is a widely researched topic with broad applications in weather forecasting, traffic control, and stock price prediction. Extreme values in time series often significantly impact human and natural systems, but predicting them is challenging due to their rare occurrence. Statistical methods based on Extreme Value Theory (EVT) provide a systematic approach to modeling the distribution of extremes, particularly the Generalized Pareto (GP) distribution for modeling the distribution of exceedances beyond a threshold. To overcome the subpar performance of deep learning in dealing with heavy-tailed data, we propose a novel framework to enhance the focus on extreme events. Specifically, we propose a Deep Extreme Mixture Model with Autoencoder (DEMMA) for time series prediction. The model comprises two main modules: 1) a generalized mixture distribution based on the Hurdle model and a reparameterized GP distribution form independent of the extreme threshold, 2) an Autoencoder-based LSTM feature extractor and a quantile prediction module with a temporal attention mechanism. We demonstrate the effectiveness of our approach on multiple real-world rainfall datasets.", "url": "https://arxiv.org/abs/2310.07435"}, {"metadata": {"arXiv": "2310.07446", "Date": "Wed, 11 Oct 2023 12:48:45 ", "Title": "ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting", "Authors": ["Jiawen Zhang", "Xumeng Wen", "Shun Zheng", "Jia Li", "Jiang Bian"], "Categories": "cs.LG", "Comments": ["Under Review"]}, "abstract": "Time-series forecasting serves as a linchpin in a myriad of applications, spanning various domains. With the growth of deep learning, this arena has bifurcated into two salient branches: one focuses on crafting specific neural architectures tailored for time series, and the other harnesses advanced deep generative models for probabilistic forecasting. While both branches have made significant progress, their differences across data scenarios, methodological focuses, and decoding schemes pose profound, yet unexplored, research questions. To bridge this knowledge chasm, we introduce ProbTS, a pioneering toolkit developed to synergize and compare these two distinct branches. Endowed with a unified data module, a modularized model module, and a comprehensive evaluator module, ProbTS allows us to revisit and benchmark leading methods from both branches. The scrutiny with ProbTS highlights their distinct characteristics, relative strengths and weaknesses, and areas that need further exploration. Our analyses point to new avenues for research, aiming for more effective time-series forecasting.", "url": "https://arxiv.org/abs/2310.07446"}, {"metadata": {"arXiv": "2310.07491", "Date": "Wed, 11 Oct 2023 13:39:04 ", "Title": "Model-based Clustering of Individuals' Ecological Momentary Assessment Time-series Data for Improving Forecasting Performance", "Authors": ["Mandani Ntekouli", "Gerasimos Spanakis", "Lourens Waldorp", "Anne Roefs"], "Categories": "cs.LG", "Comments": ["17 pages", "7 figures", "BNAIC/BeNeLearn 2023 (Joint International Scientific Conferences on AI and Machine Learning)"]}, "abstract": "Through Ecological Momentary Assessment (EMA) studies, a number of time-series data is collected across multiple individuals, continuously monitoring various items of emotional behavior. Such complex data is commonly analyzed in an individual level, using personalized models. However, it is believed that additional information of similar individuals is likely to enhance these models leading to better individuals' description. Thus, clustering is investigated with an aim to group together the most similar individuals, and subsequently use this information in group-based models in order to improve individuals' predictive performance. More specifically, two model-based clustering approaches are examined, where the first is using model-extracted parameters of personalized models, whereas the second is optimized on the model-based forecasting performance. Both methods are then analyzed using intrinsic clustering evaluation measures (e.g. Silhouette coefficients) as well as the performance of a downstream forecasting scheme, where each forecasting group-model is devoted to describe all individuals belonging to one cluster. Among these, clustering based on performance shows the best results, in terms of all examined evaluation measures. As another level of evaluation, those group-models' performance is compared to three baseline scenarios, the personalized, the all-in-one group and the random group-based concept. According to this comparison, the superiority of clustering-based methods is again confirmed, indicating that the utilization of group-based information could be effectively enhance the overall performance of all individuals' data.", "url": "https://arxiv.org/abs/2310.07491"}, {"metadata": {"arXiv": "2310.07518", "Date": "Wed, 11 Oct 2023 14:16:04 ", "Title": "Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning", "Authors": ["Mirco Mutti", "Riccardo De Santi", "Marcello Restelli", "Alexander Marx", "Giorgia Ramponi"], "Categories": "cs.LG"}, "abstract": "Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge. Our numerical evaluation conducted in illustrative domains confirms that C-PSRL strongly improves the efficiency of posterior sampling with an uninformative prior while performing close to posterior sampling with the full causal graph.", "url": "https://arxiv.org/abs/2310.07518"}, {"metadata": {"arXiv": "2310.07592", "Date": "Wed, 11 Oct 2023 15:35:20 ", "Title": "Transformers for Green Semantic Communication: Less Energy, More Semantics", "Authors": ["Shubhabrata Mukherjee", "Cory Beard", "and Sejun Song (School of Science and Engineering", "University of Missouri-Kansas City", "Kansas City", "MO", "USA)"], "Categories": "cs.LG cs.NI"}, "abstract": "Semantic communication aims to transmit meaningful and effective information rather than focusing on individual symbols or bits, resulting in benefits like reduced latency, bandwidth usage, and higher throughput compared to traditional communication. However, semantic communication poses significant challenges due to the need for universal metrics for benchmarking the joint effects of semantic information loss and practical energy consumption. This research presents a novel multi-objective loss function named \"Energy-Optimized Semantic Loss\" (EOSL), addressing the challenge of balancing semantic information loss and energy consumption. Through comprehensive experiments on transformer models, including CPU and GPU energy usage, it is demonstrated that EOSL-based encoder model selection can save up to 90\\% of energy while achieving a 44\\% improvement in semantic similarity performance during inference in this experiment. This work paves the way for energy-efficient neural network selection and the development of greener semantic communication architectures.", "url": "https://arxiv.org/abs/2310.07592"}, {"metadata": {"arXiv": "2310.07596", "Date": "Wed, 11 Oct 2023 15:37:31 ", "Title": "Prospective Side Information for Latent MDPs", "Authors": ["Jeongyeol Kwon", "Yonathan Efroni", "Shie Mannor", "Constantine Caramanis"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "In many interactive decision-making settings, there is latent and unobserved information that remains fixed. Consider, for example, a dialogue system, where complete information about a user, such as the user's preferences, is not given. In such an environment, the latent information remains fixed throughout each episode, since the identity of the user does not change during an interaction. This type of environment can be modeled as a Latent Markov Decision Process (LMDP), a special instance of Partially Observed Markov Decision Processes (POMDPs). Previous work established exponential lower bounds in the number of latent contexts for the LMDP class. This puts forward a question: under which natural assumptions a near-optimal policy of an LMDP can be efficiently learned? In this work, we study the class of LMDPs with {\\em prospective side information}, when an agent receives additional, weakly revealing, information on the latent context at the beginning of each episode. We show that, surprisingly, this problem is not captured by contemporary settings and algorithms designed for partially observed environments. We then establish that any sample efficient algorithm must suffer at least $\\Omega(K^{2/3})$-regret, as opposed to standard $\\Omega(\\sqrt{K})$ lower bounds, and design an algorithm with a matching upper bound.", "url": "https://arxiv.org/abs/2310.07596"}, {"metadata": {"arXiv": "2310.07626", "Date": "Wed, 11 Oct 2023 16:09:09 ", "Title": "Unsupervised Learning of Sea Surface Height Interpolation from Multi-variate Simulated Satellite Observations", "Authors": ["Theo Archambault", "Arthur Filoche", "Anastase Charantonis", "Dominique Bereziat", "Sylvie Thiria"], "Categories": "cs.LG", "Comments": ["submitted to JAMES. 26 pages"]}, "abstract": "Satellite-based remote sensing missions have revolutionized our understanding of the Ocean state and dynamics. Among them, spaceborne altimetry provides valuable measurements of Sea Surface Height (SSH), which is used to estimate surface geostrophic currents. However, due to the sensor technology employed, important gaps occur in SSH observations. Complete SSH maps are produced by the altimetry community using linear Optimal Interpolations (OI) such as the widely-used Data Unification and Altimeter Combination System (DUACS). However, OI is known for producing overly smooth fields and thus misses some mesostructures and eddies. On the other hand, Sea Surface Temperature (SST) products have much higher data coverage and SST is physically linked to geostrophic currents through advection. We design a realistic twin experiment to emulate the satellite observations of SSH and SST to evaluate interpolation methods. We introduce a deep learning network able to use SST information, and a trainable in two settings: one where we have no access to ground truth during training and one where it is accessible. Our investigation involves a comparative analysis of the aforementioned network when trained using either supervised or unsupervised loss functions. We assess the quality of SSH reconstructions and further evaluate the network's performance in terms of eddy detection and physical properties. We find that it is possible, even in an unsupervised setting to use SST to improve reconstruction performance compared to SST-agnostic interpolations. We compare our reconstructions to DUACS's and report a decrease of 41\\% in terms of root mean squared error.", "url": "https://arxiv.org/abs/2310.07626"}, {"metadata": {"arXiv": "2310.07630", "Date": "Wed, 11 Oct 2023 16:23:07 ", "Title": "Differentiable Euler Characteristic Transforms for Shape Classification", "Authors": ["Ernst Roell", "Bastian Rieck"], "Categories": "cs.LG"}, "abstract": "The Euler Characteristic Transform (ECT) has proven to be a powerful representation, combining geometrical and topological characteristics of shapes and graphs. However, the ECT was hitherto unable to learn task-specific representations. We overcome this issue and develop a novel computational layer that enables learning the ECT in an end-to-end fashion. Our method DECT is fast and computationally efficient, while exhibiting performance on a par with more complex models in both graph and point cloud classification tasks. Moreover, we show that this seemingly unexpressive statistic still provides the same topological expressivity as more complex topological deep learning layers provide.", "url": "https://arxiv.org/abs/2310.07630"}, {"metadata": {"arXiv": "2310.07631", "Date": "Wed, 11 Oct 2023 16:24:06 ", "Title": "Graph Transformer Network for Flood Forecasting with Heterogeneous Covariates", "Authors": ["Jimeng Shi", "Vitalii Stebliankin", "Zhaonan Wang", "Shaowen Wang", "Giri Narasimhan"], "Categories": "cs.LG"}, "abstract": "Floods can be very destructive causing heavy damage to life, property, and livelihoods. Global climate change and the consequent sea-level rise have increased the occurrence of extreme weather events, resulting in elevated and frequent flood risk. Therefore, accurate and timely flood forecasting in coastal river systems is critical to facilitate good flood management. However, the computational tools currently used are either slow or inaccurate. In this paper, we propose a Flood prediction tool using Graph Transformer Network (FloodGTN) for river systems. More specifically, FloodGTN learns the spatio-temporal dependencies of water levels at different monitoring stations using Graph Neural Networks (GNNs) and an LSTM. It is currently implemented to consider external covariates such as rainfall, tide, and the settings of hydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along the river. We use a Transformer to learn the attention given to external covariates in computing water levels. We apply the FloodGTN tool to data from the South Florida Water Management District, which manages a coastal area prone to frequent storms and hurricanes. Experimental results show that FloodGTN outperforms the physics-based model (HEC-RAS) by achieving higher accuracy with 70% improvement while speeding up run times by at least 500x.", "url": "https://arxiv.org/abs/2310.07631"}, {"metadata": {"arXiv": "2310.07707", "Date": "Wed, 11 Oct 2023 17:57:14 ", "Title": "MatFormer: Nested Transformer for Elastic Inference", "Authors": ["Devvrit", "Sneha Kudugunta", "Aditya Kusupati", "Tim Dettmers", "Kaifeng Chen", "Inderjit Dhillon", "Yulia Tsvetkov", "Hannaneh Hajishirzi", "Sham Kakade", "Ali Farhadi", "Prateek Jain"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["31 pages", "12 figures", "first three authors contributed equally"]}, "abstract": "Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones. The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama, & ViTs as a series of models of varying sizes. Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks. This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized. We empirically demonstrate MatFormer's effectiveness across different model classes (decoders & encoders), modalities (language & vision), and scales (up to 2.6B parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts. Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.", "url": "https://arxiv.org/abs/2310.07707"}, {"metadata": {"arXiv": "2310.07392", "Date": "Wed, 11 Oct 2023 11:20:35 ", "Title": "Deep Kernel and Image Quality Estimators for Optimizing Robotic Ultrasound Controller using Bayesian Optimization", "Authors": ["Deepak Raina", "SH Chandrashekhara", "Richard Voyles", "Juan Wachs", "Subir Kumar Saha"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted in IEEE International Symposium on Medical Robotics (ISMR) 2023"], "DOI": "10.1109/ISMR57123.2023.10130193"}, "abstract": "Ultrasound is a commonly used medical imaging modality that requires expert sonographers to manually maneuver the ultrasound probe based on the acquired image. Autonomous Robotic Ultrasound (A-RUS) is an appealing alternative to this manual procedure in order to reduce sonographers' workload. The key challenge to A-RUS is optimizing the ultrasound image quality for the region of interest across different patients. This requires knowledge of anatomy, recognition of error sources and precise probe position, orientation and pressure. Sample efficiency is important while optimizing these parameters associated with the robotized probe controller. Bayesian Optimization (BO), a sample-efficient optimization framework, has recently been applied to optimize the 2D motion of the probe. Nevertheless, further improvements are needed to improve the sample efficiency for high-dimensional control of the probe. We aim to overcome this problem by using a neural network to learn a low-dimensional kernel in BO, termed as Deep Kernel (DK). The neural network of DK is trained using probe and image data acquired during the procedure. The two image quality estimators are proposed that use a deep convolution neural network and provide real-time feedback to the BO. We validated our framework using these two feedback functions on three urinary bladder phantoms. We obtained over 50% increase in sample efficiency for 6D control of the robotized probe. Furthermore, our results indicate that this performance enhancement in BO is independent of the specific training dataset, demonstrating inter-patient adaptability.", "url": "https://arxiv.org/abs/2310.07392"}, {"metadata": {"arXiv": "2310.06846", "Date": "Tue, 05 Sep 2023 15:18:04 ", "Title": "Exploiting Language Models as a Source of Knowledge for Cognitive Agents", "Authors": ["James R. Kirk", "Robert E. Wray", "John E. Laird"], "Categories": "cs.AI cs.CL", "Comments": ["9 pages", "4 figures", "2 tables. AAAI FSS on Integrating Cognitive Architecture and Generative Models"], "ACM-class": "I.2.7; I.2.11"}, "abstract": "Large language models (LLMs) provide capabilities far beyond sentence completion, including question answering, summarization, and natural-language inference. While many of these capabilities have potential application to cognitive systems, our research is exploiting language models as a source of task knowledge for cognitive agents, that is, agents realized via a cognitive architecture. We identify challenges and opportunities for using language models as an external knowledge source for cognitive systems and possible ways to improve the effectiveness of knowledge extraction by integrating extraction with cognitive architecture capabilities, highlighting with examples from our recent work in this area.", "url": "https://arxiv.org/abs/2310.06846"}, {"metadata": {"arXiv": "2310.07064", "Date": "Tue, 10 Oct 2023 23:07:01 ", "Title": "Large Language Models can Learn Rules", "Authors": ["Zhaocheng Zhu", "Yuan Xue", "Xinyun Chen", "Denny Zhou", "Jian Tang", "Dale Schuurmans", "Hanjun Dai"], "Categories": "cs.AI cs.CL"}, "abstract": "When prompted with a few examples and intermediate steps, large language models (LLMs) have demonstrated impressive performance in various reasoning tasks. However, prompting methods that rely on implicit knowledge in an LLM often hallucinate incorrect answers when the implicit knowledge is wrong or inconsistent with the task. To tackle this problem, we present Hypotheses-to-Theories (HtT), a framework that learns a rule library for reasoning with LLMs. HtT contains two stages, an induction stage and a deduction stage. In the induction stage, an LLM is first asked to generate and verify rules over a set of training examples. Rules that appear and lead to correct answers sufficiently often are collected to form a rule library. In the deduction stage, the LLM is then prompted to employ the learned rule library to perform reasoning to answer test questions. Experiments on both numerical reasoning and relational reasoning problems show that HtT improves existing prompting methods, with an absolute gain of 11-27% in accuracy. The learned rules are also transferable to different models and to different forms of the same problem.", "url": "https://arxiv.org/abs/2310.07064"}, {"metadata": {"arXiv": "2310.07086", "Date": "Wed, 11 Oct 2023 00:01:05 ", "Title": "Leveraging Twitter Data for Sentiment Analysis of Transit User Feedback: An NLP Framework", "Authors": ["Adway Das", "Abhishek Kumar Prajapati", "Pengxiang Zhang", "Mukund Srinath", "Andisheh Ranjbari"], "Categories": "cs.AI cs.SI", "Comments": ["Word Count: 5515 words + 3 table (250 words per table) = 6265 words"]}, "abstract": "Traditional methods of collecting user feedback through transit surveys are often time-consuming, resource intensive, and costly. In this paper, we propose a novel NLP-based framework that harnesses the vast, abundant, and inexpensive data available on social media platforms like Twitter to understand users' perceptions of various service issues. Twitter, being a microblogging platform, hosts a wealth of real-time user-generated content that often includes valuable feedback and opinions on various products, services, and experiences. The proposed framework streamlines the process of gathering and analyzing user feedback without the need for costly and time-consuming user feedback surveys using two techniques. First, it utilizes few-shot learning for tweet classification within predefined categories, allowing effective identification of the issues described in tweets. It then employs a lexicon-based sentiment analysis model to assess the intensity and polarity of the tweet sentiments, distinguishing between positive, negative, and neutral tweets. The effectiveness of the framework was validated on a subset of manually labeled Twitter data and was applied to the NYC subway system as a case study. The framework accurately classifies tweets into predefined categories related to safety, reliability, and maintenance of the subway system and effectively measured sentiment intensities within each category. The general findings were corroborated through a comparison with an agency-run customer survey conducted in the same year. The findings highlight the effectiveness of the proposed framework in gauging user feedback through inexpensive social media data to understand the pain points of the transit system and plan for targeted improvements.", "url": "https://arxiv.org/abs/2310.07086"}, {"metadata": {"arXiv": "2310.07156", "Date": "Wed, 11 Oct 2023 03:03:50 ", "Title": "Solving Travelling Thief Problems using Coordination Based Methods", "Authors": ["Majid Namazi", "M.A. Hakim Newton", "Conrad Sanderson", "Abdul Sattar"], "Categories": "cs.AI", "Comments": ["expanded and revised version of arXiv:1911.03124"], "MSC-class": "68T20, 90B06, 90C27, 90C59", "DOI": "10.1007/s10732-023-09518-7"}, "abstract": "A travelling thief problem (TTP) is a proxy to real-life problems such as postal collection. TTP comprises an entanglement of a travelling salesman problem (TSP) and a knapsack problem (KP) since items of KP are scattered over cities of TSP, and a thief has to visit cities to collect items. In TTP, city selection and item selection decisions need close coordination since the thief's travelling speed depends on the knapsack's weight and the order of visiting cities affects the order of item collection. Existing TTP solvers deal with city selection and item selection separately, keeping decisions for one type unchanged while dealing with the other type. This separation essentially means very poor coordination between two types of decision. In this paper, we first show that a simple local search based coordination approach does not work in TTP. Then, to address the aforementioned problems, we propose a human designed coordination heuristic that makes changes to collection plans during exploration of cyclic tours. We further propose another human designed coordination heuristic that explicitly exploits the cyclic tours in item selections during collection plan exploration. Lastly, we propose a machine learning based coordination heuristic that captures characteristics of the two human designed coordination heuristics. Our proposed coordination based approaches help our TTP solver significantly outperform existing state-of-the-art TTP solvers on a set of benchmark problems. Our solver is named Cooperation Coordination (CoCo) and its source code is available from https://github.com/majid75/CoCo", "url": "https://arxiv.org/abs/2310.07156"}, {"metadata": {"arXiv": "2310.07282", "Date": "Wed, 11 Oct 2023 08:16:35 ", "Title": "An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT", "Authors": ["Shyni Sharaf and V. S. Anoop"], "Categories": "cs.AI cs.CL"}, "abstract": "This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the paper covers aspects related to model evaluation, with a focus on healthcare benchmarks and functions like processing of natural language in biomedical, question-answering, clinical document classification, and medical entity recognition. It explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models. The paper thoroughly examines ethical considerations, particularly patient privacy and data security. It highlights the benefits of incorporating BioBERT into healthcare contexts, including enhanced clinical decision support and more efficient information retrieval. Nevertheless, it acknowledges the impediments and complexities of this integration, encompassing concerns regarding data privacy, transparency, resource-intensive requirements, and the necessity for model customization to align with diverse healthcare domains.", "url": "https://arxiv.org/abs/2310.07282"}, {"metadata": {"arXiv": "2310.07348", "Date": "Wed, 11 Oct 2023 09:57:56 ", "Title": "Semantic Association Rule Learning from Time Series Data and Knowledge Graphs", "Authors": ["Erkan Karabulut", "Victoria Degeler", "Paul Groth"], "Categories": "cs.AI", "Comments": ["This paper is accepted to SemIIM23: 2nd International Workshop on Semantic Industrial Information Modelling", "7th November 2023", "Athens", "Greece", "co-located with 22nd International Semantic Web Conference (ISWC 2023)"]}, "abstract": "Digital Twins (DT) are a promising concept in cyber-physical systems research due to their advanced features including monitoring and automated reasoning. Semantic technologies such as Knowledge Graphs (KG) are recently being utilized in DTs especially for information modelling. Building on this move, this paper proposes a pipeline for semantic association rule learning in DTs using KGs and time series data. In addition to this initial pipeline, we also propose new semantic association rule criterion. The approach is evaluated on an industrial water network scenario. Initial evaluation shows that the proposed approach is able to learn a high number of association rules with semantic information which are more generalizable. The paper aims to set a foundation for further work on using semantic association rule learning especially in the context of industrial applications.", "url": "https://arxiv.org/abs/2310.07348"}, {"metadata": {"arXiv": "2310.07354", "Date": "Wed, 11 Oct 2023 10:11:54 ", "Title": "Give and Take: Federated Transfer Learning for Industrial IoT Network Intrusion Detection", "Authors": ["Lochana Telugu Rajesh", "Tapadhir Das", "Raj Mani Shukla", "and Shamik Sengupta"], "Categories": "cs.AI", "Comments": ["Accepted in IEEE International Conference on Trust", "Security and Privacy in Computing and Communications (TrustCom)"]}, "abstract": "The rapid growth in Internet of Things (IoT) technology has become an integral part of today's industries forming the Industrial IoT (IIoT) initiative, where industries are leveraging IoT to improve communication and connectivity via emerging solutions like data analytics and cloud computing. Unfortunately, the rapid use of IoT has made it an attractive target for cybercriminals. Therefore, protecting these systems is of utmost importance. In this paper, we propose a federated transfer learning (FTL) approach to perform IIoT network intrusion detection. As part of the research, we also propose a combinational neural network as the centerpiece for performing FTL. The proposed technique splits IoT data between the client and server devices to generate corresponding models, and the weights of the client models are combined to update the server model. Results showcase high performance for the FTL setup between iterations on both the IIoT clients and the server. Additionally, the proposed FTL setup achieves better overall performance than contemporary machine learning algorithms at performing network intrusion detection.", "url": "https://arxiv.org/abs/2310.07354"}, {"metadata": {"arXiv": "2310.07389", "Date": "Wed, 11 Oct 2023 11:09:44 ", "Title": "Learning a Reward Function for User-Preferred Appliance Scheduling", "Authors": ["Nikolina \\v{C}ovi\\'c", "Jochen Cremer and Hrvoje Pand\\v{z}i\\'c"], "Categories": "cs.AI", "Comments": ["Submitted to PSCC 2024"]}, "abstract": "Accelerated development of demand response service provision by the residential sector is crucial for reducing carbon-emissions in the power sector. Along with the infrastructure advancement, encouraging the end users to participate is crucial. End users highly value their privacy and control, and want to be included in the service design and decision-making process when creating the daily appliance operation schedules. Furthermore, unless they are financially or environmentally motivated, they are generally not prepared to sacrifice their comfort to help balance the power system. In this paper, we present an inverse-reinforcement-learning-based model that helps create the end users' daily appliance schedules without asking them to explicitly state their needs and wishes. By using their past consumption data, the end consumers will implicitly participate in the creation of those decisions and will thus be motivated to continue participating in the provision of demand response services.", "url": "https://arxiv.org/abs/2310.07389"}, {"metadata": {"arXiv": "2310.07472", "Date": "Wed, 11 Oct 2023 13:18:25 ", "Title": "An Ontology of Co-Creative AI Systems", "Authors": ["Zhiyu Lin", "Mark Riedl"], "Categories": "cs.AI cs.HC", "Comments": ["Submitted to NeurIPS Workshop on ML for Creativity and Design 2023"]}, "abstract": "The term co-creativity has been used to describe a wide variety of human-AI assemblages in which human and AI are both involved in a creative endeavor. In order to assist with disambiguating research efforts, we present an ontology of co-creative systems, focusing on how responsibilities are divided between human and AI system and the information exchanged between them. We extend Lubart's original ontology of creativity support tools with three new categories emphasizing artificial intelligence: computer-as-subcontractor, computer-as-critic, and computer-as-teammate, some of which have sub-categorizations.", "url": "https://arxiv.org/abs/2310.07472"}, {"metadata": {"arXiv": "2310.07478", "Date": "Wed, 11 Oct 2023 13:25:03 ", "Title": "Multimodal Graph Learning for Generative Tasks", "Authors": ["Minji Yoon", "Jing Yu Koh", "Bryan Hooi", "Ruslan Salakhutdinov"], "Categories": "cs.AI"}, "abstract": "Multimodal learning combines multiple data modalities, broadening the types and complexity of data our models can utilize: for example, from plain text to image-caption pairs. Most multimodal learning algorithms focus on modeling simple one-to-one pairs of data from two modalities, such as image-caption pairs, or audio-text pairs. However, in most real-world settings, entities of different modalities interact with each other in more complex and multifaceted ways, going beyond one-to-one mappings. We propose to represent these complex relationships as graphs, allowing us to capture data with any number of modalities, and with complex relationships between modalities that can flexibly vary from one sample to another. Toward this goal, we propose Multimodal Graph Learning (MMGL), a general and systematic framework for capturing information from multiple multimodal neighbors with relational structures among them. In particular, we focus on MMGL for generative tasks, building upon pretrained Language Models (LMs), aiming to augment their text generation with multimodal neighbor contexts. We study three research questions raised by MMGL: (1) how can we infuse multiple neighbor information into the pretrained LMs, while avoiding scalability issues? (2) how can we infuse the graph structure information among multimodal neighbors into the LMs? and (3) how can we finetune the pretrained LMs to learn from the neighbor context in a parameter-efficient manner? We conduct extensive experiments to answer these three questions on MMGL and analyze the empirical results to pave the way for future MMGL research.", "url": "https://arxiv.org/abs/2310.07478"}, {"metadata": {"arXiv": "2310.07493", "Date": "Wed, 11 Oct 2023 13:39:35 ", "Title": "Diversity for Contingency: Learning Diverse Behaviors for Efficient Adaptation and Transfer", "Authors": ["Finn Rietz and Johannes Andreas Stork"], "Categories": "cs.AI", "Comments": ["Presented at the third RL-Conform workshop at IROS 2023"]}, "abstract": "Discovering all useful solutions for a given task is crucial for transferable RL agents, to account for changes in the task or transition dynamics. This is not considered by classical RL algorithms that are only concerned with finding the optimal policy, given the current task and dynamics. We propose a simple method for discovering all possible solutions of a given task, to obtain an agent that performs well in the transfer setting and adapts quickly to changes in the task or transition dynamics. Our method iteratively learns a set of policies, while each subsequent policy is constrained to yield a solution that is unlikely under all previous policies. Unlike prior methods, our approach does not require learning additional models for novelty detection and avoids balancing task and novelty reward signals, by directly incorporating the constraint into the action selection and optimization steps.", "url": "https://arxiv.org/abs/2310.07493"}, {"metadata": {"arXiv": "2310.07589", "Date": "Wed, 11 Oct 2023 15:30:35 ", "Title": "Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models", "Authors": ["Luiza Pozzobon", "Beyza Ermis", "Patrick Lewis", "Sara Hooker"], "Categories": "cs.AI"}, "abstract": "Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language's evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43% relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild. Code and data are available at https://github.com/for-ai/goodtriever.", "url": "https://arxiv.org/abs/2310.07589"}, {"metadata": {"arXiv": "2310.07613", "Date": "Wed, 11 Oct 2023 15:58:31 ", "Title": "Reinforcement Learning-based Knowledge Graph Reasoning for Explainable Fact-checking", "Authors": ["Gustav Nikopensius", "Mohit Mayank", "Orchid Chetia Phukan", "Rajesh Sharma"], "Categories": "cs.AI cs.CY", "Comments": ["Accepted to ASONAM 2023"]}, "abstract": "Fact-checking is a crucial task as it ensures the prevention of misinformation. However, manual fact-checking cannot keep up with the rate at which false information is generated and disseminated online. Automated fact-checking by machines is significantly quicker than by humans. But for better trust and transparency of these automated systems, explainability in the fact-checking process is necessary. Fact-checking often entails contrasting a factual assertion with a body of knowledge for such explanations. An effective way of representing knowledge is the Knowledge Graph (KG). There have been sufficient works proposed related to fact-checking with the usage of KG but not much focus is given to the application of reinforcement learning (RL) in such cases. To mitigate this gap, we propose an RL-based KG reasoning approach for explainable fact-checking. Extensive experiments on FB15K-277 and NELL-995 datasets reveal that reasoning over a KG is an effective way of producing human-readable explanations in the form of paths and classifications for fact claims. The RL reasoning agent computes a path that either proves or disproves a factual claim, but does not provide a verdict itself. A verdict is reached by a voting mechanism that utilizes paths produced by the agent. These paths can be presented to human readers so that they themselves can decide whether or not the provided evidence is convincing or not. This work will encourage works in this direction for incorporating RL for explainable fact-checking as it increases trustworthiness by providing a human-in-the-loop approach.", "url": "https://arxiv.org/abs/2310.07613"}, {"metadata": {"arXiv": "2310.07623", "Date": "Wed, 11 Oct 2023 16:06:14 ", "Title": "Dual Quaternion Rotational and Translational Equivariance in 3D Rigid Motion Modelling", "Authors": ["Guilherme Vieira", "Eleonora Grassucci", "Marcos Eduardo Valle", "and Danilo Comminiello"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted at IEEE MLSP 2023 (Honorable Mention Top 10% Outstanding Paper)"]}, "abstract": "Objects' rigid motions in 3D space are described by rotations and translations of a highly-correlated set of points, each with associated $x,y,z$ coordinates that real-valued networks consider as separate entities, losing information. Previous works exploit quaternion algebra and their ability to model rotations in 3D space. However, these algebras do not properly encode translations, leading to sub-optimal performance in 3D learning tasks. To overcome these limitations, we employ a dual quaternion representation of rigid motions in the 3D space that jointly describes rotations and translations of point sets, processing each of the points as a single entity. Our approach is translation and rotation equivariant, so it does not suffer from shifts in the data and better learns object trajectories, as we validate in the experimental evaluations. Models endowed with this formulation outperform previous approaches in a human pose forecasting application, attesting to the effectiveness of the proposed dual quaternion formulation for rigid motions in 3D space.", "url": "https://arxiv.org/abs/2310.07623"}, {"metadata": {"arXiv": "2310.07637", "Date": "Wed, 11 Oct 2023 16:33:29 ", "Title": "OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models", "Authors": ["Yuhe Liu", "Changhua Pei", "Longlong Xu", "Bohan Chen", "Mingze Sun", "Zhirui Zhang", "Yongqian Sun", "Shenglin Zhang", "Kun Wang", "Haiming Zhang", "Jianhui Li", "Gaogang Xie", "Xidaoo Wen", "Xiaohui Nie", "Dan Pei"], "Categories": "cs.AI cs.NI"}, "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation. The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling. Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined. Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps. Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \\textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, and practical application). The benchmark includes 7,200 questions in both multiple-choice and question-answer (QA) formats, available in English and Chinese. With quantitative and qualitative results, we show how various LLM tricks can affect the performance of AIOps, including zero-shot, chain-of-thought, and few-shot in-context learning. We find that GPT4-score is more consistent with experts than widely used Bleu and Rouge, which can be used to replace automatic metrics for large-scale qualitative evaluations.", "url": "https://arxiv.org/abs/2310.07637"}, {"metadata": {"arXiv": "2310.07653", "Date": "Wed, 11 Oct 2023 16:53:40 ", "Title": "Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models", "Authors": ["Lai Zeqiang", "Zhu Xizhou", "Dai Jifeng", "Qiao Yu", "Wang Wenhai"], "Categories": "cs.AI", "Comments": ["Technical report. Project page at https://minidalle3.github.io/"]}, "abstract": "The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images and text correspondences using natural language. In addressing the iT2I problem, we present a simple approach that augments LLMs for iT2I with prompting techniques and off-the-shelf T2I models. We evaluate our approach for iT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT, LLAMA, Baichuan, and InternLM. We demonstrate that our approach could be a convenient and low-cost way to introduce the iT2I ability for any existing LLMs and any text-to-image models without any training while bringing little degradation on LLMs' inherent capabilities in, e.g., question answering and code generation. We hope this work could draw broader attention and provide inspiration for boosting user experience in human-machine interactions alongside the image quality of the next-generation T2I systems.", "url": "https://arxiv.org/abs/2310.07653"}, {"metadata": {"arXiv": "2310.07684", "Date": "Wed, 11 Oct 2023 17:35:20 ", "Title": "Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design", "Authors": ["Lev Telyatnikov", "Maria Sofia Bucarelli", "Guillermo Bernardez", "Olga Zaghen", "Simone Scardapane", "Pietro Lio"], "Categories": "cs.AI cs.SI"}, "abstract": "Most of the current hypergraph learning methodologies and benchmarking datasets in the hypergraph realm are obtained by lifting procedures from their graph analogs, simultaneously leading to overshadowing hypergraph network foundations. This paper attempts to confront some pending questions in that regard: Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HGNNs), similar to its significance in graph-based research? Is there room for improving current hypergraph architectures and methodologies? (e.g. by carefully addressing the specific characteristics of higher-order networks) Do existing datasets provide a meaningful benchmark for HGNNs? Diving into the details, this paper proposes a novel conceptualization of homophily in higher-order networks based on a message passing scheme; this approach harmonizes the analytical frameworks of datasets and architectures, offering a unified perspective for exploring and interpreting complex, higher-order network structures and dynamics. Further, we propose MultiSet, a novel message passing framework that redefines HGNNs by allowing hyperedge-dependent node representations, as well as introduce a novel architecture MultiSetMixer that leverages a new hyperedge sampling strategy. Finally, we provide an extensive set of experiments that contextualize our proposals and lead to valuable insights in hypergraph representation learning.", "url": "https://arxiv.org/abs/2310.07684"}, {"metadata": {"arXiv": "2310.06851", "Date": "Thu, 07 Sep 2023 01:11:11 ", "Title": "BodyFormer: Semantics-guided 3D Body Gesture Synthesis with Transformer", "Authors": ["Kunkun Pang", "Dafei Qin", "Yingruo Fan", "Julian Habekost", "Takaaki Shiratori", "Junichi Yamagishi", "Taku Komura"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["12 pages", "13 figures"], "DOI": "10.1145/3592456"}, "abstract": "Automatic gesture synthesis from speech is a topic that has attracted researchers for applications in remote communication, video games and Metaverse. Learning the mapping between speech and 3D full-body gestures is difficult due to the stochastic nature of the problem and the lack of a rich cross-modal dataset that is needed for training. In this paper, we propose a novel transformer-based framework for automatic 3D body gesture synthesis from speech. To learn the stochastic nature of the body gesture during speech, we propose a variational transformer to effectively model a probabilistic distribution over gestures, which can produce diverse gestures during inference. Furthermore, we introduce a mode positional embedding layer to capture the different motion speeds in different speaking modes. To cope with the scarcity of data, we design an intra-modal pre-training scheme that can learn the complex mapping between the speech and the 3D gesture from a limited amount of data. Our system is trained with either the Trinity speech-gesture dataset or the Talking With Hands 16.2M dataset. The results show that our system can produce more realistic, appropriate, and diverse body gestures compared to existing state-of-the-art approaches.", "url": "https://arxiv.org/abs/2310.06851"}, {"metadata": {"arXiv": "2310.06854", "Date": "Wed, 27 Sep 2023 13:04:08 ", "Title": "Learning with Noisy Labels for Human Fall Events Classification: Joint Cooperative Training with Trinity Networks", "Authors": ["Leiyu Xie", "Yang Sun", "Syed Mohsen Naqvi"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "With the increasing ageing population, fall events classification has drawn much research attention. In the development of deep learning, the quality of data labels is crucial. Most of the datasets are labelled automatically or semi-automatically, and the samples may be mislabeled, which constrains the performance of Deep Neural Networks (DNNs). Recent research on noisy label learning confirms that neural networks first focus on the clean and simple instances and then follow the noisy and hard instances in the training stage. To address the learning with noisy label problem and protect the human subjects' privacy, we propose a simple but effective approach named Joint Cooperative training with Trinity Networks (JoCoT). To mitigate the privacy issue, human skeleton data are used. The robustness and performance of the noisy label learning framework is improved by using the two teacher modules and one student module in the proposed JoCoT. To mitigate the incorrect selections, the predictions from the teacher modules are applied with the consensus-based method to guide the student module training. The performance evaluation on the widely used UP-Fall dataset and comparison with the state-of-the-art, confirms the effectiveness of the proposed JoCoT in high noise rates. Precisely, JoCoT outperforms the state-of-the-art by 5.17% and 3.35% with the averaged pairflip and symmetric noises, respectively.", "url": "https://arxiv.org/abs/2310.06854"}, {"metadata": {"arXiv": "2310.07138", "Date": "Wed, 11 Oct 2023 02:23:18 ", "Title": "Denoising Task Routing for Diffusion Models", "Authors": ["Byeongjun Park", "Sangmin Woo", "Hyojun Go", "Jin-Young Kim", "Changick Kim"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models generate highly realistic images through learning a multi-step denoising process, naturally embodying the principles of multi-task learning (MTL). Despite the inherent connection between diffusion models and MTL, there remains an unexplored area in designing neural architectures that explicitly incorporate MTL into the framework of diffusion models. In this paper, we present Denoising Task Routing (DTR), a simple add-on strategy for existing diffusion model architectures to establish distinct information pathways for individual tasks within a single architecture by selectively activating subsets of channels in the model. What makes DTR particularly compelling is its seamless integration of prior knowledge of denoising tasks into the framework: (1) Task Affinity: DTR activates similar channels for tasks at adjacent timesteps and shifts activated channels as sliding windows through timesteps, capitalizing on the inherent strong affinity between tasks at adjacent timesteps. (2) Task Weights: During the early stages (higher timesteps) of the denoising process, DTR assigns a greater number of task-specific channels, leveraging the insight that diffusion models prioritize reconstructing global structure and perceptually rich contents in earlier stages, and focus on simple noise removal in later stages. Our experiments demonstrate that DTR consistently enhances the performance of diffusion models across various evaluation protocols, all without introducing additional parameters. Furthermore, DTR contributes to accelerating convergence during training. Finally, we show the complementarity between our architectural approach and existing MTL optimization techniques, providing a more complete view of MTL within the context of diffusion training.", "url": "https://arxiv.org/abs/2310.07138"}, {"metadata": {"arXiv": "2310.07179", "Date": "Wed, 11 Oct 2023 04:05:11 ", "Title": "rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera", "Authors": ["Tongtong Zhang", "Yuanxiang Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Novel view synthesis of satellite images holds a wide range of practical applications. While recent advances in the Neural Radiance Field have predominantly targeted pin-hole cameras, and models for satellite cameras often demand sufficient input views. This paper presents rpcPRF, a Multiplane Images (MPI) based Planar neural Radiance Field for Rational Polynomial Camera (RPC). Unlike coordinate-based neural radiance fields in need of sufficient views of one scene, our model is applicable to single or few inputs and performs well on images from unseen scenes. To enable generalization across scenes, we propose to use reprojection supervision to induce the predicted MPI to learn the correct geometry between the 3D coordinates and the images. Moreover, we remove the stringent requirement of dense depth supervision from deep multiview-stereo-based methods by introducing rendering techniques of radiance fields. rpcPRF combines the superiority of implicit representations and the advantages of the RPC model, to capture the continuous altitude space while learning the 3D structure. Given an RGB image and its corresponding RPC, the end-to-end model learns to synthesize the novel view with a new RPC and reconstruct the altitude of the scene. When multiple views are provided as inputs, rpcPRF exerts extra supervision provided by the extra views. On the TLC dataset from ZY-3, and the SatMVS3D dataset with urban scenes from WV-3, rpcPRF outperforms state-of-the-art nerf-based methods by a significant margin in terms of image fidelity, reconstruction accuracy, and efficiency, for both single-view and multiview task.", "url": "https://arxiv.org/abs/2310.07179"}, {"metadata": {"arXiv": "2310.07186", "Date": "Wed, 11 Oct 2023 04:25:24 ", "Title": "Multiview Transformer: Rethinking Spatial Information in Hyperspectral Image Classification", "Authors": ["Jie Zhang", "Yongshan Zhang", "Yicong Zhou"], "Categories": "cs.CV cs.AI"}, "abstract": "Identifying the land cover category for each pixel in a hyperspectral image (HSI) relies on spectral and spatial information. An HSI cuboid with a specific patch size is utilized to extract spatial-spectral feature representation for the central pixel. In this article, we investigate that scene-specific but not essential correlations may be recorded in an HSI cuboid. This additional information improves the model performance on existing HSI datasets and makes it hard to properly evaluate the ability of a model. We refer to this problem as the spatial overfitting issue and utilize strict experimental settings to avoid it. We further propose a multiview transformer for HSI classification, which consists of multiview principal component analysis (MPCA), spectral encoder-decoder (SED), and spatial-pooling tokenization transformer (SPTT). MPCA performs dimension reduction on an HSI via constructing spectral multiview observations and applying PCA on each view data to extract low-dimensional view representation. The combination of view representations, named multiview representation, is the dimension reduction output of the MPCA. To aggregate the multiview information, a fully-convolutional SED with a U-shape in spectral dimension is introduced to extract a multiview feature map. SPTT transforms the multiview features into tokens using the spatial-pooling tokenization strategy and learns robust and discriminative spatial-spectral features for land cover identification. Classification is conducted with a linear classifier. Experiments on three HSI datasets with rigid settings demonstrate the superiority of the proposed multiview transformer over the state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.07186"}, {"metadata": {"arXiv": "2310.07212", "Date": "Wed, 11 Oct 2023 05:58:14 ", "Title": "Multi-Task Learning-Enabled Automatic Vessel Draft Reading for Intelligent Maritime Surveillance", "Authors": ["Jingxiang Qu", "Ryan Wen Liu", "Chenjie Zhao", "Yu Guo", "Sendren Sheng-Dong Xu", "Fenghua Zhu", "and Yisheng Lv"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages,11 figures", "submitted to IEEE T-ITS"]}, "abstract": "The accurate and efficient vessel draft reading (VDR) is an important component of intelligent maritime surveillance, which could be exploited to assist in judging whether the vessel is normally loaded or overloaded. The computer vision technique with an excellent price-to-performance ratio has become a popular medium to estimate vessel draft depth. However, the traditional estimation methods easily suffer from several limitations, such as sensitivity to low-quality images, high computational cost, etc. In this work, we propose a multi-task learning-enabled computational method (termed MTL-VDR) for generating highly reliable VDR. In particular, our MTL-VDR mainly consists of four components, i.e., draft mark detection, draft scale recognition, vessel/water segmentation, and final draft depth estimation. We first construct a benchmark dataset related to draft mark detection and employ a powerful and efficient convolutional neural network to accurately perform the detection task. The multi-task learning method is then proposed for simultaneous draft scale recognition and vessel/water segmentation. To obtain more robust VDR under complex conditions (e.g., damaged and stained scales, etc.), the accurate draft scales are generated by an automatic correction method, which is presented based on the spatial distribution rules of draft scales. Finally, an adaptive computational method is exploited to yield an accurate and robust draft depth. Extensive experiments have been implemented on the realistic dataset to compare our MTL-VDR with state-of-the-art methods. The results have demonstrated its superior performance in terms of accuracy, robustness, and efficiency. The computational speed exceeds 40 FPS, which satisfies the requirements of real-time maritime surveillance to guarantee vessel traffic safety.", "url": "https://arxiv.org/abs/2310.07212"}, {"metadata": {"arXiv": "2310.07259", "Date": "Wed, 11 Oct 2023 07:37:13 ", "Title": "Uncovering Hidden Connections: Iterative Tracking and Reasoning for Video-grounded Dialog", "Authors": ["Haoyu Zhang", "Meng Liu", "Yaowei Wang", "Da Cao", "Weili Guan", "Liqiang Nie"], "Categories": "cs.CV cs.AI"}, "abstract": "In contrast to conventional visual question answering, video-grounded dialog necessitates a profound understanding of both dialog history and video content for accurate response generation. Despite commendable strides made by existing methodologies, they often grapple with the challenges of incrementally understanding intricate dialog histories and assimilating video information. In response to this gap, we present an iterative tracking and reasoning strategy that amalgamates a textual encoder, a visual encoder, and a generator. At its core, our textual encoder is fortified with a path tracking and aggregation mechanism, adept at gleaning nuances from dialog history that are pivotal to deciphering the posed questions. Concurrently, our visual encoder harnesses an iterative reasoning network, meticulously crafted to distill and emphasize critical visual markers from videos, enhancing the depth of visual comprehension. Culminating this enriched information, we employ the pre-trained GPT-2 model as our response generator, stitching together coherent and contextually apt answers. Our empirical assessments, conducted on two renowned datasets, testify to the prowess and adaptability of our proposed design.", "url": "https://arxiv.org/abs/2310.07259"}, {"metadata": {"arXiv": "2310.07376", "Date": "Wed, 11 Oct 2023 10:50:15 ", "Title": "Point Cloud Denoising and Outlier Detection with Local Geometric Structure by Dynamic Graph CNN", "Authors": ["Kosuke Nakayama", "Hiroto Fukuta", "Hiroshi Watanabe"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["2023 IEEE 12th Global Conference on Consumer Electronics (GCCE 2023)"]}, "abstract": "The digitalization of society is rapidly developing toward the realization of the digital twin and metaverse. In particular, point clouds are attracting attention as a media format for 3D space. Point cloud data is contaminated with noise and outliers due to measurement errors. Therefore, denoising and outlier detection are necessary for point cloud processing. Among them, PointCleanNet is an effective method for point cloud denoising and outlier detection. However, it does not consider the local geometric structure of the patch. We solve this problem by applying two types of graph convolutional layer designed based on the Dynamic Graph CNN. Experimental results show that the proposed methods outperform the conventional method in AUPR, which indicates outlier detection accuracy, and Chamfer Distance, which indicates denoising accuracy.", "url": "https://arxiv.org/abs/2310.07376"}, {"metadata": {"arXiv": "2310.07419", "Date": "Wed, 11 Oct 2023 12:05:44 ", "Title": "Multi-Concept T2I-Zero: Tweaking Only The Text Embeddings and Nothing Else", "Authors": ["Hazarapet Tunanyan", "Dejia Xu", "Shant Navasardyan", "Zhangyang Wang", "Humphrey Shi"], "Categories": "cs.CV cs.AI"}, "abstract": "Recent advances in text-to-image diffusion models have enabled the photorealistic generation of images from text prompts. Despite the great progress, existing models still struggle to generate compositional multi-concept images naturally, limiting their ability to visualize human imagination. While several recent works have attempted to address this issue, they either introduce additional training or adopt guidance at inference time. In this work, we consider a more ambitious goal: natural multi-concept generation using a pre-trained diffusion model, and with almost no extra cost. To achieve this goal, we identify the limitations in the text embeddings used for the pre-trained text-to-image diffusion models. Specifically, we observe concept dominance and non-localized contribution that severely degrade multi-concept generation performance. We further design a minimal low-cost solution that overcomes the above issues by tweaking (not re-training) the text embeddings for more realistic multi-concept text-to-image generation. Our Correction by Similarities method tweaks the embedding of concepts by collecting semantic features from most similar tokens to localize the contribution. To avoid mixing features of concepts, we also apply Cross-Token Non-Maximum Suppression, which excludes the overlap of contributions from different concepts. Experiments show that our approach outperforms previous methods in text-to-image, image manipulation, and personalization tasks, despite not introducing additional training or inference costs to the diffusion steps.", "url": "https://arxiv.org/abs/2310.07419"}, {"metadata": {"arXiv": "2310.07492", "Date": "Wed, 11 Oct 2023 13:39:11 ", "Title": "Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models", "Authors": ["Renyang Liu", "Wei Zhou", "Tianwei Zhang", "Kangjie Chen", "Jun Zhao and Kwok-Yan Lam"], "Categories": "cs.CV cs.AI"}, "abstract": "Existing black-box attacks have demonstrated promising potential in creating adversarial examples (AE) to deceive deep learning models. Most of these attacks need to handle a vast optimization space and require a large number of queries, hence exhibiting limited practical impacts in real-world scenarios. In this paper, we propose a novel black-box attack strategy, Conditional Diffusion Model Attack (CDMA), to improve the query efficiency of generating AEs under query-limited situations. The key insight of CDMA is to formulate the task of AE synthesis as a distribution transformation problem, i.e., benign examples and their corresponding AEs can be regarded as coming from two distinctive distributions and can transform from each other with a particular converter. Unlike the conventional \\textit{query-and-optimization} approach, we generate eligible AEs with direct conditional transform using the aforementioned data converter, which can significantly reduce the number of queries needed. CDMA adopts the conditional Denoising Diffusion Probabilistic Model as the converter, which can learn the transformation from clean samples to AEs, and ensure the smooth development of perturbed noise resistant to various defense strategies. We demonstrate the effectiveness and efficiency of CDMA by comparing it with nine state-of-the-art black-box attacks across three benchmark datasets. On average, CDMA can reduce the query count to a handful of times; in most cases, the query count is only ONE. We also show that CDMA can obtain $>99\\%$ attack success rate for untarget attacks over all datasets and targeted attack over CIFAR-10 with the noise budget of $\\epsilon=16$.", "url": "https://arxiv.org/abs/2310.07492"}, {"metadata": {"arXiv": "2310.07552", "Date": "Wed, 11 Oct 2023 14:54:40 ", "Title": "ProtoHPE: Prototype-guided High-frequency Patch Enhancement for Visible-Infrared Person Re-identification", "Authors": ["Guiwei Zhang and Yongfei Zhang and Zichang Tan"], "Categories": "cs.CV cs.AI"}, "abstract": "Visible-infrared person re-identification is challenging due to the large modality gap. To bridge the gap, most studies heavily rely on the correlation of visible-infrared holistic person images, which may perform poorly under severe distribution shifts. In contrast, we find that some cross-modal correlated high-frequency components contain discriminative visual patterns and are less affected by variations such as wavelength, pose, and background clutter than holistic images. Therefore, we are motivated to bridge the modality gap based on such high-frequency components, and propose \\textbf{Proto}type-guided \\textbf{H}igh-frequency \\textbf{P}atch \\textbf{E}nhancement (ProtoHPE) with two core designs. \\textbf{First}, to enhance the representation ability of cross-modal correlated high-frequency components, we split patches with such components by Wavelet Transform and exponential moving average Vision Transformer (ViT), then empower ViT to take the split patches as auxiliary input. \\textbf{Second}, to obtain semantically compact and discriminative high-frequency representations of the same identity, we propose Multimodal Prototypical Contrast. To be specific, it hierarchically captures the comprehensive semantics of different modal instances, facilitating the aggregation of high-frequency representations belonging to the same identity. With it, ViT can capture key high-frequency components during inference without relying on ProtoHPE, thus bringing no extra complexity. Extensive experiments validate the effectiveness of ProtoHPE.", "url": "https://arxiv.org/abs/2310.07552"}, {"metadata": {"arXiv": "2310.07669", "Date": "Wed, 11 Oct 2023 17:18:15 ", "Title": "HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D Semantic Segmentation", "Authors": ["Rick Groenendijk", "Leo Dorst", "Theo Gevers"], "Categories": "cs.CV cs.AI", "ACM-class": "I.4.6; I.2.6"}, "abstract": "Signals from different modalities each have their own combination algebra which affects their sampling processing. RGB is mostly linear; depth is a geometric signal following the operations of mathematical morphology. If a network obtaining RGB-D input has both kinds of operators available in its layers, it should be able to give effective output with fewer parameters. In this paper, morphological elements in conjunction with more familiar linear modules are used to construct a mixed linear-morphological network called HaarNet. This is the first large-scale linear-morphological hybrid, evaluated on a set of sizeable real-world datasets. In the network, morphological Haar sampling is applied to both feature channels in several layers, which splits extreme values and high-frequency information such that both can be processed to improve both modalities. Moreover, morphologically parameterised ReLU is used, and morphologically-sound up-sampling is applied to obtain a full-resolution output. Experiments show that HaarNet is competitive with a state-of-the-art CNN, implying that morphological networks are a promising research direction for geometry-based learning tasks.", "url": "https://arxiv.org/abs/2310.07669"}, {"metadata": {"arXiv": "2310.07716", "Date": "Wed, 11 Oct 2023 17:59:56 ", "Title": "PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection", "Authors": ["Qiang Zhou", "Weize Li", "Lihan Jiang", "Guoliang Wang", "Guyue Zhou", "Shanghang Zhang", "Hao Zhao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by NeurIPS 2023. Codes are available at https://github.com/EricLee0224/PAD"]}, "abstract": "Object anomaly detection is an important problem in the field of machine vision and has seen remarkable progress recently. However, two significant challenges hinder its research and application. First, existing datasets lack comprehensive visual information from various pose angles. They usually have an unrealistic assumption that the anomaly-free training dataset is pose-aligned, and the testing samples have the same pose as the training data. However, in practice, anomaly may exist in any regions on a object, the training and query samples may have different poses, calling for the study on pose-agnostic anomaly detection. Second, the absence of a consensus on experimental protocols for pose-agnostic anomaly detection leads to unfair comparisons of different methods, hindering the research on pose-agnostic anomaly detection. To address these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to address the pose-agnostic anomaly detection problem. Specifically, we build MAD using 20 complex-shaped LEGO toys including 4K views with various poses, and high-quality and diverse 3D anomalies in both simulated and real environments. Additionally, we propose a novel method OmniposeAD, trained using MAD, specifically designed for pose-agnostic anomaly detection. Through comprehensive evaluations, we demonstrate the relevance of our dataset and method. Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain. Code, data, and models are publicly available at https://github.com/EricLee0224/PAD.", "url": "https://arxiv.org/abs/2310.07716"}, {"metadata": {"arXiv": "2310.07150", "Date": "Wed, 11 Oct 2023 02:52:16 ", "Title": "Determining Winners in Elections with Absent Votes", "Authors": ["Qishen Han and Am\\'elie Marian and Lirong Xia"], "Categories": "cs.GT cs.AI", "Comments": ["11 pages"]}, "abstract": "An important question in elections is the determine whether a candidate can be a winner when some votes are absent. We study this determining winner with the absent votes (WAV) problem when the votes are top-truncated. We show that the WAV problem is NP-complete for the single transferable vote, Maximin, and Copeland, and propose a special case of positional scoring rule such that the problem can be computed in polynomial time. Our results in top-truncated rankings differ from the results in full rankings as their hardness results still hold when the number of candidates or the number of missing votes are bounded, while we show that the problem can be solved in polynomial time in either case.", "url": "https://arxiv.org/abs/2310.07150"}, {"metadata": {"arXiv": "2310.07218", "Date": "Wed, 11 Oct 2023 06:09:26 ", "Title": "Quantifying Agent Interaction in Multi-agent Reinforcement Learning for Cost-efficient Generalization", "Authors": ["Yuxin Chen", "Chen Tang", "Ran Tian", "Chenran Li", "Jinning Li", "Masayoshi Tomizuka", "Wei Zhan"], "Categories": "cs.MA cs.AI", "Comments": ["12 pages", "6 figures"], "ACM-class": "I.2.6"}, "abstract": "Generalization poses a significant challenge in Multi-agent Reinforcement Learning (MARL). The extent to which an agent is influenced by unseen co-players depends on the agent's policy and the specific scenario. A quantitative examination of this relationship sheds light on effectively training agents for diverse scenarios. In this study, we present the Level of Influence (LoI), a metric quantifying the interaction intensity among agents within a given scenario and environment. We observe that, generally, a more diverse set of co-play agents during training enhances the generalization performance of the ego agent; however, this improvement varies across distinct scenarios and environments. LoI proves effective in predicting these improvement disparities within specific scenarios. Furthermore, we introduce a LoI-guided resource allocation method tailored to train a set of policies for diverse scenarios under a constrained budget. Our results demonstrate that strategic resource allocation based on LoI can achieve higher performance than uniform allocation under the same computation budget.", "url": "https://arxiv.org/abs/2310.07218"}, {"metadata": {"arXiv": "2310.06903", "Date": "Tue, 10 Oct 2023 18:01:16 ", "Title": "Reinforcement Learning in a Safety-Embedded MDP with Trajectory Optimization", "Authors": ["Fan Yang", "Wenxuan Zhou", "Zuxin Liu", "Ding Zhao", "David Held"], "Categories": "cs.RO cs.AI"}, "abstract": "Safe Reinforcement Learning (RL) plays an important role in applying RL algorithms to safety-critical real-world applications, addressing the trade-off between maximizing rewards and adhering to safety constraints. This work introduces a novel approach that combines RL with trajectory optimization to manage this trade-off effectively. Our approach embeds safety constraints within the action space of a modified Markov Decision Process (MDP). The RL agent produces a sequence of actions that are transformed into safe trajectories by a trajectory optimizer, thereby effectively ensuring safety and increasing training stability. This novel approach excels in its performance on challenging Safety Gym tasks, achieving significantly higher rewards and near-zero safety violations during inference. The method's real-world applicability is demonstrated through a safe and effective deployment in a real robot task of box-pushing around obstacles.", "url": "https://arxiv.org/abs/2310.06903"}, {"metadata": {"arXiv": "2310.07263", "Date": "Wed, 11 Oct 2023 07:39:42 ", "Title": "CoPAL: Corrective Planning of Robot Actions with Large Language Models", "Authors": ["Frank Joublin", "Antonello Ceravola", "Pavel Smirnov", "Felix Ocker", "Joerg Deigmoeller", "Anna Belardinelli", "Chao Wang", "Stephan Hasler", "Daniel Tanneberg", "Michael Gienger"], "Categories": "cs.RO cs.AI"}, "abstract": "In the pursuit of fully autonomous robotic systems capable of taking over tasks traditionally performed by humans, the complexity of open-world environments poses a considerable challenge. Addressing this imperative, this study contributes to the field of Large Language Models (LLMs) applied to task and motion planning for robots. We propose a system architecture that orchestrates a seamless interplay between multiple cognitive levels, encompassing reasoning, planning, and motion generation. At its core lies a novel replanning strategy that handles physically grounded, logical, and semantic errors in the generated plans. We demonstrate the efficacy of the proposed feedback architecture, particularly its impact on executability, correctness, and time complexity via empirical evaluation in the context of a simulation and two intricate real-world scenarios: blocks world, barman and pizza preparation.", "url": "https://arxiv.org/abs/2310.07263"}, {"metadata": {"arXiv": "2310.07706", "Date": "Wed, 11 Oct 2023 17:57:13 ", "Title": "Pixel State Value Network for Combined Prediction and Planning in Interactive Environments", "Authors": ["Sascha Rosbach", "Stefan M. Leupold", "Simon Gro{\\ss}johann and Stefan Roth"], "Categories": "cs.RO cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Automated vehicles operating in urban environments have to reliably interact with other traffic participants. Planning algorithms often utilize separate prediction modules forecasting probabilistic, multi-modal, and interactive behaviors of objects. Designing prediction and planning as two separate modules introduces significant challenges, particularly due to the interdependence of these modules. This work proposes a deep learning methodology to combine prediction and planning. A conditional GAN with the U-Net architecture is trained to predict two high-resolution image sequences. The sequences represent explicit motion predictions, mainly used to train context understanding, and pixel state values suitable for planning encoding kinematic reachability, object dynamics, safety, and driving comfort. The model can be trained offline on target images rendered by a sampling-based model-predictive planner, leveraging real-world driving data. Our results demonstrate intuitive behavior in complex situations, such as lane changes amidst conflicting objectives.", "url": "https://arxiv.org/abs/2310.07706"}, {"metadata": {"arXiv": "2310.06923", "Date": "Tue, 10 Oct 2023 18:24:50 ", "Title": "PICProp: Physics-Informed Confidence Propagation for Uncertainty Quantification", "Authors": ["Qianli Shen", "Wai Hoh Tang", "Zhun Deng", "Apostolos Psaros", "Kenji Kawaguchi"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted at NeurIPS 2023. Code is available at https://github.com/ShenQianli/PICProp"]}, "abstract": "Standard approaches for uncertainty quantification in deep learning and physics-informed learning have persistent limitations. Indicatively, strong assumptions regarding the data likelihood are required, the performance highly depends on the selection of priors, and the posterior can be sampled only approximately, which leads to poor approximations because of the associated computational cost. This paper introduces and studies confidence interval (CI) estimation for deterministic partial differential equations as a novel problem. That is, to propagate confidence, in the form of CIs, from data locations to the entire domain with probabilistic guarantees. We propose a method, termed Physics-Informed Confidence Propagation (PICProp), based on bi-level optimization to compute a valid CI without making heavy assumptions. We provide a theorem regarding the validity of our method, and computational experiments, where the focus is on physics-informed learning.", "url": "https://arxiv.org/abs/2310.06923"}, {"metadata": {"arXiv": "2310.07177", "Date": "Wed, 11 Oct 2023 04:03:42 ", "Title": "Online Speculative Decoding", "Authors": ["Xiaoxuan Liu", "Lanxiang Hu", "Peter Bailis", "Ion Stoica", "Zhijie Deng", "Alvin Cheung", "Hao Zhang"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models. We introduce online speculative decoding (OSD) to address this challenge. The main idea is to continually update (multiple) draft model(s) on observed user query data using the abundant excess computational power in an LLM serving cluster. Given that LLM inference is memory-bounded, the surplus computational power in a typical LLM serving cluster can be repurposed for online retraining of draft models, thereby making the training cost-neutral. Since the query distribution of an LLM service is relatively simple, retraining on query distribution enables the draft model to more accurately predict the target model's outputs, particularly on data originating from query distributions. As the draft model evolves online, it aligns with the query distribution in real time, mitigating distribution shifts. We develop a prototype of online speculative decoding based on online knowledge distillation and evaluate it using both synthetic and real query data on several popular LLMs. The results show a substantial increase in the token acceptance rate by 0.1 to 0.65, which translates into 1.22x to 3.06x latency reduction.", "url": "https://arxiv.org/abs/2310.07177"}, {"metadata": {"arXiv": "2310.07204", "Date": "Wed, 11 Oct 2023 05:32:29 ", "Title": "State of the Art on Diffusion Models for Visual Computing", "Authors": ["Ryan Po", "Wang Yifan", "Vladislav Golyanik", "Kfir Aberman", "Jonathan T. Barron", "Amit H. Bermano", "Eric Ryan Chan", "Tali Dekel", "Aleksander Holynski", "Angjoo Kanazawa", "C. Karen Liu", "Lingjie Liu", "Ben Mildenhall", "Matthias Nie{\\ss}ner", "Bj\\\"orn Ommer", "Christian Theobalt", "Peter Wonka", "Gordon Wetzstein"], "Categories": "cs.AI cs.GR cs.LG"}, "abstract": "The field of visual computing is rapidly advancing due to the emergence of generative artificial intelligence (AI), which unlocks unprecedented capabilities for the generation, editing, and reconstruction of images, videos, and 3D scenes. In these domains, diffusion models are the generative AI architecture of choice. Within the last year alone, the literature on diffusion-based tools and applications has seen exponential growth and relevant papers are published across the computer graphics, computer vision, and AI communities with new works appearing daily on arXiv. This rapid growth of the field makes it difficult to keep up with all recent developments. The goal of this state-of-the-art report (STAR) is to introduce the basic mathematical concepts of diffusion models, implementation details and design choices of the popular Stable Diffusion model, as well as overview important aspects of these generative AI tools, including personalization, conditioning, inversion, among others. Moreover, we give a comprehensive overview of the rapidly growing literature on diffusion-based generation and editing, categorized by the type of generated medium, including 2D images, videos, 3D objects, locomotion, and 4D scenes. Finally, we discuss available datasets, metrics, open challenges, and social implications. This STAR provides an intuitive starting point to explore this exciting topic for researchers, artists, and practitioners alike.", "url": "https://arxiv.org/abs/2310.07204"}, {"metadata": {"arXiv": "2310.07221", "Date": "Wed, 11 Oct 2023 06:11:11 ", "Title": "Using Learnable Physics for Real-Time Exercise Form Recommendations", "Authors": ["Abhishek Jaiswal", "Gautam Chauhan", "Nisheeth Srivastava"], "Categories": "cs.AI cs.HC cs.LG", "Comments": ["Accepted by ACM RecSys '23", "12 pages ", "7 Figures"], "Journal-ref": "Seventeenth ACM Conference on Recommender Systems (RecSys 2023)", "DOI": "10.1145/3604915.3608816"}, "abstract": "Good posture and form are essential for safe and productive exercising. Even in gym settings, trainers may not be readily available for feedback. Rehabilitation therapies and fitness workouts can thus benefit from recommender systems that provide real-time evaluation. In this paper, we present an algorithmic pipeline that can diagnose problems in exercise techniques and offer corrective recommendations, with high sensitivity and specificity in real-time. We use MediaPipe for pose recognition, count repetitions using peak-prominence detection, and use a learnable physics simulator to track motion evolution for each exercise. A test video is diagnosed based on deviations from the prototypical learned motion using statistical learning. The system is evaluated on six full and upper body exercises. These real-time recommendations, counseled via low-cost equipment like smartphones, will allow exercisers to rectify potential mistakes making self-practice feasible while reducing the risk of workout injuries.", "url": "https://arxiv.org/abs/2310.07221"}, {"metadata": {"arXiv": "2310.07298", "Date": "Wed, 11 Oct 2023 08:32:46 ", "Title": "Beyond Memorization: Violating Privacy Via Inference with Large Language Models", "Authors": ["Robin Staab", "Mark Vero", "Mislav Balunovi\\'c", "Martin Vechev"], "Categories": "cs.AI cs.LG", "ACM-class": "I.2.7"}, "abstract": "Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models' inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals' privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to $85\\%$ top-1 and $95.8\\%$ top-3 accuracy at a fraction of the cost ($100\\times$) and time ($240\\times$) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemingly benign questions. Finally, we show that common mitigations, i.e., text anonymization and model alignment, are currently ineffective at protecting user privacy against LLM inference. Our findings highlight that current LLMs can infer personal data at a previously unattainable scale. In the absence of working defenses, we advocate for a broader discussion around LLM privacy implications beyond memorization, striving for a wider privacy protection.", "url": "https://arxiv.org/abs/2310.07298"}, {"metadata": {"arXiv": "2310.07417", "Date": "Wed, 11 Oct 2023 12:03:19 ", "Title": "What can knowledge graph alignment gain with Neuro-Symbolic learning approaches?", "Authors": ["Pedro Giesteira Cotovio", "Ernesto Jimenez-Ruiz", "Catia Pesquita"], "Categories": "cs.AI cs.LG cs.SC"}, "abstract": "Knowledge Graphs (KG) are the backbone of many data-intensive applications since they can represent data coupled with its meaning and context. Aligning KGs across different domains and providers is necessary to afford a fuller and integrated representation. A severe limitation of current KG alignment (KGA) algorithms is that they fail to articulate logical thinking and reasoning with lexical, structural, and semantic data learning. Deep learning models are increasingly popular for KGA inspired by their good performance in other tasks, but they suffer from limitations in explainability, reasoning, and data efficiency. Hybrid neurosymbolic learning models hold the promise of integrating logical and data perspectives to produce high-quality alignments that are explainable and support validation through human-centric approaches. This paper examines the current state of the art in KGA and explores the potential for neurosymbolic integration, highlighting promising research directions for combining these fields.", "url": "https://arxiv.org/abs/2310.07417"}, {"metadata": {"arXiv": "2310.07534", "Date": "Wed, 11 Oct 2023 14:39:12 ", "Title": "Human-Centered Evaluation of XAI Methods", "Authors": ["Karam Dawoud", "Wojciech Samek", "Sebastian Lapuschkin", "Sebastian Bosse"], "Categories": "cs.AI cs.CV cs.LG"}, "abstract": "In the ever-evolving field of Artificial Intelligence, a critical challenge has been to decipher the decision-making processes within the so-called \"black boxes\" in deep learning. Over recent years, a plethora of methods have emerged, dedicated to explaining decisions across diverse tasks. Particularly in tasks like image classification, these methods typically identify and emphasize the pivotal pixels that most influence a classifier's prediction. Interestingly, this approach mirrors human behavior: when asked to explain our rationale for classifying an image, we often point to the most salient features or aspects. Capitalizing on this parallel, our research embarked on a user-centric study. We sought to objectively measure the interpretability of three leading explanation methods: (1) Prototypical Part Network, (2) Occlusion, and (3) Layer-wise Relevance Propagation. Intriguingly, our results highlight that while the regions spotlighted by these methods can vary widely, they all offer humans a nearly equivalent depth of understanding. This enables users to discern and categorize images efficiently, reinforcing the value of these methods in enhancing AI transparency.", "url": "https://arxiv.org/abs/2310.07534"}, {"metadata": {"arXiv": "2310.07644", "Date": "Wed, 11 Oct 2023 16:40:57 ", "Title": "Rethinking the BERT-like Pretraining for DNA Sequences", "Authors": ["Chaoqi Liang", "Weiqiang Bai", "Lifeng Qiao", "Yuchen Ren", "Jianle Sun", "Peng Ye", "Hongliang Yan", "Xinzhu Ma", "Wangmeng Zuo", "and Wanli Ouyang"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "With the success of large-scale pretraining in NLP, there is an increasing trend of applying it to the domain of life sciences. In particular, pretraining methods based on DNA sequences have garnered growing attention due to their potential to capture generic information about genes. However, existing pretraining methods for DNA sequences largely rely on direct adoptions of BERT pretraining from NLP, lacking a comprehensive understanding and a specifically tailored approach. To address this research gap, we first conducted a series of exploratory experiments and gained several insightful observations: 1) In the fine-tuning phase of downstream tasks, when using K-mer overlapping tokenization instead of K-mer non-overlapping tokenization, both overlapping and non-overlapping pretraining weights show consistent performance improvement.2) During the pre-training process, using K-mer overlapping tokenization quickly produces clear K-mer embeddings and reduces the loss to a very low level, while using K-mer non-overlapping tokenization results in less distinct embeddings and continuously decreases the loss. 3) Using overlapping tokenization causes the self-attention in the intermediate layers of pre-trained models to tend to overly focus on certain tokens, reflecting that these layers are not adequately optimized. In summary, overlapping tokenization can benefit the fine-tuning of downstream tasks but leads to inadequate pretraining with fast convergence. To unleash the pretraining potential, we introduce a novel approach called RandomMask, which gradually increases the task difficulty of BERT-like pretraining by continuously expanding its mask boundary, forcing the model to learn more knowledge. RandomMask is simple but effective, achieving top-tier performance across 26 datasets of 28 datasets spanning 7 downstream tasks.", "url": "https://arxiv.org/abs/2310.07644"}, {"metadata": {"arXiv": "2310.07665", "Date": "Wed, 11 Oct 2023 17:11:10 ", "Title": "Deep Backtracking Counterfactuals for Causally Compliant Explanations", "Authors": ["Klaus-Rudolf Kladny", "Julius von K\\\"ugelgen", "Bernhard Sch\\\"olkopf", "Michael Muehlebach"], "Categories": "cs.AI cs.LG stat.ML"}, "abstract": "Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. We demonstrate these properties experimentally on a modified version of MNIST and CelebA.", "url": "https://arxiv.org/abs/2310.07665"}, {"metadata": {"arXiv": "2310.07698", "Date": "Wed, 11 Oct 2023 17:46:59 ", "Title": "SurroCBM: Concept Bottleneck Surrogate Models for Generative Post-hoc Explanation", "Authors": ["Bo Pan", "Zhenke Liu", "Yifei Zhang", "Liang Zhao"], "Categories": "cs.AI cs.LG"}, "abstract": "Explainable AI seeks to bring light to the decision-making processes of black-box models. Traditional saliency-based methods, while highlighting influential data segments, often lack semantic understanding. Recent advancements, such as Concept Activation Vectors (CAVs) and Concept Bottleneck Models (CBMs), offer concept-based explanations but necessitate human-defined concepts. However, human-annotated concepts are expensive to attain. This paper introduces the Concept Bottleneck Surrogate Models (SurroCBM), a novel framework that aims to explain the black-box models with automatically discovered concepts. SurroCBM identifies shared and unique concepts across various black-box models and employs an explainable surrogate model for post-hoc explanations. An effective training strategy using self-generated data is proposed to enhance explanation quality continuously. Through extensive experiments, we demonstrate the efficacy of SurroCBM in concept discovery and explanation, underscoring its potential in advancing the field of explainable AI.", "url": "https://arxiv.org/abs/2310.07698"}, {"metadata": {"arXiv": "2310.06848", "Date": "Tue, 05 Sep 2023 18:35:34 ", "Title": "DeepTriNet: A Tri-Level Attention Based DeepLabv3+ Architecture for Semantic Segmentation of Satellite Images", "Authors": ["Tareque Bashar Ovi", "Shakil Mosharrof", "Nomaiya Bashree", "Md Shofiqul Islam", "and Muhammad Nazrul Islam"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Keywords: Attention mechanism", "Deep learning", "Satellite image", "DeepLabv3+", "Segmentation"]}, "abstract": "The segmentation of satellite images is crucial in remote sensing applications. Existing methods face challenges in recognizing small-scale objects in satellite images for semantic segmentation primarily due to ignoring the low-level characteristics of the underlying network and due to containing distinct amounts of information by different feature maps. Thus, in this research, a tri-level attention-based DeepLabv3+ architecture (DeepTriNet) is proposed for the semantic segmentation of satellite images. The proposed hybrid method combines squeeze-and-excitation networks (SENets) and tri-level attention units (TAUs) with the vanilla DeepLabv3+ architecture, where the TAUs are used to bridge the semantic feature gap among encoders output and the SENets used to put more weight on relevant features. The proposed DeepTriNet finds which features are the more relevant and more generalized way by its self-supervision rather we annotate them. The study showed that the proposed DeepTriNet performs better than many conventional techniques with an accuracy of 98% and 77%, IoU 80% and 58%, precision 88% and 68%, and recall of 79% and 55% on the 4-class Land-Cover.ai dataset and the 15-class GID-2 dataset respectively. The proposed method will greatly contribute to natural resource management and change detection in rural and urban regions through efficient and semantic satellite image segmentation", "url": "https://arxiv.org/abs/2310.06848"}, {"metadata": {"arXiv": "2310.06966", "Date": "Tue, 10 Oct 2023 19:32:59 ", "Title": "On the Interpretability of Part-Prototype Based Classifiers: A Human Centric Analysis", "Authors": ["Omid Davoodi", "Shayan Mohammadizadehsamakosh", "Majid Komeili"], "Categories": "cs.CV cs.AI cs.HC cs.LG", "Comments": ["Intended for submission to Nature Scientific Reports"]}, "abstract": "Part-prototype networks have recently become methods of interest as an interpretable alternative to many of the current black-box image classifiers. However, the interpretability of these methods from the perspective of human users has not been sufficiently explored. In this work, we have devised a framework for evaluating the interpretability of part-prototype-based models from a human perspective. The proposed framework consists of three actionable metrics and experiments. To demonstrate the usefulness of our framework, we performed an extensive set of experiments using Amazon Mechanical Turk. They not only show the capability of our framework in assessing the interpretability of various part-prototype-based models, but they also are, to the best of our knowledge, the most comprehensive work on evaluating such methods in a unified framework.", "url": "https://arxiv.org/abs/2310.06966"}, {"metadata": {"arXiv": "2310.07028", "Date": "Tue, 10 Oct 2023 21:30:05 ", "Title": "Facial Forgery-based Deepfake Detection using Fine-Grained Features", "Authors": ["Aakash Varma Nadimpalli", "Ajita Rattani"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "2 figures"]}, "abstract": "Facial forgery by deepfakes has caused major security risks and raised severe societal concerns. As a countermeasure, a number of deepfake detection methods have been proposed. Most of them model deepfake detection as a binary classification problem using a backbone convolutional neural network (CNN) architecture pretrained for the task. These CNN-based methods have demonstrated very high efficacy in deepfake detection with the Area under the Curve (AUC) as high as $0.99$. However, the performance of these methods degrades significantly when evaluated across datasets and deepfake manipulation techniques. This draws our attention towards learning more subtle, local, and discriminative features for deepfake detection. In this paper, we formulate deepfake detection as a fine-grained classification problem and propose a new fine-grained solution to it. Specifically, our method is based on learning subtle and generalizable features by effectively suppressing background noise and learning discriminative features at various scales for deepfake detection. Through extensive experimental validation, we demonstrate the superiority of our method over the published research in cross-dataset and cross-manipulation generalization of deepfake detectors for the majority of the experimental scenarios.", "url": "https://arxiv.org/abs/2310.07028"}, {"metadata": {"arXiv": "2310.07033", "Date": "Tue, 10 Oct 2023 21:40:19 ", "Title": "Computational Pathology at Health System Scale -- Self-Supervised Foundation Models from Three Billion Images", "Authors": ["Gabriele Campanella", "Ricky Kwan", "Eugene Fluder", "Jennifer Zeng", "Aryeh Stock", "Brandon Veremis", "Alexandros D. Polydorides", "Cyrus Hedvat", "Adam Schoenfeld", "Chad Vanderbilt", "Patricia Kovatch", "Carlos Cordon-Cardo", "Thomas J. Fuchs"], "Categories": "cs.CV cs.AI cs.LG eess.IV"}, "abstract": "Recent breakthroughs in self-supervised learning have enabled the use of large unlabeled datasets to train visual foundation models that can generalize to a variety of downstream tasks. While this training paradigm is well suited for the medical domain where annotations are scarce, large-scale pre-training in the medical domain, and in particular pathology, has not been extensively studied. Previous work in self-supervised learning in pathology has leveraged smaller datasets for both pre-training and evaluating downstream performance. The aim of this project is to train the largest academic foundation model and benchmark the most prominent self-supervised learning algorithms by pre-training and evaluating downstream performance on large clinical pathology datasets. We collected the largest pathology dataset to date, consisting of over 3 billion images from over 423 thousand microscopy slides. We compared pre-training of visual transformer models using the masked autoencoder (MAE) and DINO algorithms. We evaluated performance on six clinically relevant tasks from three anatomic sites and two institutions: breast cancer detection, inflammatory bowel disease detection, breast cancer estrogen receptor prediction, lung adenocarcinoma EGFR mutation prediction, and lung cancer immunotherapy response prediction. Our results demonstrate that pre-training on pathology data is beneficial for downstream performance compared to pre-training on natural images. Additionally, the DINO algorithm achieved better generalization performance across all tasks tested. The presented results signify a phase change in computational pathology research, paving the way into a new era of more performant models based on large-scale, parallel pre-training at the billion-image scale.", "url": "https://arxiv.org/abs/2310.07033"}, {"metadata": {"arXiv": "2310.07379", "Date": "Wed, 11 Oct 2023 10:54:44 ", "Title": "Causal Unsupervised Semantic Segmentation", "Authors": ["Junho Kim", "Byung-Kwan Lee", "Yong Man Ro"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["code available: https://github.com/ByungKwanLee/Causal-Unsupervised-Segmentation"]}, "abstract": "Unsupervised semantic segmentation aims to achieve high-quality semantic grouping without human-labeled annotations. With the advent of self-supervised pre-training, various frameworks utilize the pre-trained features to train prediction heads for unsupervised dense prediction. However, a significant challenge in this unsupervised setup is determining the appropriate level of clustering required for segmenting concepts. To address it, we propose a novel framework, CAusal Unsupervised Semantic sEgmentation (CAUSE), which leverages insights from causal inference. Specifically, we bridge intervention-oriented approach (i.e., frontdoor adjustment) to define suitable two-step tasks for unsupervised prediction. The first step involves constructing a concept clusterbook as a mediator, which represents possible concept prototypes at different levels of granularity in a discretized form. Then, the mediator establishes an explicit link to the subsequent concept-wise self-supervised learning for pixel-level grouping. Through extensive experiments and analyses on various datasets, we corroborate the effectiveness of CAUSE and achieve state-of-the-art performance in unsupervised semantic segmentation.", "url": "https://arxiv.org/abs/2310.07379"}, {"metadata": {"arXiv": "2310.07678", "Date": "Wed, 11 Oct 2023 17:21:48 ", "Title": "Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM", "Authors": ["Ioannis E. Livieris", "Emmanuel Pintelas", "Niki Kiriakidou", "Panagiotis Pintelas"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["The manuscript has been submitted for publication in \"Journal of Imaging\""], "MSC-class": "68T45, 68T07"}, "abstract": "With the proliferation of image-based applications in various domains, the need for accurate and interpretable image similarity measures has become increasingly critical. Existing image similarity models often lack transparency, making it challenging to understand the reasons why two images are considered similar. In this paper, we propose the concept of explainable image similarity, where the goal is the development of an approach, which is capable of providing similarity scores along with visual factual and counterfactual explanations. Along this line, we present a new framework, which integrates Siamese Networks and Grad-CAM for providing explainable image similarity and discuss the potential benefits and challenges of adopting this approach. In addition, we provide a comprehensive discussion about factual and counterfactual explanations provided by the proposed framework for assisting decision making. The proposed approach has the potential to enhance the interpretability, trustworthiness and user acceptance of image-based systems in real-world image similarity applications. The implementation code can be found in https://github.com/ioannislivieris/Grad_CAM_Siamese.git.", "url": "https://arxiv.org/abs/2310.07678"}, {"metadata": {"arXiv": "2310.07699", "Date": "Wed, 11 Oct 2023 17:49:13 ", "Title": "From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched Captions", "Authors": ["Zhengfeng Lai", "Haotian Zhang", "Wentao Wu", "Haoping Bai", "Aleksei Timofeev", "Xianzhi Du", "Zhe Gan", "Jiulong Shan", "Chen-Nee Chuah", "Yinfei Yang", "Meng Cao"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["CV/ML"]}, "abstract": "Web-crawled datasets are pivotal to the success of pre-training vision-language models, exemplified by CLIP. However, web-crawled AltTexts can be noisy and potentially irrelevant to images, thereby undermining the crucial image-text alignment. Existing methods for rewriting captions using large language models (LLMs) have shown promise on small, curated datasets like CC3M and CC12M. Nevertheless, their efficacy on massive web-captured captions is constrained by the inherent noise and randomness in such data. In this study, we address this limitation by focusing on two key aspects: data quality and data variety. Unlike recent LLM rewriting techniques, we emphasize exploiting visual concepts and their integration into the captions to improve data quality. For data variety, we propose a novel mixed training scheme that optimally leverages AltTexts alongside newly generated Visual-enriched Captions (VeC). We use CLIP as one example and adapt the method for CLIP training on large-scale web-crawled datasets, named VeCLIP. We conduct a comprehensive evaluation of VeCLIP across small, medium, and large scales of raw data. Our results show significant advantages in image-text alignment and overall model performance, underscoring the effectiveness of VeCLIP in improving CLIP training. For example, VeCLIP achieves a remarkable over 20% improvement in COCO and Flickr30k retrieval tasks under the 12M setting. For data efficiency, we also achieve a notable over 3% improvement while using only 14% of the data employed in the vanilla CLIP and 11% in ALIGN.", "url": "https://arxiv.org/abs/2310.07699"}, {"metadata": {"arXiv": "2310.07078", "Date": "Sat, 05 Aug 2023 22:38:05 ", "Title": "Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling", "Authors": ["Clay H. Yoo and Ashiqur R. KhudaBukhsh"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["This paper has been accepted at AAAI 2023 (Robust and Safe AI track)"]}, "abstract": "This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers' strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.", "url": "https://arxiv.org/abs/2310.07078"}, {"metadata": {"arXiv": "2310.07123", "Date": "Wed, 11 Oct 2023 01:52:42 ", "Title": "Off-Policy Evaluation for Human Feedback", "Authors": ["Qitong Gao", "Juncheng Dong", "Vahid Tarokh", "Min Chi", "Miroslav Pajic"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Off-policy evaluation (OPE) is important for closing the gap between offline training and evaluation of reinforcement learning (RL), by estimating performance and/or rank of target (evaluation) policies using offline trajectories only. It can improve the safety and efficiency of data collection and policy testing procedures in situations where online deployments are expensive, such as healthcare. However, existing OPE methods fall short in estimating human feedback (HF) signals, as HF may be conditioned over multiple underlying factors and is only sparsely available; as opposed to the agent-defined environmental rewards (used in policy optimization), which are usually determined over parametric functions or distributions. Consequently, the nature of HF signals makes extrapolating accurate OPE estimations to be challenging. To resolve this, we introduce an OPE for HF (OPEHF) framework that revives existing OPE methods in order to accurately evaluate the HF signals. Specifically, we develop an immediate human reward (IHR) reconstruction approach, regularized by environmental knowledge distilled in a latent space that captures the underlying dynamics of state transitions as well as issuing HF signals. Our approach has been tested over two real-world experiments, adaptive in-vivo neurostimulation and intelligent tutoring, as well as in a simulation environment (visual Q&A). Results show that our approach significantly improves the performance toward estimating HF signals accurately, compared to directly applying (variants of) existing OPE methods.", "url": "https://arxiv.org/abs/2310.07123"}, {"metadata": {"arXiv": "2310.07219", "Date": "Wed, 11 Oct 2023 06:09:48 ", "Title": "Improved Membership Inference Attacks Against Language Classification Models", "Authors": ["Shlomit Shachor", "Natalia Razinkov", "Abigail Goldsteen"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Artificial intelligence systems are prevalent in everyday life, with use cases in retail, manufacturing, health, and many other fields. With the rise in AI adoption, associated risks have been identified, including privacy risks to the people whose data was used to train models. Assessing the privacy risks of machine learning models is crucial to enabling knowledgeable decisions on whether to use, deploy, or share a model. A common approach to privacy risk assessment is to run one or more known attacks against the model and measure their success rate. We present a novel framework for running membership inference attacks against classification models. Our framework takes advantage of the ensemble method, generating many specialized attack models for different subsets of the data. We show that this approach achieves higher accuracy than either a single attack model or an attack model per class label, both on classical and language classification tasks.", "url": "https://arxiv.org/abs/2310.07219"}, {"metadata": {"arXiv": "2310.07253", "Date": "Wed, 11 Oct 2023 07:30:18 ", "Title": "ADMEOOD: Out-of-Distribution Benchmark for Drug Property Prediction", "Authors": ["Shuoying Wei", "Xinlong Wen", "Lida Zhu", "Songquan Li", "Rongbo Zhu"], "Categories": "cs.LG cs.AI q-bio.QM"}, "abstract": "Obtaining accurate and valid information for drug molecules is a crucial and challenging task. However, chemical knowledge and information have been accumulated over the past 100 years from various regions, laboratories, and experimental purposes. Little has been explored in terms of the out-of-distribution (OOD) problem with noise and inconsistency, which may lead to weak robustness and unsatisfied performance. This study proposes a novel benchmark ADMEOOD, a systematic OOD dataset curator and benchmark specifically designed for drug property prediction. ADMEOOD obtained 27 ADME (Absorption, Distribution, Metabolism, Excretion) drug properties from Chembl and relevant literature. Additionally, it includes two kinds of OOD data shifts: Noise Shift and Concept Conflict Drift (CCD). Noise Shift responds to the noise level by categorizing the environment into different confidence levels. On the other hand, CCD describes the data which has inconsistent label among the original data. Finally, it tested on a variety of domain generalization models, and the experimental results demonstrate the effectiveness of the proposed partition method in ADMEOOD: ADMEOOD demonstrates a significant difference performance between in-distribution and out-of-distribution data. Moreover, ERM (Empirical Risk Minimization) and other models exhibit distinct trends in performance across different domains and measurement types.", "url": "https://arxiv.org/abs/2310.07253"}, {"metadata": {"arXiv": "2310.07325", "Date": "Wed, 11 Oct 2023 09:14:40 ", "Title": "An Adversarial Example for Direct Logit Attribution: Memory Management in gelu-4l", "Authors": ["James Dao", "Yeu-Tong Lao", "Can Rager", "Jett Janiak"], "Categories": "cs.LG cs.AI"}, "abstract": "We provide concrete evidence for memory management in a 4-layer transformer. Specifically, we identify clean-up behavior, in which model components consistently remove the output of preceeding components during a forward pass. Our findings suggest that the interpretability technique Direct Logit Attribution provides misleading results. We show explicit examples where this technique is inaccurate, as it does not account for clean-up behavior.", "url": "https://arxiv.org/abs/2310.07325"}, {"metadata": {"arXiv": "2310.07380", "Date": "Wed, 11 Oct 2023 10:55:14 ", "Title": "Histopathological Image Classification and Vulnerability Analysis using Federated Learning", "Authors": ["Sankalp Vyas", "Amar Nath Patra", "Raj Mani Shukla"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted in IEEE International Conference on Trust", "Security and Privacy in Computing and Communications (TrustCom)"]}, "abstract": "Healthcare is one of the foremost applications of machine learning (ML). Traditionally, ML models are trained by central servers, which aggregate data from various distributed devices to forecast the results for newly generated data. This is a major concern as models can access sensitive user information, which raises privacy concerns. A federated learning (FL) approach can help address this issue: A global model sends its copy to all clients who train these copies, and the clients send the updates (weights) back to it. Over time, the global model improves and becomes more accurate. Data privacy is protected during training, as it is conducted locally on the clients' devices. However, the global model is susceptible to data poisoning. We develop a privacy-preserving FL technique for a skin cancer dataset and show that the model is prone to data poisoning attacks. Ten clients train the model, but one of them intentionally introduces flipped labels as an attack. This reduces the accuracy of the global model. As the percentage of label flipping increases, there is a noticeable decrease in accuracy. We use a stochastic gradient descent optimization algorithm to find the most optimal accuracy for the model. Although FL can protect user privacy for healthcare diagnostics, it is also vulnerable to data poisoning, which must be addressed.", "url": "https://arxiv.org/abs/2310.07380"}, {"metadata": {"arXiv": "2310.07402", "Date": "Wed, 11 Oct 2023 11:38:18 ", "Title": "NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining", "Authors": ["Chenguo Lin", "Xumeng Wen", "Wei Cao", "Congrui Huang", "Jiang Bian", "Stephen Lin", "Zhirong Wu"], "Categories": "cs.LG cs.AI"}, "abstract": "Recent research on time-series self-supervised models shows great promise in learning semantic representations. However, it has been limited to small-scale datasets, e.g., thousands of temporal sequences. In this work, we make key technical contributions that are tailored to the numerical properties of time-series data and allow the model to scale to large datasets, e.g., millions of temporal sequences. We adopt the Transformer architecture by first partitioning the input into non-overlapping windows. Each window is then characterized by its normalized shape and two scalar values denoting the mean and standard deviation within each window. To embed scalar values that may possess arbitrary numerical scales to high-dimensional vectors, we propose a numerically multi-scaled embedding module enumerating all possible scales for the scalar values. The model undergoes pretraining using the proposed numerically multi-scaled embedding with a simple contrastive objective on a large-scale dataset containing over a million sequences. We study its transfer performance on a number of univariate and multivariate classification benchmarks. Our method exhibits remarkable improvement against previous representation learning approaches and establishes the new state of the art, even compared with domain-specific non-learning-based methods.", "url": "https://arxiv.org/abs/2310.07402"}, {"metadata": {"arXiv": "2310.07418", "Date": "Wed, 11 Oct 2023 12:05:34 ", "Title": "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages", "Authors": ["Guozheng Ma", "Lu Li", "Sen Zhang", "Zixuan Liu", "Zhen Wang", "Yixin Chen", "Li Shen", "Xueqian Wang", "Dacheng Tao"], "Categories": "cs.LG cs.AI"}, "abstract": "Plasticity, the ability of a neural network to evolve with new data, is crucial for high-performance and sample-efficient visual reinforcement learning (VRL). Although methods like resetting and regularization can potentially mitigate plasticity loss, the influences of various components within the VRL framework on the agent's plasticity are still poorly understood. In this work, we conduct a systematic empirical exploration focusing on three primary underexplored facets and derive the following insightful conclusions: (1) data augmentation is essential in maintaining plasticity; (2) the critic's plasticity loss serves as the principal bottleneck impeding efficient training; and (3) without timely intervention to recover critic's plasticity in the early stages, its loss becomes catastrophic. These insights suggest a novel strategy to address the high replay ratio (RR) dilemma, where exacerbated plasticity loss hinders the potential improvements of sample efficiency brought by increased reuse frequency. Rather than setting a static RR for the entire training process, we propose Adaptive RR, which dynamically adjusts the RR based on the critic's plasticity level. Extensive evaluations indicate that Adaptive RR not only avoids catastrophic plasticity loss in the early stages but also benefits from more frequent reuse in later phases, resulting in superior sample efficiency.", "url": "https://arxiv.org/abs/2310.07418"}, {"metadata": {"arXiv": "2310.07497", "Date": "Wed, 11 Oct 2023 13:50:28 ", "Title": "Sample-Driven Federated Learning for Energy-Efficient and Real-Time IoT Sensing", "Authors": ["Minh Ngoc Luu", "Minh-Duong Nguyen", "Ebrahim Bedeer", "Van Duc Nguyen", "Dinh Thai Hoang", "Diep N. Nguyen", "Quoc-Viet Pham"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages", "5 figures"], "MSC-class": "68-00", "ACM-class": "I.2.11"}, "abstract": "In the domain of Federated Learning (FL) systems, recent cutting-edge methods heavily rely on ideal conditions convergence analysis. Specifically, these approaches assume that the training datasets on IoT devices possess similar attributes to the global data distribution. However, this approach fails to capture the full spectrum of data characteristics in real-time sensing FL systems. In order to overcome this limitation, we suggest a new approach system specifically designed for IoT networks with real-time sensing capabilities. Our approach takes into account the generalization gap due to the user's data sampling process. By effectively controlling this sampling process, we can mitigate the overfitting issue and improve overall accuracy. In particular, We first formulate an optimization problem that harnesses the sampling process to concurrently reduce overfitting while maximizing accuracy. In pursuit of this objective, our surrogate optimization problem is adept at handling energy efficiency while optimizing the accuracy with high generalization. To solve the optimization problem with high complexity, we introduce an online reinforcement learning algorithm, named Sample-driven Control for Federated Learning (SCFL) built on the Soft Actor-Critic (A2C) framework. This enables the agent to dynamically adapt and find the global optima even in changing environments. By leveraging the capabilities of SCFL, our system offers a promising solution for resource allocation in FL systems with real-time sensing capabilities.", "url": "https://arxiv.org/abs/2310.07497"}, {"metadata": {"arXiv": "2310.07535", "Date": "Wed, 11 Oct 2023 14:39:51 ", "Title": "Improving Fairness-Accuracy tradeoff with few Test Samples under Covariate Shift", "Authors": ["Shreyas Havaldar", "Jatin Chauhan", "Karthikeyan Shanmugam", "Jay Nandy", "Aravindan Raghuveer"], "Categories": "cs.LG cs.AI"}, "abstract": "Covariate shift in the test data can significantly downgrade both the accuracy and the fairness performance of the model. Ensuring fairness across different sensitive groups in such settings is of paramount importance due to societal implications like criminal justice. We operate under the unsupervised regime where only a small set of unlabeled test samples along with a labeled training set is available. Towards this problem, we make three contributions. First is a novel composite weighted entropy based objective for prediction accuracy which is optimized along with a representation matching loss for fairness. We experimentally verify that optimizing with our loss formulation outperforms a number of state-of-the-art baselines in the pareto sense with respect to the fairness-accuracy tradeoff on several standard datasets. Our second contribution is a new setting we term Asymmetric Covariate Shift that, to the best of our knowledge, has not been studied before. Asymmetric covariate shift occurs when distribution of covariates of one group shifts significantly compared to the other groups and this happens when a dominant group is over-represented. While this setting is extremely challenging for current baselines, We show that our proposed method significantly outperforms them. Our third contribution is theoretical, where we show that our weighted entropy term along with prediction loss on the training set approximates test loss under covariate shift. Empirically and through formal sample complexity bounds, we show that this approximation to the unseen test loss does not depend on importance sampling variance which affects many other baselines.", "url": "https://arxiv.org/abs/2310.07535"}, {"metadata": {"arXiv": "2310.07560", "Date": "Wed, 11 Oct 2023 15:04:33 ", "Title": "ROMO: Retrieval-enhanced Offline Model-based Optimization", "Authors": ["Mingcheng Chen", "Haoran Zhao", "Yuxiang Zhao", "Hulei Fan", "Hongqiao Gao", "Yong Yu", "Zheng Tian"], "Categories": "cs.LG cs.AI", "Comments": ["15 pages", "9 figures"]}, "abstract": "Data-driven black-box model-based optimization (MBO) problems arise in a great number of practical application scenarios, where the goal is to find a design over the whole space maximizing a black-box target function based on a static offline dataset. In this work, we consider a more general but challenging MBO setting, named constrained MBO (CoMBO), where only part of the design space can be optimized while the rest is constrained by the environment. A new challenge arising from CoMBO is that most observed designs that satisfy the constraints are mediocre in evaluation. Therefore, we focus on optimizing these mediocre designs in the offline dataset while maintaining the given constraints rather than further boosting the best observed design in the traditional MBO setting. We propose retrieval-enhanced offline model-based optimization (ROMO), a new derivable forward approach that retrieves the offline dataset and aggregates relevant samples to provide a trusted prediction, and use it for gradient-based optimization. ROMO is simple to implement and outperforms state-of-the-art approaches in the CoMBO setting. Empirically, we conduct experiments on a synthetic Hartmann (3D) function dataset, an industrial CIO dataset, and a suite of modified tasks in the Design-Bench benchmark. Results show that ROMO performs well in a wide range of constrained optimization tasks.", "url": "https://arxiv.org/abs/2310.07560"}, {"metadata": {"arXiv": "2310.07579", "Date": "Wed, 11 Oct 2023 15:19:31 ", "Title": "In-Context Unlearning: Language Models as Few Shot Unlearners", "Authors": ["Martin Pawelczyk", "Seth Neel", "Himabindu Lakkaraju"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Machine unlearning, the study of efficiently removing the impact of specific training points on the trained model, has garnered increased attention of late, driven by the need to comply with privacy regulations like the \\emph{Right to be Forgotten}. Although unlearning is particularly relevant for LLMs in light of the copyright issues they raise, achieving precise unlearning is computationally infeasible for very large models. To this end, recent work has proposed several algorithms which approximate the removal of training data without retraining the model. These algorithms crucially rely on access to the model parameters in order to update them, an assumption that may not hold in practice due to computational constraints or when the LLM is accessed via API. In this work, we propose a new class of unlearning methods for LLMs we call ``In-Context Unlearning'', providing inputs in context and without having to update model parameters. To unlearn a particular training instance, we provide the instance alongside a flipped label and additional correctly labelled instances which are prepended as inputs to the LLM at inference time. Our experimental results demonstrate that these contexts effectively remove specific information from the training set while maintaining performance levels that are competitive with (or in some cases exceed) state-of-the-art unlearning methods that require access to the LLM parameters.", "url": "https://arxiv.org/abs/2310.07579"}, {"metadata": {"arXiv": "2310.07582", "Date": "Wed, 11 Oct 2023 15:20:07 ", "Title": "Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT", "Authors": ["Dean S. Hazineh", "Zechen Zhang", "Jeffery Chiu"], "Categories": "cs.LG cs.AI"}, "abstract": "Foundation models exhibit significant capabilities in decision-making and logical deductions. Nonetheless, a continuing discourse persists regarding their genuine understanding of the world as opposed to mere stochastic mimicry. This paper meticulously examines a simple transformer trained for Othello, extending prior research to enhance comprehension of the emergent world model of Othello-GPT. The investigation reveals that Othello-GPT encapsulates a linear representation of opposing pieces, a factor that causally steers its decision-making process. This paper further elucidates the interplay between the linear world representation and causal decision-making, and their dependence on layer depth and model complexity. We have made the code public.", "url": "https://arxiv.org/abs/2310.07582"}, {"metadata": {"arXiv": "2310.07587", "Date": "Wed, 11 Oct 2023 15:28:39 ", "Title": "Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer", "Authors": ["Zikai Xiao", "Zihan Chen", "Songshang Liu", "Hualiang Wang", "Yang Feng", "Jin Hao", "Joey Tianyi Zhou", "Jian Wu", "Howard Hao Yang", "Zuozhu Liu"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by NeurIPS 2023"], "ACM-class": "I.2.0"}, "abstract": "Data privacy and long-tailed distribution are the norms rather than the exception in many real-world tasks. This paper investigates a federated long-tailed learning (Fed-LT) task in which each client holds a locally heterogeneous dataset; if the datasets can be globally aggregated, they jointly exhibit a long-tailed distribution. Under such a setting, existing federated optimization and/or centralized long-tailed learning methods hardly apply due to challenges in (a) characterizing the global long-tailed distribution under privacy constraints and (b) adjusting the local learning strategy to cope with the head-tail imbalance. In response, we propose a method termed $\\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB) module that re-weights clients' gradients in a closed-loop manner, based on the feedback of global long-tailed distribution evaluated by a Direct Prior Analyzer (DPA) module. Using $\\texttt{Fed-GraB}$, clients can effectively alleviate the distribution drift caused by data heterogeneity during the model training process and obtain a global model with better performance on the minority classes while maintaining the performance of the majority classes. Extensive experiments demonstrate that $\\texttt{Fed-GraB}$ achieves state-of-the-art performance on representative datasets such as CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist.", "url": "https://arxiv.org/abs/2310.07587"}, {"metadata": {"arXiv": "2310.07598", "Date": "Wed, 11 Oct 2023 15:38:53 ", "Title": "Survey on Imbalanced Data, Representation Learning and SEP Forecasting", "Authors": ["Josias Moukpe"], "Categories": "cs.LG cs.AI", "Comments": ["Survey Paper", "4 figures", "16 pages"]}, "abstract": "Deep Learning methods have significantly advanced various data-driven tasks such as regression, classification, and forecasting. However, much of this progress has been predicated on the strong but often unrealistic assumption that training datasets are balanced with respect to the targets they contain. This misalignment with real-world conditions, where data is frequently imbalanced, hampers the effectiveness of such models in practical applications. Methods that reconsider that assumption and tackle real-world imbalances have begun to emerge and explore avenues to address this challenge. One such promising avenue is representation learning, which enables models to capture complex data characteristics and generalize better to minority classes. By focusing on a richer representation of the feature space, these techniques hold the potential to mitigate the impact of data imbalance. In this survey, we present deep learning works that step away from the balanced-data assumption, employing strategies like representation learning to better approximate real-world imbalances. We also highlight a critical application in SEP forecasting where addressing data imbalance is paramount for success.", "url": "https://arxiv.org/abs/2310.07598"}, {"metadata": {"arXiv": "2310.07612", "Date": "Wed, 11 Oct 2023 15:56:55 ", "Title": "PHYDI: Initializing Parameterized Hypercomplex Neural Networks as Identity Functions", "Authors": ["Matteo Mancanelli", "Eleonora Grassucci", "Aurelio Uncini", "and Danilo Comminiello"], "Categories": "cs.LG cs.AI cs.ET", "Comments": ["Accepted at IEEE MLSP 2023 (Honorable Mention TOP 5% Outstanding Papers)"]}, "abstract": "Neural models based on hypercomplex algebra systems are growing and prolificating for a plethora of applications, ranging from computer vision to natural language processing. Hand in hand with their adoption, parameterized hypercomplex neural networks (PHNNs) are growing in size and no techniques have been adopted so far to control their convergence at a large scale. In this paper, we study PHNNs convergence and propose parameterized hypercomplex identity initialization (PHYDI), a method to improve their convergence at different scales, leading to more robust performance when the number of layers scales up, while also reaching the same performance with fewer iterations. We show the effectiveness of this approach in different benchmarks and with common PHNNs with ResNets- and Transformer-based architecture. The code is available at https://github.com/ispamm/PHYDI.", "url": "https://arxiv.org/abs/2310.07612"}, {"metadata": {"arXiv": "2310.07667", "Date": "Wed, 11 Oct 2023 17:16:33 ", "Title": "Global Minima, Recoverability Thresholds, and Higher-Order Structure in GNNS", "Authors": ["Drake Brown", "Trevor Garrity", "Kaden Parker", "Jason Oliphant", "Stone Carson", "Cole Hanson", "and Zachary Boyd"], "Categories": "cs.LG cs.AI", "Comments": ["28 pages"]}, "abstract": "We analyze the performance of graph neural network (GNN) architectures from the perspective of random graph theory. Our approach promises to complement existing lenses on GNN analysis, such as combinatorial expressive power and worst-case adversarial analysis, by connecting the performance of GNNs to typical-case properties of the training data. First, we theoretically characterize the nodewise accuracy of one- and two-layer GCNs relative to the contextual stochastic block model (cSBM) and related models. We additionally prove that GCNs cannot beat linear models under certain circumstances. Second, we numerically map the recoverability thresholds, in terms of accuracy, of four diverse GNN architectures (GCN, GAT, SAGE, and Graph Transformer) under a variety of assumptions about the data. Sample results of this second analysis include: heavy-tailed degree distributions enhance GNN performance, GNNs can work well on strongly heterophilous graphs, and SAGE and Graph Transformer can perform well on arbitrarily noisy edge data, but no architecture handled sufficiently noisy feature data well. Finally, we show how both specific higher-order structures in synthetic data and the mix of empirical structures in real data have dramatic effects (usually negative) on GNN performance.", "url": "https://arxiv.org/abs/2310.07667"}, {"metadata": {"arXiv": "2310.07668", "Date": "Wed, 11 Oct 2023 17:17:40 ", "Title": "GRaMuFeN: Graph-based Multi-modal Fake News Detection in Social Media", "Authors": ["Makan Kananian", "Fatima Badiei", "S. AmirAli Gh. Ghahramani"], "Categories": "cs.LG cs.AI"}, "abstract": "The proliferation of social media platforms such as Twitter, Instagram, and Weibo has significantly enhanced the dissemination of false information. This phenomenon grants both individuals and governmental entities the ability to shape public opinions, highlighting the need for deploying effective detection methods. In this paper, we propose GraMuFeN, a model designed to detect fake content by analyzing both the textual and image content of news. GraMuFeN comprises two primary components: a text encoder and an image encoder. For textual analysis, GraMuFeN treats each text as a graph and employs a Graph Convolutional Neural Network (GCN) as the text encoder. Additionally, the pre-trained ResNet-152, as a Convolutional Neural Network (CNN), has been utilized as the image encoder. By integrating the outputs from these two encoders and implementing a contrastive similarity loss function, GraMuFeN achieves remarkable results. Extensive evaluations conducted on two publicly available benchmark datasets for social media news indicate a 10 % increase in micro F1-Score, signifying improvement over existing state-of-the-art models. These findings underscore the effectiveness of combining GCN and CNN models for detecting fake news in multi-modal data, all while minimizing the additional computational burden imposed by model parameters.", "url": "https://arxiv.org/abs/2310.07668"}, {"metadata": {"arXiv": "2310.07683", "Date": "Wed, 11 Oct 2023 17:34:56 ", "Title": "Controllable Data Generation Via Iterative Data-Property Mutual Mappings", "Authors": ["Bo Pan", "Muran Qin", "Shiyu Wang", "Yifei Zhang", "Liang Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep generative models have been widely used for their ability to generate realistic data samples in various areas, such as images, molecules, text, and speech. One major goal of data generation is controllability, namely to generate new data with desired properties. Despite growing interest in the area of controllable generation, significant challenges still remain, including 1) disentangling desired properties with unrelated latent variables, 2) out-of-distribution property control, and 3) objective optimization for out-of-distribution property control. To address these challenges, in this paper, we propose a general framework to enhance VAE-based data generators with property controllability and ensure disentanglement. Our proposed objective can be optimized on both data seen and unseen in the training set. We propose a training procedure to train the objective in a semi-supervised manner by iteratively conducting mutual mappings between the data and properties. The proposed framework is implemented on four VAE-based controllable generators to evaluate its performance on property error, disentanglement, generation quality, and training time. The results indicate that our proposed framework enables more precise control over the properties of generated samples in a short training time, ensuring the disentanglement and keeping the validity of the generated samples.", "url": "https://arxiv.org/abs/2310.07683"}, {"metadata": {"arXiv": "2310.07335", "Date": "Wed, 11 Oct 2023 09:25:24 ", "Title": "Exploring Social Motion Latent Space and Human Awareness for Effective Robot Navigation in Crowded Environments", "Authors": ["Junaid Ahmed Ansari", "Satyajit Tourani", "Gourav Kumar", "Brojeshwar Bhowmick"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted at IROS 2023"]}, "abstract": "This work proposes a novel approach to social robot navigation by learning to generate robot controls from a social motion latent space. By leveraging this social motion latent space, the proposed method achieves significant improvements in social navigation metrics such as success rate, navigation time, and trajectory length while producing smoother (less jerk and angular deviations) and more anticipatory trajectories. The superiority of the proposed method is demonstrated through comparison with baseline models in various scenarios. Additionally, the concept of humans' awareness towards the robot is introduced into the social robot navigation framework, showing that incorporating human awareness leads to shorter and smoother trajectories owing to humans' ability to positively interact with the robot.", "url": "https://arxiv.org/abs/2310.07335"}, {"metadata": {"arXiv": "2310.07433", "Date": "Wed, 11 Oct 2023 12:34:39 ", "Title": "Imitation Learning from Observation with Automatic Discount Scheduling", "Authors": ["Yuyang Liu", "Weijun Dong", "Yingdong Hu", "Chuan Wen", "Zhao-Heng Yin", "Chongjie Zhang", "Yang Gao"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Submitted to ICLR 2024"]}, "abstract": "Humans often acquire new skills through observation and imitation. For robotic agents, learning from the plethora of unlabeled video demonstration data available on the Internet necessitates imitating the expert without access to its action, presenting a challenge known as Imitation Learning from Observations (ILfO). A common approach to tackle ILfO problems is to convert them into inverse reinforcement learning problems, utilizing a proxy reward computed from the agent's and the expert's observations. Nonetheless, we identify that tasks characterized by a progress dependency property pose significant challenges for such approaches; in these tasks, the agent needs to initially learn the expert's preceding behaviors before mastering the subsequent ones. Our investigation reveals that the main cause is that the reward signals assigned to later steps hinder the learning of initial behaviors. To address this challenge, we present a novel ILfO framework that enables the agent to master earlier behaviors before advancing to later ones. We introduce an Automatic Discount Scheduling (ADS) mechanism that adaptively alters the discount factor in reinforcement learning during the training phase, prioritizing earlier rewards initially and gradually engaging later rewards only when the earlier behaviors have been mastered. Our experiments, conducted on nine Meta-World tasks, demonstrate that our method significantly outperforms state-of-the-art methods across all tasks, including those that are unsolvable by them.", "url": "https://arxiv.org/abs/2310.07433"}, {"metadata": {"arXiv": "2310.07434", "Date": "Wed, 11 Oct 2023 12:36:38 ", "Title": "HealthWalk: Promoting Health and Mobility through Sensor-Based Rollator Walker Assistance", "Authors": ["Ivanna Kramer", "Kevin Weirauch", "Sabine Bauer", "Mark Oliver Mints", "Peer Neubert"], "Categories": "cs.RO cs.AI cs.HC cs.LG"}, "abstract": "Rollator walkers allow people with physical limitations to increase their mobility and give them the confidence and independence to participate in society for longer. However, rollator walker users often have poor posture, leading to further health problems and, in the worst case, falls. Integrating sensors into rollator walker designs can help to address this problem and results in a platform that allows several other interesting use cases. This paper briefly overviews existing systems and the current research directions and challenges in this field. We also present our early HealthWalk rollator walker prototype for data collection with older people, rheumatism, multiple sclerosis and Parkinson patients, and individuals with visual impairments.", "url": "https://arxiv.org/abs/2310.07434"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.02239", "Date": "Fri, 03 Nov 2023 20:58:44 ", "Title": "Using DUCK-Net for Polyp Image Segmentation", "Authors": ["Razvan-Gabriel Dumitru", "Darius Peteleaza", "Catalin Craciun"], "Categories": "cs.CV cs.LG", "ACM-class": "I.2; I.4; I.5", "Journal-ref": "Sci Rep 13, 9803 (2023)", "DOI": "10.1038/s41598-023-36940-5"}, "abstract": "This paper presents a novel supervised convolutional neural network architecture, \"DUCK-Net\", capable of effectively learning and generalizing from small amounts of medical images to perform accurate segmentation tasks. Our model utilizes an encoder-decoder structure with a residual downsampling mechanism and a custom convolutional block to capture and process image information at multiple resolutions in the encoder segment. We employ data augmentation techniques to enrich the training set, thus increasing our model's performance. While our architecture is versatile and applicable to various segmentation tasks, in this study, we demonstrate its capabilities specifically for polyp segmentation in colonoscopy images. We evaluate the performance of our method on several popular benchmark datasets for polyp segmentation, Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, and ETIS-LARIBPOLYPDB showing that it achieves state-of-the-art results in terms of mean Dice coefficient, Jaccard index, Precision, Recall, and Accuracy. Our approach demonstrates strong generalization capabilities, achieving excellent performance even with limited training data. The code is publicly available on GitHub: https://github.com/RazvanDu/DUCK-Net", "url": "https://arxiv.org/abs/2311.02239"}, {"metadata": {"arXiv": "2311.02428", "Date": "Sat, 04 Nov 2023 15:12:24 ", "Title": "Task Arithmetic with LoRA for Continual Learning", "Authors": ["Rajas Chitale", "Ankit Vaidya", "Aditya Kane", "Archana Ghotkar"], "Categories": "cs.CV cs.LG"}, "abstract": "Continual learning refers to the problem where the training data is available in sequential chunks, termed \"tasks\". The majority of progress in continual learning has been stunted by the problem of catastrophic forgetting, which is caused by sequential training of the model on streams of data. Moreover, it becomes computationally expensive to sequentially train large models multiple times. To mitigate both of these problems at once, we propose a novel method to continually train transformer-based vision models using low-rank adaptation and task arithmetic. Our method completely bypasses the problem of catastrophic forgetting, as well as reducing the computational requirement for training models on each task. When aided with a small memory of 10 samples per class, our method achieves performance close to full-set finetuning. We present rigorous ablations to support the prowess of our method.", "url": "https://arxiv.org/abs/2311.02428"}, {"metadata": {"arXiv": "2311.02601", "Date": "Sun, 05 Nov 2023 08:57:22 ", "Title": "Optimizing Implicit Neural Representations from Point Clouds via Energy-Based Models", "Authors": ["Ryutaro Yamauchi", "Jinya Sakurai", "Ryo Furukawa", "Tatsushi Matsubayashi"], "Categories": "cs.CV cs.LG"}, "abstract": "Reconstructing a continuous surface from an unoritented 3D point cloud is a fundamental task in 3D shape processing. In recent years, several methods have been proposed to address this problem using implicit neural representations (INRs). In this study, we propose a method to optimize INRs using energy-based models (EBMs). By employing the absolute value of the coordinate-based neural networks as the energy function, the INR can be optimized through the estimation of the point cloud distribution by the EBM. In addition, appropriate parameter settings of the EBM enable the model to consider the magnitude of point cloud noise. Our experiments confirmed that the proposed method is more robust against point cloud noise than conventional surface reconstruction methods.", "url": "https://arxiv.org/abs/2311.02601"}, {"metadata": {"arXiv": "2311.02665", "Date": "Sun, 05 Nov 2023 14:22:13 ", "Title": "Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones", "Authors": ["Asanobu Kitamoto and Jared Hwang and Bastien Vuillod and Lucas Gautier and Yingtao Tian and Tarin Clanuwat"], "Categories": "cs.CV cs.LG physics.ao-ph", "Comments": ["Accepted by NeurIPS 2023 Datasets and Benchmarks Track (Spotlight)"]}, "abstract": "This paper presents the official release of the Digital Typhoon dataset, the longest typhoon satellite image dataset for 40+ years aimed at benchmarking machine learning models for long-term spatio-temporal data. To build the dataset, we developed a workflow to create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection referring to the best track data. We also address data quality issues such as inter-satellite calibration to create a homogeneous dataset. To take advantage of the dataset, we organized machine learning tasks by the types and targets of inference, with other tasks for meteorological analysis, societal impact, and climate change. The benchmarking results on the analysis, forecasting, and reanalysis for the intensity suggest that the dataset is challenging for recent deep learning models, due to many choices that affect the performance of various models. This dataset reduces the barrier for machine learning researchers to meet large-scale real-world events called tropical cyclones and develop machine learning models that may contribute to advancing scientific knowledge on tropical cyclones as well as solving societal and sustainability issues such as disaster reduction and climate change. The dataset is publicly available at http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and https://github.com/kitamoto-lab/digital-typhoon/.", "url": "https://arxiv.org/abs/2311.02665"}, {"metadata": {"arXiv": "2311.02699", "Date": "Sun, 05 Nov 2023 16:09:40 ", "Title": "Nepali Video Captioning using CNN-RNN Architecture", "Authors": ["Bipesh Subedi", "Saugat Singh", "Bal Krishna Bal"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["6 pages", "5 figures", "3 tables. Presented in the International Conference on Technologies for Computer", "Electrical", "Electronics & Communication (ICT-CEEL 2023)", "Bhaktapur", "Nepal"], "ACM-class": "I.2.7; I.2.10", "Journal-ref": "In proceedings of the International Conference on Technologies for Computer, Electrical, Electronics & Communication (ICT-CEEL 2023), Bhaktapur, Nepal. Part-1 94-99"}, "abstract": "This article presents a study on Nepali video captioning using deep neural networks. Through the integration of pre-trained CNNs and RNNs, the research focuses on generating precise and contextually relevant captions for Nepali videos. The approach involves dataset collection, data preprocessing, model implementation, and evaluation. By enriching the MSVD dataset with Nepali captions via Google Translate, the study trains various CNN-RNN architectures. The research explores the effectiveness of CNNs (e.g., EfficientNetB0, ResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and BiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being EfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score of 17 and METEOR score of 46. The article also outlines challenges and future directions for advancing Nepali video captioning, offering a crucial resource for further research in this area.", "url": "https://arxiv.org/abs/2311.02699"}, {"metadata": {"arXiv": "2311.02762", "Date": "Sun, 05 Nov 2023 20:43:46 ", "Title": "Fast Sparse 3D Convolution Network with VDB", "Authors": ["Fangjun Zhou", "Anyong Mao", "Eftychios Sifakis"], "Categories": "cs.CV cs.LG"}, "abstract": "We proposed a new Convolution Neural Network implementation optimized for sparse 3D data inference. This implementation uses NanoVDB as the data structure to store the sparse tensor. It leaves a relatively small memory footprint while maintaining high performance. We demonstrate that this architecture is around 20 times faster than the state-of-the-art dense CNN model on a high-resolution 3D object classification network.", "url": "https://arxiv.org/abs/2311.02762"}, {"metadata": {"arXiv": "2311.02887", "Date": "Mon, 06 Nov 2023 05:37:03 ", "Title": "Stacked Autoencoder Based Feature Extraction and Superpixel Generation for Multifrequency PolSAR Image Classification", "Authors": ["Tushar Gadhiya", "Sumanth Tangirala", "Anil K. Roy"], "Categories": "cs.CV cs.LG", "Journal-ref": "Pattern Recognition and Machine Intelligence: 8th International Conference, PReMI 2019, Tezpur, India, December 17-20, 2019, Proceedings, Part II, Dec 2019, Pages 331-339", "DOI": "10.1007/978-3-030-34872-4_37"}, "abstract": "In this paper we are proposing classification algorithm for multifrequency Polarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR decomposition algorithms 33 features are extracted from each frequency band of the given image. Then, a two-layer autoencoder is used to reduce the dimensionality of input feature vector while retaining useful features of the input. This reduced dimensional feature vector is then applied to generate superpixels using simple linear iterative clustering (SLIC) algorithm. Next, a robust feature representation is constructed using both pixel as well as superpixel information. Finally, softmax classifier is used to perform classification task. The advantage of using superpixels is that it preserves spatial information between neighbouring PolSAR pixels and therefore minimises the effect of speckle noise during classification. Experiments have been conducted on Flevoland dataset and the proposed method was found to be superior to other methods available in the literature.", "url": "https://arxiv.org/abs/2311.02887"}, {"metadata": {"arXiv": "2311.03067", "Date": "Mon, 06 Nov 2023 12:51:01 ", "Title": "Forest aboveground biomass estimation using GEDI and earth observation data through attention-based deep learning", "Authors": ["Wenquan Dong", "Edward T.A. Mitchard", "Hao Yu", "Steven Hancock", "Casey M. Ryan"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Accurate quantification of forest aboveground biomass (AGB) is critical for understanding carbon accounting in the context of climate change. In this study, we presented a novel attention-based deep learning approach for forest AGB estimation, primarily utilizing openly accessible EO data, including: GEDI LiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2 multispectral data. The attention UNet (AU) model achieved markedly higher accuracy for biomass estimation compared to the conventional RF algorithm. Specifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and bias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87 Mg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning approach was not uniformly observed across all tested models. ResNet101 only achieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1, while the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a substantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in the absence of spatial information, fully connected (FC) layers were employed to eliminate spatial information from the remote sensing data. AU-FC achieved intermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1, outperforming RF but underperforming AU model using spatial information. We also generated 10m forest AGB maps across Guangdong for the year 2019 using AU and compared it with that produced by RF. The AGB distributions from both models showed strong agreement with similar mean values; the mean forest AGB estimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1. Additionally, it was observed that the AGB map generated by AU provided superior spatial information. Overall, this research substantiates the feasibility of employing deep learning for biomass estimation based on satellite data.", "url": "https://arxiv.org/abs/2311.03067"}, {"metadata": {"arXiv": "2311.03124", "Date": "Mon, 06 Nov 2023 14:19:05 ", "Title": "TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains", "Authors": ["Alexander Naumann", "Felix Hertlein", "Laura D\\\"orr", "Kai Furmans"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["Accepted at WACV 2024"]}, "abstract": "Due to the steadily rising amount of valuable goods in supply chains, tampering detection for parcels is becoming increasingly important. In this work, we focus on the use-case last-mile delivery, where only a single RGB image is taken and compared against a reference from an existing database to detect potential appearance changes that indicate tampering. We propose a tampering detection pipeline that utilizes keypoint detection to identify the eight corner points of a parcel. This permits applying a perspective transformation to create normalized fronto-parallel views for each visible parcel side surface. These viewpoint-invariant parcel side surface representations facilitate the identification of signs of tampering on parcels within the supply chain, since they reduce the problem to parcel side surface matching with pair-wise appearance change detection. Experiments with multiple classical and deep learning-based change detection approaches are performed on our newly collected TAMpering detection dataset for PARcels, called TAMPAR. We evaluate keypoint and change detection separately, as well as in a unified system for tampering detection. Our evaluation shows promising results for keypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score 0.83) on real images. Furthermore, a sensitivity analysis for tampering types, lens distortion and viewing angles is presented. Code and dataset are available at https://a-nau.github.io/tampar.", "url": "https://arxiv.org/abs/2311.03124"}, {"metadata": {"arXiv": "2311.03240", "Date": "Mon, 06 Nov 2023 16:30:40 ", "Title": "Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review", "Authors": ["Faruk Ahmed", "Md. Taimur Ahad", "Yousuf Rayhan Emon"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Tea leaf diseases are a major challenge to agricultural productivity, with far-reaching implications for yield and quality in the tea industry. The rise of machine learning has enabled the development of innovative approaches to combat these diseases. Early detection and diagnosis are crucial for effective crop management. For predicting tea leaf disease, several automated systems have already been developed using different image processing techniques. This paper delivers a systematic review of the literature on machine learning methodologies applied to diagnose tea leaf disease via image classification. It thoroughly evaluates the strengths and constraints of various Vision Transformer models, including Inception Convolutional Vision Transformer (ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision Transformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews models like Dense Convolutional Network (DenseNet), Residual Neural Network (ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN, Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and Lesion-Aware Visual Transformer. These machine-learning models have been tested on various datasets, demonstrating their real-world applicability. This review study not only highlights current progress in the field but also provides valuable insights for future research directions in the machine learning-based detection and classification of tea leaf diseases.", "url": "https://arxiv.org/abs/2311.03240"}, {"metadata": {"arXiv": "2311.02349", "Date": "Sat, 04 Nov 2023 08:28:33 ", "Title": "Sample Complexity of Opinion Formation on Networks", "Authors": ["Haolin Liu", "Rajmohan Rajaraman", "Ravi Sundaram", "Anil Vullikanti", "Omer Wasim", "Haifeng Xu"], "Categories": "cs.GT cs.LG cs.SI"}, "abstract": "Consider public health officials aiming to spread awareness about a new vaccine in a community interconnected by a social network. How can they distribute information with minimal resources, ensuring community-wide understanding that aligns with the actual facts? This concern mirrors numerous real-world situations. In this paper, we initialize the study of sample complexity in opinion formation to solve this problem. Our model is built on the recognized opinion formation game, where we regard each agent's opinion as a data-derived model parameter, not just a real number as in prior studies. Such an extension offers a wider understanding of opinion formation and ties closely with federated learning. Through this formulation, we characterize the sample complexity bounds for any network and also show asymptotically tight bounds for specific network structures. Intriguingly, we discover optimal strategies often allocate samples inversely to the degree, hinting at vital policy implications. Our findings are empirically validated on both synthesized and real-world networks.", "url": "https://arxiv.org/abs/2311.02349"}, {"metadata": {"arXiv": "2311.02407", "Date": "Sat, 04 Nov 2023 14:07:33 ", "Title": "The equivalence of dynamic and strategic stability under regularized learning in games", "Authors": ["Victor Boone and Panayotis Mertikopoulos"], "Categories": "cs.GT cs.LG math.OC", "Comments": ["31 pages", "8 figures", "2 tables"], "MSC-class": "Primary 91A10, 91A26, secondary 68Q32, 62L20"}, "abstract": "In this paper, we examine the long-run behavior of regularized, no-regret learning in finite games. A well-known result in the field states that the empirical frequencies of no-regret play converge to the game's set of coarse correlated equilibria; however, our understanding of how the players' actual strategies evolve over time is much more limited - and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that only strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and pointwise solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the \\emph{setwise} rationality properties of the players' day-to-day play. To that end, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator - a property known as closedness under better replies (club). In so doing, we obtain a far-reaching equivalence between strategic and dynamic stability: a product of pure strategies is closed under better replies if and only if its span is stable and attracting under regularized learning. In addition, we estimate the rate of convergence to such sets, and we show that methods based on entropic regularization (like the exponential weights algorithm) converge at a geometric rate, while projection-based methods converge within a finite number of iterations, even with bandit, payoff-based feedback.", "url": "https://arxiv.org/abs/2311.02407"}, {"metadata": {"arXiv": "2311.02423", "Date": "Sat, 04 Nov 2023 14:56:17 ", "Title": "Payoff-based learning with matrix multiplicative weights in quantum games", "Authors": ["Kyriakos Lotidis and Panayotis Mertikopoulos and Nicholas Bambos and Jose Blanchet"], "Categories": "cs.GT cs.LG math.OC quant-ph", "Comments": ["39 pages", "21 figures", "2 tables"], "MSC-class": "Primary 91A10, 91A26, 37N40, secondary 68Q32, 81Q93"}, "abstract": "In this paper, we study the problem of learning in quantum games - and other classes of semidefinite games - with scalar, payoff-based feedback. For concreteness, we focus on the widely used matrix multiplicative weights (MMW) algorithm and, instead of requiring players to have full knowledge of the game (and/or each other's chosen states), we introduce a suite of minimal-information matrix multiplicative weights (3MW) methods tailored to different information frameworks. The main difficulty to attaining convergence in this setting is that, in contrast to classical finite games, quantum games have an infinite continuum of pure states (the quantum equivalent of pure strategies), so standard importance-weighting techniques for estimating payoff vectors cannot be employed. Instead, we borrow ideas from bandit convex optimization and we design a zeroth-order gradient sampler adapted to the semidefinite geometry of the problem at hand. As a first result, we show that the 3MW method with deterministic payoff feedback retains the $\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the vanilla, full information MMW algorithm in quantum min-max games, even though the players only observe a single scalar. Subsequently, we relax the algorithm's information requirements even further and we provide a 3MW method that only requires players to observe a random realization of their payoff observable, and converges to equilibrium at an $\\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we show that a regularized variant of the proposed 3MW method guarantees local convergence with high probability to all equilibria that satisfy a certain first-order stability condition.", "url": "https://arxiv.org/abs/2311.02423"}, {"metadata": {"arXiv": "2311.02100", "Date": "Tue, 31 Oct 2023 23:26:58 ", "Title": "A Comprehensive Study on Model Initialization Techniques Ensuring Efficient Federated Learning", "Authors": ["Ishmeet Kaur and Adwaita Janardhan Jadhav"], "Categories": "cs.LG cs.CR cs.DC", "Comments": ["Accepted to be presented at IEEE 2nd International Conference on Intelligent Computing and Next Generation Networks (ICNGN2023) will be held November 17-18,2023 at Hangzhou", "China"]}, "abstract": "Advancement in the field of machine learning is unavoidable, but something of major concern is preserving the privacy of the users whose data is being used for training these machine learning algorithms. Federated learning(FL) has emerged as a promising paradigm for training machine learning models in a distributed and privacy-preserving manner which enables one to collaborate and train a global model without sharing local data. But starting this learning process on each device in the right way, called ``model initialization\" is critical. The choice of initialization methods used for models plays a crucial role in the performance, convergence speed, communication efficiency, privacy guarantees of federated learning systems, etc. In this survey, we dive deeper into a comprehensive study of various ways of model initialization techniques in FL.Unlike other studies, our research meticulously compares, categorizes, and delineates the merits and demerits of each technique, examining their applicability across diverse FL scenarios. We highlight how factors like client variability, data non-IIDness, model caliber, security considerations, and network restrictions influence FL model outcomes and propose how strategic initialization can address and potentially rectify many such challenges. The motivation behind this survey is to highlight that the right start can help overcome challenges like varying data quality, security issues, and network problems. Our insights provide a foundational base for experts looking to fully utilize FL, also while understanding the complexities of model initialization.", "url": "https://arxiv.org/abs/2311.02100"}, {"metadata": {"arXiv": "2311.02116", "Date": "Fri, 03 Nov 2023 02:47:06 ", "Title": "Resist Label Noise with PGM for Graph Neural Networks", "Authors": ["Qingqing Ge", "Jianxiang Yu", "Zeyuan Zhao and Xiang Li"], "Categories": "cs.LG"}, "abstract": "While robust graph neural networks (GNNs) have been widely studied for graph perturbation and attack, those for label noise have received significantly less attention. Most existing methods heavily rely on the label smoothness assumption to correct noisy labels, which adversely affects their performance on heterophilous graphs. Further, they generally perform poorly in high noise-rate scenarios. To address these problems, in this paper, we propose a novel probabilistic graphical model (PGM) based framework LNP. Given a noisy label set and a clean label set, our goal is to maximize the likelihood of labels in the clean set. We first present LNP-v1, which generates clean labels based on graphs only in the Bayesian network. To further leverage the information of clean labels in the noisy label set, we put forward LNP-v2, which incorporates the noisy label set into the Bayesian network to generate clean labels. The generative process can then be used to predict labels for unlabeled nodes. We conduct extensive experiments to show the robustness of LNP on varying noise types and rates, and also on graphs with different heterophilies. In particular, we show that LNP can lead to inspiring performance in high noise-rate situations.", "url": "https://arxiv.org/abs/2311.02116"}, {"metadata": {"arXiv": "2311.02213", "Date": "Fri, 03 Nov 2023 19:53:37 ", "Title": "Joint Composite Latent Space Bayesian Optimization", "Authors": ["Natalie Maus and Zhiyuan Jerry Lin and Maximilian Balandat and Eytan Bakshy"], "Categories": "cs.LG"}, "abstract": "Bayesian Optimization (BO) is a technique for sample-efficient black-box optimization that employs probabilistic models to identify promising input locations for evaluation. When dealing with composite-structured functions, such as f=g o h, evaluating a specific location x yields observations of both the final outcome f(x) = g(h(x)) as well as the intermediate output(s) h(x). Previous research has shown that integrating information from these intermediate outputs can enhance BO performance substantially. However, existing methods struggle if the outputs h(x) are high-dimensional. Many relevant problems fall into this setting, including in the context of generative AI, molecular design, or robotics. To effectively tackle these challenges, we introduce Joint Composite Latent Space Bayesian Optimization (JoCo), a novel framework that jointly trains neural network encoders and probabilistic models to adaptively compress high-dimensional input and output spaces into manageable latent representations. This enables viable BO on these compressed representations, allowing JoCo to outperform other state-of-the-art methods in high-dimensional BO on a wide variety of simulated and real-world problems.", "url": "https://arxiv.org/abs/2311.02213"}, {"metadata": {"arXiv": "2311.02221", "Date": "Fri, 03 Nov 2023 20:15:05 ", "Title": "Structured Neural Networks for Density Estimation and Causal Inference", "Authors": ["Asic Q. Chen", "Ruian Shi", "Xiang Gao", "Ricardo Baptista", "Rahul G. Krishnan"], "Categories": "cs.LG stat.ML", "Comments": ["10 pages with 5 figures", "to be published in Neural Information Processing Systems 2023"]}, "abstract": "Injecting structure into neural networks enables learning functions that satisfy invariances with respect to subsets of inputs. For instance, when learning generative models using neural networks, it is advantageous to encode the conditional independence structure of observed variables, often in the form of Bayesian networks. We propose the Structured Neural Network (StrNN), which injects structure through masking pathways in a neural network. The masks are designed via a novel relationship we explore between neural network architectures and binary matrix factorization, to ensure that the desired independencies are respected. We devise and study practical algorithms for this otherwise NP-hard design problem based on novel objectives that control the model architecture. We demonstrate the utility of StrNN in three applications: (1) binary and Gaussian density estimation with StrNN, (2) real-valued density estimation with Structured Autoregressive Flows (StrAFs) and Structured Continuous Normalizing Flows (StrCNF), and (3) interventional and counterfactual analysis with StrAFs for causal inference. Our work opens up new avenues for learning neural networks that enable data-efficient generative modeling and the use of normalizing flows for causal effect estimation.", "url": "https://arxiv.org/abs/2311.02221"}, {"metadata": {"arXiv": "2311.02225", "Date": "Fri, 03 Nov 2023 20:26:43 ", "Title": "Multi-scale Time-stepping of Partial Differential Equations with Transformers", "Authors": ["AmirPouya Hemmasian", "Amir Barati Farimani"], "Categories": "cs.LG"}, "abstract": "Developing fast surrogates for Partial Differential Equations (PDEs) will accelerate design and optimization in almost all scientific and engineering applications. Neural networks have been receiving ever-increasing attention and demonstrated remarkable success in computational modeling of PDEs, however; their prediction accuracy is not at the level of full deployment. In this work, we utilize the transformer architecture, the backbone of numerous state-of-the-art AI models, to learn the dynamics of physical systems as the mixing of spatial patterns learned by a convolutional autoencoder. Moreover, we incorporate the idea of multi-scale hierarchical time-stepping to increase the prediction speed and decrease accumulated error over time. Our model achieves similar or better results in predicting the time-evolution of Navier-Stokes equations compared to the powerful Fourier Neural Operator (FNO) and two transformer-based neural operators OFormer and Galerkin Transformer.", "url": "https://arxiv.org/abs/2311.02225"}, {"metadata": {"arXiv": "2311.02237", "Date": "Fri, 03 Nov 2023 20:51:15 ", "Title": "Explainable Authorship Identification in Cultural Heritage Applications: Analysis of a New Perspective", "Authors": ["Mattia Setzu and Silvia Corbara and Anna Monreale and Alejandro Moreo and Fabrizio Sebastiani"], "Categories": "cs.LG"}, "abstract": "While a substantial amount of work has recently been devoted to enhance the performance of computational Authorship Identification (AId) systems, little to no attention has been paid to endowing AId systems with the ability to explain the reasons behind their predictions. This lacking substantially hinders the practical employment of AId methodologies, since the predictions returned by such systems are hardly useful unless they are supported with suitable explanations. In this paper, we explore the applicability of existing general-purpose eXplainable Artificial Intelligence (XAI) techniques to AId, with a special focus on explanations addressed to scholars working in cultural heritage. In particular, we assess the relative merits of three different types of XAI techniques (feature ranking, probing, factuals and counterfactual selection) on three different AId tasks (authorship attribution, authorship verification, same-authorship verification) by running experiments on real AId data. Our analysis shows that, while these techniques make important first steps towards explainable Authorship Identification, more work remains to be done in order to provide tools that can be profitably integrated in the workflows of scholars.", "url": "https://arxiv.org/abs/2311.02237"}, {"metadata": {"arXiv": "2311.02243", "Date": "Fri, 03 Nov 2023 21:19:59 ", "Title": "Equal Opportunity of Coverage in Fair Regression", "Authors": ["Fangxin Wang", "Lu Cheng", "Ruocheng Guo", "Kay Liu", "Philip S. Yu"], "Categories": "cs.LG", "Comments": ["Accepted to NeurIPS 2023 main conference"]}, "abstract": "We study fair machine learning (ML) under predictive uncertainty to enable reliable and trustworthy decision-making. The seminal work of ``equalized coverage'' proposed an uncertainty-aware fairness notion. However, it does not guarantee equal coverage rates across more fine-grained groups (e.g., low-income females) conditioning on the true label and is biased in the assessment of uncertainty. To tackle these limitations, we propose a new uncertainty-aware fairness -- Equal Opportunity of Coverage (EOC) -- that aims to achieve two properties: (1) coverage rates for different groups with similar outcomes are close, and (2) the coverage rate for the entire population remains at a predetermined level. Further, the prediction intervals should be narrow to be informative. We propose Binned Fair Quantile Regression (BFQR), a distribution-free post-processing method to improve EOC with reasonable width for any trained ML models. It first calibrates a hold-out set to bound deviation from EOC, then leverages conformal prediction to maintain EOC on a test set, meanwhile optimizing prediction interval width. Experimental results demonstrate the effectiveness of our method in improving EOC. Our code is publicly available at https://github.com/fangxin-wang/bfqr .", "url": "https://arxiv.org/abs/2311.02243"}, {"metadata": {"arXiv": "2311.02247", "Date": "Fri, 03 Nov 2023 21:30:34 ", "Title": "PRISM: Progressive Restoration for Scene Graph-based Image Manipulation", "Authors": ["Pavel Jahoda", "Azade Farshad", "Yousef Yeganeh", "Ehsan Adeli", "Nassir Navab"], "Categories": "cs.LG"}, "abstract": "Scene graphs have emerged as accurate descriptive priors for image generation and manipulation tasks, however, their complexity and diversity of the shapes and relations of objects in data make it challenging to incorporate them into the models and generate high-quality results. To address these challenges, we propose PRISM, a novel progressive multi-head image manipulation approach to improve the accuracy and quality of the manipulated regions in the scene. Our image manipulation framework is trained using an end-to-end denoising masked reconstruction proxy task, where the masked regions are progressively unmasked from the outer regions to the inner part. We take advantage of the outer part of the masked area as they have a direct correlation with the context of the scene. Moreover, our multi-head architecture simultaneously generates detailed object-specific regions in addition to the entire image to produce higher-quality images. Our model outperforms the state-of-the-art methods in the semantic image manipulation task on the CLEVR and Visual Genome datasets. Our results demonstrate the potential of our approach for enhancing the quality and precision of scene graph-based image manipulation.", "url": "https://arxiv.org/abs/2311.02247"}, {"metadata": {"arXiv": "2311.02270", "Date": "Fri, 03 Nov 2023 23:18:21 ", "Title": "Regularized Linear Regression for Binary Classification", "Authors": ["Danil Akhtiamov", "Reza Ghane and Babak Hassibi"], "Categories": "cs.LG stat.ML"}, "abstract": "Regularized linear regression is a promising approach for binary classification problems in which the training set has noisy labels since the regularization term can help to avoid interpolating the mislabeled data points. In this paper we provide a systematic study of the effects of the regularization strength on the performance of linear classifiers that are trained to solve binary classification problems by minimizing a regularized least-squares objective. We consider the over-parametrized regime and assume that the classes are generated from a Gaussian Mixture Model (GMM) where a fraction $c<\\frac{1}{2}$ of the training data is mislabeled. Under these assumptions, we rigorously analyze the classification errors resulting from the application of ridge, $\\ell_1$, and $\\ell_\\infty$ regression. In particular, we demonstrate that ridge regression invariably improves the classification error. We prove that $\\ell_1$ regularization induces sparsity and observe that in many cases one can sparsify the solution by up to two orders of magnitude without any considerable loss of performance, even though the GMM has no underlying sparsity structure. For $\\ell_\\infty$ regularization we show that, for large enough regularization strength, the optimal weights concentrate around two values of opposite sign. We observe that in many cases the corresponding \"compression\" of each weight to a single bit leads to very little loss in performance. These latter observations can have significant practical ramifications.", "url": "https://arxiv.org/abs/2311.02270"}, {"metadata": {"arXiv": "2311.02278", "Date": "Sat, 04 Nov 2023 00:00:13 ", "Title": "Machine learning's own Industrial Revolution", "Authors": ["Yuan Luo", "Song Han", "Jingjing Liu"], "Categories": "cs.LG"}, "abstract": "Machine learning is expected to enable the next Industrial Revolution. However, lacking standardized and automated assembly networks, ML faces significant challenges to meet ever-growing enterprise demands and empower broad industries. In the Perspective, we argue that ML needs to first complete its own Industrial Revolution, elaborate on how to best achieve its goals, and discuss new opportunities to enable rapid translation from ML's innovation frontier to mass production and utilization.", "url": "https://arxiv.org/abs/2311.02278"}, {"metadata": {"arXiv": "2311.02282", "Date": "Sat, 04 Nov 2023 00:04:09 ", "Title": "Contrastive Multi-Modal Representation Learning for Spark Plug Fault Diagnosis", "Authors": ["Ardavan Modarres", "Vahid Mohammad-Zadeh Eivaghi", "Mahdi Aliyari Shoorehdeli", "Ashkan Moosavian"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Due to the incapability of one sensory measurement to provide enough information for condition monitoring of some complex engineered industrial mechanisms and also for overcoming the misleading noise of a single sensor, multiple sensors are installed to improve the condition monitoring of some industrial equipment. Therefore, an efficient data fusion strategy is demanded. In this research, we presented a Denoising Multi-Modal Autoencoder with a unique training strategy based on contrastive learning paradigm, both being utilized for the first time in the machine health monitoring realm. The presented approach, which leverages the merits of both supervised and unsupervised learning, not only achieves excellent performance in fusing multiple modalities (or views) of data into an enriched common representation but also takes data fusion to the next level wherein one of the views can be omitted during inference time with very slight performance reduction, or even without any reduction at all. The presented methodology enables multi-modal fault diagnosis systems to perform more robustly in case of sensor failure occurrence, and one can also intentionally omit one of the sensors (the more expensive one) in order to build a more cost-effective condition monitoring system without sacrificing performance for practical purposes. The effectiveness of the presented methodology is examined on a real-world private multi-modal dataset gathered under non-laboratory conditions from a complex engineered mechanism, an inline four-stroke spark-ignition engine, aiming for spark plug fault diagnosis. This dataset, which contains the accelerometer and acoustic signals as two modalities, has a very slight amount of fault, and achieving good performance on such a dataset promises that the presented method can perform well on other equipment as well.", "url": "https://arxiv.org/abs/2311.02282"}, {"metadata": {"arXiv": "2311.02316", "Date": "Sat, 04 Nov 2023 03:59:37 ", "Title": "Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells", "Authors": ["Rylan Schaeffer", "Mikail Khona", "Tzuhsuan Ma", "Crist\\'obal Eyzaguirre", "Sanmi Koyejo", "Ila Rani Fiete"], "Categories": "cs.LG cs.NE"}, "abstract": "To solve the spatial problems of mapping, localization and navigation, the mammalian lineage has developed striking spatial representations. One important spatial representation is the Nobel-prize winning grid cells: neurons that represent self-location, a local and aperiodic quantity, with seemingly bizarre non-local and spatially periodic activity patterns of a few discrete periods. Why has the mammalian lineage learnt this peculiar grid representation? Mathematical analysis suggests that this multi-periodic representation has excellent properties as an algebraic code with high capacity and intrinsic error-correction, but to date, there is no satisfactory synthesis of core principles that lead to multi-modular grid cells in deep recurrent neural networks. In this work, we begin by identifying key insights from four families of approaches to answering the grid cell question: coding theory, dynamical systems, function optimization and supervised deep learning. We then leverage our insights to propose a new approach that combines the strengths of all four approaches. Our approach is a self-supervised learning (SSL) framework - including data, data augmentations, loss functions and a network architecture - motivated from a normative perspective, without access to supervised position information or engineering of particular readout representations as needed in previous approaches. We show that multiple grid cell modules can emerge in networks trained on our SSL framework and that the networks and emergent representations generalize well outside their training distribution. This work contains insights for neuroscientists interested in the origins of grid cells as well as machine learning researchers interested in novel SSL frameworks.", "url": "https://arxiv.org/abs/2311.02316"}, {"metadata": {"arXiv": "2311.02328", "Date": "Sat, 04 Nov 2023 05:33:23 ", "Title": "An Operator Learning Framework for Spatiotemporal Super-resolution of Scientific Simulations", "Authors": ["Valentin Duruisseaux and Amit Chakraborty"], "Categories": "cs.LG", "Comments": ["31 pages"]}, "abstract": "In numerous contexts, high-resolution solutions to partial differential equations are required to capture faithfully essential dynamics which occur at small spatiotemporal scales, but these solutions can be very difficult and slow to obtain using traditional methods due to limited computational resources. A recent direction to circumvent these computational limitations is to use machine learning techniques for super-resolution, to reconstruct high-resolution numerical solutions from low-resolution simulations which can be obtained more efficiently. The proposed approach, the Super Resolution Operator Network (SROpNet), frames super-resolution as an operator learning problem and draws inspiration from existing architectures to learn continuous representations of solutions to parametric differential equations from low-resolution approximations, which can then be evaluated at any desired location. In addition, no restrictions are imposed on the locations of (the fixed number of) spatiotemporal sensors at which the low-resolution approximations are provided, thereby enabling the consideration of a broader spectrum of problems arising in practice, for which many existing super-resolution approaches are not well-suited.", "url": "https://arxiv.org/abs/2311.02328"}, {"metadata": {"arXiv": "2311.02332", "Date": "Sat, 04 Nov 2023 05:42:51 ", "Title": "Multimodal Machine Learning for Clinically-Assistive Imaging-Based Biomedical Applications", "Authors": ["Elisa Warner", "Joonsang Lee", "William Hsu", "Tanveer Syeda-Mahmood", "Charles Kahn", "and Arvind Rao"], "Categories": "cs.LG cs.CV"}, "abstract": "Machine learning (ML) applications in medical artificial intelligence (AI) systems have shifted from traditional and statistical methods to increasing application of deep learning models and even more recently generative models. Recent years have seen a rise in the discovery of widely-available deep learning architectures that support multimodal data integration, particularly with images. The incorporation of multiple modalities into these models is a thriving research topic, presenting its own unique challenges. In this work, we discuss five challenges to multimodal AI as it pertains to ML (representation, fusion, alignment, translation, and co-learning) and survey recent approaches to addressing these challenges in the context of medical image-based clinical decision support models. We conclude with a discussion of the future of the field, suggesting directions that should be elucidated further for successful clinical models and their translation to the clinical setting.", "url": "https://arxiv.org/abs/2311.02332"}, {"metadata": {"arXiv": "2311.02333", "Date": "Sat, 04 Nov 2023 06:00:56 ", "Title": "Understanding the Natural Language of DNA using Encoder-Decoder Foundation Models with Byte-level Precision", "Authors": ["Aditya Malusare and Harish Kothandaraman and Dipesh Tamboli and Nadia A. Lanman and Vaneet Aggarwal"], "Categories": "cs.LG q-bio.GN", "Comments": ["12 pages"]}, "abstract": "This paper presents the Ensemble Nucleotide Byte-level Encoder-Decoder (ENBED) foundation model, analyzing DNA sequences at byte-level precision with an encoder-decoder Transformer architecture. ENBED uses a sub-quadratic implementation of attention to develop an efficient model capable of sequence-to-sequence transformations, generalizing previous genomic models with encoder-only or decoder-only architectures. We use Masked Language Modeling to pre-train the foundation model using reference genome sequences and apply it in the following downstream tasks: (1) identification of enhancers, promotors and splice sites, (2) identification of biological function annotations of genomic sequences, (3) recognition of sequences containing base call mismatches and insertion/deletion errors, an advantage over tokenization schemes involving multiple base pairs, which lose the ability to analyze with byte-level precision, and (4) generating mutations of the Influenza virus using the encoder-decoder architecture and validating them against real-world observations. In each of these tasks, we demonstrate significant improvement as compared to the existing state-of-the-art results.", "url": "https://arxiv.org/abs/2311.02333"}, {"metadata": {"arXiv": "2311.02356", "Date": "Sat, 04 Nov 2023 09:33:08 ", "Title": "MATA*: Combining Learnable Node Matching with A* Algorithm for Approximate Graph Edit Distance Computation", "Authors": ["Junfeng Liu", "Min Zhou", "Shuai Ma", "Lujia Pan"], "Categories": "cs.LG", "Comments": ["Accepted by CIKM23"]}, "abstract": "Graph Edit Distance (GED) is a general and domain-agnostic metric to measure graph similarity, widely used in graph search or retrieving tasks. However, the exact GED computation is known to be NP-complete. For instance, the widely used A* algorithms explore the entire search space to find the optimal solution which inevitably suffers scalability issues. Learning-based methods apply graph representation techniques to learn the GED by formulating a regression task, which can not recover the edit path and lead to inaccurate GED approximation (i.e., the predicted GED is smaller than the exact). To this end, in this work, we present a data-driven hybrid approach MATA* for approximate GED computation based on Graph Neural Networks (GNNs) and A* algorithms, which models from the perspective of learning to match nodes instead of directly regressing GED. Specifically, aware of the structure-dominant operations (i.e.,node and edge insertion/deletion) property in GED computation, a structure-enhanced GNN is firstly designed to jointly learn local and high-order structural information for node embeddings for node matchings. Second, top-k candidate nodes are produced via a differentiable top-k operation to enable the training for node matchings, which is adhering to another property of GED, i.e., multiple optimal node matchings. Third, benefiting from the candidate nodes, MATA* only performs on the promising search directions, reaching the solution efficiently. Finally, extensive experiments show the superiority of MATA* as it significantly outperforms the combinatorial search-based, learning-based and hybrid methods and scales well to large-size graphs.", "url": "https://arxiv.org/abs/2311.02356"}, {"metadata": {"arXiv": "2311.02373", "Date": "Sat, 04 Nov 2023 11:00:31 ", "Title": "From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models", "Authors": ["Zhuoshi Pan", "Yuguang Yao", "Gaowen Liu", "Bingquan Shen", "H. Vicky Zhao", "Ramana Rao Kompella", "Sijia Liu"], "Categories": "cs.LG", "Comments": ["10 pages", "6 figures", "7 tables"]}, "abstract": "While state-of-the-art diffusion models (DMs) excel in image generation, concerns regarding their security persist. Earlier research highlighted DMs' vulnerability to backdoor attacks, but these studies placed stricter requirements than conventional methods like 'BadNets' in image classification. This is because the former necessitates modifications to the diffusion sampling and training procedures. Unlike the prior work, we investigate whether generating backdoor attacks in DMs can be as simple as BadNets, i.e., by only contaminating the training dataset without tampering the original diffusion process. In this more realistic backdoor setting, we uncover bilateral backdoor effects that not only serve an adversarial purpose (compromising the functionality of DMs) but also offer a defensive advantage (which can be leveraged for backdoor defense). Specifically, we find that a BadNets-like backdoor attack remains effective in DMs for producing incorrect images (misaligned with the intended text conditions), and thereby yielding incorrect predictions when DMs are used as classifiers. Meanwhile, backdoored DMs exhibit an increased ratio of backdoor triggers, a phenomenon we refer to as `trigger amplification', among the generated images. We show that this latter insight can be used to enhance the detection of backdoor-poisoned training data. Even under a low backdoor poisoning ratio, studying the backdoor effects of DMs is also valuable for designing anti-backdoor image classifiers. Last but not least, we establish a meaningful linkage between backdoor attacks and the phenomenon of data replications by exploring DMs' inherent data memorization tendencies. The codes of our work are available at https://github.com/OPTML-Group/BiBadDiff.", "url": "https://arxiv.org/abs/2311.02373"}, {"metadata": {"arXiv": "2311.02399", "Date": "Sat, 04 Nov 2023 13:11:49 ", "Title": "Entropy Aware Training for Fast and Accurate Distributed GNN", "Authors": ["Dhruv Deshmukh (1)", "Gagan Raj Gupta (1)", "Manisha Chawla (1)", "Vishwesh Jatala (1)", "Anirban Haldar (1) ((1) Department of CSE", "IIT Bhilai", "India)"], "Categories": "cs.LG cs.DC", "Comments": ["8 pages", "3 figures", "5 tables", "accepted at ICDM'23"], "ACM-class": "I.5.1; I.5.2"}, "abstract": "Several distributed frameworks have been developed to scale Graph Neural Networks (GNNs) on billion-size graphs. On several benchmarks, we observe that the graph partitions generated by these frameworks have heterogeneous data distributions and class imbalance, affecting convergence, and resulting in lower performance than centralized implementations. We holistically address these challenges and develop techniques that reduce training time and improve accuracy. We develop an Edge-Weighted partitioning technique to improve the micro average F1 score (accuracy) by minimizing the total entropy. Furthermore, we add an asynchronous personalization phase that adapts each compute-host's model to its local data distribution. We design a class-balanced sampler that considerably speeds up convergence. We implemented our algorithms on the DistDGL framework and observed that our training techniques scale much better than the existing training approach. We achieved a (2-3x) speedup in training time and 4\\% improvement on average in micro-F1 scores on 5 large graph benchmarks compared to the standard baselines.", "url": "https://arxiv.org/abs/2311.02399"}, {"metadata": {"arXiv": "2311.02401", "Date": "Sat, 04 Nov 2023 13:25:49 ", "Title": "BarcodeBERT: Transformers for Biodiversity Analysis", "Authors": ["Pablo Millan Arias and Niousha Sadjadi and Monireh Safari and ZeMing Gong and Austin T. Wang and Scott C. Lowe and Joakim Bruslund Haurum and Iuliia Zarubiieva and Dirk Steinke and Lila Kari and Angel X. Chang and Graham W. Taylor"], "Categories": "cs.LG", "Comments": ["Main text: 5 pages", "Total: 9 pages", "2 figures", "accepted at the 4th Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2023)"]}, "abstract": "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of DNA that cluster by species - play a pivotal role. In particular, invertebrates, a highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, and a DNA barcode-specific masking strategy across datasets of varying complexity. While simpler datasets and tasks favor supervised CNNs or fine-tuned transformers, challenging species-level identification demands a paradigm shift towards self-supervised pretraining. We propose BarcodeBERT, the first self-supervised method for general biodiversity analysis, leveraging a 1.5 M invertebrate DNA barcode reference library. This work highlights how dataset specifics and coverage impact model selection, and underscores the role of self-supervised pretraining in achieving high-accuracy DNA barcode-based identification at the species and genus level. Indeed, without the fine-tuning step, BarcodeBERT pretrained on a large DNA barcode dataset outperforms DNABERT and DNABERT-2 on multiple downstream classification tasks. The code repository is available at https://github.com/Kari-Genomics-Lab/BarcodeBERT", "url": "https://arxiv.org/abs/2311.02401"}, {"metadata": {"arXiv": "2311.02402", "Date": "Sat, 04 Nov 2023 13:28:06 ", "Title": "Hybrid quantum image classification and federated learning for hepatic steatosis diagnosis", "Authors": ["Luca Lusnig", "Asel Sagingalieva", "Mikhail Surmach", "Tatjana Protasevich", "Ovidiu Michiu", "Joseph McLoughlin", "Christopher Mansell", "Graziano de' Petris", "Deborah Bonazza", "Fabrizio Zanconati", "Alexey Melnikov", "and Fabio Cavalli"], "Categories": "cs.LG cs.CV quant-ph", "Comments": ["10 pages", "3 figures", "1 table"]}, "abstract": "With the maturity achieved by deep learning techniques, intelligent systems that can assist physicians in the daily interpretation of clinical images can play a very important role. In addition, quantum techniques applied to deep learning can enhance this performance, and federated learning techniques can realize privacy-friendly collaborative learning among different participants, solving privacy issues due to the use of sensitive data and reducing the number of data to be collected for each individual participant. We present in this study a hybrid quantum neural network that can be used to quantify non-alcoholic liver steatosis and could be useful in the diagnostic process to determine a liver's suitability for transplantation; at the same time, we propose a federated learning approach based on a classical deep learning solution to solve the same problem, but using a reduced data set in each part. The liver steatosis image classification accuracy of the hybrid quantum neural network, the hybrid quantum ResNet model, consisted of 5 qubits and more than 100 variational gates, reaches 97%, which is 1.8% higher than its classical counterpart, ResNet. Crucially, that even with a reduced dataset, our hybrid approach consistently outperformed its classical counterpart, indicating superior generalization and less potential for overfitting in medical applications. In addition, a federated approach with multiple clients, up to 32, despite the lower accuracy, but still higher than 90%, would allow using, for each participant, a very small dataset, i.e., up to one-thirtieth. Our work, based over real-word clinical data can be regarded as a scalable and collaborative starting point, could thus fulfill the need for an effective and reliable computer-assisted system that facilitates the daily diagnostic work of the clinical pathologist.", "url": "https://arxiv.org/abs/2311.02402"}, {"metadata": {"arXiv": "2311.02455", "Date": "Sat, 04 Nov 2023 16:42:42 ", "Title": "Attention-based Multi-instance Mixed Models", "Authors": ["Jan P. Engelmann", "Alessandro Palma", "Jakub M. Tomczak", "Fabian J Theis", "Francesco Paolo Casale"], "Categories": "cs.LG q-bio.GN q-bio.QM stat.AP"}, "abstract": "Predicting patient features from single-cell data can unveil cellular states implicated in health and disease. Linear models and average cell type expressions are typically favored for this task for their efficiency and robustness, but they overlook the rich cell heterogeneity inherent in single-cell data. To address this gap, we introduce GMIL, a framework integrating Generalized Linear Mixed Models (GLMM) and Multiple Instance Learning (MIL), upholding the advantages of linear models while modeling cell-state heterogeneity. By leveraging predefined cell embeddings, GMIL enhances computational efficiency and aligns with recent advancements in single-cell representation learning. Our empirical results reveal that GMIL outperforms existing MIL models in single-cell datasets, uncovering new associations and elucidating biological mechanisms across different domains.", "url": "https://arxiv.org/abs/2311.02455"}, {"metadata": {"arXiv": "2311.02495", "Date": "Sat, 04 Nov 2023 19:40:16 ", "Title": "Uncertainty Quantification in Multivariable Regression for Material Property Prediction with Bayesian Neural Networks", "Authors": ["Longze li", "Jiang Chang", "Aleksandar Vakanski", "Min Xian"], "Categories": "cs.LG cond-mat.mtrl-sci", "Comments": ["24 pages", "4 figures"]}, "abstract": "With the increased use of data-driven approaches and machine learning-based methods in material science, the importance of reliable uncertainty quantification (UQ) of the predicted variables for informed decision-making cannot be overstated. UQ in material property prediction poses unique challenges, including the multi-scale and multi-physics nature of advanced materials, intricate interactions between numerous factors, limited availability of large curated datasets for model training, etc. Recently, Bayesian Neural Networks (BNNs) have emerged as a promising approach for UQ, offering a probabilistic framework for capturing uncertainties within neural networks. In this work, we introduce an approach for UQ within physics-informed BNNs, which integrates knowledge from governing laws in material modeling to guide the models toward physically consistent predictions. To evaluate the effectiveness of this approach, we present case studies for predicting the creep rupture life of steel alloys. Experimental validation with three datasets of collected measurements from creep tests demonstrates the ability of BNNs to produce accurate point and uncertainty estimates that are competitive or exceed the performance of the conventional method of Gaussian Process Regression. Similarly, we evaluated the suitability of BNNs for UQ in an active learning application and reported competitive performance. The most promising framework for creep life prediction is BNNs based on Markov Chain Monte Carlo approximation of the posterior distribution of network parameters, as it provided more reliable results in comparison to BNNs based on variational inference approximation or related NNs with probabilistic outputs. The codes are available at: https://github.com/avakanski/Creep-uncertainty-quantification.", "url": "https://arxiv.org/abs/2311.02495"}, {"metadata": {"arXiv": "2311.02496", "Date": "Sat, 04 Nov 2023 19:41:50 ", "Title": "LocoMuJoCo: A Comprehensive Imitation Learning Benchmark for Locomotion", "Authors": ["Firas Al-Hafez and Guoping Zhao and Jan Peters and Davide Tateo"], "Categories": "cs.LG cs.RO", "Comments": ["https://github.com/robfiras/loco-mujoco"]}, "abstract": "Imitation Learning (IL) holds great promise for enabling agile locomotion in embodied agents. However, many existing locomotion benchmarks primarily focus on simplified toy tasks, often failing to capture the complexity of real-world scenarios and steering research toward unrealistic domains. To advance research in IL for locomotion, we present a novel benchmark designed to facilitate rigorous evaluation and comparison of IL algorithms. This benchmark encompasses a diverse set of environments, including quadrupeds, bipeds, and musculoskeletal human models, each accompanied by comprehensive datasets, such as real noisy motion capture data, ground truth expert data, and ground truth sub-optimal data, enabling evaluation across a spectrum of difficulty levels. To increase the robustness of learned agents, we provide an easy interface for dynamics randomization and offer a wide range of partially observable tasks to train agents across different embodiments. Finally, we provide handcrafted metrics for each task and ship our benchmark with state-of-the-art baseline algorithms to ease evaluation and enable fast benchmarking.", "url": "https://arxiv.org/abs/2311.02496"}, {"metadata": {"arXiv": "2311.02516", "Date": "Sat, 04 Nov 2023 21:46:28 ", "Title": "Forward $\\chi^2$ Divergence Based Variational Importance Sampling", "Authors": ["Chengrui Li", "Yule Wang", "Weihan Li and Anqi Wu"], "Categories": "cs.LG stat.CO stat.ML"}, "abstract": "Maximizing the log-likelihood is a crucial aspect of learning latent variable models, and variational inference (VI) stands as the commonly adopted method. However, VI can encounter challenges in achieving a high log-likelihood when dealing with complicated posterior distributions. In response to this limitation, we introduce a novel variational importance sampling (VIS) approach that directly estimates and maximizes the log-likelihood. VIS leverages the optimal proposal distribution, achieved by minimizing the forward $\\chi^2$ divergence, to enhance log-likelihood estimation. We apply VIS to various popular latent variable models, including mixture models, variational auto-encoders, and partially observable generalized linear models. Results demonstrate that our approach consistently outperforms state-of-the-art baselines, both in terms of log-likelihood and model parameter estimation.", "url": "https://arxiv.org/abs/2311.02516"}, {"metadata": {"arXiv": "2311.02546", "Date": "Sun, 05 Nov 2023 02:33:30 ", "Title": "Preliminary Analysis on Second-Order Convergence for Biased Policy Gradient Methods", "Authors": ["Siqiao Mu and Diego Klabjan"], "Categories": "cs.LG"}, "abstract": "Although the convergence of policy gradient algorithms to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. Therefore, recent work has focused on two extensions: ``global\" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. Our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. Existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both Monte-Carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. We present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. In our next steps we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.", "url": "https://arxiv.org/abs/2311.02546"}, {"metadata": {"arXiv": "2311.02622", "Date": "Sun, 05 Nov 2023 11:27:03 ", "Title": "Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity Bias", "Authors": ["Zhehang Du"], "Categories": "cs.LG cs.CV", "Comments": ["17 pages", "17 figures"]}, "abstract": "Neural networks exhibit simplicity bias; they rely on simpler features while ignoring equally predictive but more complex features. In this work, we introduce a novel approach termed imbalanced label coupling to investigate scenarios where simple and complex features exhibit different levels of predictive power. In these cases, complex features still contribute to predictions. The trained networks make predictions in alignment with the ascending complexity of input features according to how they correlate with the label in the training set, irrespective of the underlying predictive power. For instance, even when simple spurious features distort predictions in CIFAR-10, most cats are predicted to be dogs, and most trucks are predicted to be automobiles! This observation provides direct evidence that the neural network learns core features in the presence of spurious features. We empirically show that last-layer retraining with target data distribution is effective, yet insufficient to fully recover core features when spurious features are perfectly correlated with the target labels in our synthetic dataset. We hope our research contributes to a deeper understanding of the implicit bias of neural networks.", "url": "https://arxiv.org/abs/2311.02622"}, {"metadata": {"arXiv": "2311.02629", "Date": "Sun, 05 Nov 2023 12:03:58 ", "Title": "Pointer Networks with Q-Learning for OP Combinatorial Optimization", "Authors": ["Alessandro Barro"], "Categories": "cs.LG math.OC"}, "abstract": "The Orienteering Problem (OP) presents a unique challenge in combinatorial optimization, emphasized by its widespread use in logistics, delivery, and transportation planning. Given the NP-hard nature of OP, obtaining optimal solutions is inherently complex. While Pointer Networks (Ptr-Nets) have exhibited prowess in various combinatorial tasks, their performance in the context of OP leaves room for improvement. Recognizing the potency of Q-learning, especially when paired with deep neural structures, this research unveils the Pointer Q-Network (PQN). This innovative method combines Ptr-Nets and Q-learning, effectively addressing the specific challenges presented by OP. We deeply explore the architecture and efficiency of PQN, showcasing its superior capability in managing OP situations.", "url": "https://arxiv.org/abs/2311.02629"}, {"metadata": {"arXiv": "2311.02715", "Date": "Sun, 05 Nov 2023 17:27:06 ", "Title": "Exploiting Correlated Auxiliary Feedback in Parameterized Bandits", "Authors": ["Arun Verma", "Zhongxiang Dai", "Yao Shu", "Bryan Kian Hsiang Low"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "We study a novel variant of the parameterized bandits problem in which the learner can observe additional auxiliary feedback that is correlated with the observed reward. The auxiliary feedback is readily available in many real-life applications, e.g., an online platform that wants to recommend the best-rated services to its users can observe the user's rating of service (rewards) and collect additional information like service delivery time (auxiliary feedback). In this paper, we first develop a method that exploits auxiliary feedback to build a reward estimator with tight confidence bounds, leading to a smaller regret. We then characterize the regret reduction in terms of the correlation coefficient between reward and its auxiliary feedback. Experimental results in different settings also verify the performance gain achieved by our proposed method.", "url": "https://arxiv.org/abs/2311.02715"}, {"metadata": {"arXiv": "2311.02738", "Date": "Sun, 05 Nov 2023 19:04:25 ", "Title": "Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion", "Authors": ["Ethan Pronovost", "Meghana Reddy Ganesina", "Noureldin Hendy", "Zeyu Wang", "Andres Morales", "Kai Wang", "Nicholas Roy"], "Categories": "cs.LG cs.CV cs.RO", "Comments": ["NeurIPS 2023"]}, "abstract": "Automated creation of synthetic traffic scenarios is a key part of validating the safety of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. To provide additional control over the generated scenario, this distribution is conditioned on a map and sets of tokens describing the desired scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions.", "url": "https://arxiv.org/abs/2311.02738"}, {"metadata": {"arXiv": "2311.02746", "Date": "Sun, 05 Nov 2023 19:43:23 ", "Title": "Staged Reinforcement Learning for Complex Tasks through Decomposed Environments", "Authors": ["Rafael Pina", "Corentin Artaud", "Xiaolan Liu and Varuna De Silva"], "Categories": "cs.LG", "Comments": ["Intelligent Systems and Pattern Recognition 2023 (ISPR 2023)"]}, "abstract": "Reinforcement Learning (RL) is an area of growing interest in the field of artificial intelligence due to its many notable applications in diverse fields. Particularly within the context of intelligent vehicle control, RL has made impressive progress. However, currently it is still in simulated controlled environments where RL can achieve its full super-human potential. Although how to apply simulation experience in real scenarios has been studied, how to approximate simulated problems to the real dynamic problems is still a challenge. In this paper, we discuss two methods that approximate RL problems to real problems. In the context of traffic junction simulations, we demonstrate that, if we can decompose a complex task into multiple sub-tasks, solving these tasks first can be advantageous to help minimising possible occurrences of catastrophic events in the complex task. From a multi-agent perspective, we introduce a training structuring mechanism that exploits the use of experience learned under the popular paradigm called Centralised Training Decentralised Execution (CTDE). This experience can then be leveraged in fully decentralised settings that are conceptually closer to real settings, where agents often do not have access to a central oracle and must be treated as isolated independent units. The results show that the proposed approaches improve agents performance in complex tasks related to traffic junctions, minimising potential safety-critical problems that might happen in these scenarios. Although still in simulation, the investigated situations are conceptually closer to real scenarios and thus, with these results, we intend to motivate further research in the subject.", "url": "https://arxiv.org/abs/2311.02746"}, {"metadata": {"arXiv": "2311.02757", "Date": "Sun, 05 Nov 2023 20:29:40 ", "Title": "ELEGANT: Certified Defense on the Fairness of Graph Neural Networks", "Authors": ["Yushun Dong", "Binchi Zhang", "Hanghang Tong", "Jundong Li"], "Categories": "cs.LG cs.CR stat.ML"}, "abstract": "Graph Neural Networks (GNNs) have emerged as a prominent graph learning model in various graph-based tasks over the years. Nevertheless, due to the vulnerabilities of GNNs, it has been empirically proved that malicious attackers could easily corrupt the fairness level of their predictions by adding perturbations to the input graph data. In this paper, we take crucial steps to study a novel problem of certifiable defense on the fairness level of GNNs. Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes any GNNs as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not have any assumption over the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Hence it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs, where ELEGANT is also demonstrated to be beneficial for GNN debiasing. Open-source code can be found at https://github.com/yushundong/ELEGANT.", "url": "https://arxiv.org/abs/2311.02757"}, {"metadata": {"arXiv": "2311.02761", "Date": "Sun, 05 Nov 2023 20:43:08 ", "Title": "One-Shot Strategic Classification Under Unknown Costs", "Authors": ["Elan Rosenfeld", "Nir Rosenfeld"], "Categories": "cs.LG cs.GT stat.ML"}, "abstract": "A primary goal in strategic classification is to learn decision rules which are robust to strategic input manipulation. Earlier works assume that strategic responses are known; while some recent works address the important challenge of unknown responses, they exclusively study sequential settings which allow multiple model deployments over time. But there are many domains$\\unicode{x2014}$particularly in public policy, a common motivating use-case$\\unicode{x2014}$where multiple deployments are unrealistic, or where even a single bad round is undesirable. To address this gap, we initiate the study of strategic classification under unknown responses in the one-shot setting, which requires committing to a single classifier once. Focusing on the users' cost function as the source of uncertainty, we begin by proving that for a broad class of costs, even a small mis-estimation of the true cost can entail arbitrarily low accuracy in the worst case. In light of this, we frame the one-shot task as a minimax problem, with the goal of identifying the classifier with the smallest worst-case risk over an uncertainty set of possible costs. Our main contribution is efficient algorithms for both the full-batch and stochastic settings, which we prove converge (offline) to the minimax optimal solution at the dimension-independent rate of $\\tilde{\\mathcal{O}}(T^{-\\frac{1}{2}})$. Our analysis reveals important structure stemming from the strategic nature of user responses, particularly the importance of dual norm regularization with respect to the cost function.", "url": "https://arxiv.org/abs/2311.02761"}, {"metadata": {"arXiv": "2311.02766", "Date": "Sun, 05 Nov 2023 20:51:03 ", "Title": "Riemannian Laplace Approximation with the Fisher Metric", "Authors": ["Hanlin Yu", "Marcelo Hartmann", "Bernardo Williams", "Mark Girolami", "Arto Klami"], "Categories": "cs.LG stat.ME stat.ML"}, "abstract": "The Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties heavily depend on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.", "url": "https://arxiv.org/abs/2311.02766"}, {"metadata": {"arXiv": "2311.02798", "Date": "Sun, 05 Nov 2023 23:47:52 ", "Title": "From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning", "Authors": ["Yue Wan and Jialu Wu and Tingjun Hou and Chang-Yu Hsieh and Xiaowei Jia"], "Categories": "cs.LG physics.chem-ph q-bio.QM"}, "abstract": "Reliable molecular property prediction is essential for various scientific endeavors and industrial applications, such as drug discovery. However, the scarcity of data, combined with the highly non-linear causal relationships between physicochemical and biological properties and conventional molecular featurization schemes, complicates the development of robust molecular machine learning models. Self-supervised learning (SSL) has emerged as a popular solution, utilizing large-scale, unannotated molecular data to learn a foundational representation of chemical space that might be advantageous for downstream tasks. Yet, existing molecular SSL methods largely overlook domain-specific knowledge, such as molecular similarity and scaffold importance, as well as the context of the target application when operating over the large chemical space. This paper introduces a novel learning framework that leverages the knowledge of structural hierarchies within molecular structures, embeds them through separate pre-training tasks over distinct channels, and employs a task-specific channel selection to compose a context-dependent representation. Our approach demonstrates competitive performance across various molecular property benchmarks and establishes some state-of-the-art results. It further offers unprecedented advantages in particularly challenging yet ubiquitous scenarios like activity cliffs with enhanced robustness and generalizability compared to other baselines.", "url": "https://arxiv.org/abs/2311.02798"}, {"metadata": {"arXiv": "2311.02801", "Date": "Mon, 06 Nov 2023 00:04:12 ", "Title": "On the Intersection of Self-Correction and Trust in Language Models", "Authors": ["Satyapriya Krishna"], "Categories": "cs.LG", "Comments": ["Working Paper"]}, "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex cognitive tasks. However, their complexity and lack of transparency have raised several trustworthiness concerns, including the propagation of misinformation and toxicity. Recent research has explored the self-correction capabilities of LLMs to enhance their performance. In this work, we investigate whether these self-correction capabilities can be harnessed to improve the trustworthiness of LLMs. We conduct experiments focusing on two key aspects of trustworthiness: truthfulness and toxicity. Our findings reveal that self-correction can lead to improvements in toxicity and truthfulness, but the extent of these improvements varies depending on the specific aspect of trustworthiness and the nature of the task. Interestingly, our study also uncovers instances of \"self-doubt\" in LLMs during the self-correction process, introducing a new set of challenges that need to be addressed.", "url": "https://arxiv.org/abs/2311.02801"}, {"metadata": {"arXiv": "2311.02818", "Date": "Mon, 06 Nov 2023 01:41:46 ", "Title": "Signal Processing Meets SGD: From Momentum to Filter", "Authors": ["Zhipeng Yao", "Guisong Chang", "Jiaqi Zhang", "Qi Zhang", "Yu Zhang", "Dazhou Li"], "Categories": "cs.LG eess.SP", "Comments": ["arXiv admin note: text overlap with arXiv:2010.07468 by other authors"]}, "abstract": "In the field of deep learning, Stochastic Gradient Descent (SGD) and its momentum-based variants are the predominant choices for optimization algorithms. Despite all that, these momentum strategies, which accumulate historical gradients by using a fixed $\\beta$ hyperparameter to smooth the optimization processing, often neglect the potential impact of the variance of historical gradients on the current gradient estimation. In the gradient variance during training, fluctuation indicates the objective function does not meet the Lipschitz continuity condition at all time, which raises the troublesome optimization problem. This paper aims to explore the potential benefits of reducing the variance of historical gradients to make optimizer converge to flat solutions. Moreover, we proposed a new optimization method based on reducing the variance. We employed the Wiener filter theory to enhance the first moment estimation of SGD, notably introducing an adaptive weight to optimizer. Specifically, the adaptive weight dynamically changes along with temporal fluctuation of gradient variance during deep learning model training. Experimental results demonstrated our proposed adaptive weight optimizer, SGDF (Stochastic Gradient Descent With Filter), can achieve satisfactory performance compared with state-of-the-art optimizers.", "url": "https://arxiv.org/abs/2311.02818"}, {"metadata": {"arXiv": "2311.02832", "Date": "Mon, 06 Nov 2023 02:38:35 ", "Title": "Prioritized Propagation in Graph Neural Networks", "Authors": ["Yao Cheng and Minjie Chen and Xiang Li and Caihua Shan and Ming Gao"], "Categories": "cs.LG"}, "abstract": "Graph neural networks (GNNs) have recently received significant attention. Learning node-wise message propagation in GNNs aims to set personalized propagation steps for different nodes in the graph. Despite the success, existing methods ignore node priority that can be reflected by node influence and heterophily. In this paper, we propose a versatile framework PPro, which can be integrated with most existing GNN models and aim to learn prioritized node-wise message propagation in GNNs. Specifically, the framework consists of three components: a backbone GNN model, a propagation controller to determine the optimal propagation steps for nodes, and a weight controller to compute the priority scores for nodes. We design a mutually enhanced mechanism to compute node priority, optimal propagation step and label prediction. We also propose an alternative optimization strategy to learn the parameters in the backbone GNN model and two parametric controllers. We conduct extensive experiments to compare our framework with other 11 state-of-the-art competitors on 8 benchmark datasets. Experimental results show that our framework can lead to superior performance in terms of propagation strategies and node representations.", "url": "https://arxiv.org/abs/2311.02832"}, {"metadata": {"arXiv": "2311.02868", "Date": "Mon, 06 Nov 2023 04:45:21 ", "Title": "Sample Complexity Bounds for Estimating Probability Divergences under Invariances", "Authors": ["Behrooz Tahmasebi", "Stefanie Jegelka"], "Categories": "cs.LG"}, "abstract": "Group-invariant probability distributions appear in many data-generative models in machine learning, such as graphs, point clouds, and images. In practice, one often needs to estimate divergences between such distributions. In this work, we study how the inherent invariances, with respect to any smooth action of a Lie group on a manifold, improve sample complexity when estimating the Wasserstein distance, the Sobolev Integral Probability Metrics (Sobolev IPMs), the Maximum Mean Discrepancy (MMD), and also the complexity of the density estimation problem (in the $L^2$ and $L^\\infty$ distance). Our results indicate a two-fold gain: (1) reducing the sample complexity by a multiplicative factor corresponding to the group size (for finite groups) or the normalized volume of the quotient space (for groups of positive dimension); (2) improving the exponent in the convergence rate (for groups of positive dimension). These results are completely new for groups of positive dimension and extend recent bounds for finite group actions.", "url": "https://arxiv.org/abs/2311.02868"}, {"metadata": {"arXiv": "2311.02879", "Date": "Mon, 06 Nov 2023 05:18:01 ", "Title": "Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling", "Authors": ["Wonho Bae", "Jing Wang", "Danica J. Sutherland"], "Categories": "cs.LG"}, "abstract": "Most meta-learning methods assume that the (very small) context set used to establish a new task at test time is passively provided. In some settings, however, it is feasible to actively select which points to label; the potential gain from a careful choice is substantial, but the setting requires major differences from typical active learning setups. We clarify the ways in which active meta-learning can be used to label a context set, depending on which parts of the meta-learning process use active learning. Within this framework, we propose a natural algorithm based on fitting Gaussian mixtures for selecting which points to label; though simple, the algorithm also has theoretical motivation. The proposed algorithm outperforms state-of-the-art active learning methods when used with various meta-learning algorithms across several benchmark datasets.", "url": "https://arxiv.org/abs/2311.02879"}, {"metadata": {"arXiv": "2311.02880", "Date": "Mon, 06 Nov 2023 05:19:06 ", "Title": "MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for Traffic Forecast via Structural Entropy Optimization", "Authors": ["Dongcheng Zou", "Senzhang Wang", "Xuefeng Li", "Hao Peng", "Yuandong Wang", "Chunyang Liu", "Kehua Sheng and Bo Zhang"], "Categories": "cs.LG", "Comments": ["10 pages", "7 figures", "conference. The work has been accepted by WSDM2024"]}, "abstract": "Traffic forecasting is a complex multivariate time-series regression task of paramount importance for traffic management and planning. However, existing approaches often struggle to model complex multi-range dependencies using local spatiotemporal features and road network hierarchical knowledge. To address this, we propose MultiSPANS. First, considering that an individual recording point cannot reflect critical spatiotemporal local patterns, we design multi-filter convolution modules for generating informative ST-token embeddings to facilitate attention computation. Then, based on ST-token and spatial-temporal position encoding, we employ the Transformers to capture long-range temporal and spatial dependencies. Furthermore, we introduce structural entropy theory to optimize the spatial attention mechanism. Specifically, The structural entropy minimization algorithm is used to generate optimal road network hierarchies, i.e., encoding trees. Based on this, we propose a relative structural entropy-based position encoding and a multi-head attention masking scheme based on multi-layer encoding trees. Extensive experiments demonstrate the superiority of the presented framework over several state-of-the-art methods in real-world traffic datasets, and the longer historical windows are effectively utilized. The code is available at https://github.com/SELGroup/MultiSPANS.", "url": "https://arxiv.org/abs/2311.02880"}, {"metadata": {"arXiv": "2311.02891", "Date": "Mon, 06 Nov 2023 05:50:10 ", "Title": "AdaFlood: Adaptive Flood Regularization", "Authors": ["Wonho Bae", "Yi Ren", "Mohamad Osama Ahmed", "Frederick Tung", "Danica J. Sutherland", "Gabriel L. Oliveira"], "Categories": "cs.LG"}, "abstract": "Although neural networks are conventionally optimized towards zero training loss, it has been recently learned that targeting a non-zero training loss threshold, referred to as a flood level, often enables better test time generalization. Current approaches, however, apply the same constant flood level to all training samples, which inherently assumes all the samples have the same difficulty. We present AdaFlood, a novel flood regularization method that adapts the flood level of each training sample according to the difficulty of the sample. Intuitively, since training samples are not equal in difficulty, the target training loss should be conditioned on the instance. Experiments on datasets covering four diverse input modalities - text, images, asynchronous event sequences, and tabular - demonstrate the versatility of AdaFlood across data domains and noise levels.", "url": "https://arxiv.org/abs/2311.02891"}, {"metadata": {"arXiv": "2311.02903", "Date": "Mon, 06 Nov 2023 06:29:23 ", "Title": "HDGL: A hierarchical dynamic graph representation learning model for brain disorder classification", "Authors": ["Parniyan Jalali", "Mehran Safayani"], "Categories": "cs.LG q-bio.NC"}, "abstract": "The human brain can be considered as complex networks, composed of various regions that continuously exchange their information with each other, forming the brain network graph, from which nodes and edges are extracted using resting-state functional magnetic resonance imaging (rs-fMRI). Therefore, this graph can potentially depict abnormal patterns that have emerged under the influence of brain disorders. So far, numerous studies have attempted to find embeddings for brain network graphs and subsequently classify samples with brain disorders from healthy ones, which include limitations such as: not considering the relationship between samples, not utilizing phenotype information, lack of temporal analysis, using static functional connectivity (FC) instead of dynamic ones and using a fixed graph structure. We propose a hierarchical dynamic graph representation learning (HDGL) model, which is the first model designed to address all the aforementioned challenges. HDGL consists of two levels, where at the first level, it constructs brain network graphs and learns their spatial and temporal embeddings, and at the second level, it forms population graphs and performs classification after embedding learning. Furthermore, based on how these two levels are trained, four methods have been introduced, some of which are suggested for reducing memory complexity. We evaluated the performance of the proposed model on the ABIDE and ADHD-200 datasets, and the results indicate the improvement of this model compared to several state-of-the-art models in terms of various evaluation metrics.", "url": "https://arxiv.org/abs/2311.02903"}, {"metadata": {"arXiv": "2311.02909", "Date": "Mon, 06 Nov 2023 06:40:43 ", "Title": "Distributed Matrix-Based Sampling for Graph Neural Network Training", "Authors": ["Alok Tripathy", "Katherine Yelick", "Aydin Buluc"], "Categories": "cs.LG cs.DC cs.PF"}, "abstract": "The primary contribution of this paper is new methods for reducing communication in the sampling step for distributed GNN training. Here, we propose a matrix-based bulk sampling approach that expresses sampling as a sparse matrix multiplication (SpGEMM) and samples multiple minibatches at once. When the input graph topology does not fit on a single device, our method distributes the graph and use communication-avoiding SpGEMM algorithms to scale GNN minibatch sampling, enabling GNN training on much larger graphs than those that can fit into a single device memory. When the input graph topology (but not the embeddings) fits in the memory of one GPU, our approach (1) performs sampling without communication, (2) amortizes the overheads of sampling a minibatch, and (3) can represent multiple sampling algorithms by simply using different matrix constructions. In addition to new methods for sampling, we show that judiciously replicating feature data with a simple all-to-all exchange can outperform current methods for the feature extraction step in distributed GNN training. We provide experimental results on the largest Open Graph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is $2.5\\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a $3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\\times$ speedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the graph is distributed across GPUs and scaling for both node-wise and layer-wise sampling algorithms", "url": "https://arxiv.org/abs/2311.02909"}, {"metadata": {"arXiv": "2311.02921", "Date": "Mon, 06 Nov 2023 07:28:16 ", "Title": "Edge2Node: Reducing Edge Prediction to Node Classification", "Authors": ["Zahed Rahmati", "Ali Rahmati", "Dariush Kazemi"], "Categories": "cs.LG cs.SI"}, "abstract": "Despite the success of graph neural network models in node classification, edge prediction (the task of predicting missing or potential relationships between nodes in a graph) remains a challenging problem for these models. A common approach for edge prediction is to first obtain the embeddings of two nodes, and then a predefined scoring function is used to predict the existence of an edge between the two nodes. In this paper, we introduce a new approach called E2N (Edge2Node) which directly obtains an embedding for each edge, without the need for a scoring function. To do this, we create a new graph H based on the graph G given for the edge prediction task, and then reduce the edge prediction task on G to a node classification task on H. Our E2N method can be easily applied to any edge prediction task with superior performance and lower computational costs. For the ogbl-ddi and ogbl-collab datasets, our E2N method outperforms the state-of-the-art methods listed on the leaderboards. Our experiments on the ogbl-ddi dataset achieved a Hits@20 score of 98.79% on the validation set and 98.11% on the test set. On the ogbl-collab dataset, we achieved a Hits@50 score of 95.46% on the validation set and 95.15% on the test set.", "url": "https://arxiv.org/abs/2311.02921"}, {"metadata": {"arXiv": "2311.02922", "Date": "Mon, 06 Nov 2023 07:32:27 ", "Title": "Truly Scale-Equivariant Deep Nets with Fourier Layers", "Authors": ["Md Ashiqur Rahman", "Raymond A. Yeh"], "Categories": "cs.LG cs.CV"}, "abstract": "In computer vision, models must be able to adapt to changes in image resolution to effectively carry out tasks such as image segmentation; This is known as scale-equivariance. Recent works have made progress in developing scale-equivariant convolutional neural networks, e.g., through weight-sharing and kernel resizing. However, these networks are not truly scale-equivariant in practice. Specifically, they do not consider anti-aliasing as they formulate the down-scaling operation in the continuous domain. To address this shortcoming, we directly formulate down-scaling in the discrete domain with consideration of anti-aliasing. We then propose a novel architecture based on Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute zero equivariance-error. Following prior works, we test this model on MNIST-scale and STL-10 datasets. Our proposed model achieves competitive classification performance while maintaining zero equivariance-error.", "url": "https://arxiv.org/abs/2311.02922"}, {"metadata": {"arXiv": "2311.02940", "Date": "Mon, 06 Nov 2023 08:16:41 ", "Title": "The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning", "Authors": ["Artyom Gadetsky and Maria Brbic"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023 camera-ready"]}, "abstract": "We present HUME, a simple model-agnostic framework for inferring human labeling of a given dataset without any external supervision. The key insight behind our approach is that classes defined by many human labelings are linearly separable regardless of the representation space used to represent a dataset. HUME utilizes this insight to guide the search over all possible labelings of a dataset to discover an underlying human labeling. We show that the proposed optimization objective is strikingly well-correlated with the ground truth labeling of the dataset. In effect, we only train linear classifiers on top of pretrained representations that remain fixed during training, making our framework compatible with any large pretrained and self-supervised model. Despite its simplicity, HUME outperforms a supervised linear classifier on top of self-supervised representations on the STL-10 dataset by a large margin and achieves comparable performance on the CIFAR-10 dataset. Compared to the existing unsupervised baselines, HUME achieves state-of-the-art performance on four benchmark image classification datasets including the large-scale ImageNet-1000 dataset. Altogether, our work provides a fundamentally new view to tackle unsupervised learning by searching for consistent labelings between different representation spaces.", "url": "https://arxiv.org/abs/2311.02940"}, {"metadata": {"arXiv": "2311.02960", "Date": "Mon, 06 Nov 2023 09:00:38 ", "Title": "Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination", "Authors": ["Peng Wang", "Xiao Li", "Can Yaras", "Zhihui Zhu", "Laura Balzano", "Wei Hu", "and Qing Qu"], "Categories": "cs.LG cs.CV math.OC", "Comments": ["58 pages", "14 figures"]}, "abstract": "Over the past decade, deep learning has proven to be a highly effective tool for learning meaningful features from raw data. However, it remains an open question how deep networks perform hierarchical feature learning across layers. In this work, we attempt to unveil this mystery by investigating the structures of intermediate features. Motivated by our empirical findings that linear layers mimic the roles of deep layers in nonlinear networks for feature learning, we explore how deep linear networks transform input data into output by investigating the output (i.e., features) of each layer after training in the context of multi-class classification problems. Toward this goal, we first define metrics to measure within-class compression and between-class discrimination of intermediate features, respectively. Through theoretical analysis of these two metrics, we show that the evolution of features follows a simple and quantitative pattern from shallow to deep layers when the input data is nearly orthogonal and the network weights are minimum-norm, balanced, and approximate low-rank: Each layer of the linear network progressively compresses within-class features at a geometric rate and discriminates between-class features at a linear rate with respect to the number of layers that data have passed through. To the best of our knowledge, this is the first quantitative characterization of feature evolution in hierarchical representations of deep linear networks. Empirically, our extensive experiments not only validate our theoretical results numerically but also reveal a similar pattern in deep nonlinear networks which aligns well with recent empirical studies. Moreover, we demonstrate the practical implications of our results in transfer learning. Our code is available at \\url{https://github.com/Heimine/PNC_DLN}.", "url": "https://arxiv.org/abs/2311.02960"}, {"metadata": {"arXiv": "2311.03000", "Date": "Mon, 06 Nov 2023 10:06:30 ", "Title": "Strong statistical parity through fair synthetic data", "Authors": ["Ivona Krchova", "Michael Platzer", "Paul Tiwald"], "Categories": "cs.LG cs.CY stat.ML"}, "abstract": "AI-generated synthetic data, in addition to protecting the privacy of original data sets, allows users and data consumers to tailor data to their needs. This paper explores the creation of synthetic data that embodies Fairness by Design, focusing on the statistical parity fairness definition. By equalizing the learned target probability distributions of the synthetic data generator across sensitive attributes, a downstream model trained on such synthetic data provides fair predictions across all thresholds, that is, strong fair predictions even when inferring from biased, original data. This fairness adjustment can be either directly integrated into the sampling process of a synthetic generator or added as a post-processing step. The flexibility allows data consumers to create fair synthetic data and fine-tune the trade-off between accuracy and fairness without any previous assumptions on the data or re-training the synthetic data generator.", "url": "https://arxiv.org/abs/2311.03000"}, {"metadata": {"arXiv": "2311.03001", "Date": "Mon, 06 Nov 2023 10:12:19 ", "Title": "Variational Weighting for Kernel Density Ratios", "Authors": ["Sangwoong Yoon", "Frank C. Park", "Gunsu S Yun", "Iljung Kim", "Yung-Kyun Noh"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "Kernel density estimation (KDE) is integral to a range of generative and discriminative tasks in machine learning. Drawing upon tools from the multidimensional calculus of variations, we derive an optimal weight function that reduces bias in standard kernel density estimates for density ratios, leading to improved estimates of prediction posteriors and information-theoretic measures. In the process, we shed light on some fundamental aspects of density estimation, particularly from the perspective of algorithms that employ KDEs as their main building blocks.", "url": "https://arxiv.org/abs/2311.03001"}, {"metadata": {"arXiv": "2311.03002", "Date": "Mon, 06 Nov 2023 10:12:54 ", "Title": "Estimating treatment effects from single-arm trials via latent-variable modeling", "Authors": ["Manuel Haussmann", "Tran Minh Son Le", "Viivi Halla-aho", "Samu Kurki", "Jussi Leinonen", "Miika Koskinen", "Samuel Kaski", "Harri L\\\"ahdesm\\\"aki"], "Categories": "cs.LG stat.ML"}, "abstract": "Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for (i) patient matching if treatment outcomes are not available for the treatment group, or for (ii) direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT study and real-world electronic health records. Compared to previous methods, our results show improved performance both for direct treatment effect estimation as well as for effect estimation via patient matching.", "url": "https://arxiv.org/abs/2311.03002"}, {"metadata": {"arXiv": "2311.03037", "Date": "Mon, 06 Nov 2023 11:14:48 ", "Title": "Validity problems in clinical machine learning by indirect data labeling using consensus definitions", "Authors": ["Michael Hagmann and Shigehiko Schamoni and Stefan Riezler"], "Categories": "cs.LG q-bio.QM stat.AP stat.ML", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "11 pages"]}, "abstract": "We demonstrate a validity problem of machine learning in the vital application area of disease diagnosis in medicine. It arises when target labels in training data are determined by an indirect measurement, and the fundamental measurements needed to determine this indirect measurement are included in the input data representation. Machine learning models trained on this data will learn nothing else but to exactly reconstruct the known target definition. Such models show perfect performance on similarly constructed test data but will fail catastrophically on real-world examples where the defining fundamental measurements are not or only incompletely available. We present a general procedure allowing identification of problematic datasets and black-box machine learning models trained on them, and exemplify our detection procedure on the task of early prediction of sepsis.", "url": "https://arxiv.org/abs/2311.03037"}, {"metadata": {"arXiv": "2311.03055", "Date": "Mon, 06 Nov 2023 12:15:57 ", "Title": "DRAUC: An Instance-wise Distributionally Robust AUC Optimization Framework", "Authors": ["Siran Dai", "Qianqian Xu", "Zhiyong Yang", "Xiaochun Cao", "Qingming Huang"], "Categories": "cs.LG"}, "abstract": "The Area Under the ROC Curve (AUC) is a widely employed metric in long-tailed classification scenarios. Nevertheless, most existing methods primarily assume that training and testing examples are drawn i.i.d. from the same distribution, which is often unachievable in practice. Distributionally Robust Optimization (DRO) enhances model performance by optimizing it for the local worst-case scenario, but directly integrating AUC optimization with DRO results in an intractable optimization problem. To tackle this challenge, methodically we propose an instance-wise surrogate loss of Distributionally Robust AUC (DRAUC) and build our optimization framework on top of it. Moreover, we highlight that conventional DRAUC may induce label bias, hence introducing distribution-aware DRAUC as a more suitable metric for robust AUC learning. Theoretically, we affirm that the generalization gap between the training loss and testing error diminishes if the training set is sufficiently large. Empirically, experiments on corrupted benchmark datasets demonstrate the effectiveness of our proposed method. Code is available at: https://github.com/EldercatSAM/DRAUC.", "url": "https://arxiv.org/abs/2311.03055"}, {"metadata": {"arXiv": "2311.03061", "Date": "Mon, 06 Nov 2023 12:45:32 ", "Title": "Learned layered coding for Successive Refinement in the Wyner-Ziv Problem", "Authors": ["Boris Joukovsky and Brent De Weerdt and Nikos Deligiannis"], "Categories": "cs.LG cs.IT math.IT", "Comments": ["5 pages", "submitted to ICASSP 2024"]}, "abstract": "We propose a data-driven approach to explicitly learn the progressive encoding of a continuous source, which is successively decoded with increasing levels of quality and with the aid of correlated side information. This setup refers to the successive refinement of the Wyner-Ziv coding problem. Assuming ideal Slepian-Wolf coding, our approach employs recurrent neural networks (RNNs) to learn layered encoders and decoders for the quadratic Gaussian case. The models are trained by minimizing a variational bound on the rate-distortion function of the successively refined Wyner-Ziv coding problem. We demonstrate that RNNs can explicitly retrieve layered binning solutions akin to scalable nested quantization. Moreover, the rate-distortion performance of the scheme is on par with the corresponding monolithic Wyner-Ziv coding approach and is close to the rate-distortion bound.", "url": "https://arxiv.org/abs/2311.03061"}, {"metadata": {"arXiv": "2311.03075", "Date": "Mon, 06 Nov 2023 12:59:18 ", "Title": "SoK: Memorisation in machine learning", "Authors": ["Dmitrii Usynin", "Moritz Knolle", "Georgios Kaissis"], "Categories": "cs.LG cs.CR cs.IT math.IT"}, "abstract": "Quantifying the impact of individual data samples on machine learning models is an open research problem. This is particularly relevant when complex and high-dimensional relationships have to be learned from a limited sample of the data generating distribution, such as in deep learning. It was previously shown that, in these cases, models rely not only on extracting patterns which are helpful for generalisation, but also seem to be required to incorporate some of the training data more or less as is, in a process often termed memorisation. This raises the question: if some memorisation is a requirement for effective learning, what are its privacy implications? In this work we unify a broad range of previous definitions and perspectives on memorisation in ML, discuss their interplay with model generalisation and their implications of these phenomena on data privacy. Moreover, we systematise methods allowing practitioners to detect the occurrence of memorisation or quantify it and contextualise our findings in a broad range of ML learning settings. Finally, we discuss memorisation in the context of privacy attacks, differential privacy (DP) and adversarial actors.", "url": "https://arxiv.org/abs/2311.03075"}, {"metadata": {"arXiv": "2311.03083", "Date": "Mon, 06 Nov 2023 13:10:38 ", "Title": "Quantifying the value of information transfer in population-based SHM", "Authors": ["Aidan J. Hughes", "Jack Poole", "Nikolaos Dervilis", "Paul Gardner", "Keith Worden"], "Categories": "cs.LG stat.AP", "Comments": ["Submitted to the 42nd IMAC: A Conference and Exposition on Structural Dynamics (IMAC-XLII)", "2024"]}, "abstract": "Population-based structural health monitoring (PBSHM), seeks to address some of the limitations associated with data scarcity that arise in traditional SHM. A tenet of the population-based approach to SHM is that information can be shared between sufficiently-similar structures in order to improve predictive models. Transfer learning techniques, such as domain adaptation, have been shown to be a highly-useful technology for sharing information between structures when developing statistical classifiers for PBSHM. Nonetheless, transfer-learning techniques are not without their pitfalls. In some circumstances, for example if the data distributions associated with the structures within a population are dissimilar, applying transfer-learning methods can be detrimental to classification performance -- this phenomenon is known as negative transfer. Given the potentially-severe consequences of negative transfer, it is prudent for engineers to ask the question `when, what, and how should one transfer between structures?'. The current paper aims to demonstrate a transfer-strategy decision process for a classification task for a population of simulated structures in the context of a representative SHM maintenance problem, supported by domain adaptation. The transfer decision framework is based upon the concept of expected value of information transfer. In order to compute the expected value of information transfer, predictions must be made regarding the classification (and decision performance) in the target domain following information transfer. In order to forecast the outcome of transfers, a probabilistic regression is used here to predict classification performance from a proxy for structural similarity based on the modal assurance criterion.", "url": "https://arxiv.org/abs/2311.03083"}, {"metadata": {"arXiv": "2311.03087", "Date": "Mon, 06 Nov 2023 13:18:08 ", "Title": "Persistent homology for high-dimensional data based on spectral methods", "Authors": ["Sebastian Damrich", "Philipp Berens", "Dmitry Kobak"], "Categories": "cs.LG math.AT", "Comments": ["33 pages", "22 figures"]}, "abstract": "Persistent homology is a popular computational tool for detecting non-trivial topology of point clouds, such as the presence of loops or voids. However, many real-world datasets with low intrinsic dimensionality reside in an ambient space of much higher dimensionality. We show that in this case vanilla persistent homology becomes very sensitive to noise and fails to detect the correct topology. The same holds true for most existing refinements of persistent homology. As a remedy, we find that spectral distances on the $k$-nearest-neighbor graph of the data, such as diffusion distance and effective resistance, allow persistent homology to detect the correct topology even in the presence of high-dimensional noise. Furthermore, we derive a novel closed-form expression for effective resistance in terms of the eigendecomposition of the graph Laplacian, and describe its relation to diffusion distances. Finally, we apply these methods to several high-dimensional single-cell RNA-sequencing datasets and show that spectral distances on the $k$-nearest-neighbor graph allow robust detection of cell cycle loops.", "url": "https://arxiv.org/abs/2311.03087"}, {"metadata": {"arXiv": "2311.03094", "Date": "Mon, 06 Nov 2023 13:37:00 ", "Title": "Equivariance Is Not All You Need: Characterizing the Utility of Equivariant Graph Neural Networks for Particle Physics Tasks", "Authors": ["Savannah Thais", "Daniel Murnane"], "Categories": "cs.LG hep-ex", "Comments": ["Paper at Knowledge and Logical Reasoning in the Era of Data-driven Learning Workshop at ICML 2023"]}, "abstract": "Incorporating inductive biases into ML models is an active area of ML research, especially when ML models are applied to data about the physical world. Equivariant Graph Neural Networks (GNNs) have recently become a popular method for learning from physics data because they directly incorporate the symmetries of the underlying physical system. Drawing from the relevant literature around group equivariant networks, this paper presents a comprehensive evaluation of the proposed benefits of equivariant GNNs by using real-world particle physics reconstruction tasks as an evaluation test-bed. We demonstrate that many of the theoretical benefits generally associated with equivariant networks may not hold for realistic systems and introduce compelling directions for future research that will benefit both the scientific theory of ML and physics applications.", "url": "https://arxiv.org/abs/2311.03094"}, {"metadata": {"arXiv": "2311.03096", "Date": "Mon, 06 Nov 2023 13:37:34 ", "Title": "Weight-Sharing Regularization", "Authors": ["Mehran Shakerinava", "Motahareh Sohrabi", "Siamak Ravanbakhsh", "Simon Lacoste-Julien"], "Categories": "cs.LG stat.ML", "Comments": ["Our code is available at https://github.com/motahareh-sohrabi/weight-sharing-regularization"]}, "abstract": "Weight-sharing is ubiquitous in deep learning. Motivated by this, we introduce ''weight-sharing regularization'' for neural networks, defined as $R(w) = \\frac{1}{d - 1}\\sum_{i > j}^d |w_i - w_j|$. We study the proximal mapping of $R$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. Using this interpretation, we design a novel parallel algorithm for $\\operatorname{prox}_R$ which provides an exponential speedup over previous algorithms, with a depth of $O(\\log^3 d)$. Our algorithm makes it feasible to train weight-sharing regularized deep neural networks with proximal gradient descent. Experiments reveal that weight-sharing regularization enables fully-connected networks to learn convolution-like filters.", "url": "https://arxiv.org/abs/2311.03096"}, {"metadata": {"arXiv": "2311.03154", "Date": "Mon, 06 Nov 2023 14:48:51 ", "Title": "Convergence Analysis of Sequential Federated Learning on Heterogeneous Data", "Authors": ["Yipeng Li and Xinchen Lyu"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data. The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation. Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.", "url": "https://arxiv.org/abs/2311.03154"}, {"metadata": {"arXiv": "2311.03172", "Date": "Mon, 06 Nov 2023 15:04:48 ", "Title": "Preserving Privacy in GANs Against Membership Inference Attack", "Authors": ["Mohammadhadi Shateri", "Francisco Messina", "Fabrice Labeau", "Pablo Piantanida"], "Categories": "cs.LG cs.CR eess.SP"}, "abstract": "Generative Adversarial Networks (GANs) have been widely used for generating synthetic data for cases where there is a limited size real-world dataset or when data holders are unwilling to share their data samples. Recent works showed that GANs, due to overfitting and memorization, might leak information regarding their training data samples. This makes GANs vulnerable to Membership Inference Attacks (MIAs). Several defense strategies have been proposed in the literature to mitigate this privacy issue. Unfortunately, defense strategies based on differential privacy are proven to reduce extensively the quality of the synthetic data points. On the other hand, more recent frameworks such as PrivGAN and PAR-GAN are not suitable for small-size training datasets. In the present work, the overfitting in GANs is studied in terms of the discriminator, and a more general measure of overfitting based on the Bhattacharyya coefficient is defined. Then, inspired by Fano's inequality, our first defense mechanism against MIAs is proposed. This framework, which requires only a simple modification in the loss function of GANs, is referred to as the maximum entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs. As a second defense strategy, a more heuristic model based on minimizing the information leaked from generated samples about the training data points is presented. This approach is referred to as mutual information minimization GAN (MIMGAN) and uses a variational representation of the mutual information to minimize the information that a synthetic sample might leak about the whole training data set. Applying the proposed frameworks to some commonly used data sets against state-of-the-art MIAs reveals that the proposed methods can reduce the accuracy of the adversaries to the level of random guessing accuracy with a small reduction in the quality of the synthetic data samples.", "url": "https://arxiv.org/abs/2311.03172"}, {"metadata": {"arXiv": "2311.03191", "Date": "Mon, 06 Nov 2023 15:29:30 ", "Title": "DeepInception: Hypnotize Large Language Model to Be Jailbreaker", "Authors": ["Xuan Li", "Zhanke Zhou", "Jianing Zhu", "Jiangchao Yao", "Tongliang Liu", "Bo Han"], "Categories": "cs.LG cs.CR"}, "abstract": "Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void. However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective. In this paper, inspired by the Milgram experiment that individuals can harm another person if they are told to do so by an authoritative figure, we disclose a lightweight method, termed as DeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock its misusing risks. Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario and provides the possibility for further direct jailbreaks. Empirically, we conduct comprehensive experiments to show its efficacy. Our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna, Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay more attention to the safety aspects of LLMs and a stronger defense against their misuse risks. The code is publicly available at: https://github.com/tmlr-group/DeepInception.", "url": "https://arxiv.org/abs/2311.03191"}, {"metadata": {"arXiv": "2311.03233", "Date": "Mon, 06 Nov 2023 16:20:28 ", "Title": "Navigating Scaling Laws: Accelerating Vision Transformer's Training via Adaptive Strategies", "Authors": ["Sotiris Anagnostidis", "Gregor Bachmann", "Thomas Hofmann"], "Categories": "cs.LG cs.CV"}, "abstract": "In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data. The paradigm is very simple: Investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute. This leads to the notion of a \"compute-optimal\" model, i.e. a model that allocates a given level of compute during training optimally to maximise performance. In this work, we extend the concept of optimality by allowing for an \"adaptive\" model, i.e. a model that can change its shape during the course of training. By allowing the shape to adapt, we can optimally traverse between the underlying scaling laws, leading to a significant reduction in the required compute to reach a given target performance. We focus on vision tasks and the family of Vision Transformers, where the patch size as well as the width naturally serve as adaptive shape parameters. We demonstrate that, guided by scaling laws, we can design compute-optimal adaptive models that beat their \"static\" counterparts.", "url": "https://arxiv.org/abs/2311.03233"}, {"metadata": {"arXiv": "2311.03235", "Date": "Mon, 06 Nov 2023 16:25:56 ", "Title": "p-Laplacian Transformer", "Authors": ["Tuan Nguyen", "Tam Nguyen", "Vinh Nguyen", "Tan M. Nguyen"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "$p$-Laplacian regularization, rooted in graph and image signal processing, introduces a parameter $p$ to control the regularization effect on these data. Smaller values of $p$ promote sparsity and interpretability, while larger values encourage smoother solutions. In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture. However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably. From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers. In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed. We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets.", "url": "https://arxiv.org/abs/2311.03235"}, {"metadata": {"arXiv": "2311.03236", "Date": "Mon, 06 Nov 2023 16:26:52 ", "Title": "Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources", "Authors": ["Haotian Zheng", "Qizhou Wang", "Zhen Fang", "Xiaobo Xia", "Feng Liu", "Tongliang Liu", "Bo Han"], "Categories": "cs.LG cs.MM", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Out-of-distribution (OOD) detection discerns OOD data where the predictor cannot make valid predictions as in-distribution (ID) data, thereby increasing the reliability of open-world classification. However, it is typically hard to collect real out-of-distribution (OOD) data for training a predictor capable of discerning ID and OOD patterns. This obstacle gives rise to data generation-based learning methods, synthesizing OOD data via data generators for predictor training without requiring any real OOD data. Related methods typically pre-train a generator on ID data and adopt various selection procedures to find those data likely to be the OOD cases. However, generated data may still coincide with ID semantics, i.e., mistaken OOD generation remains, confusing the predictor between ID and OOD data. To this end, we suggest that generated data (with mistaken OOD generation) can be used to devise an auxiliary OOD detection task to facilitate real OOD detection. Specifically, we can ensure that learning from such an auxiliary task is beneficial if the ID and the OOD parts have disjoint supports, with the help of a well-designed training procedure for the predictor. Accordingly, we propose a powerful data generation-based learning method named Auxiliary Task-based OOD Learning (ATOL) that can relieve the mistaken OOD generation. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.", "url": "https://arxiv.org/abs/2311.03236"}, {"metadata": {"arXiv": "2311.03242", "Date": "Mon, 06 Nov 2023 16:31:09 ", "Title": "Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures", "Authors": ["Martin Eigel", "Charles Miranda", "Janina Sch\\\"utte", "David Sommer"], "Categories": "cs.LG math.PR math.ST stat.ML stat.TH"}, "abstract": "We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.", "url": "https://arxiv.org/abs/2311.03242"}, {"metadata": {"arXiv": "2311.03275", "Date": "Mon, 06 Nov 2023 17:18:37 ", "Title": "Exploiting Latent Attribute Interaction with Transformer on Heterogeneous Information Networks", "Authors": ["Zeyuan Zhao", "Qingqing Ge", "Anfeng Cheng", "Yiding Liu", "Xiang Li", "Shuaiqiang Wang"], "Categories": "cs.LG cs.SI", "Comments": ["10 pages", "5 figures"]}, "abstract": "Heterogeneous graph neural networks (HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications. Due to the diversity of attributes of nodes in different types, most existing models first align nodes by mapping them into the same low-dimensional space. However, in this way, they lose the type information of nodes. In addition, most of them only consider the interactions between nodes while neglecting the high-order information behind the latent interactions among different node features. To address these problems, in this paper, we propose a novel heterogeneous graph model MULAN, including two major components, i.e., a type-aware encoder and a dimension-aware encoder. Specifically, the type-aware encoder compensates for the loss of node type information and better leverages graph heterogeneity in learning node representations. Built upon transformer architecture, the dimension-aware encoder is capable of capturing the latent interactions among the diverse node features. With these components, the information of graph heterogeneity, node features and graph structure can be comprehensively encoded in node representations. We conduct extensive experiments on six heterogeneous benchmark datasets, which demonstrates the superiority of MULAN over other state-of-the-art competitors and also shows that MULAN is efficient.", "url": "https://arxiv.org/abs/2311.03275"}, {"metadata": {"arXiv": "2311.03278", "Date": "Mon, 06 Nov 2023 17:20:41 ", "Title": "Discretizing Numerical Attributes: An Analysis of Human Perceptions", "Authors": ["Minakshi Kaushik", "Rahul Sharma", "Dirk Draheim"], "Categories": "cs.LG"}, "abstract": "Machine learning (ML) has employed various discretization methods to partition numerical attributes into intervals. However, an effective discretization technique remains elusive in many ML applications, such as association rule mining. Moreover, the existing discretization techniques do not reflect best the impact of the independent numerical factor on the dependent numerical target factor. This research aims to establish a benchmark approach for numerical attribute partitioning. We conduct an extensive analysis of human perceptions of partitioning a numerical attribute and compare these perceptions with the results obtained from our two proposed measures. We also examine the perceptions of experts in data science, statistics, and engineering by employing numerical data visualization techniques. The analysis of collected responses reveals that $68.7\\%$ of human responses approximately closely align with the values generated by our proposed measures. Based on these findings, our proposed measures may be used as one of the methods for discretizing the numerical attributes.", "url": "https://arxiv.org/abs/2311.03278"}, {"metadata": {"arXiv": "2311.03287", "Date": "Mon, 06 Nov 2023 17:26:59 ", "Title": "Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges", "Authors": ["Chenhang Cui", "Yiyang Zhou", "Xinyu Yang", "Shirley Wu", "Linjun Zhang", "James Zou", "Huaxiu Yao"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "While GPT-4V(ision) impressively models both visual and textual information simultaneously, it's hallucination behavior has not been systematically assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo). This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference. Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data. Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented. We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together. Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges. We also identified similar biases and interference vulnerabilities with LLaVA and Bard. Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.", "url": "https://arxiv.org/abs/2311.03287"}, {"metadata": {"arXiv": "2311.03303", "Date": "Mon, 06 Nov 2023 17:52:08 ", "Title": "TS-Diffusion: Generating Highly Complex Time Series with Diffusion Models", "Authors": ["Yangming Li"], "Categories": "cs.LG"}, "abstract": "While current generative models have achieved promising performances in time-series synthesis, they either make strong assumptions on the data format (e.g., regularities) or rely on pre-processing approaches (e.g., interpolations) to simplify the raw data. In this work, we consider a class of time series with three common bad properties, including sampling irregularities, missingness, and large feature-temporal dimensions, and introduce a general model, TS-Diffusion, to process such complex time series. Our model consists of three parts under the framework of point process. The first part is an encoder of the neural ordinary differential equation (ODE) that converts time series into dense representations, with the jump technique to capture sampling irregularities and self-attention mechanism to handle missing values; The second component of TS-Diffusion is a diffusion model that learns from the representation of time series. These time-series representations can have a complex distribution because of their high dimensions; The third part is a decoder of another ODE that generates time series with irregularities and missing values given their representations. We have conducted extensive experiments on multiple time-series datasets, demonstrating that TS-Diffusion achieves excellent results on both conventional and complex time series and significantly outperforms previous baselines.", "url": "https://arxiv.org/abs/2311.03303"}, {"metadata": {"arXiv": "2311.03332", "Date": "Mon, 06 Nov 2023 18:29:57 ", "Title": "Learning Hard-Constrained Models with One Sample", "Authors": ["Andreas Galanis", "Alkis Kalavasis", "Anthimos Vardis Kandiros"], "Categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "Comments": ["Abstract shortened to fit arXiv requirements"]}, "abstract": "We consider the problem of estimating the parameters of a Markov Random Field with hard-constraints using a single sample. As our main running examples, we use the $k$-SAT and the proper coloring models, as well as general $H$-coloring models; for all of these we obtain both positive and negative results. In contrast to the soft-constrained case, we show in particular that single-sample estimation is not always possible, and that the existence of an estimator is related to the existence of non-satisfiable instances. Our algorithms are based on the pseudo-likelihood estimator. We show variance bounds for this estimator using coupling techniques inspired, in the case of $k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for colorings build on this new coupling approach. For $q$-colorings on graphs with maximum degree $d$, we give a linear-time estimator when $q>d+1$, whereas the problem is non-identifiable when $q\\leq d+1$. For general $H$-colorings, we show that standard conditions that guarantee sampling, such as Dobrushin's condition, are insufficient for one-sample learning; on the positive side, we provide a general condition that is sufficient to guarantee linear-time learning and obtain applications for proper colorings and permissive models. For the $k$-SAT model on formulas with maximum degree $d$, we provide a linear-time estimator when $k\\gtrsim 6.45\\log d$, whereas the problem becomes non-identifiable when $k\\lesssim \\log d$.", "url": "https://arxiv.org/abs/2311.03332"}, {"metadata": {"arXiv": "2311.03351", "Date": "Mon, 06 Nov 2023 18:58:59 ", "Title": "Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization", "Authors": ["Kun Lei", "Zhengmao He", "Chenhao Lu", "Kaizhe Hu", "Yang Gao", "Huazhe Xu"], "Categories": "cs.LG cs.RO", "Comments": ["Our website: https://lei-kun.github.io/uni-o4/"]}, "abstract": "Combining offline and online reinforcement learning (RL) is crucial for efficient and safe learning. However, previous approaches treat offline and online learning as separate procedures, resulting in redundant designs and limited performance. We ask: Can we achieve straightforward yet effective offline and online learning without introducing extra conservatism or regularization? In this study, we propose Uni-o4, which utilizes an on-policy objective for both offline and online learning. Owning to the alignment of objectives in two phases, the RL agent can transfer between offline and online learning seamlessly. This property enhances the flexibility of the learning paradigm, allowing for arbitrary combinations of pretraining, fine-tuning, offline, and online learning. In the offline phase, specifically, Uni-o4 leverages diverse ensemble policies to address the mismatch issues between the estimated behavior policy and the offline dataset. Through a simple offline policy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy improvement safely. We demonstrate that by employing the method above, the fusion of these two paradigms can yield superior offline initialization as well as stable and rapid online fine-tuning capabilities. Through real-world robot tasks, we highlight the benefits of this paradigm for rapid deployment in challenging, previously unseen real-world environments. Additionally, through comprehensive evaluations using numerous simulated benchmarks, we substantiate that our method achieves state-of-the-art performance in both offline and offline-to-online fine-tuning learning. Our website: https://lei-kun.github.io/uni-o4/ .", "url": "https://arxiv.org/abs/2311.03351"}, {"metadata": {"arXiv": "2311.02551", "Date": "Sun, 05 Nov 2023 02:59:53 ", "Title": "High-dimensional Bid Learning for Energy Storage Bidding in Energy Markets", "Authors": ["Jinyu Liu", "Hongye Guo", "Qinghu Tang", "En Lu", "Qiuna Cai", "Qixin Chen"], "Categories": "eess.SY cs.GT cs.LG cs.SY", "Comments": ["5 pages", "3 figures", "Accepted by the 15th International Conference on Applied Energy (ICAE2023)"]}, "abstract": "With the growing penetration of renewable energy resource, electricity market prices have exhibited greater volatility. Therefore, it is important for Energy Storage Systems(ESSs) to leverage the multidimensional nature of energy market bids to maximize profitability. However, current learning methods cannot fully utilize the high-dimensional price-quantity bids in the energy markets. To address this challenge, we modify the common reinforcement learning(RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs). NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. To achieve effective learning of NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. Then, we re-train the network with two training modifications to make the network output monotonic and discrete. Finally, the neural network is equivalently converted into a high-dimensional bid for bidding. We conducted experiments over real-world market datasets. Our studies show that the proposed method achieves 18% higher profit than the baseline and up to 78% profit of the optimal market bidder.", "url": "https://arxiv.org/abs/2311.02551"}, {"metadata": {"arXiv": "2311.02679", "Date": "Sun, 05 Nov 2023 15:32:37 ", "Title": "Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration", "Authors": ["Archith Athrey", "Othmane Mazhar", "Meichen Guo", "Bart De Schutter and Shengling Shi"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "In this paper, we analyze the regret incurred by a computationally efficient exploration strategy, known as naive exploration, for controlling unknown partially observable systems within the Linear Quadratic Gaussian (LQG) framework. We introduce a two-phase control algorithm called LQG-NAIVE, which involves an initial phase of injecting Gaussian input signals to obtain a system model, followed by a second phase of an interplay between naive exploration and control in an episodic fashion. We show that LQG-NAIVE achieves a regret growth rate of $\\tilde{\\mathcal{O}}(\\sqrt{T})$, i.e., $\\mathcal{O}(\\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we validate its performance through numerical simulations. Additionally, we propose LQG-IF2E, which extends the exploration signal to a `closed-loop' setting by incorporating the Fisher Information Matrix (FIM). We provide compelling numerical evidence of the competitive performance of LQG-IF2E compared to LQG-NAIVE.", "url": "https://arxiv.org/abs/2311.02679"}, {"metadata": {"arXiv": "2311.03197", "Date": "Mon, 06 Nov 2023 15:39:05 ", "Title": "Stable Linear Subspace Identification: A Machine Learning Approach", "Authors": ["Loris Di Natale", "Muhammad Zakwan", "Bratislav Svetozarevic", "Philipp Heer", "Giancarlo Ferrari Trecate", "Colin N. Jones"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["Submitted to ECC 2024"]}, "abstract": "Machine Learning (ML) and linear System Identification (SI) have been historically developed independently. In this paper, we leverage well-established ML tools - especially the automatic differentiation framework - to introduce SIMBa, a family of discrete linear multi-step-ahead state-space SI methods using backpropagation. SIMBa relies on a novel Linear-Matrix-Inequality-based free parametrization of Schur matrices to ensure the stability of the identified model. We show how SIMBa generally outperforms traditional linear state-space SI methods, and sometimes significantly, although at the price of a higher computational burden. This performance gap is particularly remarkable compared to other SI methods with stability guarantees, where the gain is frequently above 25% in our investigations, hinting at SIMBa's ability to simultaneously achieve state-of-the-art fitting performance and enforce stability. Interestingly, these observations hold for a wide variety of input-output systems and on both simulated and real-world data, showcasing the flexibility of the proposed approach. We postulate that this new SI paradigm presents a great extension potential to identify structured nonlinear models from data, and we hence open-source SIMBa on https://github.com/Cemempamoi/simba.", "url": "https://arxiv.org/abs/2311.03197"}, {"metadata": {"arXiv": "2311.02082", "Date": "Fri, 20 Oct 2023 19:36:03 ", "Title": "Semantic Modelling of Organizational Knowledge as a Basis for Enterprise Data Governance 4.0 -- Application to a Unified Clinical Data Model", "Authors": ["Miguel AP Oliveira", "Stephane Manara", "Bruno Mol\\'e", "Thomas Muller", "Aur\\'elien Guillouche", "Lysann Hesske", "Bruce Jordan", "Gilles Hubert", "Chinmay Kulkarni", "Pralipta Jagdev and Cedric R. Berger"], "Categories": "cs.AI cs.IR"}, "abstract": "Individuals and organizations cope with an always-growing data amount, heterogeneous in contents and formats. Prerequisites to get value out this data and minimise inherent risks related to multiple usages are adequate data management processes yielding data quality and control over its lifecycle. Common data governance frameworks relying on people and policies falls short of the overwhelming data complexity. Yet, harnessing this complexity is necessary to achieve high quality standards. The later will condition the outcome of any downstream data usage, including generative artificial intelligence trained on this data. In this paper, we report our concrete experience establishing a simple, cost-efficient framework, that enables metadata-driven, agile and (semi-)automated data governance (i.e. Data Governance 4.0). We explain how we implement and use this framework to integrate 25 years of clinical study data at enterprise scale, in a fully productive environment. The framework encompasses both methodologies and technologies leveraging semantic web principles. We built an knowledge graph describing data assets avatars in their business context including governance principles. Multiple ontologies articulated by an enterprise upper ontology enable key governance actions such as FAIRification, lifecycle management, definition of roles and responsibilities, lineage across transformations and provenance from source systems. This metadata model is a prerequisite to automatize data governance, make it fit-for-purpose to each use case and dynamically adapting it to business changes.", "url": "https://arxiv.org/abs/2311.02082"}, {"metadata": {"arXiv": "2311.02099", "Date": "Mon, 30 Oct 2023 21:52:37 ", "Title": "A Preference Learning Approach to Develop Safe and Personalizable Autonomous Vehicles", "Authors": ["Ruya Karagulle and Nikos Arechiga and Andrew Best and Jonathan DeCastro and Necmiye Ozay"], "Categories": "cs.AI cs.SY eess.SY", "Comments": ["8 pages", "2 figures", "2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "This work introduces a preference learning method that ensures adherence to traffic rules for autonomous vehicles. Our approach incorporates priority ordering of signal temporal logic (STL) formulas, describing traffic rules, into a learning framework. By leveraging the parametric weighted signal temporal logic (PWSTL), we formulate the problem of safety-guaranteed preference learning based on pairwise comparisons, and propose an approach to solve this learning problem. Our approach finds a feasible valuation for the weights of the given PWSTL formula such that, with these weights, preferred signals have weighted quantitative satisfaction measures greater than their non-preferred counterparts. The feasible valuation of weights given by our approach leads to a weighted STL formula which can be used in correct-and-custom-by-construction controller synthesis. We demonstrate the performance of our method with human subject studies in two different simulated driving scenarios involving a stop sign and a pedestrian crossing. Our approach yields competitive results compared to existing preference learning methods in terms of capturing preferences, and notably outperforms them when safety is considered.", "url": "https://arxiv.org/abs/2311.02099"}, {"metadata": {"arXiv": "2311.02291", "Date": "Sat, 04 Nov 2023 01:18:48 ", "Title": "A Survey of the Various Methodologies Towards making Artificial Intelligence More Explainable", "Authors": ["Sopam Dasgupta"], "Categories": "cs.AI", "Comments": ["25 pages"]}, "abstract": "Machines are being increasingly used in decision-making processes, resulting in the realization that decisions need explanations. Unfortunately, an increasing number of these deployed models are of a 'black-box' nature where the reasoning behind the decisions is unknown. Hence, there is a need for clarity behind the reasoning of these decisions. As humans, we would want these decisions to be presented to us in an explainable manner. However, explanations alone are insufficient. They do not necessarily tell us how to achieve an outcome but merely tell us what achieves the given outcome. For this reason, my research focuses on explainability/interpretability and how it extends to counterfactual thinking.", "url": "https://arxiv.org/abs/2311.02291"}, {"metadata": {"arXiv": "2311.02462", "Date": "Sat, 04 Nov 2023 17:44:58 ", "Title": "Levels of AGI: Operationalizing Progress on the Path to AGI", "Authors": ["Meredith Ringel Morris", "Jascha Sohl-dickstein", "Noah Fiedel", "Tris Warkentin", "Allan Dafoe", "Aleksandra Faust", "Clement Farabet", "Shane Legg"], "Categories": "cs.AI"}, "abstract": "We propose a framework for classifying the capabilities and behavior of Artificial General Intelligence (AGI) models and their precursors. This framework introduces levels of AGI performance, generality, and autonomy. It is our hope that this framework will be useful in an analogous way to the levels of autonomous driving, by providing a common language to compare models, assess risks, and measure progress along the path to AGI. To develop our framework, we analyze existing definitions of AGI, and distill six principles that a useful ontology for AGI should satisfy. These principles include focusing on capabilities rather than mechanisms; separately evaluating generality and performance; and defining stages along the path toward AGI, rather than focusing on the endpoint. With these principles in mind, we propose 'Levels of AGI' based on depth (performance) and breadth (generality) of capabilities, and reflect on how current systems fit into this ontology. We discuss the challenging requirements for future benchmarks that quantify the behavior and capabilities of AGI models against these levels. Finally, we discuss how these levels of AGI interact with deployment considerations such as autonomy and risk, and emphasize the importance of carefully selecting Human-AI Interaction paradigms for responsible and safe deployment of highly capable AI systems.", "url": "https://arxiv.org/abs/2311.02462"}, {"metadata": {"arXiv": "2311.02597", "Date": "Sun, 05 Nov 2023 08:34:26 ", "Title": "FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM", "Authors": ["Grace Colverd", "Paul Darm", "Leonard Silverberg", "and Noah Kasmanoff"], "Categories": "cs.AI cs.CL", "Comments": ["Version is the one submitted to Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop @Neurips2023. All authors contributed equally to this work"], "ACM-class": "I.2.7"}, "abstract": "Fast disaster impact reporting is crucial in planning humanitarian assistance. Large Language Models (LLMs) are well known for their ability to write coherent text and fulfill a variety of tasks relevant to impact reporting, such as question answering or text summarization. However, LLMs are constrained by the knowledge within their training data and are prone to generating inaccurate, or \"hallucinated\", information. To address this, we introduce a sophisticated pipeline embodied in our tool FloodBrain (floodbrain.com), specialized in generating flood disaster impact reports by extracting and curating information from the web. Our pipeline assimilates information from web search results to produce detailed and accurate reports on flood events. We test different LLMs as backbones in our tool and compare their generated reports to human-written reports on different metrics. Similar to other studies, we find a notable correlation between the scores assigned by GPT-4 and the scores given by human evaluators when comparing our generated reports to human-authored ones. Additionally, we conduct an ablation study to test our single pipeline components and their relevancy for the final reports. With our tool, we aim to advance the use of LLMs for disaster impact reporting and reduce the time for coordination of humanitarian efforts in the wake of flood disasters.", "url": "https://arxiv.org/abs/2311.02597"}, {"metadata": {"arXiv": "2311.02912", "Date": "Mon, 06 Nov 2023 06:58:16 ", "Title": "Imitation Learning based Alternative Multi-Agent Proximal Policy Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance", "Authors": ["Sizhao Li", "Yuming Xiang", "Rongpeng Li", "Zhifeng Zhao", "Honggang Zhang"], "Categories": "cs.AI cs.RO", "Comments": ["6 pages", "5 figures", "2023 IEEE the 9th International Conference on Computer and Communications (ICCC)"], "Report-no": "C233"}, "abstract": "Multi-Robot System (MRS) has garnered widespread research interest and fostered tremendous interesting applications, especially in cooperative control fields. Yet little light has been shed on the compound ability of formation, monitoring and defence in decentralized large-scale MRS for pursuit avoidance, which puts stringent requirements on the capability of coordination and adaptability. In this paper, we put forward a decentralized Imitation learning based Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm to provide a flexible and communication-economic solution to execute the pursuit avoidance task in well-formed swarm. In particular, a policy-distillation based MAPPO executor is firstly devised to capably accomplish and swiftly switch between multiple formations in a centralized manner. Furthermore, we utilize imitation learning to decentralize the formation controller, so as to reduce the communication overheads and enhance the scalability. Afterwards, alternative training is leveraged to compensate the performance loss incurred by decentralization. The simulation results validate the effectiveness of IA-MAPPO and extensive ablation experiments further show the performance comparable to a centralized solution with significant decrease in communication overheads.", "url": "https://arxiv.org/abs/2311.02912"}, {"metadata": {"arXiv": "2311.02962", "Date": "Mon, 06 Nov 2023 09:03:21 ", "Title": "Retrieval-Augmented Code Generation for Universal Information Extraction", "Authors": ["Yucan Guo", "Zixuan Li", "Xiaolong Jin", "Yantao Liu", "Yutao Zeng", "Wenxuan Liu", "Xiang Li", "Pan Yang", "Long Bai", "Jiafeng Guo and Xueqi Cheng"], "Categories": "cs.AI cs.CL cs.IR"}, "abstract": "Information Extraction (IE) aims to extract structural knowledge (e.g., entities, relations, events) from natural language texts, which brings challenges to existing methods due to task-specific schemas and complex text expressions. Code, as a typical kind of formalized language, is capable of describing structural knowledge under various schemas in a universal way. On the other hand, Large Language Models (LLMs) trained on both codes and texts have demonstrated powerful capabilities of transforming texts into codes, which provides a feasible solution to IE tasks. Therefore, in this paper, we propose a universal retrieval-augmented code generation framework based on LLMs, called Code4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define task-specific schemas of various structural knowledge in a universal way. By so doing, extracting knowledge under these schemas can be transformed into generating codes that instantiate the predefined Python classes with the information in texts. To generate these codes more precisely, Code4UIE adopts the in-context learning mechanism to instruct LLMs with examples. In order to obtain appropriate examples for different tasks, Code4UIE explores several example retrieval strategies, which can retrieve examples semantically similar to the given texts. Extensive experiments on five representative IE tasks across nine datasets demonstrate the effectiveness of the Code4UIE framework.", "url": "https://arxiv.org/abs/2311.02962"}, {"metadata": {"arXiv": "2311.03059", "Date": "Mon, 06 Nov 2023 12:41:21 ", "Title": "Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations", "Authors": ["Isma\\\"il Baaj"], "Categories": "cs.AI cs.LO"}, "abstract": "In this article, we study the inconsistency of a system of $\\max-T$ fuzzy relational equations of the form $A \\Box_{T}^{\\max} x = b$, where $T$ is a t-norm among $\\min$, the product or Lukasiewicz's t-norm. For an inconsistent $\\max-T$ system, we directly construct a canonical maximal consistent subsystem (w.r.t the inclusion order). The main tool used to obtain it is the analytical formula which compute the Chebyshev distance $\\Delta = \\inf_{c \\in \\mathcal{C}} \\Vert b - c \\Vert$ associated to the inconsistent $\\max-T$ system, where $\\mathcal{C}$ is the set of second members of consistent systems defined with the same matrix $A$. Based on the same analytical formula, we give, for an inconsistent $\\max-\\min$ system, an efficient method to obtain all its consistent subsystems, and we show how to iteratively get all its maximal consistent subsystems.", "url": "https://arxiv.org/abs/2311.03059"}, {"metadata": {"arXiv": "2311.02183", "Date": "Fri, 03 Nov 2023 18:27:43 ", "Title": "Cross-modal Prominent Fragments Enhancement Aligning Network for Image-text Retrieval", "Authors": ["Yang Zhang"], "Categories": "cs.CV cs.AI cs.MM"}, "abstract": "Image-text retrieval is a widely studied topic in the field of computer vision due to the exponential growth of multimedia data, whose core concept is to measure the similarity between images and text. However, most existing retrieval methods heavily rely on cross-attention mechanisms for cross-modal fine-grained alignment, which takes into account excessive irrelevant regions and treats prominent and non-significant words equally, thereby limiting retrieval accuracy. This paper aims to investigate an alignment approach that reduces the involvement of non-significant fragments in images and text while enhancing the alignment of prominent segments. For this purpose, we introduce the Cross-Modal Prominent Fragments Enhancement Aligning Network(CPFEAN), which achieves improved retrieval accuracy by diminishing the participation of irrelevant regions during alignment and relatively increasing the alignment similarity of prominent words. Additionally, we incorporate prior textual information into image regions to reduce misalignment occurrences. In practice, we first design a novel intra-modal fragments relationship reasoning method, and subsequently employ our proposed alignment mechanism to compute the similarity between images and text. Extensive quantitative comparative experiments on MS-COCO and Flickr30K datasets demonstrate that our approach outperforms state-of-the-art methods by about 5% to 10% in the rSum metric.", "url": "https://arxiv.org/abs/2311.02183"}, {"metadata": {"arXiv": "2311.02202", "Date": "Fri, 03 Nov 2023 19:10:37 ", "Title": "Neural Collage Transfer: Artistic Reconstruction via Material Manipulation", "Authors": ["Ganghun Lee", "Minji Kim", "Yunsu Lee", "Minsu Lee", "Byoung-Tak Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023"]}, "abstract": "Collage is a creative art form that uses diverse material scraps as a base unit to compose a single image. Although pixel-wise generation techniques can reproduce a target image in collage style, it is not a suitable method due to the solid stroke-by-stroke nature of the collage form. While some previous works for stroke-based rendering produced decent sketches and paintings, collages have received much less attention in research despite their popularity as a style. In this paper, we propose a method for learning to make collages via reinforcement learning without the need for demonstrations or collage artwork data. We design the collage Markov Decision Process (MDP), which allows the agent to handle various materials and propose a model-based soft actor-critic to mitigate the agent's training burden derived from the sophisticated dynamics of collage. Moreover, we devise additional techniques such as active material selection and complexity-based multi-scale collage to handle target images at any size and enhance the results' aesthetics by placing relatively more scraps in areas of high complexity. Experimental results show that the trained agent appropriately selected and pasted materials to regenerate the target image into a collage and obtained a higher evaluation score on content and style than pixel-wise generation methods. Code is available at https://github.com/northadventure/CollageRL.", "url": "https://arxiv.org/abs/2311.02202"}, {"metadata": {"arXiv": "2311.02305", "Date": "Sat, 04 Nov 2023 02:43:32 ", "Title": "OSM vs HD Maps: Map Representations for Trajectory Prediction", "Authors": ["Jing-Yan Liao", "Parth Doshi", "Zihan Zhang", "David Paz", "Henrik Christensen"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "While High Definition (HD) Maps have long been favored for their precise depictions of static road elements, their accessibility constraints and susceptibility to rapid environmental changes impede the widespread deployment of autonomous driving, especially in the motion forecasting task. In this context, we propose to leverage OpenStreetMap (OSM) as a promising alternative to HD Maps for long-term motion forecasting. The contributions of this work are threefold: firstly, we extend the application of OSM to long-horizon forecasting, doubling the forecasting horizon compared to previous studies. Secondly, through an expanded receptive field and the integration of intersection priors, our OSM-based approach exhibits competitive performance, narrowing the gap with HD Map-based models. Lastly, we conduct an exhaustive context-aware analysis, providing deeper insights in motion forecasting across diverse scenarios as well as conducting class-aware comparisons. This research not only advances long-term motion forecasting with coarse map representations but additionally offers a potential scalable solution within the domain of autonomous driving.", "url": "https://arxiv.org/abs/2311.02305"}, {"metadata": {"arXiv": "2311.02329", "Date": "Sat, 04 Nov 2023 05:34:24 ", "Title": "Complex Organ Mask Guided Radiology Report Generation", "Authors": ["Gu Tiancheng", "Liu Dongnan", "Li Zhiyuan", "Cai Weidong"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "7 images. Accepted by WACV 2024"]}, "abstract": "The goal of automatic report generation is to generate a clinically accurate and coherent phrase from a single given X-ray image, which could alleviate the workload of traditional radiology reporting.However, in a real-world scenario, radiologists frequently face the challenge of producing extensive reports derived from numerous medical images, thereby medical report generation from multi-image perspective is needed.In this paper, we propose the Complex Organ Mask Guided (termed as COMG) report generation model, which incorporates masks from multiple organs (e.g., bones, lungs, heart, and mediastinum), to provide more detailed information and guide the model's attention to these crucial body regions. Specifically, we leverage prior knowledge of the disease corresponding to each organ in the fusion process to enhance the disease identification phase during the report generation process. Additionally, cosine similarity loss is introduced as target function to ensure the convergence of cross-modal consistency and facilitate model optimization.Experimental results on two public datasets show that COMG achieves a 11.4% and 9.7% improvement in terms of BLEU@4 scores over the SOTA model KiUT on IU-Xray and MIMIC, respectively.", "url": "https://arxiv.org/abs/2311.02329"}, {"metadata": {"arXiv": "2311.02343", "Date": "Sat, 04 Nov 2023 07:53:59 ", "Title": "Stable Diffusion Reference Only: Image Prompt and Blueprint Jointly Guided Multi-Condition Diffusion Model for Secondary Painting", "Authors": ["Hao Ai", "Lu Sheng"], "Categories": "cs.CV cs.AI"}, "abstract": "Stable Diffusion and ControlNet have achieved excellent results in the field of image generation and synthesis. However, due to the granularity and method of its control, the efficiency improvement is limited for professional artistic creations such as comics and animation production whose main work is secondary painting. In the current workflow, fixing characters and image styles often need lengthy text prompts, and even requires further training through TextualInversion, DreamBooth or other methods, which is very complicated and expensive for painters. Therefore, we present a new method in this paper, Stable Diffusion Reference Only, a images-to-image self-supervised model that uses only two types of conditional images for precise control generation to accelerate secondary painting. The first type of conditional image serves as an image prompt, supplying the necessary conceptual and color information for generation. The second type is blueprint image, which controls the visual structure of the generated image. It is natively embedded into the original UNet, eliminating the need for ControlNet. We released all the code for the module and pipeline, and trained a controllable character line art coloring model at https://github.com/aihao2000/stable-diffusion-reference-only, that achieved state-of-the-art results in this field. This verifies the effectiveness of the structure and greatly improves the production efficiency of animations, comics, and fanworks.", "url": "https://arxiv.org/abs/2311.02343"}, {"metadata": {"arXiv": "2311.02392", "Date": "Sat, 04 Nov 2023 12:28:04 ", "Title": "Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification", "Authors": ["Hao Zheng", "Runqi Wang", "Jianzhuang Liu", "Asako Kanezaki"], "Categories": "cs.CV cs.AI"}, "abstract": "The conventional few-shot classification aims at learning a model on a large labeled base dataset and rapidly adapting to a target dataset that is from the same distribution as the base dataset. However, in practice, the base and the target datasets of few-shot classification are usually from different domains, which is the problem of cross-domain few-shot classification. We tackle this problem by making a small proportion of unlabeled images in the target domain accessible in the training stage. In this setup, even though the base data are sufficient and labeled, the large domain shift still makes transferring the knowledge from the base dataset difficult. We meticulously design a cross-level knowledge distillation method, which can strengthen the ability of the model to extract more discriminative features in the target dataset by guiding the network's shallow layers to learn higher-level information. Furthermore, in order to alleviate the overfitting in the evaluation stage, we propose a feature denoising operation which can reduce the feature redundancy and mitigate overfitting. Our approach can surpass the previous state-of-the-art method, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot classification tasks on average in the BSCD-FSL benchmark. The implementation code will be available at https://github.com/jarucezh/cldfd.", "url": "https://arxiv.org/abs/2311.02392"}, {"metadata": {"arXiv": "2311.02393", "Date": "Sat, 04 Nov 2023 12:36:07 ", "Title": "Continual Learning of Unsupervised Monocular Depth from Videos", "Authors": ["Hemang Chawla", "Arnav Varma", "Elahe Arani", "and Bahram Zonooz"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)"]}, "abstract": "Spatial scene understanding, including monocular depth estimation, is an important problem in various applications, such as robotics and autonomous driving. While improvements in unsupervised monocular depth estimation have potentially allowed models to be trained on diverse crowdsourced videos, this remains underexplored as most methods utilize the standard training protocol, wherein the models are trained from scratch on all data after new data is collected. Instead, continual training of models on sequentially collected data would significantly reduce computational and memory costs. Nevertheless, naive continual training leads to catastrophic forgetting, where the model performance deteriorates on older domains as it learns on newer domains, highlighting the trade-off between model stability and plasticity. While several techniques have been proposed to address this issue in image classification, the high-dimensional and spatiotemporally correlated outputs of depth estimation make it a distinct challenge. To the best of our knowledge, no framework or method currently exists focusing on the problem of continual learning in depth estimation. Thus, we introduce a framework that captures the challenges of continual unsupervised depth estimation (CUDE), and define the necessary metrics to evaluate model performance. We propose a rehearsal-based dual-memory method, MonoDepthCL, which utilizes spatiotemporal consistency for continual learning in depth estimation, even when the camera intrinsics are unknown.", "url": "https://arxiv.org/abs/2311.02393"}, {"metadata": {"arXiv": "2311.02523", "Date": "Sat, 04 Nov 2023 23:00:40 ", "Title": "UniTSFace: Unified Threshold Integrated Sample-to-Sample Loss for Face Recognition", "Authors": ["Qiufu Li", "Xi Jia", "Jiancan Zhou", "Linlin Shen and Jinming Duan"], "Categories": "cs.CV cs.AI cs.HC", "Comments": ["Accepted by Neurips 2023"]}, "abstract": "Sample-to-class-based face recognition models can not fully explore the cross-sample relationship among large amounts of facial images, while sample-to-sample-based models require sophisticated pairing processes for training. Furthermore, neither method satisfies the requirements of real-world face verification applications, which expect a unified threshold separating positive from negative facial pairs. In this paper, we propose a unified threshold integrated sample-to-sample based loss (USS loss), which features an explicit unified threshold for distinguishing positive from negative pairs. Inspired by our USS loss, we also derive the sample-to-sample based softmax and BCE losses, and discuss their relationship. Extensive evaluation on multiple benchmark datasets, including MFR, IJB-C, LFW, CFP-FP, AgeDB, and MegaFace, demonstrates that the proposed USS loss is highly efficient and can work seamlessly with sample-to-class-based losses. The embedded loss (USS and sample-to-class Softmax loss) overcomes the pitfalls of previous approaches and the trained facial model UniTSFace exhibits exceptional performance, outperforming state-of-the-art methods, such as CosFace, ArcFace, VPL, AnchorFace, and UNPG. Our code is available.", "url": "https://arxiv.org/abs/2311.02523"}, {"metadata": {"arXiv": "2311.02538", "Date": "Sun, 05 Nov 2023 01:45:31 ", "Title": "Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols", "Authors": ["Iqra Qasim", "Alexander Horsch", "Dilip K. Prasad"], "Categories": "cs.CV cs.AI", "Comments": ["35 pages", "10 figures"]}, "abstract": "Untrimmed videos have interrelated events, dependencies, context, overlapping events, object-object interactions, domain specificity, and other semantics that are worth highlighting while describing a video in natural language. Owing to such a vast diversity, a single sentence can only correctly describe a portion of the video. Dense Video Captioning (DVC) aims at detecting and describing different events in a given video. The term DVC originated in the 2017 ActivityNet challenge, after which considerable effort has been made to address the challenge. Dense Video Captioning is divided into three sub-tasks: (1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and (3) Dense Caption Generation (DCG). This review aims to discuss all the studies that claim to perform DVC along with its sub-tasks and summarize their results. We also discuss all the datasets that have been used for DVC. Lastly, we highlight some emerging challenges and future trends in the field.", "url": "https://arxiv.org/abs/2311.02538"}, {"metadata": {"arXiv": "2311.02647", "Date": "Sun, 05 Nov 2023 13:21:07 ", "Title": "New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction", "Authors": ["Joshua B\\`egue", "Mohamed Aymen Labiod and Abdelhamid Melloulk"], "Categories": "cs.CV cs.AI cs.HC cs.MM", "Journal-ref": "IEEE Communications Magazine, vol. 61, no. 10, pp. 54-60, October 2023", "DOI": "10.1109/MCOM.002.2200870."}, "abstract": "In human interactions, emotion recognition is crucial. For this reason, the topic of computer-vision approaches for automatic emotion recognition is currently being extensively researched. Processing multi-channel electroencephalogram (EEG) information is one of the most researched methods for automatic emotion recognition. This paper presents a new model for an affective computing-driven Quality of Experience (QoE) prediction. In order to validate the proposed model, a publicly available dataset is used. The dataset contains EEG, ECG, and respiratory data and is focused on a multimedia QoE assessment context. The EEG data are retained on which the differential entropy and the power spectral density are calculated with an observation window of three seconds. These two features were extracted to train several deep-learning models to investigate the possibility of predicting QoE with five different factors. The performance of these models is compared, and the best model is optimized to improve the results. The best results were obtained with an LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the model and its features shows that the Delta frequency band is the least necessary, that two electrodes have a higher importance, and that two other electrodes have a very low impact on the model's performances.", "url": "https://arxiv.org/abs/2311.02647"}, {"metadata": {"arXiv": "2311.02782", "Date": "Sun, 05 Nov 2023 22:13:12 ", "Title": "Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead", "Authors": ["Yunkang Cao", "Xiaohao Xu", "Chen Sun", "Xiaonan Huang", "and Weiming Shen"], "Categories": "cs.CV cs.AI", "Comments": ["Work in progress. Evaluated GPT-4V on 4 modalities", "9 tasks", "and 15 datasets. The first three authors contribute equally"]}, "abstract": "Anomaly detection is a crucial task across different domains and data types. However, existing anomaly detection models are often designed for specific domains and modalities. This study explores the use of GPT-4V(ision), a powerful visual-linguistic model, to address anomaly detection tasks in a generic manner. We investigate the application of GPT-4V in multi-modality, multi-domain anomaly detection tasks, including image, video, point cloud, and time series data, across multiple application areas, such as industrial, medical, logical, video, 3D anomaly detection, and localization tasks. To enhance GPT-4V's performance, we incorporate different kinds of additional cues such as class information, human expertise, and reference images as prompts.Based on our experiments, GPT-4V proves to be highly effective in detecting and explaining global and fine-grained semantic patterns in zero/one-shot anomaly detection. This enables accurate differentiation between normal and abnormal instances. Although we conducted extensive evaluations in this study, there is still room for future evaluation to further exploit GPT-4V's generic anomaly detection capacity from different aspects. These include exploring quantitative metrics, expanding evaluation benchmarks, incorporating multi-round interactions, and incorporating human feedback loops. Nevertheless, GPT-4V exhibits promising performance in generic anomaly detection and understanding, thus opening up a new avenue for anomaly detection.", "url": "https://arxiv.org/abs/2311.02782"}, {"metadata": {"arXiv": "2311.02820", "Date": "Mon, 06 Nov 2023 01:54:37 ", "Title": "Mesh Neural Cellular Automata", "Authors": ["Ehsan Pajouheshgar", "Yitao Xu", "Alexander Mordvintsev", "Eyvind Niklasson", "Tong Zhang", "Sabine S\\\"usstrunk"], "Categories": "cs.CV cs.AI cs.GR"}, "abstract": "Modeling and synthesizing textures are essential for enhancing the realism of virtual environments. Methods that directly synthesize textures in 3D offer distinct advantages to the UV-mapping-based methods as they can create seamless textures and align more closely with the ways textures form in nature. We propose Mesh Neural Cellular Automata (MeshNCA), a method for directly synthesizing dynamic textures on 3D meshes without requiring any UV maps. MeshNCA is a generalized type of cellular automata that can operate on a set of cells arranged on a non-grid structure such as vertices of a 3D mesh. While only being trained on an Icosphere mesh, MeshNCA shows remarkable generalization and can synthesize textures on any mesh in real time after the training. Additionally, it accommodates multi-modal supervision and can be trained using different targets such as images, text prompts, and motion vector fields. Moreover, we conceptualize a way of grafting trained MeshNCA instances, enabling texture interpolation. Our MeshNCA model enables real-time 3D texture synthesis on meshes and allows several user interactions including texture density/orientation control, a grafting brush, and motion speed/direction control. Finally, we implement the forward pass of our MeshNCA model using the WebGL shading language and showcase our trained models in an online interactive demo which is accessible on personal computers and smartphones. Our demo and the high resolution version of this PDF are available at https://meshnca.github.io/.", "url": "https://arxiv.org/abs/2311.02820"}, {"metadata": {"arXiv": "2311.02863", "Date": "Mon, 06 Nov 2023 04:29:12 ", "Title": "Temporal Shift - Multi-Objective Loss Function for Improved Anomaly Fall Detection", "Authors": ["Stefan Denkovski", "Shehroz S. Khan", "Alex Mihailidis"], "Categories": "cs.CV cs.AI"}, "abstract": "Falls are a major cause of injuries and deaths among older adults worldwide. Accurate fall detection can help reduce potential injuries and additional health complications. Different types of video modalities can be used in a home setting to detect falls, including RGB, Infrared, and Thermal cameras. Anomaly detection frameworks using autoencoders and their variants can be used for fall detection due to the data imbalance that arises from the rarity and diversity of falls. However, the use of reconstruction error in autoencoders can limit the application of networks' structures that propagate information. In this paper, we propose a new multi-objective loss function called Temporal Shift, which aims to predict both future and reconstructed frames within a window of sequential frames. The proposed loss function is evaluated on a semi-naturalistic fall detection dataset containing multiple camera modalities. The autoencoders were trained on normal activities of daily living (ADL) performed by older adults and tested on ADLs and falls performed by young adults. Temporal shift shows significant improvement to a baseline 3D Convolutional autoencoder, an attention U-Net CAE, and a multi-modal neural network. The greatest improvement was observed in an attention U-Net model improving by 0.20 AUC ROC for a single camera when compared to reconstruction alone. With significant improvement across different models, this approach has the potential to be widely adopted and improve anomaly detection capabilities in other settings besides fall detection.", "url": "https://arxiv.org/abs/2311.02863"}, {"metadata": {"arXiv": "2311.02926", "Date": "Mon, 06 Nov 2023 07:43:42 ", "Title": "Deep Image Semantic Communication Model for Artificial Intelligent Internet of Things", "Authors": ["Li Ping Qian and Yi Zhang and Sikai Lyu and Huijie Zhu and Yuan Wu and Xuemin Sherman Shen and Xiaoniu Yang"], "Categories": "cs.CV cs.AI"}, "abstract": "With the rapid development of Artificial Intelligent Internet of Things (AIoT), the image data from AIoT devices has been witnessing the explosive increasing. In this paper, a novel deep image semantic communication model is proposed for the efficient image communication in AIoT. Particularly, at the transmitter side, a high-precision image semantic segmentation algorithm is proposed to extract the semantic information of the image to achieve significant compression of the image data. At the receiver side, a semantic image restoration algorithm based on Generative Adversarial Network (GAN) is proposed to convert the semantic image to a real scene image with detailed information. Simulation results demonstrate that the proposed image semantic communication model can improve the image compression ratio and recovery accuracy by 71.93% and 25.07% on average in comparison with WebP and CycleGAN, respectively. More importantly, our demo experiment shows that the proposed model reduces the total delay by 95.26% in the image communication, when comparing with the original image transmission.", "url": "https://arxiv.org/abs/2311.02926"}, {"metadata": {"arXiv": "2311.03035", "Date": "Mon, 06 Nov 2023 11:14:19 ", "Title": "GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation", "Authors": ["Xuwei Xu", "Sen Wang", "Yudong Chen", "Yanping Zheng", "Zhewei Wei", "Jiajun Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to WACV2024"]}, "abstract": "Vision Transformers (ViTs) have revolutionized the field of computer vision, yet their deployments on resource-constrained devices remain challenging due to high computational demands. To expedite pre-trained ViTs, token pruning and token merging approaches have been developed, which aim at reducing the number of tokens involved in the computation. However, these methods still have some limitations, such as image information loss from pruned tokens and inefficiency in the token-matching process. In this paper, we introduce a novel Graph-based Token Propagation (GTP) method to resolve the challenge of balancing model efficiency and information preservation for efficient ViTs. Inspired by graph summarization algorithms, GTP meticulously propagates less significant tokens' information to spatially and semantically connected tokens that are of greater importance. Consequently, the remaining few tokens serve as a summarization of the entire token graph, allowing the method to reduce computational complexity while preserving essential information of eliminated tokens. Combined with an innovative token selection strategy, GTP can efficiently identify image tokens to be propagated. Extensive experiments have validated GTP's effectiveness, demonstrating both efficiency and performance improvements. Specifically, GTP decreases the computational complexity of both DeiT-S and DeiT-B by up to 26% with only a minimal 0.3% accuracy drop on ImageNet-1K without finetuning, and remarkably surpasses the state-of-the-art token merging method on various backbones at an even faster inference speed. The source code is available at https://github.com/Ackesnal/GTP-ViT.", "url": "https://arxiv.org/abs/2311.03035"}, {"metadata": {"arXiv": "2311.03053", "Date": "Mon, 06 Nov 2023 12:08:35 ", "Title": "Masking Hyperspectral Imaging Data with Pretrained Models", "Authors": ["Elias Arbash", "Andr\\'ea de Lima Ribeiro", "Sam Thiele", "Nina Gnann", "Behnood Rasti", "Margret Fuchs", "Pedram Ghamisi", "Richard Gloaguen"], "Categories": "cs.CV cs.AI"}, "abstract": "The presence of undesired background areas associated with potential noise and unknown spectral characteristics degrades the performance of hyperspectral data processing. Masking out unwanted regions is key to addressing this issue. Processing only regions of interest yields notable improvements in terms of computational costs, required memory, and overall performance. The proposed processing pipeline encompasses two fundamental parts: regions of interest mask generation, followed by the application of hyperspectral data processing techniques solely on the newly masked hyperspectral cube. The novelty of our work lies in the methodology adopted for the preliminary image segmentation. We employ the Segment Anything Model (SAM) to extract all objects within the dataset, and subsequently refine the segments with a zero-shot Grounding Dino object detector, followed by intersection and exclusion filtering steps, without the need for fine-tuning or retraining. To illustrate the efficacy of the masking procedure, the proposed method is deployed on three challenging applications scenarios that demand accurate masking; shredded plastics characterization, drill core scanning, and litter monitoring. The numerical evaluation of the proposed masking method on the three applications is provided along with the used hyperparameters. The scripts for the method will be available at https://github.com/hifexplo/Masking.", "url": "https://arxiv.org/abs/2311.03053"}, {"metadata": {"arXiv": "2311.03076", "Date": "Mon, 06 Nov 2023 13:01:17 ", "Title": "SugarViT - Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet", "Authors": ["Maurice G\\\"under", "Facundo Ram\\'on Ispizua Yamati", "Abel Andree Barreta Alc\\'antara", "Anne-Katrin Mahlein", "Rafet Sifa", "Christian Bauckhage"], "Categories": "cs.CV cs.AI", "Comments": ["submitted to Computers and Electronics in Agriculture"]}, "abstract": "Remote sensing and artificial intelligence are pivotal technologies of precision agriculture nowadays. The efficient retrieval of large-scale field imagery combined with machine learning techniques shows success in various tasks like phenotyping, weeding, cropping, and disease control. This work will introduce a machine learning framework for automatized large-scale plant-specific trait annotation for the use case disease severity scoring for Cercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label Distribution Learning (DLDL), special loss functions, and a tailored model architecture, we develop an efficient Vision Transformer based model for disease severity scoring called SugarViT. One novelty in this work is the combination of remote sensing data with environmental parameters of the experimental sites for disease severity prediction. Although the model is evaluated on this special use case, it is held as generic as possible to also be applicable to various image-based classification and regression tasks. With our framework, it is even possible to learn models on multi-objective problems as we show by a pretraining on environmental metadata.", "url": "https://arxiv.org/abs/2311.03076"}, {"metadata": {"arXiv": "2311.03105", "Date": "Mon, 06 Nov 2023 13:54:52 ", "Title": "Pelvic floor MRI segmentation based on semi-supervised deep learning", "Authors": ["Jianwei Zuo", "Fei Feng", "Zhuhui Wang", "James A. Ashton-Miller", "John O.L. Delancey and Jiajia Luo"], "Categories": "cs.CV cs.AI"}, "abstract": "The semantic segmentation of pelvic organs via MRI has important clinical significance. Recently, deep learning-enabled semantic segmentation has facilitated the three-dimensional geometric reconstruction of pelvic floor organs, providing clinicians with accurate and intuitive diagnostic results. However, the task of labeling pelvic floor MRI segmentation, typically performed by clinicians, is labor-intensive and costly, leading to a scarcity of labels. Insufficient segmentation labels limit the precise segmentation and reconstruction of pelvic floor organs. To address these issues, we propose a semi-supervised framework for pelvic organ segmentation. The implementation of this framework comprises two stages. In the first stage, it performs self-supervised pre-training using image restoration tasks. Subsequently, fine-tuning of the self-supervised model is performed, using labeled data to train the segmentation model. In the second stage, the self-supervised segmentation model is used to generate pseudo labels for unlabeled data. Ultimately, both labeled and unlabeled data are utilized in semi-supervised training. Upon evaluation, our method significantly enhances the performance in the semantic segmentation and geometric reconstruction of pelvic organs, Dice coefficient can increase by 2.65% averagely. Especially for organs that are difficult to segment, such as the uterus, the accuracy of semantic segmentation can be improved by up to 3.70%.", "url": "https://arxiv.org/abs/2311.03105"}, {"metadata": {"arXiv": "2311.03177", "Date": "Mon, 06 Nov 2023 15:17:17 ", "Title": "1D-Convolutional transformer for Parkinson disease diagnosis from gait", "Authors": ["Safwen Naimi", "Wassim Bouachir and Guillaume-Alexandre Bilodeau"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages", "5 Figures", "6 Tables. Accepted for publication in Neural Computing and Applications (NCAA) 2023"]}, "abstract": "This paper presents an efficient deep neural network model for diagnosing Parkinson's disease from gait. More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage. The proposed architecture exploits the strengths of both Convolutional Neural Networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data. In this manner, our hybrid architecture achieves an improved performance compared to using either models individually. Our experimental results show that our approach is effective for detecting the different stages of Parkinson's disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset. Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals. Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.", "url": "https://arxiv.org/abs/2311.03177"}, {"metadata": {"arXiv": "2311.03226", "Date": "Mon, 06 Nov 2023 16:12:10 ", "Title": "LDM3D-VR: Latent Diffusion Model for 3D VR", "Authors": ["Gabriela Ben Melech Stan", "Diana Wofk", "Estelle Aflalo", "Shao-Yen Tseng", "Zhipeng Cai", "Michael Paulitsch", "Vasudev Lal"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to Workshop on Diffusion Models", "NeurIPS 2023"]}, "abstract": "Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.", "url": "https://arxiv.org/abs/2311.03226"}, {"metadata": {"arXiv": "2311.03339", "Date": "Mon, 06 Nov 2023 18:42:05 ", "Title": "FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2", "Authors": ["Maria Sdraka", "Alkinoos Dimakos", "Alexandros Malounis", "Zisoula Ntasiou", "Konstantinos Karantzalos", "Dimitrios Michail", "Ioannis Papoutsis"], "Categories": "cs.CV cs.AI"}, "abstract": "Over the last decade there has been an increasing frequency and intensity of wildfires across the globe, posing significant threats to human and animal lives, ecosystems, and socio-economic stability. Therefore urgent action is required to mitigate their devastating impact and safeguard Earth's natural resources. Robust Machine Learning methods combined with the abundance of high-resolution satellite imagery can provide accurate and timely mappings of the affected area in order to assess the scale of the event, identify the impacted assets and prioritize and allocate resources effectively for the proper restoration of the damaged region. In this work, we create and introduce a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations for the Greek Area). This dataset is unique as it comprises of satellite imagery acquired before and after a wildfire event, it contains information from Sentinel-2 and MODIS modalities with variable spatial and spectral resolution, and contains a large number of events where the corresponding burnt area ground truth has been annotated by domain experts. FLOGA covers the wider region of Greece, which is characterized by a Mediterranean landscape and climatic conditions. We use FLOGA to provide a thorough comparison of multiple Machine Learning and Deep Learning algorithms for the automatic extraction of burnt areas, approached as a change detection task. We also compare the results to those obtained using standard specialized spectral indices for burnt area mapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our benchmark results demonstrate the efficacy of the proposed technique in the automatic extraction of burnt areas, outperforming all other methods in terms of accuracy and robustness. Our dataset and code are publicly available at: https://github.com/Orion-AI-Lab/FLOGA.", "url": "https://arxiv.org/abs/2311.03339"}, {"metadata": {"arXiv": "2311.03356", "Date": "Mon, 06 Nov 2023 18:59:57 ", "Title": "GLaMM: Pixel Grounding Large Multimodal Model", "Authors": ["Hanoona Rasheed", "Muhammad Maaz", "Sahal Shaji", "Abdelrahman Shaker", "Salman Khan", "Hisham Cholakkal", "Rao M. Anwer", "Erix Xing", "Ming-Hsuan Yang", "Fahad S. Khan"], "Categories": "cs.CV cs.AI", "Comments": ["Technical Report of GLaMM"]}, "abstract": "Large Multimodal Models (LMMs) extend Large Language Models to the vision domain. Initial efforts towards LMMs used holistic images and text prompts to generate ungrounded textual responses. Very recently, region-level LMMs have been used to generate visually grounded responses. However, they are limited to only referring a single object category at a time, require users to specify the regions in inputs, or cannot offer dense pixel-wise object grounding. In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks. GLaMM not only grounds objects appearing in the conversations but is flexible enough to accept both textual and optional visual prompts (region of interest) as input. This empowers users to interact with the model at various levels of granularity, both in textual and visual domains. Due to the lack of standard benchmarks for the novel setting of generating visually grounded detailed conversations, we introduce a comprehensive evaluation protocol with our curated grounded conversations. Our proposed Grounded Conversation Generation (GCG) task requires densely grounded concepts in natural scenes at a large-scale. To this end, we propose a densely annotated Grounding-anything Dataset (GranD) using our proposed automated annotation pipeline that encompasses 7.5M unique concepts grounded in a total of 810M regions available with segmentation masks. Besides GCG, GLaMM also performs effectively on several downstream tasks e.g., referring expression segmentation, image and region-level captioning and vision-language conversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.", "url": "https://arxiv.org/abs/2311.03356"}, {"metadata": {"arXiv": "2311.02382", "Date": "Sat, 04 Nov 2023 11:38:53 ", "Title": "Ultra-Long Sequence Distributed Transformer", "Authors": ["Xiao Wang", "Isaac Lyngaas", "Aristeidis Tsaris", "Peng Chen", "Sajal Dash", "Mayanka Chandra Shekar", "Tao Luo", "Hong-Jun Yoon", "Mohamed Wahib", "John Gouley"], "Categories": "cs.DC cs.AI"}, "abstract": "Transformer models trained on long sequences often achieve higher accuracy than short sequences. Unfortunately, conventional transformers struggle with long sequence training due to the overwhelming computation and memory requirements. Existing methods for long sequence training offer limited speedup and memory reduction, and may compromise accuracy. This paper presents a novel and efficient distributed training method, the Long Short-Sequence Transformer (LSS Transformer), for training transformer with long sequences. It distributes a long sequence into segments among GPUs, with each GPU computing a partial self-attention for its segment. Then, it uses a fused communication and a novel double gradient averaging technique to avoid the need to aggregate partial self-attention and minimize communication overhead. We evaluated the performance between LSS Transformer and the state-of-the-art Nvidia sequence parallelism on a Wikipedia enwik8 dataset. Results show that our proposed method lead to 5.6x faster and 10.2x more memory-efficient implementation compared to state-of-the-art sequence parallelism on 144 Nvidia V100 GPUs. Moreover, our algorithm scales to an extreme sequence length of 50,112 at 3,456 GPUs, achieving 161% super-linear parallel efficiency and a throughput of 32 petaflops.", "url": "https://arxiv.org/abs/2311.02382"}, {"metadata": {"arXiv": "2311.02337", "Date": "Sat, 04 Nov 2023 06:52:38 ", "Title": "STOW: Discrete-Frame Segmentation and Tracking of Unseen Objects for Warehouse Picking Robots", "Authors": ["Yi Li", "Muru Zhang", "Markus Grotz", "Kaichun Mo", "Dieter Fox"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["CoRL 2023", "project page: https://sites.google.com/view/stow-corl23"]}, "abstract": "Segmentation and tracking of unseen object instances in discrete frames pose a significant challenge in dynamic industrial robotic contexts, such as distribution warehouses. Here, robots must handle object rearrangement, including shifting, removal, and partial occlusion by new items, and track these items after substantial temporal gaps. The task is further complicated when robots encounter objects not learned in their training sets, which requires the ability to segment and track previously unseen items. Considering that continuous observation is often inaccessible in such settings, our task involves working with a discrete set of frames separated by indefinite periods during which substantial changes to the scene may occur. This task also translates to domestic robotic applications, such as rearrangement of objects on a table. To address these demanding challenges, we introduce new synthetic and real-world datasets that replicate these industrial and household scenarios. We also propose a novel paradigm for joint segmentation and tracking in discrete frames along with a transformer module that facilitates efficient inter-frame communication. The experiments we conduct show that our approach significantly outperforms recent methods. For additional results and videos, please visit \\href{https://sites.google.com/view/stow-corl23}{website}. Code and dataset will be released.", "url": "https://arxiv.org/abs/2311.02337"}, {"metadata": {"arXiv": "2311.02602", "Date": "Sun, 05 Nov 2023 08:57:59 ", "Title": "Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop", "Authors": ["Jiaxin Shen", "Yanyao Liu", "Ziming Wang", "Ziyuan Jiao", "Yufeng Chen", "Wenjuan Han"], "Categories": "cs.RO cs.AI cs.CL", "Comments": ["12 pages", "6 figures"]}, "abstract": "To facilitate the advancement of research in healthcare robots without human intervention or commands, we introduce the Autonomous Helping Challenge, along with a crowd-sourcing large-scale dataset. The goal is to create healthcare robots that possess the ability to determine when assistance is necessary, generate useful sub-tasks to aid in planning, carry out these plans through a physical robot, and receive feedback from the environment in order to generate new tasks and continue the process. Besides the general challenge in open-ended scenarios, Autonomous Helping focuses on three specific challenges: autonomous task generation, the gap between the current scene and static commonsense, and the gap between language instruction and the real world. Additionally, we propose Helpy, a potential approach to close the healthcare loop in the learning-free setting.", "url": "https://arxiv.org/abs/2311.02602"}, {"metadata": {"arXiv": "2311.02787", "Date": "Sun, 05 Nov 2023 22:43:29 ", "Title": "Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation", "Authors": ["Yang You", "Bokui Shen", "Congyue Deng", "Haoran Geng", "He Wang", "Leonidas Guibas"], "Categories": "cs.RO cs.AI", "Comments": ["9 pages"]}, "abstract": "Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the tool and subgoal for a particular stage at our disposal, we present a granular closed-loop model predictive control strategy. This leverages Differentiable Physics with Point-to-Point correspondence (DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied iteratively. Experimental findings affirm that our technique surpasses multiple benchmarks in dough manipulation, spanning both short and long horizons. Remarkably, our model demonstrates robust generalization capabilities to novel and previously unencountered complex tasks without any preliminary demonstrations. We further substantiate our approach with experimental trials on real-world robotic platforms.", "url": "https://arxiv.org/abs/2311.02787"}, {"metadata": {"arXiv": "2311.02847", "Date": "Mon, 06 Nov 2023 03:26:41 ", "Title": "Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs", "Authors": ["Wenke Xia", "Dong Wang", "Xincheng Pang", "Zhigang Wang", "Bin Zhao", "Di Hu"], "Categories": "cs.RO cs.AI", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supporting various object manipulation. To effectively prompt LLMs with the kinematic structure of different objects, we design a unified kinematic knowledge parser, which represents various articulated objects as a unified textual description containing kinematic joints and contact location. Building upon this unified description, a kinematic-aware planner model is proposed to generate precise 3D manipulation waypoints via a designed kinematic-aware chain-of-thoughts prompting method. Our evaluation spanned 48 instances across 16 distinct categories, revealing that our framework not only outperforms traditional methods on 8 seen categories but also shows a powerful zero-shot capability for 8 unseen articulated object categories. Moreover, the real-world experiments on 7 different object categories prove our framework's adaptability in practical scenarios. Code is released at \\href{https://github.com/xwinks/LLM_articulated_object_manipulation}{here}.", "url": "https://arxiv.org/abs/2311.02847"}, {"metadata": {"arXiv": "2311.02133", "Date": "Fri, 03 Nov 2023 14:23:57 ", "Title": "Safe Online Dynamics Learning with Initially Unknown Models and Infeasible Safety Certificates", "Authors": ["Alexandre Capone", "Ryan Cosner", "Aaron Ames", "Sandra Hirche"], "Categories": "eess.SY cs.AI cs.RO cs.SY"}, "abstract": "Safety-critical control tasks with high levels of uncertainty are becoming increasingly common. Typically, techniques that guarantee safety during learning and control utilize constraint-based safety certificates, which can be leveraged to compute safe control inputs. However, excessive model uncertainty can render robust safety certification methods or infeasible, meaning no control input satisfies the constraints imposed by the safety certificate. This paper considers a learning-based setting with a robust safety certificate based on a control barrier function (CBF) second-order cone program. If the control barrier function certificate is feasible, our approach leverages it to guarantee safety. Otherwise, our method explores the system dynamics to collect data and recover the feasibility of the control barrier function constraint. To this end, we employ a method inspired by well-established tools from Bayesian optimization. We show that if the sampling frequency is high enough, we recover the feasibility of the robust CBF certificate, guaranteeing safety. Our approach requires no prior model and corresponds, to the best of our knowledge, to the first algorithm that guarantees safety in settings with occasionally infeasible safety certificates without requiring a backup non-learning-based controller.", "url": "https://arxiv.org/abs/2311.02133"}, {"metadata": {"arXiv": "2311.02101", "Date": "Wed, 01 Nov 2023 14:46:46 ", "Title": "Solving MaxSAT with Matrix Multiplication", "Authors": ["David Warde-Farley", "Vinod Nair", "Yujia Li", "Ivan Lobov", "Felix Gimeno", "Simon Osindero"], "Categories": "cs.AI cs.LG cs.LO"}, "abstract": "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT) specifically designed to run on neural network accelerators such as GPUs and TPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure constructs a Restricted Boltzmann Machine (RBM) with an equilibrium distribution wherein the probability of a Boolean assignment is exponential in the number of clauses it satisfies. Block Gibbs sampling is used to stochastically search the space of assignments with parallel Markov chains. Since matrix multiplication is the main computational primitive for block Gibbs sampling in an RBM, our approach leads to an elegantly simple algorithm (40 lines of JAX) well-suited for neural network accelerators. Theoretical results about RBMs guarantee that the required number of visible and hidden units of the RBM scale only linearly with the number of variables and constant-sized clauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs step scales reasonably with the instance size. Search throughput can be increased by batching parallel chains within a single accelerator as well as by distributing them across multiple accelerators. As a further enhancement, a heuristic based on unit propagation running on CPU is periodically applied to the sampled assignments. Our approach, which we term RbmSAT, is a new design point in the algorithm-hardware co-design space for MaxSAT. We present timed results on a subset of problem instances from the annual MaxSAT Evaluation's Incomplete Unweighted Track for the years 2018 to 2021. When allotted the same running time and CPU compute budget (but no TPUs), RbmSAT outperforms other participating solvers on problems drawn from three out of the four years' competitions. Given the same running time on a TPU cluster for which RbmSAT is uniquely designed, it outperforms all solvers on problems drawn from all four years.", "url": "https://arxiv.org/abs/2311.02101"}, {"metadata": {"arXiv": "2311.02760", "Date": "Sun, 05 Nov 2023 20:33:18 ", "Title": "Causal Question Answering with Reinforcement Learning", "Authors": ["Lukas Bl\\\"ubaum", "Stefan Heindorf"], "Categories": "cs.AI cs.LG"}, "abstract": "Causal questions inquire about causal relationships between different events or phenomena. Specifically, they often aim to determine whether there is a relationship between two phenomena, or to identify all causes/effects of a phenomenon. Causal questions are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with CauseNet, a large-scale dataset of causal relations and their provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on CauseNet for causal question answering. We introduce an Actor-Critic based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, CauseNet stores its original source on the web allowing for easy verification of paths.", "url": "https://arxiv.org/abs/2311.02760"}, {"metadata": {"arXiv": "2311.02884", "Date": "Mon, 06 Nov 2023 05:25:31 ", "Title": "Deep Learning-Empowered Semantic Communication Systems with a Shared Knowledge Base", "Authors": ["Peng Yi", "Yang Cao", "Xin Kang", "and Ying-Chang Liang"], "Categories": "cs.AI cs.IT cs.LG math.IT", "Comments": ["14 pages", "Journal", "accepted by IEEE TWC"], "DOI": "10.1109/TWC.2023.3330744"}, "abstract": "Deep learning-empowered semantic communication is regarded as a promising candidate for future 6G networks. Although existing semantic communication systems have achieved superior performance compared to traditional methods, the end-to-end architecture adopted by most semantic communication systems is regarded as a black box, leading to the lack of explainability. To tackle this issue, in this paper, a novel semantic communication system with a shared knowledge base is proposed for text transmissions. Specifically, a textual knowledge base constructed by inherently readable sentences is introduced into our system. With the aid of the shared knowledge base, the proposed system integrates the message and corresponding knowledge from the shared knowledge base to obtain the residual information, which enables the system to transmit fewer symbols without semantic performance degradation. In order to make the proposed system more reliable, the semantic self-information and the source entropy are mathematically defined based on the knowledge base. Furthermore, the knowledge base construction algorithm is developed based on a similarity-comparison method, in which a pre-configured threshold can be leveraged to control the size of the knowledge base. Moreover, the simulation results have demonstrated that the proposed approach outperforms existing baseline methods in terms of transmitted data size and sentence similarity.", "url": "https://arxiv.org/abs/2311.02884"}, {"metadata": {"arXiv": "2311.02996", "Date": "Mon, 06 Nov 2023 09:58:04 ", "Title": "Visual-information-driven model for crowd simulation using temporal convolutional network", "Authors": ["Xuanwen Liang and Eric Wai Ming Lee"], "Categories": "cs.AI cs.LG"}, "abstract": "Crowd simulations play a pivotal role in building design, influencing both user experience and public safety. While traditional knowledge-driven models have their merits, data-driven crowd simulation models promise to bring a new dimension of realism to these simulations. However, most of the existing data-driven models are designed for specific geometries, leading to poor adaptability and applicability. A promising strategy for enhancing the adaptability and realism of data-driven crowd simulation models is to incorporate visual information, including the scenario geometry and pedestrian locomotion. Consequently, this paper proposes a novel visual-information-driven (VID) crowd simulation model. The VID model predicts the pedestrian velocity at the next time step based on the prior social-visual information and motion data of an individual. A radar-geometry-locomotion method is established to extract the visual information of pedestrians. Moreover, a temporal convolutional network (TCN)-based deep learning model, named social-visual TCN, is developed for velocity prediction. The VID model is tested on three public pedestrian motion datasets with distinct geometries, i.e., corridor, corner, and T-junction. Both qualitative and quantitative metrics are employed to evaluate the VID model, and the results highlight the improved adaptability of the model across all three geometric scenarios. Overall, the proposed method demonstrates effectiveness in enhancing the adaptability of data-driven crowd models.", "url": "https://arxiv.org/abs/2311.02996"}, {"metadata": {"arXiv": "2311.03246", "Date": "Mon, 06 Nov 2023 16:34:48 ", "Title": "Advancing Post Hoc Case Based Explanation with Feature Highlighting", "Authors": ["Eoin Kenny and Eoin Delaney and Mark Keane"], "Categories": "cs.AI cs.HC cs.LG", "Comments": ["9 pages", "4 figures"], "ACM-class": "I.2.6; F.2", "DOI": "10.24963/ijcai.2023/48"}, "abstract": "Explainable AI (XAI) has been proposed as a valuable tool to assist in downstream tasks involving human and AI collaboration. Perhaps the most psychologically valid XAI techniques are case based approaches which display 'whole' exemplars to explain the predictions of black box AI systems. However, for such post hoc XAI methods dealing with images, there has been no attempt to improve their scope by using multiple clear feature 'parts' of the images to explain the predictions while linking back to relevant cases in the training data, thus allowing for more comprehensive explanations that are faithful to the underlying model. Here, we address this gap by proposing two general algorithms (latent and super pixel based) which can isolate multiple clear feature parts in a test image, and then connect them to the explanatory cases found in the training data, before testing their effectiveness in a carefully designed user study. Results demonstrate that the proposed approach appropriately calibrates a users feelings of 'correctness' for ambiguous classifications in real world data on the ImageNet dataset, an effect which does not happen when just showing the explanation without feature highlighting.", "url": "https://arxiv.org/abs/2311.03246"}, {"metadata": {"arXiv": "2311.02115", "Date": "Fri, 03 Nov 2023 01:37:28 ", "Title": "Towards objective and systematic evaluation of bias in medical imaging AI", "Authors": ["Emma A.M. Stanley", "Raissa Souza", "Anthony Winder", "Vedant Gulve", "Kimberly Amador", "Matthias Wilms", "Nils D. Forkert"], "Categories": "cs.CV cs.AI cs.CY cs.LG"}, "abstract": "Artificial intelligence (AI) models trained using medical images for clinical tasks often exhibit bias in the form of disparities in performance between subgroups. Since not all sources of biases in real-world medical imaging data are easily identifiable, it is challenging to comprehensively assess how those biases are encoded in models, and how capable bias mitigation methods are at ameliorating performance disparities. In this article, we introduce a novel analysis framework for systematically and objectively investigating the impact of biases in medical images on AI models. We developed and tested this framework for conducting controlled in silico trials to assess bias in medical imaging AI using a tool for generating synthetic magnetic resonance images with known disease effects and sources of bias. The feasibility is showcased by using three counterfactual bias scenarios to measure the impact of simulated bias effects on a convolutional neural network (CNN) classifier and the efficacy of three bias mitigation strategies. The analysis revealed that the simulated biases resulted in expected subgroup performance disparities when the CNN was trained on the synthetic datasets. Moreover, reweighing was identified as the most successful bias mitigation strategy for this setup, and we demonstrated how explainable AI methods can aid in investigating the manifestation of bias in the model using this framework. Developing fair AI models is a considerable challenge given that many and often unknown sources of biases can be present in medical imaging datasets. In this work, we present a novel methodology to objectively study the impact of biases and mitigation strategies on deep learning pipelines, which can support the development of clinical AI that is robust and responsible.", "url": "https://arxiv.org/abs/2311.02115"}, {"metadata": {"arXiv": "2311.02236", "Date": "Fri, 03 Nov 2023 20:50:40 ", "Title": "Robust Fine-Tuning of Vision-Language Models for Domain Generalization", "Authors": ["Kevin Vogt-Lowell", "Noah Lee", "Theodoros Tsiligkaridis", "Marc Vaillant"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "Comments": ["In proceedings of the 27th IEEE High Performance Extreme Computing Conference"]}, "abstract": "Transfer learning enables the sharing of common knowledge among models for a variety of downstream tasks, but traditional methods suffer in limited training data settings and produce narrow models incapable of effectively generalizing under distribution shifts. Foundation models have recently demonstrated impressive zero-shot inference capabilities and robustness under distribution shifts. However, zero-shot evaluation for these models has been predominantly confined to benchmarks with simple distribution shifts, limiting our understanding of their effectiveness under the more realistic shifts found in practice. Moreover, common fine-tuning methods for these models have yet to be evaluated against vision models in few-shot scenarios where training data is limited. To address these gaps, we present a new recipe for few-shot fine-tuning of the popular vision-language foundation model CLIP and evaluate its performance on challenging benchmark datasets with realistic distribution shifts from the WILDS collection. Our experimentation demonstrates that, while zero-shot CLIP fails to match performance of trained vision models on more complex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only counterparts in terms of in-distribution and out-of-distribution accuracy at all levels of training data availability. This provides a strong incentive for adoption of foundation models within few-shot learning applications operating with real-world data. Code is available at $\\href{https://github.com/mit-ll/robust-vision-language-finetuning}{\\text{https://github.com/mit-ll/robust-vision-language-finetuning}}$.", "url": "https://arxiv.org/abs/2311.02236"}, {"metadata": {"arXiv": "2311.02314", "Date": "Sat, 04 Nov 2023 03:56:40 ", "Title": "Thermal Face Image Classification using Deep Learning Techniques", "Authors": ["Prosenjit Chatterjee and ANK Zaman"], "Categories": "cs.CV cs.AI cs.LG cs.NE", "Comments": ["6 pages. Link of the Conference: https://american-cse.org/index.html/"]}, "abstract": "Thermal images have various applications in security, medical and industrial domains. This paper proposes a practical deep-learning approach for thermal image classification. Accurate and efficient classification of thermal images poses a significant challenge across various fields due to the complex image content and the scarcity of annotated datasets. This work uses a convolutional neural network (CNN) architecture, specifically ResNet-50 and VGGNet-19, to extract features from thermal images. This work also applied Kalman filter on thermal input images for image denoising. The experimental results demonstrate the effectiveness of the proposed approach in terms of accuracy and efficiency.", "url": "https://arxiv.org/abs/2311.02314"}, {"metadata": {"arXiv": "2311.02338", "Date": "Sat, 04 Nov 2023 07:16:37 ", "Title": "Potato Leaf Disease Classification using Deep Learning: A Convolutional Neural Network Approach", "Authors": ["Utkarsh Yashwant Tambe", "A. Shobanadevi", "A. Shanthini and Hsiu-Chun Hsu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at the International Conference on Recent Trends in Data Science and its Applications (ICRTDA 2023)", "6 pages", "6 figures", "1 table"]}, "abstract": "In this study, a Convolutional Neural Network (CNN) is used to classify potato leaf illnesses using Deep Learning. The suggested approach entails preprocessing the leaf image data, training a CNN model on that data, and assessing the model's success on a test set. The experimental findings show that the CNN model, with an overall accuracy of 99.1%, is highly accurate in identifying two kinds of potato leaf diseases, including Early Blight, Late Blight, and Healthy. The suggested method may offer a trustworthy and effective remedy for identifying potato diseases, which is essential for maintaining food security and minimizing financial losses in agriculture. The model can accurately recognize the various disease types even when there are severe infections present. This work highlights the potential of deep learning methods for categorizing potato diseases, which can help with effective and automated disease management in potato farming.", "url": "https://arxiv.org/abs/2311.02338"}, {"metadata": {"arXiv": "2311.02502", "Date": "Sat, 04 Nov 2023 20:40:39 ", "Title": "MAAIP: Multi-Agent Adversarial Interaction Priors for imitation from fighting demonstrations for physics-based characters", "Authors": ["Mohamed Younes", "Ewa Kijak", "Richard Kulpa", "Simon Malinowski", "Franck Multon"], "Categories": "cs.CV cs.AI cs.GR cs.LG cs.RO", "Comments": ["SCA'23", "Supplementary video: https://youtu.be/wQfIiw_rQ3w"], "MSC-class": "68U99", "ACM-class": "I.3.8; I.3.m", "Journal-ref": "ACM SIGGRAPH / Eurographics Symposium on Computer Animation (SCA), August 4-6, 2023, Los Angeles, CA, USA", "DOI": "10.1145/3606926"}, "abstract": "Simulating realistic interaction and motions for physics-based characters is of great interest for interactive applications, and automatic secondary character animation in the movie and video game industries. Recent works in reinforcement learning have proposed impressive results for single character simulation, especially the ones that use imitation learning based techniques. However, imitating multiple characters interactions and motions requires to also model their interactions. In this paper, we propose a novel Multi-Agent Generative Adversarial Imitation Learning based approach that generalizes the idea of motion imitation for one character to deal with both the interaction and the motions of the multiple physics-based characters. Two unstructured datasets are given as inputs: 1) a single-actor dataset containing motions of a single actor performing a set of motions linked to a specific application, and 2) an interaction dataset containing a few examples of interactions between multiple actors. Based on these datasets, our system trains control policies allowing each character to imitate the interactive skills associated with each actor, while preserving the intrinsic style. This approach has been tested on two different fighting styles, boxing and full-body martial art, to demonstrate the ability of the method to imitate different styles.", "url": "https://arxiv.org/abs/2311.02502"}, {"metadata": {"arXiv": "2311.02598", "Date": "Sun, 05 Nov 2023 08:45:26 ", "Title": "Automated Camera Calibration via Homography Estimation with GNNs", "Authors": ["Giacomo D'Amicantonio", "Egor Bondarev", "Peter H.N. De With"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Over the past few decades, a significant rise of camera-based applications for traffic monitoring has occurred. Governments and local administrations are increasingly relying on the data collected from these cameras to enhance road safety and optimize traffic conditions. However, for effective data utilization, it is imperative to ensure accurate and automated calibration of the involved cameras. This paper proposes a novel approach to address this challenge by leveraging the topological structure of intersections. We propose a framework involving the generation of a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighbourhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters. As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.", "url": "https://arxiv.org/abs/2311.02598"}, {"metadata": {"arXiv": "2311.02641", "Date": "Sun, 05 Nov 2023 12:57:05 ", "Title": "PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation", "Authors": ["Sahil Nawale", "Dhruv Khut", "Daksh Dave", "Gauransh Sawhney", "Pushkar Aggrawal", "Dr. Kailas Devadakar"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["6 pages", "6 figures", "3 tables"]}, "abstract": "Pothole detection is crucial for road safety and maintenance, traditionally relying on 2D image segmentation. However, existing 3D Semantic Pothole Segmentation research often overlooks point cloud sparsity, leading to suboptimal local feature capture and segmentation accuracy. Our research presents an innovative point cloud-based pothole segmentation architecture. Our model efficiently identifies hidden features and uses a feedback mechanism to enhance local characteristics, improving feature presentation. We introduce a local relationship learning module to understand local shape relationships, enhancing structural insights. Additionally, we propose a lightweight adaptive structure for refining local point features using the K nearest neighbor algorithm, addressing point cloud density differences and domain selection. Shared MLP Pooling is integrated to learn deep aggregation features, facilitating semantic data exploration and segmentation guidance. Extensive experiments on three public datasets confirm PotholeGuard's superior performance over state-of-the-art methods. Our approach offers a promising solution for robust and accurate 3D pothole segmentation, with applications in road maintenance and safety.", "url": "https://arxiv.org/abs/2311.02641"}, {"metadata": {"arXiv": "2311.02733", "Date": "Sun, 05 Nov 2023 18:35:03 ", "Title": "AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection", "Authors": ["Sahibzada Adil Shahzad", "Ammarah Hashmi", "Yan-Tsung Peng", "Yu Tsao", "Hsin-Min Wang"], "Categories": "cs.CV cs.AI cs.LG cs.MM cs.SD eess.AS"}, "abstract": "Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multi-modal models that can exploit both pieces of information simultaneously. Previous methods mainly adopt uni-modal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multi-modal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multi-modal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.", "url": "https://arxiv.org/abs/2311.02733"}, {"metadata": {"arXiv": "2311.03355", "Date": "Mon, 06 Nov 2023 18:59:57 ", "Title": "SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis", "Authors": ["Hanrong Ye", "Jason Kuen", "Qing Liu", "Zhe Lin", "Brian Price", "Dan Xu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "We propose SegGen, a highly-effective training data generation method for image segmentation, which pushes the performance limits of state-of-the-art segmentation models to a significant extent. SegGen designs and integrates two data generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new mask-image pairs via our proposed text-to-mask generation model and mask-to-image generation model, greatly improving the diversity in segmentation masks for model supervision; (ii) ImgSyn synthesizes new images based on existing masks using the mask-to-image generation model, strongly improving image diversity for model inputs. On the highly competitive ADE20K and COCO benchmarks, our data generation method markedly improves the performance of state-of-the-art segmentation models in semantic segmentation, panoptic segmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU, Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L is also significantly increased from 56.1 to 57.4 (+1.3). These promising results strongly suggest the effectiveness of our SegGen even when abundant human-annotated training data is utilized. Moreover, training with our synthetic data makes the segmentation models more robust towards unseen domains. Project website: https://seggenerator.github.io", "url": "https://arxiv.org/abs/2311.03355"}, {"metadata": {"arXiv": "2311.03357", "Date": "Mon, 06 Nov 2023 18:59:58 ", "Title": "Exploitation-Guided Exploration for Semantic Embodied Navigation", "Authors": ["Justin Wasserman", "Girish Chowdhary", "Abhinav Gupta", "Unnat Jain"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["Code and results available at http://xgxvisnav.github.io"]}, "abstract": "In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework. However, there is more to compositionality beyond the decomposition of the learning load into modular components. In this work, we investigate a principled way to syntactically combine these components. Particularly, we propose Exploitation-Guided Exploration (XGX) where separate modules for exploration and exploitation come together in a novel and intuitive manner. We configure the exploitation module to take over in the deterministic final steps of navigation i.e. when the goal becomes visible. Crucially, an exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization. XGX, with effective decomposition and novel guidance, improves the state-of-the-art performance on the challenging object navigation task from 70% to 73%. Along with better accuracy, through targeted analysis, we show that XGX is also more efficient at goal-conditioned exploration. Finally, we show sim-to-real transfer to robot hardware and XGX performs over two-fold better than the best baseline from simulation benchmarking. Project page: xgxvisnav.github.io", "url": "https://arxiv.org/abs/2311.03357"}, {"metadata": {"arXiv": "2311.02103", "Date": "Wed, 01 Nov 2023 23:03:59 ", "Title": "Relax: Composable Abstractions for End-to-End Dynamic Machine Learning", "Authors": ["Ruihang Lai", "Junru Shao", "Siyuan Feng", "Steven S. Lyubomirsky", "Bohan Hou", "Wuwei Lin", "Zihao Ye", "Hongyi Jin", "Yuchen Jin", "Jiawei Liu", "Lesheng Jin", "Yaxing Cai", "Ziheng Jiang", "Yong Wu", "Sunghyun Park", "Prakalp Srivastava", "Jared G. Roesch", "Todd C. Mowry", "Tianqi Chen"], "Categories": "cs.LG cs.AI cs.PL"}, "abstract": "Dynamic shape computations have become critical in modern machine learning workloads, especially in emerging large language models. The success of these models has driven demand for deploying them to a diverse set of backend environments. In this paper, we present Relax, a compiler abstraction for optimizing end-to-end dynamic machine learning workloads. Relax introduces first-class symbolic shape annotations to track dynamic shape computations globally across the program. It also introduces a cross-level abstraction that encapsulates computational graphs, loop-level tensor programs, and library calls in a single representation to enable cross-level optimizations. We build an end-to-end compilation framework using the proposed approach to optimize dynamic shape models. Experimental results on large language models show that Relax delivers performance competitive with state-of-the-art hand-optimized systems across platforms and enables deployment of emerging dynamic models to a broader set of environments, including mobile phones, embedded devices, and web browsers.", "url": "https://arxiv.org/abs/2311.02103"}, {"metadata": {"arXiv": "2311.02104", "Date": "Thu, 02 Nov 2023 03:27:51 ", "Title": "Efficient Symbolic Policy Learning with Differentiable Symbolic Expression", "Authors": ["Jiaming Guo", "Rui Zhang", "Shaohui Peng", "Qi Yi", "Xing Hu", "Ruizhi Chen", "Zidong Du", "Xishan Zhang", "Ling Li", "Qi Guo", "Yunji Chen"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by NeurIPS2023"]}, "abstract": "Deep reinforcement learning (DRL) has led to a wide range of advances in sequential decision-making tasks. However, the complexity of neural network policies makes it difficult to understand and deploy with limited computational resources. Currently, employing compact symbolic expressions as symbolic policies is a promising strategy to obtain simple and interpretable policies. Previous symbolic policy methods usually involve complex training processes and pre-trained neural network policies, which are inefficient and limit the application of symbolic policies. In this paper, we propose an efficient gradient-based learning method named Efficient Symbolic Policy Learning (ESPL) that learns the symbolic policy from scratch in an end-to-end way. We introduce a symbolic network as the search space and employ a path selector to find the compact symbolic policy. By doing so we represent the policy with a differentiable symbolic expression and train it in an off-policy manner which further improves the efficiency. In addition, in contrast with previous symbolic policies which only work in single-task RL because of complexity, we expand ESPL on meta-RL to generate symbolic policies for unseen tasks. Experimentally, we show that our approach generates symbolic policies with higher performance and greatly improves data efficiency for single-task RL. In meta-RL, we demonstrate that compared with neural network policies the proposed symbolic policy achieves higher performance and efficiency and shows the potential to be interpretable.", "url": "https://arxiv.org/abs/2311.02104"}, {"metadata": {"arXiv": "2311.02105", "Date": "Thu, 02 Nov 2023 09:18:21 ", "Title": "Making Harmful Behaviors Unlearnable for Large Language Models", "Authors": ["Xin Zhou", "Yi Lu", "Ruotian Ma", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["work in process"]}, "abstract": "Large language models (LLMs) have shown great potential as general-purpose AI assistants in various domains. To meet the requirements of different applications, LLMs are often customized by further fine-tuning. However, the powerful learning ability of LLMs not only enables them to acquire new tasks but also makes them susceptible to learning undesired behaviors. For example, even safety-aligned LLMs can be easily fine-tuned into harmful assistants as the fine-tuning data often contains implicit or explicit harmful content. Can we train LLMs on harmful data without learning harmful behaviors? This paper proposes a controllable training framework that makes harmful behaviors unlearnable during the fine-tuning process. Specifically, we introduce ``security vectors'', a few new parameters that can be separated from the LLM, to ensure LLM's responses are consistent with the harmful behavior. Security vectors are activated during fine-tuning, the consistent behavior makes LLM believe that such behavior has already been learned, there is no need to further optimize for harmful data. During inference, we can deactivate security vectors to restore the LLM's normal behavior. The experimental results show that the security vectors generated by 100 harmful samples are enough to prevent LLM from learning 1000 harmful samples, while preserving the ability to learn other useful information.", "url": "https://arxiv.org/abs/2311.02105"}, {"metadata": {"arXiv": "2311.02106", "Date": "Thu, 02 Nov 2023 10:07:30 ", "Title": "Efficient Machine Learning Ensemble Methods for Detecting Gravitational Wave Glitches in LIGO Time Series", "Authors": ["Elena-Simona Apostol and Ciprian-Octavian Truic\\u{a}"], "Categories": "cs.LG astro-ph.IM cs.AI gr-qc"}, "abstract": "The phenomenon of Gravitational Wave (GW) analysis has grown in popularity as technology has advanced and the process of observing gravitational waves has become more precise. Although the sensitivity and the frequency of observation of GW signals are constantly improving, the possibility of noise in the collected GW data remains. In this paper, we propose two new Machine and Deep learning ensemble approaches (i.e., ShallowWaves and DeepWaves Ensembles) for detecting different types of noise and patterns in datasets from GW observatories. Our research also investigates various Machine and Deep Learning techniques for multi-class classification and provides a comprehensive benchmark, emphasizing the best results in terms of three commonly used performance metrics (i.e., accuracy, precision, and recall). We train and test our models on a dataset consisting of annotated time series from real-world data collected by the Advanced Laser Interferometer GW Observatory (LIGO). We empirically show that the best overall accuracy is obtained by the proposed DeepWaves Ensemble, followed close by the ShallowWaves Ensemble.", "url": "https://arxiv.org/abs/2311.02106"}, {"metadata": {"arXiv": "2311.02107", "Date": "Thu, 02 Nov 2023 11:55:07 ", "Title": "Generative Artificial Intelligence in Healthcare: Ethical Considerations and Assessment Checklist", "Authors": ["Yilin Ning", "Salinelat Teixayavong", "Yuqing Shang", "Julian Savulescu", "Vaishaanth Nagaraj", "Di Miao", "Mayli Mertens", "Daniel Shu Wei Ting", "Jasmine Chiat Ling Ong", "Mingxuan Liu", "Jiuwen Cao", "Michael Dunn", "Roger Vaughan", "Marcus Eng Hock Ong", "Joseph Jao-Yiu Sung", "Eric J Topol", "Nan Liu"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "The widespread use of ChatGPT and other emerging technology powered by generative artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in high-stakes applications such as healthcare. However, less clear is how to resolve such issues beyond following guidelines and regulations that are still under discussion and development. On the other hand, other types of generative AI have been used to synthesize images and other types of data for research and practical purposes, which have resolved some ethical issues and exposed other ethical issues, but such technology is less often the focus of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of generative AI via a systematic scoping review of relevant existing research in healthcare, and reduce the gaps by proposing an ethics checklist for comprehensive assessment and transparent documentation of ethical discussions in generative AI development. While the checklist can be readily integrated into the current peer review and publication system to enhance generative AI research, it may also be used in broader settings to disclose ethics-related considerations in generative AI-powered products (or real-life applications of such products) to help users establish reasonable trust in their capabilities.", "url": "https://arxiv.org/abs/2311.02107"}, {"metadata": {"arXiv": "2311.02117", "Date": "Fri, 03 Nov 2023 02:56:01 ", "Title": "Cooperative Network Learning for Large-Scale and Decentralized Graphs", "Authors": ["Qiang Wu", "Yiming Huang", "Yujie Zeng", "Yujie Teng", "Fang Zhou", "Linyuan L\\\"u"], "Categories": "cs.LG cs.AI cs.SI"}, "abstract": "Graph research, the systematic study of interconnected data points represented as graphs, plays a vital role in capturing intricate relationships within networked systems. However, in the real world, as graphs scale up, concerns about data security among different data-owning agencies arise, hindering information sharing and, ultimately, the utilization of graph data. Therefore, establishing a mutual trust mechanism among graph agencies is crucial for unlocking the full potential of graphs. Here, we introduce a Cooperative Network Learning (CNL) framework to ensure secure graph computing for various graph tasks. Essentially, this CNL framework unifies the local and global perspectives of GNN computing with distributed data for an agency by virtually connecting all participating agencies as a global graph without a fixed central coordinator. Inter-agency computing is protected by various technologies inherent in our framework, including homomorphic encryption and secure transmission. Moreover, each agency has a fair right to design or employ various graph learning models from its local or global perspective. Thus, CNL can collaboratively train GNN models based on decentralized graphs inferred from local and global graphs. Experiments on contagion dynamics prediction and traditional graph tasks (i.e., node classification and link prediction) demonstrate that our CNL architecture outperforms state-of-the-art GNNs developed at individual sites, revealing that CNL can provide a reliable, fair, secure, privacy-preserving, and global perspective to build effective and personalized models for network applications. We hope this framework will address privacy concerns in graph-related research and integrate decentralized graph data structures to benefit the network research community in cooperation and innovation.", "url": "https://arxiv.org/abs/2311.02117"}, {"metadata": {"arXiv": "2311.02123", "Date": "Fri, 03 Nov 2023 07:40:06 ", "Title": "RigLSTM: Recurrent Independent Grid LSTM for Generalizable Sequence Learning", "Authors": ["Ziyu Wang", "Wenhao Jiang", "Zixuan Zhang", "Wei Tang", "Junchi Yan"], "Categories": "cs.LG cs.AI"}, "abstract": "Sequential processes in real-world often carry a combination of simple subsystems that interact with each other in certain forms. Learning such a modular structure can often improve the robustness against environmental changes. In this paper, we propose recurrent independent Grid LSTM (RigLSTM), composed of a group of independent LSTM cells that cooperate with each other, for exploiting the underlying modular structure of the target task. Our model adopts cell selection, input feature selection, hidden state selection, and soft state updating to achieve a better generalization ability on the basis of the recent Grid LSTM for the tasks where some factors differ between training and evaluation. Specifically, at each time step, only a fraction of cells are activated, and the activated cells select relevant inputs and cells to communicate with. At the end of one time step, the hidden states of the activated cells are updated by considering the relevance between the inputs and the hidden states from the last and current time steps. Extensive experiments on diversified sequential modeling tasks are conducted to show the superior generalization ability when there exist changes in the testing environment. Source code is available at \\url{https://github.com/ziyuwwang/rig-lstm}.", "url": "https://arxiv.org/abs/2311.02123"}, {"metadata": {"arXiv": "2311.02125", "Date": "Fri, 03 Nov 2023 08:35:54 ", "Title": "Using General Value Functions to Learn Domain-Backed Inventory Management Policies", "Authors": ["Durgesh Kalwar", "Omkar Shelke", "Harshad Khadilkar"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "We consider the inventory management problem, where the goal is to balance conflicting objectives such as availability and wastage of a large range of products in a store. We propose a reinforcement learning (RL) approach that utilises General Value Functions (GVFs) to derive domain-backed inventory replenishment policies. The inventory replenishment decisions are modelled as a sequential decision making problem, which is challenging due to uncertain demand and the existence of aggregate (cross-product) constraints. In existing literature, GVFs have primarily been used for auxiliary task learning. We use this capability to train GVFs on domain-critical characteristics such as prediction of stock-out probability and wastage quantity. Using this domain expertise for more effective exploration, we train an RL agent to compute the inventory replenishment quantities for a large range of products (up to 6000 in the reported experiments), which share aggregate constraints such as the total weight/volume per delivery. Additionally, we show that the GVF predictions can be used to provide additional domain-backed insights into the decisions proposed by the RL agent. Finally, since the environment dynamics are fully transferred, the trained GVFs can be used for faster adaptation to vastly different business objectives (for example, due to the start of a promotional period or due to deployment in a new customer environment).", "url": "https://arxiv.org/abs/2311.02125"}, {"metadata": {"arXiv": "2311.02127", "Date": "Fri, 03 Nov 2023 10:25:47 ", "Title": "A Systematic Review of Deep Graph Neural Networks: Challenges, Classification, Architectures, Applications & Potential Utility in Bioinformatics", "Authors": ["Adil Mudasir Malla", "Asif Ali Banka"], "Categories": "cs.LG cs.AI q-bio.QM", "Comments": ["39 pages", "13 figures", "21 tables"]}, "abstract": "In recent years, tasks of machine learning ranging from image processing & audio/video analysis to natural language understanding have been transformed by deep learning. The data content in all these scenarios are expressed via Euclidean space. However, a considerable amount of application data is structured in non-Euclidean space and is expressed as graphs, e.g. dealing with complicated interactions & object interdependencies. Modelling physical systems, learning molecular signatures, identifying protein interactions and predicting diseases involve utilising a model that can adapt from graph data. Graph neural networks (GNNs), specified as artificial-neural models, employ message transmission between graph nodes to represent graph dependencies and are primarily used in the non-Euclidean domain. Variants of GNN like Graph Recurrent Networks (GRN), Graph Auto Encoder (GAE), Graph Convolution Networks (GCN), Graph Adversarial Methods & Graph Reinforcement learning have exhibited breakthrough productivity on a wide range of tasks, especially in the field of bioinformatics, in recent years as a result of the rapid collection of biological network data. Apart from presenting all existing GNN models, mathematical analysis and comparison of the variants of all types of GNN have been highlighted in this survey. Graph neural networks are investigated for their potential real-world applications in various fields, focusing on Bioinformatics. Furthermore, resources for evaluating graph neural network models and accessing open-source code & benchmark data sets are included. Ultimately, we provide some (seven) proposals for future research in this rapidly evolving domain. GNNs have the potential to be an excellent tool for solving a wide range of biological challenges in bioinformatics research, as they are best represented as connected complex graphs.", "url": "https://arxiv.org/abs/2311.02127"}, {"metadata": {"arXiv": "2311.02129", "Date": "Fri, 03 Nov 2023 12:33:00 ", "Title": "Hierarchical Reinforcement Learning for Power Network Topology Control", "Authors": ["Blazej Manczak and Jan Viebahn and Herke van Hoof"], "Categories": "cs.LG cs.AI cs.SY eess.SY"}, "abstract": "Learning in high-dimensional action spaces is a key challenge in applying reinforcement learning (RL) to real-world systems. In this paper, we study the possibility of controlling power networks using RL methods. Power networks are critical infrastructures that are complex to control. In particular, the combinatorial nature of the action space poses a challenge to both conventional optimizers and learned controllers. Hierarchical reinforcement learning (HRL) represents one approach to address this challenge. More precisely, a HRL framework for power network topology control is proposed. The HRL framework consists of three levels of action abstraction. At the highest level, there is the overall long-term task of power network operation, namely, keeping the power grid state within security constraints at all times, which is decomposed into two temporally extended actions: 'do nothing' versus 'propose a topology change'. At the intermediate level, the action space consists of all controllable substations. Finally, at the lowest level, the action space consists of all configurations of the chosen substation. By employing this HRL framework, several hierarchical power network agents are trained for the IEEE 14-bus network. Whereas at the highest level a purely rule-based policy is still chosen for all agents in this study, at the intermediate level the policy is trained using different state-of-the-art RL algorithms. At the lowest level, either an RL algorithm or a greedy algorithm is used. The performance of the different 3-level agents is compared with standard baseline (RL or greedy) approaches. A key finding is that the 3-level agent that employs RL both at the intermediate and the lowest level outperforms all other agents on the most difficult task. Our code is publicly available.", "url": "https://arxiv.org/abs/2311.02129"}, {"metadata": {"arXiv": "2311.02130", "Date": "Fri, 03 Nov 2023 13:34:44 ", "Title": "Client Orchestration and Cost-Efficient Joint Optimization for NOMA-Enabled Hierarchical Federated Learning", "Authors": ["Bibo Wu", "Fang Fang", "Xianbin Wang", "Donghong Cai", "Shu Fu and Zhiguo Ding"], "Categories": "cs.LG cs.AI"}, "abstract": "Hierarchical federated learning (HFL) shows great advantages over conventional two-layer federated learning (FL) in reducing network overhead and interaction latency while still retaining the data privacy of distributed FL clients. However, the communication and energy overhead still pose a bottleneck for HFL performance, especially as the number of clients raises dramatically. To tackle this issue, we propose a non-orthogonal multiple access (NOMA) enabled HFL system under semi-synchronous cloud model aggregation in this paper, aiming to minimize the total cost of time and energy at each HFL global round. Specifically, we first propose a novel fuzzy logic based client orchestration policy considering client heterogenerity in multiple aspects, including channel quality, data quantity and model staleness. Subsequently, given the fuzzy based client-edge association, a joint edge server scheduling and resource allocation problem is formulated. Utilizing problem decomposition, we firstly derive the closed-form solution for the edge server scheduling subproblem via the penalty dual decomposition (PDD) method. Next, a deep deterministic policy gradient (DDPG) based algorithm is proposed to tackle the resource allocation subproblem considering time-varying environments. Finally, extensive simulations demonstrate that the proposed scheme outperforms the considered benchmarks regarding HFL performance improvement and total cost reduction.", "url": "https://arxiv.org/abs/2311.02130"}, {"metadata": {"arXiv": "2311.02142", "Date": "Fri, 03 Nov 2023 16:50:26 ", "Title": "Sparse Training of Discrete Diffusion Models for Graph Generation", "Authors": ["Yiming Qin", "Clement Vignac", "Pascal Frossard"], "Categories": "cs.LG cs.AI"}, "abstract": "Generative models for graphs often encounter scalability challenges due to the inherent need to predict interactions for every node pair. Despite the sparsity often exhibited by real-world graphs, the unpredictable sparsity patterns of their adjacency matrices, stemming from their unordered nature, leads to quadratic computational complexity. In this work, we introduce SparseDiff, a denoising diffusion model for graph generation that is able to exploit sparsity during its training phase. At the core of SparseDiff is a message-passing neural network tailored to predict only a subset of edges during each forward pass. When combined with a sparsity-preserving noise model, this model can efficiently work with edge lists representations of graphs, paving the way for scalability to much larger structures. During the sampling phase, SparseDiff iteratively populates the adjacency matrix from its prior state, ensuring prediction of the full graph while controlling memory utilization. Experimental results show that SparseDiff simultaneously matches state-of-the-art in generation performance on both small and large graphs, highlighting the versatility of our method.", "url": "https://arxiv.org/abs/2311.02142"}, {"metadata": {"arXiv": "2311.02147", "Date": "Fri, 03 Nov 2023 17:57:55 ", "Title": "The Alignment Problem in Context", "Authors": ["Rapha\\\"el Milli\\`ere"], "Categories": "cs.LG cs.AI"}, "abstract": "A core challenge in the development of increasingly capable AI systems is to make them safe and reliable by ensuring their behaviour is consistent with human values. This challenge, known as the alignment problem, does not merely apply to hypothetical future AI systems that may pose catastrophic risks; it already applies to current systems, such as large language models, whose potential for harm is rapidly increasing. In this paper, I assess whether we are on track to solve the alignment problem for large language models, and what that means for the safety of future AI systems. I argue that existing strategies for alignment are insufficient, because large language models remain vulnerable to adversarial attacks that can reliably elicit unsafe behaviour. I offer an explanation of this lingering vulnerability on which it is not simply a contingent limitation of current language models, but has deep technical ties to a crucial aspect of what makes these models useful and versatile in the first place -- namely, their remarkable aptitude to learn \"in context\" directly from user instructions. It follows that the alignment problem is not only unsolved for current AI systems, but may be intrinsically difficult to solve without severely undermining their capabilities. Furthermore, this assessment raises concerns about the prospect of ensuring the safety of future and more capable AI systems.", "url": "https://arxiv.org/abs/2311.02147"}, {"metadata": {"arXiv": "2311.02171", "Date": "Fri, 03 Nov 2023 18:00:59 ", "Title": "Emergence of Abstract State Representations in Embodied Sequence Modeling", "Authors": ["Tian Yun", "Zilai Zeng", "Kunal Handa", "Ashish V Thapliyal", "Bo Pang", "Ellie Pavlick", "Chen Sun"], "Categories": "cs.LG cs.AI", "Comments": ["EMNLP 2023. Project webpage: https://abstract-state-seqmodel.github.io/"]}, "abstract": "Decision making via sequence modeling aims to mimic the success of language models, where actions taken by an embodied agent are modeled as tokens to predict. Despite their promising performance, it remains unclear if embodied sequence modeling leads to the emergence of internal representations that represent the environmental state information. A model that lacks abstract state representations would be liable to make decisions based on surface statistics which fail to generalize. We take the BabyAI environment, a grid world in which language-conditioned navigation tasks are performed, and build a sequence modeling Transformer, which takes a language instruction, a sequence of actions, and environmental observations as its inputs. In order to investigate the emergence of abstract state representations, we design a \"blindfolded\" navigation task, where only the initial environmental layout, the language instruction, and the action sequence to complete the task are available for training. Our probing results show that intermediate environmental layouts can be reasonably reconstructed from the internal activations of a trained model, and that language instructions play a role in the reconstruction accuracy. Our results suggest that many key features of state representations can emerge via embodied sequence modeling, supporting an optimistic outlook for applications of sequence modeling objectives to more complex embodied decision-making domains.", "url": "https://arxiv.org/abs/2311.02171"}, {"metadata": {"arXiv": "2311.02194", "Date": "Fri, 03 Nov 2023 18:56:48 ", "Title": "AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation", "Authors": ["Daiki E. Matsunaga", "Jongmin Lee", "Jaeseok Yoon", "Stefanos Leonardos", "Pieter Abbeel", "Kee-Eung Kim"], "Categories": "cs.LG cs.AI", "Comments": ["31 pages", "12 figures", "Accepted at NeurIPS 2023"]}, "abstract": "One of the main challenges in offline Reinforcement Learning (RL) is the distribution shift that arises from the learned policy deviating from the data collection policy. This is often addressed by avoiding out-of-distribution (OOD) actions during policy improvement as their presence can lead to substantial performance degradation. This challenge is amplified in the offline Multi-Agent RL (MARL) setting since the joint action space grows exponentially with the number of agents. To avoid this curse of dimensionality, existing MARL methods adopt either value decomposition methods or fully decentralized training of individual agents. However, even when combined with standard conservatism principles, these methods can still result in the selection of OOD joint actions in offline MARL. To this end, we introduce AlberDICE, an offline MARL algorithm that alternatively performs centralized training of individual agents based on stationary distribution optimization. AlberDICE circumvents the exponential complexity of MARL by computing the best response of one agent at a time while effectively avoiding OOD joint action selection. Theoretically, we show that the alternating optimization procedure converges to Nash policies. In the experiments, we demonstrate that AlberDICE significantly outperforms baseline algorithms on a standard suite of MARL benchmarks.", "url": "https://arxiv.org/abs/2311.02194"}, {"metadata": {"arXiv": "2311.02198", "Date": "Fri, 03 Nov 2023 19:03:20 ", "Title": "Imitation Bootstrapped Reinforcement Learning", "Authors": ["Hengyuan Hu", "Suvir Mirchandani", "Dorsa Sadigh"], "Categories": "cs.LG cs.AI"}, "abstract": "Despite the considerable potential of reinforcement learning (RL), robotics control tasks predominantly rely on imitation learning (IL) owing to its better sample efficiency. However, given the high cost of collecting extensive demonstrations, RL is still appealing if it can utilize limited imitation data for efficient autonomous self-improvement. Existing RL methods that utilize demonstrations either initialize the replay buffer with demonstrations and oversample them during RL training, which does not benefit from the generalization potential of modern IL methods, or pretrain the RL policy with IL on the demonstrations, which requires additional mechanisms to prevent catastrophic forgetting during RL fine-tuning. We propose imitation bootstrapped reinforcement learning (IBRL), a novel framework that first trains an IL policy on a limited number of demonstrations and then uses it to propose alternative actions for both online exploration and target value bootstrapping. IBRL achieves SoTA performance and sample efficiency on 7 challenging sparse reward continuous control tasks in simulation while learning directly from pixels. As a highlight of our method, IBRL achieves $6.4\\times$ higher success rate than RLPD, a strong method that combines the idea of oversampling demonstrations with modern RL improvements, under the budget of 10 demos and 100K interactions in the challenging PickPlaceCan task in the Robomimic benchmark.", "url": "https://arxiv.org/abs/2311.02198"}, {"metadata": {"arXiv": "2311.02215", "Date": "Fri, 03 Nov 2023 20:03:54 ", "Title": "Towards model-free RL algorithms that scale well with unstructured data", "Authors": ["Joseph Modayil and Zaheer Abbas"], "Categories": "cs.LG cs.AI"}, "abstract": "Conventional reinforcement learning (RL) algorithms exhibit broad generality in their theoretical formulation and high performance on several challenging domains when combined with powerful function approximation. However, developing RL algorithms that perform well across problems with unstructured observations at scale remains challenging because most function approximation methods rely on externally provisioned knowledge about the structure of the input for good performance (e.g. convolutional networks, graph neural networks, tile-coding). A common practice in RL is to evaluate algorithms on a single problem, or on problems with limited variation in the observation scale. RL practitioners lack a systematic way to study how well a single RL algorithm performs when instantiated across a range of problem scales, and they lack function approximation techniques that scale well with unstructured observations. We address these limitations by providing environments and algorithms to study scaling for unstructured observation vectors and flat action spaces. We introduce a family of combinatorial RL problems with an exponentially large state space and high-dimensional dynamics but where linear computation is sufficient to learn a (nonlinear) value function estimate for performant control. We provide an algorithm that constructs reward-relevant general value function (GVF) questions to find and exploit predictive structure directly from the experience stream. In an empirical evaluation of the approach on synthetic problems, we observe a sample complexity that scales linearly with the observation size. The proposed algorithm reliably outperforms a conventional deep RL algorithm on these scaling problems, and they exhibit several desirable auxiliary properties. These results suggest new algorithmic mechanisms by which algorithms can learn at scale from unstructured data.", "url": "https://arxiv.org/abs/2311.02215"}, {"metadata": {"arXiv": "2311.02227", "Date": "Fri, 03 Nov 2023 20:32:30 ", "Title": "State-wise Safe Reinforcement Learning With Pixel Observations", "Authors": ["Simon Sinong Zhan", "Yixuan Wang", "Qingyuan Wu", "Ruochen Jiao", "Chao Huang", "Qi Zhu"], "Categories": "cs.LG cs.AI cs.SY eess.SY", "Comments": ["10 pages", "6 figures"]}, "abstract": "Reinforcement Learning(RL) in the context of safe exploration has long grappled with the challenges of the delicate balance between maximizing rewards and minimizing safety violations, the complexities arising from contact-rich or non-smooth environments, and high-dimensional pixel observations. Furthermore, incorporating state-wise safety constraints in the exploration and learning process, where the agent is prohibited from accessing unsafe regions without prior knowledge, adds an additional layer of complexity. In this paper, we propose a novel pixel-observation safe RL algorithm that efficiently encodes state-wise safety constraints with unknown hazard regions through the introduction of a latent barrier function learning mechanism. As a joint learning framework, our approach first involves constructing a latent dynamics model with low-dimensional latent spaces derived from pixel observations. Subsequently, we build and learn a latent barrier function on top of the latent dynamics and conduct policy optimization simultaneously, thereby improving both safety and the total expected return. Experimental evaluations on the safety-gym benchmark suite demonstrate that our proposed method significantly reduces safety violations throughout the training process and demonstrates faster safety convergence compared to existing methods while achieving competitive results in reward return.", "url": "https://arxiv.org/abs/2311.02227"}, {"metadata": {"arXiv": "2311.02251", "Date": "Fri, 03 Nov 2023 21:52:05 ", "Title": "The Potential of Wearable Sensors for Assessing Patient Acuity in Intensive Care Unit (ICU)", "Authors": ["Jessica Sena", "Mohammad Tahsin Mostafiz", "Jiaqing Zhang", "Andrea Davidson", "Sabyasachi Bandyopadhyay", "Ren Yuanfang", "Tezcan Ozrazgat-Baslanti", "Benjamin Shickel", "Tyler Loftus", "William Robson Schwartz", "Azra Bihorac and Parisa Rashidi"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "Acuity assessments are vital in critical care settings to provide timely interventions and fair resource allocation. Traditional acuity scores rely on manual assessments and documentation of physiological states, which can be time-consuming, intermittent, and difficult to use for healthcare providers. Furthermore, such scores do not incorporate granular information such as patients' mobility level, which can indicate recovery or deterioration in the ICU. We hypothesized that existing acuity scores could be potentially improved by employing Artificial Intelligence (AI) techniques in conjunction with Electronic Health Records (EHR) and wearable sensor data. In this study, we evaluated the impact of integrating mobility data collected from wrist-worn accelerometers with clinical data obtained from EHR for developing an AI-driven acuity assessment score. Accelerometry data were collected from 86 patients wearing accelerometers on their wrists in an academic hospital setting. The data was analyzed using five deep neural network models: VGG, ResNet, MobileNet, SqueezeNet, and a custom Transformer network. These models outperformed a rule-based clinical score (SOFA= Sequential Organ Failure Assessment) used as a baseline, particularly regarding the precision, sensitivity, and F1 score. The results showed that while a model relying solely on accelerometer data achieved limited performance (AUC 0.50, Precision 0.61, and F1-score 0.68), including demographic information with the accelerometer data led to a notable enhancement in performance (AUC 0.69, Precision 0.75, and F1-score 0.67). This work shows that the combination of mobility and patient information can successfully differentiate between stable and unstable states in critically ill patients.", "url": "https://arxiv.org/abs/2311.02251"}, {"metadata": {"arXiv": "2311.02253", "Date": "Fri, 03 Nov 2023 21:55:33 ", "Title": "Comparative Knowledge Distillation", "Authors": ["Alex Wilf", "Alex Tianyi Xu", "Paul Pu Liang", "Alexander Obolenskiy", "Daniel Fried", "Louis-Philippe Morency"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2310.13011"]}, "abstract": "In the era of large scale pretrained models, Knowledge Distillation (KD) serves an important role in transferring the wisdom of computationally heavy teacher models to lightweight, efficient student models while preserving performance. Traditional KD paradigms, however, assume readily available access to teacher models for frequent inference -- a notion increasingly at odds with the realities of costly, often proprietary, large scale models. Addressing this gap, our paper considers how to minimize the dependency on teacher model inferences in KD in a setting we term Few Teacher Inference Knowledge Distillation (FTI KD). We observe that prevalent KD techniques and state of the art data augmentation strategies fall short in this constrained setting. Drawing inspiration from educational principles that emphasize learning through comparison, we propose Comparative Knowledge Distillation (CKD), which encourages student models to understand the nuanced differences in a teacher model's interpretations of samples. Critically, CKD provides additional learning signals to the student without making additional teacher calls. We also extend the principle of CKD to groups of samples, enabling even more efficient learning from limited teacher calls. Empirical evaluation across varied experimental settings indicates that CKD consistently outperforms state of the art data augmentation and KD techniques.", "url": "https://arxiv.org/abs/2311.02253"}, {"metadata": {"arXiv": "2311.02268", "Date": "Fri, 03 Nov 2023 23:12:57 ", "Title": "LLMs-augmented Contextual Bandit", "Authors": ["Ali Baheri", "Cecilia O. Alm"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by the Foundation Models for Decision Making workshop at NeurIPS 2023"]}, "abstract": "Contextual bandits have emerged as a cornerstone in reinforcement learning, enabling systems to make decisions with partial feedback. However, as contexts grow in complexity, traditional bandit algorithms can face challenges in adequately capturing and utilizing such contexts. In this paper, we propose a novel integration of large language models (LLMs) with the contextual bandit framework. By leveraging LLMs as an encoder, we enrich the representation of the context, providing the bandit with a denser and more informative view. Preliminary results on synthetic datasets demonstrate the potential of this approach, showing notable improvements in cumulative rewards and reductions in regret compared to traditional bandit algorithms. This integration not only showcases the capabilities of LLMs in reinforcement learning but also opens the door to a new era of contextually-aware decision systems.", "url": "https://arxiv.org/abs/2311.02268"}, {"metadata": {"arXiv": "2311.02287", "Date": "Sat, 04 Nov 2023 00:44:40 ", "Title": "Predicting Ground Reaction Force from Inertial Sensors", "Authors": ["Bowen Song", "Marco Paolieri", "Harper E. Stewart", "Leana Golubchik", "Jill L. McNitt-Gray", "Vishal Misra", "Devavrat Shah"], "Categories": "cs.LG cs.AI"}, "abstract": "The study of ground reaction forces (GRF) is used to characterize the mechanical loading experienced by individuals in movements such as running, which is clinically applicable to identify athletes at risk for stress-related injuries. Our aim in this paper is to determine if data collected with inertial measurement units (IMUs), that can be worn by athletes during outdoor runs, can be used to predict GRF with sufficient accuracy to allow the analysis of its derived biomechanical variables (e.g., contact time and loading rate). In this paper, we consider lightweight approaches in contrast to state-of-the-art prediction using LSTM neural networks. Specifically, we compare use of LSTMs to k-Nearest Neighbors (KNN) regression as well as propose a novel solution, SVD Embedding Regression (SER), using linear regression between singular value decomposition embeddings of IMUs data (input) and GRF data (output). We evaluate the accuracy of these techniques when using training data collected from different athletes, from the same athlete, or both, and we explore the use of acceleration and angular velocity data from sensors at different locations (sacrum and shanks). Our results illustrate that simple machine learning methods such as SER and KNN can be similarly accurate or more accurate than LSTM neural networks, with much faster training times and hyperparameter optimization; in particular, SER and KNN are more accurate when personal training data are available, and KNN comes with benefit of providing provenance of prediction. Notably, the use of personal data reduces prediction errors of all methods for most biomechanical variables.", "url": "https://arxiv.org/abs/2311.02287"}, {"metadata": {"arXiv": "2311.02300", "Date": "Sat, 04 Nov 2023 02:07:47 ", "Title": "Successive Model-Agnostic Meta-Learning for Few-Shot Fault Time Series Prognosis", "Authors": ["Hai Su", "Jiajun Hu", "Songsen Yu"], "Categories": "cs.LG cs.AI"}, "abstract": "Meta learning is a promising technique for solving few-shot fault prediction problems, which have attracted the attention of many researchers in recent years. Existing meta-learning methods for time series prediction, which predominantly rely on random and similarity matching-based task partitioning, face three major limitations: (1) feature exploitation inefficiency; (2) suboptimal task data allocation; and (3) limited robustness with small samples. To overcome these limitations, we introduce a novel 'pseudo meta-task' partitioning scheme that treats a continuous time period of a time series as a meta-task, composed of multiple successive short time periods. Employing continuous time series as pseudo meta-tasks allows our method to extract more comprehensive features and relationships from the data, resulting in more accurate predictions. Moreover, we introduce a differential algorithm to enhance the robustness of our method across different datasets. Through extensive experiments on several fault and time series prediction datasets, we demonstrate that our approach substantially enhances prediction performance and generalization capability under both few-shot and general conditions.", "url": "https://arxiv.org/abs/2311.02300"}, {"metadata": {"arXiv": "2311.02303", "Date": "Sat, 04 Nov 2023 02:22:40 ", "Title": "MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning", "Authors": ["Bingchang Liu", "Chaoyu Chen", "Cong Liao", "Zi Gong", "Huan Wang", "Zhichao Lei", "Ming Liang", "Dajun Chen", "Min Shen", "Hailian Zhou", "Hang Yu", "Jianguo Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Code LLMs have emerged as a specialized research field, with remarkable studies dedicated to enhancing model's coding capabilities through fine-tuning on pre-trained models. Previous fine-tuning approaches were typically tailored to specific downstream tasks or scenarios, which meant separate fine-tuning for each task, requiring extensive training resources and posing challenges in terms of deployment and maintenance. Furthermore, these approaches failed to leverage the inherent interconnectedness among different code-related tasks. To overcome these limitations, we present a multi-task fine-tuning framework, MFTcoder, that enables simultaneous and parallel fine-tuning on multiple tasks. By incorporating various loss functions, we effectively address common challenges in multi-task learning, such as data imbalance, varying difficulty levels, and inconsistent convergence speeds. Extensive experiments have conclusively demonstrated that our multi-task fine-tuning approach outperforms both individual fine-tuning on single tasks and fine-tuning on a mixed ensemble of tasks. Moreover, MFTcoder offers efficient training capabilities, including efficient data tokenization modes and PEFT fine-tuning, resulting in significantly improved speed compared to traditional fine-tuning methods. MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, \\textsc{CodeFuse-CodeLLama-34B}, achieves an impressive pass@1 score of 74.4\\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\\%, zero-shot). MFTCoder is open-sourced at \\url{https://github.com/codefuse-ai/MFTCOder}", "url": "https://arxiv.org/abs/2311.02303"}, {"metadata": {"arXiv": "2311.02326", "Date": "Sat, 04 Nov 2023 04:57:13 ", "Title": "FragXsiteDTI: Revealing Responsible Segments in Drug-Target Interaction with Transformer-Driven Interpretation", "Authors": ["Ali Khodabandeh Yalabadi", "Mehdi Yazdani-Jahromi", "Niloofar Yousefi", "Aida Tayebi", "Sina Abdidizaji", "Ozlem Ozmen Garibay"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at the NeurIPS workshop (AI4D3) - 2023"]}, "abstract": "Drug-Target Interaction (DTI) prediction is vital for drug discovery, yet challenges persist in achieving model interpretability and optimizing performance. We propose a novel transformer-based model, FragXsiteDTI, that aims to address these challenges in DTI prediction. Notably, FragXsiteDTI is the first DTI model to simultaneously leverage drug molecule fragments and protein pockets. Our information-rich representations for both proteins and drugs offer a detailed perspective on their interaction. Inspired by the Perceiver IO framework, our model features a learnable latent array, initially interacting with protein binding site embeddings using cross-attention and later refined through self-attention and used as a query to the drug fragments in the drug's cross-attention transformer block. This learnable query array serves as a mediator and enables seamless information translation, preserving critical nuances in drug-protein interactions. Our computational results on three benchmarking datasets demonstrate the superior predictive power of our model over several state-of-the-art models. We also show the interpretability of our model in terms of the critical components of both target proteins and drug molecules within drug-target pairs.", "url": "https://arxiv.org/abs/2311.02326"}, {"metadata": {"arXiv": "2311.02357", "Date": "Sat, 04 Nov 2023 09:50:37 ", "Title": "Contrastive Deep Nonnegative Matrix Factorization for Community Detection", "Authors": ["Yuecheng Li", "Jialong Chen", "Chuan Chen", "Lei Yang", "Zibin Zheng"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["5 pages", "2 figures"]}, "abstract": "Recently, nonnegative matrix factorization (NMF) has been widely adopted for community detection, because of its better interpretability. However, the existing NMF-based methods have the following three problems: 1) they directly transform the original network into community membership space, so it is difficult for them to capture the hierarchical information; 2) they often only pay attention to the topology of the network and ignore its node attributes; 3) it is hard for them to learn the global structure information necessary for community detection. Therefore, we propose a new community detection algorithm, named Contrastive Deep Nonnegative Matrix Factorization (CDNMF). Firstly, we deepen NMF to strengthen its capacity for information extraction. Subsequently, inspired by contrastive learning, our algorithm creatively constructs network topology and node attributes as two contrasting views. Furthermore, we utilize a debiased negative sampling layer and learn node similarity at the community level, thereby enhancing the suitability of our model for community detection. We conduct experiments on three public real graph datasets and the proposed model has achieved better results than state-of-the-art methods. Code available at https://github.com/6lyc/CDNMF.git.", "url": "https://arxiv.org/abs/2311.02357"}, {"metadata": {"arXiv": "2311.02466", "Date": "Sat, 04 Nov 2023 17:54:15 ", "Title": "Multi-State Brain Network Discovery", "Authors": ["Hang Yin and Yao Su and Xinyue Liu and Thomas Hartvigsen and Yanhua Li and Xiangnan Kong"], "Categories": "cs.LG cs.AI", "Comments": ["Published as a regular paper at IEEE BigData 2023"]}, "abstract": "Brain network discovery aims to find nodes and edges from the spatio-temporal signals obtained by neuroimaging data, such as fMRI scans of human brains. Existing methods tend to derive representative or average brain networks, assuming observed signals are generated by only a single brain activity state. However, the human brain usually involves multiple activity states, which jointly determine the brain activities. The brain regions and their connectivity usually exhibit intricate patterns that are difficult to capture with only a single-state network. Recent studies find that brain parcellation and connectivity change according to the brain activity state. We refer to such brain networks as multi-state, and this mixture can help us understand human behavior. Thus, compared to a single-state network, a multi-state network can prevent us from losing crucial information of cognitive brain network. To achieve this, we propose a new model called MNGL (Multi-state Network Graphical Lasso), which successfully models multi-state brain networks by combining CGL (coherent graphical lasso) with GMM (Gaussian Mixture Model). Using both synthetic and real world ADHD 200 fMRI datasets, we demonstrate that MNGL outperforms recent state-of-the-art alternatives by discovering more explanatory and realistic results.", "url": "https://arxiv.org/abs/2311.02466"}, {"metadata": {"arXiv": "2311.02485", "Date": "Sat, 04 Nov 2023 19:11:25 ", "Title": "Uncertainty Quantification of Deep Learning for Spatiotemporal Data: Challenges and Opportunities", "Authors": ["Wenchong He and Zhe Jiang"], "Categories": "cs.LG cs.AI", "Comments": ["Oral presentation in UDM-KDD'23"]}, "abstract": "With the advancement of GPS, remote sensing, and computational simulations, large amounts of geospatial and spatiotemporal data are being collected at an increasing speed. Such emerging spatiotemporal big data assets, together with the recent progress of deep learning technologies, provide unique opportunities to transform society. However, it is widely recognized that deep learning sometimes makes unexpected and incorrect predictions with unwarranted confidence, causing severe consequences in high-stake decision-making applications (e.g., disaster management, medical diagnosis, autonomous driving). Uncertainty quantification (UQ) aims to estimate a deep learning model's confidence. This paper provides a brief overview of UQ of deep learning for spatiotemporal data, including its unique challenges and existing methods. We particularly focus on the importance of uncertainty sources. We identify several future research directions for spatiotemporal data.", "url": "https://arxiv.org/abs/2311.02485"}, {"metadata": {"arXiv": "2311.02492", "Date": "Sat, 04 Nov 2023 19:32:08 ", "Title": "Forecasting Post-Wildfire Vegetation Recovery in California using a Convolutional Long Short-Term Memory Tensor Regression Network", "Authors": ["Jiahe Liu", "Xiaodi Wang"], "Categories": "cs.LG cs.AI", "Comments": ["To be included in the 6th Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response at the 37th Conference on Neural Information Processing Systems"]}, "abstract": "The study of post-wildfire plant regrowth is essential for developing successful ecosystem recovery strategies. Prior research mainly examines key ecological and biogeographical factors influencing post-fire succession. This research proposes a novel approach for predicting and analyzing post-fire plant recovery. We develop a Convolutional Long Short-Term Memory Tensor Regression (ConvLSTMTR) network that predicts future Normalized Difference Vegetation Index (NDVI) based on short-term plant growth data after fire containment. The model is trained and tested on 104 major California wildfires occurring between 2013 and 2020, each with burn areas exceeding 3000 acres. The integration of ConvLSTM with tensor regression enables the calculation of an overall logistic growth rate k using predicted NDVI. Overall, our k-value predictions demonstrate impressive performance, with 50% of predictions exhibiting an absolute error of 0.12 or less, and 75% having an error of 0.24 or less. Finally, we employ Uniform Manifold Approximation and Projection (UMAP) and KNN clustering to identify recovery trends, offering insights into regions with varying rates of recovery. This study pioneers the combined use of tensor regression and ConvLSTM, and introduces the application of UMAP for clustering similar wildfires. This advances predictive ecological modeling and could inform future post-fire vegetation management strategies.", "url": "https://arxiv.org/abs/2311.02492"}, {"metadata": {"arXiv": "2311.02544", "Date": "Sun, 05 Nov 2023 02:11:07 ", "Title": "Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees", "Authors": ["Nianli Peng and Brandon Fain"], "Categories": "cs.LG cs.AI"}, "abstract": "We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm with provable guarantees for solving a single or multi-objective Markov Decision Process (MDP) where we want to maximize the expected value of a nonlinear function over accumulated rewards. This allows us to model fairness-aware welfare optimization for multi-objective reinforcement learning as well as risk-aware reinforcement learning with nonlinear Von Neumann-Morgenstern utility functions in the single objective setting. RA-E3 extends the classic E3 algorithm that solves MDPs with scalar rewards and linear preferences. We first state a distinct reward-aware version of value iteration that calculates a non-stationary policy that is approximately optimal for a given model of the environment. This sub-procedure is based on an extended form of Bellman optimality for nonlinear optimization that explicitly considers time and current accumulated reward. We then describe how to use this optimization procedure in a larger algorithm that must simultaneously learn a model of the environment. The algorithm learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.", "url": "https://arxiv.org/abs/2311.02544"}, {"metadata": {"arXiv": "2311.02561", "Date": "Sun, 05 Nov 2023 04:21:42 ", "Title": "Ego-Network Transformer for Subsequence Classification in Time Series Data", "Authors": ["Chin-Chia Michael Yeh", "Huiyuan Chen", "Yujie Fan", "Xin Dai", "Yan Zheng", "Vivian Lai", "Junpeng Wang", "Zhongfang Zhuang", "Liang Wang", "Wei Zhang", "Eamonn Keogh"], "Categories": "cs.LG cs.AI"}, "abstract": "Time series classification is a widely studied problem in the field of time series data mining. Previous research has predominantly focused on scenarios where relevant or foreground subsequences have already been extracted, with each subsequence corresponding to a single label. However, real-world time series data often contain foreground subsequences that are intertwined with background subsequences. Successfully classifying these relevant subsequences requires not only distinguishing between different classes but also accurately identifying the foreground subsequences amidst the background. To address this challenge, we propose a novel subsequence classification method that represents each subsequence as an ego-network, providing crucial nearest neighbor information to the model. The ego-networks of all subsequences collectively form a time series subsequence graph, and we introduce an algorithm to efficiently construct this graph. Furthermore, we have demonstrated the significance of enforcing temporal consistency in the prediction of adjacent subsequences for the subsequence classification problem. To evaluate the effectiveness of our approach, we conducted experiments using 128 univariate and 30 multivariate time series datasets. The experimental results demonstrate the superior performance of our method compared to alternative approaches. Specifically, our method outperforms the baseline on 104 out of 158 datasets.", "url": "https://arxiv.org/abs/2311.02561"}, {"metadata": {"arXiv": "2311.02565", "Date": "Sun, 05 Nov 2023 04:43:48 ", "Title": "KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy", "Authors": ["Qianxiong Xu", "Cheng Long", "Ziyue Li", "Sijie Ruan", "Rui Zhao", "Zhishuai Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Sensors are commonly deployed to perceive the environment. However, due to the high cost, sensors are usually sparsely deployed. Kriging is the tailored task to infer the unobserved nodes (without sensors) using the observed source nodes (with sensors). The essence of kriging task is transferability. Recently, several inductive spatio-temporal kriging methods have been proposed based on graph neural networks, being trained based on a graph built on top of observed nodes via pretext tasks such as masking nodes out and reconstructing them. However, the graph in training is inevitably much sparser than the graph in inference that includes all the observed and unobserved nodes. The learned pattern cannot be well generalized for inference, denoted as graph gap. To address this issue, we first present a novel Increment training strategy: instead of masking nodes (and reconstructing them), we add virtual nodes into the training graph so as to mitigate the graph gap issue naturally. Nevertheless, the empty-shell virtual nodes without labels could have bad-learned features and lack supervision signals. To solve these issues, we pair each virtual node with its most similar observed node and fuse their features together; to enhance the supervision signal, we construct reliable pseudo labels for virtual nodes. As a result, the learned pattern of virtual nodes could be safely transferred to real unobserved nodes for reliable kriging. We name our new Kriging model with Increment Training Strategy as KITS. Extensive experiments demonstrate that KITS consistently outperforms existing kriging methods by large margins, e.g., the improvement over MAE score could be as high as 18.33%.", "url": "https://arxiv.org/abs/2311.02565"}, {"metadata": {"arXiv": "2311.02621", "Date": "Sun, 05 Nov 2023 11:16:24 ", "Title": "AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios", "Authors": ["Daksh Dave", "Gauransh Sawhney", "Dhruv Khut", "Sahil Nawale", "Pushkar Aggrawal", "Prasenjit Bhavathankar"], "Categories": "cs.LG cs.AI cs.IR cs.IT math.IT", "Comments": ["6 pages", "1 figure", "1 table"]}, "abstract": "Artificial intelligence operations (AIOps) play a pivotal role in identifying, mitigating, and analyzing anomalous system behaviors and alerts. However, the research landscape in this field remains limited, leaving significant gaps unexplored. This study introduces a novel hybrid framework through an innovative algorithm that incorporates an unsupervised strategy. This strategy integrates Principal Component Analysis (PCA) and Artificial Neural Networks (ANNs) and uses a custom loss function to substantially enhance the effectiveness of log anomaly detection. The proposed approach encompasses the utilization of both simulated and real-world datasets, including logs from SockShop and Hadoop Distributed File System (HDFS). The experimental results are highly promising, demonstrating significant reductions in pseudo-positives. Moreover, this strategy offers notable advantages, such as the ability to process logs in their raw, unprocessed form, and the potential for further enhancements. The successful implementation of this approach showcases a remarkable reduction in anomalous logs, thus unequivocally establishing the efficacy of the proposed methodology. Ultimately, this study makes a substantial contribution to the advancement of log anomaly detection within AIOps platforms, addressing the critical need for effective and efficient log analysis in modern and complex systems.", "url": "https://arxiv.org/abs/2311.02621"}, {"metadata": {"arXiv": "2311.02631", "Date": "Sun, 05 Nov 2023 12:20:39 ", "Title": "A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery", "Authors": ["Dedong Li", "Ziyue Li", "Zhishuai Li", "Lei Bai", "Qingyuan Gong", "Lijun Sun", "Wolfgang Ketter", "Rui Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted in ACM SIGSPATIAL 2023"]}, "abstract": "The trajectory on the road traffic is commonly collected at a low sampling rate, and trajectory recovery aims to recover a complete and continuous trajectory from the sparse and discrete inputs. Recently, sequential language models have been innovatively adopted for trajectory recovery in a pre-trained manner: it learns road segment representation vectors, which will be used in the downstream tasks. However, existing methods are incapable of handling complex trajectories: when the trajectory crosses remote road segments or makes several turns, which we call critical nodes, the quality of learned representations deteriorates, and the recovered trajectories skip the critical nodes. This work is dedicated to offering a more robust trajectory recovery for complex trajectories. Firstly, we define the trajectory complexity based on the detour score and entropy score and construct the complexity-aware semantic graphs correspondingly. Then, we propose a Multi-view Graph and Complexity Aware Transformer (MGCAT) model to encode these semantics in trajectory pre-training from two aspects: 1) adaptively aggregate the multi-view graph features considering trajectory pattern, and 2) higher attention to critical nodes in a complex trajectory. Such that, our MGCAT is perceptual when handling the critical scenario of complex trajectories. Extensive experiments are conducted on large-scale datasets. The results prove that our method learns better representations for trajectory recovery, with 5.22% higher F1-score overall and 8.16% higher F1-score for complex trajectories particularly. The code is available at https://github.com/bonaldli/ComplexTraj.", "url": "https://arxiv.org/abs/2311.02631"}, {"metadata": {"arXiv": "2311.02687", "Date": "Sun, 05 Nov 2023 15:54:17 ", "Title": "Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning", "Authors": ["Xiaojun Guo", "Yifei Wang", "Zeming Wei", "Yisen Wang"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "With the prosperity of contrastive learning for visual representation learning (VCL), it is also adapted to the graph domain and yields promising performance. However, through a systematic study of various graph contrastive learning (GCL) methods, we observe that some common phenomena among existing GCL methods that are quite different from the original VCL methods, including 1) positive samples are not a must for GCL; 2) negative samples are not necessary for graph classification, neither for node classification when adopting specific normalization modules; 3) data augmentations have much less influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian noise) can also attain fairly good performance. By uncovering how the implicit inductive bias of GNNs works in contrastive learning, we theoretically provide insights into the above intriguing properties of GCL. Rather than directly porting existing VCL methods to GCL, we advocate for more attention toward the unique architecture of graph learning and consider its implicit influence when designing GCL methods. Code is available at https: //github.com/PKU-ML/ArchitectureMattersGCL.", "url": "https://arxiv.org/abs/2311.02687"}, {"metadata": {"arXiv": "2311.02741", "Date": "Sun, 05 Nov 2023 19:12:08 ", "Title": "Learning Independently from Causality in Multi-Agent Environments", "Authors": ["Rafael Pina", "Varuna De Silva and Corentin Artaud"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["Proceedings of the 12th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2023)"]}, "abstract": "Multi-Agent Reinforcement Learning (MARL) comprises an area of growing interest in the field of machine learning. Despite notable advances, there are still problems that require investigation. The lazy agent pathology is a famous problem in MARL that denotes the event when some of the agents in a MARL team do not contribute to the common goal, letting the teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to create the bridge between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralised MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried show how this relation can be used to improve independent agents in MARL, resulting not only on better performances as a team but also on the rise of more intelligent behaviours on individual agents.", "url": "https://arxiv.org/abs/2311.02741"}, {"metadata": {"arXiv": "2311.02775", "Date": "Sun, 05 Nov 2023 21:43:02 ", "Title": "ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs", "Authors": ["Yann Hicke", "Anmol Agarwal", "Qianou Ma", "Paul Denny"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "To address the challenges of scalable and intelligent question-answering (QA), we introduce an innovative solution that leverages open-source Large Language Models (LLMs) to ensure data privacy. We use models from the LLaMA-2 family and augmentations including retrieval augmented generation (RAG), supervised fine-tuning (SFT), and an alternative to reinforcement learning with human feedback (RLHF). We perform our experiments on a Piazza dataset from an introductory CS course with 10k QA pairs and 1.5k pairs of preferences data and conduct both human evaluations and automatic LLM evaluations on a small subset. We find preliminary evidence that modeling techniques collectively enhance the quality of answers by 33%, and RAG is an impactful addition. This work paves the way for the development of ChaTA, an intelligent QA assistant customizable for courses with an online QA platform.", "url": "https://arxiv.org/abs/2311.02775"}, {"metadata": {"arXiv": "2311.02807", "Date": "Mon, 06 Nov 2023 00:21:44 ", "Title": "QualEval: Qualitative Evaluation for Model Improvement", "Authors": ["Vishvak Murahari", "Ameet Deshpande", "Peter Clark", "Tanmay Rajpurohit", "Ashish Sabharwal", "Karthik Narasimhan", "Ashwin Kalyan"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Quantitative evaluation metrics have traditionally been pivotal in gauging the advancements of artificial intelligence systems, including large language models (LLMs). However, these metrics have inherent limitations. Given the intricate nature of real-world tasks, a single scalar to quantify and compare is insufficient to capture the fine-grained nuances of model behavior. Metrics serve only as a way to compare and benchmark models, and do not yield actionable diagnostics, thus making the model improvement process challenging. Model developers find themselves amid extensive manual efforts involving sifting through vast datasets and attempting hit-or-miss adjustments to training data or setups. In this work, we address the shortcomings of quantitative metrics by proposing QualEval, which augments quantitative scalar metrics with automated qualitative evaluation as a vehicle for model improvement. QualEval uses a powerful LLM reasoner and our novel flexible linear programming solver to generate human-readable insights that when applied, accelerate model improvement. The insights are backed by a comprehensive dashboard with fine-grained visualizations and human-interpretable analyses. We corroborate the faithfulness of QualEval by demonstrating that leveraging its insights, for example, improves the absolute performance of the Llama 2 model by up to 15% points relative on a challenging dialogue task (DialogSum) when compared to baselines. QualEval successfully increases the pace of model development, thus in essence serving as a data-scientist-in-a-box. Given the focus on critiquing and improving current evaluation metrics, our method serves as a refreshingly new technique for both model evaluation and improvement.", "url": "https://arxiv.org/abs/2311.02807"}, {"metadata": {"arXiv": "2311.02840", "Date": "Mon, 06 Nov 2023 02:59:49 ", "Title": "Saturn: Efficient Multi-Large-Model Deep Learning", "Authors": ["Kabir Nagrecha and Arun Kumar"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["4 pages", "1 figure", "2 tables. Accepted to BayLearn 2023. Abstract of this paper: https://adalabucsd.github.io/papers/TR_2023_Saturn.pdf"]}, "abstract": "In this paper, we propose Saturn, a new data system to improve the efficiency of multi-large-model training (e.g., during model selection/hyperparameter optimization). We first identify three key interconnected systems challenges for users building large models in this setting -- parallelism technique selection, distribution of GPUs over jobs, and scheduling. We then formalize these as a joint problem, and build a new system architecture to tackle these challenges simultaneously. Our evaluations show that our joint-optimization approach yields 39-49% lower model selection runtimes than typical current DL practice.", "url": "https://arxiv.org/abs/2311.02840"}, {"metadata": {"arXiv": "2311.02916", "Date": "Mon, 06 Nov 2023 07:08:51 ", "Title": "Virtual Action Actor-Critic Framework for Exploration (Student Abstract)", "Authors": ["Bumgeun Park", "Taeyoung Kim", "Quoc-Vinh Lai-Dang", "Dongsoo Har"], "Categories": "cs.LG cs.AI"}, "abstract": "Efficient exploration for an agent is challenging in reinforcement learning (RL). In this paper, a novel actor-critic framework namely virtual action actor-critic (VAAC), is proposed to address the challenge of efficient exploration in RL. This work is inspired by humans' ability to imagine the potential outcomes of their actions without actually taking them. In order to emulate this ability, VAAC introduces a new actor called virtual actor (VA), alongside the conventional actor-critic framework. Unlike the conventional actor, the VA takes the virtual action to anticipate the next state without interacting with the environment. With the virtual policy following a Gaussian distribution, the VA is trained to maximize the anticipated novelty of the subsequent state resulting from a virtual action. If any next state resulting from available actions does not exhibit high anticipated novelty, training the VA leads to an increase in the virtual policy entropy. Hence, high virtual policy entropy represents that there is no room for exploration. The proposed VAAC aims to maximize a modified Q function, which combines cumulative rewards and the negative sum of virtual policy entropy. Experimental results show that the VAAC improves the exploration performance compared to existing algorithms.", "url": "https://arxiv.org/abs/2311.02916"}, {"metadata": {"arXiv": "2311.02971", "Date": "Mon, 06 Nov 2023 09:17:18 ", "Title": "TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications", "Authors": ["David Salinas and Nick Erickson"], "Categories": "cs.LG cs.AI"}, "abstract": "We introduce TabRepo, a new dataset of tabular model evaluations and predictions. TabRepo contains the predictions and metrics of 1206 models evaluated on 200 regression and classification datasets. We illustrate the benefit of our datasets in multiple ways. First, we show that it allows to perform analysis such as comparing Hyperparameter Optimization against current AutoML systems while also considering ensembling at no cost by using precomputed model predictions. Second, we show that our dataset can be readily leveraged to perform transfer-learning. In particular, we show that applying standard transfer-learning techniques allows to outperform current state-of-the-art tabular systems in accuracy, runtime and latency.", "url": "https://arxiv.org/abs/2311.02971"}, {"metadata": {"arXiv": "2311.03033", "Date": "Mon, 06 Nov 2023 11:13:17 ", "Title": "Beyond Words: A Mathematical Framework for Interpreting Large Language Models", "Authors": ["Javier Gonz\\'alez and Aditya V. Nori"], "Categories": "cs.LG cs.AI", "Comments": ["4 figures", "18 pages"]}, "abstract": "Large language models (LLMs) are powerful AI tools that can generate and comprehend natural language text and other complex information. However, the field lacks a mathematical framework to systematically describe, compare and improve LLMs. We propose Hex a framework that clarifies key terms and concepts in LLM research, such as hallucinations, alignment, self-verification and chain-of-thought reasoning. The Hex framework offers a precise and consistent way to characterize LLMs, identify their strengths and weaknesses, and integrate new findings. Using Hex, we differentiate chain-of-thought reasoning from chain-of-thought prompting and establish the conditions under which they are equivalent. This distinction clarifies the basic assumptions behind chain-of-thought prompting and its implications for methods that use it, such as self-verification and prompt programming. Our goal is to provide a formal framework for LLMs that can help both researchers and practitioners explore new possibilities for generative AI. We do not claim to have a definitive solution, but rather a tool for opening up new research avenues. We argue that our formal definitions and results are crucial for advancing the discussion on how to build generative AI systems that are safe, reliable, fair and robust, especially in domains like healthcare and software engineering.", "url": "https://arxiv.org/abs/2311.03033"}, {"metadata": {"arXiv": "2311.03040", "Date": "Mon, 06 Nov 2023 11:24:27 ", "Title": "Grouping Local Process Models", "Authors": ["Viki Peeva", "Wil M.P. van der Aalst"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "5 figures"], "ACM-class": "I.5.3"}, "abstract": "In recent years, process mining emerged as a proven technology to analyze and improve operational processes. An expanding range of organizations using process mining in their daily operation brings a broader spectrum of processes to be analyzed. Some of these processes are highly unstructured, making it difficult for traditional process discovery approaches to discover a start-to-end model describing the entire process. Therefore, the subdiscipline of Local Process Model (LPM) discovery tries to build a set of LPMs, i.e., smaller models that explain sub-behaviors of the process. However, like other pattern mining approaches, LPM discovery algorithms also face the problems of model explosion and model repetition, i.e., the algorithms may create hundreds if not thousands of models, and subsets of them are close in structure or behavior. This work proposes a three-step pipeline for grouping similar LPMs using various process model similarity measures. We demonstrate the usefulness of grouping through a real-life case study, and analyze the impact of different measures, the gravity of repetition in the discovered LPMs, and how it improves after grouping on multiple real event logs.", "url": "https://arxiv.org/abs/2311.03040"}, {"metadata": {"arXiv": "2311.03260", "Date": "Mon, 06 Nov 2023 16:47:17 ", "Title": "From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach", "Authors": ["Tuan Nguyen", "Tan M. Nguyen", "Hirotada Honda", "Takashi Sano", "Vinh Nguyen", "Shugo Nakamura"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.", "url": "https://arxiv.org/abs/2311.03260"}, {"metadata": {"arXiv": "2311.03285", "Date": "Mon, 06 Nov 2023 17:26:17 ", "Title": "S-LoRA: Serving Thousands of Concurrent LoRA Adapters", "Authors": ["Ying Sheng", "Shiyi Cao", "Dacheng Li", "Coleman Hooper", "Nicholas Lee", "Shuo Yang", "Christopher Chou", "Banghua Zhu", "Lianmin Zheng", "Kurt Keutzer", "Joseph E. Gonzalez", "Ion Stoica"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "The \"pretrain-then-finetune\" paradigm is commonly adopted in the deployment of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model. We observe that this paradigm presents significant opportunities for batched inference during serving. To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude. As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services.", "url": "https://arxiv.org/abs/2311.03285"}, {"metadata": {"arXiv": "2311.03309", "Date": "Mon, 06 Nov 2023 17:58:47 ", "Title": "Neural Structure Learning with Stochastic Differential Equations", "Authors": ["Benjie Wang", "Joel Jennings", "Wenbo Gong"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science. The dynamics of such systems are often best described using continuous-time stochastic processes. Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals. These mismatched assumptions can often lead to incorrect learned structures and models. In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures. This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points. Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits. Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals.", "url": "https://arxiv.org/abs/2311.03309"}, {"metadata": {"arXiv": "2311.03340", "Date": "Mon, 06 Nov 2023 18:44:55 ", "Title": "Embedding First Order Logic into Kernel Machines", "Authors": ["Michelangelo Diligenti", "Marco Gori", "Marco Maggini and Leonardo Rigutini"], "Categories": "cs.LG cs.AI cs.LO", "Comments": ["The 20th International Conference on Inductive Logic Programming (ILP 2010). Florence", "Italy. June 27-30 2010"], "Journal-ref": "Proceedings of The 20th International Conference on Inductive Logic Programming (ILP 2010)"}, "abstract": "In this paper we propose a general framework to integrate supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines. In particular, we consider a multi-task learning scheme where multiple predicates defined on a set of objects are to be jointly learned from examples, enforcing a set of FOL constraints on the admissible configurations of their values. The predicates are defined on the feature spaces, in which the input objects are represented, and can be either known a priori or approximated by an appropriate kernel-based learner. A general approach is presented to convert the FOL clauses into a continuous implementation that can deal with the outputs computed by the kernel-based predicates. The learning problem is formulated as a semi-supervised task that requires the optimization in the primal of a loss function that combines a fitting loss measure on the supervised examples, a regularization term, and a penalty term that enforces the constraints on both the supervised and unsupervised examples. Unfortunately, the penalty term is not convex and it can hinder the optimization process. However, it is possible to avoid poor solutions by using a two stage learning schema, in which the supervised examples are learned first and then the constraints are enforced.", "url": "https://arxiv.org/abs/2311.03340"}, {"metadata": {"arXiv": "2311.02379", "Date": "Sat, 04 Nov 2023 11:21:38 ", "Title": "Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models", "Authors": ["Kun Chu", "Xufeng Zhao", "Cornelius Weber", "Mengdi Li", "Stefan Wermter"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["CoRL 2023 Workshop (oral)"]}, "abstract": "Reinforcement Learning (RL) plays an important role in the robotic manipulation domain since it allows self-learning from trial-and-error interactions with the environment. Still, sample efficiency and reward specification seriously limit its potential. One possible solution involves learning from expert guidance. However, obtaining a human expert is impractical due to the high cost of supervising an RL agent, and developing an automatic supervisor is a challenging endeavor. Large Language Models (LLMs) demonstrate remarkable abilities to provide human-like feedback on user inputs in natural language. Nevertheless, they are not designed to directly control low-level robotic motions, as their pretraining is based on vast internet data rather than specific robotics data. In this paper, we introduce the Lafite-RL (Language agent feedback interactive Reinforcement Learning) framework, which enables RL agents to learn robotic tasks efficiently by taking advantage of LLMs' timely feedback. Our experiments conducted on RLBench tasks illustrate that, with simple prompt design in natural language, the Lafite-RL agent exhibits improved learning capabilities when guided by an LLM. It outperforms the baseline in terms of both learning efficiency and success rate, underscoring the efficacy of the rewards provided by an LLM.", "url": "https://arxiv.org/abs/2311.02379"}, {"metadata": {"arXiv": "2311.02475", "Date": "Sat, 04 Nov 2023 18:16:18 ", "Title": "Constrained Equation Learner Networks for Precision-Preserving Extrapolation of Robotic Skills", "Authors": ["Hector Perez-Villeda", "Justus Piater", "and Matteo Saveriano"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["18 pages", "10 figures. To be submitted to IEEE Transactions on Robotics (T-RO)"]}, "abstract": "In Programming by Demonstration, the robot learns novel skills from human demonstrations. After learning, the robot should be able not only to reproduce the skill, but also to generalize it to shifted domains without collecting new training data. Adaptation to similar domains has been investigated in the literature; however, an open problem is how to adapt learned skills to different conditions that are outside of the data distribution, and, more important, how to preserve the precision of the desired adaptations. This paper presents a novel supervised learning framework called Constrained Equation Learner Networks that addresses the trajectory adaptation problem in Programming by Demonstrations from a constrained regression perspective. While conventional approaches for constrained regression use one kind of basis function, e.g., Gaussian, we exploit Equation Learner Networks to learn a set of analytical expressions and use them as basis functions. These basis functions are learned from demonstration with the objective to minimize deviations from the training data while imposing constraints that represent the desired adaptations, like new initial or final points or maintaining the trajectory within given bounds. Our approach addresses three main difficulties in adapting robotic trajectories: 1) minimizing the distortion of the trajectory for new adaptations; 2) preserving the precision of the adaptations; and 3) dealing with the lack of intuition about the structure of basis functions. We validate our approach both in simulation and in real experiments in a set of robotic tasks that require adaptation due to changes in the environment, and we compare obtained results with two existing approaches. Performed experiments show that Constrained Equation Learner Networks outperform state of the art approaches by increasing generalization and adaptability of robotic skills.", "url": "https://arxiv.org/abs/2311.02475"}, {"metadata": {"arXiv": "2311.03293", "Date": "Mon, 06 Nov 2023 17:35:42 ", "Title": "Learning Reusable Manipulation Strategies", "Authors": ["Jiayuan Mao", "Joshua B. Tenenbaum", "Tom\\'as Lozano-P\\'erez", "Leslie Pack Kaelbling"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["CoRL 2023. Project page: https://concepts-ai.com/p/mechanisms/"]}, "abstract": "Humans demonstrate an impressive ability to acquire and generalize manipulation \"tricks.\" Even from a single demonstration, such as using soup ladles to reach for distant objects, we can apply this skill to new scenarios involving different object positions, sizes, and categories (e.g., forks and hammers). Additionally, we can flexibly combine various skills to devise long-term plans. In this paper, we present a framework that enables machines to acquire such manipulation skills, referred to as \"mechanisms,\" through a single demonstration and self-play. Our key insight lies in interpreting each demonstration as a sequence of changes in robot-object and object-object contact modes, which provides a scaffold for learning detailed samplers for continuous parameters. These learned mechanisms and samplers can be seamlessly integrated into standard task and motion planners, enabling their compositional use.", "url": "https://arxiv.org/abs/2311.03293"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

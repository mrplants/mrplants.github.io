<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.16700", "Date": "Tue, 15 Aug 2023 07:52:24 ", "Title": "Framework and Model Analysis on Bengali Document Layout Analysis Dataset: BaDLAD", "Authors": ["Kazi Reyazul Hasan (1)", "Mubasshira Musarrat (1)", "Sadif Ahmed (1) and Shahriar Raj (1) ((1) Bangladesh University of Engineering and Technology)"], "Categories": "cs.CV cs.LG", "Comments": ["5 pages", "6 figures", "uses IEEEtran.cls"], "ACM-class": "I.4.6"}, "abstract": "This study focuses on understanding Bengali Document Layouts using advanced computer programs: Detectron2, YOLOv8, and SAM. We looked at lots of different Bengali documents in our study. Detectron2 is great at finding and separating different parts of documents, like text boxes and paragraphs. YOLOv8 is good at figuring out different tables and pictures. We also tried SAM, which helps us understand tricky layouts. We tested these programs to see how well they work. By comparing their accuracy and speed, we learned which one is good for different types of documents. Our research helps make sense of complex layouts in Bengali documents and can be useful for other languages too.", "url": "https://arxiv.org/abs/2309.16700"}, {"metadata": {"arXiv": "2309.16705", "Date": "Thu, 17 Aug 2023 03:14:00 ", "Title": "Decoding Imagery: Unleashing Large Language Models", "Authors": ["David Noever and Samantha Elizabeth Miller Noever"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "In a challenge-response study, we subjected Google Bard to 64 visual challenges designed to probe multimodal Large Language Models (LLMs). The challenges spanned diverse categories, including \"Visual Situational Reasoning,\" \"Visual Text Reasoning,\" and \"Next Scene Prediction,\" among others, to discern Bard's competence in melding visual and linguistic analyses. Our findings indicate that Bard tends to rely on making educated guesses about visuals, especially when determining cues from images. Unlike other models like GPT4, Bard does not appear to rely on optical character recognition libraries like Tesseract but recognizes text in complex images like deep learning models such as Google Lens and Visual API. Significantly Bard can solve CAPTCHAs visually that ChatGPT fails to understand, recommending Tesseract solutions. Moreover, while the Bard model proposes solutions based on visual input, it cannot recreate or modify the original visual objects to support its conclusions. Bard fails to redraw ASCII art that the text can describe or capture a simple Tic Tac Toe grid it claims to analyze for the next moves. This study provides experimental insights into the current capacities and areas for improvement in multimodal LLMs.", "url": "https://arxiv.org/abs/2309.16705"}, {"metadata": {"arXiv": "2309.16708", "Date": "Thu, 17 Aug 2023 10:47:15 ", "Title": "Automatic Cadastral Boundary Detection of Very High Resolution Images Using Mask R-CNN", "Authors": ["Neda Rahimpour Anaraki", "Alireza Azadbakht", "Maryam Tahmasbi", "Hadi Farahani", "Saeed Reza Kheradpisheh", "Alireza Javaheri"], "Categories": "cs.CV cs.LG"}, "abstract": "Recently, there has been a high demand for accelerating and improving the detection of automatic cadastral mapping. As this problem is in its starting point, there are many methods of computer vision and deep learning that have not been considered yet. In this paper, we focus on deep learning and provide three geometric post-processing methods that improve the quality of the work. Our framework includes two parts, each of which consists of a few phases. Our solution to this problem uses instance segmentation. In the first part, we use Mask R-CNN with the backbone of pre-trained ResNet-50 on the ImageNet dataset. In the second phase, we apply three geometric post-processing methods to the output of the first part to get better overall output. Here, we also use computational geometry to introduce a new method for simplifying lines which we call it pocket-based simplification algorithm. For evaluating the quality of our solution, we use popular formulas in this field which are recall, precision and F-score. The highest recall we gain is 95 percent which also maintains high Precision of 72 percent. This resulted in an F-score of 82 percent. Implementing instance segmentation using Mask R-CNN with some geometric post-processes to its output gives us promising results for this field. Also, results show that pocket-based simplification algorithms work better for simplifying lines than Douglas-Puecker algorithm.", "url": "https://arxiv.org/abs/2309.16708"}, {"metadata": {"arXiv": "2309.16808", "Date": "Thu, 28 Sep 2023 19:30:26 ", "Title": "Granularity at Scale: Estimating Neighborhood Well-Being from High-Resolution Orthographic Imagery and Hybrid Learning", "Authors": ["Ethan Brewer", "Giovani Valdrighi", "Parikshit Solunke", "Joao Rulff", "Yurii Piadyk", "Zhonghui Lv", "Jorge Poco", "and Claudio Silva"], "Categories": "cs.CV cs.CY cs.LG"}, "abstract": "Many areas of the world are without basic information on the well-being of the residing population due to limitations in existing data collection methods. Overhead images obtained remotely, such as from satellite or aircraft, can help serve as windows into the state of life on the ground and help \"fill in the gaps\" where community information is sparse, with estimates at smaller geographic scales requiring higher resolution sensors. Concurrent with improved sensor resolutions, recent advancements in machine learning and computer vision have made it possible to quickly extract features from and detect patterns in image data, in the process correlating these features with other information. In this work, we explore how well two approaches, a supervised convolutional neural network and semi-supervised clustering based on bag-of-visual-words, estimate population density, median household income, and educational attainment of individual neighborhoods from publicly available high-resolution imagery of cities throughout the United States. Results and analyses indicate that features extracted from the imagery can accurately estimate the density (R$^2$ up to 0.81) of neighborhoods, with the supervised approach able to explain about half the variation in a population's income and education. In addition to the presented approaches serving as a basis for further geographic generalization, the novel semi-supervised approach provides a foundation for future work seeking to estimate fine-scale information from overhead imagery without the need for label data.", "url": "https://arxiv.org/abs/2309.16808"}, {"metadata": {"arXiv": "2309.16831", "Date": "Thu, 28 Sep 2023 20:23:25 ", "Title": "Propagation and Attribution of Uncertainty in Medical Imaging Pipelines", "Authors": ["Leonhard F. Feiner", "Martin J. Menten", "Kerstin Hammernik", "Paul Hager", "Wenqi Huang", "Daniel Rueckert", "Rickmer F. Braren", "and Georgios Kaissis"], "Categories": "cs.CV cs.LG", "DOI": "10.1007/978-3-031-44336-7_1"}, "abstract": "Uncertainty estimation, which provides a means of building explainable neural networks for medical imaging applications, have mostly been studied for single deep learning models that focus on a specific task. In this paper, we propose a method to propagate uncertainty through cascades of deep learning models in medical imaging pipelines. This allows us to aggregate the uncertainty in later stages of the pipeline and to obtain a joint uncertainty measure for the predictions of later models. Additionally, we can separately report contributions of the aleatoric, data-based, uncertainty of every component in the pipeline. We demonstrate the utility of our method on a realistic imaging pipeline that reconstructs undersampled brain and knee magnetic resonance (MR) images and subsequently predicts quantitative information from the images, such as the brain volume, or knee side or patient's sex. We quantitatively show that the propagated uncertainty is correlated with input uncertainty and compare the proportions of contributions of pipeline stages to the joint uncertainty measure.", "url": "https://arxiv.org/abs/2309.16831"}, {"metadata": {"arXiv": "2309.16849", "Date": "Thu, 28 Sep 2023 20:59:51 ", "Title": "Space-Time Attention with Shifted Non-Local Search", "Authors": ["Kent Gauen and Stanley Chan"], "Categories": "cs.CV cs.LG", "Comments": ["15 pages", "12 figures"]}, "abstract": "Efficiently computing attention maps for videos is challenging due to the motion of objects between frames. While a standard non-local search is high-quality for a window surrounding each query point, the window's small size cannot accommodate motion. Methods for long-range motion use an auxiliary network to predict the most similar key coordinates as offsets from each query location. However, accurately predicting this flow field of offsets remains challenging, even for large-scale networks. Small spatial inaccuracies significantly impact the attention module's quality. This paper proposes a search strategy that combines the quality of a non-local search with the range of predicted offsets. The method, named Shifted Non-Local Search, executes a small grid search surrounding the predicted offsets to correct small spatial errors. Our method's in-place computation consumes 10 times less memory and is over 3 times faster than previous work. Experimentally, correcting the small spatial errors improves the video frame alignment quality by over 3 dB PSNR. Our search upgrades existing space-time attention modules, which improves video denoising results by 0.30 dB PSNR for a 7.5% increase in overall runtime. We integrate our space-time attention module into a UNet-like architecture to achieve state-of-the-art results on video denoising.", "url": "https://arxiv.org/abs/2309.16849"}, {"metadata": {"arXiv": "2309.16870", "Date": "Thu, 28 Sep 2023 21:58:25 ", "Title": "LEF: Late-to-Early Temporal Fusion for LiDAR 3D Object Detection", "Authors": ["Tong He", "Pei Sun", "Zhaoqi Leng", "Chenxi Liu", "Dragomir Anguelov", "Mingxing Tan"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "We propose a late-to-early recurrent feature fusion scheme for 3D object detection using temporal LiDAR point clouds. Our main motivation is fusing object-aware latent embeddings into the early stages of a 3D object detector. This feature fusion strategy enables the model to better capture the shapes and poses for challenging objects, compared with learning from raw points directly. Our method conducts late-to-early feature fusion in a recurrent manner. This is achieved by enforcing window-based attention blocks upon temporally calibrated and aligned sparse pillar tokens. Leveraging bird's eye view foreground pillar segmentation, we reduce the number of sparse history features that our model needs to fuse into its current frame by 10$\\times$. We also propose a stochastic-length FrameDrop training technique, which generalizes the model to variable frame lengths at inference for improved performance without retraining. We evaluate our method on the widely adopted Waymo Open Dataset and demonstrate improvement on 3D object detection against the baseline model, especially for the challenging category of large objects.", "url": "https://arxiv.org/abs/2309.16870"}, {"metadata": {"arXiv": "2309.16992", "Date": "Fri, 29 Sep 2023 05:29:20 ", "Title": "Segment Anything Model is a Good Teacher for Local Feature Learning", "Authors": ["Jingqian Wu", "Rongtao Xu", "Zach Wood-Doughty", "Changwei Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "Local feature detection and description play an important role in many computer vision tasks, which are designed to detect and describe keypoints in \"any scene\" and \"any downstream task\". Data-driven local feature learning methods need to rely on pixel-level correspondence for training, which is challenging to acquire at scale, thus hindering further improvements in performance. In this paper, we propose SAMFeat to introduce SAM (segment anything model), a fundamental model trained on 11 million images, as a teacher to guide local feature learning and thus inspire higher performance on limited datasets. To do so, first, we construct an auxiliary task of Pixel Semantic Relational Distillation (PSRD), which distillates feature relations with category-agnostic semantic information learned by the SAM encoder into a local feature learning network, to improve local feature description using semantic discrimination. Second, we develop a technique called Weakly Supervised Contrastive Learning Based on Semantic Grouping (WSC), which utilizes semantic groupings derived from SAM as weakly supervised signals, to optimize the metric space of local descriptors. Third, we design an Edge Attention Guidance (EAG) to further improve the accuracy of local feature detection and description by prompting the network to pay more attention to the edge region guided by SAM. SAMFeat's performance on various tasks such as image matching on HPatches, and long-term visual localization on Aachen Day-Night showcases its superiority over previous local features. The release code is available at https://github.com/vignywang/SAMFeat.", "url": "https://arxiv.org/abs/2309.16992"}, {"metadata": {"arXiv": "2309.17033", "Date": "Fri, 29 Sep 2023 07:45:10 ", "Title": "Unveiling Document Structures with YOLOv5 Layout Detection", "Authors": ["Herman Sugiharto", "Yorissa Silviana", "Yani Siti Nurpazrin"], "Categories": "cs.CV cs.LG"}, "abstract": "The current digital environment is characterized by the widespread presence of data, particularly unstructured data, which poses many issues in sectors including finance, healthcare, and education. Conventional techniques for data extraction encounter difficulties in dealing with the inherent variety and complexity of unstructured data, hence requiring the adoption of more efficient methodologies. This research investigates the utilization of YOLOv5, a cutting-edge computer vision model, for the purpose of rapidly identifying document layouts and extracting unstructured data. The present study establishes a conceptual framework for delineating the notion of \"objects\" as they pertain to documents, incorporating various elements such as paragraphs, tables, photos, and other constituent parts. The main objective is to create an autonomous system that can effectively recognize document layouts and extract unstructured data, hence improving the effectiveness of data extraction. In the conducted examination, the YOLOv5 model exhibits notable effectiveness in the task of document layout identification, attaining a high accuracy rate along with a precision value of 0.91, a recall value of 0.971, an F1-score of 0.939, and an area under the receiver operating characteristic curve (AUC-ROC) of 0.975. The remarkable performance of this system optimizes the process of extracting textual and tabular data from document images. Its prospective applications are not limited to document analysis but can encompass unstructured data from diverse sources, such as audio data. This study lays the foundation for future investigations into the wider applicability of YOLOv5 in managing various types of unstructured data, offering potential for novel applications across multiple domains.", "url": "https://arxiv.org/abs/2309.17033"}, {"metadata": {"arXiv": "2309.17123", "Date": "Fri, 29 Sep 2023 10:38:08 ", "Title": "Reconstruction of Patient-Specific Confounders in AI-based Radiologic Image Interpretation using Generative Pretraining", "Authors": ["Tianyu Han", "Laura \\v{Z}igutyt\\.e", "Luisa Huck", "Marc Huppertz", "Robert Siepmann", "Yossi Gandelsman", "Christian Bl\\\"uthgen", "Firas Khader", "Christiane Kuhl", "Sven Nebelung", "Jakob Kather", "Daniel Truhn"], "Categories": "cs.CV cs.LG"}, "abstract": "Detecting misleading patterns in automated diagnostic assistance systems, such as those powered by Artificial Intelligence, is critical to ensuring their reliability, particularly in healthcare. Current techniques for evaluating deep learning models cannot visualize confounding factors at a diagnostic level. Here, we propose a self-conditioned diffusion model termed DiffChest and train it on a dataset of 515,704 chest radiographs from 194,956 patients from multiple healthcare centers in the United States and Europe. DiffChest explains classifications on a patient-specific level and visualizes the confounding factors that may mislead the model. We found high inter-reader agreement when evaluating DiffChest's capability to identify treatment-related confounders, with Fleiss' Kappa values of 0.8 or higher across most imaging findings. Confounders were accurately captured with 11.1% to 100% prevalence rates. Furthermore, our pretraining process optimized the model to capture the most relevant information from the input radiographs. DiffChest achieved excellent diagnostic accuracy when diagnosing 11 chest conditions, such as pleural effusion and cardiac insufficiency, and at least sufficient diagnostic accuracy for the remaining conditions. Our findings highlight the potential of pretraining based on diffusion models in medical image classification, specifically in providing insights into confounding factors and model robustness.", "url": "https://arxiv.org/abs/2309.17123"}, {"metadata": {"arXiv": "2309.17211", "Date": "Fri, 29 Sep 2023 13:09:40 ", "Title": "Instant Complexity Reduction in CNNs using Locality-Sensitive Hashing", "Authors": ["Lukas Meiner", "Jens Mehnert", "Alexandru Paul Condurache"], "Categories": "cs.CV cs.LG"}, "abstract": "To reduce the computational cost of convolutional neural networks (CNNs) for usage on resource-constrained devices, structured pruning approaches have shown promising results, drastically reducing floating-point operations (FLOPs) without substantial drops in accuracy. However, most recent methods require fine-tuning or specific training procedures to achieve a reasonable trade-off between retained accuracy and reduction in FLOPs. This introduces additional cost in the form of computational overhead and requires training data to be available. To this end, we propose HASTE (Hashing for Tractable Efficiency), a parameter-free and data-free module that acts as a plug-and-play replacement for any regular convolution module. It instantly reduces the network's test-time inference cost without requiring any training or fine-tuning. We are able to drastically compress latent feature maps without sacrificing much accuracy by using locality-sensitive hashing (LSH) to detect redundancies in the channel dimension. Similar channels are aggregated to reduce the input and filter depth simultaneously, allowing for cheaper convolutions. We demonstrate our approach on the popular vision benchmarks CIFAR-10 and ImageNet. In particular, we are able to instantly drop 46.72% of FLOPs while only losing 1.25% accuracy by just swapping the convolution modules in a ResNet34 on CIFAR-10 for our HASTE module.", "url": "https://arxiv.org/abs/2309.17211"}, {"metadata": {"arXiv": "2309.17342", "Date": "Fri, 29 Sep 2023 15:50:14 ", "Title": "Towards Free Data Selection with General-Purpose Models", "Authors": ["Yichen Xie", "Mingyu Ding", "Masayoshi Tomizuka", "Wei Zhan"], "Categories": "cs.CV cs.LG", "Comments": ["accepted by NeurIPS 2023"]}, "abstract": "A desirable data selection algorithm can efficiently choose the most informative samples to maximize the utility of limited annotation budgets. However, current approaches, represented by active learning methods, typically follow a cumbersome pipeline that iterates the time-consuming model training and batch data selection repeatedly. In this paper, we challenge this status quo by designing a distinct data selection pipeline that utilizes existing general-purpose models to select data from various datasets with a single-pass inference without the need for additional training or supervision. A novel free data selection (FreeSel) method is proposed following this new pipeline. Specifically, we define semantic patterns extracted from inter-mediate features of the general-purpose model to capture subtle local information in each image. We then enable the selection of all data samples in a single pass through distance-based sampling at the fine-grained semantic pattern level. FreeSel bypasses the heavy batch selection process, achieving a significant improvement in efficiency and being 530x faster than existing active learning methods. Extensive experiments verify the effectiveness of FreeSel on various computer vision tasks. Our code is available at https://github.com/yichen928/FreeSel.", "url": "https://arxiv.org/abs/2309.17342"}, {"metadata": {"arXiv": "2309.17400", "Date": "Fri, 29 Sep 2023 17:01:02 ", "Title": "Directly Fine-Tuning Diffusion Models on Differentiable Rewards", "Authors": ["Kevin Clark", "Paul Vicol", "Kevin Swersky", "David J Fleet"], "Categories": "cs.CV cs.LG"}, "abstract": "We present Direct Reward Fine-Tuning (DRaFT), a simple and effective method for fine-tuning diffusion models to maximize differentiable reward functions, such as scores from human preference models. We first show that it is possible to backpropagate the reward function gradient through the full sampling procedure, and that doing so achieves strong performance on a variety of rewards, outperforming reinforcement learning-based approaches. We then propose more efficient variants of DRaFT: DRaFT-K, which truncates backpropagation to only the last K steps of sampling, and DRaFT-LV, which obtains lower-variance gradient estimates for the case when K=1. We show that our methods work well for a variety of reward functions and can be used to substantially improve the aesthetic quality of images generated by Stable Diffusion 1.4. Finally, we draw connections between our approach and prior work, providing a unifying perspective on the design space of gradient-based fine-tuning algorithms.", "url": "https://arxiv.org/abs/2309.17400"}, {"metadata": {"arXiv": "2309.17340", "Date": "Fri, 29 Sep 2023 15:48:40 ", "Title": "Outage-Watch: Early Prediction of Outages using Extreme Event Regularizer", "Authors": ["Shubham Agarwal", "Sarthak Chakraborty", "Shaddy Garg", "Sumit Bisht", "Chahat Jain", "Ashritha Gonuguntla and Shiv Saini"], "Categories": "cs.DC cs.LG", "Comments": ["Accepted to ESEC/FSE 2023"], "DOI": "10.1145/3611643.3616316"}, "abstract": "Cloud services are omnipresent and critical cloud service failure is a fact of life. In order to retain customers and prevent revenue loss, it is important to provide high reliability guarantees for these services. One way to do this is by predicting outages in advance, which can help in reducing the severity as well as time to recovery. It is difficult to forecast critical failures due to the rarity of these events. Moreover, critical failures are ill-defined in terms of observable data. Our proposed method, Outage-Watch, defines critical service outages as deteriorations in the Quality of Service (QoS) captured by a set of metrics. Outage-Watch detects such outages in advance by using current system state to predict whether the QoS metrics will cross a threshold and initiate an extreme event. A mixture of Gaussian is used to model the distribution of the QoS metrics for flexibility and an extreme event regularizer helps in improving learning in tail of the distribution. An outage is predicted if the probability of any one of the QoS metrics crossing threshold changes significantly. Our evaluation on a real-world SaaS company dataset shows that Outage-Watch significantly outperforms traditional methods with an average AUC of 0.98. Additionally, Outage-Watch detects all the outages exhibiting a change in service metrics and reduces the Mean Time To Detection (MTTD) of outages by up to 88% when deployed in an enterprise cloud-service system, demonstrating efficacy of our proposed method.", "url": "https://arxiv.org/abs/2309.17340"}, {"metadata": {"arXiv": "2309.17383", "Date": "Fri, 29 Sep 2023 16:38:51 ", "Title": "Parallel Computation of Multi-Slice Clustering of Third-Order Tensors", "Authors": ["Dina Faneva Andriantsiory", "Camille Coti", "Joseph Ben Geloun", "Mustapha Lebbah"], "Categories": "cs.DC cs.LG"}, "abstract": "Machine Learning approaches like clustering methods deal with massive datasets that present an increasing challenge. We devise parallel algorithms to compute the Multi-Slice Clustering (MSC) for 3rd-order tensors. The MSC method is based on spectral analysis of the tensor slices and works independently on each tensor mode. Such features fit well in the parallel paradigm via a distributed memory system. We show that our parallel scheme outperforms sequential computing and allows for the scalability of the MSC method.", "url": "https://arxiv.org/abs/2309.17383"}, {"metadata": {"arXiv": "2309.16730", "Date": "Wed, 27 Sep 2023 08:46:57 ", "Title": "Explainable machine learning-based prediction model for diabetic nephropathy", "Authors": ["Jing-Mei Yin", "Yang Li", "Jun-Tang Xue", "Guo-Wei Zong", "Zhong-Ze Fang", "and Lang Zou"], "Categories": "cs.LG cs.CY"}, "abstract": "The aim of this study is to analyze the effect of serum metabolites on diabetic nephropathy (DN) and predict the prevalence of DN through a machine learning approach. The dataset consists of 548 patients from April 2018 to April 2019 in Second Affiliated Hospital of Dalian Medical University (SAHDMU). We select the optimal 38 features through a Least absolute shrinkage and selection operator (LASSO) regression model and a 10-fold cross-validation. We compare four machine learning algorithms, including eXtreme Gradient Boosting (XGB), random forest, decision tree and logistic regression, by AUC-ROC curves, decision curves, calibration curves. We quantify feature importance and interaction effects in the optimal predictive model by Shapley Additive exPlanations (SHAP) method. The XGB model has the best performance to screen for DN with the highest AUC value of 0.966. The XGB model also gains more clinical net benefits than others and the fitting degree is better. In addition, there are significant interactions between serum metabolites and duration of diabetes. We develop a predictive model by XGB algorithm to screen for DN. C2, C5DC, Tyr, Ser, Met, C24, C4DC, and Cys have great contribution in the model, and can possibly be biomarkers for DN.", "url": "https://arxiv.org/abs/2309.16730"}, {"metadata": {"arXiv": "2309.16736", "Date": "Wed, 27 Sep 2023 22:25:49 ", "Title": "Cognizance of Post-COVID-19 Multi-Organ Dysfunction through Machine Learning Analysis", "Authors": ["Hector J. Castro", "Maitham G. Yousif"], "Categories": "cs.LG q-bio.OT"}, "abstract": "In the year 2022, a total of 466 patients from various cities across Iraq were included in this study. This research paper focuses on the application of machine learning techniques to analyse and predict multi-organ dysfunction in individuals experiencing Post-COVID-19 Syndrome, commonly known as Long COVID. Post-COVID-19 Syndrome presents a wide array of persistent symptoms affecting various organ systems, posing a significant challenge to healthcare. Leveraging the power of artificial intelligence, this study aims to enhance early detection and management of this complex condition. The paper outlines the importance of data collection and preprocessing, feature selection and engineering, model development and validation, and ethical considerations in conducting research in this field. By improving our understanding of Post-COVID-19 Syndrome through machine learning, healthcare providers can identify at-risk individuals and offer timely interventions, potentially improving patient outcomes and quality of life. Further research is essential to refine models, validate their clinical utility, and explore treatment options for Long COVID. Keywords: Post-COVID-19 Syndrome, Machine Learning, Multi-Organ Dysfunction, Healthcare, Artificial Intelligence.", "url": "https://arxiv.org/abs/2309.16736"}, {"metadata": {"arXiv": "2309.16744", "Date": "Thu, 28 Sep 2023 14:44:06 ", "Title": "Predicting Long-term Renal Impairment in Post-COVID-19 Patients with Machine Learning Algorithms", "Authors": ["Maitham G. Yousif", "Hector J. Castro", "John Martin", "Hayder A. Albaqer", "Fadhil G. Al-Amran", "Habeeb W. Shubber", "Salman Rawaf"], "Categories": "cs.LG q-bio.OT"}, "abstract": "The COVID-19 pandemic has had far-reaching implications for global public health. As we continue to grapple with its consequences, it becomes increasingly clear that post-COVID-19 complications are a significant concern. Among these complications, renal impairment has garnered particular attention due to its potential long-term health impacts. This study, conducted with a cohort of 821 post-COVID-19 patients from diverse regions of Iraq across the years 2021, 2022, and 2023, endeavors to predict the risk of long-term renal impairment using advanced machine learning algorithms. Our findings have the potential to revolutionize post-COVID-19 patient care by enabling early identification and intervention for those at risk of renal impairment, ultimately improving clinical outcomes. This research encompasses comprehensive data collection and preprocessing, feature selection, and the development of predictive models using various machine learning algorithms. The study's objectives are to assess the incidence of long-term renal impairment in post-COVID-19 patients, identify associated risk factors, create predictive models, and evaluate their accuracy. We anticipate that our machine learning models, drawing from a rich dataset, will provide valuable insights into the risk of renal impairment, ultimately enhancing patient care and quality of life. In conclusion, the research presented herein offers a critical contribution to the field of post-COVID-19 care. By harnessing the power of machine learning, we aim to predict long-term renal impairment risk accurately. These predictions have the potential to inform healthcare professionals, enabling them to take proactive measures and provide targeted interventions for post-COVID-19 patients at risk of renal complications, thus minimizing the impact of this serious health concern.", "url": "https://arxiv.org/abs/2309.16744"}, {"metadata": {"arXiv": "2309.16745", "Date": "Thu, 28 Sep 2023 15:35:16 ", "Title": "Efficient Training of One Class Classification-SVMs", "Authors": ["Isaac Amornortey Yowetu", "Nana Kena Frempong"], "Categories": "cs.LG"}, "abstract": "This study examines the use of a highly effective training method to conduct one-class classification. The existence of both positive and negative examples in the training data is necessary to develop an effective classifier in common binary classification scenarios. Unfortunately, this criteria is not met in many domains. Here, there is just one class of examples. Classification algorithms that learn from solely positive input have been created to deal with this setting. In this paper, an effective algorithm for dual soft-margin one-class SVM training is presented. Our approach makes use of the Augmented Lagrangian (AL-FPGM), a variant of the Fast Projected Gradient Method. The FPGM requires only first derivatives, which for the dual soft margin OCC-SVM means computing mainly a matrix-vector product. Therefore, AL-FPGM, being computationally inexpensive, may complement existing quadratic programming solvers for training large SVMs. We extensively validate our approach over real-world datasets and demonstrate that our strategy obtains statistically significant results.", "url": "https://arxiv.org/abs/2309.16745"}, {"metadata": {"arXiv": "2309.16746", "Date": "Thu, 28 Sep 2023 16:02:39 ", "Title": "Implicit Gaussian process representation of vector fields over arbitrary latent manifolds", "Authors": ["Robert L. Peach", "Matteo Vinao-Carl", "Nir Grossman", "Michael David", "Emma Mallas", "David Sharp", "Paresh A. Malhotra", "Pierre Vandergheynst", "Adam Gosztolai"], "Categories": "cs.LG cs.MS physics.data-an q-bio.QM stat.ML"}, "abstract": "Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-density neural dynamics derived from low-density EEG recordings in healthy individuals and Alzheimer's patients. We show that vector field singularities are important disease markers and that their reconstruction leads to a comparable classification accuracy of disease states to high-density recordings. Thus, our method overcomes a significant practical limitation in experimental and clinical applications.", "url": "https://arxiv.org/abs/2309.16746"}, {"metadata": {"arXiv": "2309.16809", "Date": "Thu, 28 Sep 2023 19:31:36 ", "Title": "GraB-sampler: Optimal Permutation-based SGD Data Sampler for PyTorch", "Authors": ["Guanghao Wei"], "Categories": "cs.LG"}, "abstract": "The online Gradient Balancing (GraB) algorithm greedily choosing the examples ordering by solving the herding problem using per-sample gradients is proved to be the theoretically optimal solution that guarantees to outperform Random Reshuffling. However, there is currently no efficient implementation of GraB for the community to easily use it. This work presents an efficient Python library, $\\textit{GraB-sampler}$, that allows the community to easily use GraB algorithms and proposes 5 variants of the GraB algorithm. The best performance result of the GraB-sampler reproduces the training loss and test accuracy results while only in the cost of 8.7% training time overhead and 0.85% peak GPU memory usage overhead.", "url": "https://arxiv.org/abs/2309.16809"}, {"metadata": {"arXiv": "2309.16816", "Date": "Thu, 28 Sep 2023 19:46:07 ", "Title": "PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers", "Authors": ["Yuxuan Liu", "Zecheng Zhang", "Hayden Schaeffer"], "Categories": "cs.LG"}, "abstract": "Approximating nonlinear differential equations using a neural network provides a robust and efficient tool for various scientific computing tasks, including real-time predictions, inverse problems, optimal controls, and surrogate modeling. Previous works have focused on embedding dynamical systems into networks through two approaches: learning a single solution operator (i.e., the mapping from input parametrized functions to solutions) or learning the governing system of equations (i.e., the constitutive model relative to the state variables). Both of these approaches yield different representations for the same underlying data or function. Additionally, observing that families of differential equations often share key characteristics, we seek one network representation across a wide range of equations. Our method, called Predicting Operators and Symbolic Expressions (PROSE), learns maps from multimodal inputs to multimodal outputs, capable of generating both numerical predictions and mathematical equations. By using a transformer structure and a feature fusion approach, our network can simultaneously embed sets of solution operators for various parametric differential equations using a single trained network. Detailed experiments demonstrate that the network benefits from its multimodal nature, resulting in improved prediction accuracy and better generalization. The network is shown to be able to handle noise in the data and errors in the symbolic representation, including noisy numerical values, model misspecification, and erroneous addition or deletion of terms. PROSE provides a new neural network framework for differential equations which allows for more flexibility and generality in learning operators and governing equations from data.", "url": "https://arxiv.org/abs/2309.16816"}, {"metadata": {"arXiv": "2309.16825", "Date": "Thu, 28 Sep 2023 20:12:17 ", "Title": "FENDA-FL: Personalized Federated Learning on Heterogeneous Clinical Datasets", "Authors": ["Fatemeh Tavakoli", "D.B. Emerson", "John Jewell", "Amrit Krishnan", "Yuchong Zhang", "Amol Verma", "Fahad Razak"], "Categories": "cs.LG", "Comments": ["19 pages", "7 figures", "6 tables", "1 algorithm"], "MSC-class": "68T07"}, "abstract": "Federated learning (FL) is increasingly being recognized as a key approach to overcoming the data silos that so frequently obstruct the training and deployment of machine-learning models in clinical settings. This work contributes to a growing body of FL research specifically focused on clinical applications along three important directions. First, an extension of the FENDA method (Kim et al., 2016) to the FL setting is proposed. Experiments conducted on the FLamby benchmarks (du Terrail et al., 2022a) and GEMINI datasets (Verma et al., 2017) show that the approach is robust to heterogeneous clinical data and often outperforms existing global and personalized FL techniques. Further, the experimental results represent substantive improvements over the original FLamby benchmarks and expand such benchmarks to include evaluation of personalized FL methods. Finally, we advocate for a comprehensive checkpointing and evaluation framework for FL to better reflect practical settings and provide multiple baselines for comparison.", "url": "https://arxiv.org/abs/2309.16825"}, {"metadata": {"arXiv": "2309.16827", "Date": "Thu, 28 Sep 2023 20:16:24 ", "Title": "Post-Training Overfitting Mitigation in DNN Classifiers", "Authors": ["Hang Wang", "David J. Miller", "George Kesidis"], "Categories": "cs.LG"}, "abstract": "Well-known (non-malicious) sources of overfitting in deep neural net (DNN) classifiers include: i) large class imbalances; ii) insufficient training-set diversity; and iii) over-training. In recent work, it was shown that backdoor data-poisoning also induces overfitting, with unusually large classification margins to the attacker's target class, mediated particularly by (unbounded) ReLU activations that allow large signals to propagate in the DNN. Thus, an effective post-training (with no knowledge of the training set or training process) mitigation approach against backdoors was proposed, leveraging a small clean dataset, based on bounding neural activations. Improving upon that work, we threshold activations specifically to limit maximum margins (MMs), which yields performance gains in backdoor mitigation. We also provide some analytical support for this mitigation approach. Most importantly, we show that post-training MM-based regularization substantially mitigates non-malicious overfitting due to class imbalances and overtraining. Thus, unlike adversarial training, which provides some resilience against attacks but which harms clean (attack-free) generalization, we demonstrate an approach originating from adversarial learning that helps clean generalization accuracy. Experiments on CIFAR-10 and CIFAR-100, in comparison with peer methods, demonstrate strong performance of our methods.", "url": "https://arxiv.org/abs/2309.16827"}, {"metadata": {"arXiv": "2309.16846", "Date": "Thu, 28 Sep 2023 20:55:21 ", "Title": "Optimal Nonlinearities Improve Generalization Performance of Random Features", "Authors": ["Samet Demir and Zafer Do\\u{g}an"], "Categories": "cs.LG stat.ML", "Comments": ["ACML 2023"]}, "abstract": "Random feature model with a nonlinear activation function has been shown to perform asymptotically equivalent to a Gaussian model in terms of training and generalization errors. Analysis of the equivalent model reveals an important yet not fully understood role played by the activation function. To address this issue, we study the \"parameters\" of the equivalent model to achieve improved generalization performance for a given supervised learning problem. We show that acquired parameters from the Gaussian model enable us to define a set of optimal nonlinearities. We provide two example classes from this set, e.g., second-order polynomial and piecewise linear functions. These functions are optimized to improve generalization performance regardless of the actual form. We experiment with regression and classification problems, including synthetic and real (e.g., CIFAR10) data. Our numerical results validate that the optimized nonlinearities achieve better generalization performance than widely-used nonlinear functions such as ReLU. Furthermore, we illustrate that the proposed nonlinearities also mitigate the so-called double descent phenomenon, which is known as the non-monotonic generalization performance regarding the sample size and the model size.", "url": "https://arxiv.org/abs/2309.16846"}, {"metadata": {"arXiv": "2309.16854", "Date": "Thu, 28 Sep 2023 21:07:40 ", "Title": "Applications of Federated Learning in IoT for Hyper Personalisation", "Authors": ["Veer Dosi"], "Categories": "cs.LG"}, "abstract": "Billions of IoT devices are being deployed, taking advantage of faster internet, and the opportunity to access more endpoints. Vast quantities of data are being generated constantly by these devices but are not effectively being utilised. Using FL training machine learning models over these multiple clients without having to bring it to a central server. We explore how to use such a model to implement ultra levels of personalization unlike before", "url": "https://arxiv.org/abs/2309.16854"}, {"metadata": {"arXiv": "2309.16882", "Date": "Thu, 28 Sep 2023 22:38:18 ", "Title": "Message Propagation Through Time: An Algorithm for Sequence Dependency Retention in Time Series Modeling", "Authors": ["Shaoming Xu", "Ankush Khandelwal", "Arvind Renganathan", "Vipin Kumar"], "Categories": "cs.LG"}, "abstract": "Time series modeling, a crucial area in science, often encounters challenges when training Machine Learning (ML) models like Recurrent Neural Networks (RNNs) using the conventional mini-batch training strategy that assumes independent and identically distributed (IID) samples and initializes RNNs with zero hidden states. The IID assumption ignores temporal dependencies among samples, resulting in poor performance. This paper proposes the Message Propagation Through Time (MPTT) algorithm to effectively incorporate long temporal dependencies while preserving faster training times relative to the stateful solutions. MPTT utilizes two memory modules to asynchronously manage initial hidden states for RNNs, fostering seamless information exchange between samples and allowing diverse mini-batches throughout epochs. MPTT further implements three policies to filter outdated and preserve essential information in the hidden states to generate informative initial hidden states for RNNs, facilitating robust training. Experimental results demonstrate that MPTT outperforms seven strategies on four climate datasets with varying levels of temporal dependencies.", "url": "https://arxiv.org/abs/2309.16882"}, {"metadata": {"arXiv": "2309.16883", "Date": "Thu, 28 Sep 2023 22:41:47 ", "Title": "The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing", "Authors": ["Blaise Delattre", "Alexandre Araujo", "Quentin Barth\\'elemy and Alexandre Allauzen"], "Categories": "cs.LG stat.ML"}, "abstract": "Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernstein's concentration inequality, along with an enhanced Lipschitz bound. Experimental results show a significant improvement in certified accuracy compared to current state-of-the-art methods. Our novel certification procedure allows us to use pre-trained models that are used with randomized smoothing, effectively improving the current certification radius in a zero-shot manner.", "url": "https://arxiv.org/abs/2309.16883"}, {"metadata": {"arXiv": "2309.16896", "Date": "Thu, 28 Sep 2023 23:50:11 ", "Title": "Algorithmic Recourse for Anomaly Detection in Multivariate Time Series", "Authors": ["Xiao Han", "Lu Zhang", "Yongkai Wu", "Shuhan Yuan"], "Categories": "cs.LG"}, "abstract": "Anomaly detection in multivariate time series has received extensive study due to the wide spectrum of applications. An anomaly in multivariate time series usually indicates a critical event, such as a system fault or an external attack. Therefore, besides being effective in anomaly detection, recommending anomaly mitigation actions is also important in practice yet under-investigated. In this work, we focus on algorithmic recourse in time series anomaly detection, which is to recommend fixing actions on abnormal time series with a minimum cost so that domain experts can understand how to fix the abnormal behavior. To this end, we propose an algorithmic recourse framework, called RecAD, which can recommend recourse actions to flip the abnormal time steps. Experiments on two synthetic and one real-world datasets show the effectiveness of our framework.", "url": "https://arxiv.org/abs/2309.16896"}, {"metadata": {"arXiv": "2309.16932", "Date": "Fri, 29 Sep 2023 02:21:31 ", "Title": "Symmetry Leads to Structured Constraint of Learning", "Authors": ["Liu Ziyin"], "Categories": "cs.LG stat.ML", "Comments": ["preprint"]}, "abstract": "Due to common architecture designs, symmetries exist extensively in contemporary neural networks. In this work, we unveil the importance of the loss function symmetries in affecting, if not deciding, the learning behavior of machine learning models. We prove that every mirror symmetry of the loss function leads to a structured constraint, which becomes a favored solution when either the weight decay or gradient noise is large. As direct corollaries, we show that rescaling symmetry leads to sparsity, rotation symmetry leads to low rankness, and permutation symmetry leads to homogeneous ensembling. Then, we show that the theoretical framework can explain the loss of plasticity and various collapse phenomena in neural networks and suggest how symmetries can be used to design algorithms to enforce hard constraints in a differentiable way.", "url": "https://arxiv.org/abs/2309.16932"}, {"metadata": {"arXiv": "2309.16941", "Date": "Fri, 29 Sep 2023 02:50:57 ", "Title": "G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural Networks", "Authors": ["Zhaoyu Li", "Jinpei Guo", "Xujie Si"], "Categories": "cs.LG"}, "abstract": "Graph neural networks (GNNs) have recently emerged as a promising approach for solving the Boolean Satisfiability Problem (SAT), offering potential alternatives to traditional backtracking or local search SAT solvers. However, despite the growing volume of literature in this field, there remains a notable absence of a unified dataset and a fair benchmark to evaluate and compare existing approaches. To address this crucial gap, we present G4SATBench, the first benchmark study that establishes a comprehensive evaluation framework for GNN-based SAT solvers. In G4SATBench, we meticulously curate a large and diverse set of SAT datasets comprising 7 problems with 3 difficulty levels and benchmark a broad range of GNN models across various prediction tasks, training objectives, and inference algorithms. To explore the learning abilities and comprehend the strengths and limitations of GNN-based SAT solvers, we also compare their solving processes with the heuristics in search-based SAT solvers. Our empirical results provide valuable insights into the performance of GNN-based SAT solvers and further suggest that existing GNN models can effectively learn a solving strategy akin to greedy local search but struggle to learn backtracking search in the latent space.", "url": "https://arxiv.org/abs/2309.16941"}, {"metadata": {"arXiv": "2309.16943", "Date": "Fri, 29 Sep 2023 02:55:55 ", "Title": "Physics-Informed Induction Machine Modelling", "Authors": ["Qing Shen", "Yifan Zhou", "Peng Zhang"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "This rapid communication devises a Neural Induction Machine (NeuIM) model, which pilots the use of physics-informed machine learning to enable AI-based electromagnetic transient simulations. The contributions are threefold: (1) a formation of NeuIM to represent the induction machine in phase domain; (2) a physics-informed neural network capable of capturing fast and slow IM dynamics even in the absence of data; and (3) a data-physics-integrated hybrid NeuIM approach which is adaptive to various levels of data availability. Extensive case studies validate the efficacy of NeuIM and in particular, its advantage over purely data-driven approaches.", "url": "https://arxiv.org/abs/2309.16943"}, {"metadata": {"arXiv": "2309.16971", "Date": "Fri, 29 Sep 2023 04:41:27 ", "Title": "Multi-Resolution Active Learning of Fourier Neural Operators", "Authors": ["Shibo Li", "Xin Yu", "Wei Xing", "Mike Kirby", "Akil Narayan", "Shandian Zhe"], "Categories": "cs.LG"}, "abstract": "Fourier Neural Operator (FNO) is a popular operator learning framework, which not only achieves the state-of-the-art performance in many tasks, but also is highly efficient in training and prediction. However, collecting training data for the FNO is a costly bottleneck in practice, because it often demands expensive physical simulations. To overcome this problem, we propose Multi-Resolution Active learning of FNO (MRA-FNO), which can dynamically select the input functions and resolutions to lower the data cost as much as possible while optimizing the learning efficiency. Specifically, we propose a probabilistic multi-resolution FNO and use ensemble Monte-Carlo to develop an effective posterior inference algorithm. To conduct active learning, we maximize a utility-cost ratio as the acquisition function to acquire new examples and resolutions at each step. We use moment matching and the matrix determinant lemma to enable tractable, efficient utility computation. Furthermore, we develop a cost annealing framework to avoid over-penalizing high-resolution queries at the early stage. The over-penalization is severe when the cost difference is significant between the resolutions, which renders active learning often stuck at low-resolution queries and inferior performance. Our method overcomes this problem and applies to general multi-fidelity active learning and optimization problems. We have shown the advantage of our method in several benchmark operator learning tasks.", "url": "https://arxiv.org/abs/2309.16971"}, {"metadata": {"arXiv": "2309.16973", "Date": "Fri, 29 Sep 2023 04:42:50 ", "Title": "Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty and Smoothness", "Authors": ["Xiaoyu Wen", "Xudong Yu", "Rui Yang", "Chenjia Bai", "Zhen Wang"], "Categories": "cs.LG"}, "abstract": "To obtain a near-optimal policy with fewer interactions in Reinforcement Learning (RL), a promising approach involves the combination of offline RL, which enhances sample efficiency by leveraging offline datasets, and online RL, which explores informative transitions by interacting with the environment. Offline-to-Online (O2O) RL provides a paradigm for improving an offline trained agent within limited online interactions. However, due to the significant distribution shift between online experiences and offline data, most offline RL algorithms suffer from performance drops and fail to achieve stable policy improvement in O2O adaptation. To address this problem, we propose the Robust Offline-to-Online (RO2O) algorithm, designed to enhance offline policies through uncertainty and smoothness, and to mitigate the performance drop in online adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty penalty and adversarial samples for policy and value smoothness, which enable RO2O to maintain a consistent learning procedure in online adaptation without requiring special changes to the learning objective. Theoretical analyses in linear MDPs demonstrate that the uncertainty and smoothness lead to a tighter optimality bound in O2O against distribution shift. Experimental results illustrate the superiority of RO2O in facilitating stable offline-to-online learning and achieving significant improvement with limited online interactions.", "url": "https://arxiv.org/abs/2309.16973"}, {"metadata": {"arXiv": "2309.16976", "Date": "Fri, 29 Sep 2023 04:49:35 ", "Title": "Benchmarking and In-depth Performance Study of Large Language Models on Habana Gaudi Processors", "Authors": ["Chengming Zhang", "Baixi Sun", "Xiaodong Yu", "Zhen Xie", "Weijian Zheng", "Kamil Iskra", "Pete Beckman", "Dingwen Tao"], "Categories": "cs.LG cs.DC"}, "abstract": "Transformer models have achieved remarkable success in various machine learning tasks but suffer from high computational complexity and resource requirements. The quadratic complexity of the self-attention mechanism further exacerbates these challenges when dealing with long sequences and large datasets. Specialized AI hardware accelerators, such as the Habana GAUDI architecture, offer a promising solution to tackle these issues. GAUDI features a Matrix Multiplication Engine (MME) and a cluster of fully programmable Tensor Processing Cores (TPC). This paper explores the untapped potential of using GAUDI processors to accelerate Transformer-based models, addressing key challenges in the process. Firstly, we provide a comprehensive performance comparison between the MME and TPC components, illuminating their relative strengths and weaknesses. Secondly, we explore strategies to optimize MME and TPC utilization, offering practical insights to enhance computational efficiency. Thirdly, we evaluate the performance of Transformers on GAUDI, particularly in handling long sequences and uncovering performance bottlenecks. Lastly, we evaluate the end-to-end performance of two Transformer-based large language models (LLM) on GAUDI. The contributions of this work encompass practical insights for practitioners and researchers alike. We delve into GAUDI's capabilities for Transformers through systematic profiling, analysis, and optimization exploration. Our study bridges a research gap and offers a roadmap for optimizing Transformer-based model training on the GAUDI architecture.", "url": "https://arxiv.org/abs/2309.16976"}, {"metadata": {"arXiv": "2309.16984", "Date": "Fri, 29 Sep 2023 05:05:54 ", "Title": "Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning", "Authors": ["Zihan Ding", "Chi Jin"], "Categories": "cs.LG"}, "abstract": "Score-based generative models like the diffusion model have been testified to be effective in modeling multi-modal data from image generation to reinforcement learning (RL). However, the inference process of diffusion model can be slow, which hinders its usage in RL with iterative sampling. We propose to apply the consistency model as an efficient yet expressive policy representation, namely consistency policy, with an actor-critic style algorithm for three typical RL settings: offline, offline-to-online and online. For offline RL, we demonstrate the expressiveness of generative models as policies from multi-modal data. For offline-to-online RL, the consistency policy is shown to be more computational efficient than diffusion policy, with a comparable performance. For online RL, the consistency policy demonstrates significant speedup and even higher average performances than the diffusion policy.", "url": "https://arxiv.org/abs/2309.16984"}, {"metadata": {"arXiv": "2309.17009", "Date": "Fri, 29 Sep 2023 06:46:31 ", "Title": "Deep Representation Learning for Prediction of Temporal Event Sets in the Continuous Time Domain", "Authors": ["Parag Dutta", "Kawin Mayilvaghanan", "Pratyaksha Sinha", "Ambedkar Dukkipati"], "Categories": "cs.LG", "Comments": ["Accepted in ACML 2023 - Conference Track (Long Paper)"]}, "abstract": "Temporal Point Processes (TPP) play an important role in predicting or forecasting events. Although these problems have been studied extensively, predicting multiple simultaneously occurring events can be challenging. For instance, more often than not, a patient gets admitted to a hospital with multiple conditions at a time. Similarly people buy more than one stock and multiple news breaks out at the same time. Moreover, these events do not occur at discrete time intervals, and forecasting event sets in the continuous time domain remains an open problem. Naive approaches for extending the existing TPP models for solving this problem lead to dealing with an exponentially large number of events or ignoring set dependencies among events. In this work, we propose a scalable and efficient approach based on TPPs to solve this problem. Our proposed approach incorporates contextual event embeddings, temporal information, and domain features to model the temporal event sets. We demonstrate the effectiveness of our approach through extensive experiments on multiple datasets, showing that our model outperforms existing methods in terms of prediction metrics and computational efficiency. To the best of our knowledge, this is the first work that solves the problem of predicting event set intensities in the continuous time domain by using TPPs.", "url": "https://arxiv.org/abs/2309.17009"}, {"metadata": {"arXiv": "2309.17011", "Date": "Fri, 29 Sep 2023 06:48:16 ", "Title": "Feature Cognition Enhancement via Interaction-Aware Automated Transformation", "Authors": ["Ehtesamul Azim", "Dongjie Wang", "Kunpeng Liu", "Wei Zhang", "Yanjie Fu"], "Categories": "cs.LG", "Comments": ["Submitted to SIAM Conference on Data Mining(SDM) 2024"]}, "abstract": "Creating an effective representation space is crucial for mitigating the curse of dimensionality, enhancing model generalization, addressing data sparsity, and leveraging classical models more effectively. Recent advancements in automated feature engineering (AutoFE) have made significant progress in addressing various challenges associated with representation learning, issues such as heavy reliance on intensive labor and empirical experiences, lack of explainable explicitness, and inflexible feature space reconstruction embedded into downstream tasks. However, these approaches are constrained by: 1) generation of potentially unintelligible and illogical reconstructed feature spaces, stemming from the neglect of expert-level cognitive processes; 2) lack of systematic exploration, which subsequently results in slower model convergence for identification of optimal feature space. To address these, we introduce an interaction-aware reinforced generation perspective. We redefine feature space reconstruction as a nested process of creating meaningful features and controlling feature set size through selection. We develop a hierarchical reinforcement learning structure with cascading Markov Decision Processes to automate feature and operation selection, as well as feature crossing. By incorporating statistical measures, we reward agents based on the interaction strength between selected features, resulting in intelligent and efficient exploration of the feature space that emulates human decision-making. Extensive experiments are conducted to validate our proposed approach.", "url": "https://arxiv.org/abs/2309.17011"}, {"metadata": {"arXiv": "2309.17016", "Date": "Fri, 29 Sep 2023 07:01:28 ", "Title": "Efficient Agnostic Learning with Average Smoothness", "Authors": ["Steve Hanneke", "Aryeh Kontorovich", "Guy Kornowski"], "Categories": "cs.LG math.ST stat.ML stat.TH", "Comments": ["arXiv admin note: text overlap with arXiv:2302.06005"]}, "abstract": "We study distribution-free nonparametric regression following a notion of average smoothness initiated by Ashlagi et al. (2021), which measures the \"effective\" smoothness of a function with respect to an arbitrary unknown underlying distribution. While the recent work of Hanneke et al. (2023) established tight uniform convergence bounds for average-smooth functions in the realizable case and provided a computationally efficient realizable learning algorithm, both of these results currently lack analogs in the general agnostic (i.e. noisy) case. In this work, we fully close these gaps. First, we provide a distribution-free uniform convergence bound for average-smoothness classes in the agnostic setting. Second, we match the derived sample complexity with a computationally efficient agnostic learning algorithm. Our results, which are stated in terms of the intrinsic geometry of the data and hold over any totally bounded metric space, show that the guarantees recently obtained for realizable learning of average-smooth functions transfer to the agnostic setting. At the heart of our proof, we establish the uniform convergence rate of a function class in terms of its bracketing entropy, which may be of independent interest.", "url": "https://arxiv.org/abs/2309.17016"}, {"metadata": {"arXiv": "2309.17053", "Date": "Fri, 29 Sep 2023 08:26:44 ", "Title": "On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters", "Authors": ["Pablo Barcel\\'o", "Matthias Lanzinger"], "Categories": "cs.LG"}, "abstract": "Seminal research in the field of graph neural networks (GNNs) has revealed a direct correspondence between the expressive capabilities of GNNs and the $k$-dimensional Weisfeiler-Leman ($k$WL) test, a widely-recognized method for verifying graph isomorphism. This connection has reignited interest in comprehending the specific graph properties effectively distinguishable by the $k$WL test. A central focus of research in this field revolves around determining the least dimensionality $k$, for which $k$WL can discern graphs with different number of occurrences of a pattern graph $P$. We refer to such a least $k$ as the WL-dimension of this pattern counting problem. This inquiry traditionally delves into two distinct counting problems related to patterns: subgraph counting and induced subgraph counting. Intriguingly, despite their initial appearance as separate challenges with seemingly divergent approaches, both of these problems are interconnected components of a more comprehensive problem: \"graph motif parameters\". In this paper, we provide a precise characterization of the WL-dimension of labeled graph motif parameters. As specific instances of this result, we obtain characterizations of the WL-dimension of the subgraph counting and induced subgraph counting problem for every labeled pattern $P$. We additionally demonstrate that in cases where the $k$WL test distinguishes between graphs with varying occurrences of a pattern $P$, the exact number of occurrences of $P$ can be computed uniformly using only local information of the last layer of a corresponding GNN. We finally delve into the challenge of recognizing the WL-dimension of various graph parameters. We give a polynomial time algorithm for determining the WL-dimension of the subgraph counting problem for given pattern $P$, answering an open question from previous work.", "url": "https://arxiv.org/abs/2309.17053"}, {"metadata": {"arXiv": "2309.17086", "Date": "Fri, 29 Sep 2023 09:32:08 ", "Title": "From Empirical Measurements to Augmented Data Rates: A Machine Learning Approach for MCS Adaptation in Sidelink Communication", "Authors": ["Asif Abdullah Rokoni", "Daniel Sch\\\"aufele", "Martin Kasparick", "S{\\l}awomir Sta\\'nczak"], "Categories": "cs.LG", "Comments": ["5 pages", "8 figures"]}, "abstract": "Due to the lack of a feedback channel in the C-V2X sidelink, finding a suitable modulation and coding scheme (MCS) is a difficult task. However, recent use cases for vehicle-to-everything (V2X) communication with higher demands on data rate necessitate choosing the MCS adaptively. In this paper, we propose a machine learning approach to predict suitable MCS levels. Additionally, we propose the use of quantile prediction and evaluate it in combination with different algorithms for the task of predicting the MCS level with the highest achievable data rate. Thereby, we show significant improvements over conventional methods of choosing the MCS level. Using a machine learning approach, however, requires larger real-world data sets than are currently publicly available for research. For this reason, this paper presents a data set that was acquired in extensive drive tests, and that we make publicly available.", "url": "https://arxiv.org/abs/2309.17086"}, {"metadata": {"arXiv": "2309.17089", "Date": "Fri, 29 Sep 2023 09:36:37 ", "Title": "Too Big, so Fail? -- Enabling Neural Construction Methods to Solve Large-Scale Routing Problems", "Authors": ["Jonas K. Falkner and Lars Schmidt-Thieme"], "Categories": "cs.LG"}, "abstract": "In recent years new deep learning approaches to solve combinatorial optimization problems, in particular NP-hard Vehicle Routing Problems (VRP), have been proposed. The most impactful of these methods are sequential neural construction approaches which are usually trained via reinforcement learning. Due to the high training costs of these models, they usually are trained on limited instance sizes (e.g. serving 100 customers) and later applied to vastly larger instance size (e.g. 2000 customers). By means of a systematic scale-up study we show that even state-of-the-art neural construction methods are outperformed by simple heuristics, failing to generalize to larger problem instances. We propose to use the ruin recreate principle that alternates between completely destroying a localized part of the solution and then recreating an improved variant. In this way, neural construction methods like POMO are never applied to the global problem but just in the reconstruction step, which only involves partial problems much closer in size to their original training instances. In thorough experiments on four datasets of varying distributions and modalities we show that our neural ruin recreate approach outperforms alternative forms of improving construction methods such as sampling and beam search and in several experiments also advanced local search approaches.", "url": "https://arxiv.org/abs/2309.17089"}, {"metadata": {"arXiv": "2309.17097", "Date": "Fri, 29 Sep 2023 09:47:18 ", "Title": "Benchmarking Collaborative Learning Methods Cost-Effectiveness for Prostate Segmentation", "Authors": ["Lucia Innocenti", "Michela Antonelli", "Francesco Cremonesi", "Kenaan Sarhan", "Alejandro Granados", "Vicky Goh", "Sebastien Ourselin", "Marco Lorenzi"], "Categories": "cs.LG"}, "abstract": "Healthcare data is often split into medium/small-sized collections across multiple hospitals and access to it is encumbered by privacy regulations. This brings difficulties to use them for the development of machine learning and deep learning models, which are known to be data-hungry. One way to overcome this limitation is to use collaborative learning (CL) methods, which allow hospitals to work collaboratively to solve a task, without the need to explicitly share local data. In this paper, we address a prostate segmentation problem from MRI in a collaborative scenario by comparing two different approaches: federated learning (FL) and consensus-based methods (CBM). To the best of our knowledge, this is the first work in which CBM, such as label fusion techniques, are used to solve a problem of collaborative learning. In this setting, CBM combine predictions from locally trained models to obtain a federated strong learner with ideally improved robustness and predictive variance properties. Our experiments show that, in the considered practical scenario, CBMs provide equal or better results than FL, while being highly cost-effective. Our results demonstrate that the consensus paradigm may represent a valid alternative to FL for typical training tasks in medical imaging.", "url": "https://arxiv.org/abs/2309.17097"}, {"metadata": {"arXiv": "2309.17116", "Date": "Fri, 29 Sep 2023 10:25:43 ", "Title": "Sheaf Hypergraph Networks", "Authors": ["Iulia Duta", "Giulia Cassar\\`a", "Fabrizio Silvestri", "Pietro Li\\`o"], "Categories": "cs.LG", "Comments": ["Accepted at Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Higher-order relations are widespread in nature, with numerous phenomena involving complex interactions that extend beyond simple pairwise connections. As a result, advancements in higher-order processing can accelerate the growth of various fields requiring structured data. Current approaches typically represent these interactions using hypergraphs. We enhance this representation by introducing cellular sheaves for hypergraphs, a mathematical construction that adds extra structure to the conventional hypergraph while maintaining their local, higherorder connectivity. Drawing inspiration from existing Laplacians in the literature, we develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear. Our theoretical analysis demonstrates that incorporating sheaves into the hypergraph Laplacian provides a more expressive inductive bias than standard hypergraph diffusion, creating a powerful instrument for effectively modelling complex data structures. We employ these sheaf hypergraph Laplacians to design two categories of models: Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks. These models generalize classical Hypergraph Networks often found in the literature. Through extensive experimentation, we show that this generalization significantly improves performance, achieving top results on multiple benchmark datasets for hypergraph node classification.", "url": "https://arxiv.org/abs/2309.17116"}, {"metadata": {"arXiv": "2309.17125", "Date": "Fri, 29 Sep 2023 10:40:19 ", "Title": "Style Transfer for Non-differentiable Audio Effects", "Authors": ["Kieran Grant"], "Categories": "cs.LG cs.SD eess.AS"}, "abstract": "Digital audio effects are widely used by audio engineers to alter the acoustic and temporal qualities of audio data. However, these effects can have a large number of parameters which can make them difficult to learn for beginners and hamper creativity for professionals. Recently, there have been a number of efforts to employ progress in deep learning to acquire the low-level parameter configurations of audio effects by minimising an objective function between an input and reference track, commonly referred to as style transfer. However, current approaches use inflexible black-box techniques or require that the effects under consideration are implemented in an auto-differentiation framework. In this work, we propose a deep learning approach to audio production style matching which can be used with effects implemented in some of the most widely used frameworks, requiring only that the parameters under consideration have a continuous domain. Further, our method includes style matching for various classes of effects, many of which are difficult or impossible to be approximated closely using differentiable functions. We show that our audio embedding approach creates logical encodings of timbral information, which can be used for a number of downstream tasks. Further, we perform a listening test which demonstrates that our approach is able to convincingly style match a multi-band compressor effect.", "url": "https://arxiv.org/abs/2309.17125"}, {"metadata": {"arXiv": "2309.17130", "Date": "Fri, 29 Sep 2023 10:49:14 ", "Title": "GRANDE: Gradient-Based Decision Tree Ensembles", "Authors": ["Sascha Marton", "Stefan L\\\"udtke", "Christian Bartelt", "Heiner Stuckenschmidt"], "Categories": "cs.LG"}, "abstract": "Despite the success of deep learning for text and image data, tree-based ensemble models are still state-of-the-art for machine learning with heterogeneous tabular data. However, there is a significant need for tabular-specific gradient-based methods due to their high flexibility. In this paper, we propose $\\text{GRANDE}$, $\\text{GRA}$die$\\text{N}$t-Based $\\text{D}$ecision Tree $\\text{E}$nsembles, a novel approach for learning hard, axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE is based on a dense representation of tree ensembles, which affords to use backpropagation with a straight-through operator to jointly optimize all model parameters. Our method combines axis-aligned splits, which is a useful inductive bias for tabular data, with the flexibility of gradient-based optimization. Furthermore, we introduce an advanced instance-wise weighting that facilitates learning representations for both, simple and complex relations, within a single model. We conducted an extensive evaluation on a predefined benchmark with 19 classification datasets and demonstrate that our method outperforms existing gradient-boosting and deep learning frameworks on most datasets.", "url": "https://arxiv.org/abs/2309.17130"}, {"metadata": {"arXiv": "2309.17154", "Date": "Fri, 29 Sep 2023 11:42:59 ", "Title": "Efficient Interpretable Nonlinear Modeling for Multiple Time Series", "Authors": ["Kevin Roy", "Luis Miguel Lopez-Ramos and Baltasar Beferull-Lozano"], "Categories": "cs.LG"}, "abstract": "Predictive linear and nonlinear models based on kernel machines or deep neural networks have been used to discover dependencies among time series. This paper proposes an efficient nonlinear modeling approach for multiple time series, with a complexity comparable to linear vector autoregressive (VAR) models while still incorporating nonlinear interactions among different time-series variables. The modeling assumption is that the set of time series is generated in two steps: first, a linear VAR process in a latent space, and second, a set of invertible and Lipschitz continuous nonlinear mappings that are applied per sensor, that is, a component-wise mapping from each latent variable to a variable in the measurement space. The VAR coefficient identification provides a topology representation of the dependencies among the aforementioned variables. The proposed approach models each component-wise nonlinearity using an invertible neural network and imposes sparsity on the VAR coefficients to reflect the parsimonious dependencies usually found in real applications. To efficiently solve the formulated optimization problems, a custom algorithm is devised combining proximal gradient descent, stochastic primal-dual updates, and projection to enforce the corresponding constraints. Experimental results on both synthetic and real data sets show that the proposed algorithm improves the identification of the support of the VAR coefficients in a parsimonious manner while also improving the time-series prediction, as compared to the current state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.17154"}, {"metadata": {"arXiv": "2309.17174", "Date": "Fri, 29 Sep 2023 12:13:41 ", "Title": "FedZeN: Towards superlinear zeroth-order federated learning via incremental Hessian estimation", "Authors": ["Alessio Maritan", "Subhrakanti Dey", "Luca Schenato"], "Categories": "cs.LG math.OC"}, "abstract": "Federated learning is a distributed learning framework that allows a set of clients to collaboratively train a model under the orchestration of a central server, without sharing raw data samples. Although in many practical scenarios the derivatives of the objective function are not available, only few works have considered the federated zeroth-order setting, in which functions can only be accessed through a budgeted number of point evaluations. In this work we focus on convex optimization and design the first federated zeroth-order algorithm to estimate the curvature of the global objective, with the purpose of achieving superlinear convergence. We take an incremental Hessian estimator whose error norm converges linearly, and we adapt it to the federated zeroth-order setting, sampling the random search directions from the Stiefel manifold for improved performance. In particular, both the gradient and Hessian estimators are built at the central server in a communication-efficient and privacy-preserving way by leveraging synchronized pseudo-random number generators. We provide a theoretical analysis of our algorithm, named FedZeN, proving local quadratic convergence with high probability and global linear convergence up to zeroth-order precision. Numerical simulations confirm the superlinear convergence rate and show that our algorithm outperforms the federated zeroth-order methods available in the literature.", "url": "https://arxiv.org/abs/2309.17174"}, {"metadata": {"arXiv": "2309.17182", "Date": "Fri, 29 Sep 2023 12:27:15 ", "Title": "RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations", "Authors": ["Jiajun He", "Gergely Flamich", "Zongyu Guo", "Jos\\'e Miguel Hern\\'andez-Lobato"], "Categories": "cs.LG", "Comments": ["24 pages", "13 figures"]}, "abstract": "COMpression with Bayesian Implicit NEural Representations (COMBINER) is a recent data compression method that addresses a key inefficiency of previous Implicit Neural Representation (INR)-based approaches: it avoids quantization and enables direct optimization of the rate-distortion performance. However, COMBINER still has significant limitations: 1) it uses factorized priors and posterior approximations that lack flexibility; 2) it cannot effectively adapt to local deviations from global patterns in the data; and 3) its performance can be susceptible to modeling choices and the variational parameters' initializations. Our proposed method, Robust and Enhanced COMBINER (RECOMBINER), addresses these issues by 1) enriching the variational approximation while maintaining its computational cost via a linear reparameterization of the INR weights, 2) augmenting our INRs with learnable positional encodings that enable them to adapt to local details and 3) splitting high-resolution data into patches to increase robustness and utilizing expressive hierarchical priors to capture dependency across patches. We conduct extensive experiments across several data modalities, showcasing that RECOMBINER achieves competitive results with the best INR-based methods and even outperforms autoencoder-based codecs on low-resolution images at low bitrates.", "url": "https://arxiv.org/abs/2309.17182"}, {"metadata": {"arXiv": "2309.17192", "Date": "Fri, 29 Sep 2023 12:43:21 ", "Title": "A Survey of Incremental Transfer Learning: Combining Peer-to-Peer Federated Learning and Domain Incremental Learning for Multicenter Collaboration", "Authors": ["Yixing Huang", "Christoph Bert", "Ahmed Gomaa", "Rainer Fietkau", "Andreas Maier", "Florian Putz"], "Categories": "cs.LG cs.CV"}, "abstract": "Due to data privacy constraints, data sharing among multiple clinical centers is restricted, which impedes the development of high performance deep learning models from multicenter collaboration. Naive weight transfer methods share intermediate model weights without raw data and hence can bypass data privacy restrictions. However, performance drops are typically observed when the model is transferred from one center to the next because of the forgetting problem. Incremental transfer learning, which combines peer-to-peer federated learning and domain incremental learning, can overcome the data privacy issue and meanwhile preserve model performance by using continual learning techniques. In this work, a conventional domain/task incremental learning framework is adapted for incremental transfer learning. A comprehensive survey on the efficacy of different regularization-based continual learning methods for multicenter collaboration is performed. The influences of data heterogeneity, classifier head setting, network optimizer, model initialization, center order, and weight transfer type have been investigated thoroughly. Our framework is publicly accessible to the research community for further development.", "url": "https://arxiv.org/abs/2309.17192"}, {"metadata": {"arXiv": "2309.17194", "Date": "Fri, 29 Sep 2023 12:44:27 ", "Title": "Generalized Activation via Multivariate Projection", "Authors": ["Jiayun Li", "Yuxiao Cheng", "Zhuofan Xia", "Yilin Mo", "Gao Huang"], "Categories": "cs.LG"}, "abstract": "Activation functions are essential to introduce nonlinearity into neural networks, with the Rectified Linear Unit (ReLU) often favored for its simplicity and effectiveness. Motivated by the structural similarity between a shallow Feedforward Neural Network (FNN) and a single iteration of the Projected Gradient Descent (PGD) algorithm, a standard approach for solving constrained optimization problems, we consider ReLU as a projection from R onto the nonnegative half-line R+. Building on this interpretation, we extend ReLU by substituting it with a generalized projection operator onto a convex cone, such as the Second-Order Cone (SOC) projection, thereby naturally extending it to a Multivariate Projection Unit (MPU), an activation function with multiple inputs and multiple outputs. We further provide a mathematical proof establishing that FNNs activated by SOC projections outperform those utilizing ReLU in terms of expressive power. Experimental evaluations on widely-adopted architectures further corroborate MPU's effectiveness against a broader range of existing activation functions.", "url": "https://arxiv.org/abs/2309.17194"}, {"metadata": {"arXiv": "2309.17196", "Date": "Fri, 29 Sep 2023 12:45:39 ", "Title": "ResBit: Residual Bit Vector for Categorical Values", "Authors": ["Masane Fuchi", "Amar Zanashir", "Hiroto Minami", "Tomohiro Takagi"], "Categories": "cs.LG", "Comments": ["16pages and 6 figures"]}, "abstract": "The one-hot vector has long been widely used in machine learning as a simple and generic method for representing discrete data. However, this method increases the number of dimensions linearly with the categorical data to be represented, which is problematic from the viewpoint of spatial computational complexity in deep learning, which requires a large amount of data. Recently, Analog Bits, a method for representing discrete data as a sequence of bits, was proposed on the basis of the high expressiveness of diffusion models. However, since the number of category types to be represented in a generation task is not necessarily at a power of two, there is a discrepancy between the range that Analog Bits can represent and the range represented as category data. If such a value is generated, the problem is that the original category value cannot be restored. To address this issue, we propose Residual Bit Vector (ResBit), which is a hierarchical bit representation. Although it is a general-purpose representation method, in this paper, we treat it as numerical data and show that it can be used as an extension of Analog Bits using Table Residual Bit Diffusion (TRBD), which is incorporated into TabDDPM, a tabular data generation method. We experimentally confirmed that TRBD can generate diverse and high-quality data from small-scale table data to table data containing diverse category values faster than TabDDPM. Furthermore, we show that ResBit can also serve as an alternative to the one-hot vector by utilizing ResBit for conditioning in GANs and as a label expression in image classification.", "url": "https://arxiv.org/abs/2309.17196"}, {"metadata": {"arXiv": "2309.17207", "Date": "Fri, 29 Sep 2023 12:59:28 ", "Title": "Memory Gym: Partially Observable Challenges to Memory-Based Agents in Endless Episodes", "Authors": ["Marco Pleines and Matthias Pallasch and Frank Zimmer and Mike Preuss"], "Categories": "cs.LG", "Comments": ["40 pages", "17 figures", "5 tables", "under review"]}, "abstract": "Memory Gym introduces a unique benchmark designed to test Deep Reinforcement Learning agents, specifically comparing Gated Recurrent Unit (GRU) against Transformer-XL (TrXL), on their ability to memorize long sequences, withstand noise, and generalize. It features partially observable 2D environments with discrete controls, namely Mortar Mayhem, Mystery Path, and Searing Spotlights. These originally finite environments are extrapolated to novel endless tasks that act as an automatic curriculum, drawing inspiration from the car game ``I packed my bag\". These endless tasks are not only beneficial for evaluating efficiency but also intriguingly valuable for assessing the effectiveness of approaches in memory-based agents. Given the scarcity of publicly available memory baselines, we contribute an implementation driven by TrXL and Proximal Policy Optimization. This implementation leverages TrXL as episodic memory using a sliding window approach. In our experiments on the finite environments, TrXL demonstrates superior sample efficiency in Mystery Path and outperforms in Mortar Mayhem. However, GRU is more efficient on Searing Spotlights. Most notably, in all endless tasks, GRU makes a remarkable resurgence, consistently outperforming TrXL by significant margins.", "url": "https://arxiv.org/abs/2309.17207"}, {"metadata": {"arXiv": "2309.17224", "Date": "Fri, 29 Sep 2023 13:24:33 ", "Title": "Training and inference of large language models using 8-bit floating point", "Authors": ["Sergio P. Perez", "Yan Zhang", "James Briggs", "Charlie Blake", "Josh Levy-Kramer", "Paul Balanca", "Carlo Luschi", "Stephen Barlow", "Andrew William Fitzgibbon"], "Categories": "cs.LG cs.AR cs.CL cs.ET cs.PF", "ACM-class": "I.2.7; B.2.4"}, "abstract": "FP8 formats are gaining popularity to boost the computational efficiency for training and inference of large deep learning models. Their main challenge is that a careful choice of scaling is needed to prevent degradation due to the reduced dynamic range compared to higher-precision formats. Although there exists ample literature about selecting such scalings for INT formats, this critical aspect has yet to be addressed for FP8. This paper presents a methodology to select the scalings for FP8 linear layers, based on dynamically updating per-tensor scales for the weights, gradients and activations. We apply this methodology to train and validate large language models of the type of GPT and Llama 2 using FP8, for model sizes ranging from 111M to 70B. To facilitate the understanding of the FP8 dynamics, our results are accompanied by plots of the per-tensor scale distribution for weights, activations and gradients during both training and inference.", "url": "https://arxiv.org/abs/2309.17224"}, {"metadata": {"arXiv": "2309.17230", "Date": "Fri, 29 Sep 2023 13:29:22 ", "Title": "Spurious Feature Diversification Improves Out-of-distribution Generalization", "Authors": ["Yong Lin", "Lu Tan", "Yifan Hao", "Honam Wong", "Hanze Dong", "Weizhong Zhang", "Yujiu Yang", "Tong Zhang"], "Categories": "cs.LG", "Comments": ["70+ pages"]}, "abstract": "Generalization to out-of-distribution (OOD) data is a critical challenge in machine learning. Ensemble-based methods, like weight space ensembles that interpolate model parameters, have been shown to achieve superior OOD performance. However, the underlying mechanism for their effectiveness remains unclear. In this study, we closely examine WiSE-FT, a popular weight space ensemble method that interpolates between a pre-trained and a fine-tuned model. We observe an unexpected phenomenon, in which WiSE-FT successfully corrects many cases where each individual model makes incorrect predictions, which contributes significantly to its OOD effectiveness. To gain further insights, we conduct theoretical analysis in a multi-class setting with a large number of spurious features. Our analysis predicts the above phenomenon and it further shows that ensemble-based models reduce prediction errors in the OOD settings by utilizing a more diverse set of spurious features. Contrary to the conventional wisdom that focuses on learning invariant features for better OOD performance, our findings suggest that incorporating a large number of diverse spurious features weakens their individual contributions, leading to improved overall OOD generalization performance. Empirically we demonstrate the effectiveness of utilizing diverse spurious features on a MultiColorMNIST dataset, and our experimental results are consistent with the theoretical analysis. Building upon the new theoretical insights into the efficacy of ensemble methods, we further identify an issue of WiSE-FT caused by the overconfidence of fine-tuned models in OOD situations. This overconfidence magnifies the fine-tuned model's incorrect prediction, leading to deteriorated OOD ensemble performance. To remedy this problem, we propose a novel method called BAlaNced averaGing (BANG), which significantly enhances the OOD performance of WiSE-FT.", "url": "https://arxiv.org/abs/2309.17230"}, {"metadata": {"arXiv": "2309.17275", "Date": "Fri, 29 Sep 2023 14:27:53 ", "Title": "Utility-based Adaptive Teaching Strategies using Bayesian Theory of Mind", "Authors": ["Cl\\'emence Grislain", "Hugo Caselles-Dupr\\'e", "Olivier Sigaud", "Mohamed Chetouani"], "Categories": "cs.LG"}, "abstract": "Good teachers always tailor their explanations to the learners. Cognitive scientists model this process under the rationality principle: teachers try to maximise the learner's utility while minimising teaching costs. To this end, human teachers seem to build mental models of the learner's internal state, a capacity known as Theory of Mind (ToM). Inspired by cognitive science, we build on Bayesian ToM mechanisms to design teacher agents that, like humans, tailor their teaching strategies to the learners. Our ToM-equipped teachers construct models of learners' internal states from observations and leverage them to select demonstrations that maximise the learners' rewards while minimising teaching costs. Our experiments in simulated environments demonstrate that learners taught this way are more efficient than those taught in a learner-agnostic way. This effect gets stronger when the teacher's model of the learner better aligns with the actual learner's state, either using a more accurate prior or after accumulating observations of the learner's behaviour. This work is a first step towards social machines that teach us and each other, see https://teacher-with-tom.github.io.", "url": "https://arxiv.org/abs/2309.17275"}, {"metadata": {"arXiv": "2309.17278", "Date": "Fri, 29 Sep 2023 14:30:05 ", "Title": "Toward Robust Recommendation via Real-time Vicinal Defense", "Authors": ["Yichang Xu", "Chenwang Wu and Defu Lian"], "Categories": "cs.LG cs.CR cs.IR"}, "abstract": "Recommender systems have been shown to be vulnerable to poisoning attacks, where malicious data is injected into the dataset to cause the recommender system to provide biased recommendations. To defend against such attacks, various robust learning methods have been proposed. However, most methods are model-specific or attack-specific, making them lack generality, while other methods, such as adversarial training, are oriented towards evasion attacks and thus have a weak defense strength in poisoning attacks. In this paper, we propose a general method, Real-time Vicinal Defense (RVD), which leverages neighboring training data to fine-tune the model before making a recommendation for each user. RVD works in the inference phase to ensure the robustness of the specific sample in real-time, so there is no need to change the model structure and training process, making it more practical. Extensive experimental results demonstrate that RVD effectively mitigates targeted poisoning attacks across various models without sacrificing accuracy. Moreover, the defensive effect can be further amplified when our method is combined with other strategies.", "url": "https://arxiv.org/abs/2309.17278"}, {"metadata": {"arXiv": "2309.17296", "Date": "Fri, 29 Sep 2023 14:53:05 ", "Title": "Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation", "Authors": ["Tuan Le", "Julian Cremer", "Frank No\\'e", "Djork-Arn\\'e Clevert", "Kristof Sch\\\"utt"], "Categories": "cs.LG"}, "abstract": "Deep generative diffusion models are a promising avenue for de novo 3D molecular design in material science and drug discovery. However, their utility is still constrained by suboptimal performance with large molecular structures and limited training data. Addressing this gap, we explore the design space of E(3) equivariant diffusion models, focusing on previously blank spots. Our extensive comparative analysis evaluates the interplay between continuous and discrete state spaces. Out of this investigation, we introduce the EQGAT-diff model, which consistently surpasses the performance of established models on the QM9 and GEOM-Drugs datasets by a large margin. Distinctively, EQGAT-diff takes continuous atomic positions while chemical elements and bond types are categorical and employ a time-dependent loss weighting that significantly increases training convergence and the quality of generated samples. To further strengthen the applicability of diffusion models to limited training data, we examine the transferability of EQGAT-diff trained on the large PubChem3D dataset with implicit hydrogens to target distributions with explicit hydrogens. Fine-tuning EQGAT-diff for a couple of iterations further pushes state-of-the-art performance across datasets. We envision that our findings will find applications in structure-based drug design, where the accuracy of generative models for small datasets of complex molecules is critical.", "url": "https://arxiv.org/abs/2309.17296"}, {"metadata": {"arXiv": "2309.17310", "Date": "Fri, 29 Sep 2023 15:08:28 ", "Title": "Leave-one-out Distinguishability in Machine Learning", "Authors": ["Jiayuan Ye", "Anastasia Borovykh", "Soufiane Hayou", "Reza Shokri"], "Categories": "cs.LG"}, "abstract": "We introduce a new analytical framework to quantify the changes in a machine learning algorithm's output distribution following the inclusion of a few data points in its training set, a notion we define as leave-one-out distinguishability (LOOD). This problem is key to measuring data **memorization** and **information leakage** in machine learning, and the **influence** of training data points on model predictions. We illustrate how our method broadens and refines existing empirical measures of memorization and privacy risks associated with training data. We use Gaussian processes to model the randomness of machine learning algorithms, and validate LOOD with extensive empirical analysis of information leakage using membership inference attacks. Our theoretical framework enables us to investigate the causes of information leakage and where the leakage is high. For example, we analyze the influence of activation functions, on data memorization. Additionally, our method allows us to optimize queries that disclose the most significant information about the training data in the leave-one-out setting. We illustrate how optimal queries can be used for accurate **reconstruction** of training data.", "url": "https://arxiv.org/abs/2309.17310"}, {"metadata": {"arXiv": "2309.17339", "Date": "Fri, 29 Sep 2023 15:48:38 ", "Title": "Scaling Experiments in Self-Supervised Cross-Table Representation Learning", "Authors": ["Maximilian Schambach", "Dominique Paul", "Johannes S. Otterbach"], "Categories": "cs.LG"}, "abstract": "To analyze the scaling potential of deep tabular representation learning models, we introduce a novel Transformer-based architecture specifically tailored to tabular data and cross-table representation learning by utilizing table-specific tokenizers and a shared Transformer backbone. Our training approach encompasses both single-table and cross-table models, trained via missing value imputation through a self-supervised masked cell recovery objective. To understand the scaling behavior of our method, we train models of varying sizes, ranging from approximately $10^4$ to $10^7$ parameters. These models are trained on a carefully curated pretraining dataset, consisting of 135M training tokens sourced from 76 diverse datasets. We assess the scaling of our architecture in both single-table and cross-table pretraining setups by evaluating the pretrained models using linear probing on a curated set of benchmark datasets and comparing the results with conventional baselines.", "url": "https://arxiv.org/abs/2309.17339"}, {"metadata": {"arXiv": "2309.17347", "Date": "Wed, 27 Sep 2023 11:47:05 ", "Title": "Demographic Parity: Mitigating Biases in Real-World Data", "Authors": ["Orestis Loukas", "Ho-Ryun Chung"], "Categories": "cs.LG cs.CY", "Comments": ["24 pages", "16 Figures", "Python code attached"]}, "abstract": "Computer-based decision systems are widely used to automate decisions in many aspects of everyday life, which include sensitive areas like hiring, loaning and even criminal sentencing. A decision pipeline heavily relies on large volumes of historical real-world data for training its models. However, historical training data often contains gender, racial or other biases which are propagated to the trained models influencing computer-based decisions. In this work, we propose a robust methodology that guarantees the removal of unwanted biases while maximally preserving classification utility. Our approach can always achieve this in a model-independent way by deriving from real-world data the asymptotic dataset that uniquely encodes demographic parity and realism. As a proof-of-principle, we deduce from public census records such an asymptotic dataset from which synthetic samples can be generated to train well-established classifiers. Benchmarking the generalization capability of these classifiers trained on our synthetic data, we confirm the absence of any explicit or implicit bias in the computer-aided decision.", "url": "https://arxiv.org/abs/2309.17347"}, {"metadata": {"arXiv": "2309.17348", "Date": "Fri, 29 Sep 2023 15:55:17 ", "Title": "Efficient Biologically Plausible Adversarial Training", "Authors": ["Matilde Tristany Farinha", "Thomas Ortner", "Giorgia Dellaferrera", "Benjamin Grewe", "Angeliki Pantazi"], "Categories": "cs.LG"}, "abstract": "Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show astounding performance and are increasingly often used in performing our daily life tasks. However, ANNs are highly vulnerable to adversarial attacks, which alter inputs with small targeted perturbations that drastically disrupt the models' performance. The most effective method to make ANNs robust against these attacks is adversarial training, in which the training dataset is augmented with exemplary adversarial samples. Unfortunately, this approach has the drawback of increased training complexity since generating adversarial samples is very computationally demanding. In contrast to ANNs, humans are not susceptible to adversarial attacks. Therefore, in this work, we investigate whether biologically-plausible learning algorithms are more robust against adversarial attacks than BP. In particular, we present an extensive comparative analysis of the adversarial robustness of BP and \\textit{Present the Error to Perturb the Input To modulate Activity} (PEPITA), a recently proposed biologically-plausible learning algorithm, on various computer vision tasks. We observe that PEPITA has higher intrinsic adversarial robustness and, with adversarial training, has a more favourable natural-vs-adversarial performance trade-off as, for the same natural accuracies, PEPITA's adversarial accuracies decrease in average by 0.26% and BP's by 8.05%.", "url": "https://arxiv.org/abs/2309.17348"}, {"metadata": {"arXiv": "2309.17357", "Date": "Fri, 29 Sep 2023 16:03:25 ", "Title": "Module-wise Training of Neural Networks via the Minimizing Movement Scheme", "Authors": ["Skander Karkar and Ibrahim Ayed and Emmanuel de B\\'ezenac and Patrick Gallinari"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "Greedy layer-wise or module-wise training of neural networks is compelling in constrained and on-device settings where memory is limited, as it circumvents a number of problems of end-to-end back-propagation. However, it suffers from a stagnation problem, whereby early layers overfit and deeper layers stop increasing the test accuracy after a certain depth. We propose to solve this issue by introducing a module-wise regularization inspired by the minimizing movement scheme for gradient flows in distribution space. We call the method TRGL for Transport Regularized Greedy Learning and study it theoretically, proving that it leads to greedy modules that are regular and that progressively solve the task. Experimentally, we show improved accuracy of module-wise training of various architectures such as ResNets, Transformers and VGG, when our regularization is added, superior to that of other module-wise training methods and often to end-to-end training, with as much as 60% less memory usage.", "url": "https://arxiv.org/abs/2309.17357"}, {"metadata": {"arXiv": "2309.17370", "Date": "Fri, 29 Sep 2023 16:20:34 ", "Title": "Graph-based Neural Weather Prediction for Limited Area Modeling", "Authors": ["Joel Oskarsson", "Tomas Landelius", "Fredrik Lindsten"], "Categories": "cs.LG stat.ML", "Comments": ["37 pages", "26 figures. Code will be made available at: https://github.com/joeloskarsson/neural-lam"]}, "abstract": "The rise of accurate machine learning methods for weather forecasting is creating radical new possibilities for modeling the atmosphere. In the time of climate change, having access to high-resolution forecasts from models like these is also becoming increasingly vital. While most existing Neural Weather Prediction (NeurWP) methods focus on global forecasting, an important question is how these techniques can be applied to limited area modeling. In this work we adapt the graph-based NeurWP approach to the limited area setting and propose a multi-scale hierarchical model extension. Our approach is validated by experiments with a local model for the Nordic region.", "url": "https://arxiv.org/abs/2309.17370"}, {"metadata": {"arXiv": "2309.17371", "Date": "Fri, 29 Sep 2023 16:20:36 ", "Title": "Adversarial Imitation Learning from Visual Observations using Latent Information", "Authors": ["Vittorio Giammarino", "James Queeney", "Ioannis Ch. Paschalidis"], "Categories": "cs.LG cs.SY eess.SY stat.ML"}, "abstract": "We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-the-art performance while providing significant computational advantages. Additionally, we show how our method can be used to improve the efficiency of reinforcement learning from pixels by leveraging expert videos. To ensure reproducibility, we provide free access to our code.", "url": "https://arxiv.org/abs/2309.17371"}, {"metadata": {"arXiv": "2309.17388", "Date": "Fri, 29 Sep 2023 16:50:23 ", "Title": "Tree Cross Attention", "Authors": ["Leo Feng", "Frederick Tung", "Hossein Hajimirsadeghi", "Yoshua Bengio", "Mohamed Osama Ahmed"], "Categories": "cs.LG"}, "abstract": "Cross Attention is a popular method for retrieving information from a set of context tokens for making predictions. At inference time, for each prediction, Cross Attention scans the full set of $\\mathcal{O}(N)$ tokens. In practice, however, often only a small subset of tokens are required for good performance. Methods such as Perceiver IO are cheap at inference as they distill the information to a smaller-sized set of latent tokens $L < N$ on which cross attention is then applied, resulting in only $\\mathcal{O}(L)$ complexity. However, in practice, as the number of input tokens and the amount of information to distill increases, the number of latent tokens needed also increases significantly. In this work, we propose Tree Cross Attention (TCA) - a module based on Cross Attention that only retrieves information from a logarithmic $\\mathcal{O}(\\log(N))$ number of tokens for performing inference. TCA organizes the data in a tree structure and performs a tree search at inference time to retrieve the relevant tokens for prediction. Leveraging TCA, we introduce ReTreever, a flexible architecture for token-efficient inference. We show empirically that Tree Cross Attention (TCA) performs comparable to Cross Attention across various classification and uncertainty regression tasks while being significantly more token-efficient. Furthermore, we compare ReTreever against Perceiver IO, showing significant gains while using the same number of tokens for inference.", "url": "https://arxiv.org/abs/2309.17388"}, {"metadata": {"arXiv": "2309.17395", "Date": "Fri, 29 Sep 2023 16:57:21 ", "Title": "AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition", "Authors": ["Andrew Rouditchenko", "Ronan Collobert", "Tatiana Likhomanenko"], "Categories": "cs.LG cs.SD eess.AS stat.ML", "Comments": ["Under review"]}, "abstract": "Audio-visual speech contains synchronized audio and visual information that provides cross-modal supervision to learn representations for both automatic speech recognition (ASR) and visual speech recognition (VSR). We introduce continuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a semi-supervised method to train an audio-visual speech recognition (AVSR) model on a combination of labeled and unlabeled videos with continuously regenerated pseudo-labels. Our models are trained for speech recognition from audio-visual inputs and can perform speech recognition using both audio and visual modalities, or only one modality. Our method uses the same audio-visual model for both supervised training and pseudo-label generation, mitigating the need for external speech recognition models to generate pseudo-labels. AV-CPL obtains significant improvements in VSR performance on the LRS3 dataset while maintaining practical ASR and AVSR performance. Finally, using visual-only speech data, our method is able to leverage unlabeled visual speech to improve VSR.", "url": "https://arxiv.org/abs/2309.17395"}, {"metadata": {"arXiv": "2309.17417", "Date": "Fri, 29 Sep 2023 17:26:44 ", "Title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction", "Authors": ["Arjun Subramonian", "Levent Sagun", "Yizhou Sun"], "Categories": "cs.LG cs.CY cs.SI"}, "abstract": "Graph neural network (GNN) link prediction is increasingly deployed in citation, collaboration, and online social networks to recommend academic literature, collaborators, and friends. While prior research has investigated the dyadic fairness of GNN link prediction, the within-group fairness and ``rich get richer'' dynamics of link prediction remain underexplored. However, these aspects have significant consequences for degree and power imbalances in networks. In this paper, we shed light on how degree bias in networks affects Graph Convolutional Network (GCN) link prediction. In particular, we theoretically uncover that GCNs with a symmetric normalized graph filter have a within-group preferential attachment bias. We validate our theoretical analysis on real-world citation, collaboration, and online social networks. We further bridge GCN's preferential attachment bias with unfairness in link prediction and propose a new within-group fairness metric. This metric quantifies disparities in link prediction scores between social groups, towards combating the amplification of degree and power disparities. Finally, we propose a simple training-time strategy to alleviate within-group unfairness, and we show that it is effective on citation, online social, and credit networks.", "url": "https://arxiv.org/abs/2309.17417"}, {"metadata": {"arXiv": "2309.16683", "Date": "Wed, 02 Aug 2023 09:36:39 ", "Title": "Controlling the Solo12 Quadruped Robot with Deep Reinforcement Learning", "Authors": ["Michel Aractingi (LAAS-GEPETTO)", "Pierre-Alexandre L\\'eziart (LAAS-GEPETTO)", "Thomas Flayols (LAAS-GEPETTO)", "Julien Perez", "Tomi Silander", "Philippe Sou\\`eres (LAAS-GEPETTO)"], "Categories": "cs.RO cs.LG", "Report-no": "Rapport LAAS no 22263", "Journal-ref": "Scientific Reports, 2023, 13 (11945), pp.12", "DOI": "10.1038/s41598-023-38259-7"}, "abstract": "Quadruped robots require robust and general locomotion skills to exploit their mobility potential in complex and challenging environments. In this work, we present the first implementation of a robust end-to-end learning-based controller on the Solo12 quadruped. Our method is based on deep reinforcement learning of joint impedance references. The resulting control policies follow a commanded velocity reference while being efficient in its energy consumption, robust and easy to deploy. We detail the learning procedure and method for transfer on the real robot. In our experiments, we show that the Solo12 robot is a suitable open-source platform for research combining learning and control because of the easiness in transferring and deploying learned controllers.", "url": "https://arxiv.org/abs/2309.16683"}, {"metadata": {"arXiv": "2309.16718", "Date": "Wed, 13 Sep 2023 13:18:29 ", "Title": "A Real-World Quadrupedal Locomotion Benchmark for Offline Reinforcement Learning", "Authors": ["Hongyin Zhang", "Shuyu Yang and Donglin Wang"], "Categories": "cs.RO cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Online reinforcement learning (RL) methods are often data-inefficient or unreliable, making them difficult to train on real robotic hardware, especially quadruped robots. Learning robotic tasks from pre-collected data is a promising direction. Meanwhile, agile and stable legged robotic locomotion remains an open question in their general form. Offline reinforcement learning (ORL) has the potential to make breakthroughs in this challenging field, but its current bottleneck lies in the lack of diverse datasets for challenging realistic tasks. To facilitate the development of ORL, we benchmarked 11 ORL algorithms in the realistic quadrupedal locomotion dataset. Such dataset is collected by the classic model predictive control (MPC) method, rather than the model-free online RL method commonly used by previous benchmarks. Extensive experimental results show that the best-performing ORL algorithms can achieve competitive performance compared with the model-free RL, and even surpass it in some tasks. However, there is still a gap between the learning-based methods and MPC, especially in terms of stability and rapid adaptation. Our proposed benchmark will serve as a development platform for testing and evaluating the performance of ORL algorithms in real-world legged locomotion tasks.", "url": "https://arxiv.org/abs/2309.16718"}, {"metadata": {"arXiv": "2309.17209", "Date": "Fri, 29 Sep 2023 13:02:56 ", "Title": "Robots That Can See: Leveraging Human Pose for Trajectory Prediction", "Authors": ["Tim Salzmann", "Lewis Chiang", "Markus Ryll", "Dorsa Sadigh", "Carolina Parada and Alex Bewley"], "Categories": "cs.RO cs.CV cs.HC cs.LG", "Comments": ["Project page: https://human-scene-transformer.github.io/"], "Journal-ref": "IEEE Robotics and Automation Letters, vol. 8, no. 11, pp. 7090-7097, Nov. 2023", "DOI": "10.1109/LRA.2023.3312035"}, "abstract": "Anticipating the motion of all humans in dynamic environments such as homes and offices is critical to enable safe and effective robot navigation. Such spaces remain challenging as humans do not follow strict rules of motion and there are often multiple occluded entry points such as corners and doors that create opportunities for sudden encounters. In this work, we present a Transformer based architecture to predict human future trajectories in human-centric environments from input features including human positions, head orientations, and 3D skeletal keypoints from onboard in-the-wild sensory information. The resulting model captures the inherent uncertainty for future human trajectory prediction and achieves state-of-the-art performance on common prediction benchmarks and a human tracking dataset captured from a mobile robot adapted for the prediction task. Furthermore, we identify new agents with limited historical data as a major contributor to error and demonstrate the complementary nature of 3D skeletal poses in reducing prediction error in such challenging scenarios.", "url": "https://arxiv.org/abs/2309.17209"}, {"metadata": {"arXiv": "2309.16697", "Date": "Fri, 11 Aug 2023 06:42:29 ", "Title": "Inappropriate Benefits and Identification of ChatGPT Misuse in Programming Tests: A Controlled Experiment", "Authors": ["Hapnes Toba", "Oscar Karnalim", "Meliana Christianti Johan", "Terutoshi Tada", "Yenni Merlin Djajalaksana", "Tristan Vivaldy"], "Categories": "cs.AI cs.CY", "Comments": ["Accepted at The 26th International Conference on Interactive Collaborative Learning (ICL 2023)"]}, "abstract": "While ChatGPT may help students to learn to program, it can be misused to do plagiarism, a breach of academic integrity. Students can ask ChatGPT to complete a programming task, generating a solution from other people's work without proper acknowledgment of the source(s). To help address this new kind of plagiarism, we performed a controlled experiment measuring the inappropriate benefits of using ChatGPT in terms of completion time and programming performance. We also reported how to manually identify programs aided with ChatGPT (via student behavior while using ChatGPT) and student perspective of ChatGPT (via a survey). Seventeen students participated in the experiment. They were asked to complete two programming tests. They were divided into two groups per the test: one group should complete the test without help while the other group should complete it with ChatGPT. Our study shows that students with ChatGPT complete programming tests two times faster than those without ChatGPT, though their programming performance is comparable. The generated code is highly efficient and uses complex data structures like lists and dictionaries. Based on the survey results, ChatGPT is recommended to be used as an assistant to complete programming tasks and other general assignments. ChatGPT will be beneficial as a reference as other search engines do. Logical and critical thinking are needed to validate the result presented by ChatGPT.", "url": "https://arxiv.org/abs/2309.16697"}, {"metadata": {"arXiv": "2309.16702", "Date": "Wed, 16 Aug 2023 09:26:32 ", "Title": "Prediction and Interpretation of Vehicle Trajectories in the Graph Spectral Domain", "Authors": ["Marion Neumeier", "Sebastian Dorn", "Michael Botsch", "Wolfgang Utschick"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted as a conference paper for IEEE ITSC 2023", "Bilbao", "Spain"]}, "abstract": "This work provides a comprehensive analysis and interpretation of the graph spectral representation of traffic scenarios. Based on a spatio-temporal vehicle interaction graph, an observed traffic scenario can be transformed into the graph spectral domain by means of the multidimensional Graph Fourier Transformation. Since these spectral scenario representations have shown to successfully incorporate the complex and interactive nature of traffic scenarios, the beneficial feature representation is employed for the purpose of predicting vehicle trajectories. This work introduces GFTNNv2, a deep learning network predicting vehicle trajectories in the graph spectral domain. Evaluation of the GFTNNv2 on the publicly available datasets highD and NGSIM shows a performance gain of up to 25% in comparison to state-of-the-art prediction approaches.", "url": "https://arxiv.org/abs/2309.16702"}, {"metadata": {"arXiv": "2309.16721", "Date": "Fri, 15 Sep 2023 10:51:21 ", "Title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab", "Authors": ["Xiaokai Qin", "Mingda Song", "Yangguan Chen", "Zhehong Ai", "Jing Jiang"], "Categories": "cs.AI cs.RO"}, "abstract": "The integration of robots in chemical experiments has enhanced experimental efficiency, but lacking the human intelligence to comprehend literature, they seldom provide assistance in experimental design. Therefore, achieving full-process autonomy from experiment design to validation in self-driven laboratories (SDL) remains a challenge. The introduction of Generative Pre-trained Transformers (GPT), particularly GPT-4, into robotic experimentation offers a solution. We introduce GPT-Lab, a paradigm that employs GPT models to give robots human-like intelligence. With our robotic experimentation platform, GPT-Lab mines literature for materials and methods and validates findings through high-throughput synthesis. As a demonstration, GPT-Lab analyzed 500 articles, identified 18 potential reagents, and successfully produced an accurate humidity colorimetric sensor with a root mean square error (RMSE) of 2.68%. This showcases the rapid materials discovery and validation potential of our system.", "url": "https://arxiv.org/abs/2309.16721"}, {"metadata": {"arXiv": "2309.16960", "Date": "Fri, 29 Sep 2023 03:57:39 ", "Title": "On Generating Explanations for Reinforcement Learning Policies: An Empirical Study", "Authors": ["Mikihisa Yuasa", "Huy T. Tran", "Ramavarapu S. Sreenivas"], "Categories": "cs.AI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "In this paper, we introduce a set of \\textit{Linear Temporal Logic} (LTL) formulae designed to provide explanations for policies. Our focus is on crafting explanations that elucidate both the ultimate objectives accomplished by the policy and the prerequisites it upholds throughout its execution. These LTL-based explanations feature a structured representation, which is particularly well-suited for local-search techniques. The effectiveness of our proposed approach is illustrated through a simulated capture the flag environment. The paper concludes with suggested directions for future research.", "url": "https://arxiv.org/abs/2309.16960"}, {"metadata": {"arXiv": "2309.17057", "Date": "Fri, 29 Sep 2023 08:40:08 ", "Title": "Tell Me a Story! Narrative-Driven XAI with Large Language Models", "Authors": ["David Martens", "Camille Dams", "James Hinns", "and Mark Vergouwen"], "Categories": "cs.AI"}, "abstract": "In today's critical domains, the predominance of black-box machine learning models amplifies the demand for Explainable AI (XAI). The widely used SHAP values, while quantifying feature importance, are often too intricate and lack human-friendly explanations. Furthermore, counterfactual (CF) explanations present `what ifs' but leave users grappling with the 'why'. To bridge this gap, we introduce XAIstories. Leveraging Large Language Models, XAIstories provide narratives that shed light on AI predictions: SHAPstories do so based on SHAP explanations to explain a prediction score, while CFstories do so for CF explanations to explain a decision. Our results are striking: over 90% of the surveyed general audience finds the narrative generated by SHAPstories convincing. Data scientists primarily see the value of SHAPstories in communicating explanations to a general audience, with 92% of data scientists indicating that it will contribute to the ease and confidence of nonspecialists in understanding AI predictions. Additionally, 83% of data scientists indicate they are likely to use SHAPstories for this purpose. In image classification, CFstories are considered more or equally convincing as users own crafted stories by over 75% of lay user participants. CFstories also bring a tenfold speed gain in creating a narrative, and improves accuracy by over 20% compared to manually created narratives. The results thereby suggest that XAIstories may provide the missing link in truly explaining and understanding AI predictions.", "url": "https://arxiv.org/abs/2309.17057"}, {"metadata": {"arXiv": "2309.17122", "Date": "Fri, 29 Sep 2023 10:36:04 ", "Title": "Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?", "Authors": ["Johannes Frey and Lars-Peter Meyer and Natanael Arndt and Felix Brei and Kirill Bulert"], "Categories": "cs.AI cs.CL cs.DB", "Comments": ["accepted for proceedings of DL4KG Workshop @ ISWC 2023 at ceur-ws.org"]}, "abstract": "Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within RDF knowledge graph engineering workflows utilizing Turtle representation. While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context.", "url": "https://arxiv.org/abs/2309.17122"}, {"metadata": {"arXiv": "2309.17176", "Date": "Fri, 29 Sep 2023 12:16:19 ", "Title": "RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds", "Authors": ["Wanpeng Zhang", "Zongqing Lu"], "Categories": "cs.AI cs.CL"}, "abstract": "While reinforcement learning (RL) shows remarkable success in decision-making problems, it often requires a lot of interactions with the environment, and in sparse-reward environments, it is challenging to learn meaningful policies. Large Language Models (LLMs) can potentially provide valuable guidance to agents in learning policies, thereby enhancing the performance of RL algorithms in such environments. However, LLMs often encounter difficulties in understanding downstream tasks, which hinders their ability to optimally assist agents in these tasks. A common approach to mitigating this issue is to fine-tune the LLMs with task-related data, enabling them to offer useful guidance for RL agents. However, this approach encounters several difficulties, such as inaccessible model weights or the need for significant computational resources, making it impractical. In this work, we introduce RLAdapter, a framework that builds a better connection between RL algorithms and LLMs by incorporating an adapter model. Within the RLAdapter framework, fine-tuning a lightweight language model with information generated during the training process of RL agents significantly aids LLMs in adapting to downstream tasks, thereby providing better guidance for RL agents. We conducted experiments to evaluate RLAdapter in the Crafter environment, and the results show that RLAdapter surpasses the SOTA baselines. Furthermore, agents under our framework exhibit common-sense behaviors that are absent in baseline models.", "url": "https://arxiv.org/abs/2309.17176"}, {"metadata": {"arXiv": "2309.17252", "Date": "Fri, 29 Sep 2023 14:02:34 ", "Title": "Forest Mixing: investigating the impact of multiple search trees and a shared refinements pool on ontology learning", "Authors": ["Marco Pop-Mihali and Adrian Groza"], "Categories": "cs.AI"}, "abstract": "We aim at development white-box machine learning algorithms. We focus here on algorithms for learning axioms in description logic. We extend the Class Expression Learning for Ontology Engineering (CELOE) algorithm contained in the DL-Learner tool. The approach uses multiple search trees and a shared pool of refinements in order to split the search space in smaller subspaces. We introduce the conjunction operation of best class expressions from each tree, keeping the results which give the most information. The aim is to foster exploration from a diverse set of starting classes and to streamline the process of finding class expressions in ontologies. %, particularly in large search spaces. The current implementation and settings indicated that the Forest Mixing approach did not outperform the traditional CELOE. Despite these results, the conceptual proposal brought forward by this approach may stimulate future improvements in class expression finding in ontologies. % and influence. % the way we traverse search spaces in general.", "url": "https://arxiv.org/abs/2309.17252"}, {"metadata": {"arXiv": "2309.17255", "Date": "Fri, 29 Sep 2023 14:03:34 ", "Title": "Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities", "Authors": ["Jiaoyan Chen", "Hang Dong", "Janna Hastings", "Ernesto Jim\\'enez-Ruiz", "Vanessa Lopez", "Pierre Monnin", "Catia Pesquita", "Petr \\v{S}koda", "Valentina Tamma"], "Categories": "cs.AI cs.CL", "Comments": ["32 pages", "1 figure", "accepted for Transactions on Graph Data and Knowledge (TGDK)"], "ACM-class": "I.2.4; J.3"}, "abstract": "The term life sciences refers to the disciplines that study living organisms and life processes, and include chemistry, biology, medicine, and a range of other related disciplines. Research efforts in life sciences are heavily data-driven, as they produce and consume vast amounts of scientific data, much of which is intrinsically relational and graph-structured. The volume of data and the complexity of scientific concepts and relations referred to therein promote the application of advanced knowledge-driven technologies for managing and interpreting data, with the ultimate aim to advance scientific discovery. In this survey and position paper, we discuss recent developments and advances in the use of graph-based technologies in life sciences and set out a vision for how these technologies will impact these fields into the future. We focus on three broad topics: the construction and management of Knowledge Graphs (KGs), the use of KGs and associated technologies in the discovery of new knowledge, and the use of KGs in artificial intelligence applications to support explanations (explainable AI). We select a few exemplary use cases for each topic, discuss the challenges and open research questions within these topics, and conclude with a perspective and outlook that summarizes the overarching challenges and their potential solutions as a guide for future research.", "url": "https://arxiv.org/abs/2309.17255"}, {"metadata": {"arXiv": "2309.17277", "Date": "Fri, 29 Sep 2023 14:30:03 ", "Title": "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT4", "Authors": ["Jiaxian Guo", "Bo Yang", "Paul Yoo", "Yuchen Lin", "Yusuke Iwasawa", "Yutaka Matsuo"], "Categories": "cs.AI"}, "abstract": "Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce \\textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a planning strategy that enables GPT-4 to competently play against different opponents, adapting its gameplay style as needed, while requiring only the game rules and descriptions of observations as input. In the experiments, we qualitatively showcase the capabilities of Suspicion-Agent across three different imperfect information games and then quantitatively evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can potentially outperform traditional algorithms designed for imperfect information games, without any specialized training or examples. In order to encourage and foster deeper insights within the community, we make our game-related data publicly available.", "url": "https://arxiv.org/abs/2309.17277"}, {"metadata": {"arXiv": "2309.17288", "Date": "Fri, 29 Sep 2023 14:46:30 ", "Title": "AutoAgents: A Framework for Automatic Agent Generation", "Authors": ["Guangyao Chen", "Siwei Dong", "Yu Shu", "Ge Zhang", "Jaward Sesay", "B\\\"orje F. Karlsson", "Jie Fu", "Yemin Shi"], "Categories": "cs.AI"}, "abstract": "Large language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them. Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods. This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks. The repository of this project is available at https://github.com/LinkSoul-AI/AutoAgents.", "url": "https://arxiv.org/abs/2309.17288"}, {"metadata": {"arXiv": "2309.17319", "Date": "Fri, 29 Sep 2023 15:25:31 ", "Title": "Building Privacy-Preserving and Secure Geospatial Artificial Intelligence Foundation Models", "Authors": ["Jinmeng Rao", "Song Gao", "Gengchen Mai", "Krzysztof Janowicz"], "Categories": "cs.AI", "Comments": ["1 figure"], "ACM-class": "I.2.0", "Journal-ref": "ACM SIGSPATIAL 2023", "DOI": "10.1145/3589132.3625611"}, "abstract": "In recent years we have seen substantial advances in foundation models for artificial intelligence, including language, vision, and multimodal models. Recent studies have highlighted the potential of using foundation models in geospatial artificial intelligence, known as GeoAI Foundation Models or Geo-Foundation Models, for geographic question answering, remote sensing image understanding, map generation, and location-based services, among others. However, the development and application of GeoAI foundation models can pose serious privacy and security risks, which have not been fully discussed or addressed to date. This paper introduces the potential privacy and security risks throughout the lifecycle of GeoAI foundation models and proposes a comprehensive blueprint for preventative and control strategies. Through this vision paper, we hope to draw the attention of researchers and policymakers in geospatial domains to these privacy and security risks inherent in GeoAI foundation models and advocate for the development of privacy-preserving and secure GeoAI foundation models.", "url": "https://arxiv.org/abs/2309.17319"}, {"metadata": {"arXiv": "2309.16701", "Date": "Tue, 15 Aug 2023 17:38:55 ", "Title": "MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool", "Authors": ["Nakyeong Yang", "Minsung Kim", "Seunghyun Yoon", "Joongbo Shin", "Kyomin Jung"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["13 pages", "8 figures"]}, "abstract": "With the explosion of multimedia content in recent years, natural language video localization, which focuses on detecting video moment that matches a given natural language query, has become a critical problem. However, none of the previous research explores localizing a moment from a large corpus where multiple positive and negative videos exist. In this paper, we propose an MVMR (Massive Videos Moment Retrieval) task, which aims to localize video frames from a massive set of videos given a text query. For this task, we suggest methods for constructing datasets by employing similarity filtering on the existing video localization datasets and introduce three MVMR datasets. Specifically, we employ embedding-based text similarity matching and video-language grounding techniques to calculate the relevance score between a target query and videos to define positive and negative sets. For the proposed MVMR task, we further develop a strong model, Reliable Mutual Matching Network (RMMN), which employs a contrastive learning scheme that selectively filters the reliable and informative negatives leading the model more robust on the MVMR task. Experimental results on the introduced datasets reveal that existing NLVL models are easily distracted by negative video frames, whereas our model shows significant performance.", "url": "https://arxiv.org/abs/2309.16701"}, {"metadata": {"arXiv": "2309.16710", "Date": "Thu, 17 Aug 2023 14:39:24 ", "Title": "General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing", "Authors": ["Dmitrii Korzh", "Mikhail Pautov", "Olga Tsymboi", "Ivan Oseledets"], "Categories": "cs.CV cs.AI"}, "abstract": "Randomized smoothing is the state-of-the-art approach to construct image classifiers that are provably robust against additive adversarial perturbations of bounded magnitude. However, it is more complicated to construct reasonable certificates against semantic transformation (e.g., image blurring, translation, gamma correction) and their compositions. In this work, we propose \\emph{General Lipschitz (GL),} a new framework to certify neural networks against composable resolvable semantic perturbations. Within the framework, we analyze transformation-dependent Lipschitz-continuity of smoothed classifiers w.r.t. transformation parameters and derive corresponding robustness certificates. Our method performs comparably to state-of-the-art approaches on the ImageNet dataset.", "url": "https://arxiv.org/abs/2309.16710"}, {"metadata": {"arXiv": "2309.16715", "Date": "Mon, 21 Aug 2023 15:48:15 ", "Title": "MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving", "Authors": ["Yibo Liu", "Kelly Zhu", "Guile Wu", "Yuan Ren", "Bingbing Liu", "Yang Liu", "Jinjun Shan"], "Categories": "cs.CV cs.AI"}, "abstract": "Reconstructing 3D vehicles from noisy and sparse partial point clouds is of great significance to autonomous driving. Most existing 3D reconstruction methods cannot be directly applied to this problem because they are elaborately designed to deal with dense inputs with trivial noise. In this work, we propose a novel framework, dubbed MV-DeepSDF, which estimates the optimal Signed Distance Function (SDF) shape representation from multi-sweep point clouds to reconstruct vehicles in the wild. Although there have been some SDF-based implicit modeling methods, they only focus on single-view-based reconstruction, resulting in low fidelity. In contrast, we first analyze multi-sweep consistency and complementarity in the latent feature space and propose to transform the implicit space shape estimation problem into an element-to-set feature extraction problem. Then, we devise a new architecture to extract individual element-level representations and aggregate them to generate a set-level predicted latent code. This set-level latent code is an expression of the optimal 3D shape in the implicit space, and can be subsequently decoded to a continuous SDF of the vehicle. In this way, our approach learns consistent and complementary information among multi-sweeps for 3D vehicle reconstruction. We conduct thorough experiments on two real-world autonomous driving datasets (Waymo and KITTI) to demonstrate the superiority of our approach over state-of-the-art alternative methods both qualitatively and quantitatively.", "url": "https://arxiv.org/abs/2309.16715"}, {"metadata": {"arXiv": "2309.16772", "Date": "Thu, 28 Sep 2023 18:09:40 ", "Title": "XVO: Generalized Visual Odometry via Cross-Modal Self-Training", "Authors": ["Lei Lai and Zhongkai Shangguan and Jimuyang Zhang and Eshed Ohn-Bar"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["ICCV 2023"]}, "abstract": "We propose XVO, a semi-supervised learning method for training generalized monocular Visual Odometry (VO) models with robust off-the-self operation across diverse datasets and settings. In contrast to standard monocular VO approaches which often study a known calibration within a single dataset, XVO efficiently learns to recover relative pose with real-world scale from visual scene semantics, i.e., without relying on any known camera parameters. We optimize the motion estimation model via self-training from large amounts of unconstrained and heterogeneous dash camera videos available on YouTube. Our key contribution is twofold. First, we empirically demonstrate the benefits of semi-supervised training for learning a general-purpose direct VO regression network. Second, we demonstrate multi-modal supervision, including segmentation, flow, depth, and audio auxiliary prediction tasks, to facilitate generalized representations for the VO task. Specifically, we find audio prediction task to significantly enhance the semi-supervised learning process while alleviating noisy pseudo-labels, particularly in highly dynamic and out-of-domain video data. Our proposed teacher network achieves state-of-the-art performance on the commonly used KITTI benchmark despite no multi-frame optimization or knowledge of camera parameters. Combined with the proposed semi-supervised step, XVO demonstrates off-the-shelf knowledge transfer across diverse conditions on KITTI, nuScenes, and Argoverse without fine-tuning.", "url": "https://arxiv.org/abs/2309.16772"}, {"metadata": {"arXiv": "2309.16783", "Date": "Thu, 28 Sep 2023 18:22:41 ", "Title": "Photonic Accelerators for Image Segmentation in Autonomous Driving and Defect Detection", "Authors": ["Lakshmi Nair", "David Widemann", "Brad Turcott", "Nick Moore", "Alexandra Wleklinski", "Darius Bunandar", "Ioannis Papavasileiou", "Shihu Wang", "Eric Logan"], "Categories": "cs.CV cs.AI", "MSC-class": "I.2.10", "ACM-class": "I.2.10; I.5.0"}, "abstract": "Photonic computing promises faster and more energy-efficient deep neural network (DNN) inference than traditional digital hardware. Advances in photonic computing can have profound impacts on applications such as autonomous driving and defect detection that depend on fast, accurate and energy efficient execution of image segmentation models. In this paper, we investigate image segmentation on photonic accelerators to explore: a) the types of image segmentation DNN architectures that are best suited for photonic accelerators, and b) the throughput and energy efficiency of executing the different image segmentation models on photonic accelerators, along with the trade-offs involved therein. Specifically, we demonstrate that certain segmentation models exhibit negligible loss in accuracy (compared to digital float32 models) when executed on photonic accelerators, and explore the empirical reasoning for their robustness. We also discuss techniques for recovering accuracy in the case of models that do not perform well. Further, we compare throughput (inferences-per-second) and energy consumption estimates for different image segmentation workloads on photonic accelerators. We discuss the challenges and potential optimizations that can help improve the application of photonic accelerators to such computer vision tasks.", "url": "https://arxiv.org/abs/2309.16783"}, {"metadata": {"arXiv": "2309.16940", "Date": "Fri, 29 Sep 2023 02:45:56 ", "Title": "Robust Asynchronous Collaborative 3D Detection via Bird's Eye View Flow", "Authors": ["Sizhe Wei", "Yuxi Wei", "Yue Hu", "Yifan Lu", "Yiqi Zhong", "Siheng Chen", "Ya Zhang"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["16 pages", "9 figures. Accepted by NeurIPS 2023"]}, "abstract": "By facilitating communication among multiple agents, collaborative perception can substantially boost each agent's perception ability. However, temporal asynchrony among agents is inevitable in real-world due to communication delays, interruptions, and clock misalignments. This issue causes information mismatch during multi-agent fusion, seriously shaking the foundation of collaboration. To address this issue, we propose CoBEVFlow, an asynchrony-robust collaborative 3D perception system based on bird's eye view (BEV) flow. The key intuition of CoBEVFlow is to compensate motions to align asynchronous collaboration messages sent by multiple agents. To model the motion in a scene, we propose BEV flow, which is a collection of the motion vector corresponding to each spatial location. Based on BEV flow, asynchronous perceptual features can be reassigned to appropriate positions, mitigating the impact of asynchrony. CoBEVFlow has two advantages: (i) CoBEVFlow can handle asynchronous collaboration messages sent at irregular, continuous time stamps without discretization; and (ii) with BEV flow, CoBEVFlow only transports the original perceptual features, instead of generating new perceptual features, avoiding additional noises. To validate CoBEVFlow's efficacy, we create IRregular V2V(IRV2V), the first synthetic collaborative perception dataset with various temporal asynchronies that simulate different real-world scenarios. Extensive experiments conducted on both IRV2V and the real-world dataset DAIR-V2X show that CoBEVFlow consistently outperforms other baselines and is robust in extremely asynchronous settings. The code will be released.", "url": "https://arxiv.org/abs/2309.16940"}, {"metadata": {"arXiv": "2309.16948", "Date": "Fri, 29 Sep 2023 03:24:24 ", "Title": "Denoising Diffusion Bridge Models", "Authors": ["Linqi Zhou", "Aaron Lou", "Samar Khanna", "Stefano Ermon"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models are powerful generative models that map noise to data using stochastic processes. However, for many applications such as image editing, the model input comes from a distribution that is not random noise. As such, diffusion models must rely on cumbersome methods like guidance or projected sampling to incorporate this information in the generative process. In our work, we propose Denoising Diffusion Bridge Models (DDBMs), a natural alternative to this paradigm based on diffusion bridges, a family of processes that interpolate between two paired distributions given as endpoints. Our method learns the score of the diffusion bridge from data and maps from one endpoint distribution to the other by solving a (stochastic) differential equation based on the learned score. Our method naturally unifies several classes of generative models, such as score-based diffusion models and OT-Flow-Matching, allowing us to adapt existing design and architectural choices to our more general problem. Empirically, we apply DDBMs to challenging image datasets in both pixel and latent space. On standard image translation problems, DDBMs achieve significant improvement over baseline methods, and, when we reduce the problem to image generation by setting the source distribution to random noise, DDBMs achieve comparable FID scores to state-of-the-art methods despite being built for a more general task.", "url": "https://arxiv.org/abs/2309.16948"}, {"metadata": {"arXiv": "2309.17031", "Date": "Fri, 29 Sep 2023 07:37:26 ", "Title": "Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process", "Authors": ["Zhuo Zheng", "Shiqi Tian", "Ailong Ma", "Liangpei Zhang", "Yanfei Zhong"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV 2023"]}, "abstract": "Understanding the temporal dynamics of Earth's surface is a mission of multi-temporal remote sensing image analysis, significantly promoted by deep vision models with its fuel -- labeled multi-temporal images. However, collecting, preprocessing, and annotating multi-temporal remote sensing images at scale is non-trivial since it is expensive and knowledge-intensive. In this paper, we present a scalable multi-temporal remote sensing change data generator via generative modeling, which is cheap and automatic, alleviating these problems. Our main idea is to simulate a stochastic change process over time. We consider the stochastic change process as a probabilistic semantic state transition, namely generative probabilistic change model (GPCM), which decouples the complex simulation problem into two more trackable sub-problems, \\ie, change event simulation and semantic change synthesis. To solve these two problems, we present the change generator (Changen), a GAN-based GPCM, enabling controllable object change data generation, including customizable object property, and change event. The extensive experiments suggest that our Changen has superior generation capability, and the change detectors with Changen pre-training exhibit excellent transferability to real-world change datasets.", "url": "https://arxiv.org/abs/2309.17031"}, {"metadata": {"arXiv": "2309.17080", "Date": "Fri, 29 Sep 2023 09:20:37 ", "Title": "GAIA-1: A Generative World Model for Autonomous Driving", "Authors": ["Anthony Hu and Lloyd Russell and Hudson Yeo and Zak Murez and George Fedoseev and Alex Kendall and Jamie Shotton and Gianluca Corrado"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["Technical Report"]}, "abstract": "Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves. To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representation that captures expectations of future events, combined with its ability to generate realistic samples, provides new possibilities for innovation in the field of autonomy, enabling enhanced and accelerated training of autonomous driving technology.", "url": "https://arxiv.org/abs/2309.17080"}, {"metadata": {"arXiv": "2309.17143", "Date": "Fri, 29 Sep 2023 11:15:39 ", "Title": "Revisiting Cephalometric Landmark Detection from the view of Human Pose Estimation with Lightweight Super-Resolution Head", "Authors": ["Qian Wu and Si Yong Yeo and Yufei Chen and Jun Liu"], "Categories": "cs.CV cs.AI"}, "abstract": "Accurate localization of cephalometric landmarks holds great importance in the fields of orthodontics and orthognathics due to its potential for automating key point labeling. In the context of landmark detection, particularly in cephalometrics, it has been observed that existing methods often lack standardized pipelines and well-designed bias reduction processes, which significantly impact their performance. In this paper, we revisit a related task, human pose estimation (HPE), which shares numerous similarities with cephalometric landmark detection (CLD), and emphasize the potential for transferring techniques from the former field to benefit the latter. Motivated by this insight, we have developed a robust and adaptable benchmark based on the well-established HPE codebase known as MMPose. This benchmark can serve as a dependable baseline for achieving exceptional CLD performance. Furthermore, we introduce an upscaling design within the framework to further enhance performance. This enhancement involves the incorporation of a lightweight and efficient super-resolution module, which generates heatmap predictions on high-resolution features and leads to further performance refinement, benefiting from its ability to reduce quantization bias. In the MICCAI CLDetection2023 challenge, our method achieves 1st place ranking on three metrics and 3rd place on the remaining one. The code for our method is available at https://github.com/5k5000/CLdetection2023.", "url": "https://arxiv.org/abs/2309.17143"}, {"metadata": {"arXiv": "2309.17166", "Date": "Fri, 29 Sep 2023 11:59:57 ", "Title": "Advances in Kidney Biopsy Structural Assessment through Dense Instance Segmentation", "Authors": ["Zhan Xiong", "Junling He", "Pieter Valkema", "Tri Q. Nguyen", "Maarten Naesens", "Jesper Kers", "and Fons J. Verbeek"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "10 figures", "3 tables", "Journal"]}, "abstract": "The kidney biopsy is the gold standard for the diagnosis of kidney diseases. Lesion scores made by expert renal pathologists are semi-quantitative and suffer from high inter-observer variability. Automatically obtaining statistics per segmented anatomical object, therefore, can bring significant benefits in reducing labor and this inter-observer variability. Instance segmentation for a biopsy, however, has been a challenging problem due to (a) the on average large number (around 300 to 1000) of densely touching anatomical structures, (b) with multiple classes (at least 3) and (c) in different sizes and shapes. The currently used instance segmentation models cannot simultaneously deal with these challenges in an efficient yet generic manner. In this paper, we propose the first anchor-free instance segmentation model that combines diffusion models, transformer modules, and RCNNs (regional convolution neural networks). Our model is trained on just one NVIDIA GeForce RTX 3090 GPU, but can efficiently recognize more than 500 objects with 3 common anatomical object classes in renal biopsies, i.e., glomeruli, tubuli, and arteries. Our data set consisted of 303 patches extracted from 148 Jones' silver-stained renal whole slide images (WSIs), where 249 patches were used for training and 54 patches for evaluation. In addition, without adjustment or retraining, the model can directly transfer its domain to generate decent instance segmentation results from PAS-stained WSIs. Importantly, it outperforms other baseline models and reaches an AP 51.7% in detection as the new state-of-the-art.", "url": "https://arxiv.org/abs/2309.17166"}, {"metadata": {"arXiv": "2309.17190", "Date": "Fri, 29 Sep 2023 12:40:13 ", "Title": "PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis", "Authors": ["Haiyang Ying and Baowei Jiang and Jinzhi Zhang and Di Xu and Tao Yu and Qionghai Dai and Lu Fang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023; Project page: https://oceanying.github.io/PARF/"]}, "abstract": "This paper proposes a method for fast scene radiance field reconstruction with strong novel view synthesis performance and convenient scene editing functionality. The key idea is to fully utilize semantic parsing and primitive extraction for constraining and accelerating the radiance field reconstruction process. To fulfill this goal, a primitive-aware hybrid rendering strategy was proposed to enjoy the best of both volumetric and primitive rendering. We further contribute a reconstruction pipeline conducts primitive parsing and radiance field learning iteratively for each input frame which successfully fuses semantic, primitive, and radiance information into a single framework. Extensive evaluations demonstrate the fast reconstruction ability, high rendering quality, and convenient editing functionality of our method.", "url": "https://arxiv.org/abs/2309.17190"}, {"metadata": {"arXiv": "2309.17426", "Date": "Fri, 29 Sep 2023 17:39:19 ", "Title": "Classification of Potholes Based on Surface Area Using Pre-Trained Models of Convolutional Neural Network", "Authors": ["Chauhdary Fazeel Ahmad", "Abdullah Cheema", "Waqas Qayyum", "Rana Ehtisham", "Muhammad Haroon Yousaf", "Junaid Mir", "Nasim Shakouri Mahmoudabadi", "Afaq Ahmad"], "Categories": "cs.CV cs.AI", "Comments": ["24 Pages", "26 Figures"]}, "abstract": "Potholes are fatal and can cause severe damage to vehicles as well as can cause deadly accidents. In South Asian countries, pavement distresses are the primary cause due to poor subgrade conditions, lack of subsurface drainage, and excessive rainfalls. The present research compares the performance of three pre-trained Convolutional Neural Network (CNN) models, i.e., ResNet 50, ResNet 18, and MobileNet. At first, pavement images are classified to find whether images contain potholes, i.e., Potholes or Normal. Secondly, pavements images are classi-fied into three categories, i.e., Small Pothole, Large Pothole, and Normal. Pavement images are taken from 3.5 feet (waist height) and 2 feet. MobileNet v2 has an accuracy of 98% for detecting a pothole. The classification of images taken at the height of 2 feet has an accuracy value of 87.33%, 88.67%, and 92% for classifying the large, small, and normal pavement, respectively. Similarly, the classification of the images taken from full of waist (FFW) height has an accuracy value of 98.67%, 98.67%, and 100%.", "url": "https://arxiv.org/abs/2309.17426"}, {"metadata": {"arXiv": "2309.17444", "Date": "Fri, 29 Sep 2023 17:54:46 ", "Title": "LLM-grounded Video Diffusion Models", "Authors": ["Long Lian", "Baifeng Shi", "Adam Yala", "Trevor Darrell", "Boyi Li"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Project Page: https://llm-grounded-video-diffusion.github.io/"]}, "abstract": "Text-conditioned diffusion models have emerged as a promising tool for neural video generation. However, current models still struggle with intricate spatiotemporal prompts and often generate restricted or incorrect motion (e.g., even lacking the ability to be prompted for objects moving from left to right). To address these limitations, we introduce LLM-grounded Video Diffusion (LVD). Instead of directly generating videos from the text inputs, LVD first leverages a large language model (LLM) to generate dynamic scene layouts based on the text inputs and subsequently uses the generated layouts to guide a diffusion model for video generation. We show that LLMs are able to understand complex spatiotemporal dynamics from text alone and generate layouts that align closely with both the prompts and the object motion patterns typically observed in the real world. We then propose to guide video diffusion models with these layouts by adjusting the attention maps. Our approach is training-free and can be integrated into any video diffusion model that admits classifier guidance. Our results demonstrate that LVD significantly outperforms its base video diffusion model and several strong baseline methods in faithfully generating videos with the desired attributes and motion patterns.", "url": "https://arxiv.org/abs/2309.17444"}, {"metadata": {"arXiv": "2309.16716", "Date": "Wed, 23 Aug 2023 18:24:28 ", "Title": "Towards Safe Autonomy in Hybrid Traffic: Detecting Unpredictable Abnormal Behaviors of Human Drivers via Information Sharing", "Authors": ["Jiangwei Wang", "Lili Su", "Songyang Han", "Dongjin Song", "Fei Miao"], "Categories": "cs.RO cs.AI", "Comments": ["accepted to ACM Transactions on Cyber-Physical Systems"]}, "abstract": "Hybrid traffic which involves both autonomous and human-driven vehicles would be the norm of the autonomous vehicles practice for a while. On the one hand, unlike autonomous vehicles, human-driven vehicles could exhibit sudden abnormal behaviors such as unpredictably switching to dangerous driving modes, putting its neighboring vehicles under risks; such undesired mode switching could arise from numbers of human driver factors, including fatigue, drunkenness, distraction, aggressiveness, etc. On the other hand, modern vehicle-to-vehicle communication technologies enable the autonomous vehicles to efficiently and reliably share the scarce run-time information with each other. In this paper, we propose, to the best of our knowledge, the first efficient algorithm that can (1) significantly improve trajectory prediction by effectively fusing the run-time information shared by surrounding autonomous vehicles, and can (2) accurately and quickly detect abnormal human driving mode switches or abnormal driving behavior with formal assurance without hurting human drivers privacy. To validate our proposed algorithm, we first evaluate our proposed trajectory predictor on NGSIM and Argoverse datasets and show that our proposed predictor outperforms the baseline methods. Then through extensive experiments on SUMO simulator, we show that our proposed algorithm has great detection performance in both highway and urban traffic. The best performance achieves detection rate of 97.3%, average detection delay of 1.2s, and 0 false alarm.", "url": "https://arxiv.org/abs/2309.16716"}, {"metadata": {"arXiv": "2309.16909", "Date": "Fri, 29 Sep 2023 00:27:40 ", "Title": "ASAP: Automated Sequence Planning for Complex Robotic Assembly with Physical Feasibility", "Authors": ["Yunsheng Tian", "Karl D.D. Willis", "Bassel Al Omari", "Jieliang Luo", "Pingchuan Ma", "Yichen Li", "Farhad Javid", "Edward Gu", "Joshua Jacob", "Shinjiro Sueda", "Hui Li", "Sachin Chitta and Wojciech Matusik"], "Categories": "cs.RO cs.AI cs.GR"}, "abstract": "The automated assembly of complex products requires a system that can automatically plan a physically feasible sequence of actions for assembling many parts together. In this paper, we present ASAP, a physics-based planning approach for automatically generating such a sequence for general-shaped assemblies. ASAP accounts for gravity to design a sequence where each sub-assembly is physically stable with a limited number of parts being held and a support surface. We apply efficient tree search algorithms to reduce the combinatorial complexity of determining such an assembly sequence. The search can be guided by either geometric heuristics or graph neural networks trained on data with simulation labels. Finally, we show the superior performance of ASAP at generating physically realistic assembly sequence plans on a large dataset of hundreds of complex product assemblies. We further demonstrate the applicability of ASAP on both simulation and real-world robotic setups. Project website: asap.csail.mit.edu", "url": "https://arxiv.org/abs/2309.16909"}, {"metadata": {"arXiv": "2309.17170", "Date": "Fri, 29 Sep 2023 12:07:08 ", "Title": "A Vision-Guided Robotic System for Grasping Harvested Tomato Trusses in Cluttered Environments", "Authors": ["Luuk van den Bent", "Tom\\'as Coleman", "Robert Babuska"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["7 pages", "7 figures"]}, "abstract": "Currently, truss tomato weighing and packaging require significant manual work. The main obstacle to automation lies in the difficulty of developing a reliable robotic grasping system for already harvested trusses. We propose a method to grasp trusses that are stacked in a crate with considerable clutter, which is how they are commonly stored and transported after harvest. The method consists of a deep learning-based vision system to first identify the individual trusses in the crate and then determine a suitable grasping location on the stem. To this end, we have introduced a grasp pose ranking algorithm with online learning capabilities. After selecting the most promising grasp pose, the robot executes a pinch grasp without needing touch sensors or geometric models. Lab experiments with a robotic manipulator equipped with an eye-in-hand RGB-D camera showed a 100% clearance rate when tasked to pick all trusses from a pile. 93% of the trusses were successfully grasped on the first try, while the remaining 7% required more attempts.", "url": "https://arxiv.org/abs/2309.17170"}, {"metadata": {"arXiv": "2309.17433", "Date": "Fri, 29 Sep 2023 17:43:41 ", "Title": "DREAM: Decentralized Reinforcement Learning for Exploration and Efficient Energy Management in Multi-Robot Systems", "Authors": ["Dipam Patel", "Phu Pham", "Kshitij Tiwari and Aniket Bera"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["Submitted to 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)"]}, "abstract": "Resource-constrained robots often suffer from energy inefficiencies, underutilized computational abilities due to inadequate task allocation, and a lack of robustness in dynamic environments, all of which strongly affect their performance. This paper introduces DREAM - Decentralized Reinforcement Learning for Exploration and Efficient Energy Management in Multi-Robot Systems, a comprehensive framework that optimizes the allocation of resources for efficient exploration. It advances beyond conventional heuristic-based task planning as observed conventionally. The framework incorporates Operational Range Estimation using Reinforcement Learning to perform exploration and obstacle avoidance in unfamiliar terrains. DREAM further introduces an Energy Consumption Model for goal allocation, thereby ensuring mission completion under constrained resources using a Graph Neural Network. This approach also ensures that the entire Multi-Robot System can survive for an extended period of time for further missions compared to the conventional approach of randomly allocating goals, which compromises one or more agents. Our approach adapts to prioritizing agents in real-time, showcasing remarkable resilience against dynamic environments. This robust solution was evaluated in various simulated environments, demonstrating adaptability and applicability across diverse scenarios. We observed a substantial improvement of about 25% over the baseline method, leading the way for future research in resource-constrained robotics.", "url": "https://arxiv.org/abs/2309.17433"}, {"metadata": {"arXiv": "2309.17437", "Date": "Fri, 29 Sep 2023 17:50:57 ", "Title": "Learning Decentralized Flocking Controllers with Spatio-Temporal Graph Neural Network", "Authors": ["Siji Chen", "Yanshen Sun", "Peihan Li", "Lifeng Zhou", "Chang-Tien Lu"], "Categories": "cs.RO cs.AI"}, "abstract": "Recently a line of researches has delved the use of graph neural networks (GNNs) for decentralized control in swarm robotics. However, it has been observed that relying solely on the states of immediate neighbors is insufficient to imitate a centralized control policy. To address this limitation, prior studies proposed incorporating $L$-hop delayed states into the computation. While this approach shows promise, it can lead to a lack of consensus among distant flock members and the formation of small clusters, consequently resulting in the failure of cohesive flocking behaviors. Instead, our approach leverages spatiotemporal GNN, named STGNN that encompasses both spatial and temporal expansions. The spatial expansion collects delayed states from distant neighbors, while the temporal expansion incorporates previous states from immediate neighbors. The broader and more comprehensive information gathered from both expansions results in more effective and accurate predictions. We develop an expert algorithm for controlling a swarm of robots and employ imitation learning to train our decentralized STGNN model based on the expert algorithm. We simulate the proposed STGNN approach in various settings, demonstrating its decentralized capacity to emulate the global expert algorithm. Further, we implemented our approach to achieve cohesive flocking, leader following and obstacle avoidance by a group of Crazyflie drones. The performance of STGNN underscores its potential as an effective and reliable approach for achieving cohesive flocking, leader following and obstacle avoidance tasks.", "url": "https://arxiv.org/abs/2309.17437"}, {"metadata": {"arXiv": "2309.16970", "Date": "Fri, 29 Sep 2023 04:40:01 ", "Title": "Discrete-Choice Model with Generalized Additive Utility Network", "Authors": ["Tomoki Nishi and Yusuke Hara"], "Categories": "cs.AI cs.LG"}, "abstract": "Discrete-choice models are a powerful framework for analyzing decision-making behavior to provide valuable insights for policymakers and businesses. Multinomial logit models (MNLs) with linear utility functions have been used in practice because they are ease to use and interpretable. Recently, MNLs with neural networks (e.g., ASU-DNN) have been developed, and they have achieved higher prediction accuracy in behavior choice than classical MNLs. However, these models lack interpretability owing to complex structures. We developed utility functions with a novel neural-network architecture based on generalized additive models, named generalized additive utility network ( GAUNet), for discrete-choice models. We evaluated the performance of the MNL with GAUNet using the trip survey data collected in Tokyo. Our models were comparable to ASU-DNN in accuracy and exhibited improved interpretability compared to previous models.", "url": "https://arxiv.org/abs/2309.16970"}, {"metadata": {"arXiv": "2309.17167", "Date": "Fri, 29 Sep 2023 12:04:14 ", "Title": "DyVal: Graph-informed Dynamic Evaluation of Large Language Models", "Authors": ["Kaijie Zhu", "Jiaao Chen", "Jindong Wang", "Neil Zhenqiang Gong", "Diyi Yang", "Xing Xie"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Technical report; 36 pages; code will be released at aka.ms/dyval"]}, "abstract": "Large language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns about their performance are raised on potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. In this paper, we introduce DyVal, a novel, general, and flexible evaluation protocol for dynamic evaluation of LLMs. Based on our proposed dynamic evaluation framework, we build graph-informed DyVal by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DyVal generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments demonstrate that LLMs perform worse in DyVal-generated evaluation samples with different complexities, emphasizing the significance of dynamic evaluation. We also analyze the failure cases and results of different prompting methods. Moreover, DyVal-generated samples are not only evaluation sets, but also helpful data for fine-tuning to improve the performance of LLMs on existing benchmarks. We hope that DyVal can shed light on the future evaluation research of LLMs.", "url": "https://arxiv.org/abs/2309.17167"}, {"metadata": {"arXiv": "2309.17382", "Date": "Fri, 29 Sep 2023 16:36:39 ", "Title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "Authors": ["Zhihan Liu", "Hao Hu", "Shenao Zhang", "Hongyi Guo", "Shuqi Ke", "Boyi Liu", "Zhaoran Wang"], "Categories": "cs.AI cs.LG"}, "abstract": "Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging. In particular, it remains unclear how to complete a given task provably within a minimum number of interactions with the external environment, e.g., through an internal mechanism of reasoning. To this end, we propose a principled framework with provable regret guarantees to orchestrate reasoning and acting, which we call ``reason for future, act for now\" (\\texttt{RAFA}). Specifically, we design a prompt template for reasoning that learns from the memory buffer and plans a future trajectory over a long horizon (``reason for future\"). At each step, the LLM agent takes the initial action of the planned trajectory (``act for now\"), stores the collected feedback in the memory buffer, and reinvokes the reasoning routine to replan the future trajectory from the new state. The key idea is to cast reasoning in LLMs as learning and planning in Bayesian adaptive Markov decision processes (MDPs). Correspondingly, we prompt LLMs to form an updated posterior of the unknown environment from the memory buffer (learning) and generate an optimal trajectory for multiple future steps that maximizes a value function (planning). The learning and planning subroutines are performed in an \"in-context\" manner to emulate the actor-critic update for MDPs. Our theoretical analysis proves that the novel combination of long-term reasoning and short-term acting achieves a $\\sqrt{T}$ regret. In particular, the regret bound highlights an intriguing interplay between the prior knowledge obtained through pretraining and the uncertainty reduction achieved by reasoning and acting. Our empirical validation shows that it outperforms various existing frameworks and achieves nearly perfect scores on a few benchmarks.", "url": "https://arxiv.org/abs/2309.17382"}, {"metadata": {"arXiv": "2309.17425", "Date": "Fri, 29 Sep 2023 17:37:29 ", "Title": "Data Filtering Networks", "Authors": ["Alex Fang", "Albin Madappally Jose", "Amit Jain", "Ludwig Schmidt", "Alexander Toshev", "Vaishaal Shankar"], "Categories": "cs.AI cs.LG"}, "abstract": "Large training sets have become a cornerstone of machine learning and are the foundation for recent advances in language modeling and multimodal learning. While data curation for pre-training is often still ad-hoc, one common paradigm is to first collect a massive pool of data from the Web and then filter this candidate pool down to an actual training set via various heuristics. In this work, we study the problem of learning a data filtering network (DFN) for this second step of filtering a large uncurated dataset. Our key finding is that the quality of a network for filtering is distinct from its performance on downstream tasks: for instance, a model that performs well on ImageNet can yield worse training sets than a model with low ImageNet accuracy that is trained on a small amount of high-quality data. Based on our insights, we construct new data filtering networks that induce state-of-the-art image-text datasets. Specifically, our best performing dataset DFN-5B enables us to train state-of-the-art models for their compute budgets: among other improvements on a variety of tasks, a ViT-H trained on our dataset achieves 83.0% zero-shot transfer accuracy on ImageNet, out-performing models trained on other datasets such as LAION-2B, DataComp-1B, or OpenAI's WIT. In order to facilitate further research in dataset design, we also release a new 2 billion example dataset DFN-2B and show that high performance data filtering networks can be trained from scratch using only publicly available data.", "url": "https://arxiv.org/abs/2309.17425"}, {"metadata": {"arXiv": "2309.16779", "Date": "Thu, 28 Sep 2023 18:19:40 ", "Title": "Intriguing properties of generative classifiers", "Authors": ["Priyank Jaini and Kevin Clark and Robert Geirhos"], "Categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML"}, "abstract": "What is the best paradigm to recognize objects -- discriminative inference (fast but potentially prone to shortcut learning) or using a generative model (slow but potentially more robust)? We build on recent advances in generative modeling that turn text-to-image models into classifiers. This allows us to study their behavior and to compare them against discriminative models and human psychophysical data. We report four intriguing emergent properties of generative classifiers: they show a record-breaking human-like shape bias (99% for Imagen), near human-level out-of-distribution accuracy, state-of-the-art alignment with human classification errors, and they understand certain perceptual illusions. Our results indicate that while the current dominant paradigm for modeling human object recognition is discriminative inference, zero-shot generative models approximate human object recognition data surprisingly well.", "url": "https://arxiv.org/abs/2309.16779"}, {"metadata": {"arXiv": "2309.16859", "Date": "Thu, 28 Sep 2023 21:21:44 ", "Title": "Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis", "Authors": ["Marcel C. B\\\"uhler (1 and 2)", "Kripasindhu Sarkar (2)", "Tanmay Shah (2)", "Gengyan Li (1 and 2)", "Daoye Wang (2)", "Leonhard Helminger (2)", "Sergio Orts-Escolano (2)", "Dmitry Lagun (2)", "Otmar Hilliges (1)", "Thabo Beeler (2)", "Abhimitra Meka (2) ((1) ETH Zurich", "(2) Google)"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["In Proceedings of the IEEE/CVF International Conference on Computer Vision", "2023"]}, "abstract": "NeRFs have enabled highly realistic synthesis of human faces including complex appearance and reflectance effects of hair and skin. These methods typically require a large number of multi-view input images, making the process hardware intensive and cumbersome, limiting applicability to unconstrained settings. We propose a novel volumetric human face prior that enables the synthesis of ultra high-resolution novel views of subjects that are not part of the prior's training distribution. This prior model consists of an identity-conditioned NeRF, trained on a dataset of low-resolution multi-view images of diverse humans with known camera calibration. A simple sparse landmark-based 3D alignment of the training dataset allows our model to learn a smooth latent space of geometry and appearance despite a limited number of training identities. A high-quality volumetric representation of a novel subject can be obtained by model fitting to 2 or 3 camera views of arbitrary resolution. Importantly, our method requires as few as two views of casually captured images as input at inference time.", "url": "https://arxiv.org/abs/2309.16859"}, {"metadata": {"arXiv": "2309.16936", "Date": "Fri, 29 Sep 2023 02:32:01 ", "Title": "PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label", "Authors": ["Joonhyung Park", "Hyunjin Seo", "Eunho Yang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["11 pages; Accepted to ICCV 2023"]}, "abstract": "Understanding point clouds captured from the real-world is challenging due to shifts in data distribution caused by varying object scales, sensor angles, and self-occlusion. Prior works have addressed this issue by combining recent learning principles such as self-supervised learning, self-training, and adversarial training, which leads to significant computational overhead.Toward succinct yet powerful domain adaptation for point clouds, we revisit the unique challenges of point cloud data under domain shift scenarios and discover the importance of the global geometry of source data and trends of target pseudo-labels biased to the source label distribution. Motivated by our observations, we propose an adapter-guided domain adaptation method, PC-Adapter, that preserves the global shape information of the source domain using an attention-based adapter, while learning the local characteristics of the target domain via another adapter equipped with graph convolution. Additionally, we propose a novel pseudo-labeling strategy resilient to the classifier bias by adjusting confidence scores using their class-wise confidence distributions to consider relative confidences. Our method demonstrates superiority over baselines on various domain shift settings in benchmark datasets - PointDA, GraspNetPC, and PointSegDA.", "url": "https://arxiv.org/abs/2309.16936"}, {"metadata": {"arXiv": "2309.17144", "Date": "Fri, 29 Sep 2023 11:16:06 ", "Title": "Prototype Generation: Robust Feature Visualisation for Data Independent Interpretability", "Authors": ["Arush Tagade", "Jessica Rumbelow"], "Categories": "cs.CV cs.AI cs.HC cs.LG"}, "abstract": "We introduce Prototype Generation, a stricter and more robust form of feature visualisation for model-agnostic, data-independent interpretability of image classification models. We demonstrate its ability to generate inputs that result in natural activation paths, countering previous claims that feature visualisation algorithms are untrustworthy due to the unnatural internal activations. We substantiate these claims by quantitatively measuring similarity between the internal activations of our generated prototypes and natural images. We also demonstrate how the interpretation of generated prototypes yields important insights, highlighting spurious correlations and biases learned by models which quantitative methods over test-sets cannot identify.", "url": "https://arxiv.org/abs/2309.17144"}, {"metadata": {"arXiv": "2309.17264", "Date": "Fri, 29 Sep 2023 14:17:24 ", "Title": "A Foundation Model for General Moving Object Segmentation in Medical Images", "Authors": ["Zhongnuo Yan", "Tong Han", "Yuhao Huang", "Lian Liu", "Han Zhou", "Jiongquan Chen", "Wenlong Shi", "Yan Cao", "Xin Yang", "Dong Ni"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["6 pages", "8 figures", "3 tables"]}, "abstract": "Medical image segmentation aims to delineate the anatomical or pathological structures of interest, playing a crucial role in clinical diagnosis. A substantial amount of high-quality annotated data is crucial for constructing high-precision deep segmentation models. However, medical annotation is highly cumbersome and time-consuming, especially for medical videos or 3D volumes, due to the huge labeling space and poor inter-frame consistency. Recently, a fundamental task named Moving Object Segmentation (MOS) has made significant advancements in natural images. Its objective is to delineate moving objects from the background within image sequences, requiring only minimal annotations. In this paper, we propose the first foundation model, named iMOS, for MOS in medical images. Extensive experiments on a large multi-modal medical dataset validate the effectiveness of the proposed iMOS. Specifically, with the annotation of only a small number of images in the sequence, iMOS can achieve satisfactory tracking and segmentation performance of moving objects throughout the entire sequence in bi-directions. We hope that the proposed iMOS can help accelerate the annotation speed of experts, and boost the development of medical foundation models.", "url": "https://arxiv.org/abs/2309.17264"}, {"metadata": {"arXiv": "2309.17329", "Date": "Fri, 29 Sep 2023 15:40:58 ", "Title": "Efficient Anatomical labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks", "Authors": ["Kangxian Xie", "Jiancheng Yang", "Donglai Wei", "Ziqiao Weng", "Pascal Fua"], "Categories": "cs.CV cs.AI cs.GR cs.LG eess.IV"}, "abstract": "Pulmonary diseases rank prominently among the principal causes of death worldwide. Curing them will require, among other things, a better understanding of the many complex 3D tree-shaped structures within the pulmonary system, such as airways, arteries, and veins. In theory, they can be modeled using high-resolution image stacks. Unfortunately, standard CNN approaches operating on dense voxel grids are prohibitively expensive. To remedy this, we introduce a point-based approach that preserves graph connectivity of tree skeleton and incorporates an implicit surface representation. It delivers SOTA accuracy at a low computational cost and the resulting models have usable surfaces. Due to the scarcity of publicly accessible data, we have also curated an extensive dataset to evaluate our approach and will make it public.", "url": "https://arxiv.org/abs/2309.17329"}, {"metadata": {"arXiv": "2309.16729", "Date": "Wed, 27 Sep 2023 06:34:55 ", "Title": "SimPINNs: Simulation-Driven Physics-Informed Neural Networks for Enhanced Performance in Nonlinear Inverse Problems", "Authors": ["Sidney Besnard", "Fr\\'ed\\'eric Jurie (UNICAEN)", "Jalal M. Fadili (NU", "ENSICAEN", "GREYC)"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper introduces a novel approach to solve inverse problems by leveraging deep learning techniques. The objective is to infer unknown parameters that govern a physical system based on observed data. We focus on scenarios where the underlying forward model demonstrates pronounced nonlinear behaviour, and where the dimensionality of the unknown parameter space is substantially smaller than that of the observations. Our proposed method builds upon physics-informed neural networks (PINNs) trained with a hybrid loss function that combines observed data with simulated data generated by a known (approximate) physical model. Experimental results on an orbit restitution problem demonstrate that our approach surpasses the performance of standard PINNs, providing improved accuracy and robustness.", "url": "https://arxiv.org/abs/2309.16729"}, {"metadata": {"arXiv": "2309.16733", "Date": "Wed, 27 Sep 2023 19:22:19 ", "Title": "Resilience of Deep Learning applications: a systematic survey of analysis and hardening techniques", "Authors": ["Cristiana Bolchini", "Luca Cassano", "Antonio Miele"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to ACM Computing Surveys on May 11", "2023"]}, "abstract": "Machine Learning (ML) is currently being exploited in numerous applications being one of the most effective Artificial Intelligence (AI) technologies, used in diverse fields, such as vision, autonomous systems, and alike. The trend motivated a significant amount of contributions to the analysis and design of ML applications against faults affecting the underlying hardware. The authors investigate the existing body of knowledge on Deep Learning (among ML techniques) resilience against hardware faults systematically through a thoughtful review in which the strengths and weaknesses of this literature stream are presented clearly and then future avenues of research are set out. The review is based on 163 scientific articles published between January 2019 and March 2023. The authors adopt a classifying framework to interpret and highlight research similarities and peculiarities, based on several parameters, starting from the main scope of the work, the adopted fault and error models, to their reproducibility. This framework allows for a comparison of the different solutions and the identification of possible synergies. Furthermore, suggestions concerning the future direction of research are proposed in the form of open challenges to be addressed.", "url": "https://arxiv.org/abs/2309.16733"}, {"metadata": {"arXiv": "2309.16739", "Date": "Thu, 28 Sep 2023 06:22:59 ", "Title": "Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities", "Authors": ["Zheng Lin", "Guanqiao Qu", "Qiyuan Chen", "Xianhao Chen", "Zhe Chen and Kaibin Huang"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "5 figures"]}, "abstract": "Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, quantization, and parameter-sharing inference, to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation, challenges, and pathway for empowering LLMs at the 6G edge.", "url": "https://arxiv.org/abs/2309.16739"}, {"metadata": {"arXiv": "2309.16741", "Date": "Thu, 28 Sep 2023 08:08:08 ", "Title": "Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections", "Authors": ["Tom Bamford", "Andrea Coletta", "Elizabeth Fons", "Sriram Gopalakrishnan", "Svitlana Vyetrenko", "Tucker Balch", "Manuela Veloso"], "Categories": "cs.LG cs.AI cs.HC", "Comments": ["Accepted to ICAIF 2023"]}, "abstract": "Financial firms commonly process and store billions of time-series data, generated continuously and at a high frequency. To support efficient data storage and retrieval, specialized time-series databases and systems have emerged. These databases support indexing and querying of time-series by a constrained Structured Query Language(SQL)-like format to enable queries like \"Stocks with monthly price returns greater than 5%\", and expressed in rigid formats. However, such queries do not capture the intrinsic complexity of high dimensional time-series data, which can often be better described by images or language (e.g., \"A stock in low volatility regime\"). Moreover, the required storage, computational time, and retrieval complexity to search in the time-series space are often non-trivial. In this paper, we propose and demonstrate a framework to store multi-modal data for financial time-series in a lower-dimensional latent space using deep encoders, such that the latent space projections capture not only the time series trends but also other desirable information or properties of the financial time-series data (such as price volatility). Moreover, our approach allows user-friendly query interfaces, enabling natural language text or sketches of time-series, for which we have developed intuitive interfaces. We demonstrate the advantages of our method in terms of computational efficiency and accuracy on real historical data as well as synthetic data, and highlight the utility of latent-space projections in the storage and retrieval of financial time-series data with intuitive query modalities.", "url": "https://arxiv.org/abs/2309.16741"}, {"metadata": {"arXiv": "2309.16742", "Date": "Thu, 28 Sep 2023 08:41:12 ", "Title": "Supervised Learning Models for Early Detection of Albuminuria Risk in Type-2 Diabetes Mellitus Patients", "Authors": ["Arief Purnama Muharram", "Dicky Levenus Tahapary", "Yeni Dwi Lestari", "Randy Sarayar and Valerie Josephine Dirjayanto"], "Categories": "cs.LG cs.AI q-bio.QM", "Comments": ["Accepted in the 10th International Conference on Advanced Informatics: Concepts", "Theory and Applications (ICAICTA 2023)"]}, "abstract": "Diabetes, especially T2DM, continues to be a significant health problem. One of the major concerns associated with diabetes is the development of its complications. Diabetic nephropathy, one of the chronic complication of diabetes, adversely affects the kidneys, leading to kidney damage. Diagnosing diabetic nephropathy involves considering various criteria, one of which is the presence of a pathologically significant quantity of albumin in urine, known as albuminuria. Thus, early prediction of albuminuria in diabetic patients holds the potential for timely preventive measures. This study aimed to develop a supervised learning model to predict the risk of developing albuminuria in T2DM patients. The selected supervised learning algorithms included Na\\\"ive Bayes, Support Vector Machine (SVM), decision tree, random forest, AdaBoost, XGBoost, and Multi-Layer Perceptron (MLP). Our private dataset, comprising 184 entries of diabetes complications risk factors, was used to train the algorithms. It consisted of 10 attributes as features and 1 attribute as the target (albuminuria). Upon conducting the experiments, the MLP demonstrated superior performance compared to the other algorithms. It achieved accuracy and f1-score values as high as 0.74 and 0.75, respectively, making it suitable for screening purposes in predicting albuminuria in T2DM. Nonetheless, further studies are warranted to enhance the model's performance.", "url": "https://arxiv.org/abs/2309.16742"}, {"metadata": {"arXiv": "2309.16743", "Date": "Thu, 28 Sep 2023 09:34:52 ", "Title": "High Throughput Training of Deep Surrogates from Large Ensemble Runs", "Authors": ["Lucas Meyer (DATAMOVE", "SINCLAIR AI Lab", "EDF R&D)", "Marc Schouler (DATAMOVE )", "Robert Alexander Caulk (DATAMOVE )", "Alejandro Rib\\'es (EDF R&D)", "Bruno Raffin (DATAMOVE )"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["The International Conference for High Performance Computing", "Networking", "Storage", "and Analysis", "Nov 2023", "Denver", "CO", "United States"], "DOI": "10.1145/3581784.3607083"}, "abstract": "Recent years have seen a surge in deep learning approaches to accelerate numerical solvers, which provide faithful but computationally intensive simulations of the physical world. These deep surrogates are generally trained in a supervised manner from limited amounts of data slowly generated by the same solver they intend to accelerate. We propose an open-source framework that enables the online training of these models from a large ensemble run of simulations. It leverages multiple levels of parallelism to generate rich datasets. The framework avoids I/O bottlenecks and storage issues by directly streaming the generated data. A training reservoir mitigates the inherent bias of streaming while maximizing GPU throughput. Experiment on training a fully connected network as a surrogate for the heat equation shows the proposed approach enables training on 8TB of data in 2 hours with an accuracy improved by 47% and a batch throughput multiplied by 13 compared to a traditional offline procedure.", "url": "https://arxiv.org/abs/2309.16743"}, {"metadata": {"arXiv": "2309.16747", "Date": "Thu, 28 Sep 2023 17:36:27 ", "Title": "Harnessing Diverse Data for Global Disaster Prediction: A Multimodal Framework", "Authors": ["Gengyin Liu", "Huaiyang Zhong"], "Categories": "cs.LG cs.AI"}, "abstract": "As climate change intensifies, the urgency for accurate global-scale disaster predictions grows. This research presents a novel multimodal disaster prediction framework, combining weather statistics, satellite imagery, and textual insights. We particularly focus on \"flood\" and \"landslide\" predictions, given their ties to meteorological and topographical factors. The model is meticulously crafted based on the available data and we also implement strategies to address class imbalance. While our findings suggest that integrating multiple data sources can bolster model performance, the extent of enhancement differs based on the specific nature of each disaster and their unique underlying causes.", "url": "https://arxiv.org/abs/2309.16747"}, {"metadata": {"arXiv": "2309.16748", "Date": "Thu, 28 Sep 2023 17:55:45 ", "Title": "Discovering environments with XRM", "Authors": ["Mohammad Pezeshki", "Diane Bouchacourt", "Mark Ibrahim", "Nicolas Ballas", "Pascal Vincent", "David Lopez-Paz"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Successful out-of-distribution generalization requires environment annotations. Unfortunately, these are resource-intensive to obtain, and their relevance to model performance is limited by the expectations and perceptual biases of human annotators. Therefore, to enable robust AI systems across applications, we must develop algorithms to automatically discover environments inducing broad generalization. Current proposals, which divide examples based on their training error, suffer from one fundamental problem. These methods add hyper-parameters and early-stopping criteria that are impossible to tune without a validation set with human-annotated environments, the very information subject to discovery. In this paper, we propose Cross-Risk-Minimization (XRM) to address this issue. XRM trains two twin networks, each learning from one random half of the training data, while imitating confident held-out mistakes made by its sibling. XRM provides a recipe for hyper-parameter tuning, does not require early-stopping, and can discover environments for all training and validation data. Domain generalization algorithms built on top of XRM environments achieve oracle worst-group-accuracy, solving a long-standing problem in out-of-distribution generalization.", "url": "https://arxiv.org/abs/2309.16748"}, {"metadata": {"arXiv": "2309.16750", "Date": "Thu, 28 Sep 2023 17:57:09 ", "Title": "Memory in Plain Sight: A Survey of the Uncanny Resemblances between Diffusion Models and Associative Memories", "Authors": ["Benjamin Hoover", "Hendrik Strobelt", "Dmitry Krotov", "Judy Hoffman", "Zsolt Kira", "Duen Horng Chau"], "Categories": "cs.LG cs.AI math.DS", "Comments": ["15 pages", "4 figures"]}, "abstract": "Diffusion Models (DMs) have recently set state-of-the-art on many generation benchmarks. However, there are myriad ways to describe them mathematically, which makes it difficult to develop a simple understanding of how they work. In this survey, we provide a concise overview of DMs from the perspective of dynamical systems and Ordinary Differential Equations (ODEs) which exposes a mathematical connection to the highly related yet often overlooked class of energy-based models, called Associative Memories (AMs). Energy-based AMs are a theoretical framework that behave much like denoising DMs, but they enable us to directly compute a Lyapunov energy function on which we can perform gradient descent to denoise data. We then summarize the 40 year history of energy-based AMs, beginning with the original Hopfield Network, and discuss new research directions for AMs and DMs that are revealed by characterizing the extent of their similarities and differences", "url": "https://arxiv.org/abs/2309.16750"}, {"metadata": {"arXiv": "2309.16773", "Date": "Thu, 28 Sep 2023 18:10:43 ", "Title": "Neural scaling laws for phenotypic drug discovery", "Authors": ["Drew Linsley", "John Griffin", "Jason Parker Brown", "Adam N Roose", "Michael Frank", "Peter Linsley", "Steven Finkbeiner", "Jeremy Linsley"], "Categories": "cs.LG cs.AI cs.CV q-bio.QM"}, "abstract": "Recent breakthroughs by deep neural networks (DNNs) in natural language processing (NLP) and computer vision have been driven by a scale-up of models and data rather than the discovery of novel computing paradigms. Here, we investigate if scale can have a similar impact for models designed to aid small molecule drug discovery. We address this question through a large-scale and systematic analysis of how DNN size, data diet, and learning routines interact to impact accuracy on our Phenotypic Chemistry Arena (Pheno-CA) benchmark: a diverse set of drug development tasks posed on image-based high content screening data. Surprisingly, we find that DNNs explicitly supervised to solve tasks in the Pheno-CA do not continuously improve as their data and model size is scaled-up. To address this issue, we introduce a novel precursor task, the Inverse Biological Process (IBP), which is designed to resemble the causal objective functions that have proven successful for NLP. We indeed find that DNNs first trained with IBP then probed for performance on the Pheno-CA significantly outperform task-supervised DNNs. More importantly, the performance of these IBP-trained DNNs monotonically improves with data and model scale. Our findings reveal that the DNN ingredients needed to accurately solve small molecule drug development tasks are already in our hands, and project how much more experimental data is needed to achieve any desired level of improvement. We release our Pheno-CA benchmark and code to encourage further study of neural scaling laws for small molecule drug discovery.", "url": "https://arxiv.org/abs/2309.16773"}, {"metadata": {"arXiv": "2309.16819", "Date": "Thu, 28 Sep 2023 19:56:31 ", "Title": "Multi-Bellman operator for convergence of $Q$-learning with linear function approximation", "Authors": ["Diogo S. Carvalho", "Pedro A. Santos", "Francisco S. Melo"], "Categories": "cs.LG cs.AI"}, "abstract": "We study the convergence of $Q$-learning with linear function approximation. Our key contribution is the introduction of a novel multi-Bellman operator that extends the traditional Bellman operator. By exploring the properties of this operator, we identify conditions under which the projected multi-Bellman operator becomes contractive, providing improved fixed-point guarantees compared to the Bellman operator. To leverage these insights, we propose the multi $Q$-learning algorithm with linear function approximation. We demonstrate that this algorithm converges to the fixed-point of the projected multi-Bellman operator, yielding solutions of arbitrary accuracy. Finally, we validate our approach by applying it to well-known environments, showcasing the effectiveness and applicability of our findings.", "url": "https://arxiv.org/abs/2309.16819"}, {"metadata": {"arXiv": "2309.16878", "Date": "Thu, 28 Sep 2023 22:31:29 ", "Title": "Investigating Human-Identifiable Features Hidden in Adversarial Perturbations", "Authors": ["Dennis Y. Menn", "Tzu-hsun Feng", "Sriram Vishwanath", "Hung-yi Lee"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Neural networks perform exceedingly well across various machine learning tasks but are not immune to adversarial perturbations. This vulnerability has implications for real-world applications. While much research has been conducted, the underlying reasons why neural networks fall prey to adversarial attacks are not yet fully understood. Central to our study, which explores up to five attack algorithms across three datasets, is the identification of human-identifiable features in adversarial perturbations. Additionally, we uncover two distinct effects manifesting within human-identifiable features. Specifically, the masking effect is prominent in untargeted attacks, while the generation effect is more common in targeted attacks. Using pixel-level annotations, we extract such features and demonstrate their ability to compromise target models. In addition, our findings indicate a notable extent of similarity in perturbations across different attack algorithms when averaged over multiple models. This work also provides insights into phenomena associated with adversarial perturbations, such as transferability and model interpretability. Our study contributes to a deeper understanding of the underlying mechanisms behind adversarial attacks and offers insights for the development of more resilient defense strategies for neural networks.", "url": "https://arxiv.org/abs/2309.16878"}, {"metadata": {"arXiv": "2309.16888", "Date": "Thu, 28 Sep 2023 23:03:12 ", "Title": "Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer", "Authors": ["Lele Cao", "Gustaf Halvardsson", "Andrew McCornack", "Vilhelm von Ehrenheim and Pawel Herman"], "Categories": "cs.LG cs.AI cs.CE q-fin.PM", "Comments": ["9 pages", "8 figures", "5 tables"], "Report-no": "EQT-Motherbrain-Research-2023SIT", "MSC-class": "91B84 (Primary) 68T07 (Secondary)", "ACM-class": "I.2.6; I.2.1; H.4.0"}, "abstract": "This paper addresses the growing application of data-driven approaches within the Private Equity (PE) industry, particularly in sourcing investment targets (i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present a comprehensive review of the relevant approaches and propose a novel approach leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for predicting the success likelihood of any candidate company. The objective of our research is to optimize sourcing performance for VC and GC investments by formally defining the sourcing problem as a multivariate time series classification task. We consecutively introduce the key components of our implementation which collectively contribute to the successful application of TMTSC in VC/GC sourcing: input features, model architecture, optimization target, and investor-centric data augmentation and split. Our extensive experiments on four datasets, benchmarked towards three popular baselines, demonstrate the effectiveness of our approach in improving decision making within the VC and GC industry.", "url": "https://arxiv.org/abs/2309.16888"}, {"metadata": {"arXiv": "2309.16916", "Date": "Fri, 29 Sep 2023 01:07:38 ", "Title": "ONNXExplainer: an ONNX Based Generic Framework to Explain Neural Networks Using Shapley Values", "Authors": ["Yong Zhao", "Runxin He", "Nicholas Kersting", "Can Liu", "Shubham Agrawal", "Chiranjeet Chetia", "Yu Gu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["11 pages", "11 figures"]}, "abstract": "Understanding why a neural network model makes certain decisions can be as important as the inference performance. Various methods have been proposed to help practitioners explain the prediction of a neural network model, of which Shapley values are most popular. SHAP package is a leading implementation of Shapley values to explain neural networks implemented in TensorFlow or PyTorch but lacks cross-platform support, one-shot deployment and is highly inefficient. To address these problems, we present the ONNXExplainer, which is a generic framework to explain neural networks using Shapley values in the ONNX ecosystem. In ONNXExplainer, we develop its own automatic differentiation and optimization approach, which not only enables One-Shot Deployment of neural networks inference and explanations, but also significantly improves the efficiency to compute explanation with less memory consumption. For fair comparison purposes, we also implement the same optimization in TensorFlow and PyTorch and measure its performance against the current state of the art open-source counterpart, SHAP. Extensive benchmarks demonstrate that the proposed optimization approach improves the explanation latency of VGG19, ResNet50, DenseNet201, and EfficientNetB0 by as much as 500%.", "url": "https://arxiv.org/abs/2309.16916"}, {"metadata": {"arXiv": "2309.16918", "Date": "Fri, 29 Sep 2023 01:20:28 ", "Title": "ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph Neural Networks", "Authors": ["Yiqiao Li", "Jianlong Zhou", "Yifei Dong", "Niusha Shafiabady", "Fang Chen"], "Categories": "cs.LG cs.AI", "DOI": "10.1145/3583780.3614772"}, "abstract": "Graph neural networks (GNNs) have proven their efficacy in a variety of real-world applications, but their underlying mechanisms remain a mystery. To address this challenge and enable reliable decision-making, many GNN explainers have been proposed in recent years. However, these methods often encounter limitations, including their dependence on specific instances, lack of generalizability to unseen graphs, producing potentially invalid explanations, and yielding inadequate fidelity. To overcome these limitations, we, in this paper, introduce the Auxiliary Classifier Generative Adversarial Network (ACGAN) into the field of GNN explanation and propose a new GNN explainer dubbed~\\emph{ACGAN-GNNExplainer}. Our approach leverages a generator to produce explanations for the original input graphs while incorporating a discriminator to oversee the generation process, ensuring explanation fidelity and improving accuracy. Experimental evaluations conducted on both synthetic and real-world graph datasets demonstrate the superiority of our proposed method compared to other existing GNN explainers.", "url": "https://arxiv.org/abs/2309.16918"}, {"metadata": {"arXiv": "2309.16923", "Date": "Fri, 29 Sep 2023 01:49:03 ", "Title": "Mode Connectivity and Data Heterogeneity of Federated Learning", "Authors": ["Tailin Zhou", "Jun Zhang", "Danny H.K. Tsang"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning (FL) enables multiple clients to train a model while keeping their data private collaboratively. Previous studies have shown that data heterogeneity between clients leads to drifts across client updates. However, there are few studies on the relationship between client and global modes, making it unclear where these updates end up drifting. We perform empirical and theoretical studies on this relationship by utilizing mode connectivity, which measures performance change (i.e., connectivity) along parametric paths between different modes. Empirically, reducing data heterogeneity makes the connectivity on different paths more similar, forming more low-error overlaps between client and global modes. We also find that a barrier to connectivity occurs when linearly connecting two global modes, while it disappears with considering non-linear mode connectivity. Theoretically, we establish a quantitative bound on the global-mode connectivity using mean-field theory or dropout stability. The bound demonstrates that the connectivity improves when reducing data heterogeneity and widening trained models. Numerical results further corroborate our analytical findings.", "url": "https://arxiv.org/abs/2309.16923"}, {"metadata": {"arXiv": "2309.16928", "Date": "Fri, 29 Sep 2023 02:04:24 ", "Title": "Learning to Receive Help: Intervention-Aware Concept Embedding Models", "Authors": ["Mateo Espinosa Zarlenga", "Katherine M. Collins", "Krishnamurthy Dvijotham", "Adrian Weller", "Zohreh Shams", "Mateja Jamnik"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted as a spotlight at the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Concept Bottleneck Models (CBMs) tackle the opacity of neural architectures by constructing and explaining their predictions using a set of high-level concepts. A special property of these models is that they permit concept interventions, wherein users can correct mispredicted concepts and thus improve the model's performance. Recent work, however, has shown that intervention efficacy can be highly dependent on the order in which concepts are intervened on and on the model's architecture and training hyperparameters. We argue that this is rooted in a CBM's lack of train-time incentives for the model to be appropriately receptive to concept interventions. To address this, we propose Intervention-aware Concept Embedding models (IntCEMs), a novel CBM-based architecture and training paradigm that improves a model's receptiveness to test-time interventions. Our model learns a concept intervention policy in an end-to-end fashion from where it can sample meaningful intervention trajectories at train-time. This conditions IntCEMs to effectively select and receive concept interventions when deployed at test-time. Our experiments show that IntCEMs significantly outperform state-of-the-art concept-interpretable models when provided with test-time concept interventions, demonstrating the effectiveness of our approach.", "url": "https://arxiv.org/abs/2309.16928"}, {"metadata": {"arXiv": "2309.16935", "Date": "Fri, 29 Sep 2023 02:27:54 ", "Title": "TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework", "Authors": ["Yang Zhao", "Wenbo Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Industrial systems demand reliable predictive maintenance strategies to enhance operational efficiency and reduce downtime. This paper introduces a novel, integrated framework that leverages the power of transformer neural networks and deep reinforcement learning (DRL) algorithms to optimize maintenance actions. Our approach employs the transformer model to effectively capture complex temporal patterns in sensor data, thereby accurately predicting the Remaining Useful Life (RUL) of equipment. Simultaneously, the DRL component of our framework provides cost-effective and timely maintenance recommendations. We validate the efficacy of our framework on the NASA C-MPASS dataset, where it demonstrates significant advancements in both RUL prediction accuracy and the optimization of maintenance actions. Consequently, our pioneering approach provides an innovative data-driven methodology for prescriptive maintenance, addressing key challenges in industrial operations and leading the way to more efficient, cost-effective, and reliable systems.", "url": "https://arxiv.org/abs/2309.16935"}, {"metadata": {"arXiv": "2309.17001", "Date": "Fri, 29 Sep 2023 06:11:11 ", "Title": "A Closer Look at Bearing Fault Classification Approaches", "Authors": ["Harika Abburi", "Tanya Chaudhary", "Haider Ilyas", "Lakshmi Manne", "Deepak Mittal", "Don Williams", "Derek Snaidauf", "Edward Bowen", "Balaji Veeramani"], "Categories": "cs.LG cs.AI"}, "abstract": "Rolling bearing fault diagnosis has garnered increased attention in recent years owing to its presence in rotating machinery across various industries, and an ever increasing demand for efficient operations. Prompt detection and accurate prediction of bearing failures can help reduce the likelihood of unexpected machine downtime and enhance maintenance schedules, averting lost productivity. Recent technological advances have enabled monitoring the health of these assets at scale using a variety of sensors, and predicting the failures using modern Machine Learning (ML) approaches including deep learning architectures. Vibration data has been collected using accelerated run-to-failure of overloaded bearings, or by introducing known failure in bearings, under a variety of operating conditions such as rotating speed, load on the bearing, type of bearing fault, and data acquisition frequency. However, in the development of bearing failure classification models using vibration data there is a lack of consensus in the metrics used to evaluate the models, data partitions used to evaluate models, and methods used to generate failure labels in run-to-failure experiments. An understanding of the impact of these choices is important to reliably develop models, and deploy them in practical settings. In this work, we demonstrate the significance of these choices on the performance of the models using publicly-available vibration datasets, and suggest model development considerations for real world scenarios. Our experimental findings demonstrate that assigning vibration data from a given bearing across training and evaluation splits leads to over-optimistic performance estimates, PCA-based approach is able to robustly generate labels for failure classification in run-to-failure experiments, and $F$ scores are more insightful to evaluate the models with unbalanced real-world failure data.", "url": "https://arxiv.org/abs/2309.17001"}, {"metadata": {"arXiv": "2309.17002", "Date": "Fri, 29 Sep 2023 06:18:15 ", "Title": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "Authors": ["Hao Chen", "Jindong Wang", "Ankit Shah", "Ran Tao", "Hongxin Wei", "Xing Xie", "Masashi Sugiyama", "Bhiksha Raj"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["30 pages", "16 figures", "16 tables", "preprint"]}, "abstract": "Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models. We conduct practical experiments on popular vision and language models that are pre-trained on noisy data for evaluation of our approach. Our analysis and results show the importance of this interesting and novel research direction, which we term Noisy Model Learning.", "url": "https://arxiv.org/abs/2309.17002"}, {"metadata": {"arXiv": "2309.17007", "Date": "Fri, 29 Sep 2023 06:44:36 ", "Title": "Medical Foundation Models are Susceptible to Targeted Misinformation Attacks", "Authors": ["Tianyu Han", "Sven Nebelung", "Firas Khader", "Tianci Wang", "Gustav Mueller-Franzes", "Christiane Kuhl", "Sebastian F\\\"orsch", "Jens Kleesiek", "Christoph Haarburger", "Keno K. Bressem", "Jakob Nikolas Kather", "Daniel Truhn"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future. In this study, we demonstrate a concerning vulnerability of LLMs in medicine. Through targeted manipulation of just 1.1% of the model's weights, we can deliberately inject an incorrect biomedical fact. The erroneous information is then propagated in the model's output, whilst its performance on other biomedical tasks remains intact. We validate our findings in a set of 1,038 incorrect biomedical facts. This peculiar susceptibility raises serious security and trustworthiness concerns for the application of LLMs in healthcare settings. It accentuates the need for robust protective measures, thorough verification mechanisms, and stringent management of access to these models, ensuring their reliable and safe use in medical practice.", "url": "https://arxiv.org/abs/2309.17007"}, {"metadata": {"arXiv": "2309.17048", "Date": "Fri, 29 Sep 2023 08:14:25 ", "Title": "On Continuity of Robust and Accurate Classifiers", "Authors": ["Ramin Barati", "Reza Safabakhsh", "Mohammad Rahmati"], "Categories": "cs.LG cs.AI"}, "abstract": "The reliability of a learning model is key to the successful deployment of machine learning in various applications. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difficult to describe the phenomenon due to the complicated nature of the problems in machine learning. It has been shown that adversarial training can improve the robustness of the hypothesis. However, this improvement comes at the cost of decreased performance on natural samples. Hence, it has been suggested that robustness and accuracy of a hypothesis are at odds with each other. In this paper, we put forth the alternative proposal that it is the continuity of a hypothesis that is incompatible with its robustness and accuracy. In other words, a continuous function cannot effectively learn the optimal robust hypothesis. To this end, we will introduce a framework for a rigorous study of harmonic and holomorphic hypothesis in learning theory terms and provide empirical evidence that continuous hypotheses does not perform as well as discontinuous hypotheses in some common machine learning tasks. From a practical point of view, our results suggests that a robust and accurate learning rule would train different continuous hypotheses for different regions of the domain. From a theoretical perspective, our analysis explains the adversarial examples phenomenon as a conflict between the continuity of a sequence of functions and its uniform convergence to a discontinuous function.", "url": "https://arxiv.org/abs/2309.17048"}, {"metadata": {"arXiv": "2309.17095", "Date": "Fri, 29 Sep 2023 09:42:49 ", "Title": "Dynamic Interpretability for Model Comparison via Decision Rules", "Authors": ["Adam Rida", "Marie-Jeanne Lesot", "Xavier Renard", "and Christophe Marsala"], "Categories": "cs.LG cs.AI"}, "abstract": "Explainable AI (XAI) methods have mostly been built to investigate and shed light on single machine learning models and are not designed to capture and explain differences between multiple models effectively. This paper addresses the challenge of understanding and explaining differences between machine learning models, which is crucial for model selection, monitoring and lifecycle management in real-world applications. We propose DeltaXplainer, a model-agnostic method for generating rule-based explanations describing the differences between two binary classifiers. To assess the effectiveness of DeltaXplainer, we conduct experiments on synthetic and real-world datasets, covering various model comparison scenarios involving different types of concept drift.", "url": "https://arxiv.org/abs/2309.17095"}, {"metadata": {"arXiv": "2309.17113", "Date": "Fri, 29 Sep 2023 10:12:30 ", "Title": "Meta-Path Learning for Multi-relational Graph Neural Networks", "Authors": ["Francesco Ferrini", "Antonio Longa", "Andrea Passerini", "Manfred Jaeger"], "Categories": "cs.LG cs.AI"}, "abstract": "Existing multi-relational graph neural networks use one of two strategies for identifying informative relations: either they reduce this problem to low-level weight learning, or they rely on handcrafted chains of relational dependencies, called meta-paths. However, the former approach faces challenges in the presence of many relations (e.g., knowledge graphs), while the latter requires substantial domain expertise to identify relevant meta-paths. In this work we propose a novel approach to learn meta-paths and meta-path GNNs that are highly accurate based on a small number of informative meta-paths. Key element of our approach is a scoring function for measuring the potential informativeness of a relation in the incremental construction of the meta-path. Our experimental evaluation shows that the approach manages to correctly identify relevant meta-paths even with a large number of relations, and substantially outperforms existing multi-relational GNNs on synthetic and real-world experiments.", "url": "https://arxiv.org/abs/2309.17113"}, {"metadata": {"arXiv": "2309.17156", "Date": "Fri, 29 Sep 2023 11:44:18 ", "Title": "Age Group Discrimination via Free Handwriting Indicators", "Authors": ["Eugenio Lomurno", "Simone Toffoli", "Davide Di Febbo", "Matteo Matteucci", "Francesca Lunardini", "Simona Ferrante"], "Categories": "cs.LG cs.AI"}, "abstract": "The growing global elderly population is expected to increase the prevalence of frailty, posing significant challenges to healthcare systems. Frailty, a syndrome associated with ageing, is characterised by progressive health decline, increased vulnerability to stressors and increased risk of mortality. It represents a significant burden on public health and reduces the quality of life of those affected. The lack of a universally accepted method to assess frailty and a standardised definition highlights a critical research gap. Given this lack and the importance of early prevention, this study presents an innovative approach using an instrumented ink pen to ecologically assess handwriting for age group classification. Content-free handwriting data from 80 healthy participants in different age groups (20-40, 41-60, 61-70 and 70+) were analysed. Fourteen gesture- and tremor-related indicators were computed from the raw data and used in five classification tasks. These tasks included discriminating between adjacent and non-adjacent age groups using Catboost and Logistic Regression classifiers. Results indicate exceptional classifier performance, with accuracy ranging from 82.5% to 97.5%, precision from 81.8% to 100%, recall from 75% to 100% and ROC-AUC from 92.2% to 100%. Model interpretability, facilitated by SHAP analysis, revealed age-dependent sensitivity of temporal and tremor-related handwriting features. Importantly, this classification method offers potential for early detection of abnormal signs of ageing in uncontrolled settings such as remote home monitoring, thereby addressing the critical issue of frailty detection and contributing to improved care for older adults.", "url": "https://arxiv.org/abs/2309.17156"}, {"metadata": {"arXiv": "2309.17179", "Date": "Fri, 29 Sep 2023 12:20:19 ", "Title": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training", "Authors": ["Xidong Feng", "Ziyu Wan", "Muning Wen", "Ying Wen", "Weinan Zhang", "Jun Wang"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large language models (LLMs) typically employ sampling or beam search, accompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and decoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via Planning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing tree-search algorithms to guide multi-step reasoning. These methods mainly focus on LLMs' reasoning ability during inference and heavily rely on human-designed prompts to activate LLM as a value function, which lacks general applicability and scalability. To address these limitations, we present an AlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically illustrating how tree-search with a learned value function can guide LLMs' decoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a learned value function, our approach can be generally applied to different tasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without prompting advanced, large-scale models. (2) It can guide LLM's decoding during both inference and training. Empirical evaluations across reasoning, planning, and RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees with a depth of 64.", "url": "https://arxiv.org/abs/2309.17179"}, {"metadata": {"arXiv": "2309.17197", "Date": "Fri, 29 Sep 2023 12:45:53 ", "Title": "An Investigation Into Race Bias in Random Forest Models Based on Breast DCE-MRI Derived Radiomics Features", "Authors": ["Mohamed Huti", "Tiarna Lee", "Elinor Sawyer", "Andrew P. King"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted for publication at the MICCAI Workshop on Fairness of AI in Medical Imaging (FAIMI) 2023"]}, "abstract": "Recent research has shown that artificial intelligence (AI) models can exhibit bias in performance when trained using data that are imbalanced by protected attribute(s). Most work to date has focused on deep learning models, but classical AI techniques that make use of hand-crafted features may also be susceptible to such bias. In this paper we investigate the potential for race bias in random forest (RF) models trained using radiomics features. Our application is prediction of tumour molecular subtype from dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) of breast cancer patients. Our results show that radiomics features derived from DCE-MRI data do contain race-identifiable information, and that RF models can be trained to predict White and Black race from these data with 60-70% accuracy, depending on the subset of features used. Furthermore, RF models trained to predict tumour molecular subtype using race-imbalanced data seem to produce biased behaviour, exhibiting better performance on test data from the race on which they were trained.", "url": "https://arxiv.org/abs/2309.17197"}, {"metadata": {"arXiv": "2309.17203", "Date": "Fri, 29 Sep 2023 12:53:41 ", "Title": "ComSD: Balancing Behavioral Quality and Diversity in Unsupervised Skill Discovery", "Authors": ["Xin Liu", "Yaran Chen", "Dongbin Zhao"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "Learning diverse and qualified behaviors for utilization and adaptation without supervision is a key ability of intelligent creatures. Ideal unsupervised skill discovery methods are able to produce diverse and qualified skills in the absence of extrinsic reward, while the discovered skill set can efficiently adapt to downstream tasks in various ways. Maximizing the Mutual Information (MI) between skills and visited states can achieve ideal skill-conditioned behavior distillation in theory. However, it's difficult for recent advanced methods to well balance behavioral quality (exploration) and diversity (exploitation) in practice, which may be attributed to the unreasonable MI estimation by their rigid intrinsic reward design. In this paper, we propose Contrastive multi-objectives Skill Discovery (ComSD) which tries to mitigate the quality-versus-diversity conflict of discovered behaviors through a more reasonable MI estimation and a dynamically weighted intrinsic reward. ComSD proposes to employ contrastive learning for a more reasonable estimation of skill-conditioned entropy in MI decomposition. In addition, a novel weighting mechanism is proposed to dynamically balance different entropy (in MI decomposition) estimations into a novel multi-objective intrinsic reward, to improve both skill diversity and quality. For challenging robot behavior discovery, ComSD can produce a qualified skill set consisting of diverse behaviors at different activity levels, which recent advanced methods cannot. On numerical evaluations, ComSD exhibits state-of-the-art adaptation performance, significantly outperforming recent advanced skill discovery methods across all skill combination tasks and most skill finetuning tasks. Codes will be released at https://github.com/liuxin0824/ComSD.", "url": "https://arxiv.org/abs/2309.17203"}, {"metadata": {"arXiv": "2309.17215", "Date": "Fri, 29 Sep 2023 13:14:28 ", "Title": "RSAM: Learning on manifolds with Riemannian Sharpness-aware Minimization", "Authors": ["Tuan Truong", "Hoang-Phi Nguyen", "Tung Pham", "Minh-Tuan Tran", "Mehrtash Harandi", "Dinh Phung", "Trung Le"], "Categories": "cs.LG cs.AI"}, "abstract": "Nowadays, understanding the geometry of the loss landscape shows promise in enhancing a model's generalization ability. In this work, we draw upon prior works that apply geometric principles to optimization and present a novel approach to improve robustness and generalization ability for constrained optimization problems. Indeed, this paper aims to generalize the Sharpness-Aware Minimization (SAM) optimizer to Riemannian manifolds. In doing so, we first extend the concept of sharpness and introduce a novel notion of sharpness on manifolds. To support this notion of sharpness, we present a theoretical analysis characterizing generalization capabilities with respect to manifold sharpness, which demonstrates a tighter bound on the generalization gap, a result not known before. Motivated by this analysis, we introduce our algorithm, Riemannian Sharpness-Aware Minimization (RSAM). To demonstrate RSAM's ability to enhance generalization ability, we evaluate and contrast our algorithm on a broad set of problems, such as image classification and contrastive learning across different datasets, including CIFAR100, CIFAR10, and FGVCAircraft. Our code is publicly available at \\url{https://t.ly/RiemannianSAM}.", "url": "https://arxiv.org/abs/2309.17215"}, {"metadata": {"arXiv": "2309.17335", "Date": "Fri, 29 Sep 2023 15:46:41 ", "Title": "Asynchronous Graph Generators", "Authors": ["Christopher P. Ley and Felipe Tobar"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to ICLR 2024"]}, "abstract": "We introduce the asynchronous graph generator (AGG), a novel graph neural network architecture for multi-channel time series which models observations as nodes on a dynamic graph and can thus perform data imputation by transductive node generation. Completely free from recurrent components or assumptions about temporal regularity, AGG represents measurements, timestamps and metadata directly in the nodes via learnable embeddings, to then leverage attention to learn expressive relationships across the variables of interest. This way, the proposed architecture implicitly learns a causal graph representation of sensor measurements which can be conditioned on unseen timestamps and metadata to predict new measurements by an expansion of the learnt graph. The proposed AGG is compared both conceptually and empirically to previous work, and the impact of data augmentation on the performance of AGG is also briefly discussed. Our experiments reveal that AGG achieved state-of-the-art results in time series data imputation, classification and prediction for the benchmark datasets Beijing Air Quality, PhysioNet Challenge 2012 and UCI localisation.", "url": "https://arxiv.org/abs/2309.17335"}, {"metadata": {"arXiv": "2309.17337", "Date": "Fri, 29 Sep 2023 15:48:26 ", "Title": "Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools", "Authors": ["Emily Black", "Rakshit Naidu", "Rayid Ghani", "Kit T. Rodolfa", "Daniel E. Ho", "Hoda Heidari"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["EAAMO'23 (Archival)"], "DOI": "10.1145/3617694.3623259"}, "abstract": "While algorithmic fairness is a thriving area of research, in practice, mitigating issues of bias often gets reduced to enforcing an arbitrarily chosen fairness metric, either by enforcing fairness constraints during the optimization step, post-processing model outputs, or by manipulating the training data. Recent work has called on the ML community to take a more holistic approach to tackle fairness issues by systematically investigating the many design choices made through the ML pipeline, and identifying interventions that target the issue's root cause, as opposed to its symptoms. While we share the conviction that this pipeline-based approach is the most appropriate for combating algorithmic unfairness on the ground, we believe there are currently very few methods of \\emph{operationalizing} this approach in practice. Drawing on our experience as educators and practitioners, we first demonstrate that without clear guidelines and toolkits, even individuals with specialized ML knowledge find it challenging to hypothesize how various design choices influence model behavior. We then consult the fair-ML literature to understand the progress to date toward operationalizing the pipeline-aware approach: we systematically collect and organize the prior work that attempts to detect, measure, and mitigate various sources of unfairness through the ML pipeline. We utilize this extensive categorization of previous contributions to sketch a research agenda for the community. We hope this work serves as the stepping stone toward a more comprehensive set of resources for ML researchers, practitioners, and students interested in exploring, designing, and testing pipeline-oriented approaches to algorithmic fairness.", "url": "https://arxiv.org/abs/2309.17337"}, {"metadata": {"arXiv": "2309.17341", "Date": "Fri, 29 Sep 2023 15:49:54 ", "Title": "MixQuant: Mixed Precision Quantization with a Bit-width Optimization Search", "Authors": ["Eliska Kloberdanz and Wei Le"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Quantization is a technique for creating efficient Deep Neural Networks (DNNs), which involves performing computations and storing tensors at lower bit-widths than f32 floating point precision. Quantization reduces model size and inference latency, and therefore allows for DNNs to be deployed on platforms with constrained computational resources and real-time systems. However, quantization can lead to numerical instability caused by roundoff error which leads to inaccurate computations and therefore, a decrease in quantized model accuracy. Similarly to prior works, which have shown that both biases and activations are more sensitive to quantization and are best kept in full precision or quantized with higher bit-widths, we show that some weights are more sensitive than others which should be reflected on their quantization bit-width. To that end we propose MixQuant, a search algorithm that finds the optimal custom quantization bit-width for each layer weight based on roundoff error and can be combined with any quantization method as a form of pre-processing optimization. We show that combining MixQuant with BRECQ, a state-of-the-art quantization method, yields better quantized model accuracy than BRECQ alone. Additionally, we combine MixQuant with vanilla asymmetric quantization to show that MixQuant has the potential to optimize the performance of any quantization technique.", "url": "https://arxiv.org/abs/2309.17341"}, {"metadata": {"arXiv": "2309.17401", "Date": "Fri, 29 Sep 2023 17:01:29 ", "Title": "Adversarial Machine Learning in Latent Representations of Neural Networks", "Authors": ["Milin Zhang", "Mohammad Abdi and Francesco Restuccia"], "Categories": "cs.LG cs.AI"}, "abstract": "Distributed deep neural networks (DNNs) have been shown to reduce the computational burden of mobile devices and decrease the end-to-end inference latency in edge computing scenarios. While distributed DNNs have been studied, to the best of our knowledge the resilience of distributed DNNs to adversarial action still remains an open problem. In this paper, we fill the existing research gap by rigorously analyzing the robustness of distributed DNNs against adversarial action. We cast this problem in the context of information theory and introduce two new measurements for distortion and robustness. Our theoretical findings indicate that (i) assuming the same level of information distortion, latent features are always more robust than input representations; (ii) the adversarial robustness is jointly determined by the feature dimension and the generalization capability of the DNN. To test our theoretical findings, we perform extensive experimental analysis by considering 6 different DNN architectures, 6 different approaches for distributed DNN and 10 different adversarial attacks to the ImageNet-1K dataset. Our experimental results support our theoretical findings by showing that the compressed latent representations can reduce the success rate of adversarial attacks by 88% in the best case and by 57% on the average compared to attacks to the input space.", "url": "https://arxiv.org/abs/2309.17401"}, {"metadata": {"arXiv": "2309.17227", "Date": "Fri, 29 Sep 2023 13:25:45 ", "Title": "MORPH: Design Co-optimization with Reinforcement Learning via a Differentiable Hardware Model Proxy", "Authors": ["Zhanpeng He and Matei Ciocarlie"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "We introduce MORPH, a method for co-optimization of hardware design parameters and control policies in simulation using reinforcement learning. Like most co-optimization methods, MORPH relies on a model of the hardware being optimized, usually simulated based on the laws of physics. However, such a model is often difficult to integrate into an effective optimization routine. To address this, we introduce a proxy hardware model, which is always differentiable and enables efficient co-optimization alongside a long-horizon control policy using RL. MORPH is designed to ensure that the optimized hardware proxy remains as close as possible to its realistic counterpart, while still enabling task completion. We demonstrate our approach on simulated 2D reaching and 3D multi-fingered manipulation tasks.", "url": "https://arxiv.org/abs/2309.17227"}, {"metadata": {"arXiv": "2309.17260", "Date": "Fri, 29 Sep 2023 14:12:54 ", "Title": "PlaceNav: Topological Navigation through Place Recognition", "Authors": ["Lauri Suomela", "Jussi Kalliola", "Atakan Dag", "Harry Edelman", "Joni-Kristian K\\\"am\\\"ar\\\"ainen"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Recent results suggest that splitting topological navigation into robot-independent and robot-specific components improves navigation performance by enabling the robot-independent part to be trained with data collected by different robot types. However, the navigation methods are still limited by the scarcity of suitable training data and suffer from poor computational scaling. In this work, we present~\\methodname, subdividing the robot-independent part into navigation-specific and generic computer vision components. We utilize visual place recognition for the subgoal selection of the topological navigation pipeline. This makes subgoal selection more efficient and enables leveraging large-scale datasets from non-robotics sources, increasing training data availability. Bayes filtering, enabled by place recognition, further improves navigation performance by increasing the temporal consistency of subgoals. Our experimental results verify the design and the new model obtains a 76% higher success rate in indoor and 23% higher in outdoor navigation tasks with higher computational efficiency.", "url": "https://arxiv.org/abs/2309.17260"}, {"metadata": {"arXiv": "2309.17338", "Date": "Fri, 29 Sep 2023 15:48:35 ", "Title": "Improving Trajectory Prediction in Dynamic Multi-Agent Environment by Dropping Waypoints", "Authors": ["Pranav Singh Chib", "Pravendra Singh"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["Under Review"]}, "abstract": "The inherently diverse and uncertain nature of trajectories presents a formidable challenge in accurately modeling them. Motion prediction systems must effectively learn spatial and temporal information from the past to forecast the future trajectories of the agent. Many existing methods learn temporal motion via separate components within stacked models to capture temporal features. This paper introduces a novel framework, called Temporal Waypoint Dropping (TWD), that promotes explicit temporal learning through the waypoint dropping technique. Learning through waypoint dropping can compel the model to improve its understanding of temporal correlations among agents, thus leading to a significant enhancement in trajectory prediction. Trajectory prediction methods often operate under the assumption that observed trajectory waypoint sequences are complete, disregarding real-world scenarios where missing values may occur, which can influence their performance. Moreover, these models frequently exhibit a bias towards particular waypoint sequences when making predictions. Our TWD is capable of effectively addressing these issues. It incorporates stochastic and fixed processes that regularize projected past trajectories by strategically dropping waypoints based on temporal sequences. Through extensive experiments, we demonstrate the effectiveness of TWD in forcing the model to learn complex temporal correlations among agents. Our approach can complement existing trajectory prediction methods to enhance prediction accuracy. We also evaluate our proposed method across three datasets: NBA Sports VU, ETH-UCY, and TrajNet++.", "url": "https://arxiv.org/abs/2309.17338"}, {"metadata": {"arXiv": "2309.16977", "Date": "Fri, 29 Sep 2023 04:49:49 ", "Title": "Reliability Quantification of Deep Reinforcement Learning-based Control", "Authors": ["Hitoshi Yoshioka", "Hirotada Hashimoto"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["18 pages and 17 figures"], "MSC-class": "68T40 Artificial intelligence for robotics"}, "abstract": "Reliability quantification of deep reinforcement learning (DRL)-based control is a significant challenge for the practical application of artificial intelligence (AI) in safety-critical systems. This study proposes a method for quantifying the reliability of DRL-based control. First, an existing method, random noise distillation, was applied to the reliability evaluation to clarify the issues to be solved. Second, a novel method for reliability quantification was proposed to solve these issues. The reliability is quantified using two neural networks: reference and evaluator. They have the same structure with the same initial parameters. The outputs of the two networks were the same before training. During training, the evaluator network parameters were updated to maximize the difference between the reference and evaluator networks for trained data. Thus, the reliability of the DRL-based control for a state can be evaluated based on the difference in output between the two networks. The proposed method was applied to DQN-based control as an example of a simple task, and its effectiveness was demonstrated. Finally, the proposed method was applied to the problem of switching trained models depending on the state. Con-sequently, the performance of the DRL-based control was improved by switching the trained models according to their reliability.", "url": "https://arxiv.org/abs/2309.16977"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

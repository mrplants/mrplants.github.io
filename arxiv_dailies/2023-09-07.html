<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.02556", "Date": "Tue, 05 Sep 2023 19:45:27 ", "Title": "Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images", "Authors": ["Teru Nagamori", "Sayaka Shiota", "Hitoshi Kiya"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["Accepted by APSIPA 2023"]}, "abstract": "In recent years, deep neural networks (DNNs) trained with transformed data have been applied to various applications such as privacy-preserving learning, access control, and adversarial defenses. However, the use of transformed data decreases the performance of models. Accordingly, in this paper, we propose a novel method for fine-tuning models with transformed images under the use of the vision transformer (ViT). The proposed domain adaptation method does not cause the accuracy degradation of models, and it is carried out on the basis of the embedding structure of ViT. In experiments, we confirmed that the proposed method prevents accuracy degradation even when using encrypted images with the CIFAR-10 and CIFAR-100 datasets.", "url": "https://arxiv.org/abs/2309.02556"}, {"metadata": {"arXiv": "2309.02578", "Date": "Tue, 05 Sep 2023 20:58:15 ", "Title": "Anatomy-Driven Pathology Detection on Chest X-rays", "Authors": ["Philip M\\\"uller", "Felix Meissen", "Johannes Brandt", "Georgios Kaissis", "Daniel Rueckert"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at MICCAI 2023"]}, "abstract": "Pathology detection and delineation enables the automatic interpretation of medical scans such as chest X-rays while providing a high level of explainability to support radiologists in making informed decisions. However, annotating pathology bounding boxes is a time-consuming task such that large public datasets for this purpose are scarce. Current approaches thus use weakly supervised object detection to learn the (rough) localization of pathologies from image-level annotations, which is however limited in performance due to the lack of bounding box supervision. We therefore propose anatomy-driven pathology detection (ADPD), which uses easy-to-annotate bounding boxes of anatomical regions as proxies for pathologies. We study two training approaches: supervised training using anatomy-level pathology labels and multiple instance learning (MIL) with image-level pathology labels. Our results show that our anatomy-level training approach outperforms weakly supervised methods and fully supervised detection with limited training samples, and our MIL approach is competitive with both baseline approaches, therefore demonstrating the potential of our approach.", "url": "https://arxiv.org/abs/2309.02578"}, {"metadata": {"arXiv": "2309.02596", "Date": "Tue, 05 Sep 2023 21:36:42 ", "Title": "Self-Supervised Pretraining Improves Performance and Inference Efficiency in Multiple Lung Ultrasound Interpretation Tasks", "Authors": ["Blake VanBerlo", "Brian Li", "Jesse Hoey", "Alexander Wong"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "5 figures", "submitted to IEEE Access"]}, "abstract": "In this study, we investigated whether self-supervised pretraining could produce a neural network feature extractor applicable to multiple classification tasks in B-mode lung ultrasound analysis. When fine-tuning on three lung ultrasound tasks, pretrained models resulted in an improvement of the average across-task area under the receiver operating curve (AUC) by 0.032 and 0.061 on local and external test sets respectively. Compact nonlinear classifiers trained on features outputted by a single pretrained model did not improve performance across all tasks; however, they did reduce inference time by 49% compared to serial execution of separate fine-tuned models. When training using 1% of the available labels, pretrained models consistently outperformed fully supervised models, with a maximum observed test AUC increase of 0.396 for the task of view classification. Overall, the results indicate that self-supervised pretraining is useful for producing initial weights for lung ultrasound classifiers.", "url": "https://arxiv.org/abs/2309.02596"}, {"metadata": {"arXiv": "2309.02617", "Date": "Tue, 05 Sep 2023 23:33:39 ", "Title": "Compressing Vision Transformers for Low-Resource Visual Learning", "Authors": ["Eric Youn", "Sai Mitheran J", "Sanjana Prabhu", "Siyuan Chen"], "Categories": "cs.CV cs.LG"}, "abstract": "Vision transformer (ViT) and its variants have swept through visual learning leaderboards and offer state-of-the-art accuracy in tasks such as image classification, object detection, and semantic segmentation by attending to different parts of the visual input and capturing long-range spatial dependencies. However, these models are large and computation-heavy. For instance, the recently proposed ViT-B model has 86M parameters making it impractical for deployment on resource-constrained devices. As a result, their deployment on mobile and edge scenarios is limited. In our work, we aim to take a step toward bringing vision transformers to the edge by utilizing popular model compression techniques such as distillation, pruning, and quantization. Our chosen application environment is an unmanned aerial vehicle (UAV) that is battery-powered and memory-constrained, carrying a single-board computer on the scale of an NVIDIA Jetson Nano with 4GB of RAM. On the other hand, the UAV requires high accuracy close to that of state-of-the-art ViTs to ensure safe object avoidance in autonomous navigation, or correct localization of humans in search-and-rescue. Inference latency should also be minimized given the application requirements. Hence, our target is to enable rapid inference of a vision transformer on an NVIDIA Jetson Nano (4GB) with minimal accuracy loss. This allows us to deploy ViTs on resource-constrained devices, opening up new possibilities in surveillance, environmental monitoring, etc. Our implementation is made available at https://github.com/chensy7/efficient-vit.", "url": "https://arxiv.org/abs/2309.02617"}, {"metadata": {"arXiv": "2309.02636", "Date": "Wed, 06 Sep 2023 00:56:24 ", "Title": "Multiclass Alignment of Confidence and Certainty for Network Calibration", "Authors": ["Vinith Kugathasan and Muhammad Haris Khan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at GCPR 2023"]}, "abstract": "Deep neural networks (DNNs) have made great strides in pushing the state-of-the-art in several challenging domains. Recent studies reveal that they are prone to making overconfident predictions. This greatly reduces the overall trust in model predictions, especially in safety-critical applications. Early work in improving model calibration employs post-processing techniques which rely on limited parameters and require a hold-out set. Some recent train-time calibration methods, which involve all model parameters, can outperform the postprocessing methods. To this end, we propose a new train-time calibration method, which features a simple, plug-and-play auxiliary loss known as multi-class alignment of predictive mean confidence and predictive certainty (MACC). It is based on the observation that a model miscalibration is directly related to its predictive certainty, so a higher gap between the mean confidence and certainty amounts to a poor calibration both for in-distribution and out-of-distribution predictions. Armed with this insight, our proposed loss explicitly encourages a confident (or underconfident) model to also provide a low (or high) spread in the presoftmax distribution. Extensive experiments on ten challenging datasets, covering in-domain, out-domain, non-visual recognition and medical image classification scenarios, show that our method achieves state-of-the-art calibration performance for both in-domain and out-domain predictions. Our code and models will be publicly released.", "url": "https://arxiv.org/abs/2309.02636"}, {"metadata": {"arXiv": "2309.02954", "Date": "Wed, 06 Sep 2023 12:43:18 ", "Title": "M3D-NCA: Robust 3D Segmentation with Built-in Quality Control", "Authors": ["John Kalkhof", "Anirban Mukhopadhyay"], "Categories": "cs.CV cs.LG"}, "abstract": "Medical image segmentation relies heavily on large-scale deep learning models, such as UNet-based architectures. However, the real-world utility of such models is limited by their high computational requirements, which makes them impractical for resource-constrained environments such as primary care facilities and conflict zones. Furthermore, shifts in the imaging domain can render these models ineffective and even compromise patient safety if such errors go undetected. To address these challenges, we propose M3D-NCA, a novel methodology that leverages Neural Cellular Automata (NCA) segmentation for 3D medical images using n-level patchification. Moreover, we exploit the variance in M3D-NCA to develop a novel quality metric which can automatically detect errors in the segmentation process of NCAs. M3D-NCA outperforms the two magnitudes larger UNet models in hippocampus and prostate segmentation by 2% Dice and can be run on a Raspberry Pi 4 Model B (2GB RAM). This highlights the potential of M3D-NCA as an effective and efficient alternative for medical image segmentation in resource-constrained environments.", "url": "https://arxiv.org/abs/2309.02954"}, {"metadata": {"arXiv": "2309.03072", "Date": "Wed, 06 Sep 2023 15:19:04 ", "Title": "Character Queries: A Transformer-based Approach to On-Line Handwritten Character Segmentation", "Authors": ["Michael Jungo", "Beat Wolf", "Andrii Maksai", "Claudiu Musat and Andreas Fischer"], "Categories": "cs.CV cs.LG", "Comments": ["ICDAR 2023 Best Student Paper Award. Code available at https://github.com/jungomi/character-queries"], "Journal-ref": "International Conference on Document Analysis and Recognition - ICDAR 2023, pp. 98-114. Cham: Springer Nature Switzerland", "DOI": "10.1007/978-3-031-41676-7_6"}, "abstract": "On-line handwritten character segmentation is often associated with handwriting recognition and even though recognition models include mechanisms to locate relevant positions during the recognition process, it is typically insufficient to produce a precise segmentation. Decoupling the segmentation from the recognition unlocks the potential to further utilize the result of the recognition. We specifically focus on the scenario where the transcription is known beforehand, in which case the character segmentation becomes an assignment problem between sampling points of the stylus trajectory and characters in the text. Inspired by the $k$-means clustering algorithm, we view it from the perspective of cluster assignment and present a Transformer-based architecture where each cluster is formed based on a learned character query in the Transformer decoder block. In order to assess the quality of our approach, we create character segmentation ground truths for two popular on-line handwriting datasets, IAM-OnDB and HANDS-VNOnDB, and evaluate multiple methods on them, demonstrating that our approach achieves the overall best results.", "url": "https://arxiv.org/abs/2309.03072"}, {"metadata": {"arXiv": "2309.03179", "Date": "Wed, 06 Sep 2023 17:39:05 ", "Title": "SLiMe: Segment Like Me", "Authors": ["Aliasghar Khani", "Saeid Asgari Taghanaki", "Aditya Sanghi", "Ali Mahdavi Amiri", "Ghassan Hamarneh"], "Categories": "cs.CV cs.LG"}, "abstract": "Significant strides have been made using large vision-language models, like Stable Diffusion (SD), for a variety of downstream tasks, including image editing, image correspondence, and 3D shape generation. Inspired by these advancements, we explore leveraging these extensive vision-language models for segmenting images at any desired granularity using as few as one annotated sample by proposing SLiMe. SLiMe frames this problem as an optimization task. Specifically, given a single training image and its segmentation mask, we first extract attention maps, including our novel \"weighted accumulated self-attention map\" from the SD prior. Then, using the extracted attention maps, the text embeddings of Stable Diffusion are optimized such that, each of them, learn about a single segmented region from the training image. These learned embeddings then highlight the segmented region in the attention maps, which in turn can then be used to derive the segmentation map. This enables SLiMe to segment any real-world image during inference with the granularity of the segmented region in the training image, using just one example. Moreover, leveraging additional training data when available, i.e. few-shot, improves the performance of SLiMe. We carried out a knowledge-rich set of experiments examining various design factors and showed that SLiMe outperforms other existing one-shot and few-shot segmentation methods.", "url": "https://arxiv.org/abs/2309.03179"}, {"metadata": {"arXiv": "2309.02521", "Date": "Tue, 05 Sep 2023 18:22:11 ", "Title": "Comparative Analysis of CPU and GPU Profiling for Deep Learning Models", "Authors": ["Dipesh Gyawali"], "Categories": "cs.DC cs.LG", "Comments": ["6 pages", "11 figures"]}, "abstract": "Deep Learning(DL) and Machine Learning(ML) applications are rapidly increasing in recent days. Massive amounts of data are being generated over the internet which can derive meaningful results by the use of ML and DL algorithms. Hardware resources and open-source libraries have made it easy to implement these algorithms. Tensorflow and Pytorch are one of the leading frameworks for implementing ML projects. By using those frameworks, we can trace the operations executed on both GPU and CPU to analyze the resource allocations and consumption. This paper presents the time and memory allocation of CPU and GPU while training deep neural networks using Pytorch. This paper analysis shows that GPU has a lower running time as compared to CPU for deep neural networks. For a simpler network, there are not many significant improvements in GPU over the CPU.", "url": "https://arxiv.org/abs/2309.02521"}, {"metadata": {"arXiv": "2309.03014", "Date": "Wed, 06 Sep 2023 13:59:04 ", "Title": "SymED: Adaptive and Online Symbolic Representation of Data on the Edge", "Authors": ["Daniel Hofst\\\"atter", "Shashikant Ilager", "Ivan Lujic", "Ivona Brandic"], "Categories": "cs.DC cs.LG", "Comments": ["14 pages", "5 figures"], "Journal-ref": "Euro-Par 2023: Parallel Processing pp 411-425. Springer Nature Switzerland, Cham (2023)", "DOI": "10.1007/978-3-031-39698-4_28"}, "abstract": "The edge computing paradigm helps handle the Internet of Things (IoT) generated data in proximity to its source. Challenges occur in transferring, storing, and processing this rapidly growing amount of data on resource-constrained edge devices. Symbolic Representation (SR) algorithms are promising solutions to reduce the data size by converting actual raw data into symbols. Also, they allow data analytics (e.g., anomaly detection and trend prediction) directly on symbols, benefiting large classes of edge applications. However, existing SR algorithms are centralized in design and work offline with batch data, which is infeasible for real-time cases. We propose SymED - Symbolic Edge Data representation method, i.e., an online, adaptive, and distributed approach for symbolic representation of data on edge. SymED is based on the Adaptive Brownian Bridge-based Aggregation (ABBA), where we assume low-powered IoT devices do initial data compression (senders) and the more robust edge devices do the symbolic conversion (receivers). We evaluate SymED by measuring compression performance, reconstruction accuracy through Dynamic Time Warping (DTW) distance, and computational latency. The results show that SymED is able to (i) reduce the raw data with an average compression rate of 9.5%; (ii) keep a low reconstruction error of 13.25 in the DTW space; (iii) simultaneously provide real-time adaptability for online streaming IoT data at typical latencies of 42ms per symbol, reducing the overall network traffic.", "url": "https://arxiv.org/abs/2309.03014"}, {"metadata": {"arXiv": "2309.02449", "Date": "Sat, 02 Sep 2023 02:01:51 ", "Title": "League of Legends: Real-Time Result Prediction", "Authors": ["Jailson B. S. Junior and Claudio E. C. Campelo"], "Categories": "cs.LG", "Comments": ["8 pages"]}, "abstract": "This paper presents a study on the prediction of outcomes in matches of the electronic game League of Legends (LoL) using machine learning techniques. With the aim of exploring the ability to predict real-time results, considering different variables and stages of the match, we highlight the use of unpublished data as a fundamental part of this process. With the increasing popularity of LoL and the emergence of tournaments, betting related to the game has also emerged, making the investigation in this area even more relevant. A variety of models were evaluated and the results were encouraging. A model based on LightGBM showed the best performance, achieving an average accuracy of 81.62\\% in intermediate stages of the match when the percentage of elapsed time was between 60\\% and 80\\%. On the other hand, the Logistic Regression and Gradient Boosting models proved to be more effective in early stages of the game, with promising results. This study contributes to the field of machine learning applied to electronic games, providing valuable insights into real-time prediction in League of Legends. The results obtained may be relevant for both players seeking to improve their strategies and the betting industry related to the game.", "url": "https://arxiv.org/abs/2309.02449"}, {"metadata": {"arXiv": "2309.02467", "Date": "Tue, 05 Sep 2023 03:56:21 ", "Title": "Developing A Fair Individualized Polysocial Risk Score (iPsRS) for Identifying Increased Social Risk of Hospitalizations in Patients with Type 2 Diabetes (T2D)", "Authors": ["Yu Huang", "Jingchuan Guo", "William T Donahoo", "Zhengkang Fan", "Ying Lu", "Wei-Han Chen", "Huilin Tang", "Lori Bilello", "Elizabeth A Shenkman", "Jiang Bian"], "Categories": "cs.LG cs.CY"}, "abstract": "Background: Racial and ethnic minority groups and individuals facing social disadvantages, which often stem from their social determinants of health (SDoH), bear a disproportionate burden of type 2 diabetes (T2D) and its complications. It is therefore crucial to implement effective social risk management strategies at the point of care. Objective: To develop an EHR-based machine learning (ML) analytical pipeline to identify the unmet social needs associated with hospitalization risk in patients with T2D. Methods: We identified 10,192 T2D patients from the EHR data (from 2012 to 2022) from the University of Florida Health Integrated Data Repository, including contextual SDoH (e.g., neighborhood deprivation) and individual-level SDoH (e.g., housing stability). We developed an electronic health records (EHR)-based machine learning (ML) analytic pipeline, namely individualized polysocial risk score (iPsRS), to identify high social risk associated with hospitalizations in T2D patients, along with explainable AI (XAI) techniques and fairness assessment and optimization. Results: Our iPsRS achieved a C statistic of 0.72 in predicting 1-year hospitalization after fairness optimization across racial-ethnic groups. The iPsRS showed excellent utility for capturing individuals at high hospitalization risk; the actual 1-year hospitalization rate in the top 5% of iPsRS was ~13 times as high as the bottom decile. Conclusion: Our ML pipeline iPsRS can fairly and accurately screen for patients who have increased social risk leading to hospitalization in T2D patients.", "url": "https://arxiv.org/abs/2309.02467"}, {"metadata": {"arXiv": "2309.02517", "Date": "Tue, 05 Sep 2023 18:06:09 ", "Title": "Towards User Guided Actionable Recourse", "Authors": ["Jayanth Yetukuri", "Ian Hardy and Yang Liu"], "Categories": "cs.LG cs.CY", "Journal-ref": "In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society (AIES '23). Association for Computing Machinery, New York, NY, USA, 742 751", "DOI": "10.1145/3600211.3604708"}, "abstract": "Machine Learning's proliferation in critical fields such as healthcare, banking, and criminal justice has motivated the creation of tools which ensure trust and transparency in ML models. One such tool is Actionable Recourse (AR) for negatively impacted users. AR describes recommendations of cost-efficient changes to a user's actionable features to help them obtain favorable outcomes. Existing approaches for providing recourse optimize for properties such as proximity, sparsity, validity, and distance-based costs. However, an often-overlooked but crucial requirement for actionability is a consideration of User Preference to guide the recourse generation process. In this work, we attempt to capture user preferences via soft constraints in three simple forms: i) scoring continuous features, ii) bounding feature values and iii) ranking categorical features. Finally, we propose a gradient-based approach to identify User Preferred Actionable Recourse (UP-AR). We carried out extensive experiments to verify the effectiveness of our approach.", "url": "https://arxiv.org/abs/2309.02517"}, {"metadata": {"arXiv": "2309.02528", "Date": "Tue, 05 Sep 2023 18:40:22 ", "Title": "Adaptive Adversarial Training Does Not Increase Recourse Costs", "Authors": ["Ian Hardy", "Jayanth Yetukuri and Yang Liu"], "Categories": "cs.LG cs.CR", "Journal-ref": "In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society (AIES '23). Association for Computing Machinery, New York, NY, USA, 432 442", "DOI": "10.1145/3600211.3604704"}, "abstract": "Recent work has connected adversarial attack methods and algorithmic recourse methods: both seek minimal changes to an input instance which alter a model's classification decision. It has been shown that traditional adversarial training, which seeks to minimize a classifier's susceptibility to malicious perturbations, increases the cost of generated recourse; with larger adversarial training radii correlating with higher recourse costs. From the perspective of algorithmic recourse, however, the appropriate adversarial training radius has always been unknown. Another recent line of work has motivated adversarial training with adaptive training radii to address the issue of instance-wise variable adversarial vulnerability, showing success in domains with unknown attack radii. This work studies the effects of adaptive adversarial training on algorithmic recourse costs. We establish that the improvements in model robustness induced by adaptive adversarial training show little effect on algorithmic recourse costs, providing a potential avenue for affordable robustness in domains where recoursability is critical.", "url": "https://arxiv.org/abs/2309.02528"}, {"metadata": {"arXiv": "2309.02530", "Date": "Tue, 05 Sep 2023 18:52:35 ", "Title": "Diffusion on the Probability Simplex", "Authors": ["Griffin Floto", "Thorsteinn Jonsson", "Mihai Nica", "Scott Sanner", "Eric Zhengyu Zhu"], "Categories": "cs.LG stat.ML"}, "abstract": "Diffusion models learn to reverse the progressive noising of a data distribution to create a generative model. However, the desired continuous nature of the noising process can be at odds with discrete data. To deal with this tension between continuous and discrete objects, we propose a method of performing diffusion on the probability simplex. Using the probability simplex naturally creates an interpretation where points correspond to categorical probability distributions. Our method uses the softmax function applied to an Ornstein-Unlenbeck Process, a well-known stochastic differential equation. We find that our methodology also naturally extends to include diffusion on the unit cube which has applications for bounded image generation.", "url": "https://arxiv.org/abs/2309.02530"}, {"metadata": {"arXiv": "2309.02555", "Date": "Tue, 05 Sep 2023 19:45:09 ", "Title": "A Survey of the Impact of Self-Supervised Pretraining for Diagnostic Tasks with Radiological Images", "Authors": ["Blake VanBerlo", "Jesse Hoey", "Alexander Wong"], "Categories": "cs.LG cs.CV", "Comments": ["32 pages", "6 figures", "a literature survey submitted to BMC Medical Imaging"]}, "abstract": "Self-supervised pretraining has been observed to be effective at improving feature representations for transfer learning, leveraging large amounts of unlabelled data. This review summarizes recent research into its usage in X-ray, computed tomography, magnetic resonance, and ultrasound imaging, concentrating on studies that compare self-supervised pretraining to fully supervised learning for diagnostic tasks such as classification and segmentation. The most pertinent finding is that self-supervised pretraining generally improves downstream task performance compared to full supervision, most prominently when unlabelled examples greatly outnumber labelled examples. Based on the aggregate evidence, recommendations are provided for practitioners considering using self-supervised learning. Motivated by limitations identified in current research, directions and practices for future study are suggested, such as integrating clinical knowledge with theoretically justified self-supervised learning methods, evaluating on public datasets, growing the modest body of evidence for ultrasound, and characterizing the impact of self-supervised pretraining on generalization.", "url": "https://arxiv.org/abs/2309.02555"}, {"metadata": {"arXiv": "2309.02557", "Date": "Tue, 05 Sep 2023 19:52:24 ", "Title": "Sparse Partitioning Around Medoids", "Authors": ["Lars Lenssen and Erich Schubert"], "Categories": "cs.LG math.OC", "DOI": "10.1515/9783110785944-005"}, "abstract": "Partitioning Around Medoids (PAM, k-Medoids) is a popular clustering technique to use with arbitrary distance functions or similarities, where each cluster is represented by its most central object, called the medoid or the discrete median. In operations research, this family of problems is also known as facility location problem (FLP). FastPAM recently introduced a speedup for large k to make it applicable for larger problems, but the method still has a runtime quadratic in N. In this chapter, we discuss a sparse and asymmetric variant of this problem, to be used for example on graph data such as road networks. By exploiting sparsity, we can avoid the quadratic runtime and memory requirements, and make this method scalable to even larger problems, as long as we are able to build a small enough graph of sufficient connectivity to perform local optimization. Furthermore, we consider asymmetric cases, where the set of medoids is not identical to the set of points to be covered (or in the interpretation of facility location, where the possible facility locations are not identical to the consumer locations). Because of sparsity, it may be impossible to cover all points with just k medoids for too small k, which would render the problem unsolvable, and this breaks common heuristics for finding a good starting condition. We, hence, consider determining k as a part of the optimization problem and propose to first construct a greedy initial solution with a larger k, then to optimize the problem by alternating between PAM-style \"swap\" operations where the result is improved by replacing medoids with better alternatives and \"remove\" operations to reduce the number of k until neither allows further improving the result quality. We demonstrate the usefulness of this method on a problem from electrical engineering, with the input graph derived from cartographic data.", "url": "https://arxiv.org/abs/2309.02557"}, {"metadata": {"arXiv": "2309.02571", "Date": "Tue, 05 Sep 2023 20:45:34 ", "Title": "Causal Structure Recovery of Linear Dynamical Systems: An FFT based Approach", "Authors": ["Mishfad Shaikh Veedu", "James Melbourne", "Murti V. Salapaka"], "Categories": "cs.LG math.DS stat.ME", "Comments": ["34 pages"]}, "abstract": "Learning causal effects from data is a fundamental and well-studied problem across science, especially when the cause-effect relationship is static in nature. However, causal effect is less explored when there are dynamical dependencies, i.e., when dependencies exist between entities across time. Identifying dynamic causal effects from time-series observations is computationally expensive when compared to the static scenario. We demonstrate that the computational complexity of recovering the causation structure for the vector auto-regressive (VAR) model is $O(Tn^3N^2)$, where $n$ is the number of nodes, $T$ is the number of samples, and $N$ is the largest time-lag in the dependency between entities. We report a method, with a reduced complexity of $O(Tn^3 \\log N)$, to recover the causation structure to obtain frequency-domain (FD) representations of time-series. Since FFT accumulates all the time dependencies on every frequency, causal inference can be performed efficiently by considering the state variables as random variables at any given frequency. We additionally show that, for systems with interactions that are LTI, do-calculus machinery can be realized in the FD resulting in versions of the classical single-door (with cycles), front and backdoor criteria. We demonstrate, for a large class of problems, graph reconstruction using multivariate Wiener projections results in a significant computational advantage with $O(n)$ complexity over reconstruction algorithms such as the PC algorithm which has $O(n^q)$ complexity, where $q$ is the maximum neighborhood size. This advantage accrues due to some remarkable properties of the phase response of the frequency-dependent Wiener coefficients which is not present in any time-domain approach.", "url": "https://arxiv.org/abs/2309.02571"}, {"metadata": {"arXiv": "2309.02591", "Date": "Tue, 05 Sep 2023 21:27:27 ", "Title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning", "Authors": ["Lili Yu", "Bowen Shi", "Ramakanth Pasunuru", "Benjamin Muller", "Olga Golovneva", "Tianlu Wang", "Arun Babu", "Binh Tang", "Brian Karrer", "Shelly Sheynin", "Candace Ross", "Adam Polyak", "Russell Howes", "Vasu Sharma", "Puxin Xu", "Hovhannes Tamoyan", "Oron Ashual", "Uriel Singer", "Shang-Wen Li", "Susan Zhang", "Richard James", "Gargi Ghosh", "Yaniv Taigman", "Maryam Fazel-Zarandi", "Asli Celikyilmaz", "Luke Zettlemoyer", "Armen Aghajanyan"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "We present CM3Leon (pronounced \"Chameleon\"), a retrieval-augmented, token-based, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pre-training stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-the-art performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID of 4.88). After SFT, CM3Leon can also demonstrate unprecedented levels of controllability in tasks ranging from language-guided image editing to image-controlled generation and segmentation.", "url": "https://arxiv.org/abs/2309.02591"}, {"metadata": {"arXiv": "2309.02604", "Date": "Tue, 05 Sep 2023 22:25:30 ", "Title": "Screening of Pneumonia and Urinary Tract Infection at Triage using TriNet", "Authors": ["Stephen Z. Lu"], "Categories": "cs.LG cs.CY", "Comments": ["Index Terms: Downstream testing", "Machine Learning", "Medical directives", "Modelling", "Modular network", "Pneumonia", "Positive predictive value", "Screening", "Triage", "Urinary tract infection"]}, "abstract": "Due to the steady rise in population demographics and longevity, emergency department visits are increasing across North America. As more patients visit the emergency department, traditional clinical workflows become overloaded and inefficient, leading to prolonged wait-times and reduced healthcare quality. One of such workflows is the triage medical directive, impeded by limited human workload, inaccurate diagnoses and invasive over-testing. To address this issue, we propose TriNet: a machine learning model for medical directives that automates first-line screening at triage for conditions requiring downstream testing for diagnosis confirmation. To verify screening potential, TriNet was trained on hospital triage data and achieved high positive predictive values in detecting pneumonia (0.86) and urinary tract infection (0.93). These models outperform current clinical benchmarks, indicating that machine-learning medical directives can offer cost-free, non-invasive screening with high specificity for common conditions, reducing the risk of over-testing while increasing emergency department efficiency.", "url": "https://arxiv.org/abs/2309.02604"}, {"metadata": {"arXiv": "2309.02606", "Date": "Tue, 05 Sep 2023 22:33:02 ", "Title": "Distributed Variational Inference for Online Supervised Learning", "Authors": ["Parth Paritosh", "Nikolay Atanasov", "Sonia Martinez"], "Categories": "cs.LG cs.RO eess.SP stat.ML"}, "abstract": "Developing efficient solutions for inference problems in intelligent sensor networks is crucial for the next generation of location, tracking, and mapping services. This paper develops a scalable distributed probabilistic inference algorithm that applies to continuous variables, intractable posteriors and large-scale real-time data in sensor networks. In a centralized setting, variational inference is a fundamental technique for performing approximate Bayesian estimation, in which an intractable posterior density is approximated with a parametric density. Our key contribution lies in the derivation of a separable lower bound on the centralized estimation objective, which enables distributed variational inference with one-hop communication in a sensor network. Our distributed evidence lower bound (DELBO) consists of a weighted sum of observation likelihood and divergence to prior densities, and its gap to the measurement evidence is due to consensus and modeling errors. To solve binary classification and regression problems while handling streaming data, we design an online distributed algorithm that maximizes DELBO, and specialize it to Gaussian variational densities with non-linear likelihoods. The resulting distributed Gaussian variational inference (DGVI) efficiently inverts a $1$-rank correction to the covariance matrix. Finally, we derive a diagonalized version for online distributed inference in high-dimensional models, and apply it to multi-robot probabilistic mapping using indoor LiDAR data.", "url": "https://arxiv.org/abs/2309.02606"}, {"metadata": {"arXiv": "2309.02610", "Date": "Tue, 05 Sep 2023 22:55:10 ", "Title": "T-SaS: Toward Shift-aware Dynamic Adaptation for Streaming Data", "Authors": ["Weijieying Ren", "Tianxiang Zhao", "Wei Qin", "Kunpeng Liu"], "Categories": "cs.LG cs.DS", "Comments": ["CIKM 2023"]}, "abstract": "In many real-world scenarios, distribution shifts exist in the streaming data across time steps. Many complex sequential data can be effectively divided into distinct regimes that exhibit persistent dynamics. Discovering the shifted behaviors and the evolving patterns underlying the streaming data are important to understand the dynamic system. Existing methods typically train one robust model to work for the evolving data of distinct distributions or sequentially adapt the model utilizing explicitly given regime boundaries. However, there are two challenges: (1) shifts in data streams could happen drastically and abruptly without precursors. Boundaries of distribution shifts are usually unavailable, and (2) training a shared model for all domains could fail to capture varying patterns. This paper aims to solve the problem of sequential data modeling in the presence of sudden distribution shifts that occur without any precursors. Specifically, we design a Bayesian framework, dubbed as T-SaS, with a discrete distribution-modeling variable to capture abrupt shifts of data. Then, we design a model that enable adaptation with dynamic network selection conditioned on that discrete variable. The proposed method learns specific model parameters for each distribution by learning which neurons should be activated in the full network. A dynamic masking strategy is adopted here to support inter-distribution transfer through the overlapping of a set of sparse networks. Extensive experiments show that our proposed method is superior in both accurately detecting shift boundaries to get segments of varying distributions and effectively adapting to downstream forecast or classification tasks.", "url": "https://arxiv.org/abs/2309.02610"}, {"metadata": {"arXiv": "2309.02615", "Date": "Tue, 05 Sep 2023 23:24:34 ", "Title": "Generative Algorithms for Fusion of Physics-Based Wildfire Spread Models with Satellite Data for Initializing Wildfire Forecasts", "Authors": ["Bryan Shaddy", "Deep Ray", "Angel Farguell", "Valentina Calaza", "Jan Mandel", "James Haley", "Kyle Hilburn", "Derek V. Mallia", "Adam Kochanski and Assad Oberai"], "Categories": "cs.LG physics.ao-ph"}, "abstract": "Increases in wildfire activity and the resulting impacts have prompted the development of high-resolution wildfire behavior models for forecasting fire spread. Recent progress in using satellites to detect fire locations further provides the opportunity to use measurements to improve fire spread forecasts from numerical models through data assimilation. This work develops a method for inferring the history of a wildfire from satellite measurements, providing the necessary information to initialize coupled atmosphere-wildfire models from a measured wildfire state in a physics-informed approach. The fire arrival time, which is the time the fire reaches a given spatial location, acts as a succinct representation of the history of a wildfire. In this work, a conditional Wasserstein Generative Adversarial Network (cWGAN), trained with WRF-SFIRE simulations, is used to infer the fire arrival time from satellite active fire data. The cWGAN is used to produce samples of likely fire arrival times from the conditional distribution of arrival times given satellite active fire detections. Samples produced by the cWGAN are further used to assess the uncertainty of predictions. The cWGAN is tested on four California wildfires occurring between 2020 and 2022, and predictions for fire extent are compared against high resolution airborne infrared measurements. Further, the predicted ignition times are compared with reported ignition times. An average Sorensen's coefficient of 0.81 for the fire perimeters and an average ignition time error of 32 minutes suggest that the method is highly accurate.", "url": "https://arxiv.org/abs/2309.02615"}, {"metadata": {"arXiv": "2309.02623", "Date": "Tue, 05 Sep 2023 23:49:46 ", "Title": "Superclustering by finding statistically significant separable groups of optimal gaussian clusters", "Authors": ["Oleg I.Berngardt"], "Categories": "cs.LG", "Comments": ["32 pages", "7 figures", "1 table"]}, "abstract": "The paper presents the algorithm for clustering a dataset by grouping the optimal, from the point of view of the BIC criterion, number of Gaussian clusters into the optimal, from the point of view of their statistical separability, superclusters. The algorithm consists of three stages: representation of the dataset as a mixture of Gaussian distributions - clusters, which number is determined based on the minimum of the BIC criterion; using the Mahalanobis distance, to estimate the distances between the clusters and cluster sizes; combining the resulting clusters into superclusters using the DBSCAN method by finding its hyperparameter (maximum distance) providing maximum value of introduced matrix quality criterion at maximum number of superclusters. The matrix quality criterion corresponds to the proportion of statistically significant separated superclusters among all found superclusters. The algorithm has only one hyperparameter - statistical significance level, and automatically detects optimal number and shape of superclusters based of statistical hypothesis testing approach. The algorithm demonstrates a good results on test datasets in noise and noiseless situations. An essential advantage of the algorithm is its ability to predict correct supercluster for new data based on already trained clusterer and perform soft (fuzzy) clustering. The disadvantages of the algorithm are: its low speed and stochastic nature of the final clustering. It requires a sufficiently large dataset for clustering, which is typical for many statistical methods.", "url": "https://arxiv.org/abs/2309.02623"}, {"metadata": {"arXiv": "2309.02640", "Date": "Wed, 06 Sep 2023 00:59:27 ", "Title": "Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation", "Authors": ["Keyu Chen", "Di Zhuang", "Mingchen Li", "J. Morris Chang"], "Categories": "cs.LG cs.CL"}, "abstract": "Neural Machine Translation (NMT) models have become successful, but their performance remains poor when translating on new domains with a limited number of data. In this paper, we present a novel approach Epi-Curriculum to address low-resource domain adaptation (DA), which contains a new episodic training framework along with denoised curriculum learning. Our episodic training framework enhances the model's robustness to domain shift by episodically exposing the encoder/decoder to an inexperienced decoder/encoder. The denoised curriculum learning filters the noised data and further improves the model's adaptability by gradually guiding the learning process from easy to more difficult tasks. Experiments on English-German and English-Romanian translation show that: (i) Epi-Curriculum improves both model's robustness and adaptability in seen and unseen domains; (ii) Our episodic training framework enhances the encoder and decoder's robustness to domain shift.", "url": "https://arxiv.org/abs/2309.02640"}, {"metadata": {"arXiv": "2309.02651", "Date": "Wed, 06 Sep 2023 01:25:30 ", "Title": "Contrastive Learning as Kernel Approximation", "Authors": ["Konstantinos Christopher Tsiolis"], "Categories": "cs.LG", "Comments": ["Master's (M.Sc.) Thesis"]}, "abstract": "In standard supervised machine learning, it is necessary to provide a label for every input in the data. While raw data in many application domains is easily obtainable on the Internet, manual labelling of this data is prohibitively expensive. To circumvent this issue, contrastive learning methods produce low-dimensional vector representations (also called features) of high-dimensional inputs on large unlabelled datasets. This is done by training with a contrastive loss function, which enforces that similar inputs have high inner product and dissimilar inputs have low inner product in the feature space. Rather than annotating each input individually, it suffices to define a means of sampling pairs of similar and dissimilar inputs. Contrastive features can then be fed as inputs to supervised learning systems on much smaller labelled datasets to obtain high accuracy on end tasks of interest. The goal of this thesis is to provide an overview of the current theoretical understanding of contrastive learning, specifically as it pertains to the minimizers of contrastive loss functions and their relationship to prior methods for learning features from unlabelled data. We highlight popular contrastive loss functions whose minimizers implicitly approximate a positive semidefinite (PSD) kernel. The latter is a well-studied object in functional analysis and learning theory that formalizes a notion of similarity between elements of a space. PSD kernels provide an implicit definition of features through the theory of reproducing kernel Hilbert spaces.", "url": "https://arxiv.org/abs/2309.02651"}, {"metadata": {"arXiv": "2309.02669", "Date": "Wed, 06 Sep 2023 02:35:46 ", "Title": "Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning", "Authors": ["Tianchi Cai", "Jiyan Jiang", "Wenpeng Zhang", "Shiji Zhou", "Xierui Song", "Li Yu", "Lihong Gu", "Xiaodong Zeng", "Jinjie Gu", "Guannan Zhang"], "Categories": "cs.LG", "Comments": ["WSDM 23", "Best Paper Candidate"]}, "abstract": "We study the budget allocation problem in online marketing campaigns that utilize previously collected offline data. We first discuss the long-term effect of optimizing marketing budget allocation decisions in the offline setting. To overcome the challenge, we propose a novel game-theoretic offline value-based reinforcement learning method using mixed policies. The proposed method reduces the need to store infinitely many policies in previous methods to only constantly many policies, which achieves nearly optimal policy efficiency, making it practical and favorable for industrial usage. We further show that this method is guaranteed to converge to the optimal policy, which cannot be achieved by previous value-based reinforcement learning methods for marketing budget allocation. Our experiments on a large-scale marketing campaign with tens-of-millions users and more than one billion budget verify the theoretical results and show that the proposed method outperforms various baseline methods. The proposed method has been successfully deployed to serve all the traffic of this marketing campaign.", "url": "https://arxiv.org/abs/2309.02669"}, {"metadata": {"arXiv": "2309.02710", "Date": "Wed, 06 Sep 2023 04:46:01 ", "Title": "Improved Outlier Robust Seeding for k-means", "Authors": ["Amit Deshpande and Rameshwar Pratap"], "Categories": "cs.LG cs.CG cs.DS"}, "abstract": "The $k$-means is a popular clustering objective, although it is inherently non-robust and sensitive to outliers. Its popular seeding or initialization called $k$-means++ uses $D^{2}$ sampling and comes with a provable $O(\\log k)$ approximation guarantee \\cite{AV2007}. However, in the presence of adversarial noise or outliers, $D^{2}$ sampling is more likely to pick centers from distant outliers instead of inlier clusters, and therefore its approximation guarantees \\textit{w.r.t.} $k$-means solution on inliers, does not hold. Assuming that the outliers constitute a constant fraction of the given data, we propose a simple variant in the $D^2$ sampling distribution, which makes it robust to the outliers. Our algorithm runs in $O(ndk)$ time, outputs $O(k)$ clusters, discards marginally more points than the optimal number of outliers, and comes with a provable $O(1)$ approximation guarantee. Our algorithm can also be modified to output exactly $k$ clusters instead of $O(k)$ clusters, while keeping its running time linear in $n$ and $d$. This is an improvement over previous results for robust $k$-means based on LP relaxation and rounding \\cite{Charikar}, \\cite{KrishnaswamyLS18} and \\textit{robust $k$-means++} \\cite{DeshpandeKP20}. Our empirical results show the advantage of our algorithm over $k$-means++~\\cite{AV2007}, uniform random seeding, greedy sampling for $k$ means~\\cite{tkmeanspp}, and robust $k$-means++~\\cite{DeshpandeKP20}, on standard real-world and synthetic data sets used in previous work. Our proposal is easily amenable to scalable, faster, parallel implementations of $k$-means++ \\cite{Bahmani,BachemL017} and is of independent interest for coreset constructions in the presence of outliers \\cite{feldman2007ptas,langberg2010universal,feldman2011unified}.", "url": "https://arxiv.org/abs/2309.02710"}, {"metadata": {"arXiv": "2309.02762", "Date": "Wed, 06 Sep 2023 06:20:12 ", "Title": "Towards Unsupervised Graph Completion Learning on Graphs with Features and Structure Missing", "Authors": ["Sichao Fu", "Qinmu Peng", "Yang He", "Baokun Du", "Xinge You"], "Categories": "cs.LG", "Comments": ["Accepted by 23rd IEEE International Conference on Data Mining (ICDM 2023)"]}, "abstract": "In recent years, graph neural networks (GNN) have achieved significant developments in a variety of graph analytical tasks. Nevertheless, GNN's superior performance will suffer from serious damage when the collected node features or structure relationships are partially missing owning to numerous unpredictable factors. Recently emerged graph completion learning (GCL) has received increasing attention, which aims to reconstruct the missing node features or structure relationships under the guidance of a specifically supervised task. Although these proposed GCL methods have made great success, they still exist the following problems: the reliance on labels, the bias of the reconstructed node features and structure relationships. Besides, the generalization ability of the existing GCL still faces a huge challenge when both collected node features and structure relationships are partially missing at the same time. To solve the above issues, we propose a more general GCL framework with the aid of self-supervised learning for improving the task performance of the existing GNN variants on graphs with features and structure missing, termed unsupervised GCL (UGCL). Specifically, to avoid the mismatch between missing node features and structure during the message-passing process of GNN, we separate the feature reconstruction and structure reconstruction and design its personalized model in turn. Then, a dual contrastive loss on the structure level and feature level is introduced to maximize the mutual information of node representations from feature reconstructing and structure reconstructing paths for providing more supervision signals. Finally, the reconstructed node features and structure can be applied to the downstream node classification task. Extensive experiments on eight datasets, three GNN variants and five missing rates demonstrate the effectiveness of our proposed method.", "url": "https://arxiv.org/abs/2309.02762"}, {"metadata": {"arXiv": "2309.02769", "Date": "Wed, 06 Sep 2023 06:22:18 ", "Title": "Unifying over-smoothing and over-squashing in graph neural networks: A physics informed approach and beyond", "Authors": ["Zhiqi Shao", "Dai Shi", "Andi Han", "Yi Guo", "Qibin Zhao", "Junbin Gao"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) have emerged as one of the leading approaches for machine learning on graph-structured data. Despite their great success, critical computational challenges such as over-smoothing, over-squashing, and limited expressive power continue to impact the performance of GNNs. In this study, inspired from the time-reversal principle commonly utilized in classical and quantum physics, we reverse the time direction of the graph heat equation. The resulted reversing process yields a class of high pass filtering functions that enhance the sharpness of graph node features. Leveraging this concept, we introduce the Multi-Scaled Heat Kernel based GNN (MHKG) by amalgamating diverse filtering functions' effects on node features. To explore more flexible filtering conditions, we further generalize MHKG into a model termed G-MHKG and thoroughly show the roles of each element in controlling over-smoothing, over-squashing and expressive power. Notably, we illustrate that all aforementioned issues can be characterized and analyzed via the properties of the filtering functions, and uncover a trade-off between over-smoothing and over-squashing: enhancing node feature sharpness will make model suffer more from over-squashing, and vice versa. Furthermore, we manipulate the time again to show how G-MHKG can handle both two issues under mild conditions. Our conclusive experiments highlight the effectiveness of proposed models. It surpasses several GNN baseline models in performance across graph datasets characterized by both homophily and heterophily.", "url": "https://arxiv.org/abs/2309.02769"}, {"metadata": {"arXiv": "2309.02771", "Date": "Wed, 06 Sep 2023 06:26:21 ", "Title": "On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization", "Authors": ["Zahra Zanjani Foumani", "Amin Yousefpour", "Mehdi Shishehbor", "Ramin Bostanabad"], "Categories": "cs.LG stat.ML"}, "abstract": "Bayesian optimization (BO) is a sequential optimization strategy that is increasingly employed in a wide range of areas including materials design. In real world applications, acquiring high-fidelity (HF) data through physical experiments or HF simulations is the major cost component of BO. To alleviate this bottleneck, multi-fidelity (MF) methods are used to forgo the sole reliance on the expensive HF data and reduce the sampling costs by querying inexpensive low-fidelity (LF) sources whose data are correlated with HF samples. However, existing multi-fidelity BO (MFBO) methods operate under the following two assumptions that rarely hold in practical applications: (1) LF sources provide data that are well correlated with the HF data on a global scale, and (2) a single random process can model the noise in the fused data. These assumptions dramatically reduce the performance of MFBO when LF sources are only locally correlated with the HF source or when the noise variance varies across the data sources. In this paper, we dispense with these incorrect assumptions by proposing an MF emulation method that (1) learns a noise model for each data source, and (2) enables MFBO to leverage highly biased LF sources which are only locally correlated with the HF source. We illustrate the performance of our method through analytical examples and engineering problems on materials design.", "url": "https://arxiv.org/abs/2309.02771"}, {"metadata": {"arXiv": "2309.02787", "Date": "Wed, 06 Sep 2023 07:04:37 ", "Title": "Dynamic Encoding and Decoding of Information for Split Learning in Mobile-Edge Computing: Leveraging Information Bottleneck Theory", "Authors": ["Omar Alhussein and Moshi Wei and Arashmid Akhavain"], "Categories": "cs.LG cs.NI", "Comments": ["Accepted to Proc. IEEE Globecom 2023"]}, "abstract": "Split learning is a privacy-preserving distributed learning paradigm in which an ML model (e.g., a neural network) is split into two parts (i.e., an encoder and a decoder). The encoder shares so-called latent representation, rather than raw data, for model training. In mobile-edge computing, network functions (such as traffic forecasting) can be trained via split learning where an encoder resides in a user equipment (UE) and a decoder resides in the edge network. Based on the data processing inequality and the information bottleneck (IB) theory, we present a new framework and training mechanism to enable a dynamic balancing of the transmission resource consumption with the informativeness of the shared latent representations, which directly impacts the predictive performance. The proposed training mechanism offers an encoder-decoder neural network architecture featuring multiple modes of complexity-relevance tradeoffs, enabling tunable performance. The adaptability can accommodate varying real-time network conditions and application requirements, potentially reducing operational expenditure and enhancing network agility. As a proof of concept, we apply the training mechanism to a millimeter-wave (mmWave)-enabled throughput prediction problem. We also offer new insights and highlight some challenges related to recurrent neural networks from the perspective of the IB theory. Interestingly, we find a compression phenomenon across the temporal domain of the sequential model, in addition to the compression phase that occurs with the number of training epochs.", "url": "https://arxiv.org/abs/2309.02787"}, {"metadata": {"arXiv": "2309.02805", "Date": "Wed, 06 Sep 2023 07:48:22 ", "Title": "Introducing Thermodynamics-Informed Symbolic Regression -- A Tool for Thermodynamic Equations of State Development", "Authors": ["Viktor Martinek and Ophelia Frotscher and Markus Richter and Roland Herzog"], "Categories": "cs.LG physics.data-an"}, "abstract": "Thermodynamic equations of state (EOS) are essential for many industries as well as in academia. Even leaving aside the expensive and extensive measurement campaigns required for the data acquisition, the development of EOS is an intensely time-consuming process, which does often still heavily rely on expert knowledge and iterative fine-tuning. To improve upon and accelerate the EOS development process, we introduce thermodynamics-informed symbolic regression (TiSR), a symbolic regression (SR) tool aimed at thermodynamic EOS modeling. TiSR is already a capable SR tool, which was used in the research of https://doi.org/10.1007/s10765-023-03197-z. It aims to combine an SR base with the extensions required to work with often strongly scattered experimental data, different residual pre- and post-processing options, and additional features required to consider thermodynamic EOS development. Although TiSR is not ready for end users yet, this paper is intended to report on its current state, showcase the progress, and discuss (distant and not so distant) future directions. TiSR is available at https://github.com/scoop-group/TiSR and can be cited as https://doi.org/10.5281/zenodo.8317547.", "url": "https://arxiv.org/abs/2309.02805"}, {"metadata": {"arXiv": "2309.02842", "Date": "Wed, 06 Sep 2023 08:59:34 ", "Title": "Random postprocessing for combinatorial Bayesian optimization", "Authors": ["Keisuke Morita", "Yoshihiko Nishikawa", "Masayuki Ohzeki"], "Categories": "cs.LG cond-mat.dis-nn math.OC stat.ML", "Comments": ["5 pages", "4 figures"]}, "abstract": "Model-based sequential approaches to discrete \"black-box\" optimization, including Bayesian optimization techniques, often access the same points multiple times for a given objective function in interest, resulting in many steps to find the global optimum. Here, we numerically study the effect of a postprocessing method on Bayesian optimization that strictly prohibits duplicated samples in the dataset. We find the postprocessing method significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation. Our results provide a simple but general strategy to solve the slow convergence of Bayesian optimization for high-dimensional problems.", "url": "https://arxiv.org/abs/2309.02842"}, {"metadata": {"arXiv": "2309.02854", "Date": "Wed, 06 Sep 2023 09:31:17 ", "Title": "A Critical Review of Common Log Data Sets Used for Evaluation of Sequence-based Anomaly Detection Techniques", "Authors": ["Max Landauer and Florian Skopik and Markus Wurzenberger"], "Categories": "cs.LG"}, "abstract": "Log data store event execution patterns that correspond to underlying workflows of systems or applications. While most logs are informative, log data also include artifacts that indicate failures or incidents. Accordingly, log data are often used to evaluate anomaly detection techniques that aim to automatically disclose unexpected or otherwise relevant system behavior patterns. Recently, detection approaches leveraging deep learning have increasingly focused on anomalies that manifest as changes of sequential patterns within otherwise normal event traces. Several publicly available data sets, such as HDFS, BGL, Thunderbird, OpenStack, and Hadoop, have since become standards for evaluating these anomaly detection techniques, however, the appropriateness of these data sets has not been closely investigated in the past. In this paper we therefore analyze six publicly available log data sets with focus on the manifestations of anomalies and simple techniques for their detection. Our findings suggest that most anomalies are not directly related to sequential manifestations and that advanced detection techniques are not required to achieve high detection rates on these data sets.", "url": "https://arxiv.org/abs/2309.02854"}, {"metadata": {"arXiv": "2309.02868", "Date": "Wed, 06 Sep 2023 09:47:03 ", "Title": "Enhancing Event Sequence Modeling with Contrastive Relational Inference", "Authors": ["Yan Wang", "Zhixuan Chu", "Tao Zhou", "Caigao Jiang", "Hongyan Hao", "Minjie Zhu", "Xindong Cai", "Qing Cui", "Longfei Li", "James Y Zhang", "Siqiao Xue", "Jun Zhou"], "Categories": "cs.LG", "Comments": ["6 pages", "2 figures"]}, "abstract": "Neural temporal point processes(TPPs) have shown promise for modeling continuous-time event sequences. However, capturing the interactions between events is challenging yet critical for performing inference tasks like forecasting on event sequence data. Existing TPP models have focused on parameterizing the conditional distribution of future events but struggle to model event interactions. In this paper, we propose a novel approach that leverages Neural Relational Inference (NRI) to learn a relation graph that infers interactions while simultaneously learning the dynamics patterns from observational data. Our approach, the Contrastive Relational Inference-based Hawkes Process (CRIHP), reasons about event interactions under a variational inference framework. It utilizes intensity-based learning to search for prototype paths to contrast relationship constraints. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model in capturing event interactions for event sequence modeling tasks.", "url": "https://arxiv.org/abs/2309.02868"}, {"metadata": {"arXiv": "2309.02869", "Date": "Wed, 06 Sep 2023 09:47:36 ", "Title": "On Reducing Undesirable Behavior in Deep Reinforcement Learning Models", "Authors": ["Ophir Carmel", "Guy Katz"], "Categories": "cs.LG"}, "abstract": "Deep reinforcement learning (DRL) has proven extremely useful in a large variety of application domains. However, even successful DRL-based software can exhibit highly undesirable behavior. This is due to DRL training being based on maximizing a reward function, which typically captures general trends but cannot precisely capture, or rule out, certain behaviors of the system. In this paper, we propose a novel framework aimed at drastically reducing the undesirable behavior of DRL-based software, while maintaining its excellent performance. In addition, our framework can assist in providing engineers with a comprehensible characterization of such undesirable behavior. Under the hood, our approach is based on extracting decision tree classifiers from erroneous state-action pairs, and then integrating these trees into the DRL training loop, penalizing the system whenever it performs an error. We provide a proof-of-concept implementation of our approach, and use it to evaluate the technique on three significant case studies. We find that our approach can extend existing frameworks in a straightforward manner, and incurs only a slight overhead in training time. Further, it incurs only a very slight hit to performance, or even in some cases - improves it, while significantly reducing the frequency of undesirable behavior.", "url": "https://arxiv.org/abs/2309.02869"}, {"metadata": {"arXiv": "2309.02873", "Date": "Wed, 06 Sep 2023 09:57:58 ", "Title": "Learning Hybrid Dynamics Models With Simulator-Informed Latent States", "Authors": ["Katharina Ensinger", "Sebastian Ziesche", "Sebastian Trimpe"], "Categories": "cs.LG"}, "abstract": "Dynamics model learning deals with the task of inferring unknown dynamics from measurement data and predicting the future behavior of the system. A typical approach to address this problem is to train recurrent models. However, predictions with these models are often not physically meaningful. Further, they suffer from deteriorated behavior over time due to accumulating errors. Often, simulators building on first principles are available being physically meaningful by design. However, modeling simplifications typically cause inaccuracies in these models. Consequently, hybrid modeling is an emerging trend that aims to combine the best of both worlds. In this paper, we propose a new approach to hybrid modeling, where we inform the latent states of a learned model via a black-box simulator. This allows to control the predictions via the simulator preventing them from accumulating errors. This is especially challenging since, in contrast to previous approaches, access to the simulator's latent states is not available. We tackle the task by leveraging observers, a well-known concept from control theory, inferring unknown latent states from observations and dynamics over time. In our learning-based setting, we jointly learn the dynamics and an observer that infers the latent states via the simulator. Thus, the simulator constantly corrects the latent states, compensating for modeling mismatch caused by learning. To maintain flexibility, we train an RNN-based residuum for the latent states that cannot be informed by the simulator.", "url": "https://arxiv.org/abs/2309.02873"}, {"metadata": {"arXiv": "2309.02898", "Date": "Wed, 06 Sep 2023 10:41:30 ", "Title": "A Unified Framework for Discovering Discrete Symmetries", "Authors": ["Pavan Karjol", "Rohan Kashyap", "Aditya Gopalan", "Prathosh A.P"], "Categories": "cs.LG cs.CV"}, "abstract": "We consider the problem of learning a function respecting a symmetry from among a class of symmetries. We develop a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear and tensor-valued functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the tensor-valued functions, respectively, and to infer the symmetry that is ultimately learnt. We also discuss the necessity of the tensor-valued functions in the architecture. Experiments on image-digit sum and polynomial regression tasks demonstrate the effectiveness of our approach.", "url": "https://arxiv.org/abs/2309.02898"}, {"metadata": {"arXiv": "2309.02911", "Date": "Wed, 06 Sep 2023 11:13:34 ", "Title": "A Multimodal Learning Framework for Comprehensive 3D Mineral Prospectivity Modeling with Jointly Learned Structure-Fluid Relationships", "Authors": ["Yang Zheng", "Hao Deng", "Ruisheng Wang", "Jingjie Wu"], "Categories": "cs.LG"}, "abstract": "This study presents a novel multimodal fusion model for three-dimensional mineral prospectivity mapping (3D MPM), effectively integrating structural and fluid information through a deep network architecture. Leveraging Convolutional Neural Networks (CNN) and Multilayer Perceptrons (MLP), the model employs canonical correlation analysis (CCA) to align and fuse multimodal features. Rigorous evaluation on the Jiaojia gold deposit dataset demonstrates the model's superior performance in distinguishing ore-bearing instances and predicting mineral prospectivity, outperforming other models in result analyses. Ablation studies further reveal the benefits of joint feature utilization and CCA incorporation. This research not only advances mineral prospectivity modeling but also highlights the pivotal role of data integration and feature alignment for enhanced exploration decision-making.", "url": "https://arxiv.org/abs/2309.02911"}, {"metadata": {"arXiv": "2309.02917", "Date": "Wed, 06 Sep 2023 11:22:21 ", "Title": "GroupEnc: encoder with group loss for global structure preservation", "Authors": ["David Novak", "Sofie Van Gassen", "Yvan Saeys"], "Categories": "cs.LG", "Comments": ["Submitted to BNAIC/BeNeLearn 2023"]}, "abstract": "Recent advances in dimensionality reduction have achieved more accurate lower-dimensional embeddings of high-dimensional data. In addition to visualisation purposes, these embeddings can be used for downstream processing, including batch effect normalisation, clustering, community detection or trajectory inference. We use the notion of structure preservation at both local and global levels to create a deep learning model, based on a variational autoencoder (VAE) and the stochastic quartet loss from the SQuadMDS algorithm. Our encoder model, called GroupEnc, uses a 'group loss' function to create embeddings with less global structure distortion than VAEs do, while keeping the model parametric and the architecture flexible. We validate our approach using publicly available biological single-cell transcriptomic datasets, employing RNX curves for evaluation.", "url": "https://arxiv.org/abs/2309.02917"}, {"metadata": {"arXiv": "2309.02968", "Date": "Wed, 06 Sep 2023 13:05:42 ", "Title": "CR-VAE: Contrastive Regularization on Variational Autoencoders for Preventing Posterior Collapse", "Authors": ["Fotios Lygerakis. Elmar Rueckert"], "Categories": "cs.LG"}, "abstract": "The Variational Autoencoder (VAE) is known to suffer from the phenomenon of \\textit{posterior collapse}, where the latent representations generated by the model become independent of the inputs. This leads to degenerated representations of the input, which is attributed to the limitations of the VAE's objective function. In this work, we propose a novel solution to this issue, the Contrastive Regularization for Variational Autoencoders (CR-VAE). The core of our approach is to augment the original VAE with a contrastive objective that maximizes the mutual information between the representations of similar visual inputs. This strategy ensures that the information flow between the input and its latent representation is maximized, effectively avoiding posterior collapse. We evaluate our method on a series of visual datasets and demonstrate, that CR-VAE outperforms state-of-the-art approaches in preventing posterior collapse.", "url": "https://arxiv.org/abs/2309.02968"}, {"metadata": {"arXiv": "2309.03004", "Date": "Wed, 06 Sep 2023 13:48:40 ", "Title": "Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness", "Authors": ["Ze Peng", "Lei Qi", "Yinghuan Shi", "Yang Gao"], "Categories": "cs.LG"}, "abstract": "A recent empirical observation of activation sparsity in MLP layers offers an opportunity to drastically reduce computation costs for free. Despite several works attributing it to training dynamics, the theoretical explanation of activation sparsity's emergence is restricted to shallow networks, small training steps well as modified training, even though the sparsity has been found in deep models trained by vanilla protocols for large steps. To fill the three gaps, we propose the notion of gradient sparsity as the source of activation sparsity and a theoretical explanation based on it that explains gradient sparsity and then activation sparsity as necessary steps to adversarial robustness w.r.t. hidden features and parameters, which is approximately the flatness of minima for well-learned models. The theory applies to standardly trained LayerNorm-ed pure MLPs, and further to Transformers or other architectures if noises are added to weights during training. To eliminate other sources of flatness when arguing sparsities' necessity, we discover the phenomenon of spectral concentration, i.e., the ratio between the largest and the smallest non-zero singular values of weight matrices is small. We utilize random matrix theory (RMT) as a powerful theoretical tool to analyze stochastic gradient noises and discuss the emergence of spectral concentration. With these insights, we propose two plug-and-play modules for both training from scratch and sparsity finetuning, as well as one radical modification that only applies to from-scratch training. Another under-testing module for both sparsity and flatness is also immediate from our theories. Validational experiments are conducted to verify our explanation. Experiments for productivity demonstrate modifications' improvement in sparsity, indicating further theoretical cost reduction in both training and inference.", "url": "https://arxiv.org/abs/2309.03004"}, {"metadata": {"arXiv": "2309.03033", "Date": "Wed, 06 Sep 2023 14:22:24 ", "Title": "Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks for Accurate and Early Detection through Gene Expression Analysis", "Authors": ["Kapil Panda", "Anirudh Mazumder"], "Categories": "cs.LG q-bio.QM", "Comments": ["6 pages", "5 figures"]}, "abstract": "With Polycystic Kidney Disease (PKD) potentially leading to fatal complications in patients due to the formation of cysts in the kidneys, early detection of PKD is crucial for effective management of the condition. However, the various patient-specific factors that play a role in the diagnosis make it an intricate puzzle for clinicians to solve. Therefore, in this study, we aim to utilize a deep learning-based approach for early disease detection. The devised neural network can achieve accurate and robust predictions for possible PKD in patients by analyzing patient gene expressions.", "url": "https://arxiv.org/abs/2309.03033"}, {"metadata": {"arXiv": "2309.03060", "Date": "Wed, 06 Sep 2023 14:59:38 ", "Title": "CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra", "Authors": ["Andres Potapczynski", "Marc Finzi", "Geoff Pleiss", "Andrew Gordon Wilson"], "Categories": "cs.LG cs.NA math.NA stat.ML", "Comments": ["Code available at https://github.com/wilson-labs/cola"]}, "abstract": "Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-in tool for virtually any computational effort that requires linear algebra. We showcase its efficacy across a broad range of applications, including partial differential equations, Gaussian processes, equivariant model construction, and unsupervised learning.", "url": "https://arxiv.org/abs/2309.03060"}, {"metadata": {"arXiv": "2309.03139", "Date": "Wed, 06 Sep 2023 16:24:26 ", "Title": "Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks", "Authors": ["Daniel Levy", "S\\'ekou-Oumar Kaba", "Carmelo Gonzales", "Santiago Miret", "Siamak Ravanbakhsh"], "Categories": "cs.LG"}, "abstract": "We present a natural extension to E(n)-equivariant graph neural networks that uses multiple equivariant vectors per node. We formulate the extension and show that it improves performance across different physical systems benchmark tasks, with minimal differences in runtime or number of parameters. The proposed multichannel EGNN outperforms the standard singlechannel EGNN on N-body charged particle dynamics, molecular property predictions, and predicting the trajectories of solar system bodies. Given the additional benefits and minimal additional cost of multi-channel EGNN, we suggest that this extension may be of practical use to researchers working in machine learning for the physical sciences", "url": "https://arxiv.org/abs/2309.03139"}, {"metadata": {"arXiv": "2309.03145", "Date": "Wed, 06 Sep 2023 16:41:41 ", "Title": "The Best Arm Evades: Near-optimal Multi-pass Streaming Lower Bounds for Pure Exploration in Multi-armed Bandits", "Authors": ["Sepehr Assadi and Chen Wang"], "Categories": "cs.LG cs.DS"}, "abstract": "We give a near-optimal sample-pass trade-off for pure exploration in multi-armed bandits (MABs) via multi-pass streaming algorithms: any streaming algorithm with sublinear memory that uses the optimal sample complexity of $O(\\frac{n}{\\Delta^2})$ requires $\\Omega(\\frac{\\log{(1/\\Delta)}}{\\log\\log{(1/\\Delta)}})$ passes. Here, $n$ is the number of arms and $\\Delta$ is the reward gap between the best and the second-best arms. Our result matches the $O(\\log(\\frac{1}{\\Delta}))$-pass algorithm of Jin et al. [ICML'21] (up to lower order terms) that only uses $O(1)$ memory and answers an open question posed by Assadi and Wang [STOC'20].", "url": "https://arxiv.org/abs/2309.03145"}, {"metadata": {"arXiv": "2309.03190", "Date": "Wed, 06 Sep 2023 17:53:31 ", "Title": "Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation", "Authors": ["Xiaochen Zhu", "Vincent Y. F. Tan", "Xiaokui Xiao"], "Categories": "cs.LG cs.CR", "Comments": ["17 pages", "accepted by ACM CCS 2023 as a conference paper"]}, "abstract": "Graph neural networks (GNNs) have gained an increasing amount of popularity due to their superior capability in learning node embeddings for various graph inference tasks, but training them can raise privacy concerns. To address this, we propose using link local differential privacy over decentralized nodes, enabling collaboration with an untrusted server to train GNNs without revealing the existence of any link. Our approach spends the privacy budget separately on links and degrees of the graph for the server to better denoise the graph topology using Bayesian estimation, alleviating the negative impact of LDP on the accuracy of the trained GNNs. We bound the mean absolute error of the inferred link probabilities against the ground truth graph topology. We then propose two variants of our LDP mechanism complementing each other in different privacy settings, one of which estimates fewer links under lower privacy budgets to avoid false positive link estimates when the uncertainty is high, while the other utilizes more information and performs better given relatively higher privacy budgets. Furthermore, we propose a hybrid variant that combines both strategies and is able to perform better across different privacy budgets. Extensive experiments show that our approach outperforms existing methods in terms of accuracy under varying privacy budgets.", "url": "https://arxiv.org/abs/2309.03190"}, {"metadata": {"arXiv": "2309.02976", "Date": "Wed, 06 Sep 2023 13:20:31 ", "Title": "Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models", "Authors": ["Pierre Schumacher", "Thomas Geijtenbeek", "Vittorio Caggiano", "Vikash Kumar", "Syn Schmitt", "Georg Martius", "Daniel F. B. Haeufle"], "Categories": "cs.RO cs.LG"}, "abstract": "Humans excel at robust bipedal walking in complex natural environments. In each step, they adequately tune the interaction of biomechanical muscle dynamics and neuronal signals to be robust against uncertainties in ground conditions. However, it is still not fully understood how the nervous system resolves the musculoskeletal redundancy to solve the multi-objective control problem considering stability, robustness, and energy efficiency. In computer simulations, energy minimization has been shown to be a successful optimization target, reproducing natural walking with trajectory optimization or reflex-based control methods. However, these methods focus on particular motions at a time and the resulting controllers are limited when compensating for perturbations. In robotics, reinforcement learning~(RL) methods recently achieved highly stable (and efficient) locomotion on quadruped systems, but the generation of human-like walking with bipedal biomechanical models has required extensive use of expert data sets. This strong reliance on demonstrations often results in brittle policies and limits the application to new behaviors, especially considering the potential variety of movements for high-dimensional musculoskeletal models in 3D. Achieving natural locomotion with RL without sacrificing its incredible robustness might pave the way for a novel approach to studying human walking in complex natural environments.", "url": "https://arxiv.org/abs/2309.02976"}, {"metadata": {"arXiv": "2309.03157", "Date": "Wed, 06 Sep 2023 16:55:11 ", "Title": "Learning to Recharge: UAV Coverage Path Planning through Deep Reinforcement Learning", "Authors": ["Mirco Theile", "Harald Bayerlein", "Marco Caccamo", "and Alberto L. Sangiovanni-Vincentelli"], "Categories": "cs.RO cs.LG", "Comments": ["under review"]}, "abstract": "Coverage path planning (CPP) is a critical problem in robotics, where the goal is to find an efficient path that covers every point in an area of interest. This work addresses the power-constrained CPP problem with recharge for battery-limited unmanned aerial vehicles (UAVs). In this problem, a notable challenge emerges from integrating recharge journeys into the overall coverage strategy, highlighting the intricate task of making strategic, long-term decisions. We propose a novel proximal policy optimization (PPO)-based deep reinforcement learning (DRL) approach with map-based observations, utilizing action masking and discount factor scheduling to optimize coverage trajectories over the entire mission horizon. We further provide the agent with a position history to handle emergent state loops caused by the recharge capability. Our approach outperforms a baseline heuristic, generalizes to different target zones and maps, with limited generalization to unseen maps. We offer valuable insights into DRL algorithm design for long-horizon problems and provide a publicly available software framework for the CPP problem.", "url": "https://arxiv.org/abs/2309.03157"}, {"metadata": {"arXiv": "2309.03177", "Date": "Wed, 06 Sep 2023 17:30:26 ", "Title": "3D Object Positioning Using Differentiable Multimodal Learning", "Authors": ["Sean Zanyk-McLean", "Krishna Kumar", "Paul Navratil"], "Categories": "eess.SY cs.CV cs.LG cs.RO cs.SY", "Comments": ["7 pages", "8 figures"]}, "abstract": "This article describes a multi-modal method using simulated Lidar data via ray tracing and image pixel loss with differentiable rendering to optimize an object's position with respect to an observer or some referential objects in a computer graphics scene. Object position optimization is completed using gradient descent with the loss function being influenced by both modalities. Typical object placement optimization is done using image pixel loss with differentiable rendering only, this work shows the use of a second modality (Lidar) leads to faster convergence. This method of fusing sensor input presents a potential usefulness for autonomous vehicles, as these methods can be used to establish the locations of multiple actors in a scene. This article also presents a method for the simulation of multiple types of data to be used in the training of autonomous vehicles.", "url": "https://arxiv.org/abs/2309.03177"}, {"metadata": {"arXiv": "2309.02603", "Date": "Tue, 05 Sep 2023 22:22:30 ", "Title": "Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models", "Authors": ["Aranyak Maity", "Ayan Banerjee and Sandeep Gupta"], "Categories": "cs.AI cs.SY eess.SY"}, "abstract": "Unknown unknowns are operational scenarios in a cyber-physical system that are not accounted for in the design and test phase. As such under unknown-unknown scenarios, the operational behavior of the CPS is not guaranteed to meet requirements such as safety and efficacy specified using Signal Temporal Logic (STL) on the output trajectories. We propose a novel framework for analyzing the stochastic conformance of operational output characteristics of safety-critical cyber-physical systems that can discover unknown-unknown scenarios and evaluate potential safety hazards. We propose dynamics-induced hybrid recurrent neural networks (DiH-RNN) to mine a physics-guided surrogate model (PGSM) which is used to check the model conformance using STL on the model coefficients. We demonstrate the detection of operational changes in an Artificial Pancreas(AP) due to unknown insulin cartridge errors.", "url": "https://arxiv.org/abs/2309.02603"}, {"metadata": {"arXiv": "2309.02662", "Date": "Wed, 06 Sep 2023 02:14:53 ", "Title": "Subsethood Measures of Spatial Granules", "Authors": ["Liquan Zhao and Yiyu Yao"], "Categories": "cs.AI cs.IT math.IT"}, "abstract": "Subsethood, which is to measure the degree of set inclusion relation, is predominant in fuzzy set theory. This paper introduces some basic concepts of spatial granules, coarse-fine relation, and operations like meet, join, quotient meet and quotient join. All the atomic granules can be hierarchized by set-inclusion relation and all the granules can be hierarchized by coarse-fine relation. Viewing an information system from the micro and the macro perspectives, we can get a micro knowledge space and a micro knowledge space, from which a rough set model and a spatial rough granule model are respectively obtained. The classical rough set model is the special case of the rough set model induced from the micro knowledge space, while the spatial rough granule model will be play a pivotal role in the problem-solving of structures. We discuss twelve axioms of monotone increasing subsethood and twelve corresponding axioms of monotone decreasing supsethood, and generalize subsethood and supsethood to conditional granularity and conditional fineness respectively. We develop five conditional granularity measures and five conditional fineness measures and prove that each conditional granularity or fineness measure satisfies its corresponding twelve axioms although its subsethood or supsethood measure only hold one of the two boundary conditions. We further define five conditional granularity entropies and five conditional fineness entropies respectively, and each entropy only satisfies part of the boundary conditions but all the ten monotone conditions.", "url": "https://arxiv.org/abs/2309.02662"}, {"metadata": {"arXiv": "2309.02815", "Date": "Wed, 06 Sep 2023 08:01:17 ", "Title": "Near-continuous time Reinforcement Learning for continuous state-action spaces", "Authors": ["Lorenzo Croissant (CEREMADE)", "Marc Abeille", "Bruno Bouchard (CEREMADE)"], "Categories": "cs.AI math.OC math.ST stat.TH"}, "abstract": "We consider the Reinforcement Learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems in which interactions occur at a high frequency, if not in continuous time, and whose state spaces are large if not inherently continuous. Perhaps the only exception is the Linear Quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency $\\varepsilon^{-1}$, which captures arbitrary time scales: from discrete ($\\varepsilon=1$) to continuous time ($\\varepsilon\\downarrow0$). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on $\\mathbb{R}^d$. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning within the eluder dimension framework and propose an approximate planning method based on a diffusive limit approximation of the jump process. Overall, our algorithm enjoys a regret of order $\\tilde{\\mathcal{O}}(\\varepsilon^{1/2} T+\\sqrt{T})$. As the frequency of interactions blows up, the approximation error $\\varepsilon^{1/2} T$ vanishes, showing that $\\tilde{\\mathcal{O}}(\\sqrt{T})$ is attainable in near-continuous time.", "url": "https://arxiv.org/abs/2309.02815"}, {"metadata": {"arXiv": "2309.02856", "Date": "Wed, 06 Sep 2023 09:34:54 ", "Title": "Getting too personal(ized): The importance of feature choice in online adaptive algorithms", "Authors": ["ZhaoBin Li", "Luna Yee", "Nathaniel Sauerberg", "Irene Sakson", "Joseph Jay Williams", "Anna N. Rafferty"], "Categories": "cs.AI cs.CY", "Comments": ["11 pages", "6 figures. Correction to the original article published at https://files.eric.ed.gov/fulltext/ED607907.pdf : The Thompson sampling algorithm in the original article overweights older data resulting in an overexploitative multi-armed bandit. This arxiv version uses a normal Thompson sampling algorithm"]}, "abstract": "Digital educational technologies offer the potential to customize students' experiences and learn what works for which students, enhancing the technology as more students interact with it. We consider whether and when attempting to discover how to personalize has a cost, such as if the adaptation to personal information can delay the adoption of policies that benefit all students. We explore these issues in the context of using multi-armed bandit (MAB) algorithms to learn a policy for what version of an educational technology to present to each student, varying the relation between student characteristics and outcomes and also whether the algorithm is aware of these characteristics. Through simulations, we demonstrate that the inclusion of student characteristics for personalization can be beneficial when those characteristics are needed to learn the optimal action. In other scenarios, this inclusion decreases performance of the bandit algorithm. Moreover, including unneeded student characteristics can systematically disadvantage students with less common values for these characteristics. Our simulations do however suggest that real-time personalization will be helpful in particular real-world scenarios, and we illustrate this through case studies using existing experimental results in ASSISTments. Overall, our simulations show that adaptive personalization in educational technologies can be a double-edged sword: real-time adaptation improves student experiences in some contexts, but the slower adaptation and potentially discriminatory results mean that a more personalized model is not always beneficial.", "url": "https://arxiv.org/abs/2309.02856"}, {"metadata": {"arXiv": "2309.03041", "Date": "Wed, 06 Sep 2023 14:34:18 ", "Title": "A Refutation of Shapley Values for Explainability", "Authors": ["Xuanxiang Huang", "Joao Marques-Silva"], "Categories": "cs.AI"}, "abstract": "Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations. Such misleading information was broadly categorized into a number of possible issues. Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability. This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability. However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features. It is plain that a brute-force approach would be unlikely to provide insights on how to tackle this question. This paper answers the above question by proving that, for any number of features, there exist Boolean functions that exhibit one or more inadequacy-revealing issues, thereby contributing decisive arguments against the use of Shapley values as the theoretical underpinning of feature-attribution methods in explainability.", "url": "https://arxiv.org/abs/2309.03041"}, {"metadata": {"arXiv": "2309.02562", "Date": "Tue, 05 Sep 2023 20:22:26 ", "Title": "Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model", "Authors": ["Shanshan Tang", "Kai Wang", "David Hein", "Gloria Lin", "Nina N. Sanford", "Jing Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Objectives: Approximately 30% of non-metastatic anal squamous cell carcinoma (ASCC) patients will experience recurrence after chemoradiotherapy (CRT), and currently available clinical variables are poor predictors of treatment response. We aimed to develop a model leveraging information extracted from radiation pretreatment planning CT to predict recurrence-free survival (RFS) in ASCC patients after CRT. Methods: Radiomics features were extracted from planning CT images of 96 ASCC patients. Following pre-feature selection, the optimal feature set was selected via step-forward feature selection with a multivariate Cox proportional hazard model. The RFS prediction was generated from a radiomics-clinical combined model based on an optimal feature set with five repeats of five-fold cross validation. The risk stratification ability of the proposed model was evaluated with Kaplan-Meier analysis. Results: Shape- and texture-based radiomics features significantly predicted RFS. Compared to a clinical-only model, radiomics-clinical combined model achieves better performance in the testing cohort with higher C-index (0.80 vs 0.73) and AUC (0.84 vs 0.79 for 1-year RFS, 0.84 vs 0.78 for 2-year RFS, and 0.86 vs 0.83 for 3-year RFS), leading to distinctive high- and low-risk of recurrence groups (p<0.001). Conclusions: A treatment planning CT based radiomics and clinical combined model had improved prognostic performance in predicting RFS for ASCC patients treated with CRT as compared to a model using clinical features only.", "url": "https://arxiv.org/abs/2309.02562"}, {"metadata": {"arXiv": "2309.02713", "Date": "Wed, 06 Sep 2023 04:52:02 ", "Title": "SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video", "Authors": ["You Rim Choi", "Gyeongseon Eo", "Wonhyuck Youn", "Hyojin Lee", "Haemin Jang", "Dongyoon Kim", "Hyunwoo Shin", "Hyung-Sin Kim"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV CVAMD 2023", "poster"]}, "abstract": "Obstructive sleep apnea (OSA) is a prevalent sleep disorder affecting approximately one billion people world-wide. The current gold standard for diagnosing OSA, Polysomnography (PSG), involves an overnight hospital stay with multiple attached sensors, leading to potential inaccuracies due to the first-night effect. To address this, we present SlAction, a non-intrusive OSA detection system for daily sleep environments using infrared videos. Recognizing that sleep videos exhibit minimal motion, this work investigates the fundamental question: \"Are respiratory events adequately reflected in human motions during sleep?\" Analyzing the largest sleep video dataset of 5,098 hours, we establish correlations between OSA events and human motions during sleep. Our approach uses a low frame rate (2.5 FPS), a large size (60 seconds) and step (30 seconds) for sliding window analysis to capture slow and long-term motions related to OSA. Furthermore, we utilize a lightweight deep neural network for resource-constrained devices, ensuring all video streams are processed locally without compromising privacy. Evaluations show that SlAction achieves an average F1 score of 87.6% in detecting OSA across various environments. Implementing SlAction on NVIDIA Jetson Nano enables real-time inference (~3 seconds for a 60-second video clip), highlighting its potential for early detection and personalized treatment of OSA.", "url": "https://arxiv.org/abs/2309.02713"}, {"metadata": {"arXiv": "2309.02742", "Date": "Wed, 06 Sep 2023 05:56:30 ", "Title": "MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization", "Authors": ["Ke Wang", "Zanting Ye", "Xiang Xie", "Haidong Cui", "Tao Chen", "Banteng Liu"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages", "9 figures", "3 tables"]}, "abstract": "Accurate segmentation of clustered microcalcifications in mammography is crucial for the diagnosis and treatment of breast cancer. Despite exhibiting expert-level accuracy, recent deep learning advancements in medical image segmentation provide insufficient contribution to practical applications, due to the domain shift resulting from differences in patient postures, individual gland density, and imaging modalities of mammography etc. In this paper, a novel framework named MLN-net, which can accurately segment multi-source images using only single source images, is proposed for clustered microcalcification segmentation. We first propose a source domain image augmentation method to generate multi-source images, leading to improved generalization. And a structure of multiple layer normalization (LN) layers is used to construct the segmentation network, which can be found efficient for clustered microcalcification segmentation in different domains. Additionally, a branch selection strategy is designed for measuring the similarity of the source domain data and the target domain data. To validate the proposed MLN-net, extensive analyses including ablation experiments are performed, comparison of 12 baseline methods. Extensive experiments validate the effectiveness of MLN-net in segmenting clustered microcalcifications from different domains and the its segmentation accuracy surpasses state-of-the-art methods. Code will be available at https://github.com/yezanting/MLN-NET-VERSON1.", "url": "https://arxiv.org/abs/2309.02742"}, {"metadata": {"arXiv": "2309.02875", "Date": "Wed, 06 Sep 2023 09:59:58 ", "Title": "MAD: Modality Agnostic Distance Measure for Image Registration", "Authors": ["Vasiliki Sideri-Lampretsa", "Veronika A. Zimmer", "Huaqi Qiu", "Georgios Kaissis", "and Daniel Rueckert"], "Categories": "cs.CV cs.AI"}, "abstract": "Multi-modal image registration is a crucial pre-processing step in many medical applications. However, it is a challenging task due to the complex intensity relationships between different imaging modalities, which can result in large discrepancy in image appearance. The success of multi-modal image registration, whether it is conventional or learning based, is predicated upon the choice of an appropriate distance (or similarity) measure. Particularly, deep learning registration algorithms lack in accuracy or even fail completely when attempting to register data from an \"unseen\" modality. In this work, we present Modality Agnostic Distance (MAD), a deep image distance}] measure that utilises random convolutions to learn the inherent geometry of the images while being robust to large appearance changes. Random convolutions are geometry-preserving modules which we use to simulate an infinite number of synthetic modalities alleviating the need for aligned paired data during training. We can therefore train MAD on a mono-modal dataset and successfully apply it to a multi-modal dataset. We demonstrate that not only can MAD affinely register multi-modal images successfully, but it has also a larger capture range than traditional measures such as Mutual Information and Normalised Gradient Fields.", "url": "https://arxiv.org/abs/2309.02875"}, {"metadata": {"arXiv": "2309.03047", "Date": "Wed, 06 Sep 2023 14:41:55 ", "Title": "Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection", "Authors": ["Gr\\'egor Jouet", "Cl\\'ement Duhart", "Francis Rousseaux", "Julio Laborde", "Cyril de Runz"], "Categories": "cs.CV cs.AI"}, "abstract": "Out-of-domain (OOD) detection is a crucial component in industrial applications as it helps identify when a model encounters inputs that are outside the training distribution. Most industrial pipelines rely on pre-trained models for downstream tasks such as CNN or Vision Transformers. This paper investigates the performance of those models on the task of out-of-domain detection. Our experiments demonstrate that pre-trained transformers models achieve higher detection performance out of the box. Furthermore, we show that pre-trained ViT and CNNs can be combined with refinement methods such as CIDER to improve their OOD detection performance even more. Our results suggest that transformers are a promising approach for OOD detection and set a stronger baseline for this task in many contexts", "url": "https://arxiv.org/abs/2309.03047"}, {"metadata": {"arXiv": "2309.03198", "Date": "Wed, 06 Sep 2023 17:59:47 ", "Title": "My Art My Choice: Adversarial Protection Against Unruly AI", "Authors": ["Anthony Rhodes", "Ram Bhagat", "Umur Aybars Ciftci", "Ilke Demir"], "Categories": "cs.CV cs.AI"}, "abstract": "Generative AI is on the rise, enabling everyone to produce realistic content via publicly available interfaces. Especially for guided image generation, diffusion models are changing the creator economy by producing high quality low cost content. In parallel, artists are rising against unruly AI, since their artwork are leveraged, distributed, and dissimulated by large generative models. Our approach, My Art My Choice (MAMC), aims to empower content owners by protecting their copyrighted materials from being utilized by diffusion models in an adversarial fashion. MAMC learns to generate adversarially perturbed \"protected\" versions of images which can in turn \"break\" diffusion models. The perturbation amount is decided by the artist to balance distortion vs. protection of the content. MAMC is designed with a simple UNet-based generator, attacking black box diffusion models, combining several losses to create adversarial twins of the original artwork. We experiment on three datasets for various image-to-image tasks, with different user control values. Both protected image and diffusion output results are evaluated in visual, noise, structure, pixel, and generative spaces to validate our claims. We believe that MAMC is a crucial step for preserving ownership information for AI generated content in a flawless, based-on-need, and human-centric way.", "url": "https://arxiv.org/abs/2309.03198"}, {"metadata": {"arXiv": "2309.02561", "Date": "Tue, 05 Sep 2023 20:21:03 ", "Title": "Physically Grounded Vision-Language Models for Robotic Manipulation", "Authors": ["Jensen Gao", "Bidipta Sarkar", "Fei Xia", "Ted Xiao", "Jiajun Wu", "Brian Ichter", "Anirudha Majumdar", "Dorsa Sadigh"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 36.9K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically-grounded VLMs. We additionally illustrate the benefits of our physically-grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at https://iliad.stanford.edu/pg-vlm/.", "url": "https://arxiv.org/abs/2309.02561"}, {"metadata": {"arXiv": "2309.03130", "Date": "Wed, 06 Sep 2023 16:10:49 ", "Title": "MyoDex: A Generalizable Prior for Dexterous Manipulation", "Authors": ["Vittorio Caggiano", "Sudeep Dasari", "Vikash Kumar"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted to the 40th International Conference on Machine Learning (2023)"]}, "abstract": "Human dexterity is a hallmark of motor control. Our hands can rapidly synthesize new behaviors despite the complexity (multi-articular and multi-joints, with 23 joints controlled by more than 40 muscles) of musculoskeletal sensory-motor circuits. In this work, we take inspiration from how human dexterity builds on a diversity of prior experiences, instead of being acquired through a single task. Motivated by this observation, we set out to develop agents that can build upon their previous experience to quickly acquire new (previously unattainable) behaviors. Specifically, our approach leverages multi-task learning to implicitly capture task-agnostic behavioral priors (MyoDex) for human-like dexterity, using a physiologically realistic human hand model - MyoHand. We demonstrate MyoDex's effectiveness in few-shot generalization as well as positive transfer to a large repertoire of unseen dexterous manipulation tasks. Agents leveraging MyoDex can solve approximately 3x more tasks, and 4x faster in comparison to a distillation baseline. While prior work has synthesized single musculoskeletal control behaviors, MyoDex is the first generalizable manipulation prior that catalyzes the learning of dexterous physiological control across a large variety of contact-rich behaviors. We also demonstrate the effectiveness of our paradigms beyond musculoskeletal control towards the acquisition of dexterity in 24 DoF Adroit Hand. Website: https://sites.google.com/view/myodex", "url": "https://arxiv.org/abs/2309.03130"}, {"metadata": {"arXiv": "2309.02534", "Date": "Tue, 05 Sep 2023 19:03:26 ", "Title": "Experience and Prediction: A Metric of Hardness for a Novel Litmus Test", "Authors": ["Nicos Isaak and Loizos Michael"], "Categories": "cs.AI cs.LG", "Comments": ["33 pages", "10 figures,"], "Journal-ref": "Journal of Logic and Computation 31(8), 2028-2056", "DOI": "10.1093/logcom/exab005"}, "abstract": "In the last decade, the Winograd Schema Challenge (WSC) has become a central aspect of the research community as a novel litmus test. Consequently, the WSC has spurred research interest because it can be seen as the means to understand human behavior. In this regard, the development of new techniques has made possible the usage of Winograd schemas in various fields, such as the design of novel forms of CAPTCHAs. Work from the literature that established a baseline for human adult performance on the WSC has shown that not all schemas are the same, meaning that they could potentially be categorized according to their perceived hardness for humans. In this regard, this \\textit{hardness-metric} could be used in future challenges or in the WSC CAPTCHA service to differentiate between Winograd schemas. Recent work of ours has shown that this could be achieved via the design of an automated system that is able to output the hardness-indexes of Winograd schemas, albeit with limitations regarding the number of schemas it could be applied on. This paper adds to previous research by presenting a new system that is based on Machine Learning (ML), able to output the hardness of any Winograd schema faster and more accurately than any other previously used method. Our developed system, which works within two different approaches, namely the random forest and deep learning (LSTM-based), is ready to be used as an extension of any other system that aims to differentiate between Winograd schemas, according to their perceived hardness for humans. At the same time, along with our developed system we extend previous work by presenting the results of a large-scale experiment that shows how human performance varies across Winograd schemas.", "url": "https://arxiv.org/abs/2309.02534"}, {"metadata": {"arXiv": "2309.03023", "Date": "Wed, 06 Sep 2023 14:08:46 ", "Title": "Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals", "Authors": ["Patryk Preisner", "Heiko Paulheim"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted for DL4KG Workshop at ISWC 2023"]}, "abstract": "Knowledge graph embeddings are dense numerical representations of entities in a knowledge graph (KG). While the majority of approaches concentrate only on relational information, i.e., relations between entities, fewer approaches exist which also take information about literal values (e.g., textual descriptions or numerical information) into account. Those which exist are typically tailored towards a particular modality of literal and a particular embedding method. In this paper, we propose a set of universal preprocessing operators which can be used to transform KGs with literals for numerical, temporal, textual, and image information, so that the transformed KGs can be embedded with any method. The results on the kgbench dataset with three different embedding methods show promising results.", "url": "https://arxiv.org/abs/2309.03023"}, {"metadata": {"arXiv": "2309.03084", "Date": "Mon, 04 Sep 2023 09:16:49 ", "Title": "Pure Monte Carlo Counterfactual Regret Minimization", "Authors": ["Ju Qi", "Ting Feng", "Falun Hei", "Zhemei Fang", "Yunfeng Luo"], "Categories": "cs.AI cs.GT cs.LG"}, "abstract": "Counterfactual Regret Minimization (CFR) and its variants are the best algorithms so far for solving large-scale incomplete information games. Building upon CFR, this paper proposes a new algorithm named Pure CFR (PCFR) for achieving better performance. PCFR can be seen as a combination of CFR and Fictitious Play (FP), inheriting the concept of counterfactual regret (value) from CFR, and using the best response strategy instead of the regret matching strategy for the next iteration. Our theoretical proof that PCFR can achieve Blackwell approachability enables PCFR's ability to combine with any CFR variant including Monte Carlo CFR (MCCFR). The resultant Pure MCCFR (PMCCFR) can significantly reduce time and space complexity. Particularly, the convergence speed of PMCCFR is at least three times more than that of MCCFR. In addition, since PMCCFR does not pass through the path of strictly dominated strategies, we developed a new warm-start algorithm inspired by the strictly dominated strategies elimination method. Consequently, the PMCCFR with new warm start algorithm can converge by two orders of magnitude faster than the CFR+ algorithm.", "url": "https://arxiv.org/abs/2309.03084"}, {"metadata": {"arXiv": "2309.03092", "Date": "Fri, 01 Sep 2023 13:44:39 ", "Title": "Establishing Markov Equivalence in Cyclic Directed Graphs", "Authors": ["Tom Claassen", "Joris M. Mooij"], "Categories": "cs.AI cs.DM cs.LG", "Comments": ["Correction to original version published at UAI-2023. Includes additional experimental results and extended proof details in supplement"], "Journal-ref": "Proc. Uncertainty in Artificial Intelligence (UAI 2023), PMLR 216:433-442"}, "abstract": "We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles under the \\textit{d}-separation criterion. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid '90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires tests for d-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders. This version includes a correction to rule (iv) in Theorem 1, and the subsequent adjustment in part 2 of Algorithm 2.", "url": "https://arxiv.org/abs/2309.03092"}, {"metadata": {"arXiv": "2309.02564", "Date": "Thu, 03 Aug 2023 10:25:17 ", "Title": "Diffusion-based Time Series Data Imputation for Microsoft 365", "Authors": ["Fangkai Yang", "Wenjie Yin", "Lu Wang", "Tianci Li", "Pu Zhao", "Bo Liu", "Paul Wang", "Bo Qiao", "Yudong Liu", "M{\\aa}rten Bj\\\"orkman", "Saravan Rajmohan", "Qingwei Lin", "Dongmei Zhang"], "Categories": "cs.DC cs.AI cs.LG"}, "abstract": "Reliability is extremely important for large-scale cloud systems like Microsoft 365. Cloud failures such as disk failure, node failure, etc. threaten service reliability, resulting in online service interruptions and economic loss. Existing works focus on predicting cloud failures and proactively taking action before failures happen. However, they suffer from poor data quality like data missing in model training and prediction, which limits the performance. In this paper, we focus on enhancing data quality through data imputation by the proposed Diffusion+, a sample-efficient diffusion model, to impute the missing data efficiently based on the observed data. Our experiments and application practice show that our model contributes to improving the performance of the downstream failure prediction task.", "url": "https://arxiv.org/abs/2309.02564"}, {"metadata": {"arXiv": "2309.02460", "Date": "Mon, 04 Sep 2023 09:01:56 ", "Title": "Effective Multi-Graph Neural Networks for Illicit Account Detection on Cryptocurrency Transaction Networks", "Authors": ["Zhihao Ding", "Jieming Shi", "Qing Li", "Jiannong Cao"], "Categories": "cs.LG cs.AI"}, "abstract": "We study illicit account detection on transaction networks of cryptocurrencies that are increasi_testngly important in online financial markets. The surge of illicit activities on cryptocurrencies has resulted in billions of losses from normal users. Existing solutions either rely on tedious feature engineering to get handcrafted features, or are inadequate to fully utilize the rich semantics of cryptocurrency transaction data, and consequently, yield sub-optimal performance. In this paper, we formulate the illicit account detection problem as a classification task over directed multigraphs with edge attributes, and present DIAM, a novel multi-graph neural network model to effectively detect illicit accounts on large transaction networks. First, DIAM includes an Edge2Seq module that automatically learns effective node representations preserving intrinsic transaction patterns of parallel edges, by considering both edge attributes and directed edge sequence dependencies. Then utilizing the multigraph topology, DIAM employs a new Multigraph Discrepancy (MGD) module with a well-designed message passing mechanism to capture the discrepant features between normal and illicit nodes, supported by an attention mechanism. Assembling all techniques, DIAM is trained in an end-to-end manner. Extensive experiments, comparing against 14 existing solutions on 4 large cryptocurrency datasets of Bitcoin and Ethereum, demonstrate that DIAM consistently achieves the best performance to accurately detect illicit accounts, while being efficient. For instance, on a Bitcoin dataset with 20 million nodes and 203 million edges, DIAM achieves F1 score 96.55%, significantly higher than the F1 score 83.92% of the best competitor.", "url": "https://arxiv.org/abs/2309.02460"}, {"metadata": {"arXiv": "2309.02473", "Date": "Tue, 05 Sep 2023 11:56:07 ", "Title": "A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges", "Authors": ["Maryam Zare", "Parham M. Kebria", "Abbas Khosravi", "Saeid Nahavandi"], "Categories": "cs.LG cs.AI cs.RO stat.ML", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations. This paper aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, the paper discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of the paper is to provide a comprehensive guide to the growing field of IL in robotics and AI.", "url": "https://arxiv.org/abs/2309.02473"}, {"metadata": {"arXiv": "2309.02478", "Date": "Tue, 05 Sep 2023 15:11:16 ", "Title": "Enhancing Semantic Communication with Deep Generative Models -- An ICASSP Special Session Overview", "Authors": ["Eleonora Grassucci", "Yuki Mitsufuji", "Ping Zhang", "Danilo Comminiello"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["Submitted to IEEE ICASSP"]}, "abstract": "Semantic communication is poised to play a pivotal role in shaping the landscape of future AI-driven communication systems. Its challenge of extracting semantic information from the original complex content and regenerating semantically consistent data at the receiver, possibly being robust to channel corruptions, can be addressed with deep generative models. This ICASSP special session overview paper discloses the semantic communication challenges from the machine learning perspective and unveils how deep generative models will significantly enhance semantic communication frameworks in dealing with real-world complex data, extracting and exploiting semantic information, and being robust to channel corruptions. Alongside establishing this emerging field, this paper charts novel research pathways for the next generative semantic communication frameworks.", "url": "https://arxiv.org/abs/2309.02478"}, {"metadata": {"arXiv": "2309.02551", "Date": "Tue, 05 Sep 2023 19:37:45 ", "Title": "Continual Improvement of Threshold-Based Novelty Detection", "Authors": ["Abe Ejilemele and Jorge Mendez-Mendez"], "Categories": "cs.LG cs.AI", "Comments": ["Presented in the workshop track at CoLLAs 2023"]}, "abstract": "When evaluated in dynamic, open-world situations, neural networks struggle to detect unseen classes. This issue complicates the deployment of continual learners in realistic environments where agents are not explicitly informed when novel categories are encountered. A common family of techniques for detecting novelty relies on thresholds of similarity between observed data points and the data used for training. However, these methods often require manually specifying (ahead of time) the value of these thresholds, and are therefore incapable of adapting to the nature of the data. We propose a new method for automatically selecting these thresholds utilizing a linear search and leave-one-out cross-validation on the ID classes. We demonstrate that this novel method for selecting thresholds results in improved total accuracy on MNIST, Fashion MNIST, and CIFAR-10.", "url": "https://arxiv.org/abs/2309.02551"}, {"metadata": {"arXiv": "2309.02580", "Date": "Tue, 05 Sep 2023 21:03:36 ", "Title": "Unveiling Intractable Epileptogenic Brain Networks with Deep Learning Algorithms: A Novel and Comprehensive Framework for Scalable Seizure Prediction with Unimodal Neuroimaging Data in Pediatric Patients", "Authors": ["Bliss Singhal", "Fnu Pooja"], "Categories": "cs.LG cs.AI eess.IV", "Comments": ["9 pages", "15 figures"]}, "abstract": "Epilepsy is a prevalent neurological disorder affecting 50 million individuals worldwide and 1.2 million Americans. There exist millions of pediatric patients with intractable epilepsy, a condition in which seizures fail to come under control. The occurrence of seizures can result in physical injury, disorientation, unconsciousness, and additional symptoms that could impede children's ability to participate in everyday tasks. Predicting seizures can help parents and healthcare providers take precautions, prevent risky situations, and mentally prepare children to minimize anxiety and nervousness associated with the uncertainty of a seizure. This research proposes a novel and comprehensive framework to predict seizures in pediatric patients by evaluating machine learning algorithms on unimodal neuroimaging data consisting of electroencephalogram signals. The bandpass filtering and independent component analysis proved to be effective in reducing the noise and artifacts from the dataset. Various machine learning algorithms' performance is evaluated on important metrics such as accuracy, precision, specificity, sensitivity, F1 score and MCC. The results show that the deep learning algorithms are more successful in predicting seizures than logistic Regression, and k nearest neighbors. The recurrent neural network (RNN) gave the highest precision and F1 Score, long short-term memory (LSTM) outperformed RNN in accuracy and convolutional neural network (CNN) resulted in the highest Specificity. This research has significant implications for healthcare providers in proactively managing seizure occurrence in pediatric patients, potentially transforming clinical practices, and improving pediatric care.", "url": "https://arxiv.org/abs/2309.02580"}, {"metadata": {"arXiv": "2309.02583", "Date": "Tue, 05 Sep 2023 21:21:06 ", "Title": "Representation Learning for Sequential Volumetric Design Tasks", "Authors": ["Md Ferdous Alam", "Yi Wang", "Linh Tran", "Chin-Yi Cheng", "Jieliang Luo"], "Categories": "cs.LG cs.AI"}, "abstract": "Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the preference model by estimating the density of the learned representations whereas we train an autoregressive transformer model for sequential design generation. We demonstrate our ideas by leveraging a novel dataset of thousands of sequential volumetric designs. Our preference model can compare two arbitrarily given design sequences and is almost 90% accurate in evaluation against random design sequences. Our autoregressive model is also capable of autocompleting a volumetric design sequence from a partial design sequence.", "url": "https://arxiv.org/abs/2309.02583"}, {"metadata": {"arXiv": "2309.02614", "Date": "Tue, 05 Sep 2023 23:19:13 ", "Title": "Utilizing Generative Adversarial Networks for Stable Structure Generation in Angry Birds", "Authors": ["Frederic Abraham", "Matthew Stephenson"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["11 pages", "10 figures", "2 tables", "Accepted at the 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 23)"]}, "abstract": "This paper investigates the suitability of using Generative Adversarial Networks (GANs) to generate stable structures for the physics-based puzzle game Angry Birds. While previous applications of GANs for level generation have been mostly limited to tile-based representations, this paper explores their suitability for creating stable structures made from multiple smaller blocks. This includes a detailed encoding/decoding process for converting between Angry Birds level descriptions and a suitable grid-based representation, as well as utilizing state-of-the-art GAN architectures and training methods to produce new structure designs. Our results show that GANs can be successfully applied to generate a varied range of complex and stable Angry Birds structures.", "url": "https://arxiv.org/abs/2309.02614"}, {"metadata": {"arXiv": "2309.02632", "Date": "Wed, 06 Sep 2023 00:44:29 ", "Title": "Deep Reinforcement Learning from Hierarchical Weak Preference Feedback", "Authors": ["Alexander Bukharin", "Yixiao Li", "Pengcheng He", "Weizhu Chen", "Tuo Zhao"], "Categories": "cs.LG cs.AI", "Comments": ["28 Pages", "15 figures"]}, "abstract": "Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; simply by ranking the importance of the reward factors. More specifically, we propose a new RL framework -- HERON, which compares trajectories using a hierarchical decision tree induced by the given ranking. These comparisons are used to train a preference-based reward model, which is then used for policy learning. We find that our framework can not only train high performing agents on a variety of difficult tasks, but also provide additional benefits such as improved sample efficiency and robustness. Our code is available at https://github.com/abukharin3/HERON.", "url": "https://arxiv.org/abs/2309.02632"}, {"metadata": {"arXiv": "2309.02641", "Date": "Wed, 06 Sep 2023 01:03:14 ", "Title": "TFBEST: Dual-Aspect Transformer with Learnable Positional Encoding for Failure Prediction", "Authors": ["Rohan Mohapatra and Saptarshi Sengupta"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "6 figures", "2 tables"], "ACM-class": "I.2.0"}, "abstract": "Hard Disk Drive (HDD) failures in datacenters are costly - from catastrophic data loss to a question of goodwill, stakeholders want to avoid it like the plague. An important tool in proactively monitoring against HDD failure is timely estimation of the Remaining Useful Life (RUL). To this end, the Self-Monitoring, Analysis and Reporting Technology employed within HDDs (S.M.A.R.T.) provide critical logs for long-term maintenance of the security and dependability of these essential data storage devices. Data-driven predictive models in the past have used these S.M.A.R.T. logs and CNN/RNN based architectures heavily. However, they have suffered significantly in providing a confidence interval around the predicted RUL values as well as in processing very long sequences of logs. In addition, some of these approaches, such as those based on LSTMs, are inherently slow to train and have tedious feature engineering overheads. To overcome these challenges, in this work we propose a novel transformer architecture - a Temporal-fusion Bi-encoder Self-attention Transformer (TFBEST) for predicting failures in hard-drives. It is an encoder-decoder based deep learning technique that enhances the context gained from understanding health statistics sequences and predicts a sequence of the number of days remaining before a disk potentially fails. In this paper, we also provide a novel confidence margin statistic that can help manufacturers replace a hard-drive within a time frame. Experiments on Seagate HDD data show that our method significantly outperforms the state-of-the-art RUL prediction methods during testing over the exhaustive 10-year data from Backblaze (2013-present). Although validated on HDD failure prediction, the TFBEST architecture is well-suited for other prognostics applications and may be adapted for allied regression problems.", "url": "https://arxiv.org/abs/2309.02641"}, {"metadata": {"arXiv": "2309.02671", "Date": "Wed, 06 Sep 2023 02:40:33 ", "Title": "RLSynC: Offline-Online Reinforcement Learning for Synthon Completion", "Authors": ["Frazier N. Baker", "Ziqi Chen", "and Xia Ning"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "8 figures", "6 tables"]}, "abstract": "Retrosynthesis is the process of determining the set of reactant molecules that can react to form a desired product. Semi-template-based retrosynthesis methods, which imitate the reverse logic of synthesis reactions, first predict the reaction centers in the products, and then complete the resulting synthons back into reactants. These methods enable necessary interpretability and high practical utility to inform synthesis planning. We develop a new offline-online reinforcement learning method RLSynC for synthon completion in semi-template-based methods. RLSynC assigns one agent to each synthon, all of which complete the synthons by conducting actions step by step in a synchronized fashion. RLSynC learns the policy from both offline training episodes and online interactions which allow RLSynC to explore new reaction spaces. RLSynC uses a forward synthesis model to evaluate the likelihood of the predicted reactants in synthesizing a product, and thus guides the action search. We compare RLSynC with the state-of-the-art retrosynthesis methods. Our experimental results demonstrate that RLSynC can outperform these methods with improvement as high as 14.9% on synthon completion, and 14.0% on retrosynthesis, highlighting its potential in synthesis planning.", "url": "https://arxiv.org/abs/2309.02671"}, {"metadata": {"arXiv": "2309.02711", "Date": "Wed, 06 Sep 2023 04:47:46 ", "Title": "Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension", "Authors": ["Miguel Abreu", "Luis Paulo Reis", "Nuno Lau"], "Categories": "cs.LG cs.AI"}, "abstract": "Symmetry, a fundamental concept to understand our environment, often oversimplifies reality from a mathematical perspective. Humans are a prime example, deviating from perfect symmetry in terms of appearance and cognitive biases (e.g. having a dominant hand). Nevertheless, our brain can easily overcome these imperfections and efficiently adapt to symmetrical tasks. The driving motivation behind this work lies in capturing this ability through reinforcement learning. To this end, we introduce Adaptive Symmetry Learning (ASL) $\\unicode{x2013}$ a model-minimization actor-critic extension that addresses incomplete or inexact symmetry descriptions by adapting itself during the learning process. ASL consists of a symmetry fitting component and a modular loss function that enforces a common symmetric relation across all states while adapting to the learned policy. The performance of ASL is compared to existing symmetry-enhanced methods in a case study involving a four-legged ant model for multidirectional locomotion tasks. The results demonstrate that ASL is capable of recovering from large perturbations and generalizing knowledge to hidden symmetric states. It achieves comparable or better performance than alternative methods in most scenarios, making it a valuable approach for leveraging model symmetry while compensating for inherent perturbations.", "url": "https://arxiv.org/abs/2309.02711"}, {"metadata": {"arXiv": "2309.02712", "Date": "Wed, 06 Sep 2023 04:50:39 ", "Title": "Unveiling the frontiers of deep learning: innovations shaping diverse domains", "Authors": ["Shams Forruque Ahmed", "Md. Sakib Bin Alam", "Maliha Kabir", "Shaila Afrin", "Sabiha Jannat Rafa", "Aanushka Mehjabin", "Amir H. Gandomi"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["64 pages", "3 figures", "3 tables"], "MSC-class": "68T07"}, "abstract": "Deep learning (DL) enables the development of computer models that are capable of learning, visualizing, optimizing, refining, and predicting data. In recent years, DL has been applied in a range of fields, including audio-visual data processing, agriculture, transportation prediction, natural language, biomedicine, disaster management, bioinformatics, drug design, genomics, face recognition, and ecology. To explore the current state of deep learning, it is necessary to investigate the latest developments and applications of deep learning in these disciplines. However, the literature is lacking in exploring the applications of deep learning in all potential sectors. This paper thus extensively investigates the potential applications of deep learning across all major fields of study as well as the associated benefits and challenges. As evidenced in the literature, DL exhibits accuracy in prediction and analysis, makes it a powerful computational tool, and has the ability to articulate itself and optimize, making it effective in processing data with no prior training. Given its independence from training data, deep learning necessitates massive amounts of data for effective analysis and processing, much like data volume. To handle the challenge of compiling huge amounts of medical, scientific, healthcare, and environmental data for use in deep learning, gated architectures like LSTMs and GRUs can be utilized. For multimodal learning, shared neurons in the neural network for all activities and specialized neurons for particular tasks are necessary.", "url": "https://arxiv.org/abs/2309.02712"}, {"metadata": {"arXiv": "2309.02752", "Date": "Wed, 06 Sep 2023 06:17:35 ", "Title": "SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series", "Authors": ["Chang George Dong", "Liangwei Nathan Zheng", "Weitong Chen", "Wei Emma Zhang", "Lin Yue"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["10 pages", "8 figures"], "ACM-class": "I.2.0"}, "abstract": "Time series classification (TSC) has emerged as a critical task in various domains, and deep neural models have shown superior performance in TSC tasks. However, these models are vulnerable to adversarial attacks, where subtle perturbations can significantly impact the prediction results. Existing adversarial methods often suffer from over-parameterization or random logit perturbation, hindering their effectiveness. Additionally, increasing the attack success rate (ASR) typically involves generating more noise, making the attack more easily detectable. To address these limitations, we propose SWAP, a novel attacking method for TSC models. SWAP focuses on enhancing the confidence of the second-ranked logits while minimizing the manipulation of other logits. This is achieved by minimizing the Kullback-Leibler divergence between the target logit distribution and the predictive logit distribution. Experimental results demonstrate that SWAP achieves state-of-the-art performance, with an ASR exceeding 50% and an 18% increase compared to existing methods.", "url": "https://arxiv.org/abs/2309.02752"}, {"metadata": {"arXiv": "2309.02784", "Date": "Wed, 06 Sep 2023 06:51:15 ", "Title": "Norm Tweaking: High-performance Low-bit Quantization of Large Language Models", "Authors": ["Liang Li", "Qingyuan Li", "Bo Zhang", "Xiangxiang Chu"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "As the size of large language models (LLMs) continues to grow, model compression without sacrificing accuracy has become a crucial challenge for deployment. While some quantization methods, such as GPTQ, have made progress in achieving acceptable 4-bit weight-only quantization, attempts at lower bit quantization often result in severe performance degradation. In this paper, we introduce a technique called norm tweaking, which can be used as a plugin in current PTQ methods to achieve high precision while being cost-efficient. Our approach is inspired by the observation that rectifying the quantized activation distribution to match its float counterpart can readily restore accuracy for LLMs. To achieve this, we carefully design a tweaking strategy that includes calibration data generation and channel-wise distance constraint to update the weights of normalization layers for better generalization. We conduct extensive experiments on various datasets using several open-sourced LLMs. Our method demonstrates significant improvements in both weight-only quantization and joint quantization of weights and activations, surpassing existing PTQ methods. On GLM-130B and OPT-66B, our method even achieves the same level of accuracy at 2-bit quantization as their float ones. Our simple and effective approach makes it more practical for real-world applications.", "url": "https://arxiv.org/abs/2309.02784"}, {"metadata": {"arXiv": "2309.02818", "Date": "Wed, 06 Sep 2023 08:06:15 ", "Title": "Combining Thermodynamics-based Model of the Centrifugal Compressors and Active Machine Learning for Enhanced Industrial Design Optimization", "Authors": ["Shadi Ghiasi", "Guido Pazzi", "Concettina Del Grosso", "Giovanni De Magistris", "Giacomo Veneri"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted after peer-review at the 1st workshop on Synergy of Scientific and Machine Learning Modeling", "SynS & ML ICML", "Honolulu", "Hawaii", "USA. July", "2023. Copyright 2023 by the author(s)"]}, "abstract": "The design process of centrifugal compressors requires applying an optimization process which is computationally expensive due to complex analytical equations underlying the compressor's dynamical equations. Although the regression surrogate models could drastically reduce the computational cost of such a process, the major challenge is the scarcity of data for training the surrogate model. Aiming to strategically exploit the labeled samples, we propose the Active-CompDesign framework in which we combine a thermodynamics-based compressor model (i.e., our internal software for compressor design) and Gaussian Process-based surrogate model within a deployable Active Learning (AL) setting. We first conduct experiments in an offline setting and further, extend it to an online AL framework where a real-time interaction with the thermodynamics-based compressor's model allows the deployment in production. ActiveCompDesign shows a significant performance improvement in surrogate modeling by leveraging on uncertainty-based query function of samples within the AL framework with respect to the random selection of data points. Moreover, our framework in production has reduced the total computational time of compressor's design optimization to around 46% faster than relying on the internal thermodynamics-based simulator, achieving the same performance.", "url": "https://arxiv.org/abs/2309.02818"}, {"metadata": {"arXiv": "2309.02820", "Date": "Wed, 06 Sep 2023 08:08:12 ", "Title": "Roulette: A Semantic Privacy-Preserving Device-Edge Collaborative Inference Framework for Deep Learning Classification Tasks", "Authors": ["Jingyi Li", "Guocheng Liao", "Lin Chen", "and Xu Chen"], "Categories": "cs.LG cs.AI cs.CR cs.DC"}, "abstract": "Deep learning classifiers are crucial in the age of artificial intelligence. The device-edge-based collaborative inference has been widely adopted as an efficient framework for promoting its applications in IoT and 5G/6G networks. However, it suffers from accuracy degradation under non-i.i.d. data distribution and privacy disclosure. For accuracy degradation, direct use of transfer learning and split learning is high cost and privacy issues remain. For privacy disclosure, cryptography-based approaches lead to a huge overhead. Other lightweight methods assume that the ground truth is non-sensitive and can be exposed. But for many applications, the ground truth is the user's crucial privacy-sensitive information. In this paper, we propose a framework of Roulette, which is a task-oriented semantic privacy-preserving collaborative inference framework for deep learning classifiers. More than input data, we treat the ground truth of the data as private information. We develop a novel paradigm of split learning where the back-end DNN is frozen and the front-end DNN is retrained to be both a feature extractor and an encryptor. Moreover, we provide a differential privacy guarantee and analyze the hardness of ground truth inference attacks. To validate the proposed Roulette, we conduct extensive performance evaluations using realistic datasets, which demonstrate that Roulette can effectively defend against various attacks and meanwhile achieve good model accuracy. In a situation where the non-i.i.d. is very severe, Roulette improves the inference accuracy by 21\\% averaged over benchmarks, while making the accuracy of discrimination attacks almost equivalent to random guessing.", "url": "https://arxiv.org/abs/2309.02820"}, {"metadata": {"arXiv": "2309.02870", "Date": "Wed, 06 Sep 2023 09:49:20 ", "Title": "Rethinking Momentum Knowledge Distillation in Online Continual Learning", "Authors": ["Nicolas Michel", "Maorong Wang", "Ling Xiao", "Toshihiko Yamasaki"], "Categories": "cs.LG cs.AI", "Comments": ["Under Review"]}, "abstract": "Online Continual Learning (OCL) addresses the problem of training neural networks on a continuous data stream where multiple classification tasks emerge in sequence. In contrast to offline Continual Learning, data can be seen only once in OCL. In this context, replay-based strategies have achieved impressive results and most state-of-the-art approaches are heavily depending on them. While Knowledge Distillation (KD) has been extensively used in offline Continual Learning, it remains under-exploited in OCL, despite its potential. In this paper, we theoretically analyze the challenges in applying KD to OCL. We introduce a direct yet effective methodology for applying Momentum Knowledge Distillation (MKD) to many flagship OCL methods and demonstrate its capabilities to enhance existing approaches. In addition to improving existing state-of-the-arts accuracy by more than $10\\%$ points on ImageNet100, we shed light on MKD internal mechanics and impacts during training in OCL. We argue that similar to replay, MKD should be considered a central component of OCL.", "url": "https://arxiv.org/abs/2309.02870"}, {"metadata": {"arXiv": "2309.02908", "Date": "Wed, 06 Sep 2023 11:02:53 ", "Title": "DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings", "Authors": ["Aditya Mishra", "Haroon R. Lone", "Aayush Mishra"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "6 figures", "6 tables"]}, "abstract": "Energy prediction in buildings plays a crucial role in effective energy management. Precise predictions are essential for achieving optimal energy consumption and distribution within the grid. This paper introduces a Long Short-Term Memory (LSTM) model designed to forecast building energy consumption using historical energy data, occupancy patterns, and weather conditions. The LSTM model provides accurate short, medium, and long-term energy predictions for residential and commercial buildings compared to existing prediction models. We compare our LSTM model with established prediction methods, including linear regression, decision trees, and random forest. Encouragingly, the proposed LSTM model emerges as the superior performer across all metrics. It demonstrates exceptional prediction accuracy, boasting the highest R2 score of 0.97 and the most favorable mean absolute error (MAE) of 0.007. An additional advantage of our developed model is its capacity to achieve efficient energy consumption forecasts even when trained on a limited dataset. We address concerns about overfitting (variance) and underfitting (bias) through rigorous training and evaluation on real-world data. In summary, our research contributes to energy prediction by offering a robust LSTM model that outperforms alternative methods and operates with remarkable efficiency, generalizability, and reliability.", "url": "https://arxiv.org/abs/2309.02908"}, {"metadata": {"arXiv": "2309.02935", "Date": "Wed, 06 Sep 2023 11:55:16 ", "Title": "Estimating irregular water demands with physics-informed machine learning to inform leakage detection", "Authors": ["Ivo Daniel and Andrea Cominola"], "Categories": "cs.LG cs.AI", "Comments": ["submitted to Water Research on July 17th", "2023"]}, "abstract": "Leakages in drinking water distribution networks pose significant challenges to water utilities, leading to infrastructure failure, operational disruptions, environmental hazards, property damage, and economic losses. The timely identification and accurate localisation of such leakages is paramount for utilities to mitigate these unwanted effects. However, implementation of algorithms for leakage detection is limited in practice by requirements of either hydraulic models or large amounts of training data. Physics-informed machine learning can utilise hydraulic information thereby circumventing both limitations. In this work, we present a physics-informed machine learning algorithm that analyses pressure data and therefrom estimates unknown irregular water demands via a fully connected neural network, ultimately leveraging the Bernoulli equation and effectively linearising the leakage detection problem. Our algorithm is tested on data from the L-Town benchmark network, and results indicate a good capability for estimating most irregular demands, with R2 larger than 0.8. Identification results for leakages under the presence of irregular demands could be improved by a factor of 5.3 for abrupt leaks and a factor of 3.0 for incipient leaks when compared the results disregarding irregular demands.", "url": "https://arxiv.org/abs/2309.02935"}, {"metadata": {"arXiv": "2309.03113", "Date": "Wed, 06 Sep 2023 15:52:55 ", "Title": "Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features", "Authors": ["Jubilee Prasad-Rao", "Roohollah Heidary and Jesse Williams"], "Categories": "cs.LG cs.AI cs.CV cs.RO"}, "abstract": "Automated detection of defects in Printed Circuit Board (PCB) manufacturing using Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI) machines can help improve operational efficiency and significantly reduce the need for manual intervention. In this paper, using SPI-extracted features of 6 million pins, we demonstrate a data-centric approach to train Machine Learning (ML) models to detect PCB defects at three stages of PCB manufacturing. The 6 million PCB pins correspond to 2 million components that belong to 15,387 PCBs. Using a base extreme gradient boosting (XGBoost) ML model, we iterate on the data pre-processing step to improve detection performance. Combining pin-level SPI features using component and PCB IDs, we developed training instances also at the component and PCB level. This allows the ML model to capture any inter-pin, inter-component, or spatial effects that may not be apparent at the pin level. Models are trained at the pin, component, and PCB levels, and the detection results from the different models are combined to identify defective components.", "url": "https://arxiv.org/abs/2309.03113"}, {"metadata": {"arXiv": "2309.03167", "Date": "Wed, 06 Sep 2023 17:08:57 ", "Title": "Split-Boost Neural Networks", "Authors": ["Raffaele Giuseppe Cestari", "Gabriele Maroni", "Loris Cannelli", "Dario Piga", "Simone Formentin"], "Categories": "cs.LG cs.AI"}, "abstract": "The calibration and training of a neural network is a complex and time-consuming procedure that requires significant computational resources to achieve satisfactory results. Key obstacles are a large number of hyperparameters to select and the onset of overfitting in the face of a small amount of data. In this framework, we propose an innovative training strategy for feed-forward architectures - called split-boost - that improves performance and automatically includes a regularizing behaviour without modeling it explicitly. Such a novel approach ultimately allows us to avoid explicitly modeling the regularization term, decreasing the total number of hyperparameters and speeding up the tuning phase. The proposed strategy is tested on a real-world (anonymized) dataset within a benchmark medical insurance design problem.", "url": "https://arxiv.org/abs/2309.03167"}, {"metadata": {"arXiv": "2309.02547", "Date": "Tue, 05 Sep 2023 19:35:44 ", "Title": "Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning", "Authors": ["Manav Kulshrestha and Ahmed H. Qureshi"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Accepted to Conference on Robot Learning (CoRL) 2023"]}, "abstract": "Robotic manipulation tasks, such as object rearrangement, play a crucial role in enabling robots to interact with complex and arbitrary environments. Existing work focuses primarily on single-level rearrangement planning and, even if multiple levels exist, dependency relations among substructures are geometrically simpler, like tower stacking. We propose Structural Concept Learning (SCL), a deep learning approach that leverages graph attention networks to perform multi-level object rearrangement planning for scenes with structural dependency hierarchies. It is trained on a self-generated simulation data set with intuitive structures, works for unseen scenes with an arbitrary number of objects and higher complexity of structures, infers independent substructures to allow for task parallelization over multiple manipulators, and generalizes to the real world. We compare our method with a range of classical and model-based baselines to show that our method leverages its scene understanding to achieve better performance, flexibility, and efficiency. The dataset, supplementary details, videos, and code implementation are available at: https://manavkulshrestha.github.io/scl", "url": "https://arxiv.org/abs/2309.02547"}, {"metadata": {"arXiv": "2309.02685", "Date": "Wed, 06 Sep 2023 03:42:20 ", "Title": "Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation", "Authors": ["Hyunwoo Ryu", "Jiwoo Kim", "Junwoo Chang", "Hyun Seok Ahn", "Joohwan Seo", "Taehan Kim", "Jongeun Choi", "Roberto Horowitz"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["27 pages", "4 figures"]}, "abstract": "Recent studies have verified that equivariant methods can significantly improve the data efficiency, generalizability, and robustness in robot learning. Meanwhile, denoising diffusion-based generative modeling has recently gained significant attention as a promising approach for robotic manipulation learning from demonstrations with stochastic behaviors. In this paper, we present Diffusion-EDFs, a novel approach that incorporates spatial roto-translation equivariance, i.e., SE(3)-equivariance to diffusion generative modeling. By integrating SE(3)-equivariance into our model architectures, we demonstrate that our proposed method exhibits remarkable data efficiency, requiring only 5 to 10 task demonstrations for effective end-to-end training. Furthermore, our approach showcases superior generalizability compared to previous diffusion-based manipulation methods.", "url": "https://arxiv.org/abs/2309.02685"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

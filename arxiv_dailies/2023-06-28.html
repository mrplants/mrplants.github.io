<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2306.15008", "Date": "Mon, 26 Jun 2023 18:46:47 ", "Title": "Spectral Analysis of Marine Debris in Simulated and Observed Sentinel-2/MSI Images using Unsupervised Classification", "Authors": ["Bianca Matos de Barros", "Douglas Galimberti Barbosa and Cristiano Lima Hackmann"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Manuscript submitted to Ocean and Coastal Research journal"]}, "abstract": "Marine litter poses significant threats to marine and coastal environments, with its impacts ever-growing. Remote sensing provides an advantageous supplement to traditional mitigation techniques, such as local cleaning operations and trawl net surveys, due to its capabilities for extensive coverage and frequent observation. In this study, we used Radiative Transfer Model (RTM) simulated data and data from the Multispectral Instrument (MSI) of the Sentinel-2 mission in combination with machine learning algorithms. Our aim was to study the spectral behavior of marine plastic pollution and evaluate the applicability of RTMs within this research area. The results from the exploratory analysis and unsupervised classification using the KMeans algorithm indicate that the spectral behavior of pollutants is influenced by factors such as the type of polymer and pixel coverage percentage. The findings also reveal spectral characteristics and trends of association and differentiation among elements. The applied methodology is strongly dependent on the data, and if reapplied in new, more diverse, and detailed datasets, it can potentially generate even better results. These insights can guide future research in remote sensing applications for detecting marine plastic pollution.", "url": "https://arxiv.org/abs/2306.15008"}, {"metadata": {"arXiv": "2306.15548", "Date": "Tue, 27 Jun 2023 15:18:52 ", "Title": "Geometric Ultrasound Localization Microscopy", "Authors": ["Christopher Hahne and Raphael Sznitman"], "Categories": "cs.CV cs.LG", "Comments": ["Pre-print accepted for MICCAI 2023"]}, "abstract": "Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method for non-invasive, dynamic visualization in medical diagnostics, yet Ultrasound Localization Microscopy (ULM) has enabled a revolutionary breakthrough by offering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformers are used to render ULM frames, ultimately determining the image resolution capability. To take full advantage of ULM, this study questions whether beamforming is the most effective processing step for ULM, suggesting an alternative approach that relies solely on Time-Difference-of-Arrival (TDoA) information. To this end, a novel geometric framework for micro bubble localization via ellipse intersections is proposed to overcome existing beamforming limitations. We present a benchmark comparison based on a public dataset for which our geometric ULM outperforms existing baseline methods in terms of accuracy and reliability while only utilizing a portion of the available transducer data.", "url": "https://arxiv.org/abs/2306.15548"}, {"metadata": {"arXiv": "2306.15574", "Date": "Tue, 27 Jun 2023 15:53:20 ", "Title": "See Through the Fog: Curriculum Learning with Progressive Occlusion in Medical Imaging", "Authors": ["Pradeep Singh", "Kishore Babu Nampalle", "Uppala Vivek Narayan", "Balasubramanian Raman"], "Categories": "cs.CV cs.LG", "Comments": ["20 pages", "3 figures", "1 table"], "MSC-class": "68T05, 68T10, 92C55", "ACM-class": "I.5.1"}, "abstract": "In recent years, deep learning models have revolutionized medical image interpretation, offering substantial improvements in diagnostic accuracy. However, these models often struggle with challenging images where critical features are partially or fully occluded, which is a common scenario in clinical practice. In this paper, we propose a novel curriculum learning-based approach to train deep learning models to handle occluded medical images effectively. Our method progressively introduces occlusion, starting from clear, unobstructed images and gradually moving to images with increasing occlusion levels. This ordered learning process, akin to human learning, allows the model to first grasp simple, discernable patterns and subsequently build upon this knowledge to understand more complicated, occluded scenarios. Furthermore, we present three novel occlusion synthesis methods, namely Wasserstein Curriculum Learning (WCL), Information Adaptive Learning (IAL), and Geodesic Curriculum Learning (GCL). Our extensive experiments on diverse medical image datasets demonstrate substantial improvements in model robustness and diagnostic accuracy over conventional training methodologies.", "url": "https://arxiv.org/abs/2306.15574"}, {"metadata": {"arXiv": "2306.14920", "Date": "Fri, 23 Jun 2023 05:02:16 ", "Title": "A Cosine Similarity-based Method for Out-of-Distribution Detection", "Authors": ["Nguyen Ngoc-Hieu", "Nguyen Hung-Quang", "The-Anh Ta", "Thanh Nguyen-Tang", "Khoa D Doan", "Hoang Thanh-Tung"], "Categories": "cs.LG", "Comments": ["Accepted paper at ICML 2023 Workshop on Spurious Correlations", "Invariance", "and Stability. 10 pages (4 main + appendix)"]}, "abstract": "The ability to detect OOD data is a crucial aspect of practical machine learning applications. In this work, we show that cosine similarity between the test feature and the typical ID feature is a good indicator of OOD data. We propose Class Typical Matching (CTM), a post hoc OOD detection algorithm that uses a cosine similarity scoring function. Extensive experiments on multiple benchmarks show that CTM outperforms existing post hoc OOD detection methods.", "url": "https://arxiv.org/abs/2306.14920"}, {"metadata": {"arXiv": "2306.14975", "Date": "Mon, 26 Jun 2023 18:01:47 ", "Title": "The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets", "Authors": ["Noam Levi and Yaron Oz"], "Categories": "cs.LG cond-mat.dis-nn hep-th math.PR", "Comments": ["16 pages", "7 figures"]}, "abstract": "We study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure. We focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. Our main observations are: (i) The power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated random data compared to real-world data, (ii) this scaling behavior can be completely recovered by introducing long range correlations in a simple way to the synthetic data, (iii) both generated and real-world datasets lie in the same universality class from the RMT perspective, as chaotic rather than integrable systems, (iv) the expected RMT statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conventionally used for real-world training, and can be related to the number of samples required to approximate the population power-law scaling behavior, (v) the Shannon entropy is correlated with local RMT structure and eigenvalues scaling, and substantially smaller in strongly correlated datasets compared to uncorrelated synthetic data, and requires fewer samples to reach the distribution entropy. These findings can have numerous implications to the characterization of the complexity of data sets, including differentiating synthetically generated from natural data, quantifying noise, developing better data pruning methods and classifying effective learning models utilizing these scaling laws.", "url": "https://arxiv.org/abs/2306.14975"}, {"metadata": {"arXiv": "2306.14978", "Date": "Mon, 26 Jun 2023 18:03:56 ", "Title": "Fairness Aware Counterfactuals for Subgroups", "Authors": ["Loukas Kavouras", "Konstantinos Tsopelas", "Giorgos Giannopoulos", "Dimitris Sacharidis", "Eleni Psaroudaki", "Nikolaos Theologitis", "Dimitrios Rontogiannis", "Dimitris Fotakis", "Ioannis Emiris"], "Categories": "cs.LG cs.CY"}, "abstract": "In this work, we present Fairness Aware Counterfactuals for Subgroups (FACTS), a framework for auditing subgroup fairness through counterfactual explanations. We start with revisiting (and generalizing) existing notions and introducing new, more refined notions of subgroup fairness. We aim to (a) formulate different aspects of the difficulty of individuals in certain subgroups to achieve recourse, i.e. receive the desired outcome, either at the micro level, considering members of the subgroup individually, or at the macro level, considering the subgroup as a whole, and (b) introduce notions of subgroup fairness that are robust, if not totally oblivious, to the cost of achieving recourse. We accompany these notions with an efficient, model-agnostic, highly parameterizable, and explainable framework for evaluating subgroup fairness. We demonstrate the advantages, the wide applicability, and the efficiency of our approach through a thorough experimental evaluation of different benchmark datasets.", "url": "https://arxiv.org/abs/2306.14978"}, {"metadata": {"arXiv": "2306.14979", "Date": "Mon, 26 Jun 2023 18:05:03 ", "Title": "LM4HPC: Towards Effective Language Model Application in High-Performance Computing", "Authors": ["Le Chen and Pei-Hung Lin and Tristan Vanderbruggen and Chunhua Liao and Murali Emani and Bronis de Supinski"], "Categories": "cs.LG cs.DC"}, "abstract": "In recent years, language models (LMs), such as GPT-4, have been widely used in multiple domains, including natural language processing, visualization, and so on. However, applying them for analyzing and optimizing high-performance computing (HPC) software is still challenging due to the lack of HPC-specific support. In this paper, we design the LM4HPC framework to facilitate the research and development of HPC software analyses and optimizations using LMs. Tailored for supporting HPC datasets, AI models, and pipelines, our framework is built on top of a range of components from different levels of the machine learning software stack, with Hugging Face-compatible APIs. Using three representative tasks, we evaluated the prototype of our framework. The results show that LM4HPC can help users quickly evaluate a set of state-of-the-art models and generate insightful leaderboards.", "url": "https://arxiv.org/abs/2306.14979"}, {"metadata": {"arXiv": "2306.15015", "Date": "Mon, 26 Jun 2023 18:55:54 ", "Title": "Scaling and Resizing Symmetry in Feedforward Networks", "Authors": ["Carlos Cardona"], "Categories": "cs.LG cond-mat.dis-nn", "Comments": ["20 pages", "16 figures. Author's first paper on this topic. Comments and corrections are very welcome"]}, "abstract": "Weights initialization in deep neural networks have a strong impact on the speed of converge of the learning map. Recent studies have shown that in the case of random initializations, a chaos/order phase transition occur in the space of variances of random weights and biases. Experiments then had shown that large improvements can be made, in terms of the training speed, if a neural network is initialized on values along the critical line of such phase transition. In this contribution, we show evidence that the scaling property exhibited by physical systems at criticality, is also present in untrained feedforward networks with random weights initialization at the critical line. Additionally, we suggest an additional data-resizing symmetry, which is directly inherited from the scaling symmetry at criticality.", "url": "https://arxiv.org/abs/2306.15015"}, {"metadata": {"arXiv": "2306.15056", "Date": "Mon, 26 Jun 2023 20:40:29 ", "Title": "Optimal Differentially Private Learning with Public Data", "Authors": ["Andrew Lowy", "Zeman Li", "Tianjian Huang", "Meisam Razaviyayn"], "Categories": "cs.LG cs.CR math.OC stat.ML"}, "abstract": "Differential Privacy (DP) ensures that training a machine learning model does not leak private data. However, the cost of DP is lower model accuracy or higher sample complexity. In practice, we may have access to auxiliary public data that is free of privacy concerns. This has motivated the recent study of what role public data might play in improving the accuracy of DP models. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? What algorithms are optimal? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of DP. To answer the first question, we prove tight (up to constant factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical risk minimization, and stochastic convex optimization. We prove that public data reduces the sample complexity of DP model training. Perhaps surprisingly, we show that the optimal error rates can be attained (up to constants) by either discarding private data and training a public model, or treating public data like it's private data and using an optimal DP algorithm. To address the second question, we develop novel algorithms which are \"even more optimal\" (i.e. better constants) than the asymptotically optimal approaches described above. For local DP mean estimation with public data, our algorithm is optimal including constants. Empirically, our algorithms show benefits over existing approaches for DP model training with side access to public data.", "url": "https://arxiv.org/abs/2306.15056"}, {"metadata": {"arXiv": "2306.15058", "Date": "Mon, 26 Jun 2023 20:41:36 ", "Title": "BatchGFN: Generative Flow Networks for Batch Active Learning", "Authors": ["Shreshth A. Malik", "Salem Lahlou", "Andrew Jesson", "Moksh Jain", "Nikolay Malkin", "Tristan Deleu", "Yoshua Bengio", "Yarin Gal"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted at the Structured Probabilistic Inference & Generative Modeling workshop", "ICML 2023"]}, "abstract": "We introduce BatchGFN -- a novel approach for pool-based active learning that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for active learning in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.", "url": "https://arxiv.org/abs/2306.15058"}, {"metadata": {"arXiv": "2306.15083", "Date": "Mon, 26 Jun 2023 21:55:24 ", "Title": "Balanced Filtering via Non-Disclosive Proxies", "Authors": ["Siqi Deng", "Emily Diana", "Michael Kearns", "Aaron Roth"], "Categories": "cs.LG"}, "abstract": "We study the problem of non-disclosively collecting a sample of data that is balanced with respect to sensitive groups when group membership is unavailable or prohibited from use at collection time. Specifically, our collection mechanism does not reveal significantly more about group membership of any individual sample than can be ascertained from base rates alone. To do this, we adopt a fairness pipeline perspective, in which a learner can use a small set of labeled data to train a proxy function that can later be used for this filtering task. We then associate the range of the proxy function with sampling probabilities; given a new candidate, we classify it using our proxy function, and then select it for our sample with probability proportional to the sampling probability corresponding to its proxy classification. Importantly, we require that the proxy classification itself not reveal significant information about the sensitive group membership of any individual sample (i.e., it should be sufficiently non-disclosive). We show that under modest algorithmic assumptions, we find such a proxy in a sample- and oracle-efficient manner. Finally, we experimentally evaluate our algorithm and analyze generalization properties.", "url": "https://arxiv.org/abs/2306.15083"}, {"metadata": {"arXiv": "2306.15089", "Date": "Mon, 26 Jun 2023 22:09:51 ", "Title": "Energy Modelling and Forecasting for an Underground Agricultural Farm using a Higher Order Dynamic Mode Decomposition Approach", "Authors": ["Zack Xuereb Conti", "Rebecca Ward", "Ruchi Choudhary"], "Categories": "cs.LG"}, "abstract": "This paper presents an approach based on higher order dynamic mode decomposition (HODMD) to model, analyse, and forecast energy behaviour in an urban agriculture farm situated in a retrofitted London underground tunnel, where observed measurements are influenced by noisy and occasionally transient conditions. HODMD is a data-driven reduced order modelling method typically used to analyse and predict highly noisy and complex flows in fluid dynamics or any type of complex data from dynamical systems. HODMD is a recent extension of the classical dynamic mode decomposition method (DMD), customised to handle scenarios where the spectral complexity underlying the measurement data is higher than its spatial complexity, such as is the environmental behaviour of the farm. HODMD decomposes temporal data as a linear expansion of physically-meaningful DMD-modes in a semi-automatic approach, using a time-delay embedded approach. We apply HODMD to three seasonal scenarios using real data measured by sensors located at at the cross-sectional centre of the the underground farm. Through the study we revealed three physically-interpretable mode pairs that govern the environmental behaviour at the centre of the farm, consistently across environmental scenarios. Subsequently, we demonstrate how we can reconstruct the fundamental structure of the observed time-series using only these modes, and forecast for three days ahead, as one, compact and interpretable reduced-order model. We find HODMD to serve as a robust, semi-automatic modelling alternative for predictive modelling in Digital Twins.", "url": "https://arxiv.org/abs/2306.15089"}, {"metadata": {"arXiv": "2306.15138", "Date": "Tue, 27 Jun 2023 01:38:52 ", "Title": "A Restarted Large-Scale Spectral Clustering with Self-Guiding and Block Diagonal Representation", "Authors": ["Yongyan Guo and Gang Wu"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["36 pages"]}, "abstract": "Spectral clustering is one of the most popular unsupervised machine learning methods. Constructing similarity matrix is crucial to this type of method. In most existing works, the similarity matrix is computed once for all or is updated alternatively. However, the former is difficult to reflect comprehensive relationships among data points, and the latter is time-consuming and is even infeasible for large-scale problems. In this work, we propose a restarted clustering framework with self-guiding and block diagonal representation. An advantage of the strategy is that some useful clustering information obtained from previous cycles could be preserved as much as possible. To the best of our knowledge, this is the first work that applies restarting strategy to spectral clustering. The key difference is that we reclassify the samples in each cycle of our method, while they are classified only once in existing methods. To further release the overhead, we introduce a block diagonal representation with Nystr\\\"{o}m approximation for constructing the similarity matrix. Theoretical results are established to show the rationality of inexact computations in spectral clustering. Comprehensive experiments are performed on some benchmark databases, which show the superiority of our proposed algorithms over many state-of-the-art algorithms for large-scale problems. Specifically, our framework has a potential boost for clustering algorithms and works well even using an initial guess chosen randomly.", "url": "https://arxiv.org/abs/2306.15138"}, {"metadata": {"arXiv": "2306.15155", "Date": "Tue, 27 Jun 2023 02:24:05 ", "Title": "Input-sensitive dense-sparse primitive compositions for GNN acceleration", "Authors": ["Damitha Lenadora", "Vimarsh Sathia", "Gerasimos Gerogiannis", "Serif Yesil", "Josep Torrellas", "Charith Mendis"], "Categories": "cs.LG cs.PF"}, "abstract": "Graph neural networks (GNN) have become an important class of neural network models that have gained popularity in domains such as social and financial network analysis. Different phases of GNN computations can be modeled using both dense and sparse matrix operations. There have been many frameworks and optimization techniques proposed in the literature to accelerate GNNs. However, getting consistently high performance across many input graphs with different sparsity patterns and GNN embedding sizes has remained difficult. In this paper, we propose different algebraic reassociations of GNN computations that lead to novel dense and sparse matrix primitive selections and compositions. We show that the profitability of these compositions depends on the input graph, embedding size, and the target hardware. We developed SENSEi, a system that uses a data-driven adaptive strategy to select the best composition given the input graph and GNN embedding sizes. Our evaluations on a wide range of graphs and embedding sizes show that SENSEi achieves geomean speedups of $1.105\\times$ (up to $2.959\\times$) and $1.187\\times$ (up to $1.99\\times$) on graph convolutional networks and geomean speedups of $2.307\\times$ (up to $35.866\\times$) and $1.44\\times$ (up to $5.69\\times$) on graph attention networks on CPUs and GPUs respectively over the widely used Deep Graph Library. Further, we show that the compositions yield notable synergistic performance benefits on top of other established sparse optimizations such as sparse matrix tiling by evaluating against a well-tuned baseline.", "url": "https://arxiv.org/abs/2306.15155"}, {"metadata": {"arXiv": "2306.15157", "Date": "Tue, 27 Jun 2023 02:26:07 ", "Title": "Revisiting Tropical Polynomial Division: Theory, Algorithms and Application to Neural Networks", "Authors": ["Ioannis Kordonis", "Petros Maragos"], "Categories": "cs.LG math.OC"}, "abstract": "Tropical geometry has recently found several applications in the analysis of neural networks with piecewise linear activation functions. This paper presents a new look at the problem of tropical polynomial division and its application to the simplification of neural networks. We analyze tropical polynomials with real coefficients, extending earlier ideas and methods developed for polynomials with integer coefficients. We first prove the existence of a unique quotient-remainder pair and characterize the quotient in terms of the convex bi-conjugate of a related function. Interestingly, the quotient of tropical polynomials with integer coefficients does not necessarily have integer coefficients. Furthermore, we develop a relationship of tropical polynomial division with the computation of the convex hull of unions of convex polyhedra and use it to derive an exact algorithm for tropical polynomial division. An approximate algorithm is also presented, based on an alternation between data partition and linear programming. We also develop special techniques to divide composite polynomials, described as sums or maxima of simpler ones. Finally, we present some numerical results to illustrate the efficiency of the algorithms proposed, using the MNIST handwritten digit and CIFAR-10 datasets.", "url": "https://arxiv.org/abs/2306.15157"}, {"metadata": {"arXiv": "2306.15166", "Date": "Tue, 27 Jun 2023 02:47:59 ", "Title": "Learning from Invalid Data: On Constraint Satisfaction in Generative Models", "Authors": ["Giorgio Giannone", "Lyle Regenwetter", "Akash Srivastava", "Dan Gutfreund", "Faez Ahmed"], "Categories": "cs.LG cs.CE"}, "abstract": "Generative models have demonstrated impressive results in vision, language, and speech. However, even with massive datasets, they struggle with precision, generating physically invalid or factually incorrect data. This is particularly problematic when the generated data must satisfy constraints, for example, to meet product specifications in engineering design or to adhere to the laws of physics in a natural scene. To improve precision while preserving diversity and fidelity, we propose a novel training mechanism that leverages datasets of constraint-violating data points, which we consider invalid. Our approach minimizes the divergence between the generative distribution and the valid prior while maximizing the divergence with the invalid distribution. We demonstrate how generative models like GANs and DDPMs that we augment to train with invalid data vastly outperform their standard counterparts which solely train on valid data points. For example, our training procedure generates up to 98 % fewer invalid samples on 2D densities, improves connectivity and stability four-fold on a stacking block problem, and improves constraint satisfaction by 15 % on a structural topology optimization benchmark in engineering design. We also analyze how the quality of the invalid data affects the learning procedure and the generalization properties of models. Finally, we demonstrate significant improvements in sample efficiency, showing that a tenfold increase in valid samples leads to a negligible difference in constraint satisfaction, while less than 10 % invalid samples lead to a tenfold improvement. Our proposed mechanism offers a promising solution for improving precision in generative models while preserving diversity and fidelity, particularly in domains where constraint satisfaction is critical and data is limited, such as engineering design, robotics, and medicine.", "url": "https://arxiv.org/abs/2306.15166"}, {"metadata": {"arXiv": "2306.15169", "Date": "Tue, 27 Jun 2023 03:01:43 ", "Title": "Exploiting Inferential Structure in Neural Processes", "Authors": ["Dharmesh Tailor", "Mohammad Emtiyaz Khan", "Eric Nalisnick"], "Categories": "cs.LG stat.ML", "Comments": ["Uncertainty in Artificial Intelligence (UAI) 2023"]}, "abstract": "Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs' latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness.", "url": "https://arxiv.org/abs/2306.15169"}, {"metadata": {"arXiv": "2306.15194", "Date": "Tue, 27 Jun 2023 04:28:52 ", "Title": "Chronic pain detection from resting-state raw EEG signals using improved feature selection", "Authors": ["Jean Li", "Dirk De Ridder", "Divya Adhia", "Matthew Hall", "Jeremiah D. Deng"], "Categories": "cs.LG", "Comments": ["9 pages", "4 figures", "journal submission"]}, "abstract": "We present an automatic approach that works on resting-state raw EEG data for chronic pain detection. A new feature selection algorithm - modified Sequential Floating Forward Selection (mSFFS) - is proposed. The improved feature selection scheme is rather compact but displays better class separability as indicated by the Bhattacharyya distance measures and better visualization results. It also outperforms selections generated by other benchmark methods, boosting the test accuracy to 97.5% and yielding a test accuracy of 81.4% on an external dataset that contains different types of chronic pain", "url": "https://arxiv.org/abs/2306.15194"}, {"metadata": {"arXiv": "2306.15221", "Date": "Tue, 27 Jun 2023 05:46:18 ", "Title": "[Re] Double Sampling Randomized Smoothing", "Authors": ["Aryan Gupta", "Sarthak Gupta", "Abhay Kumar", "Harsh Dugar"], "Categories": "cs.LG cs.CR math.ST stat.TH"}, "abstract": "This paper is a contribution to the reproducibility challenge in the field of machine learning, specifically addressing the issue of certifying the robustness of neural networks (NNs) against adversarial perturbations. The proposed Double Sampling Randomized Smoothing (DSRS) framework overcomes the limitations of existing methods by using an additional smoothing distribution to improve the robustness certification. The paper provides a clear manifestation of DSRS for a generalized family of Gaussian smoothing and a computationally efficient method for implementation. The experiments on MNIST and CIFAR-10 demonstrate the effectiveness of DSRS, consistently certifying larger robust radii compared to other methods. Also various ablations studies are conducted to further analyze the hyperparameters and effect of adversarial training methods on the certified radius by the proposed framework.", "url": "https://arxiv.org/abs/2306.15221"}, {"metadata": {"arXiv": "2306.15324", "Date": "Tue, 27 Jun 2023 09:28:29 ", "Title": "Anomaly Detection in Networks via Score-Based Generative Models", "Authors": ["Dmitrii Gavrilev", "Evgeny Burnaev"], "Categories": "cs.LG", "Comments": ["16 pages", "8 figures", "ICML workshop on Structured Probabilistic Inference & Generative Modeling"]}, "abstract": "Node outlier detection in attributed graphs is a challenging problem for which there is no method that would work well across different datasets. Motivated by the state-of-the-art results of score-based models in graph generative modeling, we propose to incorporate them into the aforementioned problem. Our method achieves competitive results on small-scale graphs. We provide an empirical analysis of the Dirichlet energy, and show that generative models might struggle to accurately reconstruct it.", "url": "https://arxiv.org/abs/2306.15324"}, {"metadata": {"arXiv": "2306.15368", "Date": "Tue, 27 Jun 2023 10:33:37 ", "Title": "Mean Field Theory in Deep Metric Learning", "Authors": ["Takuya Furusawa"], "Categories": "cs.LG cond-mat.stat-mech", "Comments": ["15 pages"]}, "abstract": "In this paper, we explore the application of mean field theory, a technique from statistical physics, to deep metric learning and address the high training complexity commonly associated with conventional metric learning loss functions. By adapting mean field theory for deep metric learning, we develop an approach to design classification-based loss functions from pair-based ones, which can be considered complementary to the proxy-based approach. Applying the mean field theory to two pair-based loss functions, we derive two new loss functions, MeanFieldContrastive and MeanFieldClassWiseMultiSimilarity losses, with reduced training complexity. We extensively evaluate these derived loss functions on three image-retrieval datasets and demonstrate that our loss functions outperform baseline methods in two out of the three datasets.", "url": "https://arxiv.org/abs/2306.15368"}, {"metadata": {"arXiv": "2306.15400", "Date": "Tue, 27 Jun 2023 11:53:25 ", "Title": "Length Generalization in Arithmetic Transformers", "Authors": ["Samy Jelassi", "St\\'ephane d'Ascoli", "Carles Domingo-Enrich", "Yuhuai Wu", "Yuanzhi Li", "Fran\\c{c}ois Charton"], "Categories": "cs.LG"}, "abstract": "We examine how transformers cope with two challenges: learning basic integer arithmetic, and generalizing to longer sequences than seen during training. We find that relative position embeddings enable length generalization for simple tasks, such as addition: models trained on $5$-digit numbers can perform $15$-digit sums. However, this method fails for multiplication, and we propose train set priming: adding a few ($10$ to $50$) long sequences to the training set. We show that priming allows models trained on $5$-digit $\\times$ $3$-digit multiplications to generalize to $35\\times 3$ examples. We also show that models can be primed for different generalization lengths, and that the priming sample size scales as the logarithm of the training set size. Finally, we discuss potential applications of priming beyond arithmetic.", "url": "https://arxiv.org/abs/2306.15400"}, {"metadata": {"arXiv": "2306.15427", "Date": "Tue, 27 Jun 2023 12:38:11 ", "Title": "Adversarial Training for Graph Neural Networks", "Authors": ["Lukas Gosch and Simon Geisler and Daniel Sturm and Bertrand Charpentier and Daniel Z\\\"ugner and Stephan G\\\"unnemann"], "Categories": "cs.LG"}, "abstract": "Despite its success in the image domain, adversarial training does not (yet) stand out as an effective defense for Graph Neural Networks (GNNs) against graph structure perturbations. In the pursuit of fixing adversarial training (1) we show and overcome fundamental theoretical as well as practical limitations of the adopted graph learning setting in prior work; (2) we reveal that more flexible GNNs based on learnable graph diffusion are able to adjust to adversarial perturbations, while the learned message passing scheme is naturally interpretable; (3) we introduce the first attack for structure perturbations that, while targeting multiple nodes at once, is capable of handling global (graph-level) as well as local (node-level) constraints. Including these contributions, we demonstrate that adversarial training is a state-of-the-art defense against adversarial structure perturbations.", "url": "https://arxiv.org/abs/2306.15427"}, {"metadata": {"arXiv": "2306.15437", "Date": "Tue, 27 Jun 2023 12:53:14 ", "Title": "On-device modeling of user's social context and familiar places from smartphone-embedded sensor data", "Authors": ["Mattia Giovanni Campana", "Franca Delmastro"], "Categories": "cs.LG", "Journal-ref": "Expert Systems with Applications, Volume 181, 2021, 115124", "DOI": "10.1016/j.eswa.2021.115124"}, "abstract": "Context modeling and recognition are crucial for adaptive mobile and ubiquitous computing. Context-awareness in mobile environments relies on prompt reactions to context changes. However, current solutions focus on limited context information processed on centralized architectures, risking privacy leakage and lacking personalization. On-device context modeling and recognition are emerging research trends, addressing these concerns. Social interactions and visited locations play significant roles in characterizing daily life scenarios. This paper proposes an unsupervised and lightweight approach to model the user's social context and locations directly on the mobile device. Leveraging the ego-network model, the system extracts high-level, semantic-rich context features from smartphone-embedded sensor data. For the social context, the approach utilizes data on physical and cyber social interactions among users and their devices. Regarding location, it prioritizes modeling the familiarity degree of specific locations over raw location data, such as GPS coordinates and proximity devices. The effectiveness of the proposed approach is demonstrated through three sets of experiments, employing five real-world datasets. These experiments evaluate the structure of social and location ego networks, provide a semantic evaluation of the proposed models, and assess mobile computing performance. Finally, the relevance of the extracted features is showcased by the improved performance of three machine learning models in recognizing daily-life situations. Compared to using only features related to physical context, the proposed approach achieves a 3% improvement in AUROC, 9% in Precision, and 5% in Recall.", "url": "https://arxiv.org/abs/2306.15437"}, {"metadata": {"arXiv": "2306.15479", "Date": "Tue, 27 Jun 2023 13:57:16 ", "Title": "Causal Inference via Predictive Coding", "Authors": ["Tommaso Salvatori", "Luca Pinchetti", "Amine M'Charrak", "Beren Millidge", "Thomas Lukasiewicz"], "Categories": "cs.LG", "Comments": ["44 Pages", "24 Figures"]}, "abstract": "Bayesian and causal inference are fundamental processes for intelligence. Bayesian inference models observations: what can be inferred about y if we observe a related variable x? Causal inference models interventions: if we directly change x, how will y change? Predictive coding is a neuroscience-inspired method for performing Bayesian inference on continuous state variables using local information only. In this work, we go beyond Bayesian inference, and show how a simple change in the inference process of predictive coding enables interventional and counterfactual inference in scenarios where the causal graph is known. We then extend our results, and show how predictive coding can be generalized to cases where this graph is unknown, and has to be inferred from data, hence performing causal discovery. What results is a novel and straightforward technique that allows us to perform end-to-end causal inference on predictive-coding-based structural causal models, and demonstrate its utility for potential applications in machine learning.", "url": "https://arxiv.org/abs/2306.15479"}, {"metadata": {"arXiv": "2306.15551", "Date": "Tue, 27 Jun 2023 15:23:42 ", "Title": "CrunchGPT: A chatGPT assisted framework for scientific machine learning", "Authors": ["Varun Kumar", "Leonard Gleyzer", "Adar Kahana", "Khemraj Shukla", "George Em Karniadakis"], "Categories": "cs.LG cs.CL physics.soc-ph", "Comments": ["20 pages", "26 figures"]}, "abstract": "Scientific Machine Learning (SciML) has advanced recently across many different areas in computational science and engineering. The objective is to integrate data and physics seamlessly without the need of employing elaborate and computationally taxing data assimilation schemes. However, preprocessing, problem formulation, code generation, postprocessing and analysis are still time consuming and may prevent SciML from wide applicability in industrial applications and in digital twin frameworks. Here, we integrate the various stages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which plays the role of a conductor orchestrating the entire workflow of SciML based on simple prompts by the user. Specifically, we present two examples that demonstrate the potential use of CrunchGPT in optimizing airfoils in aerodynamics, and in obtaining flow fields in various geometries in interactive mode, with emphasis on the validation stage. To demonstrate the flow of the CrunchGPT, and create an infrastructure that can facilitate a broader vision, we built a webapp based guided user interface, that includes options for a comprehensive summary report. The overall objective is to extend CrunchGPT to handle diverse problems in computational mechanics, design, optimization and controls, and general scientific computing tasks involved in SciML, hence using it as a research assistant tool but also as an educational tool. While here the examples focus in fluid mechanics, future versions will target solid mechanics and materials science, geophysics, systems biology and bioinformatics.", "url": "https://arxiv.org/abs/2306.15551"}, {"metadata": {"arXiv": "2306.15557", "Date": "Tue, 27 Jun 2023 15:35:22 ", "Title": "Simple Steps to Success: Axiomatics of Distance-Based Algorithmic Recourse", "Authors": ["Jenny Hamer", "Jake Valladares", "Vignesh Viswanathan", "Yair Zick"], "Categories": "cs.LG"}, "abstract": "We propose a novel data-driven framework for algorithmic recourse that offers users interventions to change their predicted outcome. Existing approaches to compute recourse find a set of points that satisfy some desiderata -- e.g. an intervention in the underlying causal graph, or minimizing a cost function. Satisfying these criteria, however, requires extensive knowledge of the underlying model structure, often an unrealistic amount of information in several domains. We propose a data-driven, computationally efficient approach to computing algorithmic recourse. We do so by suggesting directions in the data manifold that users can take to change their predicted outcome. We present Stepwise Explainable Paths (StEP), an axiomatically justified framework to compute direction-based algorithmic recourse. We offer a thorough empirical and theoretical investigation of StEP. StEP offers provable privacy and robustness guarantees, and outperforms the state-of-the-art on several established recourse desiderata.", "url": "https://arxiv.org/abs/2306.15557"}, {"metadata": {"arXiv": "2306.15567", "Date": "Tue, 27 Jun 2023 15:46:22 ", "Title": "A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics", "Authors": ["T\\^ania Carvalho", "Nuno Moniz and Lu\\'is Antunes"], "Categories": "cs.LG", "Comments": ["12", "6 figures and 2 tables"]}, "abstract": "As the frontier of machine learning applications moves further into human interaction, multiple concerns arise regarding automated decision-making. Two of the most critical issues are fairness and data privacy. On the one hand, one must guarantee that automated decisions are not biased against certain groups, especially those unprotected or marginalized. On the other hand, one must ensure that the use of personal information fully abides by privacy regulations and that user identities are kept safe. The balance between privacy, fairness, and predictive performance is complex. However, despite their potential societal impact, we still demonstrate a poor understanding of the dynamics between these optimization vectors. In this paper, we study this three-way tension and how the optimization of each vector impacts others, aiming to inform the future development of safe applications. In light of claims that predictive performance and fairness can be jointly optimized, we find this is only possible at the expense of data privacy. Overall, experimental results show that one of the vectors will be penalized regardless of which of the three we optimize. Nonetheless, we find promising avenues for future work in joint optimization solutions, where smaller trade-offs are observed between the three vectors.", "url": "https://arxiv.org/abs/2306.15567"}, {"metadata": {"arXiv": "2306.15591", "Date": "Tue, 27 Jun 2023 16:15:15 ", "Title": "Learning to Sail Dynamic Networks: The MARLIN Reinforcement Learning Framework for Congestion Control in Tactical Environments", "Authors": ["Raffaele Galliera", "Mattia Zaccarini", "Alessandro Morelli", "Roberto Fronteddu", "Filippo Poltronieri", "Niranjan Suri", "Mauro Tortonesi"], "Categories": "cs.LG cs.NI cs.SE", "Comments": ["6 pages", "4 figures", "IEEE conference"]}, "abstract": "Conventional Congestion Control (CC) algorithms,such as TCP Cubic, struggle in tactical environments as they misinterpret packet loss and fluctuating network performance as congestion symptoms. Recent efforts, including our own MARLIN, have explored the use of Reinforcement Learning (RL) for CC, but they often fall short of generalization, particularly in competitive, unstable, and unforeseen scenarios. To address these challenges, this paper proposes an RL framework that leverages an accurate and parallelizable emulation environment to reenact the conditions of a tactical network. We also introduce refined RL formulation and performance evaluation methods tailored for agents operating in such intricate scenarios. We evaluate our RL learning framework by training a MARLIN agent in conditions replicating a bottleneck link transition between a Satellite Communication (SATCOM) and an UHF Wide Band (UHF) radio link. Finally, we compared its performance in file transfer tasks against Transmission Control Protocol (TCP) Cubic and the default strategy implemented in the Mockets tactical communication middleware. The results demonstrate that the MARLIN RL agent outperforms both TCP and Mockets under different perspectives and highlight the effectiveness of specialized RL solutions in optimizing CC for tactical network environments.", "url": "https://arxiv.org/abs/2306.15591"}, {"metadata": {"arXiv": "2306.15619", "Date": "Tue, 27 Jun 2023 16:59:06 ", "Title": "DCID: Deep Canonical Information Decomposition", "Authors": ["Alexander Rakowski and Christoph Lippert"], "Categories": "cs.LG"}, "abstract": "We consider the problem of identifying the signal shared between two one-dimensional target variables, in the presence of additional multivariate observations. Canonical Correlation Analysis (CCA)-based methods have traditionally been used to identify shared variables, however, they were designed for multivariate targets and only offer trivial solutions for univariate cases. In the context of Multi-Task Learning (MTL), various models were postulated to learn features that are sparse and shared across multiple tasks. However, these methods were typically evaluated by their predictive performance. To the best of our knowledge, no prior studies systematically evaluated models in terms of correctly recovering the shared signal. Here, we formalize the setting of univariate shared information retrieval, and propose ICM, an evaluation metric which can be used in the presence of ground-truth labels, quantifying 3 aspects of the learned shared features. We further propose Deep Canonical Information Decomposition (DCID) - a simple, yet effective approach for learning the shared variables. We benchmark the models on a range of scenarios on synthetic data with known ground-truths and observe DCID outperforming the baselines in a wide range of settings. Finally, we demonstrate a real-life application of DCID on brain Magnetic Resonance Imaging (MRI) data, where we are able to extract more accurate predictors of changes in brain regions and obesity. The code for our experiments as well as the supplementary materials are available at https://github.com/alexrakowski/dcid", "url": "https://arxiv.org/abs/2306.15619"}, {"metadata": {"arXiv": "2306.15636", "Date": "Tue, 27 Jun 2023 17:26:23 ", "Title": "On the Usefulness of Synthetic Tabular Data Generation", "Authors": ["Dionysis Manousakas and Serg\\\"ul Ayd\\\"ore"], "Categories": "cs.LG", "Comments": ["Data-centric Machine Learning Research (DMLR) Workshop at the 40th International Conference on Machine Learning (ICML)"]}, "abstract": "Despite recent advances in synthetic data generation, the scientific community still lacks a unified consensus on its usefulness. It is commonly believed that synthetic data can be used for both data exchange and boosting machine learning (ML) training. Privacy-preserving synthetic data generation can accelerate data exchange for downstream tasks, but there is not enough evidence to show how or why synthetic data can boost ML training. In this study, we benchmarked ML performance using synthetic tabular data for four use cases: data sharing, data augmentation, class balancing, and data summarization. We observed marginal improvements for the balancing use case on some datasets. However, we conclude that there is not enough evidence to claim that synthetic tabular data is useful for ML training.", "url": "https://arxiv.org/abs/2306.15636"}, {"metadata": {"arXiv": "2306.15649", "Date": "Tue, 27 Jun 2023 17:43:18 ", "Title": "Effective resistance in metric spaces", "Authors": ["Robi Bhattacharjee", "Alexander Cloninger", "Yoav Freund", "Andreas Oslandsbotn"], "Categories": "cs.LG"}, "abstract": "Effective resistance (ER) is an attractive way to interrogate the structure of graphs. It is an alternative to computing the eigenvectors of the graph Laplacian. One attractive application of ER is to point clouds, i.e. graphs whose vertices correspond to IID samples from a distribution over a metric space. Unfortunately, it was shown that the ER between any two points converges to a trivial quantity that holds no information about the graph's structure as the size of the sample increases to infinity. In this study, we show that this trivial solution can be circumvented by considering a region-based ER between pairs of small regions rather than pairs of points and by scaling the edge weights appropriately with respect to the underlying density in each region. By keeping the regions fixed, we show analytically that the region-based ER converges to a non-trivial limit as the number of points increases to infinity. Namely the ER on a metric space. We support our theoretical findings with numerical experiments.", "url": "https://arxiv.org/abs/2306.15649"}, {"metadata": {"arXiv": "2306.15651", "Date": "Tue, 27 Jun 2023 17:47:12 ", "Title": "Dental CLAIRES: Contrastive LAnguage Image REtrieval Search for Dental Research", "Authors": ["Tanjida Kabir", "Luyao Chen", "Muhammad F Walji", "Luca Giancardo", "Xiaoqian Jiang", "Shayan Shams"], "Categories": "cs.LG", "Comments": ["10 pages", "7 figures", "4 tables"], "Journal-ref": "AMIA 2023 Informatics Summit"}, "abstract": "Learning about diagnostic features and related clinical information from dental radiographs is important for dental research. However, the lack of expert-annotated data and convenient search tools poses challenges. Our primary objective is to design a search tool that uses a user's query for oral-related research. The proposed framework, Contrastive LAnguage Image REtrieval Search for dental research, Dental CLAIRES, utilizes periapical radiographs and associated clinical details such as periodontal diagnosis, demographic information to retrieve the best-matched images based on the text query. We applied a contrastive representation learning method to find images described by the user's text by maximizing the similarity score of positive pairs (true pairs) and minimizing the score of negative pairs (random pairs). Our model achieved a hit@3 ratio of 96% and a Mean Reciprocal Rank (MRR) of 0.82. We also designed a graphical user interface that allows researchers to verify the model's performance with interactions.", "url": "https://arxiv.org/abs/2306.15651"}, {"metadata": {"arXiv": "2306.15620", "Date": "Tue, 27 Jun 2023 16:59:15 ", "Title": "SCENEREPLICA: Benchmarking Real-World Robot Manipulation by Creating Reproducible Scenes", "Authors": ["Ninad Khargonkar", "Sai Haneesh Allu", "Yangxiao Lu", "Jishnu Jaykumar P", "Balakrishnan Prabhakaran", "Yu Xiang"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["12 pages", "10 figures", "Project page is available at https://irvlutd.github.io/SceneReplica"]}, "abstract": "We present a new reproducible benchmark for evaluating robot manipulation in the real world, specifically focusing on pick-and-place. Our benchmark uses the YCB objects, a commonly used dataset in the robotics community, to ensure that our results are comparable to other studies. Additionally, the benchmark is designed to be easily reproducible in the real world, making it accessible to researchers and practitioners. We also provide our experimental results and analyzes for model-based and model-free 6D robotic grasping on the benchmark, where representative algorithms are evaluated for object perception, grasping planning, and motion planning. We believe that our benchmark will be a valuable tool for advancing the field of robot manipulation. By providing a standardized evaluation framework, researchers can more easily compare different techniques and algorithms, leading to faster progress in developing robot manipulation methods.", "url": "https://arxiv.org/abs/2306.15620"}, {"metadata": {"arXiv": "2306.15340", "Date": "Tue, 27 Jun 2023 09:50:47 ", "Title": "A Toolbox for Fast Interval Arithmetic in numpy with an Application to Formal Verification of Neural Network Controlled Systems", "Authors": ["Akash Harapanahalli", "Saber Jafarpour", "Samuel Coogan"], "Categories": "eess.SY cs.LG cs.SY math.OC"}, "abstract": "In this paper, we present a toolbox for interval analysis in numpy, with an application to formal verification of neural network controlled systems. Using the notion of natural inclusion functions, we systematically construct interval bounds for a general class of mappings. The toolbox offers efficient computation of natural inclusion functions using compiled C code, as well as a familiar interface in numpy with its canonical features, such as n-dimensional arrays, matrix/vector operations, and vectorization. We then use this toolbox in formal verification of dynamical systems with neural network controllers, through the composition of their inclusion functions.", "url": "https://arxiv.org/abs/2306.15340"}, {"metadata": {"arXiv": "2306.14915", "Date": "Tue, 20 Jun 2023 05:26:44 ", "Title": "GPT-4 Reticular Chemist for MOF Discovery", "Authors": ["Zhiling Zheng", "Zichao Rong", "Nakul Rampal", "Christian Borgs", "Jennifer T. Chayes", "Omar M. Yaghi"], "Categories": "cs.AI cond-mat.mtrl-sci physics.chem-ph", "Comments": ["163 pages (an 8-page manuscript and 155 pages of supporting information)"]}, "abstract": "We present a new framework integrating the AI model GPT-4 into the iterative process of reticular chemistry experimentation, leveraging a cooperative workflow of interaction between AI and a human apprentice. This GPT-4 Reticular Chemist is an integrated system composed of three phases. Each of these utilizes GPT-4 in various capacities, wherein GPT-4 provides detailed instructions for chemical experimentation and the apprentice provides feedback on the experimental outcomes, including both success and failures, for the in-text learning of AI in the next iteration. This iterative human-AI interaction enabled GPT-4 to learn from the outcomes, much like an experienced chemist, by a prompt-learning strategy. Importantly, the system is based on natural language for both development and operation, eliminating the need for coding skills, and thus, make it accessible to all chemists. Our GPT-4 Reticular Chemist demonstrated the discovery of an isoreticular series of metal-organic frameworks (MOFs), each of which was made using distinct synthesis strategies and optimal conditions. This workflow presents a potential for broader applications in scientific research by harnessing the capability of large language models like GPT-4 to enhance the feasibility and efficiency of research activities.", "url": "https://arxiv.org/abs/2306.14915"}, {"metadata": {"arXiv": "2306.15035", "Date": "Mon, 26 Jun 2023 19:49:44 ", "Title": "Optimized Vectorizing of Building Structures with Swap: High-Efficiency Convolutional Channel-Swap Hybridization Strategy", "Authors": ["Moule Lin", "Weipeng Jing", "Chao Li and Andr\\'as Jung"], "Categories": "cs.AI cs.CV", "Comments": ["13 pages"]}, "abstract": "The building planar graph reconstruction, a.k.a. footprint reconstruction, which lies in the domain of computer vision and geoinformatics, has been long afflicted with the challenge of redundant parameters in conventional convolutional models. Therefore, in this paper, we proposed an advanced and adaptive shift architecture, namely the Swap operation, which incorporates non-exponential growth parameters while retaining analogous functionalities to integrate local feature spatial information, resembling a high-dimensional convolution operator. The Swap, cross-channel operation, architecture implements the XOR operation to alternately exchange adjacent or diagonal features, and then blends alternating channels through a 1x1 convolution operation to consolidate information from different channels. The SwapNN architecture, on the other hand, incorporates a group-based parameter-sharing mechanism inspired by the convolutional neural network process and thereby significantly reducing the number of parameters. We validated our proposed approach through experiments on the SpaceNet corpus, a publicly available dataset annotated with 2,001 buildings across the cities of Los Angeles, Las Vegas, and Paris. Our results demonstrate the effectiveness of this innovative architecture in building planar graph reconstruction from 2D building images.", "url": "https://arxiv.org/abs/2306.15035"}, {"metadata": {"arXiv": "2306.15121", "Date": "Tue, 27 Jun 2023 00:11:31 ", "Title": "Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation", "Authors": ["William F. Godoy", "Pedro Valero-Lara", "Keita Teranishi", "Prasanna Balaprakash", "Jeffrey S. Vetter"], "Categories": "cs.AI cs.ET cs.PL", "Comments": ["Accepted at the Sixteenth International Workshop on Parallel Programming Models and Systems Software for High-End Computing (P2S2)", "2023 to be held in conjunction with ICPP 2023: The 52nd International Conference on Parallel Processing. 10 pages", "6 figures", "5 tables"], "DOI": "10.1145/3605731.3605886"}, "abstract": "We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numba, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple <kernel> + <programming model> + <optional hints> prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model's community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions.", "url": "https://arxiv.org/abs/2306.15121"}, {"metadata": {"arXiv": "2306.15266", "Date": "Tue, 27 Jun 2023 07:50:25 ", "Title": "Internal Contrastive Learning for Generalized Out-of-distribution Fault Diagnosis (GOOFD) Framework", "Authors": ["Xingyue Wang", "Hanrong Zhang", "Ke Ma", "Shuting Tao", "Peng Peng", "Hongwei Wang"], "Categories": "cs.AI"}, "abstract": "Fault diagnosis is essential in industrial processes for monitoring the conditions of important machines. With the ever-increasing complexity of working conditions and demand for safety during production and operation, different diagnosis methods are required, and more importantly, an integrated fault diagnosis system that can cope with multiple tasks is highly desired. However, the diagnosis subtasks are often studied separately, and the currently available methods still need improvement for such a generalized system. To address this issue, we propose the Generalized Out-of-distribution Fault Diagnosis (GOOFD) framework to integrate diagnosis subtasks, such as fault detection, fault classification, and novel fault diagnosis. Additionally, a unified fault diagnosis method based on internal contrastive learning is put forward to underpin the proposed generalized framework. The method extracts features utilizing the internal contrastive learning technique and then recognizes the outliers based on the Mahalanobis distance. Experiments are conducted on a simulated benchmark dataset as well as two practical process datasets to evaluate the proposed framework. As demonstrated in the experiments, the proposed method achieves better performance compared with several existing techniques and thus verifies the effectiveness of the proposed framework.", "url": "https://arxiv.org/abs/2306.15266"}, {"metadata": {"arXiv": "2306.15362", "Date": "Tue, 27 Jun 2023 10:20:28 ", "Title": "Planning Landmark Based Goal Recognition Revisited: Does Using Initial State Landmarks Make Sense?", "Authors": ["Nils Wilken and Lea Cohausz and Christian Bartelt and Heiner Stuckenschmidt"], "Categories": "cs.AI", "Comments": ["Will be presented at KI 2023"]}, "abstract": "Goal recognition is an important problem in many application domains (e.g., pervasive computing, intrusion detection, computer games, etc.). In many application scenarios, it is important that goal recognition algorithms can recognize goals of an observed agent as fast as possible. However, many early approaches in the area of Plan Recognition As Planning, require quite large amounts of computation time to calculate a solution. Mainly to address this issue, recently, Pereira et al. developed an approach that is based on planning landmarks and is much more computationally efficient than previous approaches. However, the approach, as proposed by Pereira et al., also uses trivial landmarks (i.e., facts that are part of the initial state and goal description are landmarks by definition). In this paper, we show that it does not provide any benefit to use landmarks that are part of the initial state in a planning landmark based goal recognition approach. The empirical results show that omitting initial state landmarks for goal recognition improves goal recognition performance.", "url": "https://arxiv.org/abs/2306.15362"}, {"metadata": {"arXiv": "2306.15365", "Date": "Tue, 27 Jun 2023 10:30:51 ", "Title": "Herb-Drug Interactions: A Holistic Decision Support System in Healthcare", "Authors": ["Andreia Martins", "Eva Maia", "Isabel Pra\\c{c}a"], "Categories": "cs.AI", "Journal-ref": "2022 IEEE International Conference on E-health Networking, Application & Services (HealthCom)", "DOI": "10.1109/HealthCom54947.2022.9982729"}, "abstract": "Complementary and alternative medicine are commonly used concomitantly with conventional medications leading to adverse drug reactions and even fatality in some cases. Furthermore, the vast possibility of herb-drug interactions prevents health professionals from remembering or manually searching them in a database. Decision support systems are a powerful tool that can be used to assist clinicians in making diagnostic and therapeutic decisions in patient care. Therefore, an original and hybrid decision support system was designed to identify herb-drug interactions, applying artificial intelligence techniques to identify new possible interactions. Different machine learning models will be used to strengthen the typical rules engine used in these cases. Thus, using the proposed system, the pharmacy community, people's first line of contact within the Healthcare System, will be able to make better and more accurate therapeutic decisions and mitigate possible adverse events.", "url": "https://arxiv.org/abs/2306.15365"}, {"metadata": {"arXiv": "2306.15489", "Date": "Tue, 27 Jun 2023 14:10:09 ", "Title": "Precursor-of-Anomaly Detection for Irregular Time Series", "Authors": ["Sheo Yon Jhin", "Jaehoon Lee", "Noseong Park"], "Categories": "cs.AI", "DOI": "10.1145/3580305.3599469"}, "abstract": "Anomaly detection is an important field that aims to identify unexpected patterns or data points, and it is closely related to many real-world problems, particularly to applications in finance, manufacturing, cyber security, and so on. While anomaly detection has been studied extensively in various fields, detecting future anomalies before they occur remains an unexplored territory. In this paper, we present a novel type of anomaly detection, called \\emph{\\textbf{P}recursor-of-\\textbf{A}nomaly} (PoA) detection. Unlike conventional anomaly detection, which focuses on determining whether a given time series observation is an anomaly or not, PoA detection aims to detect future anomalies before they happen. To solve both problems at the same time, we present a neural controlled differential equation-based neural network and its multi-task learning algorithm. We conduct experiments using 17 baselines and 3 datasets, including regular and irregular time series, and demonstrate that our presented method outperforms the baselines in almost all cases. Our ablation studies also indicate that the multitasking training method significantly enhances the overall performance for both anomaly and PoA detection.", "url": "https://arxiv.org/abs/2306.15489"}, {"metadata": {"arXiv": "2306.15664", "Date": "Tue, 27 Jun 2023 17:57:34 ", "Title": "ShuttleSet22: Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset", "Authors": ["Wei-Yao Wang", "Wei-Wei Du", "Wen-Chih Peng"], "Categories": "cs.AI", "Comments": ["IT4PSS @ IJCAI-23 and CoachAI Badminton Challenge Track 2 @ IJCAI-23"]}, "abstract": "In recent years, badminton analytics has drawn attention due to the advancement of artificial intelligence and the efficiency of data collection. While there is a line of effective applications to improve and investigate player performance, there are only a few public badminton datasets that can be used for researchers outside the badminton domain. Existing badminton singles datasets focus on specific matchups; however, they cannot provide comprehensive studies on different players and various matchups. In this paper, we provide a badminton singles dataset, ShuttleSet22, which is collected from high-ranking matches in 2022. ShuttleSet22 consists of 30,172 strokes in 2,888 rallies in the training set, 1,400 strokes in 450 rallies in the validation set, and 2,040 strokes in 654 rallies in the testing set with detailed stroke-level metadata within a rally. To benchmark existing work with ShuttleSet22, we test the state-of-the-art stroke forecasting approach, ShuttleNet, with the corresponding stroke forecasting task, i.e., predict the future strokes based on the given strokes of each rally. We also hold a challenge, Track 2: Forecasting Future Turn-Based Strokes in Badminton Rallies, at CoachAI Badminton Challenge 2023 to boost researchers to tackle this problem. The baseline codes and the dataset will be made available on https://github.com/wywyWang/CoachAI-Projects/tree/main/CoachAI-Challenge-IJCAI2023/Track\\%202\\%3A\\%20Stroke\\%20Forecasting.", "url": "https://arxiv.org/abs/2306.15664"}, {"metadata": {"arXiv": "2306.15117", "Date": "Mon, 26 Jun 2023 23:55:00 ", "Title": "Continual Learning for Out-of-Distribution Pedestrian Detection", "Authors": ["Mahdiyar Molahasani", "Ali Etemad", "Michael Greenspan"], "Categories": "cs.CV cs.AI"}, "abstract": "A continual learning solution is proposed to address the out-of-distribution generalization problem for pedestrian detection. While recent pedestrian detection models have achieved impressive performance on various datasets, they remain sensitive to shifts in the distribution of the inference data. Our method adopts and modifies Elastic Weight Consolidation to a backbone object detection network, in order to penalize the changes in the model weights based on their importance towards the initially learned task. We show that when trained with one dataset and fine-tuned on another, our solution learns the new distribution and maintains its performance on the previous one, avoiding catastrophic forgetting. We use two popular datasets, CrowdHuman and CityPersons for our cross-dataset experiments, and show considerable improvements over standard fine-tuning, with a 9% and 18% miss rate percent reduction improvement in the CrowdHuman and CityPersons datasets, respectively.", "url": "https://arxiv.org/abs/2306.15117"}, {"metadata": {"arXiv": "2306.15318", "Date": "Tue, 27 Jun 2023 09:15:52 ", "Title": "Towards predicting Pedestrian Evacuation Time and Density from Floorplans using a Vision Transformer", "Authors": ["Patrick Berggold", "Stavros Nousias", "Rohit K. Dubey", "Andr\\'e Borrmann"], "Categories": "cs.CV cs.AI"}, "abstract": "Conventional pedestrian simulators are inevitable tools in the design process of a building, as they enable project engineers to prevent overcrowding situations and plan escape routes for evacuation. However, simulation runtime and the multiple cumbersome steps in generating simulation results are potential bottlenecks during the building design process. Data-driven approaches have demonstrated their capability to outperform conventional methods in speed while delivering similar or even better results across many disciplines. In this work, we present a deep learning-based approach based on a Vision Transformer to predict density heatmaps over time and total evacuation time from a given floorplan. Specifically, due to limited availability of public datasets, we implement a parametric data generation pipeline including a conventional simulator. This enables us to build a large synthetic dataset that we use to train our architecture. Furthermore, we seamlessly integrate our model into a BIM-authoring tool to generate simulation results instantly and automatically.", "url": "https://arxiv.org/abs/2306.15318"}, {"metadata": {"arXiv": "2306.15333", "Date": "Tue, 27 Jun 2023 09:39:42 ", "Title": "Shoggoth: Towards Efficient Edge-Cloud Collaborative Real-Time Video Inference via Adaptive Online Learning", "Authors": ["Liang Wang and Kai Lu and Nan Zhang and Xiaoyang Qu and Jianzong Wang and Jiguang Wan and Guokuan Li and Jing Xiao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by 60th ACM/IEEE Design Automation Conference (DAC2023)"]}, "abstract": "This paper proposes Shoggoth, an efficient edge-cloud collaborative architecture, for boosting inference performance on real-time video of changing scenes. Shoggoth uses online knowledge distillation to improve the accuracy of models suffering from data drift and offloads the labeling process to the cloud, alleviating constrained resources of edge devices. At the edge, we design adaptive training using small batches to adapt models under limited computing power, and adaptive sampling of training frames for robustness and reducing bandwidth. The evaluations on the realistic dataset show 15%-20% model accuracy improvement compared to the edge-only strategy and fewer network costs than the cloud-only strategy.", "url": "https://arxiv.org/abs/2306.15333"}, {"metadata": {"arXiv": "2306.15348", "Date": "Tue, 27 Jun 2023 10:02:28 ", "Title": "PANet: LiDAR Panoptic Segmentation with Sparse Instance Proposal and Aggregation", "Authors": ["Jianbiao Mei", "Yu Yang", "Mengmeng Wang", "Xiaojun Hou", "Laijian Li and Yong Liu"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "3 figures", "IROS2023"]}, "abstract": "Reliable LiDAR panoptic segmentation (LPS), including both semantic and instance segmentation, is vital for many robotic applications, such as autonomous driving. This work proposes a new LPS framework named PANet to eliminate the dependency on the offset branch and improve the performance on large objects, which are always over-segmented by clustering algorithms. Firstly, we propose a non-learning Sparse Instance Proposal (SIP) module with the ``sampling-shifting-grouping\" scheme to directly group thing points into instances from the raw point cloud efficiently. More specifically, balanced point sampling is introduced to generate sparse seed points with more uniform point distribution over the distance range. And a shift module, termed bubble shifting, is proposed to shrink the seed points to the clustered centers. Then we utilize the connected component label algorithm to generate instance proposals. Furthermore, an instance aggregation module is devised to integrate potentially fragmented instances, improving the performance of the SIP module on large objects. Extensive experiments show that PANet achieves state-of-the-art performance among published works on the SemanticKITII validation and nuScenes validation for the panoptic segmentation task.", "url": "https://arxiv.org/abs/2306.15348"}, {"metadata": {"arXiv": "2306.15349", "Date": "Tue, 27 Jun 2023 10:02:45 ", "Title": "SSC-RS: Elevate LiDAR Semantic Scene Completion with Representation Separation and BEV Fusion", "Authors": ["Jianbiao Mei", "Yu Yang", "Mengmeng Wang", "Tianxin Huang", "Xuemeng Yang and Yong Liu"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "5 figures", "IROS2023"]}, "abstract": "Semantic scene completion (SSC) jointly predicts the semantics and geometry of the entire 3D scene, which plays an essential role in 3D scene understanding for autonomous driving systems. SSC has achieved rapid progress with the help of semantic context in segmentation. However, how to effectively exploit the relationships between the semantic context in semantic segmentation and geometric structure in scene completion remains under exploration. In this paper, we propose to solve outdoor SSC from the perspective of representation separation and BEV fusion. Specifically, we present the network, named SSC-RS, which uses separate branches with deep supervision to explicitly disentangle the learning procedure of the semantic and geometric representations. And a BEV fusion network equipped with the proposed Adaptive Representation Fusion (ARF) module is presented to aggregate the multi-scale features effectively and efficiently. Due to the low computational burden and powerful representation ability, our model has good generality while running in real-time. Extensive experiments on SemanticKITTI demonstrate our SSC-RS achieves state-of-the-art performance.", "url": "https://arxiv.org/abs/2306.15349"}, {"metadata": {"arXiv": "2306.15390", "Date": "Tue, 27 Jun 2023 11:28:29 ", "Title": "DCP-NAS: Discrepant Child-Parent Neural Architecture Search for 1-bit CNNs", "Authors": ["Yanjing Li", "Sheng Xu", "Xianbin Cao", "Li'an Zhuo", "Baochang Zhang", "Tian Wang", "Guodong Guo"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by International Journal of Computer Vision"]}, "abstract": "Neural architecture search (NAS) proves to be among the effective approaches for many tasks by generating an application-adaptive neural architecture, which is still challenged by high computational cost and memory consumption. At the same time, 1-bit convolutional neural networks (CNNs) with binary weights and activations show their potential for resource-limited embedded devices. One natural approach is to use 1-bit CNNs to reduce the computation and memory cost of NAS by taking advantage of the strengths of each in a unified framework, while searching the 1-bit CNNs is more challenging due to the more complicated processes involved. In this paper, we introduce Discrepant Child-Parent Neural Architecture Search (DCP-NAS) to efficiently search 1-bit CNNs, based on a new framework of searching the 1-bit model (Child) under the supervision of a real-valued model (Parent). Particularly, we first utilize a Parent model to calculate a tangent direction, based on which the tangent propagation method is introduced to search the optimized 1-bit Child. We further observe a coupling relationship between the weights and architecture parameters existing in such differentiable frameworks. To address the issue, we propose a decoupled optimization method to search an optimized architecture. Extensive experiments demonstrate that our DCP-NAS achieves much better results than prior arts on both CIFAR-10 and ImageNet datasets. In particular, the backbones achieved by our DCP-NAS achieve strong generalization performance on person re-identification and object detection.", "url": "https://arxiv.org/abs/2306.15390"}, {"metadata": {"arXiv": "2306.15451", "Date": "Tue, 27 Jun 2023 13:12:25 ", "Title": "Advancing Adversarial Training by Injecting Booster Signal", "Authors": ["Hong Joo Lee", "Youngjoon Yu", "Yong Man Ro"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at IEEE Transactions on Neural Networks and Learning Systems"], "DOI": "10.1109/TNNLS.2023.3264256"}, "abstract": "Recent works have demonstrated that deep neural networks (DNNs) are highly vulnerable to adversarial attacks. To defend against adversarial attacks, many defense strategies have been proposed, among which adversarial training has been demonstrated to be the most effective strategy. However, it has been known that adversarial training sometimes hurts natural accuracy. Then, many works focus on optimizing model parameters to handle the problem. Different from the previous approaches, in this paper, we propose a new approach to improve the adversarial robustness by using an external signal rather than model parameters. In the proposed method, a well-optimized universal external signal called a booster signal is injected into the outside of the image which does not overlap with the original content. Then, it boosts both adversarial robustness and natural accuracy. The booster signal is optimized in parallel to model parameters step by step collaboratively. Experimental results show that the booster signal can improve both the natural and robust accuracies over the recent state-of-the-art adversarial training methods. Also, optimizing the booster signal is general and flexible enough to be adopted on any existing adversarial training methods.", "url": "https://arxiv.org/abs/2306.15451"}, {"metadata": {"arXiv": "2306.15457", "Date": "Tue, 27 Jun 2023 13:22:19 ", "Title": "Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning", "Authors": ["Hong Joo Lee", "Yong Man Ro"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at IEEE Transactions on Information Forensics and Security (TIFS)"], "DOI": "10.1109/TIFS.2023.3288672"}, "abstract": "Recently, it has been widely known that deep neural networks are highly vulnerable and easily broken by adversarial attacks. To mitigate the adversarial vulnerability, many defense algorithms have been proposed. Recently, to improve adversarial robustness, many works try to enhance feature representation by imposing more direct supervision on the discriminative feature. However, existing approaches lack an understanding of learning adversarially robust feature representation. In this paper, we propose a novel training framework called Robust Proxy Learning. In the proposed method, the model explicitly learns robust feature representations with robust proxies. To this end, firstly, we demonstrate that we can generate class-representative robust features by adding class-wise robust perturbations. Then, we use the class representative features as robust proxies. With the class-wise robust features, the model explicitly learns adversarially robust features through the proposed robust proxy learning framework. Through extensive experiments, we verify that we can manually generate robust features, and our proposed learning framework could increase the robustness of the DNNs.", "url": "https://arxiv.org/abs/2306.15457"}, {"metadata": {"arXiv": "2306.15668", "Date": "Tue, 27 Jun 2023 17:59:33 ", "Title": "Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties", "Authors": ["Hsiao-Yu Tung", "Mingyu Ding", "Zhenfang Chen", "Daniel Bear", "Chuang Gan", "Joshua B. Tenenbaum", "Daniel LK Yamins", "Judith E Fan", "Kevin A. Smith"], "Categories": "cs.CV cs.AI cs.GR cs.RO"}, "abstract": "General physical scene understanding requires more than simply localizing and recognizing objects -- it requires knowledge that objects can have different latent properties (e.g., mass or elasticity), and that those properties affect the outcome of physical events. While there has been great progress in physical and video prediction models in recent years, benchmarks to test their performance typically do not require an understanding that objects have individual physical properties, or at best test only those properties that are directly observable (e.g., size or color). This work proposes a novel dataset and benchmark, termed Physion++, that rigorously evaluates visual physical prediction in artificial systems under circumstances where those predictions rely on accurate estimates of the latent physical properties of objects in the scene. Specifically, we test scenarios where accurate prediction relies on estimates of properties such as mass, friction, elasticity, and deformability, and where the values of those properties can only be inferred by observing how objects move and interact with other objects or fluids. We evaluate the performance of a number of state-of-the-art prediction models that span a variety of levels of learning vs. built-in knowledge, and compare that performance to a set of human predictions. We find that models that have been trained using standard regimes and datasets do not spontaneously learn to make inferences about latent properties, but also that models that encode objectness and physical states tend to make better predictions. However, there is still a huge gap between all models and human performance, and all models' predictions correlate poorly with those made by humans, suggesting that no state-of-the-art model is learning to make physical predictions in a human-like way. Project page: https://dingmyu.github.io/physion_v2/", "url": "https://arxiv.org/abs/2306.15668"}, {"metadata": {"arXiv": "2306.15657", "Date": "Tue, 27 Jun 2023 17:50:58 ", "Title": "The Distortion of Binomial Voting Defies Expectation", "Authors": ["Yannai A. Gonczarowski", "Gregory Kehne", "Ariel D. Procaccia", "Ben Schiffer", "Shirley Zhang"], "Categories": "cs.GT cs.AI"}, "abstract": "In computational social choice, the distortion of a voting rule quantifies the degree to which the rule overcomes limited preference information to select a socially desirable outcome. This concept has been investigated extensively, but only through a worst-case lens. Instead, we study the expected distortion of voting rules with respect to an underlying distribution over voter utilities. Our main contribution is the design and analysis of a novel and intuitive rule, binomial voting, which provides strong expected distortion guarantees for all distributions.", "url": "https://arxiv.org/abs/2306.15657"}, {"metadata": {"arXiv": "2306.15136", "Date": "Tue, 27 Jun 2023 01:29:20 ", "Title": "What Truly Matters in Trajectory Prediction for Autonomous Driving?", "Authors": ["Haoran Wu", "Tran Phong", "Cunjun Yu", "Panpan Cai", "Sifa Zheng", "David Hsu"], "Categories": "cs.RO cs.AI"}, "abstract": "In the autonomous driving system, trajectory prediction plays a vital role in ensuring safety and facilitating smooth navigation. However, we observe a substantial discrepancy between the accuracy of predictors on fixed datasets and their driving performance when used in downstream tasks. This discrepancy arises from two overlooked factors in the current evaluation protocols of trajectory prediction: 1) the dynamics gap between the dataset and real driving scenario; and 2) the computational efficiency of predictors. In real-world scenarios, prediction algorithms influence the behavior of autonomous vehicles, which, in turn, alter the behaviors of other agents on the road. This interaction results in predictor-specific dynamics that directly impact prediction results. As other agents' responses are predetermined on datasets, a significant dynamics gap arises between evaluations conducted on fixed datasets and actual driving scenarios. Furthermore, focusing solely on accuracy fails to address the demand for computational efficiency, which is critical for the real-time response required by the autonomous driving system. Therefore, in this paper, we demonstrate that an interactive, task-driven evaluation approach for trajectory prediction is crucial to reflect its efficacy for autonomous driving.", "url": "https://arxiv.org/abs/2306.15136"}, {"metadata": {"arXiv": "2306.15228", "Date": "Tue, 27 Jun 2023 06:02:44 ", "Title": "IIFL: Implicit Interactive Fleet Learning from Heterogeneous Human Supervisors", "Authors": ["Gaurav Datta", "Ryan Hoque", "Anrui Gu", "Eugen Solowjow", "Ken Goldberg"], "Categories": "cs.RO cs.AI"}, "abstract": "Imitation learning has been applied to a range of robotic tasks, but can struggle when (1) robots encounter edge cases that are not represented in the training data (distribution shift) or (2) the human demonstrations are heterogeneous: taking different paths around an obstacle, for instance (multimodality). Interactive fleet learning (IFL) mitigates distribution shift by allowing robots to access remote human teleoperators during task execution and learn from them over time, but is not equipped to handle multimodality. Recent work proposes Implicit Behavior Cloning (IBC), which is able to represent multimodal demonstrations using energy-based models (EBMs). In this work, we propose addressing both multimodality and distribution shift with Implicit Interactive Fleet Learning (IIFL), the first extension of implicit policies to interactive imitation learning (including the single-robot, single-human setting). IIFL quantifies uncertainty using a novel application of Jeffreys divergence to EBMs. While IIFL is more computationally expensive than explicit methods, results suggest that IIFL achieves 4.5x higher return on human effort in simulation experiments and an 80% higher success rate in a physical block pushing task over (Explicit) IFL, IBC, and other baselines when human supervision is heterogeneous.", "url": "https://arxiv.org/abs/2306.15228"}, {"metadata": {"arXiv": "2306.15517", "Date": "Tue, 27 Jun 2023 14:46:09 ", "Title": "Enhancing Navigation Benchmarking and Perception Data Generation for Row-based Crops in Simulation", "Authors": ["Mauro Martini", "Andrea Eirale", "Brenno Tuberga", "Marco Ambrosio", "Andrea Ostuni", "Francesco Messina", "Luigi Mazzara", "Marcello Chiaberge"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted at the 14th European Conference on Precision Agriculture (ECPA) 2023"]}, "abstract": "Service robotics is recently enhancing precision agriculture enabling many automated processes based on efficient autonomous navigation solutions. However, data generation and infield validation campaigns hinder the progress of large-scale autonomous platforms. Simulated environments and deep visual perception are spreading as successful tools to speed up the development of robust navigation with low-cost RGB-D cameras. In this context, the contribution of this work is twofold: a synthetic dataset to train deep semantic segmentation networks together with a collection of virtual scenarios for a fast evaluation of navigation algorithms. Moreover, an automatic parametric approach is developed to explore different field geometries and features. The simulation framework and the dataset have been evaluated by training a deep segmentation network on different crops and benchmarking the resulting navigation.", "url": "https://arxiv.org/abs/2306.15517"}, {"metadata": {"arXiv": "2306.15182", "Date": "Tue, 27 Jun 2023 03:42:31 ", "Title": "Automatic Truss Design with Reinforcement Learning", "Authors": ["Weihua Du", "Jinglun Zhao", "Chao Yu", "Xingcheng Yao", "Zimeng Song", "Siyang Wu", "Ruifeng Luo", "Zhiyuan Liu", "Xianzhong Zhao", "Yi Wu"], "Categories": "cs.AI cs.LG", "Comments": ["IJCAI2023. The codes are available at https://github.com/StigLidu/AutoTruss"]}, "abstract": "Truss layout design, namely finding a lightweight truss layout satisfying all the physical constraints, is a fundamental problem in the building industry. Generating the optimal layout is a challenging combinatorial optimization problem, which can be extremely expensive to solve by exhaustive search. Directly applying end-to-end reinforcement learning (RL) methods to truss layout design is infeasible either, since only a tiny portion of the entire layout space is valid under the physical constraints, leading to particularly sparse rewards for RL training. In this paper, we develop AutoTruss, a two-stage framework to efficiently generate both lightweight and valid truss layouts. AutoTruss first adopts Monte Carlo tree search to discover a diverse collection of valid layouts. Then RL is applied to iteratively refine the valid solutions. We conduct experiments and ablation studies in popular truss layout design test cases in both 2D and 3D settings. AutoTruss outperforms the best-reported layouts by 25.1% in the most challenging 3D test cases, resulting in the first effective deep-RL-based approach in the truss layout design literature.", "url": "https://arxiv.org/abs/2306.15182"}, {"metadata": {"arXiv": "2306.15272", "Date": "Tue, 27 Jun 2023 07:54:18 ", "Title": "Delivering Inflated Explanations", "Authors": ["Yacine Izza", "Alexey Ignatiev", "Peter Stuckey", "Joao Marques-Silva"], "Categories": "cs.AI cs.LG"}, "abstract": "In the quest for Explainable Artificial Intelligence (XAI) one of the questions that frequently arises given a decision made by an AI system is, ``why was the decision made in this way?'' Formal approaches to explainability build a formal model of the AI system and use this to reason about the properties of the system. Given a set of feature values for an instance to be explained, and a resulting decision, a formal abductive explanation is a set of features, such that if they take the given value will always lead to the same decision. This explanation is useful, it shows that only some features were used in making the final decision. But it is narrow, it only shows that if the selected features take their given values the decision is unchanged. It's possible that some features may change values and still lead to the same decision. In this paper we formally define inflated explanations which is a set of features, and for each feature of set of values (always including the value of the instance being explained), such that the decision will remain unchanged. Inflated explanations are more informative than abductive explanations since e.g they allow us to see if the exact value of a feature is important, or it could be any nearby value. Overall they allow us to better understand the role of each feature in the decision. We show that we can compute inflated explanations for not that much greater cost than abductive explanations, and that we can extend duality results for abductive explanations also to inflated explanations.", "url": "https://arxiv.org/abs/2306.15272"}, {"metadata": {"arXiv": "2306.15482", "Date": "Tue, 27 Jun 2023 14:02:10 ", "Title": "Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets", "Authors": ["Yimu Wang", "Dinghuai Zhang", "Yihan Wu", "Heng Huang", "Hongyang Zhang"], "Categories": "cs.AI cs.CV cs.LG"}, "abstract": "Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches have been proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work takes steps forward in defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named player domination in the bargaining game, namely that the existing max-based approaches, such as MAX and MSD, do not converge. Based on our theoretical analysis, we design a novel framework that adjusts the budgets of different adversaries to avoid any player dominance. Experiments on standard benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness.", "url": "https://arxiv.org/abs/2306.15482"}, {"metadata": {"arXiv": "2306.15500", "Date": "Tue, 27 Jun 2023 14:24:02 ", "Title": "A novel structured argumentation framework for improved explainability of classification tasks", "Authors": ["Lucas Rizzo and Luca Longo"], "Categories": "cs.AI cs.LG cs.LO", "Comments": ["Submitted to the The World Conference on eXplainable Artificial Intelligence (xAI 2023)"]}, "abstract": "This paper presents a novel framework for structured argumentation, named extend argumentative decision graph ($xADG$). It is an extension of argumentative decision graphs built upon Dung's abstract argumentation graphs. The $xADG$ framework allows for arguments to use boolean logic operators and multiple premises (supports) within their internal structure, resulting in more concise argumentation graphs that may be easier for users to understand. The study presents a methodology for construction of $xADGs$ and evaluates their size and predictive capacity for classification tasks of varying magnitudes. Resulting $xADGs$ achieved strong (balanced) accuracy, which was accomplished through an input decision tree, while also reducing the average number of supports needed to reach a conclusion. The results further indicated that it is possible to construct plausibly understandable $xADGs$ that outperform other techniques for building $ADGs$ in terms of predictive capacity and overall size. In summary, the study suggests that $xADG$ represents a promising framework to developing more concise argumentative models that can be used for classification tasks and knowledge discovery, acquisition, and refinement.", "url": "https://arxiv.org/abs/2306.15500"}, {"metadata": {"arXiv": "2306.14941", "Date": "Mon, 26 Jun 2023 17:54:24 ", "Title": "SIMF: Semantics-aware Interactive Motion Forecasting for Autonomous Driving", "Authors": ["Vidyaa Krishnan Nivash", "Ahmed H. Qureshi"], "Categories": "cs.CV cs.AI cs.LG cs.RO"}, "abstract": "Autonomous vehicles require motion forecasting of their surrounding multi-agents (pedestrians and vehicles) to make optimal decisions for navigation. The existing methods focus on techniques to utilize the positions and velocities of these agents and fail to capture semantic information from the scene. Moreover, to mitigate the increase in computational complexity associated with the number of agents in the scene, some works leverage Euclidean distance to prune far-away agents. However, distance-based metric alone is insufficient to select relevant agents and accurately perform their predictions. To resolve these issues, we propose Semantics-aware Interactive Motion Forecasting (SIMF) method to capture semantics along with spatial information, and optimally select relevant agents for motion prediction. Specifically, we achieve this by implementing a semantic-aware selection of relevant agents from the scene and passing them through an attention mechanism to extract global encodings. These encodings along with agents' local information are passed through an encoder to obtain time-dependent latent variables for a motion policy predicting the future trajectories. Our results show that the proposed approach outperforms state-of-the-art baselines and provides more accurate predictions in a scene-consistent manner.", "url": "https://arxiv.org/abs/2306.14941"}, {"metadata": {"arXiv": "2306.15128", "Date": "Tue, 27 Jun 2023 00:40:12 ", "Title": "MIMIC: Masked Image Modeling with Image Correspondences", "Authors": ["Kalyani Marathe", "Mahtab Bigverdi", "Nishat Khan", "Tuhin Kundu", "Aniruddha Kembhavi", "Linda G. Shapiro", "Ranjay Krishna"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Many pixelwise dense prediction tasks-depth estimation and semantic segmentation in computer vision today rely on pretrained image representations. Therefore, curating effective pretraining datasets is vital. Unfortunately, the effective pretraining datasets are those with multi-view scenes and have only been curated using annotated 3D meshes, point clouds, and camera parameters from simulated environments. We propose a dataset-curation mechanism that does not require any annotations. We mine two datasets: MIMIC-1M with 1.3M and MIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and from synthetic 3D environments. We train multiple self-supervised models with different masked image modeling objectives to showcase the following findings: Representations trained on MIMIC-3M outperform those mined using annotations on multiple downstream tasks, including depth estimation, semantic segmentation, surface normals, and pose estimation. They also outperform representations that are frozen and when downstream training data is limited to few-shot. Larger dataset (MIMIC-3M) significantly improves performance, which is promising since our curation method can arbitrarily scale to produce even larger datasets. MIMIC code, dataset, and pretrained models are open-sourced at https://github.com/RAIVNLab/MIMIC.", "url": "https://arxiv.org/abs/2306.15128"}, {"metadata": {"arXiv": "2306.15029", "Date": "Mon, 26 Jun 2023 19:38:09 ", "Title": "Beyond dynamic programming", "Authors": ["Abhinav Muraleedharan"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["17 pages. Colab Notebook: https://colab.research.google.com/drive/1GKIMieKrYLX_YXnUOFuEvHwk8CH26zVu?usp=sharing github repo/code: https://github.com/Abhinav-Muraleedharan/Beyond_Dynamic_Programming.git"]}, "abstract": "In this paper, we present Score-life programming, a novel theoretical approach for solving reinforcement learning problems. In contrast with classical dynamic programming-based methods, our method can search over non-stationary policy functions, and can directly compute optimal infinite horizon action sequences from a given state. The central idea in our method is the construction of a mapping between infinite horizon action sequences and real numbers in a bounded interval. This construction enables us to formulate an optimization problem for directly computing optimal infinite horizon action sequences, without requiring a policy function. We demonstrate the effectiveness of our approach by applying it to nonlinear optimal control problems. Overall, our contributions provide a novel theoretical framework for formulating and solving reinforcement learning problems.", "url": "https://arxiv.org/abs/2306.15029"}, {"metadata": {"arXiv": "2306.15063", "Date": "Mon, 26 Jun 2023 21:05:20 ", "Title": "Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression", "Authors": ["Allan Ravent\\'os", "Mansheej Paul", "Feng Chen", "Surya Ganguli"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["The first two authors contributed equally"]}, "abstract": "Pretrained transformers exhibit the remarkable ability of in-context learning (ICL): they can learn tasks from just a few examples provided in the prompt without updating any weights. This raises a foundational question: can ICL solve fundamentally $\\textit{new}$ tasks that are very different from those seen during pretraining? To probe this question, we examine ICL's performance on linear regression while varying the diversity of tasks in the pretraining dataset. We empirically demonstrate a $\\textit{task diversity threshold}$ for the emergence of ICL. Below this threshold, the pretrained transformer cannot solve unseen regression tasks as it behaves like a Bayesian estimator with the $\\textit{non-diverse pretraining task distribution}$ as the prior. Beyond this threshold, the transformer significantly outperforms this estimator; its behavior aligns with that of ridge regression, corresponding to a Gaussian prior over $\\textit{all tasks}$, including those not seen during pretraining. These results highlight that, when pretrained on data with task diversity greater than the threshold, transformers $\\textit{can}$ solve fundamentally new tasks in-context. Importantly, this capability hinges on it deviating from the Bayes optimal estimator with the pretraining distribution as the prior. This study underscores, in a concrete example, the critical role of task diversity, alongside data and model scale, in the emergence of ICL. Code is available at https://github.com/mansheej/icl-task-diversity.", "url": "https://arxiv.org/abs/2306.15063"}, {"metadata": {"arXiv": "2306.15154", "Date": "Tue, 27 Jun 2023 02:22:45 ", "Title": "Contrastive Meta-Learning for Few-shot Node Classification", "Authors": ["Song Wang", "Zhen Tan", "Huan Liu", "Jundong Li"], "Categories": "cs.LG cs.AI", "Comments": ["SIGKDD 2023"]}, "abstract": "Few-shot node classification, which aims to predict labels for nodes on graphs with only limited labeled nodes as references, is of great significance in real-world graph mining tasks. Particularly, in this paper, we refer to the task of classifying nodes in classes with a few labeled nodes as the few-shot node classification problem. To tackle such a label shortage issue, existing works generally leverage the meta-learning framework, which utilizes a number of episodes to extract transferable knowledge from classes with abundant labeled nodes and generalizes the knowledge to other classes with limited labeled nodes. In essence, the primary aim of few-shot node classification is to learn node embeddings that are generalizable across different classes. To accomplish this, the GNN encoder must be able to distinguish node embeddings between different classes, while also aligning embeddings for nodes in the same class. Thus, in this work, we propose to consider both the intra-class and inter-class generalizability of the model. We create a novel contrastive meta-learning framework on graphs, named COSMIC, with two key designs. First, we propose to enhance the intra-class generalizability by involving a contrastive two-step optimization in each episode to explicitly align node embeddings in the same classes. Second, we strengthen the inter-class generalizability by generating hard node classes via a novel similarity-sensitive mix-up strategy. Extensive experiments on few-shot node classification datasets verify the superiority of our framework over state-of-the-art baselines. Our code is provided at https://github.com/SongW-SW/COSMIC.", "url": "https://arxiv.org/abs/2306.15154"}, {"metadata": {"arXiv": "2306.15156", "Date": "Tue, 27 Jun 2023 02:26:01 ", "Title": "Learning non-Markovian Decision-Making from State-only Sequences", "Authors": ["Aoyang Qin", "Feng Gao", "Qing Li", "Song-Chun Zhu", "Sirui Xie"], "Categories": "cs.LG cs.AI"}, "abstract": "Conventional imitation learning assumes access to the actions of demonstrators, but these motor signals are often non-observable in naturalistic settings. Additionally, sequential decision-making behaviors in these settings can deviate from the assumptions of a standard Markov Decision Process (MDP). To address these challenges, we explore deep generative modeling of state-only sequences with non-Markov Decision Process (nMDP), where the policy is an energy-based prior in the latent space of the state transition generator. We develop maximum likelihood estimation to achieve model-based imitation, which involves short-run MCMC sampling from the prior and importance sampling for the posterior. The learned model enables \\textit{decision-making as inference}: model-free policy execution is equivalent to prior sampling, model-based planning is posterior sampling initialized from the policy. We demonstrate the efficacy of the proposed method in a prototypical path planning task with non-Markovian constraints and show that the learned model exhibits strong performances in challenging domains from the MuJoCo suite.", "url": "https://arxiv.org/abs/2306.15156"}, {"metadata": {"arXiv": "2306.15188", "Date": "Tue, 27 Jun 2023 04:14:03 ", "Title": "One-class systems seamlessly fit in the forward-forward algorithm", "Authors": ["Michael Hopwood"], "Categories": "cs.LG cs.AI"}, "abstract": "The forward-forward algorithm presents a new method of training neural networks by updating weights during an inference, performing parameter updates for each layer individually. This immediately reduces memory requirements during training and may lead to many more benefits, like seamless online training. This method relies on a loss (\"goodness\") function that can be evaluated on the activations of each layer, of which can have a varied parameter size, depending on the hyperparamaterization of the network. In the seminal paper, a goodness function was proposed to fill this need; however, if placed in a one-class problem context, one need not pioneer a new loss because these functions can innately handle dynamic network sizes. In this paper, we investigate the performance of deep one-class objective functions when trained in a forward-forward fashion. The code is available at \\url{https://github.com/MichaelHopwood/ForwardForwardOneclass}.", "url": "https://arxiv.org/abs/2306.15188"}, {"metadata": {"arXiv": "2306.15217", "Date": "Tue, 27 Jun 2023 05:37:23 ", "Title": "Unsupervised Episode Generation for Graph Meta-learning", "Authors": ["Jihyeong Jung", "Sangwoo Seo", "Sungwon Kim and Chanyoung Park"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "9 figures", "preprint"]}, "abstract": "In this paper, we investigate Unsupervised Episode Generation methods to solve Few-Shot Node-Classification (FSNC) problem via Meta-learning without labels. Dominant meta-learning methodologies for FSNC were developed under the existence of abundant labeled nodes for training, which however may not be possible to obtain in the real-world. Although few studies have been proposed to tackle the label-scarcity problem, they still rely on a limited amount of labeled data, which hinders the full utilization of the information of all nodes in a graph. Despite the effectiveness of Self-Supervised Learning (SSL) approaches on FSNC without labels, they mainly learn generic node embeddings without consideration on the downstream task to be solved, which may limit its performance. In this work, we propose unsupervised episode generation methods to benefit from their generalization ability for FSNC tasks while resolving label-scarcity problem. We first propose a method that utilizes graph augmentation to generate training episodes called g-UMTRA, which however has several drawbacks, i.e., 1) increased training time due to the computation of augmented features and 2) low applicability to existing baselines. Hence, we propose Neighbors as Queries (NaQ), which generates episodes from structural neighbors found by graph diffusion. Our proposed methods are model-agnostic, that is, they can be plugged into any existing graph meta-learning models, while not sacrificing much of their performance or sometimes even improving them. We provide theoretical insights to support why our unsupervised episode generation methodologies work, and extensive experimental results demonstrate the potential of our unsupervised episode generation methods for graph meta-learning towards FSNC problems.", "url": "https://arxiv.org/abs/2306.15217"}, {"metadata": {"arXiv": "2306.15299", "Date": "Tue, 27 Jun 2023 08:37:57 ", "Title": "FAIRER: Fairness as Decision Rationale Alignment", "Authors": ["Tianlin Li", "Qing Guo", "Aishan Liu", "Mengnan Du", "Zhiming Li", "Yang Liu"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Deep neural networks (DNNs) have made significant progress, but often suffer from fairness issues, as deep models typically show distinct accuracy differences among certain subgroups (e.g., males and females). Existing research addresses this critical issue by employing fairness-aware loss functions to constrain the last-layer outputs and directly regularize DNNs. Although the fairness of DNNs is improved, it is unclear how the trained network makes a fair prediction, which limits future fairness improvements. In this paper, we investigate fairness from the perspective of decision rationale and define the parameter parity score to characterize the fair decision process of networks by analyzing neuron influence in various subgroups. Extensive empirical studies show that the unfair issue could arise from the unaligned decision rationales of subgroups. Existing fairness regularization terms fail to achieve decision rationale alignment because they only constrain last-layer outputs while ignoring intermediate neuron alignment. To address the issue, we formulate the fairness as a new task, i.e., decision rationale alignment that requires DNNs' neurons to have consistent responses on subgroups at both intermediate processes and the final prediction. To make this idea practical during optimization, we relax the naive objective function and propose gradient-guided parity alignment, which encourages gradient-weighted consistency of neurons across subgroups. Extensive experiments on a variety of datasets show that our method can significantly enhance fairness while sustaining a high level of accuracy and outperforming other approaches by a wide margin.", "url": "https://arxiv.org/abs/2306.15299"}, {"metadata": {"arXiv": "2306.15337", "Date": "Tue, 27 Jun 2023 09:46:16 ", "Title": "Homological Neural Networks: A Sparse Architecture for Multivariate Complexity", "Authors": ["Yuanrong Wang", "Antonio Briola", "Tomaso Aste"], "Categories": "cs.LG cs.AI"}, "abstract": "The rapid progress of Artificial Intelligence research came with the development of increasingly complex deep learning models, leading to growing challenges in terms of computational complexity, energy efficiency and interpretability. In this study, we apply advanced network-based information filtering techniques to design a novel deep neural network unit characterized by a sparse higher-order graphical architecture built over the homological structure of underlying data. We demonstrate its effectiveness in two application domains which are traditionally challenging for deep learning: tabular data and time series regression problems. Results demonstrate the advantages of this novel design which can tie or overcome the results of state-of-the-art machine learning and deep learning models using only a fraction of parameters.", "url": "https://arxiv.org/abs/2306.15337"}, {"metadata": {"arXiv": "2306.15347", "Date": "Tue, 27 Jun 2023 10:00:06 ", "Title": "FedET: A Communication-Efficient Federated Class-Incremental Learning Framework Based on Enhanced Transformer", "Authors": ["Chenghao Liu and Xiaoyang Qu and Jianzong Wang and Jing Xiao"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by 2023 International Joint Conference on Artificial Intelligence (IJCAI2023)"]}, "abstract": "Federated Learning (FL) has been widely concerned for it enables decentralized learning while ensuring data privacy. However, most existing methods unrealistically assume that the classes encountered by local clients are fixed over time. After learning new classes, this assumption will make the model's catastrophic forgetting of old classes significantly severe. Moreover, due to the limitation of communication cost, it is challenging to use large-scale models in FL, which will affect the prediction accuracy. To address these challenges, we propose a novel framework, Federated Enhanced Transformer (FedET), which simultaneously achieves high accuracy and low communication cost. Specifically, FedET uses Enhancer, a tiny module, to absorb and communicate new knowledge, and applies pre-trained Transformers combined with different Enhancers to ensure high precision on various tasks. To address local forgetting caused by new classes of new tasks and global forgetting brought by non-i.i.d (non-independent and identically distributed) class imbalance across different local clients, we proposed an Enhancer distillation method to modify the imbalance between old and new knowledge and repair the non-i.i.d. problem. Experimental results demonstrate that FedET's average accuracy on representative benchmark datasets is 14.1% higher than the state-of-the-art method, while FedET saves 90% of the communication cost compared to the previous method.", "url": "https://arxiv.org/abs/2306.15347"}, {"metadata": {"arXiv": "2306.15392", "Date": "Tue, 27 Jun 2023 11:33:31 ", "Title": "Assessing Dataset Quality Through Decision Tree Characteristics in Autoencoder-Processed Spaces", "Authors": ["Szymon Mazurek", "Maciej Wielgosz"], "Categories": "cs.LG cs.AI"}, "abstract": "In this paper, we delve into the critical aspect of dataset quality assessment in machine learning classification tasks. Leveraging a variety of nine distinct datasets, each crafted for classification tasks with varying complexity levels, we illustrate the profound impact of dataset quality on model training and performance. We further introduce two additional datasets designed to represent specific data conditions - one maximizing entropy and the other demonstrating high redundancy. Our findings underscore the importance of appropriate feature selection, adequate data volume, and data quality in achieving high-performing machine learning models. To aid researchers and practitioners, we propose a comprehensive framework for dataset quality assessment, which can help evaluate if the dataset at hand is sufficient and of the required quality for specific tasks. This research offers valuable insights into data assessment practices, contributing to the development of more accurate and robust machine learning models.", "url": "https://arxiv.org/abs/2306.15392"}, {"metadata": {"arXiv": "2306.15403", "Date": "Tue, 27 Jun 2023 12:02:25 ", "Title": "Verifying Safety of Neural Networks from Topological Perspectives", "Authors": ["Zhen Liang", "Dejin Ren", "Bai Xue", "Ji Wang", "Wenjing Yang and Wanwei Liu"], "Categories": "cs.LG cs.AI", "Comments": ["25 pages", "11 figures. arXiv admin note: substantial text overlap with arXiv:2210.04175"], "MSC-class": "68Q60, 68T07", "ACM-class": "D.2.4; I.2.0"}, "abstract": "Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper, we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property and the open map property of NNs are mainly exploited, which establish rigorous guarantees between the boundaries of the input set and the boundaries of the output set. The exploitation of these two properties facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analysis and facilitating the reduction of computation burdens for safety verification. The homeomorphism property exists in some widely used NNs such as invertible residual networks (i-ResNets) and Neural ordinary differential equations (Neural ODEs), and the open map is a less strict property and easier to satisfy compared with the homeomorphism property. For NNs establishing either of these properties, our set-boundary reachability method only needs to perform reachability analysis on the boundary of the input set. Moreover, for NNs that do not feature these properties with respect to the input set, we explore subsets of the input set for establishing the local homeomorphism property and then abandon these subsets for reachability computations. Finally, some examples demonstrate the performance of the proposed method.", "url": "https://arxiv.org/abs/2306.15403"}, {"metadata": {"arXiv": "2306.15503", "Date": "Tue, 27 Jun 2023 14:29:44 ", "Title": "Prioritized Trajectory Replay: A Replay Memory for Data-driven Reinforcement Learning", "Authors": ["Jinyi Liu", "Yi Ma", "Jianye Hao", "Yujing Hu", "Yan Zheng", "Tangjie Lv", "Changjie Fan"], "Categories": "cs.LG cs.AI"}, "abstract": "In recent years, data-driven reinforcement learning (RL), also known as offline RL, have gained significant attention. However, the role of data sampling techniques in offline RL has been overlooked despite its potential to enhance online RL performance. Recent research suggests applying sampling techniques directly to state-transitions does not consistently improve performance in offline RL. Therefore, in this study, we propose a memory technique, (Prioritized) Trajectory Replay (TR/PTR), which extends the sampling perspective to trajectories for more comprehensive information extraction from limited data. TR enhances learning efficiency by backward sampling of trajectories that optimizes the use of subsequent state information. Building on TR, we build the weighted critic target to avoid sampling unseen actions in offline training, and Prioritized Trajectory Replay (PTR) that enables more efficient trajectory sampling, prioritized by various trajectory priority metrics. We demonstrate the benefits of integrating TR and PTR with existing offline RL algorithms on D4RL. In summary, our research emphasizes the significance of trajectory-based data sampling techniques in enhancing the efficiency and performance of offline RL algorithms.", "url": "https://arxiv.org/abs/2306.15503"}, {"metadata": {"arXiv": "2306.15546", "Date": "Tue, 27 Jun 2023 15:15:55 ", "Title": "When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions", "Authors": ["Weiming Zhuang", "Chen Chen", "Lingjuan Lyu"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "The intersection of the Foundation Model (FM) and Federated Learning (FL) provides mutual benefits, presents a unique opportunity to unlock new possibilities in AI research, and address critical challenges in AI and real-world applications. FL expands the availability of data for FMs and enables computation sharing, distributing the training process and reducing the burden on FL participants. It promotes collaborative FM development, democratizing the process and fostering inclusivity and innovation. On the other hand, FM, with its enormous size, pre-trained knowledge, and exceptional performance, serves as a robust starting point for FL, facilitating faster convergence and better performance under non-iid data. Additionally, leveraging FM to generate synthetic data enriches data diversity, reduces overfitting, and preserves privacy. By examining the interplay between FL and FM, this paper aims to deepen the understanding of their synergistic relationship, highlighting the motivations, challenges, and future directions. Through an exploration of the challenges faced by FL and FM individually and their interconnections, we aim to inspire future research directions that can further enhance both fields, driving advancements and propelling the development of privacy-preserving and scalable AI systems.", "url": "https://arxiv.org/abs/2306.15546"}, {"metadata": {"arXiv": "2306.15625", "Date": "Tue, 27 Jun 2023 17:05:22 ", "Title": "Value-aware Importance Weighting for Off-policy Reinforcement Learning", "Authors": ["Kristopher De Asis", "Eric Graves", "Richard S. Sutton"], "Categories": "cs.LG cs.AI", "Comments": ["CoLLAs 2023"], "ACM-class": "I.2"}, "abstract": "Importance sampling is a central idea underlying off-policy prediction in reinforcement learning. It provides a strategy for re-weighting samples from a distribution to obtain unbiased estimates under another distribution. However, importance sampling weights tend to exhibit extreme variance, often leading to stability issues in practice. In this work, we consider a broader class of importance weights to correct samples in off-policy learning. We propose the use of $\\textit{value-aware importance weights}$ which take into account the sample space to provide lower variance, but still unbiased, estimates under a target distribution. We derive how such weights can be computed, and detail key properties of the resulting importance weights. We then extend several reinforcement learning prediction algorithms to the off-policy setting with these weights, and evaluate them empirically.", "url": "https://arxiv.org/abs/2306.15625"}, {"metadata": {"arXiv": "2306.15626", "Date": "Tue, 27 Jun 2023 17:05:32 ", "Title": "LeanDojo: Theorem Proving with Retrieval-Augmented Language Models", "Authors": ["Kaiyu Yang", "Aidan M. Swope", "Alex Gu", "Rahul Chalamala", "Peiyang Song", "Shixing Yu", "Saad Godil", "Ryan Prenger", "Anima Anandkumar"], "Categories": "cs.LG cs.AI cs.LO stat.ML"}, "abstract": "Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection: a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): the first LLM-based prover that is augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's program analysis capability to identify accessible premises and hard negative examples, which makes retrieval much more effective. Furthermore, we construct a new benchmark consisting of 96,962 theorems and proofs extracted from Lean's math library. It features challenging data split requiring the prover to generalize to theorems relying on novel premises that are never used in training. We use this benchmark for training and evaluation, and experimental results demonstrate the effectiveness of ReProver over non-retrieval baselines and GPT-4. We thus provide the first set of open-source LLM-based theorem provers without any proprietary datasets and release it under a permissive MIT license to facilitate further research.", "url": "https://arxiv.org/abs/2306.15626"}, {"metadata": {"arXiv": "2306.15632", "Date": "Tue, 27 Jun 2023 17:13:20 ", "Title": "Asynchronous Algorithmic Alignment with Cocycles", "Authors": ["Andrew Dudzik", "Tamara von Glehn", "Razvan Pascanu", "Petar Veli\\v{c}kovi\\'c"], "Categories": "cs.LG cs.AI cs.DS math.AC"}, "abstract": "State-of-the-art neural algorithmic reasoners make use of message passing in graph neural networks (GNNs). But typical GNNs blur the distinction between the definition and invocation of the message function, forcing a node to send messages to its neighbours at every layer, synchronously. When applying GNNs to learn to execute dynamic programming algorithms, however, on most steps only a handful of the nodes would have meaningful updates to send. One, hence, runs the risk of inefficiencies by sending too much irrelevant data across the graph -- with many intermediate GNN steps having to learn identity functions. In this work, we explicitly separate the concepts of node state update and message function invocation. With this separation, we obtain a mathematical formulation that allows us to reason about asynchronous computation in both algorithms and neural networks.", "url": "https://arxiv.org/abs/2306.15632"}, {"metadata": {"arXiv": "2306.15656", "Date": "Tue, 27 Jun 2023 17:50:26 ", "Title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design", "Authors": ["Fu-Ming Guo"], "Categories": "cs.LG cs.AI cs.CC cs.CL cs.MS"}, "abstract": "This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovative optimizer-compiler co-design strategy, demonstrating the potential of inference acceleration (\\textbf{3.37x}, \\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and LLVM generic compile, respectively) in SparseBERT when paired with an appropriately designed compiler. This study represents a significant step forward in the evolution of efficient, scalable, and high-performing large language models, setting a precedent for future exploration and optimization in this domain. The SparseOptimizer code and SparseALBERT model will be made available upon paper acceptance.", "url": "https://arxiv.org/abs/2306.15656"}, {"metadata": {"arXiv": "2306.15661", "Date": "Tue, 27 Jun 2023 17:55:31 ", "Title": "Enhancing Representation Learning on High-Dimensional, Small-Size Tabular Data: A Divide and Conquer Method with Ensembled VAEs", "Authors": ["Navindu Leelarathna", "Andrei Margeloiu", "Mateja Jamnik", "Nikola Simidjievski"], "Categories": "cs.LG cs.AI"}, "abstract": "Variational Autoencoders and their many variants have displayed impressive ability to perform dimensionality reduction, often achieving state-of-the-art performance. Many current methods however, struggle to learn good representations in High Dimensional, Low Sample Size (HDLSS) tasks, which is an inherently challenging setting. We address this challenge by using an ensemble of lightweight VAEs to learn posteriors over subsets of the feature-space, which get aggregated into a joint posterior in a novel divide-and-conquer approach. Specifically, we present an alternative factorisation of the joint posterior that induces a form of implicit data augmentation that yields greater sample efficiency. Through a series of experiments on eight real-world datasets, we show that our method learns better latent representations in HDLSS settings, which leads to higher accuracy in a downstream classification task. Furthermore, we verify that our approach has a positive effect on disentanglement and achieves a lower estimated Total Correlation on learnt representations. Finally, we show that our approach is robust to partial features at inference, exhibiting little performance degradation even with most features missing.", "url": "https://arxiv.org/abs/2306.15661"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.07277", "Date": "Wed, 13 Sep 2023 19:33:26 ", "Title": "Unbiased Face Synthesis With Diffusion Models: Are We There Yet?", "Authors": ["Harrison Rosenberg", "Shimaa Ahmed", "Guruprasad V Ramesh", "Ramya Korlakai Vinayak", "Kassem Fawaz"], "Categories": "cs.CV cs.LG"}, "abstract": "Text-to-image diffusion models have achieved widespread popularity due to their unprecedented image generation capability. In particular, their ability to synthesize and modify human faces has spurred research into using generated face images in both training data augmentation and model performance assessments. In this paper, we study the efficacy and shortcomings of generative models in the context of face generation. Utilizing a combination of qualitative and quantitative measures, including embedding-based metrics and user studies, we present a framework to audit the characteristics of generated faces conditioned on a set of social attributes. We applied our framework on faces generated through state-of-the-art text-to-image diffusion models. We identify several limitations of face image generation that include faithfulness to the text prompt, demographic disparities, and distributional shifts. Furthermore, we present an analytical model that provides insights into how training data selection contributes to the performance of generative models.", "url": "https://arxiv.org/abs/2309.07277"}, {"metadata": {"arXiv": "2309.07888", "Date": "Thu, 14 Sep 2023 17:40:44 ", "Title": "A Novel Local-Global Feature Fusion Framework for Body-weight Exercise Recognition with Pressure Mapping Sensors", "Authors": ["Davinder Pal Singh", "Lala Shakti Swarup Ray", "Bo Zhou", "Sungho Suh", "Paul Lukowicz"], "Categories": "cs.CV cs.LG"}, "abstract": "We present a novel local-global feature fusion framework for body-weight exercise recognition with floor-based dynamic pressure maps. One step further from the existing studies using deep neural networks mainly focusing on global feature extraction, the proposed framework aims to combine local and global features using image processing techniques and the YOLO object detection to localize pressure profiles from different body parts and consider physical constraints. The proposed local feature extraction method generates two sets of high-level local features consisting of cropped pressure mapping and numerical features such as angular orientation, location on the mat, and pressure area. In addition, we adopt a knowledge distillation for regularization to preserve the knowledge of the global feature extraction and improve the performance of the exercise recognition. Our experimental results demonstrate a notable 11 percent improvement in F1 score for exercise recognition while preserving label-specific features.", "url": "https://arxiv.org/abs/2309.07888"}, {"metadata": {"arXiv": "2309.07157", "Date": "Sun, 10 Sep 2023 21:11:36 ", "Title": "Distribution Grid Line Outage Identification with Unknown Pattern and Performance Guarantee", "Authors": ["Chenhan Xiao", "Yizheng Liao", "Yang Weng"], "Categories": "cs.LG cs.SY math.OC stat.AP", "Comments": ["12 pages"], "Journal-ref": "IEEE Transactions on Power Systems 2023"}, "abstract": "Line outage identification in distribution grids is essential for sustainable grid operation. In this work, we propose a practical yet robust detection approach that utilizes only readily available voltage magnitudes, eliminating the need for costly phase angles or power flow data. Given the sensor data, many existing detection methods based on change-point detection require prior knowledge of outage patterns, which are unknown for real-world outage scenarios. To remove this impractical requirement, we propose a data-driven method to learn the parameters of the post-outage distribution through gradient descent. However, directly using gradient descent presents feasibility issues. To address this, we modify our approach by adding a Bregman divergence constraint to control the trajectory of the parameter updates, which eliminates the feasibility problems. As timely operation is the key nowadays, we prove that the optimal parameters can be learned with convergence guarantees via leveraging the statistical and physical properties of voltage data. We evaluate our approach using many representative distribution grids and real load profiles with 17 outage configurations. The results show that we can detect and localize the outage in a timely manner with only voltage magnitudes and without assuming a prior knowledge of outage patterns.", "url": "https://arxiv.org/abs/2309.07157"}, {"metadata": {"arXiv": "2309.07158", "Date": "Mon, 11 Sep 2023 07:54:28 ", "Title": "Compressed Real Numbers for AI: a case-study using a RISC-V CPU", "Authors": ["Federico Rossi", "Marco Cococcioni", "Roger Ferrer Ib\\`a\\~nez", "Jes\\`us Labarta", "Filippo Mantovani", "Marc Casas", "Emanuele Ruffaldi and Sergio Saponara"], "Categories": "cs.LG cs.AR cs.PF"}, "abstract": "As recently demonstrated, Deep Neural Networks (DNN), usually trained using single precision IEEE 754 floating point numbers (binary32), can also work using lower precision. Therefore, 16-bit and 8-bit compressed format have attracted considerable attention. In this paper, we focused on two families of formats that have already achieved interesting results in compressing binary32 numbers in machine learning applications, without sensible degradation of the accuracy: bfloat and posit. Even if 16-bit and 8-bit bfloat/posit are routinely used for reducing the storage of the weights/biases of trained DNNs, the inference still often happens on the 32-bit FPU of the CPU (especially if GPUs are not available). In this paper we propose a way to decompress a tensor of bfloat/posits just before computations, i.e., after the compressed operands have been loaded within the vector registers of a vector capable CPU, in order to save bandwidth usage and increase cache efficiency. Finally, we show the architectural parameters and considerations under which this solution is advantageous with respect to the uncompressed one.", "url": "https://arxiv.org/abs/2309.07158"}, {"metadata": {"arXiv": "2309.07173", "Date": "Tue, 12 Sep 2023 19:00:55 ", "Title": "Using Unsupervised and Supervised Learning and Digital Twin for Deep Convective Ice Storm Classification", "Authors": ["Jason Swope", "Steve Chien", "Emily Dunkel", "Xavier Bosch-Lluis", "Qing Yue and William Deal"], "Categories": "cs.LG cs.CV"}, "abstract": "Smart Ice Cloud Sensing (SMICES) is a small-sat concept in which a primary radar intelligently targets ice storms based on information collected by a lookahead radiometer. Critical to the intelligent targeting is accurate identification of storm/cloud types from eight bands of radiance collected by the radiometer. The cloud types of interest are: clear sky, thin cirrus, cirrus, rainy anvil, and convection core. We describe multi-step use of Machine Learning and Digital Twin of the Earth's atmosphere to derive such a classifier. First, a digital twin of Earth's atmosphere called a Weather Research Forecast (WRF) is used generate simulated lookahead radiometer data as well as deeper \"science\" hidden variables. The datasets simulate a tropical region over the Caribbean and a non-tropical region over the Atlantic coast of the United States. A K-means clustering over the scientific hidden variables was utilized by human experts to generate an automatic labelling of the data - mapping each physical data point to cloud types by scientists informed by mean/centroids of hidden variables of the clusters. Next, classifiers were trained with the inputs of the simulated radiometer data and its corresponding label. The classifiers of a random decision forest (RDF), support vector machine (SVM), Gaussian na\\\"ive bayes, feed forward artificial neural network (ANN), and a convolutional neural network (CNN) were trained. Over the tropical dataset, the best performing classifier was able to identify non-storm and storm clouds with over 80% accuracy in each class for a held-out test set. Over the non-tropical dataset, the best performing classifier was able to classify non-storm clouds with over 90% accuracy and storm clouds with over 40% accuracy. Additionally both sets of classifiers were shown to be resilient to instrument noise.", "url": "https://arxiv.org/abs/2309.07173"}, {"metadata": {"arXiv": "2309.07176", "Date": "Tue, 12 Sep 2023 20:45:30 ", "Title": "Optimal and Fair Encouragement Policy Evaluation and Learning", "Authors": ["Angela Zhou"], "Categories": "cs.LG stat.ML"}, "abstract": "In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. While optimal treatment rules can maximize causal outcomes across the population, access parity constraints or other fairness considerations can be relevant in the case of encouragement. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study causal identification, statistical variance-reduced estimation, and robust estimation of optimal treatment rules, including under potential violations of positivity. We consider fairness constraints such as demographic parity in treatment take-up, and other constraints, via constrained optimization. Our framework can be extended to handle algorithmic recommendations under an often-reasonable covariate-conditional exclusion restriction, using our robustness checks for lack of positivity in the recommendation. We develop a two-stage algorithm for solving over parametrized policy classes under general constraints to obtain variance-sensitive regret bounds. We illustrate the methods in two case studies based on data from randomized encouragement to enroll in insurance and from pretrial supervised release with electronic monitoring.", "url": "https://arxiv.org/abs/2309.07176"}, {"metadata": {"arXiv": "2309.07187", "Date": "Wed, 13 Sep 2023 02:15:02 ", "Title": "Multi-step prediction of chlorophyll concentration based on Adaptive Graph-Temporal Convolutional Network with Series Decomposition", "Authors": ["Ying Chen", "Xiao Li", "Hongbo Zhang", "Wenyang Song and Chongxuan Xv"], "Categories": "cs.LG", "Comments": ["12 pages", "10 figures", "3 tables", "45 references"]}, "abstract": "Chlorophyll concentration can well reflect the nutritional status and algal blooms of water bodies, and is an important indicator for evaluating water quality. The prediction of chlorophyll concentration change trend is of great significance to environmental protection and aquaculture. However, there is a complex and indistinguishable nonlinear relationship between many factors affecting chlorophyll concentration. In order to effectively mine the nonlinear features contained in the data. This paper proposes a time-series decomposition adaptive graph-time convolutional network ( AGTCNSD ) prediction model. Firstly, the original sequence is decomposed into trend component and periodic component by moving average method. Secondly, based on the graph convolutional neural network, the water quality parameter data is modeled, and a parameter embedding matrix is defined. The idea of matrix decomposition is used to assign weight parameters to each node. The adaptive graph convolution learns the relationship between different water quality parameters, updates the state information of each parameter, and improves the learning ability of the update relationship between nodes. Finally, time dependence is captured by time convolution to achieve multi-step prediction of chlorophyll concentration. The validity of the model is verified by the water quality data of the coastal city Beihai. The results show that the prediction effect of this method is better than other methods. It can be used as a scientific resource for environmental management decision-making.", "url": "https://arxiv.org/abs/2309.07187"}, {"metadata": {"arXiv": "2309.07189", "Date": "Wed, 13 Sep 2023 09:23:09 ", "Title": "Learning From Drift: Federated Learning on Non-IID Data via Drift Regularization", "Authors": ["Yeachan Kim", "Bonggun Shin"], "Categories": "cs.LG"}, "abstract": "Federated learning algorithms perform reasonably well on independent and identically distributed (IID) data. They, on the other hand, suffer greatly from heterogeneous environments, i.e., Non-IID data. Despite the fact that many research projects have been done to address this issue, recent findings indicate that they are still sub-optimal when compared to training on IID data. In this work, we carefully analyze the existing methods in heterogeneous environments. Interestingly, we find that regularizing the classifier's outputs is quite effective in preventing performance degradation on Non-IID data. Motivated by this, we propose Learning from Drift (LfD), a novel method for effectively training the model in heterogeneous settings. Our scheme encapsulates two key components: drift estimation and drift regularization. Specifically, LfD first estimates how different the local model is from the global model (i.e., drift). The local model is then regularized such that it does not fall in the direction of the estimated drift. In the experiment, we evaluate each method through the lens of the five aspects of federated learning, i.e., Generalization, Heterogeneity, Scalability, Forgetting, and Efficiency. Comprehensive evaluation results clearly support the superiority of LfD in federated learning with Non-IID data.", "url": "https://arxiv.org/abs/2309.07189"}, {"metadata": {"arXiv": "2309.07197", "Date": "Wed, 13 Sep 2023 14:19:29 ", "Title": "Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments", "Authors": ["Simon Queyrut", "Valerio Schiavoni", "Pascal Felber"], "Categories": "cs.LG cs.CR", "Comments": ["12 pages", "4 figures", "to be published in Proceedings 23rd International Conference on Distributed Computing Systems. arXiv admin note: substantial text overlap with arXiv:2308.04373"]}, "abstract": "The main premise of federated learning (FL) is that machine learning model updates are computed locally to preserve user data privacy. This approach avoids by design user data to ever leave the perimeter of their device. Once the updates aggregated, the model is broadcast to all nodes in the federation. However, without proper defenses, compromised nodes can probe the model inside their local memory in search for adversarial examples, which can lead to dangerous real-world scenarios. For instance, in image-based applications, adversarial examples consist of images slightly perturbed to the human eye getting misclassified by the local model. These adversarial images are then later presented to a victim node's counterpart model to replay the attack. Typical examples harness dissemination strategies such as altered traffic signs (patch attacks) no longer recognized by autonomous vehicles or seemingly unaltered samples that poison the local dataset of the FL scheme to undermine its robustness. Pelta is a novel shielding mechanism leveraging Trusted Execution Environments (TEEs) that reduce the ability of attackers to craft adversarial samples. Pelta masks inside the TEE the first part of the back-propagation chain rule, typically exploited by attackers to craft the malicious samples. We evaluate Pelta on state-of-the-art accurate models using three well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the effectiveness of Pelta in mitigating six white-box state-of-the-art adversarial attacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto Projected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta constitutes the first attempt at defending an ensemble model against the Self-Attention Gradient attack to the best of our knowledge. Our code is available to the research community at https://github.com/queyrusi/Pelta.", "url": "https://arxiv.org/abs/2309.07197"}, {"metadata": {"arXiv": "2309.07207", "Date": "Wed, 13 Sep 2023 18:00:00 ", "Title": "EarthPT: a foundation model for Earth Observation", "Authors": ["Michael J. Smith", "Luke Fleming and James E. Geach"], "Categories": "cs.LG physics.geo-ph", "Comments": ["7 pages", "4 figures", "submitted to NeurIPS CCAI workshop"]}, "abstract": "We introduce EarthPT -- an Earth Observation (EO) pretrained transformer. EarthPT is a 700 million parameter decoding transformer foundation model trained in an autoregressive self-supervised manner and developed specifically with EO use-cases in mind. We demonstrate that EarthPT is an effective forecaster that can accurately predict future pixel-level surface reflectances across the 400-2300 nm range well into the future. For example, forecasts of the evolution of the Normalised Difference Vegetation Index (NDVI) have a typical error of approximately 0.05 (over a natural range of -1 -> 1) at the pixel level over a five month test set horizon, out-performing simple phase-folded models based on historical averaging. We also demonstrate that embeddings learnt by EarthPT hold semantically meaningful information and could be exploited for downstream tasks such as highly granular, dynamic land use classification. Excitingly, we note that the abundance of EO data provides us with -- in theory -- quadrillions of training tokens. Therefore, if we assume that EarthPT follows neural scaling laws akin to those derived for Large Language Models (LLMs), there is currently no data-imposed limit to scaling EarthPT and other similar `Large Observation Models.'", "url": "https://arxiv.org/abs/2309.07207"}, {"metadata": {"arXiv": "2309.07344", "Date": "Wed, 13 Sep 2023 22:48:30 ", "Title": "Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains", "Authors": ["Md Nasim", "Yexiang Xue"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Accelerating the learning of Partial Differential Equations (PDEs) from experimental data will speed up the pace of scientific discovery. Previous randomized algorithms exploit sparsity in PDE updates for acceleration. However such methods are applicable to a limited class of decomposable PDEs, which have sparse features in the value domain. We propose Reel, which accelerates the learning of PDEs via random projection and has much broader applicability. Reel exploits the sparsity by decomposing dense updates into sparse ones in both the value and frequency domains. This decomposition enables efficient learning when the source of the updates consists of gradually changing terms across large areas (sparse in the frequency domain) in addition to a few rapid updates concentrated in a small set of \"interfacial\" regions (sparse in the value domain). Random projection is then applied to compress the sparse signals for learning. To expand the model applicability, Taylor series expansion is used in Reel to approximate the nonlinear PDE updates with polynomials in the decomposable form. Theoretically, we derive a constant factor approximation between the projected loss function and the original one with poly-logarithmic number of projected dimensions. Experimentally, we provide empirical evidence that our proposed Reel can lead to faster learning of PDE models (70-98% reduction in training time when the data is compressed to 1% of its original size) with comparable quality as the non-compressed models.", "url": "https://arxiv.org/abs/2309.07344"}, {"metadata": {"arXiv": "2309.07374", "Date": "Thu, 14 Sep 2023 01:18:57 ", "Title": "Beta quantile regression for robust estimation of uncertainty in the presence of outliers", "Authors": ["Haleh Akrami", "Omar Zamzam", "Anand Joshi", "Sergul Aydore", "Richard Leahy"], "Categories": "cs.LG"}, "abstract": "Quantile Regression (QR) can be used to estimate aleatoric uncertainty in deep neural networks and can generate prediction intervals. Quantifying uncertainty is particularly important in critical applications such as clinical diagnosis, where a realistic assessment of uncertainty is essential in determining disease status and planning the appropriate treatment. The most common application of quantile regression models is in cases where the parametric likelihood cannot be specified. Although quantile regression is quite robust to outlier response observations, it can be sensitive to outlier covariate observations (features). Outlier features can compromise the performance of deep learning regression problems such as style translation, image reconstruction, and deep anomaly detection, potentially leading to misleading conclusions. To address this problem, we propose a robust solution for quantile regression that incorporates concepts from robust divergence. We compare the performance of our proposed method with (i) least trimmed quantile regression and (ii) robust regression based on the regularization of case-specific parameters in a simple real dataset in the presence of outlier. These methods have not been applied in a deep learning framework. We also demonstrate the applicability of the proposed method by applying it to a medical imaging translation task using diffusion models.", "url": "https://arxiv.org/abs/2309.07374"}, {"metadata": {"arXiv": "2309.07402", "Date": "Thu, 14 Sep 2023 03:15:57 ", "Title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy", "Authors": ["Jiaren Xiao", "Quanyu Dai", "Xiao Shen", "Xiaochen Xie", "Jing Dai", "James Lam", "Ka-Wai Kwok"], "Categories": "cs.LG"}, "abstract": "Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. To tackle the SSDA problem on graphs, a novel method called SemiGCL is proposed, which benefits from graph contrastive learning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph's local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark datasets demonstrate that SemiGCL outperforms the state-of-the-art baselines on the SSDA tasks.", "url": "https://arxiv.org/abs/2309.07402"}, {"metadata": {"arXiv": "2309.07450", "Date": "Thu, 14 Sep 2023 06:22:48 ", "Title": "TensorFlow Chaotic Prediction and Blow Up", "Authors": ["M. Andrecut"], "Categories": "cs.LG", "Comments": ["10 pages", "3 figures"]}, "abstract": "Predicting the dynamics of chaotic systems is one of the most challenging tasks for neural networks, and machine learning in general. Here we aim to predict the spatiotemporal chaotic dynamics of a high-dimensional non-linear system. In our attempt we use the TensorFlow library, representing the state of the art for deep neural networks training and prediction. While our results are encouraging, and show that the dynamics of the considered system can be predicted for short time, we also indirectly discovered an unexpected and undesirable behavior of the TensorFlow library. More specifically, the longer term prediction of the system's chaotic behavior quickly deteriorates and blows up due to the nondeterministic behavior of the TensorFlow library. Here we provide numerical evidence of the short time prediction ability, and of the longer term predictability blow up.", "url": "https://arxiv.org/abs/2309.07450"}, {"metadata": {"arXiv": "2309.07452", "Date": "Thu, 14 Sep 2023 06:24:33 ", "Title": "Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph Neural Network?", "Authors": ["Lianke Qin", "Zhao Song", "Baocheng Sun"], "Categories": "cs.LG"}, "abstract": "A rising trend in theoretical deep learning is to understand why deep learning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method that is equivalent to using gradient descent to train a multi-layer infinitely-wide neural network. NTK is a major step forward in the theoretical deep learning because it allows researchers to use traditional mathematical tools to analyze properties of deep neural networks and to explain various neural network techniques from a theoretical view. A natural extension of NTK on graph learning is \\textit{Graph Neural Tangent Kernel (GNTK)}, and researchers have already provide GNTK formulation for graph-level regression and show empirically that this kernel method can achieve similar accuracy as GNNs on various bioinformatics datasets [dhs+19]. The remaining question now is whether solving GNTK regression is equivalent to training an infinite-wide multi-layer GNN using gradient descent. In this paper, we provide three new theoretical results. First, we formally prove this equivalence for graph-level regression. Second, we present the first GNTK formulation for node-level regression. Finally, we prove the equivalence for node-level regression.", "url": "https://arxiv.org/abs/2309.07452"}, {"metadata": {"arXiv": "2309.07481", "Date": "Thu, 14 Sep 2023 07:40:10 ", "Title": "Improved Auto-Encoding using Deterministic Projected Belief Networks", "Authors": ["Paul M Baggenstoss"], "Categories": "cs.LG", "Journal-ref": "Proceedings of EUSIPCO 2023, Helsinki, September 2023"}, "abstract": "In this paper, we exploit the unique properties of a deterministic projected belief network (D-PBN) to take full advantage of trainable compound activation functions (TCAs). A D-PBN is a type of auto-encoder that operates by \"backing up\" through a feed-forward neural network. TCAs are activation functions with complex monotonic-increasing shapes that change the distribution of the data so that the linear transformation that follows is more effective. Because a D-PBN operates by \"backing up\", the TCAs are inverted in the reconstruction process, restoring the original distribution of the data, thus taking advantage of a given TCA in both analysis and reconstruction. In this paper, we show that a D-PBN auto-encoder with TCAs can significantly out-perform standard auto-encoders including variational auto-encoders.", "url": "https://arxiv.org/abs/2309.07481"}, {"metadata": {"arXiv": "2309.07526", "Date": "Thu, 14 Sep 2023 08:49:35 ", "Title": "Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning", "Authors": ["Adrian Atienza", "Jakob Bardram", "and Sadasivan Puthusserypady"], "Categories": "cs.LG"}, "abstract": "By identifying similarities between successive inputs, Self-Supervised Learning (SSL) methods for time series analysis have demonstrated their effectiveness in encoding the inherent static characteristics of temporal data. However, an exclusive emphasis on similarities might result in representations that overlook the dynamic attributes critical for modeling cardiovascular diseases within a confined subject cohort. Introducing Distilled Encoding Beyond Similarities (DEBS), this paper pioneers an SSL approach that transcends mere similarities by integrating dissimilarities among positive pairs. The framework is applied to electrocardiogram (ECG) signals, leading to a notable enhancement of +10\\% in the detection accuracy of Atrial Fibrillation (AFib) across diverse subjects. DEBS underscores the potential of attaining a more refined representation by encoding the dynamic characteristics of time series data, tapping into dissimilarities during the optimization process. Broadly, the strategy delineated in this study holds the promise of unearthing novel avenues for advancing SSL methodologies tailored to temporal data.", "url": "https://arxiv.org/abs/2309.07526"}, {"metadata": {"arXiv": "2309.07530", "Date": "Thu, 14 Sep 2023 08:56:31 ", "Title": "Adaptive approximation of monotone functions", "Authors": ["Pierre Gaillard (Thoth)", "S\\'ebastien Gerchinovitz (IMT)", "\\'Etienne de Montbrun (TSE-R)"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "We study the classical problem of approximating a non-decreasing function $f: \\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its values, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a known probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize the minimum number of evaluations of $f$ that algorithms need to guarantee an approximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after stopping. Unlike worst-case results that hold uniformly over all $f$, our complexity measure is dependent on each specific function $f$. To address this problem, we introduce GreedyBox, a generalization of an algorithm originally proposed by Novak (1992) for numerical integration. We prove that GreedyBox achieves an optimal sample complexity for any function $f$, up to logarithmic factors. Additionally, we uncover results regarding piecewise-smooth functions. Perhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster for piecewise-$C^2$ functions than predicted by the algorithm (without any knowledge on the smoothness of $f$). A simple modification even achieves optimal minimax approximation rates for such functions, which we compute explicitly. In particular, our findings highlight multiple performance gaps between adaptive and non-adaptive algorithms, smooth and piecewise-smooth functions, as well as monotone or non-monotone functions. Finally, we provide numerical experiments to support our theoretical results.", "url": "https://arxiv.org/abs/2309.07530"}, {"metadata": {"arXiv": "2309.07544", "Date": "Thu, 14 Sep 2023 09:15:34 ", "Title": "VerilogEval: Evaluating Large Language Models for Verilog Code Generation", "Authors": ["Mingjie Liu", "Nathaniel Pinckney", "Brucek Khailany and Haoxing Ren"], "Categories": "cs.LG cs.SE", "Comments": ["ICCAD 2023 Invited Paper"]}, "abstract": "The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs.", "url": "https://arxiv.org/abs/2309.07544"}, {"metadata": {"arXiv": "2309.07579", "Date": "Thu, 14 Sep 2023 10:23:43 ", "Title": "Structure-Preserving Transformers for Sequences of SPD Matrices", "Authors": ["Mathieu Seraphim", "Alexis Lechervy", "Florian Yger", "Luc Brun and Olivier Etard"], "Categories": "cs.LG eess.SP", "Comments": ["Submitted to the ICASSP 2024 Conference"]}, "abstract": "In recent years, Transformer-based auto-attention mechanisms have been successfully applied to the analysis of a variety of context-reliant data types, from texts to images and beyond, including data from non-Euclidean geometries. In this paper, we present such a mechanism, designed to classify sequences of Symmetric Positive Definite matrices while preserving their Riemannian geometry throughout the analysis. We apply our method to automatic sleep staging on timeseries of EEG-derived covariance matrices from a standard dataset, obtaining high levels of stage-wise performance.", "url": "https://arxiv.org/abs/2309.07579"}, {"metadata": {"arXiv": "2309.07672", "Date": "Thu, 14 Sep 2023 12:34:42 ", "Title": "Physics-constrained robust learning of open-form PDEs from limited and noisy data", "Authors": ["Mengge Du", "Longfeng Nie", "Siyu Lou", "Yuntian Chenc", "Dongxiao Zhang"], "Categories": "cs.LG cs.NA math.NA stat.AP"}, "abstract": "Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge, especially when encountering noisy observations and no prior knowledge available. This study proposes R-DISCOVER, a framework designed to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with superior fits are utilized to iteratively optimize the generator via the RL method and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding.", "url": "https://arxiv.org/abs/2309.07672"}, {"metadata": {"arXiv": "2309.07675", "Date": "Thu, 14 Sep 2023 12:39:26 ", "Title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis", "Authors": ["Mehdi Zadem and Sergio Mover and Sao Mai Nguyen"], "Categories": "cs.LG", "ACM-class": "K.3.2"}, "abstract": "Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.", "url": "https://arxiv.org/abs/2309.07675"}, {"metadata": {"arXiv": "2309.07703", "Date": "Thu, 14 Sep 2023 13:25:42 ", "Title": "Causal Entropy and Information Gain for Measuring Causal Control", "Authors": ["Francisco Nunes Ferreira Quialheiro Simoes", "Mehdi Dastani", "Thijs van Ommen"], "Categories": "cs.LG cs.IT math.IT stat.ML", "Comments": ["16 pages. Accepted at the third XI-ML workshop of ECAI 2023. To appear in the Springer CCIS book series"]}, "abstract": "Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed causal entropy and causal information gain, which are designed to assess how much control a feature provides over the outcome variable. These newly defined quantities capture changes in the entropy of a variable resulting from interventions on other variables. Fundamental results connecting these quantities to the existence of causal effects are derived. The use of causal information gain in feature selection is demonstrated, highlighting its superiority over standard mutual information in revealing which features provide control over a chosen outcome variable. Our investigation paves the way for the development of methods with improved interpretability in domains involving causation.", "url": "https://arxiv.org/abs/2309.07703"}, {"metadata": {"arXiv": "2309.07708", "Date": "Thu, 14 Sep 2023 13:42:27 ", "Title": "Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context", "Authors": ["Haochong Xia", "Shuo Sun", "Xinrun Wang", "Bo An"], "Categories": "cs.LG q-fin.TR"}, "abstract": "Financial simulators play an important role in enhancing forecasting accuracy, managing risks, and fostering strategic financial decision-making. Despite the development of financial market simulation methodologies, existing frameworks often struggle with adapting to specialized simulation context. We pinpoint the challenges as i) current financial datasets do not contain context labels; ii) current techniques are not designed to generate financial data with context as control, which demands greater precision compared to other modalities; iii) the inherent difficulties in generating context-aligned, high-fidelity data given the non-stationary, noisy nature of financial data. To address these challenges, our contributions are: i) we proposed the Contextual Market Dataset with market dynamics, stock ticker, and history state as context, leveraging a market dynamics modeling method that combines linear regression and Dynamic Time Warping clustering to extract market dynamics; ii) we present Market-GAN, a novel architecture incorporating a Generative Adversarial Networks (GAN) for the controllable generation with context, an autoencoder for learning low-dimension features, and supervisors for knowledge transfer; iii) we introduce a two-stage training scheme to ensure that Market-GAN captures the intrinsic market distribution with multiple objectives. In the pertaining stage, with the use of the autoencoder and supervisors, we prepare the generator with a better initialization for the adversarial training stage. We propose a set of holistic evaluation metrics that consider alignment, fidelity, data usability on downstream tasks, and market facts. We evaluate Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and showcase superior performance in comparison to 4 state-of-the-art time-series generative models.", "url": "https://arxiv.org/abs/2309.07708"}, {"metadata": {"arXiv": "2309.07716", "Date": "Thu, 14 Sep 2023 13:48:16 ", "Title": "Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks", "Authors": ["Marcos Eduardo Valle"], "Categories": "cs.LG cs.NE"}, "abstract": "Despite the many successful applications of deep learning models for multidimensional signal and image processing, most traditional neural networks process data represented by (multidimensional) arrays of real numbers. The intercorrelation between feature channels is usually expected to be learned from the training data, requiring numerous parameters and careful training. In contrast, vector-valued neural networks are conceived to process arrays of vectors and naturally consider the intercorrelation between feature channels. Consequently, they usually have fewer parameters and often undergo more robust training than traditional neural networks. This paper aims to present a broad framework for vector-valued neural networks, referred to as V-nets. In this context, hypercomplex-valued neural networks are regarded as vector-valued models with additional algebraic properties. Furthermore, this paper explains the relationship between vector-valued and traditional neural networks. Precisely, a vector-valued neural network can be obtained by placing restrictions on a real-valued model to consider the intercorrelation between feature channels. Finally, we show how V-nets, including hypercomplex-valued neural networks, can be implemented in current deep-learning libraries as real-valued networks.", "url": "https://arxiv.org/abs/2309.07716"}, {"metadata": {"arXiv": "2309.07742", "Date": "Thu, 14 Sep 2023 14:26:20 ", "Title": "Interpretability is in the Mind of the Beholder: A Causal Framework for Human-interpretable Representation Learning", "Authors": ["Emanuele Marconato and Andrea Passerini and Stefano Teso"], "Categories": "cs.LG cs.HC"}, "abstract": "Focus in Explainable AI is shifting from explanations defined in terms of low-level elements, such as input features, to explanations encoded in terms of interpretable concepts learned from data. How to reliably acquire such concepts is, however, still fundamentally unclear. An agreed-upon notion of concept interpretability is missing, with the result that concepts used by both post-hoc explainers and concept-based neural networks are acquired through a variety of mutually incompatible strategies. Critically, most of these neglect the human side of the problem: a representation is understandable only insofar as it can be understood by the human at the receiving end. The key challenge in Human-interpretable Representation Learning (HRL) is how to model and operationalize this human element. In this work, we propose a mathematical framework for acquiring interpretable representations suitable for both post-hoc explainers and concept-based neural networks. Our formalization of HRL builds on recent advances in causal representation learning and explicitly models a human stakeholder as an external observer. This allows us to derive a principled notion of alignment between the machine representation and the vocabulary of concepts understood by the human. In doing so, we link alignment and interpretability through a simple and intuitive name transfer game, and clarify the relationship between alignment and a well-known property of representations, namely disentanglment. We also show that alignment is linked to the issue of undesirable correlations among concepts, also known as concept leakage, and to content-style separation, all through a general information-theoretic reformulation of these properties. Our conceptualization aims to bridge the gap between the human and algorithmic sides of interpretability and establish a stepping stone for new research on human-interpretable representations.", "url": "https://arxiv.org/abs/2309.07742"}, {"metadata": {"arXiv": "2309.07809", "Date": "Thu, 14 Sep 2023 15:55:58 ", "Title": "Communication Efficient Private Federated Learning Using Dithering", "Authors": ["Burak Hasircioglu", "Deniz Gunduz"], "Categories": "cs.LG cs.CR"}, "abstract": "The task of preserving privacy while ensuring efficient communication is a fundamental challenge in federated learning. In this work, we tackle this challenge in the trusted aggregator model, and propose a solution that achieves both objectives simultaneously. We show that employing a quantization scheme based on subtractive dithering at the clients can effectively replicate the normal noise addition process at the aggregator. This implies that we can guarantee the same level of differential privacy against other clients while substantially reducing the amount of communication required, as opposed to transmitting full precision gradients and using central noise addition. We also experimentally demonstrate that the accuracy of our proposed approach matches that of the full precision gradient method.", "url": "https://arxiv.org/abs/2309.07809"}, {"metadata": {"arXiv": "2309.07813", "Date": "Thu, 14 Sep 2023 15:59:23 ", "Title": "Directed Scattering for Knowledge Graph-based Cellular Signaling Analysis", "Authors": ["Aarthi Venkat", "Joyce Chew", "Ferran Cardoso Rodriguez", "Christopher J. Tape", "Michael Perlmutter", "Smita Krishnaswamy"], "Categories": "cs.LG q-bio.CB", "Comments": ["5 pages", "3 figures"]}, "abstract": "Directed graphs are a natural model for many phenomena, in particular scientific knowledge graphs such as molecular interaction or chemical reaction networks that define cellular signaling relationships. In these situations, source nodes typically have distinct biophysical properties from sinks. Due to their ordered and unidirectional relationships, many such networks also have hierarchical and multiscale structure. However, the majority of methods performing node- and edge-level tasks in machine learning do not take these properties into account, and thus have not been leveraged effectively for scientific tasks such as cellular signaling network inference. We propose a new framework called Directed Scattering Autoencoder (DSAE) which uses a directed version of a geometric scattering transform, combined with the non-linear dimensionality reduction properties of an autoencoder and the geometric properties of the hyperbolic space to learn latent hierarchies. We show this method outperforms numerous others on tasks such as embedding directed graphs and learning cellular signaling networks.", "url": "https://arxiv.org/abs/2309.07813"}, {"metadata": {"arXiv": "2309.07887", "Date": "Thu, 14 Sep 2023 17:36:53 ", "Title": "Some notes concerning a generalized KMM-type optimization method for density ratio estimation", "Authors": ["Cristian Daniel Alecsa"], "Categories": "cs.LG math.OC math.ST stat.TH", "Comments": ["17 pages", "4 figures"]}, "abstract": "In the present paper we introduce new optimization algorithms for the task of density ratio estimation. More precisely, we consider extending the well-known KMM method using the construction of a suitable loss function, in order to encompass more general situations involving the estimation of density ratio with respect to subsets of the training data and test data, respectively. The associated codes can be found at https://github.com/CDAlecsa/Generalized-KMM.", "url": "https://arxiv.org/abs/2309.07887"}, {"metadata": {"arXiv": "2309.07899", "Date": "Thu, 14 Sep 2023 17:48:30 ", "Title": "Improving physics-informed DeepONets with hard constraints", "Authors": ["R\\\"udiger Brecht", "Dmytro R. Popovych", "Alex Bihlo and Roman O. Popovych"], "Categories": "cs.LG cs.NA math.NA physics.comp-ph", "Comments": ["15 pages", "5 figures", "4 tables; release version"]}, "abstract": "Current physics-informed (standard or operator) neural networks still rely on accurately learning the initial conditions of the system they are solving. In contrast, standard numerical methods evolve such initial conditions without needing to learn these. In this study, we propose to improve current physics-informed deep learning strategies such that initial conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a DeepONet is applied multiple times to time step a solution, the resulting function is continuous.", "url": "https://arxiv.org/abs/2309.07899"}, {"metadata": {"arXiv": "2309.07909", "Date": "Sun, 10 Sep 2023 13:28:46 ", "Title": "Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch", "Authors": ["Zelin Zang", "Hao Luo", "Kai Wang", "Panpan Zhang", "Fan Wang", "Stan.Z Li", "Yang You"], "Categories": "cs.LG cs.CE cs.CV", "Comments": ["arXiv admin note: text overlap with arXiv:2302.07944 by other authors"]}, "abstract": "Unsupervised contrastive learning methods have recently seen significant improvements, particularly through data augmentation strategies that aim to produce robust and generalizable representations. However, prevailing data augmentation methods, whether hand designed or based on foundation models, tend to rely heavily on prior knowledge or external data. This dependence often compromises their effectiveness and efficiency. Furthermore, the applicability of most existing data augmentation strategies is limited when transitioning to other research domains, especially science-related data. This limitation stems from the paucity of prior knowledge and labeled data available in these domains. To address these challenges, we introduce DiffAug-a novel and efficient Diffusion-based data Augmentation technique. DiffAug aims to ensure that the augmented and original data share a smoothed latent space, which is achieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug first mines sufficient prior semantic knowledge about the neighborhood. This provides a constraint to guide the diffusion steps, eliminating the need for labels, external data/models, or prior knowledge. Designed as an architecture-agnostic framework, DiffAug provides consistent improvements. Specifically, it improves image classification and clustering accuracy by 1.6%~4.5%. When applied to biological data, DiffAug improves performance by up to 10.1%, with an average improvement of 5.8%. DiffAug shows good performance in both vision and biological domains.", "url": "https://arxiv.org/abs/2309.07909"}, {"metadata": {"arXiv": "2309.07550", "Date": "Thu, 14 Sep 2023 09:26:03 ", "Title": "Naturalistic Robot Arm Trajectory Generation via Representation Learning", "Authors": ["Jayjun Lee", "Adam J. Spiers"], "Categories": "cs.RO cs.LG", "Comments": ["4 pages", "3 figures"], "Journal-ref": "Towards Autonomous Robotic Systems (TAROS), 2023"}, "abstract": "The integration of manipulator robots in household environments suggests a need for more predictable and human-like robot motion. This holds especially true for wheelchair-mounted assistive robots that can support the independence of people with paralysis. One method of generating naturalistic motion trajectories is via the imitation of human demonstrators. This paper explores a self-supervised imitation learning method using an autoregressive spatio-temporal graph neural network for an assistive drinking task. We address learning from diverse human motion trajectory data that were captured via wearable IMU sensors on a human arm as the action-free task demonstrations. Observed arm motion data from several participants is used to generate natural and functional drinking motion trajectories for a UR5e robot arm.", "url": "https://arxiv.org/abs/2309.07550"}, {"metadata": {"arXiv": "2309.07609", "Date": "Thu, 14 Sep 2023 11:17:43 ", "Title": "Learning Quasi-Static 3D Models of Markerless Deformable Linear Objects for Bimanual Robotic Manipulation", "Authors": ["Piotr Kicki", "Micha{\\l} Bidzi\\'nski", "Krzysztof Walas"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Under review for IEEE Robotics and Automation Letters"]}, "abstract": "The robotic manipulation of Deformable Linear Objects (DLOs) is a vital and challenging task that is important in many practical applications. Classical model-based approaches to this problem require an accurate model to capture how robot motions affect the deformation of the DLO. Nowadays, data-driven models offer the best tradeoff between quality and computation time. This paper analyzes several learning-based 3D models of the DLO and proposes a new one based on the Transformer architecture that achieves superior accuracy, even on the DLOs of different lengths, thanks to the proposed scaling method. Moreover, we introduce a data augmentation technique, which improves the prediction performance of almost all considered DLO data-driven models. Thanks to this technique, even a simple Multilayer Perceptron (MLP) achieves close to state-of-the-art performance while being significantly faster to evaluate. In the experiments, we compare the performance of the learning-based 3D models of the DLO on several challenging datasets quantitatively and demonstrate their applicability in the task of shaping a DLO.", "url": "https://arxiv.org/abs/2309.07609"}, {"metadata": {"arXiv": "2309.07907", "Date": "Thu, 14 Sep 2023 17:55:18 ", "Title": "Physically Plausible Full-Body Hand-Object Interaction Synthesis", "Authors": ["Jona Braun", "Sammy Christen", "Muhammed Kocabas", "Emre Aksan", "Otmar Hilliges"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project page at https://eth-ait.github.io/phys-fullbody-grasp"]}, "abstract": "We propose a physics-based method for synthesizing dexterous hand-object interactions in a full-body setting. While recent advancements have addressed specific facets of human-object interactions, a comprehensive physics-based approach remains a challenge. Existing methods often focus on isolated segments of the interaction process and rely on data-driven techniques that may result in artifacts. In contrast, our proposed method embraces reinforcement learning (RL) and physics simulation to mitigate the limitations of data-driven approaches. Through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting. The generic skill priors learn to decode a latent skill embedding into the motion of the underlying part. A high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following. It is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives. Our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation. We compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.", "url": "https://arxiv.org/abs/2309.07907"}, {"metadata": {"arXiv": "2309.07383", "Date": "Thu, 14 Sep 2023 02:02:08 ", "Title": "Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning", "Authors": ["Ali Bouland", "Shengyuan Niu", "Sai Tej Paruchuri", "Andrew Kurdila", "John Burns", "Eugenio Schuster"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["7 pages", "4 figures"]}, "abstract": "This paper studies convergence rates for some value function approximations that arise in a collection of reproducing kernel Hilbert spaces (RKHS) $H(\\Omega)$. By casting an optimal control problem in a specific class of native spaces, strong rates of convergence are derived for the operator equation that enables offline approximations that appear in policy iteration. Explicit upper bounds on error in value function approximations are derived in terms of power function $\\Pwr_{H,N}$ for the space of finite dimensional approximants $H_N$ in the native space $H(\\Omega)$. These bounds are geometric in nature and refine some well-known, now classical results concerning convergence of approximations of value functions.", "url": "https://arxiv.org/abs/2309.07383"}, {"metadata": {"arXiv": "2309.07438", "Date": "Thu, 14 Sep 2023 05:43:36 ", "Title": "Towards Artificial General Intelligence (AGI) in the Internet of Things (IoT): Opportunities and Challenges", "Authors": ["Fei Dou", "Jin Ye", "Geng Yuan", "Qin Lu", "Wei Niu", "Haijian Sun", "Le Guan", "Guoyu Lu", "Gengchen Mai", "Ninghao Liu", "Jin Lu", "Zhengliang Liu", "Zihao Wu", "Chenjiao Tan", "Shaochen Xu", "Xianqiao Wang", "Guoming Li", "Lilong Chai", "Sheng Li", "Jin Sun", "Hongyue Sun", "Yunli Shao", "Changying Li", "Tianming Liu", "Wenzhan Song"], "Categories": "cs.AI cs.NI"}, "abstract": "Artificial General Intelligence (AGI), possessing the capacity to comprehend, learn, and execute tasks with human cognitive abilities, engenders significant anticipation and intrigue across scientific, commercial, and societal arenas. This fascination extends particularly to the Internet of Things (IoT), a landscape characterized by the interconnection of countless devices, sensors, and systems, collectively gathering and sharing data to enable intelligent decision-making and automation. This research embarks on an exploration of the opportunities and challenges towards achieving AGI in the context of the IoT. Specifically, it starts by outlining the fundamental principles of IoT and the critical role of Artificial Intelligence (AI) in IoT systems. Subsequently, it delves into AGI fundamentals, culminating in the formulation of a conceptual framework for AGI's seamless integration within IoT. The application spectrum for AGI-infused IoT is broad, encompassing domains ranging from smart grids, residential environments, manufacturing, and transportation to environmental monitoring, agriculture, healthcare, and education. However, adapting AGI to resource-constrained IoT settings necessitates dedicated research efforts. Furthermore, the paper addresses constraints imposed by limited computing resources, intricacies associated with large-scale IoT communication, as well as the critical concerns pertaining to security and privacy.", "url": "https://arxiv.org/abs/2309.07438"}, {"metadata": {"arXiv": "2309.07594", "Date": "Thu, 14 Sep 2023 10:54:48 ", "Title": "Neuro-Symbolic Recommendation Model based on Logic Query", "Authors": ["Maonian Wu", "Bang Chen", "Shaojun Zhu", "Bo Zheng", "Wei Peng", "Mingyi Zhang"], "Categories": "cs.AI cs.IR", "Comments": ["17 pages", "6 figures"]}, "abstract": "A recommendation system assists users in finding items that are relevant to them. Existing recommendation models are primarily based on predicting relationships between users and items and use complex matching models or incorporate extensive external information to capture association patterns in data. However, recommendation is not only a problem of inductive statistics using data; it is also a cognitive task of reasoning decisions based on knowledge extracted from information. Hence, a logic system could naturally be incorporated for the reasoning in a recommendation task. However, although hard-rule approaches based on logic systems can provide powerful reasoning ability, they struggle to cope with inconsistent and incomplete knowledge in real-world tasks, especially for complex tasks such as recommendation. Therefore, in this paper, we propose a neuro-symbolic recommendation model, which transforms the user history interactions into a logic expression and then transforms the recommendation prediction into a query task based on this logic expression. The logic expressions are then computed based on the modular logic operations of the neural network. We also construct an implicit logic encoder to reasonably reduce the complexity of the logic computation. Finally, a user's interest items can be queried in the vector space based on the computation results. Experiments on three well-known datasets verified that our method performs better compared to state of the art shallow, deep, session, and reasoning models.", "url": "https://arxiv.org/abs/2309.07594"}, {"metadata": {"arXiv": "2309.07683", "Date": "Thu, 14 Sep 2023 12:58:30 ", "Title": "Assessing the nature of large language models: A caution against anthropocentrism", "Authors": ["Ann Speed"], "Categories": "cs.AI cs.CL cs.CY cs.HC", "Comments": ["30 pages", "6 figures"]}, "abstract": "Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans. Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability notwithstanding, GPT3.5 displays what in a human would be considered poor mental health, including low self-esteem and marked dissociation from reality despite upbeat and helpful responses.", "url": "https://arxiv.org/abs/2309.07683"}, {"metadata": {"arXiv": "2309.07864", "Date": "Thu, 14 Sep 2023 17:12:03 ", "Title": "The Rise and Potential of Large Language Model Based Agents: A Survey", "Authors": ["Zhiheng Xi", "Wenxiang Chen", "Xin Guo", "Wei He", "Yiwen Ding", "Boyang Hong", "Ming Zhang", "Junzhe Wang", "Senjie Jin", "Enyu Zhou", "Rui Zheng", "Xiaoran Fan", "Xiao Wang", "Limao Xiong", "Qin Liu", "Yuhao Zhou", "Weiran Wang", "Changhao Jiang", "Yicheng Zou", "Xiangyang Liu", "Zhangyue Yin", "Shihan Dou", "Rongxiang Weng", "Wensen Cheng", "Qi Zhang", "Wenjuan Qin", "Yongyan Zheng", "Xipeng Qiu", "Xuanjing Huan", "Tao Gui"], "Categories": "cs.AI cs.CL", "Comments": ["86 pages", "12 figures"]}, "abstract": "For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many research efforts have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for AI agents. Building upon this, we present a conceptual framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored to suit different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge when they form societies, and the insights they offer for human society. Finally, we discuss a range of key topics and open problems within the field.", "url": "https://arxiv.org/abs/2309.07864"}, {"metadata": {"arXiv": "2309.07390", "Date": "Thu, 14 Sep 2023 02:19:38 ", "Title": "Unleashing the Power of Depth and Pose Estimation Neural Networks by Designing Compatible Endoscopic Images", "Authors": ["Junyang Wu", "Yun Gu"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep learning models have witnessed depth and pose estimation framework on unannotated datasets as a effective pathway to succeed in endoscopic navigation. Most current techniques are dedicated to developing more advanced neural networks to improve the accuracy. However, existing methods ignore the special properties of endoscopic images, resulting in an inability to fully unleash the power of neural networks. In this study, we conduct a detail analysis of the properties of endoscopic images and improve the compatibility of images and neural networks, to unleash the power of current neural networks. First, we introcude the Mask Image Modelling (MIM) module, which inputs partial image information instead of complete image information, allowing the network to recover global information from partial pixel information. This enhances the network' s ability to perceive global information and alleviates the phenomenon of local overfitting in convolutional neural networks due to local artifacts. Second, we propose a lightweight neural network to enhance the endoscopic images, to explicitly improve the compatibility between images and neural networks. Extensive experiments are conducted on the three public datasets and one inhouse dataset, and the proposed modules improve baselines by a large margin. Furthermore, the enhanced images we proposed, which have higher network compatibility, can serve as an effective data augmentation method and they are able to extract more stable feature points in traditional feature point matching tasks and achieve outstanding performance.", "url": "https://arxiv.org/abs/2309.07390"}, {"metadata": {"arXiv": "2309.07425", "Date": "Thu, 14 Sep 2023 04:45:09 ", "Title": "JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation through Self-Attention and Multiscale", "Authors": ["Shuochen Xu and Zhenxin Zhang"], "Categories": "cs.CV cs.AI", "Journal-ref": "ISPRS Annals of the Photogrammetry Remote Sensing and Spatial Information Sciences 2023"}, "abstract": "The semantic understanding of indoor 3D point cloud data is crucial for a range of subsequent applications, including indoor service robots, navigation systems, and digital twin engineering. Global features are crucial for achieving high-quality semantic and instance segmentation of indoor point clouds, as they provide essential long-range context information. To this end, we propose JSMNet, which combines a multi-layer network with a global feature self-attention module to jointly segment three-dimensional point cloud semantics and instances. To better express the characteristics of indoor targets, we have designed a multi-resolution feature adaptive fusion module that takes into account the differences in point cloud density caused by varying scanner distances from the target. Additionally, we propose a framework for joint semantic and instance segmentation by integrating semantic and instance features to achieve superior results. We conduct experiments on S3DIS, which is a large three-dimensional indoor point cloud dataset. Our proposed method is compared against other methods, and the results show that it outperforms existing methods in semantic and instance segmentation and provides better results in target local area segmentation. Specifically, our proposed method outperforms PointNet (Qi et al., 2017a) by 16.0% and 26.3% in terms of semantic segmentation mIoU in S3DIS (Area 5) and instance segmentation mPre, respectively. Additionally, it surpasses ASIS (Wang et al., 2019) by 6.0% and 4.6%, respectively, as well as JSPNet (Chen et al., 2022) by a margin of 3.3% for semantic segmentation mIoU and a slight improvement of 0.3% for instance segmentation mPre.", "url": "https://arxiv.org/abs/2309.07425"}, {"metadata": {"arXiv": "2309.07495", "Date": "Thu, 14 Sep 2023 07:58:31 ", "Title": "HDTR-Net: A Real-Time High-Definition Teeth Restoration Network for Arbitrary Talking Face Generation Methods", "Authors": ["Yongyuan Li", "Xiuyuan Qin", "Chao Liang", "Mingqiang Wei"], "Categories": "cs.CV cs.AI", "Comments": ["15pages", "6 figures", "PRCV2023"]}, "abstract": "Talking Face Generation (TFG) aims to reconstruct facial movements to achieve high natural lip movements from audio and facial features that are under potential connections. Existing TFG methods have made significant advancements to produce natural and realistic images. However, most work rarely takes visual quality into consideration. It is challenging to ensure lip synchronization while avoiding visual quality degradation in cross-modal generation methods. To address this issue, we propose a universal High-Definition Teeth Restoration Network, dubbed HDTR-Net, for arbitrary TFG methods. HDTR-Net can enhance teeth regions at an extremely fast speed while maintaining synchronization, and temporal consistency. In particular, we propose a Fine-Grained Feature Fusion (FGFF) module to effectively capture fine texture feature information around teeth and surrounding regions, and use these features to fine-grain the feature map to enhance the clarity of teeth. Extensive experiments show that our method can be adapted to arbitrary TFG methods without suffering from lip synchronization and frame coherence. Another advantage of HDTR-Net is its real-time generation ability. Also under the condition of high-definition restoration of talking face video synthesis, its inference speed is $300\\%$ faster than the current state-of-the-art face restoration based on super-resolution.", "url": "https://arxiv.org/abs/2309.07495"}, {"metadata": {"arXiv": "2309.07704", "Date": "Thu, 14 Sep 2023 13:29:41 ", "Title": "NutritionVerse: Empirical Study of Various Dietary Intake Estimation Approaches", "Authors": ["Chi-en Amy Tai", "Matthew Keller", "Saeejith Nair", "Yuhao Chen", "Yifan Wu", "Olivia Markham", "Krish Parmar", "Pengcheng Xi", "Heather Keller", "Sharon Kirkpatrick", "Alexander Wong"], "Categories": "cs.CV cs.AI"}, "abstract": "Accurate dietary intake estimation is critical for informing policies and programs to support healthy eating, as malnutrition has been directly linked to decreased quality of life. However self-reporting methods such as food diaries suffer from substantial bias. Other conventional dietary assessment techniques and emerging alternative approaches such as mobile applications incur high time costs and may necessitate trained personnel. Recent work has focused on using computer vision and machine learning to automatically estimate dietary intake from food images, but the lack of comprehensive datasets with diverse viewpoints, modalities and food annotations hinders the accuracy and realism of such methods. To address this limitation, we introduce NutritionVerse-Synth, the first large-scale dataset of 84,984 photorealistic synthetic 2D food images with associated dietary information and multimodal annotations (including depth images, instance masks, and semantic masks). Additionally, we collect a real image dataset, NutritionVerse-Real, containing 889 images of 251 dishes to evaluate realism. Leveraging these novel datasets, we develop and benchmark NutritionVerse, an empirical study of various dietary intake estimation approaches, including indirect segmentation-based and direct prediction networks. We further fine-tune models pretrained on synthetic data with real images to provide insights into the fusion of synthetic and real data. Finally, we release both datasets (NutritionVerse-Synth, NutritionVerse-Real) on https://www.kaggle.com/nutritionverse/datasets as part of an open initiative to accelerate machine learning for dietary sensing.", "url": "https://arxiv.org/abs/2309.07704"}, {"metadata": {"arXiv": "2309.07823", "Date": "Thu, 14 Sep 2023 16:16:57 ", "Title": "Large-scale Weakly Supervised Learning for Road Extraction from Satellite Imagery", "Authors": ["Shiqiao Meng", "Zonglin Di", "Siwei Yang", "Yin Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Automatic road extraction from satellite imagery using deep learning is a viable alternative to traditional manual mapping. Therefore it has received considerable attention recently. However, most of the existing methods are supervised and require pixel-level labeling, which is tedious and error-prone. To make matters worse, the earth has a diverse range of terrain, vegetation, and man-made objects. It is well known that models trained in one area generalize poorly to other areas. Various shooting conditions such as light and angel, as well as different image processing techniques further complicate the issue. It is impractical to develop training data to cover all image styles. This paper proposes to leverage OpenStreetMap road data as weak labels and large scale satellite imagery to pre-train semantic segmentation models. Our extensive experimental results show that the prediction accuracy increases with the amount of the weakly labeled data, as well as the road density in the areas chosen for training. Using as much as 100 times more data than the widely used DeepGlobe road dataset, our model with the D-LinkNet architecture and the ResNet-50 backbone exceeds the top performer of the current DeepGlobe leaderboard. Furthermore, due to large-scale pre-training, our model generalizes much better than those trained with only the curated datasets, implying great application potential.", "url": "https://arxiv.org/abs/2309.07823"}, {"metadata": {"arXiv": "2309.07276", "Date": "Wed, 13 Sep 2023 19:30:53 ", "Title": "Language-Conditioned Observation Models for Visual Object Search", "Authors": ["Thao Nguyen", "Vladislav Hrosinkov", "Eric Rosen", "Stefanie Tellex"], "Categories": "cs.RO cs.AI"}, "abstract": "Object search is a challenging task because when given complex language descriptions (e.g., \"find the white cup on the table\"), the robot must move its camera through the environment and recognize the described object. Previous works map language descriptions to a set of fixed object detectors with predetermined noise models, but these approaches are challenging to scale because new detectors need to be made for each object. In this work, we bridge the gap in realistic object search by posing the search problem as a partially observable Markov decision process (POMDP) where the object detector and visual sensor noise in the observation model is determined by a single Deep Neural Network conditioned on complex language descriptions. We incorporate the neural network's outputs into our language-conditioned observation model (LCOM) to represent dynamically changing sensor noise. With an LCOM, any language description of an object can be used to generate an appropriate object detector and noise model, and training an LCOM only requires readily available supervised image-caption datasets. We empirically evaluate our method by comparing against a state-of-the-art object search algorithm in simulation, and demonstrate that planning with our observation model yields a significantly higher average task completion rate (from 0.46 to 0.66) and more efficient and quicker object search than with a fixed-noise model. We demonstrate our method on a Boston Dynamics Spot robot, enabling it to handle complex natural language object descriptions and efficiently find objects in a room-scale environment.", "url": "https://arxiv.org/abs/2309.07276"}, {"metadata": {"arXiv": "2309.07473", "Date": "Thu, 14 Sep 2023 07:11:58 ", "Title": "Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects", "Authors": ["Chuanruo Ning", "Ruihai Wu", "Haoran Lu", "Kaichun Mo", "Hao Dong"], "Categories": "cs.RO cs.AI"}, "abstract": "Articulated object manipulation is a fundamental yet challenging task in robotics. Due to significant geometric and semantic variations across object categories, previous manipulation models struggle to generalize to novel categories. Few-shot learning is a promising solution for alleviating this issue by allowing robots to perform a few interactions with unseen objects. However, extant approaches often necessitate costly and inefficient test-time interactions with each unseen instance. Recognizing this limitation, we observe that despite their distinct shapes, different categories often share similar local geometries essential for manipulation, such as pullable handles and graspable edges - a factor typically underutilized in previous few-shot learning works. To harness this commonality, we introduce 'Where2Explore', an affordance learning framework that effectively explores novel categories with minimal interactions on a limited number of instances. Our framework explicitly estimates the geometric similarity across different categories, identifying local areas that differ from shapes in the training categories for efficient exploration while concurrently transferring affordance knowledge to similar parts of the objects. Extensive experiments in simulated and real-world environments demonstrate our framework's capacity for efficient few-shot exploration and generalization.", "url": "https://arxiv.org/abs/2309.07473"}, {"metadata": {"arXiv": "2309.07504", "Date": "Thu, 14 Sep 2023 08:15:31 ", "Title": "Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure", "Authors": ["Jiankai Sun", "Shreyas Kousik", "David Fridovich-Keil", "Mac Schwager"], "Categories": "cs.RO cs.AI", "Comments": ["2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)"]}, "abstract": "Connected autonomous vehicles (CAVs) promise to enhance safety, efficiency, and sustainability in urban transportation. However, this is contingent upon a CAV correctly predicting the motion of surrounding agents and planning its own motion safely. Doing so is challenging in complex urban environments due to frequent occlusions and interactions among many agents. One solution is to leverage smart infrastructure to augment a CAV's situational awareness; the present work leverages a recently proposed \"Self-Supervised Traffic Advisor\" (SSTA) framework of smart sensors that teach themselves to generate and broadcast useful video predictions of road users. In this work, SSTA predictions are modified to predict future occupancy instead of raw video, which reduces the data footprint of broadcast predictions. The resulting predictions are used within a planning framework, demonstrating that this design can effectively aid CAV motion planning. A variety of numerical experiments study the key factors that make SSTA outputs useful for practical CAV planning in crowded urban environments.", "url": "https://arxiv.org/abs/2309.07504"}, {"metadata": {"arXiv": "2309.07510", "Date": "Thu, 14 Sep 2023 08:24:32 ", "Title": "Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions", "Authors": ["Kai Cheng", "Ruihai Wu", "Yan Shen", "Chuanruo Ning", "Guanqi Zhan", "Hao Dong"], "Categories": "cs.RO cs.AI cs.CV"}, "abstract": "Perceiving and manipulating 3D articulated objects in diverse environments is essential for home-assistant robots. Recent studies have shown that point-level affordance provides actionable priors for downstream manipulation tasks. However, existing works primarily focus on single-object scenarios with homogeneous agents, overlooking the realistic constraints imposed by the environment and the agent's morphology, e.g., occlusions and physical limitations. In this paper, we propose an environment-aware affordance framework that incorporates both object-level actionable priors and environment constraints. Unlike object-centric affordance approaches, learning environment-aware affordance faces the challenge of combinatorial explosion due to the complexity of various occlusions, characterized by their quantities, geometries, positions and poses. To address this and enhance data efficiency, we introduce a novel contrastive affordance learning framework capable of training on scenes containing a single occluder and generalizing to scenes with complex occluder combinations. Experiments demonstrate the effectiveness of our proposed approach in learning affordance considering environment constraints.", "url": "https://arxiv.org/abs/2309.07510"}, {"metadata": {"arXiv": "2309.07832", "Date": "Thu, 14 Sep 2023 16:21:27 ", "Title": "VAPOR: Holonomic Legged Robot Navigation in Outdoor Vegetation Using Offline Reinforcement Learning", "Authors": ["Kasun Weerakoon", "Adarsh Jagan Sathyamoorthy", "Mohamed Elnoor", "Dinesh Manocha"], "Categories": "cs.RO cs.AI"}, "abstract": "We present VAPOR, a novel method for autonomous legged robot navigation in unstructured, densely vegetated outdoor environments using Offline Reinforcement Learning (RL). Our method trains a novel RL policy from unlabeled data collected in real outdoor vegetation. This policy uses height and intensity-based cost maps derived from 3D LiDAR point clouds, a goal cost map, and processed proprioception data as state inputs, and learns the physical and geometric properties of the surrounding vegetation such as height, density, and solidity/stiffness for navigation. Instead of using end-to-end policy actions, the fully-trained RL policy's Q network is used to evaluate dynamically feasible robot actions generated from a novel adaptive planner capable of navigating through dense narrow passages and preventing entrapment in vegetation such as tall grass and bushes. We demonstrate our method's capabilities on a legged robot in complex outdoor vegetation. We observe an improvement in success rates, a decrease in average power consumption, and decrease in normalized trajectory length compared to both existing end-to-end offline RL and outdoor navigation methods.", "url": "https://arxiv.org/abs/2309.07832"}, {"metadata": {"arXiv": "2309.07172", "Date": "Tue, 12 Sep 2023 17:01:02 ", "Title": "Exploring Large Language Models for Ontology Alignment", "Authors": ["Yuan He", "Jiaoyan Chen", "Hang Dong", "Ian Horrocks"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["Accepted at ISWC 2023 (Posters and Demos)"]}, "abstract": "This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design.", "url": "https://arxiv.org/abs/2309.07172"}, {"metadata": {"arXiv": "2309.07398", "Date": "Thu, 14 Sep 2023 02:57:48 ", "Title": "Semantic Adversarial Attacks via Diffusion Models", "Authors": ["Chenan Wang", "Jinhao Duan", "Chaowei Xiao", "Edward Kim", "Matthew Stamm", "Kaidi Xu"], "Categories": "cs.CV cs.AI cs.CR cs.LG", "Comments": ["To appear in BMVC 2023"]}, "abstract": "Traditional adversarial attacks concentrate on manipulating clean examples in the pixel space by adding adversarial perturbations. By contrast, semantic adversarial attacks focus on changing semantic attributes of clean examples, such as color, context, and features, which are more feasible in the real world. In this paper, we propose a framework to quickly generate a semantic adversarial attack by leveraging recent diffusion models since semantic information is included in the latent space of well-trained diffusion models. Then there are two variants of this framework: 1) the Semantic Transformation (ST) approach fine-tunes the latent space of the generated image and/or the diffusion model itself; 2) the Latent Masking (LM) approach masks the latent space with another target image and local backpropagation-based interpretation methods. Additionally, the ST approach can be applied in either white-box or black-box settings. Extensive experiments are conducted on CelebA-HQ and AFHQ datasets, and our framework demonstrates great fidelity, generalizability, and transferability compared to other baselines. Our approaches achieve approximately 100% attack success rate in multiple settings with the best FID as 36.61. Code is available at https://github.com/steven202/semantic_adv_via_dm.", "url": "https://arxiv.org/abs/2309.07398"}, {"metadata": {"arXiv": "2309.07760", "Date": "Thu, 14 Sep 2023 14:48:01 ", "Title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder", "Authors": ["Anh Pham Thi Minh"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages excluding References and Appendix"], "ACM-class": "I.4.0"}, "abstract": "Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks. However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions. This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming. To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens. While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset. In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to unseen classes while maintaining the capacity to learn Base classes. Instead of directly optimizing the prompts, PRE employs a prompt encoder to reparameterize the input prompt embeddings, enhancing the exploration of task-specific knowledge from few-shot samples. Experiments and extensive ablation studies on 8 benchmarks demonstrate that our approach is an efficient method for prompt learning. Specifically, PRE achieves a notable enhancement of 5.60% in average accuracy on New classes and 3% in Harmonic mean compared to CoOp in the 16-shot setting, all achieved within a good training time.", "url": "https://arxiv.org/abs/2309.07760"}, {"metadata": {"arXiv": "2309.07808", "Date": "Thu, 14 Sep 2023 15:54:56 ", "Title": "What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving", "Authors": ["Hongkuan Zhou", "Aifen Sui", "Wei Cao", "Letian Shi"], "Categories": "cs.CV cs.AI cs.LG cs.RO", "Comments": ["8 pages", "2 figures"]}, "abstract": "More research attention has recently been given to end-to-end autonomous driving technologies where the entire driving pipeline is replaced with a single neural network because of its simpler structure and faster inference time. Despite this appealing approach largely reducing the components in driving pipeline, its simplicity also leads to interpretability problems and safety issues arXiv:2003.06404. The trained policy is not always compliant with the traffic rules and it is also hard to discover the reason for the misbehavior because of the lack of intermediate outputs. Meanwhile, Sensors are also critical to autonomous driving's security and feasibility to perceive the surrounding environment under complex driving scenarios. In this paper, we proposed P-CSG, a novel penalty-based imitation learning approach with cross semantics generation sensor fusion technologies to increase the overall performance of End-to-End Autonomous Driving. We conducted an assessment of our model's performance using the Town 05 Long benchmark, achieving an impressive driving score improvement of over 15%. Furthermore, we conducted robustness evaluations against adversarial attacks like FGSM and Dot attacks, revealing a substantial increase in robustness compared to baseline models.More detailed information, such as code-based resources, ablation studies and videos can be found at https://hk-zh.github.io/p-csg-plus.", "url": "https://arxiv.org/abs/2309.07808"}, {"metadata": {"arXiv": "2309.07168", "Date": "Tue, 12 Sep 2023 06:53:11 ", "Title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis", "Authors": ["Mehdi Zadem (LIX", "U2IS)", "Sergio Mover (LIX)", "Sao Mai Nguyen (U2IS", "Flowers", "IMT Atlantique - INFO", "Lab-STICC_RAMBO)"], "Categories": "cs.LG cs.AI cs.FL cs.RO", "Journal-ref": "Intrinsically Motivated Open-ended Learning IMOL 2023, Sep 2023, Paris, France"}, "abstract": "Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this work, we propose a developmental mechanism for subgoal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We create a HRL algorithm that gradually learns this representation along with the policies and evaluate it on navigation tasks to show the learned representation is interpretable and results in data efficiency.", "url": "https://arxiv.org/abs/2309.07168"}, {"metadata": {"arXiv": "2309.07174", "Date": "Tue, 12 Sep 2023 19:48:52 ", "Title": "HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting", "Authors": ["Shouwei Gao", "Meiyan Gao", "Yuepeng Li", "Wenqian Dong"], "Categories": "cs.LG cs.AI physics.ao-ph", "Comments": ["This paper includes 7 pages and 8 figures. And we submitted it up to the SC23 workshop. This is only a preprinting"]}, "abstract": "Hurricanes present major challenges in the U.S. due to their devastating impacts. Mitigating these risks is important, and the insurance industry is central in this effort, using intricate statistical models for risk assessment. However, these models often neglect key temporal and spatial hurricane patterns and are limited by data scarcity. This study introduces a refined approach combining the ARIMA model and K-MEANS to better capture hurricane trends, and an Autoencoder for enhanced hurricane simulations. Our experiments show that this hybrid methodology effectively simulate historical hurricane behaviors while providing detailed projections of potential future trajectories and intensities. Moreover, by leveraging a comprehensive yet selective dataset, our simulations enrich the current understanding of hurricane patterns and offer actionable insights for risk management strategies.", "url": "https://arxiv.org/abs/2309.07174"}, {"metadata": {"arXiv": "2309.07196", "Date": "Wed, 13 Sep 2023 13:57:21 ", "Title": "Attention-based Dynamic Graph Convolutional Recurrent Neural Network for Traffic Flow Prediction in Highway Transportation", "Authors": ["Tianpu Zhang", "Weilong Ding", "Mengda Xing"], "Categories": "cs.LG cs.AI cs.GR"}, "abstract": "As one of the important tools for spatial feature extraction, graph convolution has been applied in a wide range of fields such as traffic flow prediction. However, current popular works of graph convolution cannot guarantee spatio-temporal consistency in a long period. The ignorance of correlational dynamics, convolutional locality and temporal comprehensiveness would limit predictive accuracy. In this paper, a novel Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve traffic flow prediction in highway transportation. Three temporal resolutions of data sequence are effectively integrated by self-attention to extract characteristics; multi-dynamic graphs and their weights are dynamically created to compliantly combine the varying characteristics; a dedicated gated kernel emphasizing highly relative nodes is introduced on these complete graphs to reduce overfitting for graph convolution operations. Experiments on two public datasets show our work better than state-of-the-art baselines, and case studies of a real Web system prove practical benefit in highway transportation.", "url": "https://arxiv.org/abs/2309.07196"}, {"metadata": {"arXiv": "2309.07200", "Date": "Wed, 13 Sep 2023 15:59:14 ", "Title": "Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck", "Authors": ["Marco Federici", "Patrick Forr\\'e", "Ryota Tomioka", "Bastiaan S. Veeling"], "Categories": "cs.LG cs.AI cs.IT math.IT", "Comments": ["10 pages", "14 figures"]}, "abstract": "Markov processes are widely used mathematical models for describing dynamic systems in various fields. However, accurately simulating large-scale systems at long time scales is computationally expensive due to the short time steps required for accurate integration. In this paper, we introduce an inference process that maps complex systems into a simplified representational space and models large jumps in time. To achieve this, we propose Time-lagged Information Bottleneck (T-IB), a principled objective rooted in information theory, which aims to capture relevant temporal features while discarding high-frequency information to simplify the simulation task and minimize the inference error. Our experiments demonstrate that T-IB learns information-optimal representations for accurately modeling the statistical properties and dynamics of the original process at a selected time lag, outperforming existing time-lagged dimensionality reduction methods.", "url": "https://arxiv.org/abs/2309.07200"}, {"metadata": {"arXiv": "2309.07235", "Date": "Wed, 13 Sep 2023 18:15:58 ", "Title": "Autotuning Apache TVM-based Scientific Applications Using Bayesian Optimization", "Authors": ["Xingfu Wu", "Praveen Paramasivam", "Valerie Taylor"], "Categories": "cs.LG cs.AI cs.NA math.NA"}, "abstract": "Apache TVM (Tensor Virtual Machine), an open source machine learning compiler framework designed to optimize computations across various hardware platforms, provides an opportunity to improve the performance of dense matrix factorizations such as LU (Lower Upper) decomposition and Cholesky decomposition on GPUs and AI (Artificial Intelligence) accelerators. In this paper, we propose a new TVM autotuning framework using Bayesian Optimization and use the TVM tensor expression language to implement linear algebra kernels such as LU, Cholesky, and 3mm. We use these scientific computation kernels to evaluate the effectiveness of our methods on a GPU cluster, called Swing, at Argonne National Laboratory. We compare the proposed autotuning framework with the TVM autotuning framework AutoTVM with four tuners and find that our framework outperforms AutoTVM in most cases.", "url": "https://arxiv.org/abs/2309.07235"}, {"metadata": {"arXiv": "2309.07332", "Date": "Wed, 13 Sep 2023 22:04:50 ", "Title": "Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining", "Authors": ["Xianghao Zhan", "Qinmei Xu", "Yuanning Zheng", "Guangming Lu", "Olivier Gevaert"], "Categories": "cs.LG cs.AI cs.CV q-bio.GN q-bio.QM stat.AP stat.ML"}, "abstract": "Accurately labeling biomedical data presents a challenge. Traditional semi-supervised learning methods often under-utilize available unlabeled data. To address this, we propose a novel reliability-based training data cleaning method employing inductive conformal prediction (ICP). This method capitalizes on a small set of accurately labeled training data and leverages ICP-calculated reliability metrics to rectify mislabeled data and outliers within vast quantities of noisy training data. The efficacy of the method is validated across three classification tasks within distinct modalities: filtering drug-induced-liver-injury (DILI) literature with title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced through label permutation. Results show significant enhancements in classification performance: accuracy enhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC enhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and accuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing experiments (up to 74.6% and 89.0%). Our method offers the potential to substantially boost classification performance in multi-modal biomedical machine learning tasks. Importantly, it accomplishes this without necessitating an excessive volume of meticulously curated training data.", "url": "https://arxiv.org/abs/2309.07332"}, {"metadata": {"arXiv": "2309.07364", "Date": "Thu, 14 Sep 2023 00:40:07 ", "Title": "Hodge-Aware Contrastive Learning", "Authors": ["Alexander M\\\"ollers", "Alexander Immer", "Vincent Fortuin", "Elvin Isufi"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["4 pages", "2 figures"]}, "abstract": "Simplicial complexes prove effective in modeling data with multiway dependencies, such as data defined along the edges of networks or within other higher-order structures. Their spectrum can be decomposed into three interpretable subspaces via the Hodge decomposition, resulting foundational in numerous applications. We leverage this decomposition to develop a contrastive self-supervised learning approach for processing simplicial data and generating embeddings that encapsulate specific spectral information.Specifically, we encode the pertinent data invariances through simplicial neural networks and devise augmentations that yield positive contrastive examples with suitable spectral properties for downstream tasks. Additionally, we reweight the significance of negative examples in the contrastive loss, considering the similarity of their Hodge components to the anchor. By encouraging a stronger separation among less similar instances, we obtain an embedding space that reflects the spectral properties of the data. The numerical results on two standard edge flow classification tasks show a superior performance even when compared to supervised learning techniques. Our findings underscore the importance of adopting a spectral perspective for contrastive learning with higher-order data.", "url": "https://arxiv.org/abs/2309.07364"}, {"metadata": {"arXiv": "2309.07578", "Date": "Thu, 14 Sep 2023 10:22:33 ", "Title": "Equivariant Data Augmentation for Generalization in Offline Reinforcement Learning", "Authors": ["Cristina Pinneri", "Sarah Bechtle", "Markus Wulfmeier", "Arunkumar Byravan", "Jingwei Zhang", "William F. Whitney", "Martin Riedmiller"], "Categories": "cs.LG cs.AI cs.RO"}, "abstract": "We present a novel approach to address the challenge of generalization in offline reinforcement learning (RL), where the agent learns from a fixed dataset without any additional interaction with the environment. Specifically, we aim to improve the agent's ability to generalize to out-of-distribution goals. To achieve this, we propose to learn a dynamics model and check if it is equivariant with respect to a fixed type of transformation, namely translations in the state space. We then use an entropy regularizer to increase the equivariant set and augment the dataset with the resulting transformed samples. Finally, we learn a new policy offline based on the augmented dataset, with an off-the-shelf offline RL algorithm. Our experimental results demonstrate that our approach can greatly improve the test performance of the policy on the considered environments.", "url": "https://arxiv.org/abs/2309.07578"}, {"metadata": {"arXiv": "2309.07593", "Date": "Thu, 14 Sep 2023 10:53:36 ", "Title": "Statistically Valid Variable Importance Assessment through Conditional Permutations", "Authors": ["Ahmad Chamma (1 and 2 and 3)", "Denis A. Engemann (4) and Bertrand Thirion (1 and 2 and 3) ((1) Inria", "(2) Universite Paris Saclay", "(3) CEA", "(4) Roche Pharma Research and Early Development", "Neuroscience and Rare Diseases", "Roche Innovation Center Basel", "F. Hoffmann-La Roche Ltd.", "Basel", "Switzerland)"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\\textit{CPI}$ consistently showed top accuracy across benchmarks. An empirical benchmark on real-world data analysis in a large-scale medical dataset showed that $\\textit{CPI}$ provides a more parsimonious selection of statistically significant variables. Our results suggest that $\\textit{CPI}$ can be readily used as drop-in replacement for permutation-based methods.", "url": "https://arxiv.org/abs/2309.07593"}, {"metadata": {"arXiv": "2309.07610", "Date": "Thu, 14 Sep 2023 11:18:26 ", "Title": "Feature Engineering in Learning-to-Rank for Community Question Answering Task", "Authors": ["Nafis Sajid", "Md Rashidul Hasan", "Muhammad Ibrahim"], "Categories": "cs.LG cs.AI cs.IR", "Comments": ["20 pages"]}, "abstract": "Community question answering (CQA) forums are Internet-based platforms where users ask questions about a topic and other expert users try to provide solutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer, StackExchange exist with a lot of user-generated data. These data are leveraged in automated CQA ranking systems where similar questions (and answers) are presented in response to the query of the user. In this work, we empirically investigate a few aspects of this domain. Firstly, in addition to traditional features like TF-IDF, BM25 etc., we introduce a BERT-based feature that captures the semantic similarity between the question and answer. Secondly, most of the existing research works have focused on features extracted only from the question part; features extracted from answers have not been explored extensively. We combine both types of features in a linear fashion. Thirdly, using our proposed concepts, we conduct an empirical investigation with different rank-learning algorithms, some of which have not been used so far in CQA domain. On three standard CQA datasets, our proposed framework achieves state-of-the-art performance. We also analyze importance of the features we use in our investigation. This work is expected to guide the practitioners to select a better set of features for the CQA retrieval task.", "url": "https://arxiv.org/abs/2309.07610"}, {"metadata": {"arXiv": "2309.07666", "Date": "Thu, 14 Sep 2023 12:29:41 ", "Title": "Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning", "Authors": ["Eduardo Fernandes Montesuma", "Fred Ngol\\`e Mboula", "Antoine Souloumiac"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["7 pages,4 figures"]}, "abstract": "In this paper, we consider the intersection of two problems in machine learning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD). On the one hand, the first considers adapting multiple heterogeneous labeled source domains to an unlabeled target domain. On the other hand, the second attacks the problem of synthesizing a small summary containing all the information about the datasets. We thus consider a new problem called MSDA-DD. To solve it, we adapt previous works in the MSDA literature, such as Wasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD method Distribution Matching. We thoroughly experiment with this novel problem on four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous Stirred Tank Reactor, and Case Western Reserve University), where we show that, even with as little as 1 sample per class, one achieves state-of-the-art adaptation performance.", "url": "https://arxiv.org/abs/2309.07666"}, {"metadata": {"arXiv": "2309.07670", "Date": "Thu, 14 Sep 2023 12:34:22 ", "Title": "Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation", "Authors": ["Fabiola Espinosa Castellon", "Eduardo Fernandes Montesuma", "Fred Ngol\\`e Mboula", "Aur\\'elien Mayoue", "Antoine Souloumiac", "C\\'edric Gouy-Pallier"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages,2 figures"]}, "abstract": "In this article, we propose an approach for federated domain adaptation, a setting where distributional shift exists among clients and some have unlabeled data. The proposed framework, FedDaDiL, tackles the resulting challenge through dictionary learning of empirical distributions. In our setting, clients' distributions represent particular domains, and FedDaDiL collectively trains a federated dictionary of empirical distributions. In particular, we build upon the Dataset Dictionary Learning framework by designing collaborative communication protocols and aggregation operations. The chosen protocols keep clients' data private, thus enhancing overall privacy compared to its centralized counterpart. We empirically demonstrate that our approach successfully generates labeled data on the target domain with extensive experiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks. Furthermore, we compare our method to its centralized counterpart and other benchmarks in federated domain adaptation.", "url": "https://arxiv.org/abs/2309.07670"}, {"metadata": {"arXiv": "2309.07684", "Date": "Thu, 14 Sep 2023 12:58:40 ", "Title": "deepFDEnet: A Novel Neural Network Architecture for Solving Fractional Differential Equations", "Authors": ["Ali Nosrati Firoozsalari", "Hassan Dana Mazraeh", "Alireza Afzal Aghaei", "and Kourosh Parand"], "Categories": "cs.LG cs.AI cs.NA math.NA"}, "abstract": "The primary goal of this research is to propose a novel architecture for a deep neural network that can solve fractional differential equations accurately. A Gaussian integration rule and a $L_1$ discretization technique are used in the proposed design. In each equation, a deep neural network is used to approximate the unknown function. Three forms of fractional differential equations have been examined to highlight the method's versatility: a fractional ordinary differential equation, a fractional order integrodifferential equation, and a fractional order partial differential equation. The results show that the proposed architecture solves different forms of fractional differential equations with excellent precision.", "url": "https://arxiv.org/abs/2309.07684"}, {"metadata": {"arXiv": "2309.07867", "Date": "Thu, 14 Sep 2023 17:14:26 ", "Title": "Beta Diffusion", "Authors": ["Mingyuan Zhou and Tianqi Chen and Zhendong Wang and Huangjie Zheng"], "Categories": "cs.LG cs.AI stat.CO stat.ME stat.ML"}, "abstract": "We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them.", "url": "https://arxiv.org/abs/2309.07867"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.13069", "Date": "Mon, 24 Jul 2023 18:50:49 ", "Title": "General-Purpose Multi-Modal OOD Detection Framework", "Authors": ["Viet Duong", "Qiong Wu", "Zhengyi Zhou", "Eric Zavesky", "Jiahe Chen", "Xiangzhou Liu", "Wen-Ling Hsu", "Huajie Shao"], "Categories": "cs.CV cs.LG"}, "abstract": "Out-of-distribution (OOD) detection identifies test samples that differ from the training data, which is critical to ensuring the safety and reliability of machine learning (ML) systems. While a plethora of methods have been developed to detect uni-modal OOD samples, only a few have focused on multi-modal OOD detection. Current contrastive learning-based methods primarily study multi-modal OOD detection in a scenario where both a given image and its corresponding textual description come from a new domain. However, real-world deployments of ML systems may face more anomaly scenarios caused by multiple factors like sensor faults, bad weather, and environmental changes. Hence, the goal of this work is to simultaneously detect from multiple different OOD scenarios in a fine-grained manner. To reach this goal, we propose a general-purpose weakly-supervised OOD detection framework, called WOOD, that combines a binary classifier and a contrastive learning component to reap the benefits of both. In order to better distinguish the latent representations of in-distribution (ID) and OOD samples, we adopt the Hinge loss to constrain their similarity. Furthermore, we develop a new scoring metric to integrate the prediction results from both the binary classifier and contrastive learning for identifying OOD samples. We evaluate the proposed WOOD model on multiple real-world datasets, and the experimental results demonstrate that the WOOD model outperforms the state-of-the-art methods for multi-modal OOD detection. Importantly, our approach is able to achieve high accuracy in OOD detection in three different OOD scenarios simultaneously. The source code will be made publicly available upon publication.", "url": "https://arxiv.org/abs/2307.13069"}, {"metadata": {"arXiv": "2307.13136", "Date": "Mon, 24 Jul 2023 21:29:48 ", "Title": "Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?", "Authors": ["Megan Richards", "Polina Kirichenko", "Diane Bouchacourt", "Mark Ibrahim"], "Categories": "cs.CV cs.LG"}, "abstract": "For more than a decade, researchers have measured progress in object recognition on ImageNet-based generalization benchmarks such as ImageNet-A, -C, and -R. Recent advances in foundation models, trained on orders of magnitude more data, have begun to saturate these standard benchmarks, but remain brittle in practice. This suggests standard benchmarks, which tend to focus on predefined or synthetic changes, may not be sufficient for measuring real world generalization. Consequently, we propose studying generalization across geography as a more realistic measure of progress using two datasets of objects from households across the globe. We conduct an extensive empirical evaluation of progress across nearly 100 vision models up to most recent foundation models. We first identify a progress gap between standard benchmarks and real-world, geographical shifts: progress on ImageNet results in up to 2.5x more progress on standard generalization benchmarks than real-world distribution shifts. Second, we study model generalization across geographies by measuring the disparities in performance across regions, a more fine-grained measure of real world generalization. We observe all models have large geographic disparities, even foundation CLIP models, with differences of 7-20% in accuracy between regions. Counter to modern intuition, we discover progress on standard benchmarks fails to improve geographic disparities and often exacerbates them: geographic disparities between the least performant models and today's best models have more than tripled. Our results suggest scaling alone is insufficient for consistent robustness to real-world distribution shifts. Finally, we highlight in early experiments how simple last layer retraining on more representative, curated data can complement scaling as a promising direction of future work, reducing geographic disparity on both benchmarks by over two-thirds.", "url": "https://arxiv.org/abs/2307.13136"}, {"metadata": {"arXiv": "2307.13425", "Date": "Tue, 25 Jul 2023 11:45:28 ", "Title": "A signal processing interpretation of noise-reduction convolutional neural networks", "Authors": ["Luis A. Zavala-Mondrag\\'on", "Peter H.N. de With", "Fons van der Sommen"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["This article is currently accepted in IEEE Signal Processing Magazine (SPM)"]}, "abstract": "Encoding-decoding CNNs play a central role in data-driven noise reduction and can be found within numerous deep-learning algorithms. However, the development of these CNN architectures is often done in ad-hoc fashion and theoretical underpinnings for important design choices is generally lacking. Up to this moment there are different existing relevant works that strive to explain the internal operation of these CNNs. Still, these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience. In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework. By connecting basic principles from signal processing to the field of deep learning, this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures.", "url": "https://arxiv.org/abs/2307.13425"}, {"metadata": {"arXiv": "2307.13539", "Date": "Tue, 25 Jul 2023 14:40:11 ", "Title": "Model Calibration in Dense Classification with Adaptive Label Perturbation", "Authors": ["Jiawei Liu", "Changkun Ye", "Shan Wang", "Ruikai Cui", "Jing Zhang", "Kaihao Zhang", "Nick Barnes"], "Categories": "cs.CV cs.LG"}, "abstract": "For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making. Existing dense binary classification models are prone to being over-confident. To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates. ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information. It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of the target training label. Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data. The code is available on https://github.com/Carlisle-Liu/ASLP.", "url": "https://arxiv.org/abs/2307.13539"}, {"metadata": {"arXiv": "2307.13055", "Date": "Mon, 24 Jul 2023 18:05:22 ", "Title": "MARIO: Model Agnostic Recipe for Improving OOD Generalization of Graph Contrastive Learning", "Authors": ["Yun Zhu", "Haizhou Shi", "Zhenshuo Zhang", "Siliang Tang"], "Categories": "cs.LG", "Comments": ["20 pages", "15 figures"]}, "abstract": "In this work, we investigate the problem of out-of-distribution (OOD) generalization for unsupervised learning methods on graph data. This scenario is particularly challenging because graph neural networks (GNNs) have been shown to be sensitive to distributional shifts, even when labels are available. To address this challenge, we propose a \\underline{M}odel-\\underline{A}gnostic \\underline{R}ecipe for \\underline{I}mproving \\underline{O}OD generalizability of unsupervised graph contrastive learning methods, which we refer to as MARIO. MARIO introduces two principles aimed at developing distributional-shift-robust graph contrastive methods to overcome the limitations of existing frameworks: (i) Information Bottleneck (IB) principle for achieving generalizable representations and (ii) Invariant principle that incorporates adversarial data augmentation to obtain invariant representations. To the best of our knowledge, this is the first work that investigates the OOD generalization problem of graph contrastive learning, with a specific focus on node-level tasks. Through extensive experiments, we demonstrate that our method achieves state-of-the-art performance on the OOD test set, while maintaining comparable performance on the in-distribution test set when compared to existing approaches. The source code for our method can be found at: https://github.com/ZhuYun97/MARIO", "url": "https://arxiv.org/abs/2307.13055"}, {"metadata": {"arXiv": "2307.13100", "Date": "Mon, 24 Jul 2023 19:41:19 ", "Title": "Label Noise: Correcting a Correction", "Authors": ["William Toner", "Amos Storkey"], "Categories": "cs.LG"}, "abstract": "Training neural network classifiers on datasets with label noise poses a risk of overfitting them to the noisy labels. To address this issue, researchers have explored alternative loss functions that aim to be more robust. However, many of these alternatives are heuristic in nature and still vulnerable to overfitting or underfitting. In this work, we propose a more direct approach to tackling overfitting caused by label noise. We observe that the presence of label noise implies a lower bound on the noisy generalised risk. Building upon this observation, we propose imposing a lower bound on the empirical risk during training to mitigate overfitting. Our main contribution is providing theoretical results that yield explicit, easily computable bounds on the minimum achievable noisy risk for different loss functions. We empirically demonstrate that using these bounds significantly enhances robustness in various settings, with virtually no additional computational cost.", "url": "https://arxiv.org/abs/2307.13100"}, {"metadata": {"arXiv": "2307.13158", "Date": "Mon, 24 Jul 2023 22:52:02 ", "Title": "Multi-UAV Speed Control with Collision Avoidance and Handover-aware Cell Association: DRL with Action Branching", "Authors": ["Zijiang Yan", "Wael Jaafar", "Bassant Selim", "Hina Tabassum"], "Categories": "cs.LG cs.RO cs.SY eess.SY"}, "abstract": "This paper presents a deep reinforcement learning solution for optimizing multi-UAV cell-association decisions and their moving velocity on a 3D aerial highway. The objective is to enhance transportation and communication performance, including collision avoidance, connectivity, and handovers. The problem is formulated as a Markov decision process (MDP) with UAVs' states defined by velocities and communication data rates. We propose a neural architecture with a shared decision module and multiple network branches, each dedicated to a specific action dimension in a 2D transportation-communication space. This design efficiently handles the multi-dimensional action space, allowing independence for individual action dimensions. We introduce two models, Branching Dueling Q-Network (BDQ) and Branching Dueling Double Deep Q-Network (Dueling DDQN), to demonstrate the approach. Simulation results show a significant improvement of 18.32% compared to existing benchmarks.", "url": "https://arxiv.org/abs/2307.13158"}, {"metadata": {"arXiv": "2307.13178", "Date": "Mon, 24 Jul 2023 23:57:29 ", "Title": "Evaluating the reliability of automatically generated pedestrian and bicycle crash surrogates", "Authors": ["Agnimitra Sengupta", "S. Ilgin Guler", "Vikash V. Gayah", "Shannon Warchol"], "Categories": "cs.LG cs.CY"}, "abstract": "Vulnerable road users (VRUs), such as pedestrians and bicyclists, are at a higher risk of being involved in crashes with motor vehicles, and crashes involving VRUs also are more likely to result in severe injuries or fatalities. Signalized intersections are a major safety concern for VRUs due to their complex and dynamic nature, highlighting the need to understand how these road users interact with motor vehicles and deploy evidence-based countermeasures to improve safety performance. Crashes involving VRUs are relatively infrequent, making it difficult to understand the underlying contributing factors. An alternative is to identify and use conflicts between VRUs and motorized vehicles as a surrogate for safety performance. Automatically detecting these conflicts using a video-based systems is a crucial step in developing smart infrastructure to enhance VRU safety. The Pennsylvania Department of Transportation conducted a study using video-based event monitoring system to assess VRU and motor vehicle interactions at fifteen signalized intersections across Pennsylvania to improve VRU safety performance. This research builds on that study to assess the reliability of automatically generated surrogates in predicting confirmed conflicts using advanced data-driven models. The surrogate data used for analysis include automatically collectable variables such as vehicular and VRU speeds, movements, post-encroachment time, in addition to manually collected variables like signal states, lighting, and weather conditions. The findings highlight the varying importance of specific surrogates in predicting true conflicts, some being more informative than others. The findings can assist transportation agencies to collect the right types of data to help prioritize infrastructure investments, such as bike lanes and crosswalks, and evaluate their effectiveness.", "url": "https://arxiv.org/abs/2307.13178"}, {"metadata": {"arXiv": "2307.13181", "Date": "Tue, 25 Jul 2023 00:01:10 ", "Title": "Neural Memory Decoding with EEG Data and Representation Learning", "Authors": ["Glenn Bruns", "Michael Haidar", "and Federico Rubino"], "Categories": "cs.LG q-bio.NC", "Comments": ["18 pages", "18 figures"], "ACM-class": "H.3.3; I.2.1; I.2.6; J.3"}, "abstract": "We describe a method for the neural decoding of memory from EEG data. Using this method, a concept being recalled can be identified from an EEG trace with an average top-1 accuracy of about 78.4% (chance 4%). The method employs deep representation learning with supervised contrastive loss to map an EEG recording of brain activity to a low-dimensional space. Because representation learning is used, concepts can be identified even if they do not appear in the training data set. However, reference EEG data must exist for each such concept. We also show an application of the method to the problem of information retrieval. In neural information retrieval, EEG data is captured while a user recalls the contents of a document, and a list of links to predicted documents is produced.", "url": "https://arxiv.org/abs/2307.13181"}, {"metadata": {"arXiv": "2307.13206", "Date": "Tue, 25 Jul 2023 02:11:41 ", "Title": "Transferability of Graph Neural Networks using Graphon and Sampling Theories", "Authors": ["A. Martina Neuman", "Jason J. Bramburger"], "Categories": "cs.LG cs.SI"}, "abstract": "Graph neural networks (GNNs) have become powerful tools for processing graph-based information in various domains. A desirable property of GNNs is transferability, where a trained network can swap in information from a different graph without retraining and retain its accuracy. A recent method of capturing transferability of GNNs is through the use of graphons, which are symmetric, measurable functions representing the limit of large dense graphs. In this work, we contribute to the application of graphons to GNNs by presenting an explicit two-layer graphon neural network (WNN) architecture. We prove its ability to approximate bandlimited signals within a specified error tolerance using a minimal number of network weights. We then leverage this result, to establish the transferability of an explicit two-layer GNN over all sufficiently large graphs in a sequence converging to a graphon. Our work addresses transferability between both deterministic weighted graphs and simple random graphs and overcomes issues related to the curse of dimensionality that arise in other GNN results. The proposed WNN and GNN architectures offer practical solutions for handling graph data of varying sizes while maintaining performance guarantees without extensive retraining.", "url": "https://arxiv.org/abs/2307.13206"}, {"metadata": {"arXiv": "2307.13231", "Date": "Tue, 25 Jul 2023 03:45:56 ", "Title": "Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering", "Authors": ["Ce Feng", "Nuo Xu", "Wujie Wen", "Parv Venkitasubramaniam", "Caiwen Ding"], "Categories": "cs.LG cs.CR cs.CY", "Comments": ["Accepted in 2023 IEEE Symposium on Security and Privacy (SP)"], "DOI": "10.1109/SP46215.2023.00171"}, "abstract": "Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD). DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost. In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility. We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers. In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility. Through comprehensive experiments, we study and provide guidelines to implement Spectral-DP deep learning on benchmark datasets. In comparison with state-of-the-art DP-SGD based approaches, Spectral-DP is shown to have uniformly better utility performance in both training from scratch and transfer learning settings.", "url": "https://arxiv.org/abs/2307.13231"}, {"metadata": {"arXiv": "2307.13304", "Date": "Tue, 25 Jul 2023 07:44:06 ", "Title": "QuIP: 2-Bit Quantization of Large Language Models With Guarantees", "Authors": ["Jerry Chee", "Yaohui Cai", "Volodymyr Kuleshov", "Christopher De Sa"], "Categories": "cs.LG"}, "abstract": "This work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. Our code can be found at https://github.com/jerry-chee/QuIP .", "url": "https://arxiv.org/abs/2307.13304"}, {"metadata": {"arXiv": "2307.13333", "Date": "Tue, 25 Jul 2023 08:45:41 ", "Title": "Feature Importance Measurement based on Decision Tree Sampling", "Authors": ["Chao Huang", "Diptesh Das", "Koji Tsuda"], "Categories": "cs.LG"}, "abstract": "Random forest is effective for prediction tasks but the randomness of tree generation hinders interpretability in feature importance analysis. To address this, we proposed DT-Sampler, a SAT-based method for measuring feature importance in tree-based model. Our method has fewer parameters than random forest and provides higher interpretability and stability for the analysis in real-world problems. An implementation of DT-Sampler is available at https://github.com/tsudalab/DT-sampler.", "url": "https://arxiv.org/abs/2307.13333"}, {"metadata": {"arXiv": "2307.13352", "Date": "Tue, 25 Jul 2023 09:14:45 ", "Title": "High Dimensional Distributed Gradient Descent with Arbitrary Number of Byzantine Attackers", "Authors": ["Puning Zhao", "Zhiguo Wan"], "Categories": "cs.LG"}, "abstract": "Robust distributed learning with Byzantine failures has attracted extensive research interests in recent years. However, most of existing methods suffer from curse of dimensionality, which is increasingly serious with the growing complexity of modern machine learning models. In this paper, we design a new method that is suitable for high dimensional problems, under arbitrary number of Byzantine attackers. The core of our design is a direct high dimensional semi-verified mean estimation method. Our idea is to identify a subspace first. The components of mean value perpendicular to this subspace can be estimated via gradient vectors uploaded from worker machines, while the components within this subspace are estimated using auxiliary dataset. We then use our new method as the aggregator of distributed learning problems. Our theoretical analysis shows that the new method has minimax optimal statistical rates. In particular, the dependence on dimensionality is significantly improved compared with previous works.", "url": "https://arxiv.org/abs/2307.13352"}, {"metadata": {"arXiv": "2307.13371", "Date": "Tue, 25 Jul 2023 09:45:47 ", "Title": "Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation", "Authors": ["Fengxue Zhang", "Jialin Song", "James Bowden", "Alexander Ladd", "Yisong Yue", "Thomas A. Desautels", "Yuxin Chen"], "Categories": "cs.LG stat.ML"}, "abstract": "We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.", "url": "https://arxiv.org/abs/2307.13371"}, {"metadata": {"arXiv": "2307.13372", "Date": "Tue, 25 Jul 2023 09:46:02 ", "Title": "Submodular Reinforcement Learning", "Authors": ["Manish Prajapat", "Mojm\\'ir Mutn\\'y", "Melanie N. Zeilinger", "Andreas Krause"], "Categories": "cs.LG"}, "abstract": "In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\\textit{independent}$ of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose $\\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.", "url": "https://arxiv.org/abs/2307.13372"}, {"metadata": {"arXiv": "2307.13381", "Date": "Tue, 25 Jul 2023 10:04:33 ", "Title": "Scaff-PD: Communication Efficient Fair and Robust Federated Learning", "Authors": ["Yaodong Yu and Sai Praneeth Karimireddy and Yi Ma and Michael I. Jordan"], "Categories": "cs.LG cs.DC math.OC stat.ML", "MSC-class": "68W40, 68W15, 90C25, 90C06", "ACM-class": "G.1.6; F.2.1; E.4"}, "abstract": "We present Scaff-PD, a fast and communication-efficient algorithm for distributionally robust federated learning. Our approach improves fairness by optimizing a family of distributionally robust objectives tailored to heterogeneous clients. We leverage the special structure of these objectives, and design an accelerated primal dual (APD) algorithm which uses bias corrected local steps (as in Scaffold) to achieve significant gains in communication efficiency and convergence speed. We evaluate Scaff-PD on several benchmark datasets and demonstrate its effectiveness in improving fairness and robustness while maintaining competitive accuracy. Our results suggest that Scaff-PD is a promising approach for federated learning in resource-constrained and heterogeneous settings.", "url": "https://arxiv.org/abs/2307.13381"}, {"metadata": {"arXiv": "2307.13390", "Date": "Tue, 25 Jul 2023 10:21:26 ", "Title": "Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space", "Authors": ["Xuan Zhao", "Klaus Broelemann", "Gjergji Kasneci"], "Categories": "cs.LG"}, "abstract": "Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions: 1. What are the crucial factors that led to an automated prediction/decision? 2. How can these factors be changed to achieve a more favorable outcome from a user's perspective? Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems. In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods. However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable. In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions. CEs are then generated in latent space by linear interpolation between the query sample and the centroid of the target class. We show that our method maintains the characteristics of the input sample during the counterfactual search. In various experiments, we show that the proposed method is competitive based on different quality measures on image and tabular datasets -- efficiently returns results that are closer to the original data manifold compared to three state-of-the-art methods, which are essential for realistic high-dimensional machine learning applications.", "url": "https://arxiv.org/abs/2307.13390"}, {"metadata": {"arXiv": "2307.13408", "Date": "Tue, 25 Jul 2023 11:07:43 ", "Title": "The Double-Edged Sword of Big Data and Information Technology for the Disadvantaged: A Cautionary Tale from Open Banking", "Authors": ["Savina Dine Kim and Galina Andreeva and Michael Rovatsos"], "Categories": "cs.LG cs.CY"}, "abstract": "This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example. Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment. However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination. Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation. Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation. Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage. Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination. Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data. We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment.", "url": "https://arxiv.org/abs/2307.13408"}, {"metadata": {"arXiv": "2307.13412", "Date": "Tue, 25 Jul 2023 11:19:21 ", "Title": "Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation", "Authors": ["Stylianos I. Venieris", "Javier Fernandez-Marques", "Nicholas D. Lane"], "Categories": "cs.LG cs.AR cs.CV", "Comments": ["Accepted at ACM TODAES", "2023. arXiv admin note: substantial text overlap with arXiv:2103.05600"]}, "abstract": "The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings. In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of FPGA-based CNN accelerators. In this context, single computation engines constitute a popular approach to support diverse CNN modes without the overhead of fabric reconfiguration. Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine's fixed configuration. In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time. We refer to these approaches as on-the-fly. This paper presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines. The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers. We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy-performance balance. Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers. The proposed framework yields hardware designs that achieve an average of 2.57x performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94x higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators.", "url": "https://arxiv.org/abs/2307.13412"}, {"metadata": {"arXiv": "2307.13419", "Date": "Tue, 25 Jul 2023 11:38:40 ", "Title": "Co-Design of Out-of-Distribution Detectors for Autonomous Emergency Braking Systems", "Authors": ["Michael Yuhas and Arvind Easwaran"], "Categories": "cs.LG cs.RO", "Comments": ["8 pages", "6 figures", "ITSC 2023"]}, "abstract": "Learning enabled components (LECs), while critical for decision making in autonomous vehicles (AVs), are likely to make incorrect decisions when presented with samples outside of their training distributions. Out-of-distribution (OOD) detectors have been proposed to detect such samples, thereby acting as a safety monitor, however, both OOD detectors and LECs require heavy utilization of embedded hardware typically found in AVs. For both components, there is a tradeoff between non-functional and functional performance, and both impact a vehicle's safety. For instance, giving an OOD detector a longer response time can increase its accuracy at the expense of the LEC. We consider an LEC with binary output like an autonomous emergency braking system (AEBS) and use risk, the combination of severity and occurrence of a failure, to model the effect of both components' design parameters on each other's functional and non-functional performance, as well as their impact on system safety. We formulate a co-design methodology that uses this risk model to find the design parameters for an OOD detector and LEC that decrease risk below that of the baseline system and demonstrate it on a vision based AEBS. Using our methodology, we achieve a 42.3% risk reduction while maintaining equivalent resource utilization.", "url": "https://arxiv.org/abs/2307.13419"}, {"metadata": {"arXiv": "2307.13430", "Date": "Tue, 25 Jul 2023 11:51:20 ", "Title": "Achieving Linear Speedup in Decentralized Stochastic Compositional Minimax Optimization", "Authors": ["Hongchang Gao"], "Categories": "cs.LG"}, "abstract": "The stochastic compositional minimax problem has attracted a surge of attention in recent years since it covers many emerging machine learning models. Meanwhile, due to the emergence of distributed data, optimizing this kind of problem under the decentralized setting becomes badly needed. However, the compositional structure in the loss function brings unique challenges to designing efficient decentralized optimization algorithms. In particular, our study shows that the standard gossip communication strategy cannot achieve linear speedup for decentralized compositional minimax problems due to the large consensus error about the inner-level function. To address this issue, we developed a novel decentralized stochastic compositional gradient descent ascent with momentum algorithm to reduce the consensus error in the inner-level function. As such, our theoretical results demonstrate that it is able to achieve linear speedup with respect to the number of workers. We believe this novel algorithmic design could benefit the development of decentralized compositional optimization. Finally, we applied our methods to the imbalanced classification problem. The extensive experimental results provide evidence for the effectiveness of our algorithm.", "url": "https://arxiv.org/abs/2307.13430"}, {"metadata": {"arXiv": "2307.13434", "Date": "Tue, 25 Jul 2023 12:00:48 ", "Title": "Network Traffic Classification based on Single Flow Time Series Analysis", "Authors": ["Josef Koumar and Karel Hynek and Tom\\'a\\v{s} \\v{C}ejka"], "Categories": "cs.LG cs.NI", "Comments": ["Submitted to The 19th International Conference on Network and Service Management (CNSM) 2023"]}, "abstract": "Network traffic monitoring using IP flows is used to handle the current challenge of analyzing encrypted network communication. Nevertheless, the packet aggregation into flow records naturally causes information loss; therefore, this paper proposes a novel flow extension for traffic features based on the time series analysis of the Single Flow Time series, i.e., a time series created by the number of bytes in each packet and its timestamp. We propose 69 universal features based on the statistical analysis of data points, time domain analysis, packet distribution within the flow timespan, time series behavior, and frequency domain analysis. We have demonstrated the usability and universality of the proposed feature vector for various network traffic classification tasks using 15 well-known publicly available datasets. Our evaluation shows that the novel feature vector achieves classification performance similar or better than related works on both binary and multiclass classification tasks. In more than half of the evaluated tasks, the classification performance increased by up to 5\\%.", "url": "https://arxiv.org/abs/2307.13434"}, {"metadata": {"arXiv": "2307.13470", "Date": "Tue, 25 Jul 2023 13:01:25 ", "Title": "Combinatorial Auctions and Graph Neural Networks for Local Energy Flexibility Markets", "Authors": ["Awadelrahman M. A. Ahmed", "Frank Eliassen and Yan Zhang"], "Categories": "cs.LG", "Comments": ["Accepted in The IEEE PES ISGT Europe 2023 (ISGT Europe 2023)", "Grenoble", "France", "on October", "2023"]}, "abstract": "This paper proposes a new combinatorial auction framework for local energy flexibility markets, which addresses the issue of prosumers' inability to bundle multiple flexibility time intervals. To solve the underlying NP-complete winner determination problems, we present a simple yet powerful heterogeneous tri-partite graph representation and design graph neural network-based models. Our models achieve an average optimal value deviation of less than 5\\% from an off-the-shelf optimization tool and show linear inference time complexity compared to the exponential complexity of the commercial solver. Contributions and results demonstrate the potential of using machine learning to efficiently allocate energy flexibility resources in local markets and solving optimization problems in general.", "url": "https://arxiv.org/abs/2307.13470"}, {"metadata": {"arXiv": "2307.13499", "Date": "Tue, 25 Jul 2023 13:49:15 ", "Title": "Finding Money Launderers Using Heterogeneous Graph Neural Networks", "Authors": ["Fredrik Johannessen and Martin Jullum"], "Categories": "cs.LG stat.ML"}, "abstract": "Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering. As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning. Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial. In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway's largest bank. Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph. As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph. Our findings highlight the importance of using an appropriate GNN architecture when combining information in heterogeneous graphs. The performance results of our model demonstrate great potential in enhancing the quality of electronic surveillance systems employed by banks to detect instances of money laundering. To the best of our knowledge, this is the first published work applying GNN on a large real-world heterogeneous network for anti-money laundering purposes.", "url": "https://arxiv.org/abs/2307.13499"}, {"metadata": {"arXiv": "2307.13503", "Date": "Tue, 25 Jul 2023 13:54:00 ", "Title": "Continuous Time Evidential Distributions for Irregular Time Series", "Authors": ["Taylor W. Killian", "Haoran Zhang", "Thomas Hartvigsen", "Ava P. Amini"], "Categories": "cs.LG stat.ML", "Comments": ["ICML 2023 Workshop on Interpretable Machine Learning in Healthcare. Code is available at https://github.com/twkillian/EDICT"]}, "abstract": "Prevalent in many real-world settings such as healthcare, irregular time series are challenging to formulate predictions from. It is difficult to infer the value of a feature at any given time when observations are sporadic, as it could take on a range of values depending on when it was last observed. To characterize this uncertainty we present EDICT, a strategy that learns an evidential distribution over irregular time series in continuous time. This distribution enables well-calibrated and flexible inference of partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations. We demonstrate that EDICT attains competitive performance on challenging time series classification tasks and enabling uncertainty-guided inference when encountering noisy data.", "url": "https://arxiv.org/abs/2307.13503"}, {"metadata": {"arXiv": "2307.13538", "Date": "Tue, 25 Jul 2023 14:35:55 ", "Title": "INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations", "Authors": ["Louis Serrano", "Leon Migus", "Yuan Yin", "Jocelyn Ahmed Mazari", "Patrick Gallinari"], "Categories": "cs.LG physics.flu-dyn", "Comments": ["ICML 2023 Workshop on Synergy of Scientific and Machine Learning Modeling"], "Journal-ref": "ICML 2023 Workshop on Synergy of Scientific and Machine Learning Modeling"}, "abstract": "For numerical design, the development of efficient and accurate surrogate models is paramount. They allow us to approximate complex physical phenomena, thereby reducing the computational burden of direct numerical simulations. We propose INFINITY, a deep learning model that utilizes implicit neural representations (INRs) to address this challenge. Our framework encodes geometric information and physical fields into compact representations and learns a mapping between them to infer the physical fields. We use an airfoil design optimization problem as an example task and we evaluate our approach on the challenging AirfRANS dataset, which closely resembles real-world industrial use-cases. The experimental results demonstrate that our framework achieves state-of-the-art performance by accurately inferring physical fields throughout the volume and surface. Additionally we demonstrate its applicability in contexts such as design exploration and shape optimization: our model can correctly predict drag and lift coefficients while adhering to the equations.", "url": "https://arxiv.org/abs/2307.13538"}, {"metadata": {"arXiv": "2307.13571", "Date": "Tue, 25 Jul 2023 15:23:15 ", "Title": "PT$\\mathrm{L}^{p}$: Partial Transport $\\mathrm{L}^{p}$ Distances", "Authors": ["Xinran Liu", "Yikun Bai", "Huy Tran", "Zhanqi Zhu", "Matthew Thorpe", "Soheil Kolouri"], "Categories": "cs.LG"}, "abstract": "Optimal transport and its related problems, including optimal partial transport, have proven to be valuable tools in machine learning for computing meaningful distances between probability or positive measures. This success has led to a growing interest in defining transport-based distances that allow for comparing signed measures and, more generally, multi-channeled signals. Transport $\\mathrm{L}^{p}$ distances are notable extensions of the optimal transport framework to signed and possibly multi-channeled signals. In this paper, we introduce partial transport $\\mathrm{L}^{p}$ distances as a new family of metrics for comparing generic signals, benefiting from the robustness of partial transport distances. We provide theoretical background such as the existence of optimal plans and the behavior of the distance in various limits. Furthermore, we introduce the sliced variation of these distances, which allows for rapid comparison of generic signals. Finally, we demonstrate the application of the proposed distances in signal class separability and nearest neighbor classification.", "url": "https://arxiv.org/abs/2307.13571"}, {"metadata": {"arXiv": "2307.13586", "Date": "Tue, 25 Jul 2023 15:42:11 ", "Title": "Settling the Sample Complexity of Online Reinforcement Learning", "Authors": ["Zihan Zhang", "Yuxin Chen", "Jason D. Lee", "Simon S. Du"], "Categories": "cs.LG"}, "abstract": "A central issue lying at the heart of online reinforcement learning (RL) is data efficiency. While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally. How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory. We settle this problem for the context of finite-horizon inhomogeneous Markov decision processes. Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors) \\begin{equation*} \\min\\big\\{ \\sqrt{SAH^3K}, \\,HK \\big\\}, \\end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes. This regret matches the minimax lower bound for the entire range of sample size $K\\geq 1$, essentially eliminating any burn-in requirement. It also translates to a PAC sample complexity (i.e., the number of episodes needed to yield $\\varepsilon$-accuracy) of $\\frac{SAH^3}{\\varepsilon^2}$ up to log factor, which is minimax-optimal for the full $\\varepsilon$-range. Further, we extend our theory to unveil the influences of problem-dependent quantities like the optimal value/cost and certain variances. The key technical innovation lies in the development of a new regret decomposition strategy and a novel analysis paradigm to decouple complicated statistical dependency -- a long-standing challenge facing the analysis of online RL in the sample-hungry regime.", "url": "https://arxiv.org/abs/2307.13586"}, {"metadata": {"arXiv": "2307.13592", "Date": "Tue, 25 Jul 2023 15:49:25 ", "Title": "Multi-GPU Approach for Training of Graph ML Models on large CFD Meshes", "Authors": ["Sebastian Str\\\"onisch", "Maximilian Sander", "Andreas Kn\\\"upfer", "Marcus Meyer"], "Categories": "cs.LG cs.NA math.NA", "Journal-ref": "Sebastian Stroenisch, Maximilian Sander, Marcus Meyer and Andreas Knuepfer. \"Multi-GPU Approach for Training of Graph ML Models on large CFD Meshes,\" AIAA 2023-1203. AIAA SCITECH 2023 Forum. January 2023", "DOI": "10.2514/6.2023-1203"}, "abstract": "Mesh-based numerical solvers are an important part in many design tool chains. However, accurate simulations like computational fluid dynamics are time and resource consuming which is why surrogate models are employed to speed-up the solution process. Machine Learning based surrogate models on the other hand are fast in predicting approximate solutions but often lack accuracy. Thus, the development of the predictor in a predictor-corrector approach is the focus here, where the surrogate model predicts a flow field and the numerical solver corrects it. This paper scales a state-of-the-art surrogate model from the domain of graph-based machine learning to industry-relevant mesh sizes of a numerical flow simulation. The approach partitions and distributes the flow domain to multiple GPUs and provides halo exchange between these partitions during training. The utilized graph neural network operates directly on the numerical mesh and is able to preserve complex geometries as well as all other properties of the mesh. The proposed surrogate model is evaluated with an application on a three dimensional turbomachinery setup and compared to a traditionally trained distributed model. The results show that the traditional approach produces superior predictions and outperforms the proposed surrogate model. Possible explanations, improvements and future directions are outlined.", "url": "https://arxiv.org/abs/2307.13592"}, {"metadata": {"arXiv": "2307.13621", "Date": "Tue, 25 Jul 2023 16:23:32 ", "Title": "Scaling machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points", "Authors": ["Malte Esders", "Gimmy Alex Fernandez Ramirez", "Michael Gastegger", "Satya Swarup Samal"], "Categories": "cs.LG cs.CE"}, "abstract": "Idealized first-principles models of chemical plants can be inaccurate. An alternative is to fit a Machine Learning (ML) model directly to plant sensor data. We use a structured approach: Each unit within the plant gets represented by one ML model. After fitting the models to the data, the models are connected into a flowsheet-like directed graph. We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the cycle solver. We analyze this problem in depth and show that it is not merely a specialized concern but rather a more pervasive challenge that will likely occur whenever ML is applied to larger plants. To address this problem, we present a way to fine-tune ML models such that solving cycles with the usual methods becomes robust again.", "url": "https://arxiv.org/abs/2307.13621"}, {"metadata": {"arXiv": "2307.13679", "Date": "Tue, 25 Jul 2023 17:36:34 ", "Title": "RED CoMETS: An ensemble classifier for symbolically represented multivariate time series", "Authors": ["Luca A. Bennett and Zahraa S. Abdallah"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted by AALTD 2023"]}, "abstract": "Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification.", "url": "https://arxiv.org/abs/2307.13679"}, {"metadata": {"arXiv": "2307.13680", "Date": "Tue, 25 Jul 2023 17:36:56 ", "Title": "High Probability Analysis for Non-Convex Stochastic Optimization with Clipping", "Authors": ["Shaojie Li", "Yong Liu"], "Categories": "cs.LG"}, "abstract": "Gradient clipping is a commonly used technique to stabilize the training process of neural networks. A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well. While gradient clipping is significant, its theoretical guarantees are scarce. Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance. In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes. With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\\alpha$-th moments for some $\\alpha \\in (1, 2]$, which is much weaker than the standard bounded second-moment assumption. Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.", "url": "https://arxiv.org/abs/2307.13680"}, {"metadata": {"arXiv": "2307.13133", "Date": "Mon, 24 Jul 2023 21:22:58 ", "Title": "simPLE: a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects", "Authors": ["Maria Bauza", "Antonia Bronars", "Yifan Hou", "Ian Taylor", "Nikhil Chavan-Dafle", "Alberto Rodriguez"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["33 pages", "6 figures", "2 tables", "submitted to Science Robotics"]}, "abstract": "Existing robotic systems have a clear tension between generality and precision. Deployed solutions for robotic manipulation tend to fall into the paradigm of one robot solving a single task, lacking precise generalization, i.e., the ability to solve many tasks without compromising on precision. This paper explores solutions for precise and general pick-and-place. In precise pick-and-place, i.e. kitting, the robot transforms an unstructured arrangement of objects into an organized arrangement, which can facilitate further manipulation. We propose simPLE (simulation to Pick Localize and PLacE) as a solution to precise pick-and-place. simPLE learns to pick, regrasp and place objects precisely, given only the object CAD model and no prior experience. We develop three main components: task-aware grasping, visuotactile perception, and regrasp planning. Task-aware grasping computes affordances of grasps that are stable, observable, and favorable to placing. The visuotactile perception model relies on matching real observations against a set of simulated ones through supervised learning. Finally, we compute the desired robot motion by solving a shortest path problem on a graph of hand-to-hand regrasps. On a dual-arm robot equipped with visuotactile sensing, we demonstrate pick-and-place of 15 diverse objects with simPLE. The objects span a wide range of shapes and simPLE achieves successful placements into structured arrangements with 1mm clearance over 90% of the time for 6 objects, and over 80% of the time for 11 objects. Videos are available at http://mcube.mit.edu/research/simPLE.html .", "url": "https://arxiv.org/abs/2307.13133"}, {"metadata": {"arXiv": "2307.13415", "Date": "Tue, 25 Jul 2023 11:23:38 ", "Title": "Communication-Efficient Orchestrations for URLLC Service via Hierarchical Reinforcement Learning", "Authors": ["Wei Shi", "Milad Ganjalizadeh", "Hossein Shokri Ghadikolaei", "Marina Petrova"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["This work has been accepted in IEEE 34th Annual International Symposium on Personal", "Indoor and Mobile Radio Communications (PIMRC)"]}, "abstract": "Ultra-reliable low latency communications (URLLC) service is envisioned to enable use cases with strict reliability and latency requirements in 5G. One approach for enabling URLLC services is to leverage Reinforcement Learning (RL) to efficiently allocate wireless resources. However, with conventional RL methods, the decision variables (though being deployed at various network layers) are typically optimized in the same control loop, leading to significant practical limitations on the control loop's delay as well as excessive signaling and energy consumption. In this paper, we propose a multi-agent Hierarchical RL (HRL) framework that enables the implementation of multi-level policies with different control loop timescales. Agents with faster control loops are deployed closer to the base station, while the ones with slower control loops are at the edge or closer to the core network providing high-level guidelines for low-level actions. On a use case from the prior art, with our HRL framework, we optimized the maximum number of retransmissions and transmission power of industrial devices. Our extensive simulation results on the factory automation scenario show that the HRL framework achieves better performance as the baseline single-agent RL method, with significantly less overhead of signal transmissions and delay compared to the one-agent RL methods.", "url": "https://arxiv.org/abs/2307.13415"}, {"metadata": {"arXiv": "2307.13453", "Date": "Tue, 25 Jul 2023 12:33:53 ", "Title": "Monte-Carlo Tree Search for Multi-Agent Pathfinding: Preliminary Results", "Authors": ["Yelisey Pitanov", "Alexey Skrynnik", "Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov"], "Categories": "cs.AI", "Comments": ["The paper is accepted to HAIS 2023"]}, "abstract": "In this work we study a well-known and challenging problem of Multi-agent Pathfinding, when a set of agents is confined to a graph, each agent is assigned a unique start and goal vertices and the task is to find a set of collision-free paths (one for each agent) such that each agent reaches its respective goal. We investigate how to utilize Monte-Carlo Tree Search (MCTS) to solve the problem. Although MCTS was shown to demonstrate superior performance in a wide range of problems like playing antagonistic games (e.g. Go, Chess etc.), discovering faster matrix multiplication algorithms etc., its application to the problem at hand was not well studied before. To this end we introduce an original variant of MCTS, tailored to multi-agent pathfinding. The crux of our approach is how the reward, that guides MCTS, is computed. Specifically, we use individual paths to assist the agents with the the goal-reaching behavior, while leaving them freedom to get off the track if it is needed to avoid collisions. We also use a dedicated decomposition technique to reduce the branching factor of the tree search procedure. Empirically we show that the suggested method outperforms the baseline planning algorithm that invokes heuristic search, e.g. A*, at each re-planning step.", "url": "https://arxiv.org/abs/2307.13453"}, {"metadata": {"arXiv": "2307.13549", "Date": "Tue, 25 Jul 2023 14:51:07 ", "Title": "A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency", "Authors": ["Bharath Muppasani", "Vishal Pallagani", "Biplav Srivastava", "Raghava Mutharaju", "Michael N. Huhns", "Vignesh Narayanan"], "Categories": "cs.AI", "Comments": ["Ontology", "Automated Planning", "Planner Improvement"]}, "abstract": "Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse. In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state. We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain. We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology. We also make the planning ontology and associated resources available to the community to promote further research.", "url": "https://arxiv.org/abs/2307.13549"}, {"metadata": {"arXiv": "2307.13552", "Date": "Tue, 25 Jul 2023 14:52:23 ", "Title": "On Solving the Rubik's Cube with Domain-Independent Planners Using Standard Representations", "Authors": ["Bharath Muppasani", "Vishal Pallagani", "Biplav Srivastava", "Forest Agostinelli"], "Categories": "cs.AI"}, "abstract": "Rubik's Cube (RC) is a well-known and computationally challenging puzzle that has motivated AI researchers to explore efficient alternative representations and problem-solving methods. The ideal situation for planning here is that a problem be solved optimally and efficiently represented in a standard notation using a general-purpose solver and heuristics. The fastest solver today for RC is DeepCubeA with a custom representation, and another approach is with Scorpion planner with State-Action-Space+ (SAS+) representation. In this paper, we present the first RC representation in the popular PDDL language so that the domain becomes more accessible to PDDL planners, competitions, and knowledge engineering tools, and is more human-readable. We then bridge across existing approaches and compare performance. We find that in one comparable experiment, DeepCubeA solves all problems with varying complexities, albeit only 18\\% are optimal plans. For the same problem set, Scorpion with SAS+ representation and pattern database heuristics solves 61.50\\% problems, while FastDownward with PDDL representation and FF heuristic solves 56.50\\% problems, out of which all the plans generated were optimal. Our study provides valuable insights into the trade-offs between representational choice and plan optimality that can help researchers design future strategies for challenging domains combining general-purpose solving methods (planning, reinforcement learning), heuristics, and representations (standard or custom).", "url": "https://arxiv.org/abs/2307.13552"}, {"metadata": {"arXiv": "2307.13582", "Date": "Tue, 25 Jul 2023 15:36:33 ", "Title": "Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks", "Authors": ["Xiang Yin", "Nico Potyka", "Francesca Toni"], "Categories": "cs.AI", "Comments": ["Accepted at the European Conference on Artificial Intelligence (ECAI) 2023 Conference"]}, "abstract": "Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of \\emph{extension-based semantics}, explaining the quantitative reasoning outcomes of AFs under \\emph{gradual semantics} has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of \\emph{Argument Attribution Explanations (AAEs)} by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards \\emph{topic argument}s of interest. We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting. To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.", "url": "https://arxiv.org/abs/2307.13582"}, {"metadata": {"arXiv": "2307.13221", "Date": "Tue, 25 Jul 2023 03:18:04 ", "Title": "Multilevel Large Language Models for Everyone", "Authors": ["Yuanhao Gong"], "Categories": "cs.CV cs.AI cs.CE cs.DC econ.GN q-fin.EC"}, "abstract": "Large language models have made significant progress in the past few years. However, they are either generic {\\it or} field specific, splitting the community into different groups. In this paper, we unify these large language models into a larger map, where the generic {\\it and} specific models are linked together and can improve each other, based on the user personal input and information from the internet. The idea of linking several large language models together is inspired by the functionality of human brain. The specific regions on the brain cortex are specific for certain low level functionality. And these regions can jointly work together to achieve more complex high level functionality. Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models. The user level models run on local machines to achieve efficient response and protect the user's privacy. Such multilevel models reduce some redundancy and perform better than the single level models. The proposed multilevel idea can be applied in various applications, such as natural language processing, computer vision tasks, professional assistant, business and healthcare.", "url": "https://arxiv.org/abs/2307.13221"}, {"metadata": {"arXiv": "2307.13251", "Date": "Tue, 25 Jul 2023 04:43:22 ", "Title": "GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers", "Authors": ["Tuan Duc Ngo", "Binh-Son Hua", "Khoi Nguyen"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICCV 2023"]}, "abstract": "Instance segmentation on 3D point clouds (3DIS) is a longstanding challenge in computer vision, where state-of-the-art methods are mainly based on full supervision. As annotating ground truth dense instance masks is tedious and expensive, solving 3DIS with weak supervision has become more practical. In this paper, we propose GaPro, a new instance segmentation for 3D point clouds using axis-aligned 3D bounding box supervision. Our two-step approach involves generating pseudo labels from box annotations and training a 3DIS network with the resulting labels. Additionally, we employ the self-training strategy to improve the performance of our method further. We devise an effective Gaussian Process to generate pseudo instance masks from the bounding boxes and resolve ambiguities when they overlap, resulting in pseudo instance masks with their uncertainty values. Our experiments show that GaPro outperforms previous weakly supervised 3D instance segmentation methods and has competitive performance compared to state-of-the-art fully supervised ones. Furthermore, we demonstrate the robustness of our approach, where we can adapt various state-of-the-art fully supervised methods to the weak supervision task by using our pseudo labels for training. The source code and trained models are available at https://github.com/VinAIResearch/GaPro.", "url": "https://arxiv.org/abs/2307.13251"}, {"metadata": {"arXiv": "2307.13294", "Date": "Tue, 25 Jul 2023 07:20:21 ", "Title": "Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation", "Authors": ["Junbin Fang", "Canjian Jiang", "You Jiang", "Puxi Lin", "Zhaojie Chen", "Yujing Sun", "Siu-Ming Yiu", "Zoe L. Jiang"], "Categories": "cs.CV cs.AI"}, "abstract": "Although face recognition starts to play an important role in our daily life, we need to pay attention that data-driven face recognition vision systems are vulnerable to adversarial attacks. However, the current two categories of adversarial attacks, namely digital attacks and physical attacks both have drawbacks, with the former ones impractical and the latter one conspicuous, high-computational and inexecutable. To address the issues, we propose a practical, executable, inconspicuous and low computational adversarial attack based on LED illumination modulation. To fool the systems, the proposed attack generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors in face recognition systems to implant luminance information perturbation to the captured face images. In summary,we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification. We also evaluate their effectiveness against well-known face detection models, Dlib, MTCNN and RetinaFace , and face verification models, Dlib, FaceNet,and ArcFace.The extensive experiments show that the success rates of DoS attacks against face detection models reach 97.67%, 100%, and 100%, respectively, and the success rates of dodging attacks against all face verification models reach 100%.", "url": "https://arxiv.org/abs/2307.13294"}, {"metadata": {"arXiv": "2307.13345", "Date": "Tue, 25 Jul 2023 09:02:29 ", "Title": "Do humans and Convolutional Neural Networks attend to similar areas during scene classification: Effects of task and image type", "Authors": ["Romy M\\\"uller", "Marcel Duerschmidt", "Julian Ullrich", "Carsten Knoll", "Sascha Weber", "Steffen Seitz"], "Categories": "cs.CV cs.AI cs.HC"}, "abstract": "Deep Learning models like Convolutional Neural Networks (CNN) are powerful image classifiers, but what factors determine whether they attend to similar image areas as humans do? While previous studies have focused on technological factors, little is known about the role of factors that affect human attention. In the present study, we investigated how the tasks used to elicit human attention maps interact with image characteristics in modulating the similarity between humans and CNN. We varied the intentionality of human tasks, ranging from spontaneous gaze during categorization over intentional gaze-pointing up to manual area selection. Moreover, we varied the type of image to be categorized, using either singular, salient objects, indoor scenes consisting of object arrangements, or landscapes without distinct objects defining the category. The human attention maps generated in this way were compared to the CNN attention maps revealed by explainable artificial intelligence (Grad-CAM). The influence of human tasks strongly depended on image type: For objects, human manual selection produced maps that were most similar to CNN, while the specific eye movement task has little impact. For indoor scenes, spontaneous gaze produced the least similarity, while for landscapes, similarity was equally low across all human tasks. To better understand these results, we also compared the different human attention maps to each other. Our results highlight the importance of taking human factors into account when comparing the attention of humans and CNN.", "url": "https://arxiv.org/abs/2307.13345"}, {"metadata": {"arXiv": "2307.13463", "Date": "Tue, 25 Jul 2023 12:47:21 ", "Title": "Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion", "Authors": ["James Z. Wang", "Sicheng Zhao", "Chenyan Wu", "Reginald B. Adams", "Michelle G. Newman", "Tal Shafir", "Rachelle Tsachor"], "Categories": "cs.CV cs.AI", "Comments": ["Proceedings of the IEEE 2023"], "DOI": "10.1109/JPROC.2023.3273517"}, "abstract": "The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of \"emotion\", coupled with the inherently subjective nature of emotions and their intricate nuances. In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a \"Holy Grail\" research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.", "url": "https://arxiv.org/abs/2307.13463"}, {"metadata": {"arXiv": "2307.13529", "Date": "Tue, 25 Jul 2023 14:20:52 ", "Title": "Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection", "Authors": ["Yichao Cao", "Xiu Su", "Qingfei Tang", "Feng Yang", "Shan You", "Xiaobo Lu and Chang Xu"], "Categories": "cs.CV cs.AI", "Comments": ["ICCV2023"]}, "abstract": "Human-Object Interaction (HOI) detection is a challenging computer vision task that requires visual models to address the complex interactive relationship between humans and objects and predict HOI triplets. Despite the challenges posed by the numerous interaction combinations, they also offer opportunities for multimodal learning of visual texts. In this paper, we present a systematic and unified framework (RmLR) that enhances HOI detection by incorporating structured text knowledge. Firstly, we qualitatively and quantitatively analyze the loss of interaction information in the two-stage HOI detector and propose a re-mining strategy to generate more comprehensive visual representation.Secondly, we design more fine-grained sentence- and word-level alignment and knowledge transfer strategies to effectively address the many-to-many matching problem between multiple interactions and multiple texts.These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process. Finally, HOI reasoning by visual features augmented with textual knowledge substantially improves the understanding of interactions. Experimental results illustrate the effectiveness of our approach, where state-of-the-art performance is achieved on public benchmarks. We further analyze the effects of different components of our approach to provide insights into its efficacy.", "url": "https://arxiv.org/abs/2307.13529"}, {"metadata": {"arXiv": "2307.13537", "Date": "Tue, 25 Jul 2023 14:35:25 ", "Title": "Spectrum-guided Multi-granularity Referring Video Object Segmentation", "Authors": ["Bo Miao", "Mohammed Bennamoun", "Yongsheng Gao", "Ajmal Mian"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["Accepted by ICCV 2023", "code is at https://github.com/bo-miao/SgMg"]}, "abstract": "Current referring video object segmentation (R-VOS) techniques extract conditional kernels from encoded (low-resolution) vision-language features to segment the decoded high-resolution features. We discovered that this causes significant feature drift, which the segmentation kernels struggle to perceive during the forward computation. This negatively affects the ability of segmentation kernels. To address the drift problem, we propose a Spectrum-guided Multi-granularity (SgMg) approach, which performs direct segmentation on the encoded features and employs visual details to further optimize the masks. In addition, we propose Spectrum-guided Cross-modal Fusion (SCF) to perform intra-frame global interactions in the spectral domain for effective multimodal representation. Finally, we extend SgMg to perform multi-object R-VOS, a new paradigm that enables simultaneous segmentation of multiple referred objects in a video. This not only makes R-VOS faster, but also more practical. Extensive experiments show that SgMg achieves state-of-the-art performance on four video benchmark datasets, outperforming the nearest competitor by 2.8% points on Ref-YouTube-VOS. Our extended SgMg enables multi-object R-VOS, runs about 3 times faster while maintaining satisfactory performance. Code is available at https://github.com/bo-miao/SgMg.", "url": "https://arxiv.org/abs/2307.13537"}, {"metadata": {"arXiv": "2307.13541", "Date": "Tue, 25 Jul 2023 14:44:41 ", "Title": "Group Activity Recognition in Computer Vision: A Comprehensive Review, Challenges, and Future Perspectives", "Authors": ["Chuanchuan Wang", "Ahmad Sufril Azlan Mohamed"], "Categories": "cs.CV cs.AI"}, "abstract": "Group activity recognition is a hot topic in computer vision. Recognizing activities through group relationships plays a vital role in group activity recognition. It holds practical implications in various scenarios, such as video analysis, surveillance, automatic driving, and understanding social activities. The model's key capabilities encompass efficiently modeling hierarchical relationships within a scene and accurately extracting distinctive spatiotemporal features from groups. Given this technology's extensive applicability, identifying group activities has garnered significant research attention. This work examines the current progress in technology for recognizing group activities, with a specific focus on global interactivity and activities. Firstly, we comprehensively review the pertinent literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms. Subsequently, we present the relational network and relational architectures for each module. Thirdly, we investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies. We summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition. Furthermore, we review emerging perspectives in group activity recognition to explore new directions and possibilities.", "url": "https://arxiv.org/abs/2307.13541"}, {"metadata": {"arXiv": "2307.13646", "Date": "Tue, 25 Jul 2023 16:55:13 ", "Title": "QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models", "Authors": ["Justin Engelmann", "Amos Storkey", "Miguel O. Bernabeu"], "Categories": "cs.CV cs.AI q-bio.QM"}, "abstract": "Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Prior linearisation scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task. For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537). Code and model are available on GitHub: https://github.com/justinengelmann/QuickQual . QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper.", "url": "https://arxiv.org/abs/2307.13646"}, {"metadata": {"arXiv": "2307.13697", "Date": "Tue, 25 Jul 2023 17:59:59 ", "Title": "Benchmarking and Analyzing Generative Data for Visual Recognition", "Authors": ["Bo Li", "Haotian Liu", "Liangyu Chen", "Yong Jae Lee", "Chunyuan Li", "Ziwei Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Research Report"]}, "abstract": "Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition. This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\\ie generative \\vs retrieval \\vs original). Our key contributions are: \\textbf{1) GenBench Construction:} We devise \\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks. \\textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\\eg, FID, CLIP score) with downstream recognition performance, we propose \\textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training. \\textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data. \\textbf{4) External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images. Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation.", "url": "https://arxiv.org/abs/2307.13697"}, {"metadata": {"arXiv": "2307.13209", "Date": "Tue, 25 Jul 2023 02:23:58 ", "Title": "Gait Cycle-Inspired Learning Strategy for Continuous Prediction of Knee Joint Trajectory from sEMG", "Authors": ["Xueming Fu", "Hao Zheng", "Luyan Liu", "Wenjuan Zhong", "Haowen Liu", "Wenxuan Xiong", "Yuyang Zhang", "Yifeng Chen", "Dong Wei", "Mingjie Dong", "Yefeng Zheng", "Mingming Zhang"], "Categories": "cs.RO cs.AI"}, "abstract": "Predicting lower limb motion intent is vital for controlling exoskeleton robots and prosthetic limbs. Surface electromyography (sEMG) attracts increasing attention in recent years as it enables ahead-of-time prediction of motion intentions before actual movement. However, the estimation performance of human joint trajectory remains a challenging problem due to the inter- and intra-subject variations. The former is related to physiological differences (such as height and weight) and preferred walking patterns of individuals, while the latter is mainly caused by irregular and gait-irrelevant muscle activity. This paper proposes a model integrating two gait cycle-inspired learning strategies to mitigate the challenge for predicting human knee joint trajectory. The first strategy is to decouple knee joint angles into motion patterns and amplitudes former exhibit low variability while latter show high variability among individuals. By learning through separate network entities, the model manages to capture both the common and personalized gait features. In the second, muscle principal activation masks are extracted from gait cycles in a prolonged walk. These masks are used to filter out components unrelated to walking from raw sEMG and provide auxiliary guidance to capture more gait-related features. Experimental results indicate that our model could predict knee angles with the average root mean square error (RMSE) of 3.03(0.49) degrees and 50ms ahead of time. To our knowledge this is the best performance in relevant literatures that has been reported, with reduced RMSE by at least 9.5%.", "url": "https://arxiv.org/abs/2307.13209"}, {"metadata": {"arXiv": "2307.13323", "Date": "Tue, 25 Jul 2023 08:32:36 ", "Title": "Learning Autonomous Ultrasound via Latent Task Representation and Robotic Skills Adaptation", "Authors": ["Xutian Deng", "Junnan Jiang", "Wen Cheng and Miao Li"], "Categories": "cs.RO cs.AI"}, "abstract": "As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work. Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients. To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper. During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account. During the online stage, the probability model will select and evaluate the optimal prediction. For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions. Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method.", "url": "https://arxiv.org/abs/2307.13323"}, {"metadata": {"arXiv": "2307.13192", "Date": "Tue, 25 Jul 2023 01:14:56 ", "Title": "Counterfactual Explanation Policies in RL", "Authors": ["Shripad V. Deshmukh", "Srivatsan R", "Supriti Vijay", "Jayakumar Subramanian", "Chirag Agarwal"], "Categories": "cs.AI cs.LG", "Comments": ["ICML Workshop on Counterfactuals in Minds and Machines", "2023"]}, "abstract": "As Reinforcement Learning (RL) agents are increasingly employed in diverse decision-making problems using reward preferences, it becomes important to ensure that policies learned by these frameworks in mapping observations to a probability distribution of the possible actions are explainable. However, there is little to no work in the systematic understanding of these complex policies in a contrastive manner, i.e., what minimal changes to the policy would improve/worsen its performance to a desired level. In this work, we present COUNTERPOL, the first framework to analyze RL policies using counterfactual explanations in the form of minimal changes to the policy that lead to the desired outcome. We do so by incorporating counterfactuals in supervised learning in RL with the target outcome regulated using desired return. We establish a theoretical connection between Counterpol and widely used trust region-based policy optimization methods in RL. Extensive empirical analysis shows the efficacy of COUNTERPOL in generating explanations for (un)learning skills while keeping close to the original policy. Our results on five different RL environments with diverse state and action spaces demonstrate the utility of counterfactual explanations, paving the way for new frontiers in designing and developing counterfactual policies.", "url": "https://arxiv.org/abs/2307.13192"}, {"metadata": {"arXiv": "2307.12994", "Date": "Sat, 22 Jul 2023 01:57:08 ", "Title": "Multi-representations Space Separation based Graph-level Anomaly-aware Detection", "Authors": ["Fu Lin", "Haonan Gong", "Mingkang Li", "Zitong Wang", "Yue Zhang", "Xuexiong Luo"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "12 figures"], "Journal-ref": "35th International Conference on Scientific and Statistical Database Management (SSDBM 2023), July 10--12, 2023, Los Angeles, CA, USA", "DOI": "10.1145/3603719.3603739"}, "abstract": "Graph structure patterns are widely used to model different area data recently. How to detect anomalous graph information on these graph data has become a popular research problem. The objective of this research is centered on the particular issue that how to detect abnormal graphs within a graph set. The previous works have observed that abnormal graphs mainly show node-level and graph-level anomalies, but these methods equally treat two anomaly forms above in the evaluation of abnormal graphs, which is contrary to the fact that different types of abnormal graph data have different degrees in terms of node-level and graph-level anomalies. Furthermore, abnormal graphs that have subtle differences from normal graphs are easily escaped detection by the existing methods. Thus, we propose a multi-representations space separation based graph-level anomaly-aware detection framework in this paper. To consider the different importance of node-level and graph-level anomalies, we design an anomaly-aware module to learn the specific weight between them in the abnormal graph evaluation process. In addition, we learn strictly separate normal and abnormal graph representation spaces by four types of weighted graph representations against each other including anchor normal graphs, anchor abnormal graphs, training normal graphs, and training abnormal graphs. Based on the distance error between the graph representations of the test graph and both normal and abnormal graph representation spaces, we can accurately determine whether the test graph is anomalous. Our approach has been extensively evaluated against baseline methods using ten public graph datasets, and the results demonstrate its effectiveness.", "url": "https://arxiv.org/abs/2307.12994"}, {"metadata": {"arXiv": "2307.12996", "Date": "Sat, 22 Jul 2023 10:32:58 ", "Title": "Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning", "Authors": ["Romain Lacombe", "Andrew Gaut", "Jeff He", "David L\\\"udeke", "Kateryna Pistunova"], "Categories": "cs.LG cs.AI cs.CL cs.IR q-bio.QM", "Comments": ["2023 ICML Workshop on Computational Biology"]}, "abstract": "Deep learning in computational biochemistry has traditionally focused on molecular graphs neural representations; however, recent advances in language models highlight how much scientific knowledge is encoded in text. To bridge these two modalities, we investigate how molecular property information can be transferred from natural language to graph representations. We study property prediction performance gains after using contrastive learning to align neural graph representations with representations of textual descriptions of their characteristics. We implement neural relevance scoring strategies to improve text retrieval, introduce a novel chemically-valid molecular graph augmentation strategy inspired by organic reactions, and demonstrate improved performance on downstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC gain versus models pre-trained on the graph modality alone, and a +1.54% gain compared to recently proposed molecular graph/text contrastively trained MoMu model (Su et al. 2022).", "url": "https://arxiv.org/abs/2307.12996"}, {"metadata": {"arXiv": "2307.13011", "Date": "Mon, 24 Jul 2023 13:47:30 ", "Title": "Maximal Independent Sets for Pooling in Graph Neural Networks", "Authors": ["Stevan Stanovic (ENSICAEN", "UNICAEN)", "Benoit Ga\\\"uz\\`ere (INSA Rouen Normandie", "UNIROUEN", "ULH", "LITIS)", "Luc Brun (ENSICAEN", "UNICAEN)"], "Categories": "cs.LG cs.AI cs.CV", "Journal-ref": "13th IAPR-TC15 International Workshop on Graph-Based Representations in Pattern Recognition (GbR 2023), Sep 2023, Vietri Sul Mare, Italy"}, "abstract": "Convolutional Neural Networks (CNNs) have enabled major advances in image classification through convolution and pooling. In particular, image pooling transforms a connected discrete lattice into a reduced lattice with the same connectivity and allows reduction functions to consider all pixels in an image. However, there is no pooling that satisfies these properties for graphs. In fact, traditional graph pooling methods suffer from at least one of the following drawbacks: Graph disconnection or overconnection, low decimation ratio, and deletion of large parts of graphs. In this paper, we present three pooling methods based on the notion of maximal independent sets that avoid these pitfalls. Our experimental results confirm the relevance of maximal independent set constraints for graph pooling.", "url": "https://arxiv.org/abs/2307.13011"}, {"metadata": {"arXiv": "2307.13078", "Date": "Mon, 24 Jul 2023 18:59:46 ", "Title": "Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs", "Authors": ["Zhakshylyk Nurlanov", "Frank R. Schmidt", "Florian Bernard"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Presented at ICML 2023 workshop \"New Frontiers in Adversarial Machine Learning\""]}, "abstract": "As deep learning models continue to advance and are increasingly utilized in real-world systems, the issue of robustness remains a major challenge. Existing certified training methods produce models that achieve high provable robustness guarantees at certain perturbation levels. However, the main problem of such models is a dramatically low standard accuracy, i.e. accuracy on clean unperturbed data, that makes them impractical. In this work, we consider a more realistic perspective of maximizing the robustness of a model at certain levels of (high) standard accuracy. To this end, we propose a novel certified training method based on a key insight that training with adaptive certified radii helps to improve both the accuracy and robustness of the model, advancing state-of-the-art accuracy-robustness tradeoffs. We demonstrate the effectiveness of the proposed method on MNIST, CIFAR-10, and TinyImageNet datasets. Particularly, on CIFAR-10 and TinyImageNet, our method yields models with up to two times higher robustness, measured as an average certified radius of a test set, at the same levels of standard accuracy compared to baseline approaches.", "url": "https://arxiv.org/abs/2307.13078"}, {"metadata": {"arXiv": "2307.13081", "Date": "Mon, 24 Jul 2023 19:07:34 ", "Title": "Fairness Under Demographic Scarce Regime", "Authors": ["Patrik Joslin Kenfack", "Samira Ebrahimi Kahou", "Ulrich A\\\"ivodji"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages", "7 pages"]}, "abstract": "Most existing works on fairness assume the model has full access to demographic information. However, there exist scenarios where demographic information is partially available because a record was not maintained throughout data collection or due to privacy reasons. This setting is known as demographic scarce regime. Prior research have shown that training an attribute classifier to replace the missing sensitive attributes (proxy) can still improve fairness. However, the use of proxy-sensitive attributes worsens fairness-accuracy trade-offs compared to true sensitive attributes. To address this limitation, we propose a framework to build attribute classifiers that achieve better fairness-accuracy trade-offs. Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty. We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes is detrimental to fairness and accuracy. Our experiments on two datasets showed that the proposed framework yields models with significantly better fairness-accuracy trade-offs compared to classic attribute classifiers. Surprisingly, our framework outperforms models trained with constraints on the true sensitive attributes.", "url": "https://arxiv.org/abs/2307.13081"}, {"metadata": {"arXiv": "2307.13101", "Date": "Mon, 24 Jul 2023 19:43:22 ", "Title": "Contrastive Example-Based Control", "Authors": ["Kyle Hatch", "Benjamin Eysenbach", "Rafael Rafailov", "Tianhe Yu", "Ruslan Salakhutdinov", "Sergey Levine", "Chelsea Finn"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["This is an updated version of a manuscript that originally appeared at L4DC 2023. The project website is here https://sites.google.com/view/laeo-rl"], "Journal-ref": "Proceedings of The 5th Annual Learning for Dynamics and Control Conference, PMLR 211:155-169, 2023"}, "abstract": "While many real-world problems that might benefit from reinforcement learning, these problems rarely fit into the MDP mold: interacting with the environment is often expensive and specifying reward functions is challenging. Motivated by these challenges, prior work has developed data-driven approaches that learn entirely from samples from the transition dynamics and examples of high-return states. These methods typically learn a reward function from high-return states, use that reward function to label the transitions, and then apply an offline RL algorithm to these transitions. While these methods can achieve good results on many tasks, they can be complex, often requiring regularization and temporal difference updates. In this paper, we propose a method for offline, example-based control that learns an implicit model of multi-step transitions, rather than a reward function. We show that this implicit model can represent the Q-values for the example-based control problem. Across a range of state-based and image-based offline control tasks, our method outperforms baselines that use learned reward functions; additional experiments demonstrate improved robustness and scaling with dataset size.", "url": "https://arxiv.org/abs/2307.13101"}, {"metadata": {"arXiv": "2307.13108", "Date": "Mon, 24 Jul 2023 19:57:21 ", "Title": "An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment", "Authors": ["Favour Nerrise (1)", "Qingyu Zhao (2)", "Kathleen L. Poston (3)", "Kilian M. Pohl (2)", "Ehsan Adeli (2) ((1) Department of Electrical Engineering", "Stanford University", "Stanford", "CA", "USA", "(2) Dept. of Psychiatry and Behavioral Sciences", "Stanford University", "Stanford", "CA", "USA", "(3) Dept. of Neurology and Neurological Sciences", "Stanford University", "Stanford", "CA", "USA)"], "Categories": "cs.LG cs.AI eess.IV q-bio.NC", "Comments": ["Accepted by the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023). MICCAI Student-Author Registration (STAR) Award. 11 pages", "2 figures", "1 table", "appendix. Source Code: https://github.com/favour-nerrise/xGW-GAT"]}, "abstract": "One of the hallmark symptoms of Parkinson's Disease (PD) is the progressive loss of postural reflexes, which eventually leads to gait difficulties and balance problems. Identifying disruptions in brain function associated with gait impairment could be crucial in better understanding PD motor progression, thus advancing the development of more effective and personalized therapeutics. In this work, we present an explainable, geometric, weighted-graph attention neural network (xGW-GAT) to identify functional networks predictive of the progression of gait difficulties in individuals with PD. xGW-GAT predicts the multi-class gait impairment on the MDS Unified PD Rating Scale (MDS-UPDRS). Our computational- and data-efficient model represents functional connectomes as symmetric positive definite (SPD) matrices on a Riemannian manifold to explicitly encode pairwise interactions of entire connectomes, based on which we learn an attention mask yielding individual- and group-level explainability. Applied to our resting-state functional MRI (rs-fMRI) dataset of individuals with PD, xGW-GAT identifies functional connectivity patterns associated with gait impairment in PD and offers interpretable explanations of functional subnetworks associated with motor impairment. Our model successfully outperforms several existing methods while simultaneously revealing clinically-relevant connectivity patterns. The source code is available at https://github.com/favour-nerrise/xGW-GAT .", "url": "https://arxiv.org/abs/2307.13108"}, {"metadata": {"arXiv": "2307.13116", "Date": "Wed, 12 Jul 2023 08:27:37 ", "Title": "Pathway: a fast and flexible unified stream data processing framework for analytical and Machine Learning applications", "Authors": ["Michal Bartoszkiewicz", "Jan Chorowski", "Adrian Kosowski", "Jakub Kowalski", "Sergey Kulik", "Mateusz Lewandowski", "Krzysztof Nowicki", "Kamil Piechowiak", "Olivier Ruas", "Zuzanna Stamirowska", "Przemyslaw Uznanski"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "We present Pathway, a new unified data processing framework that can run workloads on both bounded and unbounded data streams. The framework was created with the original motivation of resolving challenges faced when analyzing and processing data from the physical economy, including streams of data generated by IoT and enterprise systems. These required rapid reaction while calling for the application of advanced computation paradigms (machinelearning-powered analytics, contextual analysis, and other elements of complex event processing). Pathway is equipped with a Table API tailored for Python and Python/SQL workflows, and is powered by a distributed incremental dataflow in Rust. We describe the system and present benchmarking results which demonstrate its capabilities in both batch and streaming contexts, where it is able to surpass state-of-the-art industry frameworks in both scenarios. We also discuss streaming use cases handled by Pathway which cannot be easily resolved with state-of-the-art industry frameworks, such as streaming iterative graph algorithms (PageRank, etc.).", "url": "https://arxiv.org/abs/2307.13116"}, {"metadata": {"arXiv": "2307.13214", "Date": "Tue, 25 Jul 2023 02:55:33 ", "Title": "FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal Federated Learning", "Authors": ["Huy Q. Le", "Minh N. H. Nguyen", "Chu Myaet Thwal", "Yu Qiao", "Chaoning Zhang", "and Choong Seon Hong"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning (FL) enables a decentralized machine learning paradigm for multiple clients to collaboratively train a generalized global model without sharing their private data. Most existing works simply propose typical FL systems for single-modal data, thus limiting its potential on exploiting valuable multimodal data for future personalized applications. Furthermore, the majority of FL approaches still rely on the labeled data at the client side, which is limited in real-world applications due to the inability of self-annotation from users. In light of these limitations, we propose a novel multimodal FL framework that employs a semi-supervised learning approach to leverage the representations from different modalities. Bringing this concept into a system, we develop a distillation-based multimodal embedding knowledge transfer mechanism, namely FedMEKT, which allows the server and clients to exchange the joint knowledge of their learning models extracted from a small multimodal proxy dataset. Our FedMEKT iteratively updates the generalized global encoders with the joint embedding knowledge from the participating clients. Thereby, to address the modality discrepancy and labeled data constraint in existing FL systems, our proposed FedMEKT comprises local multimodal autoencoder learning, generalized multimodal autoencoder construction, and generalized classifier learning. Through extensive experiments on three multimodal human activity recognition datasets, we demonstrate that FedMEKT achieves superior global encoder performance on linear evaluation and guarantees user privacy for personal data and model parameters while demanding less communication cost than other baselines.", "url": "https://arxiv.org/abs/2307.13214"}, {"metadata": {"arXiv": "2307.13239", "Date": "Tue, 25 Jul 2023 04:04:49 ", "Title": "RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision", "Authors": ["Hongzuo Xu and Yijie Wang and Guansong Pang and Songlei Jian and Ning Liu and Yongjun Wang"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by Information Processing and Management (IP&M)"]}, "abstract": "Semi-supervised anomaly detection methods leverage a few anomaly examples to yield drastically improved performance compared to unsupervised models. However, they still suffer from two limitations: 1) unlabeled anomalies (i.e., anomaly contamination) may mislead the learning process when all the unlabeled data are employed as inliers for model training; 2) only discrete supervision information (such as binary or ordinal data labels) is exploited, which leads to suboptimal learning of anomaly scores that essentially take on a continuous distribution. Therefore, this paper proposes a novel semi-supervised anomaly detection method, which devises \\textit{contamination-resilient continuous supervisory signals}. Specifically, we propose a mass interpolation method to diffuse the abnormality of labeled anomalies, thereby creating new data samples labeled with continuous abnormal degrees. Meanwhile, the contaminated area can be covered by new data samples generated via combinations of data with correct labels. A feature learning-based objective is added to serve as an optimization constraint to regularize the network and further enhance the robustness w.r.t. anomaly contamination. Extensive experiments on 11 real-world datasets show that our approach significantly outperforms state-of-the-art competitors by 20%-30% in AUC-PR and obtains more robust and superior performance in settings with different anomaly contamination levels and varying numbers of labeled anomalies. The source code is available at https://github.com/xuhongzuo/rosas/.", "url": "https://arxiv.org/abs/2307.13239"}, {"metadata": {"arXiv": "2307.13256", "Date": "Tue, 25 Jul 2023 04:55:45 ", "Title": "Structural Credit Assignment with Coordinated Exploration", "Authors": ["Stephen Chung"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages"], "ACM-class": "I.2.6; I.2.8; I.5.1"}, "abstract": "A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. However, this learning method tends to be slow and does not scale well with the size of the network. This inefficiency arises from two factors impeding effective structural credit assignment: (i) all units independently explore the network, and (ii) a single reward is used to evaluate the actions of all units. Accordingly, methods aimed at improving structural credit assignment can generally be classified into two categories. The first category includes algorithms that enable coordinated exploration among units, such as MAP propagation. The second category encompasses algorithms that compute a more specific reward signal for each unit within the network, like Weight Maximization and its variants. In this research report, our focus is on the first category. We propose the use of Boltzmann machines or a recurrent network for coordinated exploration. We show that the negative phase, which is typically necessary to train Boltzmann machines, can be removed. The resulting learning rules are similar to the reward-modulated Hebbian learning rule. Experimental results demonstrate that coordinated exploration significantly exceeds independent exploration in training speed for multiple stochastic and discrete units based on REINFORCE, even surpassing straight-through estimator (STE) backpropagation.", "url": "https://arxiv.org/abs/2307.13256"}, {"metadata": {"arXiv": "2307.13266", "Date": "Tue, 25 Jul 2023 05:33:06 ", "Title": "Federated Split Learning with Only Positive Labels for resource-constrained IoT environment", "Authors": ["Praveen Joshi", "Chandra Thapa", "Mohammed Hasanuzzaman", "Ted Scully", "and Haithem Afli"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "3 figures"]}, "abstract": "Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices. A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power. Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities. Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results. To overcome these challenges, we propose splitfed learning with positive labels (SFPL). SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server for model training. Additionally, SFPL incorporates the local batch normalization for the client-side model portion during the inference phase. Our results demonstrate that SFPL outperforms SFL: (i) by factors of 51.54 and 32.57 for ResNet-56 and ResNet-32, respectively, with the CIFAR-100 dataset, and (ii) by factors of 9.23 and 8.52 for ResNet-32 and ResNet-8, respectively, with CIFAR-10 dataset. Overall, this investigation underscores the efficacy of the proposed SFPL framework in DCML.", "url": "https://arxiv.org/abs/2307.13266"}, {"metadata": {"arXiv": "2307.13270", "Date": "Tue, 25 Jul 2023 05:45:52 ", "Title": "Unbiased Weight Maximization", "Authors": ["Stephen Chung"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages"], "ACM-class": "I.2.6; I.2.8; I.5.1"}, "abstract": "A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. Nevertheless, this learning method is often slow and scales poorly with network size due to inefficient structural credit assignment, since a single reward signal is broadcast to all units without considering individual contributions. Weight Maximization, a proposed solution, replaces a unit's reward signal with the norm of its outgoing weight, thereby allowing each hidden unit to maximize the norm of the outgoing weight instead of the global reward signal. In this research report, we analyze the theoretical properties of Weight Maximization and propose a variant, Unbiased Weight Maximization. This new approach provides an unbiased learning rule that increases learning speed and improves asymptotic performance. Notably, to our knowledge, this is the first learning rule for a network of Bernoulli-logistic units that is unbiased and scales well with the number of network's units in terms of learning speed.", "url": "https://arxiv.org/abs/2307.13270"}, {"metadata": {"arXiv": "2307.13275", "Date": "Tue, 25 Jul 2023 06:13:01 ", "Title": "Curvature-based Transformer for Molecular Property Prediction", "Authors": ["Yili Chen", "Zhengyu Li", "Zheng Wan", "Hui Yu", "Xian Wei"], "Categories": "cs.LG cs.AI q-bio.QM"}, "abstract": "The prediction of molecular properties is one of the most important and challenging tasks in the field of artificial intelligence-based drug design. Among the current mainstream methods, the most commonly used feature representation for training DNN models is based on SMILES and molecular graphs, although these methods are concise and effective, they also limit the ability to capture spatial information. In this work, we propose Curvature-based Transformer to improve the ability of Graph Transformer neural network models to extract structural information on molecular graph data by introducing Discretization of Ricci Curvature. To embed the curvature in the model, we add the curvature information of the graph as positional Encoding to the node features during the attention-score calculation. This method can introduce curvature information from graph data without changing the original network architecture, and it has the potential to be extended to other models. We performed experiments on chemical molecular datasets including PCQM4M-LST, MoleculeNet and compared with models such as Uni-Mol, Graphormer, and the results show that this method can achieve the state-of-the-art results. It is proved that the discretized Ricci curvature also reflects the structural and functional relationship while describing the local geometry of the graph molecular data.", "url": "https://arxiv.org/abs/2307.13275"}, {"metadata": {"arXiv": "2307.13332", "Date": "Tue, 25 Jul 2023 08:44:58 ", "Title": "The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation", "Authors": ["Philip Amortila", "Nan Jiang", "Csaba Szepesv\\'ari"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted to ICML 2023. The arXiv version contains improved results"]}, "abstract": "Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such \\emph{approximation factors} -- especially their optimal form in a given learning problem -- is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\\mu)$ norm and only one for the $L_\\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.", "url": "https://arxiv.org/abs/2307.13332"}, {"metadata": {"arXiv": "2307.13421", "Date": "Tue, 25 Jul 2023 11:40:47 ", "Title": "On the learning Dynamics of Attention Networks", "Authors": ["Rahul Vashisht and Harish G. Ramaswamy"], "Categories": "cs.LG cs.AI", "Comments": ["Preprint: Accepted at ECAI-2023"]}, "abstract": "Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \\textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization and splutters later on. On the other hand, hard attention loss behaves in the opposite fashion. Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets", "url": "https://arxiv.org/abs/2307.13421"}, {"metadata": {"arXiv": "2307.13466", "Date": "Tue, 25 Jul 2023 12:51:25 ", "Title": "Integrating processed-based models and machine learning for crop yield prediction", "Authors": ["Michiel G.J. Kallenberg", "Bernardo Maestrini", "Ron van Bree", "Paul Ravensbergen", "Christos Pylianidis", "Frits van Evert", "and Ioannis N. Athanasiadis (Wageningen University and Research", "the Netherlands)"], "Categories": "cs.LG cs.AI", "Comments": ["6 pages", "4 figures", "Accepted after peer-review at the 1st workshop on Synergy of Scientific and Machine Learning Modeling", "SynS & ML ICML", "Honolulu", "Hawaii", "USA. July", "2023"], "ACM-class": "I.2.6; I.5.1"}, "abstract": "Crop yield prediction typically involves the utilization of either theory-driven process-based crop growth models, which have proven to be difficult to calibrate for local conditions, or data-driven machine learning methods, which are known to require large datasets. In this work we investigate potato yield prediction using a hybrid meta-modeling approach. A crop growth model is employed to generate synthetic data for (pre)training a convolutional neural net, which is then fine-tuned with observational data. When applied in silico, our meta-modeling approach yields better predictions than a baseline comprising a purely data-driven approach. When tested on real-world data from field trials (n=303) and commercial fields (n=77), the meta-modeling approach yields competitive results with respect to the crop growth model. In the latter set, however, both models perform worse than a simple linear regression with a hand-picked feature set and dedicated preprocessing designed by domain experts. Our findings indicate the potential of meta-modeling for accurate crop yield prediction; however, further advancements and validation using extensive real-world datasets is recommended to solidify its practical effectiveness.", "url": "https://arxiv.org/abs/2307.13466"}, {"metadata": {"arXiv": "2307.13565", "Date": "Tue, 25 Jul 2023 15:17:31 ", "Title": "Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities", "Authors": ["Jayanta Mandi", "James Kotary", "Senne Berden", "Maxime Mulamba", "Victor Bucarey", "Tias Guns and Ferdinando Fioretto"], "Categories": "cs.LG cs.AI math.OC", "Comments": ["Experimental Survey and Benchmarking"]}, "abstract": "Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system. This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock. This paper presents a comprehensive review of DFL. It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL. Finally, the study provides valuable insights into current and potential future avenues in DFL research.", "url": "https://arxiv.org/abs/2307.13565"}, {"metadata": {"arXiv": "2307.13579", "Date": "Tue, 25 Jul 2023 15:33:38 ", "Title": "Reinterpreting survival analysis in the universal approximator age", "Authors": ["S\\\"oren Dittmer", "Michael Roberts", "Jacobus Preller", "AIX COVNET", "James H.F. Rudd", "John A.D. Aston", "Carola-Bibiane Sch\\\"onlieb"], "Categories": "cs.LG cs.AI math.ST stat.TH"}, "abstract": "Survival analysis is an integral part of the statistical toolbox. However, while most domains of classical statistics have embraced deep learning, survival analysis only recently gained some minor attention from the deep learning community. This recent development is likely in part motivated by the COVID-19 pandemic. We aim to provide the tools needed to fully harness the potential of survival analysis in deep learning. On the one hand, we discuss how survival analysis connects to classification and regression. On the other hand, we provide technical tools. We provide a new loss function, evaluation metrics, and the first universal approximating network that provably produces survival curves without numeric integration. We show that the loss function and model outperform other approaches using a large numerical study.", "url": "https://arxiv.org/abs/2307.13579"}, {"metadata": {"arXiv": "2307.13642", "Date": "Tue, 25 Jul 2023 16:49:54 ", "Title": "Safety Margins for Reinforcement Learning", "Authors": ["Alexander Grushin", "Walt Woods", "Alvaro Velasquez", "Simon Khan"], "Categories": "cs.LG cs.AI", "Comments": ["2 pages", "2 figures. Presented at the 2023 IEEE Conference on Artificial Intelligence (CAI)", "Santa Clara", "CA"], "MSC-class": "68T07", "ACM-class": "I.2.6", "DOI": "10.1109/CAI54212.2023.00026"}, "abstract": "Any autonomous controller will be unsafe in some situations. The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications. In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions. Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states. The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations.", "url": "https://arxiv.org/abs/2307.13642"}, {"metadata": {"arXiv": "2307.13447", "Date": "Tue, 25 Jul 2023 12:19:35 ", "Title": "A behavioural transformer for effective collaboration between a robot and a non-stationary human", "Authors": ["Ruaridh Mon-Williams", "Theodoros Stouraitis and Sethu Vijayakumar"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["8 pages", "6 figures"]}, "abstract": "A key challenge in human-robot collaboration is the non-stationarity created by humans due to changes in their behaviour. This alters environmental transitions and hinders human-robot collaboration. We propose a principled meta-learning framework to explore how robots could better predict human behaviour, and thereby deal with issues of non-stationarity. On the basis of this framework, we developed Behaviour-Transform (BeTrans). BeTrans is a conditional transformer that enables a robot agent to adapt quickly to new human agents with non-stationary behaviours, due to its notable performance with sequential data. We trained BeTrans on simulated human agents with different systematic biases in collaborative settings. We used an original customisable environment to show that BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than SOTA techniques.", "url": "https://arxiv.org/abs/2307.13447"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.05232", "Date": "Wed, 09 Aug 2023 21:30:18 ", "Title": "SegMatch: A semi-supervised learning method for surgical instrument segmentation", "Authors": ["Meng Wei", "Charlie Budd", "Luis C. Garcia-Peraza-Herrera", "Reuben Dorent", "Miaojing Shi", "Tom Vercauteren"], "Categories": "cs.CV cs.LG", "Comments": ["preprint under review", "12 pages", "7 figures"]}, "abstract": "Surgical instrument segmentation is recognised as a key enabler to provide advanced surgical assistance and improve computer assisted interventions. In this work, we propose SegMatch, a semi supervised learning method to reduce the need for expensive annotation for laparoscopic and robotic surgical images. SegMatch builds on FixMatch, a widespread semi supervised classification pipeline combining consistency regularization and pseudo labelling, and adapts it for the purpose of segmentation. In our proposed SegMatch, the unlabelled images are weakly augmented and fed into the segmentation model to generate a pseudo-label to enforce the unsupervised loss against the output of the model for the adversarial augmented image on the pixels with a high confidence score. Our adaptation for segmentation tasks includes carefully considering the equivariance and invariance properties of the augmentation functions we rely on. To increase the relevance of our augmentations, we depart from using only handcrafted augmentations and introduce a trainable adversarial augmentation strategy. Our algorithm was evaluated on the MICCAI Instrument Segmentation Challenge datasets Robust-MIS 2019 and EndoVis 2017. Our results demonstrate that adding unlabelled data for training purposes allows us to surpass the performance of fully supervised approaches which are limited by the availability of training data in these challenges. SegMatch also outperforms a range of state-of-the-art semi-supervised learning semantic segmentation models in different labelled to unlabelled data ratios.", "url": "https://arxiv.org/abs/2308.05232"}, {"metadata": {"arXiv": "2308.05235", "Date": "Wed, 09 Aug 2023 21:39:57 ", "Title": "Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping", "Authors": ["Ali Jamali", "Swalpa Kumar Roy", "Danfeng Hong", "Peter M Atkinson", "Pedram Ghamisi"], "Categories": "cs.CV cs.LG", "Comments": ["Submitted in IEEE"]}, "abstract": "Convolutional Neural Networks (CNNs) are models that are utilized extensively for the hierarchical extraction of features. Vision transformers (ViTs), through the use of a self-attention mechanism, have recently achieved superior modeling of global contextual information compared to CNNs. However, to realize their image classification strength, ViTs require substantial training datasets. Where the available training data are limited, current advanced multi-layer perceptrons (MLPs) can provide viable alternatives to both deep CNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithm that effectively uses both MLPs and spatial gating units (SGUs) for precise land use land cover (LULC) mapping. Results illustrated the superiority of the developed SGU-MLP classification algorithm over several CNN and CNN-ViT-based models, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. The proposed SGU-MLP algorithm was tested through three experiments in Houston, USA, Berlin, Germany and Augsburg, Germany. The SGU-MLP classification model was found to consistently outperform the benchmark CNN and CNN-ViT-based algorithms. For example, for the Houston experiment, SGU-MLP significantly outperformed HybridSN, CoAtNet, Efficientformer, iFormer and ResNet by approximately 15%, 19%, 20%, 21%, and 25%, respectively, in terms of average accuracy. The code will be made publicly available at https://github.com/aj1365/SGUMLP", "url": "https://arxiv.org/abs/2308.05235"}, {"metadata": {"arXiv": "2308.05390", "Date": "Thu, 10 Aug 2023 07:09:13 ", "Title": "Product Review Image Ranking for Fashion E-commerce", "Authors": ["Sangeet Jaiswal", "Dhruv Patel", "Sreekanth Vempati", "Konduru Saiswaroop"], "Categories": "cs.CV cs.IR cs.LG", "Comments": ["Accepted in Proceedings of ACM SIGIR Workshop on eCommerce (SIGIR eCom'22)"]}, "abstract": "In a fashion e-commerce platform where customers can't physically examine the products on their own, being able to see other customers' text and image reviews of the product is critical while making purchase decisions. Given the high reliance on these reviews, over the years we have observed customers proactively sharing their reviews. With an increase in the coverage of User Generated Content (UGC), there has been a corresponding increase in the number of customer images. It is thus imperative to display the most relevant images on top as it may influence users' online shopping choices and behavior. In this paper, we propose a simple yet effective training procedure for ranking customer images. We created a dataset consisting of Myntra (A Major Indian Fashion e-commerce company) studio posts and highly engaged (upvotes/downvotes) UGC images as our starting point and used selected distortion techniques on the images of the above dataset to bring their quality at par with those of bad UGC images. We train our network to rank bad-quality images lower than high-quality ones. Our proposed method outperforms the baseline models on two metrics, namely correlation coefficient, and accuracy, by substantial margins.", "url": "https://arxiv.org/abs/2308.05390"}, {"metadata": {"arXiv": "2308.05525", "Date": "Thu, 10 Aug 2023 12:06:03 ", "Title": "Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI", "Authors": ["Meir Yossef Levi", "Guy Gilboa"], "Categories": "cs.CV cs.LG"}, "abstract": "The ability to cope accurately and fast with Out-Of-Distribution (OOD) samples is crucial in real-world safety demanding applications. In this work we first study the interplay between critical points of 3D point clouds and OOD samples. Our findings are that common corruptions and outliers are often interpreted as critical points. We generalize the notion of critical points into importance measures. We show that training a classification network based only on less important points dramatically improves robustness, at a cost of minor performance loss on the clean set. We observe that normalized entropy is highly informative for corruption analysis. An adaptive threshold based on normalized entropy is suggested for selecting the set of uncritical points. Our proposed importance measure is extremely fast to compute. We show it can be used for a variety of applications, such as Explainable AI (XAI), Outlier Removal, Uncertainty Estimation, Robust Classification and Adversarial Defense. We reach SOTA results on the two latter tasks.", "url": "https://arxiv.org/abs/2308.05525"}, {"metadata": {"arXiv": "2308.05633", "Date": "Thu, 10 Aug 2023 15:22:11 ", "Title": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer", "Authors": ["Keqiang Fan", "Xiaohao Cai", "Mahesan Niranjan"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Automated medical report generation has become increasingly important in medical analysis. It can produce computer-aided diagnosis descriptions and thus significantly alleviate the doctors' work. Inspired by the huge success of neural machine translation and image captioning, various deep learning methods have been proposed for medical report generation. However, due to the inherent properties of medical data, including data imbalance and the length and correlation between report sequences, the generated reports by existing methods may exhibit linguistic fluency but lack adequate clinical accuracy. In this work, we propose an image-to-indicator hierarchical transformer (IIHT) framework for medical report generation. It consists of three modules, i.e., a classifier module, an indicator expansion module and a generator module. The classifier module first extracts image features from the input medical images and produces disease-related indicators with their corresponding states. The disease-related indicators are subsequently utilised as input for the indicator expansion module, incorporating the \"data-text-data\" strategy. The transformer-based generator then leverages these extracted features along with image features as auxiliary information to generate final reports. Furthermore, the proposed IIHT method is feasible for radiologists to modify disease indicators in real-world scenarios and integrate the operations into the indicator expansion module for fluent and accurate medical report generation. Extensive experiments and comparisons with state-of-the-art methods under various evaluation metrics demonstrate the great performance of the proposed method.", "url": "https://arxiv.org/abs/2308.05633"}, {"metadata": {"arXiv": "2308.05739", "Date": "Thu, 10 Aug 2023 17:57:22 ", "Title": "Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics", "Authors": ["Michael Fischer", "Tobias Ritschel"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "Gradient-based optimization is now ubiquitous across graphics, but unfortunately can not be applied to problems with undefined or zero gradients. To circumvent this issue, the loss function can be manually replaced by a \"surrogate\" that has similar minima but is differentiable. Our proposed framework, ZeroGrads, automates this process by learning a neural approximation of the objective function, the surrogate, which in turn can be used to differentiate through arbitrary black-box graphics pipelines. We train the surrogate on an actively smoothed version of the objective and encourage locality, focusing the surrogate's capacity on what matters at the current training episode. The fitting is performed online, alongside the parameter optimization, and self-supervised, without pre-computed data or pre-trained models. As sampling the objective is expensive (it requires a full rendering or simulator run), we devise an efficient sampling scheme that allows for tractable run-times and competitive performance at little overhead. We demonstrate optimizing diverse non-convex, non-differentiable black-box problems in graphics, such as visibility in rendering, discrete parameter spaces in procedural modelling or optimal control in physics-driven animation. In contrast to more traditional algorithms, our approach scales well to higher dimensions, which we demonstrate on problems with up to 35k interlinked variables.", "url": "https://arxiv.org/abs/2308.05739"}, {"metadata": {"arXiv": "2308.05110", "Date": "Fri, 04 Aug 2023 04:28:07 ", "Title": "Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke", "Authors": ["Qizhang Feng", "Jiayi Yuan", "Forhan Bin Emdad", "Karim Hanna", "Xia Hu", "Zhe He"], "Categories": "cs.LG"}, "abstract": "Stroke is a significant cause of mortality and morbidity, necessitating early predictive strategies to minimize risks. Traditional methods for evaluating patients, such as Acute Physiology and Chronic Health Evaluation (APACHE II, IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy and interpretability. This paper proposes a novel approach: an interpretable, attention-based transformer model for early stroke mortality prediction. This model seeks to address the limitations of previous predictive models, providing both interpretability (providing clear, understandable explanations of the model) and fidelity (giving a truthful explanation of the model's dynamics from input to output). Furthermore, the study explores and compares fidelity and interpretability scores using Shapley values and attention-based scores to improve model explainability. The research objectives include designing an interpretable attention-based transformer model, evaluating its performance compared to existing models, and providing feature importance derived from the model.", "url": "https://arxiv.org/abs/2308.05110"}, {"metadata": {"arXiv": "2308.05120", "Date": "Tue, 08 Aug 2023 18:25:42 ", "Title": "Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems", "Authors": ["Edward Chen", "Han Bao", "Nam Dinh"], "Categories": "cs.LG", "Comments": ["This paper was originally presented at the 13th Nuclear Plant Instrumentation", "Control & Human-Machine Interface Technologies conference and was awarded best student paper"]}, "abstract": "In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at extrapolation. This occurs when new samples are \"far\" from training samples. The method, referred to as the Laplacian distributed decay for reliability (LADDR), determines the difference between the operational and training datasets, which is used to calculate a prediction's relative reliability. LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. LADDR is intended as a \"data supervisor\" and determines the appropriateness of well-trained ML models in the context of operational conditions. Ultimately, LADDR illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.", "url": "https://arxiv.org/abs/2308.05120"}, {"metadata": {"arXiv": "2308.05194", "Date": "Wed, 09 Aug 2023 19:21:50 ", "Title": "Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving", "Authors": ["Nico Uhlemann", "Felix Fent", "Markus Lienkamp"], "Categories": "cs.LG cs.RO", "Comments": ["Submitted to the IEEE Transactions on Intelligent Transportation Systems (T-ITS); 9 pages", "5 figures", "4 tables"]}, "abstract": "In this paper, the state of the art in the field of pedestrian trajectory prediction is evaluated alongside the constant velocity model (CVM) with respect to its applicability in autonomous vehicles. The evaluation is conducted on the widely-used ETH/UCY dataset where the Average Displacement Error (ADE) and the Final Displacement Error (FDE) are reported. To align with requirements in real-world applications, modifications are made to the input features of the initially proposed models. An ablation study is conducted to examine the influence of the observed motion history on the prediction performance, thereby establishing a better understanding of its impact. Additionally, the inference time of each model is measured to evaluate the scalability of each model when confronted with varying amounts of agents. The results demonstrate that simple models remain competitive when generating single trajectories, and certain features commonly thought of as useful have little impact on the overall performance across different architectures. Based on these findings, recommendations are proposed to guide the future development of trajectory prediction algorithms.", "url": "https://arxiv.org/abs/2308.05194"}, {"metadata": {"arXiv": "2308.05292", "Date": "Thu, 10 Aug 2023 02:14:23 ", "Title": "Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error", "Authors": ["Jie Peng", "Weiyu Li", "Qing Ling"], "Categories": "cs.LG"}, "abstract": "This paper studies Byzantine-robust stochastic optimization over a decentralized network, where every agent periodically communicates with its neighbors to exchange local models, and then updates its own local model by stochastic gradient descent (SGD). The performance of such a method is affected by an unknown number of Byzantine agents, which conduct adversarially during the optimization process. To the best of our knowledge, there is no existing work that simultaneously achieves a linear convergence speed and a small learning error. We observe that the learning error is largely dependent on the intrinsic stochastic gradient noise. Motivated by this observation, we introduce two variance reduction methods, stochastic average gradient algorithm (SAGA) and loopless stochastic variance-reduced gradient (LSVRG), to Byzantine-robust decentralized stochastic optimization for eliminating the negative effect of the stochastic gradient noise. The two resulting methods, BRAVO-SAGA and BRAVO-LSVRG, enjoy both linear convergence speeds and stochastic gradient noise-independent learning errors. Such learning errors are optimal for a class of methods based on total variation (TV)-norm regularization and stochastic subgradient update. We conduct extensive numerical experiments to demonstrate their effectiveness under various Byzantine attacks.", "url": "https://arxiv.org/abs/2308.05292"}, {"metadata": {"arXiv": "2308.05345", "Date": "Thu, 10 Aug 2023 05:24:41 ", "Title": "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model", "Authors": ["Yao Lu", "Shang Liu", "Qijun Zhang", "Zhiyao Xie"], "Categories": "cs.LG cs.AR"}, "abstract": "Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisingly effective prompt engineering technique named self-planning, which proves to significantly boost the performance of GPT-3.5 in our proposed benchmark.", "url": "https://arxiv.org/abs/2308.05345"}, {"metadata": {"arXiv": "2308.05463", "Date": "Thu, 10 Aug 2023 09:42:20 ", "Title": "$\\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns", "Authors": ["Qin Zhang", "Zelin Shi", "Xiaolin Zhang", "Xiaojun Chen", "Philippe Fournier-Viger", "Shirui Pan"], "Categories": "cs.LG", "Comments": ["8 pages", "1 figure"]}, "abstract": "Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e. $\\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and external unknown proxies are generated via mixup to efficiently anticipate the distribution of novel classes. Using the generated proxies, a closed-set classifier can be transformed into an open-set one, by augmenting it with an extra proxy classifier. Under the constraints of both cross entropy loss and complement entropy loss, $\\mathcal{G}^2Pxy$ achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments on benchmark graph datasets. Moreover, $\\mathcal{G}^2Pxy$ does not have specific requirement on the GNN architecture and shows good generalizations.", "url": "https://arxiv.org/abs/2308.05463"}, {"metadata": {"arXiv": "2308.05471", "Date": "Thu, 10 Aug 2023 09:52:44 ", "Title": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs", "Authors": ["Yuan Cheng", "Jing Yang", "Yingbin Liang"], "Categories": "cs.LG"}, "abstract": "Reinforcement learning (RL) under changing environment models many real-world applications via nonstationary Markov Decision Processes (MDPs), and hence gains considerable interest. However, theoretical studies on nonstationary MDPs in the literature have mainly focused on tabular and linear (mixture) MDPs, which do not capture the nature of unknown representation in deep RL. In this paper, we make the first effort to investigate nonstationary RL under episodic low-rank MDPs, where both transition kernels and rewards may vary over time, and the low-rank model contains unknown representation in addition to the linear state embedding function. We first propose a parameter-dependent policy optimization algorithm called PORTAL, and further improve PORTAL to its parameter-free version of Ada-PORTAL, which is able to tune its hyper-parameters adaptively without any prior knowledge of nonstationarity. For both algorithms, we provide upper bounds on the average dynamic suboptimality gap, which show that as long as the nonstationarity is not significantly large, PORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily small average dynamic suboptimality gap with polynomial sample complexity.", "url": "https://arxiv.org/abs/2308.05471"}, {"metadata": {"arXiv": "2308.05509", "Date": "Thu, 10 Aug 2023 11:42:09 ", "Title": "On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem", "Authors": ["Juncai He"], "Categories": "cs.LG cs.NA math.NA", "MSC-class": "41A30, 68T07, 65D40", "ACM-class": "G.1.1; G.1.2"}, "abstract": "This paper is devoted to studying the optimal expressive power of ReLU deep neural networks (DNNs) and its application in approximation via the Kolmogorov Superposition Theorem. We first constructively prove that any continuous piecewise linear functions on $[0,1]$, comprising $O(N^2L)$ segments, can be represented by ReLU DNNs with $L$ hidden layers and $N$ neurons per layer. Subsequently, we demonstrate that this construction is optimal regarding the parameter count of the DNNs, achieved through investigating the shattering capacity of ReLU DNNs. Moreover, by invoking the Kolmogorov Superposition Theorem, we achieve an enhanced approximation rate for ReLU DNNs of arbitrary width and depth when dealing with continuous functions in high-dimensional spaces.", "url": "https://arxiv.org/abs/2308.05509"}, {"metadata": {"arXiv": "2308.05566", "Date": "Thu, 10 Aug 2023 13:28:59 ", "Title": "AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting", "Authors": ["Oleksandr Shchur", "Caner Turkmen", "Nick Erickson", "Huibin Shen", "Alexander Shirkov", "Tony Hu", "Yuyang Wang"], "Categories": "cs.LG", "Comments": ["Published at AutoML Conference 2023"]}, "abstract": "We introduce AutoGluon-TimeSeries - an open-source AutoML library for probabilistic time series forecasting. Focused on ease of use and robustness, AutoGluon-TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code. Built on the design philosophy of AutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time. AutoGluon-TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques. In our evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in terms of both point and quantile forecast accuracy, and often even improving upon the best-in-hindsight combination of prior methods.", "url": "https://arxiv.org/abs/2308.05566"}, {"metadata": {"arXiv": "2308.05575", "Date": "Thu, 10 Aug 2023 13:39:19 ", "Title": "Symmetry Defense Against XGBoost Adversarial Perturbation Attacks", "Authors": ["Blerta Lindqvist"], "Categories": "cs.LG cs.CR", "Comments": ["16 pages"]}, "abstract": "We examine whether symmetry can be used to defend tree-based ensemble classifiers such as gradient-boosting decision trees (GBDTs) against adversarial perturbation attacks. The idea is based on a recent symmetry defense for convolutional neural network classifiers (CNNs) that utilizes CNNs' lack of invariance with respect to symmetries. CNNs lack invariance because they can classify a symmetric sample, such as a horizontally flipped image, differently from the original sample. CNNs' lack of invariance also means that CNNs can classify symmetric adversarial samples differently from the incorrect classification of adversarial samples. Using CNNs' lack of invariance, the recent CNN symmetry defense has shown that the classification of symmetric adversarial samples reverts to the correct sample classification. In order to apply the same symmetry defense to GBDTs, we examine GBDT invariance and are the first to show that GBDTs also lack invariance with respect to symmetries. We apply and evaluate the GBDT symmetry defense for nine datasets against six perturbation attacks with a threat model that ranges from zero-knowledge to perfect-knowledge adversaries. Using the feature inversion symmetry against zero-knowledge adversaries, we achieve up to 100% accuracy on adversarial samples even when default and robust classifiers have 0% accuracy. Using the feature inversion and horizontal flip symmetries against perfect-knowledge adversaries, we achieve up to over 95% accuracy on adversarial samples for the GBDT classifier of the F-MNIST dataset even when default and robust classifiers have 0% accuracy.", "url": "https://arxiv.org/abs/2308.05575"}, {"metadata": {"arXiv": "2308.05600", "Date": "Thu, 10 Aug 2023 14:19:58 ", "Title": "NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search", "Authors": ["Edouard Yvinec", "Arnaud Dapogny and Kevin Bailly"], "Categories": "cs.LG cs.CV"}, "abstract": "Deep neural network (DNN) deployment has been confined to larger hardware devices due to their expensive computational requirements. This challenge has recently reached another scale with the emergence of large language models (LLMs). In order to reduce both their memory footprint and latency, a promising technique is quantization. It consists in converting floating point representations to low bit-width fixed point representations, usually by assuming a uniform mapping onto a regular grid. This process, referred to in the literature as uniform quantization, may however be ill-suited as most DNN weights and activations follow a bell-shaped distribution. This is even worse on LLMs whose weight distributions are known to exhibit large, high impact, outlier values. In this work, we propose an improvement over the most commonly adopted way to tackle this limitation in deep learning models quantization, namely, non-uniform quantization. NUPES leverages automorphisms to preserve the scalar multiplications. Such transformations are derived from power functions. However, the optimization of the exponent parameter and weight values remains a challenging and novel problem which could not be solved with previous post training optimization techniques which only learn to round up or down weight values in order to preserve the predictive function. We circumvent this limitation with a new paradigm: learning new quantized weights over the entire quantized space. Similarly, we enable the optimization of the power exponent, i.e. the optimization of the quantization operator itself during training by alleviating all the numerical instabilities. The resulting predictive function is compatible with integer-only low-bit inference. We show the ability of the method to achieve state-of-the-art compression rates in both, data-free and data-driven configurations.", "url": "https://arxiv.org/abs/2308.05600"}, {"metadata": {"arXiv": "2308.05621", "Date": "Thu, 10 Aug 2023 15:10:08 ", "Title": "Normalized Gradients for All", "Authors": ["Francesco Orabona"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "In this short note, I show how to adapt to H\\\"{o}lder smoothness using normalized gradients in a black-box way. Moreover, the bound will depend on a novel notion of local H\\\"{o}lder smoothness. The main idea directly comes from Levy [2017].", "url": "https://arxiv.org/abs/2308.05621"}, {"metadata": {"arXiv": "2308.05629", "Date": "Thu, 10 Aug 2023 15:18:16 ", "Title": "ReLU and Addition-based Gated RNN", "Authors": ["Rickard Br\\\"annvall", "Henrik Forsgren", "Fredrik Sandin and Marcus Liwicki"], "Categories": "cs.LG", "Comments": ["12 pages", "4 tables"]}, "abstract": "We replace the multiplication and sigmoid function of the conventional recurrent gate with addition and ReLU activation. This mechanism is designed to maintain long-term memory for sequence processing but at a reduced computational cost, thereby opening up for more efficient execution or larger models on restricted hardware. Recurrent Neural Networks (RNNs) with gating mechanisms such as LSTM and GRU have been widely successful in learning from sequential data due to their ability to capture long-term dependencies. Conventionally, the update based on current inputs and the previous state history is each multiplied with dynamic weights and combined to compute the next state. However, multiplication can be computationally expensive, especially for certain hardware architectures or alternative arithmetic systems such as homomorphic encryption. It is demonstrated that the novel gating mechanism can capture long-term dependencies for a standard synthetic sequence learning task while significantly reducing computational costs such that execution time is reduced by half on CPU and by one-third under encryption. Experimental results on handwritten text recognition tasks furthermore show that the proposed architecture can be trained to achieve comparable accuracy to conventional GRU and LSTM baselines. The gating mechanism introduced in this paper may enable privacy-preserving AI applications operating under homomorphic encryption by avoiding the multiplication of encrypted variables. It can also support quantization in (unencrypted) plaintext applications, with the potential for substantial performance gains since the addition-based formulation can avoid the expansion to double precision often required for multiplication.", "url": "https://arxiv.org/abs/2308.05629"}, {"metadata": {"arXiv": "2308.05707", "Date": "Thu, 10 Aug 2023 17:14:07 ", "Title": "Shadow Datasets, New challenging datasets for Causal Representation Learning", "Authors": ["Jiageng Zhu", "Hanchen Xie", "Jianhua Wu", "Jiazhi Li", "Mahyar Khayatkhoei", "Mohamed E. Hussein", "Wael AbdAlmageed"], "Categories": "cs.LG cs.CV"}, "abstract": "Discovering causal relations among semantic factors is an emergent topic in representation learning. Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling. To resolve this restriction, weakly supervised CRL methods were introduced. To evaluate CRL performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and CelebA(SMILE), are utilized. However, existing CRL datasets are limited to simple graphs with few generative factors. Thus we propose two new datasets with a larger number of diverse generative factors and more sophisticated causal graphs. In addition, current real datasets, CelebA(BEARD) and CelebA(SMILE), the originally proposed causal graphs are not aligned with the dataset distributions. Thus, we propose modifications to them.", "url": "https://arxiv.org/abs/2308.05707"}, {"metadata": {"arXiv": "2308.05711", "Date": "Thu, 10 Aug 2023 17:20:02 ", "Title": "A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control", "Authors": ["Marshall Wang", "John Willes", "Thomas Jiralerspong", "Matin Moezzi"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Reinforcement learning (RL) is a promising approach for optimizing HVAC control. RL offers a framework for improving system performance, reducing energy consumption, and enhancing cost efficiency. We benchmark two popular classical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple HVAC environments and explore the practical consideration of model hyper-parameter selection and reward tuning. The findings provide insight for configuring RL agents in HVAC systems, promoting energy-efficient and cost-effective operation.", "url": "https://arxiv.org/abs/2308.05711"}, {"metadata": {"arXiv": "2308.05724", "Date": "Thu, 10 Aug 2023 17:39:51 ", "Title": "Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions", "Authors": ["Chinmay Rane", "Kanishka Tyagi", "Michael Manry"], "Categories": "cs.LG cs.CE cs.NE", "Comments": ["Under submission in Neurocomputing"]}, "abstract": "Deep learning training training algorithms are a huge success in recent years in many fields including speech, text,image video etc. Deeper and deeper layers are proposed with huge success with resnet structures having around 152 layers. Shallow convolution neural networks(CNN's) are still an active research, where some phenomena are still unexplained. Activation functions used in the network are of utmost importance, as they provide non linearity to the networks. Relu's are the most commonly used activation function.We show a complex piece-wise linear(PWL) activation in the hidden layer. We show that these PWL activations work much better than relu activations in our networks for convolution neural networks and multilayer perceptrons. Result comparison in PyTorch for shallow and deep CNNs are given to further strengthen our case.", "url": "https://arxiv.org/abs/2308.05724"}, {"metadata": {"arXiv": "2308.05483", "Date": "Thu, 10 Aug 2023 10:19:48 ", "Title": "Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics", "Authors": ["J. Huber", "F. H\\'el\\'enon", "M. Coninx", "F. Ben Amar", "S. Doncieux"], "Categories": "cs.RO cs.LG", "Comments": ["37 pages", "17 figures. Draft version"]}, "abstract": "Quality-Diversity (QD) methods are algorithms that aim to generate a set of diverse and high-performing solutions to a given problem. Originally developed for evolutionary robotics, most QD studies are conducted on a limited set of domains - mainly applied to locomotion, where the fitness and the behavior signal are dense. Grasping is a crucial task for manipulation in robotics. Despite the efforts of many research communities, this task is yet to be solved. Grasping cumulates unprecedented challenges in QD literature: it suffers from reward sparsity, behavioral sparsity, and behavior space misalignment. The present work studies how QD can address grasping. Experiments have been conducted on 15 different methods on 10 grasping domains, corresponding to 2 different robot-gripper setups and 5 standard objects. An evaluation framework that distinguishes the evaluation of an algorithm from its internal components has also been proposed for a fair comparison. The obtained results show that MAP-Elites variants that select successful solutions in priority outperform all the compared methods on the studied metrics by a large margin. We also found experimental evidence that sparse interaction can lead to deceptive novelty. To our knowledge, the ability to efficiently produce examples of grasping trajectories demonstrated in this work has no precedent in the literature.", "url": "https://arxiv.org/abs/2308.05483"}, {"metadata": {"arXiv": "2308.05737", "Date": "Thu, 10 Aug 2023 17:57:06 ", "Title": "Follow Anything: Open-set detection, tracking, and following in real-time", "Authors": ["Alaa Maalouf and Ninad Jadhav and Krishna Murthy Jatavallabhula and Makram Chahine and Daniel M.Vogt and Robert J. Wood and Antonio Torralba and Daniela Rus"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project webpage: https://github.com/alaamaalouf/FollowAnything Explainer video: https://www.youtube.com/watch?v=6Mgt3EPytrw"]}, "abstract": "Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop. FAn can be deployed on a laptop with a lightweight (6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. To enable rapid adoption, deployment, and extensibility, we open-source all our code on our project webpage at https://github.com/alaamaalouf/FollowAnything . We also encourage the reader the watch our 5-minutes explainer video in this https://www.youtube.com/watch?v=6Mgt3EPytrw .", "url": "https://arxiv.org/abs/2308.05737"}, {"metadata": {"arXiv": "2308.05201", "Date": "Wed, 09 Aug 2023 19:45:00 ", "Title": "\"Generate\" the Future of Work through AI: Empirical Evidence from Online Labor Markets", "Authors": ["Jin Liu (1)", "Xingchen Xu (2)", "Yongjun Li (1) and Yong Tan (2) ((1) University of Science and Technology of China", "(2) University of Washington)"], "Categories": "cs.AI cs.HC econ.GN q-fin.EC", "Comments": ["32 pages", "2 figures", "13 tables"], "ACM-class": "J.4"}, "abstract": "With the advent of general-purpose Generative AI, the interest in discerning its impact on the labor market escalates. In an attempt to bridge the extant empirical void, we interpret the launch of ChatGPT as an exogenous shock, and implement a Difference-in-Differences (DID) approach to quantify its influence on text-related jobs and freelancers within an online labor marketplace. Our results reveal a significant decrease in transaction volume for gigs and freelancers directly exposed to ChatGPT. Additionally, this decline is particularly marked in units of relatively higher past transaction volume or lower quality standards. Yet, the negative effect is not universally experienced among service providers. Subsequent analyses illustrate that freelancers proficiently adapting to novel advancements and offering services that augment AI technologies can yield substantial benefits amidst this transformative period. Consequently, even though the advent of ChatGPT could conceivably substitute existing occupations, it also unfolds immense opportunities and carries the potential to reconfigure the future of work. This research contributes to the limited empirical repository exploring the profound influence of LLM-based generative AI on the labor market, furnishing invaluable insights for workers, job intermediaries, and regulatory bodies navigating this evolving landscape.", "url": "https://arxiv.org/abs/2308.05201"}, {"metadata": {"arXiv": "2308.05260", "Date": "Wed, 09 Aug 2023 23:52:41 ", "Title": "AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL", "Authors": ["Marco Jiralerspong", "Gauthier Gidel"], "Categories": "cs.AI cs.CY", "Comments": ["Presented at AI For Global Climate Cooperation Competition", "2023 (arXiv:cs/2307.06951)"], "Report-no": "AI4GCC/2023/track3/4"}, "abstract": "The AI4GCC competition presents a bold step forward in the direction of integrating machine learning with traditional economic policy analysis. Below, we highlight two potential areas for improvement that could enhance the competition's ability to identify and evaluate proposed negotiation protocols. Firstly, we suggest the inclusion of an additional index that accounts for consumption/utility as part of the evaluation criteria. Secondly, we recommend further investigation into the learning dynamics of agents in the simulator and the game theoretic properties of outcomes from proposed negotiation protocols. We hope that these suggestions can be of use for future iterations of the competition/simulation.", "url": "https://arxiv.org/abs/2308.05260"}, {"metadata": {"arXiv": "2308.05295", "Date": "Thu, 10 Aug 2023 02:29:11 ", "Title": "Multimodal Pretrained Models for Sequential Decision-Making: Synthesis, Verification, Grounding, and Perception", "Authors": ["Yunhao Yang", "Cyrus Neary", "Ufuk Topcu"], "Categories": "cs.AI cs.FL", "Comments": ["27 pages", "19 figures", "submitted to AIJ"]}, "abstract": "Recently developed pretrained models can encode rich world knowledge expressed in multiple modalities, such as text and images. However, the outputs of these models cannot be integrated into algorithms to solve sequential decision-making tasks. We develop an algorithm that utilizes the knowledge from pretrained models to construct and verify controllers for sequential decision-making tasks, and to ground these controllers to task environments through visual observations. In particular, the algorithm queries a pretrained model with a user-provided, text-based task description and uses the model's output to construct an automaton-based controller that encodes the model's task-relevant knowledge. It then verifies whether the knowledge encoded in the controller is consistent with other independently available knowledge, which may include abstract information on the environment or user-provided specifications. If this verification step discovers any inconsistency, the algorithm automatically refines the controller to resolve the inconsistency. Next, the algorithm leverages the vision and language capabilities of pretrained models to ground the controller to the task environment. It collects image-based observations from the task environment and uses the pretrained model to link these observations to the text-based control logic encoded in the controller (e.g., actions and conditions that trigger the actions). We propose a mechanism to ensure the controller satisfies the user-provided specification even when perceptual uncertainties are present. We demonstrate the algorithm's ability to construct, verify, and ground automaton-based controllers through a suite of real-world tasks, including daily life and robot manipulation tasks.", "url": "https://arxiv.org/abs/2308.05295"}, {"metadata": {"arXiv": "2308.05385", "Date": "Thu, 10 Aug 2023 07:02:24 ", "Title": "Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification", "Authors": ["Tao Zou", "Le Yu", "Leilei Sun", "Bowen Du", "Deqing Wang", "Fuzhen Zhuang"], "Categories": "cs.AI", "Comments": ["13 pages"]}, "abstract": "Patent classification aims to assign multiple International Patent Classification (IPC) codes to a given patent. Recent methods for automatically classifying patents mainly focus on analyzing the text descriptions of patents. However, apart from the texts, each patent is also associated with some assignees, and the knowledge of their applied patents is often valuable for classification. Furthermore, the hierarchical taxonomy formulated by the IPC system provides important contextual information and enables models to leverage the correlations between IPC codes for more accurate classification. However, existing methods fail to incorporate the above aspects. In this paper, we propose an integrated framework that comprehensively considers the information on patents for patent classification. To be specific, we first present an IPC codes correlations learning module to derive their semantic representations via adaptively passing and aggregating messages within the same level and across different levels along the hierarchical taxonomy. Moreover, we design a historical application patterns learning component to incorporate the corresponding assignee's previous patents by a dual channel aggregation mechanism. Finally, we combine the contextual information of patent texts that contains the semantics of IPC codes, and assignees' sequential preferences to make predictions. Experiments on real-world datasets demonstrate the superiority of our approach over the existing methods. Besides, we present the model's ability to capture the temporal patterns of assignees and the semantic dependencies among IPC codes.", "url": "https://arxiv.org/abs/2308.05385"}, {"metadata": {"arXiv": "2308.05391", "Date": "Thu, 10 Aug 2023 07:12:11 ", "Title": "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges", "Authors": ["Sivan Schwartz", "Avi Yaeli", "Segev Shlomov"], "Categories": "cs.AI", "Comments": ["Accepted to the First International Workshop on the Future of No-Code Digital Apprentices"], "MSC-class": "68T01"}, "abstract": "Trust in AI agents has been extensively studied in the literature, resulting in significant advancements in our understanding of this field. However, the rapid advancements in Large Language Models (LLMs) and the emergence of LLM-based AI agent frameworks pose new challenges and opportunities for further research. In the field of process automation, a new generation of AI-based agents has emerged, enabling the execution of complex tasks. At the same time, the process of building automation has become more accessible to business users via user-friendly no-code tools and training mechanisms. This paper explores these new challenges and opportunities, analyzes the main aspects of trust in AI agents discussed in existing literature, and identifies specific considerations and challenges relevant to this new generation of automation agents. We also evaluate how nascent products in this category address these considerations. Finally, we highlight several challenges that the research community should address in this evolving landscape.", "url": "https://arxiv.org/abs/2308.05391"}, {"metadata": {"arXiv": "2308.05496", "Date": "Thu, 10 Aug 2023 10:59:24 ", "Title": "Exploring XAI for the Arts: Explaining Latent Space in Generative Music", "Authors": ["Nick Bryan-Kinns", "Berker Banar", "Corey Ford", "Courtney N. Reed", "Yixiao Zhang", "Simon Colton", "Jack Armitage"], "Categories": "cs.AI cs.HC"}, "abstract": "Explainable AI has the potential to support more interactive and fluid co-creative AI systems which can creatively collaborate with people. To do this, creative AI models need to be amenable to debugging by offering eXplainable AI (XAI) features which are inspectable, understandable, and modifiable. However, currently there is very little XAI for the arts. In this work, we demonstrate how a latent variable model for music generation can be made more explainable; specifically we extend MeasureVAE which generates measures of music. We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect of changes to latent space dimensions. We suggest that in doing so we bridge the gap between the latent space and the generated musical outcomes in a meaningful way which makes the model and its outputs more explainable and more debuggable.", "url": "https://arxiv.org/abs/2308.05496"}, {"metadata": {"arXiv": "2308.05501", "Date": "Thu, 10 Aug 2023 11:12:04 ", "Title": "More Than Meets the Eye: Analyzing Anesthesiologists' Visual Attention in the Operating Room Using Deep Learning Models", "Authors": ["Sapir Gershov", "Fadi Mahameed", "Aeyal Raz", "Shlomi Laufer"], "Categories": "cs.AI", "Comments": ["Submitted to MICCAI Aml4HC 2023"]}, "abstract": "Patient's vital signs, which are displayed on monitors, make the anesthesiologist's visual attention (VA) a key component in the safe management of patients under general anesthesia; moreover, the distribution of said VA and the ability to acquire specific cues throughout the anesthetic, may have a direct impact on patient's outcome. Currently, most studies employ wearable eye-tracking technologies to analyze anesthesiologists' visual patterns. Albeit being able to produce meticulous data, wearable devices are not a sustainable solution for large-scale or long-term use for data collection in the operating room (OR). Thus, by utilizing a novel eye-tracking method in the form of deep learning models that process monitor-mounted webcams, we collected continuous behavioral data and gained insight into the anesthesiologist's VA distribution with minimal disturbance to their natural workflow. In this study, we collected OR video recordings using the proposed framework and compared different visual behavioral patterns. We distinguished between baseline VA distribution during uneventful periods to patterns associated with active phases or during critical, unanticipated incidents. In the future, such a platform may serve as a crucial component of context-aware assistive technologies in the OR.", "url": "https://arxiv.org/abs/2308.05501"}, {"metadata": {"arXiv": "2308.05563", "Date": "Thu, 10 Aug 2023 13:24:27 ", "Title": "Recent Advancements In The Field Of Deepfake Detection", "Authors": ["Natalie Krueger", "Dr. Mounika Vanamala", "Dr. Rushit Dave"], "Categories": "cs.AI cs.CY"}, "abstract": "A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else. Deepfakes have the potential to cause a variety of problems and are often used maliciously. A common usage is altering videos of prominent political figures and celebrities. These deepfakes can portray them making offensive, problematic, and/or untrue statements. Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions. There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical. So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods. Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection.", "url": "https://arxiv.org/abs/2308.05563"}, {"metadata": {"arXiv": "2308.05567", "Date": "Thu, 10 Aug 2023 13:29:12 ", "Title": "C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT", "Authors": ["Pan Liang", "Danwei Ye", "Zihao Zhu", "Yunchao Wang", "Wang Xia", "Ronghua Liang", "and Guodao Sun"], "Categories": "cs.AI"}, "abstract": "Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks. In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses. However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT. To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q\\&A View. The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features. The Topic View is designed to display all the question and answer nodes and their relationships within a topic using the structure of a knowledge graph, thereby display the relevance and evolution of conversations. The Context-associated Q\\&A View consists of three linked views, which allow users to explore individual conversations deeply while providing specific contextual information when posing questions. The usefulness and effectiveness of C5 were evaluated through a case study and a user study.", "url": "https://arxiv.org/abs/2308.05567"}, {"metadata": {"arXiv": "2308.05583", "Date": "Thu, 10 Aug 2023 13:49:26 ", "Title": "Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling", "Authors": ["Ushnish Sengupta", "Chinkuo Jao", "Alberto Bernacchia", "Sattar Vakili and Da-shan Shiu"], "Categories": "cs.AI cs.CE cs.NI stat.ML", "Comments": ["2023 IEEE Global Communications Conference"]}, "abstract": "Channel modelling is essential to designing modern wireless communication systems. The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges. In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data. We use a diffusion model with a U Net based architecture operating in the frequency space domain. To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions. We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and high-fidelity samples from the true channel distribution. We also show that we can pretrain the model on a simulated urban macro-cellular channel dataset and fine-tune it on a smaller, out-of-distribution urban micro-cellular dataset, therefore showing that it is feasible to model real world channels using limited data with this approach.", "url": "https://arxiv.org/abs/2308.05583"}, {"metadata": {"arXiv": "2308.05585", "Date": "Thu, 10 Aug 2023 13:50:17 ", "Title": "Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length", "Authors": ["Miao Fan", "Chen Hu", "Shuchang Zhou"], "Categories": "cs.AI"}, "abstract": "The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role in shaping the impact of large language models (LLMs), contributing significantly to controlling output toxicity and selecting output styles, particularly as LLMs often harbor misleading content, highlighting the urgency to align them with human values for secure AI systems. The RLHF, characterized by complexity, instability, and sensitivity to hyperparameters, makes the evaluation of the reward model for complex tasks challenging, thereby further complicating the use of Proximal Policy Optimization (PPO). In this paper, we introduce a simple task designed to employ Gloden as a reward model that validates the effectiveness of PPO and inspires it, primarily explaining the task of utilizing PPO to manipulate the tokenizer length of the output generated by the model. Experiments confirm that PPO is not only effective in manipulating the output tokenizer length to a certain extent in this type of task but also exhibits facilitated training once the influence of the reward model effect is excluded, making it an exciting development.", "url": "https://arxiv.org/abs/2308.05585"}, {"metadata": {"arXiv": "2308.05617", "Date": "Thu, 10 Aug 2023 15:01:52 ", "Title": "A Neural Network Based Choice Model for Assortment Optimization", "Authors": ["Hanzhao Wang", "Zhongze Cai", "Xiaocheng Li", "Kalyan Talluri"], "Categories": "cs.AI", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2208.09325"]}, "abstract": "Discrete-choice models are used in economics, marketing and revenue management to predict customer purchase probabilities, say as a function of prices and other features of the offered assortment. While they have been shown to be expressive, capturing customer heterogeneity and behaviour, they are also hard to estimate, often based on many unobservables like utilities; and moreover, they still fail to capture many salient features of customer behaviour. A natural question then, given their success in other contexts, is if neural networks can eliminate the necessity of carefully building a context-dependent customer behaviour model and hand-coding and tuning the estimation. It is unclear however how one would incorporate assortment effects into such a neural network, and also how one would optimize the assortment with such a black-box generative model of choice probabilities. In this paper we investigate first whether a single neural network architecture can predict purchase probabilities for datasets from various contexts and generated under various models and assumptions. Next, we develop an assortment optimization formulation that is solvable by off-the-shelf integer programming solvers. We compare against a variety of benchmark discrete-choice models on simulated as well as real-world datasets, developing training tricks along the way to make the neural network prediction and subsequent optimization robust and comparable in performance to the alternates.", "url": "https://arxiv.org/abs/2308.05617"}, {"metadata": {"arXiv": "2308.05658", "Date": "Thu, 10 Aug 2023 15:57:47 ", "Title": "Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model", "Authors": ["Adu-Gyamfi Kojo", "Kandiboina Raghupathi", "Ravichandra-Mouli Varsha", "Knickerbocker Skylar", "Hans Zachary N", "Hawkins", "Neal R", "Sharma Anuj"], "Categories": "cs.AI stat.ML", "Comments": ["18 pages", "13 figures"]}, "abstract": "In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters. Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections. Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable. To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques. By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections. Experimental results demonstrate an impressive overall classification accuracy of 95%, with straight roads achieving a remarkable 97% F1 score and intersections reaching a 90% F1 score. This approach not only saves time and resources but also enables more frequent updates and a comprehensive understanding of the road network. Our research showcases the potential impact on traffic management, urban planning, and autonomous vehicle navigation systems. The fusion of connected vehicle data and deep learning models holds promise for a transformative shift in road infrastructure mapping, propelling us towards a smarter, safer, and more connected transportation ecosystem.", "url": "https://arxiv.org/abs/2308.05658"}, {"metadata": {"arXiv": "2308.05665", "Date": "Thu, 10 Aug 2023 16:06:10 ", "Title": "Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data", "Authors": ["Kojo Adu-Gyamfi", "Sharma Anuj"], "Categories": "cs.AI stat.ML", "Comments": ["15 pages", "11 figures"]}, "abstract": "Modern transportation planning relies heavily on accurate predictions of person and vehicle trips. However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions. This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning. Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips. The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models. As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation. This represents a significant improvement over the performances of traditional transportation planning models, thereby demonstrating the power of deep learning in this domain. The implications of this study extend beyond just more accurate predictions. By enhancing the accuracy and reliability of trip prediction models, planners can formulate more effective, data-driven transportation policies, infrastructure, and services. As such, our research underscores the need for the transportation planning field to embrace advanced techniques like deep learning. The detailed methodology, along with a thorough discussion of the results and their implications, are presented in the subsequent sections of this paper.", "url": "https://arxiv.org/abs/2308.05665"}, {"metadata": {"arXiv": "2308.05701", "Date": "Thu, 10 Aug 2023 17:04:51 ", "Title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving", "Authors": ["Daniel Bogdoll", "Lukas Bosch", "Tim Joseph", "Helen Gremmelmaier", "Yitian Yang", "J. Marius Z\\\"ollner"], "Categories": "cs.AI cs.RO"}, "abstract": "In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.", "url": "https://arxiv.org/abs/2308.05701"}, {"metadata": {"arXiv": "2308.05713", "Date": "Thu, 10 Aug 2023 17:22:28 ", "Title": "Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems", "Authors": ["Ernest Davis and Scott Aaronson"], "Categories": "cs.AI math.HO physics.pop-ph"}, "abstract": "This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often \"interface\" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.", "url": "https://arxiv.org/abs/2308.05713"}, {"metadata": {"arXiv": "2308.05242", "Date": "Wed, 09 Aug 2023 22:02:26 ", "Title": "Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis", "Authors": ["Luv Verma", "Varun Mohan"], "Categories": "cs.CV cs.AI", "Comments": ["16 pages", "18 figures"]}, "abstract": "This study performs an ablation analysis of Vector Quantized Generative Adversarial Networks (VQGANs), concentrating on image-to-image synthesis utilizing a single NVIDIA A100 GPU. The current work explores the nuanced effects of varying critical parameters including the number of epochs, image count, and attributes of codebook vectors and latent dimensions, specifically within the constraint of limited resources. Notably, our focus is pinpointed on the vector quantization loss, keeping other hyperparameters and loss components (GAN loss) fixed. This was done to delve into a deeper understanding of the discrete latent space, and to explore how varying its size affects the reconstruction. Though, our results do not surpass the existing benchmarks, however, our findings shed significant light on VQGAN's behaviour for a smaller dataset, particularly concerning artifacts, codebook size optimization, and comparative analysis with Principal Component Analysis (PCA). The study also uncovers the promising direction by introducing 2D positional encodings, revealing a marked reduction in artifacts and insights into balancing clarity and overfitting.", "url": "https://arxiv.org/abs/2308.05242"}, {"metadata": {"arXiv": "2308.05298", "Date": "Thu, 10 Aug 2023 02:41:18 ", "Title": "Double-chain Constraints for 3D Human Pose Estimation in Images and Videos", "Authors": ["Hongbo Kang", "Yong Wang", "Mengyuan Liu", "Doudou Wu", "Peng Liu", "Wenming Yang"], "Categories": "cs.CV cs.AI"}, "abstract": "Reconstructing 3D poses from 2D poses lacking depth information is particularly challenging due to the complexity and diversity of human motion. The key is to effectively model the spatial constraints between joints to leverage their inherent dependencies. Thus, we propose a novel model, called Double-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose through a double-chain design consisting of local-to-global and global-to-local chains to obtain a complex representation more suitable for the current human pose. Specifically, we combine the advantages of GCN and Transformer and design a Local Constraint Module (LCM) based on GCN and a Global Constraint Module (GCM) based on self-attention mechanism as well as a Feature Interaction Module (FIM). The proposed method fully captures the multi-level dependencies between human body joints to optimize the modeling capability of the model. Moreover, we propose a method to use temporal information into the single-frame model by guiding the video sequence embedding through the joint embedding of the target frame, with negligible increase in computational cost. Experimental results demonstrate that DC-GCT achieves state-of-the-art performance on two challenging datasets (Human3.6M and MPI-INF-3DHP). Notably, our model achieves state-of-the-art performance on all action categories in the Human3.6M dataset using detected 2D poses from CPN, and our code is available at: https://github.com/KHB1698/DC-GCT.", "url": "https://arxiv.org/abs/2308.05298"}, {"metadata": {"arXiv": "2308.05320", "Date": "Thu, 10 Aug 2023 03:44:10 ", "Title": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion", "Authors": ["Yanjie Li", "Mingxing Duan", "Bin Xiao"], "Categories": "cs.CV cs.AI"}, "abstract": "The rudimentary adversarial attacks utilize additive noise to attack facial recognition (FR) models. However, because manipulating the total face is impractical in the physical setting, most real-world FR attacks are based on adversarial patches, which limit perturbations to a small area. Previous adversarial patch attacks often resulted in unnatural patterns and clear boundaries that were easily noticeable. In this paper, we argue that generating adversarial patches with plausible content can result in stronger transferability than using additive noise or directly sampling from the latent space. To generate natural-looking and highly transferable adversarial patches, we propose an innovative two-stage coarse-to-fine attack framework called Adv-Inpainting. In the first stage, we propose an attention-guided StyleGAN (Att-StyleGAN) that adaptively combines texture and identity features based on the attention map to generate high-transferable and natural adversarial patches. In the second stage, we design a refinement network with a new boundary variance loss to further improve the coherence between the patch and its surrounding area. Experiment results demonstrate that Adv-Inpainting is stealthy and can produce adversarial patches with stronger transferability and improved visual quality than previous adversarial patch attacks.", "url": "https://arxiv.org/abs/2308.05320"}, {"metadata": {"arXiv": "2308.05478", "Date": "Thu, 10 Aug 2023 10:10:43 ", "Title": "Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar", "Authors": ["Patrick Palmer and Martin Krueger and Richard Altendorfer and Ganesh Adam and Torsten Bertram"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["Published at CVPR 2023 Workshop on 3D Vision and Robotics (https://drive.google.com/file/d/1xj4R5ucH3PaR7QdRDJbbkjS-3iBUsruR/view)"]}, "abstract": "Recent developments and the beginning market introduction of high-resolution imaging 4D (3+1D) radar sensors have initialized deep learning-based radar perception research. We investigate deep learning-based models operating on radar point clouds for 3D object detection. 3D object detection on lidar point cloud data is a mature area of 3D vision. Many different architectures have been proposed, each with strengths and weaknesses. Due to similarities between 3D lidar point clouds and 3+1D radar point clouds, those existing 3D object detectors are a natural basis to start deep learning-based 3D object detection on radar data. Thus, the first step is to analyze the detection performance of the existing models on the new data modality and evaluate them in depth. In order to apply existing 3D point cloud object detectors developed for lidar point clouds to the radar domain, they need to be adapted first. While some detectors, such as PointPillars, have already been adapted to be applicable to radar data, we have adapted others, e.g., Voxel R-CNN, SECOND, PointRCNN, and PV-RCNN. To this end, we conduct a cross-model validation (evaluating a set of models on one particular data set) as well as a cross-data set validation (evaluating all models in the model set on several data sets). The high-resolution radar data used are the View-of-Delft and Astyx data sets. Finally, we evaluate several adaptations of the models and their training procedures. We also discuss major factors influencing the detection performance on radar data and propose possible solutions indicating potential future research avenues.", "url": "https://arxiv.org/abs/2308.05478"}, {"metadata": {"arXiv": "2308.05515", "Date": "Thu, 10 Aug 2023 11:58:38 ", "Title": "Mono-hydra: Real-time 3D scene graph construction from monocular camera input with IMU", "Authors": ["U.V.B.L. Udugama", "G. Vosselman", "F. Nex"], "Categories": "cs.RO cs.AI", "Comments": ["7 pages", "5 figures", "GSW 2023 conference paper"]}, "abstract": "The ability of robots to autonomously navigate through 3D environments depends on their comprehension of spatial concepts, ranging from low-level geometry to high-level semantics, such as objects, places, and buildings. To enable such comprehension, 3D scene graphs have emerged as a robust tool for representing the environment as a layered graph of concepts and their relationships. However, building these representations using monocular vision systems in real-time remains a difficult task that has not been explored in depth. This paper puts forth a real-time spatial perception system Mono-Hydra, combining a monocular camera and an IMU sensor setup, focusing on indoor scenarios. However, the proposed approach is adaptable to outdoor applications, offering flexibility in its potential uses. The system employs a suite of deep learning algorithms to derive depth and semantics. It uses a robocentric visual-inertial odometry (VIO) algorithm based on square-root information, thereby ensuring consistent visual odometry with an IMU and a monocular camera. This system achieves sub-20 cm error in real-time processing at 15 fps, enabling real-time 3D scene graph construction using a laptop GPU (NVIDIA 3080). This enhances decision-making efficiency and effectiveness in simple camera setups, augmenting robotic system agility. We make Mono-Hydra publicly available at: https://github.com/UAV-Centre-ITC/Mono_Hydra", "url": "https://arxiv.org/abs/2308.05515"}, {"metadata": {"arXiv": "2308.05547", "Date": "Thu, 10 Aug 2023 12:55:57 ", "Title": "Enhancing AUV Autonomy With Model Predictive Path Integral Control", "Authors": ["Pierre Nicolay", "Yvan Petillot", "Mykhaylo Marfeychuk", "Sen Wang", "Ignacio Carlucho"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages", "11 figures"]}, "abstract": "Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine environments, carrying out underwater inspection tasks, and ocean exploration. However, in order to ensure that the AUV is able to carry out its mission successfully, a control system capable of adapting to changing environmental conditions is required. Furthermore, to ensure the robotic platform's safe operation, the onboard controller should be able to operate under certain constraints. In this work, we investigate the feasibility of Model Predictive Path Integral Control (MPPI) for the control of an AUV. We utilise a non-linear model of the AUV to propagate the samples of the MPPI, which allow us to compute the control action in real time. We provide a detailed evaluation of the effect of the main hyperparameters on the performance of the MPPI controller. Furthermore, we compared the performance of the proposed method with a classical PID and Cascade PID approach, demonstrating the superiority of our proposed controller. Finally, we present results where environmental constraints are added and show how MPPI can handle them by simply incorporating those constraints in the cost function.", "url": "https://arxiv.org/abs/2308.05547"}, {"metadata": {"arXiv": "2308.05612", "Date": "Thu, 10 Aug 2023 14:54:21 ", "Title": "A Smart Robotic System for Industrial Plant Supervision", "Authors": ["D. Adriana G\\'omez-Rosal (1)", "Max Bergau (2)", "Georg K.J. Fischer (3)", "Andreas Wachaja (4)", "Johannes Gr\\\"ater (4)", "Matthias Odenweller (5)", "Uwe Piechottka (5)", "Fabian Hoeflinger (6)", "Nikhil Gosala (1)", "Niklas Wetzel (1)", "Daniel B\\\"uscher (1)", "Abhinav Valada (1)", "Wolfram Burgard (7) ((1) Department of Computer Science", "University of Freiburg", "Germany (2) Sensors Automation Lab", "Endress+Hauser Digital Solutions GmbH", "Freiburg", "Germany (3) Fraunhofer Institute for Highspeed Dynamics", "Ernst-Mach-Institute (EMI)", "Freiburg", "Germany (4) dotscene GmbH", "Freiburg", "Germany (5) Evonik Operations GmbH", "Essen", "Germany (6) Telocate GmbH", "Freiburg", "Germany (7) Department of Engineering", "University of Technology Nuremberg", "Germany)"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted for publication in IEEE Sensors 2023"]}, "abstract": "In today's chemical production plants, human field operators perform frequent checks on the plant's integrity to guarantee high safety standards, and thus are possibly the first to encounter dangerous operating conditions. To alleviate their tasks of failure detection and monitoring by audio, visual, and olfactory perceptions, we present a robotic system that consists of an autonomously navigating robot integrated with various sensors and data processing. We aim to resemble the human sensing and interpretation capabilities of sight, smell, and hearing, for providing automated inspection. We evaluate our system extensively at a wastewater facility in full working conditions. Our results demonstrate that the system is able to robustly navigate a plant and to provide useful information about critical operating conditions.", "url": "https://arxiv.org/abs/2308.05612"}, {"metadata": {"arXiv": "2308.05374", "Date": "Thu, 10 Aug 2023 06:43:44 ", "Title": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment", "Authors": ["Yang Liu", "Yuanshun Yao", "Jean-Francois Ton", "Xiaoying Zhang", "Ruocheng Guo Hao Cheng", "Yegor Klochkov", "Muhammad Faaiz Taufiq", "and Hang Li"], "Categories": "cs.AI cs.LG"}, "abstract": "Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset of 8 sub-categories is selected for further investigation, where corresponding measurement studies are designed and conducted on several widely-used LLMs. The measurement results indicate that, in general, more aligned models tend to perform better in terms of overall trustworthiness. However, the effectiveness of alignment varies across the different trustworthiness categories considered. This highlights the importance of conducting more fine-grained analyses, testing, and making continuous improvements on LLM alignment. By shedding light on these key dimensions of LLM trustworthiness, this paper aims to provide valuable insights and guidance to practitioners in the field. Understanding and addressing these concerns will be crucial in achieving reliable and ethically sound deployment of LLMs in various applications.", "url": "https://arxiv.org/abs/2308.05374"}, {"metadata": {"arXiv": "2308.05411", "Date": "Thu, 10 Aug 2023 08:12:17 ", "Title": "Explainable AI applications in the Medical Domain: a systematic review", "Authors": ["Nicoletta Prentzas", "Antonis Kakas", "and Constantinos S. Pattichis"], "Categories": "cs.AI cs.LG"}, "abstract": "Artificial Intelligence in Medicine has made significant progress with emerging applications in medical imaging, patient care, and other areas. While these applications have proven successful in retrospective studies, very few of them were applied in practice.The field of Medical AI faces various challenges, in terms of building user trust, complying with regulations, using data ethically.Explainable AI (XAI) aims to enable humans understand AI and trust its results. This paper presents a literature review on the recent developments of XAI solutions for medical decision support, based on a representative sample of 198 articles published in recent years. The systematic synthesis of the relevant articles resulted in several findings. (1) model-agnostic XAI techniques were mostly employed in these solutions, (2) deep learning models are utilized more than other types of machine learning models, (3) explainability was applied to promote trust, but very few works reported the physicians participation in the loop, (4) visual and interactive user interface is more useful in understanding the explanation and the recommendation of the system. More research is needed in collaboration between medical and AI experts, that could guide the development of suitable frameworks for the design, implementation, and evaluation of XAI solutions in medicine.", "url": "https://arxiv.org/abs/2308.05411"}, {"metadata": {"arXiv": "2308.05522", "Date": "Thu, 10 Aug 2023 12:04:47 ", "Title": "Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning", "Authors": ["Paula Torren-Peraire", "Alan Kai Hassen", "Samuel Genheden", "Jonas Verhoeven", "Djork-Arne Clevert", "Mike Preuss", "Igor Tetko"], "Categories": "cs.AI cs.LG physics.chem-ph q-bio.BM", "Comments": ["The following authors contributed equally: Paula Torren-Peraire", "Alan Kai Hassen"]}, "abstract": "Retrosynthesis consists of breaking down a chemical compound recursively step-by-step into molecular precursors until a set of commercially available molecules is found with the goal to provide a synthesis route. Its two primary research directions, single-step retrosynthesis prediction, which models the chemical reaction logic, and multi-step synthesis planning, which tries to find the correct sequence of reactions, are inherently intertwined. Still, this connection is not reflected in contemporary research. In this work, we combine these two major research directions by applying multiple single-step retrosynthesis models within multi-step synthesis planning and analyzing their impact using public and proprietary reaction data. We find a disconnection between high single-step performance and potential route-finding success, suggesting that single-step models must be evaluated within synthesis planning in the future. Furthermore, we show that the commonly used single-step retrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluation task does not represent model performance and scalability on larger and more diverse datasets. For multi-step synthesis planning, we show that the choice of the single-step model can improve the overall success rate of synthesis planning by up to +28% compared to the commonly used baseline model. Finally, we show that each single-step model finds unique synthesis routes, and differs in aspects such as route-finding success, the number of found synthesis routes, and chemical validity, making the combination of single-step retrosynthesis prediction and multi-step synthesis planning a crucial aspect when developing future methods.", "url": "https://arxiv.org/abs/2308.05522"}, {"metadata": {"arXiv": "2308.05106", "Date": "Thu, 29 Jun 2023 19:44:02 ", "Title": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures", "Authors": ["Pajon Quentin", "Serre Swan", "Wissocq Hugo", "Rabaud L\\'eo", "Haidar Siba", "Yaacoub Antoun"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["8 pages", "2 figures", "FL-IJCAI'23"]}, "abstract": "This paper presents an investigation into machine learning techniques for violence detection in videos and their adaptation to a federated learning context. The study includes experiments with spatio-temporal features extracted from benchmark video datasets, comparison of different methods, and proposal of a modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\" Additionally, various machine learning techniques, including super-convergence and transfer learning, are explored, and a method for adapting centralized datasets to a federated learning context is developed. The research achieves better accuracy results compared to state-of-the-art models by training the best violence detection model in a federated learning context.", "url": "https://arxiv.org/abs/2308.05106"}, {"metadata": {"arXiv": "2308.05189", "Date": "Wed, 09 Aug 2023 18:49:21 ", "Title": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding", "Authors": ["Miguel-\\'Angel Fern\\'andez-Torres"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["PhD thesis"]}, "abstract": "This PhD. Thesis concerns the study and development of hierarchical representations for spatio-temporal visual attention modeling and understanding in video sequences. More specifically, we propose two computational models for visual attention. First, we present a generative probabilistic model for context-aware visual attention modeling and understanding. Secondly, we develop a deep network architecture for visual attention modeling, which first estimates top-down spatio-temporal visual attention, and ultimately serves for modeling attention in the temporal domain.", "url": "https://arxiv.org/abs/2308.05189"}, {"metadata": {"arXiv": "2308.05234", "Date": "Wed, 09 Aug 2023 21:39:10 ", "Title": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving", "Authors": ["Faisal Hawlader", "Fran\\c{c}ois Robinet", "and Rapha\\\"el Frank"], "Categories": "cs.CV cs.AI cs.DC cs.LG cs.NI"}, "abstract": "Environmental perception is a key element of autonomous driving because the information received from the perception module influences core driving decisions. An outstanding challenge in real-time perception for autonomous driving lies in finding the best trade-off between detection quality and latency. Major constraints on both computation and power have to be taken into account for real-time perception in autonomous vehicles. Larger object detection models tend to produce the best results, but are also slower at runtime. Since the most accurate detectors cannot run in real-time locally, we investigate the possibility of offloading computation to edge and cloud platforms, which are less resource-constrained. We create a synthetic dataset to train object detection models and evaluate different offloading strategies. Using real hardware and network simulations, we compare different trade-offs between prediction quality and end-to-end delay. Since sending raw frames over the network implies additional transmission delays, we also explore the use of JPEG and H.265 compression at varying qualities and measure their impact on prediction metrics. We show that models with adequate compression can be run in real-time on the cloud while outperforming local detection performance.", "url": "https://arxiv.org/abs/2308.05234"}, {"metadata": {"arXiv": "2308.05407", "Date": "Thu, 10 Aug 2023 08:03:58 ", "Title": "A Comparative Assessment of Multi-view fusion learning for Crop Classification", "Authors": ["Francisco Mena", "Diego Arenas", "Marlon Nuske", "Andreas Dengel"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at IEEE International Geoscience and Remote Sensing Symposium 2023"]}, "abstract": "With a rapidly increasing amount and diversity of remote sensing (RS) data sources, there is a strong need for multi-view learning modeling. This is a complex task when considering the differences in resolution, magnitude, and noise of RS data. The typical approach for merging multiple RS sources has been input-level fusion, but other - more advanced - fusion strategies may outperform this traditional approach. This work assesses different fusion strategies for crop classification in the CropHarvest dataset. The fusion methods proposed in this work outperform models based on individual views and previous fusion methods. We do not find one single fusion method that consistently outperforms all other approaches. Instead, we present a comparison of multi-view fusion methods for three different datasets and show that, depending on the test region, different methods obtain the best performance. Despite this, we suggest a preliminary criterion for the selection of fusion methods.", "url": "https://arxiv.org/abs/2308.05407"}, {"metadata": {"arXiv": "2308.05681", "Date": "Thu, 10 Aug 2023 16:34:20 ", "Title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient", "Authors": ["Zhengzhi Lu", "He Wang", "Ziyi Chang", "Guoan Yang and Hubert P. H. Shum"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks). All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming each dimension in the data is independent. The SMI gradient can augment many gradient-based attack methods, leading to a new family of no-box attack methods. Extensive evaluation and comparison show that our method imposes a real threat to existing classifiers. They also show that the SMI gradient improves the transferability and imperceptibility of adversarial samples in both no-box and transfer-based black-box settings.", "url": "https://arxiv.org/abs/2308.05681"}, {"metadata": {"arXiv": "2308.05741", "Date": "Thu, 10 Aug 2023 17:58:02 ", "Title": "Neural Progressive Meshes", "Authors": ["Yun-Chun Chen", "Vladimir G. Kim", "Noam Aigerman", "Alec Jacobson"], "Categories": "cs.CV cs.AI cs.GR cs.LG", "Comments": ["SIGGRAPH 2023"]}, "abstract": "The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation. We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality.", "url": "https://arxiv.org/abs/2308.05741"}, {"metadata": {"arXiv": "2308.05275", "Date": "Thu, 10 Aug 2023 01:25:28 ", "Title": "Cross-heterogeneity Graph Few-shot Learning", "Authors": ["Pengfei Ding and Yan Wang and Guanfeng Liu"], "Categories": "cs.LG cs.AI"}, "abstract": "In recent years, heterogeneous graph few-shot learning has been proposed to address the label sparsity issue in heterogeneous graphs (HGs), which contain various types of nodes and edges. The existing methods have achieved good performance by transferring generalized knowledge extracted from rich-labeled classes in source HG(s) to few-labeled classes in a target HG. However, these methods only consider the single-heterogeneity scenario where the source and target HGs share a fixed set of node/edge types, ignoring the more general scenario of cross-heterogeneity, where each HG can have a different and non-fixed set of node/edge types. To this end, we focus on the unexplored cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns to capture heterogeneous information and propose a multi-view heterogeneous graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose a score module to measure the informativeness of labeled samples and determine the transferability of each source HG. Finally, by integrating MHGN and the score module into a meta-learning mechanism, CGFL can effectively transfer generalized knowledge to predict new classes with few-labeled data. Extensive experiments on four real-world datasets have demonstrated the superior performance of CGFL over the state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.05275"}, {"metadata": {"arXiv": "2308.05309", "Date": "Thu, 10 Aug 2023 02:53:30 ", "Title": "Homophily-enhanced Structure Learning for Graph Clustering", "Authors": ["Ming Gu (1)", "Gaoming Yang (2)", "Sheng Zhou (3)", "Ning Ma (1)", "Jiawei Chen (1)", "Qiaoyu Tan (4)", "Meihan Liu (1)", "Jiajun Bu (1) ((1) College of Computer Science and Technology", "Zhejiang University", "(2) School of Software Technology", "Zhejiang University", "(3) Zhejiang Provincial Key Laboratory of Service Robot", "Zhejiang University", "(4) Department of Computer Science", "New York University Shanghai)"], "Categories": "cs.LG cs.AI cs.SI", "Comments": ["11 pages with 7 figures"]}, "abstract": "Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \\textbf{ho}mophily-enhanced structure \\textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve GNNs and clustering outcomes. To realize this objective, we develop two clustering-oriented structure learning modules, i.e., hierarchical correlation estimation and cluster-aware sparsification. The former module enables a more accurate estimation of pairwise node relationships by leveraging guidance from latent and clustering spaces, while the latter one generates a sparsified structure based on the similarity matrix and clustering assignments. Additionally, we devise a joint optimization approach alternating between training the homophily-enhanced structure learning and GNN-based clustering, thereby enforcing their reciprocal effects. Extensive experiments on seven benchmark datasets of various types and scales, across a range of clustering metrics, demonstrate the superiority of HoLe against state-of-the-art baselines.", "url": "https://arxiv.org/abs/2308.05309"}, {"metadata": {"arXiv": "2308.05601", "Date": "Thu, 10 Aug 2023 14:20:43 ", "Title": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction", "Authors": ["Weilong Ding", "Tianpu Zhang", "Jianwu Wang", "Zhuofeng Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Inter-city highway transportation is significant for urban life. As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations. On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction. On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration. In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning. In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations. And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features. Beside that, meteorology and calendar features are used by our model in the full connection stage to extra external characteristics of traffic flow. By extensive experiments and case studies in one Chinese provincial highway, our method shows clear improvement in predictive accuracy than baselines and practical benefits in business.", "url": "https://arxiv.org/abs/2308.05601"}, {"metadata": {"arXiv": "2308.05732", "Date": "Thu, 10 Aug 2023 17:53:05 ", "Title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers", "Authors": ["Phillip Lippe", "Bastiaan S. Veeling", "Paris Perdikaris", "Richard E. Turner", "Johannes Brandstetter"], "Categories": "cs.LG cs.AI", "Comments": ["Project website: https://phlippe.github.io/PDERefiner/"]}, "abstract": "Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of complex fluid dynamics, demonstrating stable and accurate rollouts that consistently outperform state-of-the-art models, including neural, numerical, and hybrid neural-numerical architectures. We further demonstrate that PDE-Refiner greatly enhances data efficiency, since the denoising objective implicitly induces a novel form of spectral data augmentation. Finally, PDE-Refiner's connection to diffusion models enables an accurate and efficient assessment of the model's predictive uncertainty, allowing us to estimate when the surrogate becomes inaccurate.", "url": "https://arxiv.org/abs/2308.05732"}, {"metadata": {"arXiv": "2308.05731", "Date": "Thu, 10 Aug 2023 17:53:03 ", "Title": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review", "Authors": ["Steffen Hagedorn", "Marcel Hallgarten", "Martin Stoll", "Alexandru Condurache"], "Categories": "cs.RO cs.AI cs.CV cs.LG cs.MA"}, "abstract": "Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking. We systematically review state-of-the-art deep learning-based prediction, planning, and integrated prediction and planning models. Different facets of the integration ranging from model architecture and model design to behavioral aspects are considered and related to each other. Moreover, we discuss the implications, strengths, and limitations of different integration methods. By pointing out research gaps, describing relevant future challenges, and highlighting trends in the research field, we identify promising directions for future research.", "url": "https://arxiv.org/abs/2308.05731"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

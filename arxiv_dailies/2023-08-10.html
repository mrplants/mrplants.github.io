<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.04553", "Date": "Tue, 08 Aug 2023 19:52:28 ", "Title": "From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data", "Authors": ["Maan Qraitem", "Kate Saenko", "Bryan A. Plummer"], "Categories": "cs.CV cs.LG"}, "abstract": "Visual recognition models are prone to learning spurious correlations induced by an imbalanced training set where certain groups (\\eg Females) are under-represented in certain classes (\\eg Programmers). Generative models offer a promising direction in mitigating this bias by generating synthetic data for the minority samples and thus balancing the training set. However, prior work that uses these approaches overlooks that visual recognition models could often learn to differentiate between real and synthetic images and thus fail to unlearn the bias in the original dataset. In our work, we propose a novel two-stage pipeline to mitigate this issue where 1) we pre-train a model on a balanced synthetic dataset and then 2) fine-tune on the real data. Using this pipeline, we avoid training on both real and synthetic data, thus avoiding the bias between real and synthetic data. Moreover, we learn robust features against the bias in the first step that mitigate the bias in the second step. Moreover, our pipeline naturally integrates with bias mitigation methods; they can be simply applied to the fine-tuning step. As our experiments prove, our pipeline can further improve the performance of bias mitigation methods obtaining state-of-the-art performance on three large-scale datasets.", "url": "https://arxiv.org/abs/2308.04553"}, {"metadata": {"arXiv": "2308.04669", "Date": "Wed, 09 Aug 2023 02:27:23 ", "Title": "A General Implicit Framework for Fast NeRF Composition and Rendering", "Authors": ["Xinyu Gao", "Ziyi Yang", "Yunlu Zhao", "Yuxiang Sun", "Xiaogang Jin", "Changqing Zou"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["7 pages for main content"]}, "abstract": "Recently, a variety of Neural radiance fields methods have garnered remarkable success in high render speed. However, current accelerating methods is specialized and not compatible for various implicit method, which prevent a real-time composition over different kinds of NeRF works. Since NeRF relies on sampling along rays, it's possible to provide a guidance generally. We propose a general implicit pipeline to rapidly compose NeRF objects. This new method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works.", "url": "https://arxiv.org/abs/2308.04669"}, {"metadata": {"arXiv": "2308.04771", "Date": "Wed, 09 Aug 2023 07:58:33 ", "Title": "SUnAA: Sparse Unmixing using Archetypal Analysis", "Authors": ["Behnood Rasti (HZDR)", "Alexandre Zouaoui (Thoth)", "Julien Mairal (Thoth)", "Jocelyn Chanussot (Thoth)"], "Categories": "cs.CV cs.LG eess.IV", "Journal-ref": "IEEE Geoscience and Remote Sensing Letters, 2023, 20, pp.1-5", "DOI": "10.1109/LGRS.2023.3284221"}, "abstract": "This paper introduces a new sparse unmixing technique using archetypal analysis (SUnAA). First, we design a new model based on archetypal analysis. We assume that the endmembers of interest are a convex combination of endmembers provided by a spectral library and that the number of endmembers of interest is known. Then, we propose a minimization problem. Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex. We minimize the optimization objective iteratively using an active set algorithm. Our method is robust to the initialization and only requires the number of endmembers of interest. SUnAA is evaluated using two simulated datasets for which results confirm its better performance over other conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite dataset and the results are compared visually with the available geological map provided for this dataset. The qualitative assessment demonstrates the successful estimation of the minerals abundances and significantly improves the detection of dominant minerals compared to the conventional regression-based sparse unmixing methods. The Python implementation of SUnAA can be found at: https://github.com/BehnoodRasti/SUnAA.", "url": "https://arxiv.org/abs/2308.04771"}, {"metadata": {"arXiv": "2308.04832", "Date": "Wed, 09 Aug 2023 09:40:34 ", "Title": "TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks", "Authors": ["Yuanhao Gong"], "Categories": "cs.CV cs.CL cs.LG cs.NE", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2307.16389"]}, "abstract": "Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.", "url": "https://arxiv.org/abs/2308.04832"}, {"metadata": {"arXiv": "2308.04934", "Date": "Wed, 09 Aug 2023 13:09:07 ", "Title": "JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition", "Authors": ["Lucian Bicsi", "Bogdan Alexe", "Radu Tudor Ionescu", "Marius Leordeanu"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted in ICCV 2023 Workshops"]}, "abstract": "We propose JEDI, a multi-dataset semi-supervised learning method, which efficiently combines knowledge from multiple experts, learned on different datasets, to train and improve the performance of individual, per dataset, student models. Our approach achieves this by addressing two important problems in current machine learning research: generalization across datasets and limitations of supervised training due to scarcity of labeled data. We start with an arbitrary number of experts, pretrained on their own specific dataset, which form the initial set of student models. The teachers are immediately derived by concatenating the feature representations from the penultimate layers of the students. We then train all models in a student-teacher semi-supervised learning scenario until convergence. In our efficient approach, student-teacher training is carried out jointly and end-to-end, showing that both students and teachers improve their generalization capacity during training. We validate our approach on four video action recognition datasets. By simultaneously considering all datasets within a unified semi-supervised setting, we demonstrate significant improvements over the initial experts.", "url": "https://arxiv.org/abs/2308.04934"}, {"metadata": {"arXiv": "2308.05032", "Date": "Wed, 09 Aug 2023 15:59:42 ", "Title": "Density Crop-guided Semi-supervised Object Detection in Aerial Images", "Authors": ["Akhil Meethal", "Eric Granger", "Marco Pedersoli"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages", "8 figures"]}, "abstract": "One of the important bottlenecks in training modern object detectors is the need for labeled images where bounding box annotations have to be produced for each object present in the image. This bottleneck is further exacerbated in aerial images where the annotators have to label small objects often distributed in clusters on high-resolution images. In recent days, the mean-teacher approach trained with pseudo-labels and weak-strong augmentation consistency is gaining popularity for semi-supervised object detection. However, a direct adaptation of such semi-supervised detectors for aerial images where small clustered objects are often present, might not lead to optimal results. In this paper, we propose a density crop-guided semi-supervised detector that identifies the cluster of small objects during training and also exploits them to improve performance at inference. During training, image crops of clusters identified from labeled and unlabeled images are used to augment the training set, which in turn increases the chance of detecting small objects and creating good pseudo-labels for small objects on the unlabeled images. During inference, the detector is not only able to detect the objects of interest but also regions with a high density of small objects (density crops) so that detections from the input image and detections from image crops are combined, resulting in an overall more accurate object prediction, especially for small objects. Empirical studies on the popular benchmarks of VisDrone and DOTA datasets show the effectiveness of our density crop-guided semi-supervised detector with an average improvement of more than 2\\% over the basic mean-teacher method in COCO style AP. Our code is available at: https://github.com/akhilpm/DroneSSOD.", "url": "https://arxiv.org/abs/2308.05032"}, {"metadata": {"arXiv": "2308.05092", "Date": "Wed, 09 Aug 2023 17:40:12 ", "Title": "A degree of image identification at sub-human scales could be possible with more advanced clusters", "Authors": ["Prateek Y J"], "Categories": "cs.CV cs.LG", "Comments": ["6 pages", "5 figures", "public code and model: https://github.com/PrateekJannu/imagescale2"]}, "abstract": "The purpose of the research is to determine if currently available self-supervised learning techniques can accomplish human level comprehension of visual images using the same degree and amount of sensory input that people acquire from. Initial research on this topic solely considered data volume scaling. Here, we scale both the volume of data and the quality of the image. This scaling experiment is a self-supervised learning method that may be done without any outside financing. We find that scaling up data volume and picture resolution at the same time enables human-level item detection performance at sub-human sizes.We run a scaling experiment with vision transformers trained on up to 200000 images up to 256 ppi.", "url": "https://arxiv.org/abs/2308.05092"}, {"metadata": {"arXiv": "2308.04450", "Date": "Fri, 04 Aug 2023 07:04:52 ", "Title": "High-Accuracy Prediction of Metal-Insulator-Metal Metasurface with Deep Learning", "Authors": ["Kaizhu Liu", "Hsiang-Chen Chui", "Changsen Sun", "and Xue Han"], "Categories": "cs.LG physics.comp-ph physics.optics"}, "abstract": "Deep learning prediction of electromagnetic software calculation results has been a widely discussed issue in recent years. But the prediction accuracy was still one of the challenges to be solved. In this work, we proposed that the ResNets-10 model was used for predicting plasmonic metasurface S11 parameters. The two-stage training was performed by the k-fold cross-validation and small learning rate. After the training was completed, the prediction loss for aluminum, gold, and silver metal-insulator-metal metasurfaces was -48.45, -46.47, and -35.54, respectively. Due to the ultralow error value, the proposed network can replace the traditional electromagnetic computing method for calculation within a certain structural range. Besides, this network can finish the training process less than 1,100 epochs. This means that the network training process can effectively lower the design process time. The ResNets-10 model we proposed can also be used to design meta-diffractive devices and biosensors, thereby reducing the time required for the calculation process. The ultralow error of the network indicates that this work contributes to the development of future artificial intelligence electromagnetic computing software.", "url": "https://arxiv.org/abs/2308.04450"}, {"metadata": {"arXiv": "2308.04457", "Date": "Sun, 06 Aug 2023 18:20:24 ", "Title": "A Critical Review of Physics-Informed Machine Learning Applications in Subsurface Energy Systems", "Authors": ["Abdeldjalil Latrach", "Mohamed Lamine Malki", "Misael Morales", "Mohamed Mehana", "Minou Rabiei"], "Categories": "cs.LG stat.ML"}, "abstract": "Machine learning has emerged as a powerful tool in various fields, including computer vision, natural language processing, and speech recognition. It can unravel hidden patterns within large data sets and reveal unparalleled insights, revolutionizing many industries and disciplines. However, machine and deep learning models lack interpretability and limited domain-specific knowledge, especially in applications such as physics and engineering. Alternatively, physics-informed machine learning (PIML) techniques integrate physics principles into data-driven models. By combining deep learning with domain knowledge, PIML improves the generalization of the model, abidance by the governing physical laws, and interpretability. This paper comprehensively reviews PIML applications related to subsurface energy systems, mainly in the oil and gas industry. The review highlights the successful utilization of PIML for tasks such as seismic applications, reservoir simulation, hydrocarbons production forecasting, and intelligent decision-making in the exploration and production stages. Additionally, it demonstrates PIML's capabilities to revolutionize the oil and gas industry and other emerging areas of interest, such as carbon and hydrogen storage; and geothermal systems by providing more accurate and reliable predictions for resource management and operational efficiency.", "url": "https://arxiv.org/abs/2308.04457"}, {"metadata": {"arXiv": "2308.04460", "Date": "Mon, 07 Aug 2023 23:10:32 ", "Title": "The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data", "Authors": ["Wencong Cheng", "Yan Yan", "Jiangjiang Xia", "Qi Liu", "Chang Qu", "Zhigang Wang"], "Categories": "cs.LG physics.ao-ph"}, "abstract": "Recently, multiple data-driven models based on machine learning for weather forecasting have emerged. These models are highly competitive in terms of accuracy compared to traditional numerical weather prediction (NWP) systems. In particular, the Pangu-Weather model, which is open source for non-commercial use, has been validated for its forecasting performance by the European Centre for Medium-Range Weather Forecasts (ECMWF) and has recently been published in the journal \"Nature\". In this paper, we evaluate the compatibility of the Pangu-Weather model with several commonly used NWP operational analyses through case studies. The results indicate that the Pangu-Weather model is compatible with different operational analyses from various NWP systems as the model initial conditions, and it exhibits a relatively stable forecasting capability. Furthermore, we have verified that improving the quality of global or local initial conditions significantly contributes to enhancing the forecasting performance of the Pangu-Weather model.", "url": "https://arxiv.org/abs/2308.04460"}, {"metadata": {"arXiv": "2308.04462", "Date": "Tue, 08 Aug 2023 01:53:26 ", "Title": "Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller", "Authors": ["K\\\"ubra Akba\\c{s}", "Carlotta Mummolo", "Xianlian Zhou"], "Categories": "cs.LG cs.RO cs.SY eess.SY"}, "abstract": "Balance assessment during physical rehabilitation often relies on rubric-oriented battery tests to score a patient's physical capabilities, leading to subjectivity. While some objective balance assessments exist, they are often limited to tracking the center of pressure (COP), which does not fully capture the whole-body postural stability. This study explores the use of the center of mass (COM) state space and presents a promising avenue for monitoring the balance capabilities in humans. We employ a musculoskeletal model integrated with a balance controller, trained through reinforcement learning (RL), to investigate balancing capabilities. The RL framework consists of two interconnected neural networks governing balance recovery and muscle coordination respectively, trained using Proximal Policy Optimization (PPO) with reference state initialization, early termination, and multiple training strategies. By exploring recovery from random initial COM states (position and velocity) space for a trained controller, we obtain the final BR enclosing successful balance recovery trajectories. Comparing the BRs with analytical postural stability limits from a linear inverted pendulum model, we observe a similar trend in successful COM states but more limited ranges in the recoverable areas. We further investigate the effect of muscle weakness and neural excitation delay on the BRs, revealing reduced balancing capability in different regions. Overall, our approach of learning muscular balance controllers presents a promising new method for establishing balance recovery limits and objectively assessing balance capability in bipedal systems, particularly in humans.", "url": "https://arxiv.org/abs/2308.04462"}, {"metadata": {"arXiv": "2308.04501", "Date": "Sat, 15 Jul 2023 22:01:28 ", "Title": "Investigation of compressor cascade flow based on physics-informed neural networks", "Authors": ["Zhihui Li", "Francesco Montomoli", "Sanjiv Sharma"], "Categories": "cs.LG physics.comp-ph physics.flu-dyn"}, "abstract": "In this study, we utilize the emerging Physics Informed Neural Networks (PINNs) approach for the first time to predict the flow field of a compressor cascade. The approach is demonstrated on a two-dimensional problem, incorporating Navier-Stokes equations in both the forward and inverse problems. In the forward problem, PINNs effectively predict the flow field of the compressor. The key advantage over Deep Neural Networks (DNNs) is that the PINNs model incorporates a physical relationship between the relevant quantities, resulting in more precise predictions. PINNs show obvious advantages over the traditional CFD approaches when dealing with inverse problems in the absence of partial boundary conditions. PINNs successfully reconstruct the flow field of the compressor cascade solely based on partial velocity vectors and wall pressure information. This research provides compelling evidence that PINNs offer turbomachinery designers a promising alternative to the current dominant CFD methods, delivering higher accuracy compared to DNNs.", "url": "https://arxiv.org/abs/2308.04501"}, {"metadata": {"arXiv": "2308.04588", "Date": "Tue, 08 Aug 2023 21:17:03 ", "Title": "ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems", "Authors": ["Harry Li", "Steven Jorgensen", "John Holodnak and Allan Wollaber"], "Categories": "cs.LG cs.HC", "Comments": ["5 pages", "4 figures", "accepted to IEEE VIS 2023"]}, "abstract": "Recently, uncertainty-aware deep learning methods for multiclass labeling problems have been developed that provide calibrated class prediction probabilities and out-of-distribution (OOD) indicators, letting machine learning (ML) consumers and engineers gauge a model's confidence in its predictions. However, this extra neural network prediction information is challenging to scalably convey visually for arbitrary data sources under multiple uncertainty contexts. To address these challenges, we present ScatterUQ, an interactive system that provides targeted visualizations to allow users to better understand model performance in context-driven uncertainty settings. ScatterUQ leverages recent advances in distance-aware neural networks, together with dimensionality reduction techniques, to construct robust, 2-D scatter plots explaining why a model predicts a test example to be (1) in-distribution and of a particular class, (2) in-distribution but unsure of the class, and (3) out-of-distribution. ML consumers and engineers can visually compare the salient features of test samples with training examples through the use of a ``hover callback'' to understand model uncertainty performance and decide follow up courses of action. We demonstrate the effectiveness of ScatterUQ to explain model uncertainty for a multiclass image classification on a distance-aware neural network trained on Fashion-MNIST and tested on Fashion-MNIST (in distribution) and MNIST digits (out of distribution), as well as a deep learning model for a cyber dataset. We quantitatively evaluate dimensionality reduction techniques to optimize our contextually driven UQ visualizations. Our results indicate that the ScatterUQ system should scale to arbitrary, multiclass datasets. Our code is available at https://github.com/mit-ll-responsible-ai/equine-webapp", "url": "https://arxiv.org/abs/2308.04588"}, {"metadata": {"arXiv": "2308.04595", "Date": "Tue, 08 Aug 2023 21:38:02 ", "Title": "Quantization Aware Factorization for Deep Neural Network Compression", "Authors": ["Daria Cherniuk", "Stanislav Abukhovich", "Anh-Huy Phan", "Ivan Oseledets", "Andrzej Cichocki", "Julia Gusak"], "Categories": "cs.LG"}, "abstract": "Tensor decomposition of convolutional and fully-connected layers is an effective way to reduce parameters and FLOP in neural networks. Due to memory and power consumption limitations of mobile or embedded devices, the quantization step is usually necessary when pre-trained models are deployed. A conventional post-training quantization approach applied to networks with decomposed weights yields a drop in accuracy. This motivated us to develop an algorithm that finds tensor approximation directly with quantized factors and thus benefit from both compression techniques while keeping the prediction quality of the model. Namely, we propose to use Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whose elements lie on a specified quantization grid. We compress neural network weights with a devised algorithm and evaluate it's prediction quality and performance. We compare our approach to state-of-the-art post-training quantization methods and demonstrate competitive results and high flexibility in achiving a desirable quality-performance tradeoff.", "url": "https://arxiv.org/abs/2308.04595"}, {"metadata": {"arXiv": "2308.04604", "Date": "Tue, 08 Aug 2023 22:07:15 ", "Title": "A Survey on Decentralized Federated Learning", "Authors": ["Edoardo Gabrielli", "Giovanni Pica", "Gabriele Tolomei"], "Categories": "cs.LG cs.CR cs.DC"}, "abstract": "In recent years, federated learning (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems. In contrast to standard ML, where data must be collected at the exact location where training is performed, FL takes advantage of the computational capabilities of millions of edge devices to collaboratively train a shared, global model without disclosing their local private data. Specifically, in a typical FL system, the central server acts only as an orchestrator; it iteratively gathers and aggregates all the local models trained by each client on its private data until convergence. Although FL undoubtedly has several benefits over traditional ML (e.g., it protects private data ownership by design), it suffers from several weaknesses. One of the most critical challenges is to overcome the centralized orchestration of the classical FL client-server architecture, which is known to be vulnerable to single-point-of-failure risks and man-in-the-middle attacks, among others. To mitigate such exposure, decentralized FL solutions have emerged where all FL clients cooperate and communicate without a central server. This survey comprehensively summarizes and reviews existing decentralized FL approaches proposed in the literature. Furthermore, it identifies emerging challenges and suggests promising research directions in this under-explored domain.", "url": "https://arxiv.org/abs/2308.04604"}, {"metadata": {"arXiv": "2308.04611", "Date": "Tue, 08 Aug 2023 22:30:47 ", "Title": "Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection", "Authors": ["Valentino Constantinou", "Michela Ravanelli", "Hamlin Liu", "Jacob Bortnik"], "Categories": "cs.LG physics.ao-ph"}, "abstract": "Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere, perturbing the Total Electron Content (TEC) - referred to as Traveling Ionospheric Disturbances (TIDs) that are detectable through the Global Navigation Satellite System (GNSS). The GNSS are constellations of satellites providing signals from Earth orbit - Europe's Galileo, the United States' Global Positioning System (GPS), Russia's Global'naya Navigatsionnaya Sputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection of TIDs provides an approach for tsunami detection, enhancing early warning systems by providing open-ocean coverage in geographic areas not serviceable by buoy-based warning systems. Large volumes of the GNSS data is leveraged by deep learning, which effectively handles complex non-linear relationships across thousands of data streams. We describe a framework leveraging slant total electron content (sTEC) from the VARION (Variometric Approach for Real-Time Ionosphere Observation) algorithm by Gramian Angular Difference Fields (from Computer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs in near-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012 Haida-Gwaii earthquakes and tsunamis are used in model training, and the later-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-sample model validation. Using the experimental framework described in the paper, we achieved a 91.7% F1 score. Source code is available at: https://github.com/vc1492a/tidd. Our work represents a new frontier in detecting tsunami-driven IGWs in open-ocean, dramatically improving the potential for natural hazards detection for coastal communities.", "url": "https://arxiv.org/abs/2308.04611"}, {"metadata": {"arXiv": "2308.04616", "Date": "Tue, 08 Aug 2023 22:47:12 ", "Title": "Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review", "Authors": ["Moein Razavi", "Samira Ziyadidegan", "Reza Jahromi", "Saber Kazeminasab", "Vahid Janfaza", "Ahmadreza Mahmoudzadeh", "Elaheh Baharlouei", "Farzan Sasangohar"], "Categories": "cs.LG"}, "abstract": "This comprehensive review systematically evaluates Machine Learning (ML) methodologies employed in the detection, prediction, and analysis of mental stress and its consequent mental disorders (MDs). Utilizing a rigorous scoping review process, the investigation delves into the latest ML algorithms, preprocessing techniques, and data types employed in the context of stress and stress-related MDs. The findings highlight that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently exhibit superior accuracy and robustness among all machine learning algorithms examined. Furthermore, the review underscores that physiological parameters, such as heart rate measurements and skin response, are prevalently used as stress predictors in ML algorithms. This is attributed to their rich explanatory information concerning stress and stress-related MDs, as well as the relative ease of data acquisition. Additionally, the application of dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, is frequently observed as a crucial step preceding the training of ML algorithms. The synthesis of this review identifies significant research gaps and outlines future directions for the field. These encompass areas such as model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.", "url": "https://arxiv.org/abs/2308.04616"}, {"metadata": {"arXiv": "2308.04617", "Date": "Tue, 08 Aug 2023 22:47:39 ", "Title": "Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection", "Authors": ["Hang Wang", "Zhen Xiang", "David J. Miller", "George Kesidis"], "Categories": "cs.LG cs.CR"}, "abstract": "Deep neural networks are vulnerable to backdoor attacks (Trojans), where an attacker poisons the training set with backdoor triggers so that the neural network learns to classify test-time triggers to the attacker's designated target class. Recent work shows that backdoor poisoning induces over-fitting (abnormally large activations) in the attacked model, which motivates a general, post-training clipping method for backdoor mitigation, i.e., with bounds on internal-layer activations learned using a small set of clean samples. We devise a new such approach, choosing the activation bounds to explicitly limit classification margins. This method gives superior performance against peer methods for CIFAR-10 image classification. We also show that this method has strong robustness against adaptive attacks, X2X attacks, and on different datasets. Finally, we demonstrate a method extension for test-time detection and correction based on the output differences between the original and activation-bounded networks. The code of our method is online available.", "url": "https://arxiv.org/abs/2308.04617"}, {"metadata": {"arXiv": "2308.04620", "Date": "Tue, 08 Aug 2023 22:54:47 ", "Title": "Multiclass Online Learnability under Bandit Feedback", "Authors": ["Ananth Raman", "Vinod Raman", "Unique Subedi", "Ambuj Tewari"], "Categories": "cs.LG stat.ML", "Comments": ["13 pages"]}, "abstract": "We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.", "url": "https://arxiv.org/abs/2308.04620"}, {"metadata": {"arXiv": "2308.04650", "Date": "Wed, 09 Aug 2023 01:30:07 ", "Title": "Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals", "Authors": ["Hyewon Jeong", "Collin M. Stultz", "Marzyeh Ghassemi"], "Categories": "cs.LG eess.SP q-bio.QM"}, "abstract": "Heart failure is a debilitating condition that affects millions of people worldwide and has a significant impact on their quality of life and mortality rates. An objective assessment of cardiac pressures remains an important method for the diagnosis and treatment prognostication for patients with heart failure. Although cardiac catheterization is the gold standard for estimating central hemodynamic pressures, it is an invasive procedure that carries inherent risks, making it a potentially dangerous procedure for some patients. Approaches that leverage non-invasive signals - such as electrocardiogram (ECG) - have the promise to make the routine estimation of cardiac pressures feasible in both inpatient and outpatient settings. Prior models trained to estimate intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) in a supervised fashion have shown good discriminatory ability but have been limited to the labeled dataset from the heart failure cohort. To address this issue and build a robust representation, we apply deep metric learning (DML) and propose a novel self-supervised DML with distance-based mining that improves the performance of a model with limited labels. We use a dataset that contains over 5.4 million ECGs without concomitant central pressure labels to pre-train a self-supervised DML model which showed improved classification of elevated mPCWP compared to self-supervised contrastive baselines. Additionally, the supervised DML model that is using ECGs with access to 8,172 mPCWP labels demonstrated significantly better performance on the mPCWP regression task compared to the supervised baseline. Moreover, our data suggest that DML yields models that are performant across patient subgroups, even when some patient subgroups are under-represented in the dataset. Our code is available at https://github.com/mandiehyewon/ssldml", "url": "https://arxiv.org/abs/2308.04650"}, {"metadata": {"arXiv": "2308.04660", "Date": "Wed, 09 Aug 2023 01:56:10 ", "Title": "Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets", "Authors": ["Wenlong Lyu", "Shoubo Hu", "Jie Chuai", "Zhitang Chen"], "Categories": "cs.LG"}, "abstract": "Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.", "url": "https://arxiv.org/abs/2308.04660"}, {"metadata": {"arXiv": "2308.04697", "Date": "Wed, 09 Aug 2023 04:16:48 ", "Title": "An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms", "Authors": ["Mamata Das", "P.J.A. Alphonse", "Selvakumar K"], "Categories": "cs.LG", "Comments": ["9 pages", "28 figures", "Fifth International Conference on Smart Computing and Informatics (SCI 2021)"], "Journal-ref": "Smart Intelligent Computing and Applications, Volume 1, SCI 2021"}, "abstract": "Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is initially identified in Wuhan of China in December of 2019 and now this deadly disease has spread all over the world. According to World Health Organization (WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case, many methods, AI base techniques, and machine learning algorithms have been researched and are being used to save people from this pandemic. The SARS-CoV and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences in the structure of cell proteins. Protein-protein interaction (PPI) is an essential process in our cells and plays a very important role in the development of medicines and gives ideas about the disease. In this study, we performed clustering on PPI networks generated from 92 genes of the Covi-19 dataset. We have used three graph-based clustering algorithms to give intuition to the analysis of clusters.", "url": "https://arxiv.org/abs/2308.04697"}, {"metadata": {"arXiv": "2308.04735", "Date": "Wed, 09 Aug 2023 07:00:59 ", "Title": "Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations", "Authors": ["Yongho Kim", "Yongho Choi"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["1 table", "6 figures"]}, "abstract": "Physics-informed neural networks have been widely applied to partial differential equations with great success because the physics-informed loss essentially requires no observations or discretization. However, it is difficult to optimize model parameters, and these parameters must be trained for each distinct initial condition. To overcome these challenges in second-order reaction-diffusion type equations, a possible way is to use five-point stencil convolutional neural networks (FCNNs). FCNNs are trained using two consecutive snapshots, where the time step corresponds to the step size of the given snapshots. Thus, the time evolution of FCNNs depends on the time step, and the time step must satisfy its CFL condition to avoid blow-up solutions. In this work, we propose deep FCNNs that have large receptive fields to predict time evolutions with a time step larger than the threshold of the CFL condition. To evaluate our models, we consider the heat, Fisher's, and Allen-Cahn equations with diverse initial conditions. We demonstrate that deep FCNNs retain certain accuracies, in contrast to FDMs that blow up.", "url": "https://arxiv.org/abs/2308.04735"}, {"metadata": {"arXiv": "2308.04755", "Date": "Wed, 09 Aug 2023 07:47:12 ", "Title": "Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data", "Authors": ["Lukas Prediger", "Joonas J\\\"alk\\\"o", "Antti Honkela", "Samuel Kaski"], "Categories": "cs.LG cs.CR"}, "abstract": "Consider a setting where multiple parties holding sensitive data aim to collaboratively learn population level statistics, but pooling the sensitive data sets is not possible. We propose a framework in which each party shares a differentially private synthetic twin of their data. We study the feasibility of combining such synthetic twin data sets for collaborative learning on real-world health data from the UK Biobank. We discover that parties engaging in the collaborative learning via shared synthetic data obtain more accurate estimates of target statistics compared to using only their local data. This finding extends to the difficult case of small heterogeneous data sets. Furthermore, the more parties participate, the larger and more consistent the improvements become. Finally, we find that data sharing can especially help parties whose data contain underrepresented groups to perform better-adjusted analysis for said groups. Based on our results we conclude that sharing of synthetic twins is a viable method for enabling learning from sensitive data without violating privacy constraints even if individual data sets are small or do not represent the overall population well. The setting of distributed sensitive data is often a bottleneck in biomedical research, which our study shows can be alleviated with privacy-preserving collaborative learning methods.", "url": "https://arxiv.org/abs/2308.04755"}, {"metadata": {"arXiv": "2308.04762", "Date": "Wed, 09 Aug 2023 07:51:07 ", "Title": "Tram-FL: Routing-based Model Training for Decentralized Federated Learning", "Authors": ["Kota Maejima", "Takayuki Nishio", "Asato Yamazaki", "and Yuko Hara-Azumi"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"], "MSC-class": "68T20 (Primary) 68M14 (Secondary)", "ACM-class": "I.2.7; I.2.8; I.2.10; I.2.11"}, "abstract": "In decentralized federated learning (DFL), substantial traffic from frequent inter-node communication and non-independent and identically distributed (non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL, a novel DFL method, which progressively refines a global model by transferring it sequentially amongst nodes, rather than by exchanging and aggregating local models. We also introduce a dynamic model routing algorithm for optimal route selection, aimed at enhancing model precision with minimal forwarding. Our experiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FL with the proposed routing delivers high model accuracy under non-IID conditions, outperforming baselines while reducing communication costs.", "url": "https://arxiv.org/abs/2308.04762"}, {"metadata": {"arXiv": "2308.04791", "Date": "Wed, 09 Aug 2023 08:30:22 ", "Title": "PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer", "Authors": ["Shengsheng Lin", "Weiwei Lin", "Wentai Wu", "Songbo Wang", "Yongxiang Wang,"], "Categories": "cs.LG"}, "abstract": "Recently, Transformer-based models have shown remarkable performance in long-term time series forecasting (LTSF) tasks due to their ability to model long-term dependencies. However, the validity of Transformers for LTSF tasks remains debatable, particularly since recent work has shown that simple linear models can outperform numerous Transformer-based approaches. This suggests that there are limitations to the application of Transformer in LTSF. Therefore, this paper investigates three key issues when applying Transformer to LTSF: temporal continuity, information density, and multi-channel relationships. Accordingly, we propose three innovative solutions, including Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI), which together form a novel model called PETformer. These three key designs introduce prior biases suitable for LTSF tasks. Extensive experiments have demonstrated that PETformer achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.", "url": "https://arxiv.org/abs/2308.04791"}, {"metadata": {"arXiv": "2308.04836", "Date": "Wed, 09 Aug 2023 09:58:42 ", "Title": "Intrinsic Motivation via Surprise Memory", "Authors": ["Hung Le", "Kien Do", "Dung Nguyen", "Svetha Venkatesh"], "Categories": "cs.LG", "Comments": ["Preprint"]}, "abstract": "We present a new computing model for intrinsic rewards in reinforcement learning that addresses the limitations of existing surprise-driven explorations. The reward is the novelty of the surprise rather than the surprise norm. We estimate the surprise novelty as retrieval errors of a memory network wherein the memory stores and reconstructs surprises. Our surprise memory (SM) augments the capability of surprise-based intrinsic motivators, maintaining the agent's interest in exciting exploration while reducing unwanted attraction to unpredictable or noisy observations. Our experiments demonstrate that the SM combined with various surprise predictors exhibits efficient exploring behaviors and significantly boosts the final performance in sparse reward environments, including Noisy-TV, navigation and challenging Atari games.", "url": "https://arxiv.org/abs/2308.04836"}, {"metadata": {"arXiv": "2308.04870", "Date": "Wed, 09 Aug 2023 11:09:14 ", "Title": "Decorrelating neurons using persistence", "Authors": ["Rub\\'en Ballester", "Carles Casacuberta", "Sergio Escalera"], "Categories": "cs.LG math.AT stat.ML", "Comments": ["15 pages", "4 figures"], "MSC-class": "55N31, 68T07", "ACM-class": "I.2.6"}, "abstract": "We propose a novel way to improve the generalisation capacity of deep learning models by reducing high correlations between neurons. For this, we present two regularisation terms computed from the weights of a minimum spanning tree of the clique whose vertices are the neurons of a given network (or a sample of those), where weights on edges are correlation dissimilarities. We provide an extensive set of experiments to validate the effectiveness of our terms, showing that they outperform popular ones. Also, we demonstrate that naive minimisation of all correlations between neurons obtains lower accuracies than our regularisation terms, suggesting that redundancies play a significant role in artificial neural networks, as evidenced by some studies in neuroscience for real networks. We include a proof of differentiability of our regularisers, thus developing the first effective topological persistence-based regularisation terms that consider the whole set of neurons and that can be applied to a feedforward architecture in any deep learning task such as classification, data generation, or regression.", "url": "https://arxiv.org/abs/2308.04870"}, {"metadata": {"arXiv": "2308.04896", "Date": "Tue, 08 Aug 2023 06:45:15 ", "Title": "Why Data Science Projects Fail", "Authors": ["Balaram Panda (The University of Auckland)"], "Categories": "cs.LG cs.CY cs.DB stat.ME", "Comments": ["Proposed Enhanced Approach for Advancing Data Science Excellence"]}, "abstract": "Data Science is a modern Data Intelligence practice, which is the core of many businesses and helps businesses build smart strategies around to deal with businesses challenges more efficiently. Data Science practice also helps in automating business processes using the algorithm, and it has several other benefits, which also deliver in a non-profitable framework. In regards to data science, three key components primarily influence the effective outcome of a data science project. Those are 1.Availability of Data 2.Algorithm 3.Processing power or infrastructure", "url": "https://arxiv.org/abs/2308.04896"}, {"metadata": {"arXiv": "2308.04901", "Date": "Wed, 09 Aug 2023 12:03:12 ", "Title": "Towards true discovery of the differential equations", "Authors": ["Alexander Hvatov and Roman Titov"], "Categories": "cs.LG", "Comments": ["Knowledge and Logical Reasoning in the Era of Data-driven Learning workshop at ICML 2023"]}, "abstract": "Differential equation discovery, a machine learning subfield, is used to develop interpretable models, particularly in nature-related applications. By expertly incorporating the general parametric form of the equation of motion and appropriate differential terms, algorithms can autonomously uncover equations from data. This paper explores the prerequisites and tools for independent equation discovery without expert input, eliminating the need for equation form assumptions. We focus on addressing the challenge of assessing the adequacy of discovered equations when the correct equation is unknown, with the aim of providing insights for reliable equation discovery without prior knowledge of the equation form.", "url": "https://arxiv.org/abs/2308.04901"}, {"metadata": {"arXiv": "2308.04943", "Date": "Wed, 09 Aug 2023 13:18:41 ", "Title": "Differentially Private Graph Neural Network with Importance-Grained Noise Adaption", "Authors": ["Yuxin Qi", "Xi Lin", "Jun Wu"], "Categories": "cs.LG cs.CR"}, "abstract": "Graph Neural Networks (GNNs) with differential privacy have been proposed to preserve graph privacy when nodes represent personal and sensitive information. However, the existing methods ignore that nodes with different importance may yield diverse privacy demands, which may lead to over-protect some nodes and decrease model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that need to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.", "url": "https://arxiv.org/abs/2308.04943"}, {"metadata": {"arXiv": "2308.04964", "Date": "Wed, 09 Aug 2023 13:58:03 ", "Title": "Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning", "Authors": ["Biagio Montaruli", "Luca Demetrio", "Andrea Valenza", "Battista Biggio", "Luca Compagna", "Davide Balzarotti", "Davide Ariu", "Luca Piras"], "Categories": "cs.LG cs.CR"}, "abstract": "ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towards the protected web services, achieves a better trade-off between detection and false positive rates, improving the detection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover, our approach is able to improve its adversarial robustness against adversarial SQLi attacks by 42%, thereby taking a step forward towards building more robust and trustworthy WAFs.", "url": "https://arxiv.org/abs/2308.04964"}, {"metadata": {"arXiv": "2308.04978", "Date": "Wed, 09 Aug 2023 14:22:18 ", "Title": "Transferable Models for Bioacoustics with Human Language Supervision", "Authors": ["David Robinson", "Adelaide Robinson", "Lily Akrapongpisak"], "Categories": "cs.LG cs.SD eess.AS q-bio.QM"}, "abstract": "Passive acoustic monitoring offers a scalable, non-invasive method for tracking global biodiversity and anthropogenic impacts on species. Although deep learning has become a vital tool for processing this data, current models are inflexible, typically cover only a handful of species, and are limited by data scarcity. In this work, we propose BioLingual, a new model for bioacoustics based on contrastive language-audio pretraining. We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, with over a million audio-caption pairs holding information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to be flexibly queried in human language, we believe this model opens new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We open-source our models, dataset, and code.", "url": "https://arxiv.org/abs/2308.04978"}, {"metadata": {"arXiv": "2308.05011", "Date": "Wed, 09 Aug 2023 15:10:53 ", "Title": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories", "Authors": ["P\\'erez-Carrasco Manuel", "Cabrera-Vives Guillermo", "Hern\\'andez-Garc\\'ia Lorena", "Forster Francisco", "S\\'anchez-S\\'aez Paula", "Mu\\~noz Arancibia Alejandra", "Astorga Nicol\\'as", "Bauer Franz", "Bayo Amelia", "C\\'adiz-Leyton Martina", "Catelan Marcio"], "Categories": "cs.LG astro-ph.IM"}, "abstract": "With the increasing volume of astronomical data generated by modern survey telescopes, automated pipelines and machine learning techniques have become crucial for analyzing and extracting knowledge from these datasets. Anomaly detection, i.e. the task of identifying irregular or unexpected patterns in the data, is a complex challenge in astronomy. In this paper, we propose Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically designed to handle different inlier categories with distinct data distributions. MCDSVDD uses a neural network to map the data into hyperspheres, where each hypersphere represents a specific inlier category. The distance of each sample from the centers of these hyperspheres determines the anomaly score. We evaluate the effectiveness of MCDSVDD by comparing its performance with several anomaly detection algorithms on a large dataset of astronomical light-curves obtained from the Zwicky Transient Facility. Our results demonstrate the efficacy of MCDSVDD in detecting anomalous sources while leveraging the presence of different inlier categories. The code and the data needed to reproduce our results are publicly available at https://github.com/mperezcarrasco/AnomalyALeRCE.", "url": "https://arxiv.org/abs/2308.05011"}, {"metadata": {"arXiv": "2308.05017", "Date": "Wed, 09 Aug 2023 15:27:21 ", "Title": "When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis", "Authors": ["Yiyou Sun", "Zhenmei Shi", "Yingyu Liang", "Yixuan Li"], "Categories": "cs.LG", "Comments": ["ICML 2023"]}, "abstract": "Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.", "url": "https://arxiv.org/abs/2308.05017"}, {"metadata": {"arXiv": "2308.05021", "Date": "Wed, 09 Aug 2023 15:31:17 ", "Title": "Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization", "Authors": ["Yangming Li", "Zhaozhi Qian", "Mihaela van der Schaar"], "Categories": "cs.LG cs.CV"}, "abstract": "While diffusion models have achieved promising performances in data synthesis, they might suffer error propagation because of their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, a strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation and we then propose a regularization to address this problem. Our theoretical analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module can't recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes. We further introduce a bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.", "url": "https://arxiv.org/abs/2308.05021"}, {"metadata": {"arXiv": "2308.05059", "Date": "Wed, 09 Aug 2023 16:41:00 ", "Title": "A Novel Method for improving accuracy in neural network by reinstating traditional back propagation technique", "Authors": ["Gokulprasath R"], "Categories": "cs.LG cs.CV"}, "abstract": "Deep learning has revolutionized industries like computer vision, natural language processing, and speech recognition. However, back propagation, the main method for training deep neural networks, faces challenges like computational overhead and vanishing gradients. In this paper, we propose a novel instant parameter update methodology that eliminates the need for computing gradients at each layer. Our approach accelerates learning, avoids the vanishing gradient problem, and outperforms state-of-the-art methods on benchmark data sets. This research presents a promising direction for efficient and effective deep neural network training.", "url": "https://arxiv.org/abs/2308.05059"}, {"metadata": {"arXiv": "2308.05061", "Date": "Wed, 09 Aug 2023 16:44:25 ", "Title": "Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language", "Authors": ["Liu Yang", "Tingwei Meng", "Siting Liu", "Stanley J. Osher"], "Categories": "cs.LG cs.NA math.NA stat.ML"}, "abstract": "In the growing domain of scientific machine learning, in-context operator learning has demonstrated notable potential in learning operators from prompted data during inference stage without weight updates. However, the current model's overdependence on sensor data, may inadvertently overlook the invaluable human insight into the operator. To address this, we present a transformation of in-context operator learning into a multi-modal paradigm. We propose the use of \"captions\" to integrate human knowledge about the operator, expressed through natural language descriptions and equations. We illustrate how this method not only broadens the flexibility and generality of physics-informed learning, but also significantly boosts learning performance and reduces data needs. Furthermore, we introduce a more efficient neural network architecture for multi-modal in-context operator learning, referred to as \"ICON-LM\", based on a language-model-like architecture. We demonstrate the viability of \"ICON-LM\" for scientific machine learning tasks, which creates a new path for the application of language models.", "url": "https://arxiv.org/abs/2308.05061"}, {"metadata": {"arXiv": "2308.05075", "Date": "Wed, 09 Aug 2023 17:08:29 ", "Title": "Bayesian Inverse Transition Learning for Offline Settings", "Authors": ["Leo Benac", "Sonali Parbhoo", "Finale Doshi-Velez"], "Categories": "cs.LG", "Comments": ["8 pages", "1 plots", "2 tables"]}, "abstract": "Offline Reinforcement learning is commonly used for sequential decision-making in domains such as healthcare and education, where the rewards are known and the transition dynamics $T$ must be estimated on the basis of batch data. A key challenge for all tasks is how to learn a reliable estimate of the transition dynamics $T$ that produce near-optimal policies that are safe enough so that they never take actions that are far away from the best action with respect to their value functions and informative enough so that they communicate the uncertainties they have. Using data from an expert, we propose a new constraint-based approach that captures our desiderata for reliably learning a posterior distribution of the transition dynamics $T$ that is free from gradients. Our results demonstrate that by using our constraints, we learn a high-performing policy, while considerably reducing the policy's variance over different datasets. We also explain how combining uncertainty estimation with these constraints can help us infer a partial ranking of actions that produce higher returns, and helps us infer safer and more informative policies for planning.", "url": "https://arxiv.org/abs/2308.05075"}, {"metadata": {"arXiv": "2308.04436", "Date": "Fri, 21 Jul 2023 15:18:10 ", "Title": "The Two Faces of AI in Green Mobile Computing: A Literature Review", "Authors": ["Wander Siemers", "June Sallou", "Lu\\'is Cruz"], "Categories": "cs.AI cs.CY", "Comments": ["9 pages", "5 figures. Accepted at Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2023"]}, "abstract": "Artificial intelligence is bringing ever new functionalities to the realm of mobile devices that are now considered essential (e.g., camera and voice assistants, recommender systems). Yet, operating artificial intelligence takes up a substantial amount of energy. However, artificial intelligence is also being used to enable more energy-efficient solutions for mobile systems. Hence, artificial intelligence has two faces in that regard, it is both a key enabler of desired (efficient) mobile functionalities and a major power draw on these devices, playing a part in both the solution and the problem. In this paper, we present a review of the literature of the past decade on the usage of artificial intelligence within the realm of green mobile computing. From the analysis of 34 papers, we highlight the emerging patterns and map the field into 13 main topics that are summarized in details. Our results showcase that the field is slowly increasing in the past years, more specifically, since 2019. Regarding the double impact AI has on the mobile energy consumption, the energy consumption of AI-based mobile systems is under-studied in comparison to the usage of AI for energy-efficient mobile computing, and we argue for more exploratory studies in that direction. We observe that although most studies are framed as solution papers (94%), the large majority do not make those solutions publicly available to the community. Moreover, we also show that most contributions are purely academic (28 out of 34 papers) and that we need to promote the involvement of the mobile software industry in this field.", "url": "https://arxiv.org/abs/2308.04436"}, {"metadata": {"arXiv": "2308.04492", "Date": "Tue, 08 Aug 2023 18:00:39 ", "Title": "ChatGPT for Arabic Grammatical Error Correction", "Authors": ["Sang Yun Kwon", "Gagan Bhatia", "El Moatez Billah Nagoud", "Muhammad Abdul-Mageed"], "Categories": "cs.AI"}, "abstract": "Recently, large language models (LLMs) fine-tuned to follow human instruction have exhibited significant capabilities in various English NLP tasks. However, their performance in grammatical error correction (GEC) tasks, particularly in non-English languages, remains significantly unexplored. In this paper, we delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made complex due to Arabic's rich morphology. Our findings suggest that various prompting methods, coupled with (in-context) few-shot learning, demonstrate considerable effectiveness, with GPT-4 achieving up to $65.49$ F\\textsubscript{1} score under expert prompting (approximately $5$ points higher than our established baseline). This highlights the potential of LLMs in low-resource settings, offering a viable approach for generating useful synthetic data for model training. Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compared to fully fine-tuned models of significantly smaller sizes. This disparity highlights a substantial room for improvements for LLMs. Inspired by methods from low-resource machine translation, we also develop a method exploiting synthetic data that significantly outperforms previous models on two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with $72.19\\%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.", "url": "https://arxiv.org/abs/2308.04492"}, {"metadata": {"arXiv": "2308.04586", "Date": "Tue, 08 Aug 2023 21:14:21 ", "Title": "Developmental Bootstrapping of AIs", "Authors": ["Mark Stefik and Robert Price"], "Categories": "cs.AI", "Comments": ["101 pages", "29 figures"]}, "abstract": "Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and learn from people and establish perceptual, cognitive, and common grounding. Following a bootstrapping process, they acquire the competences that they need. However, developmental robotics has not yet produced AIs with robust adult-level competences. Projects have typically stopped at the Toddler Barrier corresponding to human infant development at about two years of age, before speech is fluent. They also do not bridge the Reading Barrier, where they can skillfully and skeptically tap into the vast socially developed recorded information resources that power LLMs. The next competences in human cognitive development involve intrinsic motivation, imitation learning, imagination, coordination, and communication. This paper lays out the logic, prospects, gaps, and challenges for extending the practice of developmental bootstrapping to create robust and resilient AIs.", "url": "https://arxiv.org/abs/2308.04586"}, {"metadata": {"arXiv": "2308.04600", "Date": "Tue, 08 Aug 2023 21:56:52 ", "Title": "Model of models -- Part 1", "Authors": ["Shimon Komarovsky"], "Categories": "cs.AI cs.LO cs.SC", "Comments": ["arXiv admin note: text overlap with arXiv:2301.13556"]}, "abstract": "This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via a cognitive evolution from infancy to adulthood, utilizing a consolidation principle. The final product of this cognitive model is a dynamic operational memory of models and instances. Lastly, some examples and preliminary ideas for the evolution phase to reach the mature state are presented.", "url": "https://arxiv.org/abs/2308.04600"}, {"metadata": {"arXiv": "2308.04623", "Date": "Tue, 08 Aug 2023 23:29:55 ", "Title": "Accelerating LLM Inference with Staged Speculative Decoding", "Authors": ["Benjamin Spector and Chris Re"], "Categories": "cs.AI cs.CL", "Comments": ["Published at ES-FOMO at ICML 2023"]}, "abstract": "Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative decoding, to accelerate LLM inference in small-batch, on-device scenarios. We address the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding. First, we restructure the speculative batch as a tree, which reduces generation costs and increases the expected tokens per batch. Second, we add a second stage of speculative decoding. Taken together, we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L model while perfectly preserving output quality.", "url": "https://arxiv.org/abs/2308.04623"}, {"metadata": {"arXiv": "2308.04639", "Date": "Wed, 09 Aug 2023 00:44:02 ", "Title": "A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem", "Authors": ["Zhang-Hua Fu", "Sipeng Sun", "Jintong Ren", "Tianshu Yu", "Haoyu Zhang", "Yuanyuan Liu", "Lingxiao Huang", "Xiang Yan", "Pinyan Lu"], "Categories": "cs.AI"}, "abstract": "For prohibitively large-scale Travelling Salesman Problems (TSPs), existing algorithms face big challenges in terms of both computational efficiency and solution quality. To address this issue, we propose a hierarchical destroy-and-repair (HDR) approach, which attempts to improve an initial solution by applying a series of carefully designed destroy-and-repair operations. A key innovative concept is the hierarchical search framework, which recursively fixes partial edges and compresses the input instance into a small-scale TSP under some equivalence guarantee. This neat search framework is able to deliver highly competitive solutions within a reasonable time. Fair comparisons based on nineteen famous large-scale instances (with 10,000 to 10,000,000 cities) show that HDR is highly competitive against existing state-of-the-art TSP algorithms, in terms of both efficiency and solution quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities, HDR breaks the world records (i.e., best-known results regardless of computation time), which were previously achieved by LKH and its variants, while HDR is completely independent of LKH. Finally, ablation studies are performed to certify the importance and validity of the hierarchical search framework.", "url": "https://arxiv.org/abs/2308.04639"}, {"metadata": {"arXiv": "2308.04689", "Date": "Wed, 09 Aug 2023 03:52:48 ", "Title": "web crawler strategies for web pages under robot.txt restriction", "Authors": ["Piyush Vyas", "Akhilesh Chauhan", "Tushar Mandge", "Surbhi Hardikar"], "Categories": "cs.AI cs.IR"}, "abstract": "In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.", "url": "https://arxiv.org/abs/2308.04689"}, {"metadata": {"arXiv": "2308.04719", "Date": "Wed, 09 Aug 2023 05:48:58 ", "Title": "JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games", "Authors": ["Yang Li and Kun Xiong and Yingping Zhang and Jiangcheng Zhu and Stephen Mcaleer and Wei Pan and Jun Wang and Zonghong Dai and Yaodong Yang"], "Categories": "cs.AI", "Comments": ["28 pages", "accepted by Transactions on Machine Learning Research (TMLR)"]}, "abstract": "This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game's strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41\\% win rate against human players. The algorithm's effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at \\url{https://sites.google.com/view/jiangjun-site/}.", "url": "https://arxiv.org/abs/2308.04719"}, {"metadata": {"arXiv": "2308.04749", "Date": "Wed, 09 Aug 2023 07:36:40 ", "Title": "Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks", "Authors": ["Bing Han", "Feifei Zhao", "Yi Zeng", "Wenxuan Pan", "Guobin Shen"], "Categories": "cs.AI", "Journal-ref": "IJCAI2023 Camera ready"}, "abstract": "Children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.", "url": "https://arxiv.org/abs/2308.04749"}, {"metadata": {"arXiv": "2308.04760", "Date": "Wed, 09 Aug 2023 07:49:24 ", "Title": "Automated Driving Without Ethics: Meaning, Design and Real-World Implementation", "Authors": ["Katherine Evans (IRCAI)", "Nelson de Moura (ASTRA)", "Raja Chatila (ISIR)", "St\\'ephane Chauvier (SND)"], "Categories": "cs.AI cs.RO", "Comments": ["Chapter 7 of the book Connected and Automated Vehicles: Integrating Engineering and Ethics (https://link.springer.com/book/9783031399909)"]}, "abstract": "The ethics of automated vehicles (AV) has received a great amount of attention in recent years, specifically in regard to their decisional policies in accident situations in which human harm is a likely consequence. After a discussion about the pertinence and cogency of the term 'artificial moral agent' to describe AVs that would accomplish these sorts of decisions, and starting from the assumption that human harm is unavoidable in some situations, a strategy for AV decision making is proposed using only pre-defined parameters to characterize the risk of possible accidents and also integrating the Ethical Valence Theory, which paints AV decision-making as a type of claim mitigation, into multiple possible decision rules to determine the most suitable action given the specific environment and decision context. The goal of this approach is not to define how moral theory requires vehicles to behave, but rather to provide a computational approach that is flexible enough to accommodate a number of human 'moral positions' concerning what morality demands and what road users may expect, offering an evaluation tool for the social acceptability of an automated vehicle's decision making.", "url": "https://arxiv.org/abs/2308.04760"}, {"metadata": {"arXiv": "2308.04778", "Date": "Wed, 09 Aug 2023 08:06:03 ", "Title": "Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization", "Authors": ["Yasser Khalafaoui (Alteca", "ETIS - UMR 8051", "CY)", "Nistor Grozavu (ETIS - UMR 8051", "CY)", "Basarab Matei (LIPN)", "Laurent-Walter Goix"], "Categories": "cs.AI", "Journal-ref": "2022 IEEE Symposium Series on Computational Intelligence (SSCI), Dec 2022, Singapore, Singapore. pp.1386-1391", "DOI": "10.1109/SSCI51031.2022.10022129"}, "abstract": "By combining related objects, unsupervised machine learning techniques aim to reveal the underlying patterns in a data set. Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements' non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which was evaluated using a variety of data sets, and the obtained results are very promising compared to state of art methods.", "url": "https://arxiv.org/abs/2308.04778"}, {"metadata": {"arXiv": "2308.04814", "Date": "Wed, 09 Aug 2023 09:12:35 ", "Title": "Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges", "Authors": ["Gunjan Singh", "Sumit Bhatia", "Raghava Mutharaju"], "Categories": "cs.AI", "Comments": ["This paper is a part of the book titled Compendium of Neuro-Symbolic Artificial Intelligence which can be found at the following link: https://www.iospress.com/ catalog/books/compendium-of-neurosymbolic-artificial-intelligence"]}, "abstract": "Ontologies are used in various domains, with RDF and OWL being prominent standards for ontology development. RDF is favored for its simplicity and flexibility, while OWL enables detailed domain knowledge representation. However, as ontologies grow larger and more expressive, reasoning complexity increases, and traditional reasoners struggle to perform efficiently. Despite optimization efforts, scalability remains an issue. Additionally, advancements in automated knowledge base construction have created large and expressive ontologies that are often noisy and inconsistent, posing further challenges for conventional reasoners. To address these challenges, researchers have explored neuro-symbolic approaches that combine neural networks' learning capabilities with symbolic systems' reasoning abilities. In this chapter,we provide an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL, discussing the techniques employed, the tasks they address, and other relevant efforts in this area.", "url": "https://arxiv.org/abs/2308.04814"}, {"metadata": {"arXiv": "2308.04867", "Date": "Wed, 09 Aug 2023 11:01:46 ", "Title": "Learning Type-Generalized Actions for Symbolic Planning", "Authors": ["Daniel Tanneberg", "Michael Gienger"], "Categories": "cs.AI cs.RO", "Comments": ["IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023"]}, "abstract": "Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior, can be solved.", "url": "https://arxiv.org/abs/2308.04867"}, {"metadata": {"arXiv": "2308.04914", "Date": "Wed, 09 Aug 2023 12:27:49 ", "Title": "Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach", "Authors": ["Xumin Huang", "Yuan Wu", "Jiawen Kang", "Jiangtian Nie", "Weifeng Zhong", "Dong In Kim", "and Shengli Xie"], "Categories": "cs.AI"}, "abstract": "Metaverse enables users to communicate, collaborate and socialize with each other through their digital avatars. Due to the spatio-temporal characteristics, co-located users are served well by performing their software components in a collaborative manner such that a Metaverse service provider (MSP) eliminates redundant data transmission and processing, ultimately reducing the total energy consumption. The energyefficient service provision is crucial for enabling the green and sustainable Metaverse. In this article, we take an augmented reality (AR) application as an example to achieve this goal. Moreover, we study an economic issue on how the users reserve offloading services from the MSP and how the MSP determines an optimal charging price since each user is rational to decide whether to accept the offloading service by taking into account the monetary cost. A single-leader multi-follower Stackelberg game is formulated between the MSP and users while each user optimizes an offloading probability to minimize the weighted sum of time, energy consumption and monetary cost. Numerical results show that our scheme achieves energy savings and satisfies individual rationality simultaneously compared with the conventional schemes. Finally, we identify and discuss open directions on how several emerging technologies are combined with the sustainable green Metaverse.", "url": "https://arxiv.org/abs/2308.04914"}, {"metadata": {"arXiv": "2308.05012", "Date": "Wed, 09 Aug 2023 15:11:37 ", "Title": "MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model", "Authors": ["Michael Leong", "Awad Abdelhalim", "Jude Ha", "Dianne Patterson", "Gabriel L. Pincus", "Anthony B. Harris", "Michael Eichler", "Jinhua Zhao"], "Categories": "cs.AI"}, "abstract": "Transit riders' feedback provided in ridership surveys, customer relationship management (CRM) channels, and in more recent times, through social media is key for transit agencies to better gauge the efficacy of their services and initiatives. Getting a holistic understanding of riders' experience through the feedback shared in those instruments is often challenging, mostly due to the open-ended, unstructured nature of text feedback. In this paper, we propose leveraging traditional transit CRM feedback to develop and deploy a transit-topic-aware large language model (LLM) capable of classifying open-ended text feedback to relevant transit-specific topics. First, we utilize semi-supervised learning to engineer a training dataset of 11 broad transit topics detected in a corpus of 6 years of customer feedback provided to the Washington Metropolitan Area Transit Authority (WMATA). We then use this dataset to train and thoroughly evaluate a language model based on the RoBERTa architecture. We compare our LLM, MetRoBERTa, to classical machine learning approaches utilizing keyword-based and lexicon representations. Our model outperforms those methods across all evaluation metrics, providing an average topic classification accuracy of 90%. Finally, we provide a value proposition of this work demonstrating how the language model, alongside additional text processing tools, can be applied to add structure to open-ended text sources of feedback like Twitter. The framework and results we present provide a pathway for an automated, generalizable approach for ingesting, visualizing, and reporting transit riders' feedback at scale, enabling agencies to better understand and improve customer experience.", "url": "https://arxiv.org/abs/2308.05012"}, {"metadata": {"arXiv": "2308.05035", "Date": "Wed, 09 Aug 2023 16:08:32 ", "Title": "Expert load matters: operating networks at high accuracy and low manual effort", "Authors": ["Sara Sangalli", "Ertunc Erdil", "Ender Konukoglu"], "Categories": "cs.AI cs.HC"}, "abstract": "In human-AI collaboration systems for critical applications, in order to ensure minimal error, users should set an operating point based on model confidence to determine when the decision should be delegated to human experts. Samples for which model confidence is lower than the operating point would be manually analysed by experts to avoid mistakes. Such systems can become truly useful only if they consider two aspects: models should be confident only for samples for which they are accurate, and the number of samples delegated to experts should be minimized. The latter aspect is especially crucial for applications where available expert time is limited and expensive, such as healthcare. The trade-off between the model accuracy and the number of samples delegated to experts can be represented by a curve that is similar to an ROC curve, which we refer to as confidence operating characteristic (COC) curve. In this paper, we argue that deep neural networks should be trained by taking into account both accuracy and expert load and, to that end, propose a new complementary loss function for classification that maximizes the area under this COC curve. This promotes simultaneously the increase in network accuracy and the reduction in number of samples delegated to humans. We perform experiments on multiple computer vision and medical image datasets for classification. Our results demonstrate that the proposed loss improves classification accuracy and delegates less number of decisions to experts, achieves better out-of-distribution samples detection and on par calibration performance compared to existing loss functions.", "url": "https://arxiv.org/abs/2308.05035"}, {"metadata": {"arXiv": "2308.05062", "Date": "Wed, 09 Aug 2023 16:47:04 ", "Title": "Competitions in AI -- Robustly Ranking Solvers Using Statistical Resampling", "Authors": ["Chris Fawcett", "Mauro Vallati", "Holger H. Hoos", "Alfonso E. Gerevini"], "Categories": "cs.AI"}, "abstract": "Solver competitions play a prominent role in assessing and advancing the state of the art for solving many problems in AI and beyond. Notably, in many areas of AI, competitions have had substantial impact in guiding research and applications for many years, and for a solver to be ranked highly in a competition carries considerable weight. But to which extent can we expect competition results to generalise to sets of problem instances different from those used in a particular competition? This is the question we investigate here, using statistical resampling techniques. We show that the rankings resulting from the standard interpretation of competition results can be very sensitive to even minor changes in the benchmark instance set used as the basis for assessment and can therefore not be expected to carry over to other samples from the same underlying instance distribution. To address this problem, we introduce a novel approach to statistically meaningful analysis of competition results based on resampling performance data. Our approach produces confidence intervals of competition scores as well as statistically robust solver rankings with bounded error. Applied to recent SAT, AI planning and computer vision competitions, our analysis reveals frequent statistical ties in solver performance as well as some inversions of ranks compared to the official results based on simple scoring.", "url": "https://arxiv.org/abs/2308.05062"}, {"metadata": {"arXiv": "2308.04529", "Date": "Tue, 08 Aug 2023 18:47:25 ", "Title": "Generating Modern Persian Carpet Map by Style-transfer", "Authors": ["Dorsa Rahmatian", "Monireh Moshavash", "Mahdi Eftekhari", "and Kamran Hoseinkhani"], "Categories": "cs.CV cs.AI", "DOI": "10.22103/jmmr.2023.20648.13"}, "abstract": "Today, the great performance of Deep Neural Networks(DNN) has been proven in various fields. One of its most attractive applications is to produce artistic designs. A carpet that is known as a piece of art is one of the most important items in a house, which has many enthusiasts all over the world. The first stage of producing a carpet is to prepare its map, which is a difficult, time-consuming, and expensive task. In this research work, our purpose is to use DNN for generating a Modern Persian Carpet Map. To reach this aim, three different DNN style transfer methods are proposed and compared against each other. In the proposed methods, the Style-Swap method is utilized to create the initial carpet map, and in the following, to generate more diverse designs, methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition, some methods are examined and introduced for coloring the produced carpet maps. The designed maps are evaluated via the results of filled questionnaires where the outcomes of user evaluations confirm the popularity of generated carpet maps. Eventually, for the first time, intelligent methods are used in producing carpet maps, and it reduces human intervention. The proposed methods can successfully produce diverse carpet designs, and at a higher speed than traditional ways.", "url": "https://arxiv.org/abs/2308.04529"}, {"metadata": {"arXiv": "2308.04589", "Date": "Tue, 08 Aug 2023 21:18:23 ", "Title": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction", "Authors": ["Izzeddin Teeti", "Rongali Sai Bhargav", "Vivek Singh", "Andrew Bradley", "Biplab Banerjee", "Fabio Cuzzolin"], "Categories": "cs.CV cs.AI"}, "abstract": "The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task using 3D-ResNet, Transformer, and LSTM architectures. The experimental results showcase significant improvements in prediction performance across these architectures, with our method achieving an average enhancement of 9.9% Precision Points (PP), highlighting its effectiveness in enhancing the backbones' capabilities of capturing long-term dependencies. Furthermore, our approach demonstrates efficiency regarding the pretraining dataset size and the number of epochs required. This method overcomes limitations present in other approaches, including considering various backbone architectures, addressing multiple prediction horizons, reducing reliance on hand-crafted augmentations, and streamlining the pretraining process into a single stage. These findings highlight the potential of our approach in diverse video-based tasks such as activity recognition, motion planning, and scene understanding.", "url": "https://arxiv.org/abs/2308.04589"}, {"metadata": {"arXiv": "2308.04672", "Date": "Wed, 09 Aug 2023 02:50:15 ", "Title": "Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks", "Authors": ["Jue Chen", "Huan Yuan", "Jianchao Tan", "Bin Chen", "Chengru Song", "Di Zhang"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["ACM MM 2023"]}, "abstract": "Brain-inspired Spiking Neural Networks (SNNs) have the characteristics of event-driven and high energy-efficient, which are different from traditional Artificial Neural Networks (ANNs) when deployed on edge devices such as neuromorphic chips. Most previous work focuses on SNNs training strategies to improve model performance and brings larger and deeper network architectures. It is difficult to deploy these complex networks on resource-limited edge devices directly. To meet such demand, people compress SNNs very cautiously to balance the performance and the computation efficiency. Existing compression methods either iteratively pruned SNNs using weights norm magnitude or formulated the problem as a sparse learning optimization. We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency. We also demonstrate that jointly applying compression and finetuning on SNNs is better than sequentially, especially for extreme compression ratios. The compressed SNN models achieved state-of-the-art (SOTA) performance on various benchmark datasets and architectures. Our code is available at https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN.", "url": "https://arxiv.org/abs/2308.04672"}, {"metadata": {"arXiv": "2308.04674", "Date": "Wed, 09 Aug 2023 03:03:35 ", "Title": "Addressing Racial Bias in Facial Emotion Recognition", "Authors": ["Alex Fan", "Xingshuo Xiao", "Peter Washington"], "Categories": "cs.CV cs.AI cs.CY"}, "abstract": "Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\\%$ points, and demographic parity increases by $15.7\\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.", "url": "https://arxiv.org/abs/2308.04674"}, {"metadata": {"arXiv": "2308.04687", "Date": "Wed, 09 Aug 2023 03:49:12 ", "Title": "Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization", "Authors": ["Abhishek Kushwaha", "Sarthak Gupta", "Anish Bhanushali", "Tathagato Rai Dastidar"], "Categories": "cs.CV cs.AI", "Comments": ["https://openaccess.thecvf.com/content_CVPRW_2020/html/w57/Kushwaha_Rapid_Training_Data_Creation_by_Synthesizing_Medical_Images_for_Classification_CVPRW_2020_paper.html"]}, "abstract": "While the use of artificial intelligence (AI) for medical image analysis is gaining wide acceptance, the expertise, time and cost required to generate annotated data in the medical field are significantly high, due to limited availability of both data and expert annotation. Strongly supervised object localization models require data that is exhaustively annotated, meaning all objects of interest in an image are identified. This is difficult to achieve and verify for medical images. We present a method for the transformation of real data to train any Deep Neural Network to solve the above problems. We show the efficacy of this approach on both a weakly supervised localization model and a strongly supervised localization model. For the weakly supervised model, we show that the localization accuracy increases significantly using the generated data. For the strongly supervised model, this approach overcomes the need for exhaustive annotation on real images. In the latter model, we show that the accuracy, when trained with generated images, closely parallels the accuracy when trained with exhaustively annotated real images. The results are demonstrated on images of human urine samples obtained using microscopy.", "url": "https://arxiv.org/abs/2308.04687"}, {"metadata": {"arXiv": "2308.04758", "Date": "Wed, 09 Aug 2023 07:48:20 ", "Title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation", "Authors": ["Rui Liu", "Xiaohan Wang", "Wenguan Wang", "Yi Yang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at ICCV 2023; Project page: https://github.com/DefaultRui/BEV-Scene-Graph"]}, "abstract": "Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach significantly outperforms state-of-the-art methods on REVERIE, R2R, and R4R, showing the potential of BEV perception in VLN.", "url": "https://arxiv.org/abs/2308.04758"}, {"metadata": {"arXiv": "2308.04767", "Date": "Wed, 09 Aug 2023 07:55:12 ", "Title": "Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization", "Authors": ["Tianyu Liu", "Peng Zhang", "Wei Huang", "Yufei Zha", "Tao You", "Yanning Zhang"], "Categories": "cs.CV cs.AI cs.MM cs.SD eess.AS", "Comments": ["Accepted to ACM Multimedia 2023"], "DOI": "10.1145/3581783.3612502"}, "abstract": "Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network. Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN", "url": "https://arxiv.org/abs/2308.04767"}, {"metadata": {"arXiv": "2308.04779", "Date": "Wed, 09 Aug 2023 08:06:28 ", "Title": "Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR", "Authors": ["Chunpeng Zhou", "Kangjie Ning", "Haishuai Wang", "Zhi Yu", "Sheng Zhou", "Jiajun Bu"], "Categories": "cs.CV cs.AI"}, "abstract": "The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress detection has gained widespread popularity. To enhance the efficiency and accuracy of detection, pioneering studies have attempted to adopt automatic detection techniques, particularly deep learning. However, existing works typically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the GPR, resulting in either insufficient spatial information or high computational complexity. To address these challenges, we introduce a novel methodology for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data. Moreover, we construct a real multi-view image dataset derived from the original 3D-GPR data for the detection task, which provides richer spatial information compared to A-scan and B-scan data, while reducing computational complexity compared to C-scan data. Subsequently, we develop a novel \\textbf{M}ulti-\\textbf{V}iew \\textbf{V}usion and \\textbf{D}istillation framework, \\textbf{GPR-MVFD}, specifically designed to optimally utilize the multi-view GPR dataset. This framework ingeniously incorporates multi-view distillation and attention-based fusion to facilitate significant feature extraction for subgrade distresses. In addition, a self-adaptive learning mechanism is adopted to stabilize the model training and prevent performance degeneration in each branch. Extensive experiments conducted on this new GPR benchmark demonstrate the effectiveness and efficiency of our proposed framework. Our framework outperforms not only the existing GPR baselines, but also the state-of-the-art methods in the fields of multi-view learning, multi-modal learning, and knowledge distillation. We will release the constructed multi-view GPR dataset with expert-annotated labels and the source codes of the proposed framework.", "url": "https://arxiv.org/abs/2308.04779"}, {"metadata": {"arXiv": "2308.04911", "Date": "Wed, 09 Aug 2023 12:22:49 ", "Title": "SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation", "Authors": ["Fan Bai", "Ke Yan", "Xiaoyu Bai", "Xinyu Mao", "Xiaoli Yin", "Jingren Zhou", "Yu Shi", "Le Lu", "Max Q.-H. Meng"], "Categories": "cs.CV cs.AI", "Comments": ["accepted by MICCAI 2023"]}, "abstract": "Medical image analysis using deep learning is often challenged by limited labeled data and high annotation costs. Fine-tuning the entire network in label-limited scenarios can lead to overfitting and suboptimal performance. Recently, prompt tuning has emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and supervised selection using prompt-based uncertainty. In addition, we propose a diversified visual prompt tuning strategy to provide multi-prompt-based discrepant predictions for TESLA. We evaluate our method on liver tumor segmentation and achieve state-of-the-art performance, outperforming traditional fine-tuning with only 6% of tunable parameters, also achieving 94% of full-data performance by labeling only 5% of the data.", "url": "https://arxiv.org/abs/2308.04911"}, {"metadata": {"arXiv": "2308.04944", "Date": "Wed, 09 Aug 2023 13:19:28 ", "Title": "Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection", "Authors": ["Tetiana Gula", "Jo\\~ao P C Bertoldo"], "Categories": "cs.CV cs.AI", "Comments": ["28 pages", "14 figures", "accepted to 2023 official workshop of the LatinX in Computer Vision (LXCV) at ICCV"]}, "abstract": "Anomaly detection (AD) in images, identifying significant deviations from normality, is a critical issue in computer vision. This paper introduces a novel approach to dimensionality reduction for AD using pre-trained convolutional neural network (CNN) that incorporate EfficientNet models. We investigate the importance of component selection and propose two types of tree search approaches, both employing a greedy strategy, for optimal eigencomponent selection. Our study conducts three main experiments to evaluate the effectiveness of our approach. The first experiment explores the influence of test set performance on component choice, the second experiment examines the performance when we train on one anomaly type and evaluate on all other types, and the third experiment investigates the impact of using a minimum number of images for training and selecting them based on anomaly types. Our approach aims to find the optimal subset of components that deliver the highest performance score, instead of focusing solely on the proportion of variance explained by each component and also understand the components behaviour in different settings. Our results indicate that the proposed method surpasses both Principal Component Analysis (PCA) and Negated Principal Component Analysis (NPCA) in terms of detection accuracy, even when using fewer components. Thus, our approach provides a promising alternative to conventional dimensionality reduction techniques in AD, and holds potential to enhance the efficiency and effectiveness of AD systems.", "url": "https://arxiv.org/abs/2308.04944"}, {"metadata": {"arXiv": "2308.04952", "Date": "Wed, 09 Aug 2023 13:38:52 ", "Title": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation", "Authors": ["Kai Huang", "Feigege Wang", "Ye Xi", "Yutao Gao"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic Segmentation (FSS) to simultaneously segment unseen classes and seen classes during evaluation. Previous works leverage additional branch or prototypical aggregation to eliminate the constrained setting of FSS. However, representation division and embedding prejudice, which heavily results in poor performance of GFSS, have not been synthetical considered. We address the aforementioned problems by jointing the prototypical kernel learning and open-set foreground perception. Specifically, a group of learnable kernels is proposed to perform segmentation with each kernel in charge of a stuff class. Then, we explore to merge the prototypical learning to the update of base-class kernels, which is consistent with the prototype knowledge aggregation of few-shot novel classes. In addition, a foreground contextual perception module cooperating with conditional bias based inference is adopted to perform class-agnostic as well as open-set foreground detection, thus to mitigate the embedding prejudice and prevent novel targets from being misclassified as background. Moreover, we also adjust our method to the Class Incremental Few-shot Semantic Segmentation (CIFSS) which takes the knowledge of novel classes in a incremental stream. Extensive experiments on PASCAL-5i and COCO-20i datasets demonstrate that our method performs better than previous state-of-the-art.", "url": "https://arxiv.org/abs/2308.04952"}, {"metadata": {"arXiv": "2308.05095", "Date": "Wed, 09 Aug 2023 17:45:04 ", "Title": "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation", "Authors": ["Leigang Qu", "Shengqiong Wu", "Hao Fei", "Liqiang Nie", "Tat-Seng Chua"], "Categories": "cs.CV cs.AI"}, "abstract": "In the text-to-image generation field, recent remarkable progress in Stable Diffusion makes it possible to generate rich kinds of novel photorealistic images. However, current models still face misalignment issues (e.g., problematic spatial relation understanding and numeration failure) in complex natural scenes, which impedes the high-faithfulness text-to-image generation. Although recent efforts have been made to improve controllability by giving fine-grained guidance (e.g., sketch and scribbles), this issue has not been fundamentally tackled since users have to provide such guidance information manually. In this work, we strive to synthesize high-fidelity images that are semantically aligned with a given textual prompt without any guidance. Toward this end, we propose a coarse-to-fine paradigm to achieve layout planning and image generation. Concretely, we first generate the coarse-grained layout conditioned on a given textual prompt via in-context learning based on Large Language Models. Afterward, we propose a fine-grained object-interaction diffusion method to synthesize high-faithfulness images conditioned on the prompt and the automatically generated layout. Extensive experiments demonstrate that our proposed method outperforms the state-of-the-art models in terms of layout and image generation. Our code and settings are available at \\url{https://layoutllm-t2i.github.io}.", "url": "https://arxiv.org/abs/2308.05095"}, {"metadata": {"arXiv": "2308.04774", "Date": "Wed, 09 Aug 2023 08:02:11 ", "Title": "E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles", "Authors": ["Jiashun Suo", "Xingzhou Zhang", "Weisong Shi", "Wei Zhou"], "Categories": "cs.RO cs.AI cs.CV cs.SY eess.SY", "Comments": ["16 pages", "8 figures"], "Journal-ref": "IEEE Internet of Things Journal, Early Access 1-1 (2023)", "DOI": "10.1109/JIOT.2023.3301623"}, "abstract": "Motivated by the advances in deep learning techniques, the application of Unmanned Aerial Vehicle (UAV)-based object detection has proliferated across a range of fields, including vehicle counting, fire detection, and city monitoring. While most existing research studies only a subset of the challenges inherent to UAV-based object detection, there are few studies that balance various aspects to design a practical system for energy consumption reduction. In response, we present the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by deciding the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task. We first present an effective evaluation metric for actual tasks and construct a transparent energy consumption model based on hundreds of actual flight data to formalize the relationship between energy consumption and flight parameters. Then we present a lightweight energy-efficient priority decision algorithm based on a large quantity of actual flight data to assist the system in deciding flight parameters. Finally, we evaluate the performance of the system, and our experimental results demonstrate that it can significantly decrease energy consumption in real-world scenarios. Additionally, we provide four insights that can assist researchers and engineers in their efforts to study UAV-based object detection further.", "url": "https://arxiv.org/abs/2308.04774"}, {"metadata": {"arXiv": "2308.04792", "Date": "Wed, 09 Aug 2023 08:31:05 ", "Title": "A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers", "Authors": ["Yiming Ji", "Yang Liu", "Guanghu Xie", "Zongwu Xie", "Baoshi Cao"], "Categories": "cs.RO cs.AI"}, "abstract": "Intelligent autonomous path planning is crucial to improve the exploration efficiency of planetary rovers. In this paper, we propose a learning-based method to quickly search for optimal paths in an elevation map, which is called NNPP. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the DEM. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to perform path planning on novel maps. Experiments show that the guidance field generated by the NNPP model can significantly reduce the search time for optimal paths under the same hardware conditions, and the advantage of NNPP increases with the scale of the map.", "url": "https://arxiv.org/abs/2308.04792"}, {"metadata": {"arXiv": "2308.04696", "Date": "Wed, 09 Aug 2023 04:15:10 ", "Title": "Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects", "Authors": ["Soheyla Amirian", "Luke A. Carlson", "Matthew F. Gong", "Ines Lohse", "Kurt R. Weiss", "Johannes F. Plate", "and Ahmad P. Tafti"], "Categories": "cs.AI cs.LG", "Comments": ["This paper was accepted at The 2023 World Congress in Computer Science", "Computer Engineering", "and Applied Computing (CSCE'23)"]}, "abstract": "While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.", "url": "https://arxiv.org/abs/2308.04696"}, {"metadata": {"arXiv": "2308.04958", "Date": "Wed, 09 Aug 2023 13:44:35 ", "Title": "Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks", "Authors": ["Marc W. Brittain", "Luis E. Alvarez", "Kara Breeden"], "Categories": "cs.AI cs.LG", "Comments": ["7 pages"]}, "abstract": "Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.", "url": "https://arxiv.org/abs/2308.04958"}, {"metadata": {"arXiv": "2308.04445", "Date": "Mon, 31 Jul 2023 16:29:28 ", "Title": "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc", "Authors": ["Doug Lenat", "Gary Marcus"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "1 Figure"], "ACM-class": "I.2.0"}, "abstract": "Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable. We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however a catch: if the logical language is expressive enough to fully represent the meaning of anything we can say in English, then the inference engine runs much too slowly. That's why symbolic AI systems typically settle for some fast but much less expressive logic, such as knowledge graphs. We describe how one AI system, Cyc, has developed ways to overcome that tradeoff and is able to reason in higher order logic in real time. We suggest that any trustworthy general AI will need to hybridize the approaches, the LLM approach and more formal approach, and lay out a path to realizing that dream.", "url": "https://arxiv.org/abs/2308.04445"}, {"metadata": {"arXiv": "2308.04469", "Date": "Tue, 08 Aug 2023 07:40:21 ", "Title": "Correlating Medi- Claim Service by Deep Learning Neural Networks", "Authors": ["Jayanthi Vajiram", "Negha Senthil", "Nean Adhith.P"], "Categories": "cs.LG cs.AI"}, "abstract": "Medical insurance claims are of organized crimes related to patients, physicians, diagnostic centers, and insurance providers, forming a chain reaction that must be monitored constantly. These kinds of frauds affect the financial growth of both insured people and health insurance companies. The Convolution Neural Network architecture is used to detect fraudulent claims through a correlation study of regression models, which helps to detect money laundering on different claims given by different providers. Supervised and unsupervised classifiers are used to detect fraud and non-fraud claims.", "url": "https://arxiv.org/abs/2308.04469"}, {"metadata": {"arXiv": "2308.04539", "Date": "Tue, 08 Aug 2023 19:12:52 ", "Title": "Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures", "Authors": ["Sandeep Madireddy", "Angel Yanguas-Gil", "Prasanna Balaprakash"], "Categories": "cs.LG cs.AI cs.NE"}, "abstract": "The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent. Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.", "url": "https://arxiv.org/abs/2308.04539"}, {"metadata": {"arXiv": "2308.04637", "Date": "Wed, 09 Aug 2023 00:23:04 ", "Title": "Sparse Binary Transformers for Multivariate Time Series Modeling", "Authors": ["Matt Gorbett", "Hossein Shirazi", "Indrakshi Ray"], "Categories": "cs.LG cs.AI", "Comments": ["Published at KDD '23"]}, "abstract": "Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.", "url": "https://arxiv.org/abs/2308.04637"}, {"metadata": {"arXiv": "2308.04708", "Date": "Wed, 09 Aug 2023 04:59:06 ", "Title": "Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution", "Authors": ["Tsuyoshi Id\\'e and Naoki Abe"], "Categories": "cs.LG cs.AI", "Journal-ref": "KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, August 2023, pp.845-856", "DOI": "10.1145/3580305.3599365"}, "abstract": "We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself. We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.", "url": "https://arxiv.org/abs/2308.04708"}, {"metadata": {"arXiv": "2308.04761", "Date": "Wed, 09 Aug 2023 07:49:39 ", "Title": "Feature Matching Data Synthesis for Non-IID Federated Learning", "Authors": ["Zijian Li", "Yuchang Sun", "Jiawei Shao", "Yuyi Mao", "Jessie Hui Wang", "Jun Zhang"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["16 pages"]}, "abstract": "Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.", "url": "https://arxiv.org/abs/2308.04761"}, {"metadata": {"arXiv": "2308.04844", "Date": "Wed, 09 Aug 2023 10:08:03 ", "Title": "Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning", "Authors": ["Astrid Vanneste", "Thomas Somers", "Simon Vanneste", "Kevin Mets", "Tom De Schepper", "Siegfried Mercelis", "Peter Hellinckx"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["Paper accepted to the BNAIC/BeNeLearn 2022 conference"]}, "abstract": "Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.", "url": "https://arxiv.org/abs/2308.04844"}, {"metadata": {"arXiv": "2308.04938", "Date": "Wed, 09 Aug 2023 13:13:19 ", "Title": "An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning", "Authors": ["Astrid Vanneste", "Simon Vanneste", "Kevin Mets", "Tom De Schepper", "Siegfried Mercelis", "Peter Hellinckx"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2204.05669"]}, "abstract": "Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.", "url": "https://arxiv.org/abs/2308.04938"}, {"metadata": {"arXiv": "2308.05101", "Date": "Wed, 09 Aug 2023 17:53:36 ", "Title": "DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels", "Authors": ["Soumadeep Saha", "Utpal Garain", "Arijit Ukil", "Arpan Pal", "Sundeep Khandelwal"], "Categories": "cs.LG cs.AI", "Comments": ["Submitted to IEEE TNNLS on March 7th 2023. 8 pages", "4 figures"], "ACM-class": "I.2.6; I.2.0"}, "abstract": "The enormous demand for annotated data brought forth by deep learning techniques has been accompanied by the problem of annotation noise. Although this issue has been widely discussed in machine learning literature, it has been relatively unexplored in the context of \"multi-label classification\" (MLC) tasks which feature more complicated kinds of noise. Additionally, when the domain in question has certain logical constraints, noisy annotations often exacerbate their violations, making such a system unacceptable to an expert. This paper studies the effect of label noise on domain rule violation incidents in the MLC task, and incorporates domain rules into our learning algorithm to mitigate the effect of noise. We propose the Domain Obedient Self-supervised Training (DOST) paradigm which not only makes deep learning models more aligned to domain rules, but also improves learning performance in key metrics and minimizes the effect of annotation noise. This novel approach uses domain guidance to detect offending annotations and deter rule-violating predictions in a self-supervised manner, thus making it more \"data efficient\" and domain compliant. Empirical studies, performed over two large scale multi-label classification datasets, demonstrate that our method results in improvement across the board, and often entirely counteracts the effect of noise.", "url": "https://arxiv.org/abs/2308.05101"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

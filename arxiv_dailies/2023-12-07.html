<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2312.03160", "Date": "Tue, 05 Dec 2023 22:04:49 ", "Title": "HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces", "Authors": ["Haithem Turki", "Vasu Agrawal", "Samuel Rota Bul\\`o", "Lorenzo Porzi", "Peter Kontschieder", "Deva Ramanan", "Michael Zollh\\\"ofer", "Christian Richardt"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page: https://haithemturki.com/hybrid-nerf/"]}, "abstract": "Neural radiance fields provide state-of-the-art view synthesis quality but tend to be slow to render. One reason is that they make use of volume rendering, thus requiring many samples (and model queries) per ray at render time. Although this representation is flexible and easy to optimize, most real-world objects can be modeled more efficiently with surfaces instead of volumes, requiring far fewer samples per ray. This observation has spurred considerable progress in surface representations such as signed distance functions, but these may struggle to model semi-opaque and thin structures. We propose a method, HybridNeRF, that leverages the strengths of both representations by rendering most objects as surfaces while modeling the (typically) small fraction of challenging regions volumetrically. We evaluate HybridNeRF against the challenging Eyeful Tower dataset along with other commonly used view synthesis datasets. When comparing to state-of-the-art baselines, including recent rasterization-based approaches, we improve error rates by 15-30% while achieving real-time framerates (at least 36 FPS) for virtual-reality resolutions (2Kx2K).", "url": "https://arxiv.org/abs/2312.03160"}, {"metadata": {"arXiv": "2312.03325", "Date": "Wed, 06 Dec 2023 07:26:02 ", "Title": "GCFA:Geodesic Curve Feature Augmentation via Shape Space Theory", "Authors": ["Yuexing Han", "Guanxin Wan and Bing Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "Deep learning has yielded remarkable outcomes in various domains. However, the challenge of requiring large-scale labeled samples still persists in deep learning. Thus, data augmentation has been introduced as a critical strategy to train deep learning models. However, data augmentation suffers from information loss and poor performance in small sample environments. To overcome these drawbacks, we propose a feature augmentation method based on shape space theory, i.e., Geodesic curve feature augmentation, called GCFA in brevity. First, we extract features from the image with the neural network model. Then, the multiple image features are projected into a pre-shape space as features. In the pre-shape space, a Geodesic curve is built to fit the features. Finally, the many generated features on the Geodesic curve are used to train the various machine learning models. The GCFA module can be seamlessly integrated with most machine learning methods. And the proposed method is simple, effective and insensitive for the small sample datasets. Several examples demonstrate that the GCFA method can greatly improve the performance of the data preprocessing model in a small sample environment.", "url": "https://arxiv.org/abs/2312.03325"}, {"metadata": {"arXiv": "2312.03406", "Date": "Wed, 06 Dec 2023 10:42:40 ", "Title": "SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting", "Authors": ["Chao Chen", "Tian Zhou", "Yanjun Zhao", "Hui Liu", "Liang Sun", "Rong Jin"], "Categories": "cs.CV cs.LG"}, "abstract": "Spatiotemporal forecasting tasks, such as weather forecasting and traffic prediction, offer significant societal benefits. These tasks can be effectively approached as image forecasting problems using computer vision models. Vector quantization (VQ) is a well-known method for discrete representation that improves the latent space, leading to enhanced generalization and transfer learning capabilities. One of the main challenges in using VQ for spatiotemporal forecasting is how to balance between keeping enough details and removing noises from the original patterns for better generalization. We address this challenge by developing sparse vector quantization, or {\\bf SVQ} for short, that leverages sparse regression to make better trade-off between the two objectives. The main innovation of this work is to approximate sparse regression by a two-layer MLP and a randomly fixed or learnable matrix, dramatically improving its computational efficiency. Through experiments conducted on diverse datasets in multiple fields including weather forecasting, traffic flow prediction, and video forecasting, we unequivocally demonstrate that our proposed method consistently enhances the performance of base models and achieves state-of-the-art results across all benchmarks.", "url": "https://arxiv.org/abs/2312.03406"}, {"metadata": {"arXiv": "2312.03511", "Date": "Wed, 06 Dec 2023 14:13:38 ", "Title": "Kandinsky 3.0 Technical Report", "Authors": ["Vladimir Arkhipkin", "Andrei Filatov", "Viacheslav Vasilev", "Anastasia Maltseva", "Said Azizov", "Igor Pavlov", "Julia Agafonova", "Andrey Kuznetsov", "Denis Dimitrov"], "Categories": "cs.CV cs.LG cs.MM", "Comments": ["Project page: https://ai-forever.github.io/Kandinsky-3"]}, "abstract": "We present Kandinsky 3.0, a large-scale text-to-image generation model based on latent diffusion, continuing the series of text-to-image Kandinsky models and reflecting our progress to achieve higher quality and realism of image generation. Compared to previous versions of Kandinsky 2.x, Kandinsky 3.0 leverages a two times larger U-Net backbone, a ten times larger text encoder and removes diffusion mapping. We describe the architecture of the model, the data collection procedure, the training technique, and the production system of user interaction. We focus on the key components that, as we have identified as a result of a large number of experiments, had the most significant impact on improving the quality of our model compared to the others. By our side-by-side comparisons, Kandinsky becomes better in text understanding and works better on specific domains. Project page: https://ai-forever.github.io/Kandinsky-3", "url": "https://arxiv.org/abs/2312.03511"}, {"metadata": {"arXiv": "2312.03556", "Date": "Wed, 06 Dec 2023 15:39:03 ", "Title": "Personalized Face Inpainting with Diffusion Models by Parallel Visual Attention", "Authors": ["Jianjin Xu", "Saman Motamed", "Praneetha Vaddamanu", "Chen Henry Wu", "Christian Haene", "Jean-Charles Bazin", "Fernando de la Torre"], "Categories": "cs.CV cs.LG"}, "abstract": "Face inpainting is important in various applications, such as photo restoration, image editing, and virtual reality. Despite the significant advances in face generative models, ensuring that a person's unique facial identity is maintained during the inpainting process is still an elusive goal. Current state-of-the-art techniques, exemplified by MyStyle, necessitate resource-intensive fine-tuning and a substantial number of images for each new identity. Furthermore, existing methods often fall short in accommodating user-specified semantic attributes, such as beard or expression. To improve inpainting results, and reduce the computational complexity during inference, this paper proposes the use of Parallel Visual Attention (PVA) in conjunction with diffusion models. Specifically, we insert parallel attention matrices to each cross-attention module in the denoising network, which attends to features extracted from reference images by an identity encoder. We train the added attention modules and identity encoder on CelebAHQ-IDI, a dataset proposed for identity-preserving face inpainting. Experiments demonstrate that PVA attains unparalleled identity resemblance in both face inpainting and face inpainting with language guidance tasks, in comparison to various benchmarks, including MyStyle, Paint by Example, and Custom Diffusion. Our findings reveal that PVA ensures good identity preservation while offering effective language-controllability. Additionally, in contrast to Custom Diffusion, PVA requires just 40 fine-tuning steps for each new identity, which translates to a significant speed increase of over 20 times.", "url": "https://arxiv.org/abs/2312.03556"}, {"metadata": {"arXiv": "2312.03002", "Date": "Sun, 03 Dec 2023 20:53:41 ", "Title": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task", "Authors": ["Gautam Reddy"], "Categories": "cs.LG"}, "abstract": "Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence. In-context learning contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training.", "url": "https://arxiv.org/abs/2312.03002"}, {"metadata": {"arXiv": "2312.03005", "Date": "Mon, 04 Dec 2023 09:45:02 ", "Title": "Few-Shot Anomaly Detection with Adversarial Loss for Robust Feature Representations", "Authors": ["Jae Young Lee", "Wonjun Lee", "Jaehyun Choi", "Yongkwi Lee", "Young Seog Yoon"], "Categories": "cs.LG cs.CV", "Comments": ["BMVC 2023"]}, "abstract": "Anomaly detection is a critical and challenging task that aims to identify data points deviating from normal patterns and distributions within a dataset. Various methods have been proposed using a one-class-one-model approach, but these techniques often face practical problems such as memory inefficiency and the requirement of sufficient data for training. In particular, few-shot anomaly detection presents significant challenges in industrial applications, where limited samples are available before mass production. In this paper, we propose a few-shot anomaly detection method that integrates adversarial training loss to obtain more robust and generalized feature representations. We utilize the adversarial loss previously employed in domain adaptation to align feature distributions between source and target domains, to enhance feature robustness and generalization in few-shot anomaly detection tasks. We hypothesize that adversarial loss is effective when applied to features that should have similar characteristics, such as those from the same layer in a Siamese network's parallel branches or input-output pairs of reconstruction-based methods. Experimental results demonstrate that the proposed method generally achieves better performance when utilizing the adversarial loss.", "url": "https://arxiv.org/abs/2312.03005"}, {"metadata": {"arXiv": "2312.03017", "Date": "Tue, 05 Dec 2023 01:48:58 ", "Title": "AI-driven emergence of frequency information non-uniform distribution via THz metasurface spectrum prediction", "Authors": ["Xiaohua Xing", "Yuqi Ren", "Die Zou", "Qiankun Zhang", "Bingxuan Mao", "Jianquan Yao", "Deyi Xiong", "Shuang Zhang and Liang Wu"], "Categories": "cs.LG physics.optics", "Comments": ["11 pages", "4 figures"]}, "abstract": "Recently, artificial intelligence has been extensively deployed across various scientific disciplines, optimizing and guiding the progression of experiments through the integration of abundant datasets, whilst continuously probing the vast theoretical space encapsulated within the data. Particularly, deep learning models, due to their end-to-end adaptive learning capabilities, are capable of autonomously learning intrinsic data features, thereby transcending the limitations of traditional experience to a certain extent. Here, we unveil previously unreported information characteristics pertaining to different frequencies emerged during our work on predicting the terahertz spectral modulation effects of metasurfaces based on AI-prediction. Moreover, we have substantiated that our proposed methodology of simply adding supplementary multi-frequency inputs to the existing dataset during the target spectral prediction process can significantly enhance the predictive accuracy of the network. This approach effectively optimizes the utilization of existing datasets and paves the way for interdisciplinary research and applications in artificial intelligence, chemistry, composite material design, biomedicine, and other fields.", "url": "https://arxiv.org/abs/2312.03017"}, {"metadata": {"arXiv": "2312.03037", "Date": "Mon, 04 Dec 2023 14:32:54 ", "Title": "Analysis and mining of low-carbon and energy-saving tourism data characteristics based on machine learning algorithm", "Authors": ["Lukasz Wierzbinski"], "Categories": "cs.LG"}, "abstract": "In order to study the formation mechanism of residents' low-carbon awareness and provide an important basis for traffic managers to guide urban residents to choose low-carbon travel mode, this paper proposes a low-carbon energy-saving travel data feature analysis and mining based on machine learning algorithm. This paper uses data mining technology to analyze the data of low-carbon travel questionnaire, and regards the 15-dimensional problem under the framework of planned behavior theory as the internal cause variable that characterizes residents' low-carbon travel willingness. The author uses K-means clustering algorithm to classify the intensity of residents' low-carbon travel willingness, and applies the results as the explanatory variables to the random forest model to explore the mechanism of residents' social attribute characteristics, travel characteristics, etc. on their low-carbon travel willingness. The experimental results show that based on the Silhouette index test and t-SNE dimensionality reduction, residents' low-carbon travel willingness can be divided into three categories: strong, neutral, and not strong; Based on the importance index, the four most significant factors are the occupation, residence, family composition and commuting time of residents. Conclusion: This method provides policy recommendations for the development and management of urban traffic low-carbon from multiple perspectives.", "url": "https://arxiv.org/abs/2312.03037"}, {"metadata": {"arXiv": "2312.03041", "Date": "Tue, 05 Dec 2023 15:54:13 ", "Title": "Transformer-Based Deep Learning Model for Bored Pile Load-Deformation Prediction in Bangkok Subsoil", "Authors": ["Sompote Youwai and Chissanupong Thongnoo"], "Categories": "cs.LG cs.CE"}, "abstract": "This paper presents a novel deep learning model based on the transformer architecture to predict the load-deformation behavior of large bored piles in Bangkok subsoil. The model encodes the soil profile and pile features as tokenization input, and generates the load-deformation curve as output. The model also incorporates the previous sequential data of load-deformation curve into the decoder to improve the prediction accuracy. The model also incorporates the previous sequential data of load-deformation curve into the decoder. The model shows a satisfactory accuracy and generalization ability for the load-deformation curve prediction, with a mean absolute error of 5.72% for the test data. The model could also be used for parametric analysis and design optimization of piles under different soil and pile conditions, pile cross section, pile length and type of pile.", "url": "https://arxiv.org/abs/2312.03041"}, {"metadata": {"arXiv": "2312.03044", "Date": "Tue, 05 Dec 2023 16:27:54 ", "Title": "REST: Enhancing Group Robustness in DNNs through Reweighted Sparse Training", "Authors": ["Jiaxu Zhao", "Lu Yin", "Shiwei Liu", "Meng Fang", "Mykola Pechenizkiy"], "Categories": "cs.LG"}, "abstract": "The deep neural network (DNN) has been proven effective in various domains. However, they often struggle to perform well on certain minority groups during inference, despite showing strong performance on the majority of data groups. This is because over-parameterized models learned \\textit{bias attributes} from a large number of \\textit{bias-aligned} training samples. These bias attributes are strongly spuriously correlated with the target variable, causing the models to be biased towards spurious correlations (i.e., \\textit{bias-conflicting}). To tackle this issue, we propose a novel \\textbf{re}weighted \\textbf{s}parse \\textbf{t}raining framework, dubbed as \\textit{\\textbf{REST}}, which aims to enhance the performance of biased data while improving computation and memory efficiency. Our proposed REST framework has been experimentally validated on three datasets, demonstrating its effectiveness in exploring unbiased subnetworks. We found that REST reduces the reliance on spuriously correlated features, leading to better performance across a wider range of data groups with fewer training and inference resources. We highlight that the \\textit{REST} framework represents a promising approach for improving the performance of DNNs on biased data, while simultaneously improving computation and memory efficiency. By reducing the reliance on spurious correlations, REST has the potential to enhance the robustness of DNNs and improve their generalization capabilities. Code is released at \\url{https://github.com/zhao1402072392/REST}", "url": "https://arxiv.org/abs/2312.03044"}, {"metadata": {"arXiv": "2312.03147", "Date": "Tue, 05 Dec 2023 21:34:59 ", "Title": "Neural parameter calibration and uncertainty quantification for epidemic forecasting", "Authors": ["Thomas Gaskin", "Tim Conrad", "Grigorios A. Pavliotis", "Christof Sch\\\"utte"], "Categories": "cs.LG math.OC", "MSC-class": "49-02, 92-02, 68-02", "ACM-class": "J.3; G.1.6; I.2.1; G.3"}, "abstract": "The recent COVID-19 pandemic has thrown the importance of accurately forecasting contagion dynamics and learning infection parameters into sharp focus. At the same time, effective policy-making requires knowledge of the uncertainty on such predictions, in order, for instance, to be able to ready hospitals and intensive care units for a worst-case scenario without needlessly wasting resources. In this work, we apply a novel and powerful computational method to the problem of learning probability densities on contagion parameters and providing uncertainty quantification for pandemic projections. Using a neural network, we calibrate an ODE model to data of the spread of COVID-19 in Berlin in 2020, achieving both a significantly more accurate calibration and prediction than Markov-Chain Monte Carlo (MCMC)-based sampling schemes. The uncertainties on our predictions provide meaningful confidence intervals e.g. on infection figures and hospitalisation rates, while training and running the neural scheme takes minutes where MCMC takes hours. We show convergence of our method to the true posterior on a simplified SIR model of epidemics, and also demonstrate our method's learning capabilities on a reduced dataset, where a complex model is learned from a small number of compartments for which data is available.", "url": "https://arxiv.org/abs/2312.03147"}, {"metadata": {"arXiv": "2312.03151", "Date": "Tue, 05 Dec 2023 21:38:24 ", "Title": "Multitask Learning Can Improve Worst-Group Outcomes", "Authors": ["Atharva Kulkarni", "Lucio Dery", "Amrith Setlur", "Aditi Raghunathan", "Ameet Talwalkar and Graham Neubig"], "Categories": "cs.LG", "Comments": ["20 pages", "7 tables", "6 Figures"]}, "abstract": "In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the common setting of fine-tuning a pre-trained model, where, following recent work (Gururangan et al., 2020; Dery et al., 2023), we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not always, achieves better worst-group accuracy than Just-Train-Twice (JTT; Liu et al. (2021)) -- a representative distributionally robust optimization (DRO) method. Leveraging insights from synthetic data experiments, we propose to modify standard MTL by regularizing the joint multitask representation space. We run a large number of fine-tuning experiments across computer vision and natural language and find that our regularized MTL approach consistently outperforms JTT on both worst and average group outcomes. Our official code can be found here: https://github.com/atharvajk98/MTL-group-robustness.", "url": "https://arxiv.org/abs/2312.03151"}, {"metadata": {"arXiv": "2312.03166", "Date": "Tue, 05 Dec 2023 22:16:54 ", "Title": "Deep Learning for Fast Inference of Mechanistic Models' Parameters", "Authors": ["Maxim Borisyak", "Stefan Born", "Peter Neubauer and Mariano Nicolas Cruz-Bournazou"], "Categories": "cs.LG q-bio.QM", "Comments": ["7 pages", "3 figures"]}, "abstract": "Inferring parameters of macro-kinetic growth models, typically represented by Ordinary Differential Equations (ODE), from the experimental data is a crucial step in bioprocess engineering. Conventionally, estimates of the parameters are obtained by fitting the mechanistic model to observations. Fitting, however, requires a significant computational power. Specifically, during the development of new bioprocesses that use previously unknown organisms or strains, efficient, robust, and computationally cheap methods for parameter estimation are of great value. In this work, we propose using Deep Neural Networks (NN) for directly predicting parameters of mechanistic models given observations. The approach requires spending computational resources for training a NN, nonetheless, once trained, such a network can provide parameter estimates orders of magnitude faster than conventional methods. We consider a training procedure that combines Neural Networks and mechanistic models. We demonstrate the performance of the proposed algorithms on data sampled from several mechanistic models used in bioengineering describing a typical industrial batch process and compare the proposed method, a typical gradient-based fitting procedure, and the combination of the two. We find that, while Neural Network estimates are slightly improved by further fitting, these estimates are measurably better than the fitting procedure alone.", "url": "https://arxiv.org/abs/2312.03166"}, {"metadata": {"arXiv": "2312.03176", "Date": "Tue, 05 Dec 2023 22:44:05 ", "Title": "Active Learning for Abrupt Shifts Change-point Detection via Derivative-Aware Gaussian Processes", "Authors": ["Hao Zhao", "Rong Pan"], "Categories": "cs.LG"}, "abstract": "Change-point detection (CPD) is crucial for identifying abrupt shifts in data, which influence decision-making and efficient resource allocation across various domains. To address the challenges posed by the costly and time-intensive data acquisition in CPD, we introduce the Derivative-Aware Change Detection (DACD) method. It leverages the derivative process of a Gaussian process (GP) for Active Learning (AL), aiming to pinpoint change-point locations effectively. DACD balances the exploitation and exploration of derivative processes through multiple data acquisition functions (AFs). By utilizing GP derivative mean and variance as criteria, DACD sequentially selects the next sampling data point, thus enhancing algorithmic efficiency and ensuring reliable and accurate results. We investigate the effectiveness of DACD method in diverse scenarios and show it outperforms other active learning change-point detection approaches.", "url": "https://arxiv.org/abs/2312.03176"}, {"metadata": {"arXiv": "2312.03196", "Date": "Wed, 06 Dec 2023 00:28:08 ", "Title": "Domain Invariant Representation Learning and Sleep Dynamics Modeling for Automatic Sleep Staging", "Authors": ["Seungyeon Lee", "Thai-Hoang Pham", "Zhao Cheng", "Ping Zhang"], "Categories": "cs.LG eess.SP"}, "abstract": "Sleep staging has become a critical task in diagnosing and treating sleep disorders to prevent sleep related diseases. With rapidly growing large scale public sleep databases and advances in machine learning, significant progress has been made toward automatic sleep staging. However, previous studies face some critical problems in sleep studies; the heterogeneity of subjects' physiological signals, the inability to extract meaningful information from unlabeled sleep signal data to improve predictive performances, the difficulty in modeling correlations between sleep stages, and the lack of an effective mechanism to quantify predictive uncertainty. In this study, we propose a neural network based automatic sleep staging model, named DREAM, to learn domain generalized representations from physiological signals and models sleep dynamics. DREAM learns sleep related and subject invariant representations from diverse subjects' sleep signal segments and models sleep dynamics by capturing interactions between sequential signal segments and between sleep stages. In the experiments, we demonstrate that DREAM outperforms the existing sleep staging methods on three datasets. The case study demonstrates that our model can learn the generalized decision function resulting in good prediction performances for the new subjects, especially in case there are differences between testing and training subjects. The usage of unlabeled data shows the benefit of leveraging unlabeled EEG data. Further, uncertainty quantification demonstrates that DREAM provides prediction uncertainty, making the model reliable and helping sleep experts in real world applications.", "url": "https://arxiv.org/abs/2312.03196"}, {"metadata": {"arXiv": "2312.03212", "Date": "Wed, 06 Dec 2023 01:00:07 ", "Title": "Constrained Bayesian Optimization Under Partial Observations: Balanced Improvements and Provable Convergence", "Authors": ["Shengbo Wang and Ke Li"], "Categories": "cs.LG stat.ML", "Comments": ["26 pages", "8 figures", "under review"]}, "abstract": "The partially observable constrained optimization problems (POCOPs) impede data-driven optimization techniques since an infeasible solution of POCOPs can provide little information about the objective as well as the constraints. We endeavor to design an efficient and provable method for expensive POCOPs under the framework of constrained Bayesian optimization. Our method consists of two key components. Firstly, we present an improved design of the acquisition functions that introduces balanced exploration during optimization. We rigorously study the convergence properties of this design to demonstrate its effectiveness. Secondly, we propose a Gaussian process embedding different likelihoods as the surrogate model for a partially observable constraint. This model leads to a more accurate representation of the feasible regions compared to traditional classification-based models. Our proposed method is empirically studied on both synthetic and real-world problems. The results demonstrate the competitiveness of our method for solving POCOPs.", "url": "https://arxiv.org/abs/2312.03212"}, {"metadata": {"arXiv": "2312.03213", "Date": "Wed, 06 Dec 2023 01:02:13 ", "Title": "Bootstrap Your Own Variance", "Authors": ["Polina Turishcheva", "Jason Ramapuram", "Sinead Williamson", "Dan Busbridge", "Eeshan Dhekane", "Russ Webb"], "Categories": "cs.LG stat.ML", "Journal-ref": "NeurIPS 2023 Workshop: Self-Supervised Learning - Theory and Practice"}, "abstract": "Understanding model uncertainty is important for many applications. We propose Bootstrap Your Own Variance (BYOV), combining Bootstrap Your Own Latent (BYOL), a negative-free Self-Supervised Learning (SSL) algorithm, with Bayes by Backprop (BBB), a Bayesian method for estimating model posteriors. We find that the learned predictive std of BYOV vs. a supervised BBB model is well captured by a Gaussian distribution, providing preliminary evidence that the learned parameter posterior is useful for label free uncertainty estimation. BYOV improves upon the deterministic BYOL baseline (+2.83% test ECE, +1.03% test Brier) and presents better calibration and reliability when tested with various augmentations (eg: +2.4% test ECE, +1.2% test Brier for Salt & Pepper noise).", "url": "https://arxiv.org/abs/2312.03213"}, {"metadata": {"arXiv": "2312.03218", "Date": "Wed, 06 Dec 2023 01:16:10 ", "Title": "Accelerated Gradient Algorithms with Adaptive Subspace Search for Instance-Faster Optimization", "Authors": ["Yuanshi Liu", "Hanzhen Zhao", "Yang Xu", "Pengyun Yue", "Cong Fang"], "Categories": "cs.LG cs.CC stat.ML", "Comments": ["Optimization for Machine Learning"]}, "abstract": "Gradient-based minimax optimal algorithms have greatly promoted the development of continuous optimization and machine learning. One seminal work due to Yurii Nesterov [Nes83a] established $\\tilde{\\mathcal{O}}(\\sqrt{L/\\mu})$ gradient complexity for minimizing an $L$-smooth $\\mu$-strongly convex objective. However, an ideal algorithm would adapt to the explicit complexity of a particular objective function and incur faster rates for simpler problems, triggering our reconsideration of two defeats of existing optimization modeling and analysis. (i) The worst-case optimality is neither the instance optimality nor such one in reality. (ii) Traditional $L$-smoothness condition may not be the primary abstraction/characterization for modern practical problems. In this paper, we open up a new way to design and analyze gradient-based algorithms with direct applications in machine learning, including linear regression and beyond. We introduce two factors $(\\alpha, \\tau_{\\alpha})$ to refine the description of the degenerated condition of the optimization problems based on the observation that the singular values of Hessian often drop sharply. We design adaptive algorithms that solve simpler problems without pre-known knowledge with reduced gradient or analogous oracle accesses. The algorithms also improve the state-of-art complexities for several problems in machine learning, thereby solving the open problem of how to design faster algorithms in light of the known complexity lower bounds. Specially, with the $\\mathcal{O}(1)$-nuclear norm bounded, we achieve an optimal $\\tilde{\\mathcal{O}}(\\mu^{-1/3})$ (v.s. $\\tilde{\\mathcal{O}}(\\mu^{-1/2})$) gradient complexity for linear regression. We hope this work could invoke the rethinking for understanding the difficulty of modern problems in optimization.", "url": "https://arxiv.org/abs/2312.03218"}, {"metadata": {"arXiv": "2312.03253", "Date": "Wed, 06 Dec 2023 02:58:49 ", "Title": "Seller-side Outcome Fairness in Online Marketplaces", "Authors": ["Zikun Ye", "Reza Yousefi Maragheh", "Lalitesh Morishetti", "Shanu Vashishtha", "Jason Cho", "Kaushiki Nag", "Sushant Kumar", "Kannan Achan"], "Categories": "cs.LG math.OC"}, "abstract": "This paper aims to investigate and achieve seller-side fairness within online marketplaces, where many sellers and their items are not sufficiently exposed to customers in an e-commerce platform. This phenomenon raises concerns regarding the potential loss of revenue associated with less exposed items as well as less marketplace diversity. We introduce the notion of seller-side outcome fairness and build an optimization model to balance collected recommendation rewards and the fairness metric. We then propose a gradient-based data-driven algorithm based on the duality and bandit theory. Our numerical experiments on real e-commerce data sets show that our algorithm can lift seller fairness measures while not hurting metrics like collected Gross Merchandise Value (GMV) and total purchases.", "url": "https://arxiv.org/abs/2312.03253"}, {"metadata": {"arXiv": "2312.03256", "Date": "Wed, 06 Dec 2023 03:09:19 ", "Title": "CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale Recommendation Models", "Authors": ["Hailin Zhang", "Zirui Liu", "Boxuan Chen", "Yikai Zhao", "Tong Zhao", "Tong Yang", "Bin Cui"], "Categories": "cs.LG"}, "abstract": "Recently, the growing memory demands of embedding tables in Deep Learning Recommendation Models (DLRMs) pose great challenges for model training and deployment. Existing embedding compression solutions cannot simultaneously meet three key design requirements: memory efficiency, low latency, and adaptability to dynamic data distribution. This paper presents CAFE, a Compact, Adaptive, and Fast Embedding compression framework that addresses the above requirements. The design philosophy of CAFE is to dynamically allocate more memory resources to important features (called hot features), and allocate less memory to unimportant ones. In CAFE, we propose a fast and lightweight sketch data structure, named HotSketch, to capture feature importance and report hot features in real time. For each reported hot feature, we assign it a unique embedding. For the non-hot features, we allow multiple features to share one embedding by using hash embedding technique. Guided by our design philosophy, we further propose a multi-level hash embedding framework to optimize the embedding tables of non-hot features. We theoretically analyze the accuracy of HotSketch, and analyze the model convergence against deviation. Extensive experiments show that CAFE significantly outperforms existing embedding compression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo Kaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The source codes of CAFE are available at GitHub.", "url": "https://arxiv.org/abs/2312.03256"}, {"metadata": {"arXiv": "2312.03259", "Date": "Wed, 06 Dec 2023 03:14:16 ", "Title": "f-FERM: A Scalable Framework for Robust Fair Empirical Risk Minimization", "Authors": ["Sina Baharlouei", "Shivam Patel", "Meisam Razaviyayn"], "Categories": "cs.LG", "Comments": ["23 Pages,5 figures"]}, "abstract": "Training and deploying machine learning models that meet fairness criteria for protected groups are fundamental in modern artificial intelligence. While numerous constraints and regularization terms have been proposed in the literature to promote fairness in machine learning tasks, most of these methods are not amenable to stochastic optimization due to the complex and nonlinear structure of constraints and regularizers. Here, the term \"stochastic\" refers to the ability of the algorithm to work with small mini-batches of data. Motivated by the limitation of existing literature, this paper presents a unified stochastic optimization framework for fair empirical risk minimization based on f-divergence measures (f-FERM). The proposed stochastic algorithm enjoys theoretical convergence guarantees. In addition, our experiments demonstrate the superiority of fairness-accuracy tradeoffs offered by f-FERM for almost all batch sizes (ranging from full-batch to batch size of one). Moreover, we show that our framework can be extended to the case where there is a distribution shift from training to the test data. Our extension is based on a distributionally robust optimization reformulation of f-FERM objective under $L_p$ norms as uncertainty sets. Again, in this distributionally robust setting, f-FERM not only enjoys theoretical convergence guarantees but also outperforms other baselines in the literature in the tasks involving distribution shifts. An efficient stochastic implementation of $f$-FERM is publicly available.", "url": "https://arxiv.org/abs/2312.03259"}, {"metadata": {"arXiv": "2312.03277", "Date": "Wed, 06 Dec 2023 04:05:17 ", "Title": "Anomaly Detection for Scalable Task Grouping in Reinforcement Learning-based RAN Optimization", "Authors": ["Jimmy Li", "Igor Kozlov", "Di Wu", "Xue Liu", "Gregory Dudek"], "Categories": "cs.LG"}, "abstract": "The use of learning-based methods for optimizing cellular radio access networks (RAN) has received increasing attention in recent years. This coincides with a rapid increase in the number of cell sites worldwide, driven largely by dramatic growth in cellular network traffic. Training and maintaining learned models that work well across a large number of cell sites has thus become a pertinent problem. This paper proposes a scalable framework for constructing a reinforcement learning policy bank that can perform RAN optimization across a large number of cell sites with varying traffic patterns. Central to our framework is a novel application of anomaly detection techniques to assess the compatibility between sites (tasks) and the policy bank. This allows our framework to intelligently identify when a policy can be reused for a task, and when a new policy needs to be trained and added to the policy bank. Our results show that our approach to compatibility assessment leads to an efficient use of computational resources, by allowing us to construct a performant policy bank without exhaustively training on all tasks, which makes it applicable under real-world constraints.", "url": "https://arxiv.org/abs/2312.03277"}, {"metadata": {"arXiv": "2312.03292", "Date": "Wed, 06 Dec 2023 05:02:10 ", "Title": "Enhancing Molecular Property Prediction via Mixture of Collaborative Experts", "Authors": ["Xu Yao", "Shuang Liang", "Songqiao Han and Hailiang Huang"], "Categories": "cs.LG cs.MA q-bio.QM", "Comments": ["11 pages", "8 figures"]}, "abstract": "Molecular Property Prediction (MPP) task involves predicting biochemical properties based on molecular features, such as molecular graph structures, contributing to the discovery of lead compounds in drug development. To address data scarcity and imbalance in MPP, some studies have adopted Graph Neural Networks (GNN) as an encoder to extract commonalities from molecular graphs. However, these approaches often use a separate predictor for each task, neglecting the shared characteristics among predictors corresponding to different tasks. In response to this limitation, we introduce the GNN-MoCE architecture. It employs the Mixture of Collaborative Experts (MoCE) as predictors, exploiting task commonalities while confronting the homogeneity issue in the expert pool and the decision dominance dilemma within the expert group. To enhance expert diversity for collaboration among all experts, the Expert-Specific Projection method is proposed to assign a unique projection perspective to each expert. To balance decision-making influence for collaboration within the expert group, the Expert-Specific Loss is presented to integrate individual expert loss into the weighted decision loss of the group for more equitable training. Benefiting from the enhancements of MoCE in expert creation, dynamic expert group formation, and experts' collaboration, our model demonstrates superior performance over traditional methods on 24 MPP datasets, especially in tasks with limited data or high imbalance.", "url": "https://arxiv.org/abs/2312.03292"}, {"metadata": {"arXiv": "2312.03318", "Date": "Wed, 06 Dec 2023 07:02:22 ", "Title": "Complementary Benefits of Contrastive Learning and Self-Training Under Distribution Shift", "Authors": ["Saurabh Garg", "Amrith Setlur", "Zachary Chase Lipton", "Sivaraman Balakrishnan", "Virginia Smith", "Aditi Raghunathan"], "Categories": "cs.LG cs.CV stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "Self-training and contrastive learning have emerged as leading techniques for incorporating unlabeled data, both under distribution shift (unsupervised domain adaptation) and when it is absent (semi-supervised learning). However, despite the popularity and compatibility of these techniques, their efficacy in combination remains unexplored. In this paper, we undertake a systematic empirical investigation of this combination, finding that (i) in domain adaptation settings, self-training and contrastive learning offer significant complementary gains; and (ii) in semi-supervised learning settings, surprisingly, the benefits are not synergistic. Across eight distribution shift datasets (e.g., BREEDs, WILDS), we demonstrate that the combined method obtains 3--8% higher accuracy than either approach independently. We then theoretically analyze these techniques in a simplified model of distribution shift, demonstrating scenarios under which the features produced by contrastive learning can yield a good initialization for self-training to further amplify gains and achieve optimal performance, even when either method alone would fail.", "url": "https://arxiv.org/abs/2312.03318"}, {"metadata": {"arXiv": "2312.03344", "Date": "Wed, 06 Dec 2023 08:36:23 ", "Title": "Interpretable Mechanistic Representations for Meal-level Glycemic Control in the Wild", "Authors": ["Ke Alexander Wang", "Emily B. Fox"], "Categories": "cs.LG math.DS stat.AP stat.ML", "Comments": ["Proceedings of Machine Learning for Health (ML4H) 2023. Code available at: https://github.com/KeAWang/interpretable-cgm-representations"]}, "abstract": "Diabetes encompasses a complex landscape of glycemic control that varies widely among individuals. However, current methods do not faithfully capture this variability at the meal level. On the one hand, expert-crafted features lack the flexibility of data-driven methods; on the other hand, learned representations tend to be uninterpretable which hampers clinical adoption. In this paper, we propose a hybrid variational autoencoder to learn interpretable representations of CGM and meal data. Our method grounds the latent space to the inputs of a mechanistic differential equation, producing embeddings that reflect physiological quantities, such as insulin sensitivity, glucose effectiveness, and basal glucose levels. Moreover, we introduce a novel method to infer the glucose appearance rate, making the mechanistic model robust to unreliable meal logs. On a dataset of CGM and self-reported meals from individuals with type-2 diabetes and pre-diabetes, our unsupervised representation discovers a separation between individuals proportional to their disease severity. Our embeddings produce clusters that are up to 4x better than naive, expert, black-box, and pure mechanistic features. Our method provides a nuanced, yet interpretable, embedding space to compare glycemic control within and across individuals, directly learnable from in-the-wild data.", "url": "https://arxiv.org/abs/2312.03344"}, {"metadata": {"arXiv": "2312.03386", "Date": "Wed, 06 Dec 2023 09:52:18 ", "Title": "An Infinite-Width Analysis on the Jacobian-Regularised Training of a Neural Network", "Authors": ["Taeyoung Kim", "Hongseok Yang"], "Categories": "cs.LG stat.ML", "Comments": ["72 pages", "21 figures"]}, "abstract": "The recent theoretical analysis of deep neural networks in their infinite-width limits has deepened our understanding of initialisation, feature learning, and training of those networks, and brought new practical techniques for finding appropriate hyperparameters, learning network weights, and performing inference. In this paper, we broaden this line of research by showing that this infinite-width analysis can be extended to the Jacobian of a deep neural network. We show that a multilayer perceptron (MLP) and its Jacobian at initialisation jointly converge to a Gaussian process (GP) as the widths of the MLP's hidden layers go to infinity and characterise this GP. We also prove that in the infinite-width limit, the evolution of the MLP under the so-called robust training (i.e., training with a regulariser on the Jacobian) is described by a linear first-order ordinary differential equation that is determined by a variant of the Neural Tangent Kernel. We experimentally show the relevance of our theoretical claims to wide finite networks, and empirically analyse the properties of kernel regression solution to obtain an insight into Jacobian regularisation.", "url": "https://arxiv.org/abs/2312.03386"}, {"metadata": {"arXiv": "2312.03414", "Date": "Wed, 06 Dec 2023 10:50:43 ", "Title": "Compressed Context Memory For Online Language Model Interaction", "Authors": ["Jang-Hyun Kim", "Junyoung Yeom", "Sangdoo Yun", "Hyun Oh Song"], "Categories": "cs.LG cs.CL"}, "abstract": "This paper presents a novel context compression method for Transformer language models in online scenarios such as ChatGPT, where the context continually expands. As the context lengthens, the attention process requires more memory and computational resources, which in turn reduces the throughput of the language model. To this end, we propose a compressed context memory system that continually compresses the growing context into a compact memory space. The compression process simply involves integrating a lightweight conditional LoRA into the language model's forward pass during inference. Based on the compressed context memory, the language model can perform inference with reduced memory and attention operations. Through evaluations on conversation, personalization, and multi-task learning, we demonstrate that our approach achieves the performance level of a full context model with $5\\times$ smaller context memory space. Codes are available at https://github.com/snu-mllab/context-memory.", "url": "https://arxiv.org/abs/2312.03414"}, {"metadata": {"arXiv": "2312.03415", "Date": "Wed, 06 Dec 2023 10:54:34 ", "Title": "Run LoRA Run: Faster and Lighter LoRA Implementations", "Authors": ["Daria Cherniuk", "Aleksandr Mikhalev", "Ivan Oseledets"], "Categories": "cs.LG"}, "abstract": "LoRA is a technique that reduces the number of trainable parameters in a neural network by introducing low-rank adapters to linear layers. This technique is used both for fine-tuning (LoRA, QLoRA) and full train (ReLoRA). This paper presents the RunLoRA framework for efficient implementations of LoRA that significantly improves the speed of neural network training and fine-tuning using low-rank adapters. The proposed implementation optimizes the computation of LoRA operations based on dimensions of corresponding linear layer, layer input dimensions and lora rank by choosing best forward and backward computation graph based on FLOPs and time estimations, resulting in faster training without sacrificing accuracy. The experimental results show up to 17% speedup on Llama family of models.", "url": "https://arxiv.org/abs/2312.03415"}, {"metadata": {"arXiv": "2312.03464", "Date": "Wed, 06 Dec 2023 12:40:06 ", "Title": "Subnetwork-to-go: Elastic Neural Network with Dynamic Training and Customizable Inference", "Authors": ["Kai Li", "Yi Luo"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["5 pages", "3 figures"]}, "abstract": "Deploying neural networks to different devices or platforms is in general challenging, especially when the model size is large or model complexity is high. Although there exist ways for model pruning or distillation, it is typically required to perform a full round of model training or finetuning procedure in order to obtain a smaller model that satisfies the model size or complexity constraints. Motivated by recent works on dynamic neural networks, we propose a simple way to train a large network and flexibly extract a subnetwork from it given a model size or complexity constraint during inference. We introduce a new way to allow a large model to be trained with dynamic depth and width during the training phase, and after the large model is trained we can select a subnetwork from it with arbitrary depth and width during the inference phase with a relatively better performance compared to training the subnetwork independently from scratch. Experiment results on a music source separation model show that our proposed method can effectively improve the separation performance across different subnetwork sizes and complexities with a single large model, and training the large model takes significantly shorter time than training all the different subnetworks.", "url": "https://arxiv.org/abs/2312.03464"}, {"metadata": {"arXiv": "2312.03466", "Date": "Wed, 06 Dec 2023 12:41:53 ", "Title": "Search Strategies for Self-driving Laboratories with Pending Experiments", "Authors": ["Hao Wen", "Jakob Zeitler", "Connor Rupnow"], "Categories": "cs.LG cs.RO", "Comments": ["Accepted at NeurIPS 2023", "AI4Mat"]}, "abstract": "Self-driving laboratories (SDLs) consist of multiple stations that perform material synthesis and characterisation tasks. To minimize station downtime and maximize experimental throughput, it is practical to run experiments in asynchronous parallel, in which multiple experiments are being performed at once in different stages. Asynchronous parallelization of experiments, however, introduces delayed feedback (i.e. \"pending experiments\"), which is known to reduce Bayesian optimiser performance. Here, we build a simulator for a multi-stage SDL and compare optimisation strategies for dealing with delayed feedback and asynchronous parallelized operation. Using data from a real SDL, we build a ground truth Bayesian optimisation simulator from 177 previously run experiments for maximizing the conductivity of functional coatings. We then compare search strategies such as expected improvement, noisy expected improvement, 4-mode exploration and random sampling. We evaluate their performance in terms of amount of delay and problem dimensionality. Our simulation results showcase the trade-off between the asynchronous parallel operation and delayed feedback.", "url": "https://arxiv.org/abs/2312.03466"}, {"metadata": {"arXiv": "2312.03510", "Date": "Wed, 06 Dec 2023 14:13:30 ", "Title": "Towards Sobolev Training", "Authors": ["Neil Kichler", "Sher Afghan", "Uwe Naumann"], "Categories": "cs.LG q-fin.CP"}, "abstract": "The increasing use of stochastic models for describing complex phenomena warrants surrogate models that capture the reference model characteristics at a fraction of the computational cost, foregoing potentially expensive Monte Carlo simulation. The predominant approach of fitting a large neural network and then pruning it to a reduced size has commonly neglected shortcomings. The produced surrogate models often will not capture the sensitivities and uncertainties inherent in the original model. In particular, (higher-order) derivative information of such surrogates could differ drastically. Given a large enough network, we expect this derivative information to match. However, the pruned model will almost certainly not share this behavior. In this paper, we propose to find surrogate models by using sensitivity information throughout the learning and pruning process. We build on work using Interval Adjoint Significance Analysis for pruning and combine it with the recent advancements in Sobolev Training to accurately model the original sensitivity information in the pruned neural network based surrogate model. We experimentally underpin the method on an example of pricing a multidimensional Basket option modelled through a stochastic differential equation with Brownian motion. The proposed method is, however, not limited to the domain of quantitative finance, which was chosen as a case study for intuitive interpretations of the sensitivities. It serves as a foundation for building further surrogate modelling techniques considering sensitivity information.", "url": "https://arxiv.org/abs/2312.03510"}, {"metadata": {"arXiv": "2312.03612", "Date": "Wed, 06 Dec 2023 16:56:28 ", "Title": "Physical Symbolic Optimization", "Authors": ["Wassim Tenachi", "Rodrigo Ibata", "Foivos I. Diakogiannis"], "Categories": "cs.LG astro-ph.IM cs.SC physics.comp-ph physics.data-an", "Comments": ["6 pages", "2 figures", "1 table. Accepted to NeurIPS 2023", "Machine Learning for Physical Sciences workshop"]}, "abstract": "We present a framework for constraining the automatic sequential generation of equations to obey the rules of dimensional analysis by construction. Combining this approach with reinforcement learning, we built $\\Phi$-SO, a Physical Symbolic Optimization method for recovering analytical functions from physical data leveraging units constraints. Our symbolic regression algorithm achieves state-of-the-art results in contexts in which variables and constants have known physical units, outperforming all other methods on SRBench's Feynman benchmark in the presence of noise (exceeding 0.1%) and showing resilience even in the presence of significant (10%) levels of noise.", "url": "https://arxiv.org/abs/2312.03612"}, {"metadata": {"arXiv": "2312.03642", "Date": "Wed, 06 Dec 2023 17:53:06 ", "Title": "Transformer-Powered Surrogates Close the ICF Simulation-Experiment Gap with Extremely Limited Data", "Authors": ["Matthew L. Olson", "Shusen Liu", "Jayaraman J. Thiagarajan", "Bogdan Kustowski", "Weng-Keen Wong", "Rushil Anirudh"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Recent advances in machine learning, specifically transformer architecture, have led to significant advancements in commercial domains. These powerful models have demonstrated superior capability to learn complex relationships and often generalize better to new data and problems. This paper presents a novel transformer-powered approach for enhancing prediction accuracy in multi-modal output scenarios, where sparse experimental data is supplemented with simulation data. The proposed approach integrates transformer-based architecture with a novel graph-based hyper-parameter optimization technique. The resulting system not only effectively reduces simulation bias, but also achieves superior prediction accuracy compared to the prior method. We demonstrate the efficacy of our approach on inertial confinement fusion experiments, where only 10 shots of real-world data are available, as well as synthetic versions of these experiments.", "url": "https://arxiv.org/abs/2312.03642"}, {"metadata": {"arXiv": "2312.03644", "Date": "Wed, 06 Dec 2023 17:59:34 ", "Title": "MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit Assignment", "Authors": ["Ziyan Wang", "Yali Du", "Yudi Zhang", "Meng Fang", "Biwei Huang"], "Categories": "cs.LG cs.MA", "Comments": ["16 pages", "4 figures"]}, "abstract": "Offline Multi-agent Reinforcement Learning (MARL) is valuable in scenarios where online interaction is impractical or risky. While independent learning in MARL offers flexibility and scalability, accurately assigning credit to individual agents in offline settings poses challenges due to partial observability and emergent behavior. Directly transferring the online credit assignment method to offline settings results in suboptimal outcomes due to the absence of real-time feedback and intricate agent interactions. Our approach, MACCA, characterizing the generative process as a Dynamic Bayesian Network, captures relationships between environmental variables, states, actions, and rewards. Estimating this model on offline data, MACCA can learn each agent's contribution by analyzing the causal relationship of their individual rewards, ensuring accurate and interpretable credit assignment. Additionally, the modularity of our approach allows it to seamlessly integrate with various offline MARL methods. Theoretically, we proved that under the setting of the offline dataset, the underlying causal structure and the function for generating the individual rewards of agents are identifiable, which laid the foundation for the correctness of our modeling. Experimentally, we tested MACCA in two environments, including discrete and continuous action settings. The results show that MACCA outperforms SOTA methods and improves performance upon their backbones.", "url": "https://arxiv.org/abs/2312.03644"}, {"metadata": {"arXiv": "2312.03656", "Date": "Wed, 06 Dec 2023 18:25:53 ", "Title": "Interpretability Illusions in the Generalization of Simplified Models", "Authors": ["Dan Friedman", "Andrew Lampinen", "Lucas Dixon", "Danqi Chen", "Asma Ghandeharioun"], "Categories": "cs.LG cs.CL"}, "abstract": "A common method to study deep learning systems is to use simplified model representations -- for example, using singular value decomposition to visualize the model's hidden states in a lower dimensional space. This approach assumes that the results of these simplified are faithful to the original model. Here, we illustrate an important caveat to this assumption: even if the simplified representations can accurately approximate the full model on the training set, they may fail to accurately capture the model's behavior out of distribution -- the understanding developed from simplified representations may be an illusion. We illustrate this by training Transformer models on controlled datasets with systematic generalization splits. First, we train models on the Dyck balanced-parenthesis languages. We simplify these models using tools like dimensionality reduction and clustering, and then explicitly test how these simplified proxies match the behavior of the original model on various out-of-distribution test sets. We find that the simplified proxies are generally less faithful out of distribution. In cases where the original model generalizes to novel structures or deeper depths, the simplified versions may fail, or generalize better. This finding holds even if the simplified representations do not directly depend on the training distribution. Next, we study a more naturalistic task: predicting the next character in a dataset of computer code. We find similar generalization gaps between the original model and simplified proxies, and conduct further analysis to investigate which aspects of the code completion task are associated with the largest gaps. Together, our results raise questions about the extent to which mechanistic interpretations derived using tools like SVD can reliably predict what a model will do in novel situations.", "url": "https://arxiv.org/abs/2312.03656"}, {"metadata": {"arXiv": "2312.03675", "Date": "Wed, 06 Dec 2023 18:39:29 ", "Title": "GeoShapley: A Game Theory Approach to Measuring Spatial Effects in Machine Learning Models", "Authors": ["Ziqi Li"], "Categories": "cs.LG stat.ML", "Comments": ["30 pages", "10 figures", "6 tables"]}, "abstract": "This paper introduces GeoShapley, a game theory approach to measuring spatial effects in machine learning models. GeoShapley extends the Nobel Prize-winning Shapley value framework in game theory by conceptualizing location as a player in a model prediction game, which enables the quantification of the importance of location and the synergies between location and other features in a model. GeoShapley is a model-agnostic approach and can be applied to statistical or black-box machine learning models in various structures. The interpretation of GeoShapley is directly linked with spatially varying coefficient models for explaining spatial effects and additive models for explaining non-spatial effects. Using simulated data, GeoShapley values are validated against known data-generating processes and are used for cross-comparison of seven statistical and machine learning models. An empirical example of house price modeling is used to illustrate GeoShapley's utility and interpretation with real world data. The method is available as an open-source Python package named geoshapley.", "url": "https://arxiv.org/abs/2312.03675"}, {"metadata": {"arXiv": "2312.03691", "Date": "Wed, 06 Dec 2023 18:54:27 ", "Title": "On the Role of Edge Dependency in Graph Generative Models", "Authors": ["Sudhanshu Chanpuriya", "Cameron Musco", "Konstantinos Sotiropoulos", "Charalampos Tsourakakis"], "Categories": "cs.LG cs.SI"}, "abstract": "In this work, we introduce a novel evaluation framework for generative models of graphs, emphasizing the importance of model-generated graph overlap (Chanpuriya et al., 2021) to ensure both accuracy and edge-diversity. We delineate a hierarchy of graph generative models categorized into three levels of complexity: edge independent, node independent, and fully dependent models. This hierarchy encapsulates a wide range of prevalent methods. We derive theoretical bounds on the number of triangles and other short-length cycles producible by each level of the hierarchy, contingent on the model overlap. We provide instances demonstrating the asymptotic optimality of our bounds. Furthermore, we introduce new generative models for each of the three hierarchical levels, leveraging dense subgraph discovery (Gionis & Tsourakakis, 2015). Our evaluation, conducted on real-world datasets, focuses on assessing the output quality and overlap of our proposed models in comparison to other popular models. Our results indicate that our simple, interpretable models provide competitive baselines to popular generative models. Through this investigation, we aim to propel the advancement of graph generative models by offering a structured framework and robust evaluation metrics, thereby facilitating the development of models capable of generating accurate and edge-diverse graphs.", "url": "https://arxiv.org/abs/2312.03691"}, {"metadata": {"arXiv": "2312.03296", "Date": "Wed, 06 Dec 2023 05:36:52 ", "Title": "Cooperative Probabilistic Trajectory Forecasting under Occlusion", "Authors": ["Anshul Nayak", "Azim Eskandarian"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["10 pages", "13 figures", "1 table"]}, "abstract": "Perception and planning under occlusion is essential for safety-critical tasks. Occlusion-aware planning often requires communicating the information of the occluded object to the ego agent for safe navigation. However, communicating rich sensor information under adverse conditions during communication loss and limited bandwidth may not be always feasible. Further, in GPS denied environments and indoor navigation, localizing and sharing of occluded objects can be challenging. To overcome this, relative pose estimation between connected agents sharing a common field of view can be a computationally effective way of communicating information about surrounding objects. In this paper, we design an end-to-end network that cooperatively estimates the current states of occluded pedestrian in the reference frame of ego agent and then predicts the trajectory with safety guarantees. Experimentally, we show that the uncertainty-aware trajectory prediction of occluded pedestrian by the ego agent is almost similar to the ground truth trajectory assuming no occlusion. The current research holds promise for uncertainty-aware navigation among multiple connected agents under occlusion.", "url": "https://arxiv.org/abs/2312.03296"}, {"metadata": {"arXiv": "2312.03328", "Date": "Wed, 06 Dec 2023 07:33:22 ", "Title": "Deep Learning for Koopman-based Dynamic Movement Primitives", "Authors": ["Tyler Han and Carl Glen Henshaw"], "Categories": "cs.RO cs.LG"}, "abstract": "The challenge of teaching robots to perform dexterous manipulation, dynamic locomotion, or whole--body manipulation from a small number of demonstrations is an important research field that has attracted interest from across the robotics community. In this work, we propose a novel approach by joining the theories of Koopman Operators and Dynamic Movement Primitives to Learning from Demonstration. Our approach, named \\gls{admd}, projects nonlinear dynamical systems into linear latent spaces such that a solution reproduces the desired complex motion. Use of an autoencoder in our approach enables generalizability and scalability, while the constraint to a linear system attains interpretability. Our results are comparable to the Extended Dynamic Mode Decomposition on the LASA Handwriting dataset but with training on only a small fractions of the letters.", "url": "https://arxiv.org/abs/2312.03328"}, {"metadata": {"arXiv": "2312.03477", "Date": "Wed, 06 Dec 2023 13:10:02 ", "Title": "From Detection to Action Recognition: An Edge-Based Pipeline for Robot Human Perception", "Authors": ["Petros Toupas", "Georgios Tsamis", "Dimitrios Giakoumis", "Konstantinos Votis", "Dimitrios Tzovaras"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["7 pages", "10 figures", "2 tables"]}, "abstract": "Mobile service robots are proving to be increasingly effective in a range of applications, such as healthcare, monitoring Activities of Daily Living (ADL), and facilitating Ambient Assisted Living (AAL). These robots heavily rely on Human Action Recognition (HAR) to interpret human actions and intentions. However, for HAR to function effectively on service robots, it requires prior knowledge of human presence (human detection) and identification of individuals to monitor (human tracking). In this work, we propose an end-to-end pipeline that encompasses the entire process, starting from human detection and tracking, leading to action recognition. The pipeline is designed to operate in near real-time while ensuring all stages of processing are performed on the edge, reducing the need for centralised computation. To identify the most suitable models for our mobile robot, we conducted a series of experiments comparing state-of-the-art solutions based on both their detection performance and efficiency. To evaluate the effectiveness of our proposed pipeline, we proposed a dataset comprising daily household activities. By presenting our findings and analysing the results, we demonstrate the efficacy of our approach in enabling mobile robots to understand and respond to human behaviour in real-world scenarios relying mainly on the data from their RGB cameras.", "url": "https://arxiv.org/abs/2312.03477"}, {"metadata": {"arXiv": "2312.03651", "Date": "Wed, 06 Dec 2023 18:13:21 ", "Title": "MICRACLE: Inverse Reinforcement and Curriculum Learning Model for Human-inspired Mobile Robot Navigation", "Authors": ["Nihal Gunukula", "Kshitij Tiwari", "Aniket Bera"], "Categories": "cs.RO cs.LG"}, "abstract": "In emergency scenarios, mobile robots must navigate like humans, interpreting stimuli to locate potential victims rapidly without interfering with first responders. Existing socially-aware navigation algorithms face computational and adaptability challenges. To overcome these, we propose a solution, MIRACLE -- an inverse reinforcement and curriculum learning model, that employs gamified learning to gather stimuli-driven human navigational data. This data is then used to train a Deep Inverse Maximum Entropy Reinforcement Learning model, reducing reliance on demonstrator abilities. Testing reveals a low loss of 2.7717 within a 400-sized environment, signifying human-like response replication. Current databases lack comprehensive stimuli-driven data, necessitating our approach. By doing so, we enable robots to navigate emergency situations with human-like perception, enhancing their life-saving capabilities.", "url": "https://arxiv.org/abs/2312.03651"}, {"metadata": {"arXiv": "2312.03673", "Date": "Wed, 06 Dec 2023 18:38:05 ", "Title": "On the Role of the Action Space in Robot Manipulation Learning and Sim-to-Real Transfer", "Authors": ["Elie Aljalbout", "Felix Frank", "Maximilian Karl", "and Patrick van der Smagt"], "Categories": "cs.RO cs.LG"}, "abstract": "We study the choice of action space in robot manipulation learning and sim-to-real transfer. We define metrics that assess the performance, and examine the emerging properties in the different action spaces. We train over 250 reinforcement learning~(RL) agents in simulated reaching and pushing tasks, using 13 different control spaces. The choice of action spaces spans popular choices in the literature as well as novel combinations of common design characteristics. We evaluate the training performance in simulation and the transfer to a real-world environment. We identify good and bad characteristics of robotic action spaces and make recommendations for future designs. Our findings have important implications for the design of RL algorithms for robot manipulation tasks, and highlight the need for careful consideration of action spaces when training and transferring RL agents for real-world robotics.", "url": "https://arxiv.org/abs/2312.03673"}, {"metadata": {"arXiv": "2312.03121", "Date": "Tue, 05 Dec 2023 20:40:37 ", "Title": "Evaluating Agents using Social Choice Theory", "Authors": ["Marc Lanctot", "Kate Larson", "Yoram Bachrach", "Luke Marris", "Zun Li", "Avishkar Bhoopchand", "Thomas Anthony", "Brian Tanner", "Anna Koop"], "Categories": "cs.AI cs.GT cs.MA"}, "abstract": "We argue that many general evaluation problems can be viewed through the lens of voting theory. Each task is interpreted as a separate voter, which requires only ordinal rankings or pairwise comparisons of agents to produce an overall evaluation. By viewing the aggregator as a social welfare function, we are able to leverage centuries of research in social choice theory to derive principled evaluation frameworks with axiomatic foundations. These evaluations are interpretable and flexible, while avoiding many of the problems currently facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE) framework across multiple settings, including reinforcement learning, large language models, and humans. In practice, we observe that VasE can be more robust than popular evaluation frameworks (Elo and Nash averaging), discovers properties in the evaluation data not evident from scores alone, and can predict outcomes better than Elo in a complex seven-player game. We identify one particular approach, maximal lotteries, that satisfies important consistency properties relevant to evaluation, is computationally efficient (polynomial in the size of the evaluation data), and identifies game-theoretic cycles", "url": "https://arxiv.org/abs/2312.03121"}, {"metadata": {"arXiv": "2312.03290", "Date": "Wed, 06 Dec 2023 04:48:26 ", "Title": "Can language agents be alternatives to PPO? A Preliminary Empirical Study On OpenAI Gym", "Authors": ["Junjie Sheng", "Zixiao Huang", "Chuyun Shen", "Wenhao Li", "Yun Hua", "Bo Jin", "Hongyuan Zha", "Xiangfeng Wang"], "Categories": "cs.AI cs.CL"}, "abstract": "The formidable capacity for zero- or few-shot decision-making in language agents encourages us to pose a compelling question: Can language agents be alternatives to PPO agents in traditional sequential decision-making tasks? To investigate this, we first take environments collected in OpenAI Gym as our testbeds and ground them to textual environments that construct the TextGym simulator. This allows for straightforward and efficient comparisons between PPO agents and language agents, given the widespread adoption of OpenAI Gym. To ensure a fair and effective benchmarking, we introduce $5$ levels of scenario for accurate domain-knowledge controlling and a unified RL-inspired framework for language agents. Additionally, we propose an innovative explore-exploit-guided language (EXE) agent to solve tasks within TextGym. Through numerical experiments and ablation studies, we extract valuable insights into the decision-making capabilities of language agents and make a preliminary evaluation of their potential to be alternatives to PPO in classical sequential decision-making problems. This paper sheds light on the performance of language agents and paves the way for future research in this exciting domain. Our code is publicly available at~\\url{https://github.com/mail-ecnu/Text-Gym-Agents}.", "url": "https://arxiv.org/abs/2312.03290"}, {"metadata": {"arXiv": "2312.03446", "Date": "Tue, 05 Dec 2023 05:34:12 ", "Title": "Visual Hindsight Self-Imitation Learning for Interactive Navigation", "Authors": ["Kibeom Kim", "Kisung Shin", "Min Whoo Lee", "Moonhoen Lee", "Minsu Lee", "Byoung-Tak Zhang"], "Categories": "cs.AI", "Comments": ["14 pages", "9 figures and under-review"]}, "abstract": "Interactive visual navigation tasks, which involve following instructions to reach and interact with specific targets, are challenging not only because successful experiences are very rare but also because the complex visual inputs require a substantial number of samples. Previous methods for these tasks often rely on intricately designed dense rewards or the use of expensive expert data for imitation learning. To tackle these challenges, we propose a novel approach, Visual Hindsight Self-Imitation Learning (VHS) for enhancing sample efficiency through hindsight goal re-labeling and self-imitation. We also introduce a prototypical goal embedding method derived from experienced goal observations, that is particularly effective in vision-based and partially observable environments. This embedding technique allows the agent to visually reinterpret its unsuccessful attempts, enabling vision-based goal re-labeling and self-imitation from enhanced successful experiences. Experimental results show that VHS outperforms existing techniques in interactive visual navigation tasks, confirming its superior performance and sample efficiency.", "url": "https://arxiv.org/abs/2312.03446"}, {"metadata": {"arXiv": "2312.03519", "Date": "Wed, 06 Dec 2023 14:25:47 ", "Title": "Active Wildfires Detection and Dynamic Escape Routes Planning for Humans through Information Fusion between Drones and Satellites", "Authors": ["Chang Liu and Tamas Sziranyi"], "Categories": "cs.AI cs.CV", "Comments": ["6 pages", "10 figures", "conference"]}, "abstract": "UAVs are playing an increasingly important role in the field of wilderness rescue by virtue of their flexibility. This paper proposes a fusion of UAV vision technology and satellite image analysis technology for active wildfires detection and road networks extraction of wildfire areas and real-time dynamic escape route planning for people in distress. Firstly, the fire source location and the segmentation of smoke and flames are targeted based on Sentinel 2 satellite imagery. Secondly, the road segmentation and the road condition assessment are performed by D-linkNet and NDVI values in the central area of the fire source by UAV. Finally, the dynamic optimal route planning for humans in real time is performed by the weighted A* algorithm in the road network with the dynamic fire spread model. Taking the Chongqing wildfire on August 24, 2022, as a case study, the results demonstrate that the dynamic escape route planning algorithm can provide an optimal real-time navigation path for humans in the presence of fire through the information fusion of UAVs and satellites.", "url": "https://arxiv.org/abs/2312.03519"}, {"metadata": {"arXiv": "2312.03664", "Date": "Wed, 06 Dec 2023 18:33:50 ", "Title": "Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia", "Authors": ["Alexander Sasha Vezhnevets", "John P. Agapiou", "Avia Aharon", "Ron Ziv", "Jayd Matyas", "Edgar A. Du\\'e\\~nez-Guzm\\'an", "William A. Cunningham", "Simon Osindero", "Danny Karmon", "Joel Z. Leibo"], "Categories": "cs.AI cs.CL", "Comments": ["31 pages", "5 figures"]}, "abstract": "Agent-based modeling has been around for decades, and applied widely across the social and natural sciences. The scope of this research method is now poised to grow dramatically as it absorbs the new affordances provided by Large Language Models (LLM)s. Generative Agent-Based Models (GABM) are not just classic Agent-Based Models (ABM)s where the agents talk to one another. Rather, GABMs are constructed using an LLM to apply common sense to situations, act \"reasonably\", recall common semantic knowledge, produce API calls to control digital technologies like apps, and communicate both within the simulation and to researchers viewing it from the outside. Here we present Concordia, a library to facilitate constructing and working with GABMs. Concordia makes it easy to construct language-mediated simulations of physically- or digitally-grounded environments. Concordia agents produce their behavior using a flexible component system which mediates between two fundamental operations: LLM calls and associative memory retrieval. A special agent called the Game Master (GM), which was inspired by tabletop role-playing games, is responsible for simulating the environment where the agents interact. Agents take actions by describing what they want to do in natural language. The GM then translates their actions into appropriate implementations. In a simulated physical world, the GM checks the physical plausibility of agent actions and describes their effects. In digital environments simulating technologies such as apps and services, the GM may handle API calls to integrate with external tools such as general AI assistants (e.g., Bard, ChatGPT), and digital apps (e.g., Calendar, Email, Search, etc.). Concordia was designed to support a wide array of applications both in scientific research and for evaluating performance of real digital services by simulating users and/or generating synthetic data.", "url": "https://arxiv.org/abs/2312.03664"}, {"metadata": {"arXiv": "2312.03011", "Date": "Mon, 04 Dec 2023 20:34:46 ", "Title": "InstructBooth: Instruction-following Personalized Text-to-Image Generation", "Authors": ["Daewon Chae", "Nokyung Park", "Jinkyu Kim", "Kimin Lee"], "Categories": "cs.CV cs.AI"}, "abstract": "Personalizing text-to-image models using a limited set of images for a specific object has been explored in subject-specific image generation. However, existing methods often encounter challenges in aligning with text prompts due to overfitting to the limited training images. In this work, we introduce InstructBooth, a novel method designed to enhance image-text alignment in personalized text-to-image models. Our approach first personalizes text-to-image models with a small number of subject-specific images using a unique identifier. After personalization, we fine-tune personalized text-to-image models using reinforcement learning to maximize a reward that quantifies image-text alignment. Additionally, we propose complementary techniques to increase the synergy between these two processes. Our method demonstrates superior image-text alignment compared to baselines while maintaining personalization ability. In human evaluations, InstructBooth outperforms DreamBooth when considering all comprehensive factors.", "url": "https://arxiv.org/abs/2312.03011"}, {"metadata": {"arXiv": "2312.03341", "Date": "Wed, 06 Dec 2023 08:26:26 ", "Title": "Online Vectorized HD Map Construction using Geometry", "Authors": ["Zhixin Zhang", "Yiyuan Zhang", "Xiaohan Ding", "Fusheng Jin", "Xiangyu Yue"], "Categories": "cs.CV cs.AI", "Comments": ["Project website https://invictus717.github.io/GeMap/"]}, "abstract": "The construction of online vectorized High-Definition (HD) maps is critical for downstream prediction and planning. Recent efforts have built strong baselines for this task, however, shapes and relations of instances in urban road systems are still under-explored, such as parallelism, perpendicular, or rectangle-shape. In our work, we propose GeMap ($\\textbf{Ge}$ometry $\\textbf{Map}$), which end-to-end learns Euclidean shapes and relations of map instances beyond basic perception. Specifically, we design a geometric loss based on angle and distance clues, which is robust to rigid transformations. We also decouple self-attention to independently handle Euclidean shapes and relations. Our method achieves new state-of-the-art performance on the NuScenes and Argoverse 2 datasets. Remarkably, it reaches a 71.8% mAP on the large-scale Argoverse 2 dataset, outperforming MapTR V2 by +4.4% and surpassing the 70% mAP threshold for the first time. Code is available at https://github.com/cnzzx/GeMap", "url": "https://arxiv.org/abs/2312.03341"}, {"metadata": {"arXiv": "2312.03517", "Date": "Wed, 06 Dec 2023 14:24:26 ", "Title": "FRDiff: Feature Reuse for Exquisite Zero-shot Acceleration of Diffusion Models", "Authors": ["Junhyuk So", "Jungwon Lee", "Eunhyeok Park"], "Categories": "cs.CV cs.AI", "Comments": ["under review"]}, "abstract": "The substantial computational costs of diffusion models, particularly due to the repeated denoising steps crucial for high-quality image generation, present a major obstacle to their widespread adoption. While several studies have attempted to address this issue by reducing the number of score function evaluations using advanced ODE solvers without fine-tuning, the decreased number of denoising iterations misses the opportunity to update fine details, resulting in noticeable quality degradation. In our work, we introduce an advanced acceleration technique that leverages the temporal redundancy inherent in diffusion models. Reusing feature maps with high temporal similarity opens up a new opportunity to save computation without sacrificing output quality. To realize the practical benefits of this intuition, we conduct an extensive analysis and propose a novel method, FRDiff. FRDiff is designed to harness the advantages of both reduced NFE and feature reuse, achieving a Pareto frontier that balances fidelity and latency trade-offs in various generative tasks.", "url": "https://arxiv.org/abs/2312.03517"}, {"metadata": {"arXiv": "2312.03520", "Date": "Wed, 06 Dec 2023 14:29:16 ", "Title": "Defense Against Adversarial Attacks using Convolutional Auto-Encoders", "Authors": ["Shreyasi Mandal"], "Categories": "cs.CV cs.AI", "Comments": ["9 pages", "6 figures", "3 tables"], "ACM-class": "I.4.5; I.5.1; I.5.4"}, "abstract": "Deep learning models, while achieving state-of-the-art performance on many tasks, are susceptible to adversarial attacks that exploit inherent vulnerabilities in their architectures. Adversarial attacks manipulate the input data with imperceptible perturbations, causing the model to misclassify the data or produce erroneous outputs. This work is based on enhancing the robustness of targeted classifier models against adversarial attacks. To achieve this, an convolutional autoencoder-based approach is employed that effectively counters adversarial perturbations introduced to the input images. By generating images closely resembling the input images, the proposed methodology aims to restore the model's accuracy.", "url": "https://arxiv.org/abs/2312.03520"}, {"metadata": {"arXiv": "2312.03543", "Date": "Wed, 06 Dec 2023 15:14:30 ", "Title": "GPT-4 Enhanced Multimodal Grounding for Autonomous Driving: Leveraging Cross-Modal Attention with Large Language Models", "Authors": ["Haicheng Liao", "Huanming Shen", "Zhenning Li", "Chengyue Wang", "Guofa Li", "Yiming Bie", "Chengzhong Xu"], "Categories": "cs.CV cs.AI"}, "abstract": "In the field of autonomous vehicles (AVs), accurately discerning commander intent and executing linguistic commands within a visual context presents a significant challenge. This paper introduces a sophisticated encoder-decoder framework, developed to address visual grounding in AVs.Our Context-Aware Visual Grounding (CAVG) model is an advanced system that integrates five core encoders-Text, Image, Context, and Cross-Modal-with a Multimodal decoder. This integration enables the CAVG model to adeptly capture contextual semantics and to learn human emotional features, augmented by state-of-the-art Large Language Models (LLMs) including GPT-4. The architecture of CAVG is reinforced by the implementation of multi-head cross-modal attention mechanisms and a Region-Specific Dynamic (RSD) layer for attention modulation. This architectural design enables the model to efficiently process and interpret a range of cross-modal inputs, yielding a comprehensive understanding of the correlation between verbal commands and corresponding visual scenes. Empirical evaluations on the Talk2Car dataset, a real-world benchmark, demonstrate that CAVG establishes new standards in prediction accuracy and operational efficiency. Notably, the model exhibits exceptional performance even with limited training data, ranging from 50% to 75% of the full dataset. This feature highlights its effectiveness and potential for deployment in practical AV applications. Moreover, CAVG has shown remarkable robustness and adaptability in challenging scenarios, including long-text command interpretation, low-light conditions, ambiguous command contexts, inclement weather conditions, and densely populated urban environments. The code for the proposed model is available at our Github.", "url": "https://arxiv.org/abs/2312.03543"}, {"metadata": {"arXiv": "2312.03585", "Date": "Wed, 06 Dec 2023 16:21:06 ", "Title": "Foundation Model Assisted Weakly Supervised Semantic Segmentation", "Authors": ["Xiaobo Yang and Xiaojin Gong"], "Categories": "cs.CV cs.AI"}, "abstract": "This work aims to leverage pre-trained foundation models, such as contrastive language-image pre-training (CLIP) and segment anything model (SAM), to address weakly supervised semantic segmentation (WSSS) using image-level labels. To this end, we propose a coarse-to-fine framework based on CLIP and SAM for generating high-quality segmentation seeds. Specifically, we construct an image classification task and a seed segmentation task, which are jointly performed by CLIP with frozen weights and two sets of learnable task-specific prompts. A SAM-based seeding (SAMS) module is designed and applied to each task to produce either coarse or fine seed maps. Moreover, we design a multi-label contrastive loss supervised by image-level labels and a CAM activation loss supervised by the generated coarse seed map. These losses are used to learn the prompts, which are the only parts need to be learned in our framework. Once the prompts are learned, we input each image along with the learned segmentation-specific prompts into CLIP and the SAMS module to produce high-quality segmentation seeds. These seeds serve as pseudo labels to train an off-the-shelf segmentation network like other two-stage WSSS methods. Experiments show that our method achieves the state-of-the-art performance on PASCAL VOC 2012 and competitive results on MS COCO 2014.", "url": "https://arxiv.org/abs/2312.03585"}, {"metadata": {"arXiv": "2312.03631", "Date": "Wed, 06 Dec 2023 17:28:03 ", "Title": "MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations", "Authors": ["Assaf Ben-Kish", "Moran Yanuka", "Morris Alper", "Raja Giryes", "Hadar Averbuch-Elor"], "Categories": "cs.CV cs.AI", "Comments": ["Website Link: https://assafbk.github.io/mocha/"]}, "abstract": "While recent years have seen rapid progress in image-conditioned text generation, image captioning still suffers from the fundamental issue of hallucinations, the generation of spurious details that cannot be inferred from the given image. Dedicated methods for reducing hallucinations in image captioning largely focus on closed-vocabulary object tokens, ignoring most types of hallucinations that occur in practice. In this work, we propose MOCHa, an approach that harnesses advancements in reinforcement learning (RL) to address the sequence-level nature of hallucinations in an open-world setup. To optimize for caption fidelity to the input image, we leverage ground-truth reference captions as proxies to measure the logical consistency of generated captions. However, optimizing for caption fidelity alone fails to preserve the semantic adequacy of generations; therefore, we propose a multi-objective reward function that jointly targets these qualities, without requiring any strong supervision. We demonstrate that these goals can be simultaneously optimized with our framework, enhancing performance for various captioning models of different scales. Our qualitative and quantitative results demonstrate MOCHa's superior performance across various established metrics. We also demonstrate the benefit of our method in the open-vocabulary setting. To this end, we contribute OpenCHAIR, a new benchmark for quantifying open-vocabulary hallucinations in image captioning models, constructed using generative foundation models. We will release our code, benchmark, and trained models.", "url": "https://arxiv.org/abs/2312.03631"}, {"metadata": {"arXiv": "2312.03698", "Date": "Wed, 06 Dec 2023 18:59:03 ", "Title": "Intrinsic Harmonization for Illumination-Aware Compositing", "Authors": ["Chris Careaga", "Ya\\u{g}{\\i}z Aksoy", "S. Mahdi H. Miangoleh"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["10 pages", "8 figures. Accepted to SIGGRAPH Asia 2023 (Conference Track). Project page: https://yaksoy.github.io/intrinsicCompositing/"]}, "abstract": "Despite significant advancements in network-based image harmonization techniques, there still exists a domain disparity between typical training pairs and real-world composites encountered during inference. Most existing methods are trained to reverse global edits made on segmented image regions, which fail to accurately capture the lighting inconsistencies between the foreground and background found in composited images. In this work, we introduce a self-supervised illumination harmonization approach formulated in the intrinsic image domain. First, we estimate a simple global lighting model from mid-level vision representations to generate a rough shading for the foreground region. A network then refines this inferred shading to generate a harmonious re-shading that aligns with the background scene. In order to match the color appearance of the foreground and background, we utilize ideas from prior harmonization approaches to perform parameterized image edits in the albedo domain. To validate the effectiveness of our approach, we present results from challenging real-world composites and conduct a user study to objectively measure the enhanced realism achieved compared to state-of-the-art harmonization methods.", "url": "https://arxiv.org/abs/2312.03698"}, {"metadata": {"arXiv": "2312.03263", "Date": "Wed, 06 Dec 2023 03:20:42 ", "Title": "Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying Partially Observable Environment", "Authors": ["Gokul Puthumanaillam", "Xiangyu Liu", "Negar Mehr and Melkior Ornik"], "Categories": "cs.RO cs.AI cs.SY eess.SY"}, "abstract": "Optimal decision-making presents a significant challenge for autonomous systems operating in uncertain, stochastic and time-varying environments. Environmental variability over time can significantly impact the system's optimal decision making strategy for mission completion. To model such environments, our work combines the previous notion of Time-Varying Markov Decision Processes (TVMDP) with partial observability and introduces Time-Varying Partially Observable Markov Decision Processes (TV-POMDP). We propose a two-pronged approach to accurately estimate and plan within the TV-POMDP: 1) Memory Prioritized State Estimation (MPSE), which leverages weighted memory to provide more accurate time-varying transition estimates; and 2) an MPSE-integrated planning strategy that optimizes long-term rewards while accounting for temporal constraint. We validate the proposed framework and algorithms using simulations and hardware, with robots exploring a partially observable, time-varying environments. Our results demonstrate superior performance over standard methods, highlighting the framework's effectiveness in stochastic, uncertain, time-varying domains.", "url": "https://arxiv.org/abs/2312.03263"}, {"metadata": {"arXiv": "2312.03275", "Date": "Wed, 06 Dec 2023 04:02:28 ", "Title": "VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation", "Authors": ["Naoki Yokoyama", "Sehoon Ha", "Dhruv Batra", "Jiuguang Wang", "Bernadette Bucher"], "Categories": "cs.RO cs.AI"}, "abstract": "Understanding how humans leverage semantic knowledge to navigate unfamiliar environments and decide where to explore next is pivotal for developing robots capable of human-like search behaviors. We introduce a zero-shot navigation approach, Vision-Language Frontier Maps (VLFM), which is inspired by human reasoning and designed to navigate towards unseen semantic objects in novel environments. VLFM builds occupancy maps from depth observations to identify frontiers, and leverages RGB observations and a pre-trained vision-language model to generate a language-grounded value map. VLFM then uses this map to identify the most promising frontier to explore for finding an instance of a given target object category. We evaluate VLFM in photo-realistic environments from the Gibson, Habitat-Matterport 3D (HM3D), and Matterport 3D (MP3D) datasets within the Habitat simulator. Remarkably, VLFM achieves state-of-the-art results on all three datasets as measured by success weighted by path length (SPL) for the Object Goal Navigation task. Furthermore, we show that VLFM's zero-shot nature enables it to be readily deployed on real-world robots such as the Boston Dynamics Spot mobile manipulation platform. We deploy VLFM on Spot and demonstrate its capability to efficiently navigate to target objects within an office building in the real world, without any prior knowledge of the environment. The accomplishments of VLFM underscore the promising potential of vision-language models in advancing the field of semantic navigation. Videos of real-world deployment can be viewed at naoki.io/vlfm.", "url": "https://arxiv.org/abs/2312.03275"}, {"metadata": {"arXiv": "2312.03297", "Date": "Wed, 06 Dec 2023 05:36:55 ", "Title": "SoftMAC: Differentiable Soft Body Simulation with Forecast-based Contact Model and Two-way Coupling with Articulated Rigid Bodies and Clothes", "Authors": ["Min Liu", "Gang Yang", "Siyuan Luo", "Chen Yu", "Lin Shao"], "Categories": "cs.RO cs.AI cs.GR"}, "abstract": "Differentiable physics simulation provides an avenue for tackling previously intractable challenges through gradient-based optimization, thereby greatly improving the efficiency of solving robotics-related problems. To apply differentiable simulation in diverse robotic manipulation scenarios, a key challenge is to integrate various materials in a unified framework. We present SoftMAC, a differentiable simulation framework coupling soft bodies with articulated rigid bodies and clothes. SoftMAC simulates soft bodies with the continuum-mechanics-based Material Point Method (MPM). We provide a forecast-based contact model for MPM, which greatly reduces artifacts like penetration and unnatural rebound. To couple MPM particles with deformable and non-volumetric clothes meshes, we also propose a penetration tracing algorithm that reconstructs the signed distance field in local area. Based on simulators for each modality and the contact model, we develop a differentiable coupling mechanism to simulate the interactions between soft bodies and the other two types of materials. Comprehensive experiments are conducted to validate the effectiveness and accuracy of the proposed differentiable pipeline in downstream robotic manipulation applications. Supplementary materials and videos are available on our project website at https://sites.google.com/view/softmac.", "url": "https://arxiv.org/abs/2312.03297"}, {"metadata": {"arXiv": "2312.03521", "Date": "Wed, 06 Dec 2023 14:30:15 ", "Title": "Optimal Wildfire Escape Route Planning for Drones under Dynamic Fire and Smoke", "Authors": ["Chang Liu and Tamas Sziranyi"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "8 figures", "conference"]}, "abstract": "In recent years, the increasing prevalence and intensity of wildfires have posed significant challenges to emergency response teams. The utilization of unmanned aerial vehicles (UAVs), commonly known as drones, has shown promise in aiding wildfire management efforts. This work focuses on the development of an optimal wildfire escape route planning system specifically designed for drones, considering dynamic fire and smoke models. First, the location of the source of the wildfire can be well located by information fusion between UAV and satellite, and the road conditions in the vicinity of the fire can be assessed and analyzed using multi-channel remote sensing data. Second, the road network can be extracted and segmented in real time using UAV vision technology, and each road in the road network map can be given priority based on the results of road condition classification. Third, the spread model of dynamic fires calculates the new location of the fire source based on the fire intensity, wind speed and direction, and the radius increases as the wildfire spreads. Smoke is generated around the fire source to create a visual representation of a burning fire. Finally, based on the improved A* algorithm, which considers all the above factors, the UAV can quickly plan an escape route based on the starting and destination locations that avoid the location of the fire source and the area where it is spreading. By considering dynamic fire and smoke models, the proposed system enhances the safety and efficiency of drone operations in wildfire environments.", "url": "https://arxiv.org/abs/2312.03521"}, {"metadata": {"arXiv": "2312.03365", "Date": "Wed, 06 Dec 2023 09:06:14 ", "Title": "Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks", "Authors": ["Fabio Pavirani", "Gargya Gokhale", "Bert Claessens", "Chris Develder"], "Categories": "eess.SY cs.AI cs.SY"}, "abstract": "Controlling energy consumption in buildings through demand response (DR) has become increasingly important to reduce global carbon emissions and limit climate change. In this paper, we specifically focus on controlling the heating system of a residential building to optimize its energy consumption while respecting user's thermal comfort. Recent works in this area have mainly focused on either model-based control, e.g., model predictive control (MPC), or model-free reinforcement learning (RL) to implement practical DR algorithms. A specific RL method that recently has achieved impressive success in domains such as board games (go, chess) is Monte Carlo Tree Search (MCTS). Yet, for building control it has remained largely unexplored. Thus, we study MCTS specifically for building demand response. Its natural structure allows a flexible optimization that implicitly integrate exogenous constraints (as opposed, for example, to conventional RL solutions), making MCTS a promising candidate for DR control problems. We demonstrate how to improve MCTS control performance by incorporating a Physics-informed Neural Network (PiNN) model for its underlying thermal state prediction, as opposed to traditional purely data-driven Black-Box approaches. Our MCTS implementation aligned with a PiNN model is able to obtain a 3% increment of the obtained reward compared to a rule-based controller; leading to a 10% cost reduction and 35% reduction on temperature difference with the desired one when applied to an artificial price profile. We further implemented a Deep Learning layer into the Monte Carlo Tree Search technique using a neural network that leads the tree search through more optimal nodes. We then compared this addition with its Vanilla version, showing the improvement in computational cost required.", "url": "https://arxiv.org/abs/2312.03365"}, {"metadata": {"arXiv": "2312.03004", "Date": "Mon, 04 Dec 2023 08:23:09 ", "Title": "Learning Multi-graph Structure for Temporal Knowledge Graph Reasoning", "Authors": ["Jinchuan Zhang", "Bei Hui", "Chong Mu", "Ling Tian"], "Categories": "cs.AI cs.LG"}, "abstract": "Temporal Knowledge Graph (TKG) reasoning that forecasts future events based on historical snapshots distributed over timestamps is denoted as extrapolation and has gained significant attention. Owing to its extreme versatility and variation in spatial and temporal correlations, TKG reasoning presents a challenging task, demanding efficient capture of concurrent structures and evolutional interactions among facts. While existing methods have made strides in this direction, they still fall short of harnessing the diverse forms of intrinsic expressive semantics of TKGs, which encompass entity correlations across multiple timestamps and periodicity of temporal information. This limitation constrains their ability to thoroughly reflect historical dependencies and future trends. In response to these drawbacks, this paper proposes an innovative reasoning approach that focuses on Learning Multi-graph Structure (LMS). Concretely, it comprises three distinct modules concentrating on multiple aspects of graph structure knowledge within TKGs, including concurrent and evolutional patterns along timestamps, query-specific correlations across timestamps, and semantic dependencies of timestamps, which capture TKG features from various perspectives. Besides, LMS incorporates an adaptive gate for merging entity representations both along and across timestamps effectively. Moreover, it integrates timestamp semantics into graph attention calculations and time-aware decoders, in order to impose temporal constraints on events and narrow down prediction scopes with historical statistics. Extensive experimental results on five event-based benchmark datasets demonstrate that LMS outperforms state-of-the-art extrapolation models, indicating the superiority of modeling a multi-graph perspective for TKG reasoning.", "url": "https://arxiv.org/abs/2312.03004"}, {"metadata": {"arXiv": "2312.03006", "Date": "Mon, 04 Dec 2023 11:13:42 ", "Title": "Cone Ranking for Multi-Criteria Decision Making", "Authors": ["Andreas H Hamel and Daniel Kostner"], "Categories": "cs.AI cs.LG math.ST stat.TH", "Comments": ["13 pages", "7 figures"], "MSC-class": "62G30, 90C29"}, "abstract": "Recently introduced cone distribution functions from statistics are turned into multi-criteria decision making (MCDM) tools. It is demonstrated that this procedure can be considered as an upgrade of the weighted sum scalarization insofar as it absorbs a whole collection of weighted sum scalarizations at once instead of fixing a particular one in advance. Moreover, situations are characterized in which different types of rank reversal occur, and it is explained why this might even be useful for analyzing the ranking procedure. A few examples will be discussed and a potential application in machine learning is outlined.", "url": "https://arxiv.org/abs/2312.03006"}, {"metadata": {"arXiv": "2312.03009", "Date": "Mon, 04 Dec 2023 19:01:19 ", "Title": "I-PHYRE: Interactive Physical Reasoning", "Authors": ["Shiqian Li", "Kewen Wu", "Chi Zhang", "Yixin Zhu"], "Categories": "cs.AI cs.CV cs.LG", "Comments": ["21 pages"]}, "abstract": "Current evaluation protocols predominantly assess physical reasoning in stationary scenes, creating a gap in evaluating agents' abilities to interact with dynamic events. While contemporary methods allow agents to modify initial scene configurations and observe consequences, they lack the capability to interact with events in real time. To address this, we introduce I-PHYRE, a framework that challenges agents to simultaneously exhibit intuitive physical reasoning, multi-step planning, and in-situ intervention. Here, intuitive physical reasoning refers to a quick, approximate understanding of physics to address complex problems; multi-step denotes the need for extensive sequence planning in I-PHYRE, considering each intervention can significantly alter subsequent choices; and in-situ implies the necessity for timely object manipulation within a scene, where minor timing deviations can result in task failure. We formulate four game splits to scrutinize agents' learning and generalization of essential principles of interactive physical reasoning, fostering learning through interaction with representative scenarios. Our exploration involves three planning strategies and examines several supervised and reinforcement agents' zero-shot generalization proficiency on I-PHYRE. The outcomes highlight a notable gap between existing learning algorithms and human performance, emphasizing the imperative for more research in enhancing agents with interactive physical reasoning capabilities. The environment and baselines will be made publicly available.", "url": "https://arxiv.org/abs/2312.03009"}, {"metadata": {"arXiv": "2312.03022", "Date": "Tue, 05 Dec 2023 07:27:08 ", "Title": "Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction", "Authors": ["Hongbin Ye", "Honghao Gui", "Aijia Zhang", "Tong Liu", "Wei Hua", "Weiqiang Jia"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["work in progress; 12 pages"]}, "abstract": "Knowledge graph construction (KGC) is a multifaceted undertaking involving the extraction of entities, relations, and events. Traditionally, large language models (LLMs) have been viewed as solitary task-solving agents in this complex landscape. However, this paper challenges this paradigm by introducing a novel framework, CooperKGC. Departing from the conventional approach, CooperKGC establishes a collaborative processing network, assembling a KGC collaboration team capable of concurrently addressing entity, relation, and event extraction tasks. Our experiments unequivocally demonstrate that fostering collaboration and information interaction among diverse agents within CooperKGC yields superior results compared to individual cognitive processes operating in isolation. Importantly, our findings reveal that the collaboration facilitated by CooperKGC enhances knowledge selection, correction, and aggregation capabilities across multiple rounds of interactions.", "url": "https://arxiv.org/abs/2312.03022"}, {"metadata": {"arXiv": "2312.03025", "Date": "Tue, 05 Dec 2023 08:11:34 ", "Title": "Training on Synthetic Data Beats Real Data in Multimodal Relation Extraction", "Authors": ["Zilin Du", "Haoxin Li", "Xu Guo", "Boyang Li"], "Categories": "cs.AI cs.CL cs.CV cs.LG"}, "abstract": "The task of multimodal relation extraction has attracted significant research attention, but progress is constrained by the scarcity of available training data. One natural thought is to extend existing datasets with cross-modal generative models. In this paper, we consider a novel problem setting, where only unimodal data, either text or image, are available during training. We aim to train a multimodal classifier from synthetic data that perform well on real multimodal test data. However, training with synthetic data suffers from two obstacles: lack of data diversity and label information loss. To alleviate the issues, we propose Mutual Information-aware Multimodal Iterated Relational dAta GEneration (MI2RAGE), which applies Chained Cross-modal Generation (CCG) to promote diversity in the generated data and exploits a teacher network to select valuable training samples with high mutual information with the ground-truth labels. Comparing our method to direct training on synthetic data, we observed a significant improvement of 24.06% F1 with synthetic text and 26.42% F1 with synthetic images. Notably, our best model trained on completely synthetic images outperforms prior state-of-the-art models trained on real multimodal data by a margin of 3.76% in F1. Our codebase will be made available upon acceptance.", "url": "https://arxiv.org/abs/2312.03025"}, {"metadata": {"arXiv": "2312.03126", "Date": "Sun, 03 Dec 2023 16:44:00 ", "Title": "Learning Curricula in Open-Ended Worlds", "Authors": ["Minqi Jiang"], "Categories": "cs.AI cs.LG", "Comments": ["PhD dissertation"]}, "abstract": "Deep reinforcement learning (RL) provides powerful methods for training optimal sequential decision-making agents. As collecting real-world interactions can entail additional costs and safety risks, the common paradigm of sim2real conducts training in a simulator, followed by real-world deployment. Unfortunately, RL agents easily overfit to the choice of simulated training environments, and worse still, learning ends when the agent masters the specific set of simulated environments. In contrast, the real world is highly open-ended, featuring endlessly evolving environments and challenges, making such RL approaches unsuitable. Simply randomizing over simulated environments is insufficient, as it requires making arbitrary distributional assumptions and can be combinatorially less likely to sample specific environment instances that are useful for learning. An ideal learning process should automatically adapt the training environment to maximize the learning potential of the agent over an open-ended task space that matches or surpasses the complexity of the real world. This thesis develops a class of methods called Unsupervised Environment Design (UED), which aim to produce such open-ended processes. Given an environment design space, UED automatically generates an infinite sequence or curriculum of training environments at the frontier of the learning agent's capabilities. Through extensive empirical studies and theoretical arguments founded on minimax-regret decision theory and game theory, the findings in this thesis show that UED autocurricula can produce RL agents exhibiting significantly improved robustness and generalization to previously unseen environment instances. Such autocurricula are promising paths toward open-ended learning systems that achieve more general intelligence by continually generating and mastering additional challenges of their own design.", "url": "https://arxiv.org/abs/2312.03126"}, {"metadata": {"arXiv": "2312.03303", "Date": "Wed, 06 Dec 2023 06:07:50 ", "Title": "Dyport: Dynamic Importance-based Hypothesis Generation Benchmarking Technique", "Authors": ["Ilya Tyagin", "Ilya Safro"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "This paper presents a novel benchmarking framework Dyport for evaluating biomedical hypothesis generation systems. Utilizing curated datasets, our approach tests these systems under realistic conditions, enhancing the relevance of our evaluations. We integrate knowledge from the curated databases into a dynamic graph, accompanied by a method to quantify discovery importance. This not only assesses hypothesis accuracy but also their potential impact in biomedical research which significantly extends traditional link prediction benchmarks. Applicability of our benchmarking process is demonstrated on several link prediction systems applied on biomedical semantic knowledge graphs. Being flexible, our benchmarking system is designed for broad application in hypothesis generation quality verification, aiming to expand the scope of scientific discovery within the biomedical research community. Availability and implementation: Dyport framework is fully open-source. All code and datasets are available at: https://github.com/IlyaTyagin/Dyport", "url": "https://arxiv.org/abs/2312.03303"}, {"metadata": {"arXiv": "2312.03497", "Date": "Wed, 06 Dec 2023 13:46:30 ", "Title": "Speculative Exploration on the Concept of Artificial Agents Conducting Autonomous Research", "Authors": ["Shiro Takagi"], "Categories": "cs.AI cs.LG"}, "abstract": "This paper engages in a speculative exploration of the concept of an artificial agent capable of conducting research. Initially, it examines how the act of research can be conceptually characterized, aiming to provide a starting point for discussions about what it means to create such agents. The focus then shifts to the core components of research: question formulation, hypothesis generation, and hypothesis verification. This discussion includes a consideration of the potential and challenges associated with enabling machines to autonomously perform these tasks. Subsequently, this paper briefly considers the overlapping themes and interconnections that underlie them. Finally, the paper presents preliminary thoughts on prototyping as an initial step towards uncovering the challenges involved in developing these research-capable agents.", "url": "https://arxiv.org/abs/2312.03497"}, {"metadata": {"arXiv": "2312.03015", "Date": "Tue, 05 Dec 2023 01:33:04 ", "Title": "PartSLIP++: Enhancing Low-Shot 3D Part Segmentation via Multi-View Instance Segmentation and Maximum Likelihood Estimation", "Authors": ["Yuchen Zhou and Jiayuan Gu and Xuanlin Li and Minghua Liu and Yunhao Fang and Hao Su"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Open-world 3D part segmentation is pivotal in diverse applications such as robotics and AR/VR. Traditional supervised methods often grapple with limited 3D data availability and struggle to generalize to unseen object categories. PartSLIP, a recent advancement, has made significant strides in zero- and few-shot 3D part segmentation. This is achieved by harnessing the capabilities of the 2D open-vocabulary detection module, GLIP, and introducing a heuristic method for converting and lifting multi-view 2D bounding box predictions into 3D segmentation masks. In this paper, we introduce PartSLIP++, an enhanced version designed to overcome the limitations of its predecessor. Our approach incorporates two major improvements. First, we utilize a pre-trained 2D segmentation model, SAM, to produce pixel-wise 2D segmentations, yielding more precise and accurate annotations than the 2D bounding boxes used in PartSLIP. Second, PartSLIP++ replaces the heuristic 3D conversion process with an innovative modified Expectation-Maximization algorithm. This algorithm conceptualizes 3D instance segmentation as unobserved latent variables, and then iteratively refines them through an alternating process of 2D-3D matching and optimization with gradient descent. Through extensive evaluations, we show that PartSLIP++ demonstrates better performance over PartSLIP in both low-shot 3D semantic and instance-based object part segmentation tasks. Code released at https://github.com/zyc00/PartSLIP2.", "url": "https://arxiv.org/abs/2312.03015"}, {"metadata": {"arXiv": "2312.03187", "Date": "Tue, 05 Dec 2023 23:33:49 ", "Title": "FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction", "Authors": ["Shuangquan Feng", "Junhua Ma", "and Virginia R. de Sa"], "Categories": "cs.CV cs.AI cs.HC cs.LG"}, "abstract": "Researchers have proposed to use data of human preference feedback to fine-tune text-to-image generative models. However, the scalability of human feedback collection has been limited by its reliance on manual annotation. Therefore, we develop and test a method to automatically annotate user preferences from their spontaneous facial expression reaction to the generated images. We collect a dataset of Facial Expression Reaction to Generated Images (FERGI) and show that the activations of multiple facial action units (AUs) are highly correlated with user evaluations of the generated images. Specifically, AU4 (brow lowerer) is most consistently reflective of negative evaluations of the generated image. This can be useful in two ways. Firstly, we can automatically annotate user preferences between image pairs with substantial difference in AU4 responses to them with an accuracy significantly outperforming state-of-the-art scoring models. Secondly, directly integrating the AU4 responses with the scoring models improves their consistency with human preferences. Additionally, the AU4 response best reflects the user's evaluation of the image fidelity, making it complementary to the state-of-the-art scoring models, which are generally better at reflecting image-text alignment. Finally, this method of automatic annotation with facial expression analysis can be potentially generalized to other generation tasks. The code is available at https://github.com/ShuangquanFeng/FERGI, and the dataset is also available at the same link for research purposes.", "url": "https://arxiv.org/abs/2312.03187"}, {"metadata": {"arXiv": "2312.03288", "Date": "Wed, 06 Dec 2023 04:36:58 ", "Title": "STEP CATFormer: Spatial-Temporal Effective Body-Part Cross Attention Transformer for Skeleton-based Action Recognition", "Authors": ["Nguyen Huu Bao Long"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted to BMVC 2023: Computer Vision for Games and Games for Computer Vision (CVG). 9 pages"], "ACM-class": "I.2.10"}, "abstract": "Graph convolutional networks (GCNs) have been widely used and achieved remarkable results in skeleton-based action recognition. We think the key to skeleton-based action recognition is a skeleton hanging in frames, so we focus on how the Graph Convolutional Convolution networks learn different topologies and effectively aggregate joint features in the global temporal and local temporal. In this work, we propose three Channel-wise Tolopogy Graph Convolution based on Channel-wise Topology Refinement Graph Convolution (CTR-GCN). Combining CTR-GCN with two joint cross-attention modules can capture the upper-lower body part and hand-foot relationship skeleton features. After that, to capture features of human skeletons changing in frames we design the Temporal Attention Transformers to extract skeletons effectively. The Temporal Attention Transformers can learn the temporal features of human skeleton sequences. Finally, we fuse the temporal features output scale with MLP and classification. We develop a powerful graph convolutional network named Spatial Temporal Effective Body-part Cross Attention Transformer which notably high-performance on the NTU RGB+D, NTU RGB+D 120 datasets. Our code and models are available at https://github.com/maclong01/STEP-CATFormer", "url": "https://arxiv.org/abs/2312.03288"}, {"metadata": {"arXiv": "2312.03526", "Date": "Wed, 06 Dec 2023 14:40:05 ", "Title": "On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm", "Authors": ["Peng Sun", "Bei Shi", "Daiwei Yu", "Tao Lin"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["17 pages", "20 figures"]}, "abstract": "Contemporary machine learning requires training large neural networks on massive datasets and thus faces the challenges of high computational demands. Dataset distillation, as a recent emerging strategy, aims to compress real-world datasets for efficient training. However, this line of research currently struggle with large-scale and high-resolution datasets, hindering its practicality and feasibility. To this end, we re-examine the existing dataset distillation methods and identify three properties required for large-scale real-world applications, namely, realism, diversity, and efficiency. As a remedy, we propose RDED, a novel computationally-efficient yet effective data distillation paradigm, to enable both diversity and realism of the distilled data. Extensive empirical results over various neural architectures and datasets demonstrate the advancement of RDED: we can distill the full ImageNet-1K to a small dataset comprising 10 images per class within 7 minutes, achieving a notable 42% top-1 accuracy with ResNet-18 on a single RTX-4090 GPU (while the SOTA only achieves 21% but requires 6 hours).", "url": "https://arxiv.org/abs/2312.03526"}, {"metadata": {"arXiv": "2312.03596", "Date": "Wed, 06 Dec 2023 16:35:59 ", "Title": "MMM: Generative Masked Motion Model", "Authors": ["Ekkasit Pinyoanuntapong", "Pu Wang", "Minwoo Lee", "Chen Chen"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recent advances in text-to-motion generation using diffusion and autoregressive models have shown promising results. However, these models often suffer from a trade-off between real-time performance, high fidelity, and motion editability. To address this gap, we introduce MMM, a novel yet simple motion generation paradigm based on Masked Motion Model. MMM consists of two key components: (1) a motion tokenizer that transforms 3D human motion into a sequence of discrete tokens in latent space, and (2) a conditional masked motion transformer that learns to predict randomly masked motion tokens, conditioned on the pre-computed text tokens. By attending to motion and text tokens in all directions, MMM explicitly captures inherent dependency among motion tokens and semantic mapping between motion and text tokens. During inference, this allows parallel and iterative decoding of multiple motion tokens that are highly consistent with fine-grained text descriptions, therefore simultaneously achieving high-fidelity and high-speed motion generation. In addition, MMM has innate motion editability. By simply placing mask tokens in the place that needs editing, MMM automatically fills the gaps while guaranteeing smooth transitions between editing and non-editing parts. Extensive experiments on the HumanML3D and KIT-ML datasets demonstrate that MMM surpasses current leading methods in generating high-quality motion (evidenced by superior FID scores of 0.08 and 0.429), while offering advanced editing features such as body-part modification, motion in-betweening, and the synthesis of long motion sequences. In addition, MMM is two orders of magnitude faster on a single mid-range GPU than editable motion diffusion models. Our project page is available at \\url{https://exitudio.github.io/MMM-page}.", "url": "https://arxiv.org/abs/2312.03596"}, {"metadata": {"arXiv": "2312.03606", "Date": "Wed, 06 Dec 2023 16:53:17 ", "Title": "DiffusionSat: A Generative Foundation Model for Satellite Imagery", "Authors": ["Samar Khanna", "Patrick Liu", "Linqi Zhou", "Chenlin Meng", "Robin Rombach", "Marshall Burke", "David Lobell", "Stefano Ermon"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Diffusion models have achieved state-of-the-art results on many modalities including images, speech, and video. However, existing models are not tailored to support remote sensing data, which is widely used in important applications including environmental monitoring and crop-yield prediction. Satellite images are significantly different from natural images -- they can be multi-spectral, irregularly sampled across time -- and existing diffusion models trained on images from the Web do not support them. Furthermore, remote sensing data is inherently spatio-temporal, requiring conditional generation tasks not supported by traditional methods based on captions or images. In this paper, we present DiffusionSat, to date the largest generative foundation model trained on a collection of publicly available large, high-resolution remote sensing datasets. As text-based captions are sparsely available for satellite images, we incorporate the associated metadata such as geolocation as conditioning information. Our method produces realistic samples and can be used to solve multiple generative tasks including temporal generation, superresolution given multi-spectral inputs and in-painting. Our method outperforms previous state-of-the-art methods for satellite image generation and is the first large-scale $\\textit{generative}$ foundation model for satellite imagery.", "url": "https://arxiv.org/abs/2312.03606"}, {"metadata": {"arXiv": "2312.03611", "Date": "Wed, 06 Dec 2023 16:55:53 ", "Title": "DreamComposer: Controllable 3D Object Generation via Multi-View Conditions", "Authors": ["Yunhan Yang", "Yukun Huang", "Xiaoyang Wu", "Yuan-Chen Guo", "Song-Hai Zhang", "Hengshuang Zhao", "Tong He", "Xihui Liu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project Page: https://yhyang-myron.github.io/DreamComposer/"]}, "abstract": "Utilizing pre-trained 2D large-scale generative models, recent works are capable of generating high-quality novel views from a single in-the-wild image. However, due to the lack of information from multiple views, these works encounter difficulties in generating controllable novel views. In this paper, we present DreamComposer, a flexible and scalable framework that can enhance existing view-aware diffusion models by injecting multi-view conditions. Specifically, DreamComposer first uses a view-aware 3D lifting module to obtain 3D representations of an object from multiple views. Then, it renders the latent features of the target view from 3D representations with the multi-view feature fusion module. Finally the target view features extracted from multi-view inputs are injected into a pre-trained diffusion model. Experiments show that DreamComposer is compatible with state-of-the-art diffusion models for zero-shot novel view synthesis, further enhancing them to generate high-fidelity novel view images with multi-view conditions, ready for controllable 3D object reconstruction and various other applications.", "url": "https://arxiv.org/abs/2312.03611"}, {"metadata": {"arXiv": "2312.03641", "Date": "Wed, 06 Dec 2023 17:49:57 ", "Title": "MotionCtrl: A Unified and Flexible Motion Controller for Video Generation", "Authors": ["Zhouxia Wang", "Ziyang Yuan", "Xintao Wang", "Tianshui Chen", "Menghan Xia", "Ping Luo", "and Ying Shan"], "Categories": "cs.CV cs.AI cs.LG cs.MM", "Comments": ["Project Page: https://wzhouxiff.github.io/projects/MotionCtrl/"]}, "abstract": "Motions in a video primarily consist of camera motion, induced by camera movement, and object motion, resulting from object movement. Accurate control of both camera and object motion is essential for video generation. However, existing works either mainly focus on one type of motion or do not clearly distinguish between the two, limiting their control capabilities and diversity. Therefore, this paper presents MotionCtrl, a unified and flexible motion controller for video generation designed to effectively and independently control camera and object motion. The architecture and training strategy of MotionCtrl are carefully devised, taking into account the inherent properties of camera motion, object motion, and imperfect training data. Compared to previous methods, MotionCtrl offers three main advantages: 1) It effectively and independently controls camera motion and object motion, enabling more fine-grained motion control and facilitating flexible and diverse combinations of both types of motion. 2) Its motion conditions are determined by camera poses and trajectories, which are appearance-free and minimally impact the appearance or shape of objects in generated videos. 3) It is a relatively generalizable model that can adapt to a wide array of camera poses and trajectories once trained. Extensive qualitative and quantitative experiments have been conducted to demonstrate the superiority of MotionCtrl over existing methods.", "url": "https://arxiv.org/abs/2312.03641"}, {"metadata": {"arXiv": "2312.03700", "Date": "Wed, 06 Dec 2023 18:59:19 ", "Title": "OneLLM: One Framework to Align All Modalities with Language", "Authors": ["Jiaming Han", "Kaixiong Gong", "Yiyuan Zhang", "Jiaqi Wang", "Kaipeng Zhang", "Dahua Lin", "Yu Qiao", "Peng Gao", "Xiangyu Yue"], "Categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "Comments": ["Code: https://github.com/csuhan/OneLLM"]}, "abstract": "Multimodal large language models (MLLMs) have gained significant attention due to their strong multimodal understanding capability. However, existing works rely heavily on modality-specific encoders, which usually differ in architecture and are limited to common modalities. In this paper, we present OneLLM, an MLLM that aligns eight modalities to language using a unified framework. We achieve this through a unified multimodal encoder and a progressive multimodal alignment pipeline. In detail, we first train an image projection module to connect a vision encoder with LLM. Then, we build a universal projection module (UPM) by mixing multiple image projection modules and dynamic routing. Finally, we progressively align more modalities to LLM with the UPM. To fully leverage the potential of OneLLM in following instructions, we also curated a comprehensive multimodal instruction dataset, including 2M items from image, audio, video, point cloud, depth/normal map, IMU and fMRI brain activity. OneLLM is evaluated on 25 diverse benchmarks, encompassing tasks such as multimodal captioning, question answering and reasoning, where it delivers excellent performance. Code, data, model and online demo are available at https://github.com/csuhan/OneLLM", "url": "https://arxiv.org/abs/2312.03700"}, {"metadata": {"arXiv": "2312.02984", "Date": "Mon, 13 Nov 2023 17:52:44 ", "Title": "Diff-GO: Diffusion Goal-Oriented Communications to Achieve Ultra-High Spectrum Efficiency", "Authors": ["Achintha Wijesinghe", "Songyang Zhang", "Suchinthaka Wanninayaka", "Weiwei Wang", "Zhi Ding"], "Categories": "cs.LG cs.AI cs.CV cs.MM eess.SP", "Comments": ["Submitted to IEEE International Conference on Communications (ICC) 2024"]}, "abstract": "The latest advances in artificial intelligence (AI) present many unprecedented opportunities to achieve much improved bandwidth saving in communications. Unlike conventional communication systems focusing on packet transport, rich datasets and AI makes it possible to efficiently transfer only the information most critical to the goals of message recipients. One of the most exciting advances in generative AI known as diffusion model presents a unique opportunity for designing ultra-fast communication systems well beyond language-based messages. This work presents an ultra-efficient communication design by utilizing generative AI-based on diffusion models as a specific example of the general goal-oriented communication framework. To better control the regenerated message at the receiver output, our diffusion system design includes a local regeneration module with finite dimensional noise latent. The critical significance of noise latent control and sharing residing on our Diff-GO is the ability to introduce the concept of \"local generative feedback\" (Local-GF), which enables the transmitter to monitor the quality and gauge the quality or accuracy of the message recovery at the semantic system receiver. To this end, we propose a new low-dimensional noise space for the training of diffusion models, which significantly reduces the communication overhead and achieves satisfactory message recovery performance. Our experimental results demonstrate that the proposed noise space and the diffusion-based generative model achieve ultra-high spectrum efficiency and accurate recovery of transmitted image signals. By trading off computation for bandwidth efficiency (C4BE), this new framework provides an important avenue to achieve exceptional computation-bandwidth tradeoff.", "url": "https://arxiv.org/abs/2312.02984"}, {"metadata": {"arXiv": "2312.03008", "Date": "Mon, 04 Dec 2023 13:45:17 ", "Title": "Deep Reinforcement Learning for Community Battery Scheduling under Uncertainties of Load, PV Generation, and Energy Prices", "Authors": ["Jiarong Fan", "Hao Wang"], "Categories": "cs.LG cs.AI math.OC", "Comments": ["The 7th IEEE Conference on Energy Internet and Energy System Integration (EI2 2023)"]}, "abstract": "In response to the growing uptake of distributed energy resources (DERs), community batteries have emerged as a promising solution to support renewable energy integration, reduce peak load, and enhance grid reliability. This paper presents a deep reinforcement learning (RL) strategy, centered around the soft actor-critic (SAC) algorithm, to schedule a community battery system in the presence of uncertainties, such as solar photovoltaic (PV) generation, local demand, and real-time energy prices. We position the community battery to play a versatile role, in integrating local PV energy, reducing peak load, and exploiting energy price fluctuations for arbitrage, thereby minimizing the system cost. To improve exploration and convergence during RL training, we utilize the noisy network technique. This paper conducts a comparative study of different RL algorithms, including proximal policy optimization (PPO) and deep deterministic policy gradient (DDPG) algorithms, to evaluate their effectiveness in the community battery scheduling problem. The results demonstrate the potential of RL in addressing community battery scheduling challenges and show that the SAC algorithm achieves the best performance compared to RL and optimization benchmarks.", "url": "https://arxiv.org/abs/2312.03008"}, {"metadata": {"arXiv": "2312.03014", "Date": "Tue, 05 Dec 2023 01:10:54 ", "Title": "Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey", "Authors": ["Shengchao Chen", "Guodong Long", "Jing Jiang", "Dikai Liu", "and Chengqi Zhang"], "Categories": "cs.LG cs.AI cs.CV physics.ao-ph", "Comments": ["Ongoing work. Survey Paper. 35 pages", "2 figures", "4 tables. The first work to comprehensively and systematically summarize DL-based weather and climate data understanding", "paving the way for the development of weather and climate foundation models"]}, "abstract": "As artificial intelligence (AI) continues to rapidly evolve, the realm of Earth and atmospheric sciences is increasingly adopting data-driven models, powered by progressive developments in deep learning (DL). Specifically, DL techniques are extensively utilized to decode the chaotic and nonlinear aspects of Earth systems, and to address climate challenges via understanding weather and climate data. Cutting-edge performance on specific tasks within narrower spatio-temporal scales has been achieved recently through DL. The rise of large models, specifically large language models (LLMs), has enabled fine-tuning processes that yield remarkable outcomes across various downstream tasks, thereby propelling the advancement of general AI. However, we are still navigating the initial stages of crafting general AI for weather and climate. In this survey, we offer an exhaustive, timely overview of state-of-the-art AI methodologies specifically engineered for weather and climate data, with a special focus on time series and text data. Our primary coverage encompasses four critical aspects: types of weather and climate data, principal model architectures, model scopes and applications, and datasets for weather and climate. Furthermore, in relation to the creation and application of foundation models for weather and climate data understanding, we delve into the field's prevailing challenges, offer crucial insights, and propose detailed avenues for future research. This comprehensive approach equips practitioners with the requisite knowledge to make substantial progress in this domain. Our survey encapsulates the most recent breakthroughs in research on large, data-driven models for weather and climate data understanding, emphasizing robust foundations, current advancements, practical applications, crucial resources, and prospective research opportunities.", "url": "https://arxiv.org/abs/2312.03014"}, {"metadata": {"arXiv": "2312.03038", "Date": "Tue, 05 Dec 2023 15:04:11 ", "Title": "Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit", "Authors": ["Fanfei Meng", "Lele Zhang", "Yu Chen", "Yuxin Wang"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "accepted by Proceedings on Engineering Sciences", "Vol.6", "2620-2832"]}, "abstract": "Transformer requires a fixed number of layers and heads which makes them inflexible to the complexity of individual samples and expensive in training and inference. To address this, we propose a sample-based Dynamic Hierarchical Transformer (DHT) model whose layers and heads can be dynamically configured with single data samples via solving contextual bandit problems. To determine the number of layers and heads, we use the Uniform Confidence Bound while we deploy combinatorial Thompson Sampling in order to select specific head combinations given their number. Different from previous work that focuses on compressing trained networks for inference only, DHT is not only advantageous for adaptively optimizing the underlying network architecture during training but also has a flexible network for efficient inference. To the best of our knowledge, this is the first comprehensive data-driven dynamic transformer without any additional auxiliary neural networks that implement the dynamic system. According to the experiment results, we achieve up to 74% computational savings for both training and inference with a minimal loss of accuracy.", "url": "https://arxiv.org/abs/2312.03038"}, {"metadata": {"arXiv": "2312.03051", "Date": "Tue, 05 Dec 2023 18:55:32 ", "Title": "Generating Interpretable Networks using Hypernetworks", "Authors": ["Isaac Liao", "Ziming Liu", "Max Tegmark"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["15 pages", "7 figures"], "MSC-class": "68T07", "ACM-class": "I.2.6"}, "abstract": "An essential goal in mechanistic interpretability to decode a network, i.e., to convert a neural network's raw weights to an interpretable algorithm. Given the difficulty of the decoding problem, progress has been made to understand the easier encoding problem, i.e., to convert an interpretable algorithm into network weights. Previous works focus on encoding existing algorithms into networks, which are interpretable by definition. However, focusing on encoding limits the possibility of discovering new algorithms that humans have never stumbled upon, but that are nevertheless interpretable. In this work, we explore the possibility of using hypernetworks to generate interpretable networks whose underlying algorithms are not yet known. The hypernetwork is carefully designed such that it can control network complexity, leading to a diverse family of interpretable algorithms ranked by their complexity. All of them are interpretable in hindsight, although some of them are less intuitive to humans, hence providing new insights regarding how to \"think\" like a neural network. For the task of computing L1 norms, hypernetworks find three algorithms: (a) the double-sided algorithm, (b) the convexity algorithm, (c) the pudding algorithm, although only the first algorithm was expected by the authors before experiments. We automatically classify these algorithms and analyze how these algorithmic phases develop during training, as well as how they are affected by complexity control. Furthermore, we show that a trained hypernetwork can correctly construct models for input dimensions not seen in training, demonstrating systematic generalization.", "url": "https://arxiv.org/abs/2312.03051"}, {"metadata": {"arXiv": "2312.03096", "Date": "Tue, 05 Dec 2023 19:29:54 ", "Title": "Incidental Polysemanticity", "Authors": ["Victor Lecomte", "Kushal Thaman", "Trevor Chow", "Rylan Schaeffer", "Sanmi Koyejo"], "Categories": "cs.LG cs.AI cs.NE"}, "abstract": "Polysemantic neurons (neurons that activate for a set of unrelated features) have been seen as a significant obstacle towards interpretability of task-optimized deep networks, with implications for AI safety. The classic origin story of polysemanticity is that the data contains more \"features\" than neurons, such that learning to perform a task forces the network to co-allocate multiple unrelated features to the same neuron, endangering our ability to understand the network's internal processing. In this work, we present a second and non-mutually exclusive origin story of polysemanticity. We show that polysemanticity can arise incidentally, even when there are ample neurons to represent all features in the data, using a combination of theory and experiments. This second type of polysemanticity occurs because random initialization can, by chance alone, initially assign multiple features to the same neuron, and the training dynamics then strengthen such overlap. Due to its origin, we term this \\textit{incidental polysemanticity}.", "url": "https://arxiv.org/abs/2312.03096"}, {"metadata": {"arXiv": "2312.03120", "Date": "Tue, 05 Dec 2023 20:40:05 ", "Title": "The Landscape of Modern Machine Learning: A Review of Machine, Distributed and Federated Learning", "Authors": ["Omer Subasi and Oceane Bel and Joseph Manzano and Kevin Barker"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "With the advance of the powerful heterogeneous, parallel and distributed computing systems and ever increasing immense amount of data, machine learning has become an indispensable part of cutting-edge technology, scientific research and consumer products. In this study, we present a review of modern machine and deep learning. We provide a high-level overview for the latest advanced machine learning algorithms, applications, and frameworks. Our discussion encompasses parallel distributed learning, deep learning as well as federated learning. As a result, our work serves as an introductory text to the vast field of modern machine learning.", "url": "https://arxiv.org/abs/2312.03120"}, {"metadata": {"arXiv": "2312.03140", "Date": "Tue, 05 Dec 2023 21:19:33 ", "Title": "FlexModel: A Framework for Interpretability of Distributed Large Language Models", "Authors": ["Matthew Choi", "Muhammad Adil Asif", "John Willes and David Emerson"], "Categories": "cs.LG cs.AI cs.CL cs.DC", "Comments": ["14 pages", "8 figures. To appear at the Socially Responsible Language Modelling Research (SoLaR) Workshop", "37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "With the growth of large language models, now incorporating billions of parameters, the hardware prerequisites for their training and deployment have seen a corresponding increase. Although existing tools facilitate model parallelization and distributed training, deeper model interactions, crucial for interpretability and responsible AI techniques, still demand thorough knowledge of distributed computing. This often hinders contributions from researchers with machine learning expertise but limited distributed computing background. Addressing this challenge, we present FlexModel, a software package providing a streamlined interface for engaging with models distributed across multi-GPU and multi-node configurations. The library is compatible with existing model distribution libraries and encapsulates PyTorch models. It exposes user-registerable HookFunctions to facilitate straightforward interaction with distributed model internals, bridging the gap between distributed and single-device model paradigms. Primarily, FlexModel enhances accessibility by democratizing model interactions and promotes more inclusive research in the domain of large-scale neural networks. The package is found at https://github.com/VectorInstitute/flex_model.", "url": "https://arxiv.org/abs/2312.03140"}, {"metadata": {"arXiv": "2312.03177", "Date": "Tue, 05 Dec 2023 22:53:05 ", "Title": "Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement Learning", "Authors": ["Pankayaraj Pathmanathan", "Natalia D\\'iaz-Rodr\\'iguez", "Javier Del Ser"], "Categories": "cs.LG cs.AI"}, "abstract": "In this work, we investigate the means of using curiosity on replay buffers to improve offline multi-task continual reinforcement learning when tasks, which are defined by the non-stationarity in the environment, are non labeled and not evenly exposed to the learner in time. In particular, we investigate the use of curiosity both as a tool for task boundary detection and as a priority metric when it comes to retaining old transition tuples, which we respectively use to propose two different buffers. Firstly, we propose a Hybrid Reservoir Buffer with Task Separation (HRBTS), where curiosity is used to detect task boundaries that are not known due to the task agnostic nature of the problem. Secondly, by using curiosity as a priority metric when it comes to retaining old transition tuples, a Hybrid Curious Buffer (HCB) is proposed. We ultimately show that these buffers, in conjunction with regular reinforcement learning algorithms, can be used to alleviate the catastrophic forgetting issue suffered by the state of the art on replay buffers when the agent's exposure to tasks is not equal along time. We evaluate catastrophic forgetting and the efficiency of our proposed buffers against the latest works such as the Hybrid Reservoir Buffer (HRB) and the Multi-Time Scale Replay Buffer (MTR) in three different continual reinforcement learning settings. Experiments were done on classical control tasks and Metaworld environment. Experiments show that our proposed replay buffers display better immunity to catastrophic forgetting compared to existing works in most of the settings.", "url": "https://arxiv.org/abs/2312.03177"}, {"metadata": {"arXiv": "2312.03186", "Date": "Tue, 05 Dec 2023 23:32:48 ", "Title": "Data-Driven Traffic Reconstruction and Kernel Methods for Identifying Stop-and-Go Congestion", "Authors": ["Edgar Ramirez Sanchez", "Shreyaa Raghavan", "Cathy Wu"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["Presented at NeurIPS 2023 workshops: Tackling Climate Change with Machine Learning & Computational Sustainability"]}, "abstract": "Identifying stop-and-go events (SAGs) in traffic flow presents an important avenue for advancing data-driven research for climate change mitigation and sustainability, owing to their substantial impact on carbon emissions, travel time, fuel consumption, and roadway safety. In fact, SAGs are estimated to account for 33-50% of highway driving externalities. However, insufficient attention has been paid to precisely quantifying where, when, and how much these SAGs take place -necessary for downstream decision making, such as intervention design and policy analysis. A key challenge is that the data available to researchers and governments are typically sparse and aggregated to a granularity that obscures SAGs. To overcome such data limitations, this study thus explores the use of traffic reconstruction techniques for SAG identification. In particular, we introduce a kernel-based method for identifying spatio-temporal features in traffic and leverage bootstrapping to quantify the uncertainty of the reconstruction process. Experimental results on California highway data demonstrate the promise of the method for capturing SAGs. This work contributes to a foundation for data-driven decision making to advance sustainability of traffic systems.", "url": "https://arxiv.org/abs/2312.03186"}, {"metadata": {"arXiv": "2312.03216", "Date": "Wed, 06 Dec 2023 01:15:34 ", "Title": "SDSRA: A Skill-Driven Skill-Recombination Algorithm for Efficient Policy Learning", "Authors": ["Eric H. Jiang and Andrew Lizarraga"], "Categories": "cs.LG cs.AI"}, "abstract": "In this paper, we introduce a novel algorithm - the Skill-Driven Skill Recombination Algorithm (SDSRA) - an innovative framework that significantly enhances the efficiency of achieving maximum entropy in reinforcement learning tasks. We find that SDSRA achieves faster convergence compared to the traditional Soft Actor-Critic (SAC) algorithm and produces improved policies. By integrating skill-based strategies within the robust Actor-Critic framework, SDSRA demonstrates remarkable adaptability and performance across a wide array of complex and diverse benchmarks.", "url": "https://arxiv.org/abs/2312.03216"}, {"metadata": {"arXiv": "2312.03231", "Date": "Wed, 06 Dec 2023 01:59:47 ", "Title": "Deep Multimodal Fusion for Surgical Feedback Classification", "Authors": ["Rafal Kocielnik", "Elyssa Y. Wong", "Timothy N. Chu", "Lydia Lin", "De-An Huang", "Jiayun Wang", "Anima Anandkumar", "Andrew J. Hung"], "Categories": "cs.LG cs.AI cs.CV cs.HC eess.AS", "Journal-ref": "Published in Proceedings of Machine Learning for Health 2024"}, "abstract": "Quantification of real-time informal feedback delivered by an experienced surgeon to a trainee during surgery is important for skill improvements in surgical training. Such feedback in the live operating room is inherently multimodal, consisting of verbal conversations (e.g., questions and answers) as well as non-verbal elements (e.g., through visual cues like pointing to anatomic elements). In this work, we leverage a clinically-validated five-category classification of surgical feedback: \"Anatomic\", \"Technical\", \"Procedural\", \"Praise\" and \"Visual Aid\". We then develop a multi-label machine learning model to classify these five categories of surgical feedback from inputs of text, audio, and video modalities. The ultimate goal of our work is to help automate the annotation of real-time contextual surgical feedback at scale. Our automated classification of surgical feedback achieves AUCs ranging from 71.5 to 77.6 with the fusion improving performance by 3.1%. We also show that high-quality manual transcriptions of feedback audio from experts improve AUCs to between 76.5 and 96.2, which demonstrates a clear path toward future improvements. Empirically, we find that the Staged training strategy, with first pre-training each modality separately and then training them jointly, is more effective than training different modalities altogether. We also present intuitive findings on the importance of modalities for different feedback categories. This work offers an important first look at the feasibility of automated classification of real-world live surgical feedback based on text, audio, and video modalities.", "url": "https://arxiv.org/abs/2312.03231"}, {"metadata": {"arXiv": "2312.03236", "Date": "Wed, 06 Dec 2023 02:16:44 ", "Title": "Multicoated and Folded Graph Neural Networks with Strong Lottery Tickets", "Authors": ["Jiale Yan", "Hiroaki Ito", "\\'Angel L\\'opez Garc\\'ia-Arias", "Yasuyuki Okoshi", "Hikari Otsuka", "Kazushi Kawamura", "Thiem Van Chu", "Masato Motomura"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["9 pages", "accepted in the Second Learning on Graphs Conference (LoG 2023)"], "Journal-ref": "Proceedings of the Second Learning on Graphs Conference (LoG 2023), PMLR 231"}, "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) demonstrates the existence of high-performing subnetworks within a randomly initialized model, discoverable through pruning a convolutional neural network (CNN) without any weight training. A recent study, called Untrained GNNs Tickets (UGT), expanded SLTH from CNNs to shallow graph neural networks (GNNs). However, discrepancies persist when comparing baseline models with learned dense weights. Additionally, there remains an unexplored area in applying SLTH to deeper GNNs, which, despite delivering improved accuracy with additional layers, suffer from excessive memory requirements. To address these challenges, this work utilizes Multicoated Supermasks (M-Sup), a scalar pruning mask method, and implements it in GNNs by proposing a strategy for setting its pruning thresholds adaptively. In the context of deep GNNs, this research uncovers the existence of untrained recurrent networks, which exhibit performance on par with their trained feed-forward counterparts. This paper also introduces the Multi-Stage Folding and Unshared Masks methods to expand the search space in terms of both architecture and parameters. Through the evaluation of various datasets, including the Open Graph Benchmark (OGB), this work establishes a triple-win scenario for SLTH-based GNNs: by achieving high sparsity, competitive performance, and high memory efficiency with up to 98.7\\% reduction, it demonstrates suitability for energy-efficient graph processing.", "url": "https://arxiv.org/abs/2312.03236"}, {"metadata": {"arXiv": "2312.03248", "Date": "Wed, 06 Dec 2023 02:47:56 ", "Title": "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning", "Authors": ["Haowen Wang", "Tao Sun", "Cong Fan", "Jinjie Gu"], "Categories": "cs.LG cs.AI", "Comments": ["22 pages", "9 figures"]}, "abstract": "Modular and composable transfer learning is an emerging direction in the field of Parameter Efficient Fine-Tuning, as it enables neural networks to better organize various aspects of knowledge, leading to improved cross-task generalization. In this paper, we introduce a novel approach Customized Polytropon C-Poly that combines task-common skills and task-specific skills, while the skill parameters being highly parameterized using low-rank techniques. Each task is associated with a customizable number of exclusive specialized skills and also benefits from skills shared with peer tasks. A skill assignment matrix is jointly learned. To evaluate our approach, we conducted extensive experiments on the Super-NaturalInstructions and the SuperGLUE benchmarks. Our findings demonstrate that C-Poly outperforms fully-shared, task-specific, and skill-indistinguishable baselines, significantly enhancing the sample efficiency in multi-task learning scenarios.", "url": "https://arxiv.org/abs/2312.03248"}, {"metadata": {"arXiv": "2312.03291", "Date": "Wed, 06 Dec 2023 04:53:12 ", "Title": "OMNIINPUT: A Model-centric Evaluation Framework through Output Distribution", "Authors": ["Weitang Liu", "Ying Wai Li", "Tianle Wang", "Yi-Zhuang You", "Jingbo Shang"], "Categories": "cs.LG cs.AI"}, "abstract": "We propose a novel model-centric evaluation framework, OmniInput, to evaluate the quality of an AI/ML model's predictions on all possible inputs (including human-unrecognizable ones), which is crucial for AI safety and reliability. Unlike traditional data-centric evaluation based on pre-defined test sets, the test set in OmniInput is self-constructed by the model itself and the model quality is evaluated by investigating its output distribution. We employ an efficient sampler to obtain representative inputs and the output distribution of the trained model, which, after selective annotation, can be used to estimate the model's precision and recall at different output values and a comprehensive precision-recall curve. Our experiments demonstrate that OmniInput enables a more fine-grained comparison between models, especially when their performance is almost the same on pre-defined datasets, leading to new findings and insights for how to train more robust, generalizable models.", "url": "https://arxiv.org/abs/2312.03291"}, {"metadata": {"arXiv": "2312.03309", "Date": "Wed, 06 Dec 2023 06:27:27 ", "Title": "Benchmarking Continual Learning from Cognitive Perspectives", "Authors": ["Xiaoqian Liu", "Junge Zhang", "Mingyi Zhang", "Peipei Yang"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages", "11 figures"]}, "abstract": "Continual learning addresses the problem of continuously acquiring and transferring knowledge without catastrophic forgetting of old concepts. While humans achieve continual learning via diverse neurocognitive mechanisms, there is a mismatch between cognitive properties and evaluation methods of continual learning models. First, the measurement of continual learning models mostly relies on evaluation metrics at a micro-level, which cannot characterize cognitive capacities of the model. Second, the measurement is method-specific, emphasizing model strengths in one aspect while obscuring potential weaknesses in other respects. To address these issues, we propose to integrate model cognitive capacities and evaluation metrics into a unified evaluation paradigm. We first characterize model capacities via desiderata derived from cognitive properties supporting human continual learning. The desiderata concern (1) adaptability in varying lengths of task sequence; (2) sensitivity to dynamic task variations; and (3) efficiency in memory usage and training time consumption. Then we design evaluation protocols for each desideratum to assess cognitive capacities of recent continual learning models. Experimental results show that no method we consider has satisfied all the desiderata and is still far away from realizing truly continual learning. Although some methods exhibit some degree of adaptability and efficiency, no method is able to identify task relationships when encountering dynamic task variations, or achieve a trade-off in learning similarities and differences between tasks. Inspired by these results, we discuss possible factors that influence model performance in these desiderata and provide guidance for the improvement of continual learning models.", "url": "https://arxiv.org/abs/2312.03309"}, {"metadata": {"arXiv": "2312.03397", "Date": "Wed, 06 Dec 2023 10:10:21 ", "Title": "Generalized Contrastive Divergence: Joint Training of Energy-Based Model and Diffusion Model through Inverse Reinforcement Learning", "Authors": ["Sangwoong Yoon", "Dohyun Kwon", "Himchan Hwang", "Yung-Kyun Noh", "Frank C. Park"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023 Workshop on Diffusion Models"]}, "abstract": "We present Generalized Contrastive Divergence (GCD), a novel objective function for training an energy-based model (EBM) and a sampler simultaneously. GCD generalizes Contrastive Divergence (Hinton, 2002), a celebrated algorithm for training EBM, by replacing Markov Chain Monte Carlo (MCMC) distribution with a trainable sampler, such as a diffusion model. In GCD, the joint training of EBM and a diffusion model is formulated as a minimax problem, which reaches an equilibrium when both models converge to the data distribution. The minimax learning with GCD bears interesting equivalence to inverse reinforcement learning, where the energy corresponds to a negative reward, the diffusion model is a policy, and the real data is expert demonstrations. We present preliminary yet promising results showing that joint training is beneficial for both EBM and a diffusion model. GCD enables EBM training without MCMC while improving the sample quality of a diffusion model.", "url": "https://arxiv.org/abs/2312.03397"}, {"metadata": {"arXiv": "2312.03413", "Date": "Wed, 06 Dec 2023 10:50:27 ", "Title": "Approximating Solutions to the Knapsack Problem using the Lagrangian Dual Framework", "Authors": ["Mitchell Keegan and Mahdi Abolghasemi"], "Categories": "cs.LG cs.AI math.OC", "Journal-ref": "Lecture Notes in Computer Science, vol 14471 (2023)", "DOI": "10.1007/978-981-99-8388-9_37"}, "abstract": "The Knapsack Problem is a classic problem in combinatorial optimisation. Solving these problems may be computationally expensive. Recent years have seen a growing interest in the use of deep learning methods to approximate the solutions to such problems. A core problem is how to enforce or encourage constraint satisfaction in predicted solutions. A promising approach for predicting solutions to constrained optimisation problems is the Lagrangian Dual Framework which builds on the method of Lagrangian Relaxation. In this paper we develop neural network models to approximate Knapsack Problem solutions using the Lagrangian Dual Framework while improving constraint satisfaction. We explore the problems of output interpretation and model selection within this context. Experimental results show strong constraint satisfaction with a minor reduction of optimality as compared to a baseline neural network which does not explicitly model the constraints.", "url": "https://arxiv.org/abs/2312.03413"}, {"metadata": {"arXiv": "2312.03475", "Date": "Wed, 06 Dec 2023 12:58:37 ", "Title": "Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D Diffusion", "Authors": ["Weitao Du", "Jiujiu Chen", "Xuecang Zhang", "Zhiming Ma", "Shengchao Liu"], "Categories": "cs.LG cs.AI q-bio.BM", "Comments": ["NeurIPS 2023"]}, "abstract": "Recently, artificial intelligence for drug discovery has raised increasing interest in both machine learning and chemistry domains. The fundamental building block for drug discovery is molecule geometry and thus, the molecule's geometrical representation is the main bottleneck to better utilize machine learning techniques for drug discovery. In this work, we propose a pretraining method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn both the 2D bond (topology) and 3D conformation (geometry) information, and a diffusion process model is applied to mimic the augmented trajectories of such two modalities, based on which, MoleculeJAE will learn the inherent chemical structure in a self-supervised manner. Thus, the pretrained geometrical representation in MoleculeJAE is expected to benefit downstream geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by reaching state-of-the-art performance on 15 out of 20 tasks by comparing it with 12 competitive baselines.", "url": "https://arxiv.org/abs/2312.03475"}, {"metadata": {"arXiv": "2312.03492", "Date": "Wed, 06 Dec 2023 13:32:17 ", "Title": "Learning From Scenarios for Stochastic Repairable Scheduling", "Authors": ["Kim van den Houten", "David M.J. Tax", "Esteban Freydell", "Mathijs de Weerdt"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages"]}, "abstract": "When optimizing problems with uncertain parameter values in a linear objective, decision-focused learning enables end-to-end learning of these values. We are interested in a stochastic scheduling problem, in which processing times are uncertain, which brings uncertain values in the constraints, and thus repair of an initial schedule may be needed. Historical realizations of the stochastic processing times are available. We show how existing decision-focused learning techniques based on stochastic smoothing can be adapted to this scheduling problem. We include an extensive experimental evaluation to investigate in which situations decision-focused learning outperforms the state of the art for such situations: scenario-based stochastic optimization.", "url": "https://arxiv.org/abs/2312.03492"}, {"metadata": {"arXiv": "2312.03682", "Date": "Wed, 06 Dec 2023 18:47:28 ", "Title": "What Planning Problems Can A Relational Neural Network Solve?", "Authors": ["Jiayuan Mao", "Tom\\'as Lozano-P\\'erez", "Joshua B. Tenenbaum", "Leslie Pack Kaelbling"], "Categories": "cs.LG cs.AI cs.NE stat.ML", "Comments": ["NeurIPS 2023 (Spotlight). Project page: https://concepts-ai.com/p/goal-regression-width/"]}, "abstract": "Goal-conditioned policies are generally understood to be \"feed-forward\" circuits, in the form of neural networks that map from the current state and the goal specification to the next action to take. However, under what circumstances such a policy can be learned and how efficient the policy will be are not well understood. In this paper, we present a circuit complexity analysis for relational neural networks (such as graph neural networks and transformers) representing policies for planning problems, by drawing connections with serialized goal regression search (S-GRS). We show that there are three general classes of planning problems, in terms of the growth of circuit width and depth as a function of the number of objects and planning horizon, providing constructive proofs. We also illustrate the utility of this analysis for designing neural networks for policy learning.", "url": "https://arxiv.org/abs/2312.03682"}, {"metadata": {"arXiv": "2312.03395", "Date": "Wed, 06 Dec 2023 10:09:22 ", "Title": "Diffused Task-Agnostic Milestone Planner", "Authors": ["Mineui Hong", "Minjae Kang", "Songhwai Oh"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["37th Conference on Neural Information Processing Systems"]}, "abstract": "Addressing decision-making problems using sequence modeling to predict future trajectories shows promising results in recent years. In this paper, we take a step further to leverage the sequence predictive method in wider areas such as long-term planning, vision-based control, and multi-task decision-making. To this end, we propose a method to utilize a diffusion-based generative sequence model to plan a series of milestones in a latent space and to have an agent to follow the milestones to accomplish a given task. The proposed method can learn control-relevant, low-dimensional latent representations of milestones, which makes it possible to efficiently perform long-term planning and vision-based control. Furthermore, our approach exploits generation flexibility of the diffusion model, which makes it possible to plan diverse trajectories for multi-task decision-making. We demonstrate the proposed method across offline reinforcement learning (RL) benchmarks and an visual manipulation environment. The results show that our approach outperforms offline RL methods in solving long-horizon, sparse-reward tasks and multi-task problems, while also achieving the state-of-the-art performance on the most challenging vision-based manipulation benchmark.", "url": "https://arxiv.org/abs/2312.03395"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

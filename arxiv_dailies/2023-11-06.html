<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.01475", "Date": "Wed, 01 Nov 2023 19:59:25 ", "Title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts", "Authors": ["Isaac Wasserman and Jeova Farias Sales Rocha Neto"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "Unsupervised image segmentation aims at grouping different semantic patterns in an image without the use of human annotation. Similarly, image clustering searches for groupings of images based on their semantic content without supervision. Classically, both problems have captivated researchers as they drew from sound mathematical concepts to produce concrete applications. With the emergence of deep learning, the scientific community turned its attention to complex neural network-based solvers that achieved impressive results in those domains but rarely leveraged the advances made by classical methods. In this work, we propose a patch-based unsupervised image segmentation strategy that bridges advances in unsupervised feature extraction from deep clustering methods with the algorithmic help of classical graph-based methods. We show that a simple convolutional neural network, trained to classify image patches and iteratively regularized using graph cuts, naturally leads to a state-of-the-art fully-convolutional unsupervised pixel-level segmenter. Furthermore, we demonstrate that this is the ideal setting for leveraging the patch-level pairwise features generated by vision transformer models. Our results on real image data demonstrate the effectiveness of our proposed methodology.", "url": "https://arxiv.org/abs/2311.01475"}, {"metadata": {"arXiv": "2311.01478", "Date": "Thu, 02 Nov 2023 04:11:45 ", "Title": "Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms", "Authors": ["Aakriti Shah"], "Categories": "cs.CV cs.LG", "Comments": ["15 pages", "17 figures"], "MSC-class": "68", "ACM-class": "I.4.0"}, "abstract": "Physical adversarial attacks on road signs are continuously exploiting vulnerabilities in modern day autonomous vehicles (AVs) and impeding their ability to correctly classify what type of road sign they encounter. Current models cannot generalize input data well, resulting in overfitting or underfitting. In overfitting, the model memorizes the input data but cannot generalize to new scenarios. In underfitting, the model does not learn enough of the input data to accurately classify these road signs. This paper explores the resilience of autonomous driving systems against three main physical adversarial attacks (tape, graffiti, illumination), specifically targeting object classifiers. Several machine learning models were developed and evaluated on two distinct datasets: road signs (stop signs, speed limit signs, traffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons, circles, squares, and triangles). The study compared algorithm performance under different conditions, including clean and adversarial training and testing on these datasets. To build robustness against attacks, defense techniques like adversarial training and transfer learning were implemented. Results demonstrated transfer learning models played a crucial role in performance by allowing knowledge gained from shape training to improve generalizability of road sign classification, despite the datasets being completely different. The paper suggests future research directions, including human-in-the-loop validation, security analysis, real-world testing, and explainable AI for transparency. This study aims to contribute to improving security and robustness of object classifiers in autonomous vehicles and mitigating adversarial example impacts on driving systems.", "url": "https://arxiv.org/abs/2311.01478"}, {"metadata": {"arXiv": "2311.01570", "Date": "Thu, 02 Nov 2023 19:49:11 ", "Title": "Sequential Subset Matching for Dataset Distillation", "Authors": ["Jiawei Du", "Qin Shi", "Joey Tianyi Zhou"], "Categories": "cs.CV cs.LG"}, "abstract": "Dataset distillation is a newly emerging task that synthesizes a small-size dataset used in training deep neural networks (DNNs) for reducing data storage and model training costs. The synthetic datasets are expected to capture the essence of the knowledge contained in real-world datasets such that the former yields a similar performance as the latter. Recent advancements in distillation methods have produced notable improvements in generating synthetic datasets. However, current state-of-the-art methods treat the entire synthetic dataset as a unified entity and optimize each synthetic instance equally. This static optimization approach may lead to performance degradation in dataset distillation. Specifically, we argue that static optimization can give rise to a coupling issue within the synthetic data, particularly when a larger amount of synthetic data is being optimized. This coupling issue, in turn, leads to the failure of the distilled dataset to extract the high-level features learned by the deep neural network (DNN) in the latter epochs. In this study, we propose a new dataset distillation strategy called Sequential Subset Matching (SeqMatch), which tackles this problem by adaptively optimizing the synthetic data to encourage sequential acquisition of knowledge during dataset distillation. Our analysis indicates that SeqMatch effectively addresses the coupling issue by sequentially generating the synthetic instances, thereby enhancing its performance significantly. Our proposed SeqMatch outperforms state-of-the-art methods in various datasets, including SVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at https://github.com/shqii1j/seqmatch.", "url": "https://arxiv.org/abs/2311.01570"}, {"metadata": {"arXiv": "2311.01646", "Date": "Fri, 03 Nov 2023 00:25:58 ", "Title": "SemiGPC: Distribution-Aware Label Refinement for Imbalanced Semi-Supervised Learning Using Gaussian Processes", "Authors": ["Abdelhak Lemkhenter", "Manchen Wang", "Luca Zancato", "Gurumurthy Swaminathan", "Paolo Favaro", "Davide Modolo"], "Categories": "cs.CV cs.LG"}, "abstract": "In this paper we introduce SemiGPC, a distribution-aware label refinement strategy based on Gaussian Processes where the predictions of the model are derived from the labels posterior distribution. Differently from other buffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC includes a normalization term that addresses imbalances in the global data distribution while maintaining local sensitivity. This explicit control allows SemiGPC to be more robust to confirmation bias especially under class imbalance. We show that SemiGPC improves performance when paired with different Semi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch and different pre-training strategies including MSN and Dino. We also show that SemiGPC achieves state of the art results under different degrees of class imbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime. Using SemiGPC also results in about 2% avg.accuracy increase compared to a new competitive baseline on the more challenging benchmarks SemiAves, SemiCUB, SemiFungi and Semi-iNat.", "url": "https://arxiv.org/abs/2311.01646"}, {"metadata": {"arXiv": "2311.01686", "Date": "Fri, 03 Nov 2023 03:18:40 ", "Title": "Disentangled Representation Learning with Transmitted Information Bottleneck", "Authors": ["Zhuohang Dang", "Minnan Luo", "Chengyou Jia", "Guang Dai", "Jihong Wang", "Xiaojun Chang", "Jingdong Wang", "Qinghua Zheng"], "Categories": "cs.CV cs.LG"}, "abstract": "Encoding only the task-related information from the raw data, \\ie, disentangled representation learning, can greatly contribute to the robustness and generalizability of models. Although significant advances have been made by regularizing the information in representations with information theory, two major challenges remain: 1) the representation compression inevitably leads to performance drop; 2) the disentanglement constraints on representations are in complicated optimization. To these issues, we introduce Bayesian networks with transmitted information to formulate the interaction among input and representations during disentanglement. Building upon this framework, we propose \\textbf{DisTIB} (\\textbf{T}ransmitted \\textbf{I}nformation \\textbf{B}ottleneck for \\textbf{Dis}entangled representation learning), a novel objective that navigates the balance between information compression and preservation. We employ variational inference to derive a tractable estimation for DisTIB. This estimation can be simply optimized via standard gradient descent with a reparameterization trick. Moreover, we theoretically prove that DisTIB can achieve optimal disentanglement, underscoring its superior efficacy. To solidify our claims, we conduct extensive experiments on various downstream tasks to demonstrate the appealing efficacy of DisTIB and validate our theoretical analyses.", "url": "https://arxiv.org/abs/2311.01686"}, {"metadata": {"arXiv": "2311.01479", "Date": "Thu, 02 Nov 2023 05:18:28 ", "Title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse", "Authors": ["Litian Liu", "Yao Qin"], "Categories": "cs.LG eess.IV"}, "abstract": "Out-of-distribution (OOD) detection is essential for the safe deployment of AI. Particularly, OOD detectors should generalize effectively across diverse scenarios. To improve upon the generalizability of existing OOD detectors, we introduce a highly versatile OOD detector, called Neural Collapse inspired OOD detector (NC-OOD). We extend the prevalent observation that in-distribution (ID) features tend to form clusters, whereas OOD features are far away. Particularly, based on the recent observation, Neural Collapse, we further demonstrate that ID features tend to cluster in proximity to weight vectors. From our extended observation, we propose to detect OOD based on feature proximity to weight vectors. To further rule out OOD samples, we leverage the observation that OOD features tend to reside closer to the origin than ID features. Extensive experiments show that our approach enhances the generalizability of existing work and can consistently achieve state-of-the-art OOD detection performance across a wide range of OOD Benchmarks over different classification tasks, training losses, and model architectures.", "url": "https://arxiv.org/abs/2311.01479"}, {"metadata": {"arXiv": "2311.01568", "Date": "Thu, 02 Nov 2023 19:44:59 ", "Title": "Anytime-Competitive Reinforcement Learning with Policy Prior", "Authors": ["Jianyi Yang", "Pengfei Li", "Tongxin Li", "Adam Wierman", "Shaolei Ren"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "This paper studies the problem of Anytime-Competitive Markov Decision Process (A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim to optimize the expected reward while constraining the expected cost over random dynamics, but the cost in a specific episode can still be unsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the expected reward while guaranteeing a bounded cost in each round of any episode against a policy prior. We propose a new algorithm, called Anytime-Competitive Reinforcement Learning (ACRL), which provably guarantees the anytime cost constraints. The regret analysis shows the policy asymptotically matches the optimal reward achievable under the anytime competitive constraints. Experiments on the application of carbon-intelligent computing verify the reward performance and cost constraint guarantee of ACRL.", "url": "https://arxiv.org/abs/2311.01568"}, {"metadata": {"arXiv": "2311.01575", "Date": "Thu, 02 Nov 2023 20:03:05 ", "Title": "On the Convergence of Encoder-only Shallow Transformers", "Authors": ["Yongtao Wu", "Fanghui Liu", "Grigorios G Chrysos", "Volkan Cevher"], "Categories": "cs.LG"}, "abstract": "In this paper, we aim to build the global convergence theory of encoder-only shallow Transformers under a realistic setting from the perspective of architectures, initialization, and scaling under a finite width regime. The difficulty lies in how to tackle the softmax in self-attention mechanism, the core ingredient of Transformer. In particular, we diagnose the scaling scheme, carefully tackle the input/output of softmax, and prove that quadratic overparameterization is sufficient for global convergence of our shallow Transformers under commonly-used He/LeCun initialization in practice. Besides, neural tangent kernel (NTK) based analysis is also given, which facilitates a comprehensive comparison. Our theory demonstrates the separation on the importance of different scaling schemes and initialization. We believe our results can pave the way for a better understanding of modern Transformers, particularly on training dynamics.", "url": "https://arxiv.org/abs/2311.01575"}, {"metadata": {"arXiv": "2311.01589", "Date": "Thu, 02 Nov 2023 20:45:29 ", "Title": "A Statistical Guarantee for Representation Transfer in Multitask Imitation Learning", "Authors": ["Bryan Chan", "Karime Pereida", "and James Bergstra"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023 Workshop on Robot Learning"]}, "abstract": "Transferring representation for multitask imitation learning has the potential to provide improved sample efficiency on learning new tasks, when compared to learning from scratch. In this work, we provide a statistical guarantee indicating that we can indeed achieve improved sample efficiency on the target task when a representation is trained using sufficiently diverse source tasks. Our theoretical results can be readily extended to account for commonly used neural network architectures with realistic assumptions. We conduct empirical analyses that align with our theoretical findings on four simulated environments$\\unicode{x2014}$in particular leveraging more data from source tasks can improve sample efficiency on learning in the new task.", "url": "https://arxiv.org/abs/2311.01589"}, {"metadata": {"arXiv": "2311.01591", "Date": "Thu, 02 Nov 2023 20:57:44 ", "Title": "Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs", "Authors": ["Debolina Halder Lina and Arlei Silva"], "Categories": "cs.LG"}, "abstract": "This paper addresses the problem of learning fair Graph Neural Networks (GNNs) under missing protected attributes. GNNs have achieved state-of-the-art results in many relevant tasks where decisions might disproportionately impact specific communities. However, existing work on fair GNNs assumes that either protected attributes are fully-observed or that the missing data imputation is fair. In practice, biases in the imputation will be propagated to the model outcomes, leading them to overestimate the fairness of their predictions. We address this challenge by proposing Better Fair than Sorry (BFtS), a fair missing data imputation model for protected attributes used by fair GNNs. The key design principle behind BFtS is that imputations should approximate the worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the hardest. We implement this idea using a 3-player adversarial scheme where two adversaries collaborate against the fair GNN. Experiments using synthetic and real datasets show that BFtS often achieves a better fairness $\\times$ accuracy trade-off than existing alternatives.", "url": "https://arxiv.org/abs/2311.01591"}, {"metadata": {"arXiv": "2311.01599", "Date": "Thu, 02 Nov 2023 21:10:16 ", "Title": "Local Borsuk-Ulam, Stability, and Replicability", "Authors": ["Zachary Chase", "Bogdan Chornomaz", "Shay Moran", "Amir Yehudayoff"], "Categories": "cs.LG cs.DS", "ACM-class": "I.2.6"}, "abstract": "We use and adapt the Borsuk-Ulam Theorem from topology to derive limitations on list-replicable and globally stable learning algorithms. We further demonstrate the applicability of our methods in combinatorics and topology. We show that, besides trivial cases, both list-replicable and globally stable learning are impossible in the agnostic PAC setting. This is in contrast with the realizable case where it is known that any class with a finite Littlestone dimension can be learned by such algorithms. In the realizable PAC setting, we sharpen previous impossibility results and broaden their scope. Specifically, we establish optimal bounds for list replicability and global stability numbers in finite classes. This provides an exponential improvement over previous works and implies an exponential separation from the Littlestone dimension. We further introduce lower bounds for weak learners, i.e., learners that are only marginally better than random guessing. Lower bounds from previous works apply only to stronger learners. To offer a broader and more comprehensive view of our topological approach, we prove a local variant of the Borsuk-Ulam theorem in topology and a result in combinatorics concerning Kneser colorings. In combinatorics, we prove that if $c$ is a coloring of all non-empty subsets of $[n]$ such that disjoint sets have different colors, then there is a chain of subsets that receives at least $1+ \\lfloor n/2\\rfloor$ colors (this bound is sharp). In topology, we prove e.g. that for any open antipodal-free cover of the $d$-dimensional sphere, there is a point $x$ that belongs to at least $t=\\lceil\\frac{d+3}{2}\\rceil$ sets.", "url": "https://arxiv.org/abs/2311.01599"}, {"metadata": {"arXiv": "2311.01642", "Date": "Fri, 03 Nov 2023 00:00:32 ", "Title": "Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula", "Authors": ["Aryaman Reddi", "Maximilian T\\\"olle", "Jan Peters", "Georgia Chalvatzaki", "Carlo D'Eramo"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Robustness against adversarial attacks and distribution shifts is a long-standing goal of Reinforcement Learning (RL). To this end, Robust Adversarial Reinforcement Learning (RARL) trains a protagonist against destabilizing forces exercised by an adversary in a competitive zero-sum Markov game, whose optimal solution, i.e., rational strategy, corresponds to a Nash equilibrium. However, finding Nash equilibria requires facing complex saddle point optimization problems, which can be prohibitive to solve, especially for high-dimensional control. In this paper, we propose a novel approach for adversarial RL based on entropy regularization to ease the complexity of the saddle point optimization problem. We show that the solution of this entropy-regularized problem corresponds to a Quantal Response Equilibrium (QRE), a generalization of Nash equilibria that accounts for bounded rationality, i.e., agents sometimes play random actions instead of optimal ones. Crucially, the connection between the entropy-regularized objective and QRE enables free modulation of the rationality of the agents by simply tuning the temperature coefficient. We leverage this insight to propose our novel algorithm, Quantal Adversarial RL (QARL), which gradually increases the rationality of the adversary in a curriculum fashion until it is fully rational, easing the complexity of the optimization problem while retaining robustness. We provide extensive evidence of QARL outperforming RARL and recent baselines across several MuJoCo locomotion and navigation problems in overall performance and robustness.", "url": "https://arxiv.org/abs/2311.01642"}, {"metadata": {"arXiv": "2311.01644", "Date": "Fri, 03 Nov 2023 00:21:36 ", "Title": "Should Under-parameterized Student Networks Copy or Average Teacher Weights?", "Authors": ["Berfin \\c{S}im\\c{s}ek", "Amire Bendjeddou", "Wulfram Gerstner", "Johanni Brea"], "Categories": "cs.LG cs.NE stat.ML", "Comments": ["40 pages", "to appear at NeurIPS 2023"]}, "abstract": "Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n< k$ neurons can thus be seen as fitting an under-parameterized \"student\" network with $n$ neurons to a \"teacher\" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that \"copy-average\" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the student network with $n=1$ neuron, we provide additionally a closed-form solution of the non-trivial critical point(s) for commonly used activation functions through solving an equivalent constrained optimization problem. Empirically, we find for the erf activation function that gradient flow converges either to the optimal copy-average critical point or to another point where each student neuron approximately copies a different teacher neuron. Finally, we find similar results for the ReLU activation function, suggesting that the optimal solution of underparameterized networks has a universal structure.", "url": "https://arxiv.org/abs/2311.01644"}, {"metadata": {"arXiv": "2311.01647", "Date": "Fri, 03 Nov 2023 00:33:24 ", "Title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs", "Authors": ["Yeyuan Chen and Dingmin Wang"], "Categories": "cs.LG cs.LO"}, "abstract": "As a powerful framework for graph representation learning, Graph Neural Networks (GNNs) have garnered significant attention in recent years. However, to the best of our knowledge, there has been no formal analysis of the logical expressiveness of GNNs as Boolean node classifiers over multi-relational graphs, where each edge carries a specific relation type. In this paper, we investigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two variables and counting quantifiers. On the negative side, we demonstrate that the R$^2$-GNN architecture, which extends the local message passing GNN by incorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in the general case. Nevertheless, on the positive side, we establish that R$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs regarding expressiveness, we propose a simple graph transformation technique, akin to a preprocessing step, which can be executed in linear time. This transformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$ classifiers when applied to the \"transformed\" input graph. Moreover, we extend our analysis of expressiveness and graph transformation to temporal graphs, exploring several temporal GNN architectures and providing an expressiveness hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the graph transformation technique and conduct empirical tests in node classification tasks against various well-known GNN architectures that support multi-relational or temporal graphs. Our experimental results consistently demonstrate that R$^2$-GNN with the graph transformation outperforms the baseline methods on both synthetic and real-world datasets", "url": "https://arxiv.org/abs/2311.01647"}, {"metadata": {"arXiv": "2311.01655", "Date": "Fri, 03 Nov 2023 01:12:35 ", "Title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification", "Authors": ["Preetam Prabhu Srikar Dammu", "Chirag Shah"], "Categories": "cs.LG cs.CV", "Comments": ["Paper accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023)", "XAIA Workshop"]}, "abstract": "Often machine learning models tend to automatically learn associations present in the training data without questioning their validity or appropriateness. This undesirable property is the root cause of the manifestation of spurious correlations, which render models unreliable and prone to failure in the presence of distribution shifts. Research shows that most methods attempting to remedy spurious correlations are only effective for a model's known spurious associations. Current spurious correlation detection algorithms either rely on extensive human annotations or are too restrictive in their formulation. Moreover, they rely on strict definitions of visual artifacts that may not apply to data produced by generative models, as they are known to hallucinate contents that do not conform to standard specifications. In this work, we introduce a general-purpose method that efficiently detects potential spurious correlations, and requires significantly less human interference in comparison to the prior art. Additionally, the proposed method provides intuitive explanations while eliminating the need for pixel-level annotations. We demonstrate the proposed method's tolerance to the peculiarity of AI-generated images, which is a considerably challenging task, one where most of the existing methods fall short. Consequently, our method is also suitable for detecting spurious correlations that may propagate to downstream applications originating from generative models.", "url": "https://arxiv.org/abs/2311.01655"}, {"metadata": {"arXiv": "2311.01660", "Date": "Fri, 03 Nov 2023 01:46:48 ", "Title": "Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling", "Authors": ["Mert Ketenci and Shreyas Bhave and No\\'emie Elhadad and Adler Perotte"], "Categories": "cs.LG stat.ML"}, "abstract": "Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show that the proposed approach matches or outperforms baselines on several real-world datasets.", "url": "https://arxiv.org/abs/2311.01660"}, {"metadata": {"arXiv": "2311.01695", "Date": "Fri, 03 Nov 2023 03:50:31 ", "Title": "Communication-Efficient Federated Non-Linear Bandit Optimization", "Authors": ["Chuanhao Li", "Chong Liu and Yu-Xiang Wang"], "Categories": "cs.LG cs.DC", "Comments": ["23 pages", "3 figures"]}, "abstract": "Federated optimization studies the problem of collaborative function optimization among multiple clients (e.g. mobile devices or organizations) under the coordination of a central server. Since the data is collected separately by each client and always remains decentralized, federated optimization preserves data privacy and allows for large-scale computing, which makes it a promising decentralized machine learning paradigm. Though it is often deployed for tasks that are online in nature, e.g., next-word prediction on keyboard apps, most works formulate it as an offline problem. The few exceptions that consider federated bandit optimization are limited to very simplistic function classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which severely hinders its practical usage. In this paper, we propose a new algorithm, named Fed-GO-UCB, for federated bandit optimization with generic non-linear objective function. Under some mild conditions, we rigorously prove that Fed-GO-UCB is able to achieve sub-linear rate for both cumulative regret and communication cost. At the heart of our theoretical analysis are distributed regression oracle and individual confidence set construction, which can be of independent interests. Empirical evaluations also demonstrate the effectiveness of the proposed algorithm.", "url": "https://arxiv.org/abs/2311.01695"}, {"metadata": {"arXiv": "2311.01698", "Date": "Fri, 03 Nov 2023 04:03:19 ", "Title": "Adversarial Attacks on Cooperative Multi-agent Bandits", "Authors": ["Jinhang Zuo", "Zhiyao Zhang", "Xuchuang Wang", "Cheng Chen", "Shuai Li", "John C.S. Lui", "Mohammad Hajiesmaili", "Adam Wierman"], "Categories": "cs.LG cs.CR cs.MA"}, "abstract": "Cooperative multi-agent multi-armed bandits (CMA2B) consider the collaborative efforts of multiple agents in a shared multi-armed bandit game. We study latent vulnerabilities exposed by this collaboration and consider adversarial attacks on a few agents with the goal of influencing the decisions of the rest. More specifically, we study adversarial attacks on CMA2B in both homogeneous settings, where agents operate with the same arm set, and heterogeneous settings, where agents have distinct arm sets. In the homogeneous setting, we propose attack strategies that, by targeting just one agent, convince all agents to select a particular target arm $T-o(T)$ times while incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we prove that a target arm attack requires linear attack costs and propose attack strategies that can force a maximum number of agents to suffer linear regrets while incurring sublinear costs and only manipulating the observations of a few target agents. Numerical experiments validate the effectiveness of our proposed attack strategies.", "url": "https://arxiv.org/abs/2311.01698"}, {"metadata": {"arXiv": "2311.01708", "Date": "Fri, 03 Nov 2023 04:29:49 ", "Title": "Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations", "Authors": ["Ruisong Gao", "Min Yang", "Jin Zhang"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["24 pages"]}, "abstract": "We propose a new class of physics-informed neural networks, called Physics-Informed Generator-Encoder Adversarial Networks, to effectively address the challenges posed by forward, inverse, and mixed problems in stochastic differential equations. In these scenarios, while the governing equations are known, the available data consist of only a limited set of snapshots for system parameters. Our model consists of two key components: the generator and the encoder, both updated alternately by gradient descent. In contrast to previous approaches of directly matching the approximated solutions with real snapshots, we employ an indirect matching that operates within the lower-dimensional latent feature space. This method circumvents challenges associated with high-dimensional inputs and complex data distributions, while yielding more accurate solutions compared to existing neural network solvers. In addition, the approach also mitigates the training instability issues encountered in previous adversarial frameworks in an efficient manner. Numerical results provide compelling evidence of the effectiveness of the proposed method in solving different types of stochastic differential equations.", "url": "https://arxiv.org/abs/2311.01708"}, {"metadata": {"arXiv": "2311.01722", "Date": "Fri, 03 Nov 2023 05:39:45 ", "Title": "Heterogeneous federated collaborative filtering using FAIR: Federated Averaging in Random Subspaces", "Authors": ["Aditya Desai", "Benjamin Meisburger", "Zichang Liu", "Anshumali Shrivastava"], "Categories": "cs.LG"}, "abstract": "Recommendation systems (RS) for items (e.g., movies, books) and ads are widely used to tailor content to users on various internet platforms. Traditionally, recommendation models are trained on a central server. However, due to rising concerns for data privacy and regulations like the GDPR, federated learning is an increasingly popular paradigm in which data never leaves the client device. Applying federated learning to recommendation models is non-trivial due to large embedding tables, which often exceed the memory constraints of most user devices. To include data from all devices in federated learning, we must enable collective training of embedding tables on devices with heterogeneous memory capacities. Current solutions to heterogeneous federated learning can only accommodate a small range of capacities and thus limit the number of devices that can participate in training. We present Federated Averaging in Random subspaces (FAIR), which allows arbitrary compression of embedding tables based on device capacity and ensures the participation of all devices in training. FAIR uses what we call consistent and collapsible subspaces defined by hashing-based random projections to jointly train large embedding tables while using varying amounts of compression on user devices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple datasets and verify that FAIR can gather and share information from a wide range of devices with varying capacities, allowing for seamless collaboration. We prove the convergence of FAIR in the homogeneous setting with non-i.i.d data distribution. Our code is open source at {https://github.com/apd10/FLCF}", "url": "https://arxiv.org/abs/2311.01722"}, {"metadata": {"arXiv": "2311.01749", "Date": "Fri, 03 Nov 2023 06:57:41 ", "Title": "Epidemic Decision-making System Based Federated Reinforcement Learning", "Authors": ["Yangxi Zhou", "Junping Du", "Zhe Xue", "Zhenhui Pan", "and Weikang Chen"], "Categories": "cs.LG cs.IR"}, "abstract": "Epidemic decision-making can effectively help the government to comprehensively consider public security and economic development to respond to public health and safety emergencies. Epidemic decision-making can effectively help the government to comprehensively consider public security and economic development to respond to public health and safety emergencies. Some studies have shown that intensive learning can effectively help the government to make epidemic decision, thus achieving the balance between health security and economic development. Some studies have shown that intensive learning can effectively help the government to make epidemic decision, thus achieving the balance between health security and economic development. However, epidemic data often has the characteristics of limited samples and high privacy. However, epidemic data often has the characteristics of limited samples and high privacy. This model can combine the epidemic situation data of various provinces for cooperative training to use as an enhanced learning model for epidemic situation decision, while protecting the privacy of data. The experiment shows that the enhanced federated learning can obtain more optimized performance and return than the enhanced learning, and the enhanced federated learning can also accelerate the training convergence speed of the training model. accelerate the training convergence speed of the client. At the same time, through the experimental comparison, A2C is the most suitable reinforcement learning model for the epidemic situation decision-making. learning model for the epidemic situation decision-making scenario, followed by the PPO model, and the performance of DDPG is unsatisfactory.", "url": "https://arxiv.org/abs/2311.01749"}, {"metadata": {"arXiv": "2311.01759", "Date": "Fri, 03 Nov 2023 07:34:47 ", "Title": "TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices", "Authors": ["Jianlei Yang", "Jiacheng Liao", "Fanding Lei", "Meichen Liu", "Junyi Chen", "Lingkun Long", "Han Wan", "Bei Yu", "Weisheng Zhao"], "Categories": "cs.LG cs.AR", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Developing deep learning models on tiny devices (e.g. Microcontroller units, MCUs) has attracted much attention in various embedded IoT applications. However, it is challenging to efficiently design and deploy recent advanced models (e.g. transformers) on tiny devices due to their severe hardware resource constraints. In this work, we propose TinyFormer, a framework specifically designed to develop and deploy resource-efficient transformers on MCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine. Separately, SuperNAS aims to search for an appropriate supernet from a vast search space. SparseNAS evaluates the best sparse single-path model including transformer architecture from the identified supernet. Finally, SparseEngine efficiently deploys the searched sparse models onto MCUs. To the best of our knowledge, SparseEngine is the first deployment framework capable of performing inference of sparse models with transformer on MCUs. Evaluation results on the CIFAR-10 dataset demonstrate that TinyFormer can develop efficient transformers with an accuracy of $96.1\\%$ while adhering to hardware constraints of $1$MB storage and $320$KB memory. Additionally, TinyFormer achieves significant speedups in sparse inference, up to $12.2\\times$, when compared to the CMSIS-NN library. TinyFormer is believed to bring powerful transformers into TinyML scenarios and greatly expand the scope of deep learning applications.", "url": "https://arxiv.org/abs/2311.01759"}, {"metadata": {"arXiv": "2311.01771", "Date": "Fri, 03 Nov 2023 08:12:05 ", "Title": "Efficient Generalized Low-Rank Tensor Contextual Bandits", "Authors": ["Qianxin Yi", "Yiyang Yang", "Yao Wang", "Shaojie Tang"], "Categories": "cs.LG stat.ML"}, "abstract": "In this paper, we aim to build a novel bandits algorithm that is capable of fully harnessing the power of multi-dimensional data and the inherent non-linearity of reward functions to provide high-usable and accountable decision-making services. To this end, we introduce a generalized low-rank tensor contextual bandits model in which an action is formed from three feature vectors, and thus can be represented by a tensor. In this formulation, the reward is determined through a generalized linear function applied to the inner product of the action's feature tensor and a fixed but unknown parameter tensor with a low tubal rank. To effectively achieve the trade-off between exploration and exploitation, we introduce a novel algorithm called \"Generalized Low-Rank Tensor Exploration Subspace then Refine\" (G-LowTESTR). This algorithm first collects raw data to explore the intrinsic low-rank tensor subspace information embedded in the decision-making scenario, and then converts the original problem into an almost lower-dimensional generalized linear contextual bandits problem. Rigorous theoretical analysis shows that the regret bound of G-LowTESTR is superior to those in vectorization and matricization cases. We conduct a series of simulations and real data experiments to further highlight the effectiveness of G-LowTESTR, leveraging its ability to capitalize on the low-rank tensor structure for enhanced learning.", "url": "https://arxiv.org/abs/2311.01771"}, {"metadata": {"arXiv": "2311.01796", "Date": "Fri, 03 Nov 2023 09:19:33 ", "Title": "Learning to Augment Distributions for Out-of-Distribution Detection", "Authors": ["Qizhou Wang", "Zhen Fang", "Yonggang Zhang", "Feng Liu", "Yixuan Li", "Bo Han"], "Categories": "cs.LG"}, "abstract": "Open-world classification systems should discern out-of-distribution (OOD) data whose labels deviate from those of in-distribution (ID) cases, motivating recent studies in OOD detection. Advanced works, despite their promising progress, may still fail in the open world, owing to the lack of knowledge about unseen OOD data in advance. Although one can access auxiliary OOD data (distinct from unseen ones) for model training, it remains to analyze how such auxiliary data will work in the open world. To this end, we delve into such a problem from a learning theory perspective, finding that the distribution discrepancy between the auxiliary and the unseen real OOD data is the key to affecting the open-world detection performance. Accordingly, we propose Distributional-Augmented OOD Learning (DAL), alleviating the OOD distribution discrepancy by crafting an OOD distribution set that contains all distributions in a Wasserstein ball centered on the auxiliary OOD distribution. We justify that the predictor trained over the worst OOD data in the ball can shrink the OOD distribution discrepancy, thus improving the open-world detection performance given only the auxiliary OOD data. We conduct extensive evaluations across representative OOD detection setups, demonstrating the superiority of our DAL over its advanced counterparts.", "url": "https://arxiv.org/abs/2311.01796"}, {"metadata": {"arXiv": "2311.01797", "Date": "Fri, 03 Nov 2023 09:20:20 ", "Title": "On the Generalization Properties of Diffusion Models", "Authors": ["Puheng Li", "Zhong Li", "Huishuai Zhang", "Jiang Bian"], "Categories": "cs.LG stat.ML", "Comments": ["42 pages", "11 figures"]}, "abstract": "Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progressively increasing distances between modes. This precisely elucidates the adverse effect of \"modes shift\" in ground truths on the model generalization. Moreover, these estimates are not solely theoretical constructs but have also been confirmed through numerical simulations. Our findings contribute to the rigorous understanding of diffusion models' generalization properties and provide insights that may guide practical applications.", "url": "https://arxiv.org/abs/2311.01797"}, {"metadata": {"arXiv": "2311.01829", "Date": "Fri, 03 Nov 2023 10:36:54 ", "Title": "Mix-ME: Quality-Diversity for Multi-Agent Learning", "Authors": ["Gar{\\dh}ar Ingvarsson", "Mikayel Samvelyan", "Bryan Lim", "Manon Flageat", "Antoine Cully", "Tim Rockt\\\"aschel"], "Categories": "cs.LG cs.MA cs.NE", "Comments": ["15 pages", "7 figures. Submitted and accepted to the ALOE workshop at NeurIPS 2023"]}, "abstract": "In many real-world systems, such as adaptive robotics, achieving a single, optimised solution may be insufficient. Instead, a diverse set of high-performing solutions is often required to adapt to varying contexts and requirements. This is the realm of Quality-Diversity (QD), which aims to discover a collection of high-performing solutions, each with their own unique characteristics. QD methods have recently seen success in many domains, including robotics, where they have been used to discover damage-adaptive locomotion controllers. However, most existing work has focused on single-agent settings, despite many tasks of interest being multi-agent. To this end, we introduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites algorithm that forms new solutions using a crossover-like operator by mixing together agents from different teams. We evaluate the proposed methods on a variety of partially observable continuous control tasks. Our evaluation shows that these multi-agent variants obtained by Mix-ME not only compete with single-agent baselines but also often outperform them in multi-agent settings under partial observability.", "url": "https://arxiv.org/abs/2311.01829"}, {"metadata": {"arXiv": "2311.01840", "Date": "Fri, 03 Nov 2023 11:05:29 ", "Title": "Spectral Clustering of Attributed Multi-relational Graphs", "Authors": ["Ylli Sadikaj", "Yllka Velaj", "Sahar Behzadi", "Claudia Plant"], "Categories": "cs.LG cs.SI", "Journal-ref": "Association for Computing Machinery, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 21, Virtual Event, Singapore, August 2021, Pages 1431-1440", "DOI": "10.1145/3447548.3467381"}, "abstract": "Graph clustering aims at discovering a natural grouping of the nodes such that similar nodes are assigned to a common cluster. Many different algorithms have been proposed in the literature: for simple graphs, for graphs with attributes associated to nodes, and for graphs where edges represent different types of relations among nodes. However, complex data in many domains can be represented as both attributed and multi-relational networks. In this paper, we propose SpectralMix, a joint dimensionality reduction technique for multi-relational graphs with categorical node attributes. SpectralMix integrates all information available from the attributes, the different types of relations, and the graph structure to enable a sound interpretation of the clustering results. Moreover, it generalizes existing techniques: it reduces to spectral embedding and clustering when only applied to a single graph and to homogeneity analysis when applied to categorical data. Experiments conducted on several real-world datasets enable us to detect dependencies between graph structure and categorical attributes, moreover, they exhibit the superiority of SpectralMix over existing methods.", "url": "https://arxiv.org/abs/2311.01840"}, {"metadata": {"arXiv": "2311.01885", "Date": "Fri, 03 Nov 2023 12:54:05 ", "Title": "Domain Randomization via Entropy Maximization", "Authors": ["Gabriele Tiboni", "Pascal Klink", "Jan Peters", "Tatiana Tommasi", "Carlo D'Eramo", "Georgia Chalvatzaki"], "Categories": "cs.LG cs.RO", "Comments": ["Project website at https://gabrieletiboni.github.io/doraemon/"]}, "abstract": "Varying dynamics parameters in simulation is a popular Domain Randomization (DR) approach for overcoming the reality gap in Reinforcement Learning (RL). Nevertheless, DR heavily hinges on the choice of the sampling distribution of the dynamics parameters, since high variability is crucial to regularize the agent's behavior but notoriously leads to overly conservative policies when randomizing excessively. In this paper, we propose a novel approach to address sim-to-real transfer, which automatically shapes dynamics distributions during training in simulation without requiring real-world data. We introduce DOmain RAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization problem that directly maximizes the entropy of the training distribution while retaining generalization capabilities. In achieving this, DORAEMON gradually increases the diversity of sampled dynamics parameters as long as the probability of success of the current policy is sufficiently high. We empirically validate the consistent benefits of DORAEMON in obtaining highly adaptive and generalizable policies, i.e. solving the task at hand across the widest range of dynamics parameters, as opposed to representative baselines from the DR literature. Notably, we also demonstrate the Sim2Real applicability of DORAEMON through its successful zero-shot transfer in a robotic manipulation setup under unknown real-world parameters.", "url": "https://arxiv.org/abs/2311.01885"}, {"metadata": {"arXiv": "2311.01902", "Date": "Fri, 03 Nov 2023 13:22:27 ", "Title": "High Precision Causal Model Evaluation with Conditional Randomization", "Authors": ["Chao Ma", "Cheng Zhang"], "Categories": "cs.LG stat.ME", "Comments": ["NeurIPS 2023 Camera Ready version"]}, "abstract": "The gold standard for causal model evaluation involves comparing model predictions with true effects estimated from randomized controlled trials (RCT). However, RCTs are not always feasible or ethical to perform. In contrast, conditionally randomized experiments based on inverse probability weighting (IPW) offer a more realistic approach but may suffer from high estimation variance. To tackle this challenge and enhance causal model evaluation in real-world conditional randomization settings, we introduce a novel low-variance estimator for causal error, dubbed as the pairs estimator. By applying the same IPW estimator to both the model and true experimental effects, our estimator effectively cancels out the variance due to IPW and achieves a smaller asymptotic variance. Empirical studies demonstrate the improved of our estimator, highlighting its potential on achieving near-RCT performance. Our method offers a simple yet powerful solution to evaluate causal inference models in conditional randomization settings without complicated modification of the IPW estimator itself, paving the way for more robust and reliable model assessments.", "url": "https://arxiv.org/abs/2311.01902"}, {"metadata": {"arXiv": "2311.01906", "Date": "Fri, 03 Nov 2023 13:30:52 ", "Title": "Simplifying Transformer Blocks", "Authors": ["Bobby He and Thomas Hofmann"], "Categories": "cs.LG"}, "abstract": "A simple design recipe for deep Transformers is to compose identical building blocks. But standard transformer blocks are far from simple, interweaving attention and MLP sub-blocks with skip connections & normalisation layers in precise arrangements. This complexity leads to brittle architectures, where seemingly minor changes can significantly reduce training speed, or render models untrainable. In this work, we ask to what extent the standard transformer block can be simplified? Combining signal propagation theory and empirical observations, we motivate modifications that allow many block components to be removed with no loss of training speed, including skip connections, projection or value parameters, sequential sub-blocks and normalisation layers. In experiments on both autoregressive decoder-only and BERT encoder-only models, our simplified transformers emulate the per-update training speed and performance of standard transformers, while enjoying 15% faster training throughput, and using 15% fewer parameters.", "url": "https://arxiv.org/abs/2311.01906"}, {"metadata": {"arXiv": "2311.01933", "Date": "Fri, 03 Nov 2023 14:17:11 ", "Title": "ForecastPFN: Synthetically-Trained Zero-Shot Forecasting", "Authors": ["Samuel Dooley", "Gurnoor Singh Khurana", "Chirag Mohapatra", "Siddartha Naidu", "Colin White"], "Categories": "cs.LG", "Journal-ref": "Thirty-seventh Conference on Neural Information Processing Systems, 2023"}, "abstract": "The vast majority of time-series forecasting approaches require a substantial training dataset. However, many real-life forecasting applications have very little initial observations, sometimes just 40 or fewer. Thus, the applicability of most forecasting methods is restricted in data-sparse commercial applications. While there is recent work in the setting of very limited initial data (so-called `zero-shot' forecasting), its performance is inconsistent depending on the data used for pretraining. In this work, we take a different approach and devise ForecastPFN, the first zero-shot forecasting model trained purely on a novel synthetic data distribution. ForecastPFN is a prior-data fitted network, trained to approximate Bayesian inference, which can make predictions on a new time series dataset in a single forward pass. Through extensive experiments, we show that zero-shot predictions made by ForecastPFN are more accurate and faster compared to state-of-the-art forecasting methods, even when the other methods are allowed to train on hundreds of additional in-distribution data points.", "url": "https://arxiv.org/abs/2311.01933"}, {"metadata": {"arXiv": "2311.01953", "Date": "Fri, 03 Nov 2023 14:47:54 ", "Title": "Optimistic Multi-Agent Policy Gradient for Cooperative Tasks", "Authors": ["Wenshuai Zhao", "Yi Zhao", "Zhiyuan Li", "Juho Kannala", "Joni Pajarinen"], "Categories": "cs.LG cs.MA", "Comments": ["16 pages", "9 figures"]}, "abstract": "\\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agent learning tasks when agents converge towards a suboptimal joint policy due to overfitting to suboptimal behavior of other agents. In early work, optimism has been shown to mitigate the \\textit{RO} problem when using tabular Q-learning. However, with function approximation optimism can amplify overestimation and thus fail on complex tasks. On the other hand, recent deep multi-agent policy gradient (MAPG) methods have succeeded in many complex tasks but may fail with severe \\textit{RO}. We propose a general, yet simple, framework to enable optimistic updates in MAPG methods and alleviate the RO problem. Specifically, we employ a \\textit{Leaky ReLU} function where a single hyperparameter selects the degree of optimism to reshape the advantages when updating the policy. Intuitively, our method remains optimistic toward individual actions with lower returns which are potentially caused by other agents' sub-optimal behavior during learning. The optimism prevents the individual agents from quickly converging to a local optimum. We also provide a formal analysis from an operator view to understand the proposed advantage transformation. In extensive evaluations on diverse sets of tasks, including illustrative matrix games, complex \\textit{Multi-agent MuJoCo} and \\textit{Overcooked} benchmarks, the proposed method\\footnote{Code can be found at \\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselines on 13 out of 19 tested tasks and matches the performance on the rest.", "url": "https://arxiv.org/abs/2311.01953"}, {"metadata": {"arXiv": "2311.01990", "Date": "Fri, 03 Nov 2023 15:42:12 ", "Title": "Conditions on Preference Relations that Guarantee the Existence of Optimal Policies", "Authors": ["Jonathan Colaco Carr", "Prakash Panangaden", "Doina Precup"], "Categories": "cs.LG", "Comments": ["32 pages", "no figures"]}, "abstract": "Learning from Preferential Feedback (LfPF) plays an essential role in training Large Language Models, as well as certain types of interactive learning agents. However, a substantial gap exists between the theory and application of LfPF algorithms. Current results guaranteeing the existence of optimal policies in LfPF problems assume that both the preferences and transition dynamics are determined by a Markov Decision Process. We introduce the Direct Preference Process, a new framework for analyzing LfPF problems in partially-observable, non-Markovian environments. Within this framework, we establish conditions that guarantee the existence of optimal policies by considering the ordinal structure of the preferences. Using the von Neumann-Morgenstern Expected Utility Theorem, we show that the Direct Preference Process generalizes the standard reinforcement learning problem. Our findings narrow the gap between the empirical success and theoretical understanding of LfPF algorithms and provide future practitioners with the tools necessary for a more principled design of LfPF agents.", "url": "https://arxiv.org/abs/2311.01990"}, {"metadata": {"arXiv": "2311.02061", "Date": "Fri, 03 Nov 2023 17:45:18 ", "Title": "Active Learning-Based Species Range Estimation", "Authors": ["Christian Lange", "Elijah Cole", "Grant Van Horn", "Oisin Mac Aodha"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"]}, "abstract": "We propose a new active learning approach for efficiently estimating the geographic range of a species from a limited number of on the ground observations. We model the range of an unmapped species of interest as the weighted combination of estimated ranges obtained from a set of different species. We show that it is possible to generate this candidate set of ranges by using models that have been trained on large weakly supervised community collected observation data. From this, we develop a new active querying approach that sequentially selects geographic locations to visit that best reduce our uncertainty over an unmapped species' range. We conduct a detailed evaluation of our approach and compare it to existing active learning methods using an evaluation dataset containing expert-derived ranges for one thousand species. Our results demonstrate that our method outperforms alternative active learning methods and approaches the performance of end-to-end trained models, even when only using a fraction of the data. This highlights the utility of active learning via transfer learned spatial representations for species range estimation. It also emphasizes the value of leveraging emerging large-scale crowdsourced datasets, not only for modeling a species' range, but also for actively discovering them.", "url": "https://arxiv.org/abs/2311.02061"}, {"metadata": {"arXiv": "2311.02076", "Date": "Fri, 03 Nov 2023 17:59:40 ", "Title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos", "Authors": ["Dayal Singh Kalra", "Tianyu He", "Maissam Barkeshli"], "Categories": "cs.LG cond-mat.dis-nn nlin.CD stat.ML", "Comments": ["9+21 pages", "8+20 Figures"]}, "abstract": "In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Finally, we demonstrate that various predictions from this simplified model generalize to real-world scenarios and discuss its limitations.", "url": "https://arxiv.org/abs/2311.02076"}, {"metadata": {"arXiv": "2311.01522", "Date": "Thu, 02 Nov 2023 18:10:20 ", "Title": "An Efficient Detection and Control System for Underwater Docking using Machine Learning and Realistic Simulation: A Comprehensive Approach", "Authors": ["Jalil Chavez-Galaviz", "Jianwen Li", "Matthew Bergman", "Miras Mengdibayev"], "Categories": "cs.RO cs.LG", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "Underwater docking is critical to enable the persistent operation of Autonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of detecting and localizing the docking station, which is complex due to the highly dynamic undersea environment. Image-based solutions offer a high acquisition rate and versatile alternative to adapt to this environment; however, the underwater environment presents challenges such as low visibility, high turbidity, and distortion. In addition to this, field experiments to validate underwater docking capabilities can be costly and dangerous due to the specialized equipment and safety considerations required to conduct the experiments. This work compares different deep-learning architectures to perform underwater docking detection and classification. The architecture with the best performance is then compressed using knowledge distillation under the teacher-student paradigm to reduce the network's memory footprint, allowing real-time implementation. To reduce the simulation-to-reality gap, a Generative Adversarial Network (GAN) is used to do image-to-image translation, converting the Gazebo simulation image into a realistic underwater-looking image. The obtained image is then processed using an underwater image formation model to simulate image attenuation over distance under different water types. The proposed method is finally evaluated according to the AUV docking success rate and compared with classical vision methods. The simulation results show an improvement of 20% in the high turbidity scenarios regardless of the underwater currents. Furthermore, we show the performance of the proposed approach by showing experimental results on the off-the-shelf AUV Iver3.", "url": "https://arxiv.org/abs/2311.01522"}, {"metadata": {"arXiv": "2311.02058", "Date": "Fri, 03 Nov 2023 17:38:35 ", "Title": "LOTUS: Continual Imitation Learning for Robot Manipulation Through Unsupervised Skill Discovery", "Authors": ["Weikang Wan", "Yifeng Zhu", "Rutav Shah", "Yuke Zhu"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Submitted to ICRA 2024"]}, "abstract": "We introduce LOTUS, a continual imitation learning algorithm that empowers a physical robot to continuously and efficiently learn to solve new manipulation tasks throughout its lifespan. The core idea behind LOTUS is constructing an ever-growing skill library from a sequence of new tasks with a small number of human demonstrations. LOTUS starts with a continual skill discovery process using an open-vocabulary vision model, which extracts skills as recurring patterns presented in unsegmented demonstrations. Continual skill discovery updates existing skills to avoid catastrophic forgetting of previous tasks and adds new skills to solve novel tasks. LOTUS trains a meta-controller that flexibly composes various skills to tackle vision-based manipulation tasks in the lifelong learning process. Our comprehensive experiments show that LOTUS outperforms state-of-the-art baselines by over 11% in success rate, showing its superior knowledge transfer ability compared to prior methods. More results and videos can be found on the project website: https://ut-austin-rpl.github.io/Lotus/.", "url": "https://arxiv.org/abs/2311.02058"}, {"metadata": {"arXiv": "2311.01550", "Date": "Thu, 02 Nov 2023 19:00:42 ", "Title": "Market Concentration Implications of Foundation Models", "Authors": ["Jai Vipra", "Anton Korinek"], "Categories": "cs.AI econ.GN q-fin.EC", "Comments": ["Working Paper"]}, "abstract": "We analyze the structure of the market for foundation models, i.e., large AI models such as those that power ChatGPT and that are adaptable to downstream uses, and we examine the implications for competition policy and regulation. We observe that the most capable models will have a tendency towards natural monopoly and may have potentially vast markets. This calls for a two-pronged regulatory response: (i) Antitrust authorities need to ensure the contestability of the market by tackling strategic behavior, in particular by ensuring that monopolies do not propagate vertically to downstream uses, and (ii) given the diminished potential for market discipline, there is a role for regulators to ensure that the most capable models meet sufficient quality standards (including safety, privacy, non-discrimination, reliability and interoperability standards) to maximally contribute to social welfare. Regulators should also ensure a level regulatory playing field between AI and non-AI applications in all sectors of the economy. For models that are behind the frontier, we expect competition to be quite intense, implying a more limited role for competition policy, although a role for regulation remains.", "url": "https://arxiv.org/abs/2311.01550"}, {"metadata": {"arXiv": "2311.01609", "Date": "Thu, 02 Nov 2023 21:37:32 ", "Title": "Responsible Emergent Multi-Agent Behavior", "Authors": ["Niko A. Grupen"], "Categories": "cs.AI", "Comments": ["234 pages", "46 figures"]}, "abstract": "Responsible AI has risen to the forefront of the AI research community. As neural network-based learning algorithms continue to permeate real-world applications, the field of Responsible AI has played a large role in ensuring that such systems maintain a high-level of human-compatibility. Despite this progress, the state of the art in Responsible AI has ignored one crucial point: human problems are multi-agent problems. Predominant approaches largely consider the performance of a single AI system in isolation, but human problems are, by their very nature, multi-agent. From driving in traffic to negotiating economic policy, human problem-solving involves interaction and the interplay of the actions and motives of multiple individuals. This dissertation develops the study of responsible emergent multi-agent behavior, illustrating how researchers and practitioners can better understand and shape multi-agent learning with respect to three pillars of Responsible AI: interpretability, fairness, and robustness. First, I investigate multi-agent interpretability, presenting novel techniques for understanding emergent multi-agent behavior at multiple levels of granularity. With respect to low-level interpretability, I examine the extent to which implicit communication emerges as an aid to coordination in multi-agent populations. I introduce a novel curriculum-driven method for learning high-performing policies in difficult, sparse reward environments and show through a measure of position-based social influence that multi-agent teams that learn sophisticated coordination strategies exchange significantly more information through implicit signals than lesser-coordinated agents. Then, at a high-level, I study concept-based interpretability in the context of multi-agent learning. I propose a novel method for learning intrinsically interpretable, concept-based policies and show that it enables...", "url": "https://arxiv.org/abs/2311.01609"}, {"metadata": {"arXiv": "2311.01937", "Date": "Fri, 03 Nov 2023 14:21:39 ", "Title": "Supermind Ideator: Exploring generative AI to support creative problem-solving", "Authors": ["Steven R. Rick", "Gianni Giacomelli", "Haoran Wen", "Robert J. Laubacher", "Nancy Taubenslag", "Jennifer L. Heyman", "Max Sina Knicker", "Younes Jeddi", "Hendrik Maier", "Stephen Dwyer", "Pranav Ragupathy", "Thomas W. Malone"], "Categories": "cs.AI cs.HC", "Comments": ["7 pages", "3 figures", "working paper"]}, "abstract": "Previous efforts to support creative problem-solving have included (a) techniques (such as brainstorming and design thinking) to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. Here, we describe such a system, Supermind Ideator. The system uses a large language model (GPT 3.5) and adds prompting, fine tuning, and a user interface specifically designed to help people use creative problem-solving techniques. Some of these techniques can be applied to any problem; others are specifically intended to help generate innovative ideas about how to design groups of people and/or computers (\"superminds\"). We also describe our early experiences with using this system and suggest ways it could be extended to support additional techniques for other specific problem-solving domains.", "url": "https://arxiv.org/abs/2311.01937"}, {"metadata": {"arXiv": "2311.02018", "Date": "Fri, 03 Nov 2023 16:24:34 ", "Title": "Active Reasoning in an Open-World Environment", "Authors": ["Manjie Xu", "Guangyuan Jiang", "Wei Liang", "Chi Zhang", "Yixin Zhu"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "Recent advances in vision-language learning have achieved notable success on complete-information question-answering datasets through the integration of extensive world knowledge. Yet, most models operate passively, responding to questions based on pre-stored knowledge. In stark contrast, humans possess the ability to actively explore, accumulate, and reason using both newfound and existing information to tackle incomplete-information questions. In response to this gap, we introduce $Conan$, an interactive open-world environment devised for the assessment of active reasoning. $Conan$ facilitates active exploration and promotes multi-round abductive inference, reminiscent of rich, open-world settings like Minecraft. Diverging from previous works that lean primarily on single-round deduction via instruction following, $Conan$ compels agents to actively interact with their surroundings, amalgamating new evidence with prior knowledge to elucidate events from incomplete observations. Our analysis on $Conan$ underscores the shortcomings of contemporary state-of-the-art models in active exploration and understanding complex scenarios. Additionally, we explore Abduction from Deduction, where agents harness Bayesian rules to recast the challenge of abduction as a deductive process. Through $Conan$, we aim to galvanize advancements in active reasoning and set the stage for the next generation of artificial intelligence agents adept at dynamically engaging in environments.", "url": "https://arxiv.org/abs/2311.02018"}, {"metadata": {"arXiv": "2311.02026", "Date": "Fri, 03 Nov 2023 16:52:27 ", "Title": "APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting Stability, Transitions, and Life-Sustaining Therapies", "Authors": ["Miguel Contreras", "Brandon Silva", "Benjamin Shickel", "Tezcan Ozrazgat Baslanti", "Yuanfang Ren", "Ziyuan Guan", "Sabyasachi Bandyopadhyay", "Kia Khezeli", "Azra Bihorac", "Parisa Rashidi"], "Categories": "cs.AI"}, "abstract": "The acuity state of patients in the intensive care unit (ICU) can quickly change from stable to unstable, sometimes leading to life-threatening conditions. Early detection of deteriorating conditions can result in providing more timely interventions and improved survival rates. Current approaches rely on manual daily assessments. Some data-driven approaches have been developed, that use mortality as a proxy of acuity in the ICU. However, these methods do not integrate acuity states to determine the stability of a patient or the need for life-sustaining therapies. In this study, we propose APRICOT (Acuity Prediction in Intensive Care Unit), a Transformer-based neural network to predict acuity state in real-time in ICU patients. We develop and extensively validate externally, temporally, and prospectively the APRICOT model on three large datasets: University of Florida Health (UFH), eICU Collaborative Research Database (eICU), and Medical Information Mart for Intensive Care (MIMIC)-IV. The performance of APRICOT shows comparable results to state-of-the-art mortality prediction models (external AUROC 0.93-0.93, temporal AUROC 0.96-0.98, and prospective AUROC 0.98) as well as acuity prediction models (external AUROC 0.80-0.81, temporal AUROC 0.77-0.78, and prospective AUROC 0.87). Furthermore, APRICOT can make predictions for the need for life-sustaining therapies, showing comparable results to state-of-the-art ventilation prediction models (external AUROC 0.80-0.81, temporal AUROC 0.87-0.88, and prospective AUROC 0.85), and vasopressor prediction models (external AUROC 0.82-0.83, temporal AUROC 0.73-0.75, prospective AUROC 0.87). This tool allows for real-time acuity monitoring of a patient and can provide helpful information to clinicians to make timely interventions. Furthermore, the model can suggest life-sustaining therapies that the patient might need in the next hours in the ICU.", "url": "https://arxiv.org/abs/2311.02026"}, {"metadata": {"arXiv": "2311.01676", "Date": "Fri, 03 Nov 2023 02:52:01 ", "Title": "MineSegSAT: An automated system to evaluate mining disturbed area extents from Sentinel-2 imagery", "Authors": ["Ezra MacDonald", "Derek Jacoby", "and Yvonne Coady"], "Categories": "cs.CV cs.AI eess.IV"}, "abstract": "Assessing the environmental impact of the mineral extraction industry plays a critical role in understanding and mitigating the ecological consequences of extractive activities. This paper presents MineSegSAT, a model that presents a novel approach to predicting environmentally impacted areas of mineral extraction sites using the SegFormer deep learning segmentation architecture trained on Sentinel-2 data. The data was collected from non-overlapping regions over Western Canada in 2021 containing areas of land that have been environmentally impacted by mining activities that were identified from high-resolution satellite imagery in 2021. The SegFormer architecture, a state-of-the-art semantic segmentation framework, is employed to leverage its advanced spatial understanding capabilities for accurate land cover classification. We investigate the efficacy of loss functions including Dice, Tversky, and Lovasz loss respectively. The trained model was utilized for inference over the test region in the ensuing year to identify potential areas of expansion or contraction over these same periods. The Sentinel-2 data is made available on Amazon Web Services through a collaboration with Earth Daily Analytics which provides corrected and tiled analytics-ready data on the AWS platform. The model and ongoing API to access the data on AWS allow the creation of an automated tool to monitor the extent of disturbed areas surrounding known mining sites to ensure compliance with their environmental impact goals.", "url": "https://arxiv.org/abs/2311.01676"}, {"metadata": {"arXiv": "2311.01723", "Date": "Fri, 03 Nov 2023 05:41:25 ", "Title": "Towards Calibrated Robust Fine-Tuning of Vision-Language Models", "Authors": ["Changdae Oh", "Mijoo Kim", "Hyesu Lim", "Junhyeok Park", "Euiseog Jeong", "Zhi-Qi Cheng", "Kyungwoo Song"], "Categories": "cs.CV cs.AI", "Comments": ["Work in progress; NeurIPS 2023 Workshop on Distribution Shifts"]}, "abstract": "While fine-tuning unleashes the potential of a pre-trained model to a specific task, it trades off the model's generalization capability on out-of-distribution (OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performance on OOD datasets as well as an in-distribution (ID) dataset for which the model is being tuned. However, another criterion for reliable machine learning (ML), confidence calibration, has been overlooked despite its increasing demand for real-world high-stakes ML applications (e.g., autonomous driving and medical diagnosis). For the first time, we raise concerns about the calibration of fine-tuned vision-language models (VLMs) under distribution shift by showing that naive fine-tuning and even state-of-the-art robust fine-tuning methods hurt the calibration of pre-trained VLMs, especially on OOD datasets. To address this, we provide a simple approach, called a calibrated robust fine-tuning (CaRot) that incentivizes the calibration and robustness on both ID and OOD datasets. Empirical results on ImageNet-1K distribution shift evaluation verify the effectiveness of our method.", "url": "https://arxiv.org/abs/2311.01723"}, {"metadata": {"arXiv": "2311.01770", "Date": "Fri, 03 Nov 2023 08:11:06 ", "Title": "Modeling the Uncertainty with Maximum Discrepant Students for Semi-supervised 2D Pose Estimation", "Authors": ["Jiaqi Wu", "Junbiao Pang", "Qingming Huang"], "Categories": "cs.CV cs.AI"}, "abstract": "Semi-supervised pose estimation is a practically challenging task for computer vision. Although numerous excellent semi-supervised classification methods have emerged, these methods typically use confidence to evaluate the quality of pseudo-labels, which is difficult to achieve in pose estimation tasks. For example, in pose estimation, confidence represents only the possibility that a position of the heatmap is a keypoint, not the quality of that prediction. In this paper, we propose a simple yet efficient framework to estimate the quality of pseudo-labels in semi-supervised pose estimation tasks from the perspective of modeling the uncertainty of the pseudo-labels. Concretely, under the dual mean-teacher framework, we construct the two maximum discrepant students (MDSs) to effectively push two teachers to generate different decision boundaries for the same sample. Moreover, we create multiple uncertainties to assess the quality of the pseudo-labels. Experimental results demonstrate that our method improves the performance of semi-supervised pose estimation on three datasets.", "url": "https://arxiv.org/abs/2311.01770"}, {"metadata": {"arXiv": "2311.01811", "Date": "Fri, 03 Nov 2023 09:41:51 ", "Title": "DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder", "Authors": ["Tao Liu", "Chenpeng Du", "Shuai Fan", "Feilong Chen", "Kai Yu"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages"]}, "abstract": "Generating high-quality and person-generic visual dubbing remains a challenge. Recent innovation has seen the advent of a two-stage paradigm, decoupling the rendering and lip synchronization process facilitated by intermediate representation as a conduit. Still, previous methodologies rely on rough landmarks or are confined to a single speaker, thus limiting their performance. In this paper, we propose DiffDub: Diffusion-based dubbing. We first craft the Diffusion auto-encoder by an inpainting renderer incorporating a mask to delineate editable zones and unaltered regions. This allows for seamless filling of the lower-face region while preserving the remaining parts. Throughout our experiments, we encountered several challenges. Primarily, the semantic encoder lacks robustness, constricting its ability to capture high-level features. Besides, the modeling ignored facial positioning, causing mouth or nose jitters across frames. To tackle these issues, we employ versatile strategies, including data augmentation and supplementary eye guidance. Moreover, we encapsulated a conformer-based reference encoder and motion generator fortified by a cross-attention mechanism. This enables our model to learn person-specific textures with varying references and reduces reliance on paired audio-visual data. Our rigorous experiments comprehensively highlight that our ground-breaking approach outpaces existing methods with considerable margins and delivers seamless, intelligible videos in person-generic and multilingual scenarios.", "url": "https://arxiv.org/abs/2311.01811"}, {"metadata": {"arXiv": "2311.01961", "Date": "Fri, 03 Nov 2023 14:57:24 ", "Title": "Assessing Fidelity in XAI post-hoc techniques: A Comparative Study with Ground Truth Explanations Datasets", "Authors": ["M. Mir\\'o-Nicolau", "A. Jaume-i-Cap\\'o", "G. Moy\\`a-Alcover"], "Categories": "cs.CV cs.AI"}, "abstract": "The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI) methods to their underlying models is a challenging task, primarily due to the absence of a ground truth for explanations. However, assessing fidelity is a necessary step for ensuring a correct XAI methodology. In this study, we conduct a fair and objective comparison of the current state-of-the-art XAI methods by introducing three novel image datasets with reliable ground truth for explanations. The primary objective of this comparison is to identify methods with low fidelity and eliminate them from further research, thereby promoting the development of more trustworthy and effective XAI techniques. Our results demonstrate that XAI methods based on the backpropagation of output information to input yield higher accuracy and reliability compared to methods relying on sensitivity analysis or Class Activation Maps (CAM). However, the backpropagation method tends to generate more noisy saliency maps. These findings have significant implications for the advancement of XAI methods, enabling the elimination of erroneous explanations and fostering the development of more robust and reliable XAI.", "url": "https://arxiv.org/abs/2311.01961"}, {"metadata": {"arXiv": "2311.01534", "Date": "Thu, 02 Nov 2023 18:33:32 ", "Title": "Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version)", "Authors": ["Daniel Garces", "Sushmita Bhattacharya", "Dimitri Bertsekas", "Stephanie Gil"], "Categories": "cs.MA cs.AI cs.RO", "Comments": ["11 pages", "5 figures", "1 lemma", "and 2 theorems"]}, "abstract": "In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but follow an estimated empirical distribution. Recent theory has shown that if a base policy is stable then a rollout-based algorithm with such a base policy produces a near-optimal stable policy. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive. Large environments tend to have a large volume of requests, and hence require a large fleet of taxis to guarantee stability. In this paper, we aim to address the computational bottleneck of multiagent (one-at-a-time) rollout, where the computational complexity grows linearly in the number of agents. We propose an approximate one-at-a-time rollout-based two-phase algorithm that reduces the computational cost, while still achieving a stable near-optimal policy. Our approach partitions the graph into sectors based on the predicted demand and an user-defined maximum number of agents that can be planned for using the one-at-a-time rollout approach. The algorithm then applies instantaneous assignment (IA) for re-balancing taxis across sectors and a sector-wide one-at-a-time rollout algorithm that is executed in parallel for each sector. We characterize the number of taxis $m$ that is sufficient for IA base policy to be stable, and derive a necessary condition on $m$ as time goes to infinity. Our numerical results show that our approach achieves stability for an $m$ that satisfies the theoretical conditions. We also empirically demonstrate that our proposed two-phase algorithm has comparable performance to the one-at-a-time rollout over the entire map, but with significantly lower runtimes.", "url": "https://arxiv.org/abs/2311.01534"}, {"metadata": {"arXiv": "2311.01530", "Date": "Thu, 02 Nov 2023 18:26:28 ", "Title": "NOD-TAMP: Multi-Step Manipulation Planning with Neural Object Descriptors", "Authors": ["Shuo Cheng", "Caelan Garrett", "Ajay Mandlekar", "Danfei Xu"], "Categories": "cs.RO cs.AI"}, "abstract": "Developing intelligent robots for complex manipulation tasks in household and factory settings remains challenging due to long-horizon tasks, contact-rich manipulation, and the need to generalize across a wide variety of object shapes and scene layouts. While Task and Motion Planning (TAMP) offers a promising solution, its assumptions such as kinodynamic models limit applicability in novel contexts. Neural object descriptors (NODs) have shown promise in object and scene generalization but face limitations in addressing broader tasks. Our proposed TAMP-based framework, NOD-TAMP, extracts short manipulation trajectories from a handful of human demonstrations, adapts these trajectories using NOD features, and composes them to solve broad long-horizon tasks. Validated in a simulation environment, NOD-TAMP effectively tackles varied challenges and outperforms existing methods, establishing a cohesive framework for manipulation planning. For videos and other supplemental material, see the project website: https://sites.google.com/view/nod-tamp/.", "url": "https://arxiv.org/abs/2311.01530"}, {"metadata": {"arXiv": "2311.01540", "Date": "Thu, 02 Nov 2023 18:50:10 ", "Title": "Open-Set Object Recognition Using Mechanical Properties During Interaction", "Authors": ["Pakorn Uttayopas", "Xiaoxiao Cheng", "Etienne Burdet"], "Categories": "cs.RO cs.AI"}, "abstract": "while most of the tactile robots are operated in close-set conditions, it is challenging for them to operate in open-set conditions where test objects are beyond the robots' knowledge. We proposed an open-set recognition framework using mechanical properties to recongise known objects and incrementally label novel objects. The main contribution is a clustering algorithm that exploits knowledge of known objects to estimate cluster centre and sizes, unlike a typical algorithm that randomly selects them. The framework is validated with the mechanical properties estimated from a real object during interaction. The results show that the framework could recognise objects better than alternative methods contributed by the novelty detector. Importantly, our clustering algorithm yields better clustering performance than other methods. Furthermore, the hyperparameters studies show that cluster size is important to clustering results and needed to be tuned properly.", "url": "https://arxiv.org/abs/2311.01540"}, {"metadata": {"arXiv": "2311.01602", "Date": "Thu, 02 Nov 2023 21:17:52 ", "Title": "DRNet: A Decision-Making Method for Autonomous Lane Changingwith Deep Reinforcement Learning", "Authors": ["Kunpeng Xu", "Lifei Chen", "Shengrui Wang"], "Categories": "cs.RO cs.AI"}, "abstract": "Machine learning techniques have outperformed numerous rule-based methods for decision-making in autonomous vehicles. Despite recent efforts, lane changing remains a major challenge, due to the complex driving scenarios and changeable social behaviors of surrounding vehicles. To help improve the state of the art, we propose to leveraging the emerging \\underline{D}eep \\underline{R}einforcement learning (DRL) approach for la\\underline{NE} changing at the \\underline{T}actical level. To this end, we present \"DRNet\", a novel and highly efficient DRL-based framework that enables a DRL agent to learn to drive by executing reasonable lane changing on simulated highways with an arbitrary number of lanes, and considering driving style of surrounding vehicles to make better decisions. Furthermore, to achieve a safe policy for decision-making, DRNet incorporates ideas from safety verification, the most important component of autonomous driving, to ensure that only safe actions are chosen at any time. The setting of our state representation and reward function enables the trained agent to take appropriate actions in a real-world-like simulator. Our DRL agent has the ability to learn the desired task without causing collisions and outperforms DDQN and other baseline models.", "url": "https://arxiv.org/abs/2311.01602"}, {"metadata": {"arXiv": "2311.01939", "Date": "Fri, 03 Nov 2023 14:26:53 ", "Title": "A Quantitative Autonomy Quantification Framework for Fully Autonomous Robotic Systems", "Authors": ["Nasser Gyagenda (1) and Hubert Roth (1) ((1) University of Siegen)"], "Categories": "cs.RO cs.AI", "Comments": ["10 pages", "5 figures and 6 tables"]}, "abstract": "Although autonomous functioning facilitates deployment of robotic systems in domains that admit limited human oversight on our planet and beyond, finding correspondence between task requirements and autonomous capability is still an open challenge. Consequently, a number of methods for quantifying autonomy have been proposed over the last three decades, but to our knowledge all these have no discernment of sub-mode features of variation of autonomy and some are based on metrics that violet the Goodhart's law. This paper focuses on the full autonomous mode and proposes a task-requirements based autonomy assessment framework. The framework starts by establishing robot task characteristics from which three autonomy metrics, namely requisite capability, reliability and responsiveness, and functions for determining autonomy as a two-part measure, namely of level of autonomy and degree of autonomy are derived. These characteristics are founded on the realization that robots ultimately replace human skilled workers, to find a mapping between human job and robot task characteristics. The distinction between level and degree of autonomy stemmed from the acknowledgment that autonomy is not just a question of existence, but also one of performance of requisite capability. When continuously monitored, the proposed metrics provide a means of monitoring the integrity of a system. The framework has been demonstrated on two case studies, namely autonomous vehicle at an on-road dynamic driving task and the DARPA subT challenge rules analysis. The framework provides not only a tool for quantifying autonomy, but also a regulatory interface and common language for autonomous systems developers and users.", "url": "https://arxiv.org/abs/2311.01939"}, {"metadata": {"arXiv": "2311.01977", "Date": "Fri, 03 Nov 2023 15:31:51 ", "Title": "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches", "Authors": ["Jiayuan Gu", "Sean Kirmani", "Paul Wohlhart", "Yao Lu", "Montserrat Gonzalez Arenas", "Kanishka Rao", "Wenhao Yu", "Chuyuan Fu", "Keerthana Gopalakrishnan", "Zhuo Xu", "Priya Sundaresan", "Peng Xu", "Hao Su", "Karol Hausman", "Chelsea Finn", "Quan Vuong", "Ted Xiao"], "Categories": "cs.RO cs.AI", "Comments": ["Evaluation videos can be found at https://rt-trajectory.github.io/"]}, "abstract": "Generalization remains one of the most important desiderata for robust robot learning systems. While recently proposed approaches show promise in generalization to novel objects, semantic concepts, or visual distribution shifts, generalization to new tasks remains challenging. For example, a language-conditioned policy trained on pick-and-place tasks will not be able to generalize to a folding task, even if the arm trajectory of folding is similar to pick-and-place. Our key insight is that this kind of generalization becomes feasible if we represent the task through rough trajectory sketches. We propose a policy conditioning method using such rough trajectory sketches, which we call RT-Trajectory, that is practical, easy to specify, and allows the policy to effectively perform new tasks that would otherwise be challenging to perform. We find that trajectory sketches strike a balance between being detailed enough to express low-level motion-centric guidance while being coarse enough to allow the learned policy to interpret the trajectory sketch in the context of situational visual observations. In addition, we show how trajectory sketches can provide a useful interface to communicate with robotic policies: they can be specified through simple human inputs like drawings or videos, or through automated methods such as modern image-generating or waypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of real-world robotic tasks, and find that RT-Trajectory is able to perform a wider range of tasks compared to language-conditioned and goal-conditioned policies, when provided the same training data.", "url": "https://arxiv.org/abs/2311.01977"}, {"metadata": {"arXiv": "2311.01473", "Date": "Wed, 01 Nov 2023 06:55:09 ", "Title": "Adversarial Examples in the Physical World: A Survey", "Authors": ["Jiakai Wang", "Donghua Wang", "Jin Hu", "Siyang Wu", "Tingsong Jiang", "Wen Yao", "Aishan Liu", "Xianglong Liu"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Adversarial examples", "physical-world scenarios", "attacks and defenses"]}, "abstract": "Deep neural networks (DNNs) have demonstrated high vulnerability to adversarial examples. Besides the attacks in the digital world, the practical implications of adversarial examples in the physical world present significant challenges and safety concerns. However, current research on physical adversarial examples (PAEs) lacks a comprehensive understanding of their unique characteristics, leading to limited significance and understanding. In this paper, we address this gap by thoroughly examining the characteristics of PAEs within a practical workflow encompassing training, manufacturing, and re-sampling processes. By analyzing the links between physical adversarial attacks, we identify manufacturing and re-sampling as the primary sources of distinct attributes and particularities in PAEs. Leveraging this knowledge, we develop a comprehensive analysis and classification framework for PAEs based on their specific characteristics, covering over 100 studies on physical-world adversarial examples. Furthermore, we investigate defense strategies against PAEs and identify open challenges and opportunities for future research. We aim to provide a fresh, thorough, and systematic understanding of PAEs, thereby promoting the development of robust adversarial learning and its application in open-world scenarios.", "url": "https://arxiv.org/abs/2311.01473"}, {"metadata": {"arXiv": "2311.01573", "Date": "Thu, 02 Nov 2023 19:51:10 ", "Title": "Improving Fairness using Vision-Language Driven Image Augmentation", "Authors": ["Moreno D'Inc\\`a", "Christos Tzelepis", "Ioannis Patras", "Nicu Sebe"], "Categories": "cs.CV cs.AI cs.CY cs.LG", "Comments": ["Accepted for publication in WACV 2024"]}, "abstract": "Fairness is crucial when training a deep-learning discriminative model, especially in the facial domain. Models tend to correlate specific characteristics (such as age and skin color) with unrelated attributes (downstream tasks), resulting in biases which do not correspond to reality. It is common knowledge that these correlations are present in the data and are then transferred to the models during training. This paper proposes a method to mitigate these correlations to improve fairness. To do so, we learn interpretable and meaningful paths lying in the semantic space of a pre-trained diffusion model (DiffAE) -- such paths being supervised by contrastive text dipoles. That is, we learn to edit protected characteristics (age and skin color). These paths are then applied to augment images to improve the fairness of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on several downstream tasks with age and skin color as protected characteristics. As a proxy for fairness, we compute the difference in accuracy with respect to the protected characteristics. Quantitative results show how the augmented images help the model improve the overall accuracy, the aforementioned metric, and the disparity of equal opportunity. Code is available at: https://github.com/Moreno98/Vision-Language-Bias-Control.", "url": "https://arxiv.org/abs/2311.01573"}, {"metadata": {"arXiv": "2311.01617", "Date": "Thu, 02 Nov 2023 22:00:23 ", "Title": "Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks", "Authors": ["Rouzbeh Meshkinnejad", "Jie Mei", "Daniel Lizotte", "Yalda Mohsenzadeh"], "Categories": "cs.CV cs.AI cs.LG cs.NE"}, "abstract": "Contrastive representation learning has emerged as a promising technique for continual learning as it can learn representations that are robust to catastrophic forgetting and generalize well to unseen future tasks. Previous work in continual learning has addressed forgetting by using previous task data and trained models. Inspired by event models created and updated in the brain, we propose a new mechanism that takes place during task boundaries, i.e., when one task finishes and another starts. By observing the redundancy-inducing ability of contrastive loss on the output of a neural network, our method leverages the first few samples of the new task to identify and retain parameters contributing most to the transfer ability of the neural network, freeing up the remaining parts of the network to learn new features. We evaluate the proposed methods on benchmark computer vision datasets including CIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the task-incremental, class-incremental, and domain-incremental continual learning scenarios.", "url": "https://arxiv.org/abs/2311.01617"}, {"metadata": {"arXiv": "2311.01623", "Date": "Fri, 03 Nov 2023 16:58:10 ", "Title": "VQPy: An Object-Oriented Approach to Modern Video Analytics", "Authors": ["Shan Yu", "Zhenting Zhu", "Yu Chen", "Hanchen Xu", "Pengzhan Zhao", "Yang Wang", "Arthi Padmanabhan", "Hugo Latapie", "Harry Xu"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.", "url": "https://arxiv.org/abs/2311.01623"}, {"metadata": {"arXiv": "2311.01483", "Date": "Thu, 02 Nov 2023 14:47:06 ", "Title": "FedSN: A General Federated Learning Framework over LEO Satellite Networks", "Authors": ["Zheng Lin", "Zhe Chen", "Zihan Fang", "Xianhao Chen", "Xiong Wang", "and Yue Gao"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["14 pages", "17 figures"]}, "abstract": "Recently, a large number of Low Earth Orbit (LEO) satellites have been launched and deployed successfully in space by commercial companies, such as SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve not only for communication but also for various machine learning applications, such as space modulation recognition, remote sensing image classification, etc. However, the ground station (GS) may be incapable of downloading such a large volume of raw sensing data for centralized model training due to the limited contact time with LEO satellites (e.g. 5 minutes). Therefore, federated learning (FL) has emerged as the promising solution to address this problem via on-device training. Unfortunately, to enable FL on LEO satellites, we still face three critical challenges that are i) heterogeneous computing and memory capabilities, ii) limited uplink rate, and iii) model staleness. To this end, we propose FedSN as a general FL framework to tackle the above challenges, and fully explore data diversity on LEO satellites. Specifically, we first present a novel sub-structure scheme to enable heterogeneous local model training considering different computing, memory, and communication constraints on LEO satellites. Additionally, we propose a pseudo-synchronous model aggregation strategy to dynamically schedule model aggregation for compensating model staleness. To further demonstrate the effectiveness of the FedSN, we evaluate it using space modulation recognition and remote sensing image classification tasks by leveraging the data from real-world satellite networks. Extensive experimental results demonstrate that FedSN framework achieves higher accuracy, lower computing, and communication overhead than the state-of-the-art benchmarks and the effectiveness of each components in FedSN.", "url": "https://arxiv.org/abs/2311.01483"}, {"metadata": {"arXiv": "2311.01864", "Date": "Fri, 03 Nov 2023 12:14:26 ", "Title": "SortNet: Learning To Rank By a Neural-Based Sorting Algorithm", "Authors": ["Leonardo Rigutini", "Tiziano Papini", "Marco Maggini", "Franco Scarselli"], "Categories": "cs.LG cs.AI cs.CL cs.IR", "Comments": ["The 31st Annual International ACM SIGIR Conference (SIGIR 2008) - Workshop: Learning to Rank for Information Retrieval (LR4IR)", "Singapore", "July 20-24 2008 - ISBN:978-16-05581-64-4"], "Journal-ref": "Proceedings of The 31st Annual International ACM SIGIR Conference (SIGIR 2008) - Workshop: Learning to Rank for Information Retrieval (LR4IR)"}, "abstract": "The problem of relevance ranking consists of sorting a set of objects with respect to a given criterion. Since users may prefer different relevance criteria, the ranking algorithms should be adaptable to the user needs. Two main approaches exist in literature for the task of learning to rank: 1) a score function, learned by examples, which evaluates the properties of each object yielding an absolute relevance value that can be used to order the objects or 2) a pairwise approach, where a \"preference function\" is learned using pairs of objects to define which one has to be ranked first. In this paper, we present SortNet, an adaptive ranking algorithm which orders objects using a neural network as a comparator. The neural network training set provides examples of the desired ordering between pairs of items and it is constructed by an iterative procedure which, at each iteration, adds the most informative training examples. Moreover, the comparator adopts a connectionist architecture that is particularly suited for implementing a preference function. We also prove that such an architecture has the universal approximation property and can implement a wide class of functions. Finally, the proposed algorithm is evaluated on the LETOR dataset showing promising performances in comparison with other state of the art algorithms.", "url": "https://arxiv.org/abs/2311.01864"}, {"metadata": {"arXiv": "2311.01875", "Date": "Fri, 03 Nov 2023 12:33:18 ", "Title": "Enhancing Functional Data Analysis with Sequential Neural Networks: Advantages and Comparative Study", "Authors": ["J. Zhao", "J. Li", "M. Chen and S. Jadhav"], "Categories": "cs.LG cs.AI"}, "abstract": "Functional Data Analysis (FDA) is a statistical domain developed to handle functional data characterized by high dimensionality and complex data structures. Sequential Neural Networks (SNNs) are specialized neural networks capable of processing sequence data, a fundamental aspect of functional data. Despite their great flexibility in modeling functional data, SNNs have been inadequately employed in the FDA community. One notable advantage of SNNs is the ease of implementation, making them accessible to a broad audience beyond academia. Conversely, FDA-based methodologies present challenges, particularly for practitioners outside the field, due to their intricate complexity. In light of this, we propose utilizing SNNs in FDA applications and demonstrate their effectiveness through comparative analyses against popular FDA regression models based on numerical experiments and real-world data analysis. SNN architectures allow us to surpass the limitations of traditional FDA methods, offering scalability, flexibility, and improved analytical performance. Our findings highlight the potential of SNN-based methodologies as powerful tools for data applications involving functional data.", "url": "https://arxiv.org/abs/2311.01875"}, {"metadata": {"arXiv": "2311.01927", "Date": "Fri, 03 Nov 2023 14:08:39 ", "Title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling", "Authors": ["Tobias Katsch"], "Categories": "cs.LG cs.AI cs.CL cs.DS", "Comments": ["14 pages", "10 figures", "ICLR2024"]}, "abstract": "Linear Recurrence has proven to be a powerful tool for modeling long sequences efficiently. In this work, we show that existing models fail to take full advantage of its potential. Motivated by this finding, we develop GateLoop, a foundational sequence model that generalizes linear recurrent models such as S4, S5, LRU and RetNet, by employing data-controlled state transitions. Utilizing this theoretical advance, GateLoop empirically outperforms existing models for auto-regressive language modeling. Our method comes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \\log_{2} l)$ parallel mode making use of highly optimized associative scan implementations. Furthermore, we derive an $O(l^2)$ surrogate attention mode, revealing remarkable implications for Transformer and recently proposed architectures. Specifically, we prove that our approach can be interpreted as providing data-controlled relative-positional information to Attention. While many existing models solely rely on data-controlled cumulative sums for context aggregation, our findings suggest that incorporating data-controlled complex cumulative products may be a crucial step towards more powerful sequence models.", "url": "https://arxiv.org/abs/2311.01927"}, {"metadata": {"arXiv": "2311.02013", "Date": "Fri, 03 Nov 2023 16:19:33 ", "Title": "Score Models for Offline Goal-Conditioned Reinforcement Learning", "Authors": ["Harshit Sikchi", "Rohan Chitnis", "Ahmed Touati", "Alborz Geramifard", "Amy Zhang", "Scott Niekum"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Preprint"]}, "abstract": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. SMORe learns scores or unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. SMORe is principled and our extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations, show that SMORe can outperform state-of-the-art baselines by a significant margin.", "url": "https://arxiv.org/abs/2311.02013"}, {"metadata": {"arXiv": "2311.02017", "Date": "Fri, 03 Nov 2023 16:23:22 ", "Title": "DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network for Food Deliveries", "Authors": ["Ashman Mehra", "Snehanshu Saha", "Vaskar Raychoudhury", "Archana Mathur"], "Categories": "cs.LG cs.AI"}, "abstract": "Delivery of items from the producer to the consumer has experienced significant growth over the past decade and has been greatly fueled by the recent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are rapidly growing and are sharing the same business model of consumer items or food delivery. Existing food delivery methods are sub-optimal because each delivery is individually optimized to go directly from the producer to the consumer via the shortest time path. We observe a significant scope for reducing the costs associated with completing deliveries under the current model. We model our food delivery problem as a multi-objective optimization, where consumer satisfaction and delivery costs, both, need to be optimized. Taking inspiration from the success of ride-sharing in the taxi industry, we propose DeliverAI - a reinforcement learning-based path-sharing algorithm. Unlike previous attempts for path-sharing, DeliverAI can provide real-time, time-efficient decision-making using a Reinforcement learning-enabled agent system. Our novel agent interaction scheme leverages path-sharing among deliveries to reduce the total distance traveled while keeping the delivery completion time under check. We generate and test our methodology vigorously on a simulation setup using real data from the city of Chicago. Our results show that DeliverAI can reduce the delivery fleet size by 12\\%, the distance traveled by 13%, and achieve 50% higher fleet utilization compared to the baselines.", "url": "https://arxiv.org/abs/2311.02017"}, {"metadata": {"arXiv": "2311.01753", "Date": "Fri, 03 Nov 2023 07:18:36 ", "Title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization", "Authors": ["Siqi Shen", "Chennan Ma", "Chao Li", "Weiquan Liu", "Yongquan Fu", "Songzhu Mei", "Xinwang Liu", "Cheng Wang"], "Categories": "cs.MA cs.AI cs.LG", "Comments": ["NeurIPS 2023 submission version: https://openreview.net/forum?id=FskZtRvMJI"]}, "abstract": "Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeling quantiles of it as weighted quantile mixtures of per-agent return distribution utilities. RiskQ satisfies the RIGM principle for the VaR and distorted risk metrics. We show that RiskQ can obtain promising performance through extensive experiments. The source code of RiskQ is available in https://github.com/xmu-rl-3dv/RiskQ.", "url": "https://arxiv.org/abs/2311.01753"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

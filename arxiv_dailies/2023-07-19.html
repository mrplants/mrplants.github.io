<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.08880", "Date": "Mon, 17 Jul 2023 22:28:16 ", "Title": "Modular Neural Network Approaches for Surgical Image Recognition", "Authors": ["Nosseiba Ben Salem", "Younes Bennani", "Joseph Karkazan", "Abir Barbara", "Charles Dacheux", "Thomas Gregory"], "Categories": "cs.CV cs.LG"}, "abstract": "Deep learning-based applications have seen a lot of success in recent years. Text, audio, image, and video have all been explored with great success using deep learning approaches. The use of convolutional neural networks (CNN) in computer vision, in particular, has yielded reliable results. In order to achieve these results, a large amount of data is required. However, the dataset cannot always be accessible. Moreover, annotating data can be difficult and time-consuming. Self-training is a semi-supervised approach that managed to alleviate this problem and achieve state-of-the-art performances. Theoretical analysis even proved that it may result in a better generalization than a normal classifier. Another problem neural networks can face is the increasing complexity of modern problems, requiring a high computational and storage cost. One way to mitigate this issue, a strategy that has been inspired by human cognition known as modular learning, can be employed. The principle of the approach is to decompose a complex problem into simpler sub-tasks. This approach has several advantages, including faster learning, better generalization, and enables interpretability. In the first part of this paper, we introduce and evaluate different architectures of modular learning for Dorsal Capsulo-Scapholunate Septum (DCSS) instability classification. Our experiments have shown that modular learning improves performances compared to non-modular systems. Moreover, we found that weighted modular, that is to weight the output using the probabilities from the gating module, achieved an almost perfect classification. In the second part, we present our approach for data labeling and segmentation with self-training applied on shoulder arthroscopy images.", "url": "https://arxiv.org/abs/2307.08880"}, {"metadata": {"arXiv": "2307.08919", "Date": "Tue, 18 Jul 2023 01:31:47 ", "Title": "Accuracy versus time frontiers of semi-supervised and self-supervised learning on medical images", "Authors": ["Zhe Huang", "Ruijie Jiang", "Shuchin Aeron", "and Michael C. Hughes"], "Categories": "cs.CV cs.LG", "Comments": ["Semi-supervised Learning; Self-supervised Learning; Medical Imaging"]}, "abstract": "For many applications of classifiers to medical images, a trustworthy label for each image can be difficult or expensive to obtain. In contrast, images without labels are more readily available. Two major research directions both promise that additional unlabeled data can improve classifier performance: self-supervised learning pretrains useful representations on unlabeled data only, then fine-tunes a classifier on these representations via the labeled set; semi-supervised learning directly trains a classifier on labeled and unlabeled data simultaneously. Recent methods from both directions have claimed significant gains on non-medical tasks, but do not systematically assess medical images and mostly compare only to methods in the same direction. This study contributes a carefully-designed benchmark to help answer a practitioner's key question: given a small labeled dataset and a limited budget of hours to spend on training, what gains from additional unlabeled images are possible and which methods best achieve them? Unlike previous benchmarks, ours uses realistic-sized validation sets to select hyperparameters, assesses runtime-performance tradeoffs, and bridges two research fields. By comparing 6 semi-supervised methods and 5 self-supervised methods to strong labeled-only baselines on 3 medical datasets with 30-1000 labels per class, we offer insights to resource-constrained, results-focused practitioners: MixMatch, SimCLR, and BYOL represent strong choices that were not surpassed by more recent methods. After much effort selecting hyperparameters on one dataset, we publish settings that enable strong methods to perform well on new medical tasks within a few hours, with further search over dozens of hours delivering modest additional gains.", "url": "https://arxiv.org/abs/2307.08919"}, {"metadata": {"arXiv": "2307.09065", "Date": "Tue, 18 Jul 2023 08:37:25 ", "Title": "Learning Adaptive Neighborhoods for Graph Neural Networks", "Authors": ["Avishkar Saha", "Oscar Mendez", "Chris Russell", "Richard Bowden"], "Categories": "cs.CV cs.LG", "Comments": ["ICCV 2023"]}, "abstract": "Graph convolutional networks (GCNs) enable end-to-end learning on graph structured data. However, many works assume a given graph structure. When the input graph is noisy or unavailable, one approach is to construct or learn a latent graph structure. These methods typically fix the choice of node degree for the entire graph, which is suboptimal. Instead, we propose a novel end-to-end differentiable graph generator which builds graph topologies where each node selects both its neighborhood and its size. Our module can be readily integrated into existing pipelines involving graph convolution operations, replacing the predetermined or existing adjacency matrix with one that is learned, and optimized, as part of the general objective. As such it is applicable to any GCN. We integrate our module into trajectory prediction, point cloud classification and node classification pipelines resulting in improved accuracy over other structure-learning methods across a wide range of datasets and GCN backbones.", "url": "https://arxiv.org/abs/2307.09065"}, {"metadata": {"arXiv": "2307.09143", "Date": "Tue, 18 Jul 2023 10:52:24 ", "Title": "MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset, Methods, and Results", "Authors": ["Yuki Kondo", "Norimichi Ukita", "Takayuki Yamaguchi", "Hao-Yu Hou", "Mu-Yi Shen", "Chia-Chi Hsu", "En-Ming Huang", "Yu-Chen Huang", "Yu-Cheng Xia", "Chien-Yao Wang", "Chun-Yi Lee", "Da Huo", "Marc A. Kastner", "Tingwei Liu", "Yasutomo Kawanishi", "Takatsugu Hirayama", "Takahiro Komamizu", "Ichiro Ide", "Yosuke Shinya", "Xinyao Liu", "Guang Liang", "Syusuke Yasui"], "Categories": "cs.CV cs.LG", "Comments": ["This paper is included in the proceedings of the 18th International Conference on Machine Vision Applications (MVA2023). It will be officially published at a later date. Project page : https://www.mva-org.jp/mva2023/challenge"]}, "abstract": "Small Object Detection (SOD) is an important machine vision topic because (i) a variety of real-world applications require object detection for distant objects and (ii) SOD is a challenging task due to the noisy, blurred, and less-informative image appearances of small objects. This paper proposes a new SOD dataset consisting of 39,070 images including 137,121 bird instances, which is called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The detail of the challenge with the SOD4SB dataset is introduced in this paper. In total, 223 participants joined this challenge. This paper briefly introduces the award-winning methods. The dataset, the baseline code, and the website for evaluation on the public testset are publicly available.", "url": "https://arxiv.org/abs/2307.09143"}, {"metadata": {"arXiv": "2307.09238", "Date": "Tue, 18 Jul 2023 13:18:52 ", "Title": "Fusing Hand and Body Skeletons for Human Action Recognition in Assembly", "Authors": ["Dustin Aganian", "Mona K\\\"ohler", "Benedict Stephan", "Markus Eisenbach", "Horst-Michael Gross"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["International Conference on Artificial Neural Networks (ICANN) 2023"]}, "abstract": "As collaborative robots (cobots) continue to gain popularity in industrial manufacturing, effective human-robot collaboration becomes crucial. Cobots should be able to recognize human actions to assist with assembly tasks and act autonomously. To achieve this, skeleton-based approaches are often used due to their ability to generalize across various people and environments. Although body skeleton approaches are widely used for action recognition, they may not be accurate enough for assembly actions where the worker's fingers and hands play a significant role. To address this limitation, we propose a method in which less detailed body skeletons are combined with highly detailed hand skeletons. We investigate CNNs and transformers, the latter of which are particularly adept at extracting and combining important information from both skeleton types using attention. This paper demonstrates the effectiveness of our proposed approach in enhancing action recognition in assembly scenarios.", "url": "https://arxiv.org/abs/2307.09238"}, {"metadata": {"arXiv": "2307.09306", "Date": "Tue, 18 Jul 2023 14:52:08 ", "Title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting", "Authors": ["Inhwan Bae", "Jean Oh", "Hae-Gon Jeon"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["Accepted at ICCV 2023"]}, "abstract": "Capturing high-dimensional social interactions and feasible futures is essential for predicting trajectories. To address this complex nature, several attempts have been devoted to reducing the dimensionality of the output variables via parametric curve fitting such as the B\\'ezier curve and B-spline function. However, these functions, which originate in computer graphics fields, are not suitable to account for socially acceptable human dynamics. In this paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction approach that uses a novel trajectory descriptor to form a compact space, known here as $\\mathbb{ET}$ space, in place of Euclidean space, for representing pedestrian movements. We first reduce the complexity of the trajectory descriptor via a low-rank approximation. We transform the pedestrians' history paths into our $\\mathbb{ET}$ space represented by spatio-temporal principle components, and feed them into off-the-shelf trajectory forecasting models. The inputs and outputs of the models as well as social interactions are all gathered and aggregated in the corresponding $\\mathbb{ET}$ space. Lastly, we propose a trajectory anchor-based refinement method to cover all possible futures in the proposed $\\mathbb{ET}$ space. Extensive experiments demonstrate that our EigenTrajectory predictor can significantly improve both the prediction accuracy and reliability of existing trajectory forecasting models on public benchmarks, indicating that the proposed descriptor is suited to represent pedestrian behaviors. Code is publicly available at https://github.com/inhwanbae/EigenTrajectory .", "url": "https://arxiv.org/abs/2307.09306"}, {"metadata": {"arXiv": "2307.08949", "Date": "Tue, 18 Jul 2023 03:34:33 ", "Title": "Alioth: A Machine Learning Based Interference-Aware Performance Monitor for Multi-Tenancy Applications in Public Cloud", "Authors": ["Tianyao Shi", "Yingxuan Yang", "Yunlong Cheng", "Xiaofeng Gao", "Zhen Fang", "Yongqiang Yang"], "Categories": "cs.DC cs.LG cs.PF", "Comments": ["Accepted by 2023 IEEE International Parallel & Distributed Processing Symposium (IPDPS)"]}, "abstract": "Multi-tenancy in public clouds may lead to co-location interference on shared resources, which possibly results in performance degradation of cloud applications. Cloud providers want to know when such events happen and how serious the degradation is, to perform interference-aware migrations and alleviate the problem. However, virtual machines (VM) in Infrastructure-as-a-Service public clouds are black-boxes to providers, where application-level performance information cannot be acquired. This makes performance monitoring intensely challenging as cloud providers can only rely on low-level metrics such as CPU usage and hardware counters. We propose a novel machine learning framework, Alioth, to monitor the performance degradation of cloud applications. To feed the data-hungry models, we first elaborate interference generators and conduct comprehensive co-location experiments on a testbed to build Alioth-dataset which reflects the complexity and dynamicity in real-world scenarios. Then we construct Alioth by (1) augmenting features via recovering low-level metrics under no interference using denoising auto-encoders, (2) devising a transfer learning model based on domain adaptation neural network to make models generalize on test cases unseen in offline training, and (3) developing a SHAP explainer to automate feature selection and enhance model interpretability. Experiments show that Alioth achieves an average mean absolute error of 5.29% offline and 10.8% when testing on applications unseen in the training stage, outperforming the baseline methods. Alioth is also robust in signaling quality-of-service violation under dynamicity. Finally, we demonstrate a possible application of Alioth's interpretability, providing insights to benefit the decision-making of cloud operators. The dataset and code of Alioth have been released on GitHub.", "url": "https://arxiv.org/abs/2307.08949"}, {"metadata": {"arXiv": "2307.09263", "Date": "Tue, 18 Jul 2023 13:48:05 ", "Title": "Mobility-Aware Joint User Scheduling and Resource Allocation for Low Latency Federated Learning", "Authors": ["Kecheng Fan", "Wen Chen", "Jun Li", "Xiumei Deng", "Xuefeng Han and Ming Ding"], "Categories": "cs.DC cs.LG"}, "abstract": "As an efficient distributed machine learning approach, Federated learning (FL) can obtain a shared model by iterative local model training at the user side and global model aggregating at the central server side, thereby protecting privacy of users. Mobile users in FL systems typically communicate with base stations (BSs) via wireless channels, where training performance could be degraded due to unreliable access caused by user mobility. However, existing work only investigates a static scenario or random initialization of user locations, which fail to capture mobility in real-world networks. To tackle this issue, we propose a practical model for user mobility in FL across multiple BSs, and develop a user scheduling and resource allocation method to minimize the training delay with constrained communication resources. Specifically, we first formulate an optimization problem with user mobility that jointly considers user selection, BS assignment to users, and bandwidth allocation to minimize the latency in each communication round. This optimization problem turned out to be NP-hard and we proposed a delay-aware greedy search algorithm (DAGSA) to solve it. Simulation results show that the proposed algorithm achieves better performance than the state-of-the-art baselines and a certain level of user mobility could improve training performance.", "url": "https://arxiv.org/abs/2307.09263"}, {"metadata": {"arXiv": "2307.09470", "Date": "Thu, 13 Jul 2023 19:05:11 ", "Title": "Multi-Player Zero-Sum Markov Games with Networked Separable Interactions", "Authors": ["Chanwoo Park", "Kaiqing Zhang", "Asuman Ozdaglar"], "Categories": "cs.GT cs.LG", "Comments": ["61 pages"]}, "abstract": "We study a new class of Markov games (MGs), \\textit{Multi-player Zero-sum Markov Games} with {\\it Networked separable interactions} (MZNMGs), to model the local interaction structure in non-cooperative multi-agent sequential decision-making. We define an MZNMG as a model where {the payoffs of the auxiliary games associated with each state are zero-sum and} have some separable (i.e., polymatrix) structure across the neighbors over some interaction network. We first identify the necessary and sufficient conditions under which an MG can be presented as an MZNMG, and show that the set of Markov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash equilibrium (NE) in these games, in that the {product of} per-state marginalization of the former for all players yields the latter. Furthermore, we show that finding approximate Markov \\emph{stationary} CCE in infinite-horizon discounted MZNMGs is \\texttt{PPAD}-hard, unless the underlying network has a ``star topology''. Then, we propose fictitious-play-type dynamics, the classical learning dynamics in normal-form games, for MZNMGs, and establish convergence guarantees to Markov stationary NE under a star-shaped network structure. Finally, in light of the hardness result, we focus on computing a Markov \\emph{non-stationary} NE and provide finite-iteration guarantees for a series of value-iteration-based algorithms. We also provide numerical experiments to corroborate our theoretical results.", "url": "https://arxiv.org/abs/2307.09470"}, {"metadata": {"arXiv": "2307.09478", "Date": "Fri, 14 Jul 2023 09:16:24 ", "Title": "The Role of Transparency in Repeated First-Price Auctions with Unknown Valuations", "Authors": ["Nicol\\`o Cesa-Bianchi", "Tommaso Cesari", "Roberto Colomboni", "Federico Fusco", "and Stefano Leonardi"], "Categories": "cs.GT cs.DS cs.LG"}, "abstract": "We study the problem of regret minimization for a single bidder in a sequence of first-price auctions where the bidder knows the item's value only if the auction is won. Our main contribution is a complete characterization, up to logarithmic factors, of the minimax regret in terms of the auction's transparency, which regulates the amount of information on competing bids disclosed by the auctioneer at the end of each auction. Our results hold under different assumptions (stochastic, adversarial, and their smoothed variants) on the environment generating the bidder's valuations and competing bids. These minimax rates reveal how the interplay between transparency and the nature of the environment affects how fast one can learn to bid optimally in first-price auctions.", "url": "https://arxiv.org/abs/2307.09478"}, {"metadata": {"arXiv": "2307.08712", "Date": "Sat, 15 Jul 2023 14:36:29 ", "Title": "Machine Learning Meets Mental Training -- A Proof of Concept Applied to Memory Sports", "Authors": ["Emanuele Regnani"], "Categories": "cs.LG", "Comments": ["75 pages", "47 figures", "2 tables", "26 code excerpts"]}, "abstract": "This work aims to combine these two fields together by presenting a practical implementation of machine learning to the particular form of mental training that is the art of memory, taken in its competitive version called \"Memory Sports\". Such a fusion, on the one hand, strives to raise awareness about both realms, while on the other it seeks to encourage research in this mixed field as a way to, ultimately, drive forward the development of this seemingly underestimated sport.", "url": "https://arxiv.org/abs/2307.08712"}, {"metadata": {"arXiv": "2307.08713", "Date": "Sat, 15 Jul 2023 21:40:36 ", "Title": "Intuitionistic Fuzzy Broad Learning System: Enhancing Robustness Against Noise and Outliers", "Authors": ["M. Sajid", "A.K. Malik", "M. Tanveer"], "Categories": "cs.LG"}, "abstract": "In the realm of data classification, broad learning system (BLS) has proven to be a potent tool that utilizes a layer-by-layer feed-forward neural network. It consists of feature learning and enhancement segments, working together to extract intricate features from input data. The traditional BLS treats all samples as equally significant, which makes it less robust and less effective for real-world datasets with noises and outliers. To address this issue, we propose the fuzzy BLS (F-BLS) model, which assigns a fuzzy membership value to each training point to reduce the influence of noises and outliers. In assigning the membership value, the F-BLS model solely considers the distance from samples to the class center in the original feature space without incorporating the extent of non-belongingness to a class. We further propose a novel BLS based on intuitionistic fuzzy theory (IF-BLS). The proposed IF-BLS utilizes intuitionistic fuzzy numbers based on fuzzy membership and non-membership values to assign scores to training points in the high-dimensional feature space by using a kernel function. We evaluate the performance of proposed F-BLS and IF-BLS models on 44 UCI benchmark datasets across diverse domains. Furthermore, Gaussian noise is added to some UCI datasets to assess the robustness of the proposed F-BLS and IF-BLS models. Experimental results demonstrate superior generalization performance of the proposed F-BLS and IF-BLS models compared to baseline models, both with and without Gaussian noise. Additionally, we implement the proposed F-BLS and IF-BLS models on the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset, and promising results showcase the models effectiveness in real-world applications. The proposed methods offer a promising solution to enhance the BLS frameworks ability to handle noise and outliers.", "url": "https://arxiv.org/abs/2307.08713"}, {"metadata": {"arXiv": "2307.08722", "Date": "Mon, 17 Jul 2023 07:09:55 ", "Title": "Certifying the Fairness of KNN in the Presence of Dataset Bias", "Authors": ["Yannan Li", "Jingbo Wang", "and Chao Wang"], "Categories": "cs.LG cs.CY cs.SE"}, "abstract": "We propose a method for certifying the fairness of the classification result of a widely used supervised learning algorithm, the k-nearest neighbors (KNN), under the assumption that the training data may have historical bias caused by systematic mislabeling of samples from a protected minority group. To the best of our knowledge, this is the first certification method for KNN based on three variants of the fairness definition: individual fairness, $\\epsilon$-fairness, and label-flipping fairness. We first define the fairness certification problem for KNN and then propose sound approximations of the complex arithmetic computations used in the state-of-the-art KNN algorithm. This is meant to lift the computation results from the concrete domain to an abstract domain, to reduce the computational cost. We show effectiveness of this abstract interpretation based technique through experimental evaluation on six datasets widely used in the fairness research literature. We also show that the method is accurate enough to obtain fairness certifications for a large number of test inputs, despite the presence of historical bias in the datasets.", "url": "https://arxiv.org/abs/2307.08722"}, {"metadata": {"arXiv": "2307.08782", "Date": "Thu, 13 Jul 2023 22:14:30 ", "Title": "Unsupervised Learning of Distributional Properties can Supplement Human Labeling and Increase Active Learning Efficiency in Anomaly Detection", "Authors": ["Jaturong Kongmanee", "Mark Chignell", "Khilan Jerath", "Abhay Raman"], "Categories": "cs.LG"}, "abstract": "Exfiltration of data via email is a serious cybersecurity threat for many organizations. Detecting data exfiltration (anomaly) patterns typically requires labeling, most often done by a human annotator, to reduce the high number of false alarms. Active Learning (AL) is a promising approach for labeling data efficiently, but it needs to choose an efficient order in which cases are to be labeled, and there are uncertainties as to what scoring procedure should be used to prioritize cases for labeling, especially when detecting rare cases of interest is crucial. We propose an adaptive AL sampling strategy that leverages the underlying prior data distribution, as well as model uncertainty, to produce batches of cases to be labeled that contain instances of rare anomalies. We show that (1) the classifier benefits from a batch of representative and informative instances of both normal and anomalous examples, (2) unsupervised anomaly detection plays a useful role in building the classifier in the early stages of training when relatively little labeling has been done thus far. Our approach to AL for anomaly detection outperformed existing AL approaches on three highly unbalanced UCI benchmarks and on one real-world redacted email data set.", "url": "https://arxiv.org/abs/2307.08782"}, {"metadata": {"arXiv": "2307.08796", "Date": "Mon, 17 Jul 2023 19:27:32 ", "Title": "Classification with Incoherent Kernel Dictionary Learning", "Authors": ["Denis C. Ilie-Ablachim", "Bogdan Dumitrescu"], "Categories": "cs.LG eess.SP", "Journal-ref": "In 2021 23rd International Conference on Control Systems and Computer Science (CSCS), pp. 106-111. IEEE, 2021"}, "abstract": "In this paper we present a new classification method based on Dictionary Learning (DL). The main contribution consists of a kernel version of incoherent DL, derived from its standard linear counterpart. We also propose an improvement of the AK-SVD algorithm concerning the representation update. Our algorithms are tested on several popular databases of classification problems.", "url": "https://arxiv.org/abs/2307.08796"}, {"metadata": {"arXiv": "2307.08801", "Date": "Mon, 17 Jul 2023 19:34:59 ", "Title": "Towards Automated Design of Riboswitches", "Authors": ["Frederic Runge", "J\\\"org K. H. Franke", "Frank Hutter"], "Categories": "cs.LG q-bio.GN", "Comments": ["9 pages", "Accepted at the 2023 ICML Workshop on Computational Biology"]}, "abstract": "Experimental screening and selection pipelines for the discovery of novel riboswitches are expensive, time-consuming, and inefficient. Using computational methods to reduce the number of candidates for the screen could drastically decrease these costs. However, existing computational approaches do not fully satisfy all requirements for the design of such initial screening libraries. In this work, we present a new method, libLEARNA, capable of providing RNA focus libraries of diverse variable-length qualified candidates. Our novel structure-based design approach considers global properties as well as desired sequence and structure features. We demonstrate the benefits of our method by designing theophylline riboswitch libraries, following a previously published protocol, and yielding 30% more unique high-quality candidates.", "url": "https://arxiv.org/abs/2307.08801"}, {"metadata": {"arXiv": "2307.08807", "Date": "Mon, 17 Jul 2023 19:44:52 ", "Title": "Anomaly Detection with Selective Dictionary Learning", "Authors": ["Denis C. Ilie-Ablachim", "Bogdan Dumitrescu"], "Categories": "cs.LG", "Journal-ref": "In 2022 8th International Conference on Control, Decision and Information Technologies (CoDIT), vol. 1, pp. 255-260. IEEE, 2022"}, "abstract": "In this paper we present new methods of anomaly detection based on Dictionary Learning (DL) and Kernel Dictionary Learning (KDL). The main contribution consists in the adaption of known DL and KDL algorithms in the form of unsupervised methods, used for outlier detection. We propose a reduced kernel version (RKDL), which is useful for problems with large data sets, due to the large kernel matrix. We also improve the DL and RKDL methods by the use of a random selection of signals, which aims to eliminate the outliers from the training procedure. All our algorithms are introduced in an anomaly detection toolbox and are compared to standard benchmark results.", "url": "https://arxiv.org/abs/2307.08807"}, {"metadata": {"arXiv": "2307.08811", "Date": "Mon, 17 Jul 2023 19:57:10 ", "Title": "DeepMem: ML Models as storage channels and their (mis-)applications", "Authors": ["Md Abdullah Al Mamun", "Quazi Mishkatul Alam", "Erfan Shaigani", "Pedram Zaree", "Ihsen Alouani", "Nael Abu-Ghazaleh"], "Categories": "cs.LG cs.IT math.IT"}, "abstract": "Machine learning (ML) models are overparameterized to support generality and avoid overfitting. Prior works have shown that these additional parameters can be used for both malicious (e.g., hiding a model covertly within a trained model) and beneficial purposes (e.g., watermarking a model). In this paper, we propose a novel information theoretic perspective of the problem; we consider the ML model as a storage channel with a capacity that increases with overparameterization. Specifically, we consider a sender that embeds arbitrary information in the model at training time, which can be extracted by a receiver with a black-box access to the deployed model. We derive an upper bound on the capacity of the channel based on the number of available parameters. We then explore black-box write and read primitives that allow the attacker to: (i) store data in an optimized way within the model by augmenting the training data at the transmitter side, and (ii) to read it by querying the model after it is deployed. We also analyze the detectability of the writing primitive and consider a new version of the problem which takes information storage covertness into account. Specifically, to obtain storage covertness, we introduce a new constraint such that the data augmentation used for the write primitives minimizes the distribution shift with the initial (baseline task) distribution. This constraint introduces a level of \"interference\" with the initial task, thereby limiting the channel's effective capacity. Therefore, we develop optimizations to improve the capacity in this case, including a novel ML-specific substitution based error correction protocol. We believe that the proposed modeling of the problem offers new tools to better understand and mitigate potential vulnerabilities of ML, especially in the context of increasingly large models.", "url": "https://arxiv.org/abs/2307.08811"}, {"metadata": {"arXiv": "2307.08840", "Date": "Mon, 17 Jul 2023 20:59:50 ", "Title": "Bayesian Safe Policy Learning with Chance Constrained Optimization: Application to Military Security Assessment during the Vietnam War", "Authors": ["Zeyang Jia", "Eli Ben-Michael and Kosuke Imai"], "Categories": "cs.LG stat.AP", "Comments": ["40 pages", "19 figures"]}, "abstract": "Algorithmic and data-driven decisions and recommendations are commonly used in high-stakes decision-making settings such as criminal justice, medicine, and public policy. We investigate whether it would have been possible to improve a security assessment algorithm employed during the Vietnam War, using outcomes measured immediately after its introduction in late 1969. This empirical application raises several methodological challenges that frequently arise in high-stakes algorithmic decision-making. First, before implementing a new algorithm, it is essential to characterize and control the risk of yielding worse outcomes than the existing algorithm. Second, the existing algorithm is deterministic, and learning a new algorithm requires transparent extrapolation. Third, the existing algorithm involves discrete decision tables that are common but difficult to optimize over. To address these challenges, we introduce the Average Conditional Risk (ACRisk), which first quantifies the risk that a new algorithmic policy leads to worse outcomes for subgroups of individual units and then averages this over the distribution of subgroups. We also propose a Bayesian policy learning framework that maximizes the posterior expected value while controlling the posterior expected ACRisk. This framework separates the estimation of heterogeneous treatment effects from policy optimization, enabling flexible estimation of effects and optimization over complex policy classes. We characterize the resulting chance-constrained optimization problem as a constrained linear programming problem. Our analysis shows that compared to the actual algorithm used during the Vietnam War, the learned algorithm assesses most regions as more secure and emphasizes economic and political factors over military factors.", "url": "https://arxiv.org/abs/2307.08840"}, {"metadata": {"arXiv": "2307.08847", "Date": "Mon, 17 Jul 2023 21:19:08 ", "Title": "Privacy-preserving patient clustering for personalized federated learning", "Authors": ["Ahmed Elhussein and Gamze Gursoy"], "Categories": "cs.LG cs.CR"}, "abstract": "Federated Learning (FL) is a machine learning framework that enables multiple organizations to train a model without sharing their data with a central server. However, it experiences significant performance degradation if the data is non-identically independently distributed (non-IID). This is a problem in medical settings, where variations in the patient population contribute significantly to distribution differences across hospitals. Personalized FL addresses this issue by accounting for site-specific distribution differences. Clustered FL, a Personalized FL variant, was used to address this problem by clustering patients into groups across hospitals and training separate models on each group. However, privacy concerns remained as a challenge as the clustering process requires exchange of patient-level information. This was previously solved by forming clusters using aggregated data, which led to inaccurate groups and performance degradation. In this study, we propose Privacy-preserving Community-Based Federated machine Learning (PCBFL), a novel Clustered FL framework that can cluster patients using patient-level data while protecting privacy. PCBFL uses Secure Multiparty Computation, a cryptographic technique, to securely calculate patient-level similarity scores across hospitals. We then evaluate PCBFL by training a federated mortality prediction model using 20 sites from the eICU dataset. We compare the performance gain from PCBFL against traditional and existing Clustered FL frameworks. Our results show that PCBFL successfully forms clinically meaningful cohorts of low, medium, and high-risk patients. PCBFL outperforms traditional and existing Clustered FL frameworks with an average AUC improvement of 4.3% and AUPRC improvement of 7.8%.", "url": "https://arxiv.org/abs/2307.08847"}, {"metadata": {"arXiv": "2307.08863", "Date": "Mon, 17 Jul 2023 21:40:57 ", "Title": "Meta-Value Learning: a General Framework for Learning with Learning Awareness", "Authors": ["Tim Cooijmans", "Milad Aghajohari", "Aaron Courville"], "Categories": "cs.LG cs.MA", "Comments": ["Submitted to NeurIPS 2023"]}, "abstract": "Gradient-based learning in multi-agent systems is difficult because the gradient derives from a first-order model which does not account for the interaction between agents' learning processes. LOLA (arXiv:1709.04326) accounts for this by differentiating through one step of optimization. We extend the ideas of LOLA and develop a fully-general value-based approach to optimization. At the core is a function we call the meta-value, which at each point in joint-policy space gives for each agent a discounted sum of its objective over future optimization steps. We argue that the gradient of the meta-value gives a more reliable improvement direction than the gradient of the original objective, because the meta-value derives from empirical observations of the effects of optimization. We show how the meta-value can be approximated by training a neural network to minimize TD error along optimization trajectories in which agents follow the gradient of the meta-value. We analyze the behavior of our method on the Logistic Game and on the Iterated Prisoner's Dilemma.", "url": "https://arxiv.org/abs/2307.08863"}, {"metadata": {"arXiv": "2307.08874", "Date": "Mon, 17 Jul 2023 22:09:12 ", "Title": "Latent Space Representations of Neural Algorithmic Reasoners", "Authors": ["Vladimir V. Mirjani\\'c (1)", "Razvan Pascanu (2)", "Petar Veli\\v{c}kovi\\'c (1 and 2) ((1) University of Cambridge", "(2) Google DeepMind)"], "Categories": "cs.LG stat.ML", "Comments": ["18 pages", "17 figures", "accepted at KLR Workshop at ICML 2023"]}, "abstract": "Neural Algorithmic Reasoning (NAR) is a research area focused on designing neural architectures that can reliably capture classical computation, usually by learning to execute algorithms. A typical approach is to rely on Graph Neural Network (GNN) architectures, which encode inputs in high-dimensional latent spaces that are repeatedly transformed during the execution of the algorithm. In this work we perform a detailed analysis of the structure of the latent space induced by the GNN when executing algorithms. We identify two possible failure modes: (i) loss of resolution, making it hard to distinguish similar values; (ii) inability to deal with values outside the range observed during training. We propose to solve the first issue by relying on a softmax aggregator, and propose to decay the latent space in order to deal with out-of-range values. We show that these changes lead to improvements on the majority of algorithms in the standard CLRS-30 benchmark when using the state-of-the-art Triplet-GMPNN processor. Our code is available at \\href{https://github.com/mirjanic/nar-latent-spaces}{https://github.com/mirjanic/nar-latent-spaces}.", "url": "https://arxiv.org/abs/2307.08874"}, {"metadata": {"arXiv": "2307.08875", "Date": "Mon, 17 Jul 2023 22:10:20 ", "Title": "Natural Actor-Critic for Robust Reinforcement Learning with Function Approximation", "Authors": ["Ruida Zhou", "Tao Liu", "Min Cheng", "Dileep Kalathil", "P. R. Kumar", "Chao Tian"], "Categories": "cs.LG cs.RO math.OC"}, "abstract": "We study robust reinforcement learning (RL) with the goal of determining a well-performing policy that is robust against model mismatch between the training simulator and the testing environment. Previous policy-based robust RL algorithms mainly focus on the tabular setting under uncertainty sets that facilitate robust policy evaluation, but are no longer tractable when the number of states scales up. To this end, we propose two novel uncertainty set formulations, one based on double sampling and the other on an integral probability metric. Both make large-scale robust RL tractable even when one only has access to a simulator. We propose a robust natural actor-critic (RNAC) approach that incorporates the new uncertainty sets and employs function approximation. We provide finite-time convergence guarantees for the proposed RNAC algorithm to the optimal robust policy within the function approximation error. Finally, we demonstrate the robust performance of the policy learned by our proposed RNAC approach in multiple MuJoCo environments and a real-world TurtleBot navigation task.", "url": "https://arxiv.org/abs/2307.08875"}, {"metadata": {"arXiv": "2307.08877", "Date": "Mon, 17 Jul 2023 22:19:12 ", "Title": "Disentangling Node Attributes from Graph Topology for Improved Generalizability in Link Prediction", "Authors": ["Ayan Chatterjee", "Robin Walters", "Giulia Menichetti", "and Tina Eliassi-Rad"], "Categories": "cs.LG cs.SI", "Comments": ["17 pages", "6 figures"]}, "abstract": "Link prediction is a crucial task in graph machine learning with diverse applications. We explore the interplay between node attributes and graph topology and demonstrate that incorporating pre-trained node attributes improves the generalization power of link prediction models. Our proposed method, UPNA (Unsupervised Pre-training of Node Attributes), solves the inductive link prediction problem by learning a function that takes a pair of node attributes and predicts the probability of an edge, as opposed to Graph Neural Networks (GNN), which can be prone to topological shortcuts in graphs with power-law degree distribution. In this manner, UPNA learns a significant part of the latent graph generation mechanism since the learned function can be used to add incoming nodes to a growing graph. By leveraging pre-trained node attributes, we overcome observational bias and make meaningful predictions about unobserved nodes, surpassing state-of-the-art performance (3X to 34X improvement on benchmark datasets). UPNA can be applied to various pairwise learning tasks and integrated with existing link prediction models to enhance their generalizability and bolster graph generative models.", "url": "https://arxiv.org/abs/2307.08877"}, {"metadata": {"arXiv": "2307.08893", "Date": "Mon, 17 Jul 2023 23:28:59 ", "Title": "Evaluating unsupervised disentangled representation learning for genomic discovery and disease risk prediction", "Authors": ["Taedong Yun"], "Categories": "cs.LG q-bio.GN stat.ML", "Comments": ["Accepted to the 2023 ICML Workshop on Computational Biology. Honolulu", "Hawaii", "USA", "2023"]}, "abstract": "High-dimensional clinical data have become invaluable resources for genetic studies, due to their accessibility in biobank-scale datasets and the development of high performance modeling techniques especially using deep learning. Recent work has shown that low dimensional embeddings of these clinical data learned by variational autoencoders (VAE) can be used for genome-wide association studies and polygenic risk prediction. In this work, we consider multiple unsupervised learning methods for learning disentangled representations, namely autoencoders, VAE, beta-VAE, and FactorVAE, in the context of genetic association studies. Using spirograms from UK Biobank as a running example, we observed improvements in the number of genome-wide significant loci, heritability, and performance of polygenic risk scores for asthma and chronic obstructive pulmonary disease by using FactorVAE or beta-VAE, compared to standard VAE or non-variational autoencoders. FactorVAEs performed effectively across multiple values of the regularization hyperparameter, while beta-VAEs were much more sensitive to the hyperparameter values.", "url": "https://arxiv.org/abs/2307.08893"}, {"metadata": {"arXiv": "2307.08910", "Date": "Tue, 18 Jul 2023 01:02:20 ", "Title": "Sharpness-Aware Graph Collaborative Filtering", "Authors": ["Huiyuan Chen", "Chin-Chia Michael Yeh", "Yujie Fan", "Yan Zheng", "Junpeng Wang", "Vivian Lai", "Mahashweta Das", "Hao Yang"], "Categories": "cs.LG cs.IR"}, "abstract": "Graph Neural Networks (GNNs) have achieved impressive performance in collaborative filtering. However, GNNs tend to yield inferior performance when the distributions of training and test data are not aligned well. Also, training GNNs requires optimizing non-convex neural networks with an abundance of local and global minima, which may differ widely in their performance at test time. Thus, it is essential to choose the minima carefully. Here we propose an effective training schema, called {gSAM}, under the principle that the \\textit{flatter} minima has a better generalization ability than the \\textit{sharper} ones. To achieve this goal, gSAM regularizes the flatness of the weight loss landscape by forming a bi-level optimization: the outer problem conducts the standard model training while the inner problem helps the model jump out of the sharp minima. Experimental results show the superiority of our gSAM.", "url": "https://arxiv.org/abs/2307.08910"}, {"metadata": {"arXiv": "2307.08913", "Date": "Tue, 18 Jul 2023 01:16:23 ", "Title": "Towards the Sparseness of Projection Head in Self-Supervised Learning", "Authors": ["Zeen Song", "Xingzhe Su", "Jingyao Wang", "Wenwen Qiang", "Changwen Zheng", "Fuchun Sun"], "Categories": "cs.LG cs.CV", "Comments": ["9 pages,3 figures"]}, "abstract": "In recent years, self-supervised learning (SSL) has emerged as a promising approach for extracting valuable representations from unlabeled data. One successful SSL method is contrastive learning, which aims to bring positive examples closer while pushing negative examples apart. Many current contrastive learning approaches utilize a parameterized projection head. Through a combination of empirical analysis and theoretical investigation, we provide insights into the internal mechanisms of the projection head and its relationship with the phenomenon of dimensional collapse. Our findings demonstrate that the projection head enhances the quality of representations by performing contrastive loss in a projected subspace. Therefore, we propose an assumption that only a subset of features is necessary when minimizing the contrastive loss of a mini-batch of data. Theoretical analysis further suggests that a sparse projection head can enhance generalization, leading us to introduce SparseHead - a regularization term that effectively constrains the sparsity of the projection head, and can be seamlessly integrated with any self-supervised learning (SSL) approaches. Our experimental results validate the effectiveness of SparseHead, demonstrating its ability to improve the performance of existing contrastive methods.", "url": "https://arxiv.org/abs/2307.08913"}, {"metadata": {"arXiv": "2307.08921", "Date": "Tue, 18 Jul 2023 01:37:57 ", "Title": "Optimistic Estimate Uncovers the Potential of Nonlinear Models", "Authors": ["Yaoyu Zhang", "Zhongwang Zhang", "Leyang Zhang", "Zhiwei Bai", "Tao Luo", "Zhi-Qin John Xu"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose an optimistic estimate to evaluate the best possible fitting performance of nonlinear models. It yields an optimistic sample size that quantifies the smallest possible sample size to fit/recover a target function using a nonlinear model. We estimate the optimistic sample sizes for matrix factorization models, deep models, and deep neural networks (DNNs) with fully-connected or convolutional architecture. For each nonlinear model, our estimates predict a specific subset of targets that can be fitted at overparameterization, which are confirmed by our experiments. Our optimistic estimate reveals two special properties of the DNN models -- free expressiveness in width and costly expressiveness in connection. These properties suggest the following architecture design principles of DNNs: (i) feel free to add neurons/kernels; (ii) restrain from connecting neurons. Overall, our optimistic estimate theoretically unveils the vast potential of nonlinear models in fitting at overparameterization. Based on this framework, we anticipate gaining a deeper understanding of how and why numerous nonlinear models such as DNNs can effectively realize their potential in practice in the near future.", "url": "https://arxiv.org/abs/2307.08921"}, {"metadata": {"arXiv": "2307.08924", "Date": "Tue, 18 Jul 2023 01:53:18 ", "Title": "Learning to Sample Tasks for Meta Learning", "Authors": ["Jingyao Wang", "Zeen Song", "Xingzhe Su", "Lingyu Si", "Hongwei Dong", "Wenwen Qiang", "Changwen Zheng"], "Categories": "cs.LG cs.CV", "Comments": ["10 pages", "7 tables", "3 figures"]}, "abstract": "Through experiments on various meta-learning methods, task samplers, and few-shot learning tasks, this paper arrives at three conclusions. Firstly, there are no universal task sampling strategies to guarantee the performance of meta-learning models. Secondly, task diversity can cause the models to either underfit or overfit during training. Lastly, the generalization performance of the models are influenced by task divergence, task entropy, and task difficulty. In response to these findings, we propose a novel task sampler called Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes task divergence, task entropy, and task difficulty to sample tasks. To optimize ASr, we rethink and propose a simple and general meta-learning algorithm. Finally, a large number of empirical experiments demonstrate the effectiveness of the proposed ASr.", "url": "https://arxiv.org/abs/2307.08924"}, {"metadata": {"arXiv": "2307.08934", "Date": "Tue, 18 Jul 2023 02:47:32 ", "Title": "Multi-stage Neural Networks: Function Approximator of Machine Precision", "Authors": ["Yongji Wang", "Ching-Yao Lai"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["38 pages", "17 pages"]}, "abstract": "Deep learning techniques are increasingly applied to scientific problems, where the precision of networks is crucial. Despite being deemed as universal function approximators, neural networks, in practice, struggle to reduce the prediction errors below $O(10^{-5})$ even with large network size and extended training iterations. To address this issue, we developed the multi-stage neural networks that divides the training process into different stages, with each stage using a new network that is optimized to fit the residue from the previous stage. Across successive stages, the residue magnitudes decreases substantially and follows an inverse power-law relationship with the residue frequencies. The multi-stage neural networks effectively mitigate the spectral biases associated with regular neural networks, enabling them to capture the high frequency feature of target functions. We demonstrate that the prediction error from the multi-stage training for both regression problems and physics-informed neural networks can nearly reach the machine-precision $O(10^{-16})$ of double-floating point within a finite number of iterations. Such levels of accuracy are rarely attainable using single neural networks alone.", "url": "https://arxiv.org/abs/2307.08934"}, {"metadata": {"arXiv": "2307.08941", "Date": "Tue, 18 Jul 2023 03:12:51 ", "Title": "NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning", "Authors": ["Tianxin Wei", "Zeming Guo", "Yifan Chen", "Jingrui He"], "Categories": "cs.LG cs.CL", "Comments": ["ICML 2023"]}, "abstract": "Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications. However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power. Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored. In this paper, we investigate the neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM. Extensive experiments of PLM fine-tuning on both natural language understanding (NLU) and generation (NLG) tasks are provided to verify the effectiveness of the proposed method MLP fusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.", "url": "https://arxiv.org/abs/2307.08941"}, {"metadata": {"arXiv": "2307.08945", "Date": "Tue, 18 Jul 2023 03:28:03 ", "Title": "Mitigating Label Bias via Decoupled Confident Learning", "Authors": ["Yunyi Li", "Maria De-Arteaga", "Maytal Saar-Tsechansky"], "Categories": "cs.LG cs.CL", "Comments": ["AI & HCI Workshop at the 40th International Conference on Machine Learning (ICML)", "Honolulu", "Hawaii", "USA. 2023"]}, "abstract": "Growing concerns regarding algorithmic fairness have led to a surge in methodologies to mitigate algorithmic bias. However, such methodologies largely assume that observed labels in training data are correct. This is problematic because bias in labels is pervasive across important domains, including healthcare, hiring, and content moderation. In particular, human-generated labels are prone to encoding societal biases. While the presence of labeling bias has been discussed conceptually, there is a lack of methodologies to address this problem. We propose a pruning method -- Decoupled Confident Learning (DeCoLe) -- specifically designed to mitigate label bias. After illustrating its performance on a synthetic dataset, we apply DeCoLe in the context of hate speech detection, where label bias has been recognized as an important challenge, and show that it successfully identifies biased labels and outperforms competing approaches.", "url": "https://arxiv.org/abs/2307.08945"}, {"metadata": {"arXiv": "2307.08951", "Date": "Tue, 18 Jul 2023 03:39:03 ", "Title": "Knowledge-infused Deep Learning Enables Interpretable Landslide Forecasting", "Authors": ["Zhengjing Ma", "Gang Mei"], "Categories": "cs.LG stat.AP"}, "abstract": "Forecasting how landslides will evolve over time or whether they will fail is a challenging task due to a variety of factors, both internal and external. Despite their considerable potential to address these challenges, deep learning techniques lack interpretability, undermining the credibility of the forecasts they produce. The recent development of transformer-based deep learning offers untapped possibilities for forecasting landslides with unprecedented interpretability and nonlinear feature learning capabilities. Here, we present a deep learning pipeline that is capable of predicting landslide behavior holistically, which employs a transformer-based network called LFIT to learn complex nonlinear relationships from prior knowledge and multiple source data, identifying the most relevant variables, and demonstrating a comprehensive understanding of landslide evolution and temporal patterns. By integrating prior knowledge, we provide improvement in holistic landslide forecasting, enabling us to capture diverse responses to various influencing factors in different local landslide areas. Using deformation observations as proxies for measuring the kinetics of landslides, we validate our approach by training models to forecast reservoir landslides in the Three Gorges Reservoir and creeping landslides on the Tibetan Plateau. When prior knowledge is incorporated, we show that interpretable landslide forecasting effectively identifies influential factors across various landslides. It further elucidates how local areas respond to these factors, making landslide behavior and trends more interpretable and predictable. The findings from this study will contribute to understanding landslide behavior in a new way and make the proposed approach applicable to other complex disasters influenced by internal and external factors in the future.", "url": "https://arxiv.org/abs/2307.08951"}, {"metadata": {"arXiv": "2307.08955", "Date": "Tue, 18 Jul 2023 03:48:27 ", "Title": "Discretization-based ensemble model for robust learning in IoT", "Authors": ["Anahita Namvar", "Chandra Thapa", "Salil S. Kanhere"], "Categories": "cs.LG cs.CR", "Comments": ["15 pages"]}, "abstract": "IoT device identification is the process of recognizing and verifying connected IoT devices to the network. This is an essential process for ensuring that only authorized devices can access the network, and it is necessary for network management and maintenance. In recent years, machine learning models have been used widely for automating the process of identifying devices in the network. However, these models are vulnerable to adversarial attacks that can compromise their accuracy and effectiveness. To better secure device identification models, discretization techniques enable reduction in the sensitivity of machine learning models to adversarial attacks contributing to the stability and reliability of the model. On the other hand, Ensemble methods combine multiple heterogeneous models to reduce the impact of remaining noise or errors in the model. Therefore, in this paper, we integrate discretization techniques and ensemble methods and examine it on model robustness against adversarial attacks. In other words, we propose a discretization-based ensemble stacking technique to improve the security of our ML models. We evaluate the performance of different ML-based IoT device identification models against white box and black box attacks using a real-world dataset comprised of network traffic from 28 IoT devices. We demonstrate that the proposed method enables robustness to the models for IoT device identification.", "url": "https://arxiv.org/abs/2307.08955"}, {"metadata": {"arXiv": "2307.08970", "Date": "Tue, 18 Jul 2023 05:04:11 ", "Title": "A Unifying Framework for Differentially Private Sums under Continual Observation", "Authors": ["Monika Henzinger and Jalaj Upadhyay and Sarvagya Upadhyay"], "Categories": "cs.LG cs.CR", "Comments": ["32 pages"]}, "abstract": "We study the problem of maintaining a differentially private decaying sum under continual observation. We give a unifying framework and an efficient algorithm for this problem for \\emph{any sufficiently smooth} function. Our algorithm is the first differentially private algorithm that does not have a multiplicative error for polynomially-decaying weights. Our algorithm improves on all prior works on differentially private decaying sums under continual observation and recovers exactly the additive error for the special case of continual counting from Henzinger et al. (SODA 2023) as a corollary. Our algorithm is a variant of the factorization mechanism whose error depends on the $\\gamma_2$ and $\\gamma_F$ norm of the underlying matrix. We give a constructive proof for an almost exact upper bound on the $\\gamma_2$ and $\\gamma_F$ norm and an almost tight lower bound on the $\\gamma_2$ norm for a large class of lower-triangular matrices. This is the first non-trivial lower bound for lower-triangular matrices whose non-zero entries are not all the same. It includes matrices for all continual decaying sums problems, resulting in an upper bound on the additive error of any differentially private decaying sums algorithm under continual observation. We also explore some implications of our result in discrepancy theory and operator algebra. Given the importance of the $\\gamma_2$ norm in computer science and the extensive work in mathematics, we believe our result will have further applications.", "url": "https://arxiv.org/abs/2307.08970"}, {"metadata": {"arXiv": "2307.08982", "Date": "Tue, 18 Jul 2023 05:39:32 ", "Title": "Neural Network Pruning as Spectrum Preserving Process", "Authors": ["Shibo Yao", "Dantong Yu", "Ioannis Koutis"], "Categories": "cs.LG cs.NE", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2304.03452"]}, "abstract": "Neural networks have achieved remarkable performance in various application domains. Nevertheless, a large number of weights in pre-trained deep neural networks prohibit them from being deployed on smartphones and embedded systems. It is highly desirable to obtain lightweight versions of neural networks for inference in edge devices. Many cost-effective approaches were proposed to prune dense and convolutional layers that are common in deep neural networks and dominant in the parameter space. However, a unified theoretical foundation for the problem mostly is missing. In this paper, we identify the close connection between matrix spectrum learning and neural network training for dense and convolutional layers and argue that weight pruning is essentially a matrix sparsification process to preserve the spectrum. Based on the analysis, we also propose a matrix sparsification algorithm tailored for neural network pruning that yields better pruning result. We carefully design and conduct experiments to support our arguments. Hence we provide a consolidated viewpoint for neural network pruning and enhance the interpretability of deep neural networks by identifying and preserving the critical neural weights.", "url": "https://arxiv.org/abs/2307.08982"}, {"metadata": {"arXiv": "2307.08989", "Date": "Tue, 18 Jul 2023 06:01:37 ", "Title": "GraphCL-DTA: a graph contrastive learning with molecular semantics for drug-target binding affinity prediction", "Authors": ["Xinxing Yang and Genke Yang and Jian Chu"], "Categories": "cs.LG cs.IR q-bio.QM", "Comments": ["13 pages", "4 figures", "5 tables"]}, "abstract": "Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets. However, the performance of previous computational models is limited by the following drawbacks. The learning of drug representation relies only on supervised data, without taking into account the information contained in the molecular graph itself. Moreover, most previous studies tended to design complicated representation learning module, while uniformity, which is used to measure representation quality, is ignored. In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. In GraphCL-DTA, we design a graph contrastive learning framework for molecular graphs to learn drug representations, so that the semantics of molecular graphs are preserved. Through this graph contrastive framework, a more essential and effective drug representation can be learned without additional supervised data. Next, we design a new loss function that can be directly used to smoothly adjust the uniformity of drug and target representations. By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved. The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis. The excellent performance of GraphCL-DTA on the above datasets suggests its superiority to the state-of-the-art model.", "url": "https://arxiv.org/abs/2307.08989"}, {"metadata": {"arXiv": "2307.08999", "Date": "Tue, 18 Jul 2023 06:34:32 ", "Title": "Oracle Efficient Online Multicalibration and Omniprediction", "Authors": ["Sumegha Garg", "Christopher Jung", "Omer Reingold", "Aaron Roth"], "Categories": "cs.LG stat.ML"}, "abstract": "A recent line of work has shown a surprising connection between multicalibration, a multi-group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions. Prior work studies omniprediction in the batch setting. We initiate the study of omniprediction in the online adversarial setting. Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting, unlike batch algorithms, they work only for small finite classes of benchmark functions $F$, because they require enumerating every function $f \\in F$ at every round. In contrast, omniprediction is most interesting for learning theoretic hypothesis classes $F$, which are generally continuously large. We develop a new online multicalibration algorithm that is well defined for infinite benchmark classes $F$, and is oracle efficient (i.e. for any class $F$, the algorithm has the form of an efficient reduction to a no-regret learning algorithm for $F$). The result is the first efficient online omnipredictor -- an oracle efficient prediction algorithm that can be used to simultaneously obtain no regret guarantees to all Lipschitz convex loss functions. For the class $F$ of linear functions, we show how to make our algorithm efficient in the worst case. Also, we show upper and lower bounds on the extent to which our rates can be improved: our oracle efficient algorithm actually promises a stronger guarantee called swap-omniprediction, and we prove a lower bound showing that obtaining $O(\\sqrt{T})$ bounds for swap-omniprediction is impossible in the online setting. On the other hand, we give a (non-oracle efficient) algorithm which can obtain the optimal $O(\\sqrt{T})$ omniprediction bounds without going through multicalibration, giving an information theoretic separation between these two solution concepts.", "url": "https://arxiv.org/abs/2307.08999"}, {"metadata": {"arXiv": "2307.09019", "Date": "Tue, 18 Jul 2023 07:15:26 ", "Title": "U-shaped Transformer: Retain High Frequency Context in Time Series Analysis", "Authors": ["Qingkui Chen", "Yiqin Zhang"], "Categories": "cs.LG cs.CV"}, "abstract": "Time series prediction plays a crucial role in various industrial fields. In recent years, neural networks with a transformer backbone have achieved remarkable success in many domains, including computer vision and NLP. In time series analysis domain, some studies have suggested that even the simplest MLP networks outperform advanced transformer-based networks on time series forecast tasks. However, we believe these findings indicate there to be low-rank properties in time series sequences. In this paper, we consider the low-pass characteristics of transformers and try to incorporate the advantages of MLP. We adopt skip-layer connections inspired by Unet into traditional transformer backbone, thus preserving high-frequency context from input to output, namely U-shaped Transformer. We introduce patch merge and split operation to extract features with different scales and use larger datasets to fully make use of the transformer backbone. Our experiments demonstrate that the model performs at an advanced level across multiple datasets with relatively low cost.", "url": "https://arxiv.org/abs/2307.09019"}, {"metadata": {"arXiv": "2307.09080", "Date": "Tue, 18 Jul 2023 09:00:26 ", "Title": "A Federated learning model for Electric Energy management using Blockchain Technology", "Authors": ["Muhammad Shoaib Farooq", "Azeen Ahmed Hayat"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["14 figures", "7 tables", "15 pages"]}, "abstract": "Energy shortfall and electricity load shedding are the main problems for developing countries. The main causes are lack of management in the energy sector and the use of non-renewable energy sources. The improved energy management and use of renewable sources can be significant to resolve energy crisis. It is necessary to increase the use of renewable energy sources (RESs) to meet the increasing energy demand due to high prices of fossil-fuel based energy. Federated learning (FL) is the most emerging technique in the field of artificial intelligence. Federated learning helps to generate global model at server side by ensemble locally trained models at remote edges sites while preserving data privacy. The global model used to predict energy demand to satisfy the needs of consumers. In this article, we have proposed Blockchain based safe distributed ledger technology for transaction of data between prosumer and consumer to ensure their transparency, traceability and security. Furthermore, we have also proposed a Federated learning model to forecast the energy requirements of consumer and prosumer. Moreover, Blockchain has been used to store excess energy data from prosumer for better management of energy between prosumer and grid. Lastly, the experiment results revealed that renewable energy sources have produced better and comparable results to other non-renewable energy resources.", "url": "https://arxiv.org/abs/2307.09080"}, {"metadata": {"arXiv": "2307.09093", "Date": "Tue, 18 Jul 2023 09:22:33 ", "Title": "Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related Rewards", "Authors": ["Saeed Ghoorchian and Setareh Maghsudi"], "Categories": "cs.LG stat.ML", "Comments": ["33 pages", "9 figures. arXiv admin note: text overlap with arXiv:2212.12923"]}, "abstract": "Sequential decision-making under uncertainty is often associated with long feedback delays. Such delays degrade the performance of the learning agent in identifying a subset of arms with the optimal collective reward in the long run. This problem becomes significantly challenging in a non-stationary environment with structural dependencies amongst the reward distributions associated with the arms. Therefore, besides adapting to delays and environmental changes, learning the causal relations alleviates the adverse effects of feedback delay on the decision-making process. We formalize the described setting as a non-stationary and delayed combinatorial semi-bandit problem with causally related rewards. We model the causal relations by a directed graph in a stationary structural equation model. The agent maximizes the long-term average payoff, defined as a linear function of the base arms' rewards. We develop a policy that learns the structural dependencies from delayed feedback and utilizes that to optimize the decision-making while adapting to drifts. We prove a regret bound for the performance of the proposed algorithm. Besides, we evaluate our method via numerical analysis using synthetic and real-world datasets to detect the regions that contribute the most to the spread of Covid-19 in Italy.", "url": "https://arxiv.org/abs/2307.09093"}, {"metadata": {"arXiv": "2307.09109", "Date": "Tue, 18 Jul 2023 09:58:15 ", "Title": "Mining of Single-Class by Active Learning for Semantic Segmentation", "Authors": ["Hugues Lambert", "Emma Slade"], "Categories": "cs.LG cs.CV", "Comments": ["29 pages", "14 figures", "2 tables"]}, "abstract": "Several Active Learning (AL) policies require retraining a target model several times in order to identify the most informative samples and rarely offer the option to focus on the acquisition of samples from underrepresented classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm is introduced where an AL policy is constructed through deep reinforcement learning and exploits quantity-accuracy correlations to build datasets on which high-performance models can be trained with regards to specific classes. MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions as is common in other AL methods. This is thanks to its ability to exploit fixed representations of the candidate data points. We find that MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes, while the strongest baseline only outperforms random on 101 classes.", "url": "https://arxiv.org/abs/2307.09109"}, {"metadata": {"arXiv": "2307.09165", "Date": "Tue, 18 Jul 2023 11:43:01 ", "Title": "Towards Trustworthy Dataset Distillation", "Authors": ["Shijie Ma", "Fei Zhu", "Zhen Cheng", "Xu-Yao Zhang"], "Categories": "cs.LG cs.CV", "Comments": ["20 pages", "20 figures"]}, "abstract": "Efficiency and trustworthiness are two eternal pursuits when applying deep learning in real-world applications. With regard to efficiency, dataset distillation (DD) endeavors to reduce training costs by distilling the large dataset into a tiny synthetic dataset. However, existing methods merely concentrate on in-distribution (InD) classification in a closed-world setting, disregarding out-of-distribution (OOD) samples. On the other hand, OOD detection aims to enhance models' trustworthiness, which is always inefficiently achieved in full-data settings. For the first time, we simultaneously consider both issues and propose a novel paradigm called Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and outliers, the condensed datasets are capable to train models competent in both InD classification and OOD detection. To alleviate the requirement of real outlier data and make OOD detection more practical, we further propose to corrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier Exposure (POE). Comprehensive experiments on various settings demonstrate the effectiveness of TrustDD, and the proposed POE surpasses state-of-the-art method Outlier Exposure (OE). Compared with the preceding DD, TrustDD is more trustworthy and applicable to real open-world scenarios. Our code will be publicly available.", "url": "https://arxiv.org/abs/2307.09165"}, {"metadata": {"arXiv": "2307.09182", "Date": "Tue, 18 Jul 2023 12:05:36 ", "Title": "Federated Learning for Computationally-Constrained Heterogeneous Devices: A Survey", "Authors": ["Kilian Pfeiffer", "Martin Rapp", "Ramin Khalili", "J\\\"org Henkel"], "Categories": "cs.LG", "Journal-ref": "ACM Comput. Surv. 55, 14s, Article 334, 2023", "DOI": "10.1145/3596907"}, "abstract": "With an increasing number of smart devices like internet of things (IoT) devices deployed in the field, offloadingtraining of neural networks (NNs) to a central server becomes more and more infeasible. Recent efforts toimprove users' privacy have led to on-device learning emerging as an alternative. However, a model trainedonly on a single device, using only local data, is unlikely to reach a high accuracy. Federated learning (FL)has been introduced as a solution, offering a privacy-preserving trade-off between communication overheadand model accuracy by sharing knowledge between devices but disclosing the devices' private data. Theapplicability and the benefit of applying baseline FL are, however, limited in many relevant use cases dueto the heterogeneity present in such environments. In this survey, we outline the heterogeneity challengesFL has to overcome to be widely applicable in real-world applications. We especially focus on the aspect ofcomputation heterogeneity among the participating devices and provide a comprehensive overview of recentworks on heterogeneity-aware FL. We discuss two groups: works that adapt the NN architecture and worksthat approach heterogeneity on a system level, covering Federated Averaging (FedAvg), distillation, and splitlearning-based approaches, as well as synchronous and asynchronous aggregation schemes.", "url": "https://arxiv.org/abs/2307.09182"}, {"metadata": {"arXiv": "2307.09191", "Date": "Mon, 17 Jul 2023 13:17:26 ", "Title": "A benchmark of categorical encoders for binary classification", "Authors": ["Federico Matteucci", "Vadim Arzamasov", "Klemens Boehm"], "Categories": "cs.LG", "Comments": ["20 pages", "8 figures", "submitted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasetsand Benchmarks"]}, "abstract": "Categorical encoders transform categorical features into numerical representations that are indispensable for a wide range of machine learning models. Existing encoder benchmark studies lack generalizability because of their limited choice of (1) encoders, (2) experimental factors, and (3) datasets. Additionally, inconsistencies arise from the adoption of varying aggregation strategies. This paper is the most comprehensive benchmark of categorical encoders to date, including an extensive evaluation of 32 configurations of encoders from diverse families, with 36 combinations of experimental factors, and on 50 datasets. The study shows the profound influence of dataset selection, experimental factors, and aggregation strategies on the benchmark's conclusions -- aspects disregarded in previous encoder benchmarks.", "url": "https://arxiv.org/abs/2307.09191"}, {"metadata": {"arXiv": "2307.09205", "Date": "Tue, 18 Jul 2023 12:41:28 ", "Title": "Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning", "Authors": ["Fan Feng and Sara Magliacane"], "Categories": "cs.LG"}, "abstract": "In many reinforcement learning tasks, the agent has to learn to interact with many objects of different types and generalize to unseen combinations and numbers of objects. Often a task is a composition of previously learned tasks (e.g. block stacking). These are examples of compositional generalization, in which we compose object-centric representations to solve complex tasks. Recent works have shown the benefits of object-factored representations and hierarchical abstractions for improving sample efficiency in these settings. On the other hand, these methods do not fully exploit the benefits of factorization in terms of object attributes. In this paper, we address this opportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL) framework. In DAFT-RL, we leverage object-centric representation learning to extract objects from visual inputs. We learn to classify them in classes and infer their latent parameters. For each class of object, we learn a class template graph that describes how the dynamics and reward of an object of this class factorize according to its attributes. We also learn an interaction pattern graph that describes how objects of different classes interact with each other at the attribute level. Through these graphs and a dynamic interaction graph that models the interactions between objects, we can learn a policy that can then be directly applied in a new environment by just estimating the interactions and latent parameters. We evaluate DAFT-RL in three benchmark datasets and show our framework outperforms the state-of-the-art in generalizing across unseen objects with varying attributes and latent parameters, as well as in the composition of previously learned tasks.", "url": "https://arxiv.org/abs/2307.09205"}, {"metadata": {"arXiv": "2307.09212", "Date": "Tue, 18 Jul 2023 12:47:35 ", "Title": "How Many Neurons Does it Take to Approximate the Maximum?", "Authors": ["Itay Safran", "Daniel Reichman", "Paul Valiant"], "Categories": "cs.LG"}, "abstract": "We study the size of a neural network needed to approximate the maximum function over $d$ inputs, in the most basic setting of approximating with respect to the $L_2$ norm, for continuous distributions, for a network that uses ReLU activations. We provide new lower and upper bounds on the width required for approximation across various depths. Our results establish new depth separations between depth 2 and 3, and depth 3 and 5 networks, as well as providing a depth $\\mathcal{O}(\\log(\\log(d)))$ and width $\\mathcal{O}(d)$ construction which approximates the maximum function, significantly improving upon the depth requirements of the best previously known bounds for networks with linearly-bounded width. Our depth separation results are facilitated by a new lower bound for depth 2 networks approximating the maximum function over the uniform distribution, assuming an exponential upper bound on the size of the weights. Furthermore, we are able to use this depth 2 lower bound to provide tight bounds on the number of neurons needed to approximate the maximum by a depth 3 network. Our lower bounds are of potentially broad interest as they apply to the widely studied and used \\emph{max} function, in contrast to many previous results that base their bounds on specially constructed or pathological functions and distributions.", "url": "https://arxiv.org/abs/2307.09212"}, {"metadata": {"arXiv": "2307.09230", "Date": "Tue, 18 Jul 2023 13:06:17 ", "Title": "Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review", "Authors": ["Mary Paterson", "James Moor", "Luisa Cutillo"], "Categories": "cs.LG cs.SD eess.AS", "Comments": ["19 pages", "10 figures"]}, "abstract": "In this work we perform a scoping review of the current literature on the detection of throat cancer from speech recordings using machine learning and artificial intelligence. We find 22 papers within this area and discuss their methods and results. We split these papers into two groups - nine performing binary classification, and 13 performing multi-class classification. The papers present a range of methods with neural networks being most commonly implemented. Many features are also extracted from the audio before classification, with the most common bring mel-frequency cepstral coefficients. None of the papers found in this search have associated code repositories and as such are not reproducible. Therefore, we create a publicly available code repository of our own classifiers. We use transfer learning on a multi-class problem, classifying three pathologies and healthy controls. Using this technique we achieve an unweighted average recall of 53.54%, sensitivity of 83.14%, and specificity of 64.00%. We compare our classifiers with the results obtained on the same dataset and find similar results.", "url": "https://arxiv.org/abs/2307.09230"}, {"metadata": {"arXiv": "2307.09248", "Date": "Tue, 18 Jul 2023 13:28:30 ", "Title": "Application of BERT in Wind Power Forecasting-Teletraan's Solution in Baidu KDD Cup 2022", "Authors": ["Longxing Tan and Hongying Yue"], "Categories": "cs.LG eess.SP"}, "abstract": "Nowadays, wind energy has drawn increasing attention as its important role in carbon neutrality and sustainable development. When wind power is integrated into the power grid, precise forecasting is necessary for the sustainability and security of the system. However, the unpredictable nature and long sequence prediction make it especially challenging. In this technical report, we introduce the BERT model applied for Baidu KDD Cup 2022, and the daily fluctuation is added by post-processing to make the predicted results in line with daily periodicity. Our solution achieves 3rd place of 2490 teams. The code is released athttps://github.com/LongxingTan/KDD2022-Baidu", "url": "https://arxiv.org/abs/2307.09248"}, {"metadata": {"arXiv": "2307.09254", "Date": "Tue, 18 Jul 2023 13:36:24 ", "Title": "PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models", "Authors": ["Sangdon Park and Taesoo Kim"], "Categories": "cs.LG cs.CL stat.ML"}, "abstract": "Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\\%$ on average, compared to a standard baseline method.", "url": "https://arxiv.org/abs/2307.09254"}, {"metadata": {"arXiv": "2307.09259", "Date": "Tue, 18 Jul 2023 13:43:53 ", "Title": "Adaptive Topological Feature via Persistent Homology: Filtration Learning for Point Clouds", "Authors": ["Naoki Nishikawa", "Yuichi Ike and Kenji Yamanishi"], "Categories": "cs.LG cs.CG cs.CV", "Comments": ["17 pages with 4 figures"]}, "abstract": "Machine learning for point clouds has been attracting much attention, with many applications in various fields, such as shape recognition and material science. To enhance the accuracy of such machine learning methods, it is known to be effective to incorporate global topological features, which are typically extracted by persistent homology. In the calculation of persistent homology for a point cloud, we need to choose a filtration for the point clouds, an increasing sequence of spaces. Because the performance of machine learning methods combined with persistent homology is highly affected by the choice of a filtration, we need to tune it depending on data and tasks. In this paper, we propose a framework that learns a filtration adaptively with the use of neural networks. In order to make the resulting persistent homology isometry-invariant, we develop a neural network architecture with such invariance. Additionally, we theoretically show a finite-dimensional approximation result that justifies our architecture. Experimental results demonstrated the efficacy of our framework in several classification tasks.", "url": "https://arxiv.org/abs/2307.09259"}, {"metadata": {"arXiv": "2307.09269", "Date": "Tue, 18 Jul 2023 13:52:12 ", "Title": "End-to-End Neural Network Training for Hyperbox-Based Classification", "Authors": ["Denis Mayr Lima Martins and Christian L\\\"ulf and Fabian Gieseke"], "Categories": "cs.LG", "Comments": ["6 pages", "accepted for poster presentation at ESANN 2023"]}, "abstract": "Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays. We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks. In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results.", "url": "https://arxiv.org/abs/2307.09269"}, {"metadata": {"arXiv": "2307.09295", "Date": "Thu, 13 Jul 2023 05:05:30 ", "Title": "Nested Elimination: A Simple Algorithm for Best-Item Identification from Choice-Based Feedback", "Authors": ["Junwen Yang", "Yifan Feng"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted to ICML 2023"]}, "abstract": "We study the problem of best-item identification from choice-based feedback. In this problem, a company sequentially and adaptively shows display sets to a population of customers and collects their choices. The objective is to identify the most preferred item with the least number of samples and at a high confidence level. We propose an elimination-based algorithm, namely Nested Elimination (NE), which is inspired by the nested structure implied by the information-theoretic lower bound. NE is simple in structure, easy to implement, and has a strong theoretical guarantee for sample complexity. Specifically, NE utilizes an innovative elimination criterion and circumvents the need to solve any complex combinatorial optimization problem. We provide an instance-specific and non-asymptotic bound on the expected sample complexity of NE. We also show NE achieves high-order worst-case asymptotic optimality. Finally, numerical experiments from both synthetic and real data corroborate our theoretical findings.", "url": "https://arxiv.org/abs/2307.09295"}, {"metadata": {"arXiv": "2307.09302", "Date": "Tue, 18 Jul 2023 14:40:48 ", "Title": "Conformal prediction under ambiguous ground truth", "Authors": ["David Stutz", "Abhijit Guha Roy", "Tatiana Matejovicova", "Patricia Strachan", "Ali Taylan Cemgil", "Arnaud Doucet"], "Categories": "cs.LG cs.CV stat.ME stat.ML"}, "abstract": "In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability. This generally assumes the availability of a held-out calibration set with access to ground truth labels. Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions. In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet. Applying conformal prediction using such labels underestimates uncertainty. Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels. That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration. In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlying posterior distribution of labels given inputs. We demonstrate our methodology on synthetic and real datasets, including a case study of skin condition classification in dermatology.", "url": "https://arxiv.org/abs/2307.09302"}, {"metadata": {"arXiv": "2307.09311", "Date": "Tue, 18 Jul 2023 14:56:12 ", "Title": "Automatic Differentiation for Inverse Problems with Applications in Quantum Transport", "Authors": ["Ivan Williams", "Eric Polizzi"], "Categories": "cs.LG cs.CE physics.comp-ph", "Comments": ["7 pages", "5 figures"]}, "abstract": "A neural solver and differentiable simulation of the quantum transmitting boundary model is presented for the inverse quantum transport problem. The neural solver is used to engineer continuous transmission properties and the differentiable simulation is used to engineer current-voltage characteristics.", "url": "https://arxiv.org/abs/2307.09311"}, {"metadata": {"arXiv": "2307.09365", "Date": "Tue, 18 Jul 2023 15:48:53 ", "Title": "An Evaluation of Zero-Cost Proxies -- from Neural Architecture Performance to Model Robustness", "Authors": ["Jovita Lukasik", "Michael Moeller", "Margret Keuper"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted at DAGM GCPR 2023"]}, "abstract": "Zero-cost proxies are nowadays frequently studied and used to search for neural architectures. They show an impressive ability to predict the performance of architectures by making use of their untrained weights. These techniques allow for immense search speed-ups. So far the joint search for well-performing and robust architectures has received much less attention in the field of NAS. Therefore, the main focus of zero-cost proxies is the clean accuracy of architectures, whereas the model robustness should play an evenly important part. In this paper, we analyze the ability of common zero-cost proxies to serve as performance predictors for robustness in the popular NAS-Bench-201 search space. We are interested in the single prediction task for robustness and the joint multi-objective of clean and robust accuracy. We further analyze the feature importance of the proxies and show that predicting the robustness makes the prediction task from existing zero-cost proxies more challenging. As a result, the joint consideration of several proxies becomes necessary to predict a model's robustness while the clean accuracy can be regressed from a single such feature.", "url": "https://arxiv.org/abs/2307.09365"}, {"metadata": {"arXiv": "2307.09366", "Date": "Tue, 18 Jul 2023 15:49:02 ", "Title": "Sparse Gaussian Graphical Models with Discrete Optimization: Computational and Statistical Perspectives", "Authors": ["Kayhan Behdin", "Wenyu Chen", "Rahul Mazumder"], "Categories": "cs.LG stat.ME stat.ML"}, "abstract": "We consider the problem of learning a sparse graph underlying an undirected Gaussian graphical model, a key problem in statistical machine learning. Given $n$ samples from a multivariate Gaussian distribution with $p$ variables, the goal is to estimate the $p \\times p$ inverse covariance matrix (aka precision matrix), assuming it is sparse (i.e., has a few nonzero entries). We propose GraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the pseudolikelihood function, while most earlier approaches are based on the $\\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer program (MIP) which can be difficult to compute at scale using off-the-shelf commercial solvers. To solve the MIP, we propose a custom nonlinear branch-and-bound (BnB) framework that solves node relaxations with tailored first-order methods. As a by-product of our BnB framework, we propose large-scale solvers for obtaining good primal solutions that are of independent interest. We derive novel statistical guarantees (estimation and variable selection) for our estimator and discuss how our approach improves upon existing estimators. Our numerical experiments on real/synthetic datasets suggest that our method can solve, to near-optimality, problem instances with $p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with $p^2/2$ binary variables. We demonstrate the usefulness of GraphL0BnB versus various state-of-the-art approaches on a range of datasets.", "url": "https://arxiv.org/abs/2307.09366"}, {"metadata": {"arXiv": "2307.09372", "Date": "Tue, 18 Jul 2023 15:56:39 ", "Title": "Enhancing Pattern Classification in Support Vector Machines through Matrix Formulation", "Authors": ["Sambhav Jain Reshma Rastogi"], "Categories": "cs.LG"}, "abstract": "Support Vector Machines (SVM) have gathered significant acclaim as classifiers due to their successful implementation of Statistical Learning Theory. However, in the context of multiclass and multilabel settings, the reliance on vector-based formulations in existing SVM-based models poses limitations regarding flexibility and ease of incorporating additional terms to handle specific challenges. To overcome these limitations, our research paper focuses on introducing a matrix formulation for SVM that effectively addresses these constraints. By employing the Accelerated Gradient Descent method in the dual, we notably enhance the efficiency of solving the Matrix-SVM problem. Experimental evaluations on multilabel and multiclass datasets demonstrate that Matrix SVM achieves superior time efficacy while delivering similar results to Binary Relevance SVM. Moreover, our matrix formulation unveils crucial insights and advantages that may not be readily apparent in traditional vector-based notations. We emphasize that numerous multilabel models can be viewed as extensions of SVM, with customised modifications to meet specific requirements. The matrix formulation presented in this paper establishes a solid foundation for developing more sophisticated models capable of effectively addressing the distinctive challenges encountered in multilabel learning.", "url": "https://arxiv.org/abs/2307.09372"}, {"metadata": {"arXiv": "2307.09377", "Date": "Tue, 18 Jul 2023 16:00:02 ", "Title": "Data Cross-Segmentation for Improved Generalization in Reinforcement Learning Based Algorithmic Trading", "Authors": ["Vikram Duvvur", "Aashay Mehta", "Edward Sun", "Bo Wu", "Ken Yew Chan", "Jeff Schneider"], "Categories": "cs.LG"}, "abstract": "The use of machine learning in algorithmic trading systems is increasingly common. In a typical set-up, supervised learning is used to predict the future prices of assets, and those predictions drive a simple trading and execution strategy. This is quite effective when the predictions have sufficient signal, markets are liquid, and transaction costs are low. However, those conditions often do not hold in thinly traded financial markets and markets for differentiated assets such as real estate or vehicles. In these markets, the trading strategy must consider the long-term effects of taking positions that are relatively more difficult to change. In this work, we propose a Reinforcement Learning (RL) algorithm that trades based on signals from a learned predictive model and addresses these challenges. We test our algorithm on 20+ years of equity data from Bursa Malaysia.", "url": "https://arxiv.org/abs/2307.09377"}, {"metadata": {"arXiv": "2307.09388", "Date": "Tue, 18 Jul 2023 16:13:35 ", "Title": "Online Learning with Costly Features in Non-stationary Environments", "Authors": ["Saeed Ghoorchian", "Evgenii Kortukov", "Setareh Maghsudi"], "Categories": "cs.LG", "Comments": ["31 pages", "6 figures"]}, "abstract": "Maximizing long-term rewards is the primary goal in sequential decision-making problems. The majority of existing methods assume that side information is freely available, enabling the learning agent to observe all features' states before making a decision. In real-world problems, however, collecting beneficial information is often costly. That implies that, besides individual arms' reward, learning the observations of the features' states is essential to improve the decision-making strategy. The problem is aggravated in a non-stationary environment where reward and cost distributions undergo abrupt changes over time. To address the aforementioned dual learning problem, we extend the contextual bandit setting and allow the agent to observe subsets of features' states. The objective is to maximize the long-term average gain, which is the difference between the accumulated rewards and the paid costs on average. Therefore, the agent faces a trade-off between minimizing the cost of information acquisition and possibly improving the decision-making process using the obtained information. To this end, we develop an algorithm that guarantees a sublinear regret in time. Numerical results demonstrate the superiority of our proposed policy in a real-world scenario.", "url": "https://arxiv.org/abs/2307.09388"}, {"metadata": {"arXiv": "2307.09458", "Date": "Tue, 18 Jul 2023 17:39:04 ", "Title": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla", "Authors": ["Tom Lieberum", "Matthew Rahtz", "J\\'anos Kram\\'ar", "Geoffrey Irving", "Rohin Shah", "Vladimir Mikulik"], "Categories": "cs.LG"}, "abstract": "\\emph{Circuit analysis} is a promising technique for understanding the internal mechanisms of language models. However, existing analyses are done in small models far from the state of the art. To address this, we present a case study of circuit analysis in the 70B Chinchilla model, aiming to test the scalability of circuit analysis. In particular, we study multiple-choice question answering, and investigate Chinchilla's capability to identify the correct answer \\emph{label} given knowledge of the correct answer \\emph{text}. We find that the existing techniques of logit attribution, attention pattern visualization, and activation patching naturally scale to Chinchilla, allowing us to identify and categorize a small set of `output nodes' (attention heads and MLPs). We further study the `correct letter' category of attention heads aiming to understand the semantics of their features, with mixed results. For normal multiple-choice question answers, we significantly compress the query, key and value subspaces of the head without loss of performance when operating on the answer labels for multiple-choice questions, and we show that the query and key subspaces represent an `Nth item in an enumeration' feature to at least some extent. However, when we attempt to use this explanation to understand the heads' behaviour on a more general distribution including randomized answer labels, we find that it is only a partial explanation, suggesting there is more to learn about the operation of `correct letter' heads on multiple choice question answering.", "url": "https://arxiv.org/abs/2307.09458"}, {"metadata": {"arXiv": "2307.09483", "Date": "Tue, 18 Jul 2023 17:59:25 ", "Title": "Forecasting the steam mass flow in a powerplant using the parallel hybrid network", "Authors": ["Andrii Kurkin", "Jonas Hegemann", "Mo Kordzanganeh", "Alexey Melnikov"], "Categories": "cs.LG cs.SE physics.data-an quant-ph", "Comments": ["11 pages", "5 figures"]}, "abstract": "Efficient and sustainable power generation is a crucial concern in the energy sector. In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction. In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future. Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error (MSE) loss on the test set after training compared to pure classical and pure quantum networks, respectively. Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model. These findings contribute to the broader scientific understanding of how integrating quantum and classical machine learning techniques can be applied to real-world challenges faced by the energy sector, ultimately leading to optimized power plant operations.", "url": "https://arxiv.org/abs/2307.09483"}, {"metadata": {"arXiv": "2307.09206", "Date": "Tue, 18 Jul 2023 12:42:59 ", "Title": "Context-Conditional Navigation with a Learning-Based Terrain- and Robot-Aware Dynamics Model", "Authors": ["Suresh Guttikonda", "Jan Achterhold", "Haolong Li", "Joschka Boedecker", "Joerg Stueckler"], "Categories": "cs.RO cs.LG", "Comments": ["\\copyright 2023 IEEE. To be presented at the 2023 European Conference on Mobile Robots (ECMR)"]}, "abstract": "In autonomous navigation settings, several quantities can be subject to variations. Terrain properties such as friction coefficients may vary over time depending on the location of the robot. Also, the dynamics of the robot may change due to, e.g., different payloads, changing the system's mass, or wear and tear, changing actuator gains or joint friction. An autonomous agent should thus be able to adapt to such variations. In this paper, we develop a novel probabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN, which is able to adapt to the above-mentioned variations. It builds on recent advances in meta-learning forward dynamics models based on Neural Processes. We evaluate our method in a simulated 2D navigation setting with a unicycle-like robot and different terrain layouts with spatially varying friction coefficients. In our experiments, the proposed model exhibits lower prediction error for the task of long-horizon trajectory prediction, compared to non-adaptive ablation models. We also evaluate our model on the downstream task of navigation planning, which demonstrates improved performance in planning control-efficient paths by taking robot and terrain properties into account.", "url": "https://arxiv.org/abs/2307.09206"}, {"metadata": {"arXiv": "2307.08721", "Date": "Mon, 17 Jul 2023 05:37:49 ", "Title": "Where Did the President Visit Last Week? Detecting Celebrity Trips from News Articles", "Authors": ["Kai Peng", "Ying Zhang", "Shuai Ling", "Zhaoru Ke", "Haipeng Zhang"], "Categories": "cs.AI", "Comments": ["Accepted to ICWSM 2024", "12 pages"]}, "abstract": "Celebrities' whereabouts are of pervasive importance. For instance, where politicians go, how often they visit, and who they meet, come with profound geopolitical and economic implications. Although news articles contain travel information of celebrities, it is not possible to perform large-scale and network-wise analysis due to the lack of automatic itinerary detection tools. To design such tools, we have to overcome difficulties from the heterogeneity among news articles: 1)One single article can be noisy, with irrelevant people and locations, especially when the articles are long. 2)Though it may be helpful if we consider multiple articles together to determine a particular trip, the key semantics are still scattered across different articles intertwined with various noises, making it hard to aggregate them effectively. 3)Over 20% of the articles refer to the celebrities' trips indirectly, instead of using the exact celebrity names or location names, leading to large portions of trips escaping regular detecting algorithms. We model text content across articles related to each candidate location as a graph to better associate essential information and cancel out the noises. Besides, we design a special pooling layer based on attention mechanism and node similarity, reducing irrelevant information from longer articles. To make up the missing information resulted from indirect mentions, we construct knowledge sub-graphs for named entities (person, organization, facility, etc.). Specifically, we dynamically update embeddings of event entities like the G7 summit from news descriptions since the properties (date and location) of the event change each time, which is not captured by the pre-trained event representations. The proposed CeleTrip jointly trains these modules, which outperforms all baseline models and achieves 82.53% in the F1 metric.", "url": "https://arxiv.org/abs/2307.08721"}, {"metadata": {"arXiv": "2307.08774", "Date": "Mon, 17 Jul 2023 18:41:03 ", "Title": "Reflections from the Workshop on AI-Assisted Decision Making for Conservation", "Authors": ["Lily Xu", "Esther Rolf", "Sara Beery", "Joseph R. Bennett", "Tanya Berger-Wolf", "Tanya Birch", "Elizabeth Bondi-Kelly", "Justin Brashares", "Melissa Chapman", "Anthony Corso", "Andrew Davies", "Nikhil Garg", "Angela Gaylard", "Robert Heilmayr", "Hannah Kerner", "Konstantin Klemmer", "Vipin Kumar", "Lester Mackey", "Claire Monteleoni", "Paul Moorcroft", "Jonathan Palmer", "Andrew Perrault", "David Thau", "Milind Tambe"], "Categories": "cs.AI", "Comments": ["Co-authored by participants from the October 2022 workshop: https://crcs.seas.harvard.edu/conservation-workshop"]}, "abstract": "In this white paper, we synthesize key points made during presentations and discussions from the AI-Assisted Decision Making for Conservation workshop, hosted by the Center for Research on Computation and Society at Harvard University on October 20-21, 2022. We identify key open research questions in resource allocation, planning, and interventions for biodiversity conservation, highlighting conservation challenges that not only require AI solutions, but also require novel methodological advances. In addition to providing a summary of the workshop talks and discussions, we hope this document serves as a call-to-action to orient the expansion of algorithmic decision-making approaches to prioritize real-world conservation challenges, through collaborative efforts of ecologists, conservation decision-makers, and AI researchers.", "url": "https://arxiv.org/abs/2307.08774"}, {"metadata": {"arXiv": "2307.08775", "Date": "Mon, 17 Jul 2023 18:42:05 ", "Title": "GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution", "Authors": ["Yining Lu and Haoping Yu and Daniel Khashabi"], "Categories": "cs.AI"}, "abstract": "Augmenting large language models (LLM) to use external tools enhances their performance across a variety of tasks. However, prior works over-rely on task-specific demonstration of tool use that limits their generalizability and computational cost due to making many calls to large-scale LLMs. We introduce GEAR, a computationally efficient query-tool grounding algorithm that is generalizable to various tasks that require tool use while not relying on task-specific demonstrations. GEAR achieves better efficiency by delegating tool grounding and execution to small language models (SLM) and LLM, respectively; while leveraging semantic and pattern-based evaluation at both question and answer levels for generalizable tool grounding. We evaluate GEAR on 14 datasets across 6 downstream tasks, demonstrating its strong generalizability to novel tasks, tools and different SLMs. Despite offering more efficiency, GEAR achieves higher precision in tool grounding compared to prior strategies using LLM prompting, thus improving downstream accuracy at a reduced computational cost. For example, we demonstrate that GEAR-augmented GPT-J and GPT-3 outperform counterpart tool-augmented baselines because of better tool use.", "url": "https://arxiv.org/abs/2307.08775"}, {"metadata": {"arXiv": "2307.08876", "Date": "Mon, 17 Jul 2023 22:17:40 ", "Title": "AI for the Generation and Testing of Ideas Towards an AI Supported Knowledge Development Environment", "Authors": ["Ted Selker"], "Categories": "cs.AI", "Comments": ["8 pages", "21 references"], "ACM-class": "H.5.0; I.2.0"}, "abstract": "New systems employ Machine Learning to sift through large knowledge sources, creating flexible Large Language Models. These models discern context and predict sequential information in various communication forms. Generative AI, leveraging Transformers, generates textual or visual outputs mimicking human responses. It proposes one or multiple contextually feasible solutions for a user to contemplate. However, generative AI does not currently support traceability of ideas, a useful feature provided by search engines indicating origin of information. The narrative style of generative AI has gained positive reception. People learn from stories. Yet, early ChatGPT efforts had difficulty with truth, reference, calculations, and aspects like accurate maps. Current capabilities of referencing locations and linking to apps seem to be better catered by the link-centric search methods we've used for two decades. Deploying truly believable solutions extends beyond simulating contextual relevance as done by generative AI. Combining the creativity of generative AI with the provenance of internet sources in hybrid scenarios could enhance internet usage. Generative AI, viewed as drafts, stimulates thinking, offering alternative ideas for final versions or actions. Scenarios for information requests are considered. We discuss how generative AI can boost idea generation by eliminating human bias. We also describe how search can verify facts, logic, and context. The user evaluates these generated ideas for selection and usage. This paper introduces a system for knowledge workers, Generate And Search Test, enabling individuals to efficiently create solutions previously requiring top collaborations of experts.", "url": "https://arxiv.org/abs/2307.08876"}, {"metadata": {"arXiv": "2307.08974", "Date": "Tue, 18 Jul 2023 05:12:52 ", "Title": "Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines", "Authors": ["Giovanni E. Cacciamani", "Michael B. Eppler", "Conner Ganjavi", "Asli Pekan", "Brett Biedermann", "Gary S. Collins", "Inderbir S. Gill"], "Categories": "cs.AI cs.CY", "Comments": ["20 pages", "1 figure", "protocol"], "Report-no": "up-23-00306"}, "abstract": "The swift progress and ubiquitous adoption of Generative AI (GAI), Generative Pre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT, have spurred queries about their ethical application, use, and disclosure in scholarly research and scientific productions. A few publishers and journals have recently created their own sets of rules; however, the absence of a unified approach may lead to a 'Babel Tower Effect,' potentially resulting in confusion rather than desired standardization. In response to this, we present the ChatGPT, Generative Artificial Intelligence, and Natural Large Language Models for Accountable Reporting and Use Guidelines (CANGARU) initiative, with the aim of fostering a cross-disciplinary global inclusive consensus on the ethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies in academia. The present protocol consists of four distinct parts: a) an ongoing systematic review of GAI/GPT/LLM applications to understand the linked ideas, findings, and reporting standards in scholarly research, and to formulate guidelines for its use and disclosure, b) a bibliometric analysis of existing author guidelines in journals that mention GAI/GPT/LLM, with the goal of evaluating existing guidelines, analyzing the disparity in their recommendations, and identifying common rules that can be brought into the Delphi consensus process, c) a Delphi survey to establish agreement on the items for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, and reporting in academia, and d) the subsequent development and dissemination of the finalized guidelines and their supplementary explanation and elaboration documents.", "url": "https://arxiv.org/abs/2307.08974"}, {"metadata": {"arXiv": "2307.09004", "Date": "Tue, 18 Jul 2023 06:44:20 ", "Title": "Ord2Seq: Regard Ordinal Regression as Label Sequence Prediction", "Authors": ["Jinhong Wang", "Yi Cheng", "Jintai Chen", "Tingting Chen", "Danny Chen and Jian Wu"], "Categories": "cs.AI cs.CV", "Comments": ["Accepted by ICCV2023"]}, "abstract": "Ordinal regression refers to classifying object instances into ordinal categories. It has been widely studied in many scenarios, such as medical disease grading, movie rating, etc. Known methods focused only on learning inter-class ordinal relationships, but still incur limitations in distinguishing adjacent categories thus far. In this paper, we propose a simple sequence prediction framework for ordinal regression called Ord2Seq, which, for the first time, transforms each ordinal category label into a special label sequence and thus regards an ordinal regression task as a sequence prediction process. In this way, we decompose an ordinal regression task into a series of recursive binary classification steps, so as to subtly distinguish adjacent categories. Comprehensive experiments show the effectiveness of distinguishing adjacent categories for performance improvement and our new approach exceeds state-of-the-art performances in four different scenarios. Codes will be available upon acceptance.", "url": "https://arxiv.org/abs/2307.09004"}, {"metadata": {"arXiv": "2307.09036", "Date": "Tue, 18 Jul 2023 07:46:25 ", "Title": "PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation", "Authors": ["Yingchaojie Feng", "Xingbo Wang", "Kam Kwai Wong", "Sijia Wang", "Yuhong Lu", "Minfeng Zhu", "Baicheng Wang", "Wei Chen"], "Categories": "cs.AI cs.HC", "Comments": ["Accepted full paper for IEEE VIS 2023"]}, "abstract": "Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model.", "url": "https://arxiv.org/abs/2307.09036"}, {"metadata": {"arXiv": "2307.09042", "Date": "Tue, 18 Jul 2023 07:49:38 ", "Title": "Emotional Intelligence of Large Language Models", "Authors": ["Xuena Wang (1)", "Xueting Li (2)", "Zi Yin (1)", "Yue Wu (1) and Liu Jia (1) ((1) Department of Psychology & Tsinghua Laboratory of Brain and Intelligence", "Tsinghua University", "(2) Department of Psychology", "Renmin University)"], "Categories": "cs.AI", "Comments": ["34 pages", "4 figures"]}, "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI, suitable for both humans and LLMs. This test requires evaluating complex emotions (e.g., surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite feeling underperformed, John surprisingly achieved a top score). With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not reply on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-intelligence.github.io/", "url": "https://arxiv.org/abs/2307.09042"}, {"metadata": {"arXiv": "2307.09047", "Date": "Tue, 18 Jul 2023 07:59:37 ", "Title": "Multimodal Machine Learning for Extraction of Theorems and Proofs in the Scientific Literature", "Authors": ["Shrey Mishra", "Antoine Gauquier", "Pierre Senellart"], "Categories": "cs.AI", "Comments": ["15 pages"]}, "abstract": "Scholarly articles in mathematical fields feature mathematical statements such as theorems, propositions, etc., as well as their proofs. Extracting them from the PDF representation of the articles requires understanding of scientific text along with visual and font-based indicators. We pose this problem as a multimodal classification problem using text, font features, and bitmap image rendering of the PDF as different modalities. In this paper we propose a multimodal machine learning approach for extraction of theorem-like environments and proofs, based on late fusion of features extracted by individual unimodal classifiers, taking into account the sequential succession of blocks in the document. For the text modality, we pretrain a new language model on a 11 GB scientific corpus; experiments shows similar performance for our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence while requiring much less fine-tuning data. Font-based information relies on training a 128-cell LSTM on the sequence of font names and sizes within each block. Bitmap renderings are dealt with using an EfficientNetv2 deep network tuned to classify each image block. Finally, a simple CRF-based approach uses the features of the multimodal model along with information on block sequences. Experimental results show the benefits of using a multimodal approach vs any single modality, as well as major performance improvements using the CRF modeling of block sequences.", "url": "https://arxiv.org/abs/2307.09047"}, {"metadata": {"arXiv": "2307.09051", "Date": "Tue, 18 Jul 2023 08:04:27 ", "Title": "QMNet: Importance-Aware Message Exchange for Decentralized Multi-Agent Reinforcement Learning", "Authors": ["Xiufeng Huang", "Sheng Zhou"], "Categories": "cs.AI"}, "abstract": "To improve the performance of multi-agent reinforcement learning under the constraint of wireless resources, we propose a message importance metric and design an importance-aware scheduling policy to effectively exchange messages. The key insight is spending the precious communication resources on important messages. The message importance depends not only on the messages themselves, but also on the needs of agents who receive them. Accordingly, we propose a query-message-based architecture, called QMNet. Agents generate queries and messages with the environment observation. Sharing queries can help calculate message importance. Exchanging messages can help agents cooperate better. Besides, we exploit the message importance to deal with random access collisions in decentralized systems. Furthermore, a message prediction mechanism is proposed to compensate for messages that are not transmitted. Finally, we evaluate the proposed schemes in a traffic junction environment, where only a fraction of agents can send messages due to limited wireless resources. Results show that QMNet can extract valuable information to guarantee the system performance even when only $30\\%$ of agents can share messages. By exploiting message prediction, the system can further save $40\\%$ of wireless resources. The importance-aware decentralized multi-access mechanism can effectively avoid collisions, achieving almost the same performance as centralized scheduling.", "url": "https://arxiv.org/abs/2307.09051"}, {"metadata": {"arXiv": "2307.09141", "Date": "Tue, 18 Jul 2023 10:46:28 ", "Title": "Machine Learning for SAT: Restricted Heuristics and New Graph Representations", "Authors": ["Mikhail Shirokikh", "Ilya Shenbin", "Anton Alekseev", "Sergey Nikolenko"], "Categories": "cs.AI"}, "abstract": "Boolean satisfiability (SAT) is a fundamental NP-complete problem with many applications, including automated planning and scheduling. To solve large instances, SAT solvers have to rely on heuristics, e.g., choosing a branching variable in DPLL and CDCL solvers. Such heuristics can be improved with machine learning (ML) models; they can reduce the number of steps but usually hinder the running time because useful models are relatively large and slow. We suggest the strategy of making a few initial steps with a trained ML model and then releasing control to classical heuristics; this simplifies cold start for SAT solving and can decrease both the number of steps and overall runtime, but requires a separate decision of when to release control to the solver. Moreover, we introduce a modification of Graph-Q-SAT tailored to SAT problems converted from other domains, e.g., open shop scheduling problems. We validate the feasibility of our approach with random and industrial SAT problems.", "url": "https://arxiv.org/abs/2307.09141"}, {"metadata": {"arXiv": "2307.09166", "Date": "Sat, 15 Jul 2023 08:09:28 ", "Title": "Safe Formulas in the General Theory of Stable Models", "Authors": ["Joohyung Lee", "Vladimir Lifschitz", "Ravi Palla"], "Categories": "cs.AI", "Comments": ["16 pages"]}, "abstract": "Safe first-order formulas generalize the concept of a safe rule, which plays an important role in the design of answer set solvers. We show that any safe sentence is equivalent, in a certain sense, to the result of its grounding -- to the variable-free sentence obtained from it by replacing all quantifiers with multiple conjunctions and disjunctions. It follows that a safe sentence and the result of its grounding have the same stable models, and that the stable models of a safe sentence can be characterized by a formula of a simple syntactic form.", "url": "https://arxiv.org/abs/2307.09166"}, {"metadata": {"arXiv": "2307.09168", "Date": "Sat, 15 Jul 2023 08:00:46 ", "Title": "Elementary Sets for Logic Programs", "Authors": ["Martin Gebser", "Joohyung Lee", "Yuliya Lierler"], "Categories": "cs.AI", "Comments": ["6 pages. AAAI 2006", "244-249. arXiv admin note: substantial text overlap with arXiv:1012.5847"]}, "abstract": "By introducing the concepts of a loop and a loop formula, Lin and Zhao showed that the answer sets of a nondisjunctive logic program are exactly the models of its Clark's completion that satisfy the loop formulas of all loops. Recently, Gebser and Schaub showed that the Lin-Zhao theorem remains correct even if we restrict loop formulas to a special class of loops called ``elementary loops.'' In this paper, we simplify and generalize the notion of an elementary loop, and clarify its role. We propose the notion of an elementary set, which is almost equivalent to the notion of an elementary loop for nondisjunctive programs, but is simpler, and, unlike elementary loops, can be extended to disjunctive programs without producing unintuitive results. We show that the maximal unfounded elementary sets for the ``relevant'' part of a program are exactly the minimal sets among the nonempty unfounded sets. We also present a graph-theoretic characterization of elementary sets for nondisjunctive programs, which is simpler than the one proposed in (Gebser & Schaub 2005). Unlike the case of nondisjunctive programs, we show that the problem of deciding an elementary set is coNP-complete for disjunctive programs.", "url": "https://arxiv.org/abs/2307.09168"}, {"metadata": {"arXiv": "2307.09193", "Date": "Tue, 18 Jul 2023 12:25:40 ", "Title": "ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint", "Authors": ["Zhenhao Jiang", "Biao Zeng", "Hao Feng", "Jin Liu", "Jicong Fan", "Jie Zhang", "Jia Jia", "Ning Hu", "Xingyu Chen", "Xuguang Lan"], "Categories": "cs.AI cs.IR"}, "abstract": "Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations. However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues. Entire space models were proposed to address the two issues via tracing the decision-making path of \"exposure_click_purchase\". Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance. Thus, the decision-making path has been extended to \"exposure_click_in-shop action_purchase\" and can be modeled with conditional probability approach. Nevertheless, we observe that the chain rule of conditional probability does not always hold. We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematically. We propose a novel Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue. Specifically, we handle \"exposure_click_in-shop action\" and \"in-shop action_purchase\" separately in the light of characteristics of in-shop action. The first path is still treated with conditional probability while the second one is treated with parameter constraint strategy. Experiments on both offline and online environments in a large-scale recommendation system illustrate the superiority of our proposed methods over state-of-the-art models. The real-world datasets will be released.", "url": "https://arxiv.org/abs/2307.09193"}, {"metadata": {"arXiv": "2307.09225", "Date": "Tue, 18 Jul 2023 12:57:35 ", "Title": "Human Body Digital Twin: A Master Plan", "Authors": ["Chenyu Tang", "Shuo Gao", "and Luigi G. Occhipinti"], "Categories": "cs.AI eess.SP", "Comments": ["3 figures"]}, "abstract": "The human body DT has the potential to revolutionize healthcare and wellness, but its responsible and effective implementation requires consideration of various factors. This article presents a comprehensive overview of the current status and future prospects of the human body DT and proposes a five-level roadmap for its development. The roadmap covers the development of various components, such as wearable devices, data collection, data analysis, and decision-making systems. The article also highlights the necessary support, security, cost, and ethical considerations that must be addressed in order to ensure responsible and effective implementation of the human body DT. The proposed roadmap provides a framework for guiding future development and offers a unique perspective on the future of the human body DT, facilitating new interdisciplinary research and innovative solutions in this rapidly evolving field.", "url": "https://arxiv.org/abs/2307.09225"}, {"metadata": {"arXiv": "2307.09296", "Date": "Tue, 18 Jul 2023 14:37:23 ", "Title": "Rumor Detection with Diverse Counterfactual Evidence", "Authors": ["Kaiwei Zhang", "Junchi Yu", "Haichao Shi", "Jian Liang", "Xiao-Yu Zhang"], "Categories": "cs.AI"}, "abstract": "The growth in social media has exacerbated the threat of fake news to individuals and communities. This draws increasing attention to developing efficient and timely rumor detection methods. The prevailing approaches resort to graph neural networks (GNNs) to exploit the post-propagation patterns of the rumor-spreading process. However, these methods lack inherent interpretation of rumor detection due to the black-box nature of GNNs. Moreover, these methods suffer from less robust results as they employ all the propagation patterns for rumor detection. In this paper, we address the above issues with the proposed Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). Our intuition is to exploit the diverse counterfactual evidence of an event graph to serve as multi-view interpretations, which are further aggregated for robust rumor detection results. Specifically, our method first designs a subgraph generation strategy to efficiently generate different subgraphs of the event graph. We constrain the removal of these subgraphs to cause the change in rumor detection results. Thus, these subgraphs naturally serve as counterfactual evidence for rumor detection. To achieve multi-view interpretation, we design a diversity loss inspired by Determinantal Point Processes (DPP) to encourage diversity among the counterfactual evidence. A GNN-based rumor detection model further aggregates the diverse counterfactual evidence discovered by the proposed DCE-RD to achieve interpretable and robust rumor detection results. Extensive experiments on two real-world datasets show the superior performance of our method. Our code is available at https://github.com/Vicinity111/DCE-RD.", "url": "https://arxiv.org/abs/2307.09296"}, {"metadata": {"arXiv": "2307.09332", "Date": "Tue, 18 Jul 2023 15:14:09 ", "Title": "Company2Vec -- German Company Embeddings based on Corporate Websites", "Authors": ["Christopher Gerling"], "Categories": "cs.AI q-fin.CP q-fin.PM", "Comments": ["Accepted for Publication in: International Journal of Information Technology & Decision Making (2023)"], "DOI": "10.1142/S0219622023500694"}, "abstract": "With Company2Vec, the paper proposes a novel application in representation learning. The model analyzes business activities from unstructured company website data using Word2Vec and dimensionality reduction. Company2Vec maintains semantic language structures and thus creates efficient company embeddings in fine-granular industries. These semantic embeddings can be used for various applications in banking. Direct relations between companies and words allow semantic business analytics (e.g. top-n words for a company). Furthermore, industry prediction is presented as a supervised learning application and evaluation method. The vectorized structure of the embeddings allows measuring companies similarities with the cosine distance. Company2Vec hence offers a more fine-grained comparison of companies than the standard industry labels (NACE). This property is relevant for unsupervised learning tasks, such as clustering. An alternative industry segmentation is shown with k-means clustering on the company embeddings. Finally, this paper proposes three algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric peer-firm identification.", "url": "https://arxiv.org/abs/2307.09332"}, {"metadata": {"arXiv": "2307.09364", "Date": "Tue, 18 Jul 2023 15:48:37 ", "Title": "Local Minima Drive Communications in Cooperative Interaction", "Authors": ["Roger K. Moore"], "Categories": "cs.AI cs.MA cs.RO", "Comments": ["6 page conference paper"]}, "abstract": "An important open question in human-robot interaction (HRI) is precisely when an agent should decide to communicate, particularly in a cooperative task. Perceptual Control Theory (PCT) tells us that agents are able to cooperate on a joint task simply by sharing the same 'intention', thereby distributing the effort required to complete the task among the agents. This is even true for agents that do not possess the same abilities, so long as the goal is observable, the combined actions are sufficient to complete the task, and there is no local minimum in the search space. If these conditions hold, then a cooperative task can be accomplished without any communication between the contributing agents. However, for tasks that do contain local minima, the global solution can only be reached if at least one of the agents adapts its intention at the appropriate moments, and this can only be achieved by appropriately timed communication. In other words, it is hypothesised that in cooperative tasks, the function of communication is to coordinate actions in a complex search space that contains local minima. These principles have been verified in a computer-based simulation environment in which two independent one-dimensional agents are obliged to cooperate in order to solve a two-dimensional path-finding task.", "url": "https://arxiv.org/abs/2307.09364"}, {"metadata": {"arXiv": "2307.09426", "Date": "Tue, 18 Jul 2023 16:53:07 ", "Title": "Balancing Privacy and Progress in Artificial Intelligence: Anonymization in Histopathology for Biomedical Research and Education", "Authors": ["Neel Kanwal", "Emiel A.M. Janssen", "Kjersti Engan"], "Categories": "cs.AI cs.CE cs.CR", "Comments": ["Submitted to FAIEMA 2023"]}, "abstract": "The advancement of biomedical research heavily relies on access to large amounts of medical data. In the case of histopathology, Whole Slide Images (WSI) and clinicopathological information are valuable for developing Artificial Intelligence (AI) algorithms for Digital Pathology (DP). Transferring medical data \"as open as possible\" enhances the usability of the data for secondary purposes but poses a risk to patient privacy. At the same time, existing regulations push towards keeping medical data \"as closed as necessary\" to avoid re-identification risks. Generally, these legal regulations require the removal of sensitive data but do not consider the possibility of data linkage attacks due to modern image-matching algorithms. In addition, the lack of standardization in DP makes it harder to establish a single solution for all formats of WSIs. These challenges raise problems for bio-informatics researchers in balancing privacy and progress while developing AI algorithms. This paper explores the legal regulations and terminologies for medical data-sharing. We review existing approaches and highlight challenges from the histopathological perspective. We also present a data-sharing guideline for histological data to foster multidisciplinary research and education.", "url": "https://arxiv.org/abs/2307.09426"}, {"metadata": {"arXiv": "2307.08930", "Date": "Tue, 18 Jul 2023 02:35:01 ", "Title": "Unsupervised Deep Graph Matching Based on Cycle Consistency", "Authors": ["Siddharth Tourani", "Carsten Rother and Muhammad Haris Khan and Bogdan Savchynskkyy"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "5 figures", "3 papers. ICCV 2023 reject"]}, "abstract": "We contribute to the sparsely populated area of unsupervised deep graph matching with application to keypoint matching in images. Contrary to the standard \\emph{supervised} approach, our method does not require ground truth correspondences between keypoint pairs. Instead, it is self-supervised by enforcing consistency of matchings between images of the same object category. As the matching and the consistency loss are discrete, their derivatives cannot be straightforwardly used for learning. We address this issue in a principled way by building our method upon the recent results on black-box differentiation of combinatorial solvers. This makes our method exceptionally flexible, as it is compatible with arbitrary network architectures and combinatorial solvers. Our experimental evaluation suggests that our technique sets a new state-of-the-art for unsupervised graph matching.", "url": "https://arxiv.org/abs/2307.08930"}, {"metadata": {"arXiv": "2307.08988", "Date": "Tue, 18 Jul 2023 05:59:27 ", "Title": "EVIL: Evidential Inference Learning for Trustworthy Semi-supervised Medical Image Segmentation", "Authors": ["Yingyu Chen", "Ziyuan Yang", "Chenyu Shen", "Zhiwen Wang", "Yang Qin", "Yi Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, uncertainty-aware methods have attracted increasing attention in semi-supervised medical image segmentation. However, current methods usually suffer from the drawback that it is difficult to balance the computational cost, estimation accuracy, and theoretical support in a unified framework. To alleviate this problem, we introduce the Dempster-Shafer Theory of Evidence (DST) into semi-supervised medical image segmentation, dubbed Evidential Inference Learning (EVIL). EVIL provides a theoretically guaranteed solution to infer accurate uncertainty quantification in a single forward pass. Trustworthy pseudo labels on unlabeled data are generated after uncertainty estimation. The recently proposed consistency regularization-based training paradigm is adopted in our framework, which enforces the consistency on the perturbed predictions to enhance the generalization with few labeled data. Experimental results show that EVIL achieves competitive performance in comparison with several state-of-the-art methods on the public dataset.", "url": "https://arxiv.org/abs/2307.08988"}, {"metadata": {"arXiv": "2307.09050", "Date": "Tue, 18 Jul 2023 08:03:51 ", "Title": "R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut", "Authors": ["Yingjie Niu", "Ming Ding", "Maoning Ge", "Robin Karlsson", "Yuxiao Zhang", "and Kazuya Takeda"], "Categories": "cs.CV cs.AI"}, "abstract": "Transformer-based models have gained popularity in the field of natural language processing (NLP) and are extensively utilized in computer vision tasks and multi-modal models such as GPT4. This paper presents a novel method to enhance the explainability of Transformer-based image classification models. Our method aims to improve trust in classification results and empower users to gain a deeper understanding of the model for downstream tasks by providing visualizations of class-specific maps. We introduce two modules: the ``Relationship Weighted Out\" and the ``Cut\" modules. The ``Relationship Weighted Out\" module focuses on extracting class-specific information from intermediate layers, enabling us to highlight relevant features. Additionally, the ``Cut\" module performs fine-grained feature decomposition, taking into account factors such as position, texture, and color. By integrating these modules, we generate dense class-specific visual explainability maps. We validate our method with extensive qualitative and quantitative experiments on the ImageNet dataset. Furthermore, we conduct a large number of experiments on the LRN dataset, specifically designed for automatic driving danger alerts, to evaluate the explainability of our method in complex backgrounds. The results demonstrate a significant improvement over previous methods. Moreover, we conduct ablation experiments to validate the effectiveness of each module. Through these experiments, we are able to confirm the respective contributions of each module, thus solidifying the overall effectiveness of our proposed approach.", "url": "https://arxiv.org/abs/2307.09050"}, {"metadata": {"arXiv": "2307.09099", "Date": "Tue, 18 Jul 2023 09:42:51 ", "Title": "A Survey on Multi-Objective Neural Architecture Search", "Authors": ["Seyed Mahdi Shariatzadeh", "Mahmood Fathy", "Reza Berangi", "Mohammad Shahverdy"], "Categories": "cs.CV cs.AI", "Comments": ["22 pages", "10 figures", "9 tables"]}, "abstract": "Recently, the expert-crafted neural architectures is increasing overtaken by the utilization of neural architecture search (NAS) and automatic generation (and tuning) of network structures which has a close relation to the Hyperparameter Optimization and Auto Machine Learning (AutoML). After the earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective Neural architecture Search (MONAS) has been attracting attentions which considers more goals such as computational complexity, power consumption, and size of the network for optimization, reaching a trade-off between the accuracy and other features like the computational cost. In this paper, we present an overview of principal and state-of-the-art works in the field of MONAS. Starting from a well-categorized taxonomy and formulation for the NAS, we address and correct some miscategorizations in previous surveys of the NAS field. We also provide a list of all known objectives used and add a number of new ones and elaborate their specifications. We have provides analyses about the most important objectives and shown that the stochastic properties of some the them should be differed from deterministic ones in the multi-objective optimization procedure of NAS. We finalize this paper with a number of future directions and topics in the field of MONAS.", "url": "https://arxiv.org/abs/2307.09099"}, {"metadata": {"arXiv": "2307.09136", "Date": "Tue, 18 Jul 2023 10:34:21 ", "Title": "DropMix: Reducing Class Dependency in Mixed Sample Data Augmentation", "Authors": ["Haeil Lee", "Hansang Lee", "Junmo Kim"], "Categories": "cs.CV cs.AI", "Comments": ["17 pages", "10 figures"]}, "abstract": "Mixed sample data augmentation (MSDA) is a widely used technique that has been found to improve performance in a variety of tasks. However, in this paper, we show that the effects of MSDA are class-dependent, with some classes seeing an improvement in performance while others experience a decline. To reduce class dependency, we propose the DropMix method, which excludes a specific percentage of data from the MSDA computation. By training on a combination of MSDA and non-MSDA data, the proposed method not only improves the performance of classes that were previously degraded by MSDA, but also increases overall average accuracy, as shown in experiments on two datasets (CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and PuzzleMix).", "url": "https://arxiv.org/abs/2307.09136"}, {"metadata": {"arXiv": "2307.09132", "Date": "Tue, 18 Jul 2023 10:28:55 ", "Title": "Cloud-native RStudio on Kubernetes for Hopsworks", "Authors": ["Gibson Chikafa", "Sina Sheikholeslami", "Salman Niazi", "Jim Dowling", "Vladimir Vlassov"], "Categories": "cs.DC cs.AI cs.SE", "Comments": ["8 pages", "4 figures"]}, "abstract": "In order to fully benefit from cloud computing, services are designed following the \"multi-tenant\" architectural model, which is aimed at maximizing resource sharing among users. However, multi-tenancy introduces challenges of security, performance isolation, scaling, and customization. RStudio server is an open-source Integrated Development Environment (IDE) accessible over a web browser for the R programming language. We present the design and implementation of a multi-user distributed system on Hopsworks, a data-intensive AI platform, following the multi-tenant model that provides RStudio as Software as a Service (SaaS). We use the most popular cloud-native technologies: Docker and Kubernetes, to solve the problems of performance isolation, security, and scaling that are present in a multi-tenant environment. We further enable secure data sharing in RStudio server instances to provide data privacy and allow collaboration among RStudio users. We integrate our system with Apache Spark, which can scale and handle Big Data processing workloads. Also, we provide a UI where users can provide custom configurations and have full control of their own RStudio server instances. Our system was tested on a Google Cloud Platform cluster with four worker nodes, each with 30GB of RAM allocated to them. The tests on this cluster showed that 44 RStudio servers, each with 2GB of RAM, can be run concurrently. Our system can scale out to potentially support hundreds of concurrently running RStudio servers by adding more resources (CPUs and RAM) to the cluster or system.", "url": "https://arxiv.org/abs/2307.09132"}, {"metadata": {"arXiv": "2307.09114", "Date": "Tue, 18 Jul 2023 10:03:45 ", "Title": "BOLD: A Benchmark for Linked Data User Agents and a Simulation Framework for Dynamic Linked Data Environments", "Authors": ["Tobias K\\\"afer", "Victor Charpenay", "Andreas Harth"], "Categories": "eess.SY cs.AI cs.SY"}, "abstract": "The paper presents the BOLD (Buildings on Linked Data) benchmark for Linked Data agents, next to the framework to simulate dynamic Linked Data environments, using which we built BOLD. The BOLD benchmark instantiates the BOLD framework by providing a read-write Linked Data interface to a smart building with simulated time, occupancy movement and sensors and actuators around lighting. On the Linked Data representation of this environment, agents carry out several specified tasks, such as controlling illumination. The simulation environment provides means to check for the correct execution of the tasks and to measure the performance of agents. We conduct measurements on Linked Data agents based on condition-action rules.", "url": "https://arxiv.org/abs/2307.09114"}, {"metadata": {"arXiv": "2307.08810", "Date": "Mon, 17 Jul 2023 19:56:09 ", "Title": "Operator Guidance Informed by AI-Augmented Simulations", "Authors": ["Samuel J. Edwards and Michael Levine"], "Categories": "cs.AI cs.LG physics.ao-ph stat.AP", "Comments": ["Presented at the 22nd Conference on Computer Applications and Information Technology in the Maritime Industries (COMPIT) in Drubeck", "Germany on May 25th", "2023"], "MSC-class": "68T07", "ACM-class": "J.2"}, "abstract": "This paper will present a multi-fidelity, data-adaptive approach with a Long Short-Term Memory (LSTM) neural network to estimate ship response statistics in bimodal, bidirectional seas. The study will employ a fast low-fidelity, volume-based tool SimpleCode and a higher-fidelity tool known as the Large Amplitude Motion Program (LAMP). SimpleCode and LAMP data were generated by common bi-modal, bi-directional sea conditions in the North Atlantic as training data. After training an LSTM network with LAMP ship motion response data, a sample route was traversed and randomly sampled historical weather was input into SimpleCode and the LSTM network, and compared against the higher fidelity results.", "url": "https://arxiv.org/abs/2307.08810"}, {"metadata": {"arXiv": "2307.08849", "Date": "Mon, 17 Jul 2023 21:21:18 ", "Title": "Autoregressive Diffusion Model for Graph Generation", "Authors": ["Lingkai Kong", "Jiaming Cui", "Haotian Sun", "Yuchen Zhuang", "B. Aditya Prakash", "Chao Zhang"], "Categories": "cs.AI cs.LG", "Comments": ["18 pages"]}, "abstract": "Diffusion-based graph generative models have recently obtained promising results for graph generation. However, existing diffusion-based graph generative models are mostly one-shot generative models that apply Gaussian diffusion in the dequantized adjacency matrix space. Such a strategy can suffer from difficulty in model training, slow sampling speed, and incapability of incorporating constraints. We propose an \\emph{autoregressive diffusion} model for graph generation. Unlike existing methods, we define a node-absorbing diffusion process that operates directly in the discrete graph space. For forward diffusion, we design a \\emph{diffusion ordering network}, which learns a data-dependent node absorbing ordering from graph topology. For reverse generation, we design a \\emph{denoising network} that uses the reverse node ordering to efficiently reconstruct the graph by predicting the node type of the new node and its edges with previously denoised nodes at a time. Based on the permutation invariance of graph, we show that the two networks can be jointly trained by optimizing a simple lower bound of data likelihood. Our experiments on six diverse generic graph datasets and two molecule datasets show that our model achieves better or comparable generation performance with previous state-of-the-art, and meanwhile enjoys fast generation speed.", "url": "https://arxiv.org/abs/2307.08849"}, {"metadata": {"arXiv": "2307.08933", "Date": "Tue, 18 Jul 2023 02:43:19 ", "Title": "IxDRL: A Novel Explainable Deep Reinforcement Learning Toolkit based on Analyses of Interestingness", "Authors": ["Pedro Sequeira and Melinda Gervasio"], "Categories": "cs.AI cs.HC cs.LG", "Comments": ["To be published in the Proceedings of the 1st World Conference on eXplainable Artificial Intelligence (xAI 2023). arXiv admin note: substantial text overlap with arXiv:2211.06376"]}, "abstract": "In recent years, advances in deep learning have resulted in a plethora of successes in the use of reinforcement learning (RL) to solve complex sequential decision tasks with high-dimensional inputs. However, existing systems lack the necessary mechanisms to provide humans with a holistic view of their competence, presenting an impediment to their adoption, particularly in critical applications where the decisions an agent makes can have significant consequences. Yet, existing RL-based systems are essentially competency-unaware in that they lack the necessary interpretation mechanisms to allow human operators to have an insightful, holistic view of their competency. Towards more explainable Deep RL (xDRL), we propose a new framework based on analyses of interestingness. Our tool provides various measures of RL agent competence stemming from interestingness analysis and is applicable to a wide range of RL algorithms, natively supporting the popular RLLib toolkit. We showcase the use of our framework by applying the proposed pipeline in a set of scenarios of varying complexity. We empirically assess the capability of the approach in identifying agent behavior patterns and competency-controlling conditions, and the task elements mostly responsible for an agent's competence, based on global and local analyses of interestingness. Overall, we show that our framework can provide agent designers with insights about RL agent competence, both their capabilities and limitations, enabling more informed decisions about interventions, additional training, and other interactions in collaborative human-machine settings.", "url": "https://arxiv.org/abs/2307.08933"}, {"metadata": {"arXiv": "2307.08962", "Date": "Tue, 18 Jul 2023 04:26:33 ", "Title": "REX: Rapid Exploration and eXploitation for AI Agents", "Authors": ["Rithesh Murthy", "Shelby Heinecke", "Juan Carlos Niebles", "Zhiwei Liu", "Le Xue", "Weiran Yao", "Yihao Feng", "Zeyuan Chen", "Akash Gokul", "Devansh Arpit", "Ran Xu", "Phil Mui", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "Categories": "cs.AI cs.LG"}, "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL). REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance. This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning. Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniques. Notably, REX-based methods exhibit remarkable reductions in execution time, enhancing their practical applicability across a diverse set of scenarios.", "url": "https://arxiv.org/abs/2307.08962"}, {"metadata": {"arXiv": "2307.09320", "Date": "Tue, 18 Jul 2023 15:03:40 ", "Title": "Biomaker CA: a Biome Maker project using Cellular Automata", "Authors": ["Ettore Randazzo and Alexander Mordvintsev"], "Categories": "cs.AI cs.LG cs.NE", "Comments": ["20 pages", "23 figures. For code base", "see https://tinyurl.com/2x8yu34s"]}, "abstract": "We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA). In Biomaker CA, morphogenesis is a first class citizen and small seeds need to grow into plant-like organisms to survive in a nutrient starved environment and eventually reproduce with variation so that a biome survives for long timelines. We simulate complex biomes by means of CA rules in 2D grids and parallelize all of its computation on GPUs through the Python JAX framework. We show how this project allows for several different kinds of environments and laws of 'physics', alongside different model architectures and mutation strategies. We further analyze some configurations to show how plant agents can grow, survive, reproduce, and evolve, forming stable and unstable biomes. We then demonstrate how one can meta-evolve models to survive in a harsh environment either through end-to-end meta-evolution or by a more surgical and efficient approach, called Petri dish meta-evolution. Finally, we show how to perform interactive evolution, where the user decides how to evolve a plant model interactively and then deploys it in a larger environment. We open source Biomaker CA at: https://tinyurl.com/2x8yu34s .", "url": "https://arxiv.org/abs/2307.09320"}, {"metadata": {"arXiv": "2307.09342", "Date": "Tue, 18 Jul 2023 15:26:46 ", "Title": "Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints", "Authors": ["Felix Ulrich-Oltean", "Peter Nightingale", "James Alfred Walker"], "Categories": "cs.AI cs.LG cs.LO", "Comments": ["24 pages", "10 figures", "submitted to Constraints Journal (Springer)"]}, "abstract": "Many constraint satisfaction and optimisation problems can be solved effectively by encoding them as instances of the Boolean Satisfiability problem (SAT). However, even the simplest types of constraints have many encodings in the literature with widely varying performance, and the problem of selecting suitable encodings for a given problem instance is not trivial. We explore the problem of selecting encodings for pseudo-Boolean and linear constraints using a supervised machine learning approach. We show that it is possible to select encodings effectively using a standard set of features for constraint problems; however we obtain better performance with a new set of features specifically designed for the pseudo-Boolean and linear constraints. In fact, we achieve good results when selecting encodings for unseen problem classes. Our results compare favourably to AutoFolio when using the same feature set. We discuss the relative importance of instance features to the task of selecting the best encodings, and compare several variations of the machine learning method.", "url": "https://arxiv.org/abs/2307.09342"}, {"metadata": {"arXiv": "2307.09477", "Date": "Thu, 13 Jul 2023 14:50:04 ", "Title": "Towards Ordinal Data Science", "Authors": ["Gerd Stumme", "Dominik D\\\"urrschnabel", "Tom Hanika"], "Categories": "cs.AI cs.DM cs.LG", "Comments": ["33 pages"], "MSC-class": "03G10, 06A15, 68T27, 68T30", "ACM-class": "G.2.3; F.4.1; H.5.0; I.2.4"}, "abstract": "Order is one of the main instruments to measure the relationship between objects in (empirical) data. However, compared to methods that use numerical properties of objects, the amount of ordinal methods developed is rather small. One reason for this is the limited availability of computational resources in the last century that would have been required for ordinal computations. Another reason -- particularly important for this line of research -- is that order-based methods are often seen as too mathematically rigorous for applying them to real-world data. In this paper, we will therefore discuss different means for measuring and 'calculating' with ordinal structures -- a specific class of directed graphs -- and show how to infer knowledge from them. Our aim is to establish Ordinal Data Science as a fundamentally new research agenda. Besides cross-fertilization with other cornerstone machine learning and knowledge representation methods, a broad range of disciplines will benefit from this endeavor, including, psychology, sociology, economics, web science, knowledge engineering, scientometrics.", "url": "https://arxiv.org/abs/2307.09477"}, {"metadata": {"arXiv": "2307.09361", "Date": "Tue, 18 Jul 2023 15:46:20 ", "Title": "MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments", "Authors": ["Spyros Gidaris", "Andrei Bursuc", "Oriane Simeoni", "Antonin Vobecky", "Nikos Komodakis", "Matthieu Cord", "Patrick P\\'erez"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Self-supervised learning can be used for mitigating the greedy needs of Vision Transformer networks for very large fully-annotated datasets. Different classes of self-supervised learning offer representations with either good contextual reasoning properties, e.g., using masked image modeling strategies, or invariance to image perturbations, e.g., with contrastive methods. In this work, we propose a single-stage and standalone method, MOCA, which unifies both desired properties using novel mask-and-predict objectives defined with high-level features (instead of pixel-level details). Moreover, we show how to effectively employ both learning paradigms in a synergistic and computation-efficient way. Doing so, we achieve new state-of-the-art results on low-shot settings and strong experimental results in various evaluation protocols with a training that is at least 3 times faster than prior methods.", "url": "https://arxiv.org/abs/2307.09361"}, {"metadata": {"arXiv": "2307.08766", "Date": "Mon, 17 Jul 2023 18:26:57 ", "Title": "Quality Assessment of Photoplethysmography Signals For Cardiovascular Biomarkers Monitoring Using Wearable Devices", "Authors": ["Felipe M. Dias", "Marcelo A. F. Toledo", "Diego A. C. Cardenas", "Douglas A. Almeida", "Filipe A. C. Oliveira", "Estela Ribeiro", "Jose E. Krieger", "Marco A. Gutierrez"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["9 pages"]}, "abstract": "Photoplethysmography (PPG) is a non-invasive technology that measures changes in blood volume in the microvascular bed of tissue. It is commonly used in medical devices such as pulse oximeters and wrist worn heart rate monitors to monitor cardiovascular hemodynamics. PPG allows for the assessment of parameters (e.g., heart rate, pulse waveform, and peripheral perfusion) that can indicate conditions such as vasoconstriction or vasodilation, and provides information about microvascular blood flow, making it a valuable tool for monitoring cardiovascular health. However, PPG is subject to a number of sources of variations that can impact its accuracy and reliability, especially when using a wearable device for continuous monitoring, such as motion artifacts, skin pigmentation, and vasomotion. In this study, we extracted 27 statistical features from the PPG signal for training machine-learning models based on gradient boosting (XGBoost and CatBoost) and Random Forest (RF) algorithms to assess quality of PPG signals that were labeled as good or poor quality. We used the PPG time series from a publicly available dataset and evaluated the algorithm s performance using Sensitivity (Se), Positive Predicted Value (PPV), and F1-score (F1) metrics. Our model achieved Se, PPV, and F1-score of 94.4, 95.6, and 95.0 for XGBoost, 94.7, 95.9, and 95.3 for CatBoost, and 93.7, 91.3 and 92.5 for RF, respectively. Our findings are comparable to state-of-the-art reported in the literature but using a much simpler model, indicating that ML models are promising for developing remote, non-invasive, and continuous measurement devices.", "url": "https://arxiv.org/abs/2307.08766"}, {"metadata": {"arXiv": "2307.08794", "Date": "Mon, 17 Jul 2023 19:25:46 ", "Title": "Non-Stationary Policy Learning for Multi-Timescale Multi-Agent Reinforcement Learning", "Authors": ["Patrick Emami", "Xiangyu Zhang", "David Biagioni", "Ahmed S. Zamzam"], "Categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "Comments": ["Accepted at IEEE CDC'23. 7 pages", "6 figures"]}, "abstract": "In multi-timescale multi-agent reinforcement learning (MARL), agents interact across different timescales. In general, policies for time-dependent behaviors, such as those induced by multiple timescales, are non-stationary. Learning non-stationary policies is challenging and typically requires sophisticated or inefficient algorithms. Motivated by the prevalence of this control problem in real-world complex systems, we introduce a simple framework for learning non-stationary policies for multi-timescale MARL. Our approach uses available information about agent timescales to define a periodic time encoding. In detail, we theoretically demonstrate that the effects of non-stationarity introduced by multiple timescales can be learned by a periodic multi-agent policy. To learn such policies, we propose a policy gradient algorithm that parameterizes the actor and critic with phase-functioned neural networks, which provide an inductive bias for periodicity. The framework's ability to effectively learn multi-timescale policies is validated on a gridworld and building energy management environment.", "url": "https://arxiv.org/abs/2307.08794"}, {"metadata": {"arXiv": "2307.08809", "Date": "Mon, 17 Jul 2023 19:50:37 ", "Title": "Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels", "Authors": ["Yae Jee Cho and Gauri Joshi and Dimitrios Dimitriadis"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["To appear in the proceedings of ICCV 2023"]}, "abstract": "Many existing FL methods assume clients with fully-labeled data, while in realistic settings, clients have limited labels due to the expensive and laborious process of labeling. Limited labeled local data of the clients often leads to their local model having poor generalization abilities to their larger unlabeled local data, such as having class-distribution mismatch with the unlabeled data. As a result, clients may instead look to benefit from the global model trained across clients to leverage their unlabeled data, but this also becomes difficult due to data heterogeneity across clients. In our work, we propose FedLabel where clients selectively choose the local or global model to pseudo-label their unlabeled data depending on which is more of an expert of the data. We further utilize both the local and global models' knowledge via global-local consistency regularization which minimizes the divergence between the two models' outputs when they have identical pseudo-labels for the unlabeled data. Unlike other semi-supervised FL baselines, our method does not require additional experts other than the local or global model, nor require additional parameters to be communicated. We also do not assume any server-labeled data or fully labeled clients. For both cross-device and cross-silo settings, we show that FedLabel outperforms other semi-supervised FL baselines by $8$-$24\\%$, and even outperforms standard fully supervised FL baselines ($100\\%$ labeled data) with only $5$-$20\\%$ of labeled data.", "url": "https://arxiv.org/abs/2307.08809"}, {"metadata": {"arXiv": "2307.08816", "Date": "Mon, 17 Jul 2023 20:11:56 ", "Title": "Towards Accelerating Benders Decomposition via Reinforcement Learning Surrogate Models", "Authors": ["Stephen Mak", "Kyle Mana", "Parisa Zehtabi", "Michael Cashmore", "Daniele Magazzeni", "Manuela Veloso"], "Categories": "cs.LG cs.AI math.OC"}, "abstract": "Stochastic optimization (SO) attempts to offer optimal decisions in the presence of uncertainty. Often, the classical formulation of these problems becomes intractable due to (a) the number of scenarios required to capture the uncertainty and (b) the discrete nature of real-world planning problems. To overcome these tractability issues, practitioners turn to decomposition methods that divide the problem into smaller, more tractable sub-problems. The focal decomposition method of this paper is Benders decomposition (BD), which decomposes stochastic optimization problems on the basis of scenario independence. In this paper we propose a method of accelerating BD with the aid of a surrogate model in place of an NP-hard integer master problem. Through the acceleration method we observe 30% faster average convergence when compared to other accelerated BD implementations. We introduce a reinforcement learning agent as a surrogate and demonstrate how it can be used to solve a stochastic inventory management problem.", "url": "https://arxiv.org/abs/2307.08816"}, {"metadata": {"arXiv": "2307.08859", "Date": "Mon, 17 Jul 2023 21:33:35 ", "Title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach", "Authors": ["Nidhi Vakil and Hadi Amiri"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["ACL 2023"], "Journal-ref": "https://aclanthology.org/2023.acl-long.389/"}, "abstract": "A curriculum is a planned sequence of learning materials and an effective one can make learning efficient and effective for both humans and machines. Recent studies developed effective data-driven curriculum learning approaches for training graph neural networks in language applications. However, existing curriculum learning approaches often employ a single criterion of difficulty in their training paradigms. In this paper, we propose a new perspective on curriculum learning by introducing a novel approach that builds on graph complexity formalisms (as difficulty criteria) and model competence during training. The model consists of a scheduling scheme which derives effective curricula by accounting for different views of sample difficulty and model competence during training. The proposed solution advances existing research in curriculum learning for graph neural networks with the ability to incorporate a fine-grained spectrum of graph difficulty criteria in their training paradigms. Experimental results on real-world link prediction and node classification tasks illustrate the effectiveness of the proposed approach.", "url": "https://arxiv.org/abs/2307.08859"}, {"metadata": {"arXiv": "2307.08873", "Date": "Mon, 17 Jul 2023 22:08:27 ", "Title": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient", "Authors": ["Yudong Luo", "Guiliang Liu", "Pascal Poupart", "Yangchen Pan"], "Categories": "cs.LG cs.AI"}, "abstract": "Restricting the variance of a policy's return is a popular choice in risk-averse Reinforcement Learning (RL) due to its clear mathematical definition and easy interpretability. Traditional methods directly restrict the total return variance. Recent methods restrict the per-step reward variance as a proxy. We thoroughly examine the limitations of these variance-based methods, such as sensitivity to numerical scale and hindering of policy learning, and propose to use an alternative risk measure, Gini deviation, as a substitute. We study various properties of this new risk measure and derive a policy gradient algorithm to minimize it. Empirical evaluation in domains where risk-aversion can be clearly defined, shows that our algorithm can mitigate the limitations of variance-based risk measures and achieves high return with low risk in terms of variance and Gini deviation when others fail to learn a reasonable policy.", "url": "https://arxiv.org/abs/2307.08873"}, {"metadata": {"arXiv": "2307.08897", "Date": "Mon, 17 Jul 2023 23:50:51 ", "Title": "Basal-Bolus Advisor for Type 1 Diabetes (T1D) Patients Using Multi-Agent Reinforcement Learning (RL) Methodology", "Authors": ["Mehrad Jalolia", "Marzia Cescon"], "Categories": "cs.LG cs.AI cs.CE cs.SY eess.SY", "Comments": ["8 pages", "2 figures", "1 Table"]}, "abstract": "This paper presents a novel multi-agent reinforcement learning (RL) approach for personalized glucose control in individuals with type 1 diabetes (T1D). The method employs a closed-loop system consisting of a blood glucose (BG) metabolic model and a multi-agent soft actor-critic RL model acting as the basal-bolus advisor. Performance evaluation is conducted in three scenarios, comparing the RL agents to conventional therapy. Evaluation metrics include glucose levels (minimum, maximum, and mean), time spent in different BG ranges, and average daily bolus and basal insulin dosages. Results demonstrate that the RL-based basal-bolus advisor significantly improves glucose control, reducing glycemic variability and increasing time spent within the target range (70-180 mg/dL). Hypoglycemia events are effectively prevented, and severe hyperglycemia events are reduced. The RL approach also leads to a statistically significant reduction in average daily basal insulin dosage compared to conventional therapy. These findings highlight the effectiveness of the multi-agent RL approach in achieving better glucose control and mitigating the risk of severe hyperglycemia in individuals with T1D.", "url": "https://arxiv.org/abs/2307.08897"}, {"metadata": {"arXiv": "2307.08925", "Date": "Tue, 18 Jul 2023 02:09:14 ", "Title": "Federated Large Language Model: A Position Paper", "Authors": ["Chaochao Chen", "Xiaohua Feng", "Jun Zhou", "Jianwei Yin", "Xiaolin Zheng"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["11 pages", "4 figures"]}, "abstract": "Large scale language models (LLM) have received significant attention and found diverse applications across various domains, but their development encounters challenges in real-world scenarios. These challenges arise due to the scarcity of public domain data availability and the need to maintain privacy with respect to private domain data. To address these issues, federated learning (FL) has emerged as a promising technology that enables collaborative training of shared models while preserving decentralized data. We propose the concept of federated LLM, which comprises three key components, i.e., federated LLM pre-training, federated LLM fine-tuning, and federated LLM prompt engineering. For each component, we discuss its advantage over traditional LLM training methods and propose specific engineering strategies for implementation. Furthermore, we explore the novel challenges introduced by the integration of FL and LLM. We analyze existing solutions and identify potential obstacles faced by these solutions within the context of federated LLM.", "url": "https://arxiv.org/abs/2307.08925"}, {"metadata": {"arXiv": "2307.08964", "Date": "Tue, 18 Jul 2023 04:29:16 ", "Title": "Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information", "Authors": ["Arman Zharmagambetov", "Brandon Amos", "Aaron Ferber", "Taoan Huang", "Bistra Dilkina", "Yuandong Tian"], "Categories": "cs.LG cs.AI"}, "abstract": "Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable Landscape Surrogate $M$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems.", "url": "https://arxiv.org/abs/2307.08964"}, {"metadata": {"arXiv": "2307.09072", "Date": "Tue, 18 Jul 2023 08:45:54 ", "Title": "DiTTO: Diffusion-inspired Temporal Transformer Operator", "Authors": ["Oded Ovadia", "Eli Turkel", "Adar Kahana", "George Em Karniadakis"], "Categories": "cs.LG cs.AI cs.CE cs.NA math.NA"}, "abstract": "Solving partial differential equations (PDEs) using a data-driven approach has become increasingly common. The recent development of the operator learning paradigm has enabled the solution of a broader range of PDE-related problems. We propose an operator learning method to solve time-dependent PDEs continuously in time without needing any temporal discretization. The proposed approach, named DiTTO, is inspired by latent diffusion models. While diffusion models are usually used in generative artificial intelligence tasks, their time-conditioning mechanism is extremely useful for PDEs. The diffusion-inspired framework is combined with elements from the Transformer architecture to improve its capabilities. We demonstrate the effectiveness of the new approach on a wide variety of PDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO achieves state-of-the-art results in terms of accuracy for these problems. We also present a method to improve the performance of DiTTO by using fast sampling concepts from diffusion models. Finally, we show that DiTTO can accurately perform zero-shot super-resolution in time.", "url": "https://arxiv.org/abs/2307.09072"}, {"metadata": {"arXiv": "2307.09218", "Date": "Sun, 16 Jul 2023 16:27:58 ", "Title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning", "Authors": ["Zhenyi Wang", "Enneng Yang", "Li Shen", "Heng Huang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Forgetting refers to the loss or deterioration of previously acquired information or knowledge. While the existing surveys on forgetting have primarily focused on continual learning, forgetting is a prevalent phenomenon observed in various other research domains within deep learning. Forgetting manifests in research fields such as generative models due to generator shifts, and federated learning due to heterogeneous data distributions across clients. Addressing forgetting encompasses several challenges, including balancing the retention of old task knowledge with fast learning of new tasks, managing task interference with conflicting goals, and preventing privacy leakage, etc. Moreover, most existing surveys on continual learning implicitly assume that forgetting is always harmful. In contrast, our survey argues that forgetting is a double-edged sword and can be beneficial and desirable in certain cases, such as privacy-preserving scenarios. By exploring forgetting in a broader context, we aim to present a more nuanced understanding of this phenomenon and highlight its potential advantages. Through this comprehensive survey, we aspire to uncover potential solutions by drawing upon ideas and approaches from various fields that have dealt with forgetting. By examining forgetting beyond its conventional boundaries, in future work, we hope to encourage the development of novel strategies for mitigating, harnessing, or even embracing forgetting in real applications. A comprehensive list of papers about forgetting in various research fields is available at \\url{https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning}.", "url": "https://arxiv.org/abs/2307.09218"}, {"metadata": {"arXiv": "2307.09244", "Date": "Tue, 18 Jul 2023 13:23:23 ", "Title": "Towards Sustainable Deep Learning for Multi-Label Classification on NILM", "Authors": ["An\\v{z}e Pirnat", "Bla\\v{z} Bertalani\\v{c}", "Gregor Cerar", "Mihael Mohor\\v{c}i\\v{c} and Carolina Fortuna"], "Categories": "cs.LG cs.AI"}, "abstract": "Non-intrusive load monitoring (NILM) is the process of obtaining appliance-level data from a single metering point, measuring total electricity consumption of a household or a business. Appliance-level data can be directly used for demand response applications and energy management systems as well as for awareness raising and motivation for improvements in energy efficiency and reduction in the carbon footprint. Recently, classical machine learning and deep learning (DL) techniques became very popular and proved as highly effective for NILM classification, but with the growing complexity these methods are faced with significant computational and energy demands during both their training and operation. In this paper, we introduce a novel DL model aimed at enhanced multi-label classification of NILM with improved computation and energy efficiency. We also propose a testing methodology for comparison of different models using data synthesized from the measurement datasets so as to better represent real-world scenarios. Compared to the state-of-the-art, the proposed model has its carbon footprint reduced by more than 23% while providing on average approximately 8 percentage points in performance improvement when testing on data derived from REFIT and UK-DALE datasets.", "url": "https://arxiv.org/abs/2307.09244"}, {"metadata": {"arXiv": "2307.09249", "Date": "Tue, 18 Jul 2023 13:28:31 ", "Title": "UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data", "Authors": ["Yazheng Yang", "Yuqi Wang", "Guang Liu", "Ledell Wu", "Qi Liu"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["9 pages"]}, "abstract": "Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks. This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks. The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time. In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures. UniTabE's core concept relies on representing each basic table element with a module, termed TabUnit. This is subsequently followed by a Transformer encoder to refine the representation. Moreover, our model is designed to facilitate pretraining and finetuning through the utilization of free-form prompts. In order to implement the pretraining phase, we curated an expansive tabular dataset comprising approximately 13 billion samples, meticulously gathered from the Kaggle platform. Rigorous experimental testing and analyses were performed under a myriad of scenarios to validate the effectiveness of our methodology. The experimental results demonstrate UniTabE's superior performance against several baseline models across a multitude of benchmark datasets. This, therefore, underscores UniTabE's potential to significantly enhance the semantic representation of tabular data, thereby marking a significant stride in the field of tabular data analysis.", "url": "https://arxiv.org/abs/2307.09249"}, {"metadata": {"arXiv": "2307.09321", "Date": "Tue, 18 Jul 2023 15:03:56 ", "Title": "Exploiting Field Dependencies for Learning on Categorical Data", "Authors": ["Zhibin Li", "Piotr Koniusz", "Lu Zhang", "Daniel Edward Pagendam", "Peyman Moghadam"], "Categories": "cs.LG cs.AI cs.DB", "Comments": ["IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted June 2022", "accepted July 2023)"]}, "abstract": "Traditional approaches for learning on categorical data underexploit the dependencies between columns (\\aka fields) in a dataset because they rely on the embedding of data points driven alone by the classification/regression loss. In contrast, we propose a novel method for learning on categorical data with the goal of exploiting dependencies between fields. Instead of modelling statistics of features globally (i.e., by the covariance matrix of features), we learn a global field dependency matrix that captures dependencies between fields and then we refine the global field dependency matrix at the instance-wise level with different weights (so-called local dependency modelling) w.r.t. each field to improve the modelling of the field dependencies. Our algorithm exploits the meta-learning paradigm, i.e., the dependency matrices are refined in the inner loop of the meta-learning algorithm without the use of labels, whereas the outer loop intertwines the updates of the embedding matrix (the matrix performing projection) and global dependency matrix in a supervised fashion (with the use of labels). Our method is simple yet it outperforms several state-of-the-art methods on six popular dataset benchmarks. Detailed ablation studies provide additional insights into our method.", "url": "https://arxiv.org/abs/2307.09321"}, {"metadata": {"arXiv": "2307.09423", "Date": "Tue, 18 Jul 2023 16:43:03 ", "Title": "Scaling Laws for Imitation Learning in NetHack", "Authors": ["Jens Tuyls", "Dhruv Madeka", "Kari Torkkola", "Dean Foster", "Karthik Narasimhan", "Sham Kakade"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where \"scaling up\" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL and find they outperform prior state-of-the-art by at least 2x in all settings. Our work both demonstrates the scaling behavior of imitation learning in a challenging domain, as well as the viability of scaling up current approaches for increasingly capable agents in NetHack, a game that remains elusively hard for current AI systems.", "url": "https://arxiv.org/abs/2307.09423"}, {"metadata": {"arXiv": "2307.09437", "Date": "Tue, 18 Jul 2023 17:11:55 ", "Title": "Unsupervised Conditional Slot Attention for Object Centric Learning", "Authors": ["Avinash Kori", "Francesco Locatello", "Francesca Toni", "Ben Glocker"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Extracting object-level representations for downstream reasoning tasks is an emerging area in AI. Learning object-centric representations in an unsupervised setting presents multiple challenges, a key one being binding an arbitrary number of object instances to a specialized object slot. Recent object-centric representation methods like Slot Attention utilize iterative attention to learn composable representations with dynamic inference level binding but fail to achieve specialized slot level binding. To address this, in this paper we propose Unsupervised Conditional Slot Attention using a novel Probabilistic Slot Dictionary (PSD). We define PSD with (i) abstract object-level property vectors as key and (ii) parametric Gaussian distribution as its corresponding value. We demonstrate the benefits of the learnt specific object-level conditioning distributions in multiple downstream tasks, namely object discovery, compositional scene generation, and compositional visual reasoning. We show that our method provides scene composition capabilities and a significant boost in a few shot adaptability tasks of compositional visual reasoning, while performing similarly or better than slot attention in object discovery tasks", "url": "https://arxiv.org/abs/2307.09437"}, {"metadata": {"arXiv": "2307.09476", "Date": "Tue, 18 Jul 2023 17:56:50 ", "Title": "Overthinking the Truth: Understanding how Language Models Process False Demonstrations", "Authors": ["Danny Halawi", "Jean-Stanislas Denain", "Jacob Steinhardt"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \"critical layer\", after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking. Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors.", "url": "https://arxiv.org/abs/2307.09476"}, {"metadata": {"arXiv": "2307.08920", "Date": "Tue, 18 Jul 2023 01:36:43 ", "Title": "Continuous-Time Reinforcement Learning: New Design Algorithms with Theoretical Insights and Performance Guarantees", "Authors": ["Brent A. Wallace", "Jennie Si"], "Categories": "eess.SY cs.AI cs.LG cs.SY"}, "abstract": "Continuous-time nonlinear optimal control problems hold great promise in real-world applications. After decades of development, reinforcement learning (RL) has achieved some of the greatest successes as a general nonlinear control design method. However, a recent comprehensive analysis of state-of-the-art continuous-time RL (CT-RL) methods, namely, adaptive dynamic programming (ADP)-based CT-RL algorithms, reveals they face significant design challenges due to their complexity, numerical conditioning, and dimensional scaling issues. Despite advanced theoretical results, existing ADP CT-RL synthesis methods are inadequate in solving even small, academic problems. The goal of this work is thus to introduce a suite of new CT-RL algorithms for control of affine nonlinear systems. Our design approach relies on two important factors. First, our methods are applicable to physical systems that can be partitioned into smaller subproblems. This constructive consideration results in reduced dimensionality and greatly improved intuitiveness of design. Second, we introduce a new excitation framework to improve persistence of excitation (PE) and numerical conditioning performance via classical input/output insights. Such a design-centric approach is the first of its kind in the ADP CT-RL community. In this paper, we progressively introduce a suite of (decentralized) excitable integral reinforcement learning (EIRL) algorithms. We provide convergence and closed-loop stability guarantees, and we demonstrate these guarantees on a significant application problem of controlling an unstable, nonminimum phase hypersonic vehicle (HSV).", "url": "https://arxiv.org/abs/2307.08920"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2312.09481", "Date": "Fri, 15 Dec 2023 01:38:26 ", "Title": "Continual Adversarial Defense", "Authors": ["Qian Wang", "Yaoyao Liu", "Hefei Ling", "Yingwei Li", "Qihao Liu", "Ping Li", "Jiazhong Chen", "Alan Yuille", "Ning Yu"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "In response to the rapidly evolving nature of adversarial attacks on a monthly basis, numerous defenses have been proposed to generalize against as many known attacks as possible. However, designing a defense method that can generalize to all types of attacks, including unseen ones, is not realistic because the environment in which defense systems operate is dynamic and comprises various unique attacks used by many attackers. The defense system needs to upgrade itself by utilizing few-shot defense feedback and efficient memory. Therefore, we propose the first continual adversarial defense (CAD) framework that adapts to any attacks in a dynamic scenario, where various attacks emerge stage by stage. In practice, CAD is modeled under four principles: (1) continual adaptation to new attacks without catastrophic forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4) high accuracy on both clean and adversarial images. We leverage cutting-edge continual learning, few-shot learning, and ensemble learning techniques to qualify the principles. Experiments conducted on CIFAR-10 and ImageNet-100 validate the effectiveness of our approach against multiple stages of 10 modern adversarial attacks and significant improvements over 10 baseline methods. In particular, CAD is capable of quickly adapting with minimal feedback and a low cost of defense failure, while maintaining good performance against old attacks. Our research sheds light on a brand-new paradigm for continual defense adaptation against dynamic and evolving attacks.", "url": "https://arxiv.org/abs/2312.09481"}, {"metadata": {"arXiv": "2312.09486", "Date": "Fri, 15 Dec 2023 01:52:35 ", "Title": "Unraveling Batch Normalization for Realistic Test-Time Adaptation", "Authors": ["Zixian Su", "Jingwei Guo", "Kai Yao", "Xi Yang", "Qiufeng Wang", "Kaizhu Huang"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted by AAAI 2024"]}, "abstract": "While recent test-time adaptations exhibit efficacy by adjusting batch normalization to narrow domain disparities, their effectiveness diminishes with realistic mini-batches due to inaccurate target estimation. As previous attempts merely introduce source statistics to mitigate this issue, the fundamental problem of inaccurate target estimation still persists, leaving the intrinsic test-time domain shifts unresolved. This paper delves into the problem of mini-batch degradation. By unraveling batch normalization, we discover that the inexact target statistics largely stem from the substantially reduced class diversity in batch. Drawing upon this insight, we introduce a straightforward tool, Test-time Exponential Moving Average (TEMA), to bridge the class diversity gap between training and testing batches. Importantly, our TEMA adaptively extends the scope of typical methods beyond the current batch to incorporate a diverse set of class information, which in turn boosts an accurate target estimation. Built upon this foundation, we further design a novel layer-wise rectification strategy to consistently promote test-time performance. Our proposed method enjoys a unique advantage as it requires neither training nor tuning parameters, offering a truly hassle-free solution. It significantly enhances model robustness against shifted domains and maintains resilience in diverse real-world scenarios with various batch sizes, achieving state-of-the-art performance on several major benchmarks. Code is available at \\url{https://github.com/kiwi12138/RealisticTTA}.", "url": "https://arxiv.org/abs/2312.09486"}, {"metadata": {"arXiv": "2312.09627", "Date": "Fri, 15 Dec 2023 09:10:05 ", "Title": "TF-CLIP: Learning Text-free CLIP for Video-based Person Re-Identification", "Authors": ["Chenyang Yu and Xuehu Liu and Yingquan Wang and Pingping Zhang and Huchuan Lu"], "Categories": "cs.CV cs.IR cs.LG cs.MM", "Comments": ["This work is accepted by AAAI2024"]}, "abstract": "Large-scale language-image pre-trained models (e.g., CLIP) have shown superior performances on many cross-modal retrieval tasks. However, the problem of transferring the knowledge learned from such models to video-based person re-identification (ReID) has barely been explored. In addition, there is a lack of decent text descriptions in current ReID benchmarks. To address these issues, in this work, we propose a novel one-stage text-free CLIP-based learning framework named TF-CLIP for video-based person ReID. More specifically, we extract the identity-specific sequence feature as the CLIP-Memory to replace the text feature. Meanwhile, we design a Sequence-Specific Prompt (SSP) module to update the CLIP-Memory online. To capture temporal information, we further propose a Temporal Memory Diffusion (TMD) module, which consists of two key components: Temporal Memory Construction (TMC) and Memory Diffusion (MD). Technically, TMC allows the frame-level memories in a sequence to communicate with each other, and to extract temporal information based on the relations within the sequence. MD further diffuses the temporal memories to each token in the original features to obtain more robust sequence features. Extensive experiments demonstrate that our proposed method shows much better results than other state-of-the-art methods on MARS, LS-VID and iLIDS-VID. The code is available at https://github.com/AsuradaYuci/TF-CLIP.", "url": "https://arxiv.org/abs/2312.09627"}, {"metadata": {"arXiv": "2312.09673", "Date": "Fri, 15 Dec 2023 10:35:30 ", "Title": "Style Generation in Robot Calligraphy with Deep Generative Adversarial Networks", "Authors": ["Xiaoming Wang", "Zhiguo Gong"], "Categories": "cs.CV cs.LG"}, "abstract": "Robot calligraphy is an emerging exploration of artificial intelligence in the fields of art and education. Traditional calligraphy generation researches mainly focus on methods such as tool-based image processing, generative models, and style transfer. Unlike the English alphabet, the number of Chinese characters is tens of thousands, which leads to difficulties in the generation of a style consistent Chinese calligraphic font with over 6000 characters. Due to the lack of high-quality data sets, formal definitions of calligraphy knowledge, and scientific art evaluation methods, The results generated are frequently of low quality and falls short of professional-level requirements. To address the above problem, this paper proposes an automatic calligraphy generation model based on deep generative adversarial networks (deepGAN) that can generate style calligraphy fonts with professional standards. The key highlights of the proposed method include: (1) The datasets use a high-precision calligraphy synthesis method to ensure its high quality and sufficient quantity; (2) Professional calligraphers are invited to conduct a series of Turing tests to evaluate the gap between model generation results and human artistic level; (3) Experimental results indicate that the proposed model is the state-of-the-art among current calligraphy generation methods. The Turing tests and similarity evaluations validate the effectiveness of the proposed method.", "url": "https://arxiv.org/abs/2312.09673"}, {"metadata": {"arXiv": "2312.09797", "Date": "Fri, 15 Dec 2023 13:54:48 ", "Title": "Part Representation Learning with Teacher-Student Decoder for Occluded Person Re-identification", "Authors": ["Shang Gao and Chenyang Yu and Pingping Zhang and Huchuan Lu"], "Categories": "cs.CV cs.LG cs.MM", "Comments": ["Accepted by ICASSP2024"]}, "abstract": "Occluded person re-identification (ReID) is a very challenging task due to the occlusion disturbance and incomplete target information. Leveraging external cues such as human pose or parsing to locate and align part features has been proven to be very effective in occluded person ReID. Meanwhile, recent Transformer structures have a strong ability of long-range modeling. Considering the above facts, we propose a Teacher-Student Decoder (TSD) framework for occluded person ReID, which utilizes the Transformer decoder with the help of human parsing. More specifically, our proposed TSD consists of a Parsing-aware Teacher Decoder (PTD) and a Standard Student Decoder (SSD). PTD employs human parsing cues to restrict Transformer's attention and imparts this information to SSD through feature distillation. Thereby, SSD can learn from PTD to aggregate information of body parts automatically. Moreover, a mask generator is designed to provide discriminative regions for better ReID. In addition, existing occluded person ReID benchmarks utilize occluded samples as queries, which will amplify the role of alleviating occlusion interference and underestimate the impact of the feature absence issue. Contrastively, we propose a new benchmark with non-occluded queries, serving as a complement to the existing benchmark. Extensive experiments demonstrate that our proposed method is superior and the new benchmark is essential. The source codes are available at https://github.com/hh23333/TSD.", "url": "https://arxiv.org/abs/2312.09797"}, {"metadata": {"arXiv": "2312.09869", "Date": "Fri, 15 Dec 2023 15:14:55 ", "Title": "Learning in Online Principle-Agent Interactions: The Power of Menus", "Authors": ["Minbiao Han", "Michael Albert", "Haifeng Xu"], "Categories": "cs.GT cs.LG", "Comments": ["AAAI Conference on Artificial Intelligence (AAAI 2024)"]}, "abstract": "We study a ubiquitous learning challenge in online principal-agent problems during which the principal learns the agent's private information from the agent's revealed preferences in historical interactions. This paradigm includes important special cases such as pricing and contract design, which have been widely studied in recent literature. However, existing work considers the case where the principal can only choose a single strategy at every round to interact with the agent and then observe the agent's revealed preference through their actions. In this paper, we extend this line of study to allow the principal to offer a menu of strategies to the agent and learn additionally from observing the agent's selection from the menu. We provide a thorough investigation of several online principal-agent problem settings and characterize their sample complexities, accompanied by the corresponding algorithms we have developed. We instantiate this paradigm to several important design problems $-$ including Stackelberg (security) games, contract design, and information design. Finally, we also explore the connection between our findings and existing results about online learning in Stackelberg games, and we offer a solution that can overcome a key hard instance of Peng et al. (2019).", "url": "https://arxiv.org/abs/2312.09869"}, {"metadata": {"arXiv": "2312.09262", "Date": "Thu, 14 Dec 2023 09:46:16 ", "Title": "Random resistive memory-based deep extreme point learning machine for unified visual processing", "Authors": ["Shaocong Wang", "Yizhao Gao", "Yi Li", "Woyu Zhang", "Yifei Yu", "Bo Wang", "Ning Lin", "Hegan Chen", "Yue Zhang", "Yang Jiang", "Dingchen Wang", "Jia Chen", "Peng Dai", "Hao Jiang", "Peng Lin", "Xumeng Zhang", "Xiaojuan Qi", "Xiaoxin Xu", "Hayden So", "Zhongrui Wang", "Dashan Shang", "Qi Liu", "Kwang-Ting Cheng", "Ming Liu"], "Categories": "cs.LG cs.AR"}, "abstract": "Visual sensors, including 3D LiDAR, neuromorphic DVS sensors, and conventional frame cameras, are increasingly integrated into edge-side intelligent machines. Realizing intensive multi-sensory data analysis directly on edge intelligent machines is crucial for numerous emerging edge applications, such as augmented and virtual reality and unmanned aerial vehicles, which necessitates unified data representation, unprecedented hardware energy efficiency and rapid model training. However, multi-sensory data are intrinsically heterogeneous, causing significant complexity in the system development for edge-side intelligent machines. In addition, the performance of conventional digital hardware is limited by the physically separated processing and memory units, known as the von Neumann bottleneck, and the physical limit of transistor scaling, which contributes to the slowdown of Moore's law. These limitations are further intensified by the tedious training of models with ever-increasing sizes. We propose a novel hardware-software co-design, random resistive memory-based deep extreme point learning machine (DEPLM), that offers efficient unified point set analysis. We show the system's versatility across various data modalities and two different learning tasks. Compared to a conventional digital hardware-based system, our co-design system achieves huge energy efficiency improvements and training cost reduction when compared to conventional systems. Our random resistive memory-based deep extreme point learning machine may pave the way for energy-efficient and training-friendly edge AI across various data modalities and tasks.", "url": "https://arxiv.org/abs/2312.09262"}, {"metadata": {"arXiv": "2312.09299", "Date": "Thu, 14 Dec 2023 19:08:56 ", "Title": "Weight subcloning: direct initialization of transformers using larger pretrained ones", "Authors": ["Mohammad Samragh", "Mehrdad Farajtabar", "Sachin Mehta", "Raviteja Vemulapalli", "Fartash Faghri", "Devang Naik", "Oncel Tuzel", "Mohammad Rastegari"], "Categories": "cs.LG cs.CL cs.CV"}, "abstract": "Training large transformer models from scratch for a target task requires lots of data and is computationally demanding. The usual practice of transfer learning overcomes this challenge by initializing the model with weights of a pretrained model of the same size and specification to increase the convergence and training speed. However, what if no pretrained model of the required size is available? In this paper, we introduce a simple yet effective technique to transfer the knowledge of a pretrained model to smaller variants. Our approach called weight subcloning expedites the training of scaled-down transformers by initializing their weights from larger pretrained models. Weight subcloning involves an operation on the pretrained model to obtain the equivalent initialized scaled-down model. It consists of two key steps: first, we introduce neuron importance ranking to decrease the embedding dimension per layer in the pretrained model. Then, we remove blocks from the transformer model to match the number of layers in the scaled-down network. The result is a network ready to undergo training, which gains significant improvements in training speed compared to random initialization. For instance, we achieve 4x faster training for vision transformers in image classification and language models designed for next token prediction.", "url": "https://arxiv.org/abs/2312.09299"}, {"metadata": {"arXiv": "2312.09304", "Date": "Thu, 14 Dec 2023 19:17:42 ", "Title": "Well-calibrated Confidence Measures for Multi-label Text Classification with a Large Number of Labels", "Authors": ["Lysimachos Maltoudoglou", "Andreas Paisios", "Ladislav Lenc", "Ji\\v{r}\\'i Mart\\'inek", "Pavel Kr\\'al", "Harris Papadopoulos"], "Categories": "cs.LG cs.CL stat.ML", "Journal-ref": "Pattern Recognition, Volume 122, February 2022", "DOI": "10.1016/j.patcog.2021.108271"}, "abstract": "We extend our previous work on Inductive Conformal Prediction (ICP) for multi-label text classification and present a novel approach for addressing the computational inefficiency of the Label Powerset (LP) ICP, arrising when dealing with a high number of unique labels. We present experimental results using the original and the proposed efficient LP-ICP on two English and one Czech language data-sets. Specifically, we apply the LP-ICP on three deep Artificial Neural Network (ANN) classifiers of two types: one based on contextualised (bert) and two on non-contextualised (word2vec) word-embeddings. In the LP-ICP setting we assign nonconformity scores to label-sets from which the corresponding p-values and prediction-sets are determined. Our approach deals with the increased computational burden of LP by eliminating from consideration a significant number of label-sets that will surely have p-values below the specified significance level. This reduces dramatically the computational complexity of the approach while fully respecting the standard CP guarantees. Our experimental results show that the contextualised-based classifier surpasses the non-contextualised-based ones and obtains state-of-the-art performance for all data-sets examined. The good performance of the underlying classifiers is carried on to their ICP counterparts without any significant accuracy loss, but with the added benefits of ICP, i.e. the confidence information encapsulated in the prediction sets. We experimentally demonstrate that the resulting prediction sets can be tight enough to be practically useful even though the set of all possible label-sets contains more than $1e+16$ combinations. Additionally, the empirical error rates of the obtained prediction-sets confirm that our outputs are well-calibrated.", "url": "https://arxiv.org/abs/2312.09304"}, {"metadata": {"arXiv": "2312.09332", "Date": "Thu, 14 Dec 2023 20:42:54 ", "Title": "A Hierarchical Nearest Neighbour Approach to Contextual Bandits", "Authors": ["Stephen Pasteris", "Chris Hicks", "Vasilios Mavroudis"], "Categories": "cs.LG stat.ML"}, "abstract": "In this paper we consider the adversarial contextual bandit problem in metric spaces. The paper \"Nearest neighbour with bandit feedback\" tackled this problem but when there are many contexts near the decision boundary of the comparator policy it suffers from a high regret. In this paper we eradicate this problem, designing an algorithm in which we can hold out any set of contexts when computing our regret term. Our algorithm builds on that of \"Nearest neighbour with bandit feedback\" and hence inherits its extreme computational efficiency.", "url": "https://arxiv.org/abs/2312.09332"}, {"metadata": {"arXiv": "2312.09352", "Date": "Thu, 14 Dec 2023 21:27:38 ", "Title": "PBES: PCA Based Exemplar Sampling Algorithm for Continual Learning", "Authors": ["Sahil Nokhwal and Nirman Kumar"], "Categories": "cs.LG"}, "abstract": "We propose a novel exemplar selection approach based on Principal Component Analysis (PCA) and median sampling, and a neural network training regime in the setting of class-incremental learning. This approach avoids the pitfalls due to outliers in the data and is both simple to implement and use across various incremental machine learning models. It also has independent usage as a sampling algorithm. We achieve better performance compared to state-of-the-art methods.", "url": "https://arxiv.org/abs/2312.09352"}, {"metadata": {"arXiv": "2312.09357", "Date": "Thu, 14 Dec 2023 21:42:21 ", "Title": "DSS: A Diverse Sample Selection Method to Preserve Knowledge in Class-Incremental Learning", "Authors": ["Sahil Nokhwal and Nirman Kumar"], "Categories": "cs.LG"}, "abstract": "Rehearsal-based techniques are commonly used to mitigate catastrophic forgetting (CF) in Incremental learning (IL). The quality of the exemplars selected is important for this purpose and most methods do not ensure the appropriate diversity of the selected exemplars. We propose a new technique \"DSS\" -- Diverse Selection of Samples from the input data stream in the Class-incremental learning (CIL) setup under both disjoint and fuzzy task boundary scenarios. Our method outperforms state-of-the-art methods and is much simpler to understand and implement.", "url": "https://arxiv.org/abs/2312.09357"}, {"metadata": {"arXiv": "2312.09361", "Date": "Thu, 14 Dec 2023 21:51:06 ", "Title": "RTRA: Rapid Training of Regularization-based Approaches in Continual Learning", "Authors": ["Sahil Nokhwal and Nirman Kumar"], "Categories": "cs.LG cs.CV"}, "abstract": "Catastrophic forgetting(CF) is a significant challenge in continual learning (CL). In regularization-based approaches to mitigate CF, modifications to important training parameters are penalized in subsequent tasks using an appropriate loss function. We propose the RTRA, a modification to the widely used Elastic Weight Consolidation (EWC) regularization scheme, using the Natural Gradient for loss function optimization. Our approach improves the training of regularization-based methods without sacrificing test-data performance. We compare the proposed RTRA approach against EWC using the iFood251 dataset. We show that RTRA has a clear edge over the state-of-the-art approaches.", "url": "https://arxiv.org/abs/2312.09361"}, {"metadata": {"arXiv": "2312.09391", "Date": "Thu, 14 Dec 2023 23:07:37 ", "Title": "Exploiting Symmetric Temporally Sparse BPTT for Efficient RNN Training", "Authors": ["Xi Chen", "Chang Gao", "Zuowen Wang", "Longbiao Cheng", "Sheng Zhou", "Shih-Chii Liu", "Tobi Delbruck"], "Categories": "cs.LG cs.NE", "Comments": ["Accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)"]}, "abstract": "Recurrent Neural Networks (RNNs) are useful in temporal sequence tasks. However, training RNNs involves dense matrix multiplications which require hardware that can support a large number of arithmetic operations and memory accesses. Implementing online training of RNNs on the edge calls for optimized algorithms for an efficient deployment on hardware. Inspired by the spiking neuron model, the Delta RNN exploits temporal sparsity during inference by skipping over the update of hidden states from those inactivated neurons whose change of activation across two timesteps is below a defined threshold. This work describes a training algorithm for Delta RNNs that exploits temporal sparsity in the backward propagation phase to reduce computational requirements for training on the edge. Due to the symmetric computation graphs of forward and backward propagation during training, the gradient computation of inactivated neurons can be skipped. Results show a reduction of $\\sim$80% in matrix operations for training a 56k parameter Delta LSTM on the Fluent Speech Commands dataset with negligible accuracy loss. Logic simulations of a hardware accelerator designed for the training algorithm show 2-10X speedup in matrix computations for an activation sparsity range of 50%-90%. Additionally, we show that the proposed Delta RNN training will be useful for online incremental learning on edge devices with limited computing resources.", "url": "https://arxiv.org/abs/2312.09391"}, {"metadata": {"arXiv": "2312.09404", "Date": "Thu, 14 Dec 2023 23:53:34 ", "Title": "Unbiasing Enhanced Sampling on a High-dimensional Free Energy Surface with Deep Generative Model", "Authors": ["Yikai Liu", "Tushar K. Ghosh", "Ming Chen"], "Categories": "cs.LG cond-mat.stat-mech physics.chem-ph"}, "abstract": "Biased enhanced sampling methods utilizing collective variables (CVs) are powerful tools for sampling conformational ensembles. Due to high intrinsic dimensions, efficiently generating conformational ensembles for complex systems requires enhanced sampling on high-dimensional free energy surfaces. While methods like temperature-accelerated molecular dynamics (TAMD) can adopt many CVs in a simulation, unbiasing the simulation requires accurate modeling of a high-dimensional CV probability distribution, which is challenging for traditional density estimation techniques. Here we propose an unbiasing method based on the score-based diffusion model, a deep generative learning method that excels in density estimation across complex data landscapes. We test the score-based diffusion unbiasing method on TAMD simulations. The results demonstrate that this unbiasing approach significantly outperforms traditional unbiasing methods, and can generate accurate unbiased conformational ensembles for simulations with a number of CVs higher than usual ranges.", "url": "https://arxiv.org/abs/2312.09404"}, {"metadata": {"arXiv": "2312.09489", "Date": "Fri, 15 Dec 2023 01:56:27 ", "Title": "Multi-stage Learning for Radar Pulse Activity Segmentation", "Authors": ["Zi Huang", "Akila Pemasiri", "Simon Denman", "Clinton Fookes", "Terrence Martin"], "Categories": "cs.LG eess.SP", "Comments": ["5 pages", "8 figures"]}, "abstract": "Radio signal recognition is a crucial function in electronic warfare. Precise identification and localisation of radar pulse activities are required by electronic warfare systems to produce effective countermeasures. Despite the importance of these tasks, deep learning-based radar pulse activity recognition methods have remained largely underexplored. While deep learning for radar modulation recognition has been explored previously, classification tasks are generally limited to short and non-interleaved IQ signals, limiting their applicability to military applications. To address this gap, we introduce an end-to-end multi-stage learning approach to detect and localise pulse activities of interleaved radar signals across an extended time horizon. We propose a simple, yet highly effective multi-stage architecture for incrementally predicting fine-grained segmentation masks that localise radar pulse activities across multiple channels. We demonstrate the performance of our approach against several reference models on a novel radar dataset, while also providing a first-of-its-kind benchmark for radar pulse activity segmentation.", "url": "https://arxiv.org/abs/2312.09489"}, {"metadata": {"arXiv": "2312.09504", "Date": "Fri, 15 Dec 2023 03:04:28 ", "Title": "Combinatorial Complexes: Bridging the Gap Between Cell Complexes and Hypergraphs", "Authors": ["Mustafa Hajij", "Ghada Zamzmi", "Theodore Papamarkou", "Aldo Guzm\\'an-S\\'aenz", "Tolga Birdal", "Michael T. Schaub"], "Categories": "cs.LG cs.SI math.AT math.CO stat.ML"}, "abstract": "Graph-based signal processing techniques have become essential for handling data in non-Euclidean spaces. However, there is a growing awareness that these graph models might need to be expanded into `higher-order' domains to effectively represent the complex relations found in high-dimensional data. Such higher-order domains are typically modeled either as hypergraphs, or as simplicial, cubical or other cell complexes. In this context, cell complexes are often seen as a subclass of hypergraphs with additional algebraic structure that can be exploited, e.g., to develop a spectral theory. In this article, we promote an alternative perspective. We argue that hypergraphs and cell complexes emphasize \\emph{different} types of relations, which may have different utility depending on the application context. Whereas hypergraphs are effective in modeling set-type, multi-body relations between entities, cell complexes provide an effective means to model hierarchical, interior-to-boundary type relations. We discuss the relative advantages of these two choices and elaborate on the previously introduced concept of a combinatorial complex that enables co-existing set-type and hierarchical relations. Finally, we provide a brief numerical experiment to demonstrate that this modelling flexibility can be advantageous in learning tasks.", "url": "https://arxiv.org/abs/2312.09504"}, {"metadata": {"arXiv": "2312.09505", "Date": "Fri, 15 Dec 2023 03:06:19 ", "Title": "Adaptive Integration of Partial Label Learning and Negative Learning for Enhanced Noisy Label Learning", "Authors": ["Mengmeng Sheng", "Zeren Sun", "Zhenhuang Cai", "Tao Chen", "Yichao Zhou", "Yazhou Yao"], "Categories": "cs.LG cs.MM", "Comments": ["accepted by AAAI 2024"]}, "abstract": "There has been significant attention devoted to the effectiveness of various domains, such as semi-supervised learning, contrastive learning, and meta-learning, in enhancing the performance of methods for noisy label learning (NLL) tasks. However, most existing methods still depend on prior assumptions regarding clean samples amidst different sources of noise (\\eg, a pre-defined drop rate or a small subset of clean samples). In this paper, we propose a simple yet powerful idea called \\textbf{NPN}, which revolutionizes \\textbf{N}oisy label learning by integrating \\textbf{P}artial label learning (PLL) and \\textbf{N}egative learning (NL). Toward this goal, we initially decompose the given label space adaptively into the candidate and complementary labels, thereby establishing the conditions for PLL and NL. We propose two adaptive data-driven paradigms of label disambiguation for PLL: hard disambiguation and soft disambiguation. Furthermore, we generate reliable complementary labels using all non-candidate labels for NL to enhance model robustness through indirect supervision. To maintain label reliability during the later stage of model training, we introduce a consistency regularization term that encourages agreement between the outputs of multiple augmentations. Experiments conducted on both synthetically corrupted and real-world noisy datasets demonstrate the superiority of NPN compared to other state-of-the-art (SOTA) methods. The source code has been made available at {\\color{purple}{\\url{https://github.com/NUST-Machine-Intelligence-Laboratory/NPN}}}.", "url": "https://arxiv.org/abs/2312.09505"}, {"metadata": {"arXiv": "2312.09533", "Date": "Fri, 15 Dec 2023 04:51:43 ", "Title": "Adversarial Robustness on Image Classification with $k$-means", "Authors": ["Rollin Omari", "Junae Kim and Paul Montague"], "Categories": "cs.LG cs.CR cs.CV cs.NE", "Comments": ["6 pages", "3 figures", "2 equations", "1 algorithm"]}, "abstract": "In this paper we explore the challenges and strategies for enhancing the robustness of $k$-means clustering algorithms against adversarial manipulations. We evaluate the vulnerability of clustering algorithms to adversarial attacks, emphasising the associated security risks. Our study investigates the impact of incremental attack strength on training, introduces the concept of transferability between supervised and unsupervised models, and highlights the sensitivity of unsupervised models to sample distributions. We additionally introduce and evaluate an adversarial training method that improves testing performance in adversarial scenarios, and we highlight the importance of various parameters in the proposed training method, such as continuous learning, centroid initialisation, and adversarial step-count.", "url": "https://arxiv.org/abs/2312.09533"}, {"metadata": {"arXiv": "2312.09540", "Date": "Fri, 15 Dec 2023 05:22:39 ", "Title": "A Novel Hybrid Ordinal Learning Model with Health Care Application", "Authors": ["Lujia Wang", "Hairong Wang", "Yi Su", "Fleming Lure", "Jing Li"], "Categories": "cs.LG math.OC", "Comments": ["16 pages", "3 figures", "2 tables"], "MSC-class": "68Q32"}, "abstract": "Ordinal learning (OL) is a type of machine learning models with broad utility in health care applications such as diagnosis of different grades of a disease (e.g., mild, modest, severe) and prediction of the speed of disease progression (e.g., very fast, fast, moderate, slow). This paper aims to tackle a situation when precisely labeled samples are limited in the training set due to cost or availability constraints, whereas there could be an abundance of samples with imprecise labels. We focus on imprecise labels that are intervals, i.e., one can know that a sample belongs to an interval of labels but cannot know which unique label it has. This situation is quite common in health care datasets due to limitations of the diagnostic instrument, sparse clinical visits, or/and patient dropout. Limited research has been done to develop OL models with imprecise/interval labels. We propose a new Hybrid Ordinal Learner (HOL) to integrate samples with both precise and interval labels to train a robust OL model. We also develop a tractable and efficient optimization algorithm to solve the HOL formulation. We compare HOL with several recently developed OL methods on four benchmarking datasets, which demonstrate the superior performance of HOL. Finally, we apply HOL to a real-world dataset for predicting the speed of progressing to Alzheimer's Disease (AD) for individuals with Mild Cognitive Impairment (MCI) based on a combination of multi-modality neuroimaging and demographic/clinical datasets. HOL achieves high accuracy in the prediction and outperforms existing methods. The capability of accurately predicting the speed of progression to AD for each individual with MCI has the potential for helping facilitate more individually-optimized interventional strategies.", "url": "https://arxiv.org/abs/2312.09540"}, {"metadata": {"arXiv": "2312.09559", "Date": "Fri, 15 Dec 2023 06:34:35 ", "Title": "STEAM & MoSAFE: SOTIF Error-and-Failure Model & Analysis for AI-Enabled Driving Automation", "Authors": ["Krzysztof Czarnecki and Hiroshi Kuwajima"], "Categories": "cs.LG cs.SE", "Comments": ["19 pages", "8 figures", "5 tables"], "ACM-class": "I.2.0"}, "abstract": "Driving Automation Systems (DAS) are subject to complex road environments and vehicle behaviors and increasingly rely on sophisticated sensors and Artificial Intelligence (AI). These properties give rise to unique safety faults stemming from specification insufficiencies and technological performance limitations, where sensors and AI introduce errors that vary in magnitude and temporal patterns, posing potential safety risks. The Safety of the Intended Functionality (SOTIF) standard emerges as a promising framework for addressing these concerns, focusing on scenario-based analysis to identify hazardous behaviors and their causes. Although the current standard provides a basic cause-and-effect model and high-level process guidance, it lacks concepts required to identify and evaluate hazardous errors, especially within the context of AI. This paper introduces two key contributions to bridge this gap. First, it defines the SOTIF Temporal Error and Failure Model (STEAM) as a refinement of the SOTIF cause-and-effect model, offering a comprehensive system-design perspective. STEAM refines error definitions, introduces error sequences, and classifies them as error sequence patterns, providing particular relevance to systems employing advanced sensors and AI. Second, this paper proposes the Model-based SOTIF Analysis of Failures and Errors (MoSAFE) method, which allows instantiating STEAM based on system-design models by deriving hazardous error sequence patterns at module level from hazardous behaviors at vehicle level via weakest precondition reasoning. Finally, the paper presents a case study centered on an automated speed-control feature, illustrating the practical applicability of the refined model and the MoSAFE method in addressing complex safety challenges in DAS.", "url": "https://arxiv.org/abs/2312.09559"}, {"metadata": {"arXiv": "2312.09606", "Date": "Fri, 15 Dec 2023 08:39:02 ", "Title": "Reliable Prediction Intervals with Regression Neural Networks", "Authors": ["Harris Papadopoulos and Haris Haralambous"], "Categories": "cs.LG stat.ML", "Journal-ref": "Neural Networks, Volume 24, Issue 8, Pages 842-851, 2011", "DOI": "10.1016/j.neunet.2011.05.008"}, "abstract": "This paper proposes an extension to conventional regression Neural Networks (NNs) for replacing the point predictions they produce with prediction intervals that satisfy a required level of confidence. Our approach follows a novel machine learning framework, called Conformal Prediction (CP), for assigning reliable confidence measures to predictions without assuming anything more than that the data are independent and identically distributed (i.i.d.). We evaluate the proposed method on four benchmark datasets and on the problem of predicting Total Electron Content (TEC), which is an important parameter in trans-ionospheric links; for the latter we use a dataset of more than 60000 TEC measurements collected over a period of 11 years. Our experimental results show that the prediction intervals produced by our method are both well-calibrated and tight enough to be useful in practice.", "url": "https://arxiv.org/abs/2312.09606"}, {"metadata": {"arXiv": "2312.09674", "Date": "Fri, 15 Dec 2023 10:36:13 ", "Title": "Optimal Regret Bounds for Collaborative Learning in Bandits", "Authors": ["Amitis Shidani and Sattar Vakili"], "Categories": "cs.LG cs.MA stat.ML", "Comments": ["Algorithmic Learning Theory (ALT) 2024"]}, "abstract": "We consider regret minimization in a general collaborative multi-agent multi-armed bandit model, in which each agent faces a finite set of arms and may communicate with other agents through a central controller. The optimal arm for each agent in this model is the arm with the largest expected mixed reward, where the mixed reward of each arm is a weighted average of its rewards across all agents, making communication among agents crucial. While near-optimal sample complexities for best arm identification are known under this collaborative model, the question of optimal regret remains open. In this work, we address this problem and propose the first algorithm with order optimal regret bounds under this collaborative bandit model. Furthermore, we show that only a small constant number of expected communication rounds is needed.", "url": "https://arxiv.org/abs/2312.09674"}, {"metadata": {"arXiv": "2312.09681", "Date": "Fri, 15 Dec 2023 10:53:09 ", "Title": "Urban Region Embedding via Multi-View Contrastive Prediction", "Authors": ["Zechen Li", "Weiming Huang", "Kai Zhao", "Min Yang", "Yongshun Gong", "Meng Chen"], "Categories": "cs.LG cs.CV cs.DB"}, "abstract": "Recently, learning urban region representations utilizing multi-modal data (information views) has become increasingly popular, for deep understanding of the distributions of various socioeconomic features in cities. However, previous methods usually blend multi-view information in a posteriors stage, falling short in learning coherent and consistent representations across different views. In this paper, we form a new pipeline to learn consistent representations across varying views, and propose the multi-view Contrastive Prediction model for urban Region embedding (ReCP), which leverages the multiple information views from point-of-interest (POI) and human mobility data. Specifically, ReCP comprises two major modules, namely an intra-view learning module utilizing contrastive learning and feature reconstruction to capture the unique information from each single view, and inter-view learning module that perceives the consistency between the two views using a contrastive prediction learning scheme. We conduct thorough experiments on two downstream tasks to assess the proposed model, i.e., land use clustering and region popularity prediction. The experimental results demonstrate that our model outperforms state-of-the-art baseline methods significantly in urban region representation learning.", "url": "https://arxiv.org/abs/2312.09681"}, {"metadata": {"arXiv": "2312.09741", "Date": "Fri, 15 Dec 2023 12:30:30 ", "Title": "PELP: Pioneer Event Log Prediction Using Sequence-to-Sequence Neural Networks", "Authors": ["Wenjun Zhou", "Artem Polyvyanyy", "James Bailey"], "Categories": "cs.LG cs.SE", "Comments": ["CAiSE 2024 submission"]}, "abstract": "Process mining, a data-driven approach for analyzing, visualizing, and improving business processes using event logs, has emerged as a powerful technique in the field of business process management. Process forecasting is a sub-field of process mining that studies how to predict future processes and process models. In this paper, we introduce and motivate the problem of event log prediction and present our approach to solving the event log prediction problem, in particular, using the sequence-to-sequence deep learning approach. We evaluate and analyze the prediction outcomes on a variety of synthetic logs and seven real-life logs and show that our approach can generate perfect predictions on synthetic logs and that deep learning techniques have the potential to be applied in real-world event log prediction tasks. We further provide practical recommendations for event log predictions grounded in the outcomes of the conducted experiments.", "url": "https://arxiv.org/abs/2312.09741"}, {"metadata": {"arXiv": "2312.09744", "Date": "Fri, 15 Dec 2023 12:31:35 ", "Title": "Bridging the Semantic-Numerical Gap: A Numerical Reasoning Method of Cross-modal Knowledge Graph for Material Property Prediction", "Authors": ["Guangxuan Song", "Dongmei Fu", "Zhongwei Qiu", "Zijiang Yang", "Jiaxin Dai", "Lingwei Ma", "Dawei Zhang"], "Categories": "cs.LG cond-mat.mtrl-sci"}, "abstract": "Using machine learning (ML) techniques to predict material properties is a crucial research topic. These properties depend on numerical data and semantic factors. Due to the limitations of small-sample datasets, existing methods typically adopt ML algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material. However, these methods cannot simultaneously handle semantic and numerical information. In this paper, we propose a numerical reasoning method for material KGs (NR-KG), which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. It captures both types of information by projecting KG into a canonical KG and utilizes a graph neural network to predict material properties. In this process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes valuable experimental data to enhance material prediction. We further propose two new High-Entropy Alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods, achieving relative improvements of 25.9% and 16.1% on two material datasets. Besides, NR-KG surpasses SOTA methods on two public physical chemistry molecular datasets, showing improvements of 22.2% and 54.3%, highlighting its potential application and generalizability. We hope the proposed datasets, algorithms, and pre-trained models can facilitate the communities of KG and AI for materials.", "url": "https://arxiv.org/abs/2312.09744"}, {"metadata": {"arXiv": "2312.09748", "Date": "Fri, 15 Dec 2023 12:39:27 ", "Title": "Verification-Friendly Deep Neural Networks", "Authors": ["Anahita Baninajjar", "Ahmed Rezine", "Amir Aminifar"], "Categories": "cs.LG cs.SE"}, "abstract": "Machine learning techniques often lack formal correctness guarantees. This is evidenced by the widespread adversarial examples that plague most deep-learning applications. This resulted in several research efforts that aim at verifying deep neural networks, with a particular focus on safety-critical applications. However, formal verification techniques still face major scalability and precision challenges when dealing with the complexity of such networks. The over-approximation introduced during the formal verification process to tackle the scalability challenge often results in inconclusive analysis. To address this challenge, we propose a novel framework to generate Verification-friendly Neural Networks (VNNs). We present a post-training optimization framework to achieve a balance between preserving prediction performance and robustness in the resulting networks. Our proposed framework proves to result in networks that are comparable to the original ones in terms of prediction performance, while amenable to verification. This essentially enables us to establish robustness for more VNNs than their deep neural network counterparts, in a more time-efficient manner.", "url": "https://arxiv.org/abs/2312.09748"}, {"metadata": {"arXiv": "2312.09766", "Date": "Fri, 15 Dec 2023 13:12:49 ", "Title": "Celestial Machine Learning: From Data to Mars and Beyond with AI Feynman", "Authors": ["Zi-Yu Khoo", "Abel Yang", "Jonathan Sze Choong Low", "St\\'ephane Bressan"], "Categories": "cs.LG", "Comments": ["v1: long version v2: accepted as a short paper"], "DOI": "10.1007/978-3-031-39821-6_41"}, "abstract": "Can a machine or algorithm discover or learn Kepler's first law from astronomical sightings alone? We emulate Johannes Kepler's discovery of the equation of the orbit of Mars with the Rudolphine tables using AI Feynman, a physics-inspired tool for symbolic regression.", "url": "https://arxiv.org/abs/2312.09766"}, {"metadata": {"arXiv": "2312.09775", "Date": "Fri, 15 Dec 2023 13:28:42 ", "Title": "A Comparative Evaluation of Additive Separability Tests for Physics-Informed Machine Learning", "Authors": ["Zi-Yu Khoo", "Jonathan Sze Choong Low", "St\\'ephane Bressan"], "Categories": "cs.LG", "DOI": "10.1007/978-3-031-48316-5_13"}, "abstract": "Many functions characterising physical systems are additively separable. This is the case, for instance, of mechanical Hamiltonian functions in physics, population growth equations in biology, and consumer preference and utility functions in economics. We consider the scenario in which a surrogate of a function is to be tested for additive separability. The detection that the surrogate is additively separable can be leveraged to improve further learning. Hence, it is beneficial to have the ability to test for such separability in surrogates. The mathematical approach is to test if the mixed partial derivative of the surrogate is zero; or empirically, lower than a threshold. We present and comparatively and empirically evaluate the eight methods to compute the mixed partial derivative of a surrogate function.", "url": "https://arxiv.org/abs/2312.09775"}, {"metadata": {"arXiv": "2312.09778", "Date": "Fri, 15 Dec 2023 13:30:04 ", "Title": "Hypergraph-MLP: Learning on Hypergraphs without Message Passing", "Authors": ["Bohan Tang", "Siheng Chen", "Xiaowen Dong"], "Categories": "cs.LG eess.SP", "Comments": ["Accepted by ICASSP 2024"]}, "abstract": "Hypergraphs are vital in modelling data with higher-order relations containing more than two entities, gaining prominence in machine learning and signal processing. Many hypergraph neural networks leverage message passing over hypergraph structures to enhance node representation learning, yielding impressive performances in tasks like hypergraph node classification. However, these message-passing-based models face several challenges, including oversmoothing as well as high latency and sensitivity to structural perturbations at inference time. To tackle those challenges, we propose an alternative approach where we integrate the information about hypergraph structures into training supervision without explicit message passing, thus also removing the reliance on it at inference. Specifically, we introduce Hypergraph-MLP, a novel learning framework for hypergraph-structured data, where the learning model is a straightforward multilayer perceptron (MLP) supervised by a loss function based on a notion of signal smoothness on hypergraphs. Experiments on hypergraph node classification tasks demonstrate that Hypergraph-MLP achieves competitive performance compared to existing baselines, and is considerably faster and more robust against structural perturbations at inference.", "url": "https://arxiv.org/abs/2312.09778"}, {"metadata": {"arXiv": "2312.09783", "Date": "Fri, 15 Dec 2023 13:36:54 ", "Title": "Keep the Faith: Faithful Explanations in Convolutional Neural Networks for Case-Based Reasoning", "Authors": ["Tom Nuno Wolf", "Fabian Bongratz", "Anne-Marie Rickmann", "Sebastian P\\\"olsterl", "Christian Wachinger"], "Categories": "cs.LG cs.CV", "Comments": ["To be published in proceedings of AAAI Conference on Artificial Intelligence"]}, "abstract": "Explaining predictions of black-box neural networks is crucial when applied to decision-critical tasks. Thus, attribution maps are commonly used to identify important image regions, despite prior work showing that humans prefer explanations based on similar examples. To this end, ProtoPNet learns a set of class-representative feature vectors (prototypes) for case-based reasoning. During inference, similarities of latent features to prototypes are linearly classified to form predictions and attribution maps are provided to explain the similarity. In this work, we evaluate whether architectures for case-based reasoning fulfill established axioms required for faithful explanations using the example of ProtoPNet. We show that such architectures allow the extraction of faithful explanations. However, we prove that the attribution maps used to explain the similarities violate the axioms. We propose a new procedure to extract explanations for trained ProtoPNets, named ProtoPFaith. Conceptually, these explanations are Shapley values, calculated on the similarity scores of each prototype. They allow to faithfully answer which prototypes are present in an unseen image and quantify each pixel's contribution to that presence, thereby complying with all axioms. The theoretical violations of ProtoPNet manifest in our experiments on three datasets (CUB-200-2011, Stanford Dogs, RSNA) and five architectures (ConvNet, ResNet, ResNet50, WideResNet50, ResNeXt50). Our experiments show a qualitative difference between the explanations given by ProtoPNet and ProtoPFaith. Additionally, we quantify the explanations with the Area Over the Perturbation Curve, on which ProtoPFaith outperforms ProtoPNet on all experiments by a factor $>10^3$.", "url": "https://arxiv.org/abs/2312.09783"}, {"metadata": {"arXiv": "2312.09787", "Date": "Fri, 15 Dec 2023 13:41:20 ", "Title": "Physics-informed Neural Network Estimation of Material Properties in Soft Tissue Nonlinear Biomechanical Models", "Authors": ["Federica Caforio and Francesco Regazzoni and Stefano Pagani and Elias Karabelas and Christoph Augustin and Gundolf Haase and Gernot Plank and Alfio Quarteroni"], "Categories": "cs.LG cs.NA math.NA physics.bio-ph physics.med-ph"}, "abstract": "The development of biophysical models for clinical applications is rapidly advancing in the research community, thanks to their predictive nature and their ability to assist the interpretation of clinical data. However, high-resolution and accurate multi-physics computational models are computationally expensive and their personalisation involves fine calibration of a large number of parameters, which may be space-dependent, challenging their clinical translation. In this work, we propose a new approach which relies on the combination of physics-informed neural networks (PINNs) with three-dimensional soft tissue nonlinear biomechanical models, capable of reconstructing displacement fields and estimating heterogeneous patient-specific biophysical properties. The proposed learning algorithm encodes information from a limited amount of displacement and, in some cases, strain data, that can be routinely acquired in the clinical setting, and combines it with the physics of the problem, represented by a mathematical model based on partial differential equations, to regularise the problem and improve its convergence properties. Several benchmarks are presented to show the accuracy and robustness of the proposed method and its great potential to enable the robust and effective identification of patient-specific, heterogeneous physical properties, s.a. tissue stiffness properties. In particular, we demonstrate the capability of the PINN to detect the presence, location and severity of scar tissue, which is beneficial to develop personalised simulation models for disease diagnosis, especially for cardiac applications.", "url": "https://arxiv.org/abs/2312.09787"}, {"metadata": {"arXiv": "2312.09790", "Date": "Fri, 15 Dec 2023 13:47:16 ", "Title": "End-to-End Training of Neural Networks for Automotive Radar Interference Mitigation", "Authors": ["Christian Oswald", "Mate Toth", "Paul Meissner", "Franz Pernkopf"], "Categories": "cs.LG eess.SP", "Comments": ["2023 IEEE International Radar Conference (RADAR)", "6 pages", "4 figures"]}, "abstract": "In this paper we propose a new method for training neural networks (NNs) for frequency modulated continuous wave (FMCW) radar mutual interference mitigation. Instead of training NNs to regress from interfered to clean radar signals as in previous work, we train NNs directly on object detection maps. We do so by performing a continuous relaxation of the cell-averaging constant false alarm rate (CA-CFAR) peak detector, which is a well-established algorithm for object detection using radar. With this new training objective we are able to increase object detection performance by a large margin. Furthermore, we introduce separable convolution kernels to strongly reduce the number of parameters and computational complexity of convolutional NN architectures for radar applications. We validate our contributions with experiments on real-world measurement data and compare them against signal processing interference mitigation methods.", "url": "https://arxiv.org/abs/2312.09790"}, {"metadata": {"arXiv": "2312.09793", "Date": "Fri, 15 Dec 2023 13:49:29 ", "Title": "PAC-Bayes Generalisation Bounds for Dynamical Systems Including Stable RNNs", "Authors": ["Deividas Eringis", "John Leth", "Zheng-Hua Tan", "Rafal Wisniewski", "Mihaly Petreczky"], "Categories": "cs.LG stat.ML", "Comments": ["Accepted to AAAI2024 conference"]}, "abstract": "In this paper, we derive a PAC-Bayes bound on the generalisation gap, in a supervised time-series setting for a special class of discrete-time non-linear dynamical systems. This class includes stable recurrent neural networks (RNN), and the motivation for this work was its application to RNNs. In order to achieve the results, we impose some stability constraints, on the allowed models. Here, stability is understood in the sense of dynamical systems. For RNNs, these stability conditions can be expressed in terms of conditions on the weights. We assume the processes involved are essentially bounded and the loss functions are Lipschitz. The proposed bound on the generalisation gap depends on the mixing coefficient of the data distribution, and the essential supremum of the data. Furthermore, the bound converges to zero as the dataset size increases. In this paper, we 1) formalize the learning problem, 2) derive a PAC-Bayesian error bound for such systems, 3) discuss various consequences of this error bound, and 4) show an illustrative example, with discussions on computing the proposed bound. Unlike other available bounds the derived bound holds for non i.i.d. data (time-series) and it does not grow with the number of steps of the RNN.", "url": "https://arxiv.org/abs/2312.09793"}, {"metadata": {"arXiv": "2312.09817", "Date": "Fri, 15 Dec 2023 14:17:16 ", "Title": "Calibrated One Round Federated Learning with Bayesian Inference in the Predictive Space", "Authors": ["Mohsin Hasan", "Guojun Zhang", "Kaiyang Guo", "Xi Chen", "Pascal Poupart"], "Categories": "cs.LG stat.ML", "Comments": ["7 pages", "2 figures. To appear at AAAI 2024"]}, "abstract": "Federated Learning (FL) involves training a model over a dataset distributed among clients, with the constraint that each client's dataset is localized and possibly heterogeneous. In FL, small and noisy datasets are common, highlighting the need for well-calibrated models that represent the uncertainty of predictions. The closest FL techniques to achieving such goals are the Bayesian FL methods which collect parameter samples from local posteriors, and aggregate them to approximate the global posterior. To improve scalability for larger models, one common Bayesian approach is to approximate the global predictive posterior by multiplying local predictive posteriors. In this work, we demonstrate that this method gives systematically overconfident predictions, and we remedy this by proposing $\\beta$-Predictive Bayes, a Bayesian FL algorithm that interpolates between a mixture and product of the predictive posteriors, using a tunable parameter $\\beta$. This parameter is tuned to improve the global ensemble's calibration, before it is distilled to a single model. Our method is evaluated on a variety of regression and classification datasets to demonstrate its superiority in calibration to other baselines, even as data heterogeneity increases. Code available at https://github.com/hasanmohsin/betaPredBayes_FL", "url": "https://arxiv.org/abs/2312.09817"}, {"metadata": {"arXiv": "2312.09821", "Date": "Fri, 15 Dec 2023 14:20:16 ", "Title": "Fragility, Robustness and Antifragility in Deep Learning", "Authors": ["Chandresh Pravin", "Ivan Martino", "Giuseppe Nicosia", "Varun Ojha"], "Categories": "cs.LG cs.CV", "Journal-ref": "Artificial Intelligence 2023"}, "abstract": "We propose a systematic analysis of deep neural networks (DNNs) based on a signal processing technique for network parameter removal, in the form of synaptic filters that identifies the fragility, robustness and antifragility characteristics of DNN parameters. Our proposed analysis investigates if the DNN performance is impacted negatively, invariantly, or positively on both clean and adversarially perturbed test datasets when the DNN undergoes synaptic filtering. We define three \\textit{filtering scores} for quantifying the fragility, robustness and antifragility characteristics of DNN parameters based on the performances for (i) clean dataset, (ii) adversarial dataset, and (iii) the difference in performances of clean and adversarial datasets. We validate the proposed systematic analysis on ResNet-18, ResNet-50, SqueezeNet-v1.1 and ShuffleNet V2 x1.0 network architectures for MNIST, CIFAR10 and Tiny ImageNet datasets. The filtering scores, for a given network architecture, identify network parameters that are invariant in characteristics across different datasets over learning epochs. Vice-versa, for a given dataset, the filtering scores identify the parameters that are invariant in characteristics across different network architectures. We show that our synaptic filtering method improves the test accuracy of ResNet and ShuffleNet models on adversarial datasets when only the robust and antifragile parameters are selectively retrained at any given epoch, thus demonstrating applications of the proposed strategy in improving model robustness.", "url": "https://arxiv.org/abs/2312.09821"}, {"metadata": {"arXiv": "2312.09830", "Date": "Fri, 15 Dec 2023 14:34:14 ", "Title": "Socio-Economic Deprivation Analysis: Diffusion Maps", "Authors": ["June Moh Goo"], "Categories": "cs.LG"}, "abstract": "This report proposes a model to predict the location of the most deprived areas in a city using data from the census. A census data is very high dimensional and needs to be simplified. We use a novel algorithm to reduce dimensionality and find patterns: The diffusion map. Features are defined by eigenvectors of the Laplacian matrix that defines the diffusion map. Eigenvectors corresponding to the smallest eigenvalues indicate specific population features. Previous work has found qualitatively that the second most important dimension for describing the census data in Bristol is linked to deprivation. In this report, we analyse how good this dimension is as a model for predicting deprivation by comparing with the recognised measures. The Pearson correlation coefficient was found to be over 0.7. The top 10 per cent of deprived areas in the UK which also locate in Bristol are extracted to test the accuracy of the model. There are 52 most deprived areas, and 38 areas are correctly identified by comparing to the model. The influence of scores of IMD domains that do not correlate with the models, Eigenvector 2 entries of non-deprived OAs and orthogonality of Eigenvectors cause the model to fail the prediction of 14 deprived areas. However, overall, the model shows a high performance to predict the future deprivation of overall areas where the project considers. This project is expected to support the government to allocate resources and funding.", "url": "https://arxiv.org/abs/2312.09830"}, {"metadata": {"arXiv": "2312.09832", "Date": "Fri, 15 Dec 2023 14:38:28 ", "Title": "Disentangling Linear Mode-Connectivity", "Authors": ["Gul Sena Altintas", "Gregor Bachmann", "Lorenzo Noci", "Thomas Hofmann"], "Categories": "cs.LG", "Comments": ["9 pages", "5 figures"]}, "abstract": "Linear mode-connectivity (LMC) (or lack thereof) is one of the intriguing characteristics of neural network loss landscapes. While empirically well established, it unfortunately still lacks a proper theoretical understanding. Even worse, although empirical data points are abound, a systematic study of when networks exhibit LMC is largely missing in the literature. In this work we aim to close this gap. We explore how LMC is affected by three factors: (1) architecture (sparsity, weight-sharing), (2) training strategy (optimization setup) as well as (3) the underlying dataset. We place particular emphasis on minimal but non-trivial settings, removing as much unnecessary complexity as possible. We believe that our insights can guide future theoretical works on uncovering the inner workings of LMC.", "url": "https://arxiv.org/abs/2312.09832"}, {"metadata": {"arXiv": "2312.09852", "Date": "Fri, 15 Dec 2023 14:58:34 ", "Title": "Learning Distributions on Manifolds with Free-form Flows", "Authors": ["Peter Sorrenson", "Felix Draxler", "Armand Rousselot", "Sander Hummerich", "Ullrich K\\\"othe"], "Categories": "cs.LG stat.ML", "Comments": ["Preprint", "under review"]}, "abstract": "Many real world data, particularly in the natural sciences and computer vision, lie on known Riemannian manifolds such as spheres, tori or the group of rotation matrices. The predominant approaches to learning a distribution on such a manifold require solving a differential equation in order to sample from the model and evaluate densities. The resulting sampling times are slowed down by a high number of function evaluations. In this work, we propose an alternative approach which only requires a single function evaluation followed by a projection to the manifold. Training is achieved by an adaptation of the recently proposed free-form flow framework to Riemannian manifolds. The central idea is to estimate the gradient of the negative log-likelihood via a trace evaluated in the tangent space. We evaluate our method on various manifolds, and find significantly faster inference at competitive performance compared to previous work. We make our code public at https://github.com/vislearn/FFF.", "url": "https://arxiv.org/abs/2312.09852"}, {"metadata": {"arXiv": "2312.09860", "Date": "Fri, 15 Dec 2023 15:05:25 ", "Title": "Automatic Rao-Blackwellization for Sequential Monte Carlo with Belief Propagation", "Authors": ["Wa\\\"iss Azizian", "Guillaume Baudart", "Marc Lelarge"], "Categories": "cs.LG stat.CO"}, "abstract": "Exact Bayesian inference on state-space models~(SSM) is in general untractable, and unfortunately, basic Sequential Monte Carlo~(SMC) methods do not yield correct approximations for complex models. In this paper, we propose a mixed inference algorithm that computes closed-form solutions using belief propagation as much as possible, and falls back to sampling-based SMC methods when exact computations fail. This algorithm thus implements automatic Rao-Blackwellization and is even exact for Gaussian tree models.", "url": "https://arxiv.org/abs/2312.09860"}, {"metadata": {"arXiv": "2312.09865", "Date": "Fri, 15 Dec 2023 15:09:16 ", "Title": "Automating reward function configuration for drug design", "Authors": ["Marius Urbonas", "Temitope Ajileye", "Paul Gainer and Douglas Pires"], "Categories": "cs.LG q-bio.BM", "Journal-ref": "The NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development (AI4D3 2023), New Orleans, LA, USA, 2023"}, "abstract": "Designing reward functions that guide generative molecular design (GMD) algorithms to desirable areas of chemical space is of critical importance in AI-driven drug discovery. Traditionally, this has been a manual and error-prone task; the selection of appropriate computational methods to approximate biological assays is challenging and the aggregation of computed values into a single score even more so, leading to potential reliance on trial-and-error approaches. We propose a novel approach for automated reward configuration that relies solely on experimental data, mitigating the challenges of manual reward adjustment on drug discovery projects. Our method achieves this by constructing a ranking over experimental data based on Pareto dominance over the multi-objective space, then training a neural network to approximate the reward function such that rankings determined by the predicted reward correlate with those determined by the Pareto dominance relation. We validate our method using two case studies. In the first study we simulate Design-Make-Test-Analyse (DMTA) cycles by alternating reward function updates and generative runs guided by that function. We show that the learned function adapts over time to yield compounds that score highly with respect to evaluation functions taken from the literature. In the second study we apply our algorithm to historical data from four real drug discovery projects. We show that our algorithm yields reward functions that outperform the predictive accuracy of human-defined functions, achieving an improvement of up to 0.4 in Spearman's correlation against a ground truth evaluation function that encodes the target drug profile for that project. Our method provides an efficient data-driven way to configure reward functions for GMD, and serves as a strong baseline for future research into transformative approaches for the automation of drug discovery.", "url": "https://arxiv.org/abs/2312.09865"}, {"metadata": {"arXiv": "2312.09871", "Date": "Fri, 15 Dec 2023 15:18:33 ", "Title": "ChemTime: Rapid and Early Classification for Multivariate Time Series Classification of Chemical Sensors", "Authors": ["Alexander M. Moore", "Randy C. Paffenroth", "Kenneth T. Ngo", "Joshua R. Uzarski"], "Categories": "cs.LG q-bio.QM", "Comments": ["14 pages", "12 figures"]}, "abstract": "Multivariate time series data are ubiquitous in the application of machine learning to problems in the physical sciences. Chemiresistive sensor arrays are highly promising in chemical detection tasks relevant to industrial, safety, and military applications. Sensor arrays are an inherently multivariate time series data collection tool which demand rapid and accurate classification of arbitrary chemical analytes. Previous research has benchmarked data-agnostic multivariate time series classifiers across diverse multivariate time series supervised tasks in order to find general-purpose classification algorithms. To our knowledge, there has yet to be an effort to survey machine learning and time series classification approaches to chemiresistive hardware sensor arrays for the detection of chemical analytes. In addition to benchmarking existing approaches to multivariate time series classifiers, we incorporate findings from a model survey to propose the novel \\textit{ChemTime} approach to sensor array classification for chemical sensing. We design experiments addressing the unique challenges of hardware sensor arrays classification including the rapid classification ability of classifiers and minimization of inference time while maintaining performance for deployed lightweight hardware sensing devices. We find that \\textit{ChemTime} is uniquely positioned for the chemical sensing task by combining rapid and early classification of time series with beneficial inference and high accuracy.", "url": "https://arxiv.org/abs/2312.09871"}, {"metadata": {"arXiv": "2312.09912", "Date": "Fri, 15 Dec 2023 16:23:25 ", "Title": "Reliable Probabilistic Classification with Neural Networks", "Authors": ["Harris Papadopoulos"], "Categories": "cs.LG", "Journal-ref": "Neurocomputing, Volume 107, May 2013", "DOI": "10.1016/j.neucom.2012.07.034"}, "abstract": "Venn Prediction (VP) is a new machine learning framework for producing well-calibrated probabilistic predictions. In particular it provides well-calibrated lower and upper bounds for the conditional probability of an example belonging to each possible class of the problem at hand. This paper proposes five VP methods based on Neural Networks (NNs), which is one of the most widely used machine learning techniques. The proposed methods are evaluated experimentally on four benchmark datasets and the obtained results demonstrate the empirical well-calibratedness of their outputs and their superiority over the outputs of the traditional NN classifier.", "url": "https://arxiv.org/abs/2312.09912"}, {"metadata": {"arXiv": "2312.09940", "Date": "Fri, 15 Dec 2023 16:53:55 ", "Title": "Sketch and shift: a robust decoder for compressive clustering", "Authors": ["Ayoub Belhadji and R\\'emi Gribonval"], "Categories": "cs.LG stat.ML"}, "abstract": "Compressive learning is an emerging approach to drastically reduce the memory footprint of large-scale learning, by first summarizing a large dataset into a low-dimensional sketch vector, and then decoding from this sketch the latent information needed for learning. In light of recent progress on information preservation guarantees for sketches based on random features, a major objective is to design easy-to-tune algorithms (called decoders) to robustly and efficiently extract this information. To address the underlying non-convex optimization problems, various heuristics have been proposed. In the case of compressive clustering, the standard heuristic is CL-OMPR, a variant of sliding Frank-Wolfe. Yet, CL-OMPR is hard to tune, and the examination of its robustness was overlooked. In this work, we undertake a scrutinized examination of CL-OMPR to circumvent its limitations. In particular, we show how this algorithm can fail to recover the clusters even in advantageous scenarios. To gain insight, we show how the deficiencies of this algorithm can be attributed to optimization difficulties related to the structure of a correlation function appearing at core steps of the algorithm. To address these limitations, we propose an alternative decoder offering substantial improvements over CL-OMPR. Its design is notably inspired from the mean shift algorithm, a classic approach to detect the local maxima of kernel density estimators. The proposed algorithm can extract clustering information from a sketch of the MNIST dataset that is 10 times smaller than previously.", "url": "https://arxiv.org/abs/2312.09940"}, {"metadata": {"arXiv": "2312.09961", "Date": "Fri, 15 Dec 2023 17:16:04 ", "Title": "Risk-Aware Continuous Control with Neural Contextual Bandits", "Authors": ["Jose A. Ayala-Romero", "Andres Garcia-Saavedra", "Xavier Costa-Perez"], "Categories": "cs.LG eess.SP stat.ML", "Comments": ["12 pages", "13 figures"]}, "abstract": "Recent advances in learning techniques have garnered attention for their applicability to a diverse range of real-world sequential decision-making problems. Yet, many practical applications have critical constraints for operation in real environments. Most learning solutions often neglect the risk of failing to meet these constraints, hindering their implementation in real-world contexts. In this paper, we propose a risk-aware decision-making framework for contextual bandit problems, accommodating constraints and continuous action spaces. Our approach employs an actor multi-critic architecture, with each critic characterizing the distribution of performance and constraint metrics. Our framework is designed to cater to various risk levels, effectively balancing constraint satisfaction against performance. To demonstrate the effectiveness of our approach, we first compare it against state-of-the-art baseline methods in a synthetic environment, highlighting the impact of intrinsic environmental noise across different risk configurations. Finally, we evaluate our framework in a real-world use case involving a 5G mobile network where only our approach consistently satisfies the system constraint (a signal processing reliability target) with a small performance toll (8.5% increase in power consumption).", "url": "https://arxiv.org/abs/2312.09961"}, {"metadata": {"arXiv": "2312.09978", "Date": "Fri, 15 Dec 2023 17:41:51 ", "Title": "Small jet engine reservoir computing digital twin", "Authors": ["C. J. Wright", "N. Biederman", "B. Gyovai", "D. J. Gauthier", "J. P. Wilhelm"], "Categories": "cs.LG nlin.AO"}, "abstract": "Machine learning was applied to create a digital twin of a numerical simulation of a single-scroll jet engine. A similar model based on the insights gained from this numerical study was used to create a digital twin of a JetCat P100-RX jet engine using only experimental data. Engine data was collected from a custom sensor system measuring parameters such as thrust, exhaust gas temperature, shaft speed, weather conditions, etc. Data was gathered while the engine was placed under different test conditions by controlling shaft speed. The machine learning model was generated (trained) using a next-generation reservoir computer, a best-in-class machine learning algorithm for dynamical systems. Once the model was trained, it was used to predict behavior it had never seen with an accuracy of better than 1.8% when compared to the testing data.", "url": "https://arxiv.org/abs/2312.09978"}, {"metadata": {"arXiv": "2312.10001", "Date": "Fri, 15 Dec 2023 18:19:22 ", "Title": "Modeling Unknown Stochastic Dynamical System via Autoencoder", "Authors": ["Zhongshu Xu", "Yuan Chen", "Qifan Chen", "Dongbin Xiu"], "Categories": "cs.LG cs.NA math.NA stat.ML", "MSC-class": "60H10, 60H35, 62M45, 65C30"}, "abstract": "We present a numerical method to learn an accurate predictive model for an unknown stochastic dynamical system from its trajectory data. The method seeks to approximate the unknown flow map of the underlying system. It employs the idea of autoencoder to identify the unobserved latent random variables. In our approach, we design an encoding function to discover the latent variables, which are modeled as unit Gaussian, and a decoding function to reconstruct the future states of the system. Both the encoder and decoder are expressed as deep neural networks (DNNs). Once the DNNs are trained by the trajectory data, the decoder serves as a predictive model for the unknown stochastic system. Through an extensive set of numerical examples, we demonstrate that the method is able to produce long-term system predictions by using short bursts of trajectory data. It is also applicable to systems driven by non-Gaussian noises.", "url": "https://arxiv.org/abs/2312.10001"}, {"metadata": {"arXiv": "2312.10004", "Date": "Fri, 15 Dec 2023 18:20:25 ", "Title": "Symplectic Autoencoders for Model Reduction of Hamiltonian Systems", "Authors": ["Benedikt Brantner", "Michael Kraus"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Many applications, such as optimization, uncertainty quantification and inverse problems, require repeatedly performing simulations of large-dimensional physical systems for different choices of parameters. This can be prohibitively expensive. In order to save computational cost, one can construct surrogate models by expressing the system in a low-dimensional basis, obtained from training data. This is referred to as model reduction. Past investigations have shown that, when performing model reduction of Hamiltonian systems, it is crucial to preserve the symplectic structure associated with the system in order to ensure long-term numerical stability. Up to this point structure-preserving reductions have largely been limited to linear transformations. We propose a new neural network architecture in the spirit of autoencoders, which are established tools for dimension reduction and feature extraction in data science, to obtain more general mappings. In order to train the network, a non-standard gradient descent approach is applied that leverages the differential-geometric structure emerging from the network design. The new architecture is shown to significantly outperform existing designs in accuracy.", "url": "https://arxiv.org/abs/2312.10004"}, {"metadata": {"arXiv": "2312.10023", "Date": "Wed, 13 Dec 2023 11:29:40 ", "Title": "A Kronecker product accelerated efficient sparse Gaussian Process (E-SGP) for flow emulation", "Authors": ["Yu Duan", "Matthew Eaton", "Michael Bluck"], "Categories": "cs.LG"}, "abstract": "In this paper, we introduce an efficient sparse Gaussian process (E-SGP) for the surrogate modelling of fluid mechanics. This novel Bayesian machine learning algorithm allows efficient model training using databases of different structures. It is a further development of the approximated sparse GP algorithm, combining the concept of efficient GP (E-GP) and variational energy free sparse Gaussian process (VEF-SGP). The developed E-SGP approach exploits the arbitrariness of inducing points and the monotonically increasing nature of the objective function with respect to the number of inducing points in VEF-SGP. By specifying the inducing points on the orthogonal grid/input subspace and using the Kronecker product, E-SGP significantly improves computational efficiency without imposing any constraints on the covariance matrix or increasing the number of parameters that need to be optimised during training. The E-SGP algorithm developed in this paper outperforms E-GP not only in scalability but also in model quality in terms of mean standardized logarithmic loss (MSLL). The computational complexity of E-GP suffers from the cubic growth regarding the growing structured training database. However, E-SGP maintains computational efficiency whilst the resolution of the model, (i.e., the number of inducing points) remains fixed. The examples show that E-SGP produces more accurate predictions in comparison with E-GP when the model resolutions are similar in both. E-GP benefits from more training data but comes with higher computational demands, while E-SGP achieves a comparable level of accuracy but is more computationally efficient, making E-SGP a potentially preferable choice for fluid mechanic problems. Furthermore, E-SGP can produce more reasonable estimates of model uncertainty, whilst E-GP is more likely to produce over-confident predictions.", "url": "https://arxiv.org/abs/2312.10023"}, {"metadata": {"arXiv": "2312.10024", "Date": "Fri, 15 Dec 2023 18:43:45 ", "Title": "Accelerating Neural Network Training: A Brief Review", "Authors": ["Sahil Nokhwal", "Priyanka Chilakalapudi", "Preeti Donekal", "Manoj Chandrasekharan", "Suman Nokhwal", "Ram Swaroop", "Raj Bala", "Saurabh Pahune and Ankit Chaudhary"], "Categories": "cs.LG"}, "abstract": "The process of training a deep neural network is characterized by significant time requirements and associated costs. Although researchers have made considerable progress in this area, further work is still required due to resource constraints. This study examines innovative approaches to expedite the training process of deep neural networks (DNN), with specific emphasis on three state-of-the-art models such as ResNet50, Vision Transformer (ViT), and EfficientNet. The research utilizes sophisticated methodologies, including Gradient Accumulation (GA), Automatic Mixed Precision (AMP), and Pin Memory (PM), in order to optimize performance and accelerate the training procedure. The study examines the effects of these methodologies on the DNN models discussed earlier, assessing their efficacy with regard to training rate and computational efficacy. The study showcases the efficacy of including GA as a strategic approach, resulting in a noteworthy decrease in the duration required for training. This enables the models to converge at a faster pace. The utilization of AMP enhances the speed of computations by taking advantage of the advantages offered by lower precision arithmetic while maintaining the correctness of the model. Furthermore, this study investigates the application of Pin Memory as a strategy to enhance the efficiency of data transmission between the central processing unit and the graphics processing unit, thereby offering a promising opportunity for enhancing overall performance. The experimental findings demonstrate that the combination of these sophisticated methodologies significantly accelerates the training of DNNs, offering vital insights for experts seeking to improve the effectiveness of deep learning processes.", "url": "https://arxiv.org/abs/2312.10024"}, {"metadata": {"arXiv": "2312.09734", "Date": "Fri, 15 Dec 2023 12:19:48 ", "Title": "Learning of Hamiltonian Dynamics with Reproducing Kernel Hilbert Spaces", "Authors": ["Torbj{\\o}rn Smith", "Olav Egeland"], "Categories": "cs.RO cs.LG cs.SY eess.SY"}, "abstract": "This paper presents a method for learning Hamiltonian dynamics from a limited set of data points. The Hamiltonian vector field is found by regularized optimization over a reproducing kernel Hilbert space of vector fields that are inherently Hamiltonian, and where the vector field is required to be odd or even. This is done with a symplectic kernel, and it is shown how this symplectic kernel can be modified to be odd or even. The performance of the method is validated in simulations for two Hamiltonian systems. It is shown that the learned dynamics are Hamiltonian, and that the learned Hamiltonian vector field can be prescribed to be odd or even.", "url": "https://arxiv.org/abs/2312.09734"}, {"metadata": {"arXiv": "2312.09316", "Date": "Thu, 14 Dec 2023 19:59:21 ", "Title": "Distributional Latent Variable Models with an Application in Active Cognitive Testing", "Authors": ["Robert Kasumba", "Dom CP Marticorena", "Anja Pahor", "Geetha Ramani", "Imani Goffney", "Susanne M Jaeggi", "Aaron Seitz", "Jacob R Gardner", "Dennis L Barbour"], "Categories": "cs.AI cs.HC", "Comments": ["9 pages", "6 figures"]}, "abstract": "Cognitive modeling commonly relies on asking participants to complete a battery of varied tests in order to estimate attention, working memory, and other latent variables. In many cases, these tests result in highly variable observation models. A near-ubiquitous approach is to repeat many observations for each test, resulting in a distribution over the outcomes from each test given to each subject. In this paper, we explore the usage of latent variable modeling to enable learning across many correlated variables simultaneously. We extend latent variable models (LVMs) to the setting where observed data for each subject are a series of observations from many different distributions, rather than simple vectors to be reconstructed. By embedding test battery results for individuals in a latent space that is trained jointly across a population, we are able to leverage correlations both between tests for a single participant and between multiple participants. We then propose an active learning framework that leverages this model to conduct more efficient cognitive test batteries. We validate our approach by demonstrating with real-time data acquisition that it performs comparably to conventional methods in making item-level predictions with fewer test items.", "url": "https://arxiv.org/abs/2312.09316"}, {"metadata": {"arXiv": "2312.09334", "Date": "Thu, 14 Dec 2023 20:48:26 ", "Title": "ArchiGuesser -- AI Art Architecture Educational Game", "Authors": ["Joern Ploennigs and Markus Berger and Eva Carnein"], "Categories": "cs.AI cs.MM", "Comments": ["NeurIPS", "Creative AI track"]}, "abstract": "The use of generative AI in education is a controversial topic. Current technology offers the potential to create educational content from text, speech, to images based on simple input prompts. This can enhance productivity by summarizing knowledge and improving communication, quickly adjusting to different types of learners. Moreover, generative AI holds the promise of making the learning itself more fun, by responding to user inputs and dynamically generating high-quality creative material. In this paper we present the multisensory educational game ArchiGuesser that combines various AI technologies from large language models, image generation, to computer vision to serve a single purpose: Teaching students in a playful way the diversity of our architectural history and how generative AI works.", "url": "https://arxiv.org/abs/2312.09334"}, {"metadata": {"arXiv": "2312.09397", "Date": "Thu, 14 Dec 2023 23:23:37 ", "Title": "Large Language Models for Autonomous Driving: Real-World Experiments", "Authors": ["Can Cui", "Zichong Yang", "Yupeng Zhou", "Yunsheng Ma", "Juanwu Lu and Ziran Wang"], "Categories": "cs.AI"}, "abstract": "Autonomous driving systems are increasingly popular in today's technological landscape, where vehicles with partial automation have already been widely available on the market, and the full automation era with ``driverless'' capabilities is near the horizon. However, accurately understanding humans' commands, particularly for autonomous vehicles that have only passengers instead of drivers, and achieving a high level of personalization remain challenging tasks in the development of autonomous driving systems. In this paper, we introduce a Large Language Model (LLM)-based framework Talk-to-Drive (Talk2Drive) to process verbal commands from humans and make autonomous driving decisions with contextual information, satisfying their personalized preferences for safety, efficiency, and comfort. First, a speech recognition module is developed for Talk2Drive to interpret verbal inputs from humans to textual instructions, which are then sent to LLMs for reasoning. Then, appropriate commands for the Electrical Control Unit (ECU) are generated, achieving a 100\\% success rate in executing codes. Real-world experiments show that our framework can substantially reduce the takeover rate for a diverse range of drivers by up to 90.1\\%. To the best of our knowledge, Talk2Drive marks the first instance of employing an LLM-based system in a real-world autonomous driving environment.", "url": "https://arxiv.org/abs/2312.09397"}, {"metadata": {"arXiv": "2312.09513", "Date": "Fri, 15 Dec 2023 03:31:21 ", "Title": "CGS-Mask: Making Time Series Predictions Intuitive for Al", "Authors": ["Feng Lu", "Wei Li", "Yifei Sun", "Cheng Song", "Yufei Ren", "Albert Y. Zomaya"], "Categories": "cs.AI"}, "abstract": "Artificial intelligence (AI) has immense potential in time series prediction, but most explainable tools have limited capabilities in providing a systematic understanding of important features over time. These tools typically rely on evaluating a single time point, overlook the time ordering of inputs, and neglect the time-sensitive nature of time series applications. These factors make it difficult for users, particularly those without domain knowledge, to comprehend AI model decisions and obtain meaningful explanations. We propose CGS-Mask, a post-hoc and model-agnostic cellular genetic strip mask-based saliency approach to address these challenges. CGS-Mask uses consecutive time steps as a cohesive entity to evaluate the impact of features on the final prediction, providing binary and sustained feature importance scores over time. Our algorithm optimizes the mask population iteratively to obtain the optimal mask in a reasonable time. We evaluated CGS-Mask on synthetic and real-world datasets, and it outperformed state-of-the-art methods in elucidating the importance of features over time. According to our pilot user study via a questionnaire survey, CGS-Mask is the most effective approach in presenting easily understandable time series prediction results, enabling users to comprehend the decision-making process of AI models with ease.", "url": "https://arxiv.org/abs/2312.09513"}, {"metadata": {"arXiv": "2312.09532", "Date": "Fri, 15 Dec 2023 04:45:48 ", "Title": "Grounding for Artificial Intelligence", "Authors": ["Bing Liu"], "Categories": "cs.AI"}, "abstract": "A core function of intelligence is grounding, which is the process of connecting the natural language and abstract knowledge to the internal representation of the real world in an intelligent being, e.g., a human. Human cognition is grounded in our sensorimotor experiences in the external world and subjective feelings in our internal world. We use languages to communicate with each other and the languages are grounded on our shared sensorimotor experiences and feelings. Without this shard grounding, it is impossible for us to understand each other because all natural languages are highly abstract and are only able to describe a tiny portion of what has happened or is happening in the real world. Although grounding at high or abstract levels has been studied in different fields and applications, to our knowledge, limited systematic work at fine-grained levels has been done. With the rapid progress of large language models (LLMs), it is imperative that we have a sound understanding of grounding in order to move to the next level of intelligence. It is also believed that grounding is necessary for Artificial General Intelligence (AGI). This paper makes an attempt to systematically study this problem.", "url": "https://arxiv.org/abs/2312.09532"}, {"metadata": {"arXiv": "2312.09539", "Date": "Fri, 15 Dec 2023 05:09:32 ", "Title": "Situation-Dependent Causal Influence-Based Cooperative Multi-agent Reinforcement Learning", "Authors": ["Xiao Du", "Yutong Ye", "Pengyu Zhang", "Yaning Yang", "Mingsong Chen", "Ting Wang"], "Categories": "cs.AI"}, "abstract": "Learning to collaborate has witnessed significant progress in multi-agent reinforcement learning (MARL). However, promoting coordination among agents and enhancing exploration capabilities remain challenges. In multi-agent environments, interactions between agents are limited in specific situations. Effective collaboration between agents thus requires a nuanced understanding of when and how agents' actions influence others. To this end, in this paper, we propose a novel MARL algorithm named Situation-Dependent Causal Influence-Based Cooperative Multi-agent Reinforcement Learning (SCIC), which incorporates a novel Intrinsic reward mechanism based on a new cooperation criterion measured by situation-dependent causal influence among agents. Our approach aims to detect inter-agent causal influences in specific situations based on the criterion using causal intervention and conditional mutual information. This effectively assists agents in exploring states that can positively impact other agents, thus promoting cooperation between agents. The resulting update links coordinated exploration and intrinsic reward distribution, which enhance overall collaboration and performance. Experimental results on various MARL benchmarks demonstrate the superiority of our method compared to state-of-the-art approaches.", "url": "https://arxiv.org/abs/2312.09539"}, {"metadata": {"arXiv": "2312.09546", "Date": "Fri, 15 Dec 2023 05:46:49 ", "Title": "On a Functional Definition of Intelligence", "Authors": ["Warisa Sritriratanarak and Paulo Garcia"], "Categories": "cs.AI", "Comments": ["submitted; under review at \"Journal of Intelligent Computing", "SPJ\""]}, "abstract": "Without an agreed-upon definition of intelligence, asking \"is this system intelligent?\"\" is an untestable question. This lack of consensus hinders research, and public perception, on Artificial Intelligence (AI), particularly since the rise of generative- and large-language models. Most work on precisely capturing what we mean by \"intelligence\" has come from the fields of philosophy, psychology, and cognitive science. Because these perspectives are intrinsically linked to intelligence as it is demonstrated by natural creatures, we argue such fields cannot, and will not, provide a sufficiently rigorous definition that can be applied to artificial means. Thus, we present an argument for a purely functional, black-box definition of intelligence, distinct from how that intelligence is actually achieved; focusing on the \"what\", rather than the \"how\". To achieve this, we first distinguish other related concepts (sentience, sensation, agency, etc.) from the notion of intelligence, particularly identifying how these concepts pertain to artificial intelligent systems. As a result, we achieve a formal definition of intelligence that is conceptually testable from only external observation, that suggests intelligence is a continuous variable. We conclude by identifying challenges that still remain towards quantifiable measurement. This work provides a useful perspective for both the development of AI, and for public perception of the capabilities and risks of AI.", "url": "https://arxiv.org/abs/2312.09546"}, {"metadata": {"arXiv": "2312.09561", "Date": "Fri, 15 Dec 2023 06:40:27 ", "Title": "Investigating Responsible AI for Scientific Research: An Empirical Study", "Authors": ["Muneera Bano", "Didar Zowghi", "Pip Shea", "Georgina Ibarra"], "Categories": "cs.AI"}, "abstract": "Scientific research organizations that are developing and deploying Artificial Intelligence (AI) systems are at the intersection of technological progress and ethical considerations. The push for Responsible AI (RAI) in such institutions underscores the increasing emphasis on integrating ethical considerations within AI design and development, championing core values like fairness, accountability, and transparency. For scientific research organizations, prioritizing these practices is paramount not just for mitigating biases and ensuring inclusivity, but also for fostering trust in AI systems among both users and broader stakeholders. In this paper, we explore the practices at a research organization concerning RAI practices, aiming to assess the awareness and preparedness regarding the ethical risks inherent in AI design and development. We have adopted a mixed-method research approach, utilising a comprehensive survey combined with follow-up in-depth interviews with selected participants from AI-related projects. Our results have revealed certain knowledge gaps concerning ethical, responsible, and inclusive AI, with limitations in awareness of the available AI ethics frameworks. This revealed an overarching underestimation of the ethical risks that AI technologies can present, especially when implemented without proper guidelines and governance. Our findings reveal the need for a holistic and multi-tiered strategy to uplift capabilities and better support science research teams for responsible, ethical, and inclusive AI development and deployment.", "url": "https://arxiv.org/abs/2312.09561"}, {"metadata": {"arXiv": "2312.09658", "Date": "Fri, 15 Dec 2023 10:12:43 ", "Title": "Algorithms for automatic intents extraction and utterances classification for goal-oriented dialogue systems", "Authors": ["Leonid Legashev", "Alexander Shukhman", "Arthur Zhigalov"], "Categories": "cs.AI", "Comments": ["in Russian language"]}, "abstract": "Modern machine learning techniques in the natural language processing domain can be used to automatically generate scripts for goal-oriented dialogue systems. The current article presents a general framework for studying the automatic generation of scripts for goal-oriented dialogue systems. A method for preprocessing dialog data sets in JSON format is described. A comparison is made of two methods for extracting user intent based on BERTopic and latent Dirichlet allocation. A comparison has been made of two implemented algorithms for classifying statements of users of a goal-oriented dialogue system based on logistic regression and BERT transformer models. The BERT transformer approach using the bert-base-uncased model showed better results for the three metrics Precision (0.80), F1-score (0.78) and Matthews correlation coefficient (0.74) in comparison with other methods.", "url": "https://arxiv.org/abs/2312.09658"}, {"metadata": {"arXiv": "2312.09693", "Date": "Fri, 15 Dec 2023 11:15:05 ", "Title": "Prompting Large Language Models for Topic Modeling", "Authors": ["Han Wang", "Nirmalendu Prakash", "Nguyen Khoi Hoang", "Ming Shan Hee", "Usman Naseem", "Roy Ka-Wei Lee"], "Categories": "cs.AI", "Comments": ["6 pages", "3 figures", "IEEE International Conference on Big Data"], "ACM-class": "I.2.7"}, "abstract": "Topic modeling is a widely used technique for revealing underlying thematic structures within textual data. However, existing models have certain limitations, particularly when dealing with short text datasets that lack co-occurring words. Moreover, these models often neglect sentence-level semantics, focusing primarily on token-level semantics. In this paper, we propose PromptTopic, a novel topic modeling approach that harnesses the advanced language understanding of large language models (LLMs) to address these challenges. It involves extracting topics at the sentence level from individual documents, then aggregating and condensing these topics into a predefined quantity, ultimately providing coherent topics for texts of varying lengths. This approach eliminates the need for manual parameter tuning and improves the quality of extracted topics. We benchmark PromptTopic against the state-of-the-art baselines on three vastly diverse datasets, establishing its proficiency in discovering meaningful topics. Furthermore, qualitative analysis showcases PromptTopic's ability to uncover relevant topics in multiple datasets.", "url": "https://arxiv.org/abs/2312.09693"}, {"metadata": {"arXiv": "2312.09695", "Date": "Fri, 15 Dec 2023 11:16:47 ", "Title": "Robustness Verification of Deep Reinforcement Learning Based Control Systems using Reward Martingales", "Authors": ["Dapeng Zhi", "Peixin Wang", "Cheng Chen", "Min Zhang"], "Categories": "cs.AI"}, "abstract": "Deep Reinforcement Learning (DRL) has gained prominence as an effective approach for control systems. However, its practical deployment is impeded by state perturbations that can severely impact system performance. Addressing this critical challenge requires robustness verification about system performance, which involves tackling two quantitative questions: (i) how to establish guaranteed bounds for expected cumulative rewards, and (ii) how to determine tail bounds for cumulative rewards. In this work, we present the first approach for robustness verification of DRL-based control systems by introducing reward martingales, which offer a rigorous mathematical foundation to characterize the impact of state perturbations on system performance in terms of cumulative rewards. Our verified results provide provably quantitative certificates for the two questions. We then show that reward martingales can be implemented and trained via neural networks, against different types of control policies. Experimental results demonstrate that our certified bounds tightly enclose simulation outcomes on various DRL-based control systems, indicating the effectiveness and generality of the proposed approach.", "url": "https://arxiv.org/abs/2312.09695"}, {"metadata": {"arXiv": "2312.09699", "Date": "Fri, 15 Dec 2023 11:23:49 ", "Title": "Social, Legal, Ethical, Empathetic, and Cultural Rules: Compilation and Reasoning (Extended Version)", "Authors": ["Nicolas Troquard", "Martina De Sanctis", "Paola Inverardi", "Patrizio Pelliccione", "Gian Luca Scoccia"], "Categories": "cs.AI", "Comments": ["To appear in the proceedings of the 38th Annual AAAI Conference on Artificial Intelligence"]}, "abstract": "The rise of AI-based and autonomous systems is raising concerns and apprehension due to potential negative repercussions stemming from their behavior or decisions. These systems must be designed to comply with the human contexts in which they will operate. To this extent, Townsend et al. (2022) introduce the concept of SLEEC (social, legal, ethical, empathetic, or cultural) rules that aim to facilitate the formulation, verification, and enforcement of the rules AI-based and autonomous systems should obey. They lay out a methodology to elicit them and to let philosophers, lawyers, domain experts, and others to formulate them in natural language. To enable their effective use in AI systems, it is necessary to translate these rules systematically into a formal language that supports automated reasoning. In this study, we first conduct a linguistic analysis of the SLEEC rules pattern, which justifies the translation of SLEEC rules into classical logic. Then we investigate the computational complexity of reasoning about SLEEC rules and show how logical programming frameworks can be employed to implement SLEEC rules in practical scenarios. The result is a readily applicable strategy for implementing AI systems that conform to norms expressed as SLEEC rules.", "url": "https://arxiv.org/abs/2312.09699"}, {"metadata": {"arXiv": "2312.09738", "Date": "Fri, 15 Dec 2023 12:24:19 ", "Title": "3DAxiesPrompts: Unleashing the 3D Spatial Task Capabilities of GPT-4V", "Authors": ["Dingning Liu", "Xiaomeng Dong", "Renrui Zhang", "Xu Luo", "Peng Gao", "Xiaoshui Huang", "Yongshun Gong", "Zhihui Wang"], "Categories": "cs.AI"}, "abstract": "In this work, we present a new visual prompting method called 3DAxiesPrompts (3DAP) to unleash the capabilities of GPT-4V in performing 3D spatial tasks. Our investigation reveals that while GPT-4V exhibits proficiency in discerning the position and interrelations of 2D entities through current visual prompting techniques, its abilities in handling 3D spatial tasks have yet to be explored. In our approach, we create a 3D coordinate system tailored to 3D imagery, complete with annotated scale information. By presenting images infused with the 3DAP visual prompt as inputs, we empower GPT-4V to ascertain the spatial positioning information of the given 3D target image with a high degree of precision. Through experiments, We identified three tasks that could be stably completed using the 3DAP method, namely, 2D to 3D Point Reconstruction, 2D to 3D point matching, and 3D Object Detection. We perform experiments on our proposed dataset 3DAP-Data, the results from these experiments validate the efficacy of 3DAP-enhanced GPT-4V inputs, marking a significant stride in 3D spatial task execution.", "url": "https://arxiv.org/abs/2312.09738"}, {"metadata": {"arXiv": "2312.09897", "Date": "Fri, 15 Dec 2023 15:47:08 ", "Title": "A Novel Dataset for Financial Education Text Simplification in Spanish", "Authors": ["Nelson Perez-Rojas", "Saul Calderon-Ramirez", "Martin Solis-Salazar", "Mario Romero-Sandoval", "Monica Arias-Monge", "Horacio Saggion"], "Categories": "cs.AI"}, "abstract": "Text simplification, crucial in natural language processing, aims to make texts more comprehensible, particularly for specific groups like visually impaired Spanish speakers, a less-represented language in this field. In Spanish, there are few datasets that can be used to create text simplification systems. Our research has the primary objective to develop a Spanish financial text simplification dataset. We created a dataset with 5,314 complex and simplified sentence pairs using established simplification rules. We also compared our dataset with the simplifications generated from GPT-3, Tuner, and MT5, in order to evaluate the feasibility of data augmentation using these systems. In this manuscript we present the characteristics of our dataset and the findings of the comparisons with other systems. The dataset is available at Hugging face, saul1917/FEINA.", "url": "https://arxiv.org/abs/2312.09897"}, {"metadata": {"arXiv": "2312.09928", "Date": "Fri, 15 Dec 2023 16:33:57 ", "Title": "Neurosymbolic Value-Inspired AI (Why, What, and How)", "Authors": ["Amit Sheth and Kaushik Roy"], "Categories": "cs.AI"}, "abstract": "The rapid progression of Artificial Intelligence (AI) systems, facilitated by the advent of Large Language Models (LLMs), has resulted in their widespread application to provide human assistance across diverse industries. This trend has sparked significant discourse centered around the ever-increasing need for LLM-based AI systems to function among humans as part of human society, sharing human values, especially as these systems are deployed in high-stakes settings (e.g., healthcare, autonomous driving, etc.). Towards this end, neurosymbolic AI systems are attractive due to their potential to enable easy-to-understand and interpretable interfaces for facilitating value-based decision-making, by leveraging explicit representations of shared values. In this paper, we introduce substantial extensions to Khaneman's System one/two framework and propose a neurosymbolic computational framework called Value-Inspired AI (VAI). It outlines the crucial components essential for the robust and practical implementation of VAI systems, aiming to represent and integrate various dimensions of human values. Finally, we further offer insights into the current progress made in this direction and outline potential future directions for the field.", "url": "https://arxiv.org/abs/2312.09928"}, {"metadata": {"arXiv": "2312.09958", "Date": "Fri, 15 Dec 2023 17:11:07 ", "Title": "Distilling Large Language Models for Matching Patients to Clinical Trials", "Authors": ["Mauro Nievas", "Aditya Basu", "Yanshan Wang", "Hrituraj Singh"], "Categories": "cs.AI cs.IR"}, "abstract": "The recent success of large language models (LLMs) has paved the way for their adoption in the high-stakes domain of healthcare. Specifically, the application of LLMs in patient-trial matching, which involves assessing patient eligibility against clinical trial's nuanced inclusion and exclusion criteria, has shown promise. Recent research has shown that GPT-3.5, a widely recognized LLM developed by OpenAI, can outperform existing methods with minimal 'variable engineering' by simply comparing clinical trial information against patient summaries. However, there are significant challenges associated with using closed-source proprietary LLMs like GPT-3.5 in practical healthcare applications, such as cost, privacy and reproducibility concerns. To address these issues, this study presents the first systematic examination of the efficacy of both proprietary (GPT-3.5, and GPT-4) and open-source LLMs (LLAMA 7B,13B, and 70B) for the task of patient-trial matching. Employing a multifaceted evaluation framework, we conducted extensive automated and human-centric assessments coupled with a detailed error analysis for each model. To enhance the adaptability of open-source LLMs, we have created a specialized synthetic dataset utilizing GPT-4, enabling effective fine-tuning under constrained data conditions. Our findings reveal that open-source LLMs, when fine-tuned on this limited and synthetic dataset, demonstrate performance parity with their proprietary counterparts. This presents a massive opportunity for their deployment in real-world healthcare applications. To foster further research and applications in this field, we release both the annotated evaluation dataset along with the fine-tuned LLM -- Trial-LLAMA -- for public use.", "url": "https://arxiv.org/abs/2312.09958"}, {"metadata": {"arXiv": "2312.09963", "Date": "Fri, 15 Dec 2023 17:20:25 ", "Title": "Symbolic Numeric Planning with Patterns", "Authors": ["Matteo Cardellini", "Enrico Giunchiglia", "and Marco Maratea"], "Categories": "cs.AI", "Comments": ["Accepted at AAAI24"]}, "abstract": "In this paper, we propose a novel approach for solving linear numeric planning problems, called Symbolic Pattern Planning. Given a planning problem $\\Pi$, a bound $n$ and a pattern -- defined as an arbitrary sequence of actions -- we encode the problem of finding a plan for $\\Pi$ with bound $n$ as a formula with fewer variables and/or clauses than the state-of-the-art rolled-up and relaxed-relaxed-$\\exists$ encodings. More importantly, we prove that for any given bound, it is never the case that the latter two encodings allow finding a valid plan while ours does not. On the experimental side, we consider 6 other planning systems -- including the ones which participated in this year's International Planning Competition (IPC) -- and we show that our planner Patty has remarkably good comparative performances on this year's IPC problems.", "url": "https://arxiv.org/abs/2312.09963"}, {"metadata": {"arXiv": "2312.09995", "Date": "Fri, 15 Dec 2023 18:12:44 ", "Title": "SAT-Based Algorithms for Regular Graph Pattern Matching", "Authors": ["Miguel Terra-Neves and Jos\\'e Amaral and Alexandre Lemos and Rui Quintino and Pedro Resende and Antonio Alegria"], "Categories": "cs.AI", "Comments": ["Shorter version accepted for publication at AAAI 2024"]}, "abstract": "Graph matching is a fundamental problem in pattern recognition, with many applications such as software analysis and computational biology. One well-known type of graph matching problem is graph isomorphism, which consists of deciding if two graphs are identical. Despite its usefulness, the properties that one may check using graph isomorphism are rather limited, since it only allows strict equality checks between two graphs. For example, it does not allow one to check complex structural properties such as if the target graph is an arbitrary length sequence followed by an arbitrary size loop. We propose a generalization of graph isomorphism that allows one to check such properties through a declarative specification. This specification is given in the form of a Regular Graph Pattern (ReGaP), a special type of graph, inspired by regular expressions, that may contain wildcard nodes that represent arbitrary structures such as variable-sized sequences or subgraphs. We propose a SAT-based algorithm for checking if a target graph matches a given ReGaP. We also propose a preprocessing technique for improving the performance of the algorithm and evaluate it through an extensive experimental evaluation on benchmarks from the CodeSearchNet dataset.", "url": "https://arxiv.org/abs/2312.09995"}, {"metadata": {"arXiv": "2312.09313", "Date": "Thu, 14 Dec 2023 19:38:06 ", "Title": "LatentEditor: Text Driven Local Editing of 3D Scenes", "Authors": ["Umar Khalid", "Hasan Iqbal", "Nazmul Karim", "Jing Hua", "Chen Chen"], "Categories": "cs.CV cs.AI", "Comments": ["Project Page: https://latenteditor.github.io/"]}, "abstract": "While neural fields have made significant strides in view synthesis and scene reconstruction, editing them poses a formidable challenge due to their implicit encoding of geometry and texture information from multi-view inputs. In this paper, we introduce \\textsc{LatentEditor}, an innovative framework designed to empower users with the ability to perform precise and locally controlled editing of neural fields using text prompts. Leveraging denoising diffusion models, we successfully embed real-world scenes into the latent space, resulting in a faster and more adaptable NeRF backbone for editing compared to traditional methods. To enhance editing precision, we introduce a delta score to calculate the 2D mask in the latent space that serves as a guide for local modifications while preserving irrelevant regions. Our novel pixel-level scoring approach harnesses the power of InstructPix2Pix (IP2P) to discern the disparity between IP2P conditional and unconditional noise predictions in the latent space. The edited latents conditioned on the 2D masks are then iteratively updated in the training set to achieve 3D local editing. Our approach achieves faster editing speeds and superior output quality compared to existing 3D editing models, bridging the gap between textual instructions and high-quality 3D scene editing in latent space. We show the superiority of our approach on four benchmark 3D datasets, LLFF, IN2N, NeRFStudio and NeRF-Art.", "url": "https://arxiv.org/abs/2312.09313"}, {"metadata": {"arXiv": "2312.09337", "Date": "Thu, 14 Dec 2023 21:00:56 ", "Title": "Promptable Behaviors: Personalizing Multi-Objective Rewards from Human Preferences", "Authors": ["Minyoung Hwang", "Luca Weihs", "Chanwoo Park", "Kimin Lee", "Aniruddha Kembhavi", "Kiana Ehsani"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "Customizing robotic behaviors to be aligned with diverse human preferences is an underexplored challenge in the field of embodied AI. In this paper, we present Promptable Behaviors, a novel framework that facilitates efficient personalization of robotic agents to diverse human preferences in complex environments. We use multi-objective reinforcement learning to train a single policy adaptable to a broad spectrum of preferences. We introduce three distinct methods to infer human preferences by leveraging different types of interactions: (1) human demonstrations, (2) preference feedback on trajectory comparisons, and (3) language instructions. We evaluate the proposed method in personalized object-goal navigation and flee navigation tasks in ProcTHOR and RoboTHOR, demonstrating the ability to prompt agent behaviors to satisfy human preferences in various scenarios. Project page: https://promptable-behaviors.github.io", "url": "https://arxiv.org/abs/2312.09337"}, {"metadata": {"arXiv": "2312.09387", "Date": "Thu, 14 Dec 2023 23:00:11 ", "Title": "High-Resolution Maps of Left Atrial Displacements and Strains Estimated with 3D CINE MRI and Unsupervised Neural Networks", "Authors": ["Christoforos Galazis", "Samuel Shepperd", "Emma Brouwer", "Sandro Queir\\'os", "Ebraham Alskaf", "Mustafa Anjari", "Amedeo Chiribiri", "Jack Lee", "Anil A. Bharath", "Marta Varela"], "Categories": "cs.CV cs.AI"}, "abstract": "The functional analysis of the left atrium (LA) is important for evaluating cardiac health and understanding diseases like atrial fibrillation. Cine MRI is ideally placed for the detailed 3D characterisation of LA motion and deformation, but it is lacking appropriate acquisition and analysis tools. In this paper, we present Analysis for Left Atrial Displacements and Deformations using unsupervIsed neural Networks, \\textit{Aladdin}, to automatically and reliably characterise regional LA deformations from high-resolution 3D Cine MRI. The tool includes: an online few-shot segmentation network (Aladdin-S), an online unsupervised image registration network (Aladdin-R), and a strain calculations pipeline tailored to the LA. We create maps of LA Displacement Vector Field (DVF) magnitude and LA principal strain values from images of 10 healthy volunteers and 8 patients with cardiovascular disease (CVD). We additionally create an atlas of these biomarkers using the data from the healthy volunteers. Aladdin is able to accurately track the LA wall across the cardiac cycle and characterize its motion and deformation. The overall DVF magnitude and principal strain values are significantly higher in the healthy group vs CVD patients: $2.85 \\pm 1.59~mm$ and $0.09 \\pm 0.05$ vs $1.96 \\pm 0.74~mm$ and $0.03 \\pm 0.04$, respectively. The time course of these metrics is also different in the two groups, with a more marked active contraction phase observed in the healthy cohort. Finally, utilizing the LA atlas allows us to identify regional deviations from the population distribution that may indicate focal tissue abnormalities. The proposed tool for the quantification of novel regional LA deformation biomarkers should have important clinical applications. The source code, anonymized images, generated maps and atlas are publicly available: https://github.com/cgalaz01/aladdin_cmr_la.", "url": "https://arxiv.org/abs/2312.09387"}, {"metadata": {"arXiv": "2312.09501", "Date": "Fri, 15 Dec 2023 02:55:24 ", "Title": "EDA: Evolving and Distinct Anchors for Multimodal Motion Prediction", "Authors": ["Longzhong Lin", "Xuewu Lin", "Tianwei Lin", "Lichao Huang", "Rong Xiong", "Yue Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI2024)"]}, "abstract": "Motion prediction is a crucial task in autonomous driving, and one of its major challenges lands in the multimodality of future behaviors. Many successful works have utilized mixture models which require identification of positive mixture components, and correspondingly fall into two main lines: prediction-based and anchor-based matching. The prediction clustering phenomenon in prediction-based matching makes it difficult to pick representative trajectories for downstream tasks, while the anchor-based matching suffers from a limited regression capability. In this paper, we introduce a novel paradigm, named Evolving and Distinct Anchors (EDA), to define the positive and negative components for multimodal motion prediction based on mixture models. We enable anchors to evolve and redistribute themselves under specific scenes for an enlarged regression capacity. Furthermore, we select distinct anchors before matching them with the ground truth, which results in impressive scoring performance. Our approach enhances all metrics compared to the baseline MTR, particularly with a notable relative reduction of 13.5% in Miss Rate, resulting in state-of-the-art performance on the Waymo Open Motion Dataset. Code is available at https://github.com/Longzhong-Lin/EDA.", "url": "https://arxiv.org/abs/2312.09501"}, {"metadata": {"arXiv": "2312.09507", "Date": "Fri, 15 Dec 2023 03:17:37 ", "Title": "WAVER: Writing-style Agnostic Video Retrieval via Distilling Vision-Language Models Through Open-Vocabulary Knowledge", "Authors": ["Huy Le", "Tung Kieu", "Anh Nguyen", "Ngan Le"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to ICASSP 2024"]}, "abstract": "Text-video retrieval, a prominent sub-field within the broader domain of multimedia content management, has witnessed remarkable growth and innovation over the past decade. However, existing methods assume the video scenes are consistent and the description annotators are unbiased. These limitations fail to align with fluid real-world scenarios, and descriptions can be influenced by annotator biases, diverse writing styles, and varying textual perspectives. To overcome the aforementioned problems, we introduce WAVER, a cross-domain knowledge distillation mechanism designed to tackle the challenge of handling writing-style agnostics. WAVER capitalizes on the open-vocabulary properties inherent in pre-trained vision-language models and employs an implicit knowledge distillation approach to transfer text-based knowledge from a teacher model to a vision-based student. Empirical studies conducted across four standard benchmark datasets, encompassing various settings, provide compelling evidence that \\WAVER can achieve state-of-the-art performance in text-video retrieval tasks while handling writing-style variations.", "url": "https://arxiv.org/abs/2312.09507"}, {"metadata": {"arXiv": "2312.09510", "Date": "Fri, 15 Dec 2023 03:28:17 ", "Title": "Fast Sampling generative model for Ultrasound image reconstruction", "Authors": ["Hengrong Lan", "Zhiqiang Li", "Qiong He", "Jianwen Luo"], "Categories": "cs.CV cs.AI", "Comments": ["submitted to ISBI 2024"]}, "abstract": "Image reconstruction from radio-frequency data is pivotal in ultrafast plane wave ultrasound imaging. Unlike the conventional delay-and-sum (DAS) technique, which relies on somewhat imprecise assumptions, deep learning-based methods perform image reconstruction by training on paired data, leading to a notable enhancement in image quality. Nevertheless, these strategies often exhibit limited generalization capabilities. Recently, denoising diffusion models have become the preferred paradigm for image reconstruction tasks. However, their reliance on an iterative sampling procedure results in prolonged generation time. In this paper, we propose a novel sampling framework that concurrently enforces data consistency of ultrasound signals and data-driven priors. By leveraging the advanced diffusion model, the generation of high-quality images is substantially expedited. Experimental evaluations on an in-vivo dataset indicate that our approach with a single plane wave surpasses DAS with spatial coherent compounding of 75 plane waves.", "url": "https://arxiv.org/abs/2312.09510"}, {"metadata": {"arXiv": "2312.09579", "Date": "Fri, 15 Dec 2023 07:21:12 ", "Title": "MobileSAMv2: Faster Segment Anything to Everything", "Authors": ["Chaoning Zhang", "Dongshen Han", "Sheng Zheng", "Jinwoo Choi", "Tae-Ho Kim", "Choong Seon Hong"], "Categories": "cs.CV cs.AI", "Comments": ["MobileSAM achieves faster segment anything", "while MobileSAMv2 achieves faster segment everything"]}, "abstract": "Segment anything model (SAM) addresses two practical yet challenging segmentation tasks: \\textbf{segment anything (SegAny)}, which utilizes a certain point to predict the mask for a single object of interest, and \\textbf{segment everything (SegEvery)}, which predicts the masks for all objects on the image. What makes SegAny slow for SAM is its heavyweight image encoder, which has been addressed by MobileSAM via decoupled knowledge distillation. The efficiency bottleneck of SegEvery with SAM, however, lies in its mask decoder because it needs to first generate numerous masks with redundant grid-search prompts and then perform filtering to obtain the final valid masks. We propose to improve its efficiency by directly generating the final masks with only valid prompts, which can be obtained through object discovery. Our proposed approach not only helps reduce the total time on the mask decoder by at least 16 times but also achieves superior performance. Specifically, our approach yields an average performance boost of 3.6\\% (42.5\\% \\textit{v.s.} 38.9\\%) for zero-shot object proposal on the LVIS dataset with the mask AR@$K$ metric. Qualitative results show that our approach generates fine-grained masks while avoiding over-segmenting things. This project targeting faster SegEvery than the original SAM is termed MobileSAMv2 to differentiate from MobileSAM which targets faster SegAny. Moreover, we demonstrate that our new prompt sampling is also compatible with the distilled image encoders in MobileSAM, contributing to a unified framework for efficient SegAny and SegEvery. The code is available at the same link as MobileSAM Project \\href{https://github.com/ChaoningZhang/MobileSAM}{\\textcolor{red}{https://github.com/ChaoningZhang/MobileSAM}}. \\end{abstract}", "url": "https://arxiv.org/abs/2312.09579"}, {"metadata": {"arXiv": "2312.09584", "Date": "Fri, 15 Dec 2023 07:46:44 ", "Title": "Multiscale Vision Transformer With Deep Clustering-Guided Refinement for Weakly Supervised Object Localization", "Authors": ["David Kim", "Sinhae Cha", "Byeongkeun Kang"], "Categories": "cs.CV cs.AI", "Comments": ["5 pages"], "Journal-ref": "IEEE International Conference on Visual Communications and Image Processing, 2023"}, "abstract": "This work addresses the task of weakly-supervised object localization. The goal is to learn object localization using only image-level class labels, which are much easier to obtain compared to bounding box annotations. This task is important because it reduces the need for labor-intensive ground-truth annotations. However, methods for object localization trained using weak supervision often suffer from limited accuracy in localization. To address this challenge and enhance localization accuracy, we propose a multiscale object localization transformer (MOLT). It comprises multiple object localization transformers that extract patch embeddings across various scales. Moreover, we introduce a deep clustering-guided refinement method that further enhances localization accuracy by utilizing separately extracted image segments. These segments are obtained by clustering pixels using convolutional neural networks. Finally, we demonstrate the effectiveness of our proposed method by conducting experiments on the publicly available ILSVRC-2012 dataset.", "url": "https://arxiv.org/abs/2312.09584"}, {"metadata": {"arXiv": "2312.09630", "Date": "Fri, 15 Dec 2023 09:19:00 ", "Title": "Pixel-Superpixel Contrastive Learning and Pseudo-Label Correction for Hyperspectral Image Clustering", "Authors": ["Renxiang Guan and Zihao Li and Xianju Li and Chang Tang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted at IEEE ICASSP 2024"]}, "abstract": "Hyperspectral image (HSI) clustering is gaining considerable attention owing to recent methods that overcome the inefficiency and misleading results from the absence of supervised information. Contrastive learning methods excel at existing pixel level and super pixel level HSI clustering tasks. The pixel-level contrastive learning method can effectively improve the ability of the model to capture fine features of HSI but requires a large time overhead. The super pixel-level contrastive learning method utilizes the homogeneity of HSI and reduces computing resources; however, it yields rough classification results. To exploit the strengths of both methods, we present a pixel super pixel contrastive learning and pseudo-label correction (PSCPC) method for the HSI clustering. PSCPC can reasonably capture domain-specific and fine-grained features through super pixels and the comparative learning of a small number of pixels within the super pixels. To improve the clustering performance of super pixels, this paper proposes a pseudo-label correction module that aligns the clustering pseudo-labels of pixels and super-pixels. In addition, pixel-level clustering results are used to supervise super pixel-level clustering, improving the generalization ability of the model. Extensive experiments demonstrate the effectiveness and efficiency of PSCPC.", "url": "https://arxiv.org/abs/2312.09630"}, {"metadata": {"arXiv": "2312.09676", "Date": "Fri, 15 Dec 2023 10:40:34 ", "Title": "nuScenes Knowledge Graph -- A comprehensive semantic representation of traffic scenes for trajectory prediction", "Authors": ["Leon Mlodzian", "Zhigang Sun", "Hendrik Berkemeyer", "Sebastian Monka", "Zixu Wang", "Stefan Dietze", "Lavdim Halilaj", "Juergen Luettin"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["Accepted to the 2023 IEEE/CVF International Converence on Computer Vision (ICCV) workshop on Scene Graphs and Graph Representation Learning (SG2RL)"], "ACM-class": "I.2.4; I.2.6; I.2.10"}, "abstract": "Trajectory prediction in traffic scenes involves accurately forecasting the behaviour of surrounding vehicles. To achieve this objective it is crucial to consider contextual information, including the driving path of vehicles, road topology, lane dividers, and traffic rules. Although studies demonstrated the potential of leveraging heterogeneous context for improving trajectory prediction, state-of-the-art deep learning approaches still rely on a limited subset of this information. This is mainly due to the limited availability of comprehensive representations. This paper presents an approach that utilizes knowledge graphs to model the diverse entities and their semantic connections within traffic scenes. Further, we present nuScenes Knowledge Graph (nSKG), a knowledge graph for the nuScenes dataset, that models explicitly all scene participants and road elements, as well as their semantic and spatial relationships. To facilitate the usage of the nSKG via graph neural networks for trajectory prediction, we provide the data in a format, ready-to-use by the PyG library. All artefacts can be found here: https://github.com/boschresearch/nuScenes_Knowledge_Graph", "url": "https://arxiv.org/abs/2312.09676"}, {"metadata": {"arXiv": "2312.09723", "Date": "Fri, 15 Dec 2023 11:53:17 ", "Title": "Tracking Skiers from the Top to the Bottom", "Authors": ["Matteo Dunnhofer", "Luca Sordi", "Niki Martinel", "Christian Micheloni"], "Categories": "cs.CV cs.AI", "Comments": ["IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024"]}, "abstract": "Skiing is a popular winter sport discipline with a long history of competitive events. In this domain, computer vision has the potential to enhance the understanding of athletes' performance, but its application lags behind other sports due to limited studies and datasets. This paper makes a step forward in filling such gaps. A thorough investigation is performed on the task of skier tracking in a video capturing his/her complete performance. Obtaining continuous and accurate skier localization is preemptive for further higher-level performance analyses. To enable the study, the largest and most annotated dataset for computer vision in skiing, SkiTB, is introduced. Several visual object tracking algorithms, including both established methodologies and a newly introduced skier-optimized baseline algorithm, are tested using the dataset. The results provide valuable insights into the applicability of different tracking methods for vision-based skiing analysis. SkiTB, code, and results are available at https://machinelearning.uniud.it/datasets/skitb.", "url": "https://arxiv.org/abs/2312.09723"}, {"metadata": {"arXiv": "2312.09812", "Date": "Fri, 15 Dec 2023 14:10:21 ", "Title": "Structural Information Guided Multimodal Pre-training for Vehicle-centric Perception", "Authors": ["Xiao Wang", "Wentao Wu", "Chenglong Li", "Zhicheng Zhao", "Zhe Chen", "Yukai Shi", "Jin Tang"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by AAAI-2024"]}, "abstract": "Understanding vehicles in images is important for various applications such as intelligent transportation and self-driving system. Existing vehicle-centric works typically pre-train models on large-scale classification datasets and then fine-tune them for specific downstream tasks. However, they neglect the specific characteristics of vehicle perception in different tasks and might thus lead to sub-optimal performance. To address this issue, we propose a novel vehicle-centric pre-training framework called VehicleMAE, which incorporates the structural information including the spatial structure from vehicle profile information and the semantic structure from informative high-level natural language descriptions for effective masked vehicle appearance reconstruction. To be specific, we explicitly extract the sketch lines of vehicles as a form of the spatial structure to guide vehicle reconstruction. The more comprehensive knowledge distilled from the CLIP big model based on the similarity between the paired/unpaired vehicle image-text sample is further taken into consideration to help achieve a better understanding of vehicles. A large-scale dataset is built to pre-train our model, termed Autobot1M, which contains about 1M vehicle images and 12693 text information. Extensive experiments on four vehicle-based downstream tasks fully validated the effectiveness of our VehicleMAE. The source code and pre-trained models will be released at https://github.com/Event-AHU/VehicleMAE.", "url": "https://arxiv.org/abs/2312.09812"}, {"metadata": {"arXiv": "2312.09894", "Date": "Fri, 15 Dec 2023 15:45:52 ", "Title": "PathoDuet: Foundation Models for Pathological Slide Analysis of H&E and IHC Stains", "Authors": ["Shengyi Hua", "Fang Yan", "Tianle Shen", "Xiaofan Zhang"], "Categories": "cs.CV cs.AI"}, "abstract": "Large amounts of digitized histopathological data display a promising future for developing pathological foundation models via self-supervised learning methods. Foundation models pretrained with these methods serve as a good basis for downstream tasks. However, the gap between natural and histopathological images hinders the direct application of existing methods. In this work, we present PathoDuet, a series of pretrained models on histopathological images, and a new self-supervised learning framework in histopathology. The framework is featured by a newly-introduced pretext token and later task raisers to explicitly utilize certain relations between images, like multiple magnifications and multiple stains. Based on this, two pretext tasks, cross-scale positioning and cross-stain transferring, are designed to pretrain the model on Hematoxylin and Eosin (H\\&E) images and transfer the model to immunohistochemistry (IHC) images, respectively. To validate the efficacy of our models, we evaluate the performance over a wide variety of downstream tasks, including patch-level colorectal cancer subtyping and whole slide image (WSI)-level classification in H\\&E field, together with expression level prediction of IHC marker and tumor identification in IHC field. The experimental results show the superiority of our models over most tasks and the efficacy of proposed pretext tasks. The codes and models are available at https://github.com/openmedlab/PathoDuet.", "url": "https://arxiv.org/abs/2312.09894"}, {"metadata": {"arXiv": "2312.09922", "Date": "Fri, 15 Dec 2023 16:30:59 ", "Title": "A Unifying Tensor View for Lightweight CNNs", "Authors": ["Jason Chun Lok Li", "Rui Lin", "Jiajun Zhou", "Edmund Yin Mun Lam", "and Ngai Wong"], "Categories": "cs.CV cs.AI", "Comments": ["4 pages", "3 figures", "accepted in 2023 IEEE 15th International Conference on ASIC (ASICON 2023)"]}, "abstract": "Despite the decomposition of convolutional kernels for lightweight CNNs being well studied, existing works that rely on tensor network diagrams or hyperdimensional abstraction lack geometry intuition. This work devises a new perspective by linking a 3D-reshaped kernel tensor to its various slice-wise and rank-1 decompositions, permitting a straightforward connection between various tensor approximations and efficient CNN modules. Specifically, it is discovered that a pointwise-depthwise-pointwise (PDP) configuration constitutes a viable construct for lightweight CNNs. Moreover, a novel link to the latest ShiftNet is established, inspiring a first-ever shift layer pruning that achieves nearly 50% compression with < 1% drop in accuracy for ShiftResNet.", "url": "https://arxiv.org/abs/2312.09922"}, {"metadata": {"arXiv": "2312.09434", "Date": "Mon, 27 Nov 2023 20:41:21 ", "Title": "Task Tree Retrieval For Robotic Cooking", "Authors": ["Chakradhar Reddy Nallu"], "Categories": "cs.RO cs.AI"}, "abstract": "This paper is based on developing different algorithms, which generate the task tree planning for the given goal node(recipe). The knowledge representation of the dishes is called FOON. It contains the different objects and their between them with respective to the motion node The graphical representation of FOON is made by noticing the change in the state of an object with respect to the human manipulators. We will explore how the FOON is created for different recipes by the robots. Task planning contains difficulties in exploring unknown problems, as its knowledge is limited to the FOON. To get the task tree planning for a given recipe, the robot will retrieve the information of different functional units from the knowledge retrieval process called FOON. Thus the generated subgraphs will allow the robot to cook the required dish. Thus the robot can able to cook the given recipe by following the sequence of instructions.", "url": "https://arxiv.org/abs/2312.09434"}, {"metadata": {"arXiv": "2312.09588", "Date": "Fri, 15 Dec 2023 07:51:20 ", "Title": "NeuroFlow: Development of lightweight and efficient model integration scheduling strategy for autonomous driving system", "Authors": ["Eunbin Seo", "Gwanjun Shin", "Eunho Lee"], "Categories": "cs.RO cs.AI", "Comments": ["9 pages"]}, "abstract": "This paper proposes a specialized autonomous driving system that takes into account the unique constraints and characteristics of automotive systems, aiming for innovative advancements in autonomous driving technology. The proposed system systematically analyzes the intricate data flow in autonomous driving and provides functionality to dynamically adjust various factors that influence deep learning models. Additionally, for algorithms that do not rely on deep learning models, the system analyzes the flow to determine resource allocation priorities. In essence, the system optimizes data flow and schedules efficiently to ensure real-time performance and safety. The proposed system was implemented in actual autonomous vehicles and experimentally validated across various driving scenarios. The experimental results provide evidence of the system's stable inference and effective control of autonomous vehicles, marking a significant turning point in the development of autonomous driving systems.", "url": "https://arxiv.org/abs/2312.09588"}, {"metadata": {"arXiv": "2312.09906", "Date": "Fri, 15 Dec 2023 16:08:49 ", "Title": "Sample-Efficient Learning to Solve a Real-World Labyrinth Game Using Data-Augmented Model-Based Reinforcement Learning", "Authors": ["Thomas Bi", "Raffaello D'Andrea"], "Categories": "cs.RO cs.AI"}, "abstract": "Motivated by the challenge of achieving rapid learning in physical environments, this paper presents the development and training of a robotic system designed to navigate and solve a labyrinth game using model-based reinforcement learning techniques. The method involves extracting low-dimensional observations from camera images, along with a cropped and rectified image patch centered on the current position within the labyrinth, providing valuable information about the labyrinth layout. The learning of a control policy is performed purely on the physical system using model-based reinforcement learning, where the progress along the labyrinth's path serves as a reward signal. Additionally, we exploit the system's inherent symmetries to augment the training data. Consequently, our approach learns to successfully solve a popular real-world labyrinth game in record time, with only 5 hours of real-world training data.", "url": "https://arxiv.org/abs/2312.09906"}, {"metadata": {"arXiv": "2312.09773", "Date": "Fri, 15 Dec 2023 13:27:31 ", "Title": "In vivo learning-based control of microbial populations density in bioreactors", "Authors": ["Sara Maria Brancato", "Davide Salzano", "Francesco De Lellis", "Davide Fiore", "Giovanni Russo", "Mario di Bernardo"], "Categories": "eess.SY cs.AI cs.SY q-bio.QM", "Comments": ["13 pages", "4 figures"]}, "abstract": "A key problem toward the use of microorganisms as bio-factories is reaching and maintaining cellular communities at a desired density and composition so that they can efficiently convert their biomass into useful compounds. Promising technological platforms for the real time, scalable control of cellular density are bioreactors. In this work, we developed a learning-based strategy to expand the toolbox of available control algorithms capable of regulating the density of a \\textit{single} bacterial population in bioreactors. Specifically, we used a sim-to-real paradigm, where a simple mathematical model, calibrated using a few data, was adopted to generate synthetic data for the training of the controller. The resulting policy was then exhaustively tested in vivo using a low-cost bioreactor known as Chi.Bio, assessing performance and robustness. In addition, we compared the performance with more traditional controllers (namely, a PI and an MPC), confirming that the learning-based controller exhibits similar performance in vivo. Our work showcases the viability of learning-based strategies for the control of cellular density in bioreactors, making a step forward toward their use for the control of the composition of microbial consortia.", "url": "https://arxiv.org/abs/2312.09773"}, {"metadata": {"arXiv": "2312.09323", "Date": "Thu, 07 Dec 2023 19:58:37 ", "Title": "Perspectives on the State and Future of Deep Learning -- 2023", "Authors": ["Micah Goldblum", "Anima Anandkumar", "Richard Baraniuk", "Tom Goldstein", "Kyunghyun Cho", "Zachary C Lipton", "Melanie Mitchell", "Preetum Nakkiran", "Max Welling", "Andrew Gordon Wilson"], "Categories": "cs.AI cs.LG"}, "abstract": "The goal of this series is to chronicle opinions and issues in the field of machine learning as they stand today and as they change over time. The plan is to host this survey periodically until the AI singularity paperclip-frenzy-driven doomsday, keeping an updated list of topical questions and interviewing new community members for each edition. In this issue, we probed people's opinions on interpretable AI, the value of benchmarking in modern NLP, the state of progress towards understanding deep learning, and the future of academia.", "url": "https://arxiv.org/abs/2312.09323"}, {"metadata": {"arXiv": "2312.09997", "Date": "Fri, 15 Dec 2023 18:15:20 ", "Title": "One Self-Configurable Model to Solve Many Abstract Visual Reasoning Problems", "Authors": ["Miko{\\l}aj Ma{\\l}ki\\'nski", "Jacek Ma\\'ndziuk"], "Categories": "cs.AI cs.CV cs.LG", "Comments": ["Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)"]}, "abstract": "Abstract Visual Reasoning (AVR) comprises a wide selection of various problems similar to those used in human IQ tests. Recent years have brought dynamic progress in solving particular AVR tasks, however, in the contemporary literature AVR problems are largely dealt with in isolation, leading to highly specialized task-specific methods. With the aim of developing universal learning systems in the AVR domain, we propose the unified model for solving Single-Choice Abstract visual Reasoning tasks (SCAR), capable of solving various single-choice AVR tasks, without making any a priori assumptions about the task structure, in particular the number and location of panels. The proposed model relies on a novel Structure-Aware dynamic Layer (SAL), which adapts its weights to the structure of the considered AVR problem. Experiments conducted on Raven's Progressive Matrices, Visual Analogy Problems, and Odd One Out problems show that SCAR (SAL-based models, in general) effectively solves diverse AVR tasks, and its performance is on par with the state-of-the-art task-specific baselines. What is more, SCAR demonstrates effective knowledge reuse in multi-task and transfer learning settings. To our knowledge, this work is the first successful attempt to construct a general single-choice AVR solver relying on self-configurable architecture and unified solving method. With this work we aim to stimulate and foster progress on task-independent research paths in the AVR domain, with the long-term goal of development of a general AVR solver.", "url": "https://arxiv.org/abs/2312.09997"}, {"metadata": {"arXiv": "2312.09788", "Date": "Fri, 15 Dec 2023 13:43:24 ", "Title": "Collaborating Foundation models for Domain Generalized Semantic Segmentation", "Authors": ["Yasser Benigmim", "Subhankar Roy", "Slim Essid", "Vicky Kalogeiton", "St\\'ephane Lathuili\\`ere"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["https://github.com/yasserben/CLOUDS"]}, "abstract": "Domain Generalized Semantic Segmentation (DGSS) deals with training a model on a labeled source domain with the aim of generalizing to unseen domains during inference. Existing DGSS methods typically effectuate robust features by means of Domain Randomization (DR). Such an approach is often limited as it can only account for style diversification and not content. In this work, we take an orthogonal approach to DGSS and propose to use an assembly of CoLlaborative FOUndation models for Domain Generalized Semantic Segmentation (CLOUDS). In detail, CLOUDS is a framework that integrates FMs of various kinds: (i) CLIP backbone for its robust feature representation, (ii) generative models to diversify the content, thereby covering various modes of the possible target distribution, and (iii) Segment Anything Model (SAM) for iteratively refining the predictions of the segmentation model. Extensive experiments show that our CLOUDS excels in adapting from synthetic to real DGSS benchmarks and under varying weather conditions, notably outperforming prior methods by 5.6% and 6.7% on averaged miou, respectively. The code is available at : https://github.com/yasserben/CLOUDS", "url": "https://arxiv.org/abs/2312.09788"}, {"metadata": {"arXiv": "2312.09792", "Date": "Fri, 15 Dec 2023 13:48:55 ", "Title": "Latent Diffusion Models with Image-Derived Annotations for Enhanced AI-Assisted Cancer Diagnosis in Histopathology", "Authors": ["Pedro Osorio and Guillermo Jimenez-Perez and Javier Montalt-Tordera and Jens Hooge and Guillem Duran-Ballester and Shivam Singh and Moritz Radbruch and Ute Bach and Sabrina Schroeder and Krystyna Siudak and Julia Vienenkoetter and Bettina Lawrenz and Sadegh Mohammadi"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Artificial Intelligence (AI) based image analysis has an immense potential to support diagnostic histopathology, including cancer diagnostics. However, developing supervised AI methods requires large-scale annotated datasets. A potentially powerful solution is to augment training data with synthetic data. Latent diffusion models, which can generate high-quality, diverse synthetic images, are promising. However, the most common implementations rely on detailed textual descriptions, which are not generally available in this domain. This work proposes a method that constructs structured textual prompts from automatically extracted image features. We experiment with the PCam dataset, composed of tissue patches only loosely annotated as healthy or cancerous. We show that including image-derived features in the prompt, as opposed to only healthy and cancerous labels, improves the Fr\\'echet Inception Distance (FID) from 178.8 to 90.2. We also show that pathologists find it challenging to detect synthetic images, with a median sensitivity/specificity of 0.55/0.55. Finally, we show that synthetic data effectively trains AI models.", "url": "https://arxiv.org/abs/2312.09792"}, {"metadata": {"arXiv": "2312.09410", "Date": "Fri, 15 Dec 2023 00:21:00 ", "Title": "Prediction of rare events in the operation of household equipment using co-evolving time series", "Authors": ["Hadia Mecheri", "Islam Benamirouche", "Feriel Fass", "Djemel Ziou", "Nassima Kadri"], "Categories": "cs.LG cs.AI"}, "abstract": "In this study, we propose an approach for predicting rare events by exploiting time series in coevolution. Our approach involves a weighted autologistic regression model, where we leverage the temporal behavior of the data to enhance predictive capabilities. By addressing the issue of imbalanced datasets, we establish constraints leading to weight estimation and to improved performance. Evaluation on synthetic and real-world datasets confirms that our approach outperform state-of-the-art of predicting home equipment failure methods.", "url": "https://arxiv.org/abs/2312.09410"}, {"metadata": {"arXiv": "2312.09411", "Date": "Fri, 15 Dec 2023 00:22:55 ", "Title": "OTOv3: Automatic Architecture-Agnostic Neural Network Training and Compression from Structured Pruning to Erasing Operators", "Authors": ["Tianyi Chen", "Tianyu Ding", "Zhihui Zhu", "Zeyu Chen", "HsiangTao Wu", "Ilya Zharkov", "Luming Liang"], "Categories": "cs.LG cs.AI cs.CL cs.CV", "Comments": ["39 pages. Due to the page dim limitation", "the full appendix is attached here https://tinyurl.com/otov3appendix. Recommend to zoom-in for finer details. arXiv admin note: text overlap with arXiv:2305.18030"]}, "abstract": "Compressing a predefined deep neural network (DNN) into a compact sub-network with competitive performance is crucial in the efficient machine learning realm. This topic spans various techniques, from structured pruning to neural architecture search, encompassing both pruning and erasing operators perspectives. Despite advancements, existing methods suffers from complex, multi-stage processes that demand substantial engineering and domain knowledge, limiting their broader applications. We introduce the third-generation Only-Train-Once (OTOv3), which first automatically trains and compresses a general DNN through pruning and erasing operations, creating a compact and competitive sub-network without the need of fine-tuning. OTOv3 simplifies and automates the training and compression process, minimizes the engineering efforts required from users. It offers key technological advancements: (i) automatic search space construction for general DNNs based on dependency graph analysis; (ii) Dual Half-Space Projected Gradient (DHSPG) and its enhanced version with hierarchical search (H2SPG) to reliably solve (hierarchical) structured sparsity problems and ensure sub-network validity; and (iii) automated sub-network construction using solutions from DHSPG/H2SPG and dependency graphs. Our empirical results demonstrate the efficacy of OTOv3 across various benchmarks in structured pruning and neural architecture search. OTOv3 produces sub-networks that match or exceed the state-of-the-arts. The source code will be available at https://github.com/tianyic/only_train_once.", "url": "https://arxiv.org/abs/2312.09411"}, {"metadata": {"arXiv": "2312.09478", "Date": "Fri, 15 Dec 2023 01:35:00 ", "Title": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection", "Authors": ["Falih Gozi Febrinanto", "Kristen Moore", "Chandra Thapa", "Mujie Liu", "Vidya Saikrishna", "Jiangang Ma", "Feng Xia"], "Categories": "cs.LG cs.AI"}, "abstract": "Many multivariate time series anomaly detection frameworks have been proposed and widely applied. However, most of these frameworks do not consider intrinsic relationships between variables in multivariate time series data, thus ignoring the causal relationship among variables and degrading anomaly detection performance. This work proposes a novel framework called CGAD, an entropy Causal Graph for multivariate time series Anomaly Detection. CGAD utilizes transfer entropy to construct graph structures that unveil the underlying causal relationships among time series data. Weighted graph convolutional networks combined with causal convolutions are employed to model both the causal graph structures and the temporal patterns within multivariate time series data. Furthermore, CGAD applies anomaly scoring, leveraging median absolute deviation-based normalization to improve the robustness of the anomaly identification process. Extensive experiments demonstrate that CGAD outperforms state-of-the-art methods on real-world datasets with a 15% average improvement based on three different multivariate time series anomaly detection metrics.", "url": "https://arxiv.org/abs/2312.09478"}, {"metadata": {"arXiv": "2312.09498", "Date": "Fri, 15 Dec 2023 02:45:33 ", "Title": "Neural Gaussian Similarity Modeling for Differential Graph Structure Learning", "Authors": ["Xiaolong Fan and Maoguo Gong and Yue Wu and Zedong Tang and Jieyi Liu"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by AAAI 2024"]}, "abstract": "Graph Structure Learning (GSL) has demonstrated considerable potential in the analysis of graph-unknown non-Euclidean data across a wide range of domains. However, constructing an end-to-end graph structure learning model poses a challenge due to the impediment of gradient flow caused by the nearest neighbor sampling strategy. In this paper, we construct a differential graph structure learning model by replacing the non-differentiable nearest neighbor sampling with a differentiable sampling using the reparameterization trick. Under this framework, we argue that the act of sampling \\mbox{nearest} neighbors may not invariably be essential, particularly in instances where node features exhibit a significant degree of similarity. To alleviate this issue, the bell-shaped Gaussian Similarity (GauSim) modeling is proposed to sample non-nearest neighbors. To adaptively model the similarity, we further propose Neural Gaussian Similarity (NeuralGauSim) with learnable parameters featuring flexible sampling behaviors. In addition, we develop a scalable method by transferring the large-scale graph to the transition graph to significantly reduce the complexity. Experimental results demonstrate the effectiveness of the proposed methods.", "url": "https://arxiv.org/abs/2312.09498"}, {"metadata": {"arXiv": "2312.09613", "Date": "Fri, 15 Dec 2023 08:54:32 ", "Title": "Rethinking Causal Relationships Learning in Graph Neural Networks", "Authors": ["Hang Gao", "Chengyu Yao", "Jiangmeng Li", "Lingyu Si", "Yifan Jin", "Fengge Wu", "Changwen Zheng", "Huaping Liu"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Graph Neural Networks (GNNs) demonstrate their significance by effectively modeling complex interrelationships within graph-structured data. To enhance the credibility and robustness of GNNs, it becomes exceptionally crucial to bolster their ability to capture causal relationships. However, despite recent advancements that have indeed strengthened GNNs from a causal learning perspective, conducting an in-depth analysis specifically targeting the causal modeling prowess of GNNs remains an unresolved issue. In order to comprehensively analyze various GNN models from a causal learning perspective, we constructed an artificially synthesized dataset with known and controllable causal relationships between data and labels. The rationality of the generated data is further ensured through theoretical foundations. Drawing insights from analyses conducted using our dataset, we introduce a lightweight and highly adaptable GNN module designed to strengthen GNNs' causal learning capabilities across a diverse range of tasks. Through a series of experiments conducted on both synthetic datasets and other real-world datasets, we empirically validate the effectiveness of the proposed module.", "url": "https://arxiv.org/abs/2312.09613"}, {"metadata": {"arXiv": "2312.09639", "Date": "Fri, 15 Dec 2023 09:28:40 ", "Title": "Multiple Instance Learning for Uplift Modeling", "Authors": ["Yao Zhao", "Haipeng Zhang", "Shiwei Lyu", "Ruiying Jiang", "Jinjie Gu", "Guannan Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["short paper of CIKM22(full version)"], "Journal-ref": "Proceedings of the 31st ACM International Conference on Information and Knowledge Management (2022) 4727-4731", "DOI": "10.1145/3511808.3557655"}, "abstract": "Uplift modeling is widely used in performance marketing to estimate effects of promotion campaigns (e.g., increase of customer retention rate). Since it is impossible to observe outcomes of a recipient in treatment (e.g., receiving a certain promotion) and control (e.g., without promotion) groups simultaneously (i.e., counter-factual), uplift models are mainly trained on instances of treatment and control groups separately to form two models respectively, and uplifts are predicted by the difference of predictions from these two models (i.e., two-model method). When responses are noisy and the treatment effect is fractional, induced individual uplift predictions will be inaccurate, resulting in targeting undesirable customers. Though it is impossible to obtain the ideal ground-truth individual uplifts, known as Individual Treatment Effects (ITEs), alternatively, an average uplift of a group of users, called Average Treatment Effect (ATE), can be observed from experimental deliveries. Upon this, similar to Multiple Instance Learning (MIL) in which each training sample is a bag of instances, our framework sums up individual user uplift predictions for each bag of users as its bag-wise ATE prediction, and regularizes it to its ATE label, thus learning more accurate individual uplifts. Additionally, to amplify the fractional treatment effect, bags are composed of instances with adjacent individual uplift predictions, instead of random instances. Experiments conducted on two datasets show the effectiveness and universality of the proposed framework.", "url": "https://arxiv.org/abs/2312.09639"}, {"metadata": {"arXiv": "2312.09691", "Date": "Fri, 15 Dec 2023 11:10:34 ", "Title": "Quilt: Robust Data Segment Selection against Concept Drifts", "Authors": ["Minsu Kim", "Seong-Hyeon Hwang", "Steven Euijong Whang"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to AAAI 2024"]}, "abstract": "Continuous machine learning pipelines are common in industrial settings where models are periodically trained on data streams. Unfortunately, concept drifts may occur in data streams where the joint distribution of the data X and label y, P(X, y), changes over time and possibly degrade model accuracy. Existing concept drift adaptation approaches mostly focus on updating the model to the new data possibly using ensemble techniques of previous models and tend to discard the drifted historical data. However, we contend that explicitly utilizing the drifted data together leads to much better model accuracy and propose Quilt, a data-centric framework for identifying and selecting data segments that maximize model accuracy. To address the potential downside of efficiency, Quilt extends existing data subset selection techniques, which can be used to reduce the training data without compromising model accuracy. These techniques cannot be used as is because they only assume virtual drifts where the posterior probabilities P(y|X) are assumed not to change. In contrast, a key challenge in our setup is to also discard undesirable data segments with concept drifts. Quilt thus discards drifted data segments and selects data segment subsets holistically for accurate and efficient model training. The two operations use gradient-based scores, which have little computation overhead. In our experiments, we show that Quilt outperforms state-of-the-art drift adaptation and data selection baselines on synthetic and real datasets.", "url": "https://arxiv.org/abs/2312.09691"}, {"metadata": {"arXiv": "2312.09708", "Date": "Fri, 15 Dec 2023 11:30:18 ", "Title": "GraphRARE: Reinforcement Learning Enhanced Graph Neural Network with Relative Entropy", "Authors": ["Tianhao Peng", "Wenjun Wu", "Haitao Yuan", "Zhifeng Bao", "Zhao Pengrui", "Xin Yu", "Xuetao Lin", "Yu Liang", "Yanjun Pu"], "Categories": "cs.LG cs.AI", "Comments": ["14 pages", "7 figures"]}, "abstract": "Graph neural networks (GNNs) have shown advantages in graph-based analysis tasks. However, most existing methods have the homogeneity assumption and show poor performance on heterophilic graphs, where the linked nodes have dissimilar features and different class labels, and the semantically related nodes might be multi-hop away. To address this limitation, this paper presents GraphRARE, a general framework built upon node relative entropy and deep reinforcement learning, to strengthen the expressive capability of GNNs. An innovative node relative entropy, which considers node features and structural similarity, is used to measure mutual information between node pairs. In addition, to avoid the sub-optimal solutions caused by mixing useful information and noises of remote nodes, a deep reinforcement learning-based algorithm is developed to optimize the graph topology. This algorithm selects informative nodes and discards noisy nodes based on the defined node relative entropy. Extensive experiments are conducted on seven real-world datasets. The experimental results demonstrate the superiority of GraphRARE in node classification and its capability to optimize the original graph topology.", "url": "https://arxiv.org/abs/2312.09708"}, {"metadata": {"arXiv": "2312.09758", "Date": "Fri, 15 Dec 2023 12:58:05 ", "Title": "Diagnosing and Rectifying Fake OOD Invariance: A Restructured Causal Approach", "Authors": ["Ziliang Chen", "Yongsen Zheng", "Zhao-Rong Lai", "Quanlong Guan", "Liang Lin"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["AAAI-2024"]}, "abstract": "Invariant representation learning (IRL) encourages the prediction from invariant causal features to labels de-confounded from the environments, advancing the technical roadmap of out-of-distribution (OOD) generalization. Despite spotlights around, recent theoretical results verified that some causal features recovered by IRLs merely pretend domain-invariantly in the training environments but fail in unseen domains. The \\emph{fake invariance} severely endangers OOD generalization since the trustful objective can not be diagnosed and existing causal surgeries are invalid to rectify. In this paper, we review a IRL family (InvRat) under the Partially and Fully Informative Invariant Feature Structural Causal Models (PIIF SCM /FIIF SCM) respectively, to certify their weaknesses in representing fake invariant features, then, unify their causal diagrams to propose ReStructured SCM (RS-SCM). RS-SCM can ideally rebuild the spurious and the fake invariant features simultaneously. Given this, we further develop an approach based on conditional mutual information with respect to RS-SCM, then rigorously rectify the spurious and fake invariant effects. It can be easily implemented by a small feature selection subnet introduced in the IRL family, which is alternatively optimized to achieve our goal. Experiments verified the superiority of our approach to fight against the fake invariant issue across a variety of OOD generalization benchmarks.", "url": "https://arxiv.org/abs/2312.09758"}, {"metadata": {"arXiv": "2312.09802", "Date": "Fri, 15 Dec 2023 14:01:56 ", "Title": "Concept Prerequisite Relation Prediction by Using Permutation-Equivariant Directed Graph Neural Networks", "Authors": ["Xiran Qu", "Xuequn Shang and Yupei Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "1figure", "1 Table", "Accepted by AAAI Workshop for AI for Education"], "MSC-class": "68T07", "ACM-class": "I.2.6"}, "abstract": "This paper studies the problem of CPRP, concept prerequisite relation prediction, which is a fundamental task in using AI for education. CPRP is usually formulated into a link-prediction task on a relationship graph of concepts and solved by training the graph neural network (GNN) model. However, current directed GNNs fail to manage graph isomorphism which refers to the invariance of non-isomorphic graphs, reducing the expressivity of resulting representations. We present a permutation-equivariant directed GNN model by introducing the Weisfeiler-Lehman test into directed GNN learning. Our method is then used for CPRP and evaluated on three public datasets. The experimental results show that our model delivers better prediction performance than the state-of-the-art methods.", "url": "https://arxiv.org/abs/2312.09802"}, {"metadata": {"arXiv": "2312.09844", "Date": "Fri, 15 Dec 2023 14:49:41 ", "Title": "Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline Pre-Training with Model Based Augmentation", "Authors": ["Girolamo Macaluso", "Alessandro Sestini", "Andrew D. Bagdanov"], "Categories": "cs.LG cs.AI"}, "abstract": "Offline reinforcement learning leverages pre-collected datasets of transitions to train policies. It can serve as effective initialization for online algorithms, enhancing sample efficiency and speeding up convergence. However, when such datasets are limited in size and quality, offline pre-training can produce sub-optimal policies and lead to degraded online reinforcement learning performance. In this paper we propose a model-based data augmentation strategy to maximize the benefits of offline reinforcement learning pre-training and reduce the scale of data needed to be effective. Our approach leverages a world model of the environment trained on the offline dataset to augment states during offline pre-training. We evaluate our approach on a variety of MuJoCo robotic tasks and our results show it can jump-start online fine-tuning and substantially reduce - in some cases by an order of magnitude - the required number of environment interactions.", "url": "https://arxiv.org/abs/2312.09844"}, {"metadata": {"arXiv": "2312.09857", "Date": "Fri, 15 Dec 2023 15:03:55 ", "Title": "Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark", "Authors": ["Hassan Ismail Fawaz", "Ganesh Del Grosso", "Tanguy Kerdoncuff", "Aurelie Boisbunon", "Illyyne Saffar"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Unsupervised Domain Adaptation (UDA) aims to harness labeled source data to train models for unlabeled target data. Despite extensive research in domains like computer vision and natural language processing, UDA remains underexplored for time series data, which has widespread real-world applications ranging from medicine and manufacturing to earth observation and human activity recognition. Our paper addresses this gap by introducing a comprehensive benchmark for evaluating UDA techniques for time series classification, with a focus on deep learning methods. We provide seven new benchmark datasets covering various domain shifts and temporal dynamics, facilitating fair and standardized UDA method assessments with state of the art neural network backbones (e.g. Inception) for time series data. This benchmark offers insights into the strengths and limitations of the evaluated approaches while preserving the unsupervised nature of domain adaptation, making it directly applicable to practical problems. Our paper serves as a vital resource for researchers and practitioners, advancing domain adaptation solutions for time series data and fostering innovation in this critical field. The implementation code of this benchmark is available at https://github.com/EricssonResearch/UDA-4-TSC.", "url": "https://arxiv.org/abs/2312.09857"}, {"metadata": {"arXiv": "2312.09877", "Date": "Fri, 15 Dec 2023 15:26:13 ", "Title": "Distributed Learning of Mixtures of Experts", "Authors": ["Fa\\\"icel Chamroukhi", "Nhat Thien Pham"], "Categories": "cs.LG cs.AI cs.DC stat.ML"}, "abstract": "In modern machine learning problems we deal with datasets that are either distributed by nature or potentially large for which distributing the computations is usually a standard way to proceed, since centralized algorithms are in general ineffective. We propose a distributed learning approach for mixtures of experts (MoE) models with an aggregation strategy to construct a reduction estimator from local estimators fitted parallelly to distributed subsets of the data. The aggregation is based on an optimal minimization of an expected transportation divergence between the large MoE composed of local estimators and the unknown desired MoE model. We show that the provided reduction estimator is consistent as soon as the local estimators to be aggregated are consistent, and its construction is performed by a proposed majorization-minimization (MM) algorithm that is computationally effective. We study the statistical and numerical properties for the proposed reduction estimator on experiments that demonstrate its performance compared to namely the global estimator constructed in a centralized way from the full dataset. For some situations, the computation time is more than ten times faster, for a comparable performance. Our source codes are publicly available on Github.", "url": "https://arxiv.org/abs/2312.09877"}, {"metadata": {"arXiv": "2312.09881", "Date": "Fri, 15 Dec 2023 15:28:25 ", "Title": "Dynamic Heterogeneous Federated Learning with Multi-Level Prototypes", "Authors": ["Shunxin Guo", "Hongsong Wang", "Xin Geng"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated learning shows promise as a privacy-preserving collaborative learning technique. Existing heterogeneous federated learning mainly focuses on skewing the label distribution across clients. However, most approaches suffer from catastrophic forgetting and concept drift, mainly when the global distribution of all classes is extremely unbalanced and the data distribution of the client dynamically evolves over time. In this paper, we study the new task, i.e., Dynamic Heterogeneous Federated Learning (DHFL), which addresses the practical scenario where heterogeneous data distributions exist among different clients and dynamic tasks within the client. Accordingly, we propose a novel federated learning framework named Federated Multi-Level Prototypes (FedMLP) and design federated multi-level regularizations. To mitigate concept drift, we construct prototypes and semantic prototypes to provide fruitful generalization knowledge and ensure the continuity of prototype spaces. To maintain the model stability and consistency of convergence, three regularizations are introduced as training losses, i.e., prototype-based regularization, semantic prototype-based regularization, and federated inter-task regularization. Extensive experiments show that the proposed method achieves state-of-the-art performance in various settings.", "url": "https://arxiv.org/abs/2312.09881"}, {"metadata": {"arXiv": "2312.09885", "Date": "Fri, 15 Dec 2023 15:32:25 ", "Title": "Simple Weak Coresets for Non-Decomposable Classification Measures", "Authors": ["Jayesh Malaviya", "Anirban Dasgupta and Rachit Chhaya"], "Categories": "cs.LG cs.AI cs.DS", "Comments": ["Accepted at AAAI 2024"]}, "abstract": "While coresets have been growing in terms of their application, barring few exceptions, they have mostly been limited to unsupervised settings. We consider supervised classification problems, and non-decomposable evaluation measures in such settings. We show that stratified uniform sampling based coresets have excellent empirical performance that are backed by theoretical guarantees too. We focus on the F1 score and Matthews Correlation Coefficient, two widely used non-decomposable objective functions that are nontrivial to optimize for and show that uniform coresets attain a lower bound for coreset size, and have good empirical performance, comparable with ``smarter'' coreset construction strategies.", "url": "https://arxiv.org/abs/2312.09885"}, {"metadata": {"arXiv": "2312.09938", "Date": "Fri, 15 Dec 2023 16:49:57 ", "Title": "Assume-Guarantee Reinforcement Learning", "Authors": ["Milad Kazemi", "Mateo Perez", "Fabio Somenzi", "Sadegh Soudjani", "Ashutosh Trivedi", "Alvaro Velasquez"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["This is the extended version of the paper accepted in the SRRAI Special Track at the Conference on Artificial Intelligence (AAAI-24)"]}, "abstract": "We present a modular approach to \\emph{reinforcement learning} (RL) in environments consisting of simpler components evolving in parallel. A monolithic view of such modular environments may be prohibitively large to learn, or may require unrealizable communication between the components in the form of a centralized controller. Our proposed approach is based on the assume-guarantee paradigm where the optimal control for the individual components is synthesized in isolation by making \\emph{assumptions} about the behaviors of neighboring components, and providing \\emph{guarantees} about their own behavior. We express these \\emph{assume-guarantee contracts} as regular languages and provide automatic translations to scalar rewards to be used in RL. By combining local probabilities of satisfaction for each component, we provide a lower bound on the probability of satisfaction of the complete system. By solving a Markov game for each component, RL can produce a controller for each component that maximizes this lower bound. The controller utilizes the information it receives through communication, observations, and any knowledge of a coarse model of other agents. We experimentally demonstrate the efficiency of the proposed approach on a variety of case studies.", "url": "https://arxiv.org/abs/2312.09938"}, {"metadata": {"arXiv": "2312.09950", "Date": "Fri, 15 Dec 2023 17:01:35 ", "Title": "Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations", "Authors": ["Cedric Derstroff", "Mattia Cerrato", "Jannis Brugger", "Jan Peters and Stefan Kramer"], "Categories": "cs.LG cs.AI cs.MA", "Comments": ["9 pages", "7 figures", "AAAI-24"]}, "abstract": "Peer learning is a novel high-level reinforcement learning framework for agents learning in groups. While standard reinforcement learning trains an individual agent in trial-and-error fashion, all on its own, peer learning addresses a related setting in which a group of agents, i.e., peers, learns to master a task simultaneously together from scratch. Peers are allowed to communicate only about their own states and actions recommended by others: \"What would you do in my situation?\". Our motivation is to study the learning behavior of these agents. We formalize the teacher selection process in the action advice setting as a multi-armed bandit problem and therefore highlight the need for exploration. Eventually, we analyze the learning behavior of the peers and observe their ability to rank the agents' performance within the study group and understand which agents give reliable advice. Further, we compare peer learning with single agent learning and a state-of-the-art action advice baseline. We show that peer learning is able to outperform single-agent learning and the baseline in several challenging discrete and continuous OpenAI Gym domains. Doing so, we also show that within such a framework complex policies from action recommendations beyond discrete action spaces can evolve.", "url": "https://arxiv.org/abs/2312.09950"}, {"metadata": {"arXiv": "2312.09971", "Date": "Fri, 15 Dec 2023 17:34:11 ", "Title": "GreenLightningAI: An Efficient AI System with Decoupled Structural and Quantitative Knowledge", "Authors": ["Jose Duato", "Jose I. Mestre", "Manuel F. Dolz and Enrique S. Quintana-Ort\\'i"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["15 pages", "7 figures"], "ACM-class": "I.2; I.2.6"}, "abstract": "The number and complexity of artificial intelligence (AI) applications is growing relentlessly. As a result, even with the many algorithmic and mathematical advances experienced over past decades as well as the impressive energy efficiency and computational capacity of current hardware accelerators, training the most powerful and popular deep neural networks comes at very high economic and environmental costs. Recognising that additional optimisations of conventional neural network training is very difficult, this work takes a radically different approach by proposing GreenLightningAI, a new AI system design consisting of a linear model that is capable of emulating the behaviour of deep neural networks by subsetting the model for each particular sample. The new AI system stores the information required to select the system subset for a given sample (referred to as structural information) separately from the linear model parameters (referred to as quantitative knowledge). In this paper we present a proof of concept, showing that the structural information stabilises far earlier than the quantitative knowledge. Additionally, we show experimentally that the structural information can be kept unmodified when re-training the AI system with new samples while still achieving a validation accuracy similar to that obtained when re-training a neural network with similar size. Since the proposed AI system is based on a linear model, multiple copies of the model, trained with different datasets, can be easily combined. This enables faster and greener (re)-training algorithms, including incremental re-training and federated incremental re-training.", "url": "https://arxiv.org/abs/2312.09971"}, {"metadata": {"arXiv": "2312.09983", "Date": "Fri, 15 Dec 2023 17:50:18 ", "Title": "Toward Computationally Efficient Inverse Reinforcement Learning via Reward Shaping", "Authors": ["Lauren H. Cooke", "Harvey Klyne", "Edwin Zhang", "Cassidy Laidlaw", "Milind Tambe", "Finale Doshi-Velez"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Inverse reinforcement learning (IRL) is computationally challenging, with common approaches requiring the solution of multiple reinforcement learning (RL) sub-problems. This work motivates the use of potential-based reward shaping to reduce the computational burden of each RL sub-problem. This work serves as a proof-of-concept and we hope will inspire future developments towards computationally efficient IRL.", "url": "https://arxiv.org/abs/2312.09983"}, {"metadata": {"arXiv": "2312.10029", "Date": "Fri, 15 Dec 2023 18:49:43 ", "Title": "Challenges with unsupervised LLM knowledge discovery", "Authors": ["Sebastian Farquhar", "Vikrant Varma", "Zachary Kenton", "Johannes Gasteiger", "Vladimir Mikulik", "Rohin Shah"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages (38 including references and appendices). First three authors equal contribution", "randomised order"]}, "abstract": "We show that existing unsupervised methods on large language model (LLM) activations do not discover knowledge -- instead they seem to discover whatever feature of the activations is most prominent. The idea behind unsupervised knowledge elicitation is that knowledge satisfies a consistency structure, which can be used to discover knowledge. We first prove theoretically that arbitrary features (not just knowledge) satisfy the consistency structure of a particular leading unsupervised knowledge-elicitation method, contrast-consistent search (Burns et al. - arXiv:2212.03827). We then present a series of experiments showing settings in which unsupervised methods result in classifiers that do not predict knowledge, but instead predict a different prominent feature. We conclude that existing unsupervised methods for discovering latent knowledge are insufficient, and we contribute sanity checks to apply to evaluating future knowledge elicitation methods. Conceptually, we hypothesise that the identification issues explored here, e.g. distinguishing a model's knowledge from that of a simulated character's, will persist for future unsupervised methods.", "url": "https://arxiv.org/abs/2312.10029"}, {"metadata": {"arXiv": "2312.09436", "Date": "Mon, 27 Nov 2023 21:18:06 ", "Title": "Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy", "Authors": ["Jung-Hoon Cho", "Sirui Li", "Jeongyun Kim", "Cathy Wu"], "Categories": "cs.RO cs.AI cs.LG cs.SY", "Comments": ["18 pages", "12 figures"]}, "abstract": "The recent development of connected and automated vehicle (CAV) technologies has spurred investigations to optimize dense urban traffic. This paper considers advisory autonomy, in which real-time driving advisories are issued to drivers, thus blending the CAV and the human driver. Due to the complexity of traffic systems, recent studies of coordinating CAVs have resorted to leveraging deep reinforcement learning (RL). Advisory autonomy is formalized as zero-order holds, and we consider a range of hold duration from 0.1 to 40 seconds. However, despite the similarity of the higher frequency tasks on CAVs, a direct application of deep RL fails to be generalized to advisory autonomy tasks. We introduce Temporal Transfer Learning (TTL) algorithms to select source tasks, systematically leveraging the temporal structure to solve the full range of tasks. TTL selects the most suitable source tasks to maximize the performance of the range of tasks. We validate our algorithms on diverse mixed-traffic scenarios, demonstrating that TTL more reliably solves the tasks than baselines. This paper underscores the potential of coarse-grained advisory autonomy with TTL in traffic flow optimization.", "url": "https://arxiv.org/abs/2312.09436"}, {"metadata": {"arXiv": "2312.09466", "Date": "Sun, 26 Nov 2023 19:03:41 ", "Title": "Enhancing Trajectory Prediction through Self-Supervised Waypoint Noise Prediction", "Authors": ["Pranav Singh Chib", "Pravendra Singh"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["Under review"]}, "abstract": "Trajectory prediction is an important task that involves modeling the indeterminate nature of traffic actors to forecast future trajectories given the observed trajectory sequences. However, current methods confine themselves to presumed data manifolds, assuming that trajectories strictly adhere to these manifolds, resulting in overly simplified predictions. To this end, we propose a novel approach called SSWNP (Self-Supervised Waypoint Noise Prediction). In our approach, we first create clean and noise-augmented views of past observed trajectories across the spatial domain of waypoints. We then compel the trajectory prediction model to maintain spatial consistency between predictions from these two views, in addition to the trajectory prediction task. Introducing the noise-augmented view mitigates the model's reliance on a narrow interpretation of the data manifold, enabling it to learn more plausible and diverse representations. We also predict the noise present in the two views of past observed trajectories as an auxiliary self-supervised task, enhancing the model's understanding of the underlying representation and future predictions. Empirical evidence demonstrates that the incorporation of SSWNP into the model learning process significantly improves performance, even in noisy environments, when compared to baseline methods. Our approach can complement existing trajectory prediction methods. To showcase the effectiveness of our approach, we conducted extensive experiments on three datasets: NBA Sports VU, ETH-UCY, and TrajNet++, with experimental results highlighting the substantial improvement achieved in trajectory prediction tasks.", "url": "https://arxiv.org/abs/2312.09466"}, {"metadata": {"arXiv": "2312.09468", "Date": "Tue, 28 Nov 2023 19:22:16 ", "Title": "Safe Reinforcement Learning in a Simulated Robotic Arm", "Authors": ["Luka Kova\\v{c} and Igor Farka\\v{s}"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["4 pages", "2 figures"]}, "abstract": "Reinforcement learning (RL) agents need to explore their environments in order to learn optimal policies. In many environments and tasks, safety is of critical importance. The widespread use of simulators offers a number of advantages, including safe exploration which will be inevitable in cases when RL systems need to be trained directly in the physical environment (e.g. in human-robot interaction). The popular Safety Gym library offers three mobile agent types that can learn goal-directed tasks while considering various safety constraints. In this paper, we extend the applicability of safe RL algorithms by creating a customized environment with Panda robotic arm where Safety Gym algorithms can be tested. We performed pilot experiments with the popular PPO algorithm comparing the baseline with the constrained version and show that the constrained version is able to learn the equally good policy while better complying with safety constraints and taking longer training time as expected.", "url": "https://arxiv.org/abs/2312.09468"}, {"metadata": {"arXiv": "2312.10008", "Date": "Fri, 15 Dec 2023 18:24:28 ", "Title": "Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects", "Authors": ["Paul Maria Scheikl", "Nicolas Schreiber", "Christoph Haas", "Niklas Freymuth", "Gerhard Neumann", "Rudolf Lioutikov", "and Franziska Mathis-Ullrich"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Policy learning in robot-assisted surgery (RAS) lacks data efficient and versatile methods that exhibit the desired motion quality for delicate surgical interventions. To this end, we introduce Movement Primitive Diffusion (MPD), a novel method for imitation learning (IL) in RAS that focuses on gentle manipulation of deformable objects. The approach combines the versatility of diffusion-based imitation learning (DIL) with the high-quality motion generation capabilities of Probabilistic Dynamic Movement Primitives (ProDMPs). This combination enables MPD to achieve gentle manipulation of deformable objects, while maintaining data efficiency critical for RAS applications where demonstration data is scarce. We evaluate MPD across various simulated tasks and a real world robotic setup on both state and image observations. MPD outperforms state-of-the-art DIL methods in success rate, motion quality, and data efficiency.", "url": "https://arxiv.org/abs/2312.10008"}, {"metadata": {"arXiv": "2312.09585", "Date": "Fri, 15 Dec 2023 07:47:03 ", "Title": "Joint State Estimation and Noise Identification Based on Variational Optimization", "Authors": ["Hua Lan and Shijie Zhao and Jinjie Hu and Zengfu Wang and Jing Fu"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["13 pages"]}, "abstract": "In this article, the state estimation problems with unknown process noise and measurement noise covariances for both linear and nonlinear systems are considered. By formulating the joint estimation of system state and noise parameters into an optimization problem, a novel adaptive Kalman filter method based on conjugate-computation variational inference, referred to as CVIAKF, is proposed to approximate the joint posterior probability density function of the latent variables. Unlike the existing adaptive Kalman filter methods utilizing variational inference in natural-parameter space, CVIAKF performs optimization in expectation-parameter space, resulting in a faster and simpler solution. Meanwhile, CVIAKF divides optimization objectives into conjugate and non-conjugate parts of nonlinear dynamical models, whereas conjugate computations and stochastic mirror-descent are applied, respectively. Remarkably, the reparameterization trick is used to reduce the variance of stochastic gradients of the non-conjugate parts. The effectiveness of CVIAKF is validated through synthetic and real-world datasets of maneuvering target tracking.", "url": "https://arxiv.org/abs/2312.09585"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2310.16115", "Date": "Tue, 24 Oct 2023 18:32:46 ", "Title": "Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos", "Authors": ["Yaoyao Liu", "Yingying Li", "Bernt Schiele", "Qianru Sun"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to WACV 2024. Code: https://github.com/yaoyao-liu/online-placebos"]}, "abstract": "Not forgetting old class knowledge is a key challenge for class-incremental learning (CIL) when the model continuously adapts to new classes. A common technique to address this is knowledge distillation (KD), which penalizes prediction inconsistencies between old and new models. Such prediction is made with almost new class data, as old class data is extremely scarce due to the strict memory limitation in CIL. In this paper, we take a deep dive into KD losses and find that \"using new class data for KD\" not only hinders the model adaption (for learning new classes) but also results in low efficiency for preserving old class knowledge. We address this by \"using the placebos of old classes for KD\", where the placebos are chosen from a free image stream, such as Google Images, in an automatical and economical fashion. To this end, we train an online placebo selection policy to quickly evaluate the quality of streaming images (good or bad placebos) and use only good ones for one-time feed-forward computation of KD. We formulate the policy training process as an online Markov Decision Process (MDP), and introduce an online learning algorithm to solve this MDP problem without causing much computation costs. In experiments, we show that our method 1) is surprisingly effective even when there is no class overlap between placebos and original old class data, 2) does not require any additional supervision or memory budget, and 3) significantly outperforms a number of top-performing CIL methods, in particular when using lower memory budgets for old class exemplars, e.g., five exemplars per class.", "url": "https://arxiv.org/abs/2310.16115"}, {"metadata": {"arXiv": "2310.16226", "Date": "Tue, 24 Oct 2023 22:41:14 ", "Title": "TiC-CLIP: Continual Training of CLIP Models", "Authors": ["Saurabh Garg", "Mehrdad Farajtabar", "Hadi Pouransari", "Raviteja Vemulapalli", "Sachin Mehta", "Oncel Tuzel", "Vaishaal Shankar", "Fartash Faghri"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\\approx 8\\%$ zero-shot accuracy on our curated retrieval task from 2021--2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the last checkpoint and replays old data reduces compute by $2.5\\times$ when compared to the standard practice of retraining from scratch.", "url": "https://arxiv.org/abs/2310.16226"}, {"metadata": {"arXiv": "2310.16305", "Date": "Wed, 25 Oct 2023 02:26:04 ", "Title": "Dolfin: Diffusion Layout Transformers without Autoencoder", "Authors": ["Yilin Wang", "Zeyuan Chen", "Liangjun Zhong", "Zheng Ding", "Zhizhou Sha", "Zhuowen Tu"], "Categories": "cs.CV cs.LG"}, "abstract": "In this paper, we introduce a novel generative model, Diffusion Layout Transformers without Autoencoder (Dolfin), which significantly improves the modeling capability with reduced complexity compared to existing methods. Dolfin employs a Transformer-based diffusion process to model layout generation. In addition to an efficient bi-directional (non-causal joint) sequence representation, we further propose an autoregressive diffusion model (Dolfin-AR) that is especially adept at capturing rich semantic correlations for the neighboring objects, such as alignment, size, and overlap. When evaluated against standard generative layout benchmarks, Dolfin notably improves performance across various metrics (fid, alignment, overlap, MaxIoU and DocSim scores), enhancing transparency and interoperability in the process. Moreover, Dolfin's applications extend beyond layout generation, making it suitable for modeling geometric structures, such as line segments. Our experiments present both qualitative and quantitative results to demonstrate the advantages of Dolfin.", "url": "https://arxiv.org/abs/2310.16305"}, {"metadata": {"arXiv": "2310.16527", "Date": "Wed, 25 Oct 2023 10:22:30 ", "Title": "Enhancing Document Information Analysis with Multi-Task Pre-training: A Robust Approach for Information Extraction in Visually-Rich Documents", "Authors": ["Tofik Ali and Partha Pratim Roy"], "Categories": "cs.CV cs.LG"}, "abstract": "This paper introduces a deep learning model tailored for document information analysis, emphasizing document classification, entity relation extraction, and document visual question answering. The proposed model leverages transformer-based models to encode all the information present in a document image, including textual, visual, and layout information. The model is pre-trained and subsequently fine-tuned for various document image analysis tasks. The proposed model incorporates three additional tasks during the pre-training phase, including reading order identification of different layout segments in a document image, layout segments categorization as per PubLayNet, and generation of the text sequence within a given layout segment (text block). The model also incorporates a collective pre-training scheme where losses of all the tasks under consideration, including pre-training and fine-tuning tasks with all datasets, are considered. Additional encoder and decoder blocks are added to the RoBERTa network to generate results for all tasks. The proposed model achieved impressive results across all tasks, with an accuracy of 95.87% on the RVL-CDIP dataset for document classification, F1 scores of 0.9306, 0.9804, 0.9794, and 0.8742 on the FUNSD, CORD, SROIE, and Kleister-NDA datasets respectively for entity relation extraction, and an ANLS score of 0.8468 on the DocVQA dataset for visual question answering. The results highlight the effectiveness of the proposed model in understanding and interpreting complex document layouts and content, making it a promising tool for document analysis tasks.", "url": "https://arxiv.org/abs/2310.16527"}, {"metadata": {"arXiv": "2310.16639", "Date": "Wed, 25 Oct 2023 13:39:04 ", "Title": "Driving through the Concept Gridlock: Unraveling Explainability Bottlenecks", "Authors": ["Jessica Echterhoff", "An Yan", "Kyungtae Han", "Amr Abdelraouf", "Rohit Gupta", "Julian McAuley"], "Categories": "cs.CV cs.LG"}, "abstract": "Concept bottleneck models have been successfully used for explainable machine learning by encoding information within the model with a set of human-defined concepts. In the context of human-assisted or autonomous driving, explainability models can help user acceptance and understanding of decisions made by the autonomous vehicle, which can be used to rationalize and explain driver or vehicle behavior. We propose a new approach using concept bottlenecks as visual features for control command predictions and explanations of user and vehicle behavior. We learn a human-understandable concept layer that we use to explain sequential driving scenes while learning vehicle control commands. This approach can then be used to determine whether a change in a preferred gap or steering commands from a human (or autonomous vehicle) is led by an external stimulus or change in preferences. We achieve competitive performance to latent visual features while gaining interpretability within our model setup.", "url": "https://arxiv.org/abs/2310.16639"}, {"metadata": {"arXiv": "2310.16695", "Date": "Wed, 25 Oct 2023 15:06:32 ", "Title": "From Pointwise to Powerhouse: Initialising Neural Networks with Generative Models", "Authors": ["Christian Harder", "Moritz Fuchs", "Yuri Tolkach", "Anirban Mukhopadhyay"], "Categories": "cs.CV cs.LG", "ACM-class": "J.3; I.5.1; I.5.4"}, "abstract": "Traditional initialisation methods, e.g. He and Xavier, have been effective in avoiding the problem of vanishing or exploding gradients in neural networks. However, they only use simple pointwise distributions, which model one-dimensional variables. Moreover, they ignore most information about the architecture and disregard past training experiences. These limitations can be overcome by employing generative models for initialisation. In this paper, we introduce two groups of new initialisation methods. First, we locally initialise weight groups by employing variational autoencoders. Secondly, we globally initialise full weight sets by employing graph hypernetworks. We thoroughly evaluate the impact of the employed generative models on state-of-the-art neural networks in terms of accuracy, convergence speed and ensembling. Our results show that global initialisations result in higher accuracy and faster initial convergence speed. However, the implementation through graph hypernetworks leads to diminished ensemble performance on out of distribution data. To counteract, we propose a modification called noise graph hypernetwork, which encourages diversity in the produced ensemble members. Furthermore, our approach might be able to transfer learned knowledge to different image distributions. Our work provides insights into the potential, the trade-offs and possible modifications of these new initialisation methods.", "url": "https://arxiv.org/abs/2310.16695"}, {"metadata": {"arXiv": "2310.16764", "Date": "Wed, 25 Oct 2023 16:52:13 ", "Title": "ConvNets Match Vision Transformers at Scale", "Authors": ["Samuel L. Smith", "Andrew Brock", "Leonard Berrada", "Soham De"], "Categories": "cs.CV cs.LG cs.NE"}, "abstract": "Many researchers believe that ConvNets perform well on small or moderately sized datasets, but are not competitive with Vision Transformers when given access to datasets on the web-scale. We challenge this belief by evaluating a performant ConvNet architecture pre-trained on JFT-4B, a large labelled dataset of images often used for training foundation models. We consider pre-training compute budgets between 0.4k and 110k TPU-v4 core compute hours, and train a series of networks of increasing depth and width from the NFNet model family. We observe a log-log scaling law between held out loss and compute budget. After fine-tuning on ImageNet, NFNets match the reported performance of Vision Transformers with comparable compute budgets. Our strongest fine-tuned model achieves a Top-1 accuracy of 90.4%.", "url": "https://arxiv.org/abs/2310.16764"}, {"metadata": {"arXiv": "2310.16781", "Date": "Wed, 25 Oct 2023 17:15:55 ", "Title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models", "Authors": ["Morris Alper and Hadar Averbuch-Elor"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["Accepted to NeurIPS 2023 (spotlight). Project webpage: https://kiki-bouba.github.io/"]}, "abstract": "Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available.", "url": "https://arxiv.org/abs/2310.16781"}, {"metadata": {"arXiv": "2310.16788", "Date": "Wed, 25 Oct 2023 17:20:38 ", "Title": "The GOOSE Dataset for Perception in Unstructured Environments", "Authors": ["Peter Mortimer", "Raphael Hagmanns", "Miguel Granero", "Thorsten Luettel", "Janko Petereit", "Hans-Joachim Wuensche"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["Preprint; Submitted to IEEE for review"]}, "abstract": "The potential for deploying autonomous systems can be significantly increased by improving the perception and interpretation of the environment. However, the development of deep learning-based techniques for autonomous systems in unstructured outdoor environments poses challenges due to limited data availability for training and testing. To address this gap, we present the German Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset specifically designed for unstructured outdoor environments. The GOOSE dataset incorporates 10 000 labeled pairs of images and point clouds, which are utilized to train a range of state-of-the-art segmentation models on both image and point cloud data. We open source the dataset, along with an ontology for unstructured terrain, as well as dataset standards and guidelines. This initiative aims to establish a common framework, enabling the seamless inclusion of existing datasets and a fast way to enhance the perception capabilities of various robots operating in unstructured environments. The dataset, pre-trained models for offroad perception, and additional documentation can be found at https://goose-dataset.de/.", "url": "https://arxiv.org/abs/2310.16788"}, {"metadata": {"arXiv": "2310.16831", "Date": "Wed, 25 Oct 2023 17:59:01 ", "Title": "PERF: Panoramic Neural Radiance Field from a Single Panorama", "Authors": ["Guangcong Wang and Peng Wang and Zhaoxi Chen and Wenping Wang and Chen Change Loy and Ziwei Liu"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project page and code: https://perf-project.github.io/"]}, "abstract": "Neural Radiance Field (NeRF) has achieved substantial progress in novel view synthesis given multi-view images. Recently, some works have attempted to train a NeRF from a single image with 3D priors. They mainly focus on a limited field of view and there are few invisible occlusions, which greatly limits their scalability to real-world 360-degree panoramic scenarios with large-size occlusions. In this paper, we present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama. Notably, PERF allows 3D roaming in a complex scene without expensive and tedious image collection. To achieve this goal, we propose a novel collaborative RGBD inpainting method and a progressive inpainting-and-erasing method to lift up a 360-degree 2D scene to a 3D scene. Specifically, we first predict a panoramic depth map as initialization given a single panorama, and reconstruct visible 3D regions with volume rendering. Then we introduce a collaborative RGBD inpainting approach into a NeRF for completing RGB images and depth maps from random views, which is derived from an RGB Stable Diffusion model and a monocular depth estimator. Finally, we introduce an inpainting-and-erasing strategy to avoid inconsistent geometry between a newly-sampled view and reference views. The two components are integrated into the learning of NeRFs in a unified optimization framework and achieve promising results. Extensive experiments on Replica and a new dataset PERF-in-the-wild demonstrate the superiority of our PERF over state-of-the-art methods. Our PERF can be widely used for real-world applications, such as panorama-to-3D, text-to-3D, and 3D scene stylization applications. Project page and code are available at https://perf-project.github.io/.", "url": "https://arxiv.org/abs/2310.16831"}, {"metadata": {"arXiv": "2310.16214", "Date": "Tue, 24 Oct 2023 22:09:03 ", "Title": "Performance Tuning for GPU-Embedded Systems: Machine-Learning-based and Analytical Model-driven Tuning Methodologies", "Authors": ["Adrian Perez Dieguez", "Margarita Amor Lopez"], "Categories": "cs.DC cs.LG cs.PF"}, "abstract": "GPU-embedded systems have gained popularity across various domains due to their efficient power consumption. However, in order to meet the demands of real-time or time-consuming applications running on these systems, it is crucial for them to be tuned to exhibit high performance. This paper addresses the issue by developing and comparing two tuning methodologies on GPU-embedded systems, and also provides performance insights for developers and researchers seeking to optimize applications running on these architectures. We focus on parallel prefix operations, such as FFT, scan primitives, and tridiagonal system solvers, which are performance-critical components in many applications. The study introduces an analytical model-driven tuning methodology and a Machine Learning (ML)-based tuning methodology. We evaluate the performance of the two tuning methodologies for different parallel prefix implementations of the BPLG library in an NVIDIA Jetson system, and compare their performance to the ones achieved through an exhaustive search. The findings shed light on the best strategies for handling the open challenge of performance portability for major computational patterns among server and embedded devices, providing practical guidance for offline and online tuning. We also address the existing gap in performance studies for parallel computational patterns in GPU-embedded systems by comparing the BPLG performance against other state-of-the-art libraries, including CUSPARSE, CUB, and CUFFT.", "url": "https://arxiv.org/abs/2310.16214"}, {"metadata": {"arXiv": "2310.16326", "Date": "Wed, 25 Oct 2023 03:14:48 ", "Title": "Reinforcement Learning for SBM Graphon Games with Re-Sampling", "Authors": ["Peihan Huo", "Oscar Peralta", "Junyu Guo", "Qiaomin Xie", "Andreea Minca"], "Categories": "cs.GT cs.LG"}, "abstract": "The Mean-Field approximation is a tractable approach for studying large population dynamics. However, its assumption on homogeneity and universal connections among all agents limits its applicability in many real-world scenarios. Multi-Population Mean-Field Game (MP-MFG) models have been introduced in the literature to address these limitations. When the underlying Stochastic Block Model is known, we show that a Policy Mirror Ascent algorithm finds the MP-MFG Nash Equilibrium. In more realistic scenarios where the block model is unknown, we propose a re-sampling scheme from a graphon integrated with the finite N-player MP-MFG model. We develop a novel learning framework based on a Graphon Game with Re-Sampling (GGR-S) model, which captures the complex network structures of agents' connections. We analyze GGR-S dynamics and establish the convergence to dynamics of MP-MFG. Leveraging this result, we propose an efficient sample-based N-player Reinforcement Learning algorithm for GGR-S without population manipulation, and provide a rigorous convergence analysis with finite sample guarantee.", "url": "https://arxiv.org/abs/2310.16326"}, {"metadata": {"arXiv": "2310.16058", "Date": "Fri, 20 Oct 2023 23:56:53 ", "Title": "A Sparse Bayesian Learning for Diagnosis of Nonstationary and Spatially Correlated Faults with Application to Multistation Assembly Systems", "Authors": ["Jihoon Chung and Zhenyu Kong"], "Categories": "cs.LG stat.AP"}, "abstract": "Sensor technology developments provide a basis for effective fault diagnosis in manufacturing systems. However, the limited number of sensors due to physical constraints or undue costs hinders the accurate diagnosis in the actual process. In addition, time-varying operational conditions that generate nonstationary process faults and the correlation information in the process require to consider for accurate fault diagnosis in the manufacturing systems. This article proposes a novel fault diagnosis method: clustering spatially correlated sparse Bayesian learning (CSSBL), and explicitly demonstrates its applicability in a multistation assembly system that is vulnerable to the above challenges. Specifically, the method is based on a practical assumption that it will likely have a few process faults (sparse). In addition, the hierarchical structure of CSSBL has several parameterized prior distributions to address the above challenges. As posterior distributions of process faults do not have closed form, this paper derives approximate posterior distributions through Variational Bayes inference. The proposed method's efficacy is provided through numerical and real-world case studies utilizing an actual autobody assembly system. The generalizability of the proposed method allows the technique to be applied in fault diagnosis in other domains, including communication and healthcare systems.", "url": "https://arxiv.org/abs/2310.16058"}, {"metadata": {"arXiv": "2310.16063", "Date": "Tue, 24 Oct 2023 09:16:13 ", "Title": "Enhancing Traffic Prediction with Learnable Filter Module", "Authors": ["Yuanshao Zhu", "Yongchao Ye", "Xiangyu Zhao", "and James J.Q. Yu"], "Categories": "cs.LG"}, "abstract": "Modeling future traffic conditions often relies heavily on complex spatial-temporal neural networks to capture spatial and temporal correlations, which can overlook the inherent noise in the data. This noise, often manifesting as unexpected short-term peaks or drops in traffic observation, is typically caused by traffic accidents or inherent sensor vibration. In practice, such noise can be challenging to model due to its stochastic nature and can lead to overfitting risks if a neural network is designed to learn this behavior. To address this issue, we propose a learnable filter module to filter out noise in traffic data adaptively. This module leverages the Fourier transform to convert the data to the frequency domain, where noise is filtered based on its pattern. The denoised data is then recovered to the time domain using the inverse Fourier transform. Our approach focuses on enhancing the quality of the input data for traffic prediction models, which is a critical yet often overlooked aspect in the field. We demonstrate that the proposed module is lightweight, easy to integrate with existing models, and can significantly improve traffic prediction performance. Furthermore, we validate our approach with extensive experimental results on real-world datasets, showing that it effectively mitigates noise and enhances prediction accuracy.", "url": "https://arxiv.org/abs/2310.16063"}, {"metadata": {"arXiv": "2310.16070", "Date": "Tue, 24 Oct 2023 13:49:13 ", "Title": "Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting", "Authors": ["Chengzhi Yao", "Zhi Li", "Junbo Wang"], "Categories": "cs.LG"}, "abstract": "Traffic forecasting, which benefits from mobile Internet development and position technologies, plays a critical role in Intelligent Transportation Systems. It helps to implement rich and varied transportation applications and bring convenient transportation services to people based on collected traffic data. Most existing methods usually leverage graph-based deep learning networks to model the complex road network for traffic forecasting shallowly. Despite their effectiveness, these methods are generally limited in fully capturing high-order spatial dependencies caused by road network topology and high-order temporal dependencies caused by traffic dynamics. To tackle the above issues, we focus on the essence of traffic system and propose STHODE: Spatio-Temporal Hypergraph Neural Ordinary Differential Equation Network, which combines road network topology and traffic dynamics to capture high-order spatio-temporal dependencies in traffic data. Technically, STHODE consists of a spatial module and a temporal module. On the one hand, we construct a spatial hypergraph and leverage an adaptive MixHop hypergraph ODE network to capture high-order spatial dependencies. On the other hand, we utilize a temporal hypergraph and employ a hyperedge evolving ODE network to capture high-order temporal dependencies. Finally, we aggregate the outputs of stacked STHODE layers to mutually enhance the prediction performance. Extensive experiments conducted on four real-world traffic datasets demonstrate the superior performance of our proposed model compared to various baselines.", "url": "https://arxiv.org/abs/2310.16070"}, {"metadata": {"arXiv": "2310.16076", "Date": "Tue, 24 Oct 2023 17:17:01 ", "Title": "Practical Computational Power of Linear Transformers and Their Recurrent and Self-Referential Extensions", "Authors": ["Kazuki Irie", "R\\'obert Csord\\'as", "J\\\"urgen Schmidhuber"], "Categories": "cs.LG", "Comments": ["Accepted to EMNLP 2023 (short paper)"]}, "abstract": "Recent studies of the computational power of recurrent neural networks (RNNs) reveal a hierarchy of RNN architectures, given real-time and finite-precision assumptions. Here we study auto-regressive Transformers with linearised attention, a.k.a. linear Transformers (LTs) or Fast Weight Programmers (FWPs). LTs are special in the sense that they are equivalent to RNN-like sequence processors with a fixed-size state, while they can also be expressed as the now-popular self-attention networks. We show that many well-known results for the standard Transformer directly transfer to LTs/FWPs. Our formal language recognition experiments demonstrate how recently proposed FWP extensions such as recurrent FWPs and self-referential weight matrices successfully overcome certain limitations of the LT, e.g., allowing for generalisation on the parity problem. Our code is public.", "url": "https://arxiv.org/abs/2310.16076"}, {"metadata": {"arXiv": "2310.16105", "Date": "Tue, 24 Oct 2023 18:15:25 ", "Title": "Locally Differentially Private Gradient Tracking for Distributed Online Learning over Directed Graphs", "Authors": ["Ziqin Chen and Yongqiang Wang"], "Categories": "cs.LG", "Comments": ["21 pages", "4 figures"]}, "abstract": "Distributed online learning has been proven extremely effective in solving large-scale machine learning problems involving streaming data. However, information sharing between learners in distributed learning also raises concerns about the potential leakage of individual learners' sensitive data. To mitigate this risk, differential privacy, which is widely regarded as the \"gold standard\" for privacy protection, has been widely employed in many existing results on distributed online learning. However, these results often face a fundamental tradeoff between learning accuracy and privacy. In this paper, we propose a locally differentially private gradient tracking based distributed online learning algorithm that successfully circumvents this tradeoff. Our analysis shows that the proposed algorithm converges in mean square to the exact optimal solution while ensuring rigorous local differential privacy, with the cumulative privacy budget guaranteed to be finite even when the number of iterations tends to infinity. The algorithm is applicable even when the communication graph among learners is directed. To the best of our knowledge, this is the first result that simultaneously ensures learning accuracy and rigorous local differential privacy in distributed online learning over directed graphs. We evaluate our algorithm's performance by using multiple benchmark machine-learning applications, including logistic regression on the \"Mushrooms\" dataset and CNN-based image classification on the \"MNIST\" and \"CIFAR-10\" datasets, respectively. The experimental results confirm that the proposed algorithm outperforms existing counterparts in both training and testing accuracies.", "url": "https://arxiv.org/abs/2310.16105"}, {"metadata": {"arXiv": "2310.16106", "Date": "Tue, 24 Oct 2023 18:15:52 ", "Title": "Decentralized Learning over Wireless Networks with Broadcast-Based Subgraph Sampling", "Authors": ["Daniel P\\'erez Herrera", "Zheng Chen and Erik G. Larsson"], "Categories": "cs.LG cs.DC cs.IT cs.SY eess.SY math.IT", "Comments": ["6 pages", "4 figures", "submitted for possible conference publication"]}, "abstract": "This work centers on the communication aspects of decentralized learning over wireless networks, using consensus-based decentralized stochastic gradient descent (D-SGD). Considering the actual communication cost or delay caused by in-network information exchange in an iterative process, our goal is to achieve fast convergence of the algorithm measured by improvement per transmission slot. We propose BASS, an efficient communication framework for D-SGD over wireless networks with broadcast transmission and probabilistic subgraph sampling. In each iteration, we activate multiple subsets of non-interfering nodes to broadcast model updates to their neighbors. These subsets are randomly activated over time, with probabilities reflecting their importance in network connectivity and subject to a communication cost constraint (e.g., the average number of transmission slots per iteration). During the consensus update step, only bi-directional links are effectively preserved to maintain communication symmetry. In comparison to existing link-based scheduling methods, the inherent broadcasting nature of wireless channels offers intrinsic advantages in speeding up convergence of decentralized learning by creating more communicated links with the same number of transmission slots.", "url": "https://arxiv.org/abs/2310.16106"}, {"metadata": {"arXiv": "2310.16113", "Date": "Tue, 24 Oct 2023 18:26:43 ", "Title": "Compressed representation of brain genetic transcription", "Authors": ["James K Ruffle", "Henry Watkins", "Robert J Gray", "Harpreet Hyare", "Michel Thiebaut de Schotten", "Parashkev Nachev"], "Categories": "cs.LG q-bio.GN q-bio.NC", "Comments": ["21 pages", "5 main figures", "1 supplementary figure"]}, "abstract": "The architecture of the brain is too complex to be intuitively surveyable without the use of compressed representations that project its variation into a compact, navigable space. The task is especially challenging with high-dimensional data, such as gene expression, where the joint complexity of anatomical and transcriptional patterns demands maximum compression. Established practice is to use standard principal component analysis (PCA), whose computational felicity is offset by limited expressivity, especially at great compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas transcription data, here we systematically compare compressed representations based on the most widely supported linear and non-linear methods-PCA, kernel PCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding (t-SNE), uniform manifold approximation and projection (UMAP), and deep auto-encoding-quantifying reconstruction fidelity, anatomical coherence, and predictive utility with respect to signalling, microstructural, and metabolic targets. We show that deep auto-encoders yield superior representations across all metrics of performance and target domains, supporting their use as the reference standard for representing transcription patterns in the human brain.", "url": "https://arxiv.org/abs/2310.16113"}, {"metadata": {"arXiv": "2310.16123", "Date": "Tue, 24 Oct 2023 18:55:12 ", "Title": "Anchor Space Optimal Transport: Accelerating Batch Processing of Multiple OT Problems", "Authors": ["Jianming Huang", "Xun Su", "Zhongxi Fang", "Hiroyuki Kasai"], "Categories": "cs.LG", "Comments": ["26 pages", "4 figures", "6 tables"]}, "abstract": "The optimal transport (OT) theory provides an effective way to compare probability distributions on a defined metric space, but it suffers from cubic computational complexity. Although the Sinkhorn's algorithm greatly reduces the computational complexity of OT solutions, the solutions of multiple OT problems are still time-consuming and memory-comsuming in practice. However, many works on the computational acceleration of OT are usually based on the premise of a single OT problem, ignoring the potential common characteristics of the distributions in a mini-batch. Therefore, we propose a translated OT problem designated as the anchor space optimal transport (ASOT) problem, which is specially designed for batch processing of multiple OT problem solutions. For the proposed ASOT problem, the distributions will be mapped into a shared anchor point space, which learns the potential common characteristics and thus help accelerate OT batch processing. Based on the proposed ASOT, the Wasserstein distance error to the original OT problem is proven to be bounded by ground cost errors. Building upon this, we propose three methods to learn an anchor space minimizing the distance error, each of which has its application background. Numerical experiments on real-world datasets show that our proposed methods can greatly reduce computational time while maintaining reasonable approximation performance.", "url": "https://arxiv.org/abs/2310.16123"}, {"metadata": {"arXiv": "2310.16125", "Date": "Tue, 24 Oct 2023 18:58:36 ", "Title": "Online Thermal Field Prediction for Metal Additive Manufacturing of Thin Walls", "Authors": ["Yifan Tang", "M. Rahmani Dehaghani", "Pouyan Sajadi", "Shahriar Bakrani Balani", "Akshay Dhalpe", "Suraj Panicker", "Di Wu", "Eric Coatanea", "G. Gary Wang"], "Categories": "cs.LG", "Comments": ["36 pages", "26 figures", "5 tables"]}, "abstract": "This paper aims to study a practical issue in metal AM, i.e., how to predict the thermal field of yet-to-print parts online when only a few sensors are available. This work proposes an online thermal field prediction method using mapping and reconstruction, which could be integrated into a metal AM process for online performance control. Based on the similarity of temperature curves (curve segments of a temperature profile of one point), the thermal field mapping applies an artificial neural network to estimate the temperature curves of points on the yet-to-print layer from measured temperatures of certain points on the previously printed layer. With measured/predicted temperature profiles of several points on the same layer, the thermal field reconstruction proposes a reduced order model (ROM) to construct the temperature profiles of all points on the same layer, which could be used to build the temperature field of the entire layer. The training of ROM is performed with an extreme learning machine (ELM) for computational efficiency. Fifteen wire arc AM experiments and nine simulations are designed for thin walls with a fixed length and unidirectional printing of each layer. The test results indicate that the proposed prediction method could construct the thermal field of a yet-to-print layer within 0.1 seconds on a low-cost desktop. Meanwhile, the method has acceptable generalization capability in most cases from lower layers to higher layers in the same simulation and from one simulation to a new simulation on different AM process parameters. More importantly, after fine-tuning the proposed method with limited experimental data, the relative errors of all predicted temperature profiles on a new experiment are sufficiently small, demonstrating the applicability and generalization of the proposed thermal field prediction method in online applications for metal AM.", "url": "https://arxiv.org/abs/2310.16125"}, {"metadata": {"arXiv": "2310.16154", "Date": "Tue, 24 Oct 2023 19:50:41 ", "Title": "Breaking the Curse of Dimensionality in Deep Neural Networks by Learning Invariant Representations", "Authors": ["Leonardo Petrini"], "Categories": "cs.LG", "Comments": ["PhD Thesis @ EPFL"]}, "abstract": "Artificial intelligence, particularly the subfield of machine learning, has seen a paradigm shift towards data-driven models that learn from and adapt to data. This has resulted in unprecedented advancements in various domains such as natural language processing and computer vision, largely attributed to deep learning, a special class of machine learning models. Deep learning arguably surpasses traditional approaches by learning the relevant features from raw data through a series of computational layers. This thesis explores the theoretical foundations of deep learning by studying the relationship between the architecture of these models and the inherent structures found within the data they process. In particular, we ask What drives the efficacy of deep learning algorithms and allows them to beat the so-called curse of dimensionality-i.e. the difficulty of generally learning functions in high dimensions due to the exponentially increasing need for data points with increased dimensionality? Is it their ability to learn relevant representations of the data by exploiting their structure? How do different architectures exploit different data structures? In order to address these questions, we push forward the idea that the structure of the data can be effectively characterized by its invariances-i.e. aspects that are irrelevant for the task at hand. Our methodology takes an empirical approach to deep learning, combining experimental studies with physics-inspired toy models. These simplified models allow us to investigate and interpret the complex behaviors we observe in deep learning systems, offering insights into their inner workings, with the far-reaching goal of bridging the gap between theory and practice.", "url": "https://arxiv.org/abs/2310.16154"}, {"metadata": {"arXiv": "2310.16162", "Date": "Tue, 24 Oct 2023 20:17:06 ", "Title": "Brainchop: Next Generation Web-Based Neuroimaging Application", "Authors": ["Mohamed Masoud", "Pratyush Reddy", "Farfalla Hu", "and Sergey Plis"], "Categories": "cs.LG"}, "abstract": "Performing volumetric image processing directly within the browser, particularly with medical data, presents unprecedented challenges compared to conventional backend tools. These challenges arise from limitations inherent in browser environments, such as constrained computational resources and the availability of frontend machine learning libraries. Consequently, there is a shortage of neuroimaging frontend tools capable of providing comprehensive end-to-end solutions for whole brain preprocessing and segmentation while preserving end-user data privacy and residency. In light of this context, we introduce Brainchop (http://www.brainchop.org) as a groundbreaking in-browser neuroimaging tool that enables volumetric analysis of structural MRI using pre-trained full-brain deep learning models, all without requiring technical expertise or intricate setup procedures. Beyond its commitment to data privacy, this frontend tool offers multiple features, including scalability, low latency, user-friendly operation, cross-platform compatibility, and enhanced accessibility. This paper outlines the processing pipeline of Brainchop and evaluates the performance of models across various software and hardware configurations. The results demonstrate the practicality of client-side processing for volumetric data, owing to the robust MeshNet architecture, even within the resource-constrained environment of web browsers.", "url": "https://arxiv.org/abs/2310.16162"}, {"metadata": {"arXiv": "2310.16173", "Date": "Tue, 24 Oct 2023 20:37:02 ", "Title": "On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $\\epsilon$-Greedy Exploration", "Authors": ["Shuai Zhang", "Hongkang Li", "Meng Wang", "Miao Liu", "Pin-Yu Chen", "Songtao Lu", "Sijia Liu", "Keerthiram Murugesan", "Subhajit Chaudhury"], "Categories": "cs.LG", "Journal-ref": "Neurips 2023"}, "abstract": "This paper provides a theoretical understanding of Deep Q-Network (DQN) with the $\\varepsilon$-greedy exploration in deep reinforcement learning. Despite the tremendous empirical achievement of the DQN, its theoretical characterization remains underexplored. First, the exploration strategy is either impractical or ignored in the existing analysis. Second, in contrast to conventional Q-learning algorithms, the DQN employs the target network and experience replay to acquire an unbiased estimation of the mean-square Bellman error (MSBE) utilized in training the Q-network. However, the existing theoretical analysis of DQNs lacks convergence analysis or bypasses the technical challenges by deploying a significantly overparameterized neural network, which is not computationally efficient. This paper provides the first theoretical convergence and sample complexity analysis of the practical setting of DQNs with $\\epsilon$-greedy policy. We prove an iterative procedure with decaying $\\epsilon$ converges to the optimal Q-value function geometrically. Moreover, a higher level of $\\epsilon$ values enlarges the region of convergence but slows down the convergence, while the opposite holds for a lower level of $\\epsilon$ values. Experiments justify our established theoretical insights on DQNs.", "url": "https://arxiv.org/abs/2310.16173"}, {"metadata": {"arXiv": "2310.16186", "Date": "Tue, 24 Oct 2023 21:11:09 ", "Title": "Image Segmentation using U-Net Architecture for Powder X-ray Diffraction Images", "Authors": ["Howard Yanxon", "Eric Roberts", "Hannah Parraga", "James Weng", "Wenqian Xu", "Uta Ruett", "Alexander Hexemer", "Petrus Zwart", "Nickolas Schwarz"], "Categories": "cs.LG hep-ex", "Comments": ["10 pages", "4 figures", "3 tables"]}, "abstract": "Scientific researchers frequently use the in situ synchrotron high-energy powder X-ray diffraction (XRD) technique to examine the crystallographic structures of materials in functional devices such as rechargeable battery materials. We propose a method for identifying artifacts in experimental XRD images. The proposed method uses deep learning convolutional neural network architectures, such as tunable U-Nets to identify the artifacts. In particular, the predicted artifacts are evaluated against the corresponding ground truth (manually implemented) using the overall true positive rate or recall. The result demonstrates that the U-Nets can consistently produce great recall performance at 92.4% on the test dataset, which is not included in the training, with a 34% reduction in average false positives in comparison to the conventional method. The U-Nets also reduce the time required to identify and separate artifacts by more than 50%. Furthermore, the exclusion of the artifacts shows major changes in the integrated 1D XRD pattern, enhancing further analysis of the post-processing XRD data.", "url": "https://arxiv.org/abs/2310.16186"}, {"metadata": {"arXiv": "2310.16187", "Date": "Tue, 24 Oct 2023 21:13:59 ", "Title": "Efficient deep data assimilation with sparse observations and time-varying sensors", "Authors": ["Sibo Cheng", "Che Liu", "Yike Guo", "Rossella Arcucci"], "Categories": "cs.LG math-ph math.MP"}, "abstract": "Variational Data Assimilation (DA) has been broadly used in engineering problems for field reconstruction and prediction by performing a weighted combination of multiple sources of noisy data. In recent years, the integration of deep learning (DL) techniques in DA has shown promise in improving the efficiency and accuracy in high-dimensional dynamical systems. Nevertheless, existing deep DA approaches face difficulties in dealing with unstructured observation data, especially when the placement and number of sensors are dynamic over time. We introduce a novel variational DA scheme, named Voronoi-tessellation Inverse operator for VariatIonal Data assimilation (VIVID), that incorporates a DL inverse operator into the assimilation objective function. By leveraging the capabilities of the Voronoi-tessellation and convolutional neural networks, VIVID is adept at handling sparse, unstructured, and time-varying sensor data. Furthermore, the incorporation of the DL inverse operator establishes a direct link between observation and state space, leading to a reduction in the number of minimization steps required for DA. Additionally, VIVID can be seamlessly integrated with Proper Orthogonal Decomposition (POD) to develop an end-to-end reduced-order DA scheme, which can further expedite field reconstruction. Numerical experiments in a fluid dynamics system demonstrate that VIVID can significantly outperform existing DA and DL algorithms. The robustness of VIVID is also accessed through the application of various levels of prior error, the utilization of varying numbers of sensors, and the misspecification of error covariance in DA.", "url": "https://arxiv.org/abs/2310.16187"}, {"metadata": {"arXiv": "2310.16194", "Date": "Tue, 24 Oct 2023 21:24:27 ", "Title": "Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights", "Authors": ["Alokendu Mazumder", "Tirthajit Baruah", "Bhartendu Kumar", "Rishab Sharma", "Vishwajeet Pattanaik", "Punit Rathore"], "Categories": "cs.LG cs.CV eess.IV", "Comments": ["Accepted @ IEEE/CVF WACV 2024"]}, "abstract": "The autoencoder is an unsupervised learning paradigm that aims to create a compact latent representation of data by minimizing the reconstruction loss. However, it tends to overlook the fact that most data (images) are embedded in a lower-dimensional space, which is crucial for effective data representation. To address this limitation, we propose a novel approach called Low-Rank Autoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to adaptively reconstruct a low-dimensional latent space while preserving the basic objective of an autoencoder. This helps embed the data in a lower-dimensional space while preserving important information. It is a simple autoencoder extension that learns low-rank latent space. Theoretically, we establish a tighter error bound for our model. Empirically, our model's superiority shines through various tasks such as image generation and downstream classification. Both theoretical and practical outcomes highlight the importance of acquiring low-dimensional embeddings.", "url": "https://arxiv.org/abs/2310.16194"}, {"metadata": {"arXiv": "2310.16209", "Date": "Tue, 24 Oct 2023 21:53:50 ", "Title": "ELM Ridge Regression Boosting", "Authors": ["M. Andrecut"], "Categories": "cs.LG", "Comments": ["6 pages", "2 figures"]}, "abstract": "We discuss a boosting approach for the Ridge Regression (RR) method, with applications to the Extreme Learning Machine (ELM), and we show that the proposed method significantly improves the classification performance and robustness of ELMs.", "url": "https://arxiv.org/abs/2310.16209"}, {"metadata": {"arXiv": "2310.16228", "Date": "Tue, 24 Oct 2023 22:54:05 ", "Title": "On the Foundations of Shortcut Learning", "Authors": ["Katherine L. Hermann", "Hossein Mobahi", "Thomas Fel", "Michael C. Mozer"], "Categories": "cs.LG cs.CV"}, "abstract": "Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on predictivity-how reliably a feature indicates train-set labels-but also on availability-how easily the feature can be extracted, or leveraged, from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and quantify a model's shortcut bias-its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less available, more predictive) feature. We find that linear models are relatively unbiased, but introducing a single hidden layer with ReLU or Tanh units yields a bias. Our empirical findings are consistent with a theoretical account based on Neural Tangent Kernels. Finally, we study how models used in practice trade off predictivity and availability in naturalistic datasets, discovering availability manipulations which increase models' degree of shortcut bias. Taken together, these findings suggest that the propensity to learn shortcut features is a fundamental characteristic of deep nonlinear architectures warranting systematic study given its role in shaping how models solve tasks.", "url": "https://arxiv.org/abs/2310.16228"}, {"metadata": {"arXiv": "2310.16231", "Date": "Tue, 24 Oct 2023 22:59:56 ", "Title": "Attention-Based Ensemble Pooling for Time Series Forecasting", "Authors": ["Dhruvit Patel and Alexander Wikner"], "Categories": "cs.LG nlin.CD", "Comments": ["9 pages", "5 figures"]}, "abstract": "A common technique to reduce model bias in time-series forecasting is to use an ensemble of predictive models and pool their output into an ensemble forecast. In cases where each predictive model has different biases, however, it is not always clear exactly how each model forecast should be weighed during this pooling. We propose a method for pooling that performs a weighted average over candidate model forecasts, where the weights are learned by an attention-based ensemble pooling model. We test this method on two time-series forecasting problems: multi-step forecasting of the dynamics of the non-stationary Lorenz `63 equation, and one-step forecasting of the weekly incident deaths due to COVID-19. We find that while our model achieves excellent valid times when forecasting the non-stationary Lorenz `63 equation, it does not consistently perform better than the existing ensemble pooling when forecasting COVID-19 weekly incident deaths.", "url": "https://arxiv.org/abs/2310.16231"}, {"metadata": {"arXiv": "2310.16241", "Date": "Tue, 24 Oct 2023 23:29:46 ", "Title": "Task Grouping for Automated Multi-Task Machine Learning via Task Affinity Prediction", "Authors": ["Afiya Ayman", "Ayan Mukhopadhyay", "Aron Laszka"], "Categories": "cs.LG"}, "abstract": "When a number of similar tasks have to be learned simultaneously, multi-task learning (MTL) models can attain significantly higher accuracy than single-task learning (STL) models. However, the advantage of MTL depends on various factors, such as the similarity of the tasks, the sizes of the datasets, and so on; in fact, some tasks might not benefit from MTL and may even incur a loss of accuracy compared to STL. Hence, the question arises: which tasks should be learned together? Domain experts can attempt to group tasks together following intuition, experience, and best practices, but manual grouping can be labor-intensive and far from optimal. In this paper, we propose a novel automated approach for task grouping. First, we study the affinity of tasks for MTL using four benchmark datasets that have been used extensively in the MTL literature, focusing on neural network-based MTL models. We identify inherent task features and STL characteristics that can help us to predict whether a group of tasks should be learned together using MTL or if they should be learned independently using STL. Building on this predictor, we introduce a randomized search algorithm, which employs the predictor to minimize the number of MTL trainings performed during the search for task groups. We demonstrate on the four benchmark datasets that our predictor-driven search approach can find better task groupings than existing baseline approaches.", "url": "https://arxiv.org/abs/2310.16241"}, {"metadata": {"arXiv": "2310.16242", "Date": "Tue, 24 Oct 2023 23:30:17 ", "Title": "ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality", "Authors": ["Yonchanok Khaokaew", "Thuc Hanh Nguyen", "Kaixin Ji", "Hiruni Kegalle", "Marwah Alaofi"], "Categories": "cs.LG cs.CL"}, "abstract": "In today's world, sleep quality is pivotal for overall well-being. While wearable sensors offer real-time monitoring, they often lack actionable insights, leading to user abandonment. This paper delves into the role of technology in understanding sleep patterns. We introduce a two-stage framework, utilizing Large Language Models (LLMs), aiming to provide accurate sleep predictions with actionable feedback. Leveraging the GLOBEM dataset and synthetic data from LLMs, we highlight enhanced results with models like XGBoost. Our approach merges advanced machine learning with user-centric design, blending scientific accuracy with practicality.", "url": "https://arxiv.org/abs/2310.16242"}, {"metadata": {"arXiv": "2310.16252", "Date": "Wed, 25 Oct 2023 00:05:37 ", "Title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits", "Authors": ["Arnab Maiti", "Ross Boczar", "Kevin Jamieson", "Lillian J. Ratliff"], "Categories": "cs.LG cs.GT", "Comments": ["22 pages", "5 figures"]}, "abstract": "We study the sample complexity of identifying the pure strategy Nash equilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally, we are given a stochastic model where any learner can sample an entry $(i,j)$ of the input matrix $A\\in[-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where $\\eta$ is a zero-mean 1-sub-Gaussian noise. The aim of the learner is to identify the PSNE of $A$, whenever it exists, with high probability while taking as few samples as possible. Zhou et al. (2017) presents an instance-dependent sample complexity lower bound that depends only on the entries in the row and column in which the PSNE lies. We design a near-optimal algorithm whose sample complexity matches the lower bound, up to log factors. The problem of identifying the PSNE also generalizes the problem of pure exploration in stochastic multi-armed bandits and dueling bandits, and our result matches the optimal bounds, up to log factors, in both the settings.", "url": "https://arxiv.org/abs/2310.16252"}, {"metadata": {"arXiv": "2310.16293", "Date": "Wed, 25 Oct 2023 01:58:37 ", "Title": "Crowd-Certain: Label Aggregation in Crowdsourced and Ensemble Learning Classification", "Authors": ["Mohammad S. Majdi and Jeffrey J. Rodriguez"], "Categories": "cs.LG cs.GT", "Comments": ["49 pages", "5 figures"]}, "abstract": "Crowdsourcing systems have been used to accumulate massive amounts of labeled data for applications such as computer vision and natural language processing. However, because crowdsourced labeling is inherently dynamic and uncertain, developing a technique that can work in most situations is extremely challenging. In this paper, we introduce Crowd-Certain, a novel approach for label aggregation in crowdsourced and ensemble learning classification tasks that offers improved performance and computational efficiency for different numbers of annotators and a variety of datasets. The proposed method uses the consistency of the annotators versus a trained classifier to determine a reliability score for each annotator. Furthermore, Crowd-Certain leverages predicted probabilities, enabling the reuse of trained classifiers on future sample data, thereby eliminating the need for recurrent simulation processes inherent in existing methods. We extensively evaluated our approach against ten existing techniques across ten different datasets, each labeled by varying numbers of annotators. The findings demonstrate that Crowd-Certain outperforms the existing methods (Tao, Sheng, KOS, MACE, MajorityVote, MMSR, Wawa, Zero-Based Skill, GLAD, and Dawid Skene), in nearly all scenarios, delivering higher average accuracy, F1 scores, and AUC rates. Additionally, we introduce a variation of two existing confidence score measurement techniques. Finally we evaluate these two confidence score techniques using two evaluation metrics: Expected Calibration Error (ECE) and Brier Score Loss. Our results show that Crowd-Certain achieves higher Brier Score, and lower ECE across the majority of the examined datasets, suggesting better calibrated results.", "url": "https://arxiv.org/abs/2310.16293"}, {"metadata": {"arXiv": "2310.16302", "Date": "Wed, 25 Oct 2023 02:19:19 ", "Title": "Imperfect Digital Twin Assisted Low Cost Reinforcement Training for Multi-UAV Networks", "Authors": ["Xiucheng Wang", "Nan Cheng", "Longfei Ma", "Zhisheng Yin", "Tom. Luan", "Ning Lu"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Deep Reinforcement Learning (DRL) is widely used to optimize the performance of multi-UAV networks. However, the training of DRL relies on the frequent interactions between the UAVs and the environment, which consumes lots of energy due to the flying and communication of UAVs in practical experiments. Inspired by the growing digital twin (DT) technology, which can simulate the performance of algorithms in the digital space constructed by coping features of the physical space, the DT is introduced to reduce the costs of practical training, e.g., energy and hardware purchases. Different from previous DT-assisted works with an assumption of perfect reflecting real physics by virtual digital, we consider an imperfect DT model with deviations for assisting the training of multi-UAV networks. Remarkably, to trade off the training cost, DT construction cost, and the impact of deviations of DT on training, the natural and virtually generated UAV mixing deployment method is proposed. Two cascade neural networks (NN) are used to optimize the joint number of virtually generated UAVs, the DT construction cost, and the performance of multi-UAV networks. These two NNs are trained by unsupervised and reinforcement learning, both low-cost label-free training methods. Simulation results show the training cost can significantly decrease while guaranteeing the training performance. This implies that an efficient decision can be made with imperfect DTs in multi-UAV networks.", "url": "https://arxiv.org/abs/2310.16302"}, {"metadata": {"arXiv": "2310.16310", "Date": "Wed, 25 Oct 2023 02:37:51 ", "Title": "Score Matching-based Pseudolikelihood Estimation of Neural Marked Spatio-Temporal Point Process with Uncertainty Quantification", "Authors": ["Zichong Li", "Qunzhi Xu", "Zhenghao Xu", "Yajun Mei", "Tuo Zhao", "Hongyuan Zha"], "Categories": "cs.LG"}, "abstract": "Spatio-temporal point processes (STPPs) are potent mathematical tools for modeling and predicting events with both temporal and spatial features. Despite their versatility, most existing methods for learning STPPs either assume a restricted form of the spatio-temporal distribution, or suffer from inaccurate approximations of the intractable integral in the likelihood training objective. These issues typically arise from the normalization term of the probability density function. Moreover, current techniques fail to provide uncertainty quantification for model predictions, such as confidence intervals for the predicted event's arrival time and confidence regions for the event's location, which is crucial given the considerable randomness of the data. To tackle these challenges, we introduce SMASH: a Score MAtching-based pSeudolikeliHood estimator for learning marked STPPs with uncertainty quantification. Specifically, our framework adopts a normalization-free objective by estimating the pseudolikelihood of marked STPPs through score-matching and offers uncertainty quantification for the predicted event time, location and mark by computing confidence regions over the generated samples. The superior performance of our proposed framework is demonstrated through extensive experiments in both event prediction and uncertainty quantification.", "url": "https://arxiv.org/abs/2310.16310"}, {"metadata": {"arXiv": "2310.16314", "Date": "Wed, 25 Oct 2023 02:41:50 ", "Title": "Understanding Code Semantics: An Evaluation of Transformer Models in Summarization", "Authors": ["Debanjan Mondal", "Abhilasha Lodha", "Ankita Sahoo", "Beena Kumari"], "Categories": "cs.LG", "Comments": ["All authors are co-first authors and have equal contributions"]}, "abstract": "This paper delves into the intricacies of code summarization using advanced transformer-based language models. Through empirical studies, we evaluate the efficacy of code summarization by altering function and variable names to explore whether models truly understand code semantics or merely rely on textual cues. We have also introduced adversaries like dead code and commented code across three programming languages (Python, Javascript, and Java) to further scrutinize the model's understanding. Ultimately, our research aims to offer valuable insights into the inner workings of transformer-based LMs, enhancing their ability to understand code and contributing to more efficient software development practices and maintenance workflows.", "url": "https://arxiv.org/abs/2310.16314"}, {"metadata": {"arXiv": "2310.16331", "Date": "Wed, 25 Oct 2023 03:27:43 ", "Title": "Brain-Inspired Reservoir Computing Using Memristors with Tunable Dynamics and Short-Term Plasticity", "Authors": ["Nicholas X. Armendarez", "Ahmed S. Mohamed", "Anurag Dhungel", "Md Razuan Hossain", "Md Sakib Hasan", "Joseph S. Najem"], "Categories": "cs.LG"}, "abstract": "Recent advancements in reservoir computing research have created a demand for analog devices with dynamics that can facilitate the physical implementation of reservoirs, promising faster information processing while consuming less energy and occupying a smaller area footprint. Studies have demonstrated that dynamic memristors, with nonlinear and short-term memory dynamics, are excellent candidates as information-processing devices or reservoirs for temporal classification and prediction tasks. Previous implementations relied on nominally identical memristors that applied the same nonlinear transformation to the input data, which is not enough to achieve a rich state space. To address this limitation, researchers either diversified the data encoding across multiple memristors or harnessed the stochastic device-to-device variability among the memristors. However, this approach requires additional pre-processing steps and leads to synchronization issues. Instead, it is preferable to encode the data once and pass it through a reservoir layer consisting of memristors with distinct dynamics. Here, we demonstrate that ion-channel-based memristors with voltage-dependent dynamics can be controllably and predictively tuned through voltage or adjustment of the ion channel concentration to exhibit diverse dynamic properties. We show, through experiments and simulations, that reservoir layers constructed with a small number of distinct memristors exhibit significantly higher predictive and classification accuracies with a single data encoding. We found that for a second-order nonlinear dynamical system prediction task, the varied memristor reservoir experimentally achieved a normalized mean square error of 0.0015 using only five distinct memristors. Moreover, in a neural activity classification task, a reservoir of just three distinct memristors experimentally attained an accuracy of 96.5%.", "url": "https://arxiv.org/abs/2310.16331"}, {"metadata": {"arXiv": "2310.16332", "Date": "Wed, 25 Oct 2023 03:28:37 ", "Title": "Corrupting Neuron Explanations of Deep Visual Features", "Authors": ["Divyansh Srivastava", "Tuomas Oikarinen", "Tsui-Wei Weng"], "Categories": "cs.LG", "Journal-ref": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023, pp. 1877-1886"}, "abstract": "The inability of DNNs to explain their black-box behavior has led to a recent surge of explainability methods. However, there are growing concerns that these explainability methods are not robust and trustworthy. In this work, we perform the first robustness analysis of Neuron Explanation Methods under a unified pipeline and show that these explanations can be significantly corrupted by random noises and well-designed perturbations added to their probing data. We find that even adding small random noise with a standard deviation of 0.02 can already change the assigned concepts of up to 28% neurons in the deeper layers. Furthermore, we devise a novel corruption algorithm and show that our algorithm can manipulate the explanation of more than 80% neurons by poisoning less than 10% of probing data. This raises the concern of trusting Neuron Explanation Methods in real-life safety and fairness critical applications.", "url": "https://arxiv.org/abs/2310.16332"}, {"metadata": {"arXiv": "2310.16335", "Date": "Wed, 25 Oct 2023 03:30:42 ", "Title": "Defense Against Model Extraction Attacks on Recommender Systems", "Authors": ["Sixiao Zhang", "Hongzhi Yin", "Hongxu Chen", "Cheng Long"], "Categories": "cs.LG"}, "abstract": "The robustness of recommender systems has become a prominent topic within the research community. Numerous adversarial attacks have been proposed, but most of them rely on extensive prior knowledge, such as all the white-box attacks or most of the black-box attacks which assume that certain external knowledge is available. Among these attacks, the model extraction attack stands out as a promising and practical method, involving training a surrogate model by repeatedly querying the target model. However, there is a significant gap in the existing literature when it comes to defending against model extraction attacks on recommender systems. In this paper, we introduce Gradient-based Ranking Optimization (GRO), which is the first defense strategy designed to counter such attacks. We formalize the defense as an optimization problem, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model. Since top-k ranking lists are non-differentiable, we transform them into swap matrices which are instead differentiable. These swap matrices serve as input to a student model that emulates the surrogate model's behavior. By back-propagating the loss of the student model, we obtain gradients for the swap matrices. These gradients are used to compute a swap loss, which maximizes the loss of the student model. We conducted experiments on three benchmark datasets to evaluate the performance of GRO, and the results demonstrate its superior effectiveness in defending against model extraction attacks.", "url": "https://arxiv.org/abs/2310.16335"}, {"metadata": {"arXiv": "2310.16336", "Date": "Wed, 25 Oct 2023 03:33:45 ", "Title": "SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process", "Authors": ["Zichong Li", "Yanbo Xu", "Simiao Zuo", "Haoming Jiang", "Chao Zhang", "Tuo Zhao", "Hongyuan Zha"], "Categories": "cs.LG stat.ML"}, "abstract": "Transformer Hawkes process models have shown to be successful in modeling event sequence data. However, most of the existing training methods rely on maximizing the likelihood of event sequences, which involves calculating some intractable integral. Moreover, the existing methods fail to provide uncertainty quantification for model predictions, e.g., confidence intervals for the predicted event's arrival time. To address these issues, we propose SMURF-THP, a score-based method for learning Transformer Hawkes process and quantifying prediction uncertainty. Specifically, SMURF-THP learns the score function of events' arrival time based on a score-matching objective that avoids the intractable computation. With such a learned score function, we can sample arrival time of events from the predictive distribution. This naturally allows for the quantification of uncertainty by computing confidence intervals over the generated samples. We conduct extensive experiments in both event type prediction and uncertainty quantification of arrival time. In all the experiments, SMURF-THP outperforms existing likelihood-based methods in confidence calibration while exhibiting comparable prediction accuracy.", "url": "https://arxiv.org/abs/2310.16336"}, {"metadata": {"arXiv": "2310.16355", "Date": "Wed, 25 Oct 2023 04:32:35 ", "Title": "Redco: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs", "Authors": ["Bowen Tan", "Yun Zhu", "Lijuan Liu", "Hongyi Wang", "Yonghao Zhuang", "Jindong Chen", "Eric Xing", "Zhiting Hu"], "Categories": "cs.LG", "Comments": ["Released under Apache License 2.0 at https://github.com/tanyuqian/redco"]}, "abstract": "The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa. These tools require users' expertise in machine learning systems (MLSys), creating a bottleneck in LLM development, particularly for developers without MLSys background. In this work, we present Redco, a lightweight and user-friendly tool crafted to automate distributed training and inference for LLMs, as well as to simplify ML pipeline development. The design of Redco emphasizes two key aspects. Firstly, to automate model parallism, our study identifies two straightforward rules to generate tensor parallel strategies for any given LLM. Integrating these rules into Redco facilitates effortless distributed LLM training and inference, eliminating the need of additional coding or complex configurations. We demonstrate the effectiveness by applying Redco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to the size of 66B. Secondly, we propose a mechanism that allows for the customization of diverse ML pipelines through the definition of merely three functions, eliminating redundant and formulaic code like multi-host related processing. This mechanism proves adaptable across a spectrum of ML algorithms, from foundational language modeling to complex algorithms like meta-learning and reinforcement learning. Consequently, Redco implementations exhibit much fewer code lines compared to their official counterparts.", "url": "https://arxiv.org/abs/2310.16355"}, {"metadata": {"arXiv": "2310.16363", "Date": "Wed, 25 Oct 2023 05:04:00 ", "Title": "Finite Time Analysis of Constrained Actor Critic and Constrained Natural Actor Critic Algorithms", "Authors": ["Prashansa Panda", "Shalabh Bhatnagar"], "Categories": "cs.LG"}, "abstract": "Actor Critic methods have found immense applications on a wide range of Reinforcement Learning tasks especially when the state-action space is large. In this paper, we consider actor critic and natural actor critic algorithms with function approximation for constrained Markov decision processes (C-MDP) involving inequality constraints and carry out a non-asymptotic analysis for both of these algorithms in a non-i.i.d (Markovian) setting. We consider the long-run average cost criterion where both the objective and the constraint functions are suitable policy-dependent long-run averages of certain prescribed cost functions. We handle the inequality constraints using the Lagrange multiplier method. We prove that these algorithms are guaranteed to find a first-order stationary point (i.e., $\\Vert \\nabla L(\\theta,\\gamma)\\Vert_2^2 \\leq \\epsilon$) of the performance (Lagrange) function $L(\\theta,\\gamma)$, with a sample complexity of $\\mathcal{\\tilde{O}}(\\epsilon^{-2.5})$ in the case of both Constrained Actor Critic (C-AC) and Constrained Natural Actor Critic (C-NAC) algorithms.We also show the results of experiments on a few different grid world settings and observe good empirical performance using both of these algorithms. In particular, for large grid sizes, Constrained Natural Actor Critic shows slightly better results than Constrained Actor Critic while the latter is slightly better for a small grid size.", "url": "https://arxiv.org/abs/2310.16363"}, {"metadata": {"arXiv": "2310.16374", "Date": "Wed, 25 Oct 2023 05:24:23 ", "Title": "Joint Distributional Learning via Cramer-Wold Distance", "Authors": ["Seunghwan An and Jong-June Jeon"], "Categories": "cs.LG stat.ML"}, "abstract": "The assumption of conditional independence among observed variables, primarily used in the Variational Autoencoder (VAE) decoder modeling, has limitations when dealing with high-dimensional datasets or complex correlation structures among observed variables. To address this issue, we introduced the Cramer-Wold distance regularization, which can be computed in a closed-form, to facilitate joint distributional learning for high-dimensional datasets. Additionally, we introduced a two-step learning method to enable flexible prior modeling and improve the alignment between the aggregated posterior and the prior distribution. Furthermore, we provide theoretical distinctions from existing methods within this category. To evaluate the synthetic data generation performance of our proposed approach, we conducted experiments on high-dimensional datasets with multiple categorical variables. Given that many readily available datasets and data science applications involve such datasets, our experiments demonstrate the effectiveness of our proposed methodology.", "url": "https://arxiv.org/abs/2310.16374"}, {"metadata": {"arXiv": "2310.16375", "Date": "Wed, 25 Oct 2023 05:26:33 ", "Title": "DyExplainer: Explainable Dynamic Graph Neural Networks", "Authors": ["Tianchun Wang", "Dongsheng Luo", "Wei Cheng", "Haifeng Chen", "Xiang Zhang"], "Categories": "cs.LG", "Comments": ["9 pages"]}, "abstract": "Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs largely unexplored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring structural relationships and temporal dependencies through a sparse attention technique. To preserve the desired properties of the explanation, such as structural consistency and temporal continuity, we augment our approach with contrastive learning techniques to provide priori-guided regularization. To model longer-term temporal dependencies, we develop a buffer-based live-updating scheme for training. The results of our extensive experiments on various datasets demonstrate the superiority of DyExplainer, not only providing faithful explainability of the model predictions but also significantly improving the model prediction accuracy, as evidenced in the link prediction task.", "url": "https://arxiv.org/abs/2310.16375"}, {"metadata": {"arXiv": "2310.16391", "Date": "Wed, 25 Oct 2023 06:10:57 ", "Title": "Winning Prize Comes from Losing Tickets: Improve Invariant Learning by Exploring Variant Parameters for Out-of-Distribution Generalization", "Authors": ["Zhuo Huang", "Muyang Li", "Li Shen", "Jun Yu", "Chen Gong", "Bo Han", "Tongliang Liu"], "Categories": "cs.LG cs.CV", "Comments": ["27 pages", "9 figures"], "MSC-class": "Computer Vision and Pattern Recognition"}, "abstract": "Out-of-Distribution (OOD) Generalization aims to learn robust models that generalize well to various environments without fitting to distribution-specific features. Recent studies based on Lottery Ticket Hypothesis (LTH) address this problem by minimizing the learning target to find some of the parameters that are critical to the task. However, in OOD problems, such solutions are suboptimal as the learning task contains severe distribution noises, which can mislead the optimization process. Therefore, apart from finding the task-related parameters (i.e., invariant parameters), we propose Exploring Variant parameters for Invariant Learning (EVIL) which also leverages the distribution knowledge to find the parameters that are sensitive to distribution shift (i.e., variant parameters). Once the variant parameters are left out of invariant learning, a robust subnetwork that is resistant to distribution shift can be found. Additionally, the parameters that are relatively stable across distributions can be considered invariant ones to improve invariant learning. By fully exploring both variant and invariant parameters, our EVIL can effectively identify a robust subnetwork to improve OOD generalization. In extensive experiments on integrated testbed: DomainBed, EVIL can effectively and efficiently enhance many popular methods, such as ERM, IRM, SAM, etc.", "url": "https://arxiv.org/abs/2310.16391"}, {"metadata": {"arXiv": "2310.16401", "Date": "Wed, 25 Oct 2023 06:38:24 ", "Title": "Graph Neural Networks with a Distribution of Parametrized Graphs", "Authors": ["See Hian Lee", "Feng Ji", "Kelin Xia and Wee Peng Tay"], "Categories": "cs.LG"}, "abstract": "Traditionally, graph neural networks have been trained using a single observed graph. However, the observed graph represents only one possible realization. In many applications, the graph may encounter uncertainties, such as having erroneous or missing edges, as well as edge weights that provide little informative value. To address these challenges and capture additional information previously absent in the observed graph, we introduce latent variables to parameterize and generate multiple graphs. We obtain the maximum likelihood estimate of the network parameters in an Expectation-Maximization (EM) framework based on the multiple graphs. Specifically, we iteratively determine the distribution of the graphs using a Markov Chain Monte Carlo (MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical experiments demonstrate improvements in performance against baseline models on node classification for heterogeneous graphs and graph regression on chemistry datasets.", "url": "https://arxiv.org/abs/2310.16401"}, {"metadata": {"arXiv": "2310.16412", "Date": "Wed, 25 Oct 2023 06:57:59 ", "Title": "FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness for Semi-Supervised Learning", "Authors": ["Zhuo Huang", "Li Shen", "Jun Yu", "Bo Han", "Tongliang Liu"], "Categories": "cs.LG", "Comments": ["NeurIPS 2023"], "MSC-class": "Machine Learning"}, "abstract": "Semi-Supervised Learning (SSL) has been an effective way to leverage abundant unlabeled data with extremely scarce labeled data. However, most SSL methods are commonly based on instance-wise consistency between different data transformations. Therefore, the label guidance on labeled data is hard to be propagated to unlabeled data. Consequently, the learning process on labeled data is much faster than on unlabeled data which is likely to fall into a local minima that does not favor unlabeled data, leading to sub-optimal generalization performance. In this paper, we propose FlatMatch which minimizes a cross-sharpness measure to ensure consistent learning performance between the two datasets. Specifically, we increase the empirical risk on labeled data to obtain a worst-case model which is a failure case that needs to be enhanced. Then, by leveraging the richness of unlabeled data, we penalize the prediction difference (i.e., cross-sharpness) between the worst-case model and the original model so that the learning direction is beneficial to generalization on unlabeled data. Therefore, we can calibrate the learning process without being limited to insufficient label information. As a result, the mismatched learning performance can be mitigated, further enabling the effective exploitation of unlabeled data and improving SSL performance. Through comprehensive validation, we show FlatMatch achieves state-of-the-art results in many SSL settings.", "url": "https://arxiv.org/abs/2310.16412"}, {"metadata": {"arXiv": "2310.16453", "Date": "Wed, 25 Oct 2023 08:16:55 ", "Title": "ClearMark: Intuitive and Robust Model Watermarking via Transposed Model Training", "Authors": ["Torsten Krau{\\ss} and Jasper Stang and Alexandra Dmitrienko"], "Categories": "cs.LG", "Comments": ["20 pages", "18 figures", "4 tables"]}, "abstract": "Due to costly efforts during data acquisition and model training, Deep Neural Networks (DNNs) belong to the intellectual property of the model creator. Hence, unauthorized use, theft, or modification may lead to legal repercussions. Existing DNN watermarking methods for ownership proof are often non-intuitive, embed human-invisible marks, require trust in algorithmic assessment that lacks human-understandable attributes, and rely on rigid thresholds, making it susceptible to failure in cases of partial watermark erasure. This paper introduces ClearMark, the first DNN watermarking method designed for intuitive human assessment. ClearMark embeds visible watermarks, enabling human decision-making without rigid value thresholds while allowing technology-assisted evaluations. ClearMark defines a transposed model architecture allowing to use of the model in a backward fashion to interwove the watermark with the main task within all model parameters. Compared to existing watermarking methods, ClearMark produces visual watermarks that are easy for humans to understand without requiring complex verification algorithms or strict thresholds. The watermark is embedded within all model parameters and entangled with the main task, exhibiting superior robustness. It shows an 8,544-bit watermark capacity comparable to the strongest existing work. Crucially, ClearMark's effectiveness is model and dataset-agnostic, and resilient against adversarial model manipulations, as demonstrated in a comprehensive study performed with four datasets and seven architectures.", "url": "https://arxiv.org/abs/2310.16453"}, {"metadata": {"arXiv": "2310.16466", "Date": "Wed, 25 Oct 2023 08:44:05 ", "Title": "Learning Continuous Network Emerging Dynamics from Scarce Observations via Data-Adaptive Stochastic Processes", "Authors": ["Jiaxu Cui", "Bingyi Sun", "Jiming Liu", "Bo Yang"], "Categories": "cs.LG stat.ME", "Comments": ["preprint"]}, "abstract": "Learning network dynamics from the empirical structure and spatio-temporal observation data is crucial to revealing the interaction mechanisms of complex networks in a wide range of domains. However, most existing methods only aim at learning network dynamic behaviors generated by a specific ordinary differential equation instance, resulting in ineffectiveness for new ones, and generally require dense observations. The observed data, especially from network emerging dynamics, are usually difficult to obtain, which brings trouble to model learning. Therefore, how to learn accurate network dynamics with sparse, irregularly-sampled, partial, and noisy observations remains a fundamental challenge. We introduce Neural ODE Processes for Network Dynamics (NDP4ND), a new class of stochastic processes governed by stochastic data-adaptive network dynamics, to overcome the challenge and learn continuous network dynamics from scarce observations. Intensive experiments conducted on various network dynamics in ecological population evolution, phototaxis movement, brain activity, epidemic spreading, and real-world empirical systems, demonstrate that the proposed method has excellent data adaptability and computational efficiency, and can adapt to unseen network emerging dynamics, producing accurate interpolation and extrapolation with reducing the ratio of required observation data to only about 6\\% and improving the learning speed for new dynamics by three orders of magnitude.", "url": "https://arxiv.org/abs/2310.16466"}, {"metadata": {"arXiv": "2310.16473", "Date": "Wed, 25 Oct 2023 08:53:51 ", "Title": "Symphony of experts: orchestration with adversarial insights in reinforcement learning", "Authors": ["Matthieu Jonckheere (LAAS)", "Chiara Mignacco (LMO", "CELESTE)", "Gilles Stoltz (LMO", "CELESTE)"], "Categories": "cs.LG stat.ML"}, "abstract": "Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model.", "url": "https://arxiv.org/abs/2310.16473"}, {"metadata": {"arXiv": "2310.16485", "Date": "Wed, 25 Oct 2023 09:13:19 ", "Title": "A Comprehensive Python Library for Deep Learning-Based Event Detection in Multivariate Time Series Data and Information Retrieval in NLP", "Authors": ["Menouar Azib", "Benjamin Renard", "Philippe Garnier", "Vincent G\\'enot", "Nicolas Andr\\'e"], "Categories": "cs.LG", "Comments": ["Accepted for the 22nd International Conference on Machine Learning and Applications (ICMLA)"]}, "abstract": "Event detection in time series data is crucial in various domains, including finance, healthcare, cybersecurity, and science. Accurately identifying events in time series data is vital for making informed decisions, detecting anomalies, and predicting future trends. Despite extensive research exploring diverse methods for event detection in time series, with deep learning approaches being among the most advanced, there is still room for improvement and innovation in this field. In this paper, we present a new deep learning supervised method for detecting events in multivariate time series data. Our method combines four distinct novelties compared to existing deep-learning supervised methods. Firstly, it is based on regression instead of binary classification. Secondly, it does not require labeled datasets where each point is labeled; instead, it only requires reference events defined as time points or intervals of time. Thirdly, it is designed to be robust by using a stacked ensemble learning meta-model that combines deep learning models, ranging from classic feed-forward neural networks (FFNs) to state-of-the-art architectures like transformers. This ensemble approach can mitigate individual model weaknesses and biases, resulting in more robust predictions. Finally, to facilitate practical implementation, we have developed a Python package to accompany our proposed method. The package, called eventdetector-ts, can be installed through the Python Package Index (PyPI). In this paper, we present our method and provide a comprehensive guide on the usage of the package. We showcase its versatility and effectiveness through different real-world use cases from natural language processing (NLP) to financial security domains.", "url": "https://arxiv.org/abs/2310.16485"}, {"metadata": {"arXiv": "2310.16487", "Date": "Wed, 25 Oct 2023 09:17:25 ", "Title": "Hyperparameter Optimization for Multi-Objective Reinforcement Learning", "Authors": ["Florian Felten", "Daniel Gareev", "El-Ghazali Talbi", "Gr\\'egoire Danoy"], "Categories": "cs.LG", "Comments": ["Presented at the MODeM workshop https://modem2023.vub.ac.be/#"]}, "abstract": "Reinforcement learning (RL) has emerged as a powerful approach for tackling complex problems. The recent introduction of multi-objective reinforcement learning (MORL) has further expanded the scope of RL by enabling agents to make trade-offs among multiple objectives. This advancement not only has broadened the range of problems that can be tackled but also created numerous opportunities for exploration and advancement. Yet, the effectiveness of RL agents heavily relies on appropriately setting their hyperparameters. In practice, this task often proves to be challenging, leading to unsuccessful deployments of these techniques in various instances. Hence, prior research has explored hyperparameter optimization in RL to address this concern. This paper presents an initial investigation into the challenge of hyperparameter optimization specifically for MORL. We formalize the problem, highlight its distinctive challenges, and propose a systematic methodology to address it. The proposed methodology is applied to a well-known environment using a state-of-the-art MORL algorithm, and preliminary results are reported. Our findings indicate that the proposed methodology can effectively provide hyperparameter configurations that significantly enhance the performance of MORL agents. Furthermore, this study identifies various future research opportunities to further advance the field of hyperparameter optimization for MORL.", "url": "https://arxiv.org/abs/2310.16487"}, {"metadata": {"arXiv": "2310.16491", "Date": "Wed, 25 Oct 2023 09:19:40 ", "Title": "TSONN: Time-stepping-oriented neural network for solving partial differential equations", "Authors": ["Wenbo Cao", "Weiwei Zhang"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Deep neural networks (DNNs), especially physics-informed neural networks (PINNs), have recently become a new popular method for solving forward and inverse problems governed by partial differential equations (PDEs). However, these methods still face challenges in achieving stable training and obtaining correct results in many problems, since minimizing PDE residuals with PDE-based soft constraint make the problem ill-conditioned. Different from all existing methods that directly minimize PDE residuals, this work integrates time-stepping method with deep learning, and transforms the original ill-conditioned optimization problem into a series of well-conditioned sub-problems over given pseudo time intervals. The convergence of model training is significantly improved by following the trajectory of the pseudo time-stepping process, yielding a robust optimization-based PDE solver. Our results show that the proposed method achieves stable training and correct results in many problems that standard PINNs fail to solve, requiring only a simple modification on the loss function. In addition, we demonstrate several novel properties and advantages of time-stepping methods within the framework of neural network-based optimization approach, in comparison to traditional grid-based numerical method. Specifically, explicit scheme allows significantly larger time step, while implicit scheme can be implemented as straightforwardly as explicit scheme.", "url": "https://arxiv.org/abs/2310.16491"}, {"metadata": {"arXiv": "2310.16496", "Date": "Wed, 25 Oct 2023 09:30:22 ", "Title": "Citizen participation: crowd-sensed sustainable indoor location services", "Authors": ["Ioannis Nasios", "Konstantinos Vogklis", "Avleen Malhi", "Anastasia Vayona", "Panos Chatziadam and Vasilis Katos"], "Categories": "cs.LG cs.CY", "Comments": ["Preprint submitted to Elsevier"]}, "abstract": "In the present era of sustainable innovation, the circular economy paradigm dictates the optimal use and exploitation of existing finite resources. At the same time, the transition to smart infrastructures requires considerable investment in capital, resources and people. In this work, we present a general machine learning approach for offering indoor location awareness without the need to invest in additional and specialised hardware. We explore use cases where visitors equipped with their smart phone would interact with the available WiFi infrastructure to estimate their location, since the indoor requirement poses a limitation to standard GPS solutions. Results have shown that the proposed approach achieves a less than 2m accuracy and the model is resilient even in the case where a substantial number of BSSIDs are dropped.", "url": "https://arxiv.org/abs/2310.16496"}, {"metadata": {"arXiv": "2310.16499", "Date": "Wed, 25 Oct 2023 09:33:57 ", "Title": "Data Optimization in Deep Learning: A Survey", "Authors": ["Ou Wu and Rujing Yao"], "Categories": "cs.LG"}, "abstract": "Large-scale, high-quality data are considered an essential factor for the successful application of many deep learning techniques. Meanwhile, numerous real-world deep learning tasks still have to contend with the lack of sufficient amounts of high-quality data. Additionally, issues such as model robustness, fairness, and trustworthiness are also closely related to training data. Consequently, a huge number of studies in the existing literature have focused on the data aspect in deep learning tasks. Some typical data optimization techniques include data augmentation, logit perturbation, sample weighting, and data condensation. These techniques usually come from different deep learning divisions and their theoretical inspirations or heuristic motivations may seem unrelated to each other. This study aims to organize a wide range of existing data optimization methodologies for deep learning from the previous literature, and makes the effort to construct a comprehensive taxonomy for them. The constructed taxonomy considers the diversity of split dimensions, and deep sub-taxonomies are constructed for each dimension. On the basis of the taxonomy, connections among the extensive data optimization methods for deep learning are built in terms of four aspects. We probe into rendering several promising and interesting future directions. The constructed taxonomy and the revealed connections will enlighten the better understanding of existing methods and the design of novel data optimization techniques. Furthermore, our aspiration for this survey is to promote data optimization as an independent subdivision of deep learning. A curated, up-to-date list of resources related to data optimization in deep learning is available at \\url{https://github.com/YaoRujing/Data-Optimization}.", "url": "https://arxiv.org/abs/2310.16499"}, {"metadata": {"arXiv": "2310.16520", "Date": "Wed, 25 Oct 2023 10:10:07 ", "Title": "Towards Self-Interpretable Graph-Level Anomaly Detection", "Authors": ["Yixin Liu", "Kaize Ding", "Qinghua Lu", "Fuyi Li", "Leo Yu Zhang", "Shirui Pan"], "Categories": "cs.LG", "Comments": ["23 pages; accepted to NeurIPS 2023"]}, "abstract": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not only measure the abnormality of each graph based on cross-view mutual information but also provide informative graph rationales by extracting bottleneck subgraphs from the input graph and its dual hypergraph in a self-supervised way. Extensive experiments on 16 datasets demonstrate the anomaly detection capability and self-interpretability of SIGNET.", "url": "https://arxiv.org/abs/2310.16520"}, {"metadata": {"arXiv": "2310.16524", "Date": "Wed, 25 Oct 2023 10:18:44 ", "Title": "Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data", "Authors": ["Boris van Breugel", "Nabeel Seedat", "Fergus Imrie", "Mihaela van der Schaar"], "Categories": "cs.LG", "Comments": ["Advances in Neural Information Processing Systems 36 (NeurIPS 2023). Van Breugel & Seedat contributed equally"]}, "abstract": "Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data. In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S Testing outperforms traditional baselines -- including real test data alone -- in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches. Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.", "url": "https://arxiv.org/abs/2310.16524"}, {"metadata": {"arXiv": "2310.16525", "Date": "Wed, 25 Oct 2023 10:19:03 ", "Title": "Cyclic Directed Probabilistic Graphical Model: A Proposal Based on Structured Outcomes", "Authors": ["Oleksii Sirotkin"], "Categories": "cs.LG", "Comments": ["41 pages", "11 figures", "arXiv:2206.06089v1"], "MSC-class": "62H22 (Primary) 05C38, 62H11 (Secondary)", "ACM-class": "G.3; H.1.0"}, "abstract": "In the process of building (structural learning) a probabilistic graphical model from a set of observed data, the directional, cyclic dependencies between the random variables of the model are often found. Existing graphical models such as Bayesian and Markov networks can reflect such dependencies. However, this requires complicating those models, such as adding additional variables or dividing the model graph into separate subgraphs. Herein, we describe a probabilistic graphical model - probabilistic relation network - that allows the direct capture of directional cyclic dependencies during structural learning. This model is based on the simple idea that each sample of the observed data can be represented by an arbitrary graph (structured outcome), which reflects the structure of the dependencies of the variables included in the sample. Each of the outcomes contains only a part of the graphical model structure; however, a complete graph of the probabilistic model is obtained by combining different outcomes. Such a graph, unlike Bayesian and Markov networks, can be directed and can have cycles. We explored the full joint distribution and conditional distribution and conditional independence properties of variables in the proposed model. We defined the algorithms for constructing of the model from the dataset and for calculating the conditional and full joint distributions. We also performed a numerical comparison with Bayesian and Markov networks. This model does not violate the probability axioms, and it supports learning from observed data. Notably, it supports probabilistic inference, making it a prospective tool in data analysis and in expert and design-making applications.", "url": "https://arxiv.org/abs/2310.16525"}, {"metadata": {"arXiv": "2310.16552", "Date": "Wed, 25 Oct 2023 11:10:08 ", "Title": "DECWA : Density-Based Clustering using Wasserstein Distance", "Authors": ["Nabil El Malki", "Robin Cugny", "Olivier Teste", "Franck Ravat"], "Categories": "cs.LG", "Comments": ["6 pages", "CIKM 2020"], "DOI": "10.1145/3340531.3412125"}, "abstract": "Clustering is a data analysis method for extracting knowledge by discovering groups of data called clusters. Among these methods, state-of-the-art density-based clustering methods have proven to be effective for arbitrary-shaped clusters. Despite their encouraging results, they suffer to find low-density clusters, near clusters with similar densities, and high-dimensional data. Our proposals are a new characterization of clusters and a new clustering algorithm based on spatial density and probabilistic approach. First of all, sub-clusters are built using spatial density represented as probability density function ($p.d.f$) of pairwise distances between points. A method is then proposed to agglomerate similar sub-clusters by using both their density ($p.d.f$) and their spatial distance. The key idea we propose is to use the Wasserstein metric, a powerful tool to measure the distance between $p.d.f$ of sub-clusters. We show that our approach outperforms other state-of-the-art density-based clustering methods on a wide variety of datasets.", "url": "https://arxiv.org/abs/2310.16552"}, {"metadata": {"arXiv": "2310.16592", "Date": "Wed, 25 Oct 2023 12:28:20 ", "Title": "Over-the-air Federated Policy Gradient", "Authors": ["Huiwen Yang", "Lingying Huang", "Subhrakanti Dey", "Ling Shi"], "Categories": "cs.LG cs.DC eess.SP"}, "abstract": "In recent years, over-the-air aggregation has been widely considered in large-scale distributed learning, optimization, and sensing. In this paper, we propose the over-the-air federated policy gradient algorithm, where all agents simultaneously broadcast an analog signal carrying local information to a common wireless channel, and a central controller uses the received aggregated waveform to update the policy parameters. We investigate the effect of noise and channel distortion on the convergence of the proposed algorithm, and establish the complexities of communication and sampling for finding an $\\epsilon$-approximate stationary point. Finally, we present some simulation results to show the effectiveness of the algorithm.", "url": "https://arxiv.org/abs/2310.16592"}, {"metadata": {"arXiv": "2310.16602", "Date": "Wed, 25 Oct 2023 12:46:34 ", "Title": "Parcel loss prediction in last-mile delivery: deep and non-deep approaches with insights from Explainable AI", "Authors": ["Jan de Leeuw", "Zaharah Bukhsh", "Yingqian Zhang"], "Categories": "cs.LG"}, "abstract": "Within the domain of e-commerce retail, an important objective is the reduction of parcel loss during the last-mile delivery phase. The ever-increasing availability of data, including product, customer, and order information, has made it possible for the application of machine learning in parcel loss prediction. However, a significant challenge arises from the inherent imbalance in the data, i.e., only a very low percentage of parcels are lost. In this paper, we propose two machine learning approaches, namely, Data Balance with Supervised Learning (DBSL) and Deep Hybrid Ensemble Learning (DHEL), to accurately predict parcel loss. The practical implication of such predictions is their value in aiding e-commerce retailers in optimizing insurance-related decision-making policies. We conduct a comprehensive evaluation of the proposed machine learning models using one year data from Belgian shipments. The findings show that the DHEL model, which combines a feed-forward autoencoder with a random forest, achieves the highest classification performance. Furthermore, we use the techniques from Explainable AI (XAI) to illustrate how prediction models can be used in enhancing business processes and augmenting the overall value proposition for e-commerce retailers in the last mile delivery.", "url": "https://arxiv.org/abs/2310.16602"}, {"metadata": {"arXiv": "2310.16608", "Date": "Wed, 25 Oct 2023 13:02:45 ", "Title": "Performative Prediction: Past and Future", "Authors": ["Moritz Hardt and Celestine Mendler-D\\\"unner"], "Categories": "cs.LG"}, "abstract": "Predictions in the social world generally influence the target of prediction, a phenomenon known as performativity. Self-fulfilling and self-negating predictions are examples of performativity. Of fundamental importance to economics, finance, and the social sciences, the notion has been absent from the development of machine learning. In machine learning applications, performativity often surfaces as distribution shift. A predictive model deployed on a digital platform, for example, influences consumption and thereby changes the data-generating distribution. We survey the recently founded area of performative prediction that provides a definition and conceptual framework to study performativity in machine learning. A consequence of performative prediction is a natural equilibrium notion that gives rise to new optimization challenges. Another consequence is a distinction between learning and steering, two mechanisms at play in performative prediction. The notion of steering is in turn intimately related to questions of power in digital markets. We review the notion of performative power that gives an answer to the question how much a platform can steer participants through its predictions. We end on a discussion of future directions, such as the role that performativity plays in contesting algorithmic systems.", "url": "https://arxiv.org/abs/2310.16608"}, {"metadata": {"arXiv": "2310.16624", "Date": "Wed, 25 Oct 2023 13:23:08 ", "Title": "Free-form Flows: Make Any Architecture a Normalizing Flow", "Authors": ["Felix Draxler", "Peter Sorrenson", "Lea Zimmermann", "Armand Rousselot", "Ullrich K\\\"othe"], "Categories": "cs.LG stat.ML"}, "abstract": "Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing $E(n)$-equivariant networks. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures.", "url": "https://arxiv.org/abs/2310.16624"}, {"metadata": {"arXiv": "2310.16633", "Date": "Wed, 25 Oct 2023 13:33:40 ", "Title": "Photometric Redshifts with Copula Entropy", "Authors": ["Jian Ma"], "Categories": "cs.LG astro-ph.CO astro-ph.IM stat.AP", "Comments": ["15 pages", "7 figures", "1 table"]}, "abstract": "In this paper we propose to apply copula entropy (CE) to photometric redshifts. CE is used to measure the correlations between photometric measurements and redshifts and then the measurements associated with high CEs are selected for predicting redshifts. We verified the proposed method on the SDSS quasar data. Experimental results show that the accuracy of photometric redshifts is improved with the selected measurements compared to the results with all the measurements used in the experiments, especially for the samples with high redshifts. The measurements selected with CE include luminosity magnitude, the brightness in ultraviolet band with standard deviation, and the brightness of the other four bands. Since CE is a rigorously defined mathematical concept, the models such derived is interpretable.", "url": "https://arxiv.org/abs/2310.16633"}, {"metadata": {"arXiv": "2310.16646", "Date": "Wed, 25 Oct 2023 13:55:14 ", "Title": "Model predictive control-based value estimation for efficient reinforcement learning", "Authors": ["Qizhen Wu and Kexin Liu and Lei Chen"], "Categories": "cs.LG"}, "abstract": "Reinforcement learning suffers from limitations in real practices primarily due to the numbers of required interactions with virtual environments. It results in a challenging problem that we are implausible to obtain an optimal strategy only with a few attempts for many learning method. Hereby, we design an improved reinforcement learning method based on model predictive control that models the environment through a data-driven approach. Based on learned environmental model, it performs multi-step prediction to estimate the value function and optimize the policy. The method demonstrates higher learning efficiency, faster convergent speed of strategies tending to the optimal value, and fewer sample capacity space required by experience replay buffers. Experimental results, both in classic databases and in a dynamic obstacle avoidance scenario for unmanned aerial vehicle, validate the proposed approaches.", "url": "https://arxiv.org/abs/2310.16646"}, {"metadata": {"arXiv": "2310.16647", "Date": "Wed, 25 Oct 2023 13:55:35 ", "Title": "Achieving Constraints in Neural Networks: A Stochastic Augmented Lagrangian Approach", "Authors": ["Diogo Lavado", "Cl\\'audia Soares and Alessandra Micheletti"], "Categories": "cs.LG math.OC"}, "abstract": "Regularizing Deep Neural Networks (DNNs) is essential for improving generalizability and preventing overfitting. Fixed penalty methods, though common, lack adaptability and suffer from hyperparameter sensitivity. In this paper, we propose a novel approach to DNN regularization by framing the training process as a constrained optimization problem. Where the data fidelity term is the minimization objective and the regularization terms serve as constraints. Then, we employ the Stochastic Augmented Lagrangian (SAL) method to achieve a more flexible and efficient regularization mechanism. Our approach extends beyond black-box regularization, demonstrating significant improvements in white-box models, where weights are often subject to hard constraints to ensure interpretability. Experimental results on image-based classification on MNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our approach. SAL consistently achieves higher Accuracy while also achieving better constraint satisfaction, thus showcasing its potential for optimizing DNNs under constrained settings.", "url": "https://arxiv.org/abs/2310.16647"}, {"metadata": {"arXiv": "2310.16648", "Date": "Wed, 25 Oct 2023 13:56:02 ", "Title": "Posterior Consistency for Missing Data in Variational Autoencoders", "Authors": ["Timur Sudak", "Sebastian Tschiatschek"], "Categories": "cs.LG stat.ML", "Comments": ["First published in ECML PKDD 2023", "Proceedings", "Part II", "by Springer Nature (https://doi.org/10.1007/978-3-031-43415-0_30). This version of the work has been extended with the addition of an Appendix", "which includes proofs", "the derivation of the posterior regularization", "additional background information on technical topics", "an extended related work section", "and additional experimental results"]}, "abstract": "We consider the problem of learning Variational Autoencoders (VAEs), i.e., a type of deep generative model, from data with missing values. Such data is omnipresent in real-world applications of machine learning because complete data is often impossible or too costly to obtain. We particularly focus on improving a VAE's amortized posterior inference, i.e., the encoder, which in the case of missing data can be susceptible to learning inconsistent posterior distributions regarding the missingness. To this end, we provide a formal definition of posterior consistency and propose an approach for regularizing an encoder's posterior distribution which promotes this consistency. We observe that the proposed regularization suggests a different training objective than that typically considered in the literature when facing missing values. Furthermore, we empirically demonstrate that our regularization leads to improved performance in missing value settings in terms of reconstruction quality and downstream tasks utilizing uncertainty in the latent space. This improved performance can be observed for many classes of VAEs including VAEs equipped with normalizing flows.", "url": "https://arxiv.org/abs/2310.16648"}, {"metadata": {"arXiv": "2310.16652", "Date": "Wed, 25 Oct 2023 14:03:11 ", "Title": "How Robust is Federated Learning to Communication Error? A Comparison Study Between Uplink and Downlink Channels", "Authors": ["Linping Qu", "Shenghui Song", "Chi-Ying Tsui", "and Yuyi Mao"], "Categories": "cs.LG", "Comments": ["Submitted to IEEE for possible publication"]}, "abstract": "Because of its privacy-preserving capability, federated learning (FL) has attracted significant attention from both academia and industry. However, when being implemented over wireless networks, it is not clear how much communication error can be tolerated by FL. This paper investigates the robustness of FL to the uplink and downlink communication error. Our theoretical analysis reveals that the robustness depends on two critical parameters, namely the number of clients and the numerical range of model parameters. It is also shown that the uplink communication in FL can tolerate a higher bit error rate (BER) than downlink communication, and this difference is quantified by a proposed formula. The findings and theoretical analyses are further validated by extensive experiments.", "url": "https://arxiv.org/abs/2310.16652"}, {"metadata": {"arXiv": "2310.16655", "Date": "Wed, 25 Oct 2023 14:09:53 ", "Title": "Towards Control-Centric Representations in Reinforcement Learning from Images", "Authors": ["Chen Liu", "Hongyu Zang", "Xin Li", "Yong Heng", "Yifei Wang", "Zhen Fang", "Yisen Wang", "Mingzhong Wang"], "Categories": "cs.LG"}, "abstract": "Image-based Reinforcement Learning is a practical yet challenging task. A major hurdle lies in extracting control-centric representations while disregarding irrelevant information. While approaches that follow the bisimulation principle exhibit the potential in learning state representations to address this issue, they still grapple with the limited expressive capacity of latent dynamics and the inadaptability to sparse reward environments. To address these limitations, we introduce ReBis, which aims to capture control-centric information by integrating reward-free control information alongside reward-specific knowledge. ReBis utilizes a transformer architecture to implicitly model the dynamics and incorporates block-wise masking to eliminate spatiotemporal redundancy. Moreover, ReBis combines bisimulation-based loss with asymmetric reconstruction loss to prevent feature collapse in environments with sparse rewards. Empirical studies on two large benchmarks, including Atari games and DeepMind Control Suit, demonstrate that ReBis has superior performance compared to existing methods, proving its effectiveness.", "url": "https://arxiv.org/abs/2310.16655"}, {"metadata": {"arXiv": "2310.16678", "Date": "Wed, 25 Oct 2023 14:43:03 ", "Title": "Robust and Actively Secure Serverless Collaborative Learning", "Authors": ["Olive Franzese", "Adam Dziedzic", "Christopher A. Choquette-Choo", "Mark R. Thomas", "Muhammad Ahmad Kaleem", "Stephan Rabanser", "Congyu Fang", "Somesh Jha", "Nicolas Papernot", "Xiao Wang"], "Categories": "cs.LG cs.CR", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "Collaborative machine learning (ML) is widely used to enable institutions to learn better models from distributed data. While collaborative approaches to learning intuitively protect user data, they remain vulnerable to either the server, the clients, or both, deviating from the protocol. Indeed, because the protocol is asymmetric, a malicious server can abuse its power to reconstruct client data points. Conversely, malicious clients can corrupt learning with malicious updates. Thus, both clients and servers require a guarantee when the other cannot be trusted to fully cooperate. In this work, we propose a peer-to-peer (P2P) learning scheme that is secure against malicious servers and robust to malicious clients. Our core contribution is a generic framework that transforms any (compatible) algorithm for robust aggregation of model updates to the setting where servers and clients can act maliciously. Finally, we demonstrate the computational efficiency of our approach even with 1-million parameter models trained by 100s of peers on standard datasets.", "url": "https://arxiv.org/abs/2310.16678"}, {"metadata": {"arXiv": "2310.16696", "Date": "Wed, 25 Oct 2023 15:06:57 ", "Title": "Interpretable time series neural representation for classification purposes", "Authors": ["Etienne Le Naour", "Ghislain Agoua", "Nicolas Baskiotis", "Vincent Guigue"], "Categories": "cs.LG", "Comments": ["International Conference on Data Science and Advanced Analytics (DSAA) 2023"]}, "abstract": "Deep learning has made significant advances in creating efficient representations of time series data by automatically identifying complex patterns. However, these approaches lack interpretability, as the time series is transformed into a latent vector that is not easily interpretable. On the other hand, Symbolic Aggregate approximation (SAX) methods allow the creation of symbolic representations that can be interpreted but do not capture complex patterns effectively. In this work, we propose a set of requirements for a neural representation of univariate time series to be interpretable. We propose a new unsupervised neural architecture that meets these requirements. The proposed model produces consistent, discrete, interpretable, and visualizable representations. The model is learned independently of any downstream tasks in an unsupervised setting to ensure robustness. As a demonstration of the effectiveness of the proposed model, we propose experiments on classification tasks using UCR archive datasets. The obtained results are extensively compared to other interpretable models and state-of-the-art neural representation learning models. The experiments show that the proposed model yields, on average better results than other interpretable approaches on multiple datasets. We also present qualitative experiments to asses the interpretability of the approach.", "url": "https://arxiv.org/abs/2310.16696"}, {"metadata": {"arXiv": "2310.16705", "Date": "Wed, 25 Oct 2023 15:20:53 ", "Title": "Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference", "Authors": ["Dai Hai Nguyen", "Tetsuya Sakurai", "Hiroshi Mamitsuka"], "Categories": "cs.LG stat.ML"}, "abstract": "Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \\textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theoretical analyses.", "url": "https://arxiv.org/abs/2310.16705"}, {"metadata": {"arXiv": "2310.16727", "Date": "Wed, 25 Oct 2023 15:55:50 ", "Title": "AI Hazard Management: A framework for the systematic management of root causes for AI risks", "Authors": ["Ronald Schnitzer", "Andreas Hapfelmeier", "Sven Gaube", "Sonja Zillner"], "Categories": "cs.LG"}, "abstract": "Recent advancements in the field of Artificial Intelligence (AI) establish the basis to address challenging tasks. However, with the integration of AI, new risks arise. Therefore, to benefit from its advantages, it is essential to adequately handle the risks associated with AI. Existing risk management processes in related fields, such as software systems, need to sufficiently consider the specifics of AI. A key challenge is to systematically and transparently identify and address AI risks' root causes - also called AI hazards. This paper introduces the AI Hazard Management (AIHM) framework, which provides a structured process to systematically identify, assess, and treat AI hazards. The proposed process is conducted in parallel with the development to ensure that any AI hazard is captured at the earliest possible stage of the AI system's life cycle. In addition, to ensure the AI system's auditability, the proposed framework systematically documents evidence that the potential impact of identified AI hazards could be reduced to a tolerable level. The framework builds upon an AI hazard list from a comprehensive state-of-the-art analysis. Also, we provide a taxonomy that supports the optimal treatment of the identified AI hazards. Additionally, we illustrate how the AIHM framework can increase the overall quality of a power grid AI use case by systematically reducing the impact of identified hazards to an acceptable level.", "url": "https://arxiv.org/abs/2310.16727"}, {"metadata": {"arXiv": "2310.16730", "Date": "Wed, 25 Oct 2023 15:58:51 ", "Title": "MultiPrompter: Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning", "Authors": ["Dong-Ki Kim", "Sungryull Sohn", "Lajanugen Logeswaran", "Dongsub Shim", "Honglak Lee"], "Categories": "cs.LG"}, "abstract": "Recently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL). This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models. However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence. This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters which take turns composing a prompt together. Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts. We test our method on the text-to-image task and show its ability to generate higher-quality images than baselines.", "url": "https://arxiv.org/abs/2310.16730"}, {"metadata": {"arXiv": "2310.16741", "Date": "Wed, 25 Oct 2023 16:17:00 ", "Title": "Stochastic Latent Transformer: Efficient Modelling of Stochastically Forced Zonal Jets", "Authors": ["Ira J. S. Shokar", "Rich R. Kerswell", "Peter H. Haynes"], "Categories": "cs.LG physics.ao-ph physics.flu-dyn", "Comments": ["23 pages", "9 figures"], "MSC-class": "68T07, 37N10, 35R60"}, "abstract": "We introduce the 'Stochastic Latent Transformer', a probabilistic deep learning approach for efficient reduced-order modelling of stochastic partial differential equations (SPDEs). Despite recent advances in deep learning for fluid mechanics, limited research has explored modelling stochastically driven flows - which play a crucial role in understanding a broad spectrum of phenomena, from jets on giant planets to ocean circulation and the variability of midlatitude weather. The model architecture consists of a stochastically-forced transformer, paired with a translation-equivariant autoencoder, that we demonstrate is capable of reproducing system dynamics across various integration periods. We demonstrate its effectiveness applied to a well-researched zonal jet system, with the neural network achieving a five-order-of-magnitude speedup compared to numerical integration. This facilitates the cost-effective generation of large ensembles, enabling the exploration of statistical questions concerning probabilities of spontaneous transition events.", "url": "https://arxiv.org/abs/2310.16741"}, {"metadata": {"arXiv": "2310.16752", "Date": "Wed, 25 Oct 2023 16:37:45 ", "Title": "Simple, Scalable and Effective Clustering via One-Dimensional Projections", "Authors": ["Moses Charikar", "Monika Henzinger", "Lunjia Hu", "Maxmilian V\\\"otsch", "Erik Waingarten"], "Categories": "cs.LG cs.DS", "Comments": ["41 pages", "6 figures", "to appear in NeurIPS 2023"]}, "abstract": "Clustering is a fundamental problem in unsupervised machine learning with many applications in data analysis. Popular clustering algorithms such as Lloyd's algorithm and $k$-means++ can take $\\Omega(ndk)$ time when clustering $n$ points in a $d$-dimensional space (represented by an $n\\times d$ matrix $X$) into $k$ clusters. In applications with moderate to large $k$, the multiplicative $k$ factor can become very expensive. We introduce a simple randomized clustering algorithm that provably runs in expected time $O(\\mathrm{nnz}(X) + n\\log n)$ for arbitrary $k$. Here $\\mathrm{nnz}(X)$ is the total number of non-zero entries in the input dataset $X$, which is upper bounded by $nd$ and can be significantly smaller for sparse datasets. We prove that our algorithm achieves approximation ratio $\\smash{\\widetilde{O}(k^4)}$ on any input dataset for the $k$-means objective. We also believe that our theoretical analysis is of independent interest, as we show that the approximation ratio of a $k$-means algorithm is approximately preserved under a class of projections and that $k$-means++ seeding can be implemented in expected $O(n \\log n)$ time in one dimension. Finally, we show experimentally that our clustering algorithm gives a new tradeoff between running time and cluster quality compared to previous state-of-the-art methods for these tasks.", "url": "https://arxiv.org/abs/2310.16752"}, {"metadata": {"arXiv": "2310.16792", "Date": "Wed, 25 Oct 2023 17:24:01 ", "Title": "Learning Independent Program and Architecture Representations for Generalizable Performance Modeling", "Authors": ["Lingda Li", "Thomas Flynn", "Adolfy Hoisie"], "Categories": "cs.LG cs.AR"}, "abstract": "This paper proposes PerfVec, a novel deep learning-based performance modeling framework that learns high-dimensional, independent/orthogonal program and microarchitecture representations. Once learned, a program representation can be used to predict its performance on any microarchitecture, and likewise, a microarchitecture representation can be applied in the performance prediction of any program. Additionally, PerfVec yields a foundation model that captures the performance essence of instructions, which can be directly used by developers in numerous performance modeling related tasks without incurring its training cost. The evaluation demonstrates that PerfVec is more general, efficient, and accurate than previous approaches.", "url": "https://arxiv.org/abs/2310.16792"}, {"metadata": {"arXiv": "2310.16795", "Date": "Wed, 25 Oct 2023 17:24:53 ", "Title": "QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models", "Authors": ["Elias Frantar and Dan Alistarh"], "Categories": "cs.LG"}, "abstract": "Mixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts. For example, the SwitchTransformer-c2048 model has 1.6 trillion parameters, requiring 3.2TB of accelerator memory to run efficiently, which makes practical deployment challenging and expensive. In this paper, we present a solution to this memory problem, in form of a new compression and execution framework called QMoE. Specifically, QMoE consists of a scalable algorithm which accurately compresses trillion-parameter MoEs to less than 1 bit per parameter, in a custom format co-designed with bespoke GPU decoding kernels to facilitate efficient end-to-end compressed inference, with minor runtime overheads relative to uncompressed execution. Concretely, QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss, in less than a day on a single GPU. This enables, for the first time, the execution of a trillion-parameter model on affordable commodity hardware, like a single server with 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead relative to ideal uncompressed inference. The source code and compressed models are available at github.com/IST-DASLab/qmoe.", "url": "https://arxiv.org/abs/2310.16795"}, {"metadata": {"arXiv": "2310.16802", "Date": "Wed, 25 Oct 2023 17:32:23 ", "Title": "From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction", "Authors": ["Nima Shoghi", "Adeesh Kolluru", "John R. Kitchin", "Zachary W. Ulissi", "C. Lawrence Zitnick", "Brandon M. Wood"], "Categories": "cs.LG"}, "abstract": "Foundation models have been transformational in machine learning fields such as natural language processing and computer vision. Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains. To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simultaneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework. Our combined training dataset consists of $\\sim$120M systems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP demonstrates an average improvement of 59% over training from scratch, and matches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks.", "url": "https://arxiv.org/abs/2310.16802"}, {"metadata": {"arXiv": "2310.16804", "Date": "Wed, 25 Oct 2023 17:35:01 ", "Title": "Learning COVID-19 Regional Transmission Using Universal Differential Equations in a SIR model", "Authors": ["Adrian Rojas-Campos", "Lukas Stelz", "Pascal Nieters"], "Categories": "cs.LG physics.soc-ph", "Comments": ["18 pages"]}, "abstract": "Highly-interconnected societies difficult to model the spread of infectious diseases such as COVID-19. Single-region SIR models fail to account for incoming forces of infection and expanding them to a large number of interacting regions involves many assumptions that do not hold in the real world. We propose using Universal Differential Equations (UDEs) to capture the influence of neighboring regions and improve the model's predictions in a combined SIR+UDE model. UDEs are differential equations totally or partially defined by a deep neural network (DNN). We include an additive term to the SIR equations composed by a DNN that learns the incoming force of infection from the other regions. The learning is performed using automatic differentiation and gradient descent to approach the change in the target system caused by the state of the neighboring regions. We compared the proposed model using a simulated COVID-19 outbreak against a single-region SIR and a fully data-driven model composed only of a DNN. The proposed UDE+SIR model generates predictions that capture the outbreak dynamic more accurately, but a decay in performance is observed at the last stages of the outbreak. The single-area SIR and the fully data-driven approach do not capture the proper dynamics accurately. Once the predictions were obtained, we employed the SINDy algorithm to substitute the DNN with a regression, removing the black box element of the model with no considerable increase in the error levels.", "url": "https://arxiv.org/abs/2310.16804"}, {"metadata": {"arXiv": "2310.16791", "Date": "Wed, 25 Oct 2023 17:23:57 ", "Title": "Covert Planning against Imperfect Observers", "Authors": ["Haoxiang Ma", "Chongyang Shi", "Shuo Han", "Michael R. Dorothy", "and Jie Fu"], "Categories": "cs.MA cs.LG"}, "abstract": "Covert planning refers to a class of constrained planning problems where an agent aims to accomplish a task with minimal information leaked to a passive observer to avoid detection. However, existing methods of covert planning often consider deterministic environments or do not exploit the observer's imperfect information. This paper studies how covert planning can leverage the coupling of stochastic dynamics and the observer's imperfect observation to achieve optimal task performance without being detected. Specifically, we employ a Markov decision process to model the interaction between the agent and its stochastic environment, and a partial observation function to capture the leaked information to a passive observer. Assuming the observer employs hypothesis testing to detect if the observation deviates from a nominal policy, the covert planning agent aims to maximize the total discounted reward while keeping the probability of being detected as an adversary below a given threshold. We prove that finite-memory policies are more powerful than Markovian policies in covert planning. Then, we develop a primal-dual proximal policy gradient method with a two-time-scale update to compute a (locally) optimal covert policy. We demonstrate the effectiveness of our methods using a stochastic gridworld example. Our experimental results illustrate that the proposed method computes a policy that maximizes the adversary's expected reward without violating the detection constraint, and empirically demonstrates how the environmental noises can influence the performance of the covert policies.", "url": "https://arxiv.org/abs/2310.16791"}, {"metadata": {"arXiv": "2310.16362", "Date": "Wed, 25 Oct 2023 05:00:21 ", "Title": "Neural Potential Field for Obstacle-Aware Local Motion Planning", "Authors": ["Muhammad Alhaddad", "Konstantin Mironov", "Aleksey Staroverov", "Aleksandr Panov"], "Categories": "cs.RO cs.LG"}, "abstract": "Model predictive control (MPC) may provide local motion planning for mobile robotic platforms. The challenging aspect is the analytic representation of collision cost for the case when both the obstacle map and robot footprint are arbitrary. We propose a Neural Potential Field: a neural network model that returns a differentiable collision cost based on robot pose, obstacle map, and robot footprint. The differentiability of our model allows its usage within the MPC solver. It is computationally hard to solve problems with a very high number of parameters. Therefore, our architecture includes neural image encoders, which transform obstacle maps and robot footprints into embeddings, which reduce problem dimensionality by two orders of magnitude. The reference data for network training are generated based on algorithmic calculation of a signed distance function. Comparative experiments showed that the proposed approach is comparable with existing local planners: it provides trajectories with outperforming smoothness, comparable path length, and safe distance from obstacles. Experiment on Husky UGV mobile robot showed that our approach allows real-time and safe local planning. The code for our approach is presented at https://github.com/cog-isa/NPField together with demo video.", "url": "https://arxiv.org/abs/2310.16362"}, {"metadata": {"arXiv": "2310.16659", "Date": "Wed, 25 Oct 2023 14:21:22 ", "Title": "UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent Reinforcement Learning", "Authors": ["Qizhen Wu and Lei Chen and Kexin Liu and Jinhu Lv"], "Categories": "cs.RO cs.LG"}, "abstract": "Multi-agent reinforcement learning based methods are significant for online planning of feasible and safe paths for agents in dynamic and uncertain scenarios. Although some methods like fully centralized and fully decentralized methods achieve a certain measure of success, they also encounter problems such as dimension explosion and poor convergence, respectively. In this paper, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning to solve the dynamic obstacle avoidance problem online. In this approach, each agent communicates only with the central planner or only with its neighbors, respectively, to plan feasible and safe paths online. We improve our methods based on the idea of model predictive control to increase the training efficiency and sample utilization of agents. The experimental results in both simulation, indoor, and outdoor environments validate the effectiveness of our method. The video is available at https://www.bilibili.com/video/BV1gw41197hV/?vd_source=9de61aecdd9fb684e546d032ef7fe7bf", "url": "https://arxiv.org/abs/2310.16659"}, {"metadata": {"arXiv": "2310.16688", "Date": "Wed, 25 Oct 2023 14:50:15 ", "Title": "Learning-based adaption of robotic friction models", "Authors": ["Philipp Scholl", "Maged Iskandar", "Sebastian Wolf", "Jinoh Lee", "Aras Bacho", "Alexander Dietrich", "Alin Albu-Sch\\\"affer and Gitta Kutyniok"], "Categories": "cs.RO cs.LG"}, "abstract": "In the Fourth Industrial Revolution, wherein artificial intelligence and the automation of machines occupy a central role, the deployment of robots is indispensable. However, the manufacturing process using robots, especially in collaboration with humans, is highly intricate. In particular, modeling the friction torque in robotic joints is a longstanding problem due to the lack of a good mathematical description. This motivates the usage of data-driven methods in recent works. However, model-based and data-driven models often exhibit limitations in their ability to generalize beyond the specific dynamics they were trained on, as we demonstrate in this paper. To address this challenge, we introduce a novel approach based on residual learning, which aims to adapt an existing friction model to new dynamics using as little data as possible. We validate our approach by training a base neural network on a symmetric friction data set to learn an accurate relation between the velocity and the friction torque. Subsequently, to adapt to more complex asymmetric settings, we train a second network on a small dataset, focusing on predicting the residual of the initial network's output. By combining the output of both networks in a suitable manner, our proposed estimator outperforms the conventional model-based approach and the base neural network significantly. Furthermore, we evaluate our method on trajectories involving external loads and still observe a substantial improvement, approximately 60-70\\%, over the conventional approach. Our method does not rely on data with external load during training, eliminating the need for external torque sensors. This demonstrates the generalization capability of our approach, even with a small amount of data-only 43 seconds of a robot movement-enabling adaptation to diverse scenarios based on prior knowledge about friction in different settings.", "url": "https://arxiv.org/abs/2310.16688"}, {"metadata": {"arXiv": "2310.16360", "Date": "Wed, 25 Oct 2023 04:52:16 ", "Title": "A Comprehensive Review of AI-enabled Unmanned Aerial Vehicle: Trends, Vision , and Challenges", "Authors": ["Osim Kumar Pal", "Md Sakib Hossain Shovon", "M. F. Mridha and Jungpil Shin"], "Categories": "cs.AI cs.RO"}, "abstract": "In recent years, the combination of artificial intelligence (AI) and unmanned aerial vehicles (UAVs) has brought about advancements in various areas. This comprehensive analysis explores the changing landscape of AI-powered UAVs and friendly computing in their applications. It covers emerging trends, futuristic visions, and the inherent challenges that come with this relationship. The study examines how AI plays a role in enabling navigation, detecting and tracking objects, monitoring wildlife, enhancing precision agriculture, facilitating rescue operations, conducting surveillance activities, and establishing communication among UAVs using environmentally conscious computing techniques. By delving into the interaction between AI and UAVs, this analysis highlights the potential for these technologies to revolutionise industries such as agriculture, surveillance practices, disaster management strategies, and more. While envisioning possibilities, it also takes a look at ethical considerations, safety concerns, regulatory frameworks to be established, and the responsible deployment of AI-enhanced UAV systems. By consolidating insights from research endeavours in this field, this review provides an understanding of the evolving landscape of AI-powered UAVs while setting the stage for further exploration in this transformative domain.", "url": "https://arxiv.org/abs/2310.16360"}, {"metadata": {"arXiv": "2310.16379", "Date": "Wed, 25 Oct 2023 05:38:38 ", "Title": "Evaluating General-Purpose AI with Psychometrics", "Authors": ["Xiting Wang", "Liming Jiang", "Jose Hernandez-Orallo", "Luning Sun", "David Stillwell", "Fang Luo", "Xing Xie"], "Categories": "cs.AI cs.CY", "Comments": ["Work in progress"]}, "abstract": "Artificial intelligence (AI) has witnessed an evolution from task-specific to general-purpose systems that trend toward human versatility. As AI systems begin to play pivotal roles in society, it is important to ensure that they are adequately evaluated. Current AI benchmarks typically assess performance on collections of specific tasks. This has drawbacks when used for assessing general-purpose AI systems. First, it is difficult to predict whether AI systems could complete a new task it has never seen or that did not previously exist. Second, these benchmarks often focus on overall performance metrics, potentially overlooking the finer details crucial for making informed decisions. Lastly, there are growing concerns about the reliability of existing benchmarks and questions about what is being measured. To solve these challenges, this paper suggests that psychometrics, the science of psychological measurement, should be placed at the core of evaluating general-purpose AI. Psychometrics provides a rigorous methodology for identifying and measuring the latent constructs that underlie performance across multiple tasks. We discuss its merits, warn against potential pitfalls, and propose a framework for putting it into practice. Finally, we explore future opportunities to integrate psychometrics with AI.", "url": "https://arxiv.org/abs/2310.16379"}, {"metadata": {"arXiv": "2310.16419", "Date": "Wed, 25 Oct 2023 07:13:06 ", "Title": "Open Knowledge Base Canonicalization with Multi-task Unlearning", "Authors": ["Bingchen Liu", "Shihao Hou", "Weixin Zeng", "Xiang Zhao", "Shijun Liu", "Li Pan"], "Categories": "cs.AI"}, "abstract": "The construction of large open knowledge bases (OKBs) is integral to many applications in the field of mobile computing. Noun phrases and relational phrases in OKBs often suffer from redundancy and ambiguity, which calls for the investigation on OKB canonicalization. However, in order to meet the requirements of some privacy protection regulations and to ensure the timeliness of the data, the canonicalized OKB often needs to remove some sensitive information or outdated data. The machine unlearning in OKB canonicalization is an excellent solution to the above problem. Current solutions address OKB canonicalization by devising advanced clustering algorithms and using knowledge graph embedding (KGE) to further facilitate the canonicalization process. Effective schemes are urgently needed to fully synergise machine unlearning with clustering and KGE learning. To this end, we put forward a multi-task unlearning framework, namely MulCanon, to tackle machine unlearning problem in OKB canonicalization. Specifically, the noise characteristics in the diffusion model are utilized to achieve the effect of machine unlearning for data in OKB. MulCanon unifies the learning objectives of diffusion model, KGE and clustering algorithms, and adopts a two-step multi-task learning paradigm for training. A thorough experimental study on popular OKB canonicalization datasets validates that MulCanon achieves advanced machine unlearning effects.", "url": "https://arxiv.org/abs/2310.16419"}, {"metadata": {"arXiv": "2310.16421", "Date": "Wed, 25 Oct 2023 07:20:16 ", "Title": "Graph Agent: Explicit Reasoning Agent for Graphs", "Authors": ["Qinyong Wang", "Zhenxiang Gao", "Rong Xu"], "Categories": "cs.AI"}, "abstract": "Graph embedding methods such as Graph Neural Networks (GNNs) and Graph Transformers have contributed to the development of graph reasoning algorithms for various tasks on knowledge graphs. However, the lack of interpretability and explainability of graph embedding methods has limited their applicability in scenarios requiring explicit reasoning. In this paper, we introduce the Graph Agent (GA), an intelligent agent methodology of leveraging large language models (LLMs), inductive-deductive reasoning modules, and long-term memory for knowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning and existing graph embedding methods to provide an innovative approach for complex graph reasoning tasks. By converting graph structures into textual data, GA enables LLMs to process, reason, and provide predictions alongside human-interpretable explanations. The effectiveness of the GA was evaluated on node classification and link prediction tasks. Results showed that GA reached state-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and 89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to existing GNN and transformer models, GA offered advantages of explicit reasoning ability, free-of-training, easy adaption to various graph reasoning tasks", "url": "https://arxiv.org/abs/2310.16421"}, {"metadata": {"arXiv": "2310.16581", "Date": "Wed, 25 Oct 2023 12:13:40 ", "Title": "Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing", "Authors": ["Marco Ant\\^onio Athayde de Aguiar Vieira", "Anderson Rocha Tavares", "Renato Perez Ribas"], "Categories": "cs.AI"}, "abstract": "Board games are a great source of entertainment for all ages, as they create a competitive and engaging environment, as well as stimulating learning and strategic thinking. It is common for digital versions of board games, as any other type of digital games, to offer the option to select the difficulty of the game. This is usually done by customizing the search parameters of the AI algorithm. However, this approach cannot be extended to General Game Playing agents, as different games might require different parametrization for each difficulty level. In this paper, we present a general approach to implement an artificial intelligence opponent with difficulty levels for zero-sum games, together with a propose of a Minimax-MCTS hybrid algorithm, which combines the minimax search process with GGP aspects of MCTS. This approach was tested in our mobile application LoBoGames, an extensible board games platform, that is intended to have an broad catalog of games, with an emphasis on accessibility: the platform is friendly to visually-impaired users, and is compatible with more than 92\\% of Android devices. The tests in this work indicate that both the hybrid Minimax-MCTS and the new difficulty adjustment system are promising GGP approaches that could be expanded in future work.", "url": "https://arxiv.org/abs/2310.16581"}, {"metadata": {"arXiv": "2310.16704", "Date": "Wed, 25 Oct 2023 15:20:05 ", "Title": "Human-centred explanation of rule-based decision-making systems in the legal domain", "Authors": ["Suzan Zuurmond", "AnneMarie Borg", "Matthijs van Kempen and Remi Wieten"], "Categories": "cs.AI cs.HC", "Comments": ["This is the full version of a demo at the 36th International Conference on Legal Knowledge and Information Systems (JURIX'23)"]}, "abstract": "We propose a human-centred explanation method for rule-based automated decision-making systems in the legal domain. Firstly, we establish a conceptual framework for developing explanation methods, representing its key internal components (content, communication and adaptation) and external dependencies (decision-making system, human recipient and domain). Secondly, we propose an explanation method that uses a graph database to enable question-driven explanations and multimedia display. This way, we can tailor the explanation to the user. Finally, we show how our conceptual framework is applicable to a real-world scenario at the Dutch Tax and Customs Administration and implement our explanation method for this scenario.", "url": "https://arxiv.org/abs/2310.16704"}, {"metadata": {"arXiv": "2310.16772", "Date": "Wed, 25 Oct 2023 17:04:11 ", "Title": "AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning", "Authors": ["Kejiang Qian", "Lingjun Mao", "Xin Liang", "Yimin Ding", "Jin Gao", "Xinran Wei", "Ziyi Guo", "Jiajie Li"], "Categories": "cs.AI cs.MA"}, "abstract": "In urban planning, land use readjustment plays a pivotal role in aligning land use configurations with the current demands for sustainable urban development. However, present-day urban planning practices face two main issues. Firstly, land use decisions are predominantly dependent on human experts. Besides, while resident engagement in urban planning can promote urban sustainability and livability, it is challenging to reconcile the diverse interests of stakeholders. To address these challenges, we introduce a Consensus-based Multi-Agent Reinforcement Learning framework for real-world land use readjustment. This framework serves participatory urban planning, allowing diverse intelligent agents as stakeholder representatives to vote for preferred land use types. Within this framework, we propose a novel consensus mechanism in reward design to optimize land utilization through collective decision making. To abstract the structure of the complex urban system, the geographic information of cities is transformed into a spatial graph structure and then processed by graph neural networks. Comprehensive experiments on both traditional top-down planning and participatory planning methods from real-world communities indicate that our computational framework enhances global benefits and accommodates diverse interests, leading to improved satisfaction across different demographic groups. By integrating Multi-Agent Reinforcement Learning, our framework ensures that participatory urban planning decisions are more dynamic and adaptive to evolving community needs and provides a robust platform for automating complex real-world urban planning processes.", "url": "https://arxiv.org/abs/2310.16772"}, {"metadata": {"arXiv": "2310.16148", "Date": "Tue, 24 Oct 2023 19:48:07 ", "Title": "Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites", "Authors": ["Augusto Seben da Rosa", "Frederico Santos de Oliveira", "Anderson da Silva Soares", "Arnaldo Candido Junior"], "Categories": "cs.CV cs.AI", "Comments": ["12 pages", "5 tables and 6 figures"], "ACM-class": "I.2.10"}, "abstract": "Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\\% test accuracy, 0.8\\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second model uses 52k parameters, losing only 3.86\\% test accuracy. We also performed an analysis on ImageNet, where we reached 66.49\\% validation accuracy with 1.6M parameters. We make the code publicly available at: https://github.com/NoSavedDATA/YinYang_CNN.", "url": "https://arxiv.org/abs/2310.16148"}, {"metadata": {"arXiv": "2310.16234", "Date": "Tue, 24 Oct 2023 23:06:29 ", "Title": "Pixel-Level Clustering Network for Unsupervised Image Segmentation", "Authors": ["Cuong Manh Hoang and Byeongkeun Kang"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages"], "Journal-ref": "Engineering Applications of Artificial Intelligence, Volume 127, Part B, 2024", "DOI": "10.1016/j.engappai.2023.107327"}, "abstract": "While image segmentation is crucial in various computer vision applications, such as autonomous driving, grasping, and robot navigation, annotating all objects at the pixel-level for training is nearly impossible. Therefore, the study of unsupervised image segmentation methods is essential. In this paper, we present a pixel-level clustering framework for segmenting images into regions without using ground truth annotations. The proposed framework includes feature embedding modules with an attention mechanism, a feature statistics computing module, image reconstruction, and superpixel segmentation to achieve accurate unsupervised segmentation. Additionally, we propose a training strategy that utilizes intra-consistency within each superpixel, inter-similarity/dissimilarity between neighboring superpixels, and structural similarity between images. To avoid potential over-segmentation caused by superpixel-based losses, we also propose a post-processing method. Furthermore, we present an extension of the proposed method for unsupervised semantic segmentation. We conducted experiments on three publicly available datasets (Berkeley segmentation dataset, PASCAL VOC 2012 dataset, and COCO-Stuff dataset) to demonstrate the effectiveness of the proposed framework. The experimental results show that the proposed framework outperforms previous state-of-the-art methods.", "url": "https://arxiv.org/abs/2310.16234"}, {"metadata": {"arXiv": "2310.16400", "Date": "Wed, 25 Oct 2023 06:35:01 ", "Title": "Fuse Your Latents: Video Editing with Multi-source Latent Diffusion Models", "Authors": ["Tianyi Lu", "Xing Zhang", "Jiaxi Gu", "Hang Xu", "Renjing Pei", "Songcen Xu", "Zuxuan Wu"], "Categories": "cs.CV cs.AI"}, "abstract": "Latent Diffusion Models (LDMs) are renowned for their powerful capabilities in image and video synthesis. Yet, video editing methods suffer from insufficient pre-training data or video-by-video re-training cost. In addressing this gap, we propose FLDM (Fused Latent Diffusion Model), a training-free framework to achieve text-guided video editing by applying off-the-shelf image editing methods in video LDMs. Specifically, FLDM fuses latents from an image LDM and an video LDM during the denoising process. In this way, temporal consistency can be kept with video LDM while high-fidelity from the image LDM can also be exploited. Meanwhile, FLDM possesses high flexibility since both image LDM and video LDM can be replaced so advanced image editing methods such as InstructPix2Pix and ControlNet can be exploited. To the best of our knowledge, FLDM is the first method to adapt off-the-shelf image editing methods into video LDMs for video editing. Extensive quantitative and qualitative experiments demonstrate that FLDM can improve the textual alignment and temporal consistency of edited videos.", "url": "https://arxiv.org/abs/2310.16400"}, {"metadata": {"arXiv": "2310.16430", "Date": "Wed, 25 Oct 2023 07:55:02 ", "Title": "An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing XGBoost and xDeepFM Algorithms", "Authors": ["Weinan Dai", "Yifeng Jiang", "Chengjie Mou", "Chongyu Zhang"], "Categories": "cs.CV cs.AI", "DOI": "10.1145/3627377.3627382"}, "abstract": "Stroke prediction plays a crucial role in preventing and managing this debilitating condition. In this study, we address the challenge of stroke prediction using a comprehensive dataset, and propose an ensemble model that combines the power of XGBoost and xDeepFM algorithms. Our work aims to improve upon existing stroke prediction models by achieving higher accuracy and robustness. Through rigorous experimentation, we validate the effectiveness of our ensemble model using the AUC metric. Through comparing our findings with those of other models in the field, we gain valuable insights into the merits and drawbacks of various approaches. This, in turn, contributes significantly to the progress of machine learning and deep learning techniques specifically in the domain of stroke prediction.", "url": "https://arxiv.org/abs/2310.16430"}, {"metadata": {"arXiv": "2310.16573", "Date": "Wed, 25 Oct 2023 11:58:14 ", "Title": "Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models", "Authors": ["Weijie Chen", "Haoyu Wang", "Shicai Yang", "Lei Zhang", "Wei Wei", "Yanning Zhang", "Luojun Lin", "Di Xie", "Yueting Zhuang"], "Categories": "cs.CV cs.AI cs.MM", "Comments": ["11 pages", "6 figures"]}, "abstract": "We do not pursue a novel method in this paper, but aim to study if a modern text-to-image diffusion model can tailor any task-adaptive image classifier across domains and categories. Existing domain adaptive image classification works exploit both source and target data for domain alignment so as to transfer the knowledge learned from the labeled source data to the unlabeled target data. However, as the development of the text-to-image diffusion model, we wonder if the high-fidelity synthetic data from the text-to-image generator can serve as a surrogate of the source data in real world. In this way, we do not need to collect and annotate the source data for each domain adaptation task in a one-for-one manner. Instead, we utilize only one off-the-shelf text-to-image model to synthesize images with category labels derived from the corresponding text prompts, and then leverage the surrogate data as a bridge to transfer the knowledge embedded in the task-agnostic text-to-image generator to the task-oriented image classifier via domain adaptation. Such a one-for-all adaptation paradigm allows us to adapt anything in the world using only one text-to-image generator as well as the corresponding unlabeled target data. Extensive experiments validate the feasibility of the proposed idea, which even surpasses the state-of-the-art domain adaptation works using the source data collected and annotated in real world.", "url": "https://arxiv.org/abs/2310.16573"}, {"metadata": {"arXiv": "2310.16584", "Date": "Wed, 25 Oct 2023 12:18:00 ", "Title": "Learning to Explain: A Model-Agnostic Framework for Explaining Black Box Models", "Authors": ["Oren Barkan", "Yuval Asher", "Amit Eshel", "Yehonatan Elisha", "Noam Koenigstein"], "Categories": "cs.CV cs.AI"}, "abstract": "We present Learning to Explain (LTX), a model-agnostic framework designed for providing post-hoc explanations for vision models. The LTX framework introduces an \"explainer\" model that generates explanation maps, highlighting the crucial regions that justify the predictions made by the model being explained. To train the explainer, we employ a two-stage process consisting of initial pretraining followed by per-instance finetuning. During both stages of training, we utilize a unique configuration where we compare the explained model's prediction for a masked input with its original prediction for the unmasked input. This approach enables the use of a novel counterfactual objective, which aims to anticipate the model's output using masked versions of the input image. Importantly, the LTX framework is not restricted to a specific model architecture and can provide explanations for both Transformer-based and convolutional models. Through our evaluations, we demonstrate that LTX significantly outperforms the current state-of-the-art in explainability across various metrics.", "url": "https://arxiv.org/abs/2310.16584"}, {"metadata": {"arXiv": "2310.16737", "Date": "Wed, 25 Oct 2023 16:09:40 ", "Title": "Translating Universal Scene Descriptions into Knowledge Graphs for Robotic Environment", "Authors": ["Giang Hoang Nguyen", "Daniel Bessler", "Simon Stelter", "Mihai Pomarlan", "Michael Beetz"], "Categories": "cs.RO cs.AI cs.GR", "Comments": ["6 pages", "3 figures", "ICRA 2024"]}, "abstract": "Robots performing human-scale manipulation tasks require an extensive amount of knowledge about their surroundings in order to perform their actions competently and human-like. In this work, we investigate the use of virtual reality technology as an implementation for robot environment modeling, and present a technique for translating scene graphs into knowledge bases. To this end, we take advantage of the Universal Scene Description (USD) format which is an emerging standard for the authoring, visualization and simulation of complex environments. We investigate the conversion of USD-based environment models into Knowledge Graph (KG) representations that facilitate semantic querying and integration with additional knowledge sources.", "url": "https://arxiv.org/abs/2310.16737"}, {"metadata": {"arXiv": "2310.16410", "Date": "Wed, 25 Oct 2023 06:49:26 ", "Title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero", "Authors": ["Lisa Schut", "Nenad Tomasev", "Tom McGrath", "Demis Hassabis", "Ulrich Paquet", "Been Kim"], "Categories": "cs.AI cs.HC cs.LG stat.ML", "Comments": ["61 pages", "29 figures"]}, "abstract": "Artificial Intelligence (AI) systems have made remarkable progress, attaining super-human performance across various domains. This presents us with an opportunity to further human knowledge and improve human expert performance by leveraging the hidden knowledge encoded within these highly performant AI systems. Yet, this knowledge is often hard to extract, and may be hard to understand or learn from. Here, we show that this is possible by proposing a new method that allows us to extract new chess concepts in AlphaZero, an AI system that mastered the game of chess via self-play without human supervision. Our analysis indicates that AlphaZero may encode knowledge that extends beyond the existing human knowledge, but knowledge that is ultimately not beyond human grasp, and can be successfully learned from. In a human study, we show that these concepts are learnable by top human experts, as four top chess grandmasters show improvements in solving the presented concept prototype positions. This marks an important first milestone in advancing the frontier of human knowledge by leveraging AI; a development that could bear profound implications and help us shape how we interact with AI systems across many AI applications.", "url": "https://arxiv.org/abs/2310.16410"}, {"metadata": {"arXiv": "2310.16686", "Date": "Wed, 25 Oct 2023 14:50:05 ", "Title": "Dynamics Generalisation in Reinforcement Learning via Adaptive Context-Aware Policies", "Authors": ["Michael Beukman", "Devon Jarvis", "Richard Klein", "Steven James", "Benjamin Rosman"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted to NeurIPS 2023"]}, "abstract": "While reinforcement learning has achieved remarkable successes in several domains, its real-world application is limited due to many methods failing to generalise to unfamiliar conditions. In this work, we consider the problem of generalising to new transition dynamics, corresponding to cases in which the environment's response to the agent's actions differs. For example, the gravitational force exerted on a robot depends on its mass and changes the robot's mobility. Consequently, in such cases, it is necessary to condition an agent's actions on extrinsic state information and pertinent contextual information reflecting how the environment responds. While the need for context-sensitive policies has been established, the manner in which context is incorporated architecturally has received less attention. Thus, in this work, we present an investigation into how context information should be incorporated into behaviour learning to improve generalisation. To this end, we introduce a neural network architecture, the Decision Adapter, which generates the weights of an adapter module and conditions the behaviour of an agent on the context information. We show that the Decision Adapter is a useful generalisation of a previously proposed architecture and empirically demonstrate that it results in superior generalisation performance compared to previous approaches in several environments. Beyond this, the Decision Adapter is more robust to irrelevant distractor variables than several alternative methods.", "url": "https://arxiv.org/abs/2310.16686"}, {"metadata": {"arXiv": "2310.16099", "Date": "Tue, 24 Oct 2023 18:03:07 ", "Title": "Anatomically-aware Uncertainty for Semi-supervised Image Segmentation", "Authors": ["Sukesh Adiga V", "Jose Dolz", "Herve Lombaert"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at Medical Image Analysis. Code is available at: $\\href{https://github.com/adigasu/Anatomically-aware_Uncertainty_for_Semi-supervised_Segmentation}{Github}$"]}, "abstract": "Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. A prominent way to exploit unlabeled data is to regularize model predictions. Since the predictions of unlabeled data can be unreliable, uncertainty-aware schemes are typically employed to gradually learn from meaningful and reliable predictions. Uncertainty estimation methods, however, rely on multiple inferences from the model predictions that must be computed for each training step, which is computationally expensive. Moreover, these uncertainty maps capture pixel-wise disparities and do not consider global information. This work proposes a novel method to estimate segmentation uncertainty by leveraging global information from the segmentation masks. More precisely, an anatomically-aware representation is first learnt to model the available segmentation masks. The learnt representation thereupon maps the prediction of a new segmentation into an anatomically-plausible segmentation. The deviation from the plausible segmentation aids in estimating the underlying pixel-level uncertainty in order to further guide the segmentation network. The proposed method consequently estimates the uncertainty using a single inference from our representation, thereby reducing the total computation. We evaluate our method on two publicly available segmentation datasets of left atria in cardiac MRIs and of multiple organs in abdominal CTs. Our anatomically-aware method improves the segmentation accuracy over the state-of-the-art semi-supervised methods in terms of two commonly used evaluation metrics.", "url": "https://arxiv.org/abs/2310.16099"}, {"metadata": {"arXiv": "2310.16457", "Date": "Wed, 25 Oct 2023 08:31:04 ", "Title": "Towards Explainability in Monocular Depth Estimation", "Authors": ["Vasileios Arampatzakis and George Pavlidis and Kyriakos Pantoglou and Nikolaos Mitianoudis and Nikos Papamarkos"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The estimation of depth in two-dimensional images has long been a challenging and extensively studied subject in computer vision. Recently, significant progress has been made with the emergence of Deep Learning-based approaches, which have proven highly successful. This paper focuses on the explainability in monocular depth estimation methods, in terms of how humans perceive depth. This preliminary study emphasizes on one of the most significant visual cues, the relative size, which is prominent in almost all viewed images. We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined. In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end. The results show that a mean accuracy of around 77% across methods is achieved, with some of the methods performing markedly better, thus, indirectly revealing their corresponding potential to uncover monocular depth cues, like relative size.", "url": "https://arxiv.org/abs/2310.16457"}, {"metadata": {"arXiv": "2310.16492", "Date": "Wed, 25 Oct 2023 09:19:45 ", "Title": "On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection", "Authors": ["Sangha Park", "Jisoo Mok", "Dahuin Jung", "Saehyung Lee", "Sungroh Yoon"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Successful detection of Out-of-Distribution (OoD) data is becoming increasingly important to ensure safe deployment of neural networks. One of the main challenges in OoD detection is that neural networks output overconfident predictions on OoD data, make it difficult to determine OoD-ness of data solely based on their predictions. Outlier exposure addresses this issue by introducing an additional loss that encourages low-confidence predictions on OoD data during training. While outlier exposure has shown promising potential in improving OoD detection performance, all previous studies on outlier exposure have been limited to utilizing visual outliers. Drawing inspiration from the recent advancements in vision-language pre-training, this paper venture out to the uncharted territory of textual outlier exposure. First, we uncover the benefits of using textual outliers by replacing real or virtual outliers in the image-domain with textual equivalents. Then, we propose various ways of generating preferable textual outliers. Our extensive experiments demonstrate that generated textual outliers achieve competitive performance on large-scale OoD and hard OoD benchmarks. Furthermore, we conduct empirical analyses of textual outliers to provide primary criteria for designing advantageous textual outliers: near-distribution, descriptiveness, and inclusion of visual semantics.", "url": "https://arxiv.org/abs/2310.16492"}, {"metadata": {"arXiv": "2310.16656", "Date": "Wed, 25 Oct 2023 14:10:08 ", "Title": "A Picture is Worth a Thousand Words: Principled Recaptioning Improves Image Generation", "Authors": ["Eyal Segalis", "Dani Valevski", "Danny Lumen", "Yossi Matias", "Yaniv Leviathan"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Text-to-image diffusion models achieved a remarkable leap in capabilities over the last few years, enabling high-quality and diverse synthesis of images from a textual prompt. However, even the most advanced models often struggle to precisely follow all of the directions in their prompts. The vast majority of these models are trained on datasets consisting of (image, caption) pairs where the images often come from the web, and the captions are their HTML alternate text. A notable example is the LAION dataset, used by Stable Diffusion and other models. In this work we observe that these captions are often of low quality, and argue that this significantly affects the model's capability to understand nuanced semantics in the textual prompts. We show that by relabeling the corpus with a specialized automatic captioning model and training a text-to-image model on the recaptioned dataset, the model benefits substantially across the board. First, in overall image quality: e.g. FID 14.84 vs. the baseline of 17.87, and 64.3% improvement in faithful image generation according to human evaluation. Second, in semantic alignment, e.g. semantic object accuracy 84.34 vs. 78.90, counting alignment errors 1.32 vs. 1.44 and positional alignment 62.42 vs. 57.60. We analyze various ways to relabel the corpus and provide evidence that this technique, which we call RECAP, both reduces the train-inference discrepancy and provides the model with more information per example, increasing sample efficiency and allowing the model to better understand the relations between captions and images.", "url": "https://arxiv.org/abs/2310.16656"}, {"metadata": {"arXiv": "2310.16835", "Date": "Wed, 25 Oct 2023 17:59:26 ", "Title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data", "Authors": ["Quentin Bouniot", "Romaric Audigier", "Ang\\'elique Loesch", "Amaury Habrard"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Published as a conference paper at ICLR 2023"]}, "abstract": "The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources. To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals. In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property. ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images. To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals. When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head. We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data.", "url": "https://arxiv.org/abs/2310.16835"}, {"metadata": {"arXiv": "2310.16062", "Date": "Tue, 24 Oct 2023 09:11:45 ", "Title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained Large Models Fine-Tuning", "Authors": ["Shuoran Jiang", "Qingcai Chen", "Yang Xiang", "Youcheng Pan", "Xiangping Wu"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "The excellent generalization, contextual learning, and emergence abilities in the pre-trained large models (PLMs) handle specific tasks without direct training data, making them the better foundation models in the adversarial domain adaptation (ADA) methods to transfer knowledge learned from the source domain to target domains. However, existing ADA methods fail to account for the confounder properly, which is the root cause of the source data distribution that differs from the target domains. This study proposes an adversarial domain adaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The ADA-CBF includes a PLM as the foundation model for a feature extractor, a domain classifier and a confounder classifier, and they are jointly trained with an adversarial loss. This loss is designed to improve the domain-invariant representation learning by diluting the discrimination in the domain classifier. At the same time, the adversarial loss also balances the confounder distribution among source and unmeasured domains in training. Compared to existing ADA methods, ADA-CBF can correctly identify confounders in domain-invariant features, thereby eliminating the confounder biases in the extracted features from PLMs. The confounder classifier in ADA-CBF is designed as a plug-and-play and can be applied in the confounder measurable, unmeasurable, or partially measurable environments. Empirical results on natural language processing and computer vision downstream tasks show that ADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.", "url": "https://arxiv.org/abs/2310.16062"}, {"metadata": {"arXiv": "2310.16065", "Date": "Tue, 24 Oct 2023 11:33:39 ", "Title": "The Hyperdimensional Transform: a Holographic Representation of Functions", "Authors": ["Pieter Dewulf", "Michiel Stock", "Bernard De Baets"], "Categories": "cs.LG cs.AI"}, "abstract": "Integral transforms are invaluable mathematical tools to map functions into spaces where they are easier to characterize. We introduce the hyperdimensional transform as a new kind of integral transform. It converts square-integrable functions into noise-robust, holographic, high-dimensional representations called hyperdimensional vectors. The central idea is to approximate a function by a linear combination of random functions. We formally introduce a set of stochastic, orthogonal basis functions and define the hyperdimensional transform and its inverse. We discuss general transform-related properties such as its uniqueness, approximation properties of the inverse transform, and the representation of integrals and derivatives. The hyperdimensional transform offers a powerful, flexible framework that connects closely with other integral transforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it provides theoretical foundations and new insights for the field of hyperdimensional computing, a computing paradigm that is rapidly gaining attention for efficient and explainable machine learning algorithms, with potential applications in statistical modelling and machine learning. In addition, we provide straightforward and easily understandable code, which can function as a tutorial and allows for the reproduction of the demonstrated examples, from computing the transform to solving differential equations.", "url": "https://arxiv.org/abs/2310.16065"}, {"metadata": {"arXiv": "2310.16071", "Date": "Tue, 24 Oct 2023 13:53:51 ", "Title": "Grid Frequency Forecasting in University Campuses using Convolutional LSTM", "Authors": ["Aneesh Sathe", "Wen Ren Yang"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "20 figures"]}, "abstract": "The modern power grid is facing increasing complexities, primarily stemming from the integration of renewable energy sources and evolving consumption patterns. This paper introduces an innovative methodology that harnesses Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks to establish robust time series forecasting models for grid frequency. These models effectively capture the spatiotemporal intricacies inherent in grid frequency data, significantly enhancing prediction accuracy and bolstering power grid reliability. The research explores the potential and development of individualized Convolutional LSTM (ConvLSTM) models for buildings within a university campus, enabling them to be independently trained and evaluated for each building. Individual ConvLSTM models are trained on power consumption data for each campus building and forecast the grid frequency based on historical trends. The results convincingly demonstrate the superiority of the proposed models over traditional forecasting techniques, as evidenced by performance metrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated to aggregate insights from the building-specific models, delivering comprehensive forecasts for the entire campus. This approach ensures the privacy and security of power consumption data specific to each building.", "url": "https://arxiv.org/abs/2310.16071"}, {"metadata": {"arXiv": "2310.16119", "Date": "Tue, 24 Oct 2023 18:47:13 ", "Title": "Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations", "Authors": ["Ond\\v{r}ej Kobza", "Jan \\v{C}uhel", "Tommaso Gargiani", "David Herel", "Petr Marek (Faculty of Electrical Engineering", "CTU in Prague)"], "Categories": "cs.LG cs.AI"}, "abstract": "We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize SocialBot Grand Challenge~5. Building upon previous versions of our system, we introduce the NRG Barista and outline several innovative approaches for integrating Barista into our SocialBot, improving the overall conversational experience. Additionally, we extend our SocialBot to support multimodal devices. This paper offers insights into the development of Alquist~5.0, which meets evolving user expectations while maintaining empathetic and knowledgeable conversational abilities across diverse topics.", "url": "https://arxiv.org/abs/2310.16119"}, {"metadata": {"arXiv": "2310.16157", "Date": "Tue, 24 Oct 2023 20:02:02 ", "Title": "Context-aware feature attribution through argumentation", "Authors": ["Jinfeng Zhong", "Elsa Negre"], "Categories": "cs.LG cs.AI cs.IR stat.AP"}, "abstract": "Feature attribution is a fundamental task in both machine learning and data analysis, which involves determining the contribution of individual features or variables to a model's output. This process helps identify the most important features for predicting an outcome. The history of feature attribution methods can be traced back to General Additive Models (GAMs), which extend linear regression models by incorporating non-linear relationships between dependent and independent variables. In recent years, gradient-based methods and surrogate models have been applied to unravel complex Artificial Intelligence (AI) systems, but these methods have limitations. GAMs tend to achieve lower accuracy, gradient-based methods can be difficult to interpret, and surrogate models often suffer from stability and fidelity issues. Furthermore, most existing methods do not consider users' contexts, which can significantly influence their preferences. To address these limitations and advance the current state-of-the-art, we define a novel feature attribution framework called Context-Aware Feature Attribution Through Argumentation (CA-FATA). Our framework harnesses the power of argumentation by treating each feature as an argument that can either support, attack or neutralize a prediction. Additionally, CA-FATA formulates feature attribution as an argumentation procedure, and each computation has explicit semantics, which makes it inherently interpretable. CA-FATA also easily integrates side information, such as users' contexts, resulting in more accurate predictions.", "url": "https://arxiv.org/abs/2310.16157"}, {"metadata": {"arXiv": "2310.16221", "Date": "Tue, 24 Oct 2023 22:24:44 ", "Title": "Hierarchical Randomized Smoothing", "Authors": ["Yan Scholten", "Jan Schuchardt", "Aleksandar Bojchevski", "Stephan G\\\"unnemann"], "Categories": "cs.LG cs.AI cs.CV stat.ML"}, "abstract": "Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both - certifiably robust to perturbations and accurate.", "url": "https://arxiv.org/abs/2310.16221"}, {"metadata": {"arXiv": "2310.16256", "Date": "Wed, 25 Oct 2023 00:20:50 ", "Title": "A Causal Disentangled Multi-Granularity Graph Classification Method", "Authors": ["Yuan Li", "Li Liu", "Penggang Chen", "Youmin Zhang", "Guoyin Wang"], "Categories": "cs.LG cs.AI stat.ME"}, "abstract": "Graph data widely exists in real life, with large amounts of data and complex structures. It is necessary to map graph data to low-dimensional embedding. Graph classification, a critical graph task, mainly relies on identifying the important substructures within the graph. At present, some graph classification methods do not combine the multi-granularity characteristics of graph data. This lack of granularity distinction in modeling leads to a conflation of key information and false correlations within the model. So, achieving the desired goal of a credible and interpretable model becomes challenging. This paper proposes a causal disentangled multi-granularity graph representation learning method (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the important substructures and bias parts within the graph from a multi-granularity perspective. The disentanglement of the CDM-GNN model reveals important and bias parts, forming the foundation for its classification task, specifically, model interpretations. The CDM-GNN model exhibits strong classification performance and generates explanatory outcomes aligning with human cognitive patterns. In order to verify the effectiveness of the model, this paper compares the three real-world datasets MUTAG, PTC, and IMDM-M. Six state-of-the-art models, namely GCN, GAT, Top-k, ASAPool, SUGAR, and SAT are employed for comparison purposes. Additionally, a qualitative analysis of the interpretation results is conducted.", "url": "https://arxiv.org/abs/2310.16256"}, {"metadata": {"arXiv": "2310.16277", "Date": "Wed, 25 Oct 2023 01:17:08 ", "Title": "Bayesian Domain Invariant Learning via Posterior Generalization of Parameter Distributions", "Authors": ["Shiyu Shen", "Bin Pan", "Tianyang Shi", "Tao Li", "Zhenwei Shi"], "Categories": "cs.LG cs.AI"}, "abstract": "Domain invariant learning aims to learn models that extract invariant features over various training domains, resulting in better generalization to unseen target domains. Recently, Bayesian Neural Networks have achieved promising results in domain invariant learning, but most works concentrate on aligning features distributions rather than parameter distributions. Inspired by the principle of Bayesian Neural Network, we attempt to directly learn the domain invariant posterior distribution of network parameters. We first propose a theorem to show that the invariant posterior of parameters can be implicitly inferred by aggregating posteriors on different training domains. Our assumption is more relaxed and allows us to extract more domain invariant information. We also propose a simple yet effective method, named PosTerior Generalization (PTG), that can be used to estimate the invariant parameter distribution. PTG fully exploits variational inference to approximate parameter distributions, including the invariant posterior and the posteriors on training domains. Furthermore, we develop a lite version of PTG for widespread applications. PTG shows competitive performance on various domain generalization benchmarks on DomainBed. Additionally, PTG can use any existing domain generalization methods as its prior, and combined with previous state-of-the-art method the performance can be further improved. Code will be made public.", "url": "https://arxiv.org/abs/2310.16277"}, {"metadata": {"arXiv": "2310.16295", "Date": "Wed, 25 Oct 2023 02:07:39 ", "Title": "Instance-wise Linearization of Neural Network for Model Interpretation", "Authors": ["Zhimin Li", "Shusen Liu", "Kailkhura Bhavya", "Timo Bremer", "Valerio Pascucci"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Neural network have achieved remarkable successes in many scientific fields. However, the interpretability of the neural network model is still a major bottlenecks to deploy such technique into our daily life. The challenge can dive into the non-linear behavior of the neural network, which rises a critical question that how a model use input feature to make a decision. The classical approach to address this challenge is feature attribution, which assigns an important score to each input feature and reveal its importance of current prediction. However, current feature attribution approaches often indicate the importance of each input feature without detail of how they are actually processed by a model internally. These attribution approaches often raise a concern that whether they highlight correct features for a model prediction. For a neural network model, the non-linear behavior is often caused by non-linear activation units of a model. However, the computation behavior of a prediction from a neural network model is locally linear, because one prediction has only one activation pattern. Base on the observation, we propose an instance-wise linearization approach to reformulates the forward computation process of a neural network prediction. This approach reformulates different layers of convolution neural networks into linear matrix multiplication. Aggregating all layers' computation, a prediction complex convolution neural network operations can be described as a linear matrix multiplication $F(x) = W \\cdot x + b$. This equation can not only provides a feature attribution map that highlights the important of the input features but also tells how each input feature contributes to a prediction exactly. Furthermore, we discuss the application of this technique in both supervise classification and unsupervised neural network learning parametric t-SNE dimension reduction.", "url": "https://arxiv.org/abs/2310.16295"}, {"metadata": {"arXiv": "2310.16316", "Date": "Wed, 25 Oct 2023 02:50:10 ", "Title": "Sum-of-Parts Models: Faithful Attributions for Groups of Features", "Authors": ["Weiqiu You", "Helen Qu", "Marco Gatti", "Bhuvnesh Jain", "Eric Wong"], "Categories": "cs.LG cs.AI"}, "abstract": "An explanation of a machine learning model is considered \"faithful\" if it accurately reflects the model's decision-making process. However, explanations such as feature attributions for deep learning are not guaranteed to be faithful, and can produce potentially misleading interpretations. In this work, we develop Sum-of-Parts (SOP), a class of models whose predictions come with grouped feature attributions that are faithful-by-construction. This model decomposes a prediction into an interpretable sum of scores, each of which is directly attributable to a sparse group of features. We evaluate SOP on benchmarks with standard interpretability metrics, and in a case study, we use the faithful explanations from SOP to help astrophysicists discover new knowledge about galaxy formation.", "url": "https://arxiv.org/abs/2310.16316"}, {"metadata": {"arXiv": "2310.16318", "Date": "Wed, 25 Oct 2023 03:03:34 ", "Title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder", "Authors": ["Huiwon Jang", "Jihoon Tack", "Daewon Choi", "Jongheon Jeong", "Jinwoo Shin"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted to NeurIPS 2023. The first two authors contributed equally"]}, "abstract": "Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning techniques. First, we adapt the amortized latent of the Transformer encoder using gradient-based meta-learning to enhance the reconstruction. Then, we maximize the alignment between amortized and adapted latents through task contrastive learning which guides the Transformer encoder to better encode the task-specific knowledge. Our experiment demonstrates the superiority of MetaMAE in the modality-agnostic SSL benchmark (called DABS), significantly outperforming prior baselines. Code is available at https://github.com/alinlab/MetaMAE.", "url": "https://arxiv.org/abs/2310.16318"}, {"metadata": {"arXiv": "2310.16376", "Date": "Wed, 25 Oct 2023 05:27:45 ", "Title": "GADY: Unsupervised Anomaly Detection on Dynamic Graphs", "Authors": ["Shiqi Lou", "Qingyue Zhang", "Shujie Yang", "Yuyang Tian", "Zhaoxuan Tan", "Minnan Luo"], "Categories": "cs.LG cs.AI"}, "abstract": "Anomaly detection on dynamic graphs refers to detecting entities whose behaviors obviously deviate from the norms observed within graphs and their temporal information. This field has drawn increasing attention due to its application in finance, network security, social networks, and more. However, existing methods face two challenges: dynamic structure constructing challenge - difficulties in capturing graph structure with complex time information and negative sampling challenge - unable to construct excellent negative samples for unsupervised learning. To address these challenges, we propose Unsupervised Generative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first challenge, we propose a continuous dynamic graph model to capture the fine-grained information, which breaks the limit of existing discrete methods. Specifically, we employ a message-passing framework combined with positional features to get edge embeddings, which are decoded to identify anomalies. For the second challenge, we pioneer the use of Generative Adversarial Networks to generate negative interactions. Moreover, we design a loss function to alter the training goal of the generator while ensuring the diversity and quality of generated samples. Extensive experiments demonstrate that our proposed GADY significantly outperforms the previous state-of-the-art method on three real-world datasets. Supplementary experiments further validate the effectiveness of our model design and the necessity of each module.", "url": "https://arxiv.org/abs/2310.16376"}, {"metadata": {"arXiv": "2310.16506", "Date": "Wed, 25 Oct 2023 09:47:15 ", "Title": "Identifying Reasons for Bias: An Argumentation-Based Approach", "Authors": ["Madeleine Waller", "Odinaldo Rodrigues", "Oana Cocarascu"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["10 pages"]}, "abstract": "As algorithmic decision-making systems become more prevalent in society, ensuring the fairness of these systems is becoming increasingly important. Whilst there has been substantial research in building fair algorithmic decision-making systems, the majority of these methods require access to the training data, including personal characteristics, and are not transparent regarding which individuals are classified unfairly. In this paper, we propose a novel model-agnostic argumentation-based method to determine why an individual is classified differently in comparison to similar individuals. Our method uses a quantitative argumentation framework to represent attribute-value pairs of an individual and of those similar to them, and uses a well-known semantics to identify the attribute-value pairs in the individual contributing most to their different classification. We evaluate our method on two datasets commonly used in the fairness literature and illustrate its effectiveness in the identification of bias.", "url": "https://arxiv.org/abs/2310.16506"}, {"metadata": {"arXiv": "2310.16546", "Date": "Wed, 25 Oct 2023 10:53:04 ", "Title": "Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion", "Authors": ["Taehyun Cho", "Seungyub Han", "Heesoo Lee", "Kyungjae Lee", "Jungwoo Lee"], "Categories": "cs.LG cs.AI", "Comments": ["NeurIPS 2023"]}, "abstract": "Distributional reinforcement learning algorithms have attempted to utilize estimated uncertainty for exploration, such as optimism in the face of uncertainty. However, using the estimated variance for optimistic exploration may cause biased data collection and hinder convergence or performance. In this paper, we present a novel distributional reinforcement learning algorithm that selects actions by randomizing risk criterion to avoid one-sided tendency on risk. We provide a perturbed distributional Bellman optimality operator by distorting the risk measure and prove the convergence and optimality of the proposed method with the weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and is guaranteed to converge to an optimal return. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including Atari 55 games.", "url": "https://arxiv.org/abs/2310.16546"}, {"metadata": {"arXiv": "2310.16560", "Date": "Wed, 25 Oct 2023 11:28:26 ", "Title": "Label Propagation for Graph Label Noise", "Authors": ["Yao Cheng", "Caihua Shan", "Yifei Shen", "Xiang Li", "Siqiang Luo", "Dongsheng Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Label noise is a common challenge in large datasets, as it can significantly degrade the generalization ability of deep neural networks. Most existing studies focus on noisy labels in computer vision; however, graph models encompass both node features and graph topology as input, and become more susceptible to label noise through message-passing mechanisms. Recently, only a few works have been proposed to tackle the label noise on graphs. One major limitation is that they assume the graph is homophilous and the labels are smoothly distributed. Nevertheless, real-world graphs may contain varying degrees of heterophily or even be heterophily-dominated, leading to the inadequacy of current methods. In this paper, we study graph label noise in the context of arbitrary heterophily, with the aim of rectifying noisy labels and assigning labels to previously unlabeled nodes. We begin by conducting two empirical analyses to explore the impact of graph homophily on graph label noise. Following observations, we propose a simple yet efficient algorithm, denoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three steps: (1) reconstruct the graph to recover the homophily property, (2) utilize label propagation to rectify the noisy labels, (3) select high-confidence labels to retain for the next iteration. By iterating these steps, we obtain a set of correct labels, ultimately achieving high accuracy in the node classification task. The theoretical analysis is also provided to demonstrate its remarkable denoising \"effect\". Finally, we conduct experiments on 10 benchmark datasets under varying graph heterophily levels and noise types, comparing the performance of LP4GLN with 7 typical baselines. Our results illustrate the superior performance of the proposed LP4GLN.", "url": "https://arxiv.org/abs/2310.16560"}, {"metadata": {"arXiv": "2310.16587", "Date": "Wed, 25 Oct 2023 12:22:18 ", "Title": "Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations", "Authors": ["Tsai Hor Chan", "Kin Wai Lau", "Jiajun Shen", "Guosheng Yin", "Lequan Yu"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["NeurIPS 2023"]}, "abstract": "Uncertainty estimation aims to evaluate the confidence of a trained deep neural network. However, existing uncertainty estimation approaches rely on low-dimensional distributional assumptions and thus suffer from the high dimensionality of latent features. Existing approaches tend to focus on uncertainty on discrete classification probabilities, which leads to poor generalizability to uncertainty estimation for other tasks. Moreover, most of the literature requires seeing the out-of-distribution (OOD) data in the training for better estimation of uncertainty, which limits the uncertainty estimation performance in practice because the OOD data are typically unseen. To overcome these limitations, we propose a new framework using data-adaptive high-dimensional hypothesis testing for uncertainty estimation, which leverages the statistical properties of the feature representations. Our method directly operates on latent representations and thus does not require retraining the feature encoder under a modified objective. The test statistic relaxes the feature distribution assumptions to high dimensionality, and it is more discriminative to uncertainties in the latent representations. We demonstrate that encoding features with Bayesian neural networks can enhance testing performance and lead to more accurate uncertainty estimation. We further introduce a family-wise testing procedure to determine the optimal threshold of OOD detection, which minimizes the false discovery rate (FDR). Extensive experiments validate the satisfactory performance of our framework on uncertainty estimation and task-specific prediction over a variety of competitors. The experiments on the OOD detection task also show satisfactory performance of our method when the OOD data are unseen in the training. Codes are available at https://github.com/HKU-MedAI/bnn_uncertainty.", "url": "https://arxiv.org/abs/2310.16587"}, {"metadata": {"arXiv": "2310.16779", "Date": "Wed, 25 Oct 2023 17:11:21 ", "Title": "Multi-scale Diffusion Denoised Smoothing", "Authors": ["Jongheon Jeong", "Jinwoo Shin"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["24 pages; NeurIPS 2023; Code is available at https://github.com/jh-jeong/smoothing-multiscale"]}, "abstract": "Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple \"denoise-and-classify\" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise. Our experiments show that this fine-tuning scheme of diffusion models combined with the multi-scale smoothing enables a strong certified robustness possible at highest noise level while maintaining the accuracy closer to non-smoothed classifiers.", "url": "https://arxiv.org/abs/2310.16779"}, {"metadata": {"arXiv": "2310.16828", "Date": "Wed, 25 Oct 2023 17:57:07 ", "Title": "TD-MPC2: Scalable, Robust World Models for Continuous Control", "Authors": ["Nicklas Hansen", "Hao Su", "Xiaolong Wang"], "Categories": "cs.LG cs.AI cs.CV cs.RO", "Comments": ["Explore videos", "models", "data", "code", "and more at https://nicklashansen.github.io/td-mpc2"]}, "abstract": "TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://nicklashansen.github.io/td-mpc2", "url": "https://arxiv.org/abs/2310.16828"}, {"metadata": {"arXiv": "2310.16837", "Date": "Wed, 25 Oct 2023 17:59:34 ", "Title": "RDBench: ML Benchmark for Relational Databases", "Authors": ["Zizhao Zhang", "Yi Yang", "Lutong Zou", "He Wen", "Tao Feng", "Jiaxuan You"], "Categories": "cs.LG cs.AI cs.DB cs.SI"}, "abstract": "Benefiting from high-quality datasets and standardized evaluation metrics, machine learning (ML) has achieved sustained progress and widespread applications. However, while applying machine learning to relational databases (RDBs), the absence of a well-established benchmark remains a significant obstacle to the development of ML. To address this issue, we introduce ML Benchmark For Relational Databases (RDBench), a standardized benchmark that aims to promote reproducible ML research on RDBs that include multiple tables. RDBench offers diverse RDB datasets of varying scales, domains, and relational structures, organized into 4 levels. Notably, to simplify the adoption of RDBench for diverse ML domains, for any given database, RDBench exposes three types of interfaces including tabular data, homogeneous graphs, and heterogeneous graphs, sharing the same underlying task definition. For the first time, RDBench enables meaningful comparisons between ML methods from diverse domains, ranging from XGBoost to Graph Neural Networks, under RDB prediction tasks. We design multiple classification and regression tasks for each RDB dataset and report averaged results over the same dataset, further enhancing the robustness of the experimental findings. RDBench is implemented with DBGym, a user-friendly platform for ML research and application on databases, enabling benchmarking new ML methods with RDBench at ease.", "url": "https://arxiv.org/abs/2310.16837"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

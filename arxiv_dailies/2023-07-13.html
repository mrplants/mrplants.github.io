<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.05591", "Date": "Mon, 10 Jul 2023 17:59:21 ", "Title": "SITTA: A Semantic Image-Text Alignment for Image Captioning", "Authors": ["Fabian Paischer", "Thomas Adler", "Markus Hofmarcher", "Sepp Hochreiter"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["10 pages (+ references and appendix)", "Code: https://github.com/ml-jku/semantic-image-text-alignment"]}, "abstract": "Textual and semantic comprehension of images is essential for generating proper captions. The comprehension requires detection of objects, modeling of relations between them, an assessment of the semantics of the scene and, finally, representing the extracted knowledge in a language space. To achieve rich language capabilities while ensuring good image-language mappings, pretrained language models (LMs) were conditioned on pretrained multi-modal (image-text) models that allow for image inputs. This requires an alignment of the image representation of the multi-modal model with the language representations of a generative LM. However, it is not clear how to best transfer semantics detected by the vision encoder of the multi-modal model to the LM. We introduce two novel ways of constructing a linear mapping that successfully transfers semantics between the embedding spaces of the two pretrained models. The first aligns the embedding space of the multi-modal language encoder with the embedding space of the pretrained LM via token correspondences. The latter leverages additional data that consists of image-text pairs to construct the mapping directly from vision to language space. Using our semantic mappings, we unlock image captioning for LMs without access to gradient information. By using different sources of data we achieve strong captioning performance on MS-COCO and Flickr30k datasets. Even in the face of limited data, our method partly exceeds the performance of other zero-shot and even finetuned competitors. Our ablation studies show that even LMs at a scale of merely 250M parameters can generate decent captions employing our semantic mappings. Our approach makes image captioning more accessible for institutions with restricted computational resources.", "url": "https://arxiv.org/abs/2307.05591"}, {"metadata": {"arXiv": "2307.05601", "Date": "Mon, 10 Jul 2023 20:28:58 ", "Title": "Unsupervised Domain Adaptation with Deep Neural-Network", "Authors": ["Artem Bituitskii"], "Categories": "cs.CV cs.LG", "Comments": ["Master's thesis", "34 pages", "13 figures"]}, "abstract": "This report contributes to the field of unsupervised domain adaptation by providing an analysis of existing methods, introducing a new approach, and demonstrating the potential for improving visual recognition tasks across different domains. The results of this study open up opportunities for further study and development of advanced methods in the field of domain adaptation.", "url": "https://arxiv.org/abs/2307.05601"}, {"metadata": {"arXiv": "2307.05707", "Date": "Tue, 11 Jul 2023 18:17:50 ", "Title": "MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning", "Authors": ["Julien Nicolas", "Florent Chiaroni", "Imtiaz Ziko", "Ola Ahmad", "Christian Desrosiers", "Jose Dolz"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages", "5 figures"]}, "abstract": "Despite the recent progress in incremental learning, addressing catastrophic forgetting under distributional drift is still an open and important problem. Indeed, while state-of-the-art domain incremental learning (DIL) methods perform satisfactorily within known domains, their performance largely degrades in the presence of novel domains. This limitation hampers their generalizability, and restricts their scalability to more realistic settings where train and test data are drawn from different distributions. To address these limitations, we present a novel DIL approach based on a mixture of prompt-tuned CLIP models (MoP-CLIP), which generalizes the paradigm of S-Prompting to handle both in-distribution and out-of-distribution data at inference. In particular, at the training stage we model the features distribution of every class in each domain, learning individual text and visual prompts to adapt to a given domain. At inference, the learned distributions allow us to identify whether a given test sample belongs to a known domain, selecting the correct prompt for the classification task, or from an unseen domain, leveraging a mixture of the prompt-tuned CLIP models. Our empirical evaluation reveals the poor performance of existing DIL methods under domain shift, and suggests that the proposed MoP-CLIP performs competitively in the standard DIL settings while outperforming state-of-the-art methods in OOD scenarios. These results demonstrate the superiority of MoP-CLIP, offering a robust and general solution to the problem of domain incremental learning.", "url": "https://arxiv.org/abs/2307.05707"}, {"metadata": {"arXiv": "2307.05845", "Date": "Tue, 11 Jul 2023 23:36:49 ", "Title": "PIGEON: Predicting Image Geolocations", "Authors": ["Lukas Haas", "Silas Alberti", "Michal Skreta"], "Categories": "cs.CV cs.LG"}, "abstract": "We introduce PIGEON, a multi-task end-to-end system for planet-scale image geolocalization that achieves state-of-the-art performance on both external benchmarks and in human evaluation. Our work incorporates semantic geocell creation with label smoothing, conducts pretraining of a vision transformer on images with geographic information, and refines location predictions with ProtoNets across a candidate set of geocells. The contributions of PIGEON are three-fold: first, we design a semantic geocells creation and splitting algorithm based on open-source data which can be adapted to any geospatial dataset. Second, we show the effectiveness of intra-geocell refinement and the applicability of unsupervised clustering and ProtNets to the task. Finally, we make our pre-trained CLIP transformer model, StreetCLIP, publicly available for use in adjacent domains with applications to fighting climate change and urban and rural scene understanding.", "url": "https://arxiv.org/abs/2307.05845"}, {"metadata": {"arXiv": "2307.05945", "Date": "Wed, 12 Jul 2023 06:22:51 ", "Title": "YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention", "Authors": ["Raja Sunkara and Tie Luo"], "Categories": "cs.CV cs.LG", "Comments": ["Published in Pattern Recognition (Elsevier)", "July 2023"], "Journal-ref": "Pattern Recognition, vol. 139, pp. 109451, July 2023", "DOI": "10.1016/j.patcog.2023.109451"}, "abstract": "We introduce YOGA, a deep learning based yet lightweight object detection model that can operate on low-end edge devices while still achieving competitive accuracy. The YOGA architecture consists of a two-phase feature learning pipeline with a cheap linear transformation, which learns feature maps using only half of the convolution filters required by conventional convolutional neural networks. In addition, it performs multi-scale feature fusion in its neck using an attention mechanism instead of the naive concatenation used by conventional detectors. YOGA is a flexible model that can be easily scaled up or down by several orders of magnitude to fit a broad range of hardware constraints. We evaluate YOGA on COCO-val and COCO-testdev datasets with other over 10 state-of-the-art object detectors. The results show that YOGA strikes the best trade-off between model size and accuracy (up to 22% increase of AP and 23-34% reduction of parameters and FLOPs), making it an ideal choice for deployment in the wild on low-end edge devices. This is further affirmed by our hardware implementation and evaluation on NVIDIA Jetson Nano.", "url": "https://arxiv.org/abs/2307.05945"}, {"metadata": {"arXiv": "2307.06006", "Date": "Wed, 12 Jul 2023 08:35:24 ", "Title": "What Happens During Finetuning of Vision Transformers: An Invariance Based Investigation", "Authors": ["Gabriele Merlin", "Vedant Nanda", "Ruchit Rawal", "Mariya Toneva"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted to CoLLAs 2023"]}, "abstract": "The pretrain-finetune paradigm usually improves downstream performance over training a model from scratch on the same task, becoming commonplace across many areas of machine learning. While pretraining is empirically observed to be beneficial for a range of tasks, there is not a clear understanding yet of the reasons for this effect. In this work, we examine the relationship between pretrained vision transformers and the corresponding finetuned versions on several benchmark datasets and tasks. We present new metrics that specifically investigate the degree to which invariances learned by a pretrained model are retained or forgotten during finetuning. Using these metrics, we present a suite of empirical findings, including that pretraining induces transferable invariances in shallow layers and that invariances from deeper pretrained layers are compressed towards shallower layers during finetuning. Together, these findings contribute to understanding some of the reasons for the successes of pretrained models and the changes that a pretrained model undergoes when finetuned on a downstream task.", "url": "https://arxiv.org/abs/2307.06006"}, {"metadata": {"arXiv": "2307.06272", "Date": "Wed, 12 Jul 2023 16:16:37 ", "Title": "Exposing the Fake: Effective Diffusion-Generated Images Detection", "Authors": ["Ruipeng Ma", "Jinhao Duan", "Fei Kong", "Xiaoshuang Shi", "Kaidi Xu"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["AdvML-Frontiers@ICML 2023"]}, "abstract": "Image synthesis has seen significant advancements with the advent of diffusion-based generative models like Denoising Diffusion Probabilistic Models (DDPM) and text-to-image diffusion models. Despite their efficacy, there is a dearth of research dedicated to detecting diffusion-generated images, which could pose potential security and privacy risks. This paper addresses this gap by proposing a novel detection method called Stepwise Error for Diffusion-generated Image Detection (SeDID). Comprising statistical-based $\\text{SeDID}_{\\text{Stat}}$ and neural network-based $\\text{SeDID}_{\\text{NNs}}$, SeDID exploits the unique attributes of diffusion models, namely deterministic reverse and deterministic denoising computation errors. Our evaluations demonstrate SeDID's superior performance over existing methods when applied to diffusion models. Thus, our work makes a pivotal contribution to distinguishing diffusion model-generated images, marking a significant step in the domain of artificial intelligence security.", "url": "https://arxiv.org/abs/2307.06272"}, {"metadata": {"arXiv": "2307.06307", "Date": "Wed, 12 Jul 2023 17:09:18 ", "Title": "Facial Reenactment Through a Personalized Generator", "Authors": ["Ariel Elazary", "Yotam Nitzan", "Daniel Cohen-Or"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["Project webpage: https://arielazary.github.io/PGR/"]}, "abstract": "In recent years, the role of image generative models in facial reenactment has been steadily increasing. Such models are usually subject-agnostic and trained on domain-wide datasets. The appearance of the reenacted individual is learned from a single image, and hence, the entire breadth of the individual's appearance is not entirely captured, leading these methods to resort to unfaithful hallucination. Thanks to recent advancements, it is now possible to train a personalized generative model tailored specifically to a given individual. In this paper, we propose a novel method for facial reenactment using a personalized generator. We train the generator using frames from a short, yet varied, self-scan video captured using a simple commodity camera. Images synthesized by the personalized generator are guaranteed to preserve identity. The premise of our work is that the task of reenactment is thus reduced to accurately mimicking head poses and expressions. To this end, we locate the desired frames in the latent space of the personalized generator using carefully designed latent optimization. Through extensive evaluation, we demonstrate state-of-the-art performance for facial reenactment. Furthermore, we show that since our reenactment takes place in a semantic latent space, it can be semantically edited and stylized in post-processing.", "url": "https://arxiv.org/abs/2307.06307"}, {"metadata": {"arXiv": "2307.05517", "Date": "Fri, 07 Jul 2023 09:55:41 ", "Title": "Adaptive Graph Convolution Networks for Traffic Flow Forecasting", "Authors": ["Zhengdao Li", "Wei Li", "and Kai Hwang"], "Categories": "cs.LG"}, "abstract": "Traffic flow forecasting is a highly challenging task due to the dynamic spatial-temporal road conditions. Graph neural networks (GNN) has been widely applied in this task. However, most of these GNNs ignore the effects of time-varying road conditions due to the fixed range of the convolution receptive field. In this paper, we propose a novel Adaptive Graph Convolution Networks (AGC-net) to address this issue in GNN. The AGC-net is constructed by the Adaptive Graph Convolution (AGC) based on a novel context attention mechanism, which consists of a set of graph wavelets with various learnable scales. The AGC transforms the spatial graph representations into time-sensitive features considering the temporal context. Moreover, a shifted graph convolution kernel is designed to enhance the AGC, which attempts to correct the deviations caused by inaccurate topology. Experimental results on two public traffic datasets demonstrate the effectiveness of the AGC-net\\footnote{Code is available at: https://github.com/zhengdaoli/AGC-net} which outperforms other baseline models significantly.", "url": "https://arxiv.org/abs/2307.05517"}, {"metadata": {"arXiv": "2307.05520", "Date": "Fri, 07 Jul 2023 12:07:59 ", "Title": "Do DL models and training environments have an impact on energy consumption?", "Authors": ["Santiago del Rey", "Silverio Mart\\'inez-Fern\\'andez", "Lu\\'is Cruz", "Xavier Franch"], "Categories": "cs.LG cs.CY cs.SE", "Comments": ["49th Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA). 8 pages", "3 figures"]}, "abstract": "Current research in the computer vision field mainly focuses on improving Deep Learning (DL) correctness and inference time performance. However, there is still little work on the huge carbon footprint that has training DL models. This study aims to analyze the impact of the model architecture and training environment when training greener computer vision models. We divide this goal into two research questions. First, we analyze the effects of model architecture on achieving greener models while keeping correctness at optimal levels. Second, we study the influence of the training environment on producing greener models. To investigate these relationships, we collect multiple metrics related to energy efficiency and model correctness during the models' training. Then, we outline the trade-offs between the measured energy efficiency and the models' correctness regarding model architecture, and their relationship with the training environment. We conduct this research in the context of a computer vision system for image classification. In conclusion, we show that selecting the proper model architecture and training environment can reduce energy consumption dramatically (up to 98.83\\%) at the cost of negligible decreases in correctness. Also, we find evidence that GPUs should scale with the models' computational complexity for better energy efficiency.", "url": "https://arxiv.org/abs/2307.05520"}, {"metadata": {"arXiv": "2307.05521", "Date": "Fri, 07 Jul 2023 13:48:50 ", "Title": "Toward High-Performance Energy and Power Battery Cells with Machine Learning-based Optimization of Electrode Manufacturing", "Authors": ["Marc Duquesnoy", "Chaoyue Liu", "Vishank Kumar", "Elixabete Ayerbe", "Alejandro A. Franco"], "Categories": "cs.LG", "Comments": ["17 pages", "5 figures"]}, "abstract": "The optimization of the electrode manufacturing process is important for upscaling the application of Lithium Ion Batteries (LIBs) to cater for growing energy demand. In particular, LIB manufacturing is very important to be optimized because it determines the practical performance of the cells when the latter are being used in applications such as electric vehicles. In this study, we tackled the issue of high-performance electrodes for desired battery application conditions by proposing a powerful data-driven approach supported by a deterministic machine learning (ML)-assisted pipeline for bi-objective optimization of the electrochemical performance. This ML pipeline allows the inverse design of the process parameters to adopt in order to manufacture electrodes for energy or power applications. The latter work is an analogy to our previous work that supported the optimization of the electrode microstructures for kinetic, ionic, and electronic transport properties improvement. An electrochemical pseudo-two-dimensional model is fed with the electrode properties characterizing the electrode microstructures generated by manufacturing simulations and used to simulate the electrochemical performances. Secondly, the resulting dataset was used to train a deterministic ML model to implement fast bi-objective optimizations to identify optimal electrodes. Our results suggested a high amount of active material, combined with intermediate values of solid content in the slurry and calendering degree, to achieve the optimal electrodes.", "url": "https://arxiv.org/abs/2307.05521"}, {"metadata": {"arXiv": "2307.05529", "Date": "Fri, 07 Jul 2023 23:12:16 ", "Title": "Keystroke Dynamics for User Identification", "Authors": ["Atharva Sharma and Martin Jure\\v{c}ek and Mark Stamp"], "Categories": "cs.LG cs.CR"}, "abstract": "In previous research, keystroke dynamics has shown promise for user authentication, based on both fixed-text and free-text data. In this research, we consider the more challenging multiclass user identification problem, based on free-text data. We experiment with a complex image-like feature that has previously been used to achieve state-of-the-art authentication results over free-text data. Using this image-like feature and multiclass Convolutional Neural Networks, we are able to obtain a classification (i.e., identification) accuracy of 0.78 over a set of 148 users. However, we find that a Random Forest classifier trained on a slightly modified version of this same feature yields an accuracy of 0.93.", "url": "https://arxiv.org/abs/2307.05529"}, {"metadata": {"arXiv": "2307.05537", "Date": "Sat, 08 Jul 2023 15:06:48 ", "Title": "NLP Meets RNA: Unsupervised Embedding Learning for Ribozymes with Word2Vec", "Authors": ["Andrew Kean Gao"], "Categories": "cs.LG q-bio.BM", "ACM-class": "I.2.7"}, "abstract": "Ribozymes, RNA molecules with distinct 3D structures and catalytic activity, have widespread applications in synthetic biology and therapeutics. However, relatively little research has focused on leveraging deep learning to enhance our understanding of ribozymes. This study implements Word2Vec, an unsupervised learning technique for natural language processing, to learn ribozyme embeddings. Ribo2Vec was trained on over 9,000 diverse ribozymes, learning to map sequences to 128 and 256-dimensional vector spaces. Using Ribo2Vec, sequence embeddings for five classes of ribozymes (hatchet, pistol, hairpin, hovlinc, and twister sister) were calculated. Principal component analysis demonstrated the ability of these embeddings to distinguish between ribozyme classes. Furthermore, a simple SVM classifier trained on ribozyme embeddings showed promising results in accurately classifying ribozyme types. Our results suggest that the embedding vectors contained meaningful information about ribozymes. Interestingly, 256-dimensional embeddings behaved similarly to 128-dimensional embeddings, suggesting that a lower dimension vector space is generally sufficient to capture ribozyme features. This approach demonstrates the potential of Word2Vec for bioinformatics, opening new avenues for ribozyme research. Future research includes using a Transformer-based method to learn RNA embeddings, which can capture long-range interactions between nucleotides.", "url": "https://arxiv.org/abs/2307.05537"}, {"metadata": {"arXiv": "2307.05551", "Date": "Sun, 09 Jul 2023 09:08:38 ", "Title": "Graph Neural Network-enabled Terahertz-based Flow-guided Nanoscale Localization", "Authors": ["Gerard Calvo Bartra", "Filip Lemic", "Sergi Abadal", "Xavier Costa Perez"], "Categories": "cs.LG cs.ET cs.NI", "Comments": ["6 pages", "5 figures", "1 table", "15 references. arXiv admin note: text overlap with arXiv:2305.18493"]}, "abstract": "Scientific advancements in nanotechnology and advanced materials are paving the way toward nanoscale devices for in-body precision medicine; comprising integrated sensing, computing, communication, data and energy storage capabilities. In the human cardiovascular system, such devices are envisioned to be passively flowing and continuously sensing for detecting events of diagnostic interest. The diagnostic value of detecting such events can be enhanced by assigning to them their physical locations (e.g., body region), which is the main proposition of flow-guided localization. Current flow-guided localization approaches suffer from low localization accuracy and they are by-design unable to localize events within the entire cardiovascular system. Toward addressing this issue, we propose the utilization of Graph Neural Networks (GNNs) for this purpose, and demonstrate localization accuracy and coverage enhancements of our proposal over the existing State of the Art (SotA) approaches. Based on our evaluation, we provide several design guidelines for GNN-enabled flow-guided localization.", "url": "https://arxiv.org/abs/2307.05551"}, {"metadata": {"arXiv": "2307.05596", "Date": "Mon, 10 Jul 2023 19:30:32 ", "Title": "Compositional Generalization from First Principles", "Authors": ["Thadd\\\"aus Wiedemer", "Prasanna Mayilvahanan", "Matthias Bethge", "Wieland Brendel"], "Categories": "cs.LG stat.ML", "Comments": ["9 pages", "5 figures", "submitted to NeurIPS 2023"]}, "abstract": "Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization.", "url": "https://arxiv.org/abs/2307.05596"}, {"metadata": {"arXiv": "2307.05633", "Date": "Tue, 11 Jul 2023 07:48:39 ", "Title": "Transaction Fraud Detection via an Adaptive Graph Neural Network", "Authors": ["Yue Tian", "Guanjun Liu", "Jiacun Wang", "Mengchu Zhou"], "Categories": "cs.LG"}, "abstract": "Many machine learning methods have been proposed to achieve accurate transaction fraud detection, which is essential to the financial security of individuals and banks. However, most existing methods leverage original features only or require manual feature engineering. They lack the ability to learn discriminative representations from transaction data. Moreover, criminals often commit fraud by imitating cardholders' behaviors, which causes the poor performance of existing detection models. In this paper, we propose an Adaptive Sampling and Aggregation-based Graph Neural Network (ASA-GNN) that learns discriminative representations to improve the performance of transaction fraud detection. A neighbor sampling strategy is performed to filter noisy nodes and supplement information for fraudulent nodes. Specifically, we leverage cosine similarity and edge weights to adaptively select neighbors with similar behavior patterns for target nodes and then find multi-hop neighbors for fraudulent nodes. A neighbor diversity metric is designed by calculating the entropy among neighbors to tackle the camouflage issue of fraudsters and explicitly alleviate the over-smoothing phenomena. Extensive experiments on three real financial datasets demonstrate that the proposed method ASA-GNN outperforms state-of-the-art ones.", "url": "https://arxiv.org/abs/2307.05633"}, {"metadata": {"arXiv": "2307.05635", "Date": "Tue, 11 Jul 2023 08:30:50 ", "Title": "Fundamental limits of overparametrized shallow neural networks for supervised learning", "Authors": ["Francesco Camilli", "Daria Tieplova", "Jean Barbier"], "Categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT math.ST stat.TH", "Comments": ["30 pages", "1 figure"], "MSC-class": "68Txx, 68T07"}, "abstract": "We carry out an information-theoretical analysis of a two-layer neural network trained from input-output pairs generated by a teacher network with matching architecture, in overparametrized regimes. Our results come in the form of bounds relating i) the mutual information between training data and network weights, or ii) the Bayes-optimal generalization error, to the same quantities but for a simpler (generalized) linear model for which explicit expressions are rigorously known. Our bounds, which are expressed in terms of the number of training samples, input dimension and number of hidden units, thus yield fundamental performance limits for any neural network (and actually any learning procedure) trained from limited data generated according to our two-layer teacher neural network model. The proof relies on rigorous tools from spin glasses and is guided by ``Gaussian equivalence principles'' lying at the core of numerous recent analyses of neural networks. With respect to the existing literature, which is either non-rigorous or restricted to the case of the learning of the readout weights only, our results are information-theoretic (i.e. are not specific to any learning algorithm) and, importantly, cover a setting where all the network parameters are trained.", "url": "https://arxiv.org/abs/2307.05635"}, {"metadata": {"arXiv": "2307.05735", "Date": "Tue, 11 Jul 2023 19:03:17 ", "Title": "GOKU-UI: Ubiquitous Inference through Attention and Multiple Shooting for Continuous-time Generative Models", "Authors": ["Germ\\'an Abrevaya", "Mahta Ramezanian-Panahi", "Jean-Christophe Gagnon-Audet", "Irina Rish", "Pablo Polosecki", "Silvina Ponce Dawson", "Guillermo Cecchi", "Guillaume Dumas"], "Categories": "cs.LG nlin.CD physics.data-an physics.med-ph"}, "abstract": "Scientific Machine Learning (SciML) is a burgeoning field that synergistically combines domain-aware and interpretable models with agnostic machine learning techniques. In this work, we introduce GOKU-UI, an evolution of the SciML generative model GOKU-nets. The GOKU-UI broadens the original model's spectrum to incorporate other classes of differential equations, such as Stochastic Differential Equations (SDEs), and integrates a distributed, i.e. ubiquitous, inference through attention mechanisms and a novel multiple shooting training strategy in the latent space. These enhancements have led to a significant increase in its performance in both reconstruction and forecast tasks, as demonstrated by our evaluation of simulated and empirical data. Specifically, GOKU-UI outperformed all baseline models on synthetic datasets even with a training set 32-fold smaller, underscoring its remarkable data efficiency. Furthermore, when applied to empirical human brain data, while incorporating stochastic Stuart-Landau oscillators into its dynamical core, it not only surpassed state-of-the-art baseline methods in the reconstruction task, but also demonstrated better prediction of future brain activity up to 12 seconds ahead. By training GOKU-UI on resting-state fMRI data, we encoded whole-brain dynamics into a latent representation, learning an effective low-dimensional dynamical system model that could offer insights into brain functionality and open avenues for practical applications such as mental state or psychiatric condition classification. Ultimately, our research provides further impetus for the field of Scientific Machine Learning, showcasing the potential for advancements when established scientific insights are interwoven with modern machine learning.", "url": "https://arxiv.org/abs/2307.05735"}, {"metadata": {"arXiv": "2307.05772", "Date": "Tue, 11 Jul 2023 20:00:35 ", "Title": "Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning", "Authors": ["Shireen Kudukkil Manchingal", "Muhammad Mubashar", "Kaizheng Wang", "Keivan Shariatmadar", "Fabio Cuzzolin"], "Categories": "cs.LG stat.ML"}, "abstract": "Machine learning is increasingly deployed in safety-critical domains where robustness against adversarial attacks is crucial and erroneous predictions could lead to potentially catastrophic consequences. This highlights the need for learning systems to be equipped with the means to determine a model's confidence in its prediction and the epistemic uncertainty associated with it, 'to know when a model does not know'. In this paper, we propose a novel Random-Set Convolutional Neural Network (RS-CNN) for classification which predicts belief functions rather than probability vectors over the set of classes, using the mathematics of random sets, i.e., distributions over the power set of the sample space. Based on the epistemic deep learning approach, random-set models are capable of representing the 'epistemic' uncertainty induced in machine learning by limited training sets. We estimate epistemic uncertainty by approximating the size of credal sets associated with the predicted belief functions, and experimentally demonstrate how our approach outperforms competing uncertainty-aware approaches in a classical evaluation setting. The performance of RS-CNN is best demonstrated on OOD samples where it manages to capture the true prediction while standard CNNs fail.", "url": "https://arxiv.org/abs/2307.05772"}, {"metadata": {"arXiv": "2307.05775", "Date": "Tue, 11 Jul 2023 20:06:12 ", "Title": "Weisfeiler and Lehman Go Measurement Modeling: Probing the Validity of the WL Test", "Authors": ["Arjun Subramonian", "Adina Williams", "Maximilian Nickel", "Yizhou Sun", "Levent Sagun"], "Categories": "cs.LG cs.SI"}, "abstract": "The expressive power of graph neural networks is usually measured by comparing how many pairs of graphs or nodes an architecture can possibly distinguish as non-isomorphic to those distinguishable by the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test. In this paper, we uncover misalignments between practitioners' conceptualizations of expressive power and $k$-WL through a systematic analysis of the reliability and validity of $k$-WL. We further conduct a survey ($n = 18$) of practitioners to surface their conceptualizations of expressive power and their assumptions about $k$-WL. In contrast to practitioners' opinions, our analysis (which draws from graph theory and benchmark auditing) reveals that $k$-WL does not guarantee isometry, can be irrelevant to real-world graph tasks, and may not promote generalization or trustworthiness. We argue for extensional definitions and measurement of expressive power based on benchmarks; we further contribute guiding questions for constructing such benchmarks, which is critical for progress in graph machine learning.", "url": "https://arxiv.org/abs/2307.05775"}, {"metadata": {"arXiv": "2307.05801", "Date": "Tue, 11 Jul 2023 20:52:46 ", "Title": "Differentiable Forward Projector for X-ray Computed Tomography", "Authors": ["Hyojin Kim and Kyle Champley"], "Categories": "cs.LG cs.CV cs.MS", "Comments": ["ICML 2023 Workshop: Differentiable Almost Everything: Differentiable Relaxations", "Algorithms", "Operators", "and Simulators"]}, "abstract": "Data-driven deep learning has been successfully applied to various computed tomographic reconstruction problems. The deep inference models may outperform existing analytical and iterative algorithms, especially in ill-posed CT reconstruction. However, those methods often predict images that do not agree with the measured projection data. This paper presents an accurate differentiable forward and back projection software library to ensure the consistency between the predicted images and the original measurements. The software library efficiently supports various projection geometry types while minimizing the GPU memory footprint requirement, which facilitates seamless integration with existing deep learning training and inference pipelines. The proposed software is available as open source: https://github.com/LLNL/LEAP.", "url": "https://arxiv.org/abs/2307.05801"}, {"metadata": {"arXiv": "2307.05888", "Date": "Wed, 12 Jul 2023 03:31:34 ", "Title": "Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud Computing Environment", "Authors": ["Ziru Zhang", "Xuling Zhang", "Guangzhi Zhu", "Yuyang Wang and Pan Hui"], "Categories": "cs.LG cs.DC cs.NI"}, "abstract": "In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to empower various areas as a bridge between physical objects and the digital world. Through virtualization and simulation techniques, multiple functions can be achieved by leveraging computing resources. In this process, Mobile Cloud Computing (MCC) and Mobile Edge Computing (MEC) have become two of the key factors to achieve real-time feedback. However, current works only considered edge servers or cloud servers in the DT system models. Besides, The models ignore the DT with not only one data resource. In this paper, we propose a new DT system model considering a heterogeneous MEC/MCC environment. Each DT in the model is maintained in one of the servers via multiple data collection devices. The offloading decision-making problem is also considered and a new offloading scheme is proposed based on Distributed Deep Learning (DDL). Simulation results demonstrate that our proposed algorithm can effectively and efficiently decrease the system's average latency and energy consumption. Significant improvement is achieved compared with the baselines under the dynamic environment of DTs.", "url": "https://arxiv.org/abs/2307.05888"}, {"metadata": {"arXiv": "2307.05906", "Date": "Wed, 12 Jul 2023 04:23:26 ", "Title": "Mini-Batch Optimization of Contrastive Loss", "Authors": ["Jaewoong Cho", "Kartik Sreenivasan", "Keon Lee", "Kyunghoo Mun", "Soheun Yi", "Jeong-Gwan Lee", "Anna Lee", "Jy-yong Sohn", "Dimitris Papailiopoulos", "Kangwook Lee"], "Categories": "cs.LG"}, "abstract": "Contrastive learning has gained significant attention as a method for self-supervised learning. The contrastive loss function ensures that embeddings of positive sample pairs (e.g., different samples from the same class or different views of the same object) are similar, while embeddings of negative pairs are dissimilar. Practical constraints such as large memory requirements make it challenging to consider all possible positive and negative pairs, leading to the use of mini-batch optimization. In this paper, we investigate the theoretical aspects of mini-batch optimization in contrastive learning. We show that mini-batch optimization is equivalent to full-batch optimization if and only if all $\\binom{N}{B}$ mini-batches are selected, while sub-optimality may arise when examining only a subset. We then demonstrate that utilizing high-loss mini-batches can speed up SGD convergence and propose a spectral clustering-based approach for identifying these high-loss mini-batches. Our experimental results validate our theoretical findings and demonstrate that our proposed algorithm outperforms vanilla SGD in practically relevant settings, providing a better understanding of mini-batch optimization in contrastive learning.", "url": "https://arxiv.org/abs/2307.05906"}, {"metadata": {"arXiv": "2307.05915", "Date": "Wed, 12 Jul 2023 04:44:31 ", "Title": "Prompt Generate Train (PGT): A framework for few-shot domain adaptation, alignment, and uncertainty calibration of a retriever augmented generation (RAG) model for domain specific open book question-answering", "Authors": ["C. S. Krishna"], "Categories": "cs.LG", "Comments": ["10"]}, "abstract": "We present a framework - Prompt, Generate, Train (PGT) - to efficiently develop a generative question-answering model for open-book question-answering over a proprietary collection of text documents. The framework adapts a retriever augmented generation model to the target domain using supervised finetuning and reinforcement learning with synthetic feedback in a few-shot setting. This yields an aligned, uncertainty calibrated model that is competitive with GPT-4 based in-context retrieval augmented generation in generating relevant answers at lower serving costs. The synthetic generation pipeline generates high quality synthetic training data musing a medium sized LLM, Flan-T5 XXL, and a novel consistency filtering scheme. The pipeline is designed to generate both abstractive and extractive questions that span the entire corpus. Using samples from this dataset, the framework fine-tunes a smaller RAG model comprising a dense retriever and a smaller sized LLM on samples from the dataset. In parallel, the framework trains a Reward model to score domain grounded answers higher than hallucinated answers. In the next phase, the framework aligns to the RAG model with the target domain using reinforcement learning. This step improves the RAG model's ability to generate grounded answers and ignore out of domain questions. In the final phase, the framework calibrates the model uncertainty for extractive question-answers. This is a desirable feature since the model can be integrated into a cascading system where the RAG model's answer is surfaced only when the model is confident of its answer.", "url": "https://arxiv.org/abs/2307.05915"}, {"metadata": {"arXiv": "2307.05926", "Date": "Wed, 12 Jul 2023 05:46:37 ", "Title": "Filling time-series gaps using image techniques: Multidimensional context autoencoder approach for building energy data imputation", "Authors": ["Chun Fu", "Matias Quintana", "Zoltan Nagy", "Clayton Miller"], "Categories": "cs.LG"}, "abstract": "Building energy prediction and management has become increasingly important in recent decades, driven by the growth of Internet of Things (IoT) devices and the availability of more energy data. However, energy data is often collected from multiple sources and can be incomplete or inconsistent, which can hinder accurate predictions and management of energy systems and limit the usefulness of the data for decision-making and research. To address this issue, past studies have focused on imputing missing gaps in energy data, including random and continuous gaps. One of the main challenges in this area is the lack of validation on a benchmark dataset with various building and meter types, making it difficult to accurately evaluate the performance of different imputation methods. Another challenge is the lack of application of state-of-the-art imputation methods for missing gaps in energy data. Contemporary image-inpainting methods, such as Partial Convolution (PConv), have been widely used in the computer vision domain and have demonstrated their effectiveness in dealing with complex missing patterns. To study whether energy data imputation can benefit from the image-based deep learning method, this study compared PConv, Convolutional neural networks (CNNs), and weekly persistence method using one of the biggest publicly available whole building energy datasets, consisting of 1479 power meters worldwide, as the benchmark. The results show that, compared to the CNN with the raw time series (1D-CNN) and the weekly persistence method, neural network models with reshaped energy data with two dimensions reduced the Mean Squared Error (MSE) by 10% to 30%. The advanced deep learning method, Partial convolution (PConv), has further reduced the MSE by 20-30% than 2D-CNN and stands out among all models.", "url": "https://arxiv.org/abs/2307.05926"}, {"metadata": {"arXiv": "2307.05946", "Date": "Wed, 12 Jul 2023 06:23:31 ", "Title": "A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models", "Authors": ["Agnimitra Sengupta", "Sudeepta Mondal", "Adway Das", "S. Ilgin Guler"], "Categories": "cs.LG stat.ML"}, "abstract": "Deep-learning models for traffic data prediction can have superior performance in modeling complex functions using a multi-layer architecture. However, a major drawback of these approaches is that most of these approaches do not offer forecasts with uncertainty estimates, which are essential for traffic operations and control. Without uncertainty estimates, it is difficult to place any level of trust to the model predictions, and operational strategies relying on overconfident predictions can lead to worsening traffic conditions. In this study, we propose a Bayesian recurrent neural network framework for uncertainty quantification in traffic prediction with higher generalizability by introducing spectral normalization to its hidden layers. In our paper, we have shown that normalization alters the training process of deep neural networks by controlling the model's complexity and reducing the risk of overfitting to the training data. This, in turn, helps improve the generalization performance of the model on out-of-distribution datasets. Results demonstrate that spectral normalization improves uncertainty estimates and significantly outperforms both the layer normalization and model without normalization in single-step prediction horizons. This improved performance can be attributed to the ability of spectral normalization to better localize the feature space of the data under perturbations. Our findings are especially relevant to traffic management applications, where predicting traffic conditions across multiple locations is the goal, but the availability of training data from multiple locations is limited. Spectral normalization, therefore, provides a more generalizable approach that can effectively capture the underlying patterns in traffic data without requiring location-specific models.", "url": "https://arxiv.org/abs/2307.05946"}, {"metadata": {"arXiv": "2307.05948", "Date": "Wed, 12 Jul 2023 06:29:02 ", "Title": "Diversity-enhancing Generative Network for Few-shot Hypothesis Adaptation", "Authors": ["Ruijiang Dong", "Feng Liu", "Haoang Chi", "Tongliang Liu", "Mingming Gong", "Gang Niu", "Masashi Sugiyama and Bo Han"], "Categories": "cs.LG"}, "abstract": "Generating unlabeled data has been recently shown to help address the few-shot hypothesis adaptation (FHA) problem, where we aim to train a classifier for the target domain with a few labeled target-domain data and a well-trained source-domain classifier (i.e., a source hypothesis), for the additional information of the highly-compatible unlabeled data. However, the generated data of the existing methods are extremely similar or even the same. The strong dependency among the generated data will lead the learning to fail. In this paper, we propose a diversity-enhancing generative network (DEG-Net) for the FHA problem, which can generate diverse unlabeled data with the help of a kernel independence measure: the Hilbert-Schmidt independence criterion (HSIC). Specifically, DEG-Net will generate data via minimizing the HSIC value (i.e., maximizing the independence) among the semantic features of the generated data. By DEG-Net, the generated unlabeled data are more diverse and more effective for addressing the FHA problem. Experimental results show that the DEG-Net outperforms existing FHA baselines and further verifies that generating diverse data plays a vital role in addressing the FHA problem", "url": "https://arxiv.org/abs/2307.05948"}, {"metadata": {"arXiv": "2307.05949", "Date": "Wed, 12 Jul 2023 06:31:43 ", "Title": "Newell's theory based feature transformations for spatio-temporal traffic prediction", "Authors": ["Agnimitra Sengupta", "S. Ilgin Guler"], "Categories": "cs.LG stat.ML"}, "abstract": "Deep learning (DL) models for spatio-temporal traffic flow forecasting employ convolutional or graph-convolutional filters along with recurrent neural networks to capture spatial and temporal dependencies in traffic data. These models, such as CNN-LSTM, utilize traffic flows from neighboring detector stations to predict flows at a specific location of interest. However, these models are limited in their ability to capture the broader dynamics of the traffic system, as they primarily learn features specific to the detector configuration and traffic characteristics at the target location. Hence, the transferability of these models to different locations becomes challenging, particularly when data is unavailable at the new location for model training. To address this limitation, we propose a traffic flow physics-based feature transformation for spatio-temporal DL models. This transformation incorporates Newell's uncongested and congested-state estimators of traffic flows at the target locations, enabling the models to learn broader dynamics of the system. Our methodology is empirically validated using traffic data from two different locations. The results demonstrate that the proposed feature transformation improves the models' performance in predicting traffic flows over different prediction horizons, as indicated by better goodness-of-fit statistics. An important advantage of our framework is its ability to be transferred to new locations where data is unavailable. This is achieved by appropriately accounting for spatial dependencies based on station distances and various traffic parameters. In contrast, regular DL models are not easily transferable as their inputs remain fixed. It should be noted that due to data limitations, we were unable to perform spatial sensitivity analysis, which calls for further research using simulated data.", "url": "https://arxiv.org/abs/2307.05949"}, {"metadata": {"arXiv": "2307.05988", "Date": "Wed, 12 Jul 2023 08:04:29 ", "Title": "A Comprehensive Review of Automated Data Annotation Techniques in Human Activity Recognition", "Authors": ["Florenc Demrozi and Cristian Turetta and Fadi Al Machot and Graziano Pravadelli and Philipp H. Kindt"], "Categories": "cs.LG cs.HC", "Comments": ["37 pages", "5 figures", "20 tables"]}, "abstract": "Human Activity Recognition (HAR) has become one of the leading research topics of the last decade. As sensing technologies have matured and their economic costs have declined, a host of novel applications, e.g., in healthcare, industry, sports, and daily life activities have become popular. The design of HAR systems requires different time-consuming processing steps, such as data collection, annotation, and model training and optimization. In particular, data annotation represents the most labor-intensive and cumbersome step in HAR, since it requires extensive and detailed manual work from human annotators. Therefore, different methodologies concerning the automation of the annotation procedure in HAR have been proposed. The annotation problem occurs in different notions and scenarios, which all require individual solutions. In this paper, we provide the first systematic review on data annotation techniques for HAR. By grouping existing approaches into classes and providing a taxonomy, our goal is to support the decision on which techniques can be beneficially used in a given scenario.", "url": "https://arxiv.org/abs/2307.05988"}, {"metadata": {"arXiv": "2307.06026", "Date": "Wed, 12 Jul 2023 09:14:35 ", "Title": "Learning from Exemplary Explanations", "Authors": ["Misgina Tsighe Hagos", "Kathleen M. Curran", "Brian Mac Namee"], "Categories": "cs.LG cs.CV"}, "abstract": "eXplanation Based Learning (XBL) is a form of Interactive Machine Learning (IML) that provides a model refining approach via user feedback collected on model explanations. Although the interactivity of XBL promotes model transparency, XBL requires a huge amount of user interaction and can become expensive as feedback is in the form of detailed annotation rather than simple category labelling which is more common in IML. This expense is exacerbated in high stakes domains such as medical image classification. To reduce the effort and expense of XBL we introduce a new approach that uses two input instances and their corresponding Gradient Weighted Class Activation Mapping (GradCAM) model explanations as exemplary explanations to implement XBL. Using a medical image classification task, we demonstrate that, using minimal human input, our approach produces improved explanations (+0.02, +3%) and achieves reduced classification performance (-0.04, -4%) when compared against a model trained without interactions.", "url": "https://arxiv.org/abs/2307.06026"}, {"metadata": {"arXiv": "2307.06055", "Date": "Wed, 12 Jul 2023 10:17:54 ", "Title": "Function-Space Regularization for Deep Bayesian Classification", "Authors": ["Jihao Andreas Lin", "Joe Watson", "Pascal Klink", "Jan Peters"], "Categories": "cs.LG stat.ML", "Comments": ["Advances in Approximate Bayesian Inference 2023"]}, "abstract": "Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior. However, weight-space priors are model-specific, can be difficult to interpret and are hard to specify. Instead, we apply a Dirichlet prior in predictive space and perform approximate function-space variational inference. To this end, we interpret conventional categorical predictions from stochastic neural network classifiers as samples from an implicit Dirichlet distribution. By adapting the inference, the same function-space prior can be combined with different models without affecting model architecture or size. We illustrate the flexibility and efficacy of such a prior with toy experiments and demonstrate scalability, improved uncertainty quantification and adversarial robustness with large-scale image classification experiments.", "url": "https://arxiv.org/abs/2307.06055"}, {"metadata": {"arXiv": "2307.06093", "Date": "Wed, 12 Jul 2023 11:36:27 ", "Title": "Online Laplace Model Selection Revisited", "Authors": ["Jihao Andreas Lin", "Javier Antor\\'an", "Jos\\'e Miguel Hern\\'andez-Lobato"], "Categories": "cs.LG stat.ML", "Comments": ["Advances in Approximate Bayesian Inference 2023"]}, "abstract": "The Laplace approximation provides a closed-form model selection objective for neural networks (NN). Online variants, which optimise NN parameters jointly with hyperparameters, like weight decay strength, have seen renewed interest in the Bayesian deep learning community. However, these methods violate Laplace's method's critical assumption that the approximation is performed around a mode of the loss, calling into question their soundness. This work re-derives online Laplace methods, showing them to target a variational bound on a mode-corrected variant of the Laplace evidence which does not make stationarity assumptions. Online Laplace and its mode-corrected counterpart share stationary points where 1. the NN parameters are a maximum a posteriori, satisfying the Laplace method's assumption, and 2. the hyperparameters maximise the Laplace evidence, motivating online methods. We demonstrate that these optima are roughly attained in practise by online algorithms using full-batch gradient descent on UCI regression datasets. The optimised hyperparameters prevent overfitting and outperform validation-based early stopping.", "url": "https://arxiv.org/abs/2307.06093"}, {"metadata": {"arXiv": "2307.06097", "Date": "Wed, 12 Jul 2023 11:38:34 ", "Title": "Learning Stochastic Dynamical Systems as an Implicit Regularization with Graph Neural Networks", "Authors": ["Jin Guo", "Ting Gao", "Yufu Lan", "Peng Zhang", "Sikun Yang", "Jinqiao Duan"], "Categories": "cs.LG math.DS", "Comments": ["8 pages", "5 figures"]}, "abstract": "Stochastic Gumbel graph networks are proposed to learn high-dimensional time series, where the observed dimensions are often spatially correlated. To that end, the observed randomness and spatial-correlations are captured by learning the drift and diffusion terms of the stochastic differential equation with a Gumble matrix embedding, respectively. In particular, this novel framework enables us to investigate the implicit regularization effect of the noise terms in S-GGNs. We provide a theoretical guarantee for the proposed S-GGNs by deriving the difference between the two corresponding loss functions in a small neighborhood of weight. Then, we employ Kuramoto's model to generate data for comparing the spectral density from the Hessian Matrix of the two loss functions. Experimental results on real-world data, demonstrate that S-GGNs exhibit superior convergence, robustness, and generalization, compared with state-of-the-arts.", "url": "https://arxiv.org/abs/2307.06097"}, {"metadata": {"arXiv": "2307.06104", "Date": "Wed, 12 Jul 2023 12:02:36 ", "Title": "Deep learning for dynamic graphs: models and benchmarks", "Authors": ["Alessio Gravina and Davide Bacciu"], "Categories": "cs.LG cs.SI"}, "abstract": "Recent progress in research on Deep Graph Networks (DGNs) has led to a maturation of the domain of learning on graphs. Despite the growth of this research field, there are still important challenges that are yet unsolved. Specifically, there is an urge of making DGNs suitable for predictive tasks on realworld systems of interconnected entities, which evolve over time. With the aim of fostering research in the domain of dynamic graphs, at first, we survey recent advantages in learning both temporal and spatial information, providing a comprehensive overview of the current state-of-the-art in the domain of representation learning for dynamic graphs. Secondly, we conduct a fair performance comparison among the most popular proposed approaches, leveraging rigorous model selection and assessment for all the methods, thus establishing a sound baseline for evaluating new architectures and approaches", "url": "https://arxiv.org/abs/2307.06104"}, {"metadata": {"arXiv": "2307.06148", "Date": "Wed, 12 Jul 2023 13:10:08 ", "Title": "NetGPT: A Native-AI Network Architecture Beyond Provisioning Personalized Generative Services", "Authors": ["Yuxuan Chen", "Rongpeng Li", "Zhifeng Zhao", "Chenghui Peng", "Jianjun Wu", "Ekram Hossain", "and Honggang Zhang"], "Categories": "cs.LG"}, "abstract": "Large language models (LLMs) have triggered tremendous success to empower daily life by generative information, and the personalization of LLMs could further contribute to their applications due to better alignment with human intents. Towards personalized generative services, a collaborative cloud-edge methodology sounds promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources. In this article, after discussing the pros and cons of several candidate cloud-edge collaboration techniques, we put forward NetGPT to capably deploy appropriate LLMs at the edge and the cloud in accordance with their computing capacity. In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with cloud LLMs. After deploying representative open-source LLMs (e.g., GPT-2-base and LLaMA model) at the edge and the cloud, we present the feasibility of NetGPT on the basis of low-rank adaptation-based light-weight fine-tuning. Subsequently, we highlight substantial essential changes required for a native artificial intelligence (AI) network architecture towards NetGPT, with special emphasis on deeper integration of communications and computing resources and careful calibration of logical AI workflow. Furthermore, we demonstrate several by-product benefits of NetGPT, given edge LLM's astonishing capability to predict trends and infer intents, which possibly leads to a unified solution for intelligent network management \\& orchestration. In a nutshell, we argue that NetGPT is a promising native-AI network architecture beyond provisioning personalized generative services.", "url": "https://arxiv.org/abs/2307.06148"}, {"metadata": {"arXiv": "2307.06167", "Date": "Wed, 12 Jul 2023 13:46:40 ", "Title": "Auxiliary-Tasks Learning for Physics-Informed Neural Network-Based Partial Differential Equations Solving", "Authors": ["Junjun Yan", "Xinhai Chen", "Zhichao Wang", "Enqiang Zhou and Jie Liu"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Physics-informed neural networks (PINNs) have emerged as promising surrogate modes for solving partial differential equations (PDEs). Their effectiveness lies in the ability to capture solution-related features through neural networks. However, original PINNs often suffer from bottlenecks, such as low accuracy and non-convergence, limiting their applicability in complex physical contexts. To alleviate these issues, we proposed auxiliary-task learning-based physics-informed neural networks (ATL-PINNs), which provide four different auxiliary-task learning modes and investigate their performance compared with original PINNs. We also employ the gradient cosine similarity algorithm to integrate auxiliary problem loss with the primary problem loss in ATL-PINNs, which aims to enhance the effectiveness of the auxiliary-task learning modes. To the best of our knowledge, this is the first study to introduce auxiliary-task learning modes in the context of physics-informed learning. We conduct experiments on three PDE problems across different fields and scenarios. Our findings demonstrate that the proposed auxiliary-task learning modes can significantly improve solution accuracy, achieving a maximum performance boost of 96.62% (averaging 28.23%) compared to the original single-task PINNs. The code and dataset are open source at https://github.com/junjun-yan/ATL-PINN.", "url": "https://arxiv.org/abs/2307.06167"}, {"metadata": {"arXiv": "2307.06175", "Date": "Wed, 12 Jul 2023 14:02:03 ", "Title": "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior", "Authors": ["Kai Cui", "Sascha Hauck", "Christian Fabian", "Heinz Koeppl"], "Categories": "cs.LG cs.MA math.OC"}, "abstract": "Recent reinforcement learning (RL) methods have achieved success in various domains. However, multi-agent RL (MARL) remains a challenge in terms of decentralization, partial observability and scalability to many agents. Meanwhile, collective behavior requires resolution of the aforementioned challenges, and remains of importance to many state-of-the-art applications such as active matter physics, self-organizing systems, opinion dynamics, and biological or robotic swarms. Here, MARL via mean field control (MFC) offers a potential solution to scalability, but fails to consider decentralized and partially observable systems. In this paper, we enable decentralized behavior of agents under partial information by proposing novel models for decentralized partially observable MFC (Dec-POMFC), a broad class of problems with permutation-invariant agents allowing for reduction to tractable single-agent Markov decision processes (MDP) with single-agent RL solution. We provide rigorous theoretical results, including a dynamic programming principle, together with optimality guarantees for Dec-POMFC solutions applied to finite swarms of interest. Algorithmically, we propose Dec-POMFC-based policy gradient methods for MARL via centralized training and decentralized execution, together with policy gradient approximation guarantees. In addition, we improve upon state-of-the-art histogram-based MFC by kernel methods, which is of separate interest also for fully observable MFC. We evaluate numerically on representative collective behavior tasks such as adapted Kuramoto and Vicsek swarming models, being on par with state-of-the-art MARL. Overall, our framework takes a step towards RL-based engineering of artificial collective behavior via MFC.", "url": "https://arxiv.org/abs/2307.06175"}, {"metadata": {"arXiv": "2307.06235", "Date": "Wed, 12 Jul 2023 15:27:06 ", "Title": "Unified Molecular Modeling via Modality Blending", "Authors": ["Qiying Yu", "Yudi Zhang", "Yuyan Ni", "Shikun Feng", "Yanyan Lan", "Hao Zhou", "Jingjing Liu"], "Categories": "cs.LG q-bio.BM"}, "abstract": "Self-supervised molecular representation learning is critical for molecule-based tasks such as AI-assisted drug discovery. Recent studies consider leveraging both 2D and 3D information for representation learning, with straightforward alignment strategies that treat each modality separately. In this work, we introduce a novel \"blend-then-predict\" self-supervised learning method (MoleBLEND), which blends atom relations from different modalities into one unified relation matrix for encoding, then recovers modality-specific information for both 2D and 3D structures. By treating atom relationships as anchors, seemingly dissimilar 2D and 3D manifolds are aligned and integrated at fine-grained relation-level organically. Extensive experiments show that MoleBLEND achieves state-of-the-art performance across major 2D/3D benchmarks. We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (inter-modal prediction) and mask-then-predict (intra-modal prediction) objectives into a single cohesive blend-then-predict framework.", "url": "https://arxiv.org/abs/2307.06235"}, {"metadata": {"arXiv": "2307.06255", "Date": "Wed, 12 Jul 2023 15:50:38 ", "Title": "Machine learning and Topological data analysis identify unique features of human papillae in 3D scans", "Authors": ["Rayna Andreeva", "Anwesha Sarkar", "Rik Sarkar"], "Categories": "cs.LG math.AT math.DG"}, "abstract": "The tongue surface houses a range of papillae that are integral to the mechanics and chemistry of taste and textural sensation. Although gustatory function of papillae is well investigated, the uniqueness of papillae within and across individuals remains elusive. Here, we present the first machine learning framework on 3D microscopic scans of human papillae (n = 2092), uncovering the uniqueness of geometric and topological features of papillae. The finer differences in shapes of papillae are investigated computationally based on a number of features derived from discrete differential geometry and computational topology. Interpretable machine learning techniques show that persistent homology features of the papillae shape are the most effective in predicting the biological variables. Models trained on these features with small volumes of data samples predict the type of papillae with an accuracy of 85%. The papillae type classification models can map the spatial arrangement of filiform and fungiform papillae on a surface. Remarkably, the papillae are found to be distinctive across individuals and an individual can be identified with an accuracy of 48% among the 15 participants from a single papillae. Collectively, this is the first unprecedented evidence demonstrating that tongue papillae can serve as a unique identifier inspiring new research direction for food preferences and oral diagnostics.", "url": "https://arxiv.org/abs/2307.06255"}, {"metadata": {"arXiv": "2307.06263", "Date": "Wed, 12 Jul 2023 16:03:34 ", "Title": "On the hierarchical Bayesian modelling of frequency response functions", "Authors": ["T.A. Dardeno", "R.S. Mills", "N. Dervilis", "K. Worden", "L.A. Bull"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Population-based structural health monitoring (PBSHM) aims to share valuable information among members of a population, such as normal- and damage-condition data, to improve inferences regarding the health states of the members. Even when the population is comprised of nominally-identical structures, benign variations among the members will exist as a result of slight differences in material properties, geometry, boundary conditions, or environmental effects (e.g., temperature changes). These discrepancies can affect modal properties and present as changes in the characteristics of the resonance peaks of the frequency response function (FRF). Many SHM strategies depend on monitoring the dynamic properties of structures, so benign variations can be challenging for the practical implementation of these systems. Another common challenge with vibration-based SHM is data loss, which may result from transmission issues, sensor failure, a sample-rate mismatch between sensors, and other causes. Missing data in the time domain will result in decreased resolution in the frequency domain, which can impair dynamic characterisation. The hierarchical Bayesian approach provides a useful modelling structure for PBSHM, because statistical distributions at the population and individual (or domain) level are learnt simultaneously to bolster statistical strength among the parameters. As a result, variance is reduced among the parameter estimates, particularly when data are limited. In this paper, combined probabilistic FRF models are developed for a small population of nominally-identical helicopter blades under varying temperature conditions, using a hierarchical Bayesian structure. These models address critical challenges in SHM, by accommodating benign variations that present as differences in the underlying dynamics, while also considering (and utilising), the similarities among the blades.", "url": "https://arxiv.org/abs/2307.06263"}, {"metadata": {"arXiv": "2307.06267", "Date": "Wed, 12 Jul 2023 16:11:57 ", "Title": "Physics-informed Machine Learning for Calibrating Macroscopic Traffic Flow Models", "Authors": ["Yu Tang", "Li Jin", "Kaan Ozbay"], "Categories": "cs.LG"}, "abstract": "Well-calibrated traffic flow models are fundamental to understanding traffic phenomena and designing control strategies. Traditional calibration has been developed base on optimization methods. In this paper, we propose a novel physics-informed, learning-based calibration approach that achieves performances comparable to and even better than those of optimization-based methods. To this end, we combine the classical deep autoencoder, an unsupervised machine learning model consisting of one encoder and one decoder, with traffic flow models. Our approach informs the decoder of the physical traffic flow models and thus induces the encoder to yield reasonable traffic parameters given flow and speed measurements. We also introduce the denoising autoencoder into our method so that it can handles not only with normal data but also with corrupted data with missing values. We verified our approach with a case study of I-210 E in California.", "url": "https://arxiv.org/abs/2307.06267"}, {"metadata": {"arXiv": "2307.06283", "Date": "Wed, 12 Jul 2023 16:28:21 ", "Title": "Tackling Computational Heterogeneity in FL: A Few Theoretical Insights", "Authors": ["Adnan Ben Mansour", "Gaia Carenini", "Alexandre Duplessis"], "Categories": "cs.LG cs.DC", "Comments": ["22 pages", "7 figures. Extended version of the paper \"Federated Learning Aggregation: New Robust Algorithms with Guarantees\" (arXiv:2205.10864)"]}, "abstract": "The future of machine learning lies in moving data collection along with training to the edge. Federated Learning, for short FL, has been recently proposed to achieve this goal. The principle of this approach is to aggregate models learned over a large number of distributed clients, i.e., resource-constrained mobile devices that collect data from their environment, to obtain a new more general model. The latter is subsequently redistributed to clients for further training. A key feature that distinguishes federated learning from data-center-based distributed training is the inherent heterogeneity. In this work, we introduce and analyse a novel aggregation framework that allows for formalizing and tackling computational heterogeneity in federated optimization, in terms of both heterogeneous data and local updates. Proposed aggregation algorithms are extensively analyzed from a theoretical, and an experimental prospective.", "url": "https://arxiv.org/abs/2307.06283"}, {"metadata": {"arXiv": "2307.06306", "Date": "Wed, 12 Jul 2023 17:02:32 ", "Title": "Locally Adaptive Federated Learning via Stochastic Polyak Stepsizes", "Authors": ["Sohom Mukherjee", "Nicolas Loizou", "Sebastian U. Stich"], "Categories": "cs.LG math.OC stat.ML", "Comments": ["33 pages", "6 figures"]}, "abstract": "State-of-the-art federated learning algorithms such as FedAvg require carefully tuned stepsizes to achieve their best performance. The improvements proposed by existing adaptive federated methods involve tuning of additional hyperparameters such as momentum parameters, and consider adaptivity only in the server aggregation round, but not locally. These methods can be inefficient in many practical scenarios because they require excessive tuning of hyperparameters and do not capture local geometric information. In this work, we extend the recently proposed stochastic Polyak stepsize (SPS) to the federated learning setting, and propose new locally adaptive and nearly parameter-free distributed SPS variants (FedSPS and FedDecSPS). We prove that FedSPS converges linearly in strongly convex and sublinearly in convex settings when the interpolation condition (overparametrization) is satisfied, and converges to a neighborhood of the solution in the general case. We extend our proposed method to a decreasing stepsize version FedDecSPS, that converges also when the interpolation condition does not hold. We validate our theoretical claims by performing illustrative convex experiments. Our proposed algorithms match the optimization performance of FedAvg with the best tuned hyperparameters in the i.i.d. case, and outperform FedAvg in the non-i.i.d. case.", "url": "https://arxiv.org/abs/2307.06306"}, {"metadata": {"arXiv": "2307.06244", "Date": "Wed, 12 Jul 2023 15:34:39 ", "Title": "Diffusion Based Multi-Agent Adversarial Tracking", "Authors": ["Sean Ye", "Manisha Natarajan", "Zixuan Wu", "Matthew Gombolay"], "Categories": "cs.RO cs.LG cs.MA"}, "abstract": "Target tracking plays a crucial role in real-world scenarios, particularly in drug-trafficking interdiction, where the knowledge of an adversarial target's location is often limited. Improving autonomous tracking systems will enable unmanned aerial, surface, and underwater vehicles to better assist in interdicting smugglers that use manned surface, semi-submersible, and aerial vessels. As unmanned drones proliferate, accurate autonomous target estimation is even more crucial for security and safety. This paper presents Constrained Agent-based Diffusion for Enhanced Multi-Agent Tracking (CADENCE), an approach aimed at generating comprehensive predictions of adversary locations by leveraging past sparse state information. To assess the effectiveness of this approach, we evaluate predictions on single-target and multi-target pursuit environments, employing Monte-Carlo sampling of the diffusion model to estimate the probability associated with each generated trajectory. We propose a novel cross-attention based diffusion model that utilizes constraint-based sampling to generate multimodal track hypotheses. Our single-target model surpasses the performance of all baseline methods on Average Displacement Error (ADE) for predictions across all time horizons.", "url": "https://arxiv.org/abs/2307.06244"}, {"metadata": {"arXiv": "2307.05763", "Date": "Tue, 11 Jul 2023 19:40:02 ", "Title": "Realtime Spectrum Monitoring via Reinforcement Learning -- A Comparison Between Q-Learning and Heuristic Methods", "Authors": ["Tobias Braun", "Tobias Korzyzkowske", "Larissa Putzar", "Jan Mietzner", "Peter A. Hoeher"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["5 pages", "6 figures"]}, "abstract": "Due to technological advances in the field of radio technology and its availability, the number of interference signals in the radio spectrum is continuously increasing. Interference signals must be detected in a timely fashion, in order to maintain standards and keep emergency frequencies open. To this end, specialized (multi-channel) receivers are used for spectrum monitoring. In this paper, the performances of two different approaches for controlling the available receiver resources are compared. The methods used for resource management (ReMa) are linear frequency tuning as a heuristic approach and a Q-learning algorithm from the field of reinforcement learning. To test the methods to be investigated, a simplified scenario was designed with two receiver channels monitoring ten non-overlapping frequency bands with non-uniform signal activity. For this setting, it is shown that the Q-learning algorithm used has a significantly higher detection rate than the heuristic approach at the expense of a smaller exploration rate. In particular, the Q-learning approach can be parameterized to allow for a suitable trade-off between detection and exploration rate.", "url": "https://arxiv.org/abs/2307.05763"}, {"metadata": {"arXiv": "2307.05812", "Date": "Tue, 11 Jul 2023 21:38:52 ", "Title": "Safe Reinforcement Learning for Strategic Bidding of Virtual Power Plants in Day-Ahead Markets", "Authors": ["Ognjen Stanojev", "Lesia Mitridati", "Riccardo de Nardis di Prata", "Gabriela Hug"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "This paper presents a novel safe reinforcement learning algorithm for strategic bidding of Virtual Power Plants (VPPs) in day-ahead electricity markets. The proposed algorithm utilizes the Deep Deterministic Policy Gradient (DDPG) method to learn competitive bidding policies without requiring an accurate market model. Furthermore, to account for the complex internal physical constraints of VPPs we introduce two enhancements to the DDPG method. Firstly, a projection-based safety shield that restricts the agent's actions to the feasible space defined by the non-linear power flow equations and operating constraints of distributed energy resources is derived. Secondly, a penalty for the shield activation in the reward function that incentivizes the agent to learn a safer policy is introduced. A case study based on the IEEE 13-bus network demonstrates the effectiveness of the proposed approach in enabling the agent to learn a highly competitive, safe strategic policy.", "url": "https://arxiv.org/abs/2307.05812"}, {"metadata": {"arXiv": "2307.06287", "Date": "Wed, 12 Jul 2023 16:35:41 ", "Title": "Rational Neural Network Controllers", "Authors": ["Matthew Newton and Antonis Papachristodoulou"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["20 Pages", "12 Figures"]}, "abstract": "Neural networks have shown great success in many machine learning related tasks, due to their ability to act as general function approximators. Recent work has demonstrated the effectiveness of neural networks in control systems (known as neural feedback loops), most notably by using a neural network as a controller. However, one of the big challenges of this approach is that neural networks have been shown to be sensitive to adversarial attacks. This means that, unless they are designed properly, they are not an ideal candidate for controllers due to issues with robustness and uncertainty, which are pivotal aspects of control systems. There has been initial work on robustness to both analyse and design dynamical systems with neural network controllers. However, one prominent issue with these methods is that they use existing neural network architectures tailored for traditional machine learning tasks. These structures may not be appropriate for neural network controllers and it is important to consider alternative architectures. This paper considers rational neural networks and presents novel rational activation functions, which can be used effectively in robustness problems for neural feedback loops. Rational activation functions are replaced by a general rational neural network structure, which is convex in the neural network's parameters. A method is proposed to recover a stabilising controller from a Sum of Squares feasibility test. This approach is then applied to a refined rational neural network which is more compatible with Sum of Squares programming. Numerical examples show that this method can successfully recover stabilising rational neural network controllers for neural feedback loops with non-linear plants with noise and parametric uncertainty.", "url": "https://arxiv.org/abs/2307.06287"}, {"metadata": {"arXiv": "2307.05494", "Date": "Tue, 20 Jun 2023 17:13:33 ", "Title": "Towards Environmentally Equitable AI via Geographical Load Balancing", "Authors": ["Pengfei Li and Jianyi Yang and Adam Wierman and Shaolei Ren"], "Categories": "cs.AI cs.CY", "Comments": ["Source code: https://github.com/Ren-Research/Environmentally-Equitable-AI"]}, "abstract": "Fueled by the soaring popularity of large language and foundation models, the accelerated growth of artificial intelligence (AI) models' enormous environmental footprint has come under increased scrutiny. While many approaches have been proposed to make AI more energy-efficient and environmentally friendly, environmental inequity -- the fact that AI's environmental footprint can be disproportionately higher in certain regions than in others -- has emerged, raising social-ecological justice concerns. This paper takes a first step toward addressing AI's environmental inequity by balancing its regional negative environmental impact. Concretely, we focus on the carbon and water footprints of AI model inference and propose equity-aware geographical load balancing (GLB) to explicitly address AI's environmental impacts on the most disadvantaged regions. We run trace-based simulations by considering a set of 10 geographically-distributed data centers that serve inference requests for a large language AI model. The results demonstrate that existing GLB approaches may amplify environmental inequity while our proposed equity-aware GLB can significantly reduce the regional disparity in terms of carbon and water footprints.", "url": "https://arxiv.org/abs/2307.05494"}, {"metadata": {"arXiv": "2307.05629", "Date": "Tue, 11 Jul 2023 07:07:15 ", "Title": "Characterization of AGM Belief Contraction in Terms of Conditionals", "Authors": ["Giacomo Bonanno (University of California", "Davis)"], "Categories": "cs.AI cs.LO", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 142-156", "DOI": "10.4204/EPTCS.379.13"}, "abstract": "We provide a semantic characterization of AGM belief contraction based on frames consisting of a Kripke belief relation and a Stalnaker-Lewis selection function. The central idea is as follows. Let K be the initial belief set and K-A be the contraction of K by the formula A; then B belongs to the set K-A if and only if, at the actual state, the agent believes B and believes that if not-A is (were) the case then B is (would be) the case.", "url": "https://arxiv.org/abs/2307.05629"}, {"metadata": {"arXiv": "2307.05631", "Date": "Tue, 11 Jul 2023 07:08:14 ", "Title": "Causal Kripke Models", "Authors": ["Yiwen Ding (Vrije Universiteit Amsterdam)", "Krishna Manoorkar (Vrije Universiteit Amsterdam)", "Apostolos Tzimoulis (Vrije Universiteit Amsterdam)", "Ruoding Wang (Vrije Universiteit Amsterdam)", "Xiaolong Wang (Vrije Universiteit Amsterdam)"], "Categories": "cs.AI cs.LO", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 185-200", "DOI": "10.4204/EPTCS.379.16"}, "abstract": "This work extends Halpern and Pearl's causal models for actual causality to a possible world semantics environment. Using this framework we introduce a logic of actual causality with modal operators, which allows for reasoning about causality in scenarios involving multiple possibilities, temporality, knowledge and uncertainty. We illustrate this with a number of examples, and conclude by discussing some future directions for research.", "url": "https://arxiv.org/abs/2307.05631"}, {"metadata": {"arXiv": "2307.05632", "Date": "Tue, 11 Jul 2023 07:11:30 ", "Title": "Belief Revision from Probability", "Authors": ["Jeremy Goodman (University of Southern California)", "Bernhard Salow (University of Oxford)"], "Categories": "cs.AI cs.LO", "Comments": ["In Proceedings TARK 2023", "arXiv:2307.04005"], "Journal-ref": "EPTCS 379, 2023, pp. 308-317", "DOI": "10.4204/EPTCS.379.25"}, "abstract": "In previous work (\"Knowledge from Probability\", TARK 2021) we develop a question-relative, probabilistic account of belief. On this account, what someone believes relative to a given question is (i) closed under entailment, (ii) sufficiently probable given their evidence, and (iii) sensitive to the relative probabilities of the answers to the question. Here we explore the implications of this account for the dynamics of belief. We show that the principles it validates are much weaker than those of orthodox theories of belief revision like AGM, but still stronger than those valid according to the popular Lockean theory of belief, which equates belief with high subjective probability. We then consider a restricted class of models, suitable for many but not all applications, and identify some further natural principles valid on this class. We conclude by arguing that the present framework compares favorably to the rival probabilistic accounts of belief developed by Leitgeb and by Lin and Kelly.", "url": "https://arxiv.org/abs/2307.05632"}, {"metadata": {"arXiv": "2307.05722", "Date": "Mon, 10 Jul 2023 11:29:41 ", "Title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations", "Authors": ["Likang Wu", "Zhaopeng Qiu", "Zhi Zheng", "Hengshu Zhu", "and Enhong Chen"], "Categories": "cs.AI cs.CL cs.IR"}, "abstract": "Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for behavior graph understanding in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including the promotion of out-of-distribution (OOD) application. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that leverages LLM recommender to understand behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By leveraging this capability, our framework enables personalized and accurate job recommendations for individual users. We evaluate the effectiveness of our approach on a comprehensive dataset and demonstrate its ability to improve the relevance and quality of recommended quality. This research not only sheds light on the untapped potential of large language models but also provides valuable insights for developing advanced recommendation systems in the recruitment market. The findings contribute to the growing field of natural language processing and offer practical implications for enhancing job search experiences.", "url": "https://arxiv.org/abs/2307.05722"}, {"metadata": {"arXiv": "2307.05727", "Date": "Tue, 11 Jul 2023 18:55:09 ", "Title": "An Open-Source Knowledge Graph Ecosystem for the Life Sciences", "Authors": ["Tiffany J. Callahan", "Ignacio J. Tripodi", "Adrianne L. Stefanski", "Luca Cappelletti", "Sanya B. Taneja", "Jordan M. Wyrwa", "Elena Casiraghi", "Nicolas A. Matentzoglu", "Justin Reese", "Jonathan C. Silverstein", "Charles Tapley Hoyt", "Richard D. Boyce", "Scott A. Malec", "Deepak R. Unni", "Marcin P. Joachimiak", "Peter N. Robinson", "Christopher J. Mungall", "Emanuele Cavalleri", "Tommaso Fontana", "Giorgio Valentini", "Marco Mesiti", "Lucas A. Gillenwater", "Brook Santangelo", "Nicole A. Vasilevsky", "Robert Hoehndorf", "Tellen D. Bennett", "Patrick B. Ryan", "George Hripcsak", "Michael G. Kahn", "Michael Bada", "William A. Baumgartner Jr", "Lawrence E. Hunter"], "Categories": "cs.AI cs.CE"}, "abstract": "Translational research requires data at multiple scales of biological organization. Advancements in sequencing and multi-omics technologies have increased the availability of these data but researchers face significant integration challenges. Knowledge graphs (KGs) are used to model complex phenomena, and methods exist to automatically construct them. However, tackling complex biomedical integration problems requires flexibility in the way knowledge is modeled. Moreover, existing KG construction methods provide robust tooling at the cost of fixed or limited choices among knowledge representation models. PheKnowLator (Phenotype Knowledge Translator) is a semantic ecosystem for automating the FAIR (Findable, Accessible, Interoperable, and Reusable) construction of ontologically grounded KGs with fully customizable knowledge representation. The ecosystem includes KG construction resources (e.g., data preparation APIs), analysis tools (e.g., SPARQL endpoints and abstraction algorithms), and benchmarks (e.g., prebuilt KGs and embeddings). We evaluate the ecosystem by surveying open-source KG construction methods and analyzing its computational performance when constructing 12 large-scale KGs. With flexible knowledge representation, PheKnowLator enables fully customizable KGs without compromising performance or usability.", "url": "https://arxiv.org/abs/2307.05727"}, {"metadata": {"arXiv": "2307.05793", "Date": "Tue, 11 Jul 2023 20:40:19 ", "Title": "Neuro-Inspired Efficient Map Building via Fragmentation and Recall", "Authors": ["Jaedong Hwang", "Zhang-Wei Hong", "Eric Chen", "Akhilan Boopathy", "Pulkit Agrawal", "Ila Fiete"], "Categories": "cs.AI cs.RO"}, "abstract": "Animals and robots navigate through environments by building and refining maps of the space. These maps enable functions including navigating back to home, planning, search, and foraging. In large environments, exploration of the space is a hard problem: agents can become stuck in local regions. Here, we use insights from neuroscience to propose and apply the concept of Fragmentation-and-Recall (FarMap), with agents solving the mapping problem by building local maps via a surprisal-based clustering of space, which they use to set subgoals for spatial exploration. Agents build and use a local map to predict their observations; high surprisal leads to a ``fragmentation event'' that truncates the local map. At these events, the recent local map is placed into long-term memory (LTM), and a different local map is initialized. If observations at a fracture point match observations in one of the stored local maps, that map is recalled (and thus reused) from LTM. The fragmentation points induce a natural online clustering of the larger space, forming a set of intrinsic potential subgoals that are stored in LTM as a topological graph. Agents choose their next subgoal from the set of near and far potential subgoals from within the current local map or LTM, respectively. Thus, local maps guide exploration locally, while LTM promotes global exploration. We evaluate FarMap on complex procedurally-generated spatial environments to demonstrate that this mapping strategy much more rapidly covers the environment (number of agent steps and wall clock time) and is more efficient in active memory usage, without loss of performance.", "url": "https://arxiv.org/abs/2307.05793"}, {"metadata": {"arXiv": "2307.06033", "Date": "Wed, 12 Jul 2023 09:25:56 ", "Title": "AI-Generated Imagery: A New Era for the `Readymade'", "Authors": ["Amy Smith and Michael Cook"], "Categories": "cs.AI cs.CY", "Comments": ["5 pages", "1 figure"]}, "abstract": "While the term `art' defies any concrete definition, this paper aims to examine how digital images produced by generative AI systems, such as Midjourney, have come to be so regularly referred to as such. The discourse around the classification of AI-generated imagery as art is currently somewhat homogeneous, lacking the more nuanced aspects that would apply to more traditional modes of artistic media production. This paper aims to bring important philosophical considerations to the surface of the discussion around AI-generated imagery in the context of art. We employ existing philosophical frameworks and theories of language to suggest that some AI-generated imagery, by virtue of its visual properties within these frameworks, can be presented as `readymades' for consideration as art.", "url": "https://arxiv.org/abs/2307.06033"}, {"metadata": {"arXiv": "2307.06082", "Date": "Wed, 12 Jul 2023 11:08:24 ", "Title": "VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View", "Authors": ["Raphael Schumann and Wanrong Zhu and Weixi Feng and Tsu-Jui Fu and Stefan Riezler and William Yang Wang"], "Categories": "cs.AI cs.CL cs.CV"}, "abstract": "Incremental decision making in real-world environments is one of the most challenging tasks in embodied artificial intelligence. One particularly demanding scenario is Vision and Language Navigation~(VLN) which requires visual and natural language understanding as well as spatial and temporal reasoning capabilities. The embodied agent needs to ground its understanding of navigation instructions in observations of a real-world environment like Street View. Despite the impressive results of LLMs in other research areas, it is an ongoing problem of how to best connect them with an interactive visual environment. In this work, we propose VELMA, an embodied LLM agent that uses a verbalization of the trajectory and of visual environment observations as contextual prompt for the next action. Visual information is verbalized by a pipeline that extracts landmarks from the human written navigation instructions and uses CLIP to determine their visibility in the current panorama view. We show that VELMA is able to successfully follow navigation instructions in Street View with only two in-context examples. We further finetune the LLM agent on a few thousand examples and achieve 25%-30% relative improvement in task completion over the previous state-of-the-art for two datasets.", "url": "https://arxiv.org/abs/2307.06082"}, {"metadata": {"arXiv": "2307.06126", "Date": "Wed, 12 Jul 2023 12:25:37 ", "Title": "Guided Bottom-Up Interactive Constraint Acquisition", "Authors": ["Dimos Tsouros", "Senne Berden", "Tias Guns"], "Categories": "cs.AI"}, "abstract": "Constraint Acquisition (CA) systems can be used to assist in the modeling of constraint satisfaction problems. In (inter)active CA, the system is given a set of candidate constraints and posts queries to the user with the goal of finding the right constraints among the candidates. Current interactive CA algorithms suffer from at least two major bottlenecks. First, in order to converge, they require a large number of queries to be asked to the user. Second, they cannot handle large sets of candidate constraints, since these lead to large waiting times for the user. For this reason, the user must have fairly precise knowledge about what constraints the system should consider. In this paper, we alleviate these bottlenecks by presenting two novel methods that improve the efficiency of CA. First, we introduce a bottom-up approach named GrowAcq that reduces the maximum waiting time for the user and allows the system to handle much larger sets of candidate constraints. It also reduces the total number of queries for problems in which the target constraint network is not sparse. Second, we propose a probability-based method to guide query generation and show that it can significantly reduce the number of queries required to converge. We also propose a new technique that allows the use of openly accessible CP solvers in query generation, removing the dependency of existing methods on less well-maintained custom solvers that are not publicly available. Experimental results show that our proposed methods outperform state-of-the-art CA methods, reducing the number of queries by up to 60%. Our methods work well even in cases where the set of candidate constraints is 50 times larger than the ones commonly used in the literature.", "url": "https://arxiv.org/abs/2307.06126"}, {"metadata": {"arXiv": "2307.06159", "Date": "Wed, 12 Jul 2023 13:32:24 ", "Title": "Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems", "Authors": ["Catholijn M. Jonker", "Luciano Cavalcante Siebert and Pradeep K. Murukannaiah"], "Categories": "cs.AI cs.CY", "Comments": ["Accepted for publication at the Research Handbook on Meaningful Human Control of Artificial Intelligence Systems"]}, "abstract": "With the growing capabilities and pervasiveness of AI systems, societies must collectively choose between reduced human autonomy, endangered democracies and limited human rights, and AI that is aligned to human and social values, nurturing collaboration, resilience, knowledge and ethical behaviour. In this chapter, we introduce the notion of self-reflective AI systems for meaningful human control over AI systems. Focusing on decision support systems, we propose a framework that integrates knowledge from psychology and philosophy with formal reasoning methods and machine learning approaches to create AI systems responsive to human values and social norms. We also propose a possible research approach to design and develop self-reflective capability in AI systems. Finally, we argue that self-reflective AI systems can lead to self-reflective hybrid systems (human + AI), thus increasing meaningful human control and empowering human moral reasoning by providing comprehensible information and insights on possible human moral blind spots.", "url": "https://arxiv.org/abs/2307.06159"}, {"metadata": {"arXiv": "2307.05561", "Date": "Sun, 09 Jul 2023 17:33:13 ", "Title": "TransPose: A Transformer-based 6D Object Pose Estimation Network with Depth Refinement", "Authors": ["Mahmoud Abdulsalam and Nabil Aouf"], "Categories": "cs.CV cs.AI"}, "abstract": "As demand for robotics manipulation application increases, accurate vision-based 6D pose estimation becomes essential for autonomous operations. Convolutional Neural Networks (CNNs) based approaches for pose estimation have been previously introduced. However, the quest for better performance still persists especially for accurate robotics manipulation. This quest extends to the Agri-robotics domain. In this paper, we propose TransPose, an improved Transformer-based 6D pose estimation with a depth refinement module. The architecture takes in only an RGB image as input with no additional supplementing modalities such as depth or thermal images. The architecture encompasses an innovative lighter depth estimation network that estimates depth from an RGB image using feature pyramid with an up-sampling method. A transformer-based detection network with additional prediction heads is proposed to directly regress the object's centre and predict the 6D pose of the target. A novel depth refinement module is then used alongside the predicted centers, 6D poses and depth patches to refine the accuracy of the estimated 6D pose. We extensively compared our results with other state-of-the-art methods and analysed our results for fruit-picking applications. The results we achieved show that our proposed technique outperforms the other methods available in the literature.", "url": "https://arxiv.org/abs/2307.05561"}, {"metadata": {"arXiv": "2307.05663", "Date": "Tue, 11 Jul 2023 17:57:40 ", "Title": "Objaverse-XL: A Universe of 10M+ 3D Objects", "Authors": ["Matt Deitke", "Ruoshi Liu", "Matthew Wallingford", "Huong Ngo", "Oscar Michel", "Aditya Kusupati", "Alan Fan", "Christian Laforte", "Vikram Voleti", "Samir Yitzhak Gadre", "Eli VanderBilt", "Aniruddha Kembhavi", "Carl Vondrick", "Georgia Gkioxari", "Kiana Ehsani", "Ludwig Schmidt", "Ali Farhadi"], "Categories": "cs.CV cs.AI"}, "abstract": "Natural language processing and 2D vision models have attained remarkable proficiency on many tasks primarily by escalating the scale of training data. However, 3D vision tasks have not seen the same progress, in part due to the challenges of acquiring high-quality 3D data. In this work, we present Objaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises deduplicated 3D objects from a diverse set of sources, including manually designed objects, photogrammetry scans of landmarks and everyday items, and professional scans of historic and antique artifacts. Representing the largest scale and diversity in the realm of 3D datasets, Objaverse-XL enables significant new possibilities for 3D vision. Our experiments demonstrate the improvements enabled with the scale provided by Objaverse-XL. We show that by training Zero123 on novel view synthesis, utilizing over 100 million multi-view rendered images, we achieve strong zero-shot generalization abilities. We hope that releasing Objaverse-XL will enable further innovations in the field of 3D vision at scale.", "url": "https://arxiv.org/abs/2307.05663"}, {"metadata": {"arXiv": "2307.05766", "Date": "Tue, 11 Jul 2023 19:47:05 ", "Title": "Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting", "Authors": ["Chantal Pellegrini", "Matthias Keicher", "Ege \\\"Ozsoy", "Nassir Navab"], "Categories": "cs.CV cs.AI", "Comments": ["accepted at MICCAI 2023"]}, "abstract": "Radiology reporting is a crucial part of the communication between radiologists and other medical professionals, but it can be time-consuming and error-prone. One approach to alleviate this is structured reporting, which saves time and enables a more accurate evaluation than free-text reports. However, there is limited research on automating structured reporting, and no public benchmark is available for evaluating and comparing different methods. To close this gap, we introduce Rad-ReStruct, a new benchmark dataset that provides fine-grained, hierarchically ordered annotations in the form of structured reports for X-Ray images. We model the structured reporting task as hierarchical visual question answering (VQA) and propose hi-VQA, a novel method that considers prior context in the form of previously asked questions and answers for populating a structured radiology report. Our experiments show that hi-VQA achieves competitive performance to the state-of-the-art on the medical VQA benchmark VQARad while performing best among methods without domain-specific vision-language pretraining and provides a strong baseline on Rad-ReStruct. Our work represents a significant step towards the automated population of structured radiology reports and provides a valuable first benchmark for future research in this area. We will make all annotations and our code for annotation generation, model evaluation, and training publicly available upon acceptance. Our dataset and code is available at https://github.com/ChantalMP/Rad-ReStruct.", "url": "https://arxiv.org/abs/2307.05766"}, {"metadata": {"arXiv": "2307.05784", "Date": "Tue, 11 Jul 2023 20:23:23 ", "Title": "EgoAdapt: A multi-stream evaluation study of adaptation to real-world egocentric user video", "Authors": ["Matthias De Lange", "Hamid Eghbalzadeh", "Reuben Tan", "Michael Iuzzolino", "Franziska Meier", "Karl Ridgeway"], "Categories": "cs.CV cs.AI", "Comments": ["Preprint"]}, "abstract": "In egocentric action recognition a single population model is typically trained and subsequently embodied on a head-mounted device, such as an augmented reality headset. While this model remains static for new users and environments, we introduce an adaptive paradigm of two phases, where after pretraining a population model, the model adapts on-device and online to the user's experience. This setting is highly challenging due to the change from population to user domain and the distribution shifts in the user's data stream. Coping with the latter in-stream distribution shifts is the focus of continual learning, where progress has been rooted in controlled benchmarks but challenges faced in real-world applications often remain unaddressed. We introduce EgoAdapt, a benchmark for real-world egocentric action recognition that facilitates our two-phased adaptive paradigm, and real-world challenges naturally occur in the egocentric video streams from Ego4d, such as long-tailed action distributions and large-scale classification over 2740 actions. We introduce an evaluation framework that directly exploits the user's data stream with new metrics to measure the adaptation gain over the population model, online generalization, and hindsight performance. In contrast to single-stream evaluation in existing works, our framework proposes a meta-evaluation that aggregates the results from 50 independent user streams. We provide an extensive empirical study for finetuning and experience replay.", "url": "https://arxiv.org/abs/2307.05784"}, {"metadata": {"arXiv": "2307.05786", "Date": "Tue, 11 Jul 2023 20:27:12 ", "Title": "Merging multiple input descriptors and supervisors in a deep neural network for tractogram filtering", "Authors": ["Daniel J\\\"orgens", "Pierre-Marc Jodoin", "Maxime Descoteaux", "Rodrigo Moreno"], "Categories": "cs.CV cs.AI", "Comments": ["21 pages", "8 figures"]}, "abstract": "One of the main issues of the current tractography methods is their high false-positive rate. Tractogram filtering is an option to remove false-positive streamlines from tractography data in a post-processing step. In this paper, we train a deep neural network for filtering tractography data in which every streamline of a tractogram is classified as {\\em plausible, implausible}, or {\\em inconclusive}. For this, we use four different tractogram filtering strategies as supervisors: TractQuerier, RecobundlesX, TractSeg, and an anatomy-inspired filter. Their outputs are combined to obtain the classification labels for the streamlines. We assessed the importance of different types of information along the streamlines for performing this classification task, including the coordinates of the streamlines, diffusion data, landmarks, T1-weighted information, and a brain parcellation. We found that the streamline coordinates are the most relevant followed by the diffusion data in this particular classification task.", "url": "https://arxiv.org/abs/2307.05786"}, {"metadata": {"arXiv": "2307.05832", "Date": "Tue, 11 Jul 2023 22:56:55 ", "Title": "Bag of Views: An Appearance-based Approach to Next-Best-View Planning for 3D Reconstruction", "Authors": ["Sara Hatami Gazani", "Matthew Tucsok", "Iraj Mantegh", "Homayoun Najjaran"], "Categories": "cs.CV cs.AI", "Comments": ["Submitted to IEEE Robotics and Automation Letters (RA-L)"], "MSC-class": "68T45", "ACM-class": "I.2.10; I.2.9; I.4.10; I.5.3"}, "abstract": "UAV-based intelligent data acquisition for 3D reconstruction and monitoring of infrastructure has been experiencing an increasing surge of interest due to the recent advancements in image processing and deep learning-based techniques. View planning is an essential part of this task that dictates the information capture strategy and heavily impacts the quality of the 3D model generated from the captured data. Recent methods have used prior knowledge or partial reconstruction of the target to accomplish view planning for active reconstruction; the former approach poses a challenge for complex or newly identified targets while the latter is computationally expensive. In this work, we present Bag-of-Views (BoV), a fully appearance-based model used to assign utility to the captured views for both offline dataset refinement and online next-best-view (NBV) planning applications targeting the task of 3D reconstruction. With this contribution, we also developed the View Planning Toolbox (VPT), a lightweight package for training and testing machine learning-based view planning frameworks, custom view dataset generation of arbitrary 3D scenes, and 3D reconstruction. Through experiments which pair a BoV-based reinforcement learning model with VPT, we demonstrate the efficacy of our model in reducing the number of required views for high-quality reconstructions in dataset refinement and NBV planning.", "url": "https://arxiv.org/abs/2307.05832"}, {"metadata": {"arXiv": "2307.05913", "Date": "Wed, 12 Jul 2023 04:40:00 ", "Title": "Close-up View synthesis by Interpolating Optical Flow", "Authors": ["Xinyi Bai", "Ze Wang", "Lu Yang", "Hong Cheng"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["4 pages", "5 figures"], "MSC-class": "I.4.5, I.4.0, I.4.1"}, "abstract": "The virtual viewpoint is perceived as a new technique in virtual navigation, as yet not supported due to the lack of depth information and obscure camera parameters. In this paper, a method for achieving close-up virtual view is proposed and it only uses optical flow to build parallax effects to realize pseudo 3D projection without using depth sensor. We develop a bidirectional optical flow method to obtain any virtual viewpoint by proportional interpolation of optical flow. Moreover, with the ingenious application of the optical-flow-value, we achieve clear and visual-fidelity magnified results through lens stretching in any corner, which overcomes the visual distortion and image blur through viewpoint magnification and transition in Google Street View system.", "url": "https://arxiv.org/abs/2307.05913"}, {"metadata": {"arXiv": "2307.05921", "Date": "Wed, 12 Jul 2023 05:36:47 ", "Title": "Reading Radiology Imaging Like The Radiologist", "Authors": ["Yuhao Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Automated radiology report generation aims to generate radiology reports that contain rich, fine-grained descriptions of radiology imaging. Compared with image captioning in the natural image domain, medical images are very similar to each other, with only minor differences in the occurrence of diseases. Given the importance of these minor differences in the radiology report, it is crucial to encourage the model to focus more on the subtle regions of disease occurrence. Secondly, the problem of visual and textual data biases is serious. Not only do normal cases make up the majority of the dataset, but sentences describing areas with pathological changes also constitute only a small part of the paragraph. Lastly, generating medical image reports involves the challenge of long text generation, which requires more expertise and empirical training in medical knowledge. As a result, the difficulty of generating such reports is increased. To address these challenges, we propose a disease-oriented retrieval framework that utilizes similar reports as prior knowledge references. We design a factual consistency captioning generator to generate more accurate and factually consistent disease descriptions. Our framework can find most similar reports for a given disease from the CXR database by retrieving a disease-oriented mask consisting of the position and morphological characteristics. By referencing the disease-oriented similar report and the visual features, the factual consistency model can generate a more accurate radiology report.", "url": "https://arxiv.org/abs/2307.05921"}, {"metadata": {"arXiv": "2307.05929", "Date": "Wed, 12 Jul 2023 05:49:21 ", "Title": "A New Dataset and Comparative Study for Aphid Cluster Detection", "Authors": ["Tianxiao Zhang", "Kaidong Li", "Xiangyu Chen", "Cuncong Zhong", "Bo Luo", "Ivan Grijalva Teran", "Brian McCornack", "Daniel Flippo", "Ajay Sharda", "Guanghui Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Aphids are one of the main threats to crops, rural families, and global food security. Chemical pest control is a necessary component of crop production for maximizing yields, however, it is unnecessary to apply the chemical approaches to the entire fields in consideration of the environmental pollution and the cost. Thus, accurately localizing the aphid and estimating the infestation level is crucial to the precise local application of pesticides. Aphid detection is very challenging as each individual aphid is really small and all aphids are crowded together as clusters. In this paper, we propose to estimate the infection level by detecting aphid clusters. We have taken millions of images in the sorghum fields, manually selected 5,447 images that contain aphids, and annotated each aphid cluster in the image. To use these images for machine learning models, we crop the images into patches and created a labeled dataset with over 151,000 image patches. Then, we implement and compare the performance of four state-of-the-art object detection models.", "url": "https://arxiv.org/abs/2307.05929"}, {"metadata": {"arXiv": "2307.06052", "Date": "Wed, 12 Jul 2023 10:12:57 ", "Title": "Visualization for Multivariate Gaussian Anomaly Detection in Images", "Authors": ["Joao P C Bertoldo and David Arrustico"], "Categories": "cs.CV cs.AI", "Comments": ["6 pages", "8 figures", "accepted to 2023 Twelfth International Conference on Image Processing Theory", "Tools and Applications (IPTA)"]}, "abstract": "This paper introduces a simplified variation of the PaDiM (Pixel-Wise Anomaly Detection through Instance Modeling) method for anomaly detection in images, fitting a single multivariate Gaussian (MVG) distribution to the feature vectors extracted from a backbone convolutional neural network (CNN) and using their Mahalanobis distance as the anomaly score. We introduce an intermediate step in this framework by applying a whitening transformation to the feature vectors, which enables the generation of heatmaps capable of visually explaining the features learned by the MVG. The proposed technique is evaluated on the MVTec-AD dataset, and the results show the importance of visual model validation, providing insights into issues in this framework that were otherwise invisible. The visualizations generated for this paper are publicly available at https://doi.org/10.5281/zenodo.7937978.", "url": "https://arxiv.org/abs/2307.06052"}, {"metadata": {"arXiv": "2307.06118", "Date": "Wed, 12 Jul 2023 12:19:36 ", "Title": "TreeFormer: a Semi-Supervised Transformer-based Framework for Tree Counting from a Single High Resolution Image", "Authors": ["Hamed Amini Amirkolaee", "Miaojing Shi", "Mark Mulligan"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted in IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING"]}, "abstract": "Automatic tree density estimation and counting using single aerial and satellite images is a challenging task in photogrammetry and remote sensing, yet has an important role in forest management. In this paper, we propose the first semisupervised transformer-based framework for tree counting which reduces the expensive tree annotations for remote sensing images. Our method, termed as TreeFormer, first develops a pyramid tree representation module based on transformer blocks to extract multi-scale features during the encoding stage. Contextual attention-based feature fusion and tree density regressor modules are further designed to utilize the robust features from the encoder to estimate tree density maps in the decoder. Moreover, we propose a pyramid learning strategy that includes local tree density consistency and local tree count ranking losses to utilize unlabeled images into the training process. Finally, the tree counter token is introduced to regulate the network by computing the global tree counts for both labeled and unlabeled images. Our model was evaluated on two benchmark tree counting datasets, Jiangsu, and Yosemite, as well as a new dataset, KCL-London, created by ourselves. Our TreeFormer outperforms the state of the art semi-supervised methods under the same setting and exceeds the fully-supervised methods using the same number of labeled images. The codes and datasets are available at https://github.com/HAAClassic/TreeFormer.", "url": "https://arxiv.org/abs/2307.06118"}, {"metadata": {"arXiv": "2307.06166", "Date": "Wed, 12 Jul 2023 13:46:28 ", "Title": "Can Vision-Language Models be a Good Guesser? Exploring VLMs for Times and Location Reasoning", "Authors": ["Gengyuan Zhang", "Yurui Zhang", "Kerui Zhang", "Volker Tresp"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages"]}, "abstract": "Vision-Language Models (VLMs) are expected to be capable of reasoning with commonsense knowledge as human beings. One example is that humans can reason where and when an image is taken based on their knowledge. This makes us wonder if, based on visual cues, Vision-Language Models that are pre-trained with large-scale image-text resources can achieve and even outperform human's capability in reasoning times and location. To address this question, we propose a two-stage \\recognition\\space and \\reasoning\\space probing task, applied to discriminative and generative VLMs to uncover whether VLMs can recognize times and location-relevant features and further reason about it. To facilitate the investigation, we introduce WikiTiLo, a well-curated image dataset compromising images with rich socio-cultural cues. In the extensive experimental studies, we find that although VLMs can effectively retain relevant features in visual encoders, they still fail to make perfect reasoning. We will release our dataset and codes to facilitate future studies.", "url": "https://arxiv.org/abs/2307.06166"}, {"metadata": {"arXiv": "2307.06187", "Date": "Wed, 12 Jul 2023 14:26:46 ", "Title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems", "Authors": ["Nathalia Nascimento", "Paulo Alencar", "Donald Cowan"], "Categories": "cs.MA cs.AI cs.CL", "Comments": ["6 pages", "submitted"]}, "abstract": "In autonomic computing, self-adaptation has been proposed as a fundamental paradigm to manage the complexity of multiagent systems (MASs). This achieved by extending a system with support to monitor and adapt itself to achieve specific concerns of interest. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, improving the expressiveness of the interaction communication with MASs is not without challenges. In this sense, the interplay between self-adaptive systems and effective communication is crucial for future MAS advancements. In this paper, we propose the integration of large language models (LLMs) such as GPT-based technologies into multiagent systems. We anchor our methodology on the MAPE-K model, which is renowned for its robust support in monitoring, analyzing, planning, and executing system adaptations in response to dynamic environments. We also present a practical illustration of the proposed approach, in which we implement and assess a basic MAS-based application. The approach significantly advances the state-of-the-art of self-adaptive systems by proposing a new paradigm for MAS self-adaptation of autonomous systems based on LLM capabilities.", "url": "https://arxiv.org/abs/2307.06187"}, {"metadata": {"arXiv": "2307.05933", "Date": "Wed, 12 Jul 2023 05:58:59 ", "Title": "BiRP: Learning Robot Generalized Bimanual Coordination using Relative Parameterization Method on Human Demonstration", "Authors": ["Junjia Liu", "Hengyi Sim", "Chenzui Li", "and Fei Chen"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "4 figures. Accepted by IEEE Conference on Decision and Control (IEEE CDC 2023)"]}, "abstract": "Human bimanual manipulation can perform more complex tasks than a simple combination of two single arms, which is credited to the spatio-temporal coordination between the arms. However, the description of bimanual coordination is still an open topic in robotics. This makes it difficult to give an explainable coordination paradigm, let alone applied to robotics. In this work, we divide the main bimanual tasks in human daily activities into two types: leader-follower and synergistic coordination. Then we propose a relative parameterization method to learn these types of coordination from human demonstration. It represents coordination as Gaussian mixture models from bimanual demonstration to describe the change in the importance of coordination throughout the motions by probability. The learned coordinated representation can be generalized to new task parameters while ensuring spatio-temporal coordination. We demonstrate the method using synthetic motions and human demonstration data and deploy it to a humanoid robot to perform a generalized bimanual coordination motion. We believe that this easy-to-use bimanual learning from demonstration (LfD) method has the potential to be used as a data augmentation plugin for robot large manipulation model training. The corresponding codes are open-sourced in https://github.com/Skylark0924/Rofunc.", "url": "https://arxiv.org/abs/2307.05933"}, {"metadata": {"arXiv": "2307.06135", "Date": "Wed, 12 Jul 2023 12:37:55 ", "Title": "SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning", "Authors": ["Krishan Rana", "Jesse Haviland", "Sourav Garg", "Jad Abou-Chakra", "Ian Reid and Niko Suenderhauf"], "Categories": "cs.RO cs.AI", "Comments": ["Under review for CoRL 2023. Project page can be found here: https://sayplan.github.io"]}, "abstract": "Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a semantic search for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an iterative replanning pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors, 36 rooms and 140 objects, and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute.", "url": "https://arxiv.org/abs/2307.06135"}, {"metadata": {"arXiv": "2307.06013", "Date": "Wed, 12 Jul 2023 08:51:20 ", "Title": "An Effective and Efficient Time-aware Entity Alignment Framework via Two-aspect Three-view Label Propagation", "Authors": ["Li Cai", "Xin Mao", "Youshao Xiao", "Changxu Wu", "Man Lan"], "Categories": "cs.AI cs.LG", "Comments": ["Accepted by IJCAI 2023"]}, "abstract": "Entity alignment (EA) aims to find the equivalent entity pairs between different knowledge graphs (KGs), which is crucial to promote knowledge fusion. With the wide use of temporal knowledge graphs (TKGs), time-aware EA (TEA) methods appear to enhance EA. Existing TEA models are based on Graph Neural Networks (GNN) and achieve state-of-the-art (SOTA) performance, but it is difficult to transfer them to large-scale TKGs due to the scalability issue of GNN. In this paper, we propose an effective and efficient non-neural EA framework between TKGs, namely LightTEA, which consists of four essential components: (1) Two-aspect Three-view Label Propagation, (2) Sparse Similarity with Temporal Constraints, (3) Sinkhorn Operator, and (4) Temporal Iterative Learning. All of these modules work together to improve the performance of EA while reducing the time consumption of the model. Extensive experiments on public datasets indicate that our proposed model significantly outperforms the SOTA methods for EA between TKGs, and the time consumed by LightTEA is only dozens of seconds at most, no more than 10% of the most efficient TEA method.", "url": "https://arxiv.org/abs/2307.06013"}, {"metadata": {"arXiv": "2307.06152", "Date": "Wed, 12 Jul 2023 13:20:18 ", "Title": "Maneuver Decision-Making Through Automatic Curriculum Reinforcement Learning Without Handcrafted Reward functions", "Authors": ["Zhang Hong-Peng"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "Maneuver decision-making is the core of unmanned combat aerial vehicle for autonomous air combat. To solve this problem, we propose an automatic curriculum reinforcement learning method, which enables agents to learn effective decisions in air combat from scratch. The range of initial states are used for distinguishing curricula of different difficulty levels, thereby maneuver decision is divided into a series of sub-tasks from easy to difficult, and test results are used to change sub-tasks. As sub-tasks change, agents gradually learn to complete a series of sub-tasks from easy to difficult, enabling them to make effective maneuvering decisions to cope with various states without the need to spend effort designing reward functions. The ablation studied show that the automatic curriculum learning proposed in this article is an essential component for training through reinforcement learning, namely, agents cannot complete effective decisions without curriculum learning. Simulation experiments show that, after training, agents are able to make effective decisions given different states, including tracking, attacking and escaping, which are both rational and interpretable.", "url": "https://arxiv.org/abs/2307.06152"}, {"metadata": {"arXiv": "2307.05563", "Date": "Sun, 09 Jul 2023 22:09:15 ", "Title": "RidgeBase: A Cross-Sensor Multi-Finger Contactless Fingerprint Dataset", "Authors": ["Bhavin Jawade", "Deen Dayal Mohan", "Srirangaraj Setlur", "Nalini Ratha and Venu Govindaraju"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Paper accepted at IJCB 2022"], "Journal-ref": "2022 IEEE International Joint Conference on Biometrics (IJCB), Abu Dhabi, United Arab Emirates, 2022, pp. 1-9", "DOI": "10.1109/IJCB54206.2022.10007936"}, "abstract": "Contactless fingerprint matching using smartphone cameras can alleviate major challenges of traditional fingerprint systems including hygienic acquisition, portability and presentation attacks. However, development of practical and robust contactless fingerprint matching techniques is constrained by the limited availability of large scale real-world datasets. To motivate further advances in contactless fingerprint matching across sensors, we introduce the RidgeBase benchmark dataset. RidgeBase consists of more than 15,000 contactless and contact-based fingerprint image pairs acquired from 88 individuals under different background and lighting conditions using two smartphone cameras and one flatbed contact sensor. Unlike existing datasets, RidgeBase is designed to promote research under different matching scenarios that include Single Finger Matching and Multi-Finger Matching for both contactless- to-contactless (CL2CL) and contact-to-contactless (C2CL) verification and identification. Furthermore, due to the high intra-sample variance in contactless fingerprints belonging to the same finger, we propose a set-based matching protocol inspired by the advances in facial recognition datasets. This protocol is specifically designed for pragmatic contactless fingerprint matching that can account for variances in focus, polarity and finger-angles. We report qualitative and quantitative baseline results for different protocols using a COTS fingerprint matcher (Verifinger) and a Deep CNN based approach on the RidgeBase dataset. The dataset can be downloaded here: https://www.buffalo.edu/cubs/research/datasets/ridgebase-benchmark-dataset.html", "url": "https://arxiv.org/abs/2307.05563"}, {"metadata": {"arXiv": "2307.05587", "Date": "Mon, 10 Jul 2023 15:47:13 ", "Title": "Active Learning for Video Classification with Frame Level Queries", "Authors": ["Debanjan Goswami", "Shayok Chakraborty"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Deep learning algorithms have pushed the boundaries of computer vision research and have depicted commendable performance in a variety of applications. However, training a robust deep neural network necessitates a large amount of labeled training data, acquiring which involves significant time and human effort. This problem is even more serious for an application like video classification, where a human annotator has to watch an entire video end-to-end to furnish a label. Active learning algorithms automatically identify the most informative samples from large amounts of unlabeled data; this tremendously reduces the human annotation effort in inducing a machine learning model, as only the few samples that are identified by the algorithm, need to be labeled manually. In this paper, we propose a novel active learning framework for video classification, with the goal of further reducing the labeling onus on the human annotators. Our framework identifies a batch of exemplar videos, together with a set of informative frames for each video; the human annotator needs to merely review the frames and provide a label for each video. This involves much less manual work than watching the complete video to come up with a label. We formulate a criterion based on uncertainty and diversity to identify the informative videos and exploit representative sampling techniques to extract a set of exemplar frames from each video. To the best of our knowledge, this is the first research effort to develop an active learning framework for video classification, where the annotators need to inspect only a few frames to produce a label, rather than watching the end-to-end video.", "url": "https://arxiv.org/abs/2307.05587"}, {"metadata": {"arXiv": "2307.05977", "Date": "Wed, 12 Jul 2023 07:48:29 ", "Title": "Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models", "Authors": ["Sanghyun Kim", "Seohyeon Jung", "Balhae Kim", "Moonseok Choi", "Jinwoo Shin", "Juho Lee"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["17 pages", "13 figures", "ICML 2023 Workshop on Challenges in Deployable Generative AI"]}, "abstract": "Large-scale image generation models, with impressive quality made possible by the vast amount of data available on the Internet, raise social concerns that these models may generate harmful or copyrighted content. The biases and harmfulness arise throughout the entire training process and are hard to completely remove, which have become significant hurdles to the safe deployment of these models. In this paper, we propose a method called SDD to prevent problematic content generation in text-to-image diffusion models. We self-distill the diffusion model to guide the noise estimate conditioned on the target removal concept to match the unconditional one. Compared to the previous methods, our method eliminates a much greater proportion of harmful content from the generated images without degrading the overall image quality. Furthermore, our method allows the removal of multiple concepts at once, whereas previous works are limited to removing a single concept at a time.", "url": "https://arxiv.org/abs/2307.05977"}, {"metadata": {"arXiv": "2307.06304", "Date": "Wed, 12 Jul 2023 17:01:03 ", "Title": "Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution", "Authors": ["Mostafa Dehghani", "Basil Mustafa", "Josip Djolonga", "Jonathan Heek", "Matthias Minderer", "Mathilde Caron", "Andreas Steiner", "Joan Puigcerver", "Robert Geirhos", "Ibrahim Alabdulmohsin", "Avital Oliver", "Piotr Padlewski", "Alexey Gritsenko", "Mario Lu\\v{c}i\\'c", "Neil Houlsby"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViT marks a departure from the standard, CNN-designed, input and modelling pipeline used by most computer vision models, and represents a promising direction for ViTs.", "url": "https://arxiv.org/abs/2307.06304"}, {"metadata": {"arXiv": "2307.05582", "Date": "Mon, 10 Jul 2023 14:39:57 ", "Title": "DBFed: Debiasing Federated Learning Framework based on Domain-Independent", "Authors": ["Jiale Li", "Zhixin Li", "Yibo Wang", "Yao Li", "Lei Wang"], "Categories": "cs.LG cs.AI cs.CY cs.DC"}, "abstract": "As digital transformation continues, enterprises are generating, managing, and storing vast amounts of data, while artificial intelligence technology is rapidly advancing. However, it brings challenges in information security and data security. Data security refers to the protection of digital information from unauthorized access, damage, theft, etc. throughout its entire life cycle. With the promulgation and implementation of data security laws and the emphasis on data security and data privacy by organizations and users, Privacy-preserving technology represented by federated learning has a wide range of application scenarios. Federated learning is a distributed machine learning computing framework that allows multiple subjects to train joint models without sharing data to protect data privacy and solve the problem of data islands. However, the data among multiple subjects are independent of each other, and the data differences in quality may cause fairness issues in federated learning modeling, such as data bias among multiple subjects, resulting in biased and discriminatory models. Therefore, we propose DBFed, a debiasing federated learning framework based on domain-independent, which mitigates model bias by explicitly encoding sensitive attributes during client-side training. This paper conducts experiments on three real datasets and uses five evaluation metrics of accuracy and fairness to quantify the effect of the model. Most metrics of DBFed exceed those of the other three comparative methods, fully demonstrating the debiasing effect of DBFed.", "url": "https://arxiv.org/abs/2307.05582"}, {"metadata": {"arXiv": "2307.05610", "Date": "Mon, 10 Jul 2023 22:40:10 ", "Title": "Substance or Style: What Does Your Image Embedding Know?", "Authors": ["Cyrus Rashtchian and Charles Herrmann and Chun-Sung Ferng and Ayan Chakrabarti and Dilip Krishnan and Deqing Sun and Da-Cheng Juan and Andrew Tomkins"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["27 pages", "9 figures"]}, "abstract": "Probes are small networks that predict properties of underlying data from embeddings, and they provide a targeted, effective way to illuminate the information contained in embeddings. While analysis through the use of probes has become standard in NLP, there has been much less exploration in vision. Image foundation models have primarily been evaluated for semantic content. Better understanding the non-semantic information in popular embeddings (e.g., MAE, SimCLR, or CLIP) will shed new light both on the training algorithms and on the uses for these foundation models. We design a systematic transformation prediction task and measure the visual content of embeddings along many axes, including image style, quality, and a range of natural and artificial transformations. Surprisingly, six embeddings (including SimCLR) encode enough non-semantic information to identify dozens of transformations. We also consider a generalization task, where we group similar transformations and hold out several for testing. We find that image-text models (CLIP and ALIGN) are better at recognizing new examples of style transfer than masking-based models (CAN and MAE). Overall, our results suggest that the choice of pre-training algorithm impacts the types of information in the embedding, and certain models are better than others for non-semantic downstream tasks.", "url": "https://arxiv.org/abs/2307.05610"}, {"metadata": {"arXiv": "2307.05614", "Date": "Mon, 10 Jul 2023 23:58:45 ", "Title": "Impact of Feature Encoding on Malware Classification Explainability", "Authors": ["Elyes Manai", "Mohamed Mejri and Jaouhar Fattahi"], "Categories": "cs.LG cs.AI", "Comments": ["This paper is accpeted in the 15th Edition of INTERNATIONAL CONFERENCE on Electronics", "Computers and Artificial Intelligence", "BUCHAREST", "ROMANIA (ECAI 2023)"]}, "abstract": "This paper investigates the impact of feature encoding techniques on the explainability of XAI (Explainable Artificial Intelligence) algorithms. Using a malware classification dataset, we trained an XGBoost model and compared the performance of two feature encoding methods: Label Encoding (LE) and One Hot Encoding (OHE). Our findings reveal a marginal performance loss when using OHE instead of LE. However, the more detailed explanations provided by OHE compensated for this loss. We observed that OHE enables deeper exploration of details in both global and local contexts, facilitating more comprehensive answers. Additionally, we observed that using OHE resulted in smaller explanation files and reduced analysis time for human analysts. These findings emphasize the significance of considering feature encoding techniques in XAI research and suggest potential for further exploration by incorporating additional encoding methods and innovative visualization approaches.", "url": "https://arxiv.org/abs/2307.05614"}, {"metadata": {"arXiv": "2307.05623", "Date": "Tue, 11 Jul 2023 04:58:45 ", "Title": "A DeepLearning Framework for Dynamic Estimation of Origin-Destination Sequence", "Authors": ["Zheli Xiong", "Defu Lian", "Enhong Chen", "Gang Chen and Xiaomin Cheng"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages,25 figures"], "ACM-class": "I.2.1"}, "abstract": "OD matrix estimation is a critical problem in the transportation domain. The principle method uses the traffic sensor measured information such as traffic counts to estimate the traffic demand represented by the OD matrix. The problem is divided into two categories: static OD matrix estimation and dynamic OD matrices sequence(OD sequence for short) estimation. The above two face the underdetermination problem caused by abundant estimated parameters and insufficient constraint information. In addition, OD sequence estimation also faces the lag challenge: due to different traffic conditions such as congestion, identical vehicle will appear on different road sections during the same observation period, resulting in identical OD demands correspond to different trips. To this end, this paper proposes an integrated method, which uses deep learning methods to infer the structure of OD sequence and uses structural constraints to guide traditional numerical optimization. Our experiments show that the neural network(NN) can effectively infer the structure of the OD sequence and provide practical constraints for numerical optimization to obtain better results. Moreover, the experiments show that provided structural information contains not only constraints on the spatial structure of OD matrices but also provides constraints on the temporal structure of OD sequence, which solve the effect of the lagging problem well.", "url": "https://arxiv.org/abs/2307.05623"}, {"metadata": {"arXiv": "2307.05624", "Date": "Tue, 11 Jul 2023 05:21:28 ", "Title": "CILF:Causality Inspired Learning Framework for Out-of-Distribution Vehicle Trajectory Prediction", "Authors": ["Shengyi Li", "Qifan Xue", "Yezhuo Zhang", "and Xuanpeng Li"], "Categories": "cs.LG cs.AI"}, "abstract": "Trajectory prediction is critical for autonomous driving vehicles. Most existing methods tend to model the correlation between history trajectory (input) and future trajectory (output). Since correlation is just a superficial description of reality, these methods rely heavily on the i.i.d. assumption and evince a heightened susceptibility to out-of-distribution data. To address this problem, we propose an Out-of- Distribution Causal Graph (OOD-CG), which explicitly defines the underlying causal structure of the data with three entangled latent features: 1) domain-invariant causal feature (IC), 2) domain-variant causal feature (VC), and 3) domain-variant non-causal feature (VN ). While these features are confounded by confounder (C) and domain selector (D). To leverage causal features for prediction, we propose a Causal Inspired Learning Framework (CILF), which includes three steps: 1) extracting domain-invariant causal feature by means of an invariance loss, 2) extracting domain variant feature by domain contrastive learning, and 3) separating domain-variant causal and non-causal feature by encouraging causal sufficiency. We evaluate the performance of CILF in different vehicle trajectory prediction models on the mainstream datasets NGSIM and INTERACTION. Experiments show promising improvements in CILF on domain generalization.", "url": "https://arxiv.org/abs/2307.05624"}, {"metadata": {"arXiv": "2307.05638", "Date": "Tue, 11 Jul 2023 09:37:52 ", "Title": "A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions", "Authors": ["Peng Yan", "Ahmed Abdulkadir", "Matthias Rosenthal", "Gerrit A. Schatte", "Benjamin F. Grewe", "Thilo Stadelmann"], "Categories": "cs.LG cs.AI", "Comments": ["21 pages", "4 figures", "2 tables"], "ACM-class": "I.2.0"}, "abstract": "Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, the algorithms demand large volumes of labeled training data. However, due to the dynamic nature of processes and the environment, it is impractical to acquire the needed data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, this learning framework solves new tasks even with little or no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applying deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We conclude this survey by underlining the challenges and limitations of deep transfer learning in industrial contexts. We also provide practical directions for solution design and implementation for these tasks, leading to specific, actionable suggestions.", "url": "https://arxiv.org/abs/2307.05638"}, {"metadata": {"arXiv": "2307.05639", "Date": "Tue, 11 Jul 2023 09:54:30 ", "Title": "Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks", "Authors": ["Danny D'Agostino", "Ilija Ilievski", "Christine Annette Shoemaker"], "Categories": "cs.LG cs.AI cs.NE stat.ML"}, "abstract": "Providing a model that achieves a strong predictive performance and at the same time is interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the Radial Basis Function Neural Network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models and the state-of-the-art deep learning-based embedding feature selection techniques. Our results demonstrate that the proposed model does not only yield an attractive prediction performance with respect to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link. https://github.com/dannyzx/GRBF-NNs", "url": "https://arxiv.org/abs/2307.05639"}, {"metadata": {"arXiv": "2307.05643", "Date": "Tue, 11 Jul 2023 10:38:31 ", "Title": "Multiobjective Hydropower Reservoir Operation Optimization with Transformer-Based Deep Reinforcement Learning", "Authors": ["Rixin Wu", "Ran Wang", "Jie Hao", "Qiang Wu", "Ping Wang"], "Categories": "cs.LG cs.AI", "Comments": ["11 figures", "16 pages", "submitted to Journal of Hydrology"]}, "abstract": "Due to shortage of water resources and increasing water demands, the joint operation of multireservoir systems for balancing power generation, ecological protection, and the residential water supply has become a critical issue in hydropower management. However, the numerous constraints and nonlinearity of multiple reservoirs make solving this problem time-consuming. To address this challenge, a deep reinforcement learning approach that incorporates a transformer framework is proposed. The multihead attention mechanism of the encoder effectively extracts information from reservoirs and residential areas, and the multireservoir attention network of the decoder generates suitable operational decisions. The proposed method is applied to Lake Mead and Lake Powell in the Colorado River Basin. The experimental results demonstrate that the transformer-based deep reinforcement learning approach can produce appropriate operational outcomes. Compared to a state-of-the-art method, the operation strategies produced by the proposed approach generate 10.11% more electricity, reduce the amended annual proportional flow deviation by 39.69%, and increase water supply revenue by 4.10%. Consequently, the proposed approach offers an effective method for the multiobjective operation of multihydropower reservoir systems.", "url": "https://arxiv.org/abs/2307.05643"}, {"metadata": {"arXiv": "2307.05704", "Date": "Tue, 11 Jul 2023 18:12:05 ", "Title": "A Causal Ordering Prior for Unsupervised Representation Learning", "Authors": ["Avinash Kori", "Pedro Sanchez", "Konstantinos Vilouras", "Ben Glocker", "Sotirios A. Tsaftaris"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Unsupervised representation learning with variational inference relies heavily on independence assumptions over latent variables. Causal representation learning (CRL), however, argues that factors of variation in a dataset are, in fact, causally related. Allowing latent variables to be correlated, as a consequence of causal relationships, is more realistic and generalisable. So far, provably identifiable methods rely on: auxiliary information, weak labels, and interventional or even counterfactual data. Inspired by causal discovery with functional causal models, we propose a fully unsupervised representation learning method that considers a data generation process with a latent additive noise model (ANM). We encourage the latent space to follow a causal ordering via loss function based on the Hessian of the latent distribution.", "url": "https://arxiv.org/abs/2307.05704"}, {"metadata": {"arXiv": "2307.05728", "Date": "Tue, 11 Jul 2023 18:55:27 ", "Title": "Towards A Scalable Solution for Improving Multi-Group Fairness in Compositional Classification", "Authors": ["James Atwood", "Tina Tian", "Ben Packer", "Meghana Deodhar", "Jilin Chen", "Alex Beutel", "Flavien Prost", "Ahmad Beirami"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Despite the rich literature on machine learning fairness, relatively little attention has been paid to remediating complex systems, where the final prediction is the combination of multiple classifiers and where multiple groups are present. In this paper, we first show that natural baseline approaches for improving equal opportunity fairness scale linearly with the product of the number of remediated groups and the number of remediated prediction labels, rendering them impractical. We then introduce two simple techniques, called {\\em task-overconditioning} and {\\em group-interleaving}, to achieve a constant scaling in this multi-group multi-label setup. Our experimental results in academic and real-world environments demonstrate the effectiveness of our proposal at mitigation within this environment.", "url": "https://arxiv.org/abs/2307.05728"}, {"metadata": {"arXiv": "2307.05747", "Date": "Sat, 08 Jul 2023 14:14:55 ", "Title": "Integrating Curricula with Replays: Its Effects on Continual Learning", "Authors": ["Ren Jie Tee and Mengmi Zhang"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["8 pages", "7 figures"]}, "abstract": "Humans engage in learning and reviewing processes with curricula when acquiring new skills or knowledge. This human learning behavior has inspired the integration of curricula with replay methods in continual learning agents. The goal is to emulate the human learning process, thereby improving knowledge retention and facilitating learning transfer. Existing replay methods in continual learning agents involve the random selection and ordering of data from previous tasks, which has shown to be effective. However, limited research has explored the integration of different curricula with replay methods to enhance continual learning. Our study takes initial steps in examining the impact of integrating curricula with replay methods on continual learning in three specific aspects: the interleaved frequency of replayed exemplars with training data, the sequence in which exemplars are replayed, and the strategy for selecting exemplars into the replay buffer. These aspects of curricula design align with cognitive psychology principles and leverage the benefits of interleaved practice during replays, easy-to-hard rehearsal, and exemplar selection strategy involving exemplars from a uniform distribution of difficulties. Based on our results, these three curricula effectively mitigated catastrophic forgetting and enhanced positive knowledge transfer, demonstrating the potential of curricula in advancing continual learning methodologies.", "url": "https://arxiv.org/abs/2307.05747"}, {"metadata": {"arXiv": "2307.05831", "Date": "Tue, 11 Jul 2023 22:53:09 ", "Title": "Memorization Through the Lens of Curvature of Loss Function Around Samples", "Authors": ["Isha Garg and Kaushik Roy"], "Categories": "cs.LG cs.AI", "Comments": ["Preprint"]}, "abstract": "Neural networks are overparametrized and easily overfit the datasets they train on. In the extreme case, it is shown that they can memorize a training set with fully randomized labels. We propose using the curvature of loss function around the training sample as a measure of its memorization, averaged over all training epochs. We use this to study the generalization versus memorization properties of different samples in popular image datasets. We visualize samples with the highest curvature of loss around them, and show that these visually correspond to long-tailed, mislabeled or conflicting samples. This analysis helps us find a, to the best of our knowledge, novel failure model on the CIFAR100 dataset, that of duplicated images with different labels. We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields high AUROC values for identifying the mislabeled samples.", "url": "https://arxiv.org/abs/2307.05831"}, {"metadata": {"arXiv": "2307.05834", "Date": "Tue, 11 Jul 2023 22:58:53 ", "Title": "Scaling Distributed Multi-task Reinforcement Learning with Experience Sharing", "Authors": ["Sanae Amani", "Khushbu Pahwa", "Vladimir Braverman", "Lin F. Yang"], "Categories": "cs.LG cs.AI"}, "abstract": "Recently, DARPA launched the ShELL program, which aims to explore how experience sharing can benefit distributed lifelong learning agents in adapting to new challenges. In this paper, we address this issue by conducting both theoretical and empirical research on distributed multi-task reinforcement learning (RL), where a group of $N$ agents collaboratively solves $M$ tasks without prior knowledge of their identities. We approach the problem by formulating it as linearly parameterized contextual Markov decision processes (MDPs), where each task is represented by a context that specifies the transition dynamics and rewards. To tackle this problem, we propose an algorithm called DistMT-LSVI. First, the agents identify the tasks, and then they exchange information through a central server to derive $\\epsilon$-optimal policies for the tasks. Our research demonstrates that to achieve $\\epsilon$-optimal policies for all $M$ tasks, a single agent using DistMT-LSVI needs to run a total number of episodes that is at most $\\tilde{\\mathcal{O}}({d^3H^6(\\epsilon^{-2}+c_{\\rm sep}^{-2})}\\cdot M/N)$, where $c_{\\rm sep}>0$ is a constant representing task separability, $H$ is the horizon of each episode, and $d$ is the feature dimension of the dynamics and rewards. Notably, DistMT-LSVI improves the sample complexity of non-distributed settings by a factor of $1/N$, as each agent independently learns $\\epsilon$-optimal policies for all $M$ tasks using $\\tilde{\\mathcal{O}}(d^3H^6M\\epsilon^{-2})$ episodes. Additionally, we provide numerical experiments conducted on OpenAI Gym Atari environments that validate our theoretical findings.", "url": "https://arxiv.org/abs/2307.05834"}, {"metadata": {"arXiv": "2307.05857", "Date": "Wed, 12 Jul 2023 00:35:19 ", "Title": "FAIRO: Fairness-aware Adaptation in Sequential-Decision Making for Human-in-the-Loop Systems", "Authors": ["Tianyu Zhao", "Mojtaba Taherisadr", "Salma Elmalaki"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "Achieving fairness in sequential-decision making systems within Human-in-the-Loop (HITL) environments is a critical concern, especially when multiple humans with different behavior and expectations are affected by the same adaptation decisions in the system. This human variability factor adds more complexity since policies deemed fair at one point in time may become discriminatory over time due to variations in human preferences resulting from inter- and intra-human variability. This paper addresses the fairness problem from an equity lens, considering human behavior variability, and the changes in human preferences over time. We propose FAIRO, a novel algorithm for fairness-aware sequential-decision making in HITL adaptation, which incorporates these notions into the decision-making process. In particular, FAIRO decomposes this complex fairness task into adaptive sub-tasks based on individual human preferences through leveraging the Options reinforcement learning framework. We design FAIRO to generalize to three types of HITL application setups that have the shared adaptation decision problem. Furthermore, we recognize that fairness-aware policies can sometimes conflict with the application's utility. To address this challenge, we provide a fairness-utility tradeoff in FAIRO, allowing system designers to balance the objectives of fairness and utility based on specific application requirements. Extensive evaluations of FAIRO on the three HITL applications demonstrate its generalizability and effectiveness in promoting fairness while accounting for human variability. On average, FAIRO can improve fairness compared with other methods across all three applications by 35.36%.", "url": "https://arxiv.org/abs/2307.05857"}, {"metadata": {"arXiv": "2307.05862", "Date": "Wed, 12 Jul 2023 01:11:52 ", "Title": "Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes", "Authors": ["Connor Toups", "Rishi Bommasani", "Kathleen A. Creel", "Sarah H. Bana", "Dan Jurafsky", "Percy Liang"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["All code is available at https://github.com/rishibommasani/EcosystemLevelAnalysis"]}, "abstract": "Machine learning is traditionally studied at the model level: researchers measure and improve the accuracy, robustness, bias, efficiency, and other dimensions of specific models. In practice, the societal impact of machine learning is determined by the surrounding context of machine learning deployments. To capture this, we introduce ecosystem-level analysis: rather than analyzing a single model, we consider the collection of models that are deployed in a given context. For example, ecosystem-level analysis in hiring recognizes that a job candidate's outcomes are not only determined by a single hiring algorithm or firm but instead by the collective decisions of all the firms they applied to. Across three modalities (text, images, speech) and 11 datasets, we establish a clear trend: deployed machine learning is prone to systemic failure, meaning some users are exclusively misclassified by all models available. Even when individual models improve at the population level over time, we find these improvements rarely reduce the prevalence of systemic failure. Instead, the benefits of these improvements predominantly accrue to individuals who are already correctly classified by other models. In light of these trends, we consider medical imaging for dermatology where the costs of systemic failure are especially high. While traditional analyses reveal racial performance disparities for both models and humans, ecosystem-level analysis reveals new forms of racial disparity in model predictions that do not present in human predictions. These examples demonstrate ecosystem-level analysis has unique strengths for characterizing the societal impact of machine learning.", "url": "https://arxiv.org/abs/2307.05862"}, {"metadata": {"arXiv": "2307.05891", "Date": "Wed, 12 Jul 2023 03:42:24 ", "Title": "PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks", "Authors": ["Ian Char and Jeff Schneider"], "Categories": "cs.LG cs.AI"}, "abstract": "Deep reinforcement learning (RL) has shown immense potential for learning to control systems through data alone. However, one challenge deep RL faces is that the full state of the system is often not observable. When this is the case, the policy needs to leverage the history of observations to infer the current state. At the same time, differences between the training and testing environments makes it critical for the policy not to overfit to the sequence of observations it sees at training time. As such, there is an important balancing act between having the history encoder be flexible enough to extract relevant information, yet be robust to changes in the environment. To strike this balance, we look to the PID controller for inspiration. We assert the PID controller's success shows that only summing and differencing are needed to accumulate information over time for many control tasks. Following this principle, we propose two architectures for encoding history: one that directly uses PID features and another that extends these core ideas and can be used in arbitrary control tasks. When compared with prior approaches, our encoders produce policies that are often more robust and achieve better performance on a variety of tracking tasks. Going beyond tracking tasks, our policies achieve 1.7x better performance on average over previous state-of-the-art methods on a suite of high dimensional control tasks.", "url": "https://arxiv.org/abs/2307.05891"}, {"metadata": {"arXiv": "2307.05902", "Date": "Wed, 12 Jul 2023 04:19:47 ", "Title": "Stability Guarantees for Feature Attributions with Multiplicative Smoothing", "Authors": ["Anton Xue", "Rajeev Alur", "Eric Wong"], "Categories": "cs.LG cs.AI"}, "abstract": "Explanation methods for machine learning models tend to not provide any formal guarantees and may not reflect the underlying decision-making process. In this work, we analyze stability as a property for reliable feature attribution methods. We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features. To achieve such a model, we develop a smoothing method called Multiplicative Smoothing (MuS). We show that MuS overcomes theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method. We evaluate MuS on vision and language models with a variety of feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees.", "url": "https://arxiv.org/abs/2307.05902"}, {"metadata": {"arXiv": "2307.05979", "Date": "Wed, 12 Jul 2023 07:51:12 ", "Title": "Transformers in Reinforcement Learning: A Survey", "Authors": ["Pranav Agarwal", "Aamer Abdul Rahman", "Pierre-Luc St-Charles", "Simon J.D. Prince", "Samira Ebrahimi Kahou"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["35 pages", "11 figures"]}, "abstract": "Transformers have significantly impacted domains like natural language processing, computer vision, and robotics, where they improve performance compared to other neural networks. This survey explores how transformers are used in reinforcement learning (RL), where they are seen as a promising solution for addressing challenges such as unstable training, credit assignment, lack of interpretability, and partial observability. We begin by providing a brief domain overview of RL, followed by a discussion on the challenges of classical RL algorithms. Next, we delve into the properties of the transformer and its variants and discuss the characteristics that make them well-suited to address the challenges inherent in RL. We examine the application of transformers to various aspects of RL, including representation learning, transition and reward function modeling, and policy optimization. We also discuss recent research that aims to enhance the interpretability and efficiency of transformers in RL, using visualization techniques and efficient training strategies. Often, the transformer architecture must be tailored to the specific needs of a given application. We present a broad overview of how transformers have been adapted for several applications, including robotics, medicine, language modeling, cloud computing, and combinatorial optimization. We conclude by discussing the limitations of using transformers in RL and assess their potential for catalyzing future breakthroughs in this field.", "url": "https://arxiv.org/abs/2307.05979"}, {"metadata": {"arXiv": "2307.06046", "Date": "Wed, 12 Jul 2023 09:49:15 ", "Title": "An OOD Multi-Task Perspective for Link Prediction with New Relation Types and Nodes", "Authors": ["Jincheng Zhou", "Beatrice Bevilacqua", "Bruno Ribeiro"], "Categories": "cs.LG cs.AI", "Comments": ["23 pages", "3 figures"]}, "abstract": "The task of inductive link prediction in (discrete) attributed multigraphs infers missing attributed links (relations) between nodes in new test multigraphs. Traditional relational learning methods face the challenge of limited generalization to OOD test multigraphs containing both novel nodes and novel relation types not seen in training. Recently, under the only assumption that all relation types share the same structural predictive patterns (single task), Gao et al. (2023) proposed an OOD link prediction method using the theoretical concept of double exchangeability (for nodes & relation types), in contrast to the (single) exchangeability (only for nodes) used to design Graph Neural Networks (GNNs). In this work we further extend the double exchangeability concept to multi-task double exchangeability, where we define link prediction in attributed multigraphs that can have distinct and potentially conflicting predictive patterns for different sets of relation types (multiple tasks). Our empirical results on real-world datasets demonstrate that our approach can effectively generalize to entirely new relation types in test, without access to additional information, yielding significant performance improvements over existing methods.", "url": "https://arxiv.org/abs/2307.06046"}, {"metadata": {"arXiv": "2307.06092", "Date": "Wed, 12 Jul 2023 11:35:37 ", "Title": "Quantitative CLTs in Deep Neural Networks", "Authors": ["Stefano Favaro", "Boris Hanin", "Domenico Marinucci", "Ivan Nourdin", "Giovanni Peccati"], "Categories": "cs.LG cs.AI math.PR stat.ML"}, "abstract": "We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\\gamma}$ for $\\gamma>0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.", "url": "https://arxiv.org/abs/2307.06092"}, {"metadata": {"arXiv": "2307.06162", "Date": "Wed, 12 Jul 2023 13:42:09 ", "Title": "Deep Generative Models for Physiological Signals: A Systematic Literature Review", "Authors": ["Nour Neifar and Afef Mdhaffar and Achraf Ben-Hamadou and Mohamed Jmaiel"], "Categories": "cs.LG cs.AI eess.SP", "Comments": ["paper under review", "34 pages"]}, "abstract": "In this paper, we present a systematic literature review on deep generative models for physiological signals, particularly electrocardiogram, electroencephalogram, photoplethysmogram and electromyogram. Compared to the existing review papers, we present the first review that summarizes the recent state-of-the-art deep generative models. By analysing the state-of-the-art research related to deep generative models along with their main applications and challenges, this review contributes to the overall understanding of these models applied to physiological signals. Additionally, by highlighting the employed evaluation protocol and the most used physiological databases, this review facilitates the assessment and benchmarking of deep generative models.", "url": "https://arxiv.org/abs/2307.06162"}, {"metadata": {"arXiv": "2307.06240", "Date": "Wed, 12 Jul 2023 15:28:26 ", "Title": "DSSE: a drone swarm search environment", "Authors": ["Manuel Castanares and Luis F. S. Carrete and Enrico F. Damiani and Leonardo D. M. de Abreu and Jos\\'e Fernando B. Brancalion and Fabr\\'icio J. Barth"], "Categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "Comments": ["6 pages"], "ACM-class": "I.2.6; I.6.7"}, "abstract": "The Drone Swarm Search project is an environment, based on PettingZoo, that is to be used in conjunction with multi-agent (or single-agent) reinforcement learning algorithms. It is an environment in which the agents (drones), have to find the targets (shipwrecked people). The agents do not know the position of the target and do not receive rewards related to their own distance to the target(s). However, the agents receive the probabilities of the target(s) being in a certain cell of the map. The aim of this project is to aid in the study of reinforcement learning algorithms that require dynamic probabilities as inputs.", "url": "https://arxiv.org/abs/2307.06240"}, {"metadata": {"arXiv": "2307.06328", "Date": "Wed, 12 Jul 2023 17:47:35 ", "Title": "Budgeting Counterfactual for Offline RL", "Authors": ["Yao Liu", "Pratik Chaudhari", "Rasool Fakoor"], "Categories": "cs.LG cs.AI"}, "abstract": "The main challenge of offline reinforcement learning, where data is limited, arises from a sequence of counterfactual reasoning dilemmas within the realm of potential actions: What if we were to choose a different course of action? These circumstances frequently give rise to extrapolation errors, which tend to accumulate exponentially with the problem horizon. Hence, it becomes crucial to acknowledge that not all decision steps are equally important to the final outcome, and to budget the number of counterfactual decisions a policy make in order to control the extrapolation. Contrary to existing approaches that use regularization on either the policy or value function, we propose an approach to explicitly bound the amount of out-of-distribution actions during training. Specifically, our method utilizes dynamic programming to decide where to extrapolate and where not to, with an upper bound on the decisions different from behavior policy. It balances between the potential for improvement from taking out-of-distribution actions and the risk of making errors due to extrapolation. Theoretically, we justify our method by the constrained optimality of the fixed point solution to our $Q$ updating rules. Empirically, we show that the overall performance of our method is better than the state-of-the-art offline RL methods on tasks in the widely-used D4RL benchmarks.", "url": "https://arxiv.org/abs/2307.06328"}, {"metadata": {"arXiv": "2307.06333", "Date": "Wed, 12 Jul 2023 17:55:08 ", "Title": "Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation", "Authors": ["Andi Peng", "Aviv Netanyahu", "Mark Ho", "Tianmin Shu", "Andreea Bobu", "Julie Shah", "Pulkit Agrawal"], "Categories": "cs.LG cs.AI cs.HC cs.RO", "Comments": ["International Conference on Machine Learning (ICML) 2023"]}, "abstract": "Policies often fail due to distribution shift -- changes in the state and reward that occur when a policy is deployed in new environments. Data augmentation can increase robustness by making the model invariant to task-irrelevant changes in the agent's observation. However, designers don't know which concepts are irrelevant a priori, especially when different end users have different preferences about how the task is performed. We propose an interactive framework to leverage feedback directly from the user to identify personalized task-irrelevant concepts. Our key idea is to generate counterfactual demonstrations that allow users to quickly identify possible task-relevant and irrelevant concepts. The knowledge of task-irrelevant concepts is then used to perform data augmentation and thus obtain a policy adapted to personalized user objectives. We present experiments validating our framework on discrete and continuous control tasks with real human users. Our method (1) enables users to better understand agent failure, (2) reduces the number of demonstrations required for fine-tuning, and (3) aligns the agent to individual user task preferences.", "url": "https://arxiv.org/abs/2307.06333"}, {"metadata": {"arXiv": "2307.05959", "Date": "Wed, 12 Jul 2023 07:04:53 ", "Title": "Giving Robots a Hand: Learning Generalizable Manipulation with Eye-in-Hand Human Video Demonstrations", "Authors": ["Moo Jin Kim", "Jiajun Wu", "Chelsea Finn"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["21 pages", "7 figures", "project webpage at https://giving-robots-a-hand.github.io/"]}, "abstract": "Eye-in-hand cameras have shown promise in enabling greater sample efficiency and generalization in vision-based robotic manipulation. However, for robotic imitation, it is still expensive to have a human teleoperator collect large amounts of expert demonstrations with a real robot. Videos of humans performing tasks, on the other hand, are much cheaper to collect since they eliminate the need for expertise in robotic teleoperation and can be quickly captured in a wide range of scenarios. Therefore, human video demonstrations are a promising data source for learning generalizable robotic manipulation policies at scale. In this work, we augment narrow robotic imitation datasets with broad unlabeled human video demonstrations to greatly enhance the generalization of eye-in-hand visuomotor policies. Although a clear visual domain gap exists between human and robot data, our framework does not need to employ any explicit domain adaptation method, as we leverage the partial observability of eye-in-hand cameras as well as a simple fixed image masking scheme. On a suite of eight real-world tasks involving both 3-DoF and 6-DoF robot arm control, our method improves the success rates of eye-in-hand manipulation policies by 58% (absolute) on average, enabling robots to generalize to both new environment configurations and new tasks that are unseen in the robot demonstration data. See video results at https://giving-robots-a-hand.github.io/ .", "url": "https://arxiv.org/abs/2307.05959"}, {"metadata": {"arXiv": "2307.05973", "Date": "Wed, 12 Jul 2023 07:40:48 ", "Title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models", "Authors": ["Wenlong Huang", "Chen Wang", "Ruohan Zhang", "Yunzhu Li", "Jiajun Wu", "Li Fei-Fei"], "Categories": "cs.RO cs.AI cs.CL cs.CV cs.LG"}, "abstract": "Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction. More importantly, by leveraging their code-writing capabilities, they can interact with a visual-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations. We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions. We present a large-scale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language. Project website: https://voxposer.github.io", "url": "https://arxiv.org/abs/2307.05973"}, {"metadata": {"arXiv": "2307.06125", "Date": "Wed, 12 Jul 2023 12:25:33 ", "Title": "Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation", "Authors": ["Fabian Schmalstieg", "Daniel Honerkamp", "Tim Welschehold", "Abhinav Valada"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["10 pages", "5 figures"]}, "abstract": "Existing object-search approaches enable robots to search through free pathways, however, robots operating in unstructured human-centered environments frequently also have to manipulate the environment to their needs. In this work, we introduce a novel interactive multi-object search task in which a robot has to open doors to navigate rooms and search inside cabinets and drawers to find target objects. These new challenges require combining manipulation and navigation skills in unexplored environments. We present HIMOS, a hierarchical reinforcement learning approach that learns to compose exploration, navigation, and manipulation skills. To achieve this, we design an abstract high-level action space around a semantic map memory and leverage the explored environment as instance navigation points. We perform extensive experiments in simulation and the real-world that demonstrate that HIMOS effectively transfers to new environments in a zero-shot manner. It shows robustness to unseen subpolicies, failures in their execution, and different robot kinematics. These capabilities open the door to a wide range of downstream tasks across embodied AI and real-world use cases.", "url": "https://arxiv.org/abs/2307.06125"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

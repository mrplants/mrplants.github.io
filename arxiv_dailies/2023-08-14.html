<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.05881", "Date": "Thu, 10 Aug 2023 23:53:07 ", "Title": "Aphid Cluster Recognition and Detection in the Wild Using Deep Learning Models", "Authors": ["Tianxiao Zhang", "Kaidong Li", "Xiangyu Chen", "Cuncong Zhong", "Bo Luo", "Ivan Grijalva", "Brian McCornack", "Daniel Flippo", "Ajay Sharda", "Guanghui Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "Aphid infestation poses a significant threat to crop production, rural communities, and global food security. While chemical pest control is crucial for maximizing yields, applying chemicals across entire fields is both environmentally unsustainable and costly. Hence, precise localization and management of aphids are essential for targeted pesticide application. The paper primarily focuses on using deep learning models for detecting aphid clusters. We propose a novel approach for estimating infection levels by detecting aphid clusters. To facilitate this research, we have captured a large-scale dataset from sorghum fields, manually selected 5,447 images containing aphids, and annotated each individual aphid cluster within these images. To facilitate the use of machine learning models, we further process the images by cropping them into patches, resulting in a labeled dataset comprising 151,380 image patches. Then, we implemented and compared the performance of four state-of-the-art object detection models (VFNet, GFLV2, PAA, and ATSS) on the aphid dataset. Extensive experimental results show that all models yield stable similar performance in terms of average precision and recall. We then propose to merge close neighboring clusters and remove tiny clusters caused by cropping, and the performance is further boosted by around 17%. The study demonstrates the feasibility of automatically detecting and managing insects using machine learning models. The labeled dataset will be made openly available to the research community.", "url": "https://arxiv.org/abs/2308.05881"}, {"metadata": {"arXiv": "2308.06093", "Date": "Fri, 11 Aug 2023 12:05:12 ", "Title": "Experts Weights Averaging: A New General Training Scheme for Vision Transformers", "Authors": ["Yongqi Huang", "Peng Ye", "Xiaoshui Huang", "Sheng Li", "Tao Chen", "Wanli Ouyang"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages", "2 figures"]}, "abstract": "Structural re-parameterization is a general training scheme for Convolutional Neural Networks (CNNs), which achieves performance improvement without increasing inference cost. As Vision Transformers (ViTs) are gradually surpassing CNNs in various visual tasks, one may question: if a training scheme specifically for ViTs exists that can also achieve performance improvement without increasing inference cost? Recently, Mixture-of-Experts (MoE) has attracted increasing attention, as it can efficiently scale up the capacity of Transformers at a fixed cost through sparsely activated experts. Considering that MoE can also be viewed as a multi-branch structure, can we utilize MoE to implement a ViT training scheme similar to structural re-parameterization? In this paper, we affirmatively answer these questions, with a new general training strategy for ViTs. Specifically, we decouple the training and inference phases of ViTs. During training, we replace some Feed-Forward Networks (FFNs) of the ViT with specially designed, more efficient MoEs that assign tokens to experts by random uniform partition, and perform Experts Weights Averaging (EWA) on these MoEs at the end of each iteration. After training, we convert each MoE into an FFN by averaging the experts, transforming the model back into original ViT for inference. We further provide a theoretical analysis to show why and how it works. Comprehensive experiments across various 2D and 3D visual tasks, ViT architectures, and datasets validate the effectiveness and generalizability of the proposed training scheme. Besides, our training scheme can also be applied to improve performance when fine-tuning ViTs. Lastly, but equally important, the proposed EWA technique can significantly improve the effectiveness of naive MoE in various 2D visual small datasets and 3D visual tasks.", "url": "https://arxiv.org/abs/2308.06093"}, {"metadata": {"arXiv": "2308.06100", "Date": "Fri, 11 Aug 2023 12:22:37 ", "Title": "Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation", "Authors": ["Philipp Vaeth and Alexander M. Fruehwald and Benjamin Paassen and Magda Gregorova"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at the 5th International Workshop on eXplainable Knowledge Discovery in Data Mining @ ECML 2023"]}, "abstract": "Latest methods for visual counterfactual explanations (VCE) harness the power of deep generative models to synthesize new examples of high-dimensional images of impressive quality. However, it is currently difficult to compare the performance of these VCE methods as the evaluation procedures largely vary and often boil down to visual inspection of individual examples and small scale user studies. In this work, we propose a framework for systematic, quantitative evaluation of the VCE methods and a minimal set of metrics to be used. We use this framework to explore the effects of certain crucial design choices in the latest diffusion-based generative models for VCEs of natural image classification (ImageNet). We conduct a battery of ablation-like experiments, generating thousands of VCEs for a suite of classifiers of various complexity, accuracy and robustness. Our findings suggest multiple directions for future advancements and improvements of VCE methods. By sharing our methodology and our approach to tackle the computational challenges of such a study on a limited hardware setup (including the complete code base), we offer a valuable guidance for researchers in the field fostering consistency and transparency in the assessment of counterfactual explanations.", "url": "https://arxiv.org/abs/2308.06100"}, {"metadata": {"arXiv": "2308.06129", "Date": "Fri, 11 Aug 2023 13:35:52 ", "Title": "Uncertainty Quantification for Image-based Traffic Prediction across Cities", "Authors": ["Alexander Timans", "Nina Wiedemann", "Nishant Kumar", "Ye Hong", "Martin Raubal"], "Categories": "cs.CV cs.LG stat.ML", "Comments": ["39 pages", "22 figures. Code publicly available at: https://github.com/alextimans/traffic4cast-uncertainty"], "ACM-class": "I.4.9; I.2.6; I.5.4; J.2"}, "abstract": "Despite the strong predictive performance of deep learning models for traffic prediction, their widespread deployment in real-world intelligent transportation systems has been restrained by a lack of interpretability. Uncertainty quantification (UQ) methods provide an approach to induce probabilistic reasoning, improve decision-making and enhance model deployment potential. To gain a comprehensive picture of the usefulness of existing UQ methods for traffic prediction and the relation between obtained uncertainties and city-wide traffic dynamics, we investigate their application to a large-scale image-based traffic dataset spanning multiple cities and time periods. We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered. We further demonstrate how uncertainty estimates can be employed for unsupervised outlier detection on changes in city traffic dynamics. We find that our approach can capture both temporal and spatial effects on traffic behaviour in a representative case study for the city of Moscow. Our work presents a further step towards boosting uncertainty awareness in traffic prediction tasks, and aims to highlight the value contribution of UQ methods to a better understanding of city traffic dynamics.", "url": "https://arxiv.org/abs/2308.06129"}, {"metadata": {"arXiv": "2308.06142", "Date": "Fri, 11 Aug 2023 14:02:52 ", "Title": "CompTLL-UNet: Compressed Domain Text-Line Localization in Challenging Handwritten Documents using Deep Feature Learning from JPEG Coefficients", "Authors": ["Bulla Rajesh and Sk Mahafuz Zaman and Mohammed Javed and P. Nagabhushan"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted in 7th Asian Conference on Pattern Recognition (ACPR 2023)", "5-8 November 2023", "Kitakyushu", "Japan"]}, "abstract": "Automatic localization of text-lines in handwritten documents is still an open and challenging research problem. Various writing issues such as uneven spacing between the lines, oscillating and touching text, and the presence of skew become much more challenging when the case of complex handwritten document images are considered for segmentation directly in their respective compressed representation. This is because, the conventional way of processing compressed documents is through decompression, but here in this paper, we propose an idea that employs deep feature learning directly from the JPEG compressed coefficients without full decompression to accomplish text-line localization in the JPEG compressed domain. A modified U-Net architecture known as Compressed Text-Line Localization Network (CompTLL-UNet) is designed to accomplish it. The model is trained and tested with JPEG compressed version of benchmark datasets including ICDAR2017 (cBAD) and ICDAR2019 (cBAD), reporting the state-of-the-art performance with reduced storage and computational costs in the JPEG compressed domain.", "url": "https://arxiv.org/abs/2308.06142"}, {"metadata": {"arXiv": "2308.06248", "Date": "Fri, 11 Aug 2023 17:29:02 ", "Title": "FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods", "Authors": ["Robin Hesse", "Simone Schaub-Meyer", "Stefan Roth"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICCV 2023. Code: https://github.com/visinf/funnybirds"]}, "abstract": "The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.", "url": "https://arxiv.org/abs/2308.06248"}, {"metadata": {"arXiv": "2308.05750", "Date": "Tue, 25 Jul 2023 16:29:07 ", "Title": "Turning hazardous volatile matter compounds into fuel by catalytic steam reforming: An evolutionary machine learning approach", "Authors": ["Alireza Shafizadeh", "Hossein Shahbeik", "Mohammad Hossein Nadian", "Vijai Kumar Gupta", "Abdul-Sattar Nizami", "Su Shiung Lam", "Wanxi Peng", "Junting Pan", "Meisam Tabatabaei", "Mortaza Aghbashlo"], "Categories": "cs.LG", "DOI": "10.1016/j.jclepro.2023.137329"}, "abstract": "Chemical and biomass processing systems release volatile matter compounds into the environment daily. Catalytic reforming can convert these compounds into valuable fuels, but developing stable and efficient catalysts is challenging. Machine learning can handle complex relationships in big data and optimize reaction conditions, making it an effective solution for addressing the mentioned issues. This study is the first to develop a machine-learning-based research framework for modeling, understanding, and optimizing the catalytic steam reforming of volatile matter compounds. Toluene catalytic steam reforming is used as a case study to show how chemical/textural analyses (e.g., X-ray diffraction analysis) can be used to obtain input features for machine learning models. Literature is used to compile a database covering a variety of catalyst characteristics and reaction conditions. The process is thoroughly analyzed, mechanistically discussed, modeled by six machine learning models, and optimized using the particle swarm optimization algorithm. Ensemble machine learning provides the best prediction performance (R2 > 0.976) for toluene conversion and product distribution. The optimal tar conversion (higher than 77.2%) is obtained at temperatures between 637.44 and 725.62 {\\deg}C, with a steam-to-carbon molar ratio of 5.81-7.15 and a catalyst BET surface area 476.03-638.55 m2/g. The feature importance analysis satisfactorily reveals the effects of input descriptors on model prediction. Operating conditions (50.9%) and catalyst properties (49.1%) are equally important in modeling. The developed framework can expedite the search for optimal catalyst characteristics and reaction conditions, not only for catalytic chemical processing but also for related research areas.", "url": "https://arxiv.org/abs/2308.05750"}, {"metadata": {"arXiv": "2308.05870", "Date": "Thu, 10 Aug 2023 22:52:13 ", "Title": "UFed-GAN: A Secure Federated Learning Framework with Constrained Computation and Unlabeled Data", "Authors": ["Achintha Wijesinghe", "Songyang Zhang", "Siyu Qi", "Zhi Ding"], "Categories": "cs.LG eess.SP"}, "abstract": "To satisfy the broad applications and insatiable hunger for deploying low latency multimedia data classification and data privacy in a cloud-based setting, federated learning (FL) has emerged as an important learning paradigm. For the practical cases involving limited computational power and only unlabeled data in many wireless communications applications, this work investigates FL paradigm in a resource-constrained and label-missing environment. Specifically, we propose a novel framework of UFed-GAN: Unsupervised Federated Generative Adversarial Network, which can capture user-side data distribution without local classification training. We also analyze the convergence and privacy of the proposed UFed-GAN. Our experimental results demonstrate the strong potential of UFed-GAN in addressing limited computational resources and unlabeled data while preserving privacy.", "url": "https://arxiv.org/abs/2308.05870"}, {"metadata": {"arXiv": "2308.05877", "Date": "Thu, 10 Aug 2023 23:22:41 ", "Title": "Revisiting N-CNN for Clinical Practice", "Authors": ["Leonardo Antunes Ferreira", "Lucas Pereira Carlini", "Gabriel de Almeida S\\'a Coutrin", "Tatiany Marcondes Heideirich", "Marina Carvalho de Moraes Barros", "Ruth Guinsburg and Carlos Eduardo Thomaz"], "Categories": "cs.LG", "Comments": ["AICAI 2023 in conjuction with MICCAI"]}, "abstract": "This paper revisits the Neonatal Convolutional Neural Network (N-CNN) by optimizing its hyperparameters and evaluating how they affect its classification metrics, explainability and reliability, discussing their potential impact in clinical practice. We have chosen hyperparameters that do not modify the original N-CNN architecture, but mainly modify its learning rate and training regularization. The optimization was done by evaluating the improvement in F1 Score for each hyperparameter individually, and the best hyperparameters were chosen to create a Tuned N-CNN. We also applied soft labels derived from the Neonatal Facial Coding System, proposing a novel approach for training facial expression classification models for neonatal pain assessment. Interestingly, while the Tuned N-CNN results point towards improvements in classification metrics and explainability, these improvements did not directly translate to calibration performance. We believe that such insights might have the potential to contribute to the development of more reliable pain evaluation tools for newborns, aiding healthcare professionals in delivering appropriate interventions and improving patient outcomes.", "url": "https://arxiv.org/abs/2308.05877"}, {"metadata": {"arXiv": "2308.05878", "Date": "Thu, 10 Aug 2023 23:24:51 ", "Title": "Composable Core-sets for Diversity Approximation on Multi-Dataset Streams", "Authors": ["Stephanie Wang", "Michael Flynn", "and Fangyu Luo"], "Categories": "cs.LG"}, "abstract": "Core-sets refer to subsets of data that maximize some function that is commonly a diversity or group requirement. These subsets are used in place of the original data to accomplish a given task with comparable or even enhanced performance if biases are removed. Composable core-sets are core-sets with the property that subsets of the core set can be unioned together to obtain an approximation for the original data; lending themselves to be used for streamed or distributed data. Recent work has focused on the use of core-sets for training machine learning models. Preceding solutions such as CRAIG have been proven to approximate gradient descent while providing a reduced training time. In this paper, we introduce a core-set construction algorithm for constructing composable core-sets to summarize streamed data for use in active learning environments. If combined with techniques such as CRAIG and heuristics to enhance construction speed, composable core-sets could be used for real time training of models when the amount of sensor data is large. We provide empirical analysis by considering extrapolated data for the runtime of such a brute force algorithm. This algorithm is then analyzed for efficiency through averaged empirical regression and key results and improvements are suggested for further research on the topic.", "url": "https://arxiv.org/abs/2308.05878"}, {"metadata": {"arXiv": "2308.05903", "Date": "Fri, 11 Aug 2023 01:55:14 ", "Title": "Comparing the quality of neural network uncertainty estimates for classification problems", "Authors": ["Daniel Ries", "Joshua Michalenko", "Tyler Ganter", "Rashad Imad-Fayez Baiyasi", "Jason Adams"], "Categories": "cs.LG stat.ML"}, "abstract": "Traditional deep learning (DL) models are powerful classifiers, but many approaches do not provide uncertainties for their estimates. Uncertainty quantification (UQ) methods for DL models have received increased attention in the literature due to their usefulness in decision making, particularly for high-consequence decisions. However, there has been little research done on how to evaluate the quality of such methods. We use statistical methods of frequentist interval coverage and interval width to evaluate the quality of credible intervals, and expected calibration error to evaluate classification predicted confidence. These metrics are evaluated on Bayesian neural networks (BNN) fit using Markov Chain Monte Carlo (MCMC) and variational inference (VI), bootstrapped neural networks (NN), Deep Ensembles (DE), and Monte Carlo (MC) dropout. We apply these different UQ for DL methods to a hyperspectral image target detection problem and show the inconsistency of the different methods' results and the necessity of a UQ quality metric. To reconcile these differences and choose a UQ method that appropriately quantifies the uncertainty, we create a simulated data set with fully parameterized probability distribution for a two-class classification problem. The gold standard MCMC performs the best overall, and the bootstrapped NN is a close second, requiring the same computational expense as DE. Through this comparison, we demonstrate that, for a given data set, different models can produce uncertainty estimates of markedly different quality. This in turn points to a great need for principled assessment methods of UQ quality in DL applications.", "url": "https://arxiv.org/abs/2308.05903"}, {"metadata": {"arXiv": "2308.05906", "Date": "Fri, 11 Aug 2023 02:05:08 ", "Title": "On the equivalence of Occam algorithms", "Authors": ["Zaman Keinath-Esmail"], "Categories": "cs.LG cs.DS cs.IT math.IT", "Comments": ["13 pages", "submitted to Information and Computation"], "ACM-class": "F.1.1; F.4.1"}, "abstract": "Blumer et al. (1987, 1989) showed that any concept class that is learnable by Occam algorithms is PAC learnable. Board and Pitt (1990) showed a partial converse of this theorem: for concept classes that are closed under exception lists, any class that is PAC learnable is learnable by an Occam algorithm. However, their Occam algorithm outputs a hypothesis whose complexity is $\\delta$-dependent, which is an important limitation. In this paper, we show that their partial converse applies to Occam algorithms with $\\delta$-independent complexities as well. Thus, we provide a posteriori justification of various theoretical results and algorithm design methods which use the partial converse as a basis for their work.", "url": "https://arxiv.org/abs/2308.05906"}, {"metadata": {"arXiv": "2308.05969", "Date": "Fri, 11 Aug 2023 07:07:21 ", "Title": "Learning nonparametric DAGs with incremental information via high-order HSIC", "Authors": ["Yafei Wang", "Jianguo Liu"], "Categories": "cs.LG stat.ML"}, "abstract": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HSIC. Numerical experiments for different synthetic datasets and real-world datasets show that the OT algorithm outperforms existing methods. Especially in Sigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the structure intervention distance (SID) of the OT algorithm is 329.7 smaller than the one obtained by CAM, which indicates that the graph estimated by the OT algorithm misses fewer edges compared with CAM.", "url": "https://arxiv.org/abs/2308.05969"}, {"metadata": {"arXiv": "2308.05986", "Date": "Fri, 11 Aug 2023 07:50:40 ", "Title": "Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance", "Authors": ["Huiwen Xu", "U Kang"], "Categories": "cs.LG"}, "abstract": "Given a set of pre-trained models, how can we quickly and accurately find the most useful pre-trained model for a downstream task? Transferability measurement is to quantify how transferable is a pre-trained model learned on a source task to a target task. It is used for quickly ranking pre-trained models for a given task and thus becomes a crucial step for transfer learning. Existing methods measure transferability as the discrimination ability of a source model for a target data before transfer learning, which cannot accurately estimate the fine-tuning performance. Some of them restrict the application of transferability measurement in selecting the best supervised pre-trained models that have classifiers. It is important to have a general method for measuring transferability that can be applied in a variety of situations, such as selecting the best self-supervised pre-trained models that do not have classifiers, and selecting the best transferring layer for a target task. In this work, we propose TMI (TRANSFERABILITY MEASUREMENT WITH INTRA-CLASS FEATURE VARIANCE), a fast and accurate algorithm to measure transferability. We view transferability as the generalization of a pre-trained model on a target task by measuring intra-class feature variance. Intra-class variance evaluates the adaptability of the model to a new task, which measures how transferable the model is. Compared to previous studies that estimate how discriminative the models are, intra-class variance is more accurate than those as it does not require an optimal feature extractor and classifier. Extensive experiments on real-world datasets show that TMI outperforms competitors for selecting the top-5 best models, and exhibits consistently better correlation in 13 out of 17 cases.", "url": "https://arxiv.org/abs/2308.05986"}, {"metadata": {"arXiv": "2308.05999", "Date": "Fri, 11 Aug 2023 08:06:58 ", "Title": "Does AI for science need another ImageNet Or totally different benchmarks? A case study of machine learning force fields", "Authors": ["Yatao Li", "Wanling Gao", "Lei Wang", "Lixin Sun", "Zun Wang", "Jianfeng Zhan"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "AI for science (AI4S) is an emerging research field that aims to enhance the accuracy and speed of scientific computing tasks using machine learning methods. Traditional AI benchmarking methods struggle to adapt to the unique challenges posed by AI4S because they assume data in training, testing, and future real-world queries are independent and identically distributed, while AI4S workloads anticipate out-of-distribution problem instances. This paper investigates the need for a novel approach to effectively benchmark AI for science, using the machine learning force field (MLFF) as a case study. MLFF is a method to accelerate molecular dynamics (MD) simulation with low computational cost and high accuracy. We identify various missed opportunities in scientifically meaningful benchmarking and propose solutions to evaluate MLFF models, specifically in the aspects of sample efficiency, time domain sensitivity, and cross-dataset generalization capabilities. By setting up the problem instantiation similar to the actual scientific applications, more meaningful performance metrics from the benchmark can be achieved. This suite of metrics has demonstrated a better ability to assess a model's performance in real-world scientific applications, in contrast to traditional AI benchmarking methodologies. This work is a component of the SAIBench project, an AI4S benchmarking suite. The project homepage is https://www.computercouncil.org/SAIBench.", "url": "https://arxiv.org/abs/2308.05999"}, {"metadata": {"arXiv": "2308.06051", "Date": "Fri, 11 Aug 2023 09:58:47 ", "Title": "Towards Instance-adaptive Inference for Federated Learning", "Authors": ["Chun-Mei Feng", "Kai Yu", "Nian Liu", "Xinxing Xu", "Salman Khan", "Wangmeng Zuo"], "Categories": "cs.LG cs.CV"}, "abstract": "Federated learning (FL) is a distributed learning paradigm that enables multiple clients to learn a powerful global model by aggregating local training. However, the performance of the global model is often hampered by non-i.i.d. distribution among the clients, requiring extensive efforts to mitigate inter-client data heterogeneity. Going beyond inter-client data heterogeneity, we note that intra-client heterogeneity can also be observed on complex real-world data and seriously deteriorate FL performance. In this paper, we present a novel FL algorithm, i.e., FedIns, to handle intra-client data heterogeneity by enabling instance-adaptive inference in the FL framework. Instead of huge instance-adaptive models, we resort to a parameter-efficient fine-tuning method, i.e., scale and shift deep features (SSF), upon a pre-trained model. Specifically, we first train an SSF pool for each client, and aggregate these SSF pools on the server side, thus still maintaining a low communication cost. To enable instance-adaptive inference, for a given instance, we dynamically find the best-matched SSF subsets from the pool and aggregate them to generate an adaptive SSF specified for the instance, thereby reducing the intra-client as well as the inter-client heterogeneity. Extensive experiments show that our FedIns outperforms state-of-the-art FL algorithms, e.g., a 6.64\\% improvement against the top-performing method with less than 15\\% communication cost on Tiny-ImageNet. Our code and models will be publicly released.", "url": "https://arxiv.org/abs/2308.06051"}, {"metadata": {"arXiv": "2308.06058", "Date": "Fri, 11 Aug 2023 10:17:29 ", "Title": "Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction", "Authors": ["Xiaowen Jiang and Sebastian U. Stich"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value as input. Secondly, we equip AdaSPS and AdaSLS with a novel variance reduction technique and obtain algorithms that require $\\smash{\\widetilde{\\mathcal{O}}}(n+1/\\epsilon)$ gradient evaluations to achieve an $\\mathcal{O}(\\epsilon)$-suboptimality for convex functions, which improves upon the slower $\\mathcal{O}(1/\\epsilon^2)$ rates of AdaSPS and AdaSLS without variance reduction in the non-interpolation regimes. Moreover, our result matches the fast rates of AdaSVRG but removes the inner-outer-loop structure, which is easier to implement and analyze. Finally, numerical experiments on synthetic and real datasets validate our theory and demonstrate the effectiveness and robustness of our algorithms.", "url": "https://arxiv.org/abs/2308.06058"}, {"metadata": {"arXiv": "2308.06103", "Date": "Fri, 11 Aug 2023 12:27:22 ", "Title": "Composable Function-preserving Expansions for Transformer Architectures", "Authors": ["Andrea Gesmundo and Kaitlin Maile"], "Categories": "cs.LG"}, "abstract": "Training state-of-the-art neural networks requires a high cost in terms of compute and time. Model scale is recognized to be a critical factor to achieve and improve the state-of-the-art. Increasing the scale of a neural network normally requires restarting from scratch by randomly initializing all the parameters of the model, as this implies a change of architecture's parameters that does not allow for a straightforward transfer of knowledge from smaller size models. In this work, we propose six composable transformations to incrementally increase the size of transformer-based neural networks while preserving functionality, allowing to expand the capacity of the model as needed. We provide proof of exact function preservation under minimal initialization constraints for each transformation. The proposed methods may enable efficient training pipelines for larger and more powerful models by progressively expanding the architecture throughout training.", "url": "https://arxiv.org/abs/2308.06103"}, {"metadata": {"arXiv": "2308.06106", "Date": "Fri, 11 Aug 2023 12:43:43 ", "Title": "Hawkes Processes with Delayed Granger Causality", "Authors": ["Chao Yang", "Hengyuan Miao", "Shuang Li"], "Categories": "cs.LG stat.ML", "Comments": ["19 pages"]}, "abstract": "We aim to explicitly model the delayed Granger causal effects based on multivariate Hawkes processes. The idea is inspired by the fact that a causal event usually takes some time to exert an effect. Studying this time lag itself is of interest. Given the proposed model, we first prove the identifiability of the delay parameter under mild conditions. We further investigate a model estimation method under a complex setting, where we want to infer the posterior distribution of the time lags and understand how this distribution varies across different scenarios. We treat the time lags as latent variables and formulate a Variational Auto-Encoder (VAE) algorithm to approximate the posterior distribution of the time lags. By explicitly modeling the time lags in Hawkes processes, we add flexibility to the model. The inferred time-lag posterior distributions are of scientific meaning and help trace the original causal time that supports the root cause analysis. We empirically evaluate our model's event prediction and time-lag inference accuracy on synthetic and real data, achieving promising results.", "url": "https://arxiv.org/abs/2308.06106"}, {"metadata": {"arXiv": "2308.06127", "Date": "Fri, 11 Aug 2023 13:33:59 ", "Title": "Learning Control Policies for Variable Objectives from Offline Data", "Authors": ["Marc Weber", "Phillip Swazinna", "Daniel Hein", "Steffen Udluft", "and Volkmar Sterzing"], "Categories": "cs.LG", "Comments": ["8 pages", "7 figures"]}, "abstract": "Offline reinforcement learning provides a viable approach to obtain advanced control strategies for dynamical systems, in particular when direct interaction with the environment is not available. In this paper, we introduce a conceptual extension for model-based policy search methods, called variable objective policy (VOP). With this approach, policies are trained to generalize efficiently over a variety of objectives, which parameterize the reward function. We demonstrate that by altering the objectives passed as input to the policy, users gain the freedom to adjust its behavior or re-balance optimization targets at runtime, without need for collecting additional observation batches or re-training.", "url": "https://arxiv.org/abs/2308.06127"}, {"metadata": {"arXiv": "2308.06132", "Date": "Fri, 11 Aug 2023 13:39:21 ", "Title": "PDE Discovery for Soft Sensors Using Coupled Physics-Informed Neural Network with Akaike's Information Criterion", "Authors": ["Aina Wang", "Pan Qin", "Xi-Ming Sun"], "Categories": "cs.LG"}, "abstract": "Soft sensors have been extensively used to monitor key variables using easy-to-measure variables and mathematical models. Partial differential equations (PDEs) are model candidates for soft sensors in industrial processes with spatiotemporal dependence. However, gaps often exist between idealized PDEs and practical situations. Discovering proper structures of PDEs, including the differential operators and source terms, can remedy the gaps. To this end, a coupled physics-informed neural network with Akaike's criterion information (CPINN-AIC) is proposed for PDE discovery of soft sensors. First, CPINN is adopted for obtaining solutions and source terms satisfying PDEs. Then, we propose a data-physics-hybrid loss function for training CPINN, in which undetermined combinations of differential operators are involved. Consequently, AIC is used to discover the proper combination of differential operators. Finally, the artificial and practical datasets are used to verify the feasibility and effectiveness of CPINN-AIC for soft sensors. The proposed CPINN-AIC is a data-driven method to discover proper PDE structures and neural network-based solutions for soft sensors.", "url": "https://arxiv.org/abs/2308.06132"}, {"metadata": {"arXiv": "2308.06228", "Date": "Fri, 11 Aug 2023 16:58:57 ", "Title": "MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features", "Authors": ["Cheng-Chun Lee", "Lipai Huang", "Federico Antolini", "Matthew Garcia", "Andrew Juanb", "Samuel D. Brody", "Ali Mostafavi"], "Categories": "cs.LG physics.soc-ph"}, "abstract": "Timely, accurate, and reliable information is essential for decision-makers, emergency managers, and infrastructure operators during flood events. This study demonstrates a proposed machine learning model, MaxFloodCast, trained on physics-based hydrodynamic simulations in Harris County, offers efficient and interpretable flood inundation depth predictions. Achieving an average R-squared of 0.949 and a Root Mean Square Error of 0.61 ft on unseen data, it proves reliable in forecasting peak flood inundation depths. Validated against Hurricane Harvey and Storm Imelda, MaxFloodCast shows the potential in supporting near-time floodplain management and emergency operations. The model's interpretability aids decision-makers in offering critical information to inform flood mitigation strategies, to prioritize areas with critical facilities and to examine how rainfall in other watersheds influences flood exposure in one area. The MaxFloodCast model enables accurate and interpretable inundation depth predictions while significantly reducing computational time, thereby supporting emergency response efforts and flood risk management more effectively.", "url": "https://arxiv.org/abs/2308.06228"}, {"metadata": {"arXiv": "2308.06239", "Date": "Fri, 11 Aug 2023 17:15:12 ", "Title": "Private Distribution Learning with Public Data: The View from Sample Compression", "Authors": ["Shai Ben-David", "Alex Bie", "Cl\\'ement L. Canonne", "Gautam Kamath", "Vikrant Singhal"], "Categories": "cs.LG cs.CR stat.ML", "Comments": ["30 pages"]}, "abstract": "We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples. We show that the public-private learnability of a class $\\mathcal Q$ is connected to the existence of a sample compression scheme for $\\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in $\\mathbb R^d$, at least $d$ public samples are necessary for private learnability, which is close to the known upper bound of $d+1$ public samples.", "url": "https://arxiv.org/abs/2308.06239"}, {"metadata": {"arXiv": "2308.05780", "Date": "Thu, 10 Aug 2023 14:02:05 ", "Title": "Optical Script Identification for multi-lingual Indic-script", "Authors": ["Sidhantha Poddar and Rohan Gupta"], "Categories": "cs.AI", "Comments": ["20 pages ", "12 figures Keywords: Optical character Identification", "Pre-processing", "feature extraction", "multi-script", "Indic-script", "Script Recognition"]}, "abstract": "Script identification and text recognition are some of the major domains in the application of Artificial Intelligence. In this era of digitalization, the use of digital note-taking has become a common practice. Still, conventional methods of using pen and paper is a prominent way of writing. This leads to the classification of scripts based on the method they are obtained. A survey on the current methodologies and state-of-art methods used for processing and identification would prove beneficial for researchers. The aim of this article is to discuss the advancement in the techniques for script pre-processing and text recognition. In India there are twelve prominent Indic scripts, unlike the English language, these scripts have layers of characteristics. Complex characteristics such as similarity in text shape make them difficult to recognize and analyze, thus this requires advance preprocessing methods for their accurate recognition. A sincere attempt is made in this survey to provide a comparison between all algorithms. We hope that this survey would provide insight to a researcher working not only on Indic scripts but also other languages.", "url": "https://arxiv.org/abs/2308.05780"}, {"metadata": {"arXiv": "2308.05960", "Date": "Fri, 11 Aug 2023 06:37:54 ", "Title": "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents", "Authors": ["Zhiwei Liu", "Weiran Yao", "Jianguo Zhang", "Le Xue", "Shelby Heinecke", "Rithesh Murthy", "Yihao Feng", "Zeyuan Chen", "Juan Carlos Niebles", "Devansh Arpit", "Ran Xu", "Phil Mui", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "Categories": "cs.AI", "Comments": ["Preprint"]}, "abstract": "The massive successes of large language models (LLMs) encourage the emerging exploration of LLM-augmented Autonomous Agents (LAAs). An LAA is able to generate actions with its core LLM and interact with environments, which facilitates the ability to resolve complex tasks by conditioning on past interactions such as observations and actions. Since the investigation of LAA is still very recent, limited explorations are available. Therefore, we provide a comprehensive comparison of LAA in terms of both agent architectures and LLM backbones. Additionally, we propose a new strategy to orchestrate multiple LAAs such that each labor LAA focuses on one type of action, \\textit{i.e.} BOLAA, where a controller manages the communication among multiple agents. We conduct simulations on both decision-making and multi-step reasoning environments, which comprehensively justify the capacity of LAAs. Our performance results provide quantitative suggestions for designing LAA architectures and the optimal choice of LLMs, as well as the compatibility of both. We release our implementation code of LAAs to the public at \\url{https://github.com/salesforce/BOLAA}.", "url": "https://arxiv.org/abs/2308.05960"}, {"metadata": {"arXiv": "2308.05973", "Date": "Fri, 11 Aug 2023 07:16:49 ", "Title": "Tweet Sentiment Extraction using Viterbi Algorithm with Transfer Learning", "Authors": ["Zied Baklouti (UPCit\\'e", "ENIT)"], "Categories": "cs.AI cs.CL"}, "abstract": "Tweet sentiment extraction extracts the most significant portion of the sentence, determining whether the sentiment is positive or negative. This research aims to identify the part of tweet sentences that strikes any emotion. To reach this objective, we continue improving the Viterbi algorithm previously modified by the author to make it able to receive pre-trained model parameters. We introduce the confidence score and vector as two indicators responsible for evaluating the model internally before assessing the final results. We then present a method to fine-tune this nonparametric model. We found that the model gets highly explainable as the confidence score vector reveals precisely where the least confidence predicted states are and if the modifications approved ameliorate the confidence score or if the tuning is going in the wrong direction.", "url": "https://arxiv.org/abs/2308.05973"}, {"metadata": {"arXiv": "2308.05984", "Date": "Fri, 11 Aug 2023 07:42:17 ", "Title": "Contrastive Explanations of Multi-agent Optimization Solutions", "Authors": ["Parisa Zehtabi", "Alberto Pozanco", "Ayala Bloch", "Daniel Borrajo", "Sarit Kraus"], "Categories": "cs.AI"}, "abstract": "In many real-world scenarios, agents are involved in optimization problems. Since most of these scenarios are over-constrained, optimal solutions do not always satisfy all agents. Some agents might be unhappy and ask questions of the form ``Why does solution $S$ not satisfy property $P$?''. In this paper, we propose MAoE, a domain-independent approach to obtain contrastive explanations by (i) generating a new solution $S^\\prime$ where the property $P$ is enforced, while also minimizing the differences between $S$ and $S^\\prime$; and (ii) highlighting the differences between the two solutions. Such explanations aim to help agents understanding why the initial solution is better than what they expected. We have carried out a computational evaluation that shows that MAoE can generate contrastive explanations for large multi-agent optimization problems. We have also performed an extensive user study in four different domains that shows that, after being presented with these explanations, humans' satisfaction with the original solution increases.", "url": "https://arxiv.org/abs/2308.05984"}, {"metadata": {"arXiv": "2308.05985", "Date": "Fri, 11 Aug 2023 07:43:00 ", "Title": "TrajPAC: Towards Robustness Verification of Pedestrian Trajectory Prediction Models", "Authors": ["Liang Zhang", "Nathaniel Xu", "Pengfei Yang", "Gaojie Jin", "Cheng-Chao Huang", "Lijun Zhang"], "Categories": "cs.AI", "Comments": ["ICCV 2023 version"]}, "abstract": "Robust pedestrian trajectory forecasting is crucial to developing safe autonomous vehicles. Although previous works have studied adversarial robustness in the context of trajectory forecasting, some significant issues remain unaddressed. In this work, we try to tackle these crucial problems. Firstly, the previous definitions of robustness in trajectory prediction are ambiguous. We thus provide formal definitions for two kinds of robustness, namely label robustness and pure robustness. Secondly, as previous works fail to consider robustness about all points in a disturbance interval, we utilise a probably approximately correct (PAC) framework for robustness verification. Additionally, this framework can not only identify potential counterexamples, but also provides interpretable analyses of the original methods. Our approach is applied using a prototype tool named TrajPAC. With TrajPAC, we evaluate the robustness of four state-of-the-art trajectory prediction models -- Trajectron++, MemoNet, AgentFormer, and MID -- on trajectories from five scenes of the ETH/UCY dataset and scenes of the Stanford Drone Dataset. Using our framework, we also experimentally study various factors that could influence robustness performance.", "url": "https://arxiv.org/abs/2308.05985"}, {"metadata": {"arXiv": "2308.05996", "Date": "Fri, 11 Aug 2023 08:04:43 ", "Title": "Deep Task-specific Bottom Representation Network for Multi-Task Recommendation", "Authors": ["Qi Liu", "Zhilong Zhou", "Gangwei Jiang", "Tiezheng Ge", "Defu Lian"], "Categories": "cs.AI"}, "abstract": "Neural-based multi-task learning (MTL) has gained significant improvement, and it has been successfully applied to recommendation system (RS). Recent deep MTL methods for RS (e.g. MMoE, PLE) focus on designing soft gating-based parameter-sharing networks that implicitly learn a generalized representation for each task. However, MTL methods may suffer from performance degeneration when dealing with conflicting tasks, as negative transfer effects can occur on the task-shared bottom representation. This can result in a reduced capacity for MTL methods to capture task-specific characteristics, ultimately impeding their effectiveness and hindering the ability to generalize well on all tasks. In this paper, we focus on the bottom representation learning of MTL in RS and propose the Deep Task-specific Bottom Representation Network (DTRN) to alleviate the negative transfer problem. DTRN obtains task-specific bottom representation explicitly by making each task has its own representation learning network in the bottom representation modeling stage. Specifically, it extracts the user's interests from multiple types of behavior sequences for each task through the parameter-efficient hypernetwork. To further obtain the dedicated representation for each task, DTRN refines the representation of each feature by employing a SENet-like network for each task. The two proposed modules can achieve the purpose of getting task-specific bottom representation to relieve tasks' mutual interference. Moreover, the proposed DTRN is flexible to combine with existing MTL methods. Experiments on one public dataset and one industrial dataset demonstrate the effectiveness of the proposed DTRN. Furthermore, we deploy DTRN in an industrial recommender system and gain remarkable improvements in multiple tasks.", "url": "https://arxiv.org/abs/2308.05996"}, {"metadata": {"arXiv": "2308.06032", "Date": "Fri, 11 Aug 2023 09:23:11 ", "Title": "Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?", "Authors": ["Arianna Trozze", "Toby Davies", "and Bennett Kleinberg"], "Categories": "cs.AI cs.CL"}, "abstract": "Large Language Models (LLMs) could enhance access to the legal system. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying LLMs' legal reasoning and drafting capabilities. We examine whether a) an LLM can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to an LLM. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). GPT-3.5 performed better at legal drafting, and jurors' decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because LLMs cannot satisfactorily conduct legal reasoning tasks, they would be unable to replace lawyers at this stage. However, their drafting skills (though, perhaps, still inferior to lawyers), could provide access to justice for more individuals by reducing the cost of legal services. Our research is the first to systematically study LLMs' legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.", "url": "https://arxiv.org/abs/2308.06032"}, {"metadata": {"arXiv": "2308.06035", "Date": "Fri, 11 Aug 2023 09:30:07 ", "Title": "Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing", "Authors": ["Viktor Kewenig", "Christopher Edwards", "Quitterie Lacome DEstalenx", "Akilles Rechardt", "Jeremy I Skipper and Gabriella Vigliocco"], "Categories": "cs.AI cs.CL", "Comments": ["13 pages", "4 figures", "submitted to journal"]}, "abstract": "The advanced language processing abilities of large language models (LLMs) have stimulated debate over their capacity to replicate human-like cognitive processes. One differentiating factor between language processing in LLMs and humans is that language input is often grounded in more than one perceptual modality, whereas most LLMs process solely text-based information. Multimodal grounding allows humans to integrate - e.g. visual context with linguistic information and thereby place constraints on the space of upcoming words, reducing cognitive load and improving perception and comprehension. Recent multimodal LLMs (mLLMs) combine visual and linguistic embedding spaces with a transformer type attention mechanism for next-word prediction. To what extent does predictive language processing based on multimodal input align in mLLMs and humans? To answer this question, 200 human participants watched short audio-visual clips and estimated the predictability of an upcoming verb or noun. The same clips were processed by the mLLM CLIP, with predictability scores based on a comparison of image and text feature vectors. Eye-tracking was used to estimate what visual features participants attended to, and CLIP's visual attention weights were recorded. We find that human estimates of predictability align significantly with CLIP scores, but not for a unimodal LLM of comparable parameter size. Further, alignment vanished when CLIP's visual attention weights were perturbed, and when the same input was fed to a multimodal model without attention. Analysing attention patterns, we find a significant spatial overlap between CLIP's visual attention weights and human eye-tracking data. Results suggest that comparable processes of integrating multimodal information, guided by attention to relevant visual features, supports predictive language processing in mLLMs and humans.", "url": "https://arxiv.org/abs/2308.06035"}, {"metadata": {"arXiv": "2308.06039", "Date": "Fri, 11 Aug 2023 09:36:33 ", "Title": "Learning to Guide Human Experts via Personalized Large Language Models", "Authors": ["Debodeep Banerjee", "Stefano Teso", "Andrea Passerini"], "Categories": "cs.AI cs.CL"}, "abstract": "In learning to defer, a predictor identifies risky decisions and defers them to a human expert. One key issue with this setup is that the expert may end up over-relying on the machine's decisions, due to anchoring bias. At the same time, whenever the machine chooses the deferral option the expert has to take decisions entirely unassisted. As a remedy, we propose learning to guide (LTG), an alternative framework in which -- rather than suggesting ready-made decisions -- the machine provides guidance useful to guide decision-making, and the human is entirely responsible for coming up with a decision. We also introduce SLOG, an LTG implementation that leverages (a small amount of) human supervision to convert a generic large language model into a module capable of generating textual guidance, and present preliminary but promising results on a medical diagnosis task.", "url": "https://arxiv.org/abs/2308.06039"}, {"metadata": {"arXiv": "2308.06088", "Date": "Fri, 11 Aug 2023 12:03:12 ", "Title": "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models: A Comparative Study with Human Raters", "Authors": ["Arne Bewersdorff", "Kathrin Se{\\ss}ler", "Armin Baur", "Enkelejda Kasneci", "Claudia Nerdel"], "Categories": "cs.AI"}, "abstract": "Identifying logical errors in complex, incomplete or even contradictory and overall heterogeneous data like students' experimentation protocols is challenging. Recognizing the limitations of current evaluation methods, we investigate the potential of Large Language Models (LLMs) for automatically identifying student errors and streamlining teacher assessments. Our aim is to provide a foundation for productive, personalized feedback. Using a dataset of 65 student protocols, an Artificial Intelligence (AI) system based on the GPT-3.5 and GPT-4 series was developed and tested against human raters. Our results indicate varying levels of accuracy in error detection between the AI system and human raters. The AI system can accurately identify many fundamental student errors, for instance, the AI system identifies when a student is focusing the hypothesis not on the dependent variable but solely on an expected observation (acc. = 0.90), when a student modifies the trials in an ongoing investigation (acc. = 1), and whether a student is conducting valid test trials (acc. = 0.82) reliably. The identification of other, usually more complex errors, like whether a student conducts a valid control trial (acc. = .60), poses a greater challenge. This research explores not only the utility of AI in educational settings, but also contributes to the understanding of the capabilities of LLMs in error detection in inquiry-based learning like experimentation.", "url": "https://arxiv.org/abs/2308.06088"}, {"metadata": {"arXiv": "2308.06137", "Date": "Fri, 11 Aug 2023 13:56:39 ", "Title": "A Game-Theoretic Framework for Joint Forecasting and Planning", "Authors": ["Kushal Kedia", "Prithwish Dan", "Sanjiban Choudhury"], "Categories": "cs.AI"}, "abstract": "Planning safe robot motions in the presence of humans requires reliable forecasts of future human motion. However, simply predicting the most likely motion from prior interactions does not guarantee safety. Such forecasts fail to model the long tail of possible events, which are rarely observed in limited datasets. On the other hand, planning for worst-case motions leads to overtly conservative behavior and a ``frozen robot''. Instead, we aim to learn forecasts that predict counterfactuals that humans guard against. We propose a novel game-theoretic framework for joint planning and forecasting with the payoff being the performance of the planner against the demonstrator, and present practical algorithms to train models in an end-to-end fashion. We demonstrate that our proposed algorithm results in safer plans in a crowd navigation simulator and real-world datasets of pedestrian motion. We release our code at https://github.com/portal-cornell/Game-Theoretic-Forecasting-Planning.", "url": "https://arxiv.org/abs/2308.06137"}, {"metadata": {"arXiv": "2308.05822", "Date": "Thu, 10 Aug 2023 18:43:44 ", "Title": "Encode-Store-Retrieve: Enhancing Memory Augmentation through Language-Encoded Egocentric Perception", "Authors": ["Junxiao Shen", "John Dudley", "Per Ola Kristensson"], "Categories": "cs.CV cs.AI cs.HC"}, "abstract": "We depend on our own memory to encode, store, and retrieve our experiences. However, memory lapses can occur. One promising avenue for achieving memory augmentation is through the use of augmented reality head-mounted displays to capture and preserve egocentric videos, a practice commonly referred to as life logging. However, a significant challenge arises from the sheer volume of video data generated through life logging, as the current technology lacks the capability to encode and store such large amounts of data efficiently. Further, retrieving specific information from extensive video archives requires substantial computational power, further complicating the task of quickly accessing desired content. To address these challenges, we propose a memory augmentation system that involves leveraging natural language encoding for video data and storing them in a vector database. This approach harnesses the power of large vision language models to perform the language encoding process. Additionally, we propose using large language models to facilitate natural language querying. Our system underwent extensive evaluation using the QA-Ego4D dataset and achieved state-of-the-art results with a BLEU score of 8.3, outperforming conventional machine learning models that scored between 3.4 and 5.8. Additionally, in a user study, our system received a higher mean response score of 4.13/5 compared to the human participants' score of 2.46/5 on real-life episodic memory tasks.", "url": "https://arxiv.org/abs/2308.05822"}, {"metadata": {"arXiv": "2308.05846", "Date": "Thu, 10 Aug 2023 19:56:15 ", "Title": "Seed Kernel Counting using Domain Randomization and Object Tracking Neural Networks", "Authors": ["Venkat Margapuri and Prapti Thapaliya and Mitchell Neilsen"], "Categories": "cs.CV cs.AI"}, "abstract": "High-throughput phenotyping (HTP) of seeds, also known as seed phenotyping, is the comprehensive assessment of complex seed traits such as growth, development, tolerance, resistance, ecology, yield, and the measurement of parameters that form more complex traits. One of the key aspects of seed phenotyping is cereal yield estimation that the seed production industry relies upon to conduct their business. While mechanized seed kernel counters are available in the market currently, they are often priced high and sometimes outside the range of small scale seed production firms' affordability. The development of object tracking neural network models such as You Only Look Once (YOLO) enables computer scientists to design algorithms that can estimate cereal yield inexpensively. The key bottleneck with neural network models is that they require a plethora of labelled training data before they can be put to task. We demonstrate that the use of synthetic imagery serves as a feasible substitute to train neural networks for object tracking that includes the tasks of object classification and detection. Furthermore, we propose a seed kernel counter that uses a low-cost mechanical hopper, trained YOLOv8 neural network model, and object tracking algorithms on StrongSORT and ByteTrack to estimate cereal yield from videos. The experiment yields a seed kernel count with an accuracy of 95.2\\% and 93.2\\% for Soy and Wheat respectively using the StrongSORT algorithm, and an accuray of 96.8\\% and 92.4\\% for Soy and Wheat respectively using the ByteTrack algorithm.", "url": "https://arxiv.org/abs/2308.05846"}, {"metadata": {"arXiv": "2308.05938", "Date": "Fri, 11 Aug 2023 04:42:10 ", "Title": "FoodSAM: Any Food Segmentation", "Authors": ["Xing Lan", "Jiayi Lyu", "Hanyu Jiang", "Kun Dong", "Zehai Niu", "Yi Zhang", "Jian Xue"], "Categories": "cs.CV cs.AI", "Comments": ["Code is available at https://github.com/jamesjg/FoodSAM"]}, "abstract": "In this paper, we explore the zero-shot capability of the Segment Anything Model (SAM) for food image segmentation. To address the lack of class-specific information in SAM-generated masks, we propose a novel framework, called FoodSAM. This innovative approach integrates the coarse semantic mask with SAM-generated masks to enhance semantic segmentation quality. Besides, we recognize that the ingredients in food can be supposed as independent individuals, which motivated us to perform instance segmentation on food images. Furthermore, FoodSAM extends its zero-shot capability to encompass panoptic segmentation by incorporating an object detector, which renders FoodSAM to effectively capture non-food object information. Drawing inspiration from the recent success of promptable segmentation, we also extend FoodSAM to promptable segmentation, supporting various prompt variants. Consequently, FoodSAM emerges as an all-encompassing solution capable of segmenting food items at multiple levels of granularity. Remarkably, this pioneering framework stands as the first-ever work to achieve instance, panoptic, and promptable segmentation on food images. Extensive experiments demonstrate the feasibility and impressing performance of FoodSAM, validating SAM's potential as a prominent and influential tool within the domain of food image segmentation. We release our code at https://github.com/jamesjg/FoodSAM.", "url": "https://arxiv.org/abs/2308.05938"}, {"metadata": {"arXiv": "2308.05983", "Date": "Fri, 11 Aug 2023 07:38:46 ", "Title": "Face Encryption via Frequency-Restricted Identity-Agnostic Attacks", "Authors": ["Xin Dong", "Rui Wang", "Siyuan Liang", "Aishan Liu", "Lihua Jing"], "Categories": "cs.CV cs.AI cs.CR"}, "abstract": "Billions of people are sharing their daily live images on social media everyday. However, malicious collectors use deep face recognition systems to easily steal their biometric information (e.g., faces) from these images. Some studies are being conducted to generate encrypted face photos using adversarial attacks by introducing imperceptible perturbations to reduce face information leakage. However, existing studies need stronger black-box scenario feasibility and more natural visual appearances, which challenge the feasibility of privacy protection. To address these problems, we propose a frequency-restricted identity-agnostic (FRIA) framework to encrypt face images from unauthorized face recognition without access to personal information. As for the weak black-box scenario feasibility, we obverse that representations of the average feature in multiple face recognition models are similar, thus we propose to utilize the average feature via the crawled dataset from the Internet as the target to guide the generation, which is also agnostic to identities of unknown face recognition systems; in nature, the low-frequency perturbations are more visually perceptible by the human vision system. Inspired by this, we restrict the perturbation in the low-frequency facial regions by discrete cosine transform to achieve the visual naturalness guarantee. Extensive experiments on several face recognition models demonstrate that our FRIA outperforms other state-of-the-art methods in generating more natural encrypted faces while attaining high black-box attack success rates of 96%. In addition, we validate the efficacy of FRIA using real-world black-box commercial API, which reveals the potential of FRIA in practice. Our codes can be found in https://github.com/XinDong10/FRIA.", "url": "https://arxiv.org/abs/2308.05983"}, {"metadata": {"arXiv": "2308.05857", "Date": "Thu, 10 Aug 2023 21:06:18 ", "Title": "Knowledge Propagation over Conditional Independence Graphs", "Authors": ["Urszula Chajewska", "Harsh Shrivastava"], "Categories": "cs.AI cs.LG"}, "abstract": "Conditional Independence (CI) graph is a special type of a Probabilistic Graphical Model (PGM) where the feature connections are modeled using an undirected graph and the edge weights show the partial correlation strength between the features. Since the CI graphs capture direct dependence between features, they have been garnering increasing interest within the research community for gaining insights into the systems from various domains, in particular discovering the domain topology. In this work, we propose algorithms for performing knowledge propagation over the CI graphs. Our experiments demonstrate that our techniques improve upon the state-of-the-art on the publicly available Cora and PubMed datasets.", "url": "https://arxiv.org/abs/2308.05857"}, {"metadata": {"arXiv": "2308.05893", "Date": "Fri, 11 Aug 2023 00:59:29 ", "Title": "Learning to Team-Based Navigation: A Review of Deep Reinforcement Learning Techniques for Multi-Agent Pathfinding", "Authors": ["Jaehoon Chung", "Jamil Fayyad", "Younes Al Younes", "and Homayoun Najjaran"], "Categories": "cs.AI cs.LG cs.MA cs.RO cs.SY eess.SY"}, "abstract": "Multi-agent pathfinding (MAPF) is a critical field in many large-scale robotic applications, often being the fundamental step in multi-agent systems. The increasing complexity of MAPF in complex and crowded environments, however, critically diminishes the effectiveness of existing solutions. In contrast to other studies that have either presented a general overview of the recent advancements in MAPF or extensively reviewed Deep Reinforcement Learning (DRL) within multi-agent system settings independently, our work presented in this review paper focuses on highlighting the integration of DRL-based approaches in MAPF. Moreover, we aim to bridge the current gap in evaluating MAPF solutions by addressing the lack of unified evaluation metrics and providing comprehensive clarification on these metrics. Finally, our paper discusses the potential of model-based DRL as a promising future direction and provides its required foundational understanding to address current challenges in MAPF. Our objective is to assist readers in gaining insight into the current research direction, providing unified metrics for comparing different MAPF algorithms and expanding their knowledge of model-based DRL to address the existing challenges in MAPF.", "url": "https://arxiv.org/abs/2308.05893"}, {"metadata": {"arXiv": "2308.06025", "Date": "Fri, 11 Aug 2023 09:07:38 ", "Title": "Controlling Character Motions without Observable Driving Source", "Authors": ["Weiyuan Li", "Bin Dai", "Ziyi Zhou", "Qi Yao and Baoyuan Wang"], "Categories": "cs.AI cs.LG"}, "abstract": "How to generate diverse, life-like, and unlimited long head/body sequences without any driving source? We argue that this under-investigated research problem is non-trivial at all, and has unique technical challenges behind it. Without semantic constraints from the driving sources, using the standard autoregressive model to generate infinitely long sequences would easily result in 1) out-of-distribution (OOD) issue due to the accumulated error, 2) insufficient diversity to produce natural and life-like motion sequences and 3) undesired periodic patterns along the time. To tackle the above challenges, we propose a systematic framework that marries the benefits of VQ-VAE and a novel token-level control policy trained with reinforcement learning using carefully designed reward functions. A high-level prior model can be easily injected on top to generate unlimited long and diverse sequences. Although we focus on no driving sources now, our framework can be generalized for controlled synthesis with explicit driving sources. Through comprehensive evaluations, we conclude that our proposed framework can address all the above-mentioned challenges and outperform other strong baselines very significantly.", "url": "https://arxiv.org/abs/2308.06025"}, {"metadata": {"arXiv": "2308.06197", "Date": "Fri, 11 Aug 2023 15:42:48 ", "Title": "Complex Facial Expression Recognition Using Deep Knowledge Distillation of Basic Features", "Authors": ["Angus Maiden (1)", "Bahareh Nakisa (1) ((1) Deakin University)"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["17 pages", "9 figures", "6 tables. Code available at https://github.com/AngusMaiden/complex-FER"], "MSC-class": "68T45 (Primary) 68T07, 68T01, 68T05 (Secondary)", "ACM-class": "I.2.1; I.2.10; I.2.6; I.2.0"}, "abstract": "Complex emotion recognition is a cognitive task that has so far eluded the same excellent performance of other tasks that are at or above the level of human cognition. Emotion recognition through facial expressions is particularly difficult due to the complexity of emotions expressed by the human face. For a machine to approach the same level of performance in this domain as a human, it may need to synthesise knowledge and understand new concepts in real-time as humans do. Humans are able to learn new concepts using only few examples, by distilling the important information from memories and discarding the rest. Similarly, continual learning methods learn new classes whilst retaining the knowledge of known classes, whilst few-shot learning methods are able to learn new classes using very few training examples. We propose a novel continual learning method inspired by human cognition and learning that can accurately recognise new compound expression classes using few training samples, by building on and retaining its knowledge of basic expression classes. Using GradCAM visualisations, we demonstrate the relationship between basic and compound facial expressions, which our method leverages through knowledge distillation and a novel Predictive Sorting Memory Replay. Our method achieves the current state-of-the-art in continual learning for complex facial expression recognition with 74.28% Overall Accuracy on new classes. We also demonstrate that using continual learning for complex facial expression recognition achieves far better performance than non-continual learning methods, improving on state-of-the-art non-continual learning methods by 13.95%. To the best of our knowledge, our work is also the first to apply few-shot learning to complex facial expression recognition, achieving the state-of-the-art with 100% accuracy using a single training sample for each expression class.", "url": "https://arxiv.org/abs/2308.06197"}, {"metadata": {"arXiv": "2308.06202", "Date": "Fri, 11 Aug 2023 15:57:45 ", "Title": "Exploring Predicate Visual Context in Detecting of Human-Object Interactions", "Authors": ["Frederic Z. Zhang", "Yuhui Yuan", "Dylan Campbell", "Zhuoyao Zhong", "Stephen Gould"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["To appear in ICCV2023"]}, "abstract": "Recently, the DETR framework has emerged as the dominant approach for human--object interaction (HOI) research. In particular, two-stage transformer-based HOI detectors are amongst the most performant and training-efficient approaches. However, these often condition HOI classification on object features that lack fine-grained contextual information, eschewing pose and orientation information in favour of visual cues about object identity and box extremities. This naturally hinders the recognition of complex or ambiguous interactions. In this work, we study these issues through visualisations and carefully designed experiments. Accordingly, we investigate how best to re-introduce image features via cross-attention. With an improved query design, extensive exploration of keys and values, and box pair positional embeddings as spatial guidance, our model with enhanced predicate visual context (PViC) outperforms state-of-the-art methods on the HICO-DET and V-COCO benchmarks, while maintaining low training cost.", "url": "https://arxiv.org/abs/2308.06202"}, {"metadata": {"arXiv": "2308.05765", "Date": "Wed, 09 Aug 2023 11:47:28 ", "Title": "Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients", "Authors": ["Md. Simul Hasan Talukder", "Rejwan Bin Sulaiman", "Mouli Bardhan Paul Angon"], "Categories": "cs.LG cs.AI", "Comments": ["7 page", "6 Table and 6 Figure"]}, "abstract": "Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.", "url": "https://arxiv.org/abs/2308.05765"}, {"metadata": {"arXiv": "2308.05889", "Date": "Fri, 11 Aug 2023 00:44:46 ", "Title": "DF2: Distribution-Free Decision-Focused Learning", "Authors": ["Lingkai Kong", "Wenhao Mu", "Jiaming Cui", "Yuchen Zhuang", "B. Aditya Prakash", "Bo Dai", "Chao Zhang"], "Categories": "cs.LG cs.AI", "Comments": ["24 pages"]}, "abstract": "Decision-focused learning (DFL) has recently emerged as a powerful approach for predict-then-optimize problems by customizing a predictive model to a downstream optimization task. However, existing end-to-end DFL methods are hindered by three significant bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs as DFL relies on the KKT condition for exact gradient computation, while most methods approximate the gradient for backpropagation in non-convex objectives. In this paper, we present DF2 -- the first \\textit{distribution-free} decision-focused learning method explicitly designed to address these three bottlenecks. Rather than depending on a task-specific forecaster that requires precise model assumptions, our method directly learns the expected optimization function during training. To efficiently learn the function in a data-driven manner, we devise an attention-based model architecture inspired by the distribution-based parameterization of the expected objective. Our method is, to the best of our knowledge, the first to address all three bottlenecks within a single model. We evaluate DF2 on a synthetic problem, a wind power bidding problem, and a non-convex vaccine distribution problem, demonstrating the effectiveness of DF2.", "url": "https://arxiv.org/abs/2308.05889"}, {"metadata": {"arXiv": "2308.06053", "Date": "Fri, 11 Aug 2023 10:05:53 ", "Title": "Cost-effective On-device Continual Learning over Memory Hierarchy with Miro", "Authors": ["Xinyue Ma", "Suyeon Jeong", "Minjia Zhang", "Di Wang", "Jonghyun Choi", "Myeongjae Jeon"], "Categories": "cs.LG cs.AI cs.AR", "Comments": ["This paper is submitted for publication to MobiCom 2023"]}, "abstract": "Continual learning (CL) trains NN models incrementally from a continuous stream of tasks. To remember previously learned knowledge, prior studies store old samples over a memory hierarchy and replay them when new tasks arrive. Edge devices that adopt CL to preserve data privacy are typically energy-sensitive and thus require high model accuracy while not compromising energy efficiency, i.e., cost-effectiveness. Our work is the first to explore the design space of hierarchical memory replay-based CL to gain insights into achieving cost-effectiveness on edge devices. We present Miro, a novel system runtime that carefully integrates our insights into the CL framework by enabling it to dynamically configure the CL system based on resource states for the best cost-effectiveness. To reach this goal, Miro also performs online profiling on parameters with clear accuracy-energy trade-offs and adapts to optimal values with low overhead. Extensive evaluations show that Miro significantly outperforms baseline systems we build for comparison, consistently achieving higher cost-effectiveness.", "url": "https://arxiv.org/abs/2308.06053"}, {"metadata": {"arXiv": "2308.06094", "Date": "Fri, 11 Aug 2023 12:05:32 ", "Title": "Reinforcement Logic Rule Learning for Temporal Point Processes", "Authors": ["Chao Yang", "Lu Wang", "Kun Gao", "Shuang Li"], "Categories": "cs.LG cs.AI", "Comments": ["27 pages"]}, "abstract": "We propose a framework that can incrementally expand the explanatory temporal logic rule set to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and weights will be gradually optimized until the likelihood of the observational event sequences is optimal. The proposed algorithm alternates between a master problem, where the current rule set weights are updated, and a subproblem, where a new rule is searched and included to best increase the likelihood. The formulated master problem is convex and relatively easy to solve using continuous optimization, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be efficiently queried by evaluating the subproblem objective. The trained policy can be used to generate new rules in a controllable way. We evaluate our methods on both synthetic and real healthcare datasets, obtaining promising results.", "url": "https://arxiv.org/abs/2308.06094"}, {"metadata": {"arXiv": "2308.06138", "Date": "Fri, 11 Aug 2023 13:58:42 ", "Title": "Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling", "Authors": ["Masoume Kazemi", "Davood Moradkhani", "Alireza A. Alipour"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Machine Learning (ML) is a powerful tool for material science applications. Artificial Neural Network (ANN) is a machine learning technique that can provide high prediction accuracy. This study aimed to develop an ANN model to predict the cake moisture of the pressure filtration process of zinc production. The cake moisture was influenced by seven parameters: temperature (35 and 65 Celsius), solid concentration (0.2 and 0.38 g/L), pH (2, 3.5, and 5), air-blow time (2, 10, and 15 min), cake thickness (14, 20, 26, and 34 mm), pressure, and filtration time. The study conducted 288 tests using two types of fabrics: polypropylene (S1) and polyester (S2). The ANN model was evaluated by the Coefficient of determination (R2), the Mean Square Error (MSE), and the Mean Absolute Error (MAE) metrics for both datasets. The results showed R2 values of 0.88 and 0.83, MSE values of 6.243x10-07 and 1.086x10-06, and MAE values of 0.00056 and 0.00088 for S1 and S2, respectively. These results indicated that the ANN model could predict the cake moisture of pressure filtration in the zinc leaching process with high accuracy.", "url": "https://arxiv.org/abs/2308.06138"}, {"metadata": {"arXiv": "2308.06155", "Date": "Fri, 11 Aug 2023 14:33:20 ", "Title": "Phased Deep Spatio-temporal Learning for Highway Traffic Volume Prediction", "Authors": ["Weilong Ding", "Tianpu Zhang", "Zhe Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Inter-city highway transportation is significant for citizens' modern urban life and generates heterogeneous sensory data with spatio-temporal characteristics. As a routine analysis in transportation domain, daily traffic volume estimation faces challenges for highway toll stations including lacking of exploration of correlative spatio-temporal features from a long-term perspective and effective means to deal with data imbalance which always deteriorates the predictive performance. In this paper, a deep spatio-temporal learning method is proposed to predict daily traffic volume in three phases. In feature pre-processing phase, data is normalized elaborately according to latent long-tail distribution. In spatio-temporal learning phase, a hybrid model is employed combining fully convolution network (FCN) and long short-term memory (LSTM), which considers time, space, meteorology, and calendar from heterogeneous data. In decision phase, traffic volumes on a coming day at network-wide toll stations would be achieved effectively, which is especially calibrated for vital few highway stations. Using real-world data from one Chinese provincial highway, extensive experiments show our method has distinct improvement for predictive accuracy than various traditional models, reaching 5.269 and 0.997 in MPAE and R-squre metrics, respectively.", "url": "https://arxiv.org/abs/2308.06155"}, {"metadata": {"arXiv": "2308.06221", "Date": "Fri, 11 Aug 2023 16:48:31 ", "Title": "Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms", "Authors": ["Kanishka Tyagi", "Chinmay Rane", "Michael Manry"], "Categories": "cs.LG cs.AI"}, "abstract": "We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for deep autoencoders. We investigate several problems in deep autoencoders networks including training issues, the theoretical, mathematical and experimental justification that the networks are linear, optimizing the number of hidden units in each layer and determining the depth of the deep learning model. A direct implication of the current work is the ability to construct fast deep learning models using desktop level computational resources. This, in our opinion, promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi layer perceptron and deep learners reported in the literature.", "url": "https://arxiv.org/abs/2308.06221"}, {"metadata": {"arXiv": "2308.06262", "Date": "Fri, 11 Aug 2023 17:54:44 ", "Title": "Foundation Model is Efficient Multimodal Multitask Model Selector", "Authors": ["Fanqing Meng", "Wenqi Shao", "Zhanglin Peng", "Chonghe Jiang", "Kaipeng Zhang", "Yu Qiao", "Ping Luo"], "Categories": "cs.LG cs.AI"}, "abstract": "This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0\\%, 26.3\\%, 20.1\\%, 54.8\\%, 12.2\\% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.", "url": "https://arxiv.org/abs/2308.06262"}, {"metadata": {"arXiv": "2308.06203", "Date": "Fri, 11 Aug 2023 15:58:15 ", "Title": "Towards a Causal Probabilistic Framework for Prediction, Action-Selection & Explanations for Robot Block-Stacking Tasks", "Authors": ["Ricardo Cannizzaro", "Jonathan Routley", "and Lars Kunze"], "Categories": "cs.RO cs.AI cs.LG stat.AP stat.ML", "Comments": ["3 pages", "3 figures", "accepted to the \"Causality for Robotics: Answering the Question of Why\" workshop at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"], "ACM-class": "I.2.9; I.2.8; I.2.3; G.3; I.6.8"}, "abstract": "Uncertainties in the real world mean that is impossible for system designers to anticipate and explicitly design for all scenarios that a robot might encounter. Thus, robots designed like this are fragile and fail outside of highly-controlled environments. Causal models provide a principled framework to encode formal knowledge of the causal relationships that govern the robot's interaction with its environment, in addition to probabilistic representations of noise and uncertainty typically encountered by real-world robots. Combined with causal inference, these models permit an autonomous agent to understand, reason about, and explain its environment. In this work, we focus on the problem of a robot block-stacking task due to the fundamental perception and manipulation capabilities it demonstrates, required by many applications including warehouse logistics and domestic human support robotics. We propose a novel causal probabilistic framework to embed a physics simulation capability into a structural causal model to permit robots to perceive and assess the current state of a block-stacking task, reason about the next-best action from placement candidates, and generate post-hoc counterfactual explanations. We provide exemplar next-best action selection results and outline planned experimentation in simulated and real-world robot block-stacking tasks.", "url": "https://arxiv.org/abs/2308.06203"}, {"metadata": {"arXiv": "2308.06204", "Date": "Fri, 11 Aug 2023 16:09:12 ", "Title": "Safety in Traffic Management Systems: A Comprehensive Survey", "Authors": ["Wenlu Du", "Ankan Dash", "Jing Li", "Hua Wei and Guiling Wang"], "Categories": "eess.SY cs.AI cs.LG cs.SY", "Comments": ["Accepted by MDPI Designs journal", "the Special Issue Design and Application of Intelligent Transportation Systems. 30 pages", "6 figures", "published on 10 August 2023"], "Journal-ref": "Designs 2023, 7, 100", "DOI": "10.3390/designs7040100"}, "abstract": "Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.", "url": "https://arxiv.org/abs/2308.06204"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

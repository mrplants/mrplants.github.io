<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2308.00924", "Date": "Wed, 02 Aug 2023 03:47:19 ", "Title": "Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather", "Authors": ["Chowdhury Sadman Jahan and Andreas Savakis"], "Categories": "cs.CV cs.LG"}, "abstract": "Domain adaptation (DA) strives to mitigate the domain gap between the source domain where a model is trained, and the target domain where the model is deployed. When a deep learning model is deployed on an aerial platform, it may face gradually degrading weather conditions during operation, leading to widening domain gaps between the training data and the encountered evaluation data. We synthesize two such gradually worsening weather conditions on real images from two existing aerial imagery datasets, generating a total of four benchmark datasets. Under the continual, or test-time adaptation setting, we evaluate three DA models on our datasets: a baseline standard DA model and two continual DA models. In such setting, the models can access only one small portion, or one batch of the target data at a time, and adaptation takes place continually, and over only one epoch of the data. The combination of the constraints of continual adaptation, and gradually deteriorating weather conditions provide the practical DA scenario for aerial deployment. Among the evaluated models, we consider both convolutional and transformer architectures for comparison. We discover stability issues during adaptation for existing buffer-fed continual DA methods, and offer gradient normalization as a simple solution to curb training instability.", "url": "https://arxiv.org/abs/2308.00924"}, {"metadata": {"arXiv": "2308.00956", "Date": "Wed, 02 Aug 2023 05:47:56 ", "Title": "Curriculum Guided Domain Adaptation in the Dark", "Authors": ["Chowdhury Sadman Jahan and Andreas Savakis"], "Categories": "cs.CV cs.LG"}, "abstract": "Addressing the rising concerns of privacy and security, domain adaptation in the dark aims to adapt a black-box source trained model to an unlabeled target domain without access to any source data or source model parameters. The need for domain adaptation of black-box predictors becomes even more pronounced to protect intellectual property as deep learning based solutions are becoming increasingly commercialized. Current methods distill noisy predictions on the target data obtained from the source model to the target model, and/or separate clean/noisy target samples before adapting using traditional noisy label learning algorithms. However, these methods do not utilize the easy-to-hard learning nature of the clean/noisy data splits. Also, none of the existing methods are end-to-end, and require a separate fine-tuning stage and an initial warmup stage. In this work, we present Curriculum Adaptation for Black-Box (CABB) which provides a curriculum guided adaptation approach to gradually train the target model, first on target data with high confidence (clean) labels, and later on target data with noisy labels. CABB utilizes Jensen-Shannon divergence as a better criterion for clean-noisy sample separation, compared to the traditional criterion of cross entropy loss. Our method utilizes co-training of a dual-branch network to suppress error accumulation resulting from confirmation bias. The proposed approach is end-to-end trainable and does not require any extra finetuning stage, unlike existing methods. Empirical results on standard domain adaptation datasets show that CABB outperforms existing state-of-the-art black-box DA models and is comparable to white-box domain adaptation models.", "url": "https://arxiv.org/abs/2308.00956"}, {"metadata": {"arXiv": "2308.00994", "Date": "Wed, 02 Aug 2023 07:59:25 ", "Title": "Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective", "Authors": ["Moon Ye-Bin", "Nam Hyeon-Woo", "Wonseok Choi", "Nayeong Kim", "Suha Kwak", "Tae-Hyun Oh"], "Categories": "cs.CV cs.LG"}, "abstract": "We live in a vast ocean of data, and deep neural networks are no exception to this. However, this data exhibits an inherent phenomenon of imbalance. This imbalance poses a risk of deep neural networks producing biased predictions, leading to potentially severe ethical and social consequences. To address these challenges, we believe that the use of generative models is a promising approach for comprehending tasks, given the remarkable advancements demonstrated by recent diffusion models in generating high-quality images. In this work, we propose a simple yet effective baseline, SYNAuG, that utilizes synthetic data as a preliminary step before employing task-specific algorithms to address data imbalance problems. This straightforward approach yields impressive performance on datasets such as CIFAR100-LT, ImageNet100-LT, UTKFace, and Waterbird, surpassing the performance of existing task-specific methods. While we do not claim that our approach serves as a complete solution to the problem of data imbalance, we argue that supplementing the existing data with synthetic data proves to be an effective and crucial preliminary step in addressing data imbalance concerns.", "url": "https://arxiv.org/abs/2308.00994"}, {"metadata": {"arXiv": "2308.01000", "Date": "Wed, 02 Aug 2023 08:20:00 ", "Title": "MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization", "Authors": ["Louis Soum-Fontez", "Jean-Emmanuel Deschaud", "Fran\\c{c}ois Goulette"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted for publication at IROS 2023"]}, "abstract": "Supervised 3D Object Detection models have been displaying increasingly better performance in single-domain cases where the training data comes from the same environment and sensor as the testing data. However, in real-world scenarios data from the target domain may not be available for finetuning or for domain adaptation methods. Indeed, 3D object detection models trained on a source dataset with a specific point distribution have shown difficulties in generalizing to unseen datasets. Therefore, we decided to leverage the information available from several annotated source datasets with our Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the robustness of 3D object detection models when tested in a new environment with a different sensor configuration. To tackle the labelling gap between datasets, we used a new label mapping based on coarse labels. Furthermore, we show how we managed the mix of datasets during training and finally introduce a new cross-dataset augmentation method: cross-dataset object injection. We demonstrate that this training paradigm shows improvements for different types of 3D object detection models. The source code and additional results for this research project will be publicly available on GitHub for interested parties to access and utilize: https://github.com/LouisSF/MDT3D", "url": "https://arxiv.org/abs/2308.01000"}, {"metadata": {"arXiv": "2308.01086", "Date": "Wed, 02 Aug 2023 11:31:43 ", "Title": "Homography Estimation in Complex Topological Scenes", "Authors": ["Giacomo D'Amicantonio", "Egor Bondarau", "Peter H.N. De With"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Will be published in Intelligent Vehicle Symposium 2023"]}, "abstract": "Surveillance videos and images are used for a broad set of applications, ranging from traffic analysis to crime detection. Extrinsic camera calibration data is important for most analysis applications. However, security cameras are susceptible to environmental conditions and small camera movements, resulting in a need for an automated re-calibration method that can account for these varying conditions. In this paper, we present an automated camera-calibration process leveraging a dictionary-based approach that does not require prior knowledge on any camera settings. The method consists of a custom implementation of a Spatial Transformer Network (STN) and a novel topological loss function. Experiments reveal that the proposed method improves the IoU metric by up to 12% w.r.t. a state-of-the-art model across five synthetic datasets and the World Cup 2014 dataset.", "url": "https://arxiv.org/abs/2308.01086"}, {"metadata": {"arXiv": "2308.01097", "Date": "Wed, 02 Aug 2023 12:04:28 ", "Title": "Spatio-Temporal Branching for Motion Prediction using Motion Increments", "Authors": ["Jiexin Wang", "Yujie Zhou", "Wenwen Qiang", "Ying Ba", "Bing Su", "Ji-Rong Wen"], "Categories": "cs.CV cs.LG"}, "abstract": "Human motion prediction (HMP) has emerged as a popular research topic due to its diverse applications, but it remains a challenging task due to the stochastic and aperiodic nature of future poses. Traditional methods rely on hand-crafted features and machine learning techniques, which often struggle to model the complex dynamics of human motion. Recent deep learning-based methods have achieved success by learning spatio-temporal representations of motion, but these models often overlook the reliability of motion data. Additionally, the temporal and spatial dependencies of skeleton nodes are distinct. The temporal relationship captures motion information over time, while the spatial relationship describes body structure and the relationships between different nodes. In this paper, we propose a novel spatio-temporal branching network using incremental information for HMP, which decouples the learning of temporal-domain and spatial-domain features, extracts more motion information, and achieves complementary cross-domain knowledge learning through knowledge distillation. Our approach effectively reduces noise interference and provides more expressive information for characterizing motion by separately extracting temporal and spatial features. We evaluate our approach on standard HMP benchmarks and outperform state-of-the-art methods in terms of prediction accuracy.", "url": "https://arxiv.org/abs/2308.01097"}, {"metadata": {"arXiv": "2308.01184", "Date": "Wed, 02 Aug 2023 14:48:25 ", "Title": "Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior", "Authors": ["Fengbei Liu", "Yuanhong Chen", "Chong Wang", "Yuyuan Liu", "Gustavo Carneiro"], "Categories": "cs.CV cs.LG"}, "abstract": "The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model. Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning. Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models.", "url": "https://arxiv.org/abs/2308.01184"}, {"metadata": {"arXiv": "2308.01246", "Date": "Wed, 02 Aug 2023 16:00:39 ", "Title": "Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites", "Authors": ["Jyotirmaya Shivottam and Subhankar Mishra"], "Categories": "cs.CV cs.HC cs.LG", "Comments": ["Accepted at The 28th International ACM Conference on 3D Web Technology (Web3D 2023)"], "ACM-class": "I.4.5"}, "abstract": "Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.", "url": "https://arxiv.org/abs/2308.01246"}, {"metadata": {"arXiv": "2308.00709", "Date": "Fri, 28 Jul 2023 22:52:15 ", "Title": "DeepTSF: Codeless machine learning operations for time series forecasting", "Authors": ["Sotiris Pelekis", "Evangelos Karakolis", "Theodosios Pountridis", "George Kormpakis", "George Lampropoulos", "Spiros Mouzakits", "Dimitris Askounis"], "Categories": "cs.LG cs.SE"}, "abstract": "This paper presents DeepTSF, a comprehensive machine learning operations (MLOps) framework aiming to innovate time series forecasting through workflow automation and codeless modeling. DeepTSF automates key aspects of the ML lifecycle, making it an ideal tool for data scientists and MLops engineers engaged in machine learning (ML) and deep learning (DL)-based forecasting. DeepTSF empowers users with a robust and user-friendly solution, while it is designed to seamlessly integrate with existing data analysis workflows, providing enhanced productivity and compatibility. The framework offers a front-end user interface (UI) suitable for data scientists, as well as other higher-level stakeholders, enabling comprehensive understanding through insightful visualizations and evaluation metrics. DeepTSF also prioritizes security through identity management and access authorization mechanisms. The application of DeepTSF in real-life use cases of the I-NERGY project has already proven DeepTSF's efficacy in DL-based load forecasting, showcasing its significant added value in the electrical power and energy systems domain.", "url": "https://arxiv.org/abs/2308.00709"}, {"metadata": {"arXiv": "2308.00720", "Date": "Tue, 01 Aug 2023 11:13:54 ", "Title": "Divergence of the ADAM algorithm with fixed-stepsize: a (very) simple example", "Authors": ["Ph. L. Toint"], "Categories": "cs.LG", "MSC-class": "65K10, 90C26, 90C30", "ACM-class": "G.6.1; I.2.6"}, "abstract": "A very simple unidimensional function with Lipschitz continuous gradient is constructed such that the ADAM algorithm with constant stepsize, started from the origin, diverges when applied to minimize this function in the absence of noise on the gradient. Divergence occurs irrespective of the choice of the method parameters.", "url": "https://arxiv.org/abs/2308.00720"}, {"metadata": {"arXiv": "2308.00755", "Date": "Tue, 01 Aug 2023 18:00:08 ", "Title": "The Bias Amplification Paradox in Text-to-Image Generation", "Authors": ["Preethi Seshadri", "Sameer Singh", "Yanai Elazar"], "Categories": "cs.LG cs.CL cs.CV cs.CY"}, "abstract": "Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding factors that contribute to bias amplification.", "url": "https://arxiv.org/abs/2308.00755"}, {"metadata": {"arXiv": "2308.00788", "Date": "Tue, 01 Aug 2023 18:59:07 ", "Title": "An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning", "Authors": ["Yihua Zhang", "Prashant Khanduri", "Ioannis Tsaknakis", "Yuguang Yao", "Mingyi Hong", "Sijia Liu"], "Categories": "cs.LG math.OC"}, "abstract": "Recently, bi-level optimization (BLO) has taken center stage in some very exciting developments in the area of signal processing (SP) and machine learning (ML). Roughly speaking, BLO is a classical optimization problem that involves two levels of hierarchy (i.e., upper and lower levels), wherein obtaining the solution to the upper-level problem requires solving the lower-level one. BLO has become popular largely because it is powerful in modeling problems in SP and ML, among others, that involve optimizing nested objective functions. Prominent applications of BLO range from resource allocation for wireless systems to adversarial machine learning. In this work, we focus on a class of tractable BLO problems that often appear in SP and ML applications. We provide an overview of some basic concepts of this class of BLO problems, such as their optimality conditions, standard algorithms (including their optimization principles and practical implementations), as well as how they can be leveraged to obtain state-of-the-art results for a number of key SP and ML applications. Further, we discuss some recent advances in BLO theory, its implications for applications, and point out some limitations of the state-of-the-art that require significant future research efforts. Overall, we hope that this article can serve to accelerate the adoption of BLO as a generic tool to model, analyze, and innovate on a wide array of emerging SP applications.", "url": "https://arxiv.org/abs/2308.00788"}, {"metadata": {"arXiv": "2308.00824", "Date": "Tue, 01 Aug 2023 20:22:53 ", "Title": "An Exact Kernel Equivalence for Finite Classification Models", "Authors": ["Brian Bell", "Michael Geyer", "Juston Moore", "David Glickenstein", "Amanda Fernandez"], "Categories": "cs.LG", "Comments": ["TAG-ML at ICML 2023 in Proceedings. 8 pages", "6 figures", "proofs in Appendix"], "ACM-class": "F.2; G.1"}, "abstract": "We explore the equivalence between neural networks and kernel methods by deriving the first exact representation of any finite-size parametric classification model trained with gradient descent as a kernel machine. We compare our exact representation to the well-known Neural Tangent Kernel (NTK) and discuss approximation error relative to the NTK and other non-exact path kernel formulations. We experimentally demonstrate that the kernel can be computed for realistic networks up to machine precision. We use this exact kernel to show that our theoretical contribution can provide useful insights into the predictions made by neural networks, particularly the way in which they generalize.", "url": "https://arxiv.org/abs/2308.00824"}, {"metadata": {"arXiv": "2308.00856", "Date": "Tue, 01 Aug 2023 21:59:22 ", "Title": "Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation", "Authors": ["Muhammad Irfan Khan", "Esa Alhoniemi", "Elina Kontio", "Suleiman A. Khan", "and Mojtaba Jafaritadi"], "Categories": "cs.LG cs.CR eess.IV"}, "abstract": "Federated Learning (FL) is a distributed machine learning approach that safeguards privacy by creating an impartial global model while respecting the privacy of individual client data. However, the conventional FL method can introduce security risks when dealing with diverse client data, potentially compromising privacy and data integrity. To address these challenges, we present a differential privacy (DP) federated deep learning framework in medical image segmentation. In this paper, we extend our similarity weight aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private similarity-weighted aggregation algorithm for brain tumor segmentation in multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only enhances model segmentation capabilities but also provides an additional layer of privacy preservation. Extensive benchmarking and evaluation of our framework, with computational performance as a key consideration, demonstrate that DP-SimAgg enables accurate and robust brain tumor segmentation while minimizing communication costs during model training. This advancement is crucial for preserving the privacy of medical image data and safeguarding sensitive information. In conclusion, adding a differential privacy layer in the global weight aggregation phase of the federated brain tumor segmentation provides a promising solution to privacy concerns without compromising segmentation model efficacy. By leveraging DP, we ensure the protection of client data against adversarial attacks and malicious participants.", "url": "https://arxiv.org/abs/2308.00856"}, {"metadata": {"arXiv": "2308.00887", "Date": "Wed, 02 Aug 2023 00:32:02 ", "Title": "Factor Graph Neural Networks", "Authors": ["Zhen Zhang", "Mohammed Haroon Dupty", "Fan Wu", "Javen Qinfeng Shi and Wee Sun Lee"], "Categories": "cs.LG", "Comments": ["Accepted by JMLR"]}, "abstract": "In recent years, we have witnessed a surge of Graph Neural Networks (GNNs), most of which can learn powerful representations in an end-to-end fashion with great success in many real-world applications. They have resemblance to Probabilistic Graphical Models (PGMs), but break free from some limitations of PGMs. By aiming to provide expressive methods for representation learning instead of computing marginals or most likely configurations, GNNs provide flexibility in the choice of information flowing rules while maintaining good performance. Despite their success and inspirations, they lack efficient ways to represent and learn higher-order relations among variables/nodes. More expressive higher-order GNNs which operate on k-tuples of nodes need increased computational resources in order to process higher-order tensors. We propose Factor Graph Neural Networks (FGNNs) to effectively capture higher-order relations for inference and learning. To do so, we first derive an efficient approximate Sum-Product loopy belief propagation inference algorithm for discrete higher-order PGMs. We then neuralize the novel message passing scheme into a Factor Graph Neural Network (FGNN) module by allowing richer representations of the message update rules; this facilitates both efficient inference and powerful end-to-end learning. We further show that with a suitable choice of message aggregation operators, our FGNN is also able to represent Max-Product belief propagation, providing a single family of architecture that can represent both Max and Sum-Product loopy belief propagation. Our extensive experimental evaluation on synthetic as well as real datasets demonstrates the potential of the proposed model.", "url": "https://arxiv.org/abs/2308.00887"}, {"metadata": {"arXiv": "2308.00890", "Date": "Wed, 02 Aug 2023 00:51:37 ", "Title": "Tango: rethinking quantization for graph neural network training on GPUs", "Authors": ["Shiyang Chen", "Da Zheng", "Caiwen Ding", "Chengying Huan", "Yuede Ji", "Hang Liu"], "Categories": "cs.LG"}, "abstract": "Graph Neural Networks (GNNs) are becoming increasingly popular due to their superior performance in critical graph-related tasks. While quantization is widely used to accelerate GNN computation, quantized training faces unprecedented challenges. Current quantized GNN training systems often have longer training times than their full-precision counterparts for two reasons: (i) addressing the accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quantization is not adequately leveraged. This paper introduces Tango which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations that can speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over state-of-the-art approaches on various GNN models and datasets.", "url": "https://arxiv.org/abs/2308.00890"}, {"metadata": {"arXiv": "2308.00928", "Date": "Wed, 02 Aug 2023 04:06:16 ", "Title": "QUANT: A Minimalist Interval Method for Time Series Classification", "Authors": ["Angus Dempster", "Daniel F. Schmidt", "Geoffrey I. Webb"], "Categories": "cs.LG", "Comments": ["26 pages", "20 figures"]}, "abstract": "We show that it is possible to achieve the same accuracy, on average, as the most accurate existing interval methods for time series classification on a standard set of benchmark datasets using a single type of feature (quantiles), fixed intervals, and an 'off the shelf' classifier. This distillation of interval-based approaches represents a fast and accurate method for time series classification, achieving state-of-the-art accuracy on the expanded set of 142 datasets in the UCR archive with a total compute time (training and inference) of less than 15 minutes using a single CPU core.", "url": "https://arxiv.org/abs/2308.00928"}, {"metadata": {"arXiv": "2308.00978", "Date": "Wed, 02 Aug 2023 07:20:37 ", "Title": "Certified Multi-Fidelity Zeroth-Order Optimization", "Authors": ["\\'Etienne de Montbrun (TSE-R)", "S\\'ebastien Gerchinovitz (IMT)"], "Categories": "cs.LG math.OC math.ST stat.ML stat.TH"}, "abstract": "We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \\emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.", "url": "https://arxiv.org/abs/2308.00978"}, {"metadata": {"arXiv": "2308.01028", "Date": "Wed, 02 Aug 2023 09:23:16 ", "Title": "Maximizing Success Rate of Payment Routing using Non-stationary Bandits", "Authors": ["Aayush Chaudhary", "Abhinav Rai", "Abhishek Gupta"], "Categories": "cs.LG cs.DC", "Comments": ["7 Pages", "6 Figures"]}, "abstract": "This paper discusses the system architecture design and deployment of non-stationary multi-armed bandit approaches to determine a near-optimal payment routing policy based on the recent history of transactions. We propose a Routing Service architecture using a novel Ray-based implementation for optimally scaling bandit-based payment routing to over 10000 transactions per second, adhering to the system design requirements and ecosystem constraints with Payment Card Industry Data Security Standard (PCI DSS). We first evaluate the effectiveness of multiple bandit-based payment routing algorithms on a custom simulator to benchmark multiple non-stationary bandit approaches and identify the best hyperparameters. We then conducted live experiments on the payment transaction system on a fantasy sports platform Dream11. In the live experiments, we demonstrated that our non-stationary bandit-based algorithm consistently improves the success rate of transactions by 0.92\\% compared to the traditional rule-based methods over one month.", "url": "https://arxiv.org/abs/2308.01028"}, {"metadata": {"arXiv": "2308.01039", "Date": "Wed, 02 Aug 2023 09:30:22 ", "Title": "Computing the Distance between unbalanced Distributions -- The flat Metric", "Authors": ["Henri Schmidt and Christian D\\\"ull"], "Categories": "cs.LG"}, "abstract": "We provide an implementation to compute the flat metric in any dimension. The flat metric, also called dual bounded Lipschitz distance, generalizes the well-known Wasserstein distance W1 to the case that the distributions are of unequal total mass. This is of particular interest for unbalanced optimal transport tasks and for the analysis of data distributions where the sample size is important or normalization is not possible. The core of the method is based on a neural network to determine on optimal test function realizing the distance between two given measures. Special focus was put on achieving comparability of pairwise computed distances from independently trained networks. We tested the quality of the output in several experiments where ground truth was available as well as with simulated data.", "url": "https://arxiv.org/abs/2308.01039"}, {"metadata": {"arXiv": "2308.01070", "Date": "Wed, 02 Aug 2023 10:37:25 ", "Title": "When Analytic Calculus Cracks AdaBoost Code", "Authors": ["Jean-Marc Brossier", "Olivier Lafitte", "Lenny R\\'ethor\\'e"], "Categories": "cs.LG", "Comments": ["8 pages", "1 figure"]}, "abstract": "The principle of boosting in supervised learning involves combining multiple weak classifiers to obtain a stronger classifier. AdaBoost has the reputation to be a perfect example of this approach. We have previously shown that AdaBoost is not truly an optimization algorithm. This paper shows that AdaBoost is an algorithm in name only, as the resulting combination of weak classifiers can be explicitly calculated using a truth table. This study is carried out by considering a problem with two classes and is illustrated by the particular case of three binary classifiers and presents results in comparison with those from the implementation of AdaBoost algorithm of the Python library scikit-learn.", "url": "https://arxiv.org/abs/2308.01070"}, {"metadata": {"arXiv": "2308.01071", "Date": "Wed, 02 Aug 2023 10:46:42 ", "Title": "Automatic Feature Engineering for Time Series Classification: Evaluation and Discussion", "Authors": ["Aur\\'elien Renault and Alexis Bondu and Vincent Lemaire and Dominique Gay"], "Categories": "cs.LG"}, "abstract": "Time Series Classification (TSC) has received much attention in the past two decades and is still a crucial and challenging problem in data science and knowledge engineering. Indeed, along with the increasing availability of time series data, many TSC algorithms have been suggested by the research community in the literature. Besides state-of-the-art methods based on similarity measures, intervals, shapelets, dictionaries, deep learning methods or hybrid ensemble methods, several tools for extracting unsupervised informative summary statistics, aka features, from time series have been designed in the recent years. Originally designed for descriptive analysis and visualization of time series with informative and interpretable features, very few of these feature engineering tools have been benchmarked for TSC problems and compared with state-of-the-art TSC algorithms in terms of predictive performance. In this article, we aim at filling this gap and propose a simple TSC process to evaluate the potential predictive performance of the feature sets obtained with existing feature engineering tools. Thus, we present an empirical study of 11 feature engineering tools branched with 9 supervised classifiers over 112 time series data sets. The analysis of the results of more than 10000 learning experiments indicate that feature-based methods perform as accurately as current state-of-the-art TSC algorithms, and thus should rightfully be considered further in the TSC literature.", "url": "https://arxiv.org/abs/2308.01071"}, {"metadata": {"arXiv": "2308.01084", "Date": "Wed, 02 Aug 2023 11:26:33 ", "Title": "Data-Driven Identification of Quadratic Symplectic Representations of Nonlinear Hamiltonian Systems", "Authors": ["S\\\"uleyman Yildiz", "Pawan Goyal", "Thomas Bendokat and Peter Benner"], "Categories": "cs.LG"}, "abstract": "We present a framework for learning Hamiltonian systems using data. This work is based on the lifting hypothesis, which posits that nonlinear Hamiltonian systems can be written as nonlinear systems with cubic Hamiltonians. By leveraging this, we obtain quadratic dynamics that are Hamiltonian in a transformed coordinate system. To that end, for given generalized position and momentum data, we propose a methodology to learn quadratic dynamical systems, enforcing the Hamiltonian structure in combination with a symplectic auto-encoder. The enforced Hamiltonian structure exhibits long-term stability of the system, while the cubic Hamiltonian function provides relatively low model complexity. For low-dimensional data, we determine a higher-order transformed coordinate system, whereas, for high-dimensional data, we find a lower-order coordinate system with the desired properties. We demonstrate the proposed methodology by means of both low-dimensional and high-dimensional nonlinear Hamiltonian systems.", "url": "https://arxiv.org/abs/2308.01084"}, {"metadata": {"arXiv": "2308.01139", "Date": "Wed, 02 Aug 2023 13:30:33 ", "Title": "Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives", "Authors": ["Jiaojiao Zhang", "Dominik Fay", "and Mikael Johansson"], "Categories": "cs.LG cs.CR cs.DC"}, "abstract": "This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server. The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint. This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations. Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.", "url": "https://arxiv.org/abs/2308.01139"}, {"metadata": {"arXiv": "2308.01140", "Date": "Wed, 02 Aug 2023 13:31:41 ", "Title": "DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning", "Authors": ["Siladittya Manna", "Soumitri Chattopadhyay", "Rakesh Dey", "Saumik Bhattacharya", "Umapada Pal"], "Categories": "cs.LG cs.CV"}, "abstract": "In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples. While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance. In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values. We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space. We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization. Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies. Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms. We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning.", "url": "https://arxiv.org/abs/2308.01140"}, {"metadata": {"arXiv": "2308.01170", "Date": "Wed, 02 Aug 2023 14:16:22 ", "Title": "Direct Gradient Temporal Difference Learning", "Authors": ["Xiaochi Qian", "Shangtong Zhang"], "Categories": "cs.LG", "Comments": ["Submitted to JMLR in Apr 2023"]}, "abstract": "Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL. It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning. This is the notorious deadly triad. Gradient Temporal Difference (GTD) is one powerful tool to solve the deadly triad. Its success results from solving a doubling sampling issue indirectly with weight duplication or Fenchel duality. In this paper, we instead propose a direct method to solve the double sampling issue by simply using two samples in a Markovian data stream with an increasing gap. The resulting algorithm is as computationally efficient as GTD but gets rid of GTD's extra weights. The only price we pay is a logarithmically increasing memory as time progresses. We provide both asymptotic and finite sample analysis, where the convergence rate is on-par with the canonical on-policy temporal difference learning. Key to our analysis is a novel refined discretization of limiting ODEs.", "url": "https://arxiv.org/abs/2308.01170"}, {"metadata": {"arXiv": "2308.01314", "Date": "Sat, 29 Jul 2023 19:17:49 ", "Title": "Evaluating the Robustness of Test Selection Methods for Deep Neural Networks", "Authors": ["Qiang Hu", "Yuejun Guo", "Xiaofei Xie", "Maxime Cordy", "Wei Ma", "Mike Papadakis and Yves Le Traon"], "Categories": "cs.LG cs.SE stat.ML", "Comments": ["12 pages"]}, "abstract": "Testing deep learning-based systems is crucial but challenging due to the required time and labor for labeling collected raw data. To alleviate the labeling effort, multiple test selection methods have been proposed where only a subset of test data needs to be labeled while satisfying testing requirements. However, we observe that such methods with reported promising results are only evaluated under simple scenarios, e.g., testing on original test data. This brings a question to us: are they always reliable? In this paper, we explore when and to what extent test selection methods fail for testing. Specifically, first, we identify potential pitfalls of 11 selection methods from top-tier venues based on their construction. Second, we conduct a study on five datasets with two model architectures per dataset to empirically confirm the existence of these pitfalls. Furthermore, we demonstrate how pitfalls can break the reliability of these methods. Concretely, methods for fault detection suffer from test data that are: 1) correctly classified but uncertain, or 2) misclassified but confident. Remarkably, the test relative coverage achieved by such methods drops by up to 86.85%. On the other hand, methods for performance estimation are sensitive to the choice of intermediate-layer output. The effectiveness of such methods can be even worse than random selection when using an inappropriate layer.", "url": "https://arxiv.org/abs/2308.01314"}, {"metadata": {"arXiv": "2308.00735", "Date": "Tue, 01 Aug 2023 17:34:30 ", "Title": "A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem", "Authors": ["Marcio Ferreira Moreno and Rafael Rossi de Mello Brand\\~ao"], "Categories": "cs.AI cs.DC cs.IR cs.NI"}, "abstract": "The Polkadot ecosystem is a disruptive and highly complex multi-chain architecture that poses challenges in terms of data analysis and communicability. Currently, there is a lack of standardized and holistic approaches to retrieve and analyze data across parachains and applications, making it difficult for general users and developers to access ecosystem data consistently. This paper proposes a conceptual framework that includes a domain ontology called POnto (a Polkadot Ontology) to address these challenges. POnto provides a structured representation of the ecosystem's concepts and relationships, enabling a formal understanding of the platform. The proposed knowledge-oriented approach enhances integration and communicability, enabling a wider range of users to participate in the ecosystem and facilitating the development of AI-based applications. The paper presents a case study methodology to validate the proposed framework, which includes expert feedback and insights from the Polkadot community. The POnto ontology and the roadmap for a query engine based on a Controlled Natural Language using the ontology, provide valuable contributions to the growth and adoption of the Polkadot ecosystem in heterogeneous socio-technical environments.", "url": "https://arxiv.org/abs/2308.00735"}, {"metadata": {"arXiv": "2308.00868", "Date": "Tue, 01 Aug 2023 22:38:14 ", "Title": "Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems", "Authors": ["Alex John London and Hoda heidari"], "Categories": "cs.AI cs.CY"}, "abstract": "The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum's capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders' ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains underscores the gravity of these issues and the imperative to take an ethics-led approach to AI systems from their inception.", "url": "https://arxiv.org/abs/2308.00868"}, {"metadata": {"arXiv": "2308.01094", "Date": "Wed, 02 Aug 2023 11:58:30 ", "Title": "Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case", "Authors": ["Baifan Zhou", "Nikolay Nikolov", "Zhuoxun Zheng", "Xianghui Luo", "Ognjen Savkovic", "Dumitru Roman", "Ahmet Soylu", "Evgeny Kharlamov"], "Categories": "cs.AI cs.DC", "Comments": ["Paper accepted at ISWC2023 In-Use track"]}, "abstract": "Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedented amount of data from factory production, posing big data challenges in volume and variety. In that context, distributed computing solutions such as cloud systems are leveraged to parallelise the data processing and reduce computation time. As the cloud systems become increasingly popular, there is increased demand that more users that were originally not cloud experts (such as data scientists, domain experts) deploy their solutions on the cloud systems. However, it is non-trivial to address both the high demand for cloud system users and the excessive time required to train them. To this end, we propose SemCloud, a semantics-enhanced cloud system, that couples cloud system with semantic technologies and machine learning. SemCloud relies on domain ontologies and mappings for data integration, and parallelises the semantic data integration and data analysis on distributed computing nodes. Furthermore, SemCloud adopts adaptive Datalog rules and machine learning for automated resource configuration, allowing non-cloud experts to use the cloud system. The system has been evaluated in industrial use case with millions of data, thousands of repeated runs, and domain users, showing promising results.", "url": "https://arxiv.org/abs/2308.01094"}, {"metadata": {"arXiv": "2308.01105", "Date": "Wed, 02 Aug 2023 12:22:35 ", "Title": "Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case", "Authors": ["Zhipeng Tan", "Baifan Zhou", "Zhuoxun Zheng", "Ognjen Savkovic", "Ziqi Huang", "Irlan-Grangel Gonzalez", "Ahmet Soylu", "Evgeny Kharlamov"], "Categories": "cs.AI", "Comments": ["Paper accepted at ISWC2023 In-Use track"]}, "abstract": "Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML). However, there has been limited research that applies KGE for industrial problems in manufacturing. This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually. The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste. The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to. The problem setting is difficult for traditional ML because there exist a high number of car bodies that should be assigned as class labels. We formulate the problem as link prediction, and experimented popular KGE methods on real industry data, with consideration of literals. Our results reveal both limitations and promising aspects of adapted KGE methods.", "url": "https://arxiv.org/abs/2308.01105"}, {"metadata": {"arXiv": "2308.01154", "Date": "Wed, 02 Aug 2023 13:58:37 ", "Title": "Arithmetic with Language Models: from Memorization to Computation", "Authors": ["Davide Maltoni and Matteo Ferrara"], "Categories": "cs.AI cs.CL"}, "abstract": "A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.", "url": "https://arxiv.org/abs/2308.01154"}, {"metadata": {"arXiv": "2308.01264", "Date": "Wed, 02 Aug 2023 16:36:58 ", "Title": "Exploring the psychology of GPT-4's Moral and Legal Reasoning", "Authors": ["Guilherme F. C. F. Almeida", "Jos\\'e Luiz Nunes", "Neele Engelmann", "Alex Wiegmann", "Marcelo de Ara\\'ujo"], "Categories": "cs.AI cs.CL"}, "abstract": "Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI responses, but also several significant systematic differences between them. We conclude with a discussion of the philosophical implications of our findings.", "url": "https://arxiv.org/abs/2308.01264"}, {"metadata": {"arXiv": "2308.01285", "Date": "Wed, 02 Aug 2023 17:14:22 ", "Title": "Flows: Building Blocks of Reasoning and Collaborating AI", "Authors": ["Martin Josifoski", "Lars Klein", "Maxime Peyrard", "Yifei Li", "Saibo Geng", "Julian Paul Schnitzler", "Yuxing Yao", "Jiheng Wei", "Debjit Paul", "Robert West"], "Categories": "cs.AI cs.HC"}, "abstract": "Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles. Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate. To support rapid and rigorous research, we introduce the aiFlows library. The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows. The aiFlows library is available at https://github.com/epfl-dlab/aiflows. Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.", "url": "https://arxiv.org/abs/2308.01285"}, {"metadata": {"arXiv": "2308.00801", "Date": "Fri, 07 Jul 2023 10:00:50 ", "Title": "Artificial Eye for the Blind", "Authors": ["Abhinav Benagi", "Dhanyatha Narayan", "Charith Rage", "A Sushmitha"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["23 pages ", "16 figures"]}, "abstract": "The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection model to detect the objects in fronrson by converting the texts to speech by using the gTTS module. Along with the above mentioned process going on there will be an active MYCROFT voice assistant model which can be used to interact with the blind person. The blind person can ask about the weather , daily news , any information on the internet ,etc", "url": "https://arxiv.org/abs/2308.00801"}, {"metadata": {"arXiv": "2308.00854", "Date": "Tue, 01 Aug 2023 21:40:30 ", "Title": "Training on Foveated Images Improves Robustness to Adversarial Attacks", "Authors": ["Muhammad A. Shah and Bhiksha Raj"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \\RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\% higher accuracy on perturbed data.", "url": "https://arxiv.org/abs/2308.00854"}, {"metadata": {"arXiv": "2308.01006", "Date": "Wed, 02 Aug 2023 08:29:44 ", "Title": "FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving", "Authors": ["Tengju Ye", "Wei Jing", "Chunyong Hu", "Shikun Huang", "Lingping Gao", "Fangzhen Li", "Jingke Wang", "Ke Guo", "Wencong Xiao", "Weibo Mao", "Hang Zheng", "Kun Li", "Junbo Chen", "Kaicheng Yu"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "Building a multi-modality multi-task neural network toward accurate and robust performance is a de-facto standard in perception task of autonomous driving. However, leveraging such data from multiple sensors to jointly optimize the prediction and planning tasks remains largely unexplored. In this paper, we present FusionAD, to the best of our knowledge, the first unified framework that fuse the information from two most critical sensors, camera and LiDAR, goes beyond perception task. Concretely, we first build a transformer based multi-modality fusion network to effectively produce fusion based features. In constrast to camera-based end-to-end method UniAD, we then establish a fusion aided modality-aware prediction and status-aware planning modules, dubbed FMSPnP that take advantages of multi-modality features. We conduct extensive experiments on commonly used benchmark nuScenes dataset, our FusionAD achieves state-of-the-art performance and surpassing baselines on average 15% on perception tasks like detection and tracking, 10% on occupancy prediction accuracy, reducing prediction error from 0.708 to 0.389 in ADE score and reduces the collision rate from 0.31% to only 0.12%.", "url": "https://arxiv.org/abs/2308.01006"}, {"metadata": {"arXiv": "2308.01088", "Date": "Wed, 02 Aug 2023 11:44:49 ", "Title": "Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks", "Authors": ["Gianluca Amprimo", "Giulia Masi", "Giuseppe Pettiti", "Gabriella Olmo", "Lorenzo Priano and Claudia Ferraris"], "Categories": "cs.CV cs.AI"}, "abstract": "Accurate 3D tracking of hand and fingers movements poses significant challenges in computer vision. The potential applications span across multiple domains, including human-computer interaction, virtual reality, industry, and medicine. While gesture recognition has achieved remarkable accuracy, quantifying fine movements remains a hurdle, particularly in clinical applications where the assessment of hand dysfunctions and rehabilitation training outcomes necessitate precise measurements. Several novel and lightweight frameworks based on Deep Learning have emerged to address this issue; however, their performance in accurately and reliably measuring fingers movements requires validation against well-established gold standard systems. In this paper, the aim is to validate the handtracking framework implemented by Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D, that exploits the depth estimation of an RGB-Depth camera to achieve more accurate tracking of 3D movements. Three dynamic exercises commonly administered by clinicians to assess hand dysfunctions, namely Hand Opening-Closing, Single Finger Tapping and Multiple Finger Tapping are considered. Results demonstrate high temporal and spectral consistency of both frameworks with the gold standard. However, the enhanced GMH-D framework exhibits superior accuracy in spatial measurements compared to the baseline GMH, for both slow and fast movements. Overall, our study contributes to the advancement of hand tracking technology, the establishment of a validation procedure as a good-practice to prove efficacy of deep-learning-based hand-tracking, and proves the effectiveness of GMH-D as a reliable framework for assessing 3D hand movements in clinical applications.", "url": "https://arxiv.org/abs/2308.01088"}, {"metadata": {"arXiv": "2308.01189", "Date": "Wed, 02 Aug 2023 14:53:43 ", "Title": "Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation", "Authors": ["Yongkang He", "Mingjin Chen", "Zhijing Yang", "Yongyi Lu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted by ICML workshops 2023"]}, "abstract": "This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy. We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples. To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score. To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems. Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sources.", "url": "https://arxiv.org/abs/2308.01189"}, {"metadata": {"arXiv": "2308.00937", "Date": "Wed, 02 Aug 2023 04:37:07 ", "Title": "LEMMA: Learning Language-Conditioned Multi-Robot Manipulation", "Authors": ["Ran Gong", "Xiaofeng Gao", "Qiaozi Gao", "Suhaila Shakiah", "Govind Thattai", "Gaurav S. Sukhatme"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["8 pages", "3 figures"]}, "abstract": "Complex manipulation tasks often require robots with complementary capabilities to collaborate. We introduce a benchmark for LanguagE-Conditioned Multi-robot MAnipulation (LEMMA) focused on task allocation and long-horizon object manipulation based on human language instructions in a tabletop setting. LEMMA features 8 types of procedurally generated tasks with varying degree of complexity, some of which require the robots to use tools and pass tools to each other. For each task, we provide 800 expert demonstrations and human instructions for training and evaluations. LEMMA poses greater challenges compared to existing benchmarks, as it requires the system to identify each manipulator's limitations and assign sub-tasks accordingly while also handling strong temporal dependencies in each task. To address these challenges, we propose a modular hierarchical planning approach as a baseline. Our results highlight the potential of LEMMA for developing future language-conditioned multi-robot systems.", "url": "https://arxiv.org/abs/2308.00937"}, {"metadata": {"arXiv": "2308.01085", "Date": "Wed, 02 Aug 2023 11:27:41 ", "Title": "Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making", "Authors": ["Stanislav Kikot"], "Categories": "cs.RO cs.AI"}, "abstract": "In this paper we show how rule-based decision making can be combined with traditional motion planning techniques to achieve human-like behavior of a self-driving vehicle in complex traffic situations. We give and discuss examples of decision rules in autonomous driving. We draw on these examples to illustrate that developing techniques for spatial awareness of robots is an exciting activity which deserves more attention from spatial reasoning community that it had received so far.", "url": "https://arxiv.org/abs/2308.01085"}, {"metadata": {"arXiv": "2308.01313", "Date": "Wed, 02 Aug 2023 17:57:25 ", "Title": "More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes", "Authors": ["Bang An", "Sicheng Zhu", "Michael-Andrei Panaitescu-Liess", "Chaithanya Kumar Mummadi", "Furong Huang"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.", "url": "https://arxiv.org/abs/2308.01313"}, {"metadata": {"arXiv": "2308.00707", "Date": "Thu, 27 Jul 2023 15:19:45 ", "Title": "Approximate Model-Based Shielding for Safe Reinforcement Learning", "Authors": ["Alexander W. Goodall", "Francesco Belardinelli"], "Categories": "cs.LG cs.AI cs.SY eess.SY", "Comments": ["Accepted at ECAI 2023 (main technical track)"]}, "abstract": "Reinforcement learning (RL) has shown great potential for solving complex tasks in a variety of domains. However, applying RL to safety-critical systems in the real-world is not easy as many algorithms are sample-inefficient and maximising the standard RL objective comes with no guarantees on worst-case performance. In this paper we propose approximate model-based shielding (AMBS), a principled look-ahead shielding algorithm for verifying the performance of learned RL policies w.r.t. a set of given safety constraints. Our algorithm differs from other shielding approaches in that it does not require prior knowledge of the safety-relevant dynamics of the system. We provide a strong theoretical justification for AMBS and demonstrate superior performance to other safety-aware approaches on a set of Atari games with state-dependent safety-labels.", "url": "https://arxiv.org/abs/2308.00707"}, {"metadata": {"arXiv": "2308.00710", "Date": "Sat, 29 Jul 2023 11:13:11 ", "Title": "Towards the Visualization of Aggregated Class Activation Maps to Analyse the Global Contribution of Class Features", "Authors": ["Igor Cherepanov", "David Sessler", "Alex Ulmer", "Hendrik L\\\"ucke-Tieke", "J\\\"orn Kohlhammer"], "Categories": "cs.LG cs.AI cs.HC", "Comments": ["submitted to xaiworldconference2023"]}, "abstract": "Deep learning (DL) models achieve remarkable performance in classification tasks. However, models with high complexity can not be used in many risk-sensitive applications unless a comprehensible explanation is presented. Explainable artificial intelligence (xAI) focuses on the research to explain the decision-making of AI systems like DL. We extend a recent method of Class Activation Maps (CAMs) which visualizes the importance of each feature of a data sample contributing to the classification. In this paper, we aggregate CAMs from multiple samples to show a global explanation of the classification for semantically structured data. The aggregation allows the analyst to make sophisticated assumptions and analyze them with further drill-down visualizations. Our visual representation for the global CAM illustrates the impact of each feature with a square glyph containing two indicators. The color of the square indicates the classification impact of this feature. The size of the filled square describes the variability of the impact between single samples. For interesting features that require further analysis, a detailed view is necessary that provides the distribution of these values. We propose an interactive histogram to filter samples and refine the CAM to show relevant samples only. Our approach allows an analyst to detect important features of high-dimensional data and derive adjustments to the AI model based on our global explanation visualization.", "url": "https://arxiv.org/abs/2308.00710"}, {"metadata": {"arXiv": "2308.00721", "Date": "Mon, 31 Jul 2023 03:56:46 ", "Title": "A Pre-trained Data Deduplication Model based on Active Learning", "Authors": ["Xinyao Liu", "Shengdong Du", "Fengmao Lv", "Hongtao Xue", "Jie Hu", "and Tianrui Li"], "Categories": "cs.LG cs.AI"}, "abstract": "In the era of big data, the issue of data quality has become increasingly prominent. One of the main challenges is the problem of duplicate data, which can arise from repeated entry or the merging of multiple data sources. These \"dirty data\" problems can significantly limit the effective application of big data. To address the issue of data deduplication, we propose a pre-trained deduplication model based on active learning, which is the first work that utilizes active learning to address the problem of deduplication at the semantic level. The model is built on a pre-trained Transformer and fine-tuned to solve the deduplication problem as a sequence to classification task, which firstly integrate the transformer with active learning into an end-to-end architecture to select the most valuable data for deduplication model training, and also firstly employ the R-Drop method to perform data augmentation on each round of labeled data, which can reduce the cost of manual labeling and improve the model's performance. Experimental results demonstrate that our proposed model outperforms previous state-of-the-art (SOTA) for deduplicated data identification, achieving up to a 28% improvement in Recall score on benchmark datasets.", "url": "https://arxiv.org/abs/2308.00721"}, {"metadata": {"arXiv": "2308.00858", "Date": "Tue, 01 Aug 2023 22:12:30 ", "Title": "Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes", "Authors": ["Stephan Johann Lehmler and Muhammad Saif-ur-Rehman and Tobias Glasmachers and Ioannis Iossifidis"], "Categories": "cs.LG cs.AI cs.CC", "ACM-class": "F.2.0; F.2.3; I.2.6"}, "abstract": "To gain a deeper understanding of the behavior and learning dynamics of (deep) artificial neural networks, it is valuable to employ mathematical abstractions and models. These tools provide a simplified perspective on network performance and facilitate systematic investigations through simulations. In this paper, we propose utilizing the framework of stochastic processes, which has been underutilized thus far. Our approach models activation patterns of thresholded nodes in (deep) artificial neural networks as stochastic processes. We focus solely on activation frequency, leveraging neuroscience techniques used for real neuron spike trains. During a classification task, we extract spiking activity and use an arrival process following the Poisson distribution. We examine observed data from various artificial neural networks in image recognition tasks, fitting the proposed model's assumptions. Through this, we derive parameters describing activation patterns in each network. Our analysis covers randomly initialized, generalizing, and memorizing networks, revealing consistent differences across architectures and training sets. Calculating Mean Firing Rate, Mean Fano Factor, and Variances, we find stable indicators of memorization during learning, providing valuable insights into network behavior. The proposed model shows promise in describing activation patterns and could serve as a general framework for future investigations. It has potential applications in theoretical simulations, pruning, and transfer learning.", "url": "https://arxiv.org/abs/2308.00858"}, {"metadata": {"arXiv": "2308.00864", "Date": "Tue, 01 Aug 2023 22:25:40 ", "Title": "PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems", "Authors": ["Aamir Hasan", "Neeloy Chakraborty", "Haonan Chen", "Jung-Hoon Cho", "Cathy Wu", "Katherine Driggs-Campbell"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted to ITSC 2023. Additional material and code is available at the project webpage: https://sites.google.com/illinois.edu/perp"]}, "abstract": "Intelligent driving systems can be used to mitigate congestion through simple actions, thus improving many socioeconomic factors such as commute time and gas costs. However, these systems assume precise control over autonomous vehicle fleets, and are hence limited in practice as they fail to account for uncertainty in human behavior. Piecewise Constant (PC) Policies address these issues by structurally modeling the likeness of human driving to reduce traffic congestion in dense scenarios to provide action advice to be followed by human drivers. However, PC policies assume that all drivers behave similarly. To this end, we develop a co-operative advisory system based on PC policies with a novel driver trait conditioned Personalized Residual Policy, PeRP. PeRP advises drivers to behave in ways that mitigate traffic congestion. We first infer the driver's intrinsic traits on how they follow instructions in an unsupervised manner with a variational autoencoder. Then, a policy conditioned on the inferred trait adapts the action of the PC policy to provide the driver with a personalized recommendation. Our system is trained in simulation with novel driver modeling of instruction adherence. We show that our approach successfully mitigates congestion while adapting to different driver behaviors, with 4 to 22% improvement in average speed over baselines.", "url": "https://arxiv.org/abs/2308.00864"}, {"metadata": {"arXiv": "2308.00886", "Date": "Wed, 02 Aug 2023 00:28:22 ", "Title": "Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction", "Authors": ["Boluwatife E. Faremi", "Jonathon Stavres", "Nuno Oliveira", "Zhaoxian Zhou and Andrew H. Sung"], "Categories": "cs.LG cs.AI cs.SE eess.SP", "Comments": ["18 pages", "2-page Appendix", "7 figures"], "ACM-class": "B.7; D.2.5; D.2.9; H.2.8; H.2.1; I.2; J.2; J.6; K.6.3"}, "abstract": "Machine learning (ML) models trained on subjective self-report scores struggle to objectively classify pain accurately due to the significant variance between real-time pain experiences and recorded scores afterwards. This study developed two devices for acquisition of real-time, continuous in-session pain scores and gathering of ANS-modulated endodermal activity (EDA).The experiment recruited N = 24 subjects who underwent a post-exercise circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data were stored in a custom pain platform, facilitating extraction of time-domain EDA features and in-session ground truth scores. Moreover, post-experiment visual analog scale (VAS) scores were collected from each subject. Machine learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF), were trained using corresponding objective EDA features combined with in-session scores and post-session scores, respectively. Over a 10-fold cross-validation, the macro-averaged geometric mean score revealed MLP and RF models trained with objective EDA features and in-session scores achieved superior performance (75.9% and 78.3%) compared to models trained with post-session scores (70.3% and 74.6%) respectively. This pioneering study demonstrates that using continuous in-session ground truth scores significantly enhances ML performance in pain intensity characterization, overcoming ground truth sparsity-related issues, data imbalance, and high variance. This study informs future objective-based ML pain system training.", "url": "https://arxiv.org/abs/2308.00886"}, {"metadata": {"arXiv": "2308.00904", "Date": "Wed, 02 Aug 2023 01:44:30 ", "Title": "VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference", "Authors": ["Yonghe Zhao", "Qiang Huang", "Siwei Wu", "Yun Peng", "Huiyan Sun"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["15 pages", "8 figures"]}, "abstract": "Causal inference plays a vital role in diverse domains like epidemiology, healthcare, and economics. De-confounding and counterfactual prediction in observational data has emerged as a prominent concern in causal inference research. While existing models tackle observed confounders, the presence of unobserved confounders remains a significant challenge, distorting causal inference and impacting counterfactual outcome accuracy. To address this, we propose a novel variational learning model of unobserved confounders for counterfactual inference (VLUCI), which generates the posterior distribution of unobserved confounders. VLUCI relaxes the unconfoundedness assumption often overlooked by most causal inference methods. By disentangling observed and unobserved confounders, VLUCI constructs a doubly variational inference model to approximate the distribution of unobserved confounders, which are used for inferring more accurate counterfactual outcomes. Extensive experiments on synthetic and semi-synthetic datasets demonstrate VLUCI's superior performance in inferring unobserved confounders. It is compatible with state-of-the-art counterfactual inference models, significantly improving inference accuracy at both group and individual levels. Additionally, VLUCI provides confidence intervals for counterfactual outcomes, aiding decision-making in risk-sensitive domains. We further clarify the considerations when applying VLUCI to cases where unobserved confounders don't strictly conform to our model assumptions using the public IHDP dataset as an example, highlighting the practical advantages of VLUCI.", "url": "https://arxiv.org/abs/2308.00904"}, {"metadata": {"arXiv": "2308.00951", "Date": "Wed, 02 Aug 2023 05:20:55 ", "Title": "From Sparse to Soft Mixtures of Experts", "Authors": ["Joan Puigcerver", "Carlos Riquelme", "Basil Mustafa", "Neil Houlsby"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Sparse mixture of expert architectures (MoEs) scale model capacity without large increases in training or inference costs. Despite their success, MoEs suffer from a number of issues: training instability, token dropping, inability to scale the number of experts, or ineffective finetuning. In this work, we proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these challenges, while maintaining the benefits of MoEs. Soft MoE performs an implicit soft assignment by passing different weighted combinations of all input tokens to each expert. As in other MoE works, experts in Soft MoE only process a subset of the (combined) tokens, enabling larger model capacity at lower inference cost. In the context of visual recognition, Soft MoE greatly outperforms standard Transformers (ViTs) and popular MoE variants (Tokens Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its performance after similar training. Soft MoE also scales well: Soft MoE Huge/14 with 128 experts in 16 MoE layers has over 40x more parameters than ViT Huge/14, while inference time cost grows by only 2%, and it performs substantially better.", "url": "https://arxiv.org/abs/2308.00951"}, {"metadata": {"arXiv": "2308.00989", "Date": "Wed, 02 Aug 2023 07:45:24 ", "Title": "Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning", "Authors": ["Haorui Li", "Jiaqi Liang", "Linjing Li", "and Daniel Zeng"], "Categories": "cs.LG cs.AI"}, "abstract": "Hierarchical reinforcement learning composites subpolicies in different hierarchies to accomplish complex tasks.Automated subpolicies discovery, which does not depend on domain knowledge, is a promising approach to generating subpolicies.However, the degradation problem is a challenge that existing methods can hardly deal with due to the lack of consideration of diversity or the employment of weak regularizers. In this paper, we propose a novel task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer (WDER), which enlarges the diversity of subpolicies by maximizing the Wasserstein distances among action distributions. The proposed WDER can be easily incorporated into the loss function of existing methods to boost their performance further.Experimental results demonstrate that our WDER improves performance and sample efficiency in comparison with prior work without modifying hyperparameters, which indicates the applicability and robustness of the WDER.", "url": "https://arxiv.org/abs/2308.00989"}, {"metadata": {"arXiv": "2308.01011", "Date": "Wed, 02 Aug 2023 08:37:45 ", "Title": "Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach", "Authors": ["Chunwei Yang", "Xiaoxu Chen", "Lijun Sun", "Hongyu Yang", "Yuankai Wu"], "Categories": "cs.LG cs.AI", "Comments": ["12 pages"]}, "abstract": "Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, forecasting, and anomaly detection tasks to demonstrate the effectiveness of Floss. We incorporate Floss into several representative deep learning solutions to justify our design choices and demonstrate that it is capable of automatically discovering periodic dynamics and improving state-of-the-art deep learning models.", "url": "https://arxiv.org/abs/2308.01011"}, {"metadata": {"arXiv": "2308.01030", "Date": "Wed, 02 Aug 2023 09:27:11 ", "Title": "Three Factors to Improve Out-of-Distribution Detection", "Authors": ["Hyunjun Choi", "JaeHo Chung", "Hawook Jeong", "Jin Young Choi"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Under review"]}, "abstract": "In the problem of out-of-distribution (OOD) detection, the usage of auxiliary data as outlier data for fine-tuning has demonstrated encouraging performance. However, previous methods have suffered from a trade-off between classification accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve this trade-off, we make three contributions: (i) Incorporating a self-knowledge distillation loss can enhance the accuracy of the network; (ii) Sampling semi-hard outlier data for training can improve OOD detection performance with minimal impact on accuracy; (iii) The introduction of our novel supervised contrastive learning can simultaneously improve OOD detection performance and the accuracy of the network. By incorporating all three factors, our approach enhances both accuracy and OOD detection performance by addressing the trade-off between classification and OOD detection. Our method achieves improvements over previous approaches in both performance metrics.", "url": "https://arxiv.org/abs/2308.01030"}, {"metadata": {"arXiv": "2308.01063", "Date": "Wed, 02 Aug 2023 10:22:04 ", "Title": "Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach", "Authors": ["Xing Ai", "Jialong Zhou", "Yulin Zhu", "Gaolei Li", "Tomasz P. Michalak", "Xiapu Luo", "Kai Zhou"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph anomaly detection (GAD) has achieved success and has been widely applied in various domains, such as fraud detection, cybersecurity, finance security, and biochemistry. However, existing graph anomaly detection algorithms focus on distinguishing individual entities (nodes or graphs) and overlook the possibility of anomalous groups within the graph. To address this limitation, this paper introduces a novel unsupervised framework for a new task called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups by capturing long-range inconsistencies. Subsequently, group sampling is employed to sample candidate groups, which are then fed into the proposed Topology Pattern-based Graph Contrastive Learning (TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to generate embeddings for each candidate group and thus distinct anomaly groups. The experimental results on both real-world and synthetic datasets demonstrate that the proposed framework shows superior performance in identifying and localizing anomaly groups, highlighting it as a promising solution for Gr-GAD. Datasets and codes of the proposed framework are at the github repository https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.", "url": "https://arxiv.org/abs/2308.01063"}, {"metadata": {"arXiv": "2308.01138", "Date": "Wed, 02 Aug 2023 13:29:31 ", "Title": "Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases", "Authors": ["Haiwen Du", "Zheng Ju", "Yu An", "Honghui Du", "Dongjie Zhu", "Zhaoshuo Tian", "Aonghus Lawlor", "Ruihai Dong"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models. From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases. The source code is made publicly available online at https://github.com/Magnomic/CNST.", "url": "https://arxiv.org/abs/2308.01138"}, {"metadata": {"arXiv": "2308.01220", "Date": "Wed, 02 Aug 2023 15:26:08 ", "Title": "Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case", "Authors": ["Rebekka G\\\"orge", "Elena Haedecke", "Michael Mock"], "Categories": "cs.LG cs.AI cs.CY cs.HC", "Comments": ["Accepted at AAAI Spring Symposium 2023 AITA: AI Trustworthiness Assessment"]}, "abstract": "Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets. Model performance depends on labeling quality to a large extent. In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly. Often, data sets are labeled by collecting opinions of groups of experts. We use our VA tool to analyse the influence of label variations between different experts on the model performance. ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses. We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.", "url": "https://arxiv.org/abs/2308.01220"}, {"metadata": {"arXiv": "2308.01222", "Date": "Wed, 02 Aug 2023 15:28:10 ", "Title": "Calibration in Deep Learning: A Survey of the State-of-the-Art", "Authors": ["Cheng Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent methods proposed to calibrate deep models by using different mechanisms. In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also covered some recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.", "url": "https://arxiv.org/abs/2308.01222"}, {"metadata": {"arXiv": "2308.01271", "Date": "Wed, 02 Aug 2023 16:52:56 ", "Title": "A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC", "Authors": ["Masoumeh Javanbakhat", "Christoph Lippert"], "Categories": "cs.LG cs.AI"}, "abstract": "In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.", "url": "https://arxiv.org/abs/2308.01271"}, {"metadata": {"arXiv": "2308.01312", "Date": "Wed, 02 Aug 2023 17:56:29 ", "Title": "Lode Encoder: AI-constrained co-creativity", "Authors": ["Debosmita Bhaumik", "Ahmed Khalifa", "Julian Togelius"], "Categories": "cs.LG cs.AI", "Journal-ref": "2021 IEEE Conference on Games (CoG), Copenhagen, Denmark, 2021, pp. 01-08", "DOI": "10.1109/CoG52621.2021.9619009"}, "abstract": "We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.", "url": "https://arxiv.org/abs/2308.01312"}, {"metadata": {"arXiv": "2308.01050", "Date": "Wed, 02 Aug 2023 09:48:08 ", "Title": "A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness", "Authors": ["Alessandro Zanardi", "Andrea Censi", "Margherita Atzei", "Luigi Di Lillo", "Emilio Frazzoli"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "Autonomous Vehicles (AVs) have the potential to provide numerous societal benefits, such as decreased road accidents and increased overall transportation efficiency. However, quantifying the risk associated with AVs is challenging due to the lack of historical data and the rapidly evolving technology. This paper presents a data-driven framework for comparing the risk of different AVs' behaviors in various operational design domains (ODDs), based on counterfactual simulations of \"misbehaving\" road users. We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to find the most critical scenarios but also to assess the frequency and severity of risk of AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown -- through worst- and best-case analyses -- making the method useful also to external third-party risk assessors. Our experimental results demonstrate the correlation between the safety margin, the driving policy quality, and the ODD shedding light on the relative risk associated with different AV providers. This work contributes to AV safety assessment and aids in addressing legislative and insurance concerns surrounding this emerging technology.", "url": "https://arxiv.org/abs/2308.01050"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.03350", "Date": "Mon, 04 Sep 2023 15:00:33 ", "Title": "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis", "Authors": ["Jiayan Teng", "Wendi Zheng", "Ming Ding", "Wenyi Hong", "Jianqiao Wangni", "Zhuoyi Yang", "Jie Tang"], "Categories": "cs.CV cs.LG"}, "abstract": "Diffusion models achieved great success in image synthesis, but still face challenges in high-resolution generation. Through the lens of discrete cosine transformation, we find the main reason is that \\emph{the same noise level on a higher resolution results in a higher Signal-to-Noise Ratio in the frequency domain}. In this work, we present Relay Diffusion Model (RDM), which transfers a low-resolution image or noise into an equivalent high-resolution one for diffusion model via blurring diffusion and block noise. Therefore, the diffusion process can continue seamlessly in any new resolution or model without restarting from pure noise or low-resolution conditioning. RDM achieves state-of-the-art FID on CelebA-HQ and sFID on ImageNet 256$\\times$256, surpassing previous works such as ADM, LDM and DiT by a large margin. All the codes and checkpoints are open-sourced at \\url{https://github.com/THUDM/RelayDiffusion}.", "url": "https://arxiv.org/abs/2309.03350"}, {"metadata": {"arXiv": "2309.03351", "Date": "Wed, 06 Sep 2023 20:24:13 ", "Title": "Using Neural Networks for Fast SAR Roughness Estimation of High Resolution Images", "Authors": ["Li Fan", "Jeova Farias Sales Rocha Neto"], "Categories": "cs.CV cs.LG eess.IV stat.AP"}, "abstract": "The analysis of Synthetic Aperture Radar (SAR) imagery is an important step in remote sensing applications, and it is a challenging problem due to its inherent speckle noise. One typical solution is to model the data using the $G_I^0$ distribution and extract its roughness information, which in turn can be used in posterior imaging tasks, such as segmentation, classification and interpretation. This leads to the need of quick and reliable estimation of the roughness parameter from SAR data, especially with high resolution images. Unfortunately, traditional parameter estimation procedures are slow and prone to estimation failures. In this work, we proposed a neural network-based estimation framework that first learns how to predict underlying parameters of $G_I^0$ samples and then can be used to estimate the roughness of unseen data. We show that this approach leads to an estimator that is quicker, yields less estimation error and is less prone to failures than the traditional estimation procedures for this problem, even when we use a simple network. More importantly, we show that this same methodology can be generalized to handle image inputs and, even if trained on purely synthetic data for a few seconds, is able to perform real time pixel-wise roughness estimation for high resolution real SAR imagery.", "url": "https://arxiv.org/abs/2309.03351"}, {"metadata": {"arXiv": "2309.03353", "Date": "Wed, 06 Sep 2023 20:36:17 ", "Title": "Source Camera Identification and Detection in Digital Videos through Blind Forensics", "Authors": ["Venkata Udaya Sameer", "Shilpa Mukhopadhyay", "Ruchira Naskar and Ishaan Dali"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["Submitted to IEEE for inclusion in Xplore- Digital Library. Paper presented at the International Conference on Recent Trends in Computational Engineering & Technologies (ICRTCET 18)with Paper Id: ICRTCET-227"]}, "abstract": "Source camera identification in digital videos is the problem of associating an unknown digital video with its source device, within a closed set of possible devices. The existing techniques in source detection of digital videos try to find a fingerprint of the actual source in the video in form of PRNU (Photo Response Non--Uniformity), and match it against the SPN (Sensor Pattern Noise) of each possible device. The highest correlation indicates the correct source. We investigate the problem of identifying a video source through a feature based approach using machine learning. In this paper, we present a blind forensic technique of video source authentication and identification, based on feature extraction, feature selection and subsequent source classification. The main aim is to determine whether a claimed source for a video is actually its original source. If not, we identify its original source. Our experimental results prove the efficiency of the proposed method compared to traditional fingerprint based technique.", "url": "https://arxiv.org/abs/2309.03353"}, {"metadata": {"arXiv": "2309.03360", "Date": "Wed, 06 Sep 2023 21:04:53 ", "Title": "ViewMix: Augmentation for Robust Representation in Self-Supervised Learning", "Authors": ["Arjon Das", "Xin Zhong"], "Categories": "cs.CV cs.LG"}, "abstract": "Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learning, upon generating different views of the same image, patches are cut and pasted from one view to another. By leveraging the different views created by this augmentation strategy, multiple joint embedding-based self-supervised methodologies obtained better localization capability and consistently outperformed their corresponding baseline methods. It is also demonstrated that incorporating ViewMix augmentation policy promotes robustness of the representations in the state-of-the-art methods. Furthermore, our experimentation and analysis of compute times suggest that ViewMix augmentation doesn't introduce any additional overhead compared to other counterparts.", "url": "https://arxiv.org/abs/2309.03360"}, {"metadata": {"arXiv": "2309.03452", "Date": "Thu, 07 Sep 2023 02:26:55 ", "Title": "Multi-Modality Guidance Network For Missing Modality Inference", "Authors": ["Zhuokai Zhao", "Harish Palani", "Tianyi Liu", "Lena Evans and Ruth Toner"], "Categories": "cs.CV cs.LG"}, "abstract": "Multimodal models have gained significant success in recent years. Standard multimodal approaches often assume unchanged modalities from training stage to inference stage. In practice, however, many scenarios fail to satisfy such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference cost.", "url": "https://arxiv.org/abs/2309.03452"}, {"metadata": {"arXiv": "2309.03530", "Date": "Thu, 07 Sep 2023 07:23:55 ", "Title": "Efficient Single Object Detection on Image Patches with Early Exit Enhanced High-Precision CNNs", "Authors": ["Arne Moos"], "Categories": "cs.CV cs.LG cs.RO"}, "abstract": "This paper proposes a novel approach for detecting objects using mobile robots in the context of the RoboCup Standard Platform League, with a primary focus on detecting the ball. The challenge lies in detecting a dynamic object in varying lighting conditions and blurred images caused by fast movements. To address this challenge, the paper presents a convolutional neural network architecture designed specifically for computationally constrained robotic platforms. The proposed CNN is trained to achieve high precision classification of single objects in image patches and to determine their precise spatial positions. The paper further integrates Early Exits into the existing high-precision CNN architecture to reduce the computational cost of easily rejectable cases in the background class. The training process involves a composite loss function based on confidence and positional losses with dynamic weighting and data augmentation. The proposed approach achieves a precision of 100% on the validation dataset and a recall of almost 87%, while maintaining an execution time of around 170 $\\mu$s per hypotheses. By combining the proposed approach with an Early Exit, a runtime optimization of more than 28%, on average, can be achieved compared to the original CNN. Overall, this paper provides an efficient solution for an enhanced detection of objects, especially the ball, in computationally constrained robotic platforms.", "url": "https://arxiv.org/abs/2309.03530"}, {"metadata": {"arXiv": "2309.03531", "Date": "Thu, 07 Sep 2023 07:26:27 ", "Title": "A Robust Negative Learning Approach to Partial Domain Adaptation Using Source Prototypes", "Authors": ["Sandipan Choudhuri", "Suli Adeniye", "Arunabha Sen"], "Categories": "cs.CV cs.LG"}, "abstract": "This work proposes a robust Partial Domain Adaptation (PDA) framework that mitigates the negative transfer problem by incorporating a robust target-supervision strategy. It leverages ensemble learning and includes diverse, complementary label feedback, alleviating the effect of incorrect feedback and promoting pseudo-label refinement. Rather than relying exclusively on first-order moments for distribution alignment, our approach offers explicit objectives to optimize intra-class compactness and inter-class separation with the inferred source prototypes and highly-confident target samples in a domain-invariant fashion. Notably, we ensure source data privacy by eliminating the need to access the source data during the adaptation phase through a priori inference of source prototypes. We conducted a series of comprehensive experiments, including an ablation analysis, covering a range of partial domain adaptation tasks. Comprehensive evaluations on benchmark datasets corroborate our framework's enhanced robustness and generalization, demonstrating its superiority over existing state-of-the-art PDA approaches.", "url": "https://arxiv.org/abs/2309.03531"}, {"metadata": {"arXiv": "2309.03827", "Date": "Thu, 07 Sep 2023 16:40:49 ", "Title": "ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation", "Authors": ["Hrishav Bakul Barua", "Ganesh Krishnasamy", "KokSheik Wong", "Kalin Stefanov", "Abhinav Dhall"], "Categories": "cs.CV cs.GR cs.LG cs.MM eess.IV", "Comments": ["Accepted in Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)", "Taipei", "Taiwan"], "ACM-class": "I.2.10; I.4.5; I.3.3; I.4.3"}, "abstract": "High Dynamic Range (HDR) content creation has become an important topic for modern media and entertainment sectors, gaming and Augmented/Virtual Reality industries. Many methods have been proposed to recreate the HDR counterparts of input Low Dynamic Range (LDR) images/videos given a single exposure or multi-exposure LDRs. The state-of-the-art methods focus primarily on the preservation of the reconstruction's structural similarity and the pixel-wise accuracy. However, these conventional approaches do not emphasize preserving the artistic intent of the images in terms of human visual perception, which is an essential element in media, entertainment and gaming. In this paper, we attempt to study and fill this gap. We propose an architecture called ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR features as input. Experimental results show that ArtHDR-Net can achieve state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean opinion score index) while reaching competitive performance in terms of PSNR and SSIM.", "url": "https://arxiv.org/abs/2309.03827"}, {"metadata": {"arXiv": "2309.03837", "Date": "Thu, 07 Sep 2023 16:50:40 ", "Title": "Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications", "Authors": ["Sangwook Kim", "Thomas G. Purdie", "Chris McIntosh"], "Categories": "cs.CV cs.LG", "Comments": ["13 pages", "2 figures"]}, "abstract": "Multi-task learning (MTL) is a powerful approach in deep learning that leverages the information from multiple tasks during training to improve model performance. In medical imaging, MTL has shown great potential to solve various tasks. However, existing MTL architectures in medical imaging are limited in sharing information across tasks, reducing the potential performance improvements of MTL. In this study, we introduce a novel attention-based MTL framework to better leverage inter-task interactions for various tasks from pixel-level to image-level predictions. Specifically, we propose a Cross-Task Attention Network (CTAN) which utilizes cross-task attention mechanisms to incorporate information by interacting across tasks. We validated CTAN on four medical imaging datasets that span different domains and tasks including: radiation treatment planning prediction using planning CT images of two different target cancers (Prostate, OpenKBP); pigmented skin lesion segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19 diagnosis and severity prediction using chest CT scans (STOIC). Our study demonstrates the effectiveness of CTAN in improving the accuracy of medical imaging tasks. Compared to standard single-task learning (STL), CTAN demonstrated a 4.67% improvement in performance and outperformed both widely used MTL baselines: hard parameter sharing (HPS) with an average performance improvement of 3.22%; and multi-task attention network (MTAN) with a relative decrease of 5.38%. These findings highlight the significance of our proposed MTL framework in solving medical imaging tasks and its potential to improve their accuracy across domains.", "url": "https://arxiv.org/abs/2309.03837"}, {"metadata": {"arXiv": "2309.03232", "Date": "Tue, 05 Sep 2023 06:26:57 ", "Title": "Retail store customer behavior analysis system: Design and Implementation", "Authors": ["Tuan Dinh Nguyen", "Keisuke Hihara", "Tung Cao Hoang", "Yumeka Utada", "Akihiko Torii", "Naoki Izumi", "Nguyen Thanh Thuy and Long Quoc Tran"], "Categories": "cs.LG cs.CV cs.HC"}, "abstract": "Understanding customer behavior in retail stores plays a crucial role in improving customer satisfaction by adding personalized value to services. Behavior analysis reveals both general and detailed patterns in the interaction of customers with a store items and other people, providing store managers with insight into customer preferences. Several solutions aim to utilize this data by recognizing specific behaviors through statistical visualization. However, current approaches are limited to the analysis of small customer behavior sets, utilizing conventional methods to detect behaviors. They do not use deep learning techniques such as deep neural networks, which are powerful methods in the field of computer vision. Furthermore, these methods provide limited figures when visualizing the behavioral data acquired by the system. In this study, we propose a framework that includes three primary parts: mathematical modeling of customer behaviors, behavior analysis using an efficient deep learning based system, and individual and group behavior visualization. Each module and the entire system were validated using data from actual situations in a retail store.", "url": "https://arxiv.org/abs/2309.03232"}, {"metadata": {"arXiv": "2309.03237", "Date": "Wed, 06 Sep 2023 02:09:14 ", "Title": "Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat", "Authors": ["Erdong Hu", "Yuxin Tang", "Anastasios Kyrillidis", "Chris Jermaine"], "Categories": "cs.LG cs.IT math.IT math.OC", "Comments": ["16 pages", "7 figures", "Accepted at ICCV2023"]}, "abstract": "We carefully evaluate a number of algorithms for learning in a federated environment, and test their utility for a variety of image classification tasks. We consider many issues that have not been adequately considered before: whether learning over data sets that do not have diverse sets of images affects the results; whether to use a pre-trained feature extraction \"backbone\"; how to evaluate learner performance (we argue that classification accuracy is not enough), among others. Overall, across a wide variety of settings, we find that vertically decomposing a neural network seems to give the best results, and outperforms more standard reconciliation-used methods.", "url": "https://arxiv.org/abs/2309.03237"}, {"metadata": {"arXiv": "2309.03238", "Date": "Wed, 06 Sep 2023 02:45:42 ", "Title": "Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation", "Authors": ["Mimansa Jaiswal"], "Categories": "cs.LG cs.CL cs.SD eess.AS", "Comments": ["PhD Thesis"]}, "abstract": "Emotion recognition is a complex task due to the inherent subjectivity in both the perception and production of emotions. The subjectivity of emotions poses significant challenges in developing accurate and robust computational models. This thesis examines critical facets of emotion recognition, beginning with the collection of diverse datasets that account for psychological factors in emotion production. To handle the challenge of non-representative training data, this work collects the Multimodal Stressed Emotion dataset, which introduces controlled stressors during data collection to better represent real-world influences on emotion production. To address issues with label subjectivity, this research comprehensively analyzes how data augmentation techniques and annotation schemes impact emotion perception and annotator labels. It further handles natural confounding variables and variations by employing adversarial networks to isolate key factors like stress from learned emotion representations during model training. For tackling concerns about leakage of sensitive demographic variables, this work leverages adversarial learning to strip sensitive demographic information from multimodal encodings. Additionally, it proposes optimized sociological evaluation metrics aligned with cost-effective, real-world needs for model testing. This research advances robust, practical emotion recognition through multifaceted studies of challenges in datasets, labels, modeling, demographic and membership variable encoding in representations, and evaluation. The groundwork has been laid for cost-effective, generalizable emotion recognition models that are less likely to encode sensitive demographic information.", "url": "https://arxiv.org/abs/2309.03238"}, {"metadata": {"arXiv": "2309.03246", "Date": "Wed, 06 Sep 2023 12:02:15 ", "Title": "EvoCLINICAL: Evolving Cyber-Cyber Digital Twin with Active Transfer Learning for Automated Cancer Registry System", "Authors": ["Chengjie Lu", "Qinghua Xu", "Tao Yue", "Shaukat Ali", "Thomas Schwitalla", "Jan F. Nyg{\\aa}rd"], "Categories": "cs.LG cs.SE", "Comments": ["12 pages", "2 figures", "5 tables; accepted to the industry track of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '23)"], "DOI": "10.1145/3611643.3613897"}, "abstract": "The Cancer Registry of Norway (CRN) collects information on cancer patients by receiving cancer messages from different medical entities (e.g., medical labs, and hospitals) in Norway. Such messages are validated by an automated cancer registry system: GURI. Its correct operation is crucial since it lays the foundation for cancer research and provides critical cancer-related statistics to its stakeholders. Constructing a cyber-cyber digital twin (CCDT) for GURI can facilitate various experiments and advanced analyses of the operational state of GURI without requiring intensive interactions with the real system. However, GURI constantly evolves due to novel medical diagnostics and treatment, technological advances, etc. Accordingly, CCDT should evolve as well to synchronize with GURI. A key challenge of achieving such synchronization is that evolving CCDT needs abundant data labelled by the new GURI. To tackle this challenge, we propose EvoCLINICAL, which considers the CCDT developed for the previous version of GURI as the pretrained model and fine-tunes it with the dataset labelled by querying a new GURI version. EvoCLINICAL employs a genetic algorithm to select an optimal subset of cancer messages from a candidate dataset and query GURI with it. We evaluate EvoCLINICAL on three evolution processes. The precision, recall, and F1 score are all greater than 91%, demonstrating the effectiveness of EvoCLINICAL. Furthermore, we replace the active learning part of EvoCLINICAL with random selection to study the contribution of transfer learning to the overall performance of EvoCLINICAL. Results show that employing active learning in EvoCLINICAL increases its performances consistently.", "url": "https://arxiv.org/abs/2309.03246"}, {"metadata": {"arXiv": "2309.03249", "Date": "Wed, 06 Sep 2023 15:47:18 ", "Title": "Graph Theory Applications in Advanced Geospatial Research", "Authors": ["Surajit Ghosh", "Archita Mallick", "Anuva Chowdhury", "Kounik De Sarkar"], "Categories": "cs.LG cs.CE cs.CY physics.geo-ph"}, "abstract": "Geospatial sciences include a wide range of applications, from environmental monitoring transportation to infrastructure planning, as well as location-based analysis and services. Graph theory algorithms in mathematics have emerged as indispensable tools in these domains due to their capability to model and analyse spatial relationships efficiently. This technical report explores the applications of graph theory algorithms in geospatial sciences, highlighting their role in network analysis, spatial connectivity, geographic information systems, and various other spatial problem-solving scenarios. It provides a comprehensive idea about the key concepts and algorithms of graph theory that assist the modelling processes. The report provides insights into the practical significance of graph theory in addressing real-world geospatial challenges and opportunities. It lists the extensive research, innovative technologies and methodologies implemented in this field.", "url": "https://arxiv.org/abs/2309.03249"}, {"metadata": {"arXiv": "2309.03426", "Date": "Thu, 07 Sep 2023 01:10:01 ", "Title": "Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making", "Authors": ["Yuancheng Xu", "Chenghao Deng", "Yanchao Sun", "Ruijie Zheng", "Xiyao Wang", "Jieyu Zhao", "Furong Huang"], "Categories": "cs.LG cs.CY"}, "abstract": "Decisions made by machine learning models may have lasting impacts over time, making long-term fairness a crucial consideration. It has been shown that when ignoring the long-term effect, naively imposing fairness criterion in static settings can actually exacerbate bias over time. To explicitly address biases in sequential decision-making, recent works formulate long-term fairness notions in Markov Decision Process (MDP) framework. They define the long-term bias to be the sum of static bias over each time step. However, we demonstrate that naively summing up the step-wise bias can cause a false sense of fairness since it fails to consider the importance difference of different time steps during transition. In this work, we introduce a long-term fairness notion called Equal Long-term Benefit Rate (ELBERT), which explicitly considers varying temporal importance and adapts static fairness principles to the sequential setting. Moreover, we show that the policy gradient of Long-term Benefit Rate can be analytically reduced to standard policy gradient. This makes standard policy optimization methods applicable for reducing the bias, leading to our proposed bias mitigation method ELBERT-PO. Experiments on three sequential decision making environments show that ELBERT-PO significantly reduces bias and maintains high utility. Code is available at https://github.com/Yuancheng-Xu/ELBERT.", "url": "https://arxiv.org/abs/2309.03426"}, {"metadata": {"arXiv": "2309.03437", "Date": "Thu, 07 Sep 2023 01:39:02 ", "Title": "Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy", "Authors": ["Zikai Zhang", "Rui Hu"], "Categories": "cs.LG cs.CR"}, "abstract": "Federated learning (FL) is designed to preserve data privacy during model training, where the data remains on the client side (i.e., IoT devices), and only model updates of clients are shared iteratively for collaborative learning. However, this process is vulnerable to privacy attacks and Byzantine attacks: the local model updates shared throughout the FL network will leak private information about the local training data, and they can also be maliciously crafted by Byzantine attackers to disturb the learning. In this paper, we propose a new FL scheme that guarantees rigorous privacy and simultaneously enhances system robustness against Byzantine attacks. Our approach introduces sparsification- and momentum-driven variance reduction into the client-level differential privacy (DP) mechanism, to defend against Byzantine attackers. The security design does not violate the privacy guarantee of the client-level DP mechanism; hence, our approach achieves the same client-level DP guarantee as the state-of-the-art. We conduct extensive experiments on both IID and non-IID datasets and different tasks and evaluate the performance of our approach against different Byzantine attacks by comparing it with state-of-the-art defense methods. The results of our experiments show the efficacy of our framework and demonstrate its ability to improve system robustness against Byzantine attacks while achieving a strong privacy guarantee.", "url": "https://arxiv.org/abs/2309.03437"}, {"metadata": {"arXiv": "2309.03439", "Date": "Thu, 07 Sep 2023 01:43:47 ", "Title": "Personalized Tucker Decomposition: Modeling Commonality and Peculiarity on Tensor Data", "Authors": ["Jiuyun Hu", "Naichen Shi", "Raed Al Kontar", "Hao Yan"], "Categories": "cs.LG stat.ME"}, "abstract": "We propose personalized Tucker decomposition (perTucker) to address the limitations of traditional tensor decomposition methods in capturing heterogeneity across different datasets. perTucker decomposes tensor data into shared global components and personalized local components. We introduce a mode orthogonality assumption and develop a proximal gradient regularized block coordinate descent algorithm that is guaranteed to converge to a stationary point. By learning unique and common representations across datasets, we demonstrate perTucker's effectiveness in anomaly detection, client classification, and clustering through a simulation study and two case studies on solar flare detection and tonnage signal classification.", "url": "https://arxiv.org/abs/2309.03439"}, {"metadata": {"arXiv": "2309.03487", "Date": "Thu, 07 Sep 2023 05:45:47 ", "Title": "Privacy-preserving Continual Federated Clustering via Adaptive Resonance Theory", "Authors": ["Naoki Masuyama", "Yusuke Nojima", "Yuichiro Toda", "Chu Kiong Loo", "Hisao Ishibuchi", "Naoyuki Kubota"], "Categories": "cs.LG cs.CR cs.NE", "Comments": ["This paper is currently under review. arXiv admin note: substantial text overlap with arXiv:2305.01507"]}, "abstract": "With the increasing importance of data privacy protection, various privacy-preserving machine learning methods have been proposed. In the clustering domain, various algorithms with a federated learning framework (i.e., federated clustering) have been actively studied and showed high clustering performance while preserving data privacy. However, most of the base clusterers (i.e., clustering algorithms) used in existing federated clustering algorithms need to specify the number of clusters in advance. These algorithms, therefore, are unable to deal with data whose distributions are unknown or continually changing. To tackle this problem, this paper proposes a privacy-preserving continual federated clustering algorithm. In the proposed algorithm, an adaptive resonance theory-based clustering algorithm capable of continual learning is used as a base clusterer. Therefore, the proposed algorithm inherits the ability of continual learning. Experimental results with synthetic and real-world datasets show that the proposed algorithm has superior clustering performance to state-of-the-art federated clustering algorithms while realizing data privacy protection and continual learning ability. The source code is available at \\url{https://github.com/Masuyama-lab/FCAC}.", "url": "https://arxiv.org/abs/2309.03487"}, {"metadata": {"arXiv": "2309.03569", "Date": "Thu, 07 Sep 2023 08:58:41 ", "Title": "Sparse Federated Training of Object Detection in the Internet of Vehicles", "Authors": ["Luping Rao", "Chuan Ma", "Ming Ding", "Yuwen Qian", "Lu Zhou", "Zhe Liu"], "Categories": "cs.LG cs.CV"}, "abstract": "As an essential component part of the Intelligent Transportation System (ITS), the Internet of Vehicles (IoV) plays a vital role in alleviating traffic issues. Object detection is one of the key technologies in the IoV, which has been widely used to provide traffic management services by analyzing timely and sensitive vehicle-related information. However, the current object detection methods are mostly based on centralized deep training, that is, the sensitive data obtained by edge devices need to be uploaded to the server, which raises privacy concerns. To mitigate such privacy leakage, we first propose a federated learning-based framework, where well-trained local models are shared in the central server. However, since edge devices usually have limited computing power, plus a strict requirement of low latency in IoVs, we further propose a sparse training process on edge devices, which can effectively lighten the model, and ensure its training efficiency on edge devices, thereby reducing communication overheads. In addition, due to the diverse computing capabilities and dynamic environment, different sparsity rates are applied to edge devices. To further guarantee the performance, we propose, FedWeg, an improved aggregation scheme based on FedAvg, which is designed by the inverse ratio of sparsity rates. Experiments on the real-life dataset using YOLO show that the proposed scheme can achieve the required object detection rate while saving considerable communication costs.", "url": "https://arxiv.org/abs/2309.03569"}, {"metadata": {"arXiv": "2309.03616", "Date": "Thu, 07 Sep 2023 10:18:36 ", "Title": "Filtration Surfaces for Dynamic Graph Classification", "Authors": ["Franz Srambical and Bastian Rieck"], "Categories": "cs.LG"}, "abstract": "Existing approaches for classifying dynamic graphs either lift graph kernels to the temporal domain, or use graph neural networks (GNNs). However, current baselines have scalability issues, cannot handle a changing node set, or do not take edge weight information into account. We propose filtration surfaces, a novel method that is scalable and flexible, to alleviate said restrictions. We experimentally validate the efficacy of our model and show that filtration surfaces outperform previous state-of-the-art baselines on datasets that rely on edge weight information. Our method does so while being either completely parameter-free or having at most one parameter, and yielding the lowest overall standard deviation.", "url": "https://arxiv.org/abs/2309.03616"}, {"metadata": {"arXiv": "2309.03631", "Date": "Thu, 07 Sep 2023 10:54:06 ", "Title": "Insights Into the Inner Workings of Transformer Models for Protein Function Prediction", "Authors": ["Markus Wenzel", "Erik Gr\\\"uner", "Nils Strodthoff"], "Categories": "cs.LG q-bio.BM", "Comments": ["20 pages", "9 figures", "4 tables", "source code available at https://github.com/markuswenzel/xai-proteins"]}, "abstract": "Motivation: We explored how explainable AI (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g., transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins .", "url": "https://arxiv.org/abs/2309.03631"}, {"metadata": {"arXiv": "2309.03664", "Date": "Thu, 07 Sep 2023 12:01:01 ", "Title": "Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal Fluid via Topological Machine Learning", "Authors": ["Francesco Conti", "Martina Banchelli", "Valentina Bessi", "Cristina Cecchi", "Fabrizio Chiti", "Sara Colantonio", "Cristiano D'Andrea", "Marella de Angelis", "Davide Moroni", "Benedetta Nacmias", "Maria Antonietta Pascali", "Sandro Sorbi and Paolo Matteini"], "Categories": "cs.LG", "Comments": ["Accepter for inclusion in AITA 2023 (http://aita.isti.cnr.it/)"], "MSC-class": "55N31 (primary), 55N35 (secondary)", "ACM-class": "I.2.6; I.5"}, "abstract": "The cerebrospinal fluid (CSF) of 19 subjects who received a clinical diagnosis of Alzheimer's disease (AD) as well as of 5 pathological controls have been collected and analysed by Raman spectroscopy (RS). We investigated whether the raw and preprocessed Raman spectra could be used to distinguish AD from controls. First, we applied standard Machine Learning (ML) methods obtaining unsatisfactory results. Then, we applied ML to a set of topological descriptors extracted from raw spectra, achieving a very good classification accuracy (>87%). Although our results are preliminary, they indicate that RS and topological analysis together may provide an effective combination to confirm or disprove a clinical diagnosis of AD. The next steps will include enlarging the dataset of CSF samples to validate the proposed method better and, possibly, to understand if topological data analysis could support the characterization of AD subtypes.", "url": "https://arxiv.org/abs/2309.03664"}, {"metadata": {"arXiv": "2309.03694", "Date": "Thu, 07 Sep 2023 13:06:52 ", "Title": "Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head Attention-Augmented CNN-LSTM Network", "Authors": ["Paapa Kwesi Quansah"], "Categories": "cs.LG cs.NE cs.SY eess.SY"}, "abstract": "Short-term load forecasting is of paramount importance in the efficient operation and planning of power systems, given its inherent non-linear and dynamic nature. Recent strides in deep learning have shown promise in addressing this challenge. However, these methods often grapple with hyperparameter sensitivity, opaqueness in interpretability, and high computational overhead for real-time deployment. In this paper, I propose a novel solution that surmounts these obstacles. Our approach harnesses the power of the Particle-Swarm Optimization algorithm to autonomously explore and optimize hyperparameters, a Multi-Head Attention mechanism to discern the salient features crucial for accurate forecasting, and a streamlined framework for computational efficiency. Our method undergoes rigorous evaluation using a genuine electricity demand dataset. The results underscore its superiority in terms of accuracy, robustness, and computational efficiency. Notably, our Mean Absolute Percentage Error of 1.9376 marks a significant advancement over existing state-of-the-art approaches, heralding a new era in short-term load forecasting.", "url": "https://arxiv.org/abs/2309.03694"}, {"metadata": {"arXiv": "2309.03702", "Date": "Thu, 07 Sep 2023 13:28:36 ", "Title": "DiffDefense: Defending against Adversarial Attacks via Diffusion Models", "Authors": ["Hondamunige Prasanna Silva", "Lorenzo Seidenari", "and Alberto Del Bimbo"], "Categories": "cs.LG cs.CR cs.CV", "Comments": ["Paper published at ICIAP23"], "Journal-ref": "ICIAP 2023", "DOI": "10.1007/978-3-031-43153-1_36"}, "abstract": "This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves. The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks. While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility. Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence.", "url": "https://arxiv.org/abs/2309.03702"}, {"metadata": {"arXiv": "2309.03710", "Date": "Thu, 07 Sep 2023 13:38:36 ", "Title": "A State Representation for Diminishing Rewards", "Authors": ["Ted Moskovitz", "Samo Hromadka", "Ahmed Touati", "Diana Borsa", "Maneesh Sahani"], "Categories": "cs.LG"}, "abstract": "A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution. In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function. However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli. Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature. We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging.", "url": "https://arxiv.org/abs/2309.03710"}, {"metadata": {"arXiv": "2309.03730", "Date": "Thu, 07 Sep 2023 14:14:30 ", "Title": "A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions", "Authors": ["Christopher Bockel-Rickermann", "Sam Verboven", "Tim Verdonck", "Wouter Verbeke"], "Categories": "cs.LG econ.EM", "Comments": ["24 pages", "5 figures"]}, "abstract": "In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making. Typically, such a policy must be derived from observational data, which introduces several challenges. While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not. We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference. Specifically, we consider the reaction of a customer to price a treatment effect. In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium. We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions. Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias. In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data.", "url": "https://arxiv.org/abs/2309.03730"}, {"metadata": {"arXiv": "2309.03731", "Date": "Thu, 07 Sep 2023 14:17:44 ", "Title": "Learning continuous-valued treatment effects through representation balancing", "Authors": ["Christopher Bockel-Rickermann", "Toon Vanderschueren", "Jeroen Berrevoets", "Tim Verdonck", "Wouter Verbeke"], "Categories": "cs.LG stat.ME", "Comments": ["24 pages", "8 figures"], "MSC-class": "62D20"}, "abstract": "Estimating the effects of treatments with an associated dose on an instance's outcome, the \"dose response\", is relevant in a variety of domains, from healthcare to business, economics, and beyond. Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias. This means that the allocation of doses depends on pre-treatment covariates. Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias. In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data. CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments. Our work is the first to apply representation balancing in a continuous-valued treatment setting. We evaluate our method on a newly proposed benchmark. Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods.", "url": "https://arxiv.org/abs/2309.03731"}, {"metadata": {"arXiv": "2309.03751", "Date": "Thu, 07 Sep 2023 14:46:48 ", "Title": "Medoid Silhouette clustering with automatic cluster number selection", "Authors": ["Lars Lenssen and Erich Schubert"], "Categories": "cs.LG stat.ML", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2209.12553"]}, "abstract": "The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\\times$ speedup compared to the original PAMMEDSIL algorithm. Additionally, we provide a variant to choose the optimal number of clusters directly.", "url": "https://arxiv.org/abs/2309.03751"}, {"metadata": {"arXiv": "2309.03754", "Date": "Thu, 07 Sep 2023 14:50:31 ", "Title": "Convergence Analysis of Decentralized ASGD", "Authors": ["Mauro DL Tosi", "Martin Theobald"], "Categories": "cs.LG cs.DC"}, "abstract": "Over the last decades, Stochastic Gradient Descent (SGD) has been intensively studied by the Machine Learning community. Despite its versatility and excellent performance, the optimization of large models via SGD still is a time-consuming task. To reduce training time, it is common to distribute the training process across multiple devices. Recently, it has been shown that the convergence of asynchronous SGD (ASGD) will always be faster than mini-batch SGD. However, despite these improvements in the theoretical bounds, most ASGD convergence-rate proofs still rely on a centralized parameter server, which is prone to become a bottleneck when scaling out the gradient computations across many distributed processes. In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) which does not require partial synchronization among nodes nor restrictive network topologies. Specifically, we provide a bound of $\\mathcal{O}(\\sigma\\epsilon^{-2}) + \\mathcal{O}(QS_{avg}\\epsilon^{-3/2}) + \\mathcal{O}(S_{avg}\\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\\epsilon$ is a (small) error that is allowed within the bound. Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\\mathcal{O}(\\sigma\\epsilon^{-2}) + \\mathcal{O}(\\sqrt{\\hat{S}_{avg}\\hat{S}_{max}}\\epsilon^{-1})$, with $\\hat{S}_{max}$ and $\\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively. Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function. We anticipate that our results will be of high relevance for the adoption of DASGD by a broad community of researchers and developers.", "url": "https://arxiv.org/abs/2309.03754"}, {"metadata": {"arXiv": "2309.03774", "Date": "Thu, 07 Sep 2023 15:25:47 ", "Title": "Deep Learning Safety Concerns in Automated Driving Perception", "Authors": ["Stephanie Abrecht", "Alexander Hirsch", "Shervin Raafatnia", "Matthias Woehrle"], "Categories": "cs.LG cs.CV cs.SY eess.SY"}, "abstract": "Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems. The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs. In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element. On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800. While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field. In particular, this paper introduces an additional categorization for a better understanding as well as enabling cross-functional teams to jointly address the concerns.", "url": "https://arxiv.org/abs/2309.03774"}, {"metadata": {"arXiv": "2309.03791", "Date": "Thu, 07 Sep 2023 15:41:45 ", "Title": "Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences", "Authors": ["Jeremiah Birrell", "Mohammadreza Ebrahimi"], "Categories": "cs.LG stat.ML", "Comments": ["30 pages", "5 figures"]}, "abstract": "We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$ against $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to prior methods. Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and $57.53\\%$, respectively.", "url": "https://arxiv.org/abs/2309.03791"}, {"metadata": {"arXiv": "2309.03797", "Date": "Thu, 07 Sep 2023 15:50:48 ", "Title": "Conformal Autoregressive Generation: Beam Search with Coverage Guarantees", "Authors": ["Nicolas Deutschmann", "Marvin Alberts", "Mar\\'ia Rodr\\'iguez Mart\\'inez"], "Categories": "cs.LG", "Comments": ["11 pages", "4 figures"]}, "abstract": "We introduce two new extensions to the beam search algorithm based on conformal predictions (CP) to produce sets of sequences with theoretical coverage guarantees. The first method is very simple and proposes dynamically-sized subsets of beam search results but, unlike typical CP procedures, has an upper bound on the achievable guarantee depending on a post-hoc calibration measure. Our second algorithm introduces the conformal set prediction procedure as part of the decoding process, producing a variable beam width which adapts to the current uncertainty. While more complex, this procedure can achieve coverage guarantees selected a priori. We provide marginal coverage bounds for each method, and evaluate them empirically on a selection of tasks drawing from natural language processing and chemistry.", "url": "https://arxiv.org/abs/2309.03797"}, {"metadata": {"arXiv": "2309.03825", "Date": "Thu, 07 Sep 2023 16:34:30 ", "Title": "Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues", "Authors": ["Sama Daryanavard", "Bernd Porr"], "Categories": "cs.LG", "Comments": ["14 pages", "6 figures"]}, "abstract": "Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems. Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units. In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning. This is inspired by the interaction between local plasticity and a global neuromodulation. For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once. Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change. The advantages of this Prime and Modulate paradigm is twofold: it is free from normalisation and it makes use of relevant cues from the environment to enrich the learning. We present a mathematical derivation of the learning rule in z-space and demonstrate the real-time performance with a robotic platform. The results show a significant improvement in the speed of convergence compared to that of the conventional back-propagation.", "url": "https://arxiv.org/abs/2309.03825"}, {"metadata": {"arXiv": "2309.03851", "Date": "Thu, 07 Sep 2023 17:07:33 ", "Title": "CenTime: Event-Conditional Modelling of Censoring in Survival Analysis", "Authors": ["Ahmed H. Shahin", "An Zhao", "Alexander C. Whitehead", "Daniel C. Alexander", "Joseph Jacob", "David Barber"], "Categories": "cs.LG cs.CV"}, "abstract": "Survival analysis is a valuable tool for estimating the time until specific events, such as death or cancer recurrence, based on baseline observations. This is particularly useful in healthcare to prognostically predict clinically important events based on patient data. However, existing approaches often have limitations; some focus only on ranking patients by survivability, neglecting to estimate the actual event time, while others treat the problem as a classification task, ignoring the inherent time-ordered structure of the events. Furthermore, the effective utilization of censored samples - training data points where the exact event time is unknown - is essential for improving the predictive accuracy of the model. In this paper, we introduce CenTime, a novel approach to survival analysis that directly estimates the time to event. Our method features an innovative event-conditional censoring mechanism that performs robustly even when uncensored data is scarce. We demonstrate that our approach forms a consistent estimator for the event model parameters, even in the absence of uncensored data. Furthermore, CenTime is easily integrated with deep learning models with no restrictions on batch size or the number of uncensored samples. We compare our approach with standard survival analysis methods, including the Cox proportional-hazard model and DeepHit. Our results indicate that CenTime offers state-of-the-art performance in predicting time-to-death while maintaining comparable ranking performance. Our implementation is publicly available at https://github.com/ahmedhshahin/CenTime.", "url": "https://arxiv.org/abs/2309.03851"}, {"metadata": {"arXiv": "2309.03879", "Date": "Thu, 07 Sep 2023 17:44:18 ", "Title": "Better Practices for Domain Adaptation", "Authors": ["Linus Ericsson", "Da Li and Timothy M. Hospedales"], "Categories": "cs.LG cs.CV", "Comments": ["AutoML 2023 (Best paper award)"]}, "abstract": "Distribution shifts are all too common in real-world applications of machine learning. Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels. However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set. The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available. This has resulted in over-optimism about DA research progress compared to reality. In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms. We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date. Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.", "url": "https://arxiv.org/abs/2309.03879"}, {"metadata": {"arXiv": "2309.03315", "Date": "Wed, 06 Sep 2023 18:56:20 ", "Title": "Robotic Table Tennis: A Case Study into a High Speed Learning System", "Authors": ["David B. D'Ambrosio", "Jonathan Abelian", "Saminda Abeyruwan", "Michael Ahn", "Alex Bewley", "Justin Boyd", "Krzysztof Choromanski", "Omar Cortes", "Erwin Coumans", "Tianli Ding", "Wenbo Gao", "Laura Graesser", "Atil Iscen", "Navdeep Jaitly", "Deepali Jain", "Juhana Kangaspunta", "Satoshi Kataoka", "Gus Kouretas", "Yuheng Kuang", "Nevena Lazic", "Corey Lynch", "Reza Mahjourian", "Sherry Q. Moore", "Thinh Nguyen", "Ken Oslund", "Barney J Reed", "Krista Reymann", "Pannag R. Sanketi", "Anish Shankar", "Pierre Sermanet", "Vikas Sindhwani", "Avi Singh", "Vincent Vanhoucke", "Grace Vesom", "and Peng Xu"], "Categories": "cs.RO cs.LG", "Comments": ["Published and presented at Robotics: Science and Systems (RSS2023)"]}, "abstract": "We present a deep-dive into a real-world robotic learning system that, in previous work, was shown to be capable of hundreds of table tennis rallies with a human and has the ability to precisely return the ball to desired targets. This system puts together a highly optimized perception subsystem, a high-speed low-latency robot controller, a simulation paradigm that can prevent damage in the real world and also train policies for zero-shot transfer, and automated real world environment resets that enable autonomous training and evaluation on physical robots. We complement a complete system description, including numerous design decisions that are typically not widely disseminated, with a collection of studies that clarify the importance of mitigating various sources of latency, accounting for training and deployment distribution shifts, robustness of the perception system, sensitivity to policy hyper-parameters, and choice of action space. A video demonstrating the components of the system and details of experimental results can be found at https://youtu.be/uFcnWjB42I0.", "url": "https://arxiv.org/abs/2309.03315"}, {"metadata": {"arXiv": "2309.03708", "Date": "Thu, 07 Sep 2023 13:36:03 ", "Title": "Chat Failures and Troubles: Reasons and Solutions", "Authors": ["Manal Helal", "Patrick Holthaus", "Gabriella Lakatos", "Farshid Amirabdollahian"], "Categories": "cs.RO cs.HC cs.LG", "Comments": ["4 pages"], "Journal-ref": "Working with Trouble and Failures in Conversation between humans and Robots (WTF) workshop held alongside the 5th International Conference on Conversational User Interfaces (CUI '23), June 19, 2023, Eindhoven, Netherlands"}, "abstract": "This paper examines some common problems in Human-Robot Interaction (HRI) causing failures and troubles in Chat. A given use case's design decisions start with the suitable robot, the suitable chatting model, identifying common problems that cause failures, identifying potential solutions, and planning continuous improvement. In conclusion, it is recommended to use a closed-loop control algorithm that guides the use of trained Artificial Intelligence (AI) pre-trained models and provides vocabulary filtering, re-train batched models on new datasets, learn online from data streams, and/or use reinforcement learning models to self-update the trained models and reduce errors.", "url": "https://arxiv.org/abs/2309.03708"}, {"metadata": {"arXiv": "2309.03835", "Date": "Thu, 07 Sep 2023 16:49:38 ", "Title": "Learning from Demonstration via Probabilistic Diagrammatic Teaching", "Authors": ["Weiming Zhi and Tianyi Zhang and Matthew Johnson-Roberson"], "Categories": "cs.RO cs.LG"}, "abstract": "Learning for Demonstration (LfD) enables robots to acquire new skills by imitating expert demonstrations, allowing users to communicate their instructions in an intuitive manner. Recent progress in LfD often relies on kinesthetic teaching or teleoperation as the medium for users to specify the demonstrations. Kinesthetic teaching requires physical handling of the robot, while teleoperation demands proficiency with additional hardware. This paper introduces an alternative paradigm for LfD called Diagrammatic Teaching. Diagrammatic Teaching aims to teach robots novel skills by prompting the user to sketch out demonstration trajectories on 2D images of the scene, these are then synthesised as a generative model of motion trajectories in 3D task space. Additionally, we present the Ray-tracing Probabilistic Trajectory Learning (RPTL) framework for Diagrammatic Teaching. RPTL extracts time-varying probability densities from the 2D sketches, applies ray-tracing to find corresponding regions in 3D Cartesian space, and fits a probabilistic model of motion trajectories to these regions. New motion trajectories, which mimic those sketched by the user, can then be generated from the probabilistic model. We empirically validate our framework both in simulation and on real robots, which include a fixed-base manipulator and a quadruped-mounted manipulator.", "url": "https://arxiv.org/abs/2309.03835"}, {"metadata": {"arXiv": "2309.03839", "Date": "Thu, 07 Sep 2023 16:52:27 ", "Title": "Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning", "Authors": ["Jensen Gao", "Siddharth Reddy", "Glen Berseth", "Anca D. Dragan", "Sergey Levine"], "Categories": "cs.RO cs.HC cs.LG", "Comments": ["Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023"]}, "abstract": "Adaptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface). Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice. In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning. To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory. We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam. The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance. We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well. Extensive ablation experiments with simulated user commands empirically motivate each component of our method.", "url": "https://arxiv.org/abs/2309.03839"}, {"metadata": {"arXiv": "2309.03891", "Date": "Thu, 07 Sep 2023 17:53:20 ", "Title": "ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation", "Authors": ["Hui Zhang", "Sammy Christen", "Zicong Fan", "Luocheng Zheng", "Jemin Hwangbo", "Jie Song", "Otmar Hilliges"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Project page: https://eth-ait.github.io/artigrasp/"]}, "abstract": "We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping, relocation, and articulation. We show our method's efficacy towards this task. We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor.", "url": "https://arxiv.org/abs/2309.03891"}, {"metadata": {"arXiv": "2309.03292", "Date": "Wed, 06 Sep 2023 18:12:07 ", "Title": "Scalable Learning of Intrusion Responses through Recursive Decomposition", "Authors": ["Kim Hammar and Rolf Stadler"], "Categories": "eess.SY cs.CR cs.LG cs.SY", "Comments": ["A shortened version of this paper will appear in the conference proceedings of GameSec 2023"]}, "abstract": "We study automated intrusion response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed stochastic game. To solve the game we follow an approach where attack and defense strategies co-evolve through reinforcement learning and self-play toward an equilibrium. Solutions proposed in previous work prove the feasibility of this approach for small infrastructures but do not scale to realistic scenarios due to the exponential growth in computational complexity with the infrastructure size. We address this problem by introducing a method that recursively decomposes the game into subgames which can be solved in parallel. Applying optimal stopping theory we show that the best response strategies in these subgames exhibit threshold structures, which allows us to compute them efficiently. To solve the decomposed game we introduce an algorithm called Decompositional Fictitious Self-Play (DFSP), which learns Nash equilibria through stochastic approximation. We evaluate the learned strategies in an emulation environment where real intrusions and response actions can be executed. The results show that the learned strategies approximate an equilibrium and that DFSP significantly outperforms a state-of-the-art algorithm for a realistic infrastructure configuration.", "url": "https://arxiv.org/abs/2309.03292"}, {"metadata": {"arXiv": "2309.03672", "Date": "Thu, 07 Sep 2023 12:21:22 ", "Title": "A computationally lightweight safe learning algorithm", "Authors": ["Dominik Baumann and Krzysztof Kowalczyk and Koen Tiels and Pawe{\\l} Wachel"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["Accepted final version to appear in: Proc. of the IEEE Conference on Decision and Control"]}, "abstract": "Safety is an essential asset when learning control policies for physical systems, as violating safety constraints during training can lead to expensive hardware damage. In response to this need, the field of safe learning has emerged with algorithms that can provide probabilistic safety guarantees without knowledge of the underlying system dynamics. Those algorithms often rely on Gaussian process inference. Unfortunately, Gaussian process inference scales cubically with the number of data points, limiting applicability to high-dimensional and embedded systems. In this paper, we propose a safe learning algorithm that provides probabilistic safety guarantees but leverages the Nadaraya-Watson estimator instead of Gaussian processes. For the Nadaraya-Watson estimator, we can reach logarithmic scaling with the number of data points. We provide theoretical guarantees for the estimates, embed them into a safe learning algorithm, and show numerical experiments on a simulated seven-degrees-of-freedom robot manipulator.", "url": "https://arxiv.org/abs/2309.03672"}, {"metadata": {"arXiv": "2309.03873", "Date": "Thu, 07 Sep 2023 17:33:30 ", "Title": "A Tutorial on the Non-Asymptotic Theory of System Identification", "Authors": ["Ingvar Ziemann", "Anastasios Tsiamis", "Bruce Lee", "Yassir Jedra", "Nikolai Matni", "George J. Pappas"], "Categories": "eess.SY cs.LG cs.SY stat.ML"}, "abstract": "This tutorial serves as an introduction to recently developed non-asymptotic methods in the theory of -- mainly linear -- system identification. We emphasize tools we deem particularly useful for a range of problems in this domain, such as the covering technique, the Hanson-Wright Inequality and the method of self-normalized martingales. We then employ these tools to give streamlined proofs of the performance of various least-squares based estimators for identifying the parameters in autoregressive models. We conclude by sketching out how the ideas presented herein can be extended to certain nonlinear identification problems.", "url": "https://arxiv.org/abs/2309.03873"}, {"metadata": {"arXiv": "2309.03215", "Date": "Wed, 30 Aug 2023 09:05:52 ", "Title": "Explainable and Trustworthy Traffic Sign Detection for Safe Autonomous Driving: An Inductive Logic Programming Approach", "Authors": ["Zahra Chaghazardi (University of Surrey)", "Saber Fallah (University of Surrey)", "Alireza Tamaddoni-Nezhad (University of Surrey)"], "Categories": "cs.AI cs.CV cs.LO", "Comments": ["In Proceedings ICLP 2023", "arXiv:2308.14898"], "Journal-ref": "EPTCS 385, 2023, pp. 201-212", "DOI": "10.4204/EPTCS.385.21"}, "abstract": "Traffic sign detection is a critical task in the operation of Autonomous Vehicles (AV), as it ensures the safety of all road users. Current DNN-based sign classification systems rely on pixel-level features to detect traffic signs and can be susceptible to adversarial attacks. These attacks involve small, imperceptible changes to a sign that can cause traditional classifiers to misidentify the sign. We propose an Inductive Logic Programming (ILP) based approach for stop sign detection in AVs to address this issue. This method utilises high-level features of a sign, such as its shape, colour, and text, to detect categories of traffic signs. This approach is more robust against adversarial attacks, as it mimics human-like perception and is less susceptible to the limitations of current DNN classifiers. We consider two adversarial attacking methods to evaluate our approach: Robust Physical Perturbation (PR2) and Adversarial Camouflage (AdvCam). These attacks are able to deceive DNN classifiers, causing them to misidentify stop signs as other signs with high confidence. The results show that the proposed ILP-based technique is able to correctly identify all targeted stop signs, even in the presence of PR2 and ADvCam attacks. The proposed learning method is also efficient as it requires minimal training data. Moreover, it is fully explainable, making it possible to debug AVs.", "url": "https://arxiv.org/abs/2309.03215"}, {"metadata": {"arXiv": "2309.03217", "Date": "Wed, 30 Aug 2023 17:07:54 ", "Title": "Algebraic Models for Qualified Aggregation in General Rough Sets, and Reasoning Bias Discovery", "Authors": ["Mani A"], "Categories": "cs.AI cs.LO math.RA", "Comments": ["15 Pages"], "MSC-class": "03G25, 03G10 (Primary), 03B60, 06B35, 08A70 (Secondary)"}, "abstract": "In the context of general rough sets, the act of combining two things to form another is not straightforward. The situation is similar for other theories that concern uncertainty and vagueness. Such acts can be endowed with additional meaning that go beyond structural conjunction and disjunction as in the theory of $*$-norms and associated implications over $L$-fuzzy sets. In the present research, algebraic models of acts of combining things in generalized rough sets over lattices with approximation operators (called rough convenience lattices) is invented. The investigation is strongly motivated by the desire to model skeptical or pessimistic, and optimistic or possibilistic aggregation in human reasoning, and the choice of operations is constrained by the perspective. Fundamental results on the weak negations and implications afforded by the minimal models are proved. In addition, the model is suitable for the study of discriminatory/toxic behavior in human reasoning, and of ML algorithms learning such behavior.", "url": "https://arxiv.org/abs/2309.03217"}, {"metadata": {"arXiv": "2309.03222", "Date": "Fri, 01 Sep 2023 07:52:28 ", "Title": "Sherlock Holmes Doesn't Play Dice: The significance of Evidence Theory for the Social and Life Sciences", "Authors": ["V. L. Raju Chinthalapati and Guido Fioretti"], "Categories": "cs.AI cs.HC", "Comments": ["18 pages", "1 figure"], "MSC-class": "94.D.99", "ACM-class": "H.m"}, "abstract": "While Evidence Theory (Demster-Shafer Theory, Belief Functions Theory) is being increasingly used in data fusion, its potentialities in the Social and Life Sciences are often obscured by lack of awareness of its distinctive features. With this paper we stress that Evidence Theory can express the uncertainty deriving from the fear that events may materialize, that one has not been able to figure out. By contrast, Probability Theory must limit itself to the possibilities that a decision-maker is currently envisaging. Subsequently, we illustrate how Dempster-Shafer's combination rule relates to Bayes' Theorem for various versions of Probability Theory and discuss which applications of Information Theory can be enhanced by Evidence Theory. Finally, we illustrate our claims with an example where Evidence Theory is used to make sense of the partially overlapping, partially contradictory solutions that appear in an auditing exercise.", "url": "https://arxiv.org/abs/2309.03222"}, {"metadata": {"arXiv": "2309.03638", "Date": "Thu, 07 Sep 2023 11:08:14 ", "Title": "Beyond XAI:Obstacles Towards Responsible AI", "Authors": ["Yulu Pi"], "Categories": "cs.AI", "Comments": ["work in progress"]}, "abstract": "The rapidly advancing domain of Explainable Artificial Intelligence (XAI) has sparked significant interests in developing techniques to make AI systems more transparent and understandable. Nevertheless, in real-world contexts, the methods of explainability and their evaluation strategies present numerous limitations.Moreover, the scope of responsible AI extends beyond just explainability. In this paper, we explore these limitations and discuss their implications in a boarder context of responsible AI when considering other important aspects, including privacy, fairness and contestability.", "url": "https://arxiv.org/abs/2309.03638"}, {"metadata": {"arXiv": "2309.03651", "Date": "Thu, 07 Sep 2023 11:46:57 ", "Title": "Learning of Generalizable and Interpretable Knowledge in Grid-Based Reinforcement Learning Environments", "Authors": ["Manuel Eberhardinger", "Johannes Maucher", "Setareh Maghsudi"], "Categories": "cs.AI", "Comments": ["to be published in AIIDE 2023"]}, "abstract": "Understanding the interactions of agents trained with deep reinforcement learning is crucial for deploying agents in games or the real world. In the former, unreasonable actions confuse players. In the latter, that effect is even more significant, as unexpected behavior cause accidents with potentially grave and long-lasting consequences for the involved individuals. In this work, we propose using program synthesis to imitate reinforcement learning policies after seeing a trajectory of the action sequence. Programs have the advantage that they are inherently interpretable and verifiable for correctness. We adapt the state-of-the-art program synthesis system DreamCoder for learning concepts in grid-based environments, specifically, a navigation task and two miniature versions of Atari games, Space Invaders and Asterix. By inspecting the generated libraries, we can make inferences about the concepts the black-box agent has learned and better understand the agent's behavior. We achieve the same by visualizing the agent's decision-making process for the imitated sequences. We evaluate our approach with different types of program synthesizers based on a search-only method, a neural-guided search, and a language model fine-tuned on code.", "url": "https://arxiv.org/abs/2309.03651"}, {"metadata": {"arXiv": "2309.03685", "Date": "Thu, 07 Sep 2023 13:00:09 ", "Title": "PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips", "Authors": ["Nicolas Hubert", "Pierre Monnin", "Mathieu d'Aquin", "Armelle Brun", "Davy Monticolo"], "Categories": "cs.AI cs.SE"}, "abstract": "Knowledge graphs (KGs) have emerged as a prominent data representation and management paradigm. Being usually underpinned by a schema (e.g. an ontology), KGs capture not only factual information but also contextual knowledge. In some tasks, a few KGs established themselves as standard benchmarks. However, recent works outline that relying on a limited collection of datasets is not sufficient to assess the generalization capability of an approach. In some data-sensitive fields such as education or medicine, access to public datasets is even more limited. To remedy the aforementioned issues, we release PyGraft, a Python-based tool that generates highly customized, domain-agnostic schemas and knowledge graphs. The synthesized schemas encompass various RDFS and OWL constructs, while the synthesized KGs emulate the characteristics and scale of real-world KGs. Logical consistency of the generated resources is ultimately ensured by running a description logic (DL) reasoner. By providing a way of generating both a schema and KG in a single pipeline, PyGraft's aim is to empower the generation of a more diverse array of KGs for benchmarking novel approaches in areas such as graph-based machine learning (ML), or more generally KG processing. In graph-based ML in particular, this should foster a more holistic evaluation of model performance and generalization capability, thereby going beyond the limited collection of available benchmarks. PyGraft is available at: https://github.com/nicolas-hbt/pygraft.", "url": "https://arxiv.org/abs/2309.03685"}, {"metadata": {"arXiv": "2309.03773", "Date": "Thu, 07 Sep 2023 15:24:18 ", "Title": "Extending Transductive Knowledge Graph Embedding Models for Inductive Logical Relational Inference", "Authors": ["Thomas Gebhart and John Cobb"], "Categories": "cs.AI cs.IR cs.SI"}, "abstract": "Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting. To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures. These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks. In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting. This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods. In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks.", "url": "https://arxiv.org/abs/2309.03773"}, {"metadata": {"arXiv": "2309.03295", "Date": "Wed, 06 Sep 2023 18:17:47 ", "Title": "Comparative Analysis of Deep-Fake Algorithms", "Authors": ["Nikhil Sontakke", "Sejal Utekar", "Shivansh Rastogi", "Shriraj Sonawane"], "Categories": "cs.CV cs.AI", "Comments": ["7 pages", "4 figures", "2 tables", "Published with International Journal of Computer Science Trends and Technology (IJCST)"], "Journal-ref": "International Journal of Computer Science Trends and Technology (IJCST) V11(4): Page(109-115) Jul - Aug 2023. ISSN: 2347-8578"}, "abstract": "Due to the widespread use of smartphones with high-quality digital cameras and easy access to a wide range of software apps for recording, editing, and sharing videos and images, as well as the deep learning AI platforms, a new phenomenon of 'faking' videos has emerged. Deepfake algorithms can create fake images and videos that are virtually indistinguishable from authentic ones. Therefore, technologies that can detect and assess the integrity of digital visual media are crucial. Deepfakes, also known as deep learning-based fake videos, have become a major concern in recent years due to their ability to manipulate and alter images and videos in a way that is virtually indistinguishable from the original. These deepfake videos can be used for malicious purposes such as spreading misinformation, impersonating individuals, and creating fake news. Deepfake detection technologies use various approaches such as facial recognition, motion analysis, and audio-visual synchronization to identify and flag fake videos. However, the rapid advancement of deepfake technologies has made it increasingly difficult to detect these videos with high accuracy. In this paper, we aim to provide a comprehensive review of the current state of deepfake creation and detection technologies. We examine the various deep learning-based approaches used for creating deepfakes, as well as the techniques used for detecting them. Additionally, we analyze the limitations and challenges of current deepfake detection methods and discuss future research directions in this field. Overall, the paper highlights the importance of continued research and development in deepfake detection technologies in order to combat the negative impact of deepfakes on society and ensure the integrity of digital visual media.", "url": "https://arxiv.org/abs/2309.03295"}, {"metadata": {"arXiv": "2309.03367", "Date": "Wed, 06 Sep 2023 21:20:10 ", "Title": "Self-Supervised Masked Digital Elevation Models Encoding for Low-Resource Downstream Tasks", "Authors": ["Priyam Mazumdar", "Aiman Soliman", "Volodymyr Kindratenko", "Luigi Marini", "Kenton McHenry"], "Categories": "cs.CV cs.AI"}, "abstract": "The lack of quality labeled data is one of the main bottlenecks for training Deep Learning models. As the task increases in complexity, there is a higher penalty for overfitting and unstable learning. The typical paradigm employed today is Self-Supervised learning, where the model attempts to learn from a large corpus of unstructured and unlabeled data and then transfer that knowledge to the required task. Some notable examples of self-supervision in other modalities are BERT for Large Language Models, Wav2Vec for Speech Recognition, and the Masked AutoEncoder for Vision, which all utilize Transformers to solve a masked prediction task. GeoAI is uniquely poised to take advantage of the self-supervised methodology due to the decades of data collected, little of which is precisely and dependably annotated. Our goal is to extract building and road segmentations from Digital Elevation Models (DEM) that provide a detailed topography of the earths surface. The proposed architecture is the Masked Autoencoder pre-trained on ImageNet (with the limitation that there is a large domain discrepancy between ImageNet and DEM) with an UperNet Head for decoding segmentations. We tested this model with 450 and 50 training images only, utilizing roughly 5% and 0.5% of the original data respectively. On the building segmentation task, this model obtains an 82.1% Intersection over Union (IoU) with 450 Images and 69.1% IoU with only 50 images. On the more challenging road detection task the model obtains an 82.7% IoU with 450 images and 73.2% IoU with only 50 images. Any hand-labeled dataset made today about the earths surface will be immediately obsolete due to the constantly changing nature of the landscape. This motivates the clear necessity for data-efficient learners that can be used for a wide variety of downstream tasks.", "url": "https://arxiv.org/abs/2309.03367"}, {"metadata": {"arXiv": "2309.03453", "Date": "Thu, 07 Sep 2023 02:28:04 ", "Title": "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image", "Authors": ["Yuan Liu and Cheng Lin and Zijiao Zeng and Xiaoxiao Long and Lingjie Liu and Taku Komura and Wenping Wang"], "Categories": "cs.CV cs.AI cs.GR", "Comments": ["Project page: https://liuyuan-pal.github.io/SyncDreamer/"]}, "abstract": "In this paper, we present a novel diffusion model called that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation tasks such as novel-view-synthesis, text-to-3D, and image-to-3D.", "url": "https://arxiv.org/abs/2309.03453"}, {"metadata": {"arXiv": "2309.03467", "Date": "Thu, 07 Sep 2023 03:22:59 ", "Title": "Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation", "Authors": ["Zhuqiang Lu", "Kun Hu", "Chaoyue Wang", "Lei Bai", "Zhiyong Wang"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages"], "ACM-class": "I.4.0"}, "abstract": "A 360-degree (omni-directional) image provides an all-encompassing spherical view of a scene. Recently, there has been an increasing interest in synthesising 360-degree images from conventional narrow field of view (NFoV) images captured by digital cameras and smartphones, for providing immersive experiences in various scenarios such as virtual reality. Yet, existing methods typically fall short in synthesizing intricate visual details or ensure the generated images align consistently with user-provided prompts. In this study, autoregressive omni-aware generative network (AOG-Net) is proposed for 360-degree image generation by out-painting an incomplete 360-degree image progressively with NFoV and text guidances joinly or individually. This autoregressive scheme not only allows for deriving finer-grained and text-consistent patterns by dynamically generating and adjusting the process but also offers users greater flexibility to edit their conditions throughout the generation process. A global-local conditioning mechanism is devised to comprehensively formulate the outpainting guidance in each autoregressive step. Text guidances, omni-visual cues, NFoV inputs and omni-geometry are encoded and further formulated with cross-attention based transformers into a global stream and a local stream into a conditioned generative backbone model. As AOG-Net is compatible to leverage large-scale models for the conditional encoder and the generative prior, it enables the generation to use extensive open-vocabulary text guidances. Comprehensive experiments on two commonly used 360-degree image datasets for both indoor and outdoor settings demonstrate the state-of-the-art performance of our proposed method. Our code will be made publicly available.", "url": "https://arxiv.org/abs/2309.03467"}, {"metadata": {"arXiv": "2309.03506", "Date": "Thu, 07 Sep 2023 06:33:30 ", "Title": "Towards Robust Natural-Looking Mammography Lesion Synthesis on Ipsilateral Dual-Views Breast Cancer Analysis", "Authors": ["Thanh-Huy Nguyen", "Quang Hien Kha", "Thai Ngoc Toan Truong", "Ba Thinh Lam", "Ba Hung Ngo", "Quang Vinh Dinh", "and Nguyen Quoc Khanh Le"], "Categories": "cs.CV cs.AI"}, "abstract": "In recent years, many mammographic image analysis methods have been introduced for improving cancer classification tasks. Two major issues of mammogram classification tasks are leveraging multi-view mammographic information and class-imbalance handling. In the first problem, many multi-view methods have been released for concatenating features of two or more views for the training and inference stage. Having said that, most multi-view existing methods are not explainable in the meaning of feature fusion, and treat many views equally for diagnosing. Our work aims to propose a simple but novel method for enhancing examined view (main view) by leveraging low-level feature information from the auxiliary view (ipsilateral view) before learning the high-level feature that contains the cancerous features. For the second issue, we also propose a simple but novel malignant mammogram synthesis framework for upsampling minor class samples. Our easy-to-implement and no-training framework has eliminated the current limitation of the CutMix algorithm which is unreliable synthesized images with random pasted patches, hard-contour problems, and domain shift problems. Our results on VinDr-Mammo and CMMD datasets show the effectiveness of our two new frameworks for both multi-view training and synthesizing mammographic images, outperforming the previous conventional methods in our experimental settings.", "url": "https://arxiv.org/abs/2309.03506"}, {"metadata": {"arXiv": "2309.03549", "Date": "Thu, 07 Sep 2023 08:12:58 ", "Title": "Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation", "Authors": ["Jiaxi Gu", "Shicong Wang", "Haoyu Zhao", "Tianyi Lu", "Xing Zhang", "Zuxuan Wu", "Songcen Xu", "Wei Zhang", "Yu-Gang Jiang", "Hang Xu"], "Categories": "cs.CV cs.AI cs.MM"}, "abstract": "Inspired by the remarkable success of Latent Diffusion Models (LDMs) for image synthesis, we study LDM for text-to-video generation, which is a formidable challenge due to the computational and memory constraints during both model training and inference. A single LDM is usually only capable of generating a very limited number of video frames. Some existing works focus on separate prediction models for generating more video frames, which suffer from additional training cost and frame-level jittering, however. In this paper, we propose a framework called \"Reuse and Diffuse\" dubbed $\\textit{VidRD}$ to produce more frames following the frames already generated by an LDM. Conditioned on an initial video clip with a small number of frames, additional frames are iteratively generated by reusing the original latent features and following the previous diffusion process. Besides, for the autoencoder used for translation between pixel space and latent space, we inject temporal layers into its decoder and fine-tune these layers for higher temporal consistency. We also propose a set of strategies for composing video-text data that involve diverse content from multiple existing datasets including video datasets for action recognition and image-text datasets. Extensive experiments show that our method achieves good results in both quantitative and qualitative evaluations. Our project page is available $\\href{https://anonymous0x233.github.io/ReuseAndDiffuse/}{here}$.", "url": "https://arxiv.org/abs/2309.03549"}, {"metadata": {"arXiv": "2309.03799", "Date": "Thu, 07 Sep 2023 15:51:31 ", "Title": "FisheyePP4AV: A privacy-preserving method for autonomous vehicles on fisheye camera images", "Authors": ["Linh Trinh", "Bach Ha", "Tu Tran"], "Categories": "cs.CV cs.AI"}, "abstract": "In many parts of the world, the use of vast amounts of data collected on public roadways for autonomous driving has increased. In order to detect and anonymize pedestrian faces and nearby car license plates in actual road-driving scenarios, there is an urgent need for effective solutions. As more data is collected, privacy concerns regarding it increase, including but not limited to pedestrian faces and surrounding vehicle license plates. Normal and fisheye cameras are the two common camera types that are typically mounted on collection vehicles. With complex camera distortion models, fisheye camera images were deformed in contrast to regular images. It causes computer vision tasks to perform poorly when using numerous deep learning models. In this work, we pay particular attention to protecting privacy while yet adhering to several laws for fisheye camera photos taken by driverless vehicles. First, we suggest a framework for extracting face and plate identification knowledge from several teacher models. Our second suggestion is to transform both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation. Finally, we run a test using the open-source PP4AV dataset. The experimental findings demonstrated that our model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled. The implementation code is available at our github: https://github.com/khaclinh/FisheyePP4AV.", "url": "https://arxiv.org/abs/2309.03799"}, {"metadata": {"arXiv": "2309.03387", "Date": "Wed, 06 Sep 2023 22:18:16 ", "Title": "Efficient Baselines for Motion Prediction in Autonomous Driving", "Authors": ["Carlos G\\'omez-Hu\\'elamo", "Marcos V. Conde", "Rafael Barea", "Manuel Oca\\~na", "Luis M. Bergasa"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["Journal Paper (under review). arXiv admin note: text overlap with arXiv:2205.13071"]}, "abstract": "Motion Prediction (MP) of multiple surroundings agents is a crucial task in arbitrarily complex environments, from simple robots to Autonomous Driving Stacks (ADS). Current techniques tackle this problem using end-to-end pipelines, where the input data is usually a rendered top-view of the physical information and the past trajectories of the most relevant agents; leveraging this information is a must to obtain optimal performance. In that sense, a reliable ADS must produce reasonable predictions on time. However, despite many approaches use simple ConvNets and LSTMs to obtain the social latent features, State-Of-The-Art (SOTA) models might be too complex for real-time applications when using both sources of information (map and past trajectories) as well as little interpretable, specially considering the physical information. Moreover, the performance of such models highly depends on the number of available inputs for each particular traffic scenario, which are expensive to obtain, particularly, annotated High-Definition (HD) maps. In this work, we propose several efficient baselines for the well-known Argoverse 1 Motion Forecasting Benchmark. We aim to develop compact models using SOTA techniques for MP, including attention mechanisms and GNNs. Our lightweight models use standard social information and interpretable map information such as points from the driveable area and plausible centerlines by means of a novel preprocessing step based on kinematic constraints, in opposition to black-box CNN-based or too-complex graphs methods for map encoding, to generate plausible multimodal trajectories achieving up-to-pair accuracy with less operations and parameters than other SOTA methods. Our code is publicly available at https://github.com/Cram3r95/mapfe4mp .", "url": "https://arxiv.org/abs/2309.03387"}, {"metadata": {"arXiv": "2309.03475", "Date": "Thu, 07 Sep 2023 04:41:02 ", "Title": "InteractionNet: Joint Planning and Prediction for Autonomous Driving with Transformers", "Authors": ["Jiawei Fu", "Yanqing Shen", "Zhiqiang Jian", "Shitao Chen", "Jingmin Xin", "and Nanning Zheng"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted to IROS 2023"]}, "abstract": "Planning and prediction are two important modules of autonomous driving and have experienced tremendous advancement recently. Nevertheless, most existing methods regard planning and prediction as independent and ignore the correlation between them, leading to the lack of consideration for interaction and dynamic changes of traffic scenarios. To address this challenge, we propose InteractionNet, which leverages transformer to share global contextual reasoning among all traffic participants to capture interaction and interconnect planning and prediction to achieve joint. Besides, InteractionNet deploys another transformer to help the model pay extra attention to the perceived region containing critical or unseen vehicles. InteractionNet outperforms other baselines in several benchmarks, especially in terms of safety, which benefits from the joint consideration of planning and forecasting. The code will be available at https://github.com/fujiawei0724/InteractionNet.", "url": "https://arxiv.org/abs/2309.03475"}, {"metadata": {"arXiv": "2309.03758", "Date": "Thu, 07 Sep 2023 15:00:49 ", "Title": "Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning", "Authors": ["Chengmin Zhou", "Xin Lu", "Jiapeng Dai", "Bingding Huang", "Xiaoxu Liu", "and Pasi Fr\\\"anti"], "Categories": "cs.RO cs.AI"}, "abstract": "Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based DSAC faces the overfitting problem in training. Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed. Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training. Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations. The physical robot is also implemented and tested in the real world.", "url": "https://arxiv.org/abs/2309.03758"}, {"metadata": {"arXiv": "2309.03219", "Date": "Thu, 31 Aug 2023 08:14:07 ", "Title": "Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning", "Authors": ["Van Thuy Hoang", "Sang Thanh Nguyen", "Sangmyeong Lee", "Jooho Lee", "Luong Vuong Nguyen", "and O-Joun Lee"], "Categories": "cs.AI cs.CL cs.LG", "Comments": ["16 pages"]}, "abstract": "Knowledge graph (KG) embedding has been used to benefit the diagnosis of animal diseases by analyzing electronic medical records (EMRs), such as notes and veterinary records. However, learning representations to capture entities and relations with literal information in KGs is challenging as the KGs show heterogeneous properties and various types of literal information. Meanwhile, the existing methods mostly aim to preserve graph structures surrounding target nodes without considering different types of literals, which could also carry significant information. In this paper, we propose a knowledge graph embedding model for the efficient diagnosis of animal diseases, which could learn various types of literal information and graph structure and fuse them into unified representations, namely LiteralKG. Specifically, we construct a knowledge graph that is built from EMRs along with literal information collected from various animal hospitals. We then fuse different types of entities and node feature information into unified vector representations through gate networks. Finally, we propose a self-supervised learning task to learn graph structure in pretext tasks and then towards various downstream tasks. Experimental results on link prediction tasks demonstrate that our model outperforms the baselines that consist of state-of-the-art models. The source code is available at https://github.com/NSLab-CUK/LiteralKG.", "url": "https://arxiv.org/abs/2309.03219"}, {"metadata": {"arXiv": "2309.03224", "Date": "Fri, 01 Sep 2023 13:10:54 ", "Title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function", "Authors": ["Haotian Xu"], "Categories": "cs.AI cs.LG", "Comments": ["arXiv admin note: text overlap with arXiv:2109.13582 by other authors"]}, "abstract": "Large language models (LLMs) exhibit impressive language understanding and in-context learning abilities including natural language processing (NLP) tasks and challenging mathematical reasoning. However, due to the lack of process-supervision, applying PLMs to mathematical reasoning tasks often fail to generate correct reasoning steps and final answer even though solutions have high probabilities. To unleash the mathematical reasoning of finetuned-LLMs without any further fineutuning steps, we propose a method to endow LLMs with immediate reaction and delicate reasoning system via Monte Carlo Tree Search(MCTS) and a light energy function to rank the decision steps. In particular, We first re-formalize the finetuned-LLMs to a Residual-based Energy Model~(Residual-EBM) and apply noise contrastive estimation to estimate the parameters of energy function . Then we use MCTS with energy function as path verifier to search the output space and evaluating the reasoning path. Through extensive experiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary capabilities of our method that improve the pass@1 of the finetuned-model without further finetuning or RLHF alignment by a substantial margin.", "url": "https://arxiv.org/abs/2309.03224"}, {"metadata": {"arXiv": "2309.03227", "Date": "Mon, 04 Sep 2023 02:30:19 ", "Title": "Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates", "Authors": ["Yongseung Jegal", "Jaewoong Choi", "Jiho Lee", "Ki-Su Park", "Seyoung Lee", "Janghyeok Yoon"], "Categories": "cs.AI cs.CL cs.LG q-bio.QM"}, "abstract": "Drug repositioning-a promising strategy for discovering new therapeutic uses for existing drugs-has been increasingly explored in the computational science literature using biomedical databases. However, the technological potential of drug repositioning candidates has often been overlooked. This study presents a novel protocol to comprehensively analyse various sources such as pharmaceutical patents and biomedical databases, and identify drug repositioning candidates with both technological potential and scientific evidence. To this end, first, we constructed a scientific biomedical knowledge graph (s-BKG) comprising relationships between drugs, diseases, and genes derived from biomedical databases. Our protocol involves identifying drugs that exhibit limited association with the target disease but are closely located in the s-BKG, as potential drug candidates. We constructed a patent-informed biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information. Finally, we developed a graph embedding protocol to ascertain the structure of the p-BKG, thereby calculating the relevance scores of those candidates with target disease-related patents to evaluate their technological potential. Our case study on Alzheimer's disease demonstrates its efficacy and feasibility, while the quantitative outcomes and systematic methods are expected to bridge the gap between computational discoveries and successful market applications in drug repositioning research.", "url": "https://arxiv.org/abs/2309.03227"}, {"metadata": {"arXiv": "2309.03229", "Date": "Mon, 04 Sep 2023 15:13:56 ", "Title": "Which algorithm to select in sports timetabling?", "Authors": ["David Van Bulck", "Dries Goossens", "Jan-Patrick Clarner", "Angelos Dimitsas", "George H. G. Fonseca", "Carlos Lamas-Fernandez", "Martin Mariusz Lester", "Jaap Pedersen", "Antony E. Phillips", "Roberto Maria Rosati"], "Categories": "cs.AI cs.LG", "Comments": ["This is a non-peer-reviewed working paper"]}, "abstract": "Any sports competition needs a timetable, specifying when and where teams meet each other. The recent International Timetabling Competition (ITC2021) on sports timetabling showed that, although it is possible to develop general algorithms, the performance of each algorithm varies considerably over the problem instances. This paper provides an instance space analysis for sports timetabling, resulting in powerful insights into the strengths and weaknesses of eight state-of-the-art algorithms. Based on machine learning techniques, we propose an algorithm selection system that predicts which algorithm is likely to perform best when given the characteristics of a sports timetabling problem instance. Furthermore, we identify which characteristics are important in making that prediction, providing insights in the performance of the algorithms, and suggestions to further improve them. Finally, we assess the empirical hardness of the instances. Our results are based on large computational experiments involving about 50 years of CPU time on more than 500 newly generated problem instances.", "url": "https://arxiv.org/abs/2309.03229"}, {"metadata": {"arXiv": "2309.03234", "Date": "Tue, 05 Sep 2023 09:46:20 ", "Title": "Natural Example-Based Explainability: a Survey", "Authors": ["Antonin Poch\\'e", "Lucas Hervier", "Mohamed-Chafik Bakkay"], "Categories": "cs.AI cs.LG", "Comments": ["Preprint version of a paper accepted in eXplainable Artificial Intelligence. 1st World Conference on eXplainable Artificial Intelligence", "xAI-2023", "Lisbon", "Portugal"]}, "abstract": "Explainable Artificial Intelligence (XAI) has become increasingly significant for improving the interpretability and trustworthiness of machine learning models. While saliency maps have stolen the show for the last few years in the XAI field, their ability to reflect models' internal processes has been questioned. Although less in the spotlight, example-based XAI methods have continued to improve. It encompasses methods that use examples as explanations for a machine learning model's predictions. This aligns with the psychological mechanisms of human reasoning and makes example-based explanations natural and intuitive for users to understand. Indeed, humans learn and reason by forming mental representations of concepts based on examples. This paper provides an overview of the state-of-the-art in natural example-based XAI, describing the pros and cons of each approach. A \"natural\" example simply means that it is directly drawn from the training data without involving any generative process. The exclusion of methods that require generating examples is justified by the need for plausibility which is in some regards required to gain a user's trust. Consequently, this paper will explore the following family of methods: similar examples, counterfactual and semi-factual, influential instances, prototypes, and concepts. In particular, it will compare their semantic definition, their cognitive impact, and added values. We hope it will encourage and facilitate future work on natural example-based XAI.", "url": "https://arxiv.org/abs/2309.03234"}, {"metadata": {"arXiv": "2309.03251", "Date": "Wed, 06 Sep 2023 17:37:40 ", "Title": "Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning", "Authors": ["Hao Dong", "Pengyang Wang", "Meng Xiao", "Zhiyuan Ning", "Pengfei Wang", "Yuanchun Zhou"], "Categories": "cs.AI cs.LG"}, "abstract": "Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph (KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial task that aims to predict future facts based on historical occurrences. The key challenge lies in uncovering structural dependencies within historical subgraphs and temporal patterns. Most existing approaches model TKGs relying on entity modeling, as nodes in the graph play a crucial role in knowledge representation. However, the real-world scenario often involves an extensive number of entities, with new entities emerging over time. This makes it challenging for entity-dependent methods to cope with extensive volumes of entities, and effectively handling newly emerging entities also becomes a significant challenge. Therefore, we propose Temporal Inductive Path Neural Network (TiPNN), which models historical information in an entity-independent perspective. Specifically, TiPNN adopts a unified graph, namely history temporal graph, to comprehensively capture and encapsulate information from history. Subsequently, we utilize the defined query-aware temporal paths to model historical path information related to queries on history temporal graph for the reasoning. Extensive experiments illustrate that the proposed model not only attains significant performance enhancements but also handles inductive settings, while additionally facilitating the provision of reasoning evidence through history temporal graphs.", "url": "https://arxiv.org/abs/2309.03251"}, {"metadata": {"arXiv": "2309.03468", "Date": "Thu, 07 Sep 2023 03:33:49 ", "Title": "Cross-Image Context Matters for Bongard Problems", "Authors": ["Nikhil Raghuraman", "Adam W. Harley", "Leonidas Guibas"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Main paper: 7 pages", "Appendix: 10 pages", "30 figures. Code: https://github.com/nraghuraman/bongard-context"]}, "abstract": "Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract \"concept\" from a set of positive and negative \"support\" images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, existing methods have only reached 66% accuracy (where chance is 50%). Low accuracy is often attributed to neural nets' lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not incorporate information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because unlike in few-shot learning tasks concerning object classification, the \"key concept\" in a typical Bongard problem can only be distinguished using multiple positives and multiple negatives. We explore a variety of simple methods to take this cross-image context into account, and demonstrate substantial gains over prior methods, leading to new state-of-the-art performance on Bongard-LOGO (75.3%) and Bongard-HOI (72.45%) and strong performance on the original Bongard problem set (60.84%).", "url": "https://arxiv.org/abs/2309.03468"}, {"metadata": {"arXiv": "2309.03659", "Date": "Thu, 07 Sep 2023 11:56:23 ", "Title": "Towards Comparable Knowledge Distillation in Semantic Image Segmentation", "Authors": ["Onno Niemann", "Christopher Vox", "and Thorben Werner"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted by the ECML PKDD 2023 workshop track: Simplification", "Compression", "Efficiency", "and Frugality for Artificial Intelligence (SCEFA). This preprint has not undergone peer review or any post-submission improvements or corrections"]}, "abstract": "Knowledge Distillation (KD) is one proposed solution to large model sizes and slow inference speed in semantic segmentation. In our research we identify 25 proposed distillation loss terms from 14 publications in the last 4 years. Unfortunately, a comparison of terms based on published results is often impossible, because of differences in training configurations. A good illustration of this problem is the comparison of two publications from 2022. Using the same models and dataset, Structural and Statistical Texture Distillation (SSTKD) reports an increase of student mIoU of 4.54 and a final performance of 29.19, while Adaptive Perspective Distillation (APD) only improves student performance by 2.06 percentage points, but achieves a final performance of 39.25. The reason for such extreme differences is often a suboptimal choice of hyperparameters and a resulting underperformance of the student model used as reference point. In our work, we reveal problems of insufficient hyperparameter tuning by showing that distillation improvements of two widely accepted frameworks, SKD and IFVD, vanish when hyperparameters are optimized sufficiently. To improve comparability of future research in the field, we establish a solid baseline for three datasets and two student models and provide extensive information on hyperparameter tuning. We find that only two out of eight techniques can compete with our simple baseline on the ADE20K dataset.", "url": "https://arxiv.org/abs/2309.03659"}, {"metadata": {"arXiv": "2309.03671", "Date": "Thu, 07 Sep 2023 12:19:51 ", "Title": "Dataset Generation and Bonobo Classification from Weakly Labelled Videos", "Authors": ["Pierre-Etienne Martin"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["IntelliSys 2023 paper"]}, "abstract": "This paper presents a bonobo detection and classification pipeline built from the commonly used machine learning methods. Such application is motivated by the need to test bonobos in their enclosure using touch screen devices without human assistance. This work introduces a newly acquired dataset based on bonobo recordings generated semi-automatically. The recordings are weakly labelled and fed to a macaque detector in order to spatially detect the individual present in the video. Handcrafted features coupled with different classification algorithms and deep-learning methods using a ResNet architecture are investigated for bonobo identification. Performance is compared in terms of classification accuracy on the splits of the database using different data separation methods. We demonstrate the importance of data preparation and how a wrong data separation can lead to false good results. Finally, after a meaningful separation of the data, the best classification performance is obtained using a fine-tuned ResNet model and reaches 75% of accuracy.", "url": "https://arxiv.org/abs/2309.03671"}, {"metadata": {"arXiv": "2309.03812", "Date": "Thu, 07 Sep 2023 16:09:06 ", "Title": "AnthroNet: Conditional Generation of Humans via Anthropometrics", "Authors": ["Francesco Picetti", "Shrinath Deshpande", "Jonathan Leban", "Soroosh Shahtalebi", "Jay Patel", "Peifeng Jing", "Chunpu Wang", "Charles Metze III", "Cameron Sun", "Cera Laidlaw", "James Warren", "Kathy Huynh", "River Page", "Jonathan Hogins", "Adam Crespi", "Sujoy Ganguly", "Salehe Erfanian Ebadi"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["AnthroNet's Unity data generator source code is available at: https://unity-technologies.github.io/AnthroNet/"]}, "abstract": "We present a novel human body model formulated by an extensive set of anthropocentric measurements, which is capable of generating a wide range of human body shapes and poses. The proposed model enables direct modeling of specific human identities through a deep generative architecture, which can produce humans in any arbitrary pose. It is the first of its kind to have been trained end-to-end using only synthetically generated data, which not only provides highly accurate human mesh representations but also allows for precise anthropometry of the body. Moreover, using a highly diverse animation library, we articulated our synthetic humans' body and hands to maximize the diversity of the learnable priors for model training. Our model was trained on a dataset of $100k$ procedurally-generated posed human meshes and their corresponding anthropometric measurements. Our synthetic data generator can be used to generate millions of unique human identities and poses for non-commercial academic research purposes.", "url": "https://arxiv.org/abs/2309.03812"}, {"metadata": {"arXiv": "2309.03893", "Date": "Thu, 07 Sep 2023 17:55:01 ", "Title": "DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection", "Authors": ["Manlin Zhang", "Jie Wu", "Yuxi Ren", "Ming Li", "Jie Qin", "Xuefeng Xiao", "Wei Liu", "Rui Wang", "Min Zheng", "Andy J. Ma"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Code and Models are publicly available. Project Page: https://mettyz.github.io/DiffusionEngine"]}, "abstract": "Data is the cornerstone of deep learning. This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection. Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity. To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage. DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner. Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions. Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research. Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning. For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.", "url": "https://arxiv.org/abs/2309.03893"}, {"metadata": {"arXiv": "2309.03239", "Date": "Wed, 06 Sep 2023 02:51:24 ", "Title": "Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference", "Authors": ["Songyu Ke", "Ting Li", "Li Song", "Yanping Sun", "Qintian Sun", "Junbo Zhang", "Yu Zheng"], "Categories": "cs.LG cs.AI", "Comments": ["18 pages; submitted to TKDD;"], "ACM-class": "I.2"}, "abstract": "Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal for effective traffic management, public service, and urban planning. Despite this importance, due to the limitations of urban sensing techniques, the data quality from most sources is inadequate for monitoring crowd flow at each POI. This renders the inference of accurate crowd flow from low-quality data a critical and challenging task. The complexity is heightened by three key factors: 1) \\emph{The scarcity and rarity of labeled data}, 2) \\emph{The intricate spatio-temporal dependencies among POIs}, and 3) \\emph{The myriad correlations between precise crowd flow and GPS reports}. To address these challenges, we recast the crowd flow inference problem as a self-supervised attributed graph representation learning task and introduce a novel \\underline{C}ontrastive \\underline{S}elf-learning framework for \\underline{S}patio-\\underline{T}emporal data (\\model). Our approach initiates with the construction of a spatial adjacency graph founded on the POIs and their respective distances. We then employ a contrastive learning technique to exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped prediction approach to anticipate the representation of the target subgraph from similar instances. Following the pre-training phase, the model is fine-tuned with accurate crowd flow data. Our experiments, conducted on two real-world datasets, demonstrate that the \\model pre-trained on extensive noisy data consistently outperforms models trained from scratch.", "url": "https://arxiv.org/abs/2309.03239"}, {"metadata": {"arXiv": "2309.03241", "Date": "Wed, 06 Sep 2023 06:18:16 ", "Title": "GPT Can Solve Mathematical Problems Without a Calculator", "Authors": ["Zhen Yang", "Ming Ding", "Qingsong Lv", "Zhihuan Jiang", "Zehai He", "Yuyi Guo", "Jinfeng Bai", "Jie Tang"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["26pages,14figures"]}, "abstract": "Previous studies have typically assumed that large language models are unable to accurately perform arithmetic operations, particularly multiplication of >8 digits, and operations involving decimals and fractions, without the use of calculator tools. This paper aims to challenge this misconception. With sufficient training data, a 2 billion-parameter language model can accurately perform multi-digit arithmetic operations with almost 100% accuracy without data leakage, significantly surpassing GPT-4 (whose multi-digit multiplication accuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from GLM-10B on a dataset with additional multi-step arithmetic operations and math problems described in text, achieves similar performance to GPT-4 on a 5,000-samples Chinese math problem test set.", "url": "https://arxiv.org/abs/2309.03241"}, {"metadata": {"arXiv": "2309.03322", "Date": "Wed, 06 Sep 2023 19:05:31 ", "Title": "REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation", "Authors": ["Zheyuan Hu", "Aaron Rovinsky", "Jianlan Luo", "Vikash Kumar", "Abhishek Gupta", "Sergey Levine"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Accepted at CORL 2023. The first two authors contributed equally"]}, "abstract": "Dexterous manipulation tasks involving contact-rich interactions pose a significant challenge for both model-based control systems and imitation learning algorithms. The complexity arises from the need for multi-fingered robotic hands to dynamically establish and break contacts, balance non-prehensile forces, and control large degrees of freedom. Reinforcement learning (RL) offers a promising approach due to its general applicability and capacity to autonomously acquire optimal manipulation strategies. However, its real-world application is often hindered by the necessity to generate a large number of samples, reset the environment, and obtain reward signals. In this work, we introduce an efficient system for learning dexterous manipulation skills with RL to alleviate these challenges. The main idea of our approach is the integration of recent advances in sample-efficient RL and replay buffer bootstrapping. This combination allows us to utilize data from different tasks or objects as a starting point for training new tasks, significantly improving learning efficiency. Additionally, our system completes the real-world training cycle by incorporating learned resets via an imitation-based pickup policy as well as learned reward functions, eliminating the need for manual resets and reward engineering. We demonstrate the benefits of reusing past data as replay buffer initialization for new tasks, for instance, the fast acquisition of intricate manipulation skills in the real world on a four-fingered robotic hand. (Videos: https://sites.google.com/view/reboot-dexterous)", "url": "https://arxiv.org/abs/2309.03322"}, {"metadata": {"arXiv": "2309.03386", "Date": "Wed, 06 Sep 2023 22:16:58 ", "Title": "Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction", "Authors": ["Yang Wu", "Xurui Li", "Xuhong Zhang", "Yangyang Kang", "Changlong Sun and Xiaozhong Liu"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by CIKM 2023 as a long paper"]}, "abstract": "Positive-Unlabeled (PU) Learning is a challenge presented by binary classification problems where there is an abundance of unlabeled data along with a small number of positive data instances, which can be used to address chronic disease screening problem. State-of-the-art PU learning methods have resulted in the development of various risk estimators, yet they neglect the differences among distinct populations. To address this issue, we present a novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed to take into account communities such as different age or income brackets, in tasks of chronic disease prediction. We propose a novel approach for binary decision-making, which hierarchically builds community-based PU models and then aggregates their deliverables. Our method can explicate each PU model on the tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery data augmentation strategy enables sufficient training of the model in individual communities. Additionally, the proposed approach includes an adversarial PU risk estimator to capture hierarchical PU-relationships, and a model fusion network that integrates data from each tree path, resulting in robust binary classification results. We demonstrate the superior performance of PUtree as well as its variants on two benchmarks and a new diabetes-prediction dataset.", "url": "https://arxiv.org/abs/2309.03386"}, {"metadata": {"arXiv": "2309.03409", "Date": "Thu, 07 Sep 2023 00:07:15 ", "Title": "Large Language Models as Optimizers", "Authors": ["Chengrun Yang", "Xuezhi Wang", "Yifeng Lu", "Hanxiao Liu", "Quoc V. Le", "Denny Zhou", "Xinyun Chen"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.", "url": "https://arxiv.org/abs/2309.03409"}, {"metadata": {"arXiv": "2309.03469", "Date": "Thu, 07 Sep 2023 03:34:51 ", "Title": "Fast FixMatch: Faster Semi-Supervised Learning with Curriculum Batch Size", "Authors": ["John Chen", "Chen Dun", "Anastasios Kyrillidis"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Advances in Semi-Supervised Learning (SSL) have almost entirely closed the gap between SSL and Supervised Learning at a fraction of the number of labels. However, recent performance improvements have often come \\textit{at the cost of significantly increased training computation}. To address this, we propose Curriculum Batch Size (CBS), \\textit{an unlabeled batch size curriculum which exploits the natural training dynamics of deep neural networks.} A small unlabeled batch size is used in the beginning of training and is gradually increased to the end of training. A fixed curriculum is used regardless of dataset, model or number of epochs, and reduced training computations is demonstrated on all settings. We apply CBS, strong labeled augmentation, Curriculum Pseudo Labeling (CPL) \\citep{FlexMatch} to FixMatch \\citep{FixMatch} and term the new SSL algorithm Fast FixMatch. We perform an ablation study to show that strong labeled augmentation and/or CPL do not significantly reduce training computations, but, in synergy with CBS, they achieve optimal performance. Fast FixMatch also achieves substantially higher data utilization compared to previous state-of-the-art. Fast FixMatch achieves between $2.1\\times$ - $3.4\\times$ reduced training computations on CIFAR-10 with all but 40, 250 and 4000 labels removed, compared to vanilla FixMatch, while attaining the same cited state-of-the-art error rate \\citep{FixMatch}. Similar results are achieved for CIFAR-100, SVHN and STL-10. Finally, Fast MixMatch achieves between $2.6\\times$ - $3.3\\times$ reduced training computations in federated SSL tasks and online/streaming learning SSL tasks, which further demonstrate the generializbility of Fast MixMatch to different scenarios and tasks.", "url": "https://arxiv.org/abs/2309.03469"}, {"metadata": {"arXiv": "2309.03579", "Date": "Thu, 07 Sep 2023 09:18:12 ", "Title": "DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend", "Authors": ["Ajitesh Srivastava"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "13 figures"]}, "abstract": "Measuring distance or similarity between time-series data is a fundamental aspect of many applications including classification and clustering. Existing measures may fail to capture similarities due to local trends (shapes) and may even produce misleading results. Our goal is to develop a measure that looks for similar trends occurring around similar times and is easily interpretable for researchers in applied domains. This is particularly useful for applications where time-series have a sequence of meaningful local trends that are ordered, such as in epidemics (a surge to an increase to a peak to a decrease). We propose a novel measure, DTW+S, which creates an interpretable \"closeness-preserving\" matrix representation of the time-series, where each column represents local trends, and then it applies Dynamic Time Warping to compute distances between these matrices. We present a theoretical analysis that supports the choice of this representation. We demonstrate the utility of DTW+S in ensemble building and clustering of epidemic curves. We also demonstrate that our approach results in better classification compared to Dynamic Time Warping for a class of datasets, particularly when local trends rather than scale play a decisive role.", "url": "https://arxiv.org/abs/2309.03579"}, {"metadata": {"arXiv": "2309.03581", "Date": "Thu, 07 Sep 2023 09:22:05 ", "Title": "Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning", "Authors": ["Joseph Giovanelli", "Alexander Tornede", "Tanja Tornede", "Marius Lindauer"], "Categories": "cs.LG cs.AI"}, "abstract": "Hyperparameter optimization (HPO) is important to leverage the full potential of machine learning (ML). In practice, users are often interested in multi-objective (MO) problems, i.e., optimizing potentially conflicting objectives, like accuracy and energy consumption. To tackle this, the vast majority of MO-ML algorithms return a Pareto front of non-dominated machine learning models to the user. Optimizing the hyperparameters of such algorithms is non-trivial as evaluating a hyperparameter configuration entails evaluating the quality of the resulting Pareto front. In literature, there are known indicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by quantifying different properties (e.g., volume, proximity to a reference point). However, choosing the indicator that leads to the desired Pareto front might be a hard task for a user. In this paper, we propose a human-centered interactive HPO approach tailored towards multi-objective ML leveraging preference learning to extract desiderata from users that guide the optimization. Instead of relying on the user guessing the most suitable indicator for their needs, our approach automatically learns an appropriate indicator. Concretely, we leverage pairwise comparisons of distinct Pareto fronts to learn such an appropriate quality indicator. Then, we optimize the hyperparameters of the underlying MO-ML algorithm towards this learned indicator using a state-of-the-art HPO approach. In an experimental study targeting the environmental impact of ML, we demonstrate that our approach leads to substantially better Pareto fronts compared to optimizing based on a wrong indicator pre-selected by the user, and performs comparable in the case of an advanced user knowing which indicator to pick.", "url": "https://arxiv.org/abs/2309.03581"}, {"metadata": {"arXiv": "2309.03648", "Date": "Thu, 07 Sep 2023 11:29:16 ", "Title": "Characterizing Lipschitz Stability of GNN for Fairness", "Authors": ["Yaning Jia", "Chunhui Zhang", "Jundong Li", "Chuxu Zhang"], "Categories": "cs.LG cs.AI cs.CY"}, "abstract": "The Lipschitz bound, a technique from robust statistics, can limit the maximum changes in the output concerning the input, taking into account associated irrelevant biased factors. It is an efficient and provable method for examining the output stability of machine learning models without incurring additional computation costs. Recently, Graph Neural Networks (GNNs), which operate on non-Euclidean data, have gained significant attention. However, no previous research has investigated the GNN Lipschitz bounds to shed light on stabilizing model outputs, especially when working on non-Euclidean data with inherent biases. Given the inherent biases in common graph data used for GNN training, it poses a serious challenge to constraining the GNN output perturbations induced by input biases, thereby safeguarding fairness during training. Recently, despite the Lipschitz constant's use in controlling the stability of Euclideanneural networks, the calculation of the precise Lipschitz constant remains elusive for non-Euclidean neural networks like GNNs, especially within fairness contexts. To narrow this gap, we begin with the general GNNs operating on an attributed graph, and formulate a Lipschitz bound to limit the changes in the output regarding biases associated with the input. Additionally, we theoretically analyze how the Lipschitz constant of a GNN model could constrain the output perturbations induced by biases learned from data for fairness training. We experimentally validate the Lipschitz bound's effectiveness in limiting biases of the model output. Finally, from a training dynamics perspective, we demonstrate why the theoretical Lipschitz bound can effectively guide the GNN training to better trade-off between accuracy and fairness.", "url": "https://arxiv.org/abs/2309.03648"}, {"metadata": {"arXiv": "2309.03665", "Date": "Thu, 07 Sep 2023 12:02:00 ", "Title": "How adversarial attacks can disrupt seemingly stable accurate classifiers", "Authors": ["Oliver J. Sutton", "Qinghua Zhou", "Ivan Y. Tyukin", "Alexander N. Gorban", "Alexander Bastounis", "Desmond J. Higham"], "Categories": "cs.LG cs.AI", "Comments": ["11 pages", "8 figures", "additional supplementary materials"]}, "abstract": "Adversarial attacks dramatically change the output of an otherwise accurate learning system using a seemingly inconsequential modification to a piece of input data. Paradoxically, empirical evidence indicates that even systems which are robust to large random perturbations of the input data remain susceptible to small, easily constructed, adversarial perturbations of their inputs. Here, we show that this may be seen as a fundamental feature of classifiers working with high dimensional input data. We introduce a simple generic and generalisable framework for which key behaviours observed in practical systems arise with high probability -- notably the simultaneous susceptibility of the (otherwise accurate) model to easily constructed adversarial attacks, and robustness to random perturbations of the input data. We confirm that the same phenomena are directly observed in practical neural networks trained on standard image classification problems, where even large additive random noise fails to trigger the adversarial instability of the network. A surprising takeaway is that even small margins separating a classifier's decision surface from training and testing data can hide adversarial susceptibility from being detected using randomly sampled perturbations. Counterintuitively, using additive noise during training or testing is therefore inefficient for eradicating or detecting adversarial examples, and more demanding adversarial training is required.", "url": "https://arxiv.org/abs/2309.03665"}, {"metadata": {"arXiv": "2309.03720", "Date": "Thu, 07 Sep 2023 13:52:20 ", "Title": "A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism", "Authors": ["Radek Svoboda", "Sebastian Basterrech", "J\\k{e}drzej Kozal", "Jan Plato\\v{s}", "Micha{\\l} Wo\\'zniak"], "Categories": "cs.LG cs.AI"}, "abstract": "Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.", "url": "https://arxiv.org/abs/2309.03720"}, {"metadata": {"arXiv": "2309.03755", "Date": "Thu, 07 Sep 2023 14:51:42 ", "Title": "TSGBench: Time Series Generation Benchmark", "Authors": ["Yihao Ang", "Qiang Huang", "Yifan Bao", "Anthony K. H. Tung", "Zhiyong Huang"], "Categories": "cs.LG cs.AI cs.DB", "Comments": ["14 pages", "8 figures", "and 4 tables"]}, "abstract": "Synthetic Time Series Generation (TSG) is crucial in a range of applications, including data augmentation, anomaly detection, and privacy preservation. Although significant strides have been made in this field, existing methods exhibit three key limitations: (1) They often benchmark against similar model types, constraining a holistic view of performance capabilities. (2) The use of specialized synthetic and private datasets introduces biases and hampers generalizability. (3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison. To overcome these limitations, we introduce \\textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods. It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods. We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \\textsf{TSGBench}. The results highlight its remarkable efficacy and consistency. More importantly, \\textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method.", "url": "https://arxiv.org/abs/2309.03755"}, {"metadata": {"arXiv": "2309.03779", "Date": "Thu, 07 Sep 2023 15:28:03 ", "Title": "CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning", "Authors": ["Ti Zhou and Man Lin"], "Categories": "cs.LG cs.AI cs.AR cs.OS cs.SY eess.SY", "Comments": ["Accepted to Journal of Systems Architecture"], "Journal-ref": "Journal of Systems Architecture, 2023", "DOI": "10.1016/j.sysarc.2023.102955"}, "abstract": "Small devices are frequently used in IoT and smart-city applications to perform periodic dedicated tasks with soft deadlines. This work focuses on developing methods to derive efficient power-management methods for periodic tasks on small devices. We first study the limitations of the existing Linux built-in methods used in small devices. We illustrate three typical workload/system patterns that are challenging to manage with Linux's built-in solutions. We develop a reinforcement-learning-based technique with temporal encoding to derive an effective DVFS governor even with the presence of the three system patterns. The derived governor uses only one performance counter, the same as the built-in Linux mechanism, and does not require an explicit task model for the workload. We implemented a prototype system on the Nvidia Jetson Nano Board and experimented with it with six applications, including two self-designed and four benchmark applications. Under different deadline constraints, our approach can quickly derive a DVFS governor that can adapt to performance requirements and outperform the built-in Linux approach in energy saving. On Mibench workloads, with performance slack ranging from 0.04 s to 0.4 s, the proposed method can save 3% - 11% more energy compared to Ondemand. AudioReg and FaceReg applications tested have 5%- 14% energy-saving improvement. We have open-sourced the implementation of our in-kernel quantized neural network engine. The codebase can be found at: https://github.com/coladog/tinyagent.", "url": "https://arxiv.org/abs/2309.03779"}, {"metadata": {"arXiv": "2309.03800", "Date": "Thu, 07 Sep 2023 15:52:48 ", "Title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck", "Authors": ["Benjamin L. Edelman", "Surbhi Goel", "Sham Kakade", "Eran Malach", "Cyril Zhang"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.", "url": "https://arxiv.org/abs/2309.03800"}, {"metadata": {"arXiv": "2309.03824", "Date": "Thu, 07 Sep 2023 16:33:42 ", "Title": "Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization", "Authors": ["Habib Hajimolahoseini and Walid Ahmed and Yang Liu"], "Categories": "cs.LG cs.AI"}, "abstract": "Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models", "url": "https://arxiv.org/abs/2309.03824"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <script>
        var papers = [{"id": "2306.02306", "date": "Sun, 4 Jun 2023 09:03:05 GMT", "title": "Cross-CBAM: A Lightweight network for Scene Segmentation\n", "authors": ["Zhengbin Zhang", "Zhenhao Xu", "Xingsheng Gu", "Juan Xiong\n"], "categories": ["cs.CV", "cs.LG", "eess.IV\n"], "abstract": "Scene parsing is a great challenge for real-time semantic segmentation. Although traditional semantic segmentation networks have made remarkable leap-forwards in semantic accuracy, the performance of inference speed is unsatisfactory. Meanwhile, this progress is achieved with fairly large networks and powerful computational resources. However, it is difficult to run extremely large models on edge computing devices with limited computing power, which poses a huge challenge to the real-time semantic segmentation tasks. In this paper, we present the Cross-CBAM network, a novel lightweight network for real-time semantic segmentation. Specifically, a Squeeze-and-Excitation Atrous Spatial Pyramid Pooling Module(SE-ASPP) is proposed to get variable field-of-view and multiscale information. And we propose a Cross Convolutional Block Attention Module(CCBAM), in which a cross-multiply operation is employed in the CCBAM module to make high-level semantic information guide low-level detail information. Different from previous work, these works use attention to focus on the desired information in the backbone. CCBAM uses cross-attention for feature fusion in the FPN structure. Extensive experiments on the Cityscapes dataset and Camvid dataset demonstrate the effectiveness of the proposed Cross-CBAM model by achieving a promising trade-off between segmentation accuracy and inference speed. On the Cityscapes test set, we achieve 73.4% mIoU with a speed of 240.9FPS and 77.2% mIoU with a speed of 88.6FPS on NVIDIA GTX 1080Ti.", "link": "https://arxiv.org/abs/2306.02306"}, {"id": "2306.03066", "date": "Mon, 5 Jun 2023 17:43:50 GMT", "title": "Of Mice and Mates: Automated Classification and Modelling of Mouse\n Behaviour in Groups using a Single Model across Cages\n", "authors": ["Michael P. J. Camilleri and Rasneer S. Bains and Christopher K. I.\n Williams\n"], "categories": ["cs.CV", "cs.LG", "stat.ML\n"], "abstract": "Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.", "link": "https://arxiv.org/abs/2306.03066"}, {"id": "2306.01768", "date": "Sun, 28 May 2023 20:25:20 GMT", "title": "A Quantitative Review on Language Model Efficiency Research\n", "authors": ["Meng Jiang", "Hy Dang", "Lingbo Tong\n"], "categories": ["cs.LG", "cs.CL\nComments:", "29", "pages,", "24", "tables\n"], "abstract": "Language models (LMs) are being scaled and becoming powerful. Improving their efficiency is one of the core research topics in neural information processing systems. Tay et al. (2022) provided a comprehensive overview of efficient Transformers that have become an indispensable staple in the field of NLP. However, in the section of \"On Evaluation\", they left an open question \"which fundamental efficient Transformer one should consider,\" answered by \"still a mystery\" because \"many research papers select their own benchmarks.\" Unfortunately, there was not quantitative analysis about the performances of Transformers on any benchmarks. Moreover, state space models (SSMs) have demonstrated their abilities of modeling long-range sequences with non-attention mechanisms, which were not discussed in the prior review. This article makes a meta analysis on the results from a set of papers on efficient Transformers as well as those on SSMs. It provides a quantitative review on LM efficiency research and gives suggestions for future research.", "link": "https://arxiv.org/abs/2306.01768"}, {"id": "2306.01804", "date": "Thu, 1 Jun 2023 17:59:12 GMT", "title": "Extracting Reward Functions from Diffusion Models\n", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\\~ao F. Henriques\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Diffusion models have achieved remarkable results in image generation, and have similarly been used to learn high-performing policies in sequential decision-making tasks. Decision-making diffusion models can be trained on lower-quality data, and then be steered with a reward function to generate near-optimal trajectories. We consider the problem of extracting a reward function by comparing a decision-making diffusion model that models low-reward behavior and one that models high-reward behavior; a setting related to inverse reinforcement learning. We first define the notion of a relative reward function of two diffusion models and show conditions under which it exists and is unique. We then devise a practical learning algorithm for extracting it by aligning the gradients of a reward function -- parametrized by a neural network -- to the difference in outputs of both diffusion models. Our method finds correct reward functions in navigation environments, and we demonstrate that steering the base model with the learned reward functions results in significantly increased performance in standard locomotion benchmarks. Finally, we demonstrate that our approach generalizes beyond sequential decision-making by learning a reward-like function from two large-scale image generation diffusion models. The extracted reward function successfully assigns lower rewards to harmful images.", "link": "https://arxiv.org/abs/2306.01804"}, {"id": "2306.01811", "date": "Fri, 2 Jun 2023 07:00:42 GMT", "title": "DVFO: Dynamic Voltage, Frequency Scaling and Workload Offloading for DNN\n Edge Inference\n", "authors": ["Ziyang Zhang", "Yang Zhao", "Huan Li", "and Jie Liu\n"], "categories": ["cs.LG", "cs.DC", "cs.OS\n"], "abstract": "Due to edge device resource constraints and different characteristics of deep neural network (DNN) models, it is a big challenge to optimize DNN inference performance in terms of energy consumption and inference latency on edge devices. In addition to the dynamic voltage frequency scaling (DVFS) technique, the edge-cloud architecture provides a collaborative approach to efficient DNN inference. However, current edge-cloud collaborative inference methods have not optimized various compute resources on edge devices. Thus, we propose DVFO, a novel DVFS-enabled edge-cloud collaborative inference framework, which jointly optimize DVFS and offloading parameters via deep reinforcement learning (DRL). Specifically, DVFO automatically co-optimizes 1) CPU, GPU and memory frequencies of edge devices, and 2) feature maps to be offloaded to cloud servers. In addition, it leverages a thinking-while-moving concurrent mechanism to accelerate the DRL learning process, and a spatialchannel attention mechanism to extract DNN feature maps of secondary importance for workload offloading. This approach improves energy efficiency and inference latency for different DNN models under various edge-cloud network conditions. Experimental results on different datasets show that DVFO reduces the average energy consumption by 33% compared to state-of-the-art schemes. Moreover, DVFO achieves up to 54% end-to-end inference latency reduction.", "link": "https://arxiv.org/abs/2306.01811"}, {"id": "2306.01813", "date": "Fri, 2 Jun 2023 09:04:45 GMT", "title": "Learning the effective order of a hypergraph dynamical system\n", "authors": ["Leonie Neuh\\\"auser", "Michael Scholkemper", "Francesco Tudisco", "Michael T.\n Schaub\n"], "categories": ["cs.LG", "cs.SI", "physics.soc-ph\n"], "abstract": "Dynamical systems on hypergraphs can display a rich set of behaviours not observable for systems with pairwise interactions. Given a distributed dynamical system with a putative hypergraph structure, an interesting question is thus how much of this hypergraph structure is actually necessary to faithfully replicate the observed dynamical behaviour. To answer this question, we propose a method to determine the minimum order of a hypergraph necessary to approximate the corresponding dynamics accurately. Specifically, we develop an analytical framework that allows us to determine this order when the type of dynamics is known. We utilize these ideas in conjunction with a hypergraph neural network to directly learn the dynamics itself and the resulting order of the hypergraph from both synthetic and real data sets consisting of observed system trajectories.", "link": "https://arxiv.org/abs/2306.01813"}, {"id": "2306.01816", "date": "Fri, 2 Jun 2023 11:35:58 GMT", "title": "Prediction of Citrus Diseases Using Machine Learning And Deep Learning:\n Classifier, Models SLR\n", "authors": ["Muhammad Shoaib Farooq", "Abdullah Mehboob\n"], "categories": ["cs.LG", "cs.AI\nComments:", "13", "pages,", "9", "figures\n"], "abstract": "Citrus diseases have been major issues for citrus growing worldwide for many years they can lead significantly reduce fruit quality. the most harmful citrus diseases are citrus canker, citrus greening, citrus black spot, citrus leaf miner which can have significant economic losses of citrus industry in worldwide prevention and management strategies like chemical treatments. Citrus diseases existing in all over the world where citrus is growing its effects the citrus tree root, citrus tree leaf, citrus tree orange etc. Existing of citrus diseases is highly impact on economic factor that can also produce low quality fruits and increased the rate for diseases management. Sanitation and routine monitoring can be effective in managing certain citrus diseases, but others may require more intensive treatments like chemical or biological control methods.", "link": "https://arxiv.org/abs/2306.01816"}, {"id": "2306.01817", "date": "Fri, 2 Jun 2023 11:46:58 GMT", "title": "Heart Diseases Prediction Using Block-chain and Machine Learning\n", "authors": ["Muhammad Shoaib Farooq", "Kiran Amjad\n"], "categories": ["cs.LG", "cs.AI\nComments:", "page", "23,", "figurse", "19\n"], "abstract": "Most people around the globe are dying due to heart disease. The main reason behind the rapid increase in the death rate due to heart disease is that there is no infrastructure developed for the healthcare department that can provide a secure way of data storage and transmission. Due to redundancy in the patient data, it is difficult for cardiac Professionals to predict the disease early on. This rapid increase in the death rate due to heart disease can be controlled by monitoring and eliminating some of the key attributes in the early stages such as blood pressure, cholesterol level, body weight, and addiction to smoking. Patient data can be monitored by cardiac Professionals (Cp) by using the advanced framework in the healthcare departments. Blockchain is the world's most reliable provider. The use of advanced systems in the healthcare departments providing new ways of dealing with diseases has been developed as well. In this article Machine Learning (ML) algorithm known as a sine-cosine weighted k-nearest neighbor (SCA-WKNN) is used for predicting the Hearth disease with the maximum accuracy among the existing approaches. Blockchain technology has been used in the research to secure the data throughout the session and can give more accurate results using this technology. The performance of the system can be improved by using this algorithm and the dataset proposed has been improved by using different resources as well.", "link": "https://arxiv.org/abs/2306.01817"}, {"id": "2306.01854", "date": "Fri, 2 Jun 2023 18:16:35 GMT", "title": "Reinforcement Learning with General Utilities: Simpler Variance\n Reduction and Large State-Action Space\n", "authors": ["Anas Barakat", "Ilyas Fatkhullin", "Niao He\n"], "categories": ["cs.LG", "math.OC\nComments:", "48", "pages,", "2", "figures,", "ICML", "2023,", "this", "paper", "was", "initially", "submitted", "in\n", "January", "26th", "2023\nJournal-ref:", "Proceedings", "of", "the", "Fortieth", "International", "Conference", "on", "Machine\n", "Learning", "(ICML", "2023)\n"], "abstract": "We consider the reinforcement learning (RL) problem with general utilities which consists in maximizing a function of the state-action occupancy measure. Beyond the standard cumulative reward RL setting, this problem includes as particular cases constrained RL, pure exploration and learning from demonstrations among others. For this problem, we propose a simpler single-loop parameter-free normalized policy gradient algorithm. Implementing a recursive momentum variance reduction mechanism, our algorithm achieves $\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ and $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ sample complexities for $\\epsilon$-first-order stationarity and $\\epsilon$-global optimality respectively, under adequate assumptions. We further address the setting of large finite state action spaces via linear function approximation of the occupancy measure and show a $\\tilde{\\mathcal{O}}(\\epsilon^{-4})$ sample complexity for a simple policy gradient method with a linear regression subroutine.", "link": "https://arxiv.org/abs/2306.01854"}, {"id": "2306.01864", "date": "Fri, 2 Jun 2023 18:41:39 GMT", "title": "Discovering COVID-19 Coughing and Breathing Patterns from Unlabeled Data\n Using Contrastive Learning with Varying Pre-Training Domains\n", "authors": ["Jinjin Cai", "Sudip Vhaduri", "and Xiao Luo\n"], "categories": ["cs.LG", "cs.SD", "eess.AS\nComments:", "Accepted", "by", "Proceedings", "of", "INTERSPEECH", "2023\nJournal-ref:", "Proceedings", "of", "INTERSPEECH", "2023\n"], "abstract": "Rapid discovery of new diseases, such as COVID-19 can enable a timely epidemic response, preventing the large-scale spread and protecting public health. However, limited research efforts have been taken on this problem. In this paper, we propose a contrastive learning-based modeling approach for COVID-19 coughing and breathing pattern discovery from non-COVID coughs. To validate our models, extensive experiments have been conducted using four large audio datasets and one image dataset. We further explore the effects of different factors, such as domain relevance and augmentation order on the pre-trained models. Our results show that the proposed model can effectively distinguish COVID-19 coughing and breathing from unlabeled data and labeled non-COVID coughs with an accuracy of up to 0.81 and 0.86, respectively. Findings from this work will guide future research to detect an outbreak of a new disease early.", "link": "https://arxiv.org/abs/2306.01864"}, {"id": "2306.01870", "date": "Fri, 2 Jun 2023 18:57:24 GMT", "title": "Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks\n", "authors": ["Zachary Robertson", "Oluwasanmi Koyejo\n"], "categories": ["cs.LG", "stat.ML\nComments:", "8", "pages,", "2", "figures\n"], "abstract": "In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized two-layer linear networks trained with FA converge to minimum-norm solutions. The implications of our findings offer avenues for developing more efficient and biologically plausible alternatives to backpropagation through an understanding of the principles governing learning dynamics in deep networks.", "link": "https://arxiv.org/abs/2306.01870"}, {"id": "2306.01885", "date": "Fri, 2 Jun 2023 19:37:38 GMT", "title": "Multifunctionality in a Connectome-Based Reservoir Computer\n", "authors": ["Jacob Morra", "Andrew Flynn", "Andreas Amann", "Mark Daley\n"], "categories": ["cs.LG", "cs.NE\nComments:", "6", "pages,", "6", "figures\n"], "abstract": "Multifunctionality describes the capacity for a neural network to perform multiple mutually exclusive tasks without altering its network connections; and is an emerging area of interest in the reservoir computing machine learning paradigm. Multifunctionality has been observed in the brains of humans and other animals: particularly, in the lateral horn of the fruit fly. In this work, we transplant the connectome of the fruit fly lateral horn to a reservoir computer (RC), and investigate the extent to which this 'fruit fly RC' (FFRC) exhibits multifunctionality using the 'seeing double' problem as a benchmark test. We furthermore explore the dynamics of how this FFRC achieves multifunctionality while varying the network's spectral radius. Compared to the widely-used Erd\\\"os-Renyi Reservoir Computer (ERRC), we report that the FFRC exhibits a greater capacity for multifunctionality; is multifunctional across a broader hyperparameter range; and solves the seeing double problem far beyond the previously observed spectral radius limit, wherein the ERRC's dynamics become chaotic.", "link": "https://arxiv.org/abs/2306.01885"}, {"id": "2306.01890", "date": "Fri, 2 Jun 2023 19:51:48 GMT", "title": "Kernel Metric Learning for Clustering Mixed-type Data\n", "authors": ["Jesse S. Ghashti and John R. J. Thompson\n"], "categories": ["cs.LG", "stat.CO", "stat.ME", "stat.OT\nComments:", "23", "pages,", "5", "tables,", "2", "figures\nMSC-class:", "62G07,", "65D10\nACM-class:", "I.5.3;", "G.3;", "I.6.6\n"], "abstract": "Distance-based clustering and classification are widely used in various fields to group mixed numeric and categorical data. A predefined distance measurement is used to cluster data points based on their dissimilarity. While there exist numerous distance-based measures for data with pure numerical attributes and several ordered and unordered categorical metrics, an optimal distance for mixed-type data is an open problem. Many metrics convert numerical attributes to categorical ones or vice versa. They handle the data points as a single attribute type or calculate a distance between each attribute separately and add them up. We propose a metric that uses mixed kernels to measure dissimilarity, with cross-validated optimal kernel bandwidths. Our approach improves clustering accuracy when utilized for existing distance-based clustering algorithms on simulated and real-world datasets containing pure continuous, categorical, and mixed-type data.", "link": "https://arxiv.org/abs/2306.01890"}, {"id": "2306.01893", "date": "Fri, 2 Jun 2023 19:58:14 GMT", "title": "Hierarchical Quadratic Random Forest Classifier\n", "authors": ["Faezeh Fallah\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "In this paper, we proposed a hierarchical quadratic random forest classifier for classifying multiresolution samples extracted from multichannel data. This forest incorporated a penalized multivariate linear discriminant in each of its decision nodes and processed squared features to realize quadratic decision boundaries in the original feature space. The penalized discriminant was based on a multiclass sparse discriminant analysis and the penalization was based on a group Lasso regularizer which was an intermediate between the Lasso and the ridge regularizer. The classification probabilities estimated by this forest and the features learned by its decision nodes could be used standalone or foster graph-based classifiers.", "link": "https://arxiv.org/abs/2306.01893"}, {"id": "2306.01937", "date": "Fri, 2 Jun 2023 22:39:14 GMT", "title": "LIC-GAN: Language Information Conditioned Graph Generative GAN Model\n", "authors": ["Robert Lo", "Arnhav Datar", "Abishek Sridhar\n"], "categories": ["cs.LG", "cs.AI\nComments:", "15", "pages,", "8", "figures\n"], "abstract": "Deep generative models for Natural Language data offer a new angle on the problem of graph synthesis: by optimizing differentiable models that directly generate graphs, it is possible to side-step expensive search procedures in the discrete and vast space of possible graphs. We introduce LIC-GAN, an implicit, likelihood-free generative model for small graphs that circumvents the need for expensive graph matching procedures. Our method takes as input a natural language query and using a combination of language modelling and Generative Adversarial Networks (GANs) and returns a graph that closely matches the description of the query. We combine our approach with a reward network to further enhance the graph generation with desired properties. Our experiments, show that LIC-GAN does well on metrics such as PropMatch and Closeness getting scores of 0.36 and 0.48. We also show that LIC-GAN performs as good as ChatGPT, with ChatGPT getting scores of 0.40 and 0.42. We also conduct a few experiments to demonstrate the robustness of our method, while also highlighting a few interesting caveats of the model.", "link": "https://arxiv.org/abs/2306.01937"}, {"id": "2306.01958", "date": "Fri, 2 Jun 2023 23:36:49 GMT", "title": "A Survey on Explainability of Graph Neural Networks\n", "authors": ["Jaykumar Kakkad", "Jaspal Jannu", "Kartik Sharma", "Charu Aggarwal", "Sourav\n Medya\n"], "categories": ["cs.LG", "cs.AI\nComments:", "submitted", "to", "Bulletin", "of", "the", "IEEE", "Computer", "Society", "Technical\n", "Committee", "on", "Data", "Engineering\n"], "abstract": "Graph neural networks (GNNs) are powerful graph-based deep-learning models that have gained significant attention and demonstrated remarkable performance in various domains, including natural language processing, drug discovery, and recommendation systems. However, combining feature information and combinatorial graph structures has led to complex non-linear GNN models. Consequently, this has increased the challenges of understanding the workings of GNNs and the underlying reasons behind their predictions. To address this, numerous explainability methods have been proposed to shed light on the inner mechanism of the GNNs. Explainable GNNs improve their security and enhance trust in their recommendations. This survey aims to provide a comprehensive overview of the existing explainability techniques for GNNs. We create a novel taxonomy and hierarchy to categorize these methods based on their objective and methodology. We also discuss the strengths, limitations, and application scenarios of each category. Furthermore, we highlight the key evaluation metrics and datasets commonly used to assess the explainability of GNNs. This survey aims to assist researchers and practitioners in understanding the existing landscape of explainability methods, identifying gaps, and fostering further advancements in interpretable graph-based machine learning.", "link": "https://arxiv.org/abs/2306.01958"}, {"id": "2306.01992", "date": "Sat, 3 Jun 2023 03:41:33 GMT", "title": "On Size-Independent Sample Complexity of ReLU Networks\n", "authors": ["Mark Sellke\n"], "categories": ["cs.LG", "stat.ML\nComments:", "4", "pages\n"], "abstract": "We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.", "link": "https://arxiv.org/abs/2306.01992"}, {"id": "2306.01993", "date": "Sat, 3 Jun 2023 03:42:30 GMT", "title": "Provable benefits of score matching\n", "authors": ["Chirag Pabbaraju", "Dhruv Rohatgi", "Anish Sevekari", "Holden Lee", "Ankur\n Moitra", "Andrej Risteski\n"], "categories": ["cs.LG", "cs.DS", "stat.ML\nComments:", "25", "Pages\n"], "abstract": "Score matching is an alternative to maximum likelihood (ML) for estimating a probability distribution parametrized up to a constant of proportionality. By fitting the ''score'' of the distribution, it sidesteps the need to compute this constant of proportionality (which is often intractable). While score matching and variants thereof are popular in practice, precise theoretical understanding of the benefits and tradeoffs with maximum likelihood -- both computational and statistical -- are not well understood. In this work, we give the first example of a natural exponential family of distributions such that the score matching loss is computationally efficient to optimize, and has a comparable statistical efficiency to ML, while the ML loss is intractable to optimize using a gradient-based method. The family consists of exponentials of polynomials of fixed degree, and our result can be viewed as a continuous analogue of recent developments in the discrete setting. Precisely, we show: (1) Designing a zeroth-order or first-order oracle for optimizing the maximum likelihood loss is NP-hard. (2) Maximum likelihood has a statistical efficiency polynomial in the ambient dimension and the radius of the parameters of the family. (3) Minimizing the score matching loss is both computationally and statistically efficient, with complexity polynomial in the ambient dimension.", "link": "https://arxiv.org/abs/2306.01993"}, {"id": "2306.01995", "date": "Sat, 3 Jun 2023 04:00:47 GMT", "title": "Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits\n", "authors": ["Xiao-Yue Gong", "Mark Sellke\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "We study pure exploration with infinitely many bandit arms generated i.i.d. from an unknown distribution. Our goal is to efficiently select a single high quality arm whose average reward is, with probability $1-\\delta$, within $\\varepsilon$ of being among the top $\\eta$-fraction of arms; this is a natural adaptation of the classical PAC guarantee for infinite action sets. We consider both the fixed confidence and fixed budget settings, aiming respectively for minimal expected and fixed sample complexity. For fixed confidence, we give an algorithm with expected sample complexity $O\\left(\\frac{\\log (1/\\eta)\\log (1/\\delta)}{\\eta\\varepsilon^2}\\right)$. This is optimal except for the $\\log (1/\\eta)$ factor, and the $\\delta$-dependence closes a quadratic gap in the literature. For fixed budget, we show the asymptotically optimal sample complexity as $\\delta\\to 0$ is $c^{-1}\\log(1/\\delta)\\big(\\log\\log(1/\\delta)\\big)^2$ to leading order. Equivalently, the optimal failure probability given exactly $N$ samples decays as $\\exp\\big(-cN/\\log^2 N\\big)$, up to a factor $1\\pm o_N(1)$ inside the exponent. The constant $c$ depends explicitly on the problem parameters (including the unknown arm distribution) through a certain Fisher information distance. Even the strictly super-linear dependence on $\\log(1/\\delta)$ was not known and resolves a question of Grossman and Moshkovitz (FOCS 2016, SIAM Journal on Computing 2020).", "link": "https://arxiv.org/abs/2306.01995"}, {"id": "2306.01999", "date": "Sat, 3 Jun 2023 04:23:49 GMT", "title": "GAT-GAN : A Graph-Attention-based Time-Series Generative Adversarial\n Network\n", "authors": ["Srikrishna Iyer and Teng Teck Hou\n"], "categories": ["cs.LG", "cs.AI\nComments:", "9", "pages,", "1", "figure,", "3", "tables,", "preprint", "under", "review\n"], "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful tool for generating realistic synthetic data. However, traditional GANs often struggle to capture complex relationships between features which results in generation of unrealistic multivariate time-series data. In this paper, we propose a Graph-Attention-based Generative Adversarial Network (GAT-GAN) that explicitly includes two graph-attention layers, one that learns temporal dependencies while the other captures spatial relationships. Unlike RNN-based GANs that struggle with modeling long sequences of data points, GAT-GAN generates long time-series data of high fidelity using an adversarially trained autoencoder architecture. Our empirical evaluations, using a variety of real-time-series datasets, show that our framework consistently outperforms state-of-the-art benchmarks based on \\emph{Frechet Transformer distance} and \\emph{Predictive score}, that characterizes (\\emph{Fidelity, Diversity}) and \\emph{predictive performance} respectively. Moreover, we introduce a Frechet Inception distance-like (FID) metric for time-series data called Frechet Transformer distance (FTD) score (lower is better), to evaluate the quality and variety of generated data. We also found that low FTD scores correspond to the best-performing downstream predictive experiments. Hence, FTD scores can be used as a standardized metric to evaluate synthetic time-series data.", "link": "https://arxiv.org/abs/2306.01999"}, {"id": "2306.02049", "date": "Sat, 3 Jun 2023 08:24:53 GMT", "title": "LambdaBeam: Neural Program Search with Higher-Order Functions and\n Lambdas\n", "authors": ["Kensen Shi", "Hanjun Dai", "Wen-Ding Li", "Kevin Ellis", "Charles Sutton\n"], "categories": ["cs.LG", "cs.PL\n"], "abstract": "Search is an important technique in program synthesis that allows for adaptive strategies such as focusing on particular search directions based on execution results. Several prior works have demonstrated that neural models are effective at guiding program synthesis searches. However, a common drawback of those approaches is the inability to handle iterative loops, higher-order functions, or lambda functions, thus limiting prior neural searches from synthesizing longer and more general programs. We address this gap by designing a search algorithm called LambdaBeam that can construct arbitrary lambda functions that compose operations within a given DSL. We create semantic vector representations of the execution behavior of the lambda functions and train a neural policy network to choose which lambdas to construct during search, and pass them as arguments to higher-order functions to perform looping computations. Our experiments show that LambdaBeam outperforms neural, symbolic, and LLM-based techniques in an integer list manipulation domain.", "link": "https://arxiv.org/abs/2306.02049"}, {"id": "2306.02050", "date": "Sat, 3 Jun 2023 08:32:35 GMT", "title": "Provable Dynamic Fusion for Low-Quality Multimodal Data\n", "authors": ["Qingyang Zhang", "Haitao Wu", "Changqing Zhang", "Qinghua Hu", "Huazhu Fu,\n Joey Tianyi Zhou", "Xi Peng\n"], "categories": ["cs.LG", "cs.CV\nComments:", "Accepted", "by", "ICML", "2023\n"], "abstract": "The inherent challenge of multimodal fusion is to precisely capture the cross-modal correlation and flexibly conduct cross-modal interaction. To fully release the value of each modality and mitigate the influence of low-quality multimodal data, dynamic multimodal fusion emerges as a promising learning paradigm. Despite its widespread use, theoretical justifications in this field are still notably lacking. Can we design a provably robust multimodal fusion method? This paper provides theoretical understandings to answer this question under a most popular multimodal fusion framework from the generalization perspective. We proceed to reveal that several uncertainty estimation solutions are naturally available to achieve robust multimodal fusion. Then a novel multimodal fusion framework termed Quality-aware Multimodal Fusion (QMF) is proposed, which can improve the performance in terms of classification accuracy and model robustness. Extensive experimental results on multiple benchmarks can support our findings.", "link": "https://arxiv.org/abs/2306.02050"}, {"id": "2306.02066", "date": "Sat, 3 Jun 2023 09:43:59 GMT", "title": "Variational Gaussian Process Diffusion Processes\n", "authors": ["Prakhar Verma", "Vincent Adam", "Arno Solin\n"], "categories": ["cs.LG", "stat.ML\nComments:", "26", "pages,", "11", "figures\n"], "abstract": "Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.", "link": "https://arxiv.org/abs/2306.02066"}, {"id": "2306.02081", "date": "Sat, 3 Jun 2023 11:07:18 GMT", "title": "Message-passing selection: Towards interpretable GNNs for graph\n classification\n", "authors": ["Wenda Li", "Kaixuan Chen", "Shunyu Liu", "Wenjie Huang", "Haofei Zhang,\n Yingjie Tian", "Yun Su", "Mingli Song\n"], "categories": ["cs.LG", "cs.AI\nComments:", "6", "pages,", "1", "figures\n"], "abstract": "In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection scheme(MSScheme) to select the critical paths for GNNs' message aggregations, which aims at reaching the self-explaination instead of post-hoc explanations. In detail, the elaborate MSScheme is designed to calculate weight factors of message aggregation paths by considering the vanilla structure and node embedding components, where the structure base aims at weight factors among node-induced substructures; on the other hand, the node embedding base focuses on weight factors via node embeddings obtained by one-layer GNN.Finally, we demonstrate the effectiveness of our approach on graph classification benchmarks.", "link": "https://arxiv.org/abs/2306.02081"}, {"id": "2306.02090", "date": "Sat, 3 Jun 2023 11:45:16 GMT", "title": "Deep Classifier Mimicry without Data Access\n", "authors": ["Steven Braun", "Martin Mundt", "Kristian Kersting\n"], "categories": ["cs.LG", "cs.AI\nComments:", "10", "pages", "main,", "4", "figures,", "2", "tables,", "2", "pages", "appendix\n"], "abstract": "Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.", "link": "https://arxiv.org/abs/2306.02090"}, {"id": "2306.02117", "date": "Sat, 3 Jun 2023 14:12:31 GMT", "title": "Scaling Up, Scaling Deep: Blockwise Graph Contrastive Learning\n", "authors": ["Jintang Li", "Wangbin Sun", "Ruofan Wu", "Yuchang Zhu", "Liang Chen", "Zibin\n Zheng\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Preprint;", "Code", "is", "available", "at\n", "https://github.com/EdisonLeeeee/BlockGCL\n"], "abstract": "Oversmoothing is a common phenomenon in graph neural networks (GNNs), in which an increase in the network depth leads to a deterioration in their performance. Graph contrastive learning (GCL) is emerging as a promising way of leveraging vast unlabeled graph data. As a marriage between GNNs and contrastive learning, it remains unclear whether GCL inherits the same oversmoothing defect from GNNs. This work undertakes a fundamental analysis of GCL from the perspective of oversmoothing on the first hand. We demonstrate empirically that increasing network depth in GCL also leads to oversmoothing in their deep representations, and surprisingly, the shallow ones. We refer to this phenomenon in GCL as long-range starvation', wherein lower layers in deep networks suffer from degradation due to the lack of sufficient guidance from supervision (e.g., loss computing). Based on our findings, we present BlockGCL, a remarkably simple yet effective blockwise training framework to prevent GCL from notorious oversmoothing. Without bells and whistles, BlockGCL consistently improves robustness and stability for well-established GCL methods with increasing numbers of layers on real-world graph benchmarks. We believe our work will provide insights for future improvements of scalable and deep GCL frameworks.", "link": "https://arxiv.org/abs/2306.02117"}, {"id": "2306.02192", "date": "Sat, 3 Jun 2023 20:34:14 GMT", "title": "Correcting auto-differentiation in neural-ODE training\n", "authors": ["Yewei Xu", "Shi Chen", "Qin Li and Stephen J. Wright\n"], "categories": ["cs.LG", "cs.NA", "math.NA\n"], "abstract": "Does the use of auto-differentiation yield reasonable updates to deep neural networks that represent neural ODEs? Through mathematical analysis and numerical evidence, we find that when the neural network employs high-order forms to approximate the underlying ODE flows (such as the Linear Multistep Method (LMM)), brute-force computation using auto-differentiation often produces non-converging artificial oscillations. In the case of Leapfrog, we propose a straightforward post-processing technique that effectively eliminates these oscillations, rectifies the gradient computation and thus respects the updates of the underlying flow.", "link": "https://arxiv.org/abs/2306.02192"}, {"id": "2306.02208", "date": "Sat, 3 Jun 2023 22:41:44 GMT", "title": "Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits\n", "authors": ["Chen Wang\n"], "categories": ["cs.LG", "cs.DS", "stat.ML\nComments:", "ICML", "2023\n"], "abstract": "Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively in recent years. In the single-pass setting with $K$ arms and $T$ trials, a regret lower bound of $\\Omega(T^{2/3})$ has been proved for any algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al. [COLT'22]). On the other hand, however, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\\log^{1/3}(T))$, which is achieved by the streaming implementation of the simple uniform exploration. The $O(K^{1/3}\\log^{1/3}(T))$ gap leaves the open question of the tight regret bound in the single-pass MABs with sublinear arm memory. In this paper, we answer this open problem and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which matches the uniform exploration regret up to a logarithm factor in $T$. We then show that the $\\log^{1/3}(T)$ factor is not necessary, and we can achieve $O(K^{1/3}T^{2/3})$ regret by finding an $\\varepsilon$-best arm and committing to it in the rest of the trials. For regret minimization with high constant probability, we can apply the single-memory $\\varepsilon$-best arm algorithms in Jin et al. [ICML'21] to obtain the optimal bound. Furthermore, for the expected regret minimization, we design an algorithm with a single-arm memory that achieves $O(K^{1/3} T^{2/3}\\log(K))$ regret, and an algorithm with $O(\\log^{*}(n))$-memory with the optimal $O(K^{1/3} T^{2/3})$ regret following the $\\varepsilon$-best arm algorithm in Assadi and Wang [STOC'20]. We further tested the empirical performances of our algorithms. The simulation results show that the proposed algorithms consistently outperform the benchmark uniform exploration algorithm by a large margin, and on occasion, reduce the regret by up to 70%.", "link": "https://arxiv.org/abs/2306.02208"}, {"id": "2306.02210", "date": "Sat, 3 Jun 2023 22:57:59 GMT", "title": "GPT-FL: Generative Pre-trained Model-Assisted Federated Learning\n", "authors": ["Tuo Zhang", "Tiantian Feng", "Samiul Alam", "Mi Zhang", "Shrikanth S.\n Narayanan", "Salman Avestimehr\n"], "categories": ["cs.LG", "cs.DC\n"], "abstract": "In this work, we propose GPT-FL, a generative pre-trained model-assisted federated learning (FL) framework. At its core, GPT-FL leverages generative pre-trained models to generate diversified synthetic data. These generated data are used to train a downstream model on the server, which is then fine-tuned with private client data under the standard FL framework. We show that GPT-FL consistently outperforms state-of-the-art FL methods in terms of model test accuracy, communication efficiency, and client sampling efficiency. Through comprehensive ablation analysis, we discover that the downstream model generated by synthetic data plays a crucial role in controlling the direction of gradient diversity during FL training, which enhances convergence speed and contributes to the notable accuracy boost observed with GPT-FL. Also, regardless of whether the target data falls within or outside the domain of the pre-trained generative model, GPT-FL consistently achieves significant performance gains, surpassing the results obtained by models trained solely with FL or synthetic data.", "link": "https://arxiv.org/abs/2306.02210"}, {"id": "2306.02216", "date": "Sat, 3 Jun 2023 23:53:57 GMT", "title": "Forgettable Federated Linear Learning with Certified Data Removal\n", "authors": ["Ruinan Jin", "Minghui Chen", "Qiong Zhang", "Xiaoxiao Li\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "Federated learning (FL) is a trending distributed learning framework that enables collaborative model training without data sharing. Machine learning models trained on datasets can potentially expose the private information of the training data, revealing details about individual data records. In this study, we focus on the FL paradigm that grants clients the ``right to be forgotten''. The forgettable FL framework should bleach its global model weights as it has never seen that client and hence does not reveal any information about the client. To this end, we propose the Forgettable Federated Linear Learning (2F2L) framework featured with novel training and data removal strategies. The training pipeline, named Federated linear training, employs linear approximation on the model parameter space to enable our 2F2L framework work for deep neural networks while achieving comparable results with canonical neural network training. We also introduce FedRemoval, an efficient and effective removal strategy that tackles the computational challenges in FL by approximating the Hessian matrix using public server data from the pretrained model. Unlike the previous uncertified and heuristic machine unlearning methods in FL, we provide theoretical guarantees by bounding the differences of model weights by our FedRemoval and that from retraining from scratch. Experimental results on MNIST and Fashion-MNIST datasets demonstrate the effectiveness of our method in achieving a balance between model accuracy and information removal, outperforming baseline strategies and approaching retraining from scratch.", "link": "https://arxiv.org/abs/2306.02216"}, {"id": "2306.02223", "date": "Sun, 4 Jun 2023 00:50:35 GMT", "title": "Prescriptive PCA: Dimensionality Reduction for Two-stage Stochastic\n Optimization\n", "authors": ["Long He", "Ho-Yin Mak\n"], "categories": ["cs.LG", "math.OC\n"], "abstract": "In this paper, we consider the alignment between an upstream dimensionality reduction task of learning a low-dimensional representation of a set of high-dimensional data and a downstream optimization task of solving a stochastic program parameterized by said representation. In this case, standard dimensionality reduction methods (e.g., principal component analysis) may not perform well, as they aim to maximize the amount of information retained in the representation and do not generally reflect the importance of such information in the downstream optimization problem. To address this problem, we develop a prescriptive dimensionality reduction framework that aims to minimize the degree of suboptimality in the optimization phase. For the case where the downstream stochastic optimization problem has an expected value objective, we show that prescriptive dimensionality reduction can be performed via solving a distributionally-robust optimization problem, which admits a semidefinite programming relaxation. Computational experiments based on a warehouse transshipment problem and a vehicle repositioning problem show that our approach significantly outperforms principal component analysis with real and synthetic data sets.", "link": "https://arxiv.org/abs/2306.02223"}, {"id": "2306.02285", "date": "Sun, 4 Jun 2023 07:26:20 GMT", "title": "Clarify Confused Nodes Through Separated Learning\n", "authors": ["Shengbo Gong", "Jiajun Zhou", "Qi Xuan\n"], "categories": ["cs.LG", "cs.SI\nComments:", "20", "pages\n"], "abstract": "Graph neural networks (GNNs) have achieved remarkable advances in graph-oriented tasks. However, real-world graphs invariably contain a certain proportion of heterophilous nodes, challenging the homophily assumption of classical GNNs and hindering their performance. Most existing studies continue to design generic models with shared weights between heterophilous and homophilous nodes. Despite the incorporation of high-order message or multi-channel architectures, these efforts often fall short. A minority of studies attempt to train different node groups separately, but suffering from inappropriate separation metric and low efficiency. In this paper, we first propose a new metric, termed Neighborhood Confusion (NC), to facilitate a more reliable separation of nodes. We observe that node groups with different levels of NC values exhibit certain differences in intra-group accuracy and visualized embeddings. These pave a way for Neighborhood Confusion-guided Graph Convolutional Network (NCGCN), in which nodes are grouped by their NC values and accept intra-group weight sharing and message passing. Extensive experiments on both homophilous and heterophilous benchmarks demonstrate that NCGCN can effectively separate nodes and offers significant performance improvement compared to latest methods.", "link": "https://arxiv.org/abs/2306.02285"}, {"id": "2306.02312", "date": "Sun, 4 Jun 2023 09:34:41 GMT", "title": "(Un)reasonable Allure of Ante-hoc Interpretability for High-stakes\n Domains: Transparency Is Necessary but Insufficient for Explainability\n", "authors": ["Kacper Sokol and Julia E. Vogt\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Ante-hoc interpretability has become the holy grail of explainable machine learning for high-stakes domains such as healthcare; however, this notion is elusive, lacks a widely-accepted definition and depends on the deployment context. It can refer to predictive models whose structure adheres to domain-specific constraints, or ones that are inherently transparent. The latter notion assumes observers who judge this quality, whereas the former presupposes them to have technical and domain expertise, in certain cases rendering such models unintelligible. Additionally, its distinction from the less desirable post-hoc explainability, which refers to methods that construct a separate explanatory model, is vague given that transparent predictors may still require (post-)processing to yield satisfactory explanatory insights. Ante-hoc interpretability is thus an overloaded concept that comprises a range of implicit properties, which we unpack in this paper to better understand what is needed for its safe deployment across high-stakes domains. To this end, we outline model- and explainer-specific desiderata that allow us to navigate its distinct realisations in view of the envisaged application and audience.", "link": "https://arxiv.org/abs/2306.02312"}, {"id": "2306.02325", "date": "Sun, 4 Jun 2023 10:50:13 GMT", "title": "Random Feedback Alignment Algorithms to train Neural Networks: Why do\n they Align?\n", "authors": ["Dominique Chu", "Florian Bacho\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Feedback alignment algorithms are an alternative to backpropagation to train neural networks, whereby some of the partial derivatives that are required to compute the gradient are replaced by random terms. This essentially transforms the update rule into a random walk in weight space. Surprisingly, learning still works with those algorithms, including training of deep neural networks. This is generally attributed to an alignment of the update of the random walker with the true gradient - the eponymous gradient alignment -- which drives an approximate gradient descend. The mechanism that leads to this alignment remains unclear, however. In this paper, we use mathematical reasoning and simulations to investigate gradient alignment. We observe that the feedback alignment update rule has fixed points, which correspond to extrema of the loss function. We show that gradient alignment is a stability criterion for those fixed points. It is only a necessary criterion for algorithm performance. Experimentally, we demonstrate that high levels of gradient alignment can lead to poor algorithm performance and that the alignment is not always driving the gradient descend.", "link": "https://arxiv.org/abs/2306.02325"}, {"id": "2306.02335", "date": "Sun, 4 Jun 2023 11:52:59 GMT", "title": "Towards Robust Feature Learning with t-vFM Similarity for Continual\n Learning\n", "authors": ["Bilan Gao", "YoungBin Kim\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "Continual learning has been developed using standard supervised contrastive loss from the perspective of feature learning. Due to the data imbalance during the training, there are still challenges in learning better representations. In this work, we suggest using a different similarity metric instead of cosine similarity in supervised contrastive loss in order to learn more robust representations. We validate the our method on one of the image classification datasets Seq-CIFAR-10 and the results outperform recent continual learning baselines.", "link": "https://arxiv.org/abs/2306.02335"}, {"id": "2306.02368", "date": "Sun, 4 Jun 2023 14:27:50 GMT", "title": "Revisiting Data-Free Knowledge Distillation with Poisoned Teachers\n", "authors": ["Junyuan Hong", "Yi Zeng", "Shuyang Yu", "Lingjuan Lyu", "Ruoxi Jia", "Jiayu Zhou\n"], "categories": ["cs.LG", "cs.CR\nComments:", "Accepted", "to", "ICML", "2023\n"], "abstract": "Data-free knowledge distillation (KD) helps transfer knowledge from a pre-trained model (known as the teacher model) to a smaller model (known as the student model) without access to the original training data used for training the teacher model. However, the security of the synthetic or out-of-distribution (OOD) data required in data-free KD is largely unknown and under-explored. In this work, we make the first effort to uncover the security risk of data-free KD w.r.t. untrusted pre-trained models. We then propose Anti-Backdoor Data-Free KD (ABD), the first plug-in defensive method for data-free KD methods to mitigate the chance of potential backdoors being transferred. We empirically evaluate the effectiveness of our proposed ABD in diminishing transferred backdoor knowledge while maintaining compatible downstream performances as the vanilla KD. We envision this work as a milestone for alarming and mitigating the potential backdoors in data-free KD. Codes are released at https://github.com/illidanlab/ABD.", "link": "https://arxiv.org/abs/2306.02368"}, {"id": "2306.02376", "date": "Sun, 4 Jun 2023 15:19:44 GMT", "title": "Towards Deep Attention in Graph Neural Networks: Problems and Remedies\n", "authors": ["Soo Yong Lee", "Fanchen Bu", "Jaemin Yoo", "Kijung Shin\n"], "categories": ["cs.LG", "cs.AI\nComments:", "22", "pages,", "6", "figures,", "conference", "paper,", "published", "in", "International\n", "Conference", "on", "Machine", "Learning.", "PMLR,", "2023\n"], "abstract": "Graph neural networks (GNNs) learn the representation of graph-structured data, and their expressiveness can be further enhanced by inferring node relations for propagation. Attention-based GNNs infer neighbor importance to manipulate the weight of its propagation. Despite their popularity, the discussion on deep graph attention and its unique challenges has been limited. In this work, we investigate some problematic phenomena related to deep graph attention, including vulnerability to over-smoothed features and smooth cumulative attention. Through theoretical and empirical analyses, we show that various attention-based GNNs suffer from these problems. Motivated by our findings, we propose AEROGNN, a novel GNN architecture designed for deep graph attention. AERO-GNN provably mitigates the proposed problems of deep graph attention, which is further empirically demonstrated with (a) its adaptive and less smooth attention functions and (b) higher performance at deep layers (up to 64). On 9 out of 12 node classification benchmarks, AERO-GNN outperforms the baseline GNNs, highlighting the advantages of deep graph attention. Our code is available at https://github.com/syleeheal/AERO-GNN.", "link": "https://arxiv.org/abs/2306.02376"}, {"id": "2306.02389", "date": "Sun, 4 Jun 2023 15:48:09 GMT", "title": "Fast Continual Multi-View Clustering with Incomplete Views\n", "authors": ["Xinhang Wan", "Bin Xiao", "Xinwang Liu", "Jiyuan Liu", "Weixuan Liang", "En Zhu\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Multi-view clustering (MVC) has gained broad attention owing to its capacity to exploit consistent and complementary information across views. This paper focuses on a challenging issue in MVC called the incomplete continual data problem (ICDP). In specific, most existing algorithms assume that views are available in advance and overlook the scenarios where data observations of views are accumulated over time. Due to privacy considerations or memory limitations, previous views cannot be stored in these situations. Some works are proposed to handle it, but all fail to address incomplete views. Such an incomplete continual data problem (ICDP) in MVC is tough to solve since incomplete information with continual data increases the difficulty of extracting consistent and complementary knowledge among views. We propose Fast Continual Multi-View Clustering with Incomplete Views (FCMVC-IV) to address it. Specifically, it maintains a consensus coefficient matrix and updates knowledge with the incoming incomplete view rather than storing and recomputing all the data matrices. Considering that the views are incomplete, the newly collected view might contain samples that have yet to appear; two indicator matrices and a rotation matrix are developed to match matrices with different dimensions. Besides, we design a three-step iterative algorithm to solve the resultant problem in linear complexity with proven convergence. Comprehensive experiments on various datasets show the superiority of FCMVC-IV.", "link": "https://arxiv.org/abs/2306.02389"}, {"id": "2306.02400", "date": "Sun, 4 Jun 2023 16:29:30 GMT", "title": "Perceptual Kalman Filters: Online State Estimation under a Perfect\n Perceptual-Quality Constraint\n", "authors": ["Dror Freirich and Tomer Michaeli and Ron Meir\n"], "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML\n"], "abstract": "Many practical settings call for the reconstruction of temporal signals from corrupted or missing data. Classic examples include decoding, tracking, signal enhancement and denoising. Since the reconstructed signals are ultimately viewed by humans, it is desirable to achieve reconstructions that are pleasing to human perception. Mathematically, perfect perceptual-quality is achieved when the distribution of restored signals is the same as that of natural signals, a requirement which has been heavily researched in static estimation settings (i.e. when a whole signal is processed at once). Here, we study the problem of optimal causal filtering under a perfect perceptual-quality constraint, which is a task of fundamentally different nature. Specifically, we analyze a Gaussian Markov signal observed through a linear noisy transformation. In the absence of perceptual constraints, the Kalman filter is known to be optimal in the MSE sense for this setting. Here, we show that adding the perfect perceptual quality constraint (i.e. the requirement of temporal consistency), introduces a fundamental dilemma whereby the filter may have to \"knowingly\" ignore new information revealed by the observations in order to conform to its past decisions. This often comes at the cost of a significant increase in the MSE (beyond that encountered in static settings). Our analysis goes beyond the classic innovation process of the Kalman filter, and introduces the novel concept of an unutilized information process. Using this tool, we present a recursive formula for perceptual filters, and demonstrate the qualitative effects of perfect perceptual-quality estimation on a video reconstruction problem.", "link": "https://arxiv.org/abs/2306.02400"}, {"id": "2306.02426", "date": "Sun, 4 Jun 2023 18:14:18 GMT", "title": "Resilient Constrained Learning\n", "authors": ["Ignacio Hounie", "Alejandro Ribeiro", "Luiz F. O. Chamon\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems that adapt to disruptions by modifying their operation. We show conditions under which this balance can be achieved and introduce a practical algorithm to compute it, for which we derive approximation and generalization guarantees. We showcase the advantages of this resilient learning method in image classification tasks involving multiple potential invariances and in heterogeneous federated learning.", "link": "https://arxiv.org/abs/2306.02426"}, {"id": "2306.02447", "date": "Sun, 4 Jun 2023 19:30:28 GMT", "title": "Active Inference-Based Optimization of Discriminative Neural Network\n Classifiers\n", "authors": ["Faezeh Fallah\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Commonly used objective functions (losses) for a supervised optimization of discriminative neural network classifiers were either distribution-based or metric-based. The distribution-based losses could compromise the generalization or cause classification biases towards the dominant classes of an imbalanced class-sample distribution. The metric-based losses could make the network model independent of any distribution and thus improve its generalization. However, they could still be biased towards the dominant classes and could suffer from discrepancies when a class was absent in both the reference (ground truth) and the predicted labels. In this paper, we proposed a novel optimization process which not only tackled the unbalancedness of the class-sample distribution of the training samples but also provided a mechanism to tackle errors in the reference labels of the training samples. This was achieved by proposing a novel algorithm to find candidate classification labels of the training samples from their prior probabilities and the currently estimated posteriors on the network and a novel objective function for the optimizations. The algorithm was the result of casting the generalized Kelly criterion for optimal betting into a multiclass classification problem. The proposed objective function was the expected free energy of a prospective active inference and could incorporate the candidate labels, the original reference labels, and the priors of the training samples while still being distribution-based. The incorporation of the priors into the optimization not only helped to tackle errors in the reference labels but also allowed to reduce classification biases towards the dominant classes by focusing the attention of the neural network on important but minority foreground classes.", "link": "https://arxiv.org/abs/2306.02447"}, {"id": "2306.02459", "date": "Sun, 4 Jun 2023 20:22:14 GMT", "title": "Multi-Predict: Few Shot Predictors For Efficient Neural Architecture\n Search\n", "authors": ["Yash Akhauri", "Mohamed S. Abdelfattah\n"], "categories": ["cs.LG", "cs.AR", "cs.CV", "cs.PF\n"], "abstract": "Many hardware-aware neural architecture search (NAS) methods have been developed to optimize the topology of neural networks (NN) with the joint objectives of higher accuracy and lower latency. Recently, both accuracy and latency predictors have been used in NAS with great success, achieving high sample efficiency and accurate modeling of hardware (HW) device latency respectively. However, a new accuracy predictor needs to be trained for every new NAS search space or NN task, and a new latency predictor needs to be additionally trained for every new HW device. In this paper, we explore methods to enable multi-task, multi-search-space, and multi-HW adaptation of accuracy and latency predictors to reduce the cost of NAS. We introduce a novel search-space independent NN encoding based on zero-cost proxies that achieves sample-efficient prediction on multiple tasks and NAS search spaces, improving the end-to-end sample efficiency of latency and accuracy predictors by over an order of magnitude in multiple scenarios. For example, our NN encoding enables multi-search-space transfer of latency predictors from NASBench-201 to FBNet (and vice-versa) in under 85 HW measurements, a 400$\\times$ improvement in sample efficiency compared to a recent meta-learning approach. Our method also improves the total sample efficiency of accuracy predictors by over an order of magnitude. Finally, we demonstrate the effectiveness of our method for multi-search-space and multi-task accuracy prediction on 28 NAS search spaces and tasks.", "link": "https://arxiv.org/abs/2306.02459"}, {"id": "2306.02497", "date": "Sun, 4 Jun 2023 22:16:49 GMT", "title": "Learning on Bandwidth Constrained Multi-Source Data with MIMO-inspired\n DPP MAP Inference\n", "authors": ["Xiwen Chen", "Huayu Li", "Rahul Amin", "Abolfazl Razi\n"], "categories": ["cs.LG", "cs.IT", "math.IT\n"], "abstract": "This paper proposes a distributed version of Determinant Point Processing (DPP) inference to enhance multi-source data diversification under limited communication bandwidth. DPP is a popular probabilistic approach that improves data diversity by enforcing the repulsion of elements in the selected subsets. The well-studied Maximum A Posteriori (MAP) inference in DPP aims to identify the subset with the highest diversity quantified by DPP. However, this approach is limited by the presumption that all data samples are available at one point, which hinders its applicability to real-world applications such as traffic datasets where data samples are distributed across sources and communication between them is band-limited. Inspired by the techniques used in Multiple-Input Multiple-Output (MIMO) communication systems, we propose a strategy for performing MAP inference among distributed sources. Specifically, we show that a lower bound of the diversity-maximized distributed sample selection problem can be treated as a power allocation problem in MIMO systems. A determinant-preserved sparse representation of selected samples is used to perform sample precoding in local sources to be processed by DPP. Our method does not require raw data exchange among sources, but rather a band-limited feedback channel to send lightweight diversity measures, analogous to the CSI message in MIMO systems, from the center to data sources. The experiments show that our scalable approach can outperform baseline methods, including random selection, uninformed individual DPP with no feedback, and DPP with SVD-based feedback, in both i.i.d and non-i.i.d setups. Specifically, it achieves 1 to 6 log-difference diversity gain in the latent representation of CIFAR-10, CIFAR-100, StanfordCars, and GTSRB datasets.", "link": "https://arxiv.org/abs/2306.02497"}, {"id": "2306.02508", "date": "Mon, 5 Jun 2023 00:01:17 GMT", "title": "Graph Fourier MMD for Signals on Graphs\n", "authors": ["Samuel Leone", "Aarthi Venkat", "Guillaume Huguet", "Alexander Tong", "Guy\n Wolf", "Smita Krishnaswamy\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "While numerous methods have been proposed for computing distances between probability distributions in Euclidean space, relatively little attention has been given to computing such distances for distributions on graphs. However, there has been a marked increase in data that either lies on graph (such as protein interaction networks) or can be modeled as a graph (single cell data), particularly in the biomedical sciences. Thus, it becomes important to find ways to compare signals defined on such graphs. Here, we propose Graph Fourier MMD (GFMMD), a novel distance between distributions and signals on graphs. GFMMD is defined via an optimal witness function that is both smooth on the graph and maximizes difference in expectation between the pair of distributions on the graph. We find an analytical solution to this optimization problem as well as an embedding of distributions that results from this method. We also prove several properties of this method including scale invariance and applicability to disconnected graphs. We showcase it on graph benchmark datasets as well on single cell RNA-sequencing data analysis. In the latter, we use the GFMMD-based gene embeddings to find meaningful gene clusters. We also propose a novel type of score for gene selection called \"gene localization score\" which helps select genes for cellular state space characterization.", "link": "https://arxiv.org/abs/2306.02508"}, {"id": "2306.02516", "date": "Mon, 5 Jun 2023 00:43:37 GMT", "title": "SamToNe: Improving Contrastive Loss for Dual Encoder Retrieval Models\n with Same Tower Negatives\n", "authors": ["Fedor Moiseev", "Gustavo Hernandez Abrego", "Peter Dornbach", "Imed Zitouni,\n Enrique Alfonseca", "Zhe Dong\n"], "categories": ["cs.LG", "cs.IR\nComments:", "ACL", "2023", "Findings\n"], "abstract": "Dual encoders have been used for retrieval tasks and representation learning with good results. A standard way to train dual encoders is using a contrastive loss with in-batch negatives. In this work, we propose an improved contrastive learning objective by adding queries or documents from the same encoder towers to the negatives, for which we name it as \"contrastive loss with SAMe TOwer NEgatives\" (SamToNe). By evaluating on question answering retrieval benchmarks from MS MARCO and MultiReQA, and heterogenous zero-shot information retrieval benchmarks (BEIR), we demonstrate that SamToNe can effectively improve the retrieval quality for both symmetric and asymmetric dual encoders. By directly probing the embedding spaces of the two encoding towers via the t-SNE algorithm (van der Maaten and Hinton, 2008), we observe that SamToNe ensures the alignment between the embedding spaces from the two encoder towers. Based on the analysis of the embedding distance distributions of the top-$1$ retrieved results, we further explain the efficacy of the method from the perspective of regularisation.", "link": "https://arxiv.org/abs/2306.02516"}, {"id": "2306.02533", "date": "Mon, 5 Jun 2023 01:45:22 GMT", "title": "On Emergence of Clean-Priority Learning in Early Stopped Neural Networks\n", "authors": ["Chaoyue Liu", "Amirhesam Abedsoltan", "Mikhail Belkin\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally results in a termination of the clean-priority learning and fitting of the noisy samples.", "link": "https://arxiv.org/abs/2306.02533"}, {"id": "2306.02556", "date": "Mon, 5 Jun 2023 03:08:29 GMT", "title": "Improved Active Multi-Task Representation Learning via Lasso\n", "authors": ["Yiping Wang", "Yifang Chen", "Kevin Jamieson", "Simon S. Du\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "by", "ICML", "2023\n"], "abstract": "To leverage the copious amount of data from source tasks and overcome the scarcity of the target task samples, representation learning based on multi-task pretraining has become a standard approach in many applications. However, up until now, most existing works design a source task selection strategy from a purely empirical perspective. Recently, \\citet{chen2022active} gave the first active multi-task representation learning (A-MTRL) algorithm which adaptively samples from source tasks and can provably reduce the total sample complexity using the L2-regularized-target-source-relevance parameter $\\nu^2$. But their work is theoretically suboptimal in terms of total source sample complexity and is less practical in some real-world scenarios where sparse training source task selection is desired. In this paper, we address both issues. Specifically, we show the strict dominance of the L1-regularized-relevance-based ($\\nu^1$-based) strategy by giving a lower bound for the $\\nu^2$-based strategy. When $\\nu^1$ is unknown, we propose a practical algorithm that uses the LASSO program to estimate $\\nu^1$. Our algorithm successfully recovers the optimal result in the known case. In addition to our sample complexity results, we also characterize the potential of our $\\nu^1$-based strategy in sample-cost-sensitive settings. Finally, we provide experiments on real-world computer vision datasets to illustrate the effectiveness of our proposed method.", "link": "https://arxiv.org/abs/2306.02556"}, {"id": "2306.02563", "date": "Mon, 5 Jun 2023 03:33:26 GMT", "title": "Large-Scale Distributed Learning via Private On-Device\n Locality-Sensitive Hashing\n", "authors": ["Tahseen Rabbani", "Marco Bornstein", "Furong Huang\n"], "categories": ["cs.LG", "cs.CR", "cs.DC\nComments:", "18", "pages,", "10", "figures\n"], "abstract": "Locality-sensitive hashing (LSH) based frameworks have been used efficiently to select weight vectors in a dense hidden layer with high cosine similarity to an input, enabling dynamic pruning. While this type of scheme has been shown to improve computational training efficiency, existing algorithms require repeated randomized projection of the full layer weight, which is impractical for computational- and memory-constrained devices. In a distributed setting, deferring LSH analysis to a centralized host is (i) slow if the device cluster is large and (ii) requires access to input data which is forbidden in a federated context. Using a new family of hash functions, we develop one of the first private, personalized, and memory-efficient on-device LSH frameworks. Our framework enables privacy and personalization by allowing each device to generate hash tables, without the help of a central host, using device-specific hashing hyper-parameters (e.g. number of hash tables or hash length). Hash tables are generated with a compressed set of the full weights, and can be serially generated and discarded if the process is memory-intensive. This allows devices to avoid maintaining (i) the fully-sized model and (ii) large amounts of hash tables in local memory for LSH analysis. We prove several statistical and sensitivity properties of our hash functions, and experimentally demonstrate that our framework is competitive in training large-scale recommender networks compared to other LSH frameworks which assume unrestricted on-device capacity.", "link": "https://arxiv.org/abs/2306.02563"}, {"id": "2306.02564", "date": "Mon, 5 Jun 2023 03:36:01 GMT", "title": "Spatial Implicit Neural Representations for Global-Scale Species Mapping\n", "authors": ["Elijah Cole", "Grant Van Horn", "Christian Lange", "Alexander Shepard,\n Patrick Leary", "Pietro Perona", "Scott Loarie", "Oisin Mac Aodha\n"], "categories": ["cs.LG", "cs.CV\nComments:", "ICML", "2023\n"], "abstract": "Estimating the geographical range of a species from sparse observations is a challenging and important geospatial prediction problem. Given a set of locations where a species has been observed, the goal is to build a model to predict whether the species is present or absent at any location. This problem has a long history in ecology, but traditional methods struggle to take advantage of emerging large-scale crowdsourced datasets which can include tens of millions of records for hundreds of thousands of species. In this work, we use Spatial Implicit Neural Representations (SINRs) to jointly estimate the geographical range of 47k species simultaneously. We find that our approach scales gracefully, making increasingly better predictions as we increase the number of species and the amount of data per species when training. To make this problem accessible to machine learning researchers, we provide four new benchmarks that measure different aspects of species range estimation and spatial representation learning. Using these benchmarks, we demonstrate that noisy and biased crowdsourced data can be combined with implicit neural representations to approximate expert-developed range maps for many species.", "link": "https://arxiv.org/abs/2306.02564"}, {"id": "2306.02570", "date": "Mon, 5 Jun 2023 03:51:14 GMT", "title": "When Decentralized Optimization Meets Federated Learning\n", "authors": ["Hongchang Gao", "My T. Thai", "Jie Wu\n"], "categories": ["cs.LG", "math.OC\nComments:", "Accepted", "to", "IEEE", "Network\n"], "abstract": "Federated learning is a new learning paradigm for extracting knowledge from distributed data. Due to its favorable properties in preserving privacy and saving communication costs, it has been extensively studied and widely applied to numerous data analysis applications. However, most existing federated learning approaches concentrate on the centralized setting, which is vulnerable to a single-point failure. An alternative strategy for addressing this issue is the decentralized communication topology. In this article, we systematically investigate the challenges and opportunities when renovating decentralized optimization for federated learning. In particular, we discussed them from the model, data, and communication sides, respectively, which can deepen our understanding about decentralized federated learning.", "link": "https://arxiv.org/abs/2306.02570"}, {"id": "2306.02572", "date": "Mon, 5 Jun 2023 03:55:26 GMT", "title": "Introduction to Latent Variable Energy-Based Models: A Path Towards\n Autonomous Machine Intelligence\n", "authors": ["Anna Dawid", "Yann LeCun\n"], "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML\nComments:", "23", "pages", "+", "1-page", "appendix,", "11", "figures.", "These", "notes", "follow", "the\n", "content", "of", "three", "lectures", "given", "by", "Yann", "LeCun", "during", "the", "Les", "Houches", "Summer\n", "School", "on", "Statistical", "Physics", "and", "Machine", "Learning", "in", "2022.", "Feedback", "and\n", "comments", "are", "most", "welcome!\n"], "abstract": "Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack Level 5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In particular, we introduce energy-based and latent variable models and combine their advantages in the building block of LeCun's proposal, that is, in the hierarchical joint embedding predictive architecture (H-JEPA).", "link": "https://arxiv.org/abs/2306.02572"}, {"id": "2306.02587", "date": "Mon, 5 Jun 2023 04:28:04 GMT", "title": "Jammer classification with Federated Learning\n", "authors": ["Peng Wu", "Helena Calatrava", "Tales Imbiriba", "Pau Closas\n"], "categories": ["cs.LG", "cs.CR\n"], "abstract": "Jamming signals can jeopardize the operation of GNSS receivers until denying its operation. Given their ubiquity, jamming mitigation and localization techniques are of crucial importance, for which jammer classification is of help. Data-driven models have been proven useful in detecting these threats, while their training using crowdsourced data still poses challenges when it comes to private data sharing. This article investigates the use of federated learning to train jamming signal classifiers locally on each device, with model updates aggregated and averaged at the central server. This allows for privacy-preserving training procedures that do not require centralized data storage or access to client local data. The used framework FedAvg is assessed on a dataset consisting of spectrogram images of simulated interfered GNSS signal. Six different jammer types are effectively classified with comparable results to a fully centralized solution that requires vast amounts of data communication and involves privacy-preserving concerns.", "link": "https://arxiv.org/abs/2306.02587"}, {"id": "2306.02595", "date": "Mon, 5 Jun 2023 04:58:41 GMT", "title": "Explore and Exploit the Diverse Knowledge in Model Zoo for Domain\n Generalization\n", "authors": ["Yimeng Chen", "Tianyang Hu", "Fengwei Zhou", "Zhenguo Li", "Zhiming Ma\n"], "categories": ["cs.LG", "stat.ML\nComments:", "Accepted", "to", "ICML", "2023\n"], "abstract": "The proliferation of pretrained models, as a result of advancements in pretraining techniques, has led to the emergence of a vast zoo of publicly available models. Effectively utilizing these resources to obtain models with robust out-of-distribution generalization capabilities for downstream tasks has become a crucial area of research. Previous research has primarily focused on identifying the most powerful models within the model zoo, neglecting to fully leverage the diverse inductive biases contained within. This paper argues that the knowledge contained in weaker models is valuable and presents a method for leveraging the diversity within the model zoo to improve out-of-distribution generalization capabilities. Specifically, we investigate the behaviors of various pretrained models across different domains of downstream tasks by characterizing the variations in their encoded representations in terms of two dimensions: diversity shift and correlation shift. This characterization enables us to propose a new algorithm for integrating diverse pretrained models, not limited to the strongest models, in order to achieve enhanced out-of-distribution generalization performance. Our proposed method demonstrates state-of-the-art empirical results on a variety of datasets, thus validating the benefits of utilizing diverse knowledge.", "link": "https://arxiv.org/abs/2306.02595"}, {"id": "2306.02601", "date": "Mon, 5 Jun 2023 05:21:01 GMT", "title": "Aiming towards the minimizers: fast convergence of SGD for\n overparametrized problems\n", "authors": ["Chaoyue Liu", "Dmitriy Drusvyatskiy", "Mikhail Belkin", "Damek Davis", "Yi-An\n Ma\n"], "categories": ["cs.LG", "math.OC", "stat.ML\n"], "abstract": "Modern machine learning paradigms, such as deep learning, occur in or close to the interpolation regime, wherein the number of model parameters is much larger than the number of data samples. In this work, we propose a regularity condition within the interpolation regime which endows the stochastic gradient method with the same worst-case iteration complexity as the deterministic gradient method, while using only a single sampled gradient (or a minibatch) in each iteration. In contrast, all existing guarantees require the stochastic gradient method to take small steps, thereby resulting in a much slower linear rate of convergence. Finally, we demonstrate that our condition holds when training sufficiently wide feedforward neural networks with a linear output layer.", "link": "https://arxiv.org/abs/2306.02601"}, {"id": "2306.02618", "date": "Mon, 5 Jun 2023 06:36:18 GMT", "title": "Enhance Diffusion to Improve Robust Generalization\n", "authors": ["Jianhui Sun and Sanchit Sinha and Aidong Zhang\n"], "categories": ["cs.LG", "cs.AI\nComments:", "Accepted", "at", "KDD", "2023\nDOI:", "10.1145/3580305.3599333\n"], "abstract": "Deep neural networks are susceptible to human imperceptible adversarial perturbations. One of the strongest defense mechanisms is \\emph{Adversarial Training} (AT). In this paper, we aim to address two predominant problems in AT. First, there is still little consensus on how to set hyperparameters with a performance guarantee for AT research, and customized settings impede a fair comparison between different model designs in AT research. Second, the robustly trained neural networks struggle to generalize well and suffer from tremendous overfitting. This paper focuses on the primary AT framework - Projected Gradient Descent Adversarial Training (PGD-AT). We approximate the dynamic of PGD-AT by a continuous-time Stochastic Differential Equation (SDE), and show that the diffusion term of this SDE determines the robust generalization. An immediate implication of this theoretical finding is that robust generalization is positively correlated with the ratio between learning rate and batch size. We further propose a novel approach, \\emph{Diffusion Enhanced Adversarial Training} (DEAT), to manipulate the diffusion term to improve robust generalization with virtually no extra computational burden. We theoretically show that DEAT obtains a tighter generalization bound than PGD-AT. Our empirical investigation is extensive and firmly attests that DEAT universally outperforms PGD-AT by a significant margin.", "link": "https://arxiv.org/abs/2306.02618"}, {"id": "2306.02639", "date": "Mon, 5 Jun 2023 07:15:54 GMT", "title": "Evaluating robustness of support vector machines with the Lagrangian\n dual approach\n", "authors": ["Yuting Liu", "Hong Gu", "Pan Qin\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Adversarial examples bring a considerable security threat to support vector machines (SVMs), especially those used in safety-critical applications. Thus, robustness verification is an essential issue for SVMs, which can provide provable robustness against various kinds of adversary attacks. The evaluation results obtained through the robustness verification can provide a safe guarantee for the use of SVMs. The existing verification method does not often perform well in verifying SVMs with nonlinear kernels. To this end, we propose a method to improve the verification performance for SVMs with nonlinear kernels. We first formalize the adversarial robustness evaluation of SVMs as an optimization problem. Then a lower bound of the original problem is obtained by solving the Lagrangian dual problem of the original problem. Finally, the adversarial robustness of SVMs is evaluated concerning the lower bound. We evaluate the adversarial robustness of SVMs with linear and nonlinear kernels on the MNIST and Fashion-MNIST datasets. The experimental results show that the percentage of provable robustness obtained by our method on the test set is better than that of the state-of-the-art.", "link": "https://arxiv.org/abs/2306.02639"}, {"id": "2306.02658", "date": "Mon, 5 Jun 2023 07:47:30 GMT", "title": "Faster Training of Diffusion Models and Improved Density Estimation via\n Parallel Score Matching\n", "authors": ["Etrit Haxholli", "Marco Lorenzi\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "In Diffusion Probabilistic Models (DPMs), the task of modeling the score evolution via a single time-dependent neural network necessitates extended training periods and may potentially impede modeling flexibility and capacity. To counteract these challenges, we propose leveraging the independence of learning tasks at different time points inherent to DPMs. More specifically, we partition the learning task by utilizing independent networks, each dedicated to learning the evolution of scores within a specific time sub-interval. Further, inspired by residual flows, we extend this strategy to its logical conclusion by employing separate networks to independently model the score at each individual time point. As empirically demonstrated on synthetic and image datasets, our approach not only significantly accelerates the training process by introducing an additional layer of parallelization atop data parallelization, but it also enhances density estimation performance when compared to the conventional training methodology for DPMs.", "link": "https://arxiv.org/abs/2306.02658"}, {"id": "2306.02664", "date": "Mon, 5 Jun 2023 07:53:52 GMT", "title": "Structure-free Graph Condensation: From Large-scale Graphs to Condensed\n Graph-free Data\n", "authors": ["Xin Zheng", "Miao Zhang", "Chunyang Chen", "Quoc Viet Hung Nguyen", "Xingquan\n Zhu", "Shirui Pan\n"], "categories": ["cs.LG", "cs.SI\nComments:", "9", "pages,", "3", "figures\n"], "abstract": "Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks. However, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability. In this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data. Our idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix. Specifically, SFGC contains two collaborative components: (1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data; (2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. Through training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data. Afterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data. Extensive experiments verify the superiority of SFGC across different condensation ratios.", "link": "https://arxiv.org/abs/2306.02664"}, {"id": "2306.02677", "date": "Mon, 5 Jun 2023 08:11:44 GMT", "title": "A Privacy-Preserving Federated Learning Approach for Kernel methods\n", "authors": ["Anika Hannemann", "Ali Burak \\\"Unal", "Arjhun Swaminathan", "Erik Buchmann,\n Mete Akg\\\"un\n"], "categories": ["cs.LG", "cs.CR\nComments:", "Preprint", "version", "of", "the", "full", "paper", "with", "supplementary", "material\nACM-class:", "I.2;", "I.2;", "K.6.5;", "E.3\n"], "abstract": "It is challenging to implement Kernel methods, if the data sources are distributed and cannot be joined at a trusted third party for privacy reasons. It is even more challenging, if the use case rules out privacy-preserving approaches that introduce noise. An example for such a use case is machine learning on clinical data. To realize exact privacy preserving computation of kernel methods, we propose FLAKE, a Federated Learning Approach for KErnel methods on horizontally distributed data. With FLAKE, the data sources mask their data so that a centralized instance can compute a Gram matrix without compromising privacy. The Gram matrix allows to calculate many kernel matrices, which can be used to train kernel-based machine learning algorithms such as Support Vector Machines. We prove that FLAKE prevents an adversary from learning the input data or the number of input features under a semi-honest threat model. Experiments on clinical and synthetic data confirm that FLAKE is outperforming the accuracy and efficiency of comparable methods. The time needed to mask the data and to compute the Gram matrix is several orders of magnitude less than the time a Support Vector Machine needs to be trained. Thus, FLAKE can be applied to many use cases.", "link": "https://arxiv.org/abs/2306.02677"}, {"id": "2306.02685", "date": "Mon, 5 Jun 2023 08:22:18 GMT", "title": "Predicting malaria dynamics in Burundi using deep Learning Models\n", "authors": ["Daxelle Sakubu", "Kelly Joelle Gatore Sinigirira", "David Niyukuri\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Malaria continues to be a major public health problem on the African continent, particularly in Sub-Saharan Africa. Nonetheless, efforts are ongoing, and significant progress has been made. In Burundi, malaria is among the main public health concerns. In the literature, there are limited prediction models for Burundi. We know that such tools are much needed for interventions design. In our study, we built machine-learning based models to estimates malaria cases in Burundi. The forecast was carried out at province level, allowing us to estimate malaria cases on a national scale as well. Long short term memory (LSTM) model, a type of deep learning model has been used to achieve best results using climate-change related factors such as temperature, rainfal, and relative humidity, together with malaria historical data and human population. The results showed that at country level different tuning of parameters can be used in order to determine the minimum and maximum expected malaria", "link": "https://arxiv.org/abs/2306.02685"}, {"id": "2306.02688", "date": "Mon, 5 Jun 2023 08:28:42 GMT", "title": "Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided\n Exploration for Mitigating Scale Shift on Combinatorial Optimization\n", "authors": ["Jiwoo Son", "Minsu Kim", "Hyeonah Kim", "Jinkyoo Park\n"], "categories": ["cs.LG", "stat.ML\nComments:", "18", "pages,", "9", "figures,", "International", "Conference", "on", "Machine", "Learning\n", "(ICML)", "2023\n"], "abstract": "This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage", "link": "https://arxiv.org/abs/2306.02688"}, {"id": "2306.02689", "date": "Mon, 5 Jun 2023 08:29:55 GMT", "title": "Solving NP-hard Min-max Routing Problems as Sequential Generation with\n Equity Context\n", "authors": ["Jiwoo Son", "Minsu Kim", "Sanghyeok Choi", "Jinkyoo Park\n"], "categories": ["cs.LG", "math.OC", "stat.ML\nComments:", "18", "pages,", "7", "figures\n"], "abstract": "Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing tasks: the min-max multiple traveling salesman problem (min-max mTSP) and the min-max multiple pick-up and delivery problem (min-max mPDP). Notably, our method achieves significant reductions of runtime, approximately 335 times, and cost values of about 53% compared to a competitive heuristic (LKH3) in the case of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source code: https://github.com/kaist-silab/equity-transformer", "link": "https://arxiv.org/abs/2306.02689"}, {"id": "2306.02701", "date": "Mon, 5 Jun 2023 08:45:44 GMT", "title": "Unlocking the Potential of Federated Learning for Deeper Models\n", "authors": ["Haolin Wang", "Xuefeng Liu", "Jianwei Niu", "Shaojie Tang", "Jiaxing Shen\n"], "categories": ["cs.LG", "cs.AI\nComments:", "16", "pages,", "8", "figures\n"], "abstract": "Federated learning (FL) is a new paradigm for distributed machine learning that allows a global model to be trained across multiple clients without compromising their privacy. Although FL has demonstrated remarkable success in various scenarios, recent studies mainly utilize shallow and small neural networks. In our research, we discover a significant performance decline when applying the existing FL framework to deeper neural networks, even when client data are independently and identically distributed (i.i.d.). Our further investigation shows that the decline is due to the continuous accumulation of dissimilarities among client models during the layer-by-layer back-propagation process, which we refer to as \"divergence accumulation.\" As deeper models involve a longer chain of divergence accumulation, they tend to manifest greater divergence, subsequently leading to performance decline. Both theoretical derivations and empirical evidence are proposed to support the existence of divergence accumulation and its amplified effects in deeper models. To address this issue, we propose several technical guidelines based on reducing divergence, such as using wider models and reducing the receptive field. These approaches can greatly improve the accuracy of FL on deeper models. For example, the application of these guidelines can boost the ResNet101 model's performance by as much as 43\\% on the Tiny-ImageNet dataset.", "link": "https://arxiv.org/abs/2306.02701"}, {"id": "2306.02709", "date": "Mon, 5 Jun 2023 09:01:38 GMT", "title": "Comparative Study on Semi-supervised Learning Applied for Anomaly\n Detection in Hydraulic Condition Monitoring System\n", "authors": ["Yongqi Dong", "Kejia Chen", "Zhiyuan Ma\n"], "categories": ["cs.LG", "stat.ML\nComments:", "7", "pages,", "8", "figures,", "accepted", "by", "2023", "IEEE", "International", "Conference", "on\n", "Systems,", "Man,", "and", "Cybernetics", "(SMC", "2023)", "https://ieeesmc2023.org/\n"], "abstract": "Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation Forest), and deep neural network based models (e.g., autoencoder, Hierarchical Extreme Learning Machine (HELM)). Typically, this study customized and implemented an extreme learning machine based semi-supervised HELM model and verified its superiority over other semi-supervised methods. Extensive experiments show that the customized HELM model obtained state-of-the-art performance with the highest accuracy (99.5%), the lowest false positive rate (0.015), and the best F1-score (0.985) beating other semi-supervised methods.", "link": "https://arxiv.org/abs/2306.02709"}, {"id": "2306.02729", "date": "Mon, 5 Jun 2023 09:26:38 GMT", "title": "Gibbs Sampling the Posterior of Neural Networks\n", "authors": ["Giovanni Piccioli", "Emanuele Troiani and Lenka Zdeborov\\'a\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium.", "link": "https://arxiv.org/abs/2306.02729"}, {"id": "2306.02781", "date": "Mon, 5 Jun 2023 11:14:18 GMT", "title": "A survey of Generative AI Applications\n", "authors": ["Roberto Gozalo-Brizuela", "Eduardo C. Garrido-Merch\\'an\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Generative AI has experienced remarkable growth in recent years, leading to a wide array of applications across diverse domains. In this paper, we present a comprehensive survey of more than 350 generative AI applications, providing a structured taxonomy and concise descriptions of various unimodal and even multimodal generative AIs. The survey is organized into sections, covering a wide range of unimodal generative AI applications such as text, images, video, gaming and brain information. Our survey aims to serve as a valuable resource for researchers and practitioners to navigate the rapidly expanding landscape of generative AI, facilitating a better understanding of the current state-of-the-art and fostering further innovation in the field.", "link": "https://arxiv.org/abs/2306.02781"}, {"id": "2306.02786", "date": "Mon, 5 Jun 2023 11:26:46 GMT", "title": "Navigating Explanatory Multiverse Through Counterfactual Path Geometry\n", "authors": ["Kacper Sokol and Edward Small and Yueqing Xuan\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Counterfactual explanations are the de facto standard when tasked with interpreting decisions of (opaque) predictive models. Their generation is often subject to algorithmic and domain-specific constraints -- such as density-based feasibility for the former and attribute (im)mutability or directionality of change for the latter -- that aim to maximise their real-life utility. In addition to desiderata with respect to the counterfactual instance itself, the existence of a viable path connecting it with the factual data point, known as algorithmic recourse, has become an important technical consideration. While both of these requirements ensure that the steps of the journey as well as its destination are admissible, current literature neglects the multiplicity of such counterfactual paths. To address this shortcoming we introduce the novel concept of explanatory multiverse that encompasses all the possible counterfactual journeys and shows how to navigate, reason about and compare the geometry of these paths -- their affinity, branching, divergence and possible future convergence -- with two methods: vector spaces and graphs. Implementing this (interactive) explanatory process grants explainees more agency by allowing them to select counterfactuals based on the properties of the journey leading to them in addition to their absolute differences.", "link": "https://arxiv.org/abs/2306.02786"}, {"id": "2306.02806", "date": "Mon, 5 Jun 2023 11:58:07 GMT", "title": "A Data-driven Region Generation Framework for Spatiotemporal\n Transportation Service Management\n", "authors": ["Liyue Chen", "Jiangyi Fang", "Zhe Yu", "Yongxin Tong", "Shaosheng Cao", "Leye\n Wang\n"], "categories": ["cs.LG", "cs.DB\nDOI:", "10.1145/3580305.3599760\n"], "abstract": "MAUP (modifiable areal unit problem) is a fundamental problem for spatial data management and analysis. As an instantiation of MAUP in online transportation platforms, region generation (i.e., specifying the areal unit for service operations) is the first and vital step for supporting spatiotemporal transportation services such as ride-sharing and freight transport. Most existing region generation methods are manually specified (e.g., fixed-size grids), suffering from poor spatial semantic meaning and inflexibility to meet service operation requirements. In this paper, we propose RegionGen, a data-driven region generation framework that can specify regions with key characteristics (e.g., good spatial semantic meaning and predictability) by modeling region generation as a multi-objective optimization problem. First, to obtain good spatial semantic meaning, RegionGen segments the whole city into atomic spatial elements based on road networks and obstacles (e.g., rivers). Then, it clusters the atomic spatial elements into regions by maximizing various operation characteristics, which is formulated as a multi-objective optimization problem. For this optimization problem, we propose a multi-objective co-optimization algorithm. Extensive experiments verify that RegionGen can generate more suitable regions than traditional methods for spatiotemporal service management.", "link": "https://arxiv.org/abs/2306.02806"}, {"id": "2306.02808", "date": "Mon, 5 Jun 2023 12:00:12 GMT", "title": "Deep Active Learning with Structured Neural Depth Search\n", "authors": ["Xiaoyun Zhang", "Xieyi Ping and Jianwei Zhang\n"], "categories": ["cs.LG", "cs.AI\nComments:", "10", "pages,", "8", "figures,", "prepare", "for", "TNNLS\n"], "abstract": "Previous work optimizes traditional active learning (AL) processes with incremental neural network architecture search (Active-iNAS) based on data complexity change, which improves the accuracy and learning efficiency. However, Active-iNAS trains several models and selects the model with the best generalization performance for querying the subsequent samples after each active learning cycle. The independent training processes lead to an insufferable computational budget, which is significantly inefficient and limits search flexibility and final performance. To address this issue, we propose a novel active strategy with the method called structured variational inference (SVI) or structured neural depth search (SNDS) whereby we could use the gradient descent method in neural network depth search during AL processes. At the same time, we theoretically demonstrate that the current VI-based methods based on the mean-field assumption could lead to poor performance. We apply our strategy using three querying techniques and three datasets and show that our strategy outperforms current methods.", "link": "https://arxiv.org/abs/2306.02808"}, {"id": "2306.02816", "date": "Mon, 5 Jun 2023 12:12:59 GMT", "title": "MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale\n Training of Physics-informed Neural Networks\n", "authors": ["Jiachen Yao", "Chang Su", "Zhongkai Hao", "Songming Liu", "Hang Su", "Jun Zhu\n"], "categories": ["cs.LG", "cs.NA", "math.NA\n"], "abstract": "Physics-informed Neural Networks (PINNs) have recently achieved remarkable progress in solving Partial Differential Equations (PDEs) in various fields by minimizing a weighted sum of PDE loss and boundary loss. However, there are several critical challenges in the training of PINNs, including the lack of theoretical frameworks and the imbalance between PDE loss and boundary loss. In this paper, we present an analysis of second-order non-homogeneous PDEs, which are classified into three categories and applicable to various common problems. We also characterize the connections between the training loss and actual error, guaranteeing convergence under mild conditions. The theoretical analysis inspires us to further propose MultiAdam, a scale-invariant optimizer that leverages gradient momentum to parameter-wisely balance the loss terms. Extensive experiment results on multiple problems from different physical domains demonstrate that our MultiAdam solver can improve the predictive accuracy by 1-2 orders of magnitude compared with strong baselines.", "link": "https://arxiv.org/abs/2306.02816"}, {"id": "2306.02822", "date": "Mon, 5 Jun 2023 12:20:40 GMT", "title": "Discovering Dynamic Causal Space for DAG Structure Learning\n", "authors": ["Fangfu Liu", "Wenchang Ma", "An Zhang", "Xiang Wang", "Yueqi Duan", "Tat-Seng\n Chua\n"], "categories": ["cs.LG", "stat.ML\nComments:", "Accepted", "by", "KDD", "2023\n"], "abstract": "Discovering causal structure from purely observational data (i.e., causal discovery), aiming to identify causal relationships among variables, is a fundamental task in machine learning. The recent invention of differentiable score-based DAG learners is a crucial enabler, which reframes the combinatorial optimization problem into a differentiable optimization with a DAG constraint over directed graph space. Despite their great success, these cutting-edge DAG learners incorporate DAG-ness independent score functions to evaluate the directed graph candidates, lacking in considering graph structure. As a result, measuring the data fitness alone regardless of DAG-ness inevitably leads to discovering suboptimal DAGs and model vulnerabilities. Towards this end, we propose a dynamic causal space for DAG structure learning, coined CASPER, that integrates the graph structure into the score function as a new measure in the causal space to faithfully reflect the causal distance between estimated and ground truth DAG. CASPER revises the learning process as well as enhances the DAG structure learning via adaptive attention to DAG-ness. Grounded by empirical visualization, CASPER, as a space, satisfies a series of desired properties, such as structure awareness and noise robustness. Extensive experiments on both synthetic and real-world datasets clearly validate the superiority of our CASPER over the state-of-the-art causal discovery methods in terms of accuracy and robustness.", "link": "https://arxiv.org/abs/2306.02822"}, {"id": "2306.02834", "date": "Mon, 5 Jun 2023 12:29:34 GMT", "title": "Computational Complexity of Detecting Proximity to Losslessly\n Compressible Neural Network Parameters\n", "authors": ["Matthew Farrugia-Roberts (The University of Melbourne)\n"], "categories": ["cs.LG", "cs.CC\nComments:", "9", "pages", "paper,", "31", "pages", "total,", "9", "figures,", "3", "tables\n"], "abstract": "To better understand complexity in neural networks, we theoretically investigate the idealised phenomenon of lossless network compressibility, whereby an identical function can be implemented with a smaller network. We give an efficient formal algorithm for optimal lossless compression in the setting of single-hidden-layer hyperbolic tangent networks. To measure lossless compressibility, we define the rank of a parameter as the minimum number of hidden units required to implement the same function. Losslessly compressible parameters are atypical, but their existence has implications for nearby parameters. We define the proximate rank of a parameter as the rank of the most compressible parameter within a small $L^\\infty$ neighbourhood. Unfortunately, detecting nearby losslessly compressible parameters is not so easy: we show that bounding the proximate rank is an NP-complete problem, using a reduction from Boolean satisfiability via a geometric problem involving covering points in the plane with small squares. These results underscore the computational complexity of measuring neural network complexity, laying a foundation for future theoretical and empirical work in this direction.", "link": "https://arxiv.org/abs/2306.02834"}, {"id": "2306.02848", "date": "Mon, 5 Jun 2023 12:58:13 GMT", "title": "HireVAE: An Online and Adaptive Factor Model Based on Hierarchical and\n Regime-Switch VAE\n", "authors": ["Zikai Wei", "Anyi Rao", "Bo Dai", "Dahua Lin\n"], "categories": ["cs.LG", "cs.CV", "q-fin.PM\nComments:", "Accepted", "to", "IJCAI", "2023\n"], "abstract": "Factor model is a fundamental investment tool in quantitative investment, which can be empowered by deep learning to become more flexible and efficient in practical complicated investing situations. However, it is still an open question to build a factor model that can conduct stock prediction in an online and adaptive setting, where the model can adapt itself to match the current market regime identified based on only point-in-time market information. To tackle this problem, we propose the first deep learning based online and adaptive factor model, HireVAE, at the core of which is a hierarchical latent space that embeds the underlying relationship between the market situation and stock-wise latent factors, so that HireVAE can effectively estimate useful latent factors given only historical market information and subsequently predict accurate stock returns. Across four commonly used real stock market benchmarks, the proposed HireVAE demonstrate superior performance in terms of active returns over previous methods, verifying the potential of such online and adaptive factor model.", "link": "https://arxiv.org/abs/2306.02848"}, {"id": "2306.02865", "date": "Mon, 5 Jun 2023 13:38:14 GMT", "title": "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy\n Actor-Critic\n", "authors": ["Tianying Ji", "Yu Luo", "Fuchun Sun", "Xianyuan Zhan", "Jianwei Zhang", "Huazhe\n Xu\n"], "categories": ["cs.LG", "cs.AI\n"], "abstract": "Learning high-quality Q-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. Previous works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. Deviating from the common viewpoint, we observe that Q-values are indeed underestimated in the latter stage of the RL training process, primarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer. We hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency. Our insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism. We propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates Q-value using both historical best-performing actions and the current policy. The instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks.", "link": "https://arxiv.org/abs/2306.02865"}, {"id": "2306.02866", "date": "Mon, 5 Jun 2023 13:40:54 GMT", "title": "Learning Probabilistic Symmetrization for Architecture Agnostic\n Equivariance\n", "authors": ["Jinwoo Kim", "Tien Dat Nguyen", "Ayhan Suleymanzade", "Hyeokjun An,\n Seunghoon Hong\n"], "categories": ["cs.LG", "cs.AI\nComments:", "25", "pages,", "3", "figures\n"], "abstract": "We present a novel framework to overcome the limitations of equivariant architectures in learning functions with group symmetries. In contrary to equivariant architectures, we use an arbitrary base model (such as an MLP or a transformer) and symmetrize it to be equivariant to the given group by employing a small equivariant network that parameterizes the probabilistic distribution underlying the symmetrization. The distribution is end-to-end trained with the base model which can maximize performance while reducing sample complexity of symmetrization. We show that this approach ensures not only equivariance to given group but also universal approximation capability in expectation. We implement our method on a simple patch-based transformer that can be initialized from pretrained vision transformers, and test it for a wide range of symmetry groups including permutation and Euclidean groups and their combinations. Empirical tests show competitive results against tailored equivariant architectures, suggesting the potential for learning equivariant functions for diverse groups using a non-equivariant universal base architecture. We further show evidence of enhanced learning in symmetric modalities, like graphs, when pretrained from non-symmetric modalities, like vision. Our implementation will be open-sourced at https://github.com/jw9730/lps.", "link": "https://arxiv.org/abs/2306.02866"}, {"id": "2306.02896", "date": "Mon, 5 Jun 2023 14:05:04 GMT", "title": "Representational Strengths and Limitations of Transformers\n", "authors": ["Clayton Sanford", "Daniel Hsu", "Matus Telgarsky\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be efficiently solved by attention layers. The proof techniques emphasize the value of communication complexity in the analysis of transformers and related models, and the role of sparse averaging as a prototypical attention task, which even finds use in the analysis of triple detection.", "link": "https://arxiv.org/abs/2306.02896"}, {"id": "2306.02913", "date": "Mon, 5 Jun 2023 14:19:52 GMT", "title": "Decentralized SGD and Average-direction SAM are Asymptotically\n Equivalent\n", "authors": ["Tongtian Zhu", "Fengxiang He", "Kaixuan Chen", "Mingli Song", "Dacheng Tao\n"], "categories": ["cs.LG", "cs.CY", "cs.DC", "cs.SY", "eess.SY", "stat.ML\nComments:", "Accepted", "for", "publication", "in", "the", "40th", "International", "Conference", "on\n", "Machine", "Learning", "(ICML", "2023)\n"], "abstract": "Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization benefit of D-SGD over centralized SGD (C-SGD) in large-batch scenarios.", "link": "https://arxiv.org/abs/2306.02913"}, {"id": "2306.02939", "date": "Mon, 5 Jun 2023 15:03:01 GMT", "title": "Improved Stability and Generalization Analysis of the Decentralized SGD\n Algorithm\n", "authors": ["Batiste Le Bars", "Aur\\'elien Bellet", "Marc Tommasi\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.", "link": "https://arxiv.org/abs/2306.02939"}, {"id": "2306.02947", "date": "Mon, 5 Jun 2023 15:11:59 GMT", "title": "Continual Learning with Pretrained Backbones by Tuning in the Input\n Space\n", "authors": ["Simone Marullo and Matteo Tiezzi and Marco Gori and Stefano Melacci\n and Tinne Tuytelaars\n"], "categories": ["cs.LG", "cs.CV\n"], "abstract": "The intrinsic difficulty in adapting deep learning models to non-stationary environments limits the applicability of neural networks to real-world tasks. This issue is critical in practical supervised learning settings, such as the ones in which a pre-trained model computes projections toward a latent space where different task predictors are sequentially learned over time. As a matter of fact, incrementally fine-tuning the whole model to better adapt to new tasks usually results in catastrophic forgetting, with decreasing performance over the past experiences and losing valuable knowledge from the pre-training stage. In this paper, we propose a novel strategy to make the fine-tuning procedure more effective, by avoiding to update the pre-trained part of the network and learning not only the usual classification head, but also a set of newly-introduced learnable parameters that are responsible for transforming the input data. This process allows the network to effectively leverage the pre-training knowledge and find a good trade-off between plasticity and stability with modest computational efforts, thus especially suitable for on-the-edge settings. Our experiments on four image classification problems in a continual learning setting confirm the quality of the proposed approach when compared to several fine-tuning procedures and to popular continual learning methods.", "link": "https://arxiv.org/abs/2306.02947"}, {"id": "2306.02957", "date": "Mon, 5 Jun 2023 15:24:39 GMT", "title": "Complex Preferences for Different Convergent Priors in Discrete Graph\n Diffusion\n", "authors": ["Alex M. Tseng", "Nathaniel Diamant", "Tommaso Biancalani", "Gabriele Scalia\n"], "categories": ["cs.LG", "stat.ML\n"], "abstract": "Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuitions which previous works have suggested.", "link": "https://arxiv.org/abs/2306.02957"}, {"id": "2306.02968", "date": "Mon, 5 Jun 2023 15:31:18 GMT", "title": "Time Interpret: a Unified Model Interpretability Library for Time Series\n", "authors": ["Joseph Enguehard\n"], "categories": ["cs.LG", "cs.AI\nComments:", "7", "pages,", "1", "figure.", "Code", "available", "at\n", "https://github.com/josephenguehard/time_interpret\n"], "abstract": "We introduce $\\texttt{time_interpret}$, a library designed as an extension of Captum, with a specific focus on temporal data. As such, this library implements several feature attribution methods that can be used to explain predictions made by any Pytorch model. $\\texttt{time_interpret}$ also provides several synthetic and real world time series datasets, various PyTorch models, as well as a set of methods to evaluate feature attributions. Moreover, while being primarily developed to explain predictions based on temporal data, some of its components have a different application, including for instance methods explaining predictions made by language models. In this paper, we give a general introduction of this library. We also present several previously unpublished feature attribution methods, which have been developed along with $\\texttt{time_interpret}$.", "link": "https://arxiv.org/abs/2306.02968"}, {"id": "2306.02971", "date": "Mon, 5 Jun 2023 15:35:00 GMT", "title": "Online Learning with Feedback Graphs: The True Shape of Regret\n", "authors": ["Tom\\'a\\v{s} Koc\\'ak and Alexandra Carpentier\n"], "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.TH\n"], "abstract": "Sequential learning with feedback graphs is a natural extension of the multi-armed bandit problem where the problem is equipped with an underlying graph structure that provides additional information - playing an action reveals the losses of all the neighbors of the action. This problem was introduced by \\citet{mannor2011} and received considerable attention in recent years. It is generally stated in the literature that the minimax regret rate for this problem is of order $\\sqrt{\\alpha T}$, where $\\alpha$ is the independence number of the graph, and $T$ is the time horizon. However, this is proven only when the number of rounds $T$ is larger than $\\alpha^3$, which poses a significant restriction for the usability of this result in large graphs. In this paper, we define a new quantity $R^*$, called the \\emph{problem complexity}, and prove that the minimax regret is proportional to $R^*$ for any graph and time horizon $T$. Introducing an intricate exploration strategy, we define the \\mainAlgorithm algorithm that achieves the minimax optimal regret bound and becomes the first provably optimal algorithm for this setting, even if $T$ is smaller than $\\alpha^3$.", "link": "https://arxiv.org/abs/2306.02971"}, {"id": "2306.02996", "date": "Mon, 5 Jun 2023 16:06:39 GMT", "title": "Over-the-Air Federated Learning in Satellite systems\n", "authors": ["Edward Akito Carlos", "Raphael Pinard", "Mitra Hassani\n"], "categories": ["cs.LG", "eess.IV\n"], "abstract": "Federated learning in satellites offers several advantages. Firstly, it ensures data privacy and security, as sensitive data remains on the satellites and is not transmitted to a central location. This is particularly important when dealing with sensitive or classified information. Secondly, federated learning allows satellites to collectively learn from a diverse set of data sources, benefiting from the distributed knowledge across the satellite network. Lastly, the use of federated learning reduces the communication bandwidth requirements between satellites and the central server, as only model updates are exchanged instead of raw data. By leveraging federated learning, satellites can collaborate and continuously improve their machine learning models while preserving data privacy and minimizing communication overhead. This enables the development of more intelligent and efficient satellite systems for various applications, such as Earth observation, weather forecasting, and space exploration.", "link": "https://arxiv.org/abs/2306.02996"}, {"id": "2306.03010", "date": "Mon, 5 Jun 2023 16:25:33 GMT", "title": "Interval Load Forecasting for Individual Households in the Presence of\n Electric Vehicle Charging\n", "authors": ["Raiden Skala", "Mohamed Ahmed T. A. Elgalhud", "Katarina Grolinger", "and\n Syed Mir\n"], "categories": ["cs.LG", "cs.AI\nJournal-ref:", "Energies", "2023,", "16(10)\nDOI:", "10.3390/en16104093\n"], "abstract": "The transition to Electric Vehicles (EV) in place of traditional internal combustion engines is increasing societal demand for electricity. The ability to integrate the additional demand from EV charging into forecasting electricity demand is critical for maintaining the reliability of electricity generation and distribution. Load forecasting studies typically exclude households with home EV charging, focusing on offices, schools, and public charging stations. Moreover, they provide point forecasts which do not offer information about prediction uncertainty. Consequently, this paper proposes the Long Short-Term Memory Bayesian Neural Networks (LSTM-BNNs) for household load forecasting in presence of EV charging. The approach takes advantage of the LSTM model to capture the time dependencies and uses the dropout layer with Bayesian inference to generate prediction intervals. Results show that the proposed LSTM-BNNs achieve accuracy similar to point forecasts with the advantage of prediction intervals. Moreover, the impact of lockdowns related to the COVID-19 pandemic on the load forecasting model is examined, and the analysis shows that there is no major change in the model performance as, for the considered households, the randomness of the EV charging outweighs the change due to pandemic.", "link": "https://arxiv.org/abs/2306.03010"}, {"id": "2306.03018", "date": "Mon, 5 Jun 2023 16:35:01 GMT", "title": "Quantification of Uncertainties in Deep Learning-based Environment\n Perception\n", "authors": ["Marco Braun", "Moritz Luszek", "Jan Siegemund", "Kevin Kollek", "Anton Kummert\n"], "categories": ["cs.LG", "cs.AI\nComments:", "2021", "IEEE", "International", "Conference", "on", "Omni-Layer", "Intelligent", "Systems\n", "(COINS),", "Barcelona,", "Spain,", "2021\nDOI:", "10.1109/COINS51742.2021.9524106\n"], "abstract": "In this work, we introduce a novel Deep Learning-based method to perceive the environment of a vehicle based on radar scans while accounting for uncertainties in its predictions. The environment of the host vehicle is segmented into equally sized grid cells which are classified individually. Complementary to the segmentation output, our Deep Learning-based algorithm is capable of differentiating uncertainties in its predictions as being related to an inadequate model (epistemic uncertainty) or noisy data (aleatoric uncertainty). To this end, weights are described as probability distributions accounting for uncertainties in the model parameters. Distributions are learned in a supervised fashion using gradient descent. We prove that uncertainties in the model output correlate with the precision of its predictions. Compared to previous concepts, we show superior performance of our approach to reliably perceive the environment of a vehicle.", "link": "https://arxiv.org/abs/2306.03018"}, {"id": "2306.03042", "date": "Mon, 5 Jun 2023 17:06:23 GMT", "title": "SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with\n Missing Values for Environmental Monitoring\n", "authors": ["Amin Shoari Nejad", "Roc\\'io Alaiz-Rodr\\'iguez", "Gerard D. McCarthy,\n Brian Kelleher", "Anthony Grey", "Andrew Parnell\n"], "categories": ["cs.LG", "cs.AI\nComments:", "11", "pages,", "7", "figures\n"], "abstract": "Environmental monitoring is crucial to our understanding of climate change, biodiversity loss and pollution. The availability of large-scale spatio-temporal data from sources such as sensors and satellites allows us to develop sophisticated models for forecasting and understanding key drivers. However, the data collected from sensors often contain missing values due to faulty equipment or maintenance issues. The missing values rarely occur simultaneously leading to data that are multivariate misaligned sparse time series. We propose two models that are capable of performing multivariate spatio-temporal forecasting while handling missing data naturally without the need for imputation. The first model is a transformer-based model, which we name SERT (Spatio-temporal Encoder Representations from Transformers). The second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial Neural Network) which is capable of providing interpretable results. We conduct extensive experiments on two different datasets for multivariate spatio-temporal forecasting and show that our models have competitive or superior performance to those at the state-of-the-art.", "link": "https://arxiv.org/abs/2306.03042"}, {"id": "2306.03076", "date": "Mon, 5 Jun 2023 17:52:44 GMT", "title": "Sensitivity-Aware Finetuning for Accuracy Recovery on Deep Learning\n Hardware\n", "authors": ["Lakshmi Nair and Darius Bunandar\n"], "categories": ["cs.LG", "cs.AR\nComments:", "7", "pages,", "2", "figures\n"], "abstract": "Existing methods to recover model accuracy on analog-digital hardware in the presence of quantization and analog noise include noise-injection training. However, it can be slow in practice, incurring high computational costs, even when starting from pretrained models. We introduce the Sensitivity-Aware Finetuning (SAFT) approach that identifies noise sensitive layers in a model, and uses the information to freeze specific layers for noise-injection training. Our results show that SAFT achieves comparable accuracy to noise-injection training and is 2x to 8x faster.", "link": "https://arxiv.org/abs/2306.03076"}, {"id": "2306.01914", "date": "Fri, 2 Jun 2023 20:43:38 GMT", "title": "Smooth Model Predictive Control with Applications to Statistical\n Learning\n", "authors": ["Kwangjun Ahn", "Daniel Pfrommer", "Jack Umenberger", "Tobia Marcucci", "Zak\n Mhammedi and Ali Jadbabaie\n"], "categories": ["eess.SY", "cs.LG", "cs.SY\nComments:", "15", "pages,", "1", "figure\n"], "abstract": "Statistical learning theory and high dimensional statistics have had a tremendous impact on Machine Learning theory and have impacted a variety of domains including systems and control theory. Over the past few years we have witnessed a variety of applications of such theoretical tools to help answer questions such as: how many state-action pairs are needed to learn a static control policy to a given accuracy? Recent results have shown that continuously differentiable and stabilizing control policies can be well-approximated using neural networks with hard guarantees on performance, yet often even the simplest constrained control problems are not smooth. To address this void, in this paper we study smooth approximations of linear Model Predictive Control (MPC) policies, in which hard constraints are replaced by barrier functions, a.k.a. barrier MPC. In particular, we show that barrier MPC inherits the exponential stability properties of the original non-smooth MPC policy. Using a careful analysis of the proposed barrier MPC, we show that its smoothness constant can be carefully controlled, thereby paving the way for new sample complexity results for approximating MPC policies from sampled state-action pairs.", "link": "https://arxiv.org/abs/2306.01914"}, {"id": "2306.02574", "date": "Mon, 5 Jun 2023 03:57:16 GMT", "title": "Bayesian Learning of Optimal Policies in Markov Decision Processes with\n Countably Infinite State-Space\n", "authors": ["Saghar Adler", "Vijay Subramanian\n"], "categories": ["eess.SY", "cs.LG", "cs.SY\n"], "abstract": "Models of many real-life applications, such as queuing models of communication networks or computing systems, have a countably infinite state-space. Algorithmic and learning procedures that have been developed to produce optimal policies mainly focus on finite state settings, and do not directly apply to these models. To overcome this lacuna, in this work we study the problem of optimal control of a family of discrete-time countable state-space Markov Decision Processes (MDPs) governed by an unknown parameter $\\theta\\in\\Theta$, and defined on a countably-infinite state space $\\mathcal X=\\mathbb{Z}_+^d$, with finite action space $\\mathcal A$, and an unbounded cost function. We take a Bayesian perspective with the random unknown parameter $\\boldsymbol{\\theta}^*$ generated via a given fixed prior distribution on $\\Theta$. To optimally control the unknown MDP, we propose an algorithm based on Thompson sampling with dynamically-sized episodes: at the beginning of each episode, the posterior distribution formed via Bayes' rule is used to produce a parameter estimate, which then decides the policy applied during the episode. To ensure the stability of the Markov chain obtained by following the policy chosen for each parameter, we impose ergodicity assumptions. From this condition and using the solution of the average cost Bellman equation, we establish an $\\tilde O(\\sqrt{|\\mathcal A|T})$ upper bound on the Bayesian regret of our algorithm, where $T$ is the time-horizon. Finally, to elucidate the applicability of our algorithm, we consider two different queuing models with unknown dynamics, and show that our algorithm can be applied to develop approximately optimal control algorithms.", "link": "https://arxiv.org/abs/2306.02574"}, {"id": "2306.02634", "date": "Mon, 5 Jun 2023 07:09:21 GMT", "title": "Computational 3D topographic microscopy from terabytes of data per\n sample\n", "authors": ["Kevin C. Zhou", "Mark Harfouche", "Maxwell Zheng", "Joakim J\\\"onsson", "Kyung\n Chul Lee", "Ron Appel", "Paul Reamey", "Thomas Doman", "Veton Saliu", "Gregor\n Horstmeyer", "and Roarke Horstmeyer\n"], "categories": ["physics.optics", "cs.CV", "cs.LG", "eess.IV\n"], "abstract": "We present a large-scale computational 3D topographic microscope that enables 6-gigapixel profilometric 3D imaging at micron-scale resolution across $>$110 cm$^2$ areas over multi-millimeter axial ranges. Our computational microscope, termed STARCAM (Scanning Topographic All-in-focus Reconstruction with a Computational Array Microscope), features a parallelized, 54-camera architecture with 3-axis translation to capture, for each sample of interest, a multi-dimensional, 2.1-terabyte (TB) dataset, consisting of a total of 224,640 9.4-megapixel images. We developed a self-supervised neural network-based algorithm for 3D reconstruction and stitching that jointly estimates an all-in-focus photometric composite and 3D height map across the entire field of view, using multi-view stereo information and image sharpness as a focal metric. The memory-efficient, compressed differentiable representation offered by the neural network effectively enables joint participation of the entire multi-TB dataset during the reconstruction process. To demonstrate the broad utility of our new computational microscope, we applied STARCAM to a variety of decimeter-scale objects, with applications ranging from cultural heritage to industrial inspection.", "link": "https://arxiv.org/abs/2306.02634"}, {"id": "2306.01751", "date": "Mon, 22 May 2023 16:33:23 GMT", "title": "Differential Privacy with Random Projections and Sign Random Projections\n", "authors": ["Ping Li and Xiaoyun Li\n"], "categories": ["cs.CR", "cs.LG", "stat.ML\n"], "abstract": "In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \\textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \\textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \\textbf{DP-OPORP} achieves the best performance. The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embeddings across companies or countries). In our study, we find that \\textbf{iDP-SignRP} is remarkably effective for search and machine learning applications, in that the utilities are exceptionally good even at a very small privacy parameter $\\epsilon$ (e.g., $\\epsilon<0.5$).", "link": "https://arxiv.org/abs/2306.01751"}, {"id": "2306.01785", "date": "Wed, 31 May 2023 12:01:02 GMT", "title": "Beyond Rankings: Exploring the Impact of SERP Features on Organic\n Click-through Rates\n", "authors": ["Erik Fubel and Niclas Michael Groll and Patrick Gundlach and Qiwei Han\n and Maximilian Kaiser\n"], "categories": ["cs.IR", "cs.LG", "cs.SI\nComments:", "submitted", "IEEE", "DSAA", "conference,", "14", "pages,", "5", "figures,", "2", "tables\n"], "abstract": "Search Engine Result Pages (SERPs) serve as the digital gateways to the vast expanse of the internet. Past decades have witnessed a surge in research primarily centered on the influence of website ranking on these pages, to determine the click-through rate (CTR). However, during this period, the landscape of SERPs has undergone a dramatic evolution: SERP features, encompassing elements such as knowledge panels, media galleries, FAQs, and more, have emerged as an increasingly prominent facet of these result pages. Our study examines the crucial role of these features, revealing them to be not merely aesthetic components, but strongly influence CTR and the associated behavior of internet users. We demonstrate how these features can significantly modulate web traffic, either amplifying or attenuating it. We dissect these intricate interaction effects leveraging a unique dataset of 67,000 keywords and their respective Google SERPs, spanning over 40 distinct US-based e-commerce domains, generating over 6 million clicks from 24 million views. This cross-website dataset, unprecedented in its scope, enables us to assess the impact of 24 different SERP features on organic CTR. Through an ablation study modeling CTR, we illustrate the incremental predictive power these features hold.", "link": "https://arxiv.org/abs/2306.01785"}, {"id": "2306.01802", "date": "Thu, 1 Jun 2023 16:31:36 GMT", "title": "Linear Time GPs for Inferring Latent Trajectories from Neural Spike\n Trains\n", "authors": ["Matthew Dowling", "Yuan Zhao", "Il Memming Park\n"], "categories": ["q-bio.NC", "cs.LG", "stat.AP", "stat.ML\nComments:", "Published", "at", "ICML", "2023\n"], "abstract": "Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Mat\\'ern kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Mat\\'ern GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more concise implementation. Furthermore, we employ the Whittle approximate likelihood to achieve highly efficient hyperparameter learning.", "link": "https://arxiv.org/abs/2306.01802"}, {"id": "2306.01824", "date": "Fri, 2 Jun 2023 14:13:50 GMT", "title": "Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence\n Alignment Generation\n", "authors": ["Le Zhang", "Jiayang Chen", "Tao Shen", "Yu Li", "Siqi Sun\n"], "categories": ["q-bio.QM", "cs.CE", "cs.LG", "q-bio.BM\n"], "abstract": "The field of protein folding research has been greatly advanced by deep learning methods, with AlphaFold2 (AF2) demonstrating exceptional performance and atomic-level precision. As co-evolution is integral to protein structure prediction, AF2's accuracy is significantly influenced by the depth of multiple sequence alignment (MSA), which requires extensive exploration of a large protein database for similar sequences. However, not all protein sequences possess abundant homologous families, and consequently, AF2's performance can degrade on such queries, at times failing to produce meaningful results. To address this, we introduce a novel generative language model, MSA-Augmenter, which leverages protein-specific attention mechanisms and large-scale MSAs to generate useful, novel protein sequences not currently found in databases. These sequences supplement shallow MSAs, enhancing the accuracy of structural property predictions. Our experiments on CASP14 demonstrate that MSA-Augmenter can generate de novo sequences that retain co-evolutionary information from inferior MSAs, thereby improving protein structure prediction quality on top of strong AF2.", "link": "https://arxiv.org/abs/2306.01824"}, {"id": "2306.02015", "date": "Sat, 3 Jun 2023 06:19:20 GMT", "title": "Machine learning enabled experimental design and parameter estimation\n for ultrafast spin dynamics\n", "authors": ["Zhantao Chen", "Cheng Peng", "Alexander N. Petsch", "Sathya R. Chitturi,\n Alana Okullo", "Sugata Chowdhury", "Chun Hong Yoon", "Joshua J. Turner\n"], "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph", "physics.data-an\n"], "abstract": "Advanced experimental measurements are crucial for driving theoretical developments and unveiling novel phenomena in condensed matter and material physics, which often suffer from the scarcity of facility resources and increasing complexities. To address the limitations, we introduce a methodology that combines machine learning with Bayesian optimal experimental design (BOED), exemplified with x-ray photon fluctuation spectroscopy (XPFS) measurements for spin fluctuations. Our method employs a neural network model for large-scale spin dynamics simulations for precise distribution and utility calculations in BOED. The capability of automatic differentiation from the neural network model is further leveraged for more robust and accurate parameter estimation. Our numerical benchmarks demonstrate the superior performance of our method in guiding XPFS experiments, predicting model parameters, and yielding more informative measurements within limited experimental time. Although focusing on XPFS and spin fluctuations, our method can be adapted to other experiments, facilitating more efficient data collection and accelerating scientific discoveries.", "link": "https://arxiv.org/abs/2306.02015"}, {"id": "2306.02108", "date": "Sat, 3 Jun 2023 13:16:17 GMT", "title": "Random matrix theory and the loss surfaces of neural networks\n", "authors": ["Nicholas P Baskerville\n"], "categories": ["math-ph", "cs.LG", "math.MP", "math.PR\nComments:", "320", "pages,", "PhD", "thesis\n"], "abstract": "Neural network models are one of the most successful approaches to machine learning, enjoying an enormous amount of development and research over recent years and finding concrete real-world applications in almost any conceivable area of science, engineering and modern life in general. The theoretical understanding of neural networks trails significantly behind their practical success and the engineering heuristics that have grown up around them. Random matrix theory provides a rich framework of tools with which aspects of neural network phenomenology can be explored theoretically. In this thesis, we establish significant extensions of prior work using random matrix theory to understand and describe the loss surfaces of large neural networks, particularly generalising to different architectures. Informed by the historical applications of random matrix theory in physics and elsewhere, we establish the presence of local random matrix universality in real neural networks and then utilise this as a modeling assumption to derive powerful and novel results about the Hessians of neural network loss surfaces and their spectra. In addition to these major contributions, we make use of random matrix models for neural network loss surfaces to shed light on modern neural network training approaches and even to derive a novel and effective variant of a popular optimisation algorithm. Overall, this thesis provides important contributions to cement the place of random matrix theory in the theoretical study of modern neural networks, reveals some of the limits of existing approaches and begins the study of an entirely new role for random matrix theory in the theory of deep learning with important experimental discoveries and novel theoretical results based on local random matrix universality.", "link": "https://arxiv.org/abs/2306.02108"}, {"id": "2306.02149", "date": "Sat, 3 Jun 2023 16:34:25 GMT", "title": "Infomorphic networks: Locally learning neural networks derived from\n partial information decomposition\n", "authors": ["Marcel Graetz", "Abdullah Makkeh", "Andreas C. Schneider", "David A.\n Ehrlich", "Viola Priesemann and Michael Wibral\n"], "categories": ["cs.IT", "cs.LG", "cs.NE", "math.IT\nComments:", "31", "pages,", "5", "figures\n"], "abstract": "Understanding the intricate cooperation among individual neurons in performing complex tasks remains a challenge to this date. In this paper, we propose a novel type of model neuron that emulates the functional characteristics of biological neurons by optimizing an abstract local information processing goal. We have previously formulated such a goal function based on principles from partial information decomposition (PID). Here, we present a corresponding parametric local learning rule which serves as the foundation of \"infomorphic networks\" as a novel concrete model of neural networks. We demonstrate the versatility of these networks to perform tasks from supervised, unsupervised and memory learning. By leveraging the explanatory power and interpretable nature of the PID framework, these infomorphic networks represent a valuable tool to advance our understanding of cortical function.", "link": "https://arxiv.org/abs/2306.02149"}, {"id": "2306.02153", "date": "Sat, 3 Jun 2023 16:44:21 GMT", "title": "Acoustic Word Embeddings for Untranscribed Target Languages with\n Continued Pretraining and Learned Pooling\n", "authors": ["Ramon Sanabria", "Ondrej Klejch", "Hao Tang", "Sharon Goldwater\n"], "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS\nComments:", "Accepted", "to", "Interspeech", "2023\n"], "abstract": "Acoustic word embeddings are typically created by training a pooling function using pairs of word-like units. For unsupervised systems, these are mined using k-nearest neighbor (KNN) search, which is slow. Recently, mean-pooled representations from a pre-trained self-supervised English model were suggested as a promising alternative, but their performance on target languages was not fully competitive. Here, we explore improvements to both approaches: we use continued pre-training to adapt the self-supervised model to the target language, and we use a multilingual phone recognizer (MPR) to mine phone n-gram pairs for training the pooling function. Evaluating on four languages, we show that both methods outperform a recent approach on word discrimination. Moreover, the MPR method is orders of magnitude faster than KNN, and is highly data efficient. We also show a small improvement from performing learned pooling on top of the continued pre-trained representations.", "link": "https://arxiv.org/abs/2306.02153"}, {"id": "2306.02212", "date": "Sat, 3 Jun 2023 23:31:27 GMT", "title": "Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth\n Convex Optimization\n", "authors": ["Ruichen Jiang and Aryan Mokhtari\n"], "categories": ["math.OC", "cs.LG", "stat.ML\nComments:", "44", "pages,", "1", "figure\n"], "abstract": "In this paper, we propose an accelerated quasi-Newton proximal extragradient (A-QPNE) method for solving unconstrained smooth convex optimization problems. With access only to the gradients of the objective, we prove that our method can achieve a convergence rate of ${O}\\bigl(\\min\\{\\frac{1}{k^2}, \\frac{\\sqrt{d\\log k}}{k^{2.5}}\\}\\bigr)$, where $d$ is the problem dimension and $k$ is the number of iterations. In particular, in the regime where $k = {O}(d)$, our method matches the optimal rate of ${O}(\\frac{1}{k^2})$ by Nesterov's accelerated gradient (NAG). Moreover, in the the regime where $k = \\Omega(d \\log d)$, it outperforms NAG and converges at a faster rate of ${O}\\bigl(\\frac{\\sqrt{d\\log k}}{k^{2.5}}\\bigr)$. To the best of our knowledge, this result is the first to demonstrate a provable gain of a quasi-Newton-type method over NAG in the convex setting. To achieve such results, we build our method on a recent variant of the Monteiro-Svaiter acceleration framework and adopt an online learning perspective to update the Hessian approximation matrices, in which we relate the convergence rate of our method to the dynamic regret of a specific online convex optimization problem in the space of matrices.", "link": "https://arxiv.org/abs/2306.02212"}, {"id": "2306.02383", "date": "Sun, 4 Jun 2023 15:33:16 GMT", "title": "Evolution of Efficient Symbolic Communication Codes\n", "authors": ["Anton Kolonin\n"], "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT\nComments:", "9", "pages,", "6", "figures\n"], "abstract": "The paper explores how the human natural language structure can be seen as a product of evolution of inter-personal communication code, targeting maximisation of such culture-agnostic and cross-lingual metrics such as anti-entropy, compression factor and cross-split F1 score. The exploration is done as part of a larger unsupervised language learning effort, the attempt is made to perform meta-learning in a space of hyper-parameters maximising F1 score based on the \"ground truth\" language structure, by means of maximising the metrics mentioned above. The paper presents preliminary results of cross-lingual word-level segmentation tokenisation study for Russian, Chinese and English as well as subword segmentation or morphological parsing study for English. It is found that language structure form the word-level segmentation or tokenisation can be found as driven by all of these metrics, anti-entropy being more relevant to English and Russian while compression factor more specific for Chinese. The study for subword segmentation or morphological parsing on English lexicon has revealed straight connection between the compression been found to be associated with compression factor, while, surprising, the same connection with anti-entropy has turned to be the inverse.", "link": "https://arxiv.org/abs/2306.02383"}, {"id": "2306.02534", "date": "Mon, 5 Jun 2023 01:55:33 GMT", "title": "Incorporating L2 Phonemes Using Articulatory Features for Robust Speech\n Recognition\n", "authors": ["Jisung Wang", "Haram Lee", "Myungwoo Oh\n"], "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS\nComments:", "Accepted", "at", "INTERSPEECH", "2023\n"], "abstract": "The limited availability of non-native speech datasets presents a major challenge in automatic speech recognition (ASR) to narrow the performance gap between native and non-native speakers. To address this, the focus of this study is on the efficient incorporation of the L2 phonemes, which in this work refer to Korean phonemes, through articulatory feature analysis. This not only enables accurate modeling of pronunciation variants but also allows for the utilization of both native Korean and English speech datasets. We employ the lattice-free maximum mutual information (LF-MMI) objective in an end-to-end manner, to train the acoustic model to align and predict one of multiple pronunciation candidates. Experimental results show that the proposed method improves ASR accuracy for Korean L2 speech by training solely on L1 speech data. Furthermore, fine-tuning on L2 speech improves recognition accuracy for both L1 and L2 speech without performance trade-offs.", "link": "https://arxiv.org/abs/2306.02534"}, {"id": "2306.02680", "date": "Mon, 5 Jun 2023 08:12:17 GMT", "title": "BeAts: Bengali Speech Acts Recognition using Multimodal Attention Fusion\n", "authors": ["Ahana Deb", "Sayan Nag", "Ayan Mahapatra", "Soumitri Chattopadhyay", "Aritra\n Marik", "Pijush Kanti Gayen", "Shankha Sanyal", "Archi Banerjee", "Samir Karmakar\n"], "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS\nComments:", "Accepted", "at", "INTERSPEECH", "2023\n"], "abstract": "Spoken languages often utilise intonation, rhythm, intensity, and structure, to communicate intention, which can be interpreted differently depending on the rhythm of speech of their utterance. These speech acts provide the foundation of communication and are unique in expression to the language. Recent advancements in attention-based models, demonstrating their ability to learn powerful representations from multilingual datasets, have performed well in speech tasks and are ideal to model specific tasks in low resource languages. Here, we develop a novel multimodal approach combining two models, wav2vec2.0 for audio and MarianMT for text translation, by using multimodal attention fusion to predict speech acts in our prepared Bengali speech corpus. We also show that our model BeAts ($\\underline{\\textbf{Be}}$ngali speech acts recognition using Multimodal $\\underline{\\textbf{At}}$tention Fu$\\underline{\\textbf{s}}$ion) significantly outperforms both the unimodal baseline using only speech data and a simpler bimodal fusion using both speech and text data. Project page: https://soumitri2001.github.io/BeAts", "link": "https://arxiv.org/abs/2306.02680"}, {"id": "2306.02719", "date": "Mon, 5 Jun 2023 09:12:34 GMT", "title": "Multiple output samples for each input in a single-output Gaussian\n process\n", "authors": ["Jeremy H. M. Wong", "Huayun Zhang", "and Nancy F. Chen\n"], "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS\n"], "abstract": "The standard Gaussian Process (GP) only considers a single output sample per input in the training set. Datasets for subjective tasks, such as spoken language assessment, may be annotated with output labels from multiple human raters per input. This paper proposes to generalise the GP to allow for these multiple output samples in the training set, and thus make use of available output uncertainty information. This differs from a multi-output GP, as all output samples are from the same task here. The output density function is formulated to be the joint likelihood of observing all output samples, and latent variables are not repeated to reduce computation cost. The test set predictions are inferred similarly to a standard GP, with a difference being in the optimised hyper-parameters. This is evaluated on speechocean762, showing that it allows the GP to compute a test set output distribution that is more similar to the collection of reference outputs from the multiple human raters.", "link": "https://arxiv.org/abs/2306.02719"}, {"id": "2306.02833", "date": "Mon, 5 Jun 2023 12:29:13 GMT", "title": "The $L^\\infty$ Learnability of Reproducing Kernel Hilbert Spaces\n", "authors": ["Hongrui Chen", "Jihao Long", "Lei Wu\n"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH\nComments:", "20", "pages\n"], "abstract": "In this work, we analyze the learnability of reproducing kernel Hilbert spaces (RKHS) under the $L^\\infty$ norm, which is critical for understanding the performance of kernel methods and random feature models in safety- and security-critical applications. Specifically, we relate the $L^\\infty$ learnability of a RKHS to the spectrum decay of the associate kernel and both lower bounds and upper bounds of the sample complexity are established. In particular, for dot-product kernels on the sphere, we identify conditions when the $L^\\infty$ learning can be achieved with polynomial samples. Let $d$ denote the input dimension and assume the kernel spectrum roughly decays as $\\lambda_k\\sim k^{-1-\\beta}$ with $\\beta>0$. We prove that if $\\beta$ is independent of the input dimension $d$, then functions in the RKHS can be learned efficiently under the $L^\\infty$ norm, i.e., the sample complexity depends polynomially on $d$. In contrast, if $\\beta=1/\\mathrm{poly}(d)$, then the $L^\\infty$ learning requires exponentially many samples.", "link": "https://arxiv.org/abs/2306.02833"}, {"id": "2306.02895", "date": "Mon, 5 Jun 2023 14:04:53 GMT", "title": "Evading Black-box Classifiers Without Breaking Eggs\n", "authors": ["Edoardo Debenedetti", "Nicholas Carlini and Florian Tram\\`er\n"], "categories": ["cs.CR", "cs.LG", "stat.ML\nComments:", "Code", "at", "https://github.com/ethz-privsec/realistic-adv-examples\n"], "abstract": "Decision-based evasion attacks repeatedly query a black-box classifier to generate adversarial examples. Prior work measures the cost of such attacks by the total number of queries made to the classifier. We argue this metric is flawed. Most security-critical machine learning systems aim to weed out \"bad\" data (e.g., malware, harmful content, etc). Queries to such systems carry a fundamentally asymmetric cost: queries detected as \"bad\" come at a higher cost because they trigger additional security filters, e.g., usage throttling or account suspension. Yet, we find that existing decision-based attacks issue a large number of \"bad\" queries, which likely renders them ineffective against security-critical systems. We then design new attacks that reduce the number of bad queries by $1.5$-$7.3\\times$, but often at a significant increase in total (non-bad) queries. We thus pose it as an open problem to build black-box attacks that are more effective under realistic cost metrics.", "link": "https://arxiv.org/abs/2306.02895"}, {"id": "2306.02948", "date": "Mon, 5 Jun 2023 15:14:34 GMT", "title": "Random Distribution Shift in Refugee Placement: Strategies for Building\n Robust Models\n", "authors": ["Kirk Bansak", "Elisabeth Paulson", "Dominik Rothenh\\\"ausler\n"], "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME\n"], "abstract": "Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -- the failure points of the other two methods, respectively. We compare these approaches empirically using data on asylum seekers in the Netherlands. Surprisingly, we find that both the proxy and hybrid approaches out-perform the standard approach in practice. These insights support the development of a real-world recommendation tool currently used by NGOs and government agencies.", "link": "https://arxiv.org/abs/2306.02948"}, {"id": "2306.02984", "date": "Mon, 5 Jun 2023 15:53:56 GMT", "title": "A Deep Learning Approach Utilizing Covariance Matrix Analysis for the\n ISBI Edited MRS Reconstruction Challenge\n", "authors": ["Julian P. Merkofer", "Dennis M. J. van de Sande", "Sina Amirrajab", "Gerhard\n S. Drenthen", "Mitko Veta", "Jacobus F. A. Jansen", "Marcel Breeuwer", "and Ruud J.\n G. van Sloun\n"], "categories": ["physics.med-ph", "cs.LG", "eess.IV\n"], "abstract": "This work proposes a method to accelerate the acquisition of high-quality edited magnetic resonance spectroscopy (MRS) scans using machine learning models taking the sample covariance matrix as input. The method is invariant to the number of transients and robust to noisy input data for both synthetic as well as in-vivo scenarios.", "link": "https://arxiv.org/abs/2306.02984"}, {"id": "2306.02990", "date": "Mon, 5 Jun 2023 16:01:33 GMT", "title": "Integrated Sensing, Computation, and Communication for UAV-assisted\n Federated Edge Learning\n", "authors": ["Yao Tang", "Guangxu Zhu", "Wei Xu", "Man Hon Cheung", "Tat-Ming Lok", "Shuguang\n Cui\n"], "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT\n"], "abstract": "Federated edge learning (FEEL) enables privacy-preserving model training through periodic communication between edge devices and the server. Unmanned Aerial Vehicle (UAV)-mounted edge devices are particularly advantageous for FEEL due to their flexibility and mobility in efficient data collection. In UAV-assisted FEEL, sensing, computation, and communication are coupled and compete for limited onboard resources, and UAV deployment also affects sensing and communication performance. Therefore, the joint design of UAV deployment and resource allocation is crucial to achieving the optimal training performance. In this paper, we address the problem of joint UAV deployment design and resource allocation for FEEL via a concrete case study of human motion recognition based on wireless sensing. We first analyze the impact of UAV deployment on the sensing quality and identify a threshold value for the sensing elevation angle that guarantees a satisfactory quality of data samples. Due to the non-ideal sensing channels, we consider the probabilistic sensing model, where the successful sensing probability of each UAV is determined by its position. Then, we derive the upper bound of the FEEL training loss as a function of the sensing probability. Theoretical results suggest that the convergence rate can be improved if UAVs have a uniform successful sensing probability. Based on this analysis, we formulate a training time minimization problem by jointly optimizing UAV deployment, integrated sensing, computation, and communication (ISCC) resources under a desirable optimality gap constraint. To solve this challenging mixed-integer non-convex problem, we apply the alternating optimization technique, and propose the bandwidth, batch size, and position optimization (BBPO) scheme to optimize these three decision variables alternately.", "link": "https://arxiv.org/abs/2306.02990"}, {"id": "2306.03009", "date": "Mon, 5 Jun 2023 16:19:48 GMT", "title": "Using Sequences of Life-events to Predict Human Lives\n", "authors": ["Germans Savcisens", "Tina Eliassi-Rad", "Lars Kai Hansen", "Laust Mortensen,\n Lau Lilleholt", "Anna Rogers", "Ingo Zettler", "Sune Lehmann\n"], "categories": ["stat.ML", "cs.LG", "stat.AP\nDOI:", "10.21203/rs.3.rs-2975478/v1\n"], "abstract": "Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our data include information about life-events related to health, education, occupation, income, address, and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to identify new potential mechanisms that impact life outcomes and associated possibilities for personalized interventions.", "link": "https://arxiv.org/abs/2306.03009"}, {"id": "2306.03014", "date": "Mon, 5 Jun 2023 16:30:17 GMT", "title": "On the Behavior of Intrusive and Non-intrusive Speech Enhancement\n Metrics in Predictive and Generative Settings\n", "authors": ["Danilo de Oliveira", "Julius Richter", "Jean-Marie Lemercier", "Tal Peer,\n Timo Gerkmann\n"], "categories": ["eess.AS", "cs.LG", "cs.SD\nComments:", "Submitted", "to", "ITG", "Conference", "on", "Speech", "Communication\n"], "abstract": "Since its inception, the field of deep speech enhancement has been dominated by predictive (discriminative) approaches, such as spectral mapping or masking. Recently, however, novel generative approaches have been applied to speech enhancement, attaining good denoising performance with high subjective quality scores. At the same time, advances in deep learning also allowed for the creation of neural network-based metrics, which have desirable traits such as being able to work without a reference (non-intrusively). Since generatively enhanced speech tends to exhibit radically different residual distortions, its evaluation using instrumental speech metrics may behave differently compared to predictively enhanced speech. In this paper, we evaluate the performance of the same speech enhancement backbone trained under predictive and generative paradigms on a variety of metrics and show that intrusive and non-intrusive measures correlate differently for each paradigm. This analysis motivates the search for metrics that can together paint a complete and unbiased picture of speech enhancement performance, irrespective of the model's training process.", "link": "https://arxiv.org/abs/2306.03014"}, {"id": "2306.01744", "date": "Sat, 13 May 2023 11:40:31 GMT", "title": "Disproving XAI Myths with Formal Methods -- Initial Results\n", "authors": ["Joao Marques-Silva\n"], "categories": ["cs.AI", "cs.LG\n"], "abstract": "The advances in Machine Learning (ML) in recent years have been both impressive and far-reaching. However, the deployment of ML models is still impaired by a lack of trust in how the best-performing ML models make predictions. The issue of lack of trust is even more acute in the uses of ML models in high-risk or safety-critical domains. eXplainable artificial intelligence (XAI) is at the core of ongoing efforts for delivering trustworthy AI. Unfortunately, XAI is riddled with critical misconceptions, that foster distrust instead of building trust. This paper details some of the most visible misconceptions in XAI, and shows how formal methods have been used, both to disprove those misconceptions, but also to devise practically effective alternatives.", "link": "https://arxiv.org/abs/2306.01744"}, {"id": "2306.01750", "date": "Sat, 20 May 2023 11:55:27 GMT", "title": "A Survey of Explainable AI and Proposal for a Discipline of Explanation\n Engineering\n", "authors": ["Clive Gomes", "Lalitha Natraj", "Shijun Liu", "Anushka Datta\n"], "categories": ["cs.AI", "cs.HC\n"], "abstract": "In this survey paper, we deep dive into the field of Explainable Artificial Intelligence (XAI). After introducing the scope of this paper, we start by discussing what an \"explanation\" really is. We then move on to discuss some of the existing approaches to XAI and build a taxonomy of the most popular methods. Next, we also look at a few applications of these and other XAI techniques in four primary domains: finance, autonomous driving, healthcare and manufacturing. We end by introducing a promising discipline, \"Explanation Engineering,\" which includes a systematic approach for designing explainability into AI systems.", "link": "https://arxiv.org/abs/2306.01750"}, {"id": "2306.01769", "date": "Sun, 28 May 2023 21:33:15 GMT", "title": "Towards a Technology-Driven Adaptive Decision Support System for\n Integrated Pavement and Maintenance strategies (TDADSS-IPM): focus on risk\n assessment framework for climate change adaptation\n", "authors": ["Shahrzad Pour", "Amir Masoumi", "Niels Skov Dujardin\n"], "categories": ["cs.AI", "stat.AP\n"], "abstract": "Decision Support Systems for pavement and maintenance strategies have traditionally been designed as silos led to local optimum systems. Moreover, since big data usage didn't exist as result of Industry 4.0 as of today, DSSs were not initially designed adaptive to the sources of uncertainties led to rigid decisions. Motivated by the vulnerability of the road assets to the climate phenomena, this paper takes a visionary step towards introducing a Technology-Driven Adaptive Decision Support System for Integrated Pavement and Maintenance activities called TDADSS-IPM. As part of such DSS, a bottom-up risk assessment model is met via Bayesian Belief Networks (BBN) to realize the actual condition of the Danish roads due to weather condition. Such model fills the gaps in the knowledge domain and develops a platform that can be trained over time, and applied in real-time to the actual event.", "link": "https://arxiv.org/abs/2306.01769"}, {"id": "2306.01784", "date": "Wed, 31 May 2023 10:36:16 GMT", "title": "Evaluating GPT's Programming Capability through CodeWars' Katas\n", "authors": ["Zizhuo Zhang", "Lian Wen", "Shaoyang Zhang", "David Chen", "Yanfei Jiang\n"], "categories": ["cs.AI", "cs.SE\nComments:", "9", "pages\n"], "abstract": "In the burgeoning field of artificial intelligence (AI), understanding the capabilities and limitations of programming-oriented models is crucial. This paper presents a novel evaluation of the programming proficiency of Generative Pretrained Transformer (GPT) models, specifically GPT-3.5 and GPT-4, against coding problems of varying difficulty levels drawn from Codewars. The experiments reveal a distinct boundary at the 3kyu level, beyond which these GPT models struggle to provide solutions. These findings led to the proposal of a measure for coding problem complexity that incorporates both problem difficulty and the time required for solution. The research emphasizes the need for validation and creative thinking capabilities in AI models to better emulate human problem-solving techniques. Future work aims to refine this proposed complexity measure, enhance AI models with these suggested capabilities, and develop an objective measure for programming problem difficulty. The results of this research offer invaluable insights for improving AI programming capabilities and advancing the frontier of AI problem-solving abilities.", "link": "https://arxiv.org/abs/2306.01784"}, {"id": "2306.01795", "date": "Thu, 1 Jun 2023 12:28:08 GMT", "title": "AI and the creative realm: A short review of current and future\n applications\n", "authors": ["Fabio Crimaldi", "Manuele Leonelli\n"], "categories": ["cs.AI", "cs.HC\n"], "abstract": "This study explores the concept of creativity and artificial intelligence (AI) and their recent integration. While AI has traditionally been perceived as incapable of generating new ideas or creating art, the development of more sophisticated AI models and the proliferation of human-computer interaction tools have opened up new possibilities for AI in artistic creation. This study investigates the various applications of AI in a creative context, differentiating between the type of art, language, and algorithms used. It also considers the philosophical implications of AI and creativity, questioning whether consciousness can be researched in machines and AI's potential interests and decision-making capabilities. Overall, we aim to stimulate a reflection on AI's use and ethical implications in creative contexts.", "link": "https://arxiv.org/abs/2306.01795"}, {"id": "2306.02071", "date": "Sat, 3 Jun 2023 10:22:50 GMT", "title": "DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation\n", "authors": ["Felipe Garrido-Lucero and Benjamin Heymann and Maxime Vono and Patrick\n Loiseau and Vianney Perchet\n"], "categories": ["cs.AI", "cs.GT", "stat.CO", "stat.ML\nComments:", "22", "pages\n"], "abstract": "Many machine learning problems require performing dataset valuation, i.e. to quantify the incremental gain, to some relevant pre-defined utility, of aggregating an individual dataset to others. As seminal examples, dataset valuation has been leveraged in collaborative and federated learning to create incentives for data sharing across several data owners. The Shapley value has recently been proposed as a principled tool to achieve this goal due to formal axiomatic justification. Since its computation often requires exponential time, standard approximation strategies based on Monte Carlo integration have been considered. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation of the Shapley value, referred to as discrete uniform Shapley (DU-Shapley) which is expressed as an expectation under a discrete uniform distribution with support of reasonable size. We justify the relevancy of the proposed framework via asymptotic and non-asymptotic theoretical guarantees and show that DU-Shapley tends towards the Shapley value when the number of data owners is large. The benefits of the proposed framework are finally illustrated on several dataset valuation benchmarks. DU-Shapley outperforms other Shapley value approximations, even when the number of data owners is small.", "link": "https://arxiv.org/abs/2306.02071"}, {"id": "2306.02165", "date": "Sat, 3 Jun 2023 17:51:04 GMT", "title": "Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning\n in Cybersecurity Games\n", "authors": ["Tyler Malloy", "Cleotilde Gonzalez\n"], "categories": ["cs.AI", "cs.CR", "cs.LG\n"], "abstract": "Designing cyber defense systems to account for cognitive biases in human decision making has demonstrated significant success in improving performance against human attackers. However, much of the attention in this area has focused on relatively simple accounts of biases in human attackers, and little is known about adversarial behavior or how defenses could be improved by disrupting attacker's behavior. In this work, we present a novel model of human decision-making inspired by the cognitive faculties of Instance-Based Learning Theory, Theory of Mind, and Transfer of Learning. This model functions by learning from both roles in a security scenario: defender and attacker, and by making predictions of the opponent's beliefs, intentions, and actions. The proposed model can better defend against attacks from a wide range of opponents compared to alternatives that attempt to perform optimally without accounting for human biases. Additionally, the proposed model performs better against a range of human-like behavior by explicitly modeling human transfer of learning, which has not yet been applied to cyber defense scenarios. Results from simulation experiments demonstrate the potential usefulness of cognitively inspired models of agents trained in attack and defense roles and how these insights could potentially be used in real-world cybersecurity.", "link": "https://arxiv.org/abs/2306.02165"}, {"id": "2306.02224", "date": "Sun, 4 Jun 2023 01:07:20 GMT", "title": "Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions\n", "authors": ["Hui Yang", "Sifu Yue", "Yunzhong He\n"], "categories": ["cs.AI", "cs.LG\n"], "abstract": "Auto-GPT is an autonomous agent that leverages recent advancements in adapting Large Language Models (LLMs) for decision-making tasks. While there has been a growing interest in Auto-GPT stypled agents, questions remain regarding the effectiveness and flexibility of Auto-GPT in solving real-world decision-making tasks. Its limited capability for real-world engagement and the absence of benchmarks contribute to these uncertainties. In this paper, we present a comprehensive benchmark study of Auto-GPT styled agents in decision-making tasks that simulate real-world scenarios. Our aim is to gain deeper insights into this problem and understand the adaptability of GPT-based agents. We compare the performance of popular LLMs such as GPT-4, GPT-3.5, Claude, and Vicuna in Auto-GPT styled decision-making tasks. Furthermore, we introduce the Additional Opinions algorithm, an easy and effective method that incorporates supervised/imitation-based learners into the Auto-GPT scheme. This approach enables lightweight supervised learning without requiring fine-tuning of the foundational LLMs. We demonstrate through careful baseline comparisons and ablation studies that the Additional Opinions algorithm significantly enhances performance in online decision-making benchmarks, including WebShop and ALFWorld.", "link": "https://arxiv.org/abs/2306.02224"}, {"id": "2306.02487", "date": "Sun, 4 Jun 2023 21:40:11 GMT", "title": "Discussion Paper: The Threat of Real Time Deepfakes\n", "authors": ["Guy Frankovits and Yisroel Mirsky\n"], "categories": ["cs.AI", "cs.CR", "cs.CV\nJournal-ref:", "FRANKOVITS,", "Guy;", "YISROEL,", "Mirsky.", "Discussion", "Paper:", "The", "Threat", "of\n", "Real", "Time", "Deepfakes.", "In:", "Proceedings", "of", "the", "2st", "Workshop", "on", "Security\n", "Implications", "of", "Deepfakes", "and", "Cheapfakes.", "2023\n"], "abstract": "Generative deep learning models are able to create realistic audio and video. This technology has been used to impersonate the faces and voices of individuals. These ``deepfakes'' are being used to spread misinformation, enable scams, perform fraud, and blackmail the innocent. The technology continues to advance and today attackers have the ability to generate deepfakes in real-time. This new capability poses a significant threat to society as attackers begin to exploit the technology in advances social engineering attacks. In this paper, we discuss the implications of this emerging threat, identify the challenges with preventing these attacks and suggest a better direction for researching stronger defences.", "link": "https://arxiv.org/abs/2306.02487"}, {"id": "2306.02684", "date": "Mon, 5 Jun 2023 08:20:37 GMT", "title": "A Novel Multi-Agent Deep RL Approach for Traffic Signal Control\n", "authors": ["Shijie Wang and Shangbo Wang\n"], "categories": ["cs.AI", "cs.MA\nComments:", "Accepted", "by", "PerCOM2023", "Workshops\n"], "abstract": "As travel demand increases and urban traffic condition becomes more complicated, applying multi-agent deep reinforcement learning (MARL) to traffic signal control becomes one of the hot topics. The rise of Reinforcement Learning (RL) has opened up opportunities for solving Adaptive Traffic Signal Control (ATSC) in complex urban traffic networks, and deep neural networks have further enhanced their ability to handle complex data. Traditional research in traffic signal control is based on the centralized Reinforcement Learning technique. However, in a large-scale road network, centralized RL is infeasible because of an exponential growth of joint state-action space. In this paper, we propose a Friend-Deep Q-network (Friend-DQN) approach for multiple traffic signal control in urban networks, which is based on an agent-cooperation scheme. In particular, the cooperation between multiple agents can reduce the state-action space and thus speed up the convergence. We use SUMO (Simulation of Urban Transport) platform to evaluate the performance of Friend-DQN model, and show its feasibility and superiority over other existing methods.", "link": "https://arxiv.org/abs/2306.02684"}, {"id": "2306.02864", "date": "Mon, 5 Jun 2023 13:35:01 GMT", "title": "Leveraging Large Language Models for Topic Classification in the Domain\n of Public Affairs\n", "authors": ["Alejandro Pe\\~na", "Aythami Morales", "Julian Fierrez", "Ignacio Serna,\n Javier Ortega-Garcia", "I\\~nigo Puente", "Jorge Cordova", "Gonzalo Cordova\n"], "categories": ["cs.AI", "cs.CL\nComments:", "Accepted", "in", "ICDAR", "2023", "Workshop", "on", "Automatic", "Domain-Adapted", "and\n", "Personalized", "Document", "Analysis\n"], "abstract": "The analysis of public affairs documents is crucial for citizens as it promotes transparency, accountability, and informed decision-making. It allows citizens to understand government policies, participate in public discourse, and hold representatives accountable. This is crucial, and sometimes a matter of life or death, for companies whose operation depend on certain regulations. Large Language Models (LLMs) have the potential to greatly enhance the analysis of public affairs documents by effectively processing and understanding the complex language used in such documents. In this work, we analyze the performance of LLMs in classifying public affairs documents. As a natural multi-label task, the classification of these documents presents important challenges. In this work, we use a regex-powered tool to collect a database of public affairs documents with more than 33K samples and 22.5M tokens. Our experiments assess the performance of 4 different Spanish LLMs to classify up to 30 different topics in the data in different configurations. The results shows that LLMs can be of great use to process domain-specific documents, such as those in the domain of public affairs.", "link": "https://arxiv.org/abs/2306.02864"}, {"id": "2306.02918", "date": "Mon, 5 Jun 2023 14:28:39 GMT", "title": "Adversarial Ink: Componentwise Backward Error Attacks on Deep Learning\n", "authors": ["Lucas Beerens and Desmond J. Higham\n"], "categories": ["cs.AI", "cs.NA", "math.NA\nMSC-class:", "65F35\nACM-class:", "I.2.10;", "G.1.3\n"], "abstract": "Deep neural networks are capable of state-of-the-art performance in many classification tasks. However, they are known to be vulnerable to adversarial attacks -- small perturbations to the input that lead to a change in classification. We address this issue from the perspective of backward error and condition number, concepts that have proved useful in numerical analysis. To do this, we build on the work of Beuzeville et al. (2021). In particular, we develop a new class of attack algorithms that use componentwise relative perturbations. Such attacks are highly relevant in the case of handwritten documents or printed texts where, for example, the classification of signatures, postcodes, dates or numerical quantities may be altered by changing only the ink consistency and not the background. This makes the perturbed images look natural to the naked eye. Such ``adversarial ink'' attacks therefore reveal a weakness that can have a serious impact on safety and security. We illustrate the new attacks on real data and contrast them with existing algorithms. We also study the use of a componentwise condition number to quantify vulnerability.", "link": "https://arxiv.org/abs/2306.02918"}, {"id": "2306.03034", "date": "Mon, 5 Jun 2023 16:51:38 GMT", "title": "Tackling Cooperative Incompatibility for Zero-Shot Human-AI Coordination\n", "authors": ["Yang Li", "Shao Zhang", "Jichen Sun", "Wenhao Zhang", "Yali Du", "Ying Wen,\n Xinbing Wang", "Wei Pan\n"], "categories": ["cs.AI", "cs.HC\nComments:", "arXiv", "admin", "note:", "substantial", "text", "overlap", "with", "arXiv:2302.04831\n"], "abstract": "Achieving coordination between humans and artificial intelligence in scenarios involving previously unencountered humans remains a substantial obstacle within Zero-Shot Human-AI Coordination, which aims to develop AI agents capable of efficiently working alongside previously unknown human teammates. Traditional algorithms have aimed to collaborate with humans by optimizing fixed objectives within a population, fostering diversity in strategies and behaviors. However, these techniques may lead to learning loss and an inability to cooperate with specific strategies within the population, a phenomenon named cooperative incompatibility. To mitigate this issue, we introduce the Cooperative Open-ended LEarning (COLE) framework, which formulates open-ended objectives in cooperative games with two players using perspectives of graph theory to evaluate and pinpoint the cooperative capacity of each strategy. We put forth a practical algorithm incorporating insights from game theory and graph theory, e.g., Shapley Value and Centrality. We also show that COLE could effectively overcome the cooperative incompatibility from theoretical and empirical analysis. Subsequently, we created an online Overcooked human-AI experiment platform, the COLE platform, which enables easy customization of questionnaires, model weights, and other aspects. Utilizing the COLE platform, we enlist 130 participants for human experiments. Our findings reveal a preference for our approach over state-of-the-art methods using a variety of subjective metrics. Moreover, objective experimental outcomes in the Overcooked game environment indicate that our method surpasses existing ones when coordinating with previously unencountered AI agents and the human proxy model. Our code and demo are publicly available at https://sites.google.com/view/cole-2023.", "link": "https://arxiv.org/abs/2306.03034"}, {"id": "2306.03081", "date": "Mon, 5 Jun 2023 17:55:05 GMT", "title": "Sequential Monte Carlo Steering of Large Language Models using\n Probabilistic Programs\n", "authors": ["Alexander K. Lew", "Tan Zhi-Xuan", "Gabriel Grand", "and Vikash K.\n Mansinghka\n"], "categories": ["cs.AI", "cs.CL", "cs.PL", "stat.CO\n"], "abstract": "Even after fine-tuning and reinforcement learning, large language models (LLMs) can be difficult, if not impossible, to control reliably with prompts alone. We propose a new inference-time approach to enforcing syntactic and semantic constraints on the outputs of LLMs, called sequential Monte Carlo (SMC) steering. The key idea is to specify language generation tasks as posterior inference problems in a class of discrete probabilistic sequence models, and replace standard decoding with sequential Monte Carlo inference. For a computational cost similar to that of beam search, SMC can steer LLMs to solve diverse tasks, including infilling, generation under syntactic constraints, and prompt intersection. To facilitate experimentation with SMC steering, we present a probabilistic programming library, LLaMPPL (https://github.com/probcomp/LLaMPPL), for concisely specifying new generation tasks as language model probabilistic programs, and automating steering of LLaMA-family Transformers.", "link": "https://arxiv.org/abs/2306.03081"}, {"id": "2306.03088", "date": "Mon, 5 Jun 2023 17:58:49 GMT", "title": "DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear\n Functional Brain Network Dynamics\n", "authors": ["Md Asadullah Turja", "Martin Styner and Guorong Wu\n"], "categories": ["cs.AI", "cs.LG\nComments:", "to", "be", "published", "in", "MICCAI", "2023\n"], "abstract": "Functional brain dynamics is supported by parallel and overlapping functional network modes that are associated with specific neural circuits. Decomposing these network modes from fMRI data and finding their temporal characteristics is challenging due to their time-varying nature and the non-linearity of the functional dynamics. Dynamic Mode Decomposition (DMD) algorithms have been quite popular for solving this decomposition problem in recent years. In this work, we apply GraphDMD -- an extension of the DMD for network data -- to extract the dynamic network modes and their temporal characteristics from the fMRI time series in an interpretable manner. GraphDMD, however, regards the underlying system as a linear dynamical system that is sub-optimal for extracting the network modes from non-linear functional data. In this work, we develop a generalized version of the GraphDMD algorithm -- DeepGraphDMD -- applicable to arbitrary non-linear graph dynamical systems. DeepGraphDMD is an autoencoder-based deep learning model that learns Koopman eigenfunctions for graph data and embeds the non-linear graph dynamics into a latent linear space. We show the effectiveness of our method in both simulated data and the HCP resting-state fMRI data. In the HCP data, DeepGraphDMD provides novel insights into cognitive brain functions by discovering two major network modes related to fluid and crystallized intelligence.", "link": "https://arxiv.org/abs/2306.03088"}, {"id": "2306.01755", "date": "Tue, 23 May 2023 04:54:26 GMT", "title": "Training Priors Predict Text-To-Image Model Performance\n", "authors": ["Charles Lovering and Ellie Pavlick\n"], "categories": ["cs.CV", "cs.AI", "cs.CL\n"], "abstract": "Text-to-image models can often generate some relations, i.e., \"astronaut riding horse\", but fail to generate other relations composed of the same basic parts, i.e., \"horse riding astronaut\". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., \"astronaut\", \"ride\", \"horse\"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if \"astronaut riding horse\" appears frequently in the training data, the image for \"horse riding astronaut\" will tend to be poorly aligned. We also find that models often struggle to generate terms in atypical roles, e.g., if \"horse\" is more often the semantic patient (object), the model might struggle to visualize it as a semantic agent (subject). Our results thus show that current models are biased to generate images aligned with relations seen in training and provide important new data in the ongoing debate on whether these text-to-image models employ abstract compositional structure in a traditional sense, or rather, interpolate between relations explicitly seen in the training data.", "link": "https://arxiv.org/abs/2306.01755"}, {"id": "2306.01756", "date": "Wed, 24 May 2023 04:02:49 GMT", "title": "CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy\n Convolution Neural Network\n", "authors": ["Jingtao Guo", "Ivan Wang-Hei Ho\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "6", "pages,", "7", "figures,", "to", "be", "published", "in", "Proceedings", "of", "the", "8th", "IEEE\n", "World", "Forum", "on", "the", "Internet", "of", "Things\n"], "abstract": "Nowadays, Coronavirus disease (COVID-19) has become a global pandemic because of its fast spread in various countries. To build an anti-epidemic barrier, self-isolation is required for people who have been to any at-risk places or have been in close contact with infected people. However, existing camera or wearable device-based monitoring systems may present privacy leakage risks or cause user inconvenience in some cases. In this paper, we propose a Wi-Fi-based device-free self-quarantine monitoring system. Specifically, we exploit channel state information (CSI) derived from Wi-Fi signals as human activity features. We collect CSI data in a simulated self-quarantine scenario and present BranchyGhostNet, a lightweight convolution neural network (CNN) with an early exit prediction branch, for the efficient joint task of room occupancy detection (ROD) and human activity recognition (HAR). The early exiting branch is used for ROD, and the final one is used for HAR. Our experimental results indicate that the proposed model can achieve an average accuracy of 98.19% for classifying five different human activities. They also confirm that after leveraging the early exit prediction mechanism, the inference latency for ROD can be significantly reduced by 54.04% when compared with the final exiting branch while guaranteeing the accuracy of ROD.", "link": "https://arxiv.org/abs/2306.01756"}, {"id": "2306.01879", "date": "Fri, 2 Jun 2023 19:19:43 GMT", "title": "VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative\n Pre-Training Scores\n", "authors": ["Zhiqiu Lin", "Xinyue Chen", "Deepak Pathak", "Pengchuan Zhang", "Deva Ramanan\n"], "categories": ["cs.CV", "cs.AI", "cs.CL\nComments:", "Website:", "https://linzhiqiu.github.io/papers/visual_gpt_score/", "Code:\n", "https://github.com/linzhiqiu/visual_gpt_score/\n"], "abstract": "Vision-language models (VLMs) discriminatively pre-trained with contrastive image-text matching losses such as $P(\\text{match}|\\text{text}, \\text{image})$ have been criticized for lacking compositional understanding. This means they might output similar scores even if the original caption is rearranged into a different semantic statement. To address this, we propose to use the ${\\bf V}$isual ${\\bf G}$enerative ${\\bf P}$re-${\\bf T}$raining Score (${\\bf VisualGPTScore}$) of $P(\\text{text}|\\text{image})$, a $\\textit{multimodal generative}$ score that captures the likelihood of a text caption conditioned on an image using an image-conditioned language model. Contrary to the belief that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore demonstrates top-tier performance on recently proposed image-text retrieval benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore, we factorize VisualGPTScore into a product of the $\\textit{marginal}$ P(text) and the $\\textit{Pointwise Mutual Information}$ (PMI). This helps to (a) diagnose datasets with strong language bias, and (b) debias results on other benchmarks like Winoground using an information-theoretic framework. VisualGPTScore provides valuable insights and serves as a strong baseline for future evaluation of visio-linguistic compositionality.", "link": "https://arxiv.org/abs/2306.01879"}, {"id": "2306.02236", "date": "Sun, 4 Jun 2023 02:33:12 GMT", "title": "Detector Guidance for Multi-Object Text-to-Image Generation\n", "authors": ["Luping Liu and Zijian Zhang and Yi Ren and Rongjie Huang and Xiang Yin\n and Zhou Zhao\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\n"], "abstract": "Diffusion models have demonstrated impressive performance in text-to-image generation. They utilize a text encoder and cross-attention blocks to infuse textual information into images at a pixel level. However, their capability to generate images with text containing multiple objects is still restricted. Previous works identify the problem of information mixing in the CLIP text encoder and introduce the T5 text encoder or incorporate strong prior knowledge to assist with the alignment. We find that mixing problems also occur on the image side and in the cross-attention blocks. The noisy images can cause different objects to appear similar, and the cross-attention blocks inject information at a pixel level, leading to leakage of global object understanding and resulting in object mixing. In this paper, we introduce Detector Guidance (DG), which integrates a latent object detection model to separate different objects during the generation process. DG first performs latent object detection on cross-attention maps (CAMs) to obtain object information. Based on this information, DG then masks conflicting prompts and enhances related prompts by manipulating the following CAMs. We evaluate the effectiveness of DG using Stable Diffusion on COCO, CC, and a novel multi-related object benchmark, MRO. Human evaluations demonstrate that DG provides an 8-22\\% advantage in preventing the amalgamation of conflicting concepts and ensuring that each object possesses its unique region without any human involvement and additional iterations. Our implementation is available at \\url{https://github.com/luping-liu/Detector-Guidance}.", "link": "https://arxiv.org/abs/2306.02236"}, {"id": "2306.02268", "date": "Sun, 4 Jun 2023 06:01:53 GMT", "title": "Revisiting Class Imbalance for End-to-end Semi-Supervised Object\n Detection\n", "authors": ["Purbayan Kar", "Vishal Chudasama", "Naoyuki Onoe", "Pankaj Wasnik\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "Accepted", "at", "the", "Efficient", "Deep", "Learning", "for", "Computer", "Vision", "Workshop,\n", "CVPR", "2023\n"], "abstract": "Semi-supervised object detection (SSOD) has made significant progress with the development of pseudo-label-based end-to-end methods. However, many of these methods face challenges due to class imbalance, which hinders the effectiveness of the pseudo-label generator. Furthermore, in the literature, it has been observed that low-quality pseudo-labels severely limit the performance of SSOD. In this paper, we examine the root causes of low-quality pseudo-labels and present novel learning mechanisms to improve the label generation quality. To cope with high false-negative and low precision rates, we introduce an adaptive thresholding mechanism that helps the proposed network to filter out optimal bounding boxes. We further introduce a Jitter-Bagging module to provide accurate information on localization to help refine the bounding boxes. Additionally, two new losses are introduced using the background and foreground scores predicted by the teacher and student networks to improvise the pseudo-label recall rate. Furthermore, our method applies strict supervision to the teacher network by feeding strong & weak augmented data to generate robust pseudo-labels so that it can detect small and complex objects. Finally, the extensive experiments show that the proposed network outperforms state-of-the-art methods on MS-COCO and Pascal VOC datasets and allows the baseline network to achieve 100% supervised performance with much less (i.e., 20%) labeled data.", "link": "https://arxiv.org/abs/2306.02268"}, {"id": "2306.02407", "date": "Sun, 4 Jun 2023 16:55:38 GMT", "title": "Heteroskedastic Geospatial Tracking with Distributed Camera Networks\n", "authors": ["Colin Samplawski", "Shiwei Fang", "Ziqi Wang", "Deepak Ganesan", "Mani\n Srivastava", "Benjamin M. Marlin\n"], "categories": ["cs.CV", "cs.AI", "cs.DC", "cs.LG\n"], "abstract": "Visual object tracking has seen significant progress in recent years. However, the vast majority of this work focuses on tracking objects within the image plane of a single camera and ignores the uncertainty associated with predicted object locations. In this work, we focus on the geospatial object tracking problem using data from a distributed camera network. The goal is to predict an object's track in geospatial coordinates along with uncertainty over the object's location while respecting communication constraints that prohibit centralizing raw image data. We present a novel single-object geospatial tracking data set that includes high-accuracy ground truth object locations and video data from a network of four cameras. We present a modeling framework for addressing this task including a novel backbone model and explore how uncertainty calibration and fine-tuning through a differentiable tracker affect performance.", "link": "https://arxiv.org/abs/2306.02407"}, {"id": "2306.02577", "date": "Mon, 5 Jun 2023 04:00:39 GMT", "title": "Exploring the Role of the Bottleneck in Slot-Based Models Through\n Covariance Regularization\n", "authors": ["Andrew Stange", "Robert Lo", "Abishek Sridhar", "Kousik Rajesh\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "14", "pages,", "10", "figures\n"], "abstract": "In this project we attempt to make slot-based models with an image reconstruction objective competitive with those that use a feature reconstruction objective on real world datasets. We propose a loss-based approach to constricting the bottleneck of slot-based models, allowing larger-capacity encoder networks to be used with Slot Attention without producing degenerate stripe-shaped masks. We find that our proposed method offers an improvement over the baseline Slot Attention model but does not reach the performance of \\dinosaur on the COCO2017 dataset. Throughout this project, we confirm the superiority of a feature reconstruction objective over an image reconstruction objective and explore the role of the architectural bottleneck in slot-based models.", "link": "https://arxiv.org/abs/2306.02577"}, {"id": "2306.02589", "date": "Mon, 5 Jun 2023 04:33:32 GMT", "title": "DAGrid: Directed Accumulator Grid\n", "authors": ["Hang Zhang", "Renjiu Hu", "Xiang Chen", "Rongguang Wang", "Jinwei Zhang", "and\n Jiahao Li\n"], "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP\nComments:", "19", "pages,", "9", "figures,", "4", "tables\n"], "abstract": "Recent research highlights that the Directed Accumulator (DA), through its parametrization of geometric priors into neural networks, has notably improved the performance of medical image recognition, particularly with small and imbalanced datasets. However, DA's potential in pixel-wise dense predictions is unexplored. To bridge this gap, we present the Directed Accumulator Grid (DAGrid), which allows geometric-preserving filtering in neural networks, thus broadening the scope of DA's applications to include pixel-level dense prediction tasks. DAGrid utilizes homogeneous data types in conjunction with designed sampling grids to construct geometrically transformed representations, retaining intricate geometric information and promoting long-range information propagation within the neural networks. Contrary to its symmetric counterpart, grid sampling, which might lose information in the sampling process, DAGrid aggregates all pixels, ensuring a comprehensive representation in the transformed space. The parallelization of DAGrid on modern GPUs is facilitated using CUDA programming, and also back propagation is enabled for deep neural network training. Empirical results show DAGrid-enhanced neural networks excel in supervised skin lesion segmentation and unsupervised cardiac image registration. Specifically, the network incorporating DAGrid has realized a 70.8% reduction in network parameter size and a 96.8% decrease in FLOPs, while concurrently improving the Dice score for skin lesion segmentation by 1.0% compared to state-of-the-art transformers. Furthermore, it has achieved improvements of 4.4% and 8.2% in the average Dice score and Dice score of the left ventricular mass, respectively, indicating an increase in registration accuracy for cardiac images. The source code is available at https://github.com/tinymilky/DeDA.", "link": "https://arxiv.org/abs/2306.02589"}, {"id": "2306.02744", "date": "Mon, 5 Jun 2023 09:52:05 GMT", "title": "Towards Better Explanations for Object Detection\n", "authors": ["Van Binh Truong", "Truong Thanh Hung Nguyen", "Vo Thanh Khang Nguyen", "Quoc\n Khanh Nguyen", "Quoc Hung Cao\n"], "categories": ["cs.CV", "cs.AI", "cs.LG\nComments:", "9", "pages,", "10", "figures\n"], "abstract": "Recent advances in Artificial Intelligence (AI) technology have promoted their use in almost every field. The growing complexity of deep neural networks (DNNs) makes it increasingly difficult and important to explain the inner workings and decisions of the network. However, most current techniques for explaining DNNs focus mainly on interpreting classification tasks. This paper proposes a method to explain the decision for any object detection model called D-CLOSE. To closely track the model's behavior, we used multiple levels of segmentation on the image and a process to combine them. We performed tests on the MS-COCO dataset with the YOLOX model, which shows that our method outperforms D-RISE and can give a better quality and less noise explanation.", "link": "https://arxiv.org/abs/2306.02744"}, {"id": "2306.01860", "date": "Fri, 2 Jun 2023 18:29:07 GMT", "title": "No Bidding, No Regret: Pairwise-Feedback Mechanisms for Digital Goods\n and Data Auctions\n", "authors": ["Zachary Robertson", "Oluwasanmi Koyejo\n"], "categories": ["cs.GT", "cs.AI", "cs.LG\nComments:", "18", "pages,", "2", "figures\n"], "abstract": "The growing demand for data and AI-generated digital goods, such as personalized written content and artwork, necessitates effective pricing and feedback mechanisms that account for uncertain utility and costly production. Motivated by these developments, this study presents a novel mechanism design addressing a general repeated-auction setting where the utility derived from a sold good is revealed post-sale. The mechanism's novelty lies in using pairwise comparisons for eliciting information from the bidder, arguably easier for humans than assigning a numerical value. Our mechanism chooses allocations using an epsilon-greedy strategy and relies on pairwise comparisons between realized utility from allocated goods and an arbitrary value, avoiding the learning-to-bid problem explored in previous work. We prove this mechanism to be asymptotically truthful, individually rational, and welfare and revenue maximizing. The mechanism's relevance is broad, applying to any setting with made-to-order goods of variable quality. Experimental results on multi-label toxicity annotation data, an example of negative utilities, highlight how our proposed mechanism could enhance social welfare in data auctions. Overall, our focus on human factors contributes to the development of more human-aware and efficient mechanism design.", "link": "https://arxiv.org/abs/2306.01860"}, {"id": "2306.01920", "date": "Fri, 2 Jun 2023 21:22:27 GMT", "title": "Context-Aware Bayesian Network Actor-Critic Methods for Cooperative\n Multi-Agent Reinforcement Learning\n", "authors": ["Dingyang Chen", "Qi Zhang\n"], "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG\n"], "abstract": "Executing actions in a correlated manner is a common strategy for human coordination that often leads to better cooperation, which is also potentially beneficial for cooperative multi-agent reinforcement learning (MARL). However, the recent success of MARL relies heavily on the convenient paradigm of purely decentralized execution, where there is no action correlation among agents for scalability considerations. In this work, we introduce a Bayesian network to inaugurate correlations between agents' action selections in their joint policy. Theoretically, we establish a theoretical justification for why action dependencies are beneficial by deriving the multi-agent policy gradient formula under such a Bayesian network joint policy and proving its global convergence to Nash equilibria under tabular softmax policy parameterization in cooperative Markov games. Further, by equipping existing MARL algorithms with a recent method of differentiable directed acyclic graphs (DAGs), we develop practical algorithms to learn the context-aware Bayesian network policies in scenarios with partial observability and various difficulty. We also dynamically decrease the sparsity of the learned DAG throughout the training process, which leads to weakly or even purely independent policies for decentralized execution. Empirical results on a range of MARL benchmarks show the benefits of our approach.", "link": "https://arxiv.org/abs/2306.01920"}, {"id": "2306.01753", "date": "Mon, 22 May 2023 16:57:52 GMT", "title": "Preconditioned Visual Language Inference with Weak Supervision\n", "authors": ["Ehsan Qasemi", "Amani R. Maina-Kilaas", "Devadutta Dash", "Khalid Alsaggaf,\n Muhao Chen\n"], "categories": ["cs.CL", "cs.AI", "cs.CV\n"], "abstract": "Humans can infer the affordance of objects by extracting related contextual preconditions for each scenario. For example, upon seeing an image of a broken cup, we can infer that this precondition prevents the cup from being used for drinking. Reasoning with preconditions of commonsense is studied in NLP where the model explicitly gets the contextual precondition. However, it is unclear if SOTA visual language models (VLMs) can extract such preconditions and infer the affordance of objects with them. In this work, we introduce the task of preconditioned visual language inference and rationalization (PVLIR). We propose a learning resource based on three strategies to retrieve weak supervision signals for the task and develop a human-verified test set for evaluation. Our results reveal the shortcomings of SOTA VLM models in the task and draw a road map to address the challenges ahead in improving them.", "link": "https://arxiv.org/abs/2306.01753"}, {"id": "2306.01754", "date": "Tue, 23 May 2023 01:21:55 GMT", "title": "Transformer-based Vulnerability Detection in Code at EditTime:\n Zero-shot, Few-shot, or Fine-tuning?\n", "authors": ["Aaron Chan", "Anant Kharkar", "Roshanak Zilouchian Moghaddam", "Yevhen\n Mohylevskyy", "Alec Helyar", "Eslam Kamal", "Mohamed Elkamhawy", "Neel Sundaresan\n"], "categories": ["cs.CR", "cs.AI", "cs.LG\n"], "abstract": "Software vulnerabilities bear enterprises significant costs. Despite extensive efforts in research and development of software vulnerability detection methods, uncaught vulnerabilities continue to put software owners and users at risk. Many current vulnerability detection methods require that code snippets can compile and build before attempting detection. This, unfortunately, introduces a long latency between the time a vulnerability is injected to the time it is removed, which can substantially increases the cost of fixing a vulnerability. We recognize that the current advances in machine learning can be used to detect vulnerable code patterns on syntactically incomplete code snippets as the developer is writing the code at EditTime. In this paper we present a practical system that leverages deep learning on a large-scale data set of vulnerable code patterns to learn complex manifestations of more than 250 vulnerability types and detect vulnerable code patterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning approaches on state of the art pre-trained Large Language Models (LLMs). We show that in comparison with state of the art vulnerability detection models our approach improves the state of the art by 10%. We also evaluate our approach to detect vulnerability in auto-generated code by code LLMs. Evaluation on a benchmark of high-risk code scenarios shows a reduction of up to 90% vulnerability reduction.", "link": "https://arxiv.org/abs/2306.01754"}, {"id": "2306.01761", "date": "Fri, 26 May 2023 09:27:43 GMT", "title": "Distinguishing Human Generated Text From ChatGPT Generated Text Using\n Machine Learning\n", "authors": ["Niful Islam", "Debopom Sutradhar", "Humaira Noor", "Jarin Tasnim Raya,\n Monowara Tabassum Maisha", "Dewan Md Farid\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\n"], "abstract": "ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was fine-tuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%.", "link": "https://arxiv.org/abs/2306.01761"}, {"id": "2306.01762", "date": "Sat, 27 May 2023 06:00:51 GMT", "title": "Pre-trained transformer for adversarial purification\n", "authors": ["Kai Wu", "Yujian Betterest Li", "Xiaoyu Zhang", "Handing Wang", "Jing Liu\n"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG\n"], "abstract": "With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the generalization and the universal computation ability of pre-trained transformer models, we come up with a new defender method, CeTaD, which stands for Considering Pre-trained Transformers as Defenders. In particular, we evaluate the effectiveness and the transferability of CeTaD in the case of one-shot adversarial examples and explore the impact of different parts of CeTaD as well as training data conditions. CeTaD is flexible, able to be embedded into an arbitrary differentiable model, and suitable for various types of attacks.", "link": "https://arxiv.org/abs/2306.01762"}, {"id": "2306.01774", "date": "Mon, 29 May 2023 11:57:07 GMT", "title": "RE-centric Recommendations for the Development of Trustworthy(er)\n Autonomous Systems\n", "authors": ["Krishna Ronanki", "Beatriz Cabrero-Daniel", "Jennifer Horkoff", "Christian\n Berger\n"], "categories": ["cs.CY", "cs.AI", "cs.SE\nComments:", "Accepted", "at", "[TAS", "'23]{First", "International", "Symposium", "on", "Trustworthy\n", "Autonomous", "Systems}\nDOI:", "10.1145/3597512.3599697\n"], "abstract": "Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address this concern, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.", "link": "https://arxiv.org/abs/2306.01774"}, {"id": "2306.01787", "date": "Wed, 31 May 2023 14:11:51 GMT", "title": "Power Control with QoS Guarantees: A Differentiable Projection-based\n Unsupervised Learning Framework\n", "authors": ["Mehrazin Alizadeh and Hina Tabassum\n"], "categories": ["cs.NI", "cs.AI", "cs.LG\nComments:", "accepted", "in", "IEEE", "Transactions", "on", "Communications\n"], "abstract": "Deep neural networks (DNNs) are emerging as a potential solution to solve NP-hard wireless resource allocation problems. However, in the presence of intricate constraints, e.g., users' quality-of-service (QoS) constraints, guaranteeing constraint satisfaction becomes a fundamental challenge. In this paper, we propose a novel unsupervised learning framework to solve the classical power control problem in a multi-user interference channel, where the objective is to maximize the network sumrate under users' minimum data rate or QoS requirements and power budget constraints. Utilizing a differentiable projection function, two novel deep learning (DL) solutions are pursued. The first is called Deep Implicit Projection Network (DIPNet), and the second is called Deep Explicit Projection Network (DEPNet). DIPNet utilizes a differentiable convex optimization layer to implicitly define a projection function. On the other hand, DEPNet uses an explicitly-defined projection function, which has an iterative nature and relies on a differentiable correction process. DIPNet requires convex constraints; whereas, the DEPNet does not require convexity and has a reduced computational complexity. To enhance the sum-rate performance of the proposed models even further, Frank-Wolfe algorithm (FW) has been applied to the output of the proposed models. Extensive simulations depict that the proposed DNN solutions not only improve the achievable data rate but also achieve zero constraint violation probability, compared to the existing DNNs. The proposed solutions outperform the classic optimization methods in terms of computation time complexity.", "link": "https://arxiv.org/abs/2306.01787"}, {"id": "2306.01788", "date": "Wed, 31 May 2023 15:47:12 GMT", "title": "Responsible Design Patterns for Machine Learning Pipelines\n", "authors": ["Saud Hakem Al Harbi", "Lionel Nganyewou Tidjon and Foutse Khomh\n"], "categories": ["cs.SE", "cs.AI", "cs.LG\nComments:", "20", "pages,", "4", "figures,", "5", "tables\n"], "abstract": "Integrating ethical practices into the AI development process for artificial intelligence (AI) is essential to ensure safe, fair, and responsible operation. AI ethics involves applying ethical principles to the entire life cycle of AI systems. This is essential to mitigate potential risks and harms associated with AI, such as algorithm biases. To achieve this goal, responsible design patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee ethical and fair outcomes. In this paper, we propose a comprehensive framework incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical development of AI systems. Our framework comprises new responsible AI design patterns for ML pipelines identified through a survey of AI ethics and data management experts and validated through real-world scenarios with expert feedback. The framework guides AI developers, data scientists, and policy-makers to implement ethical practices in AI development and deploy responsible AI systems in production.", "link": "https://arxiv.org/abs/2306.01788"}, {"id": "2306.01792", "date": "Thu, 1 Jun 2023 08:10:03 GMT", "title": "Task Relation-aware Continual User Representation Learning\n", "authors": ["Sein Kim", "Namkyeong Lee", "Donghyun Kim", "Minchul Yang", "Chanyoung Park\n"], "categories": ["cs.IR", "cs.AI", "cs.LG\nComments:", "KDD", "2023\nDOI:", "10.1145/3580305.3599516\n"], "abstract": "User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number of learned tasks increases while capturing the relationship between the tasks. The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured. Moreover, we introduce a novel knowledge retention module with pseudo-labeling strategy that successfully alleviates the long-standing problem of continual learning, i.e., catastrophic forgetting. Extensive experiments on public and proprietary real-world datasets demonstrate the superiority and practicality of TERACON. Our code is available at https://github.com/Sein-Kim/TERACON.", "link": "https://arxiv.org/abs/2306.01792"}, {"id": "2306.01805", "date": "Thu, 1 Jun 2023 18:49:47 GMT", "title": "Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes\n", "authors": ["Revathy Venkataramanan", "Kaushik Roy", "Kanak Raj", "Renjith Prasad", "Yuxin\n Zi", "Vignesh Narayanan", "Amit Sheth\n"], "categories": ["cs.CL", "cs.AI", "cs.IR\n"], "abstract": "As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive large language models, can lead to robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we explore the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.). Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions for the same action (e.g., marinate the meat vs. marinate the meat and leave overnight) and infrequently occurring patterns (e.g., add salt occurs far more frequently than marinating the meat). The prototypical approach to handling irregular data patterns is to increase the volume of data that the model ingests by orders of magnitude. Unfortunately, in the cooking domain, these problems are further compounded with larger data volumes presenting a unique challenge that is not easily handled by simply scaling up. In this work, we propose novel aggregation-based generative AI methods, Cook-Gen, that reliably generate cooking actions from recipes, despite difficulties with irregular data patterns, while also outperforming Large Language Models and other strong baselines.", "link": "https://arxiv.org/abs/2306.01805"}, {"id": "2306.01809", "date": "Fri, 2 Jun 2023 03:11:32 GMT", "title": "Adversarial Attack Based on Prediction-Correction\n", "authors": ["Chen Wan", "Fangjun Huang\n"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG\nComments:", "This", "manuscript", "was", "submitted", "to", "CVPR", "2022\n"], "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples obtained by adding small perturbations to original examples. The added perturbations in existing attacks are mainly determined by the gradient of the loss function with respect to the inputs. In this paper, the close relationship between gradient-based attacks and the numerical methods for solving ordinary differential equation (ODE) is studied for the first time. Inspired by the numerical solution of ODE, a new prediction-correction (PC) based adversarial attack is proposed. In our proposed PC-based attack, some existing attack can be selected to produce a predicted example first, and then the predicted example and the current example are combined together to determine the added perturbations. The proposed method possesses good extensibility and can be applied to all available gradient-based attacks easily. Extensive experiments demonstrate that compared with the state-of-the-art gradient-based adversarial attacks, our proposed PC-based attacks have higher attack success rates, and exhibit better transferability.", "link": "https://arxiv.org/abs/2306.01809"}, {"id": "2306.01855", "date": "Fri, 2 Jun 2023 18:17:52 GMT", "title": "5IDER: Unified Query Rewriting for Steering, Intent Carryover,\n Disfluencies, Entity Carryover and Repair\n", "authors": ["Jiarui Lu", "Bo-Hsiang Tseng", "Joel Ruben Antony Moniz", "Site Li", "Xueyun\n Zhu", "Hong Yu", "Murat Akbacak\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "Interspeech", "2023\n"], "abstract": "Providing voice assistants the ability to navigate multi-turn conversations is a challenging problem. Handling multi-turn interactions requires the system to understand various conversational use-cases, such as steering, intent carryover, disfluencies, entity carryover, and repair. The complexity of this problem is compounded by the fact that these use-cases mix with each other, often appearing simultaneously in natural language. This work proposes a non-autoregressive query rewriting architecture that can handle not only the five aforementioned tasks, but also complex compositions of these use-cases. We show that our proposed model has competitive single task performance compared to the baseline approach, and even outperforms a fine-tuned T5 model in use-case compositions, despite being 15 times smaller in parameters and 25 times faster in latency.", "link": "https://arxiv.org/abs/2306.01855"}, {"id": "2306.01941", "date": "Fri, 2 Jun 2023 22:51:26 GMT", "title": "AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap\n", "authors": ["Q. Vera Liao and Jennifer Wortman Vaughan\n"], "categories": ["cs.HC", "cs.AI", "cs.CY\n"], "abstract": "The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused applications being built, and the new usage patterns and challenges around LLMs, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for LLMs, along with lessons learned from HCI and responsible AI research that has taken a human-centered perspective on AI transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to LLMs. We hope this provides a starting point for discussion and a useful roadmap for future research.", "link": "https://arxiv.org/abs/2306.01941"}, {"id": "2306.01944", "date": "Fri, 2 Jun 2023 23:04:01 GMT", "title": "EdGCon: Auto-assigner of Iconicity Ratings Grounded by Lexical\n Properties to Aid in Generation of Technical Gestures\n", "authors": ["Sameena Hossain", "Payal Kamboj", "Aranyak Maity", "Tamiko Azuma", "Ayan\n Banerjee", "Sandeep K. S. Gupta\n"], "categories": ["cs.HC", "cs.AI", "cs.CL\nComments:", "Accepted", "for", "publication", "in", "ACM", "SAC", "2023\nReport-no:", "ILTR-2023-1\n"], "abstract": "Gestures that share similarities in their forms and are related in their meanings, should be easier for learners to recognize and incorporate into their existing lexicon. In that regard, to be more readily accepted as standard by the Deaf and Hard of Hearing community, technical gestures in American Sign Language (ASL) will optimally share similar in forms with their lexical neighbors. We utilize a lexical database of ASL, ASL-LEX, to identify lexical relations within a set of technical gestures. We use automated identification for 3 unique sub-lexical properties in ASL- location, handshape and movement. EdGCon assigned an iconicity rating based on the lexical property similarities of the new gesture with an existing set of technical gestures and the relatedness of the meaning of the new technical word to that of the existing set of technical words. We collected 30 ad hoc crowdsourced technical gestures from different internet websites and tested them against 31 gestures from the DeafTEC technical corpus. We found that EdGCon was able to correctly auto-assign the iconicity ratings 80.76% of the time.", "link": "https://arxiv.org/abs/2306.01944"}, {"id": "2306.01953", "date": "Fri, 2 Jun 2023 23:29:28 GMT", "title": "Generative Autoencoders as Watermark Attackers: Analyses of\n Vulnerabilities and Threats\n", "authors": ["Xuandong Zhao", "Kexun Zhang", "Yu-Xiang Wang", "Lei Li\n"], "categories": ["cs.CR", "cs.AI", "cs.CV\n"], "abstract": "Invisible watermarks safeguard images' copyrights by embedding hidden messages detectable by owners. It also prevents people from misusing images, especially those generated by AI models. Malicious adversaries can violate these rights by removing the watermarks. In order to remove watermarks without damaging the visual quality, the adversary needs to erase them while retaining the essential information in the image. This is analogous to the encoding and decoding process of generative autoencoders, especially variational autoencoders (VAEs) and diffusion models. We propose a framework using generative autoencoders to remove invisible watermarks and test it using VAEs and diffusions. Our results reveal that, even without specific training, off-the-shelf Stable Diffusion effectively removes most watermarks, surpassing all current attackers. The result underscores the vulnerabilities in existing watermarking schemes and calls for more robust methods for copyright protection.", "link": "https://arxiv.org/abs/2306.01953"}, {"id": "2306.01981", "date": "Sat, 3 Jun 2023 02:27:08 GMT", "title": "SGEM: Test-Time Adaptation for Automatic Speech Recognition via\n Sequential-Level Generalized Entropy Minimization\n", "authors": ["Changhun Kim", "Joonhyung Park", "Hajin Shim and Eunho Yang\n"], "categories": ["eess.AS", "cs.AI", "cs.LG\nComments:", "Accepted", "to", "INTERSPEECH", "2023\n"], "abstract": "Automatic speech recognition (ASR) models are frequently exposed to data distribution shifts in many real-world scenarios, leading to erroneous predictions. To tackle this issue, an existing test-time adaptation (TTA) method has recently been proposed to adapt the pre-trained ASR model on unlabeled test instances without source data. Despite decent performance gain, this work relies solely on naive greedy decoding and performs adaptation across timesteps at a frame level, which may not be optimal given the sequential nature of the model output. Motivated by this, we propose a novel TTA framework, dubbed SGEM, for general ASR models. To treat the sequential output, SGEM first exploits beam search to explore candidate output logits and selects the most plausible one. Then, it utilizes generalized entropy minimization and negative sampling as unsupervised objectives to adapt the model. SGEM achieves state-of-the-art performance for three mainstream ASR models under various domain shifts.", "link": "https://arxiv.org/abs/2306.01981"}, {"id": "2306.02038", "date": "Sat, 3 Jun 2023 07:32:25 GMT", "title": "Span Identification of Epistemic Stance-Taking in Academic Written\n English\n", "authors": ["Masaki Eguchi and Kristopher Kyle\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "The", "18th", "Workshop", "on", "Innovative", "Use", "of", "NLP", "for", "Building", "Educational\n", "Applications\n"], "abstract": "Responding to the increasing need for automated writing evaluation (AWE) systems to assess language use beyond lexis and grammar (Burstein et al., 2016), we introduce a new approach to identify rhetorical features of stance in academic English writing. Drawing on the discourse-analytic framework of engagement in the Appraisal analysis (Martin & White, 2005), we manually annotated 4,688 sentences (126,411 tokens) for eight rhetorical stance categories (e.g., PROCLAIM, ATTRIBUTION) and additional discourse elements. We then report an experiment to train machine learning models to identify and categorize the spans of these stance expressions. The best-performing model (RoBERTa + LSTM) achieved macro-averaged F1 of .7208 in the span identification of stance-taking expressions, slightly outperforming the intercoder reliability estimates before adjudication (F1 = .6629).", "link": "https://arxiv.org/abs/2306.02038"}, {"id": "2306.02069", "date": "Sat, 3 Jun 2023 10:10:38 GMT", "title": "MultiLegalPile: A 689GB Multilingual Legal Corpus\n", "authors": ["Joel Niklaus", "Veton Matoshi", "Matthias St\\\"urmer", "Ilias Chalkidis,\n Daniel E. Ho\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nMSC-class:", "68T50\nACM-class:", "I.2\n"], "abstract": "Large, high-quality datasets are crucial for training \\acp{LLM}. However, so far, there are few datasets available for specialized critical domains such as law and the available ones are often only for the English language. We curate and release \\textsc{MultiLegalPile}, a 689GB corpus in 24 languages from 17 jurisdictions. The \\textsc{MultiLegalPile} corpus, which includes diverse legal data sources with varying licenses, allows for pretraining NLP models under fair use, with more permissive licenses for the Eurlex Resources and Legal mC4 subsets. We pretrain two RoBERTa models and one Longformer multilingually, and 24 monolingual models on each of the language-specific subsets and evaluate them on LEXTREME. Additionally, we evaluate the English and multilingual models on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English models on LexGLUE. We release the dataset, the trained models, and all of the code under the most open possible licenses.", "link": "https://arxiv.org/abs/2306.02069"}, {"id": "2306.02174", "date": "Sat, 3 Jun 2023 18:36:12 GMT", "title": "Training Data Attribution for Diffusion Models\n", "authors": ["Zheng Dai and David K Gifford\n"], "categories": ["stat.ML", "cs.AI", "cs.LG\nComments:", "14", "pages,", "6", "figures\n"], "abstract": "Diffusion models have become increasingly popular for synthesizing high-quality samples based on training datasets. However, given the oftentimes enormous sizes of the training datasets, it is difficult to assess how training data impact the samples produced by a trained diffusion model. The difficulty of relating diffusion model inputs and outputs poses significant challenges to model explainability and training data attribution. Here we propose a novel solution that reveals how training data influence the output of diffusion models through the use of ensembles. In our approach individual models in an encoded ensemble are trained on carefully engineered splits of the overall training data to permit the identification of influential training examples. The resulting model ensembles enable efficient ablation of training data influence, allowing us to assess the impact of training data on model outputs. We demonstrate the viability of these ensembles as generative models and the validity of our approach to assessing influence.", "link": "https://arxiv.org/abs/2306.02174"}, {"id": "2306.02207", "date": "Sat, 3 Jun 2023 22:35:27 GMT", "title": "SpeechGen: Unlocking the Generative Power of Speech Language Models with\n Prompts\n", "authors": ["Haibin Wu", "Kai-Wei Chang", "Yuan-Kuei Wu", "Hung-yi Lee\n"], "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG\nComments:", "Work", "in", "progress.", "The", "first", "three", "authors", "contributed", "equally\n"], "abstract": "Large language models (LLMs) have gained considerable attention for Artificial Intelligence Generated Content (AIGC), particularly with the emergence of ChatGPT. However, the direct adaptation of continuous speech to LLMs that process discrete tokens remains an unsolved challenge, hindering the application of LLMs for speech generation. The advanced speech LMs are in the corner, as that speech signals encapsulate a wealth of information, including speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated notable gains in parameter efficiency and competitive performance on some speech classification tasks. However, the extent to which prompts can effectively elicit generation tasks from speech LMs remains an open question. In this paper, we present pioneering research that explores the application of prompt tuning to stimulate speech LMs for various generation tasks, within a unified framework called SpeechGen, with around 10M trainable parameters. The proposed unified framework holds great promise for efficiency and effectiveness, particularly with the imminent arrival of advanced speech LMs, which will significantly enhance the capabilities of the framework. The code and demos of SpeechGen will be available on the project website: \\url{https://ga642381.github.io/SpeechPrompt/speechgen}", "link": "https://arxiv.org/abs/2306.02207"}, {"id": "2306.02296", "date": "Sun, 4 Jun 2023 08:13:33 GMT", "title": "Onsite Job Scheduling by Adaptive Genetic Algorithm\n", "authors": ["Avijit Basak", "Subhas Acharya\n"], "categories": ["math.OC", "cs.AI", "cs.NE\n"], "abstract": "Onsite Job Scheduling is a specialized variant of Vehicle Routing Problem (VRP) with multiple depots. The objective of this problem is to execute jobs requested by customers, belonging to different geographic locations by a limited number of technicians, with minimum travel and overtime of technicians. Each job is expected to be completed within a specified time limit according to the service level agreement with customers. Each technician is assumed to start from a base location, serve several customers and return to the starting place. Technicians are allotted jobs based on their skill sets, expertise levels of each skill and availability slots. Although there are considerable number of literatures on VRP we do not see any explicit work related to Onsite Job Scheduling. In this paper we have proposed an Adaptive Genetic Algorithm to solve the scheduling problem. We found an optimized travel route for a substantial number of jobs and technicians, minimizing travel distance, overtime duration as well as meeting constraints related to SLA.", "link": "https://arxiv.org/abs/2306.02296"}, {"id": "2306.02307", "date": "Sun, 4 Jun 2023 09:16:39 GMT", "title": "Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference\n in Low Resource Settings\n", "authors": ["Daniel Rotem", "Michael Hassid", "Jonathan Mamou", "Roy Schwartz\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "Proceedings", "of", "ACL", "2023\n"], "abstract": "Adaptive inference is a simple method for reducing inference costs. The method works by maintaining multiple classifiers of different capacities, and allocating resources to each test instance according to its difficulty. In this work, we compare the two main approaches for adaptive inference, Early-Exit and Multi-Model, when training data is limited. First, we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%. We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights. We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach. To address these issues, we propose SWEET (Separating Weights in Early Exit Transformers), an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers. We compare SWEET's speed-accuracy curve to standard Early-Exit and Multi-Model baselines and find that it outperforms both methods at fast speeds while maintaining comparable scores to Early-Exit at slow speeds. Moreover, SWEET individual classifiers outperform Early-Exit ones by 1.1% on average. SWEET enjoys the benefits of both methods, paving the way for further reduction of inference costs in NLP.", "link": "https://arxiv.org/abs/2306.02307"}, {"id": "2306.02317", "date": "Sun, 4 Jun 2023 10:00:12 GMT", "title": "SpellMapper: A non-autoregressive neural spellchecker for ASR\n customization with candidate retrieval based on n-gram mappings\n", "authors": ["Alexandra Antonova", "Evelina Bakhturina", "Boris Ginsburg\n"], "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS\nComments:", "Accepted", "by", "INTERSPEECH", "2023\n"], "abstract": "Contextual spelling correction models are an alternative to shallow fusion to improve automatic speech recognition (ASR) quality given user vocabulary. To deal with large user vocabularies, most of these models include candidate retrieval mechanisms, usually based on minimum edit distance between fragments of ASR hypothesis and user phrases. However, the edit-distance approach is slow, non-trainable, and may have low recall as it relies only on common letters. We propose: 1) a novel algorithm for candidate retrieval, based on misspelled n-gram mappings, which gives up to 90% recall with just the top 10 candidates on Spoken Wikipedia; 2) a non-autoregressive neural model based on BERT architecture, where the initial transcript and ten candidates are combined into one input. The experiments on Spoken Wikipedia show 21.4% word error rate improvement compared to a baseline ASR system.", "link": "https://arxiv.org/abs/2306.02317"}, {"id": "2306.02388", "date": "Sun, 4 Jun 2023 15:44:51 GMT", "title": "Commonsense Knowledge Transfer for Pre-trained Language Models\n", "authors": ["Wangchunshu Zhou", "Ronan Le Bras", "Yejin Choi\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "ACL", "2023", "Findings\n"], "abstract": "Despite serving as the foundation models for a wide range of NLP benchmarks, pre-trained language models have shown limited capabilities of acquiring implicit commonsense knowledge from self-supervision alone, compared to learning linguistic and factual knowledge that appear more explicitly in the surface patterns in text. In this work, we introduce commonsense knowledge transfer, a framework to transfer the commonsense knowledge stored in a neural commonsense knowledge model to a general-purpose pre-trained language model. It first exploits general texts to form queries for extracting commonsense knowledge from the neural commonsense knowledge model and then refines the language model with two self-supervised objectives: commonsense mask infilling and commonsense relation prediction, which align human language with the underlying commonsense knowledge. Empirical results show that our approach consistently improves the model's performance on downstream tasks that require commonsense reasoning. Moreover, we find that the improvement is more significant in the few-shot setting. This suggests that our approach helps language models better transfer to downstream tasks without extensive supervision by injecting commonsense knowledge into their parameters.", "link": "https://arxiv.org/abs/2306.02388"}, {"id": "2306.02411", "date": "Sun, 4 Jun 2023 17:08:41 GMT", "title": "A Topological Approach to Measuring Training Data Quality\n", "authors": ["\\'Alvaro Torras-Casas", "Eduardo Paluzo-Hidalgo", "Rocio Gonzalez-Diaz\n"], "categories": ["math.AT", "cs.AI", "cs.LG\n"], "abstract": "Data quality is crucial for the successful training, generalization and performance of artificial intelligence models. Furthermore, it is known that the leading approaches in artificial intelligence are notoriously data-hungry. In this paper, we propose the use of small training datasets towards faster training. Specifically, we provide a novel topological method based on morphisms between persistence modules to measure the training data quality with respect to the complete dataset. This way, we can provide an explanation of why the chosen training dataset will lead to poor performance.", "link": "https://arxiv.org/abs/2306.02411"}, {"id": "2306.02520", "date": "Mon, 5 Jun 2023 01:01:12 GMT", "title": "A Study of Situational Reasoning for Traffic Understanding\n", "authors": ["Jiarui Zhang", "Filip Ilievski", "Kaixin Ma", "Aravinda Kollaa", "Jonathan\n Francis", "Alessandro Oltramari\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "11", "pages,", "6", "figures,", "5", "tables,", "camera", "ready", "version", "of", "SIGKDD", "2023\nDOI:", "10.1145/3580305.3599246\n"], "abstract": "Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work, based on natural language inference, commonsense knowledge-graph self-supervision, multi-QA joint training, and dense retrieval of domain information. We associate each method with a relevant knowledge source, including knowledge graphs, relevant benchmarks, and driving manuals. In extensive experiments, we benchmark various knowledge-aware methods against the three datasets, under zero-shot evaluation; we provide in-depth analyses of model performance on data partitions and examine model predictions categorically, to yield useful insights on traffic understanding, given different background knowledge and reasoning strategies.", "link": "https://arxiv.org/abs/2306.02520"}, {"id": "2306.02521", "date": "Mon, 5 Jun 2023 01:10:23 GMT", "title": "Connecting Proof Theory and Knowledge Representation: Sequent Calculi\n and the Chase with Existential Rules\n", "authors": ["Tim S. Lyon and Piotr Ostropolski-Nalewaja\n"], "categories": ["cs.LO", "cs.AI", "cs.DB", "math.LO\nComments:", "Appended", "version", "of", "paper", "accepted", "to", "KR", "2023\n"], "abstract": "Chase algorithms are indispensable in the domain of knowledge base querying, which enable the extraction of implicit knowledge from a given database via applications of rules from a given ontology. Such algorithms have proved beneficial in identifying logical languages which admit decidable query entailment. Within the discipline of proof theory, sequent calculi have been used to write and design proof-search algorithms to identify decidable classes of logics. In this paper, we show that the chase mechanism in the context of existential rules is in essence the same as proof-search in an extension of Gentzen's sequent calculus for first-order logic. Moreover, we show that proof-search generates universal models of knowledge bases, a feature also exhibited by the chase. Thus, we formally connect a central tool for establishing decidability proof-theoretically with a central decidability tool in the context of knowledge representation.", "link": "https://arxiv.org/abs/2306.02521"}, {"id": "2306.02549", "date": "Mon, 5 Jun 2023 02:52:54 GMT", "title": "Evaluation of AI Chatbots for Patient-Specific EHR Questions\n", "authors": ["Alaleh Hamidi and Kirk Roberts\n"], "categories": ["cs.CL", "cs.AI", "cs.IR\n"], "abstract": "This paper investigates the use of artificial intelligence chatbots for patient-specific question answering (QA) from clinical notes using several large language model (LLM) based systems: ChatGPT (versions 3.5 and 4), Google Bard, and Claude. We evaluate the accuracy, relevance, comprehensiveness, and coherence of the answers generated by each model using a 5-point Likert scale on a set of patient-specific questions.", "link": "https://arxiv.org/abs/2306.02549"}, {"id": "2306.02561", "date": "Mon, 5 Jun 2023 03:32:26 GMT", "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and\n Generative Fusion\n", "authors": ["Dongfu Jiang", "Xiang Ren", "Bill Yuchen Lin\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "ACL", "2023", "(Main", "conference).", "Project", "website:\n", "https://yuchenlin.xyz/LLM-Blender/\n"], "abstract": "We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.", "link": "https://arxiv.org/abs/2306.02561"}, {"id": "2306.02592", "date": "Mon, 5 Jun 2023 04:46:44 GMT", "title": "Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help\n Multiple Graph Applications\n", "authors": ["Han Xie", "Da Zheng", "Jun Ma", "Houyu Zhang", "Vassilis N. Ioannidis", "Xiang\n Song", "Qing Ping", "Sheng Wang", "Carl Yang", "Yi Xu", "Belinda Zeng", "Trishul Chilimbi\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "To", "be", "published", "in", "the", "KDD", "2023", "proceedings", "as", "a", "full", "paper\n"], "abstract": "Model pre-training on large text corpora has been demonstrated effective for various downstream applications in the NLP domain. In the graph mining domain, a similar analogy can be drawn for pre-training graph models on large graphs in the hope of benefiting downstream graph applications, which has also been explored by several recent studies. However, no existing study has ever investigated the pre-training of text plus graph models on large heterogeneous graphs with abundant textual information (a.k.a. large graph corpora) and then fine-tuning the model on different related downstream applications with different graph schemas. To address this problem, we propose a framework of graph-aware language model pre-training (GALM) on a large graph corpus, which incorporates large language models and graph neural networks, and a variety of fine-tuning methods on downstream applications. We conduct extensive experiments on Amazon's real internal datasets and large public datasets. Comprehensive empirical results and in-depth analysis demonstrate the effectiveness of our proposed methods along with lessons learned.", "link": "https://arxiv.org/abs/2306.02592"}, {"id": "2306.02608", "date": "Mon, 5 Jun 2023 05:43:35 GMT", "title": "Computing Education in the Era of Generative AI\n", "authors": ["Paul Denny and James Prather and Brett A. Becker and James\n Finnie-Ansley and Arto Hellas and Juho Leinonen and Andrew Luxton-Reilly and\n Brent N. Reeves and Eddie Antonio Santos and Sami Sarsa\n"], "categories": ["cs.CY", "cs.AI", "cs.HC\nComments:", "Accepted", "for", "publication", "as", "a", "Contributed", "Article", "in", "Communications\n", "of", "the", "ACM", "(CACM)\n"], "abstract": "The computing education community has a rich history of pedagogical innovation designed to support students in introductory courses, and to support teachers in facilitating student learning. Very recent advances in artificial intelligence have resulted in code generation models that can produce source code from natural language problem descriptions -- with impressive accuracy in many cases. The wide availability of these models and their ease of use has raised concerns about potential impacts on many aspects of society, including the future of computing education. In this paper, we discuss the challenges and opportunities such models present to computing educators, with a focus on introductory programming classrooms. We summarize the results of two recent articles, the first evaluating the performance of code generation models on typical introductory-level programming problems, and the second exploring the quality and novelty of learning resources generated by these models. We consider likely impacts of such models upon pedagogical practice in the context of the most recent advances at the time of writing.", "link": "https://arxiv.org/abs/2306.02608"}, {"id": "2306.02613", "date": "Mon, 5 Jun 2023 06:14:08 GMT", "title": "Controllable Lyrics-to-Melody Generation\n", "authors": ["Zhe Zhang", "Yi Yu", "Atsuhiro Takasu\n"], "categories": ["cs.SD", "cs.AI", "eess.AS\n"], "abstract": "Lyrics-to-melody generation is an interesting and challenging topic in AI music research field. Due to the difficulty of learning the correlations between lyrics and melody, previous methods suffer from low generation quality and lack of controllability. Controllability of generative models enables human interaction with models to generate desired contents, which is especially important in music generation tasks towards human-centered AI that can facilitate musicians in creative activities. To address these issues, we propose a controllable lyrics-to-melody generation network, ConL2M, which is able to generate realistic melodies from lyrics in user-desired musical style. Our work contains three main novelties: 1) To model the dependencies of music attributes cross multiple sequences, inter-branch memory fusion (Memofu) is proposed to enable information flow between multi-branch stacked LSTM architecture; 2) Reference style embedding (RSE) is proposed to improve the quality of generation as well as control the musical style of generated melodies; 3) Sequence-level statistical loss (SeqLoss) is proposed to help the model learn sequence-level features of melodies given lyrics. Verified by evaluation metrics for music quality and controllability, initial study of controllable lyrics-to-melody generation shows better generation quality and the feasibility of interacting with users to generate the melodies in desired musical styles when given lyrics.", "link": "https://arxiv.org/abs/2306.02613"}, {"id": "2306.02769", "date": "Mon, 5 Jun 2023 10:53:27 GMT", "title": "On simple expectations and observations of intelligent agents: A\n complexity study\n", "authors": ["Sourav Chakraborty", "Avijeet Ghosh", "Sujata Ghosh and Fran\\c{c}ois\n Schwarzentruber\n"], "categories": ["cs.LO", "cs.AI", "cs.CC\nComments:", "Accepted", "in", "KR", "2023\n"], "abstract": "Public observation logic (POL) reasons about agent expectations and agent observations in various real world situations. The expectations of agents take shape based on certain protocols about the world around and they remove those possible scenarios where their expectations and observations do not match. This in turn influences the epistemic reasoning of these agents. In this work, we study the computational complexity of the satisfaction problems of various fragments of POL. In the process, we also highlight the inevitable link that these fragments have with the well-studied Public announcement logic.", "link": "https://arxiv.org/abs/2306.02769"}, {"id": "2306.02771", "date": "Mon, 5 Jun 2023 10:55:15 GMT", "title": "Identifying the style by a qualified reader on a short fragment of\n generated poetry\n", "authors": ["Boris Orekhov\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\nComments:", "6", "pages,", "2", "tables\n"], "abstract": "Style is an important concept in today's challenges in natural language generating. After the success in the field of image style transfer, the task of text style transfer became actual and attractive. Researchers are also interested in the tasks of style reproducing in generation of the poetic text. Evaluation of style reproducing in natural poetry generation remains a problem. I used 3 character-based LSTM-models to work with style reproducing assessment. All three models were trained on the corpus of texts by famous Russian-speaking poets. Samples were shown to the assessors and 4 answer options were offered, the style of which poet this sample reproduces. In addition, the assessors were asked how well they were familiar with the work of the poet they had named. Students studying history of literature were the assessors, 94 answers were received. It has appeared that accuracy of definition of style increases if the assessor can quote the poet by heart. Each model showed at least 0.7 macro-average accuracy. The experiment showed that it is better to involve a professional rather than a naive reader in the evaluation of style in the tasks of poetry generation, while lstm models are good at reproducing the style of Russian poets even on a limited training corpus.", "link": "https://arxiv.org/abs/2306.02771"}, {"id": "2306.02797", "date": "Mon, 5 Jun 2023 11:46:45 GMT", "title": "Modeling Human-like Concept Learning with Bayesian Inference over\n Natural Language\n", "authors": ["Kevin Ellis\n"], "categories": ["cs.CL", "cs.AI", "cs.LG\n"], "abstract": "We model learning of abstract symbolic concepts by performing Bayesian inference over utterances in natural language. For efficient inference, we use a large language model as a proposal distribution. We fit a prior to human data to better model human learners, and evaluate on both generative and logical concepts.", "link": "https://arxiv.org/abs/2306.02797"}, {"id": "2306.03040", "date": "Mon, 5 Jun 2023 17:03:10 GMT", "title": "Learning Similarity among Users for Personalized Session-Based\n Recommendation from hierarchical structure of User-Session-Item\n", "authors": ["Jisoo Cha", "Haemin Jeong", "Wooju Kim\n"], "categories": ["cs.IR", "cs.AI", "cs.LG\nComments:", "7", "pages,", "5", "figures\nMSC-class:", "68P20\n"], "abstract": "The task of the session-based recommendation is to predict the next interaction of the user based on the anonymized user's behavior pattern. And personalized version of this system is a promising research field due to its availability to deal with user information. However, there's a problem that the user's preferences and historical sessions were not considered in the typical session-based recommendation since it concentrates only on user-item interaction. In addition, the existing personalized session-based recommendation model has a limited capability in that it only considers the preference of the current user without considering those of similar users. It means there can be the loss of information included within the hierarchical data structure of the user-session-item. To tackle with this problem, we propose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender). To model global historical sessions of users, we propose UserGraph that has two types of nodes - ItemNode and UserNode. We then connect the nodes with three types of edges. The first type of edges connects ItemNode as chronological order, and the second connects ItemNode to UserNode, and the last connects UserNode to ItemNode. With these user embeddings, we propose additional contrastive loss, that makes users with similar intention be close to each other in the vector space. we apply graph neural network on these UserGraph and update nodes. Experimental results on two real-world datasets demonstrate that our method outperforms some state-of-the-art approaches.", "link": "https://arxiv.org/abs/2306.03040"}, {"id": "2306.03091", "date": "Mon, 5 Jun 2023 17:59:41 GMT", "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems\n", "authors": ["Tianyang Liu", "Canwen Xu", "Julian McAuley\n"], "categories": ["cs.CL", "cs.AI", "cs.SE\n"], "abstract": "Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is publicly available at https://github.com/Leolty/repobench.", "link": "https://arxiv.org/abs/2306.03091"}, {"id": "2306.01818", "date": "Fri, 2 Jun 2023 11:59:57 GMT", "title": "Beta Thalassemia Carriers detection empowered federated Learning\n", "authors": ["Muhammad Shoaib Farooq", "Hafiz Ali Younas\n"], "categories": ["cs.LG", "cs.AI", "cs.CL\nComments:", "pages", "17,", "figures", "8\n"], "abstract": "Thalassemia is a group of inherited blood disorders that happen when hemoglobin, the protein in red blood cells that carries oxygen, is not made enough. It is found all over the body and is needed for survival. If both parents have thalassemia, a child's chance of getting it increases. Genetic counselling and early diagnosis are essential for treating thalassemia and stopping it from being passed on to future generations. It may be hard for healthcare professionals to differentiate between people with thalassemia carriers and those without. The current blood tests for beta thalassemia carriers are too expensive, take too long, and require too much screening equipment. The World Health Organization says there is a high death rate for people with thalassemia. Therefore, it is essential to find thalassemia carriers to act quickly. High-performance liquid chromatography (HPLC), the standard test method, has problems such as cost, time, and equipment needs. So, there must be a quick and cheap way to find people carrying the thalassemia gene. Using federated learning (FL) techniques, this study shows a new way to find people with the beta-thalassemia gene. FL allows data to be collected and processed on-site while following privacy rules, making it an excellent choice for sensitive health data. Researchers used FL to train a model for beta-thalassemia carriers by looking at the complete blood count results and red blood cell indices. The model was 92.38 % accurate at telling the difference between beta-thalassemia carriers and people who did not have the disease. The proposed FL model is better than other published methods in terms of how well it works, how reliable it is, and how private it is. This research shows a promising, quick, accurate, and low-cost way to find thalassemia carriers and opens the door for screening them on a large scale.", "link": "https://arxiv.org/abs/2306.01818"}, {"id": "2306.01926", "date": "Fri, 2 Jun 2023 21:45:13 GMT", "title": "RITA: Group Attention is All You Need for Timeseries Analytics\n", "authors": ["Jiaming Liang", "Lei Cao", "Samuel Madden", "Zachary Ives", "Guoliang Li\n"], "categories": ["cs.LG", "cs.AI", "cs.DB\n"], "abstract": "Timeseries analytics is of great importance in many real-world applications. Recently, the Transformer model, popular in natural language processing, has been leveraged to learn high quality feature embeddings from timeseries, core to the performance of various timeseries analytics tasks. However, the quadratic time and space complexities limit Transformers' scalability, especially for long timeseries. To address these issues, we develop a timeseries analytics tool, RITA, which uses a novel attention mechanism, named group attention, to address this scalability issue. Group attention dynamically clusters the objects based on their similarity into a small number of groups and approximately computes the attention at the coarse group granularity. It thus significantly reduces the time and space complexity, yet provides a theoretical guarantee on the quality of the computed attention. The dynamic scheduler of RITA continuously adapts the number of groups and the batch size in the training process, ensuring group attention always uses the fewest groups needed to meet the approximation quality requirement. Extensive experiments on various timeseries datasets and analytics tasks demonstrate that RITA outperforms the state-of-the-art in accuracy and is significantly faster -- with speedups of up to 63X.", "link": "https://arxiv.org/abs/2306.01926"}, {"id": "2306.01970", "date": "Sat, 3 Jun 2023 00:38:40 GMT", "title": "Temporal-spatial Correlation Attention Network for Clinical Data\n Analysis in Intensive Care Unit\n", "authors": ["Weizhi Nie", "Yuhe Yu", "Chen Zhang", "Dan Song", "Lina Zhao", "Yunpeng Bai\n"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.CY\n"], "abstract": "In recent years, medical information technology has made it possible for electronic health record (EHR) to store fairly complete clinical data. This has brought health care into the era of \"big data\". However, medical data are often sparse and strongly correlated, which means that medical problems cannot be solved effectively. With the rapid development of deep learning in recent years, it has provided opportunities for the use of big data in healthcare. In this paper, we propose a temporal-saptial correlation attention network (TSCAN) to handle some clinical characteristic prediction problems, such as predicting death, predicting length of stay, detecting physiologic decline, and classifying phenotypes. Based on the design of the attention mechanism model, our approach can effectively remove irrelevant items in clinical data and irrelevant nodes in time according to different tasks, so as to obtain more accurate prediction results. Our method can also find key clinical indicators of important outcomes that can be used to improve treatment options. Our experiments use information from the Medical Information Mart for Intensive Care (MIMIC-IV) database, which is open to the public. Finally, we have achieved significant performance benefits of 2.0\\% (metric) compared to other SOTA prediction methods. We achieved a staggering 90.7\\% on mortality rate, 45.1\\% on length of stay. The source code can be find: \\url{https://github.com/yuyuheintju/TSCAN}.", "link": "https://arxiv.org/abs/2306.01970"}, {"id": "2306.01984", "date": "Sat, 3 Jun 2023 02:46:31 GMT", "title": "DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal\n Forecasting\n", "authors": ["Salva R\\\"uhling Cachay", "Bo Zhao", "Hailey James", "Rose Yu\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\nComments:", "Code", "will", "be", "released", "at:", "https://github.com/Rose-STL-Lab/dyffusion\n"], "abstract": "While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for training diffusion models for dynamics forecasting that leverages the temporal dynamics encoded in the data, directly coupling it with the diffusion steps in the network. We train a stochastic, time-conditioned interpolator and a backbone forecaster network that mimic the forward and reverse processes of conventional diffusion models, respectively. This design choice naturally encodes multi-step and long-range forecasting capabilities, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process imposes a strong inductive bias, allowing for improved computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic skill score metrics in complex dynamics forecasting of sea surface temperatures, Navier-Stokes flows, and spring mesh systems.", "link": "https://arxiv.org/abs/2306.01984"}, {"id": "2306.01986", "date": "Sat, 3 Jun 2023 02:47:46 GMT", "title": "A Novel Deep Knowledge-based Learning Method for Wind Speed Forecast\n", "authors": ["Yang Yang", "Jin Lang", "Jian Wu", "Yanyan Zhang\n"], "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC\n"], "abstract": "The increasing installation rate of wind power poses great challenges to the global power system. In order to ensure the reliable operation of the power system, it is necessary to accurately forecast the wind speed and power of the wind turbines. At present, deep learning is progressively applied to the wind speed prediction. Nevertheless, the recent deep learning methods still reflect the embarrassment for practical applications due to model interpretability and hardware limitation. To this end, a novel deep knowledge-based learning method is proposed in this paper. The proposed method hybridizes pre-training method and auto-encoder structure to improve data representation and modeling of the deep knowledge-based learning framework. In order to form knowledge and corresponding absorbers, the original data is preprocessed by an optimization model based on correlation to construct multi-layer networks (knowledge) which are absorbed by sequence to sequence (Seq2Seq) models. Specifically, new cognition and memory units (CMU) are designed to reinforce traditional deep learning framework. Finally, the effectiveness of the proposed method is verified by three wind prediction cases from a wind farm in Liaoning, China. Experimental results show that the proposed method increases the stability and training efficiency compared to the traditional LSTM method and LSTM/GRU-based Seq2Seq method for applications of wind speed forecasting.", "link": "https://arxiv.org/abs/2306.01986"}, {"id": "2306.01991", "date": "Sat, 3 Jun 2023 03:36:47 GMT", "title": "A Bio-Inspired Chaos Sensor Based on the Perceptron Neural Network:\n Concept and Application for Computational Neuro-science\n", "authors": ["Andrei Velichko", "Petr Boriskov", "Maksim Belyaev and Vadim Putrolaynen\n"], "categories": ["cs.LG", "cs.AI", "cs.NE", "nlin.CD\nComments:", "12", "pages,", "22", "figures,", "4", "tables\n"], "abstract": "The study presents a bio-inspired chaos sensor based on the perceptron neural network. After training, the sensor on perceptron, having 50 neurons in the hidden layer and 1 neuron at the output, approximates the fuzzy entropy of short time series with high accuracy with a determination coefficient R2 ~ 0.9. The Hindmarsh-Rose spike model was used to generate time series of spike intervals, and datasets for training and testing the perceptron. The selection of the hyperparameters of the perceptron model and the estimation of the sensor accuracy were performed using the K-block cross-validation method. Even for a hidden layer with 1 neuron, the model approximates the fuzzy entropy with good results and the metric R2 ~ 0.5-0.8. In a simplified model with 1 neuron and equal weights in the first layer, the principle of approximation is based on the linear transformation of the average value of the time series into the entropy value. The bio-inspired chaos sensor model based on an ensemble of neurons is able to dynamically track the chaotic behavior of a spiked biosystem and transmit this information to other parts of the bio-system for further processing. The study will be useful for specialists in the field of computational neuroscience.", "link": "https://arxiv.org/abs/2306.01991"}, {"id": "2306.02002", "date": "Sat, 3 Jun 2023 04:56:04 GMT", "title": "Can Directed Graph Neural Networks be Adversarially Robust?\n", "authors": ["Zhichao Hou", "Xitong Zhang", "Wei Wang", "Charu C. Aggarwal", "Xiaorui Liu\n"], "categories": ["cs.LG", "cs.AI", "cs.CR\n"], "abstract": "The existing research on robust Graph Neural Networks (GNNs) fails to acknowledge the significance of directed graphs in providing rich information about networks' inherent structure. This work presents the first investigation into the robustness of GNNs in the context of directed graphs, aiming to harness the profound trust implications offered by directed graphs to bolster the robustness and resilience of GNNs. Our study reveals that existing directed GNNs are not adversarially robust. In pursuit of our goal, we introduce a new and realistic directed graph attack setting and propose an innovative, universal, and efficient message-passing framework as a plug-in layer to significantly enhance the robustness of GNNs. Combined with existing defense strategies, this framework achieves outstanding clean accuracy and state-of-the-art robust performance, offering superior defense against both transfer and adaptive attacks. The findings in this study reveal a novel and promising direction for this crucial research area. The code will be made publicly available upon the acceptance of this work.", "link": "https://arxiv.org/abs/2306.02002"}, {"id": "2306.02003", "date": "Sat, 3 Jun 2023 05:01:51 GMT", "title": "On Optimal Caching and Model Multiplexing for Large Model Inference\n", "authors": ["Banghua Zhu", "Ying Sheng", "Lianmin Zheng", "Clark Barrett", "Michael I.\n Jordan", "Jiantao Jiao\n"], "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SY", "eess.SY", "stat.ML\n"], "abstract": "Large Language Models (LLMs) and other large foundation models have achieved noteworthy success, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model multiplexer to choose from an ensemble of models for query processing. Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we achieve optimal rates in both offline and online settings. Empirically, simulations show that the combination of our caching and model multiplexing algorithms greatly improves over the baselines, with up to $50\\times$ improvement over the baseline when the ratio between the maximum cost and minimum cost is $100$. Experiments on real datasets show a $4.3\\times$ improvement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a $1.8\\times$ improvement in latency when the ratio for average latency is $1.85$.", "link": "https://arxiv.org/abs/2306.02003"}, {"id": "2306.02121", "date": "Sat, 3 Jun 2023 14:25:15 GMT", "title": "Identifying Subgroups of ICU Patients Using End-to-End Multivariate\n Time-Series Clustering Algorithm Based on Real-World Vital Signs Data\n", "authors": ["Tongyue Shi", "Zhilong Zhang", "Wentie Liu", "Junhua Fang", "Jianguo Hao,\n Shuai Jin", "Huiying Zhao and Guilan Kong\n"], "categories": ["cs.LG", "cs.AI", "cs.CY", "math.OC\nComments:", "Proceedings", "of", "Beijing", "Health", "Data", "Science", "Summit", "(HDSS)", "2023\n"], "abstract": "This study employed the MIMIC-IV database as data source to investigate the use of dynamic, high-frequency, multivariate time-series vital signs data, including temperature, heart rate, mean blood pressure, respiratory rate, and SpO2, monitored first 8 hours data in the ICU stay. Various clustering algorithms were compared, and an end-to-end multivariate time series clustering system called Time2Feat, combined with K-Means, was chosen as the most effective method to cluster patients in the ICU. In clustering analysis, data of 8,080 patients admitted between 2008 and 2016 was used for model development and 2,038 patients admitted between 2017 and 2019 for model validation. By analyzing the differences in clinical mortality prognosis among different categories, varying risks of ICU mortality and hospital mortality were found between different subgroups. Furthermore, the study visualized the trajectory of vital signs changes. The findings of this study provide valuable insights into the potential use of multivariate time-series clustering systems in patient management and monitoring in the ICU setting.", "link": "https://arxiv.org/abs/2306.02121"}, {"id": "2306.02235", "date": "Sun, 4 Jun 2023 02:32:12 GMT", "title": "Learning Linear Causal Representations from Interventions under General\n Nonlinear Mixing\n", "authors": ["Simon Buchholz", "Goutham Rajendran", "Elan Rosenfeld", "Bryon Aragam,\n Bernhard Sch\\\"olkopf", "Pradeep Ravikumar\n"], "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ME", "stat.ML", "stat.TH\nComments:", "38", "pages\n"], "abstract": "We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.", "link": "https://arxiv.org/abs/2306.02235"}, {"id": "2306.02399", "date": "Sun, 4 Jun 2023 16:24:19 GMT", "title": "Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz\n Dynamic Risk Measures\n", "authors": ["Hao Liang", "Zhi-quan Luo\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \\emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, distortion risk measures among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes, while reflecting the inherent trade-off between risk sensitivity and sample complexity. Additionally, we substantiate our theoretical results through numerical experiments.", "link": "https://arxiv.org/abs/2306.02399"}, {"id": "2306.02418", "date": "Sun, 4 Jun 2023 17:50:20 GMT", "title": "ContraBAR: Contrastive Bayes-Adaptive Deep RL\n", "authors": ["Era Choshen", "Aviv Tamar\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\nComments:", "ICML", "2023.", "Pytorch", "code", "available", "at\n", "https://github.com/ec2604/ContraBAR\n"], "abstract": "In meta reinforcement learning (meta RL), an agent seeks a Bayes-optimal policy -- the optimal policy when facing an unknown task that is sampled from some known task distribution. Previous approaches tackled this problem by inferring a belief over task parameters, using variational inference methods. Motivated by recent successes of contrastive learning approaches in RL, such as contrastive predictive coding (CPC), we investigate whether contrastive methods can be used for learning Bayes-optimal behavior. We begin by proving that representations learned by CPC are indeed sufficient for Bayes optimality. Based on this observation, we propose a simple meta RL algorithm that uses CPC in lieu of variational belief inference. Our method, ContraBAR, achieves comparable performance to state-of-the-art in domains with state-based observation and circumvents the computational toll of future observation reconstruction, enabling learning in domains with image-based observations. It can also be combined with image augmentations for domain randomization and used seamlessly in both online and offline meta RL settings.", "link": "https://arxiv.org/abs/2306.02418"}, {"id": "2306.02420", "date": "Sun, 4 Jun 2023 17:52:49 GMT", "title": "Complexity of Block Coordinate Descent with Proximal Regularization and\n Applications to Wasserstein CP-dictionary Learning\n", "authors": ["Dohyun Kwon", "Hanbaek Lyu\n"], "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.OC\nComments:", "Proceedings", "of", "the", "40th", "International", "Conference", "on", "Machine", "Learning\n"], "abstract": "We consider the block coordinate descent methods of Gauss-Seidel type with proximal regularization (BCD-PR), which is a classical method of minimizing general nonconvex objectives under constraints that has a wide range of practical applications. We theoretically establish the worst-case complexity bound for this algorithm. Namely, we show that for general nonconvex smooth objectives with block-wise constraints, the classical BCD-PR algorithm converges to an epsilon-stationary point within O(1/epsilon) iterations. Under a mild condition, this result still holds even if the algorithm is executed inexactly in each step. As an application, we propose a provable and efficient algorithm for `Wasserstein CP-dictionary learning', which seeks a set of elementary probability distributions that can well-approximate a given set of d-dimensional joint probability distributions. Our algorithm is a version of BCD-PR that operates in the dual space, where the primal problem is regularized both entropically and proximally.", "link": "https://arxiv.org/abs/2306.02420"}, {"id": "2306.02451", "date": "Sun, 4 Jun 2023 19:47:46 GMT", "title": "For SALE: State-Action Representation Learning for Deep Reinforcement\n Learning\n", "authors": ["Scott Fujimoto", "Wei-Di Chang", "Edward J. Smith", "Shixiang Shane Gu,\n Doina Precup", "David Meger\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings.", "link": "https://arxiv.org/abs/2306.02451"}, {"id": "2306.02532", "date": "Mon, 5 Jun 2023 01:41:23 GMT", "title": "R-Mixup: Riemannian Mixup for Biological Networks\n", "authors": ["Xuan Kan", "Zimu Li", "Hejie Cui", "Yue Yu", "Ran Xu", "Shaojun Yu", "Zilong\n Zhang", "Ying Guo", "Carl Yang\n"], "categories": ["cs.LG", "cs.AI", "q-bio.QM\nComments:", "Accepted", "to", "KDD", "2023\nMSC-class:", "68T07,", "68T05\nACM-class:", "I.2.6;", "J.3\nDOI:", "10.1145/3580305.3599483\n"], "abstract": "Biological networks are commonly used in biomedical and healthcare domains to effectively model the structure of complex biological systems with interactions linking biological entities. However, due to their characteristics of high dimensionality and low sample size, directly applying deep learning models on biological networks usually faces severe overfitting. In this work, we propose R-MIXUP, a Mixup-based data augmentation technique that suits the symmetric positive definite (SPD) property of adjacency matrices from biological networks with optimized training efficiency. The interpolation process in R-MIXUP leverages the log-Euclidean distance metrics from the Riemannian manifold, effectively addressing the swelling effect and arbitrarily incorrect label issues of vanilla Mixup. We demonstrate the effectiveness of R-MIXUP with five real-world biological network datasets on both regression and classification tasks. Besides, we derive a commonly ignored necessary condition for identifying the SPD matrices of biological networks and empirically study its influence on the model performance. The code implementation can be found in Appendix E.", "link": "https://arxiv.org/abs/2306.02532"}, {"id": "2306.02555", "date": "Mon, 5 Jun 2023 03:05:43 GMT", "title": "Barriers for the performance of graph neural networks (GNN) in discrete\n random structures. A comment\n on~\\cite{schuetz2022combinatorial},\\cite{angelini2023modern},\\cite{schuetz2023reply}\n", "authors": ["David Gamarnik\n"], "categories": ["cs.LG", "cs.AI", "cs.DM\nComments:", "5", "pages\n"], "abstract": "Recently graph neural network (GNN) based algorithms were proposed to solve a variety of combinatorial optimization problems, including Maximum Cut problem, Maximum Independent Set problem and similar other problems~\\cite{schuetz2022combinatorial},\\cite{schuetz2022graph}. The publication~\\cite{schuetz2022combinatorial} stirred a debate whether GNN based method was adequately benchmarked against best prior methods. In particular, critical commentaries~\\cite{angelini2023modern} and~\\cite{boettcher2023inability} point out that simple greedy algorithm performs better than GNN in the setting of random graphs, and in fact stronger algorithmic performance can be reached with more sophisticated methods. A response from the authors~\\cite{schuetz2023reply} pointed out that GNN performance can be improved further by tuning up the parameters better. We do not intend to discuss the merits of arguments and counter-arguments in~\\cite{schuetz2022combinatorial},\\cite{angelini2023modern},\\cite{boettcher2023inability},\\cite{schuetz2023reply}. Rather in this note we establish a fundamental limitation for running GNN on random graphs considered in these references, for a broad range of choices of GNN architecture. These limitations arise from the presence of the Overlap Gap Property (OGP) phase transition, which is a barrier for many algorithms, both classical and quantum. As we demonstrate in this paper, it is also a barrier to GNN due to its local structure. We note that at the same time known algorithms ranging from simple greedy algorithms to more sophisticated algorithms based on message passing, provide best results for these problems \\emph{up to} the OGP phase transition. This leaves very little space for GNN to outperform the known algorithms, and based on this we side with the conclusions made in~\\cite{angelini2023modern} and~\\cite{boettcher2023inability}.", "link": "https://arxiv.org/abs/2306.02555"}, {"id": "2306.02622", "date": "Mon, 5 Jun 2023 06:50:09 GMT", "title": "What Makes Entities Similar? A Similarity Flooding Perspective for\n Multi-sourced Knowledge Graph Embeddings\n", "authors": ["Zequn Sun and Jiacheng Huang and Xiaozhou Xu and Qijin Chen and Weijun\n Ren and Wei Hu\n"], "categories": ["cs.LG", "cs.AI", "cs.CL\nComments:", "Accepted", "in", "the", "40th", "International", "Conference", "on", "Machine", "Learning\n", "(ICML", "2023)\n"], "abstract": "Joint representation learning over multi-sourced knowledge graphs (KGs) yields transferable and expressive embeddings that improve downstream tasks. Entity alignment (EA) is a critical step in this process. Despite recent considerable research progress in embedding-based EA, how it works remains to be explored. In this paper, we provide a similarity flooding perspective to explain existing translation-based and aggregation-based EA models. We prove that the embedding learning process of these models actually seeks a fixpoint of pairwise similarities between entities. We also provide experimental evidence to support our theoretical analysis. We propose two simple but effective methods inspired by the fixpoint computation in similarity flooding, and demonstrate their effectiveness on benchmark datasets. Our work bridges the gap between recent embedding-based models and the conventional similarity flooding algorithm. It would improve our understanding of and increase our faith in embedding-based EA.", "link": "https://arxiv.org/abs/2306.02622"}, {"id": "2306.02652", "date": "Mon, 5 Jun 2023 07:38:13 GMT", "title": "Towards Anytime Classification in Early-Exit Architectures by Enforcing\n Conditional Monotonicity\n", "authors": ["Metod Jazbec", "James Urquhart Allingham", "Dan Zhang", "Eric Nalisnick\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly anytime predictive modeling using early-exit architectures. Our empirical results on standard image-classification tasks demonstrate that such behaviors can be achieved while preserving competitive accuracy on average.", "link": "https://arxiv.org/abs/2306.02652"}, {"id": "2306.02869", "date": "Mon, 5 Jun 2023 13:43:34 GMT", "title": "Data-Driven Regret Balancing for Online Model Selection in Bandits\n", "authors": ["Aldo Pacchiano", "Christoph Dann", "Claudio Gentile\n"], "categories": ["cs.LG", "cs.AI", "stat.ML\n"], "abstract": "We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets instead of candidate regret bounds.", "link": "https://arxiv.org/abs/2306.02869"}, {"id": "2306.03007", "date": "Mon, 5 Jun 2023 16:19:07 GMT", "title": "Nonparametric Iterative Machine Teaching\n", "authors": ["Chen Zhang", "Xiaofeng Cao", "Weiyang Liu", "Ivor Tsang", "James Kwok\n"], "categories": ["cs.LG", "cs.AI", "cs.CV\nComments:", "ICML", "2023", "(20", "pages,", "10", "figures)\n"], "abstract": "In this paper, we consider the problem of Iterative Machine Teaching (IMT), where the teacher provides examples to the learner iteratively such that the learner can achieve fast convergence to a target model. However, existing IMT algorithms are solely based on parameterized families of target models. They mainly focus on convergence in the parameter space, resulting in difficulty when the target models are defined to be functions without dependency on parameters. To address such a limitation, we study a more general task -- Nonparametric Iterative Machine Teaching (NIMT), which aims to teach nonparametric target models to learners in an iterative fashion. Unlike parametric IMT that merely operates in the parameter space, we cast NIMT as a functional optimization problem in the function space. To solve it, we propose both random and greedy functional teaching algorithms. We obtain the iterative teaching dimension (ITD) of the random teaching algorithm under proper assumptions, which serves as a uniform upper bound of ITD in NIMT. Further, the greedy teaching algorithm has a significantly lower ITD, which reaches a tighter upper bound of ITD in NIMT. Finally, we verify the correctness of our theoretical findings with extensive experiments in nonparametric scenarios.", "link": "https://arxiv.org/abs/2306.03007"}, {"id": "2306.03065", "date": "Mon, 5 Jun 2023 17:43:46 GMT", "title": "LibAUC: A Deep Learning Library for X-Risk Optimization\n", "authors": ["Zhuoning Yuan", "Dixian Zhu", "Zi-Hao Qiu", "Gang Li", "Xuanhui Wang", "Tianbao\n Yang\n"], "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML\nComments:", "Accepted", "by", "KDD2023\nDOI:", "10.1145/3580305.3599861\n"], "abstract": "This paper introduces the award-winning deep learning (DL) library called LibAUC for implementing state-of-the-art algorithms towards optimizing a family of risk functions named X-risks. X-risks refer to a family of compositional functions in which the loss function of each data point is defined in a way that contrasts the data point with a large number of others. They have broad applications in AI for solving classical and emerging problems, including but not limited to classification for imbalanced data (CID), learning to rank (LTR), and contrastive learning of representations (CLR). The motivation of developing LibAUC is to address the convergence issues of existing libraries for solving these problems. In particular, existing libraries may not converge or require very large mini-batch sizes in order to attain good performance for these problems, due to the usage of the standard mini-batch technique in the empirical risk minimization (ERM) framework. Our library is for deep X-risk optimization (DXO) that has achieved great success in solving a variety of tasks for CID, LTR and CLR. The contributions of this paper include: (1) It introduces a new mini-batch based pipeline for implementing DXO algorithms, which differs from existing DL pipeline in the design of controlled data samplers and dynamic mini-batch losses; (2) It provides extensive benchmarking experiments for ablation studies and comparison with existing libraries. The LibAUC library features scalable performance for millions of items to be contrasted, faster and better convergence than existing libraries for optimizing X-risks, seamless PyTorch deployment and versatile APIs for various loss optimization. Our library is available to the open source community at https://github.com/Optimization-AI/LibAUC, to facilitate further academic research and industrial applications.", "link": "https://arxiv.org/abs/2306.03065"}, {"id": "2306.02766", "date": "Mon, 5 Jun 2023 10:45:39 GMT", "title": "Networked Communication for Decentralised Agents in Mean-Field Games\n", "authors": ["Patrick Benjamin and Alessandro Abate\n"], "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.SI", "cs.SY", "eess.SY\n"], "abstract": "We introduce networked communication to the mean-field game framework. In particular, we look at oracle-free settings where $N$ decentralised agents learn along a single, non-episodic evolution path of the empirical system, such as we may encounter for a large range of many-agent cooperation problems in the real-world. We provide theoretical evidence that by spreading improved policies through the network in a decentralised fashion, our sample guarantees are upper-bounded by those of the purely independent-learning case. Moreover, we show empirically that our networked method can give faster convergence in practice, while removing the reliance on a centralised controller. We also demonstrate that our decentralised communication architecture brings significant benefits over both the centralised and independent alternatives in terms of robustness and flexibility to unexpected learning failures and changes in population size. For comparison purposes with our new architecture, we modify recent algorithms for the centralised and independent cases to make their practical convergence feasible: while contributing the first empirical demonstrations of these algorithms in our setting of $N$ agents learning along a single system evolution with only local state observability, we additionally display the empirical benefits of our new, networked approach.", "link": "https://arxiv.org/abs/2306.02766"}, {"id": "2306.01906", "date": "Fri, 2 Jun 2023 20:31:33 GMT", "title": "Synaptic motor adaptation: A three-factor learning rule for adaptive\n robotic control in spiking neural networks\n", "authors": ["Samuel Schmidgall", "Joe Hays\n"], "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.NE\n"], "abstract": "Legged robots operating in real-world environments must possess the ability to rapidly adapt to unexpected conditions, such as changing terrains and varying payloads. This paper introduces the Synaptic Motor Adaptation (SMA) algorithm, a novel approach to achieving real-time online adaptation in quadruped robots through the utilization of neuroscience-derived rules of synaptic plasticity with three-factor learning. To facilitate rapid adaptation, we meta-optimize a three-factor learning rule via gradient descent to adapt to uncertainty by approximating an embedding produced by privileged information using only locally accessible onboard sensing data. Our algorithm performs similarly to state-of-the-art motor adaptation algorithms and presents a clear path toward achieving adaptive robotics with neuromorphic hardware.", "link": "https://arxiv.org/abs/2306.01906"}, {"id": "2306.02231", "date": "Sun, 4 Jun 2023 01:59:40 GMT", "title": "Fine-Tuning Language Models with Advantage-Induced Policy Alignment\n", "authors": ["Banghua Zhu", "Hiteshi Sharma", "Felipe Vieira Frujeri", "Shi Dong,\n Chenguang Zhu", "Michael I. Jordan", "Jiantao Jiao\n"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SY", "eess.SY\n"], "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a reliable approach to aligning large language models (LLMs) to human preferences. Among the plethora of RLHF techniques, proximal policy optimization (PPO) is of the most widely used methods. Despite its popularity, however, PPO may suffer from mode collapse, instability, and poor sample efficiency. We show that these issues can be alleviated by a novel algorithm that we refer to as Advantage-Induced Policy Alignment (APA), which leverages a squared error loss function based on the estimated advantages. We demonstrate empirically that APA consistently outperforms PPO in language tasks by a large margin, when a separate reward model is employed as the evaluator. In addition, compared with PPO, APA offers a more stable form of control over the deviation from the model's initial policy, ensuring that the model improves its performance without collapsing to deterministic output. In addition to empirical results, we also provide a theoretical justification supporting the design of our loss function.", "link": "https://arxiv.org/abs/2306.02231"}, {"id": "2306.02826", "date": "Mon, 5 Jun 2023 12:22:46 GMT", "title": "Near-Optimal Quantum Coreset Construction Algorithms for Clustering\n", "authors": ["Yecheng Xue", "Xiaoyu Chen", "Tongyang Li", "Shaofeng H.-C. Jiang\n"], "categories": ["quant-ph", "cs.AI", "cs.DS", "cs.LG", "stat.ML\nComments:", "Comments:", "32", "pages,", "0", "figures,", "1", "table.", "To", "appear", "in", "the", "Fortieth\n", "International", "Conference", "on", "Machine", "Learning", "(ICML", "2023)\n"], "abstract": "$k$-Clustering in $\\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\\mathbb{R}^d$ with $\\tilde{O}(\\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\\mathrm{poly}(k\\epsilon^{-1}d)$, so that existing $\\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \\epsilon)\\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\\Omega(\\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering.", "link": "https://arxiv.org/abs/2306.02826"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.link + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

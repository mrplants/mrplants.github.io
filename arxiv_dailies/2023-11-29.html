<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.16125", "Date": "Sat, 28 Oct 2023 23:33:00 ", "Title": "Vision-Based Incoming Traffic Estimator Using Deep Neural Network on General Purpose Embedded Hardware", "Authors": ["K. G. Zoysa", "and S. R. Munasinghe"], "Categories": "cs.CV cs.LG", "Comments": ["6 pages", "11 figures", "journal"]}, "abstract": "Traffic management is a serious problem in many cities around the world. Even the suburban areas are now experiencing regular traffic congestion. Inappropriate traffic control wastes fuel, time, and the productivity of nations. Though traffic signals are used to improve traffic flow, they often cause problems due to inappropriate or obsolete timing that does not tally with the actual traffic intensity at the intersection. Traffic intensity determination based on statistical methods only gives the average intensity expected at any given time. However, to control traffic accurately, it is required to know the real-time traffic intensity. In this research, image processing and machine learning have been used to estimate actual traffic intensity in real time. General-purpose electronic hardware has been used for in-situ image processing based on the edge-detection method. A deep neural network (DNN) was trained to infer traffic intensity in each image in real time. The trained DNN estimated traffic intensity accurately in 90% of the real-time images during road tests. The electronic system was implemented on a Raspberry Pi single-board computer; hence, it is cost-effective for large-scale deployment.", "url": "https://arxiv.org/abs/2311.16125"}, {"metadata": {"arXiv": "2311.16145", "Date": "Tue, 07 Nov 2023 02:31:51 ", "Title": "Dual-Stream Attention Transformers for Sewer Defect Classification", "Authors": ["Abdullah Al Redwan Newaz", "Mahdi Abdeldguerfi", "Kendall N. Niles", "and Joe Tom"], "Categories": "cs.CV cs.LG"}, "abstract": "We propose a dual-stream multi-scale vision transformer (DS-MSHViT) architecture that processes RGB and optical flow inputs for efficient sewer defect classification. Unlike existing methods that combine the predictions of two separate networks trained on each modality, we jointly train a single network with two branches for RGB and motion. Our key idea is to use self-attention regularization to harness the complementary strengths of the RGB and motion streams. The motion stream alone struggles to generate accurate attention maps, as motion images lack the rich visual features present in RGB images. To facilitate this, we introduce an attention consistency loss between the dual streams. By leveraging motion cues through a self-attention regularizer, we align and enhance RGB attention maps, enabling the network to concentrate on pertinent input regions. We evaluate our data on a public dataset as well as cross-validate our model performance in a novel dataset. Our method outperforms existing models that utilize either convolutional neural networks (CNNs) or multi-scale hybrid vision transformers (MSHViTs) without employing attention regularization between the two streams.", "url": "https://arxiv.org/abs/2311.16145"}, {"metadata": {"arXiv": "2311.16157", "Date": "Wed, 08 Nov 2023 23:38:32 ", "Title": "GeoTop: Advancing Image Classification with Geometric-Topological Analysis", "Authors": ["Mariem Abaach", "Ian Morilla"], "Categories": "cs.CV cs.LG eess.IV math.GT", "Comments": ["17 pages", "15 figures"], "MSC-class": "68T05, 55N31, 62R40, 49K30", "ACM-class": "J.3; K.3.2"}, "abstract": "In this study, we explore the application of Topological Data Analysis (TDA) and Lipschitz-Killing Curvatures (LKCs) as powerful tools for feature extraction and classification in the context of biomedical multiomics problems. TDA allows us to capture topological features and patterns within complex datasets, while LKCs provide essential geometric insights. We investigate the potential of combining both methods to improve classification accuracy. Using a dataset of biomedical images, we demonstrate that TDA and LKCs can effectively extract topological and geometrical features, respectively. The combination of these features results in enhanced classification performance compared to using each method individually. This approach offers promising results and has the potential to advance our understanding of complex biological processes in various biomedical applications. Our findings highlight the value of integrating topological and geometrical information in biomedical data analysis. As we continue to delve into the intricacies of multiomics problems, the fusion of these insights holds great promise for unraveling the underlying biological complexities.", "url": "https://arxiv.org/abs/2311.16157"}, {"metadata": {"arXiv": "2311.16346", "Date": "Mon, 27 Nov 2023 22:25:46 ", "Title": "Small and Dim Target Detection in IR Imagery: A Review", "Authors": ["Nikhil Kumar", "Pravendra Singh"], "Categories": "cs.CV cs.LG", "Comments": ["Under Review"]}, "abstract": "While there has been significant progress in object detection using conventional image processing and machine learning algorithms, exploring small and dim target detection in the IR domain is a relatively new area of study. The majority of small and dim target detection methods are derived from conventional object detection algorithms, albeit with some alterations. The task of detecting small and dim targets in IR imagery is complex. This is because these targets often need distinct features, the background is cluttered with unclear details, and the IR signatures of the scene can change over time due to fluctuations in thermodynamics. The primary objective of this review is to highlight the progress made in this field. This is the first review in the field of small and dim target detection in infrared imagery, encompassing various methodologies ranging from conventional image processing to cutting-edge deep learning-based approaches. The authors have also introduced a taxonomy of such approaches. There are two main types of approaches: methodologies using several frames for detection, and single-frame-based detection techniques. Single frame-based detection techniques encompass a diverse range of methods, spanning from traditional image processing-based approaches to more advanced deep learning methodologies. Our findings indicate that deep learning approaches perform better than traditional image processing-based approaches. In addition, a comprehensive compilation of various available datasets has also been provided. Furthermore, this review identifies the gaps and limitations in existing techniques, paving the way for future research and development in this area.", "url": "https://arxiv.org/abs/2311.16346"}, {"metadata": {"arXiv": "2311.16507", "Date": "Tue, 28 Nov 2023 06:19:30 ", "Title": "Exploring Straighter Trajectories of Flow Matching with Diffusion Guidance", "Authors": ["Siyu Xing", "Jie Cao", "Huaibo Huang", "Xiao-Yu Zhang", "Ran He"], "Categories": "cs.CV cs.LG"}, "abstract": "Flow matching as a paradigm of generative model achieves notable success across various domains. However, existing methods use either multi-round training or knowledge within minibatches, posing challenges in finding a favorable coupling strategy for straight trajectories. To address this issue, we propose a novel approach, Straighter trajectories of Flow Matching (StraightFM). It straightens trajectories with the coupling strategy guided by diffusion model from entire distribution level. First, we propose a coupling strategy to straighten trajectories, creating couplings between image and noise samples under diffusion model guidance. Second, StraightFM also integrates real data to enhance training, employing a neural network to parameterize another coupling process from images to noise samples. StraightFM is jointly optimized with couplings from above two mutually complementary directions, resulting in straighter trajectories and enabling both one-step and few-step generation. Extensive experiments demonstrate that StraightFM yields high quality samples with fewer step. StraightFM generates visually appealing images with a lower FID among diffusion and traditional flow matching methods within 5 sampling steps when trained on pixel space. In the latent space (i.e., Latent Diffusion), StraightFM achieves a lower KID value compared to existing methods on the CelebA-HQ 256 dataset in fewer than 10 sampling steps.", "url": "https://arxiv.org/abs/2311.16507"}, {"metadata": {"arXiv": "2311.16524", "Date": "Tue, 28 Nov 2023 05:06:22 ", "Title": "3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit Functions", "Authors": ["Sihwa Park", "Seongjun Kim", "In-Seok Song", "Seung Jun Baek"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages", "2 figures", "accepted to International Conference on Medical Image Computing and Computer-Assisted Intervention MICCAI 2023"], "DOI": "10.1007/978-3-031-43999-5_36"}, "abstract": "Panoramic radiography is a widely used imaging modality in dental practice and research. However, it only provides flattened 2D images, which limits the detailed assessment of dental structures. In this paper, we propose Occudent, a framework for 3D teeth reconstruction from panoramic radiographs using neural implicit functions, which, to the best of our knowledge, is the first work to do so. For a given point in 3D space, the implicit function estimates whether the point is occupied by a tooth, and thus implicitly determines the boundaries of 3D tooth shapes. Firstly, Occudent applies multi-label segmentation to the input panoramic radiograph. Next, tooth shape embeddings as well as tooth class embeddings are generated from the segmentation outputs, which are fed to the reconstruction network. A novel module called Conditional eXcitation (CX) is proposed in order to effectively incorporate the combined shape and class embeddings into the implicit function. The performance of Occudent is evaluated using both quantitative and qualitative measures. Importantly, Occudent is trained and validated with actual panoramic radiographs as input, distinct from recent works which used synthesized images. Experiments demonstrate the superiority of Occudent over state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.16524"}, {"metadata": {"arXiv": "2311.16589", "Date": "Tue, 28 Nov 2023 08:15:27 ", "Title": "Improving Lane Detection Generalization: A Novel Framework using HD Maps for Boosting Diversity", "Authors": ["Daeun Lee", "Minhyeok Heo and Jiwon Kim"], "Categories": "cs.CV cs.LG cs.RO", "Comments": ["6 pages", "5 figures"]}, "abstract": "Lane detection is a vital task for vehicles to navigate and localize their position on the road. To ensure reliable results, lane detection algorithms must have robust generalization performance in various road environments. However, despite the significant performance improvement of deep learning-based lane detection algorithms, their generalization performance in response to changes in road environments still falls short of expectations. In this paper, we present a novel framework for single-source domain generalization (SSDG) in lane detection. By decomposing data into lane structures and surroundings, we enhance diversity using High-Definition (HD) maps and generative models. Rather than expanding data volume, we strategically select a core subset of data, maximizing diversity and optimizing performance. Our extensive experiments demonstrate that our framework enhances the generalization performance of lane detection, comparable to the domain adaptation-based method.", "url": "https://arxiv.org/abs/2311.16589"}, {"metadata": {"arXiv": "2311.16766", "Date": "Tue, 28 Nov 2023 13:14:55 ", "Title": "Rescuing referral failures during automated diagnosis of domain-shifted medical images", "Authors": ["Anuj Srivastava", "Karm Patel", "Pradeep Shenoy", "Devarajan Sridharan"], "Categories": "cs.CV cs.LG"}, "abstract": "The success of deep learning models deployed in the real world depends critically on their ability to generalize well across diverse data domains. Here, we address a fundamental challenge with selective classification during automated diagnosis with domain-shifted medical images. In this scenario, models must learn to avoid making predictions when label confidence is low, especially when tested with samples far removed from the training set (covariate shift). Such uncertain cases are typically referred to the clinician for further analysis and evaluation. Yet, we show that even state-of-the-art domain generalization approaches fail severely during referral when tested on medical images acquired from a different demographic or using a different technology. We examine two benchmark diagnostic medical imaging datasets exhibiting strong covariate shifts: i) diabetic retinopathy prediction with retinal fundus images and ii) multilabel disease prediction with chest X-ray images. We show that predictive uncertainty estimates do not generalize well under covariate shifts leading to non-monotonic referral curves, and severe drops in performance (up to 50%) at high referral rates (>70%). We evaluate novel combinations of robust generalization and post hoc referral approaches, that rescue these failures and achieve significant performance improvements, typically >10%, over baseline methods. Our study identifies a critical challenge with referral in domain-shifted medical images and finds key applications in reliable, automated disease diagnosis.", "url": "https://arxiv.org/abs/2311.16766"}, {"metadata": {"arXiv": "2311.16829", "Date": "Tue, 28 Nov 2023 14:48:22 ", "Title": "Decomposer: Semi-supervised Learning of Image Restoration and Image Decomposition", "Authors": ["Boris Meinardus", "Mariusz Trzeciakiewicz", "Tim Herzig", "Monika Kwiatkowski", "Simon Matern", "Olaf Hellwich"], "Categories": "cs.CV cs.LG"}, "abstract": "We present Decomposer, a semi-supervised reconstruction model that decomposes distorted image sequences into their fundamental building blocks - the original image and the applied augmentations, i.e., shadow, light, and occlusions. To solve this problem, we use the SIDAR dataset that provides a large number of distorted image sequences: each sequence contains images with shadows, lighting, and occlusions applied to an undistorted version. Each distortion changes the original signal in different ways, e.g., additive or multiplicative noise. We propose a transformer-based model to explicitly learn this decomposition. The sequential model uses 3D Swin-Transformers for spatio-temporal encoding and 3D U-Nets as prediction heads for individual parts of the decomposition. We demonstrate that by separately pre-training our model on weakly supervised pseudo labels, we can steer our model to optimize for our ambiguous problem definition and learn to differentiate between the different image distortions.", "url": "https://arxiv.org/abs/2311.16829"}, {"metadata": {"arXiv": "2311.16882", "Date": "Tue, 28 Nov 2023 15:31:11 ", "Title": "Optimisation-Based Multi-Modal Semantic Image Editing", "Authors": ["Bowen Li", "Yongxin Yang", "Steven McDonagh", "Shifeng Zhang", "Petru-Daniel Tudosiu", "Sarah Parisot"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Image editing affords increased control over the aesthetics and content of generated images. Pre-existing works focus predominantly on text-based instructions to achieve desired image modifications, which limit edit precision and accuracy. In this work, we propose an inference-time editing optimisation, designed to extend beyond textual edits to accommodate multiple editing instruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We propose to disentangle the editing task into two competing subtasks: successful local image modifications and global content consistency preservation, where subtasks are guided through two dedicated loss functions. By allowing to adjust the influence of each loss function, we build a flexible editing solution that can be adjusted to user preferences. We evaluate our method using text, pose and scribble edit conditions, and highlight our ability to achieve complex edits, through both qualitative and quantitative experiments.", "url": "https://arxiv.org/abs/2311.16882"}, {"metadata": {"arXiv": "2311.16943", "Date": "Tue, 28 Nov 2023 16:46:44 ", "Title": "Image segmentation with traveling waves in an exactly solvable recurrent neural network", "Authors": ["Luisa H. B. Liboni", "Roberto C. Budzinski", "Alexandra N. Busch", "Sindy L\\\"owe", "Thomas A. Keller", "Max Welling", "Lyle E. Muller"], "Categories": "cs.CV cs.LG cs.NE"}, "abstract": "We study image segmentation using spatiotemporal dynamics in a recurrent neural network where the state of each unit is given by a complex number. We show that this network generates sophisticated spatiotemporal dynamics that can effectively divide an image into groups according to a scene's structural characteristics. Using an exact solution of the recurrent network's dynamics, we present a precise description of the mechanism underlying object segmentation in this network, providing a clear mathematical interpretation of how the network performs this task. We then demonstrate a simple algorithm for object segmentation that generalizes across inputs ranging from simple geometric objects in grayscale images to natural images. Object segmentation across all images is accomplished with one recurrent neural network that has a single, fixed set of weights. This demonstrates the expressive potential of recurrent neural networks when constructed using a mathematical approach that brings together their structure, dynamics, and computation.", "url": "https://arxiv.org/abs/2311.16943"}, {"metadata": {"arXiv": "2311.17049", "Date": "Tue, 28 Nov 2023 18:55:42 ", "Title": "MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training", "Authors": ["Pavan Kumar Anasosalu Vasu", "Hadi Pouransari", "Fartash Faghri", "Raviteja Vemulapalli", "Oncel Tuzel"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Contrastive pretraining of image-text foundation models, such as CLIP, demonstrated excellent zero-shot performance and improved robustness on a wide range of downstream tasks. However, these models utilize large transformer-based encoders with significant memory and latency overhead which pose challenges for deployment on mobile devices. In this work, we introduce MobileCLIP -- a new family of efficient image-text models optimized for runtime performance along with a novel and efficient training approach, namely multi-modal reinforced training. The proposed training approach leverages knowledge transfer from an image captioning model and an ensemble of strong CLIP encoders to improve the accuracy of efficient models. Our approach avoids train-time compute overhead by storing the additional knowledge in a reinforced dataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for zero-shot classification and retrieval tasks on several datasets. Our MobileCLIP-S2 variant is 2.3$\\times$ faster while more accurate compared to previous best CLIP model based on ViT-B/16. We further demonstrate the effectiveness of our multi-modal reinforced training by training a CLIP model based on ViT-B/16 image backbone and achieving +2.9% average performance improvement on 38 evaluation benchmarks compared to the previous best. Moreover, we show that the proposed approach achieves 10$\\times$-1000$\\times$ improved learning efficiency when compared with non-reinforced CLIP training.", "url": "https://arxiv.org/abs/2311.17049"}, {"metadata": {"arXiv": "2311.16104", "Date": "Thu, 20 Jul 2023 17:43:29 ", "Title": "Data Analytics with Differential Privacy", "Authors": ["Vassilis Digalakis Jr"], "Categories": "cs.LG cs.CR cs.DB", "Comments": ["Diploma Thesis", "School of Electrical and Computer Engineering", "Technical University of Crete", "Chania", "Greece", "2018"], "DOI": "10.26233/heallink.tuc.78371"}, "abstract": "Differential privacy is the state-of-the-art definition for privacy, guaranteeing that any analysis performed on a sensitive dataset leaks no information about the individuals whose data are contained therein. In this thesis, we develop differentially private algorithms to analyze distributed and streaming data. In the distributed model, we consider the particular problem of learning -- in a distributed fashion -- a global model of the data, that can subsequently be used for arbitrary analyses. We build upon PrivBayes, a differentially private method that approximates the high-dimensional distribution of a centralized dataset as a product of low-order distributions, utilizing a Bayesian Network model. We examine three novel approaches to learning a global Bayesian Network from distributed data, while offering the differential privacy guarantee to all local datasets. Our work includes a detailed theoretical analysis of the distributed, differentially private entropy estimator which we use in one of our algorithms, as well as a detailed experimental evaluation, using both synthetic and real-world data. In the streaming model, we focus on the problem of estimating the density of a stream of users, which expresses the fraction of all users that actually appear in the stream. We offer one of the strongest privacy guarantees for the streaming model, user-level pan-privacy, which ensures that the privacy of any user is protected, even against an adversary that observes the internal state of the algorithm. We provide a detailed analysis of an existing, sampling-based algorithm for the problem and propose two novel modifications that significantly improve it, both theoretically and experimentally, by optimally using all the allocated \"privacy budget.\"", "url": "https://arxiv.org/abs/2311.16104"}, {"metadata": {"arXiv": "2311.16168", "Date": "Wed, 15 Nov 2023 19:37:20 ", "Title": "Inexpensive High Fidelity Melt Pool Models in Additive Manufacturing Using Generative Deep Diffusion", "Authors": ["Francis Ogoke", "Quanliang Liu", "Olabode Ajenifujah", "Alexander Myers", "Guadalupe Quirarte", "Jack Beuth", "Jonathan Malen", "Amir Barati Farimani"], "Categories": "cs.LG cond-mat.mtrl-sci"}, "abstract": "Defects in laser powder bed fusion (L-PBF) parts often result from the meso-scale dynamics of the molten alloy near the laser, known as the melt pool. For instance, the melt pool can directly contribute to the formation of undesirable porosity, residual stress, and surface roughness in the final part. Experimental in-situ monitoring of the three-dimensional melt pool physical fields is challenging, due to the short length and time scales involved in the process. Multi-physics simulation methods can describe the three-dimensional dynamics of the melt pool, but are computationally expensive at the mesh refinement required for accurate predictions of complex effects, such as the formation of keyhole porosity. Therefore, in this work, we develop a generative deep learning model based on the probabilistic diffusion framework to map low-fidelity, coarse-grained simulation information to the high-fidelity counterpart. By doing so, we bypass the computational expense of conducting multiple high-fidelity simulations for analysis by instead upscaling lightweight coarse mesh simulations. Specifically, we implement a 2-D diffusion model to spatially upscale cross-sections of the coarsely simulated melt pool to their high-fidelity equivalent. We demonstrate the preservation of key metrics of the melting process between the ground truth simulation data and the diffusion model output, such as the temperature field, the melt pool dimensions and the variability of the keyhole vapor cavity. Specifically, we predict the melt pool depth within 3 $\\mu m$ based on low-fidelity input data 4$\\times$ coarser than the high-fidelity simulations, reducing analysis time by two orders of magnitude.", "url": "https://arxiv.org/abs/2311.16168"}, {"metadata": {"arXiv": "2311.16187", "Date": "Sat, 25 Nov 2023 22:09:14 ", "Title": "Modelling wildland fire burn severity in California using a spatial Super Learner approach", "Authors": ["Nicholas Simafranca", "Bryant Willoughby", "Erin O'Neil", "Sophie Farr", "Brian J Reich", "Naomi Giertych", "Margaret Johnson", "Madeleine Pascolini-Campbell"], "Categories": "cs.LG stat.AP", "Comments": ["18 pages", "3 figures"], "MSC-class": "62-08, 62P12"}, "abstract": "Given the increasing prevalence of wildland fires in the Western US, there is a critical need to develop tools to understand and accurately predict burn severity. We develop a machine learning model to predict post-fire burn severity using pre-fire remotely sensed data. Hydrological, ecological, and topographical variables collected from four regions of California - the sites of the Kincade fire (2019), the CZU Lightning Complex fire (2020), the Windy fire (2021), and the KNP Fire (2021) - are used as predictors of the difference normalized burn ratio. We hypothesize that a Super Learner (SL) algorithm that accounts for spatial autocorrelation using Vecchia's Gaussian approximation will accurately model burn severity. In all combinations of test and training sets explored, the results of our model showed the SL algorithm outperformed standard Linear Regression methods. After fitting and verifying the performance of the SL model, we use interpretable machine learning tools to determine the main drivers of severe burn damage, including greenness, elevation and fire weather variables. These findings provide actionable insights that enable communities to strategize interventions, such as early fire detection systems, pre-fire season vegetation clearing activities, and resource allocation during emergency responses. When implemented, this model has the potential to minimize the loss of human life, property, resources, and ecosystems in California.", "url": "https://arxiv.org/abs/2311.16187"}, {"metadata": {"arXiv": "2311.16198", "Date": "Mon, 27 Nov 2023 03:53:19 ", "Title": "Ultra-short-term multi-step wind speed prediction for wind farms based on adaptive noise reduction technology and temporal convolutional network", "Authors": ["Haojian Huang"], "Categories": "cs.LG cs.CE", "Comments": ["Project Technical Report"]}, "abstract": "As an important clean and renewable kind of energy, wind power plays an important role in coping with energy crisis and environmental pollution. However, the volatility and intermittency of wind speed restrict the development of wind power. To improve the utilization of wind power, this study proposes a new wind speed prediction model based on data noise reduction technology, temporal convolutional network (TCN), and gated recurrent unit (GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed based on singular spectrum analysis (SSA) and Pearson correlation coefficient. The original wind speed is decomposed into multiple subsequences by SSA and then reconstructed. When the Pearson correlation coefficient between the reconstructed sequence and the original sequence is greater than 0.99, other noise subsequences are deleted to complete the data denoising. Then, the receptive field of the samples is expanded through the causal convolution and dilated convolution of TCN, and the characteristics of wind speed change are extracted. Then, the time feature information of the sequence is extracted by GRU, and then the wind speed is predicted to form the wind speed sequence prediction model of P-SSA-TCN-GRU. The proposed model was validated on three wind farms in Shandong Province. The experimental results show that the prediction performance of the proposed model is better than that of the traditional model and other models based on TCN, and the wind speed prediction of wind farms with high precision and strong stability is realized. The wind speed predictions of this model have the potential to become the data that support the operation and management of wind farms. The code is available at link.", "url": "https://arxiv.org/abs/2311.16198"}, {"metadata": {"arXiv": "2311.16199", "Date": "Mon, 27 Nov 2023 05:32:21 ", "Title": "Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for Molecule Generation", "Authors": ["Ameya Daigavane", "Song Kim", "Mario Geiger", "Tess Smidt"], "Categories": "cs.LG q-bio.BM", "Comments": ["Preprint under review"]}, "abstract": "We present Symphony, an $E(3)$-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Existing autoregressive models such as G-SchNet and G-SphereNet for molecules utilize rotationally invariant features to respect the 3D symmetries of molecules. In contrast, Symphony uses message-passing with higher-degree $E(3)$-equivariant features. This allows a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. We show that Symphony is able to accurately generate small molecules from the QM9 dataset, outperforming existing autoregressive models and approaching the performance of diffusion models.", "url": "https://arxiv.org/abs/2311.16199"}, {"metadata": {"arXiv": "2311.16298", "Date": "Mon, 27 Nov 2023 20:19:22 ", "Title": "Influence Scores at Scale for Efficient Language Data Sampling", "Authors": ["Nikhil Anand and Joshua Tan and Maria Minakova"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted at EMNLP '23"]}, "abstract": "Modern ML systems ingest data aggregated from diverse sources, such as synthetic, human-annotated, and live customer traffic. Understanding \\textit{which} examples are important to the performance of a learning algorithm is crucial for efficient model training. Recently, a growing body of literature has given rise to various \"influence scores,\" which use training artifacts such as model confidence or checkpointed gradients to identify important subsets of data. However, these methods have primarily been developed in computer vision settings, and it remains unclear how well they generalize to language-based tasks using pretrained models. In this paper, we explore the applicability of influence scores in language classification tasks. We evaluate a diverse subset of these scores on the SNLI dataset by quantifying accuracy changes in response to pruning training data through random and influence-score-based sampling. We then stress-test one of the scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an NLU model stack that was exposed to dynamic user speech patterns in a voice assistant type of setting. Our experiments demonstrate that in many cases, encoder-based language models can be finetuned on roughly 50% of the original data without degradation in performance metrics. Along the way, we summarize lessons learned from applying out-of-the-box implementations of influence scores, quantify the effects of noisy and class-imbalanced data, and offer recommendations on score-based sampling for better accuracy and training efficiency.", "url": "https://arxiv.org/abs/2311.16298"}, {"metadata": {"arXiv": "2311.16302", "Date": "Mon, 27 Nov 2023 20:33:54 ", "Title": "Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics for Data Selection", "Authors": ["Anusha Sabbineni and Nikhil Anand and Maria Minakova"], "Categories": "cs.LG cs.CL", "Comments": ["Accepted to Efficient Natural Language and Speech Processing (ENLSP-III) workshop at NeurIPS '23"]}, "abstract": "While data selection methods have been studied extensively in active learning, data pruning, and data augmentation settings, there is little evidence for the efficacy of these methods in industry scale settings, particularly in low-resource languages. Our work presents ways of assessing prospective training examples in those settings for their \"usefulness\" or \"difficulty\". We also demonstrate how these measures can be used in selecting important examples for training supervised machine learning models. We primarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these metrics to curate high quality datasets from a large pool of \\textit{Weak Signal Labeled} data, which assigns no-defect high confidence hypotheses during inference as ground truth labels. We then conduct training data augmentation experiments using these de-identified datasets and demonstrate that score-based selection can result in a 2% decrease in semantic error rate and 4%-7% decrease in domain classification error rate when compared to the baseline technique of random selection.", "url": "https://arxiv.org/abs/2311.16302"}, {"metadata": {"arXiv": "2311.16328", "Date": "Mon, 27 Nov 2023 21:23:41 ", "Title": "Target-Free Compound Activity Prediction via Few-Shot Learning", "Authors": ["Peter Eckmann", "Jake Anderson", "Michael K. Gilson", "Rose Yu"], "Categories": "cs.LG q-bio.QM", "Comments": ["9 pages", "2 figures"]}, "abstract": "Predicting the activities of compounds against protein-based or phenotypic assays using only a few known compounds and their activities is a common task in target-free drug discovery. Existing few-shot learning approaches are limited to predicting binary labels (active/inactive). However, in real-world drug discovery, degrees of compound activity are highly relevant. We study Few-Shot Compound Activity Prediction (FS-CAP) and design a novel neural architecture to meta-learn continuous compound activities across large bioactivity datasets. Our model aggregates encodings generated from the known compounds and their activities to capture assay information. We also introduce a separate encoder for the unknown compound. We show that FS-CAP surpasses traditional similarity-based techniques as well as other state of the art few-shot learning methods on a variety of target-free drug discovery settings and datasets.", "url": "https://arxiv.org/abs/2311.16328"}, {"metadata": {"arXiv": "2311.16357", "Date": "Mon, 27 Nov 2023 22:40:02 ", "Title": "Cross Entropy in Deep Learning of Classifiers Is Unnecessary -- ISBE Error is All You Need", "Authors": ["Wladyslaw Skarbek"], "Categories": "cs.LG", "Comments": ["18 pages", "4 figures"], "ACM-class": "I.2.5"}, "abstract": "In deep learning classifiers, the cost function usually takes the form of a combination of SoftMax and CrossEntropy functions. The SoftMax unit transforms the scores predicted by the model network into assessments of the degree (probabilities) of an object's membership to a given class. On the other hand, CrossEntropy measures the divergence of this prediction from the distribution of target scores. This work introduces the ISBE functionality, justifying the thesis about the redundancy of cross entropy computation in deep learning of classifiers. Not only can we omit the calculation of entropy, but also, during back-propagation, there is no need to direct the error to the normalization unit for its backward transformation. Instead, the error is sent directly to the model's network. Using examples of perceptron and convolutional networks as classifiers of images from the MNIST collection, it is observed for ISBE that results are not degraded with SoftMax only, but also with other activation functions such as Sigmoid, Tanh, or their hard variants HardSigmoid and HardTanh. Moreover, up to three percent of time is saved within the total time of forward and backward stages. The article is addressed mainly to programmers and students interested in deep model learning. For example, it illustrates in code snippets possible ways to implement ISBE units, but also formally proves that the softmax trick only applies to the class of softmax functions with relocations.", "url": "https://arxiv.org/abs/2311.16357"}, {"metadata": {"arXiv": "2311.16361", "Date": "Mon, 27 Nov 2023 22:52:45 ", "Title": "Making Self-supervised Learning Robust to Spurious Correlation via Learning-speed Aware Sampling", "Authors": ["Weicheng Zhu", "Sheng Liu", "Carlos Fernandez-Granda", "Narges Razavian"], "Categories": "cs.LG", "Comments": ["Accepted by NeurIPS 2023 Workshop Self-Supervised Learning - Theory and Practice", "18 pages", "7 figures", "7 tables"]}, "abstract": "Self-supervised learning (SSL) has emerged as a powerful technique for learning rich representations from unlabeled data. The data representations are able to capture many underlying attributes of data, and be useful in downstream prediction tasks. In real-world settings, spurious correlations between some attributes (e.g. race, gender and age) and labels for downstream tasks often exist, e.g. cancer is usually more prevalent among elderly patients. In this paper, we investigate SSL in the presence of spurious correlations and show that the SSL training loss can be minimized by capturing only a subset of the conspicuous features relevant to those sensitive attributes, despite the presence of other important predictive features for the downstream tasks. To address this issue, we investigate the learning dynamics of SSL and observe that the learning is slower for samples that conflict with such correlations (e.g. elder patients without cancer). Motivated by these findings, we propose a learning-speed aware SSL (LA-SSL) approach, in which we sample each training data with a probability that is inversely related to its learning speed. We evaluate LA-SSL on three datasets that exhibit spurious correlations between different attributes, demonstrating that it improves the robustness of pretrained representations on downstream classification tasks.", "url": "https://arxiv.org/abs/2311.16361"}, {"metadata": {"arXiv": "2311.16374", "Date": "Mon, 27 Nov 2023 23:35:40 ", "Title": "Physics-Informed Neural Network for Discovering Systems with Unmeasurable States with Application to Lithium-Ion Batteries", "Authors": ["Yuichi Kajiura", "Jorge Espin", "Dong Zhang"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["7 pages", "4 figure", "submitted to American Control Conference 2024"]}, "abstract": "Combining machine learning with physics is a trending approach for discovering unknown dynamics, and one of the most intensively studied frameworks is the physics-informed neural network (PINN). However, PINN often fails to optimize the network due to its difficulty in concurrently minimizing multiple losses originating from the system's governing equations. This problem can be more serious when the system's states are unmeasurable, like lithium-ion batteries (LiBs). In this work, we introduce a robust method for training PINN that uses fewer loss terms and thus constructs a less complex landscape for optimization. In particular, instead of having loss terms from each differential equation, this method embeds the dynamics into a loss function that quantifies the error between observed and predicted system outputs. This is accomplished by numerically integrating the predicted states from the neural network(NN) using known dynamics and transforming them to obtain a sequence of predicted outputs. Minimizing such a loss optimizes the NN to predict states consistent with observations given the physics. Further, the system's parameters can be added to the optimization targets. To demonstrate the ability of this method to perform various modeling and control tasks, we apply it to a battery model to concurrently estimate its states and parameters.", "url": "https://arxiv.org/abs/2311.16374"}, {"metadata": {"arXiv": "2311.16378", "Date": "Mon, 27 Nov 2023 23:53:19 ", "Title": "Bayesian Formulations for Graph Spectral Denoising", "Authors": ["Sam Leone", "Xingzhi Sun", "Michael Perlmutter", "Smita Krishnaswamy"], "Categories": "cs.LG eess.SP"}, "abstract": "We consider noisy signals which are defined on the vertices of a graph and present smoothing algorithms for the cases of Gaussian, dropout, and uniformly distributed noise. The signals are assumed to follow a prior distribution defined in the frequency domain which favors signals which are smooth across the edges of the graph. By pairing this prior distribution with our three models of noise generation, we propose \\textit{Maximum A Posteriori} (M.A.P.) estimates of the true signal in the presence of noisy data and provide algorithms for computing the M.A.P. Finally, we demonstrate the algorithms' ability to effectively restore white noise on image data, and from severe dropout in toy \\& EHR data.", "url": "https://arxiv.org/abs/2311.16378"}, {"metadata": {"arXiv": "2311.16381", "Date": "Tue, 28 Nov 2023 00:03:18 ", "Title": "Deep Learning for Time Series Classification of Parkinson's Disease Eye Tracking Data", "Authors": ["Gonzalo Uribarri", "Simon Ekman von Huth", "Josefine Waldthaler", "Per Svenningsson", "Erik Frans\\'en"], "Categories": "cs.LG q-bio.QM", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "12 pages"]}, "abstract": "Eye-tracking is an accessible and non-invasive technology that provides information about a subject's motor and cognitive abilities. As such, it has proven to be a valuable resource in the study of neurodegenerative diseases such as Parkinson's disease. Saccade experiments, in particular, have proven useful in the diagnosis and staging of Parkinson's disease. However, to date, no single eye-movement biomarker has been found to conclusively differentiate patients from healthy controls. In the present work, we investigate the use of state-of-the-art deep learning algorithms to perform Parkinson's disease classification using eye-tracking data from saccade experiments. In contrast to previous work, instead of using hand-crafted features from the saccades, we use raw $\\sim1.5\\,s$ long fixation intervals recorded during the preparatory phase before each trial. Using these short time series as input we implement two different classification models, InceptionTime and ROCKET. We find that the models are able to learn the classification task and generalize to unseen subjects. InceptionTime achieves $78\\%$ accuracy, while ROCKET achieves $88\\%$ accuracy. We also employ a novel method for pruning the ROCKET model to improve interpretability and generalizability, achieving an accuracy of $96\\%$. Our results suggest that fixation data has low inter-subject variability and potentially carries useful information about brain cognitive and motor conditions, making it suitable for use with machine learning in the discovery of disease-relevant biomarkers.", "url": "https://arxiv.org/abs/2311.16381"}, {"metadata": {"arXiv": "2311.16420", "Date": "Tue, 28 Nov 2023 02:00:47 ", "Title": "Model-free Test Time Adaptation for Out-Of-Distribution Detection", "Authors": ["YiFan Zhang", "Xue Wang", "Tian Zhou", "Kun Yuan", "Zhang Zhang", "Liang Wang", "Rong Jin", "Tieniu Tan"], "Categories": "cs.LG cs.CV", "Comments": ["12 pages", "10 figures"]}, "abstract": "Out-of-distribution (OOD) detection is essential for the reliability of ML models. Most existing methods for OOD detection learn a fixed decision criterion from a given in-distribution dataset and apply it universally to decide if a data point is OOD. Recent work~\\cite{fang2022is} shows that given only in-distribution data, it is impossible to reliably detect OOD data without extra assumptions. Motivated by the theoretical result and recent exploration of test-time adaptation methods, we propose a Non-Parametric Test Time \\textbf{Ada}ptation framework for \\textbf{O}ut-Of-\\textbf{D}istribution \\textbf{D}etection (\\abbr). Unlike conventional methods, \\abbr utilizes online test samples for model adaptation during testing, enhancing adaptability to changing data distributions. The framework incorporates detected OOD instances into decision-making, reducing false positive rates, particularly when ID and OOD distributions overlap significantly. We demonstrate the effectiveness of \\abbr through comprehensive experiments on multiple OOD detection benchmarks, extensive empirical studies show that \\abbr significantly improves the performance of OOD detection over state-of-the-art methods. Specifically, \\abbr reduces the false positive rate (FPR95) by $23.23\\%$ on the CIFAR-10 benchmarks and $38\\%$ on the ImageNet-1k benchmarks compared to the advanced methods. Lastly, we theoretically verify the effectiveness of \\abbr.", "url": "https://arxiv.org/abs/2311.16420"}, {"metadata": {"arXiv": "2311.16442", "Date": "Tue, 28 Nov 2023 02:44:59 ", "Title": "Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and Asynchronous Dequantization", "Authors": ["Jinhao Li", "Shiyao Li", "Jiaming Xu", "Shan Huang", "Yaoxiu Lian", "Jun Liu", "Yu Wang", "Guohao Dai"], "Categories": "cs.LG cs.DC"}, "abstract": "Large language models (LLMs) have demonstrated impressive abilities in various domains while the inference cost is expensive. The state-of-the-art methods use 2-bit quantization for mainstream LLMs. However, challenges still exist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are quantized by groups, while the ranges of weights are large in some groups, resulting in large quantization errors and nonnegligible accuracy loss (e.g. 3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited accuracy improvement by adding 4-bit weights. Increasing 10% extra average bit more 4-bit weights only leads to <0.5% accuracy improvement on a quantized Llama2-7b. (3) Time-consuming dequantization operations on GPUs. The dequantization operations lead to >50% execution time, hindering the potential of reducing LLM inference cost. To tackle these challenges, we propose the following techniques: (1) We only quantize a small fraction of groups with the larger range using 4-bit with memory alignment consideration on GPUs. (2) We point out that the distribution of the sparse outliers with larger weights is different in 2-bit and 4-bit groups, and only a small fraction of outliers require 16-bit quantization. Such design leads to >0.5% accuracy improvement with <3% average increased bit for Llama2-7b. (3) We design the asynchronous dequantization on GPUs, leading to up to 3.92X speedup. We conduct extensive experiments on different model families and model sizes. We achieve 2.85-bit for each weight and the end-to-end speedup for Llama2-7b is 1.74X over the original model, and we reduce both runtime cost and hardware cost by up to 2.70X and 2.81X with less GPU requirements.", "url": "https://arxiv.org/abs/2311.16442"}, {"metadata": {"arXiv": "2311.16459", "Date": "Tue, 28 Nov 2023 03:34:22 ", "Title": "On the Effect of Defections in Federated Learning and How to Prevent Them", "Authors": ["Minbiao Han", "Kumar Kshitij Patel", "Han Shao", "Lingxiao Wang"], "Categories": "cs.LG cs.DC"}, "abstract": "Federated learning is a machine learning protocol that enables a large population of agents to collaborate over multiple rounds to produce a single consensus model. There are several federated learning applications where agents may choose to defect permanently$-$essentially withdrawing from the collaboration$-$if they are content with their instantaneous model in that round. This work demonstrates the detrimental impact of such defections on the final model's robustness and ability to generalize. We also show that current federated optimization algorithms fail to disincentivize these harmful defections. We introduce a novel optimization algorithm with theoretical guarantees to prevent defections while ensuring asymptotic convergence to an effective solution for all participating agents. We also provide numerical experiments to corroborate our findings and demonstrate the effectiveness of our algorithm.", "url": "https://arxiv.org/abs/2311.16459"}, {"metadata": {"arXiv": "2311.16485", "Date": "Mon, 27 Nov 2023 02:17:14 ", "Title": "Class-Adaptive Sampling Policy for Efficient Continual Learning", "Authors": ["Hossein Rezaei", "Mohammad Sabokrou"], "Categories": "cs.LG cs.CV"}, "abstract": "Continual learning (CL) aims to acquire new knowledge while preserving information from previous experiences without forgetting. Though buffer-based methods (i.e., retaining samples from previous tasks) have achieved acceptable performance, determining how to allocate the buffer remains a critical challenge. Most recent research focuses on refining these methods but often fails to sufficiently consider the varying influence of samples on the learning process, and frequently overlooks the complexity of the classes/concepts being learned. Generally, these methods do not directly take into account the contribution of individual classes. However, our investigation indicates that more challenging classes necessitate preserving a larger number of samples compared to less challenging ones. To address this issue, we propose a novel method and policy named 'Class-Adaptive Sampling Policy' (CASP), which dynamically allocates storage space within the buffer. By utilizing concepts of class contribution and difficulty, CASP adaptively manages buffer space, allowing certain classes to occupy a larger portion of the buffer while reducing storage for others. This approach significantly improves the efficiency of knowledge retention and utilization. CASP provides a versatile solution to boost the performance and efficiency of CL. It meets the demand for dynamic buffer allocation, accommodating the varying contributions of different classes and their learning complexities over time.", "url": "https://arxiv.org/abs/2311.16485"}, {"metadata": {"arXiv": "2311.16487", "Date": "Tue, 28 Nov 2023 04:34:04 ", "Title": "On the Robustness of Decision-Focused Learning", "Authors": ["Yehya Farhat"], "Categories": "cs.LG math.OC", "Comments": ["17 pages", "45 figures", "submitted to AAAI artificial intelligence for operations research workshop"], "MSC-class": "68Txx"}, "abstract": "Decision-Focused Learning (DFL) is an emerging learning paradigm that tackles the task of training a machine learning (ML) model to predict missing parameters of an incomplete optimization problem, where the missing parameters are predicted. DFL trains an ML model in an end-to-end system, by integrating the prediction and optimization tasks, providing better alignment of the training and testing objectives. DFL has shown a lot of promise and holds the capacity to revolutionize decision-making in many real-world applications. However, very little is known about the performance of these models under adversarial attacks. We adopt ten unique DFL methods and benchmark their performance under two distinctly focused attacks adapted towards the Predict-then-Optimize problem setting. Our study proposes the hypothesis that the robustness of a model is highly correlated with its ability to find predictions that lead to optimal decisions without deviating from the ground-truth label. Furthermore, we provide insight into how to target the models that violate this condition and show how these models respond differently depending on the achieved optimality at the end of their training cycles.", "url": "https://arxiv.org/abs/2311.16487"}, {"metadata": {"arXiv": "2311.16496", "Date": "Mon, 27 Nov 2023 08:49:26 ", "Title": "Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in Multi-Modal Fake News Detection", "Authors": ["Debarshi Brahma", "Amartya Bhattacharya", "Suraj Nagaje Mahadev", "Anmol Asati", "Vikas Verma", "Soma Biswas"], "Categories": "cs.LG"}, "abstract": "The spread of fake news using out-of-context images has become widespread and is a challenging task in this era of information overload. Since annotating huge amounts of such data requires significant time of domain experts, it is imperative to develop methods which can work in limited annotated data scenarios. In this work, we explore whether out-of-domain data can help to improve out-of-context misinformation detection (termed here as multi-modal fake news detection) of a desired domain, eg. politics, healthcare, etc. Towards this goal, we propose a novel framework termed DPOD (Domain-specific Prompt-tuning using Out-of-Domain data). First, to compute generalizable features, we modify the Vision-Language Model, CLIP to extract features that helps to align the representations of the images and corresponding text captions of both the in-domain and out-of-domain data in a label-aware manner. Further, we propose a domain-specific prompt learning technique which leverages the training samples of all the available domains based on the the extent they can be useful to the desired domain. Extensive experiments on a large-scale benchmark dataset, namely NewsClippings demonstrate that the proposed framework achieves state of-the-art performance, significantly surpassing the existing approaches for this challenging task.", "url": "https://arxiv.org/abs/2311.16496"}, {"metadata": {"arXiv": "2311.16519", "Date": "Tue, 28 Nov 2023 04:58:17 ", "Title": "B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the Response of Complex Dynamical Systems to Length-Variant Multiple Input Functions", "Authors": ["Zhihao Kong and Amirhossein Mollaali and Christian Moya and Na Lu and Guang Lin"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Deep Operator Network (DeepONet) is a neural network framework for learning nonlinear operators such as those from ordinary differential equations (ODEs) describing complex systems. Multiple-input deep neural operators (MIONet) extended DeepONet to allow multiple input functions in different Banach spaces. MIONet offers flexibility in training dataset grid spacing, without constraints on output location. However, it requires offline inputs and cannot handle varying sequence lengths in testing datasets, limiting its real-time application in dynamic complex systems. This work redesigns MIONet, integrating Long Short Term Memory (LSTM) to learn neural operators from time-dependent data. This approach overcomes data discretization constraints and harnesses LSTM's capability with variable-length, real-time data. Factors affecting learning performance, like algorithm extrapolation ability are presented. The framework is enhanced with uncertainty quantification through a novel Bayesian method, sampling from MIONet parameter distributions. Consequently, we develop the B-LSTM-MIONet, incorporating LSTM's temporal strengths with Bayesian robustness, resulting in a more precise and reliable model for noisy datasets.", "url": "https://arxiv.org/abs/2311.16519"}, {"metadata": {"arXiv": "2311.16522", "Date": "Tue, 28 Nov 2023 05:00:27 ", "Title": "Evaluation of dynamic characteristics of power grid based on GNN and application on knowledge graph", "Authors": ["Hao Pei", "Si Lin", "Chuanfu Li", "Che Wang", "Haoming Chen", "Sizhe Li"], "Categories": "cs.LG cs.CL eess.SP"}, "abstract": "A novel method for detecting faults in power grids using a graph neural network (GNN) has been developed, aimed at enhancing intelligent fault diagnosis in network operation and maintenance. This GNN-based approach identifies faulty nodes within the power grid through a specialized electrical feature extraction model coupled with a knowledge graph. Incorporating temporal data, the method leverages the status of nodes from preceding and subsequent time periods to aid in current fault detection. To validate the effectiveness of this GNN in extracting node features, a correlation analysis of the output features from each node within the neural network layer was conducted. The results from experiments show that this method can accurately locate fault nodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally, the graph neural network's feature modeling allows for a qualitative examination of how faults spread across nodes, providing valuable insights for analyzing fault nodes.", "url": "https://arxiv.org/abs/2311.16522"}, {"metadata": {"arXiv": "2311.16526", "Date": "Tue, 28 Nov 2023 05:11:53 ", "Title": "On robust overfitting: adversarial training induced distribution matters", "Authors": ["Runzhi Tian", "Yongyi Mao"], "Categories": "cs.LG"}, "abstract": "Adversarial training may be regarded as standard training with a modified loss function. But its generalization error appears much larger than standard training under standard loss. This phenomenon, known as robust overfitting, has attracted significant research attention and remains largely as a mystery. In this paper, we first show empirically that robust overfitting correlates with the increasing generalization difficulty of the perturbation-induced distributions along the trajectory of adversarial training (specifically PGD-based adversarial training). We then provide a novel upper bound for generalization error with respect to the perturbation-induced distributions, in which a notion of the perturbation operator, referred to \"local dispersion\", plays an important role.", "url": "https://arxiv.org/abs/2311.16526"}, {"metadata": {"arXiv": "2311.16535", "Date": "Tue, 28 Nov 2023 05:44:26 ", "Title": "Contrastive encoder pre-training-based clustered federated learning for heterogeneous data", "Authors": ["Ye Lin Tun", "Minh N.H. Nguyen", "Chu Myaet Thwal", "Jinwoo Choi", "Choong Seon Hong"], "Categories": "cs.LG cs.DC", "Comments": ["Published in Neural Networks"], "DOI": "10.1016/j.neunet.2023.06.010"}, "abstract": "Federated learning (FL) is a promising approach that enables distributed clients to collaboratively train a global model while preserving their data privacy. However, FL often suffers from data heterogeneity problems, which can significantly affect its performance. To address this, clustered federated learning (CFL) has been proposed to construct personalized models for different client clusters. One effective client clustering strategy is to allow clients to choose their own local models from a model pool based on their performance. However, without pre-trained model parameters, such a strategy is prone to clustering failure, in which all clients choose the same model. Unfortunately, collecting a large amount of labeled data for pre-training can be costly and impractical in distributed environments. To overcome this challenge, we leverage self-supervised contrastive learning to exploit unlabeled data for the pre-training of FL systems. Together, self-supervised pre-training and client clustering can be crucial components for tackling the data heterogeneity issues of FL. Leveraging these two crucial strategies, we propose contrastive pre-training-based clustered federated learning (CP-CFL) to improve the model convergence and overall performance of FL systems. In this work, we demonstrate the effectiveness of CP-CFL through extensive experiments in heterogeneous FL settings, and present various interesting observations.", "url": "https://arxiv.org/abs/2311.16535"}, {"metadata": {"arXiv": "2311.16536", "Date": "Tue, 28 Nov 2023 05:45:20 ", "Title": "Personalized Predictions of Glioblastoma Infiltration: Mathematical Models, Physics-Informed Neural Networks and Multimodal Scans", "Authors": ["Ray Zirui Zhang", "Ivan Ezhov", "Michal Balcerak", "Andy Zhu", "Benedikt Wiestler", "Bjoern Menze", "John Lowengrub"], "Categories": "cs.LG eess.IV q-bio.QM", "MSC-class": "92-08, 92C50, 35Q92", "ACM-class": "J.3; J.2; I.2.6"}, "abstract": "Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is crucial for understanding tumor growth dynamics and designing personalized radiotherapy treatment plans.Mathematical models of GBM growth can complement the data in the prediction of spatial distributions of tumor cells. However, this requires estimating patient-specific parameters of the model from clinical data, which is a challenging inverse problem due to limited temporal data and the limited time between imaging and diagnosis. This work proposes a method that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific parameters of a reaction-diffusion PDE model of GBM growth from a single 3D structural MRI snapshot. PINNs embed both the data and the PDE into a loss function, thus integrating theory and data. Key innovations include the identification and estimation of characteristic non-dimensional parameters, a pre-training step that utilizes the non-dimensional parameters and a fine-tuning step to determine the patient specific parameters. Additionally, the diffuse domain method is employed to handle the complex brain geometry within the PINN framework. Our method is validated both on synthetic and patient datasets, and shows promise for real-time parametric inference in the clinical setting for personalized GBM treatment.", "url": "https://arxiv.org/abs/2311.16536"}, {"metadata": {"arXiv": "2311.16538", "Date": "Tue, 28 Nov 2023 06:08:16 ", "Title": "Federated Learning with Diffusion Models for Privacy-Sensitive Vision Tasks", "Authors": ["Ye Lin Tun", "Chu Myaet Thwal", "Ji Su Yoon", "Sun Moo Kang", "Chaoning Zhang", "Choong Seon Hong"], "Categories": "cs.LG cs.CR"}, "abstract": "Diffusion models have shown great potential for vision-related tasks, particularly for image generation. However, their training is typically conducted in a centralized manner, relying on data collected from publicly available sources. This approach may not be feasible or practical in many domains, such as the medical field, which involves privacy concerns over data collection. Despite the challenges associated with privacy-sensitive data, such domains could still benefit from valuable vision services provided by diffusion models. Federated learning (FL) plays a crucial role in enabling decentralized model training without compromising data privacy. Instead of collecting data, an FL system gathers model parameters, effectively safeguarding the private data of different parties involved. This makes FL systems vital for managing decentralized learning tasks, especially in scenarios where privacy-sensitive data is distributed across a network of clients. Nonetheless, FL presents its own set of challenges due to its distributed nature and privacy-preserving properties. Therefore, in this study, we explore the FL strategy to train diffusion models, paving the way for the development of federated diffusion models. We conduct experiments on various FL scenarios, and our findings demonstrate that federated diffusion models have great potential to deliver vision services to privacy-sensitive domains.", "url": "https://arxiv.org/abs/2311.16538"}, {"metadata": {"arXiv": "2311.16540", "Date": "Tue, 28 Nov 2023 06:12:57 ", "Title": "Communication Efficiency Optimization of Federated Learning for Computing and Network Convergence of 6G Networks", "Authors": ["Yizhuo Cai", "Bo Lei", "Qianying Zhao", "Jing Peng", "Min Wei", "Yushun Zhang", "Xing Zhang"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["13 pages", "11 figures", "accepted by Frontiers of Information Technology & Electronic Engineering"], "DOI": "10.1631/FITEE.2300122"}, "abstract": "Federated learning effectively addresses issues such as data privacy by collaborating across participating devices to train global models. However, factors such as network topology and device computing power can affect its training or communication process in complex network environments. A new network architecture and paradigm with computing-measurable, perceptible, distributable, dispatchable, and manageable capabilities, computing and network convergence (CNC) of 6G networks can effectively support federated learning training and improve its communication efficiency. By guiding the participating devices' training in federated learning based on business requirements, resource load, network conditions, and arithmetic power of devices, CNC can reach this goal. In this paper, to improve the communication efficiency of federated learning in complex networks, we study the communication efficiency optimization of federated learning for computing and network convergence of 6G networks, methods that gives decisions on its training process for different network conditions and arithmetic power of participating devices in federated learning. The experiments address two architectures that exist for devices in federated learning and arrange devices to participate in training based on arithmetic power while achieving optimization of communication efficiency in the process of transferring model parameters. The results show that the method we proposed can (1) cope well with complex network situations (2) effectively balance the delay distribution of participating devices for local training (3) improve the communication efficiency during the transfer of model parameters (4) improve the resource utilization in the network.", "url": "https://arxiv.org/abs/2311.16540"}, {"metadata": {"arXiv": "2311.16556", "Date": "Tue, 28 Nov 2023 06:52:53 ", "Title": "Scalable Label Distribution Learning for Multi-Label Classification", "Authors": ["Xingyu Zhao", "Yuexuan An", "Lei Qi", "Xin Geng"], "Categories": "cs.LG"}, "abstract": "Multi-label classification (MLC) refers to the problem of tagging a given instance with a set of relevant labels. Most existing MLC methods are based on the assumption that the correlation of two labels in each label pair is symmetric, which is violated in many real-world scenarios. Moreover, most existing methods design learning processes associated with the number of labels, which makes their computational complexity a bottleneck when scaling up to large-scale output space. To tackle these issues, we propose a novel MLC learning method named Scalable Label Distribution Learning (SLDL) for multi-label classification which can describe different labels as distributions in a latent space, where the label correlation is asymmetric and the dimension is independent of the number of labels. Specifically, SLDL first converts labels into continuous distributions within a low-dimensional latent space and leverages the asymmetric metric to establish the correlation between different labels. Then, it learns the mapping from the feature space to the latent space, resulting in the computational complexity is no longer related to the number of labels. Finally, SLDL leverages a nearest-neighbor-based strategy to decode the latent representations and obtain the final predictions. Our extensive experiments illustrate that SLDL can achieve very competitive classification performances with little computational consumption.", "url": "https://arxiv.org/abs/2311.16556"}, {"metadata": {"arXiv": "2311.16584", "Date": "Tue, 28 Nov 2023 08:01:43 ", "Title": "FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial Learning", "Authors": ["Pengchao Han", "Xingyan Shi", "Jianwei Huang"], "Categories": "cs.LG cs.DC"}, "abstract": "Knowledge distillation (KD) can enable collaborative learning among distributed clients that have different model architectures and do not share their local data and model parameters with others. Each client updates its local model using the average model output/feature of all client models as the target, known as federated KD. However, existing federated KD methods often do not perform well when clients' local models are trained with heterogeneous local datasets. In this paper, we propose Federated knowledge distillation enabled by Adversarial Learning (FedAL) to address the data heterogeneity among clients. First, to alleviate the local model output divergence across clients caused by data heterogeneity, the server acts as a discriminator to guide clients' local model training to achieve consensus model outputs among clients through a min-max game between clients and the discriminator. Moreover, catastrophic forgetting may happen during the clients' local training and global knowledge transfer due to clients' heterogeneous local data. Towards this challenge, we design the less-forgetting regularization for both local training and global knowledge transfer to guarantee clients' ability to transfer/learn knowledge to/from others. Experimental results show that FedAL and its variants achieve higher accuracy than other federated KD baselines.", "url": "https://arxiv.org/abs/2311.16584"}, {"metadata": {"arXiv": "2311.16616", "Date": "Tue, 28 Nov 2023 09:12:37 ", "Title": "Adversarial Distribution Balancing for Counterfactual Reasoning", "Authors": ["Stefan Schrod", "Fabian Sinz", "Michael Altenbuchinger"], "Categories": "cs.LG", "Comments": ["Implementation available at https://github.com/sschrod/ADBCR"]}, "abstract": "The development of causal prediction models is challenged by the fact that the outcome is only observable for the applied (factual) intervention and not for its alternatives (the so-called counterfactuals); in medicine we only know patients' survival for the administered drug and not for other therapeutic options. Machine learning approaches for counterfactual reasoning have to deal with both unobserved outcomes and distributional differences due to non-random treatment administration. Unsupervised domain adaptation (UDA) addresses similar issues; one has to deal with unobserved outcomes -- the labels of the target domain -- and distributional differences between source and target domain. We propose Adversarial Distribution Balancing for Counterfactual Reasoning (ADBCR), which directly uses potential outcome estimates of the counterfactuals to remove spurious causal relations. We show that ADBCR outcompetes state-of-the-art methods on three benchmark datasets, and demonstrate that ADBCR's performance can be further improved if unlabeled validation data are included in the training procedure to better adapt the model to the validation domain.", "url": "https://arxiv.org/abs/2311.16616"}, {"metadata": {"arXiv": "2311.16620", "Date": "Tue, 28 Nov 2023 09:21:48 ", "Title": "On the Long Range Abilities of Transformers", "Authors": ["Itamar Zimerman", "Lior Wolf"], "Categories": "cs.LG cs.CL", "Comments": ["18 pages"], "ACM-class": "F.2.2; I.2.7"}, "abstract": "Despite their dominance in modern DL and, especially, NLP domains, transformer architectures exhibit sub-optimal performance on long-range tasks compared to recent layers that are specifically designed for this purpose. In this work, drawing inspiration from key attributes of long-range layers, such as state-space layers, linear RNN layers, and global convolution layers, we demonstrate that minimal modifications to the transformer architecture can significantly enhance performance on the Long Range Arena (LRA) benchmark, thus narrowing the gap with these specialized layers. We identify that two key principles for long-range tasks are (i) incorporating an inductive bias towards smoothness, and (ii) locality. As we show, integrating these ideas into the attention mechanism improves results with a negligible amount of additional computation and without any additional trainable parameters. Our theory and experiments also shed light on the reasons for the inferior performance of transformers on long-range tasks and identify critical properties that are essential for successfully capturing long-range dependencies.", "url": "https://arxiv.org/abs/2311.16620"}, {"metadata": {"arXiv": "2311.16625", "Date": "Tue, 28 Nov 2023 09:25:23 ", "Title": "Gaussian Processes for Monitoring Air-Quality in Kampala", "Authors": ["Clara Stoddart", "Lauren Shrack", "Richard Sserunjogi", "Usman Abdul-Ganiy", "Engineer Bainomugisha", "Deo Okure", "Ruth Misener", "Jose Pablo Folch", "Ruby Sedgwick"], "Categories": "cs.LG stat.ML"}, "abstract": "Monitoring air pollution is of vital importance to the overall health of the population. Unfortunately, devices that can measure air quality can be expensive, and many cities in low and middle-income countries have to rely on a sparse allocation of them. In this paper, we investigate the use of Gaussian Processes for both nowcasting the current air-pollution in places where there are no sensors and forecasting the air-pollution in the future at the sensor locations. In particular, we focus on the city of Kampala in Uganda, using data from AirQo's network of sensors. We demonstrate the advantage of removing outliers, compare different kernel functions and additional inputs. We also compare two sparse approximations to allow for the large amounts of temporal data in the dataset.", "url": "https://arxiv.org/abs/2311.16625"}, {"metadata": {"arXiv": "2311.16630", "Date": "Tue, 28 Nov 2023 09:30:52 ", "Title": "Outfit Completion via Conditional Set Transformation", "Authors": ["Takuma Nakamura", "Yuki Saito", "Ryosuke Goto"], "Categories": "cs.LG", "Comments": ["8 pages", "8 figures"]}, "abstract": "In this paper, we formulate the outfit completion problem as a set retrieval task and propose a novel framework for solving this problem. The proposal includes a conditional set transformation architecture with deep neural networks and a compatibility-based regularization method. The proposed method utilizes a map with permutation-invariant for the input set and permutation-equivariant for the condition set. This allows retrieving a set that is compatible with the input set while reflecting the properties of the condition set. In addition, since this structure outputs the element of the output set in a single inference, it can achieve a scalable inference speed with respect to the cardinality of the output set. Experimental results on real data reveal that the proposed method outperforms existing approaches in terms of accuracy of the outfit completion task, condition satisfaction, and compatibility of completion results.", "url": "https://arxiv.org/abs/2311.16630"}, {"metadata": {"arXiv": "2311.16646", "Date": "Tue, 28 Nov 2023 09:53:05 ", "Title": "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective", "Authors": ["Ming-Yu Chung", "Sheng-Yen Chou", "Chia-Mu Yu", "Pin-Yu Chen", "Sy-Yen Kuo", "Tsung-Yi Ho"], "Categories": "cs.LG cs.CR", "Comments": ["19 pages", "4 figures"]}, "abstract": "Dataset distillation offers a potential means to enhance data efficiency in deep learning. Recent studies have shown its ability to counteract backdoor risks present in original training samples. In this study, we delve into the theoretical aspects of backdoor attacks and dataset distillation based on kernel methods. We introduce two new theory-driven trigger pattern generation methods specialized for dataset distillation. Following a comprehensive set of analyses and experiments, we show that our optimization-based trigger design framework informs effective backdoor attacks on dataset distillation. Notably, datasets poisoned by our designed trigger prove resilient against conventional backdoor attack detection and mitigation methods. Our empirical results validate that the triggers developed using our approaches are proficient at executing resilient backdoor attacks.", "url": "https://arxiv.org/abs/2311.16646"}, {"metadata": {"arXiv": "2311.16654", "Date": "Tue, 28 Nov 2023 10:13:31 ", "Title": "Elucidating Discrepancy in Explanations of Predictive Models Developed using EMR", "Authors": ["Aida Brankovic", "Wenjie Huang", "David Cook", "Sankalp Khanna", "Konstanty Bialkowski"], "Categories": "cs.LG"}, "abstract": "The lack of transparency and explainability hinders the clinical adoption of Machine learning (ML) algorithms. While explainable artificial intelligence (XAI) methods have been proposed, little research has focused on the agreement between these methods and expert clinical knowledge. This study applies current state-of-the-art explainability methods to clinical decision support algorithms developed for Electronic Medical Records (EMR) data to analyse the concordance between these factors and discusses causes for identified discrepancies from a clinical and technical perspective. Important factors for achieving trustworthy XAI solutions for clinical decision support are also discussed.", "url": "https://arxiv.org/abs/2311.16654"}, {"metadata": {"arXiv": "2311.16656", "Date": "Tue, 28 Nov 2023 10:17:52 ", "Title": "Pseudo-Likelihood Inference", "Authors": ["Theo Gruner", "Boris Belousov", "Fabio Muratore", "Daniel Palenicek", "Jan Peters"], "Categories": "cs.LG stat.ML", "Comments": ["27 pages", "12 figures", "Published as a conference paper at NeurIPS 2023"]}, "abstract": "Simulation-Based Inference (SBI) is a common name for an emerging family of approaches that infer the model parameters when the likelihood is intractable. Existing SBI methods either approximate the likelihood, such as Approximate Bayesian Computation (ABC) or directly model the posterior, such as Sequential Neural Posterior Estimation (SNPE). While ABC is efficient on low-dimensional problems, on higher-dimensional tasks, it is generally outperformed by SNPE, which leverages function approximation. In this paper, we propose Pseudo-Likelihood Inference (PLI), a new method that brings neural approximation into ABC, making it competitive on challenging Bayesian system identification tasks. By utilizing integral probability metrics, we introduce a smooth likelihood kernel with an adaptive bandwidth that is updated based on information-theoretic trust regions. Thanks to this formulation, our method (i) allows for optimizing neural posteriors via gradient descent, (ii) does not rely on summary statistics, and (iii) enables multiple observations as input. In comparison to SNPE, it leads to improved performance when more data is available. The effectiveness of PLI is evaluated on four classical SBI benchmark tasks and on a highly dynamic physical system, showing particular advantages on stochastic simulations and multi-modal posterior landscapes.", "url": "https://arxiv.org/abs/2311.16656"}, {"metadata": {"arXiv": "2311.16670", "Date": "Tue, 28 Nov 2023 10:34:48 ", "Title": "PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network", "Authors": ["Xiyuan Wang", "Muhan Zhang"], "Categories": "cs.LG"}, "abstract": "We introduce PyTorch Geometric High Order (PyGHO), a library for High Order Graph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike ordinary Message Passing Neural Networks (MPNNs) that exchange messages between nodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a method previously lacking a standardized framework and often requiring complex coding. PyGHO's main objective is to provide an unified and user-friendly interface for various HOGNNs. It accomplishes this through streamlined data structures for node tuples, comprehensive data processing utilities, and a flexible suite of operators for high-order GNN methodologies. In this work, we present a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO with their official implementation on real-world tasks. PyGHO achieves up to $50\\%$ acceleration and reduces the code needed for implementation by an order of magnitude. Our library is available at \\url{https://github.com/GraphPKU/PygHO}.", "url": "https://arxiv.org/abs/2311.16670"}, {"metadata": {"arXiv": "2311.16706", "Date": "Tue, 28 Nov 2023 11:29:12 ", "Title": "Sinkhorn Flow: A Continuous-Time Framework for Understanding and Generalizing the Sinkhorn Algorithm", "Authors": ["Mohammad Reza Karimi", "Ya-Ping Hsieh", "Andreas Krause"], "Categories": "cs.LG math.PR stat.ML"}, "abstract": "Many problems in machine learning can be formulated as solving entropy-regularized optimal transport on the space of probability measures. The canonical approach involves the Sinkhorn iterates, renowned for their rich mathematical properties. Recently, the Sinkhorn algorithm has been recast within the mirror descent framework, thus benefiting from classical optimization theory insights. Here, we build upon this result by introducing a continuous-time analogue of the Sinkhorn algorithm. This perspective allows us to derive novel variants of Sinkhorn schemes that are robust to noise and bias. Moreover, our continuous-time dynamics not only generalize but also offer a unified perspective on several recently discovered dynamics in machine learning and mathematics, such as the \"Wasserstein mirror flow\" of (Deb et al. 2023) or the \"mean-field Schr\\\"odinger equation\" of (Claisse et al. 2023).", "url": "https://arxiv.org/abs/2311.16706"}, {"metadata": {"arXiv": "2311.16741", "Date": "Tue, 28 Nov 2023 12:39:34 ", "Title": "Asynchronous Wireless Federated Learning with Probabilistic Client Selection", "Authors": ["Jiarong Yang", "Yuan Liu", "Fangjiong Chen", "Wen Chen", "Changle Li"], "Categories": "cs.LG cs.DC cs.NI", "Comments": ["To appear in IEEE Transactions on Wireless Communications"]}, "abstract": "Federated learning (FL) is a promising distributed learning framework where distributed clients collaboratively train a machine learning model coordinated by a server. To tackle the stragglers issue in asynchronous FL, we consider that each client keeps local updates and probabilistically transmits the local model to the server at arbitrary times. We first derive the (approximate) expression for the convergence rate based on the probabilistic client selection. Then, an optimization problem is formulated to trade off the convergence rate of asynchronous FL and mobile energy consumption by joint probabilistic client selection and bandwidth allocation. We develop an iterative algorithm to solve the non-convex problem globally optimally. Experiments demonstrate the superiority of the proposed approach compared with the traditional schemes.", "url": "https://arxiv.org/abs/2311.16741"}, {"metadata": {"arXiv": "2311.16822", "Date": "Tue, 28 Nov 2023 14:36:43 ", "Title": "Large Language Models Suffer From Their Own Output: An Analysis of the Self-Consuming Training Loop", "Authors": ["Martin Briesch", "Dominik Sobania", "Franz Rothlauf"], "Categories": "cs.LG cs.CL cs.NE"}, "abstract": "Large language models (LLM) have become state of the art in many benchmarks and conversational LLM applications like ChatGPT are now widely used by the public. Those LLMs can be used to generate large amounts of content which is posted on the internet to various platforms. As LLMs are trained on datasets usually collected from the internet, this LLM-generated content might be used to train the next generation of LLMs. Therefore, a self-consuming training loop emerges in which new LLM generations are trained on the output from the previous generations. We empirically study this self-consuming training loop using a novel dataset to analytically and accurately measure quality and diversity of generated outputs. We find that this self-consuming training loop initially improves both quality and diversity. However, after a few generations the output inevitably degenerates in diversity. We find that the rate of degeneration depends on the proportion of real and generated data.", "url": "https://arxiv.org/abs/2311.16822"}, {"metadata": {"arXiv": "2311.16833", "Date": "Tue, 28 Nov 2023 14:50:50 ", "Title": "1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness", "Authors": ["Bernd Prach", "Fabio Brau", "Giorgio Buttazzo", "Christoph H. Lampert"], "Categories": "cs.LG cs.CV cs.NE"}, "abstract": "The robustness of neural networks against input perturbations with bounded magnitude represents a serious concern in the deployment of deep learning models in safety-critical systems. Recently, the scientific community has focused on enhancing certifiable robustness guarantees by crafting 1-Lipschitz neural networks that leverage Lipschitz bounded dense and convolutional layers. Although different methods have been proposed in the literature to achieve this goal, understanding the performance of such methods is not straightforward, since different metrics can be relevant (e.g., training time, memory usage, accuracy, certifiable robustness) for different applications. For this reason, this work provides a thorough theoretical and empirical comparison between methods by evaluating them in terms of memory usage, speed, and certifiable robust accuracy. The paper also provides some guidelines and recommendations to support the user in selecting the methods that work best depending on the available resources. We provide code at https://github.com/berndprach/1LipschitzLayersCompared.", "url": "https://arxiv.org/abs/2311.16833"}, {"metadata": {"arXiv": "2311.16856", "Date": "Tue, 28 Nov 2023 15:05:13 ", "Title": "Attentional Graph Neural Networks for Robust Massive Network Localization", "Authors": ["Wenzhong Yan", "Juntao Wang", "Feng Yin", "Abdelhak M. Zoubir"], "Categories": "cs.LG eess.SP stat.ML"}, "abstract": "Graph neural networks (GNNs) have gained significant popularity for classification tasks in machine learning, yet their applications to regression problems remain limited. Concurrently, attention mechanisms have emerged as powerful tools in sequential learning tasks. In this paper, we employ GNNs and attention mechanisms to address a classical but challenging nonlinear regression problem: network localization. We propose a novel GNN-based network localization method that achieves exceptional stability and accuracy in the presence of severe non-line-of-sight (NLOS) propagations, while eliminating the need for laborious offline calibration or NLOS identification. Extensive experimental results validate the effectiveness and high accuracy of our GNN-based localization model, particularly in challenging NLOS scenarios. However, the proposed GNN-based model exhibits limited flexibility, and its accuracy is highly sensitive to a specific hyperparameter that determines the graph structure. To address the limitations and extend the applicability of the GNN-based model to real scenarios, we introduce two attentional graph neural networks (AGNNs) that offer enhanced flexibility and the ability to automatically learn the optimal hyperparameter for each node. Experimental results confirm that the AGNN models are able to enhance localization accuracy, providing a promising solution for real-world applications. We also provide some analyses of the improved performance achieved by the AGNN models from the perspectives of dynamic attention and signal denoising characteristics.", "url": "https://arxiv.org/abs/2311.16856"}, {"metadata": {"arXiv": "2311.16860", "Date": "Tue, 28 Nov 2023 15:07:25 ", "Title": "Data-efficient operator learning for solving high Mach number fluid flow problems", "Authors": ["Noah Ford", "Victor J. Leon", "Honest Merman", "Jeffrey Gilbert", "Alexander New"], "Categories": "cs.LG cs.NA math.NA physics.flu-dyn"}, "abstract": "We consider the problem of using SciML to predict solutions of high Mach fluid flows over irregular geometries. In this setting, data is limited, and so it is desirable for models to perform well in the low-data setting. We show that Neural Basis Functions (NBF), which learns a basis of behavior modes from the data and then uses this basis to make predictions, is more effective than a basis-unaware baseline model. In addition, we identify continuing challenges in the space of predicting solutions for this type of problem.", "url": "https://arxiv.org/abs/2311.16860"}, {"metadata": {"arXiv": "2311.16863", "Date": "Tue, 28 Nov 2023 15:09:36 ", "Title": "Power Hungry Processing: Watts Driving the Cost of AI Deployment?", "Authors": ["Alexandra Sasha Luccioni", "Yacine Jernite", "Emma Strubell"], "Categories": "cs.LG"}, "abstract": "Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of \"generality\" comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and `general-purpose' models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.", "url": "https://arxiv.org/abs/2311.16863"}, {"metadata": {"arXiv": "2311.16872", "Date": "Tue, 28 Nov 2023 15:24:02 ", "Title": "A unified weighting framework for evaluating nearest neighbour classification", "Authors": ["Oliver Urs Lenz", "Henri Bollaert", "Chris Cornelis"], "Categories": "cs.LG stat.ML"}, "abstract": "We present the first comprehensive and large-scale evaluation of classical (NN), fuzzy (FNN) and fuzzy rough (FRNN) nearest neighbour classification. We show that existing proposals for nearest neighbour weighting can be standardised in the form of kernel functions, applied to the distance values and/or ranks of the nearest neighbours of a test instance. Furthermore, we identify three commonly used distance functions and four scaling measures. We systematically evaluate these choices on a collection of 85 real-life classification datasets. We find that NN, FNN and FRNN all perform best with Boscovich distance. NN and FRNN perform best with a combination of Samworth rank- and distance weights and scaling by the mean absolute deviation around the median ($r_1$), the standard deviaton ($r_2$) or the interquartile range ($r_{\\infty}^*$), while FNN performs best with only Samworth distance-weights and $r_1$- or $r_2$-scaling. We also introduce a new kernel based on fuzzy Yager negation, and show that NN achieves comparable performance with Yager distance-weights, which are simpler to implement than a combination of Samworth distance- and rank-weights. Finally, we demonstrate that FRNN generally outperforms NN, which in turns performs systematically better than FNN.", "url": "https://arxiv.org/abs/2311.16872"}, {"metadata": {"arXiv": "2311.16877", "Date": "Tue, 28 Nov 2023 15:26:09 ", "Title": "Imputation using training labels and classification via label imputation", "Authors": ["Thu Nguyen", "P{\\aa}l Halvorsen", "Michael A. Riegler"], "Categories": "cs.LG stat.ML"}, "abstract": "Missing data is a common problem in practical settings. Various imputation methods have been developed to deal with missing data. However, even though the label is usually available in the training data, the common practice of imputation usually only relies on the input and ignores the label. In this work, we illustrate how stacking the label into the input can significantly improve the imputation of the input. In addition, we propose a classification strategy that initializes the predicted test label with missing values and stacks the label with the input for imputation. This allows imputing the label and the input at the same time. Also, the technique is capable of handling data training with missing labels without any prior imputation and is applicable to continuous, categorical, or mixed-type data. Experiments show promising results in terms of accuracy.", "url": "https://arxiv.org/abs/2311.16877"}, {"metadata": {"arXiv": "2311.16883", "Date": "Tue, 28 Nov 2023 15:31:31 ", "Title": "Compressing the Backward Pass of Large-Scale Neural Architectures by Structured Activation Pruning", "Authors": ["Daniel Barley", "Holger Fr\\\"oning"], "Categories": "cs.LG cs.PF", "Comments": ["8 pages", "10 figures", "submitted to the 6th AccML workshop at HiPEAC conference 2024"]}, "abstract": "The rise of Deep Neural Networks (DNNs) has led to an increase in model size and complexity, straining the memory capacity of GPUs. Sparsity in DNNs, characterized as structural or ephemeral, has gained attention as a solution. This work focuses on ephemeral sparsity, aiming to reduce memory consumption during training. It emphasizes the significance of activations, an often overlooked component, and their role in memory usage. This work employs structured pruning in Block Sparse Compressed Row (BSR) format in combination with a magnitude-based criterion to efficiently prune activations. We furthermore introduce efficient block-sparse operators for GPUs and showcase their effectiveness, as well as the superior compression offered by block sparsity. We report the effectiveness of activation pruning by evaluating training speed, accuracy, and memory usage of large-scale neural architectures on the example of ResMLP on image classification tasks. As a result, we observe a memory reduction of up to 32\\% while maintaining accuracy. Ultimately, our approach aims to democratize large-scale model training, reduce GPU requirements, and address ecological concerns.", "url": "https://arxiv.org/abs/2311.16883"}, {"metadata": {"arXiv": "2311.16894", "Date": "Tue, 28 Nov 2023 15:46:12 ", "Title": "Dendrogram distance: an evaluation metric for generative networks using hierarchical clustering", "Authors": ["Gustavo Sutter Carvalho and Moacir Antonelli Ponti"], "Categories": "cs.LG cs.CV"}, "abstract": "We present a novel metric for generative modeling evaluation, focusing primarily on generative networks. The method uses dendrograms to represent real and fake data, allowing for the divergence between training and generated samples to be computed. This metric focus on mode collapse, targeting generators that are not able to capture all modes in the training set. To evaluate the proposed method it is introduced a validation scheme based on sampling from real datasets, therefore the metric is evaluated in a controlled environment and proves to be competitive with other state-of-the-art approaches.", "url": "https://arxiv.org/abs/2311.16894"}, {"metadata": {"arXiv": "2311.17006", "Date": "Tue, 28 Nov 2023 17:59:49 ", "Title": "On the Impact of Sampling on Deep Sequential State Estimation", "Authors": ["Helena Calatrava and Ricardo Augusto Borsoi and Tales Imbiriba and Pau Closas"], "Categories": "cs.LG eess.SP", "Comments": ["To appear in the Proceedings of the Asilomar Conference on Signals", "Systems", "and Computers", "October 2023", "5 pages", "3 figures", "3 tables"]}, "abstract": "State inference and parameter learning in sequential models can be successfully performed with approximation techniques that maximize the evidence lower bound to the marginal log-likelihood of the data distribution. These methods may be referred to as Dynamical Variational Autoencoders, and our specific focus lies on the deep Kalman filter. It has been shown that the ELBO objective can oversimplify data representations, potentially compromising estimation quality. Tighter Monte Carlo objectives have been proposed in the literature to enhance generative modeling performance. For instance, the IWAE objective uses importance weights to reduce the variance of marginal log-likelihood estimates. In this paper, importance sampling is applied to the DKF framework for learning deep Markov models, resulting in the IW-DKF, which shows an improvement in terms of log-likelihood estimates and KL divergence between the variational distribution and the transition model. The framework using the sampled DKF update rule is also accommodated to address sequential state and parameter estimation when working with highly non-linear physics-based models. An experiment with the 3-space Lorenz attractor shows an enhanced generative modeling performance and also a decrease in RMSE when estimating the model parameters and latent states, indicating that tighter MCOs lead to improved state inference performance.", "url": "https://arxiv.org/abs/2311.17006"}, {"metadata": {"arXiv": "2311.17008", "Date": "Tue, 28 Nov 2023 18:02:06 ", "Title": "An Investigation of Time Reversal Symmetry in Reinforcement Learning", "Authors": ["Brett Barkley", "Amy Zhang", "David Fridovich-Keil"], "Categories": "cs.LG"}, "abstract": "One of the fundamental challenges associated with reinforcement learning (RL) is that collecting sufficient data can be both time-consuming and expensive. In this paper, we formalize a concept of time reversal symmetry in a Markov decision process (MDP), which builds upon the established structure of dynamically reversible Markov chains (DRMCs) and time-reversibility in classical physics. Specifically, we investigate the utility of this concept in reducing the sample complexity of reinforcement learning. We observe that utilizing the structure of time reversal in an MDP allows every environment transition experienced by an agent to be transformed into a feasible reverse-time transition, effectively doubling the number of experiences in the environment. To test the usefulness of this newly synthesized data, we develop a novel approach called time symmetric data augmentation (TSDA) and investigate its application in both proprioceptive and pixel-based state within the realm of off-policy, model-free RL. Empirical evaluations showcase how these synthetic transitions can enhance the sample efficiency of RL agents in time reversible scenarios without friction or contact. We also test this method in more realistic environments where these assumptions are not globally satisfied. We find that TSDA can significantly degrade sample efficiency and policy performance, but can also improve sample efficiency under the right conditions. Ultimately we conclude that time symmetry shows promise in enhancing the sample efficiency of reinforcement learning and provide guidance when the environment and reward structures are of an appropriate form for TSDA to be employed effectively.", "url": "https://arxiv.org/abs/2311.17008"}, {"metadata": {"arXiv": "2311.17035", "Date": "Tue, 28 Nov 2023 18:47:03 ", "Title": "Scalable Extraction of Training Data from (Production) Language Models", "Authors": ["Milad Nasr", "Nicholas Carlini", "Jonathan Hayase", "Matthew Jagielski", "A. Feder Cooper", "Daphne Ippolito", "Christopher A. Choquette-Choo", "Eric Wallace", "Florian Tram\\`er", "Katherine Lee"], "Categories": "cs.LG cs.CL cs.CR"}, "abstract": "This paper studies extractable memorization: training data that an adversary can efficiently extract by querying a machine learning model without prior knowledge of the training dataset. We show an adversary can extract gigabytes of training data from open-source language models like Pythia or GPT-Neo, semi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing techniques from the literature suffice to attack unaligned models; in order to attack the aligned ChatGPT, we develop a new divergence attack that causes the model to diverge from its chatbot-style generations and emit training data at a rate 150x higher than when behaving properly. Our methods show practical attacks can recover far more data than previously thought, and reveal that current alignment techniques do not eliminate memorization.", "url": "https://arxiv.org/abs/2311.17035"}, {"metadata": {"arXiv": "2311.16380", "Date": "Mon, 27 Nov 2023 23:56:59 ", "Title": "Learning Multimodal Latent Dynamics for Human-Robot Interaction", "Authors": ["Vignesh Prasad", "Lea Heitlinger", "Dorothea Koert", "Ruth Stock-Homburg", "Jan Peters", "Georgia Chalvatzaki"], "Categories": "cs.RO cs.HC cs.LG", "Comments": ["20 Pages", "10 Figures"]}, "abstract": "This article presents a method for learning well-coordinated Human-Robot Interaction (HRI) from Human-Human Interactions (HHI). We devise a hybrid approach using Hidden Markov Models (HMMs) as the latent space priors for a Variational Autoencoder to model a joint distribution over the interacting agents. We leverage the interaction dynamics learned from HHI to learn HRI and incorporate the conditional generation of robot motions from human observations into the training, thereby predicting more accurate robot trajectories. The generated robot motions are further adapted with Inverse Kinematics to ensure the desired physical proximity with a human, combining the ease of joint space learning and accurate task space reachability. For contact-rich interactions, we modulate the robot's stiffness using HMM segmentation for a compliant interaction. We verify the effectiveness of our approach deployed on a Humanoid robot via a user study. Our method generalizes well to various humans despite being trained on data from just two humans. We find that Users perceive our method as more human-like, timely, and accurate and rank our method with a higher degree of preference over other baselines.", "url": "https://arxiv.org/abs/2311.16380"}, {"metadata": {"arXiv": "2311.16520", "Date": "Tue, 28 Nov 2023 04:58:41 ", "Title": "Value Approximation for Two-Player General-Sum Differential Games with State Constraints", "Authors": ["Lei Zhang", "Mukesh Ghimire", "Wenlong Zhang", "Zhe Xu", "Yi Ren"], "Categories": "cs.RO cs.GT cs.LG", "Comments": ["Submitted to TRO"]}, "abstract": "Solving Hamilton-Jacobi-Isaacs (HJI) PDEs enables equilibrial feedback control in two-player differential games, yet faces the curse of dimensionality (CoD). While physics-informed machine learning has been adopted to address CoD in solving PDEs, this method falls short in learning discontinuous solutions due to its sampling nature, leading to poor safety performance of the resulting controllers in robotics applications where values are discontinuous due to state or other temporal logic constraints. In this study, we explore three potential solutions to this problem: (1) a hybrid learning method that uses both equilibrium demonstrations and the HJI PDE, (2) a value-hardening method where a sequence of HJIs are solved with increasing Lipschitz constant on the constraint violation penalty, and (3) the epigraphical technique that lifts the value to a higher dimensional auxiliary state space where the value becomes continuous. Evaluations through 5D and 9D vehicle simulations and 13D drone simulations reveal that the hybrid method outperforms others in terms of generalization and safety performance.", "url": "https://arxiv.org/abs/2311.16520"}, {"metadata": {"arXiv": "2311.16534", "Date": "Tue, 28 Nov 2023 05:36:59 ", "Title": "Graph Prompt Learning: A Comprehensive Survey and Beyond", "Authors": ["Xiangguo Sun", "Jiawen Zhang", "Xixi Wu", "Hong Cheng", "Yun Xiong", "Jia Li"], "Categories": "cs.AI"}, "abstract": "Artificial General Intelligence (AGI) has revolutionized numerous fields, yet its integration with graph data, a cornerstone in our interconnected world, remains nascent. This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications. Despite substantial advancements in AGI across natural language processing and computer vision, the application to graph data is relatively underexplored. This survey critically evaluates the current landscape of AGI in handling graph data, highlighting the distinct challenges in cross-modality, cross-domain, and cross-task applications specific to graphs. Our work is the first to propose a unified framework for understanding graph prompt learning, offering clarity on prompt tokens, token structures, and insertion patterns in the graph domain. We delve into the intrinsic properties of graph prompts, exploring their flexibility, expressiveness, and interplay with existing graph models. A comprehensive taxonomy categorizes over 100 works in this field, aligning them with pre-training tasks across node-level, edge-level, and graph-level objectives. Additionally, we present, ProG, a Python library, and an accompanying website, to support and advance research in graph prompting. The survey culminates in a discussion of current challenges and future directions, offering a roadmap for research in graph prompting within AGI. Through this comprehensive analysis, we aim to catalyze further exploration and practical applications of AGI in graph data, underlining its potential to reshape AGI fields and beyond. ProG and the website can be accessed by \\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and \\url{https://github.com/sheldonresearch/ProG}, respectively.", "url": "https://arxiv.org/abs/2311.16534"}, {"metadata": {"arXiv": "2311.16781", "Date": "Tue, 28 Nov 2023 13:45:03 ", "Title": "Generation of Games for Opponent Model Differentiation", "Authors": ["David Milec", "Viliam Lis\\'y", "Christopher Kiekintveld"], "Categories": "cs.AI", "Comments": ["4 pages"]}, "abstract": "Protecting against adversarial attacks is a common multiagent problem. Attackers in the real world are predominantly human actors, and the protection methods often incorporate opponent models to improve the performance when facing humans. Previous results show that modeling human behavior can significantly improve the performance of the algorithms. However, modeling humans correctly is a complex problem, and the models are often simplified and assume humans make mistakes according to some distribution or train parameters for the whole population from which they sample. In this work, we use data gathered by psychologists who identified personality types that increase the likelihood of performing malicious acts. However, in the previous work, the tests on a handmade game could not show strategic differences between the models. We created a novel model that links its parameters to psychological traits. We optimized over parametrized games and created games in which the differences are profound. Our work can help with automatic game generation when we need a game in which some models will behave differently and to identify situations in which the models do not align.", "url": "https://arxiv.org/abs/2311.16781"}, {"metadata": {"arXiv": "2311.16807", "Date": "Tue, 28 Nov 2023 14:09:43 ", "Title": "Agent-Aware Training for Agent-Agnostic Action Advising in Deep Reinforcement Learning", "Authors": ["Yaoquan Wei", "Shunyu Liu", "Jie Song", "Tongya Zheng", "Kaixuan Chen", "Yong Wang", "Mingli Song"], "Categories": "cs.AI"}, "abstract": "Action advising endeavors to leverage supplementary guidance from expert teachers to alleviate the issue of sampling inefficiency in Deep Reinforcement Learning (DRL). Previous agent-specific action advising methods are hindered by imperfections in the agent itself, while agent-agnostic approaches exhibit limited adaptability to the learning agent. In this study, we propose a novel framework called Agent-Aware trAining yet Agent-Agnostic Action Advising (A7) to strike a balance between the two. The underlying concept of A7 revolves around utilizing the similarity of state features as an indicator for soliciting advice. However, unlike prior methodologies, the measurement of state feature similarity is performed by neither the error-prone learning agent nor the agent-agnostic advisor. Instead, we employ a proxy model to extract state features that are both discriminative (adaptive to the agent) and generally applicable (robust to agent noise). Furthermore, we utilize behavior cloning to train a model for reusing advice and introduce an intrinsic reward for the advised samples to incentivize the utilization of expert guidance. Experiments are conducted on the GridWorld, LunarLander, and six prominent scenarios from Atari games. The results demonstrate that A7 significantly accelerates the learning process and surpasses existing methods (both agent-specific and agent-agnostic) by a substantial margin. Our code will be made publicly available.", "url": "https://arxiv.org/abs/2311.16807"}, {"metadata": {"arXiv": "2311.16133", "Date": "Thu, 02 Nov 2023 13:14:01 ", "Title": "Effective Quantization for Diffusion Models on CPUs", "Authors": ["Hanwen Chang", "Haihao Shen", "Yiyang Cai", "Xinyu Ye", "Zhenzhong Xu", "Wenhua Cheng", "Kaokao Lv", "Weiwei Zhang", "Yintong Lu", "Heng Guo"], "Categories": "cs.CV cs.AI"}, "abstract": "Diffusion models have gained popularity for generating images from textual descriptions. Nonetheless, the substantial need for computational resources continues to present a noteworthy challenge, contributing to time-consuming processes. Quantization, a technique employed to compress deep learning models for enhanced efficiency, presents challenges when applied to diffusion models. These models are notably more sensitive to quantization compared to other model types, potentially resulting in a degradation of image quality. In this paper, we introduce a novel approach to quantize the diffusion models by leveraging both quantization-aware training and distillation. Our results show the quantized models can maintain the high image quality while demonstrating the inference efficiency on CPUs.", "url": "https://arxiv.org/abs/2311.16133"}, {"metadata": {"arXiv": "2311.16138", "Date": "Fri, 03 Nov 2023 16:56:02 ", "Title": "After-Stroke Arm Paresis Detection using Kinematic Data", "Authors": ["Kenneth Lai", "Mohammed Almekhlafi", "Svetlana Yanushkevich"], "Categories": "cs.CV cs.AI", "Comments": ["submitted to IEEE Symposium Series on Computational Intelligence"]}, "abstract": "This paper presents an approach for detecting unilateral arm paralysis/weakness using kinematic data. Our method employs temporal convolution networks and recurrent neural networks, guided by knowledge distillation, where we use inertial measurement units attached to the body to capture kinematic information such as acceleration, rotation, and flexion of body joints during an action. This information is then analyzed to recognize body actions and patterns. Our proposed network achieves a high paretic detection accuracy of 97.99\\%, with an action classification accuracy of 77.69\\%, through knowledge sharing. Furthermore, by incorporating causal reasoning, we can gain additional insights into the patient's condition, such as their Fugl-Meyer assessment score or impairment level based on the machine learning result. Overall, our approach demonstrates the potential of using kinematic data and machine learning for detecting arm paralysis/weakness. The results suggest that our method could be a useful tool for clinicians and healthcare professionals working with patients with this condition.", "url": "https://arxiv.org/abs/2311.16138"}, {"metadata": {"arXiv": "2311.16161", "Date": "Thu, 09 Nov 2023 09:06:21 ", "Title": "Vision Encoder-Decoder Models for AI Coaching", "Authors": ["Jyothi S Nayak", "Afifah Khan Mohammed Ajmal Khan", "Chirag Manjeshwar and Imadh Ajaz Banday"], "Categories": "cs.CV cs.AI", "Comments": ["6 pages", "2 figures"], "ACM-class": "I.2.1"}, "abstract": "This research paper introduces an innovative AI coaching approach by integrating vision-encoder-decoder models. The feasibility of this method is demonstrated using a Vision Transformer as the encoder and GPT-2 as the decoder, achieving a seamless integration of visual input and textual interaction. Departing from conventional practices of employing distinct models for image recognition and text-based coaching, our integrated architecture directly processes input images, enabling natural question-and-answer dialogues with the AI coach. This unique strategy simplifies model architecture while enhancing the overall user experience in human-AI interactions. We showcase sample results to demonstrate the capability of the model. The results underscore the methodology's potential as a promising paradigm for creating efficient AI coach models in various domains involving visual inputs. Importantly, this potential holds true regardless of the particular visual encoder or text decoder chosen. Additionally, we conducted experiments with different sizes of GPT-2 to assess the impact on AI coach performance, providing valuable insights into the scalability and versatility of our proposed methodology.", "url": "https://arxiv.org/abs/2311.16161"}, {"metadata": {"arXiv": "2311.16179", "Date": "Fri, 24 Nov 2023 22:42:47 ", "Title": "Next-gen traffic surveillance: AI-assisted mobile traffic violation detection system", "Authors": ["Dila Dede", "Mehmet Ali Sars{\\i}l", "Ata Shaker", "Olgu Alt{\\i}nta\\c{s}", "Onur Ergen"], "Categories": "cs.CV cs.AI"}, "abstract": "Road traffic accidents pose a significant global public health concern, leading to injuries, fatalities, and vehicle damage. Approximately 1,3 million people lose their lives daily due to traffic accidents [World Health Organization, 2022]. Addressing this issue requires accurate traffic law violation detection systems to ensure adherence to regulations. The integration of Artificial Intelligence algorithms, leveraging machine learning and computer vision, has facilitated the development of precise traffic rule enforcement. This paper illustrates how computer vision and machine learning enable the creation of robust algorithms for detecting various traffic violations. Our model, capable of identifying six common traffic infractions, detects red light violations, illegal use of breakdown lanes, violations of vehicle following distance, breaches of marked crosswalk laws, illegal parking, and parking on marked crosswalks. Utilizing online traffic footage and a self-mounted on-dash camera, we apply the YOLOv5 algorithm's detection module to identify traffic agents such as cars, pedestrians, and traffic signs, and the strongSORT algorithm for continuous interframe tracking. Six discrete algorithms analyze agents' behavior and trajectory to detect violations. Subsequently, an Identification Module extracts vehicle ID information, such as the license plate, to generate violation notices sent to relevant authorities.", "url": "https://arxiv.org/abs/2311.16179"}, {"metadata": {"arXiv": "2311.16254", "Date": "Mon, 27 Nov 2023 19:02:17 ", "Title": "Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image Retrieval and Generation", "Authors": ["Samuele Poppi", "Tobia Poppi", "Federico Cocchi", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "Categories": "cs.CV cs.AI cs.CL cs.MM"}, "abstract": "Vision-and-Language models such as CLIP have demonstrated remarkable effectiveness across a wide range of tasks. However, these models are typically trained on web-scale data, which can introduce inappropriate content and lead to the development of unsafe and biased behavior. This, in turn, hampers their applicability in sensitive and trustworthy contexts and could raise significant concern in their adoption. To overcome these limitations, we introduce a methodology to make Vision-and-Language models safer by removing their sensitivity to not-safe-for-work concepts. We show how this can be done by distilling from a large language model which converts between safe and unsafe sentences and which is fine-tuned starting from just 100 manually-curated pairs. We conduct extensive experiments on the resulting embedding space for both retrieval and text-to-image generation, where we show that our model can also be properly employed with pre-trained image generators. Our source code and trained models are available at: https://github.com/aimagelab/safe-clip.", "url": "https://arxiv.org/abs/2311.16254"}, {"metadata": {"arXiv": "2311.16261", "Date": "Mon, 27 Nov 2023 19:08:08 ", "Title": "RelVAE: Generative Pretraining for few-shot Visual Relationship Detection", "Authors": ["Sotiris Karapiperis", "Markos Diomataris", "Vassilis Pitsikalis"], "Categories": "cs.CV cs.AI"}, "abstract": "Visual relations are complex, multimodal concepts that play an important role in the way humans perceive the world. As a result of their complexity, high-quality, diverse and large scale datasets for visual relations are still absent. In an attempt to overcome this data barrier, we choose to focus on the problem of few-shot Visual Relationship Detection (VRD), a setting that has been so far neglected by the community. In this work we present the first pretraining method for few-shot predicate classification that does not require any annotated relations. We achieve this by introducing a generative model that is able to capture the variation of semantic, visual and spatial information of relations inside a latent space and later exploiting its representations in order to achieve efficient few-shot classification. We construct few-shot training splits and show quantitative experiments on VG200 and VRD datasets where our model outperforms the baselines. Lastly we attempt to interpret the decisions of the model by conducting various qualitative experiments.", "url": "https://arxiv.org/abs/2311.16261"}, {"metadata": {"arXiv": "2311.16450", "Date": "Tue, 28 Nov 2023 03:11:33 ", "Title": "Typhoon Intensity Prediction with Vision Transformer", "Authors": ["Huanxin Chen", "Pengshuai Yin", "Huichou Huang", "Qingyao Wu", "Ruirui Liu and Xiatian Zhu"], "Categories": "cs.CV cs.AI", "Comments": ["8 pages", "2 figures", "accepted by Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023"]}, "abstract": "Predicting typhoon intensity accurately across space and time is crucial for issuing timely disaster warnings and facilitating emergency response. This has vast potential for minimizing life losses and property damages as well as reducing economic and environmental impacts. Leveraging satellite imagery for scenario analysis is effective but also introduces additional challenges due to the complex relations among clouds and the highly dynamic context. Existing deep learning methods in this domain rely on convolutional neural networks (CNNs), which suffer from limited per-layer receptive fields. This limitation hinders their ability to capture long-range dependencies and global contextual knowledge during inference. In response, we introduce a novel approach, namely \"Typhoon Intensity Transformer\" (Tint), which leverages self-attention mechanisms with global receptive fields per layer. Tint adopts a sequence-to-sequence feature representation learning perspective. It begins by cutting a given satellite image into a sequence of patches and recursively employs self-attention operations to extract both local and global contextual relations between all patch pairs simultaneously, thereby enhancing per-patch feature representation learning. Extensive experiments on a publicly available typhoon benchmark validate the efficacy of Tint in comparison with both state-of-the-art deep learning and conventional meteorological methods. Our code is available at https://github.com/chen-huanxin/Tint.", "url": "https://arxiv.org/abs/2311.16450"}, {"metadata": {"arXiv": "2311.16464", "Date": "Tue, 28 Nov 2023 03:55:23 ", "Title": "Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection", "Authors": ["Yicheng Xiao", "Zhuoyan Luo", "Yong Liu", "Yue Ma", "Hengwei Bian", "Yatai Ji", "Yujiu Yang", "Xiu Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted significant attention due to the growing demand for video analysis. Recent approaches treat MR and HD as similar video grounding problems and address them together with transformer-based architecture. However, we observe that the emphasis of MR and HD differs, with one necessitating the perception of local relationships and the other prioritizing the understanding of global contexts. Consequently, the lack of task-specific design will inevitably lead to limitations in associating the intrinsic specialty of two tasks. To tackle the issue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the gap and jointly solve MR and HD effectively. By performing progressive integration on intra and inter-modality across multi-granularity, UVCOM achieves the comprehensive understanding in processing a video. Moreover, we present multi-aspect contrastive learning to consolidate the local relation modeling and global knowledge accumulation via well aligned multi-modal space. Extensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights and TVSum datasets demonstrate the effectiveness and rationality of UVCOM which outperforms the state-of-the-art methods by a remarkable margin.", "url": "https://arxiv.org/abs/2311.16464"}, {"metadata": {"arXiv": "2311.16476", "Date": "Sat, 25 Nov 2023 04:11:19 ", "Title": "LANS: A Layout-Aware Neural Solver for Plane Geometry Problem", "Authors": ["Ming-Liang Zhang", "Zhong-Zhi Li", "Fei Yin", "Cheng-Lin Liu"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "5 figures", "conference"]}, "abstract": "Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion and reasoning. Existing neural solvers take GPS as a vision-language task but be short in the representation of geometry diagrams which carry rich and complex layout information. In this paper, we propose a layout-aware neural solver named LANS, integrated with two new modules: multimodal layout-aware pre-trained language model (MLA-PLM) and layout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic pre-training (SSP) to implement global relationship modeling, and point matching pre-training (PMP) to achieve alignment between visual points and textual points. LA-FA employs a layout-aware attention mask to realize point-guided cross-modal fusion for further boosting layout awareness of LANS. Extensive experiments on datasets Geometry3K and PGPS9K validate the effectiveness of the layout-aware modules and superior problem solving performance of our LANS solver, over existing symbolic solvers and neural solvers. The code will make public available soon.", "url": "https://arxiv.org/abs/2311.16476"}, {"metadata": {"arXiv": "2311.16480", "Date": "Mon, 27 Nov 2023 05:05:41 ", "Title": "MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images", "Authors": ["Pingyi Chen", "Honglin Li", "Chenglu Zhu", "Sunyi Zheng", "Lin Yang"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation, we investigate how to generate pathology reports given whole slide images. On the data end, we curated the largest WSI-text dataset (TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text pairs for visual-language models by recognizing and cleaning pathology reports which narrate diagnostic slides in TCGA. On the model end, we propose the multiple instance generative model (MI-Gen) which can produce pathology reports for gigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText. Experimental results show our model can generate pathology reports which contain multiple clinical clues. Furthermore, WSI-text prediction can be seen as an approach of visual-language pre-training, which enables our model to be transferred to downstream diagnostic tasks like carcinoma grading and phenotyping. We observe that simple semantic extraction from the pathology reports can achieve the best performance (0.838 of F1 score) on BRCA subtyping without adding extra parameters or tricky fine-tuning. Our collected dataset and related code will all be publicly available.", "url": "https://arxiv.org/abs/2311.16480"}, {"metadata": {"arXiv": "2311.16488", "Date": "Tue, 28 Nov 2023 04:34:44 ", "Title": "Efficient Multimodal Diffusion Models Using Joint Data Infilling with Partially Shared U-Net", "Authors": ["Zizhao Hu", "Shaochong Jia", "Mohammad Rostami"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, diffusion models have been used successfully to fit distributions for cross-modal data translation and multimodal data generation. However, these methods rely on extensive scaling, overlooking the inefficiency and interference between modalities. We develop Partially Shared U-Net (PS-U-Net) architecture which is an efficient multimodal diffusion model that allows text and image inputs to pass through dedicated layers and skip-connections for preserving modality-specific fine-grained details. Inspired by image inpainting, we also propose a new efficient multimodal sampling method that introduces new scenarios for conditional generation while only requiring a simple joint distribution to be learned. Our empirical exploration of the MS-COCO dataset demonstrates that our method generates multimodal text and image data with higher quality compared to existing multimodal diffusion models while having a comparable size, faster training, faster multimodal sampling, and more flexible generation.", "url": "https://arxiv.org/abs/2311.16488"}, {"metadata": {"arXiv": "2311.16512", "Date": "Mon, 27 Nov 2023 16:33:29 ", "Title": "CoSeR: Bridging Image and Language for Cognitive Super-Resolution", "Authors": ["Haoze Sun", "Wenbo Li", "Jianzhuang Liu", "Haoyu Chen", "Renjing Pei", "Xueyi Zou", "Youliang Yan", "Yujiu Yang"], "Categories": "cs.CV cs.AI", "Comments": ["Project page: https://coser-main.github.io ; GitHub repository: https://github.com/VINHYU/CoSeR"]}, "abstract": "Existing super-resolution (SR) models primarily focus on restoring local texture details, often neglecting the global semantic information within the scene. This oversight can lead to the omission of crucial semantic details or the introduction of inaccurate textures during the recovery process. In our work, we introduce the Cognitive Super-Resolution (CoSeR) framework, empowering SR models with the capacity to comprehend low-resolution images. We achieve this by marrying image appearance and language understanding to generate a cognitive embedding, which not only activates prior information from large text-to-image diffusion models but also facilitates the generation of high-quality reference images to optimize the SR process. To further improve image fidelity, we propose a novel condition injection scheme called \"All-in-Attention\", consolidating all conditional information into a single module. Consequently, our method successfully restores semantically correct and photorealistic details, demonstrating state-of-the-art performance across multiple benchmarks.", "url": "https://arxiv.org/abs/2311.16512"}, {"metadata": {"arXiv": "2311.16515", "Date": "Sat, 25 Nov 2023 14:24:49 ", "Title": "Word for Person: Zero-shot Composed Person Retrieval", "Authors": ["Delong Liu", "Haiwen Li", "Zhicheng Zhao", "Fei Su", "Hongying Meng"], "Categories": "cs.CV cs.AI cs.IR"}, "abstract": "Searching for specific person has great security value and social benefits, and it often involves a combination of visual and textual information. Conventional person retrieval methods, whether image-based or text-based, usually fall short in effectively harnessing both types of information, leading to the loss of accuracy. In this paper, a whole new task called Composed Person Retrieval (CPR) is proposed to jointly utilize both image and text information for target person retrieval. However, the supervised CPR must depend on very costly manual annotation dataset, while there are currently no available resources. To mitigate this issue, we firstly introduce the Zero-shot Composed Person Retrieval (ZS-CPR), which leverages existing domain-related data to resolve the CPR problem without reliance on expensive annotations. Secondly, to learn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where a lightweight Textual Inversion Network (TINet) and a text-based person retrieval model based on fine-tuned Contrastive Language-Image Pre-training (CLIP) network are learned without utilizing any CPR data. Thirdly, a finely annotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the benchmark to assess the performance of the proposed Word4Per framework. Extensive experiments under both Rank-1 and mAP demonstrate the effectiveness of Word4Per for the ZS-CPR task, surpassing the comparative methods by over 10%. The code and ITCPR dataset will be publicly available at https://github.com/Delong-liu-bupt/Word4Per.", "url": "https://arxiv.org/abs/2311.16515"}, {"metadata": {"arXiv": "2311.16671", "Date": "Tue, 28 Nov 2023 10:36:36 ", "Title": "SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry, Illumination, and Material Estimation", "Authors": ["Jesus Zarzar", "Bernard Ghanem"], "Categories": "cs.CV cs.AI cs.GR"}, "abstract": "We present a novel approach for digitizing real-world objects by estimating their geometry, material properties, and environmental lighting from a set of posed images with fixed lighting. Our method incorporates into Neural Radiance Field (NeRF) pipelines the split sum approximation used with image-based lighting for real-time physical-based rendering. We propose modeling the scene's lighting with a single scene-specific MLP representing pre-integrated image-based lighting at arbitrary resolutions. We achieve accurate modeling of pre-integrated lighting by exploiting a novel regularizer based on efficient Monte Carlo sampling. Additionally, we propose a new method of supervising self-occlusion predictions by exploiting a similar regularizer based on Monte Carlo sampling. Experimental results demonstrate the efficiency and effectiveness of our approach in estimating scene geometry, material properties, and lighting. Our method is capable of attaining state-of-the-art relighting quality after only ${\\sim}1$ hour of training in a single NVIDIA A100 GPU.", "url": "https://arxiv.org/abs/2311.16671"}, {"metadata": {"arXiv": "2311.16673", "Date": "Tue, 28 Nov 2023 10:39:19 ", "Title": "Large Language Models Meet Computer Vision: A Brief Survey", "Authors": ["Raby Hamadi"], "Categories": "cs.CV cs.AI"}, "abstract": "Recently, the intersection of Large Language Models (LLMs) and Computer Vision (CV) has emerged as a pivotal area of research, driving significant advancements in the field of Artificial Intelligence (AI). As transformers have become the backbone of many state-of-the-art models in both Natural Language Processing (NLP) and CV, understanding their evolution and potential enhancements is crucial. This survey paper delves into the latest progressions in the domain of transformers and their subsequent successors, emphasizing their potential to revolutionize Vision Transformers (ViTs) and LLMs. This survey also presents a comparative analysis, juxtaposing the performance metrics of several leading paid and open-source LLMs, shedding light on their strengths and areas of improvement as well as a literature review on how LLMs are being used to tackle vision related tasks. Furthermore, the survey presents a comprehensive collection of datasets employed to train LLMs, offering insights into the diverse data available to achieve high performance in various pre-training and downstream tasks of LLMs. The survey is concluded by highlighting open directions in the field, suggesting potential venues for future research and development. This survey aims to underscores the profound intersection of LLMs on CV, leading to a new era of integrated and advanced AI models.", "url": "https://arxiv.org/abs/2311.16673"}, {"metadata": {"arXiv": "2311.16681", "Date": "Tue, 28 Nov 2023 10:53:26 ", "Title": "Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with Prototypical Concept-based Explanations", "Authors": ["Maximilian Dreyer", "Reduan Achtibat", "Wojciech Samek", "Sebastian Lapuschkin"], "Categories": "cs.CV cs.AI", "Comments": ["37 pages (9 pages manuscript", "2 pages references", "26 pages appendix)"]}, "abstract": "Ensuring both transparency and safety is critical when deploying Deep Neural Networks (DNNs) in high-risk applications, such as medicine. The field of explainable AI (XAI) has proposed various methods to comprehend the decision-making processes of opaque DNNs. However, only few XAI methods are suitable of ensuring safety in practice as they heavily rely on repeated labor-intensive and possibly biased human assessment. In this work, we present a novel post-hoc concept-based XAI framework that conveys besides instance-wise (local) also class-wise (global) decision-making strategies via prototypes. What sets our approach apart is the combination of local and global strategies, enabling a clearer understanding of the (dis-)similarities in model decisions compared to the expected (prototypical) concept use, ultimately reducing the dependence on human long-term assessment. Quantifying the deviation from prototypical behavior not only allows to associate predictions with specific model sub-strategies but also to detect outlier behavior. As such, our approach constitutes an intuitive and explainable tool for model validation. We demonstrate the effectiveness of our approach in identifying out-of-distribution samples, spurious model behavior and data quality issues across three datasets (ImageNet, CUB-200, and CIFAR-10) utilizing VGG, ResNet, and EfficientNet architectures. Code is available on https://github.com/maxdreyer/pcx.", "url": "https://arxiv.org/abs/2311.16681"}, {"metadata": {"arXiv": "2311.16754", "Date": "Tue, 28 Nov 2023 12:52:49 ", "Title": "Towards Full-scene Domain Generalization in Multi-agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving", "Authors": ["Senkang Hu", "Zhengru Fang", "Xianhao Chen", "Yuguang Fang", "Sam Kwong"], "Categories": "cs.CV cs.AI"}, "abstract": "Collaborative perception has recently gained significant attention in autonomous driving, improving perception quality by enabling the exchange of additional information among vehicles. However, deploying collaborative perception systems can lead to domain shifts due to diverse environmental conditions and data heterogeneity among connected and autonomous vehicles (CAVs). To address these challenges, we propose a unified domain generalization framework applicable in both training and inference stages of collaborative perception. In the training phase, we introduce an Amplitude Augmentation (AmpAug) method to augment low-frequency image variations, broadening the model's ability to learn across various domains. We also employ a meta-consistency training scheme to simulate domain shifts, optimizing the model with a carefully designed consistency loss to encourage domain-invariant representations. In the inference phase, we introduce an intra-system domain alignment mechanism to reduce or potentially eliminate the domain discrepancy among CAVs prior to inference. Comprehensive experiments substantiate the effectiveness of our method in comparison with the existing state-of-the-art works. Code will be released at https://github.com/DG-CAVs/DG-CoPerception.git.", "url": "https://arxiv.org/abs/2311.16754"}, {"metadata": {"arXiv": "2311.16782", "Date": "Tue, 28 Nov 2023 13:45:15 ", "Title": "The curse of language biases in remote sensing VQA: the role of spatial attributes, language diversity, and the need for clear evaluation", "Authors": ["Christel Chappuis and Eliot Walt and Vincent Mendez and Sylvain Lobry and Bertrand Le Saux and Devis Tuia"], "Categories": "cs.CV cs.AI"}, "abstract": "Remote sensing visual question answering (RSVQA) opens new opportunities for the use of overhead imagery by the general public, by enabling human-machine interaction with natural language. Building on the recent advances in natural language processing and computer vision, the goal of RSVQA is to answer a question formulated in natural language about a remote sensing image. Language understanding is essential to the success of the task, but has not yet been thoroughly examined in RSVQA. In particular, the problem of language biases is often overlooked in the remote sensing community, which can impact model robustness and lead to wrong conclusions about the performances of the model. Thus, the present work aims at highlighting the problem of language biases in RSVQA with a threefold analysis strategy: visual blind models, adversarial testing and dataset analysis. This analysis focuses both on model and data. Moreover, we motivate the use of more informative and complementary evaluation metrics sensitive to the issue. The gravity of language biases in RSVQA is then exposed for all of these methods with the training of models discarding the image data and the manipulation of the visual input during inference. Finally, a detailed analysis of question-answer distribution demonstrates the root of the problem in the data itself. Thanks to this analytical study, we observed that biases in remote sensing are more severe than in standard VQA, likely due to the specifics of existing remote sensing datasets for the task, e.g. geographical similarities and sparsity, as well as a simpler vocabulary and question generation strategies. While new, improved and less-biased datasets appear as a necessity for the development of the promising field of RSVQA, we demonstrate that more informed, relative evaluation metrics remain much needed to transparently communicate results of future RSVQA methods.", "url": "https://arxiv.org/abs/2311.16782"}, {"metadata": {"arXiv": "2311.16918", "Date": "Tue, 28 Nov 2023 16:22:33 ", "Title": "RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D", "Authors": ["Lingteng Qiu", "Guanying Chen", "Xiaodong Gu", "Qi Zuo", "Mutian Xu", "Yushuang Wu", "Weihao Yuan", "Zilong Dong", "Liefeng Bo", "Xiaoguang Han"], "Categories": "cs.CV cs.AI", "Comments": ["Project Page: https://lingtengqiu.github.io/RichDreamer/"], "Report-no": "26"}, "abstract": "Lifting 2D diffusion for 3D generation is a challenging problem due to the lack of geometric prior and the complex entanglement of materials and lighting in natural images. Existing methods have shown promise by first creating the geometry through score-distillation sampling (SDS) applied to rendered surface normals, followed by appearance modeling. However, relying on a 2D RGB diffusion model to optimize surface normals is suboptimal due to the distribution discrepancy between natural images and normals maps, leading to instability in optimization. In this paper, recognizing that the normal and depth information effectively describe scene geometry and be automatically estimated from images, we propose to learn a generalizable Normal-Depth diffusion model for 3D generation. We achieve this by training on the large-scale LAION dataset together with the generalizable image-to-depth and normal prior models. In an attempt to alleviate the mixed illumination effects in the generated materials, we introduce an albedo diffusion model to impose data-driven constraints on the albedo component. Our experiments show that when integrated into existing text-to-3D pipelines, our models significantly enhance the detail richness, achieving state-of-the-art results. Our project page is https://lingtengqiu.github.io/RichDreamer/.", "url": "https://arxiv.org/abs/2311.16918"}, {"metadata": {"arXiv": "2311.16922", "Date": "Tue, 28 Nov 2023 16:26:35 ", "Title": "Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding", "Authors": ["Sicong Leng", "Hang Zhang", "Guanzheng Chen", "Xin Li", "Shijian Lu", "Chunyan Miao", "Lidong Bing"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Large Vision-Language Models (LVLMs) have advanced considerably, intertwining visual recognition and language understanding to generate content that is not only coherent but also contextually attuned. Despite their success, LVLMs still suffer from the issue of object hallucinations, where models generate plausible yet incorrect outputs that include objects that do not exist in the images. To mitigate this issue, we introduce Visual Contrastive Decoding (VCD), a simple and training-free method that contrasts output distributions derived from original and distorted visual inputs. The proposed VCD effectively reduces the over-reliance on statistical bias and unimodal priors, two essential causes of object hallucinations. This adjustment ensures the generated content is closely grounded to visual inputs, resulting in contextually accurate outputs. Our experiments show that VCD, without either additional training or the usage of external tools, significantly mitigates the object hallucination issue across different LVLM families. Beyond mitigating object hallucinations, VCD also excels in general LVLM benchmarks, highlighting its wide-ranging applicability.", "url": "https://arxiv.org/abs/2311.16922"}, {"metadata": {"arXiv": "2311.17041", "Date": "Tue, 28 Nov 2023 18:53:06 ", "Title": "Efficient In-Context Learning in Vision-Language Models for Egocentric Videos", "Authors": ["Keunwoo Peter Yu", "Zheyuan Zhang", "Fengyuan Hu", "Joyce Chai"], "Categories": "cs.CV cs.AI cs.CL"}, "abstract": "Recent advancements in text-only large language models (LLMs) have highlighted the benefit of in-context learning for adapting to new tasks with a few demonstrations. However, extending in-context learning to large vision-language models (VLMs) using a huge amount of naturalistic vision-language data has shown limited success, particularly for egocentric videos, due to high data collection costs. We propose a novel training method $\\mathbb{E}$fficient $\\mathbb{I}$n-context $\\mathbb{L}$earning on $\\mathbb{E}$gocentric $\\mathbb{V}$ideos ($\\mathbb{EILEV}$), which elicits in-context learning in VLMs for egocentric videos without requiring massive, naturalistic egocentric video datasets. $\\mathbb{EILEV}$ involves architectural and training data adaptations to allow the model to process contexts interleaved with video clips and narrations, sampling of in-context examples with clusters of similar verbs and nouns, use of data with skewed marginal distributions with a long tail of infrequent verbs and nouns, as well as homonyms and synonyms. Our evaluations show that $\\mathbb{EILEV}$-trained models outperform larger VLMs trained on a huge amount of naturalistic data in in-context learning. Furthermore, they can generalize to not only out-of-distribution, but also novel, rare egocentric videos and texts via in-context learning, demonstrating potential for applications requiring cost-effective training, and rapid post-deployment adaptability. Our code and demo are available at \\url{https://github.com/yukw777/EILEV}.", "url": "https://arxiv.org/abs/2311.17041"}, {"metadata": {"arXiv": "2311.17058", "Date": "Tue, 28 Nov 2023 18:59:57 ", "Title": "Panoptic Video Scene Graph Generation", "Authors": ["Jingkang Yang", "Wenxuan Peng", "Xiangtai Li", "Zujin Guo", "Liangyu Chen", "Bo Li", "Zheng Ma", "Kaiyang Zhou", "Wayne Zhang", "Chen Change Loy", "Ziwei Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to CVPR 2023. Project Page: https://jingkang50.github.io/PVSG/. Codebase: https://github.com/LilyDaytoy/OpenPVSG. We provide 400 long videos with frame-level panoptic segmentation", "scene graph", "dense captions", "and QA annotations"]}, "abstract": "Towards building comprehensive real-world visual perception systems, we propose and study a new problem called panoptic scene graph generation (PVSG). PVSG relates to the existing video scene graph generation (VidSGG) problem, which focuses on temporal interactions between humans and objects grounded with bounding boxes in videos. However, the limitation of bounding boxes in detecting non-rigid objects and backgrounds often causes VidSGG to miss key details crucial for comprehensive video understanding. In contrast, PVSG requires nodes in scene graphs to be grounded by more precise, pixel-level segmentation masks, which facilitate holistic scene understanding. To advance research in this new area, we contribute the PVSG dataset, which consists of 400 videos (289 third-person + 111 egocentric videos) with a total of 150K frames labeled with panoptic segmentation masks as well as fine, temporal scene graphs. We also provide a variety of baseline methods and share useful design practices for future work.", "url": "https://arxiv.org/abs/2311.17058"}, {"metadata": {"arXiv": "2311.16392", "Date": "Tue, 28 Nov 2023 00:39:02 ", "Title": "Multi-defender Security Games with Schedules", "Authors": ["Zimeng Song", "Chun Kai Ling", "Fei Fang"], "Categories": "cs.GT cs.AI", "Comments": ["Extended version of the paper accepted to GameSec 2023"]}, "abstract": "Stackelberg Security Games are often used to model strategic interactions in high-stakes security settings. The majority of existing models focus on single-defender settings where a single entity assumes command of all security assets. However, many realistic scenarios feature multiple heterogeneous defenders with their own interests and priorities embedded in a more complex system. Furthermore, defenders rarely choose targets to protect. Instead, they have a multitude of defensive resources or schedules at its disposal, each with different protective capabilities. In this paper, we study security games featuring multiple defenders and schedules simultaneously. We show that unlike prior work on multi-defender security games, the introduction of schedules can cause non-existence of equilibrium even under rather restricted environments. We prove that under the mild restriction that any subset of a schedule is also a schedule, non-existence of equilibrium is not only avoided, but can be computed in polynomial time in games with two defenders. Under additional assumptions, our algorithm can be extended to games with more than two defenders and its computation scaled up in special classes of games with compactly represented schedules such as those used in patrolling applications. Experimental results suggest that our methods scale gracefully with game size, making our algorithms amongst the few that can tackle multiple heterogeneous defenders.", "url": "https://arxiv.org/abs/2311.16392"}, {"metadata": {"arXiv": "2311.16137", "Date": "Fri, 03 Nov 2023 15:44:28 ", "Title": "A Graph-to-Text Approach to Knowledge-Grounded Response Generation in Human-Robot Interaction", "Authors": ["Nicholas Thomas Walker", "Stefan Ultes", "Pierre Lison"], "Categories": "cs.RO cs.AI", "Comments": ["Submitted to Dialogue & Discourse 2023"]}, "abstract": "Knowledge graphs are often used to represent structured information in a flexible and efficient manner, but their use in situated dialogue remains under-explored. This paper presents a novel conversational model for human--robot interaction that rests upon a graph-based representation of the dialogue state. The knowledge graph representing the dialogue state is continuously updated with new observations from the robot sensors, including linguistic, situated and multimodal inputs, and is further enriched by other modules, in particular for spatial understanding. The neural conversational model employed to respond to user utterances relies on a simple but effective graph-to-text mechanism that traverses the dialogue state graph and converts the traversals into a natural language form. This conversion of the state graph into text is performed using a set of parameterized functions, and the values for those parameters are optimized based on a small set of Wizard-of-Oz interactions. After this conversion, the text representation of the dialogue state graph is included as part of the prompt of a large language model used to decode the agent response. The proposed approach is empirically evaluated through a user study with a humanoid robot that acts as conversation partner to evaluate the impact of the graph-to-text mechanism on the response generation. After moving a robot along a tour of an indoor environment, participants interacted with the robot using spoken dialogue and evaluated how well the robot was able to answer questions about what the robot observed during the tour. User scores show a statistically significant improvement in the perceived factuality of the robot responses when the graph-to-text approach is employed, compared to a baseline using inputs structured as semantic triples.", "url": "https://arxiv.org/abs/2311.16137"}, {"metadata": {"arXiv": "2311.16680", "Date": "Tue, 28 Nov 2023 10:52:35 ", "Title": "ROSO: Improving Robotic Policy Inference via Synthetic Observations", "Authors": ["Yusuke Miyashita", "Dimitris Gahtidis", "Colin La", "Jeremy Rabinowicz", "Juxi Leitner"], "Categories": "cs.RO cs.AI", "Comments": ["ACRA 2023 Oral"]}, "abstract": "In this paper, we propose the use of generative artificial intelligence (AI) to improve zero-shot performance of a pre-trained policy by altering observations during inference. Modern robotic systems, powered by advanced neural networks, have demonstrated remarkable capabilities on pre-trained tasks. However, generalizing and adapting to new objects and environments is challenging, and fine-tuning visuomotor policies is time-consuming. To overcome these issues we propose Robotic Policy Inference via Synthetic Observations (ROSO). ROSO uses stable diffusion to pre-process a robot's observation of novel objects during inference time to fit within its distribution of observations of the pre-trained policies. This novel paradigm allows us to transfer learned knowledge from known tasks to previously unseen scenarios, enhancing the robot's adaptability without requiring lengthy fine-tuning. Our experiments show that incorporating generative AI into robotic inference significantly improves successful outcomes, finishing up to 57% of tasks otherwise unsuccessful with the pre-trained policy.", "url": "https://arxiv.org/abs/2311.16680"}, {"metadata": {"arXiv": "2311.16841", "Date": "Tue, 28 Nov 2023 14:55:50 ", "Title": "Two-step dynamic obstacle avoidance", "Authors": ["Fabian Hart", "Martin Waltz", "Ostap Okhrin"], "Categories": "cs.RO cs.AI"}, "abstract": "Dynamic obstacle avoidance (DOA) is a fundamental challenge for any autonomous vehicle, independent of whether it operates in sea, air, or land. This paper proposes a two-step architecture for handling DOA tasks by combining supervised and reinforcement learning (RL). In the first step, we introduce a data-driven approach to estimate the collision risk of an obstacle using a recurrent neural network, which is trained in a supervised fashion and offers robustness to non-linear obstacle movements. In the second step, we include these collision risk estimates into the observation space of an RL agent to increase its situational awareness.~We illustrate the power of our two-step approach by training different RL agents in a challenging environment that requires to navigate amid multiple obstacles. The non-linear movements of obstacles are exemplarily modeled based on stochastic processes and periodic patterns, although our architecture is suitable for any obstacle dynamics. The experiments reveal that integrating our collision risk metrics into the observation space doubles the performance in terms of reward, which is equivalent to halving the number of collisions in the considered environment. Furthermore, we show that the architecture's performance improvement is independent of the applied RL algorithm.", "url": "https://arxiv.org/abs/2311.16841"}, {"metadata": {"arXiv": "2311.16895", "Date": "Tue, 28 Nov 2023 15:49:29 ", "Title": "Optimization Theory Based Deep Reinforcement Learning for Resource Allocation in Ultra-Reliable Wireless Networked Control Systems", "Authors": ["Hamida Qumber Ali", "Amirhassan Babazadeh Darabi", "Sinem Coleri"], "Categories": "eess.SY cs.AI cs.IT cs.SY math.IT", "Comments": ["13 pages", "11 figures"]}, "abstract": "The design of Wireless Networked Control System (WNCS) requires addressing critical interactions between control and communication systems with minimal complexity and communication overhead while providing ultra-high reliability. This paper introduces a novel optimization theory based deep reinforcement learning (DRL) framework for the joint design of controller and communication systems. The objective of minimum power consumption is targeted while satisfying the schedulability and rate constraints of the communication system in the finite blocklength regime and stability constraint of the control system. Decision variables include the sampling period in the control system, and blocklength and packet error probability in the communication system. The proposed framework contains two stages: optimization theory and DRL. In the optimization theory stage, following the formulation of the joint optimization problem, optimality conditions are derived to find the mathematical relations between the optimal values of the decision variables. These relations allow the decomposition of the problem into multiple building blocks. In the DRL stage, the blocks that are simplified but not tractable are replaced by DRL. Via extensive simulations, the proposed optimization theory based DRL approach is demonstrated to outperform the optimization theory and pure DRL based approaches, with close to optimal performance and much lower complexity.", "url": "https://arxiv.org/abs/2311.16895"}, {"metadata": {"arXiv": "2311.16171", "Date": "Mon, 20 Nov 2023 10:32:28 ", "Title": "Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce", "Authors": ["Omkar Shelke and Pranavi Pathakota and Anandsingh Chauhan and Harshad Khadilkar and Hardik Meisheri and Balaraman Ravindran"], "Categories": "cs.AI cs.LG cs.MA"}, "abstract": "This paper presents an integrated algorithmic framework for minimising product delivery costs in e-commerce (known as the cost-to-serve or C2S). One of the major challenges in e-commerce is the large volume of spatio-temporally diverse orders from multiple customers, each of which has to be fulfilled from one of several warehouses using a fleet of vehicles. This results in two levels of decision-making: (i) selection of a fulfillment node for each order (including the option of deferral to a future time), and then (ii) routing of vehicles (each of which can carry multiple orders originating from the same warehouse). We propose an approach that combines graph neural networks and reinforcement learning to train the node selection and vehicle routing agents. We include real-world constraints such as warehouse inventory capacity, vehicle characteristics such as travel times, service times, carrying capacity, and customer constraints including time windows for delivery. The complexity of this problem arises from the fact that outcomes (rewards) are driven both by the fulfillment node mapping as well as the routing algorithms, and are spatio-temporally distributed. Our experiments show that this algorithmic pipeline outperforms pure heuristic policies.", "url": "https://arxiv.org/abs/2311.16171"}, {"metadata": {"arXiv": "2311.16173", "Date": "Wed, 22 Nov 2023 03:36:18 ", "Title": "Conditions for Length Generalization in Learning Reasoning Skills", "Authors": ["Changnan Xiao and Bing Liu"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "Reasoning is a fundamental capability of AI agents. Recently, large language models (LLMs) have shown remarkable abilities to perform reasoning tasks. However, numerous evaluations of the reasoning capabilities of LLMs have also showed some limitations. An outstanding limitation is length generalization, meaning that when trained on reasoning problems of smaller lengths or sizes, the resulting models struggle with problems of larger sizes or lengths. This potentially indicates some theoretical limitations of generalization in learning reasoning skills. These evaluations and their observations motivated us to perform a theoretical study of the length generalization problem. This work focused on reasoning tasks that can be formulated as Markov dynamic processes (MDPs) and/or directed acyclic graphs (DAGs). It identifies and proves conditions that decide whether the length generalization problem can be solved or not for a reasoning task in a particular representation. Experiments are also conducted to verify the theoretical results.", "url": "https://arxiv.org/abs/2311.16173"}, {"metadata": {"arXiv": "2311.16683", "Date": "Tue, 28 Nov 2023 10:55:00 ", "Title": "Hyper-Relational Knowledge Graph Neural Network for Next POI", "Authors": ["Jixiao Zhang", "Yongkang Li", "Ruotong Zou", "Jingyuan Zhang", "Zipei Fan", "Xuan Song"], "Categories": "cs.AI cs.IR cs.LG"}, "abstract": "With the advancement of mobile technology, Point of Interest (POI) recommendation systems in Location-based Social Networks (LBSN) have brought numerous benefits to both users and companies. Many existing works employ Knowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These approaches primarily focus on modeling the pair-wise relations in LBSN to enrich the semantics and thereby relieve the data sparsity issue. However, existing approaches seldom consider the hyper-relations in LBSN, such as the mobility relation (a 3-ary relation: user-POI-time). This makes the model hard to exploit the semantics accurately. In addition, prior works overlook the rich structural information inherent in KG, which consists of higher-order relations and can further alleviate the impact of data sparsity.To this end, we propose a Hyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a Hyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed to maintain and exploit the rich semantics of hyper-relations. Then we proposed a Hypergraph Neural Network to utilize the structural information of HKG in a cohesive way. In addition, a self-attention network is used to leverage sequential information and make personalized recommendations. Furthermore, side information, essential in reducing data sparsity by providing background knowledge of POIs, is not fully utilized in current methods. In light of this, we extended the current dataset with available side information to further lessen the impact of data sparsity. Results of experiments on four real-world LBSN datasets demonstrate the effectiveness of our approach compared to existing state-of-the-art methods.", "url": "https://arxiv.org/abs/2311.16683"}, {"metadata": {"arXiv": "2311.16109", "Date": "Mon, 04 Sep 2023 20:58:57 ", "Title": "Transfer Learning between Motor Imagery Datasets using Deep Learning -- Validation of Framework and Comparison of Datasets", "Authors": ["Pierre Guetschel", "Michael Tangermann"], "Categories": "cs.CV cs.AI cs.HC cs.LG", "Comments": ["Keywords: EEG", "BCI", "Motor Imagery", "Deep Learning", "Transfer Learning", "Cross-Dataset. 3 figures", "2 tables"]}, "abstract": "We present a simple deep learning-based framework commonly used in computer vision and demonstrate its effectiveness for cross-dataset transfer learning in mental imagery decoding tasks that are common in the field of Brain-Computer Interfaces (BCI). We investigate, on a large selection of 12 motor-imagery datasets, which ones are well suited for transfer, both as donors and as receivers. Challenges. Deep learning models typically require long training times and are data-hungry, which impedes their use for BCI systems that have to minimize the recording time for (training) examples and are subject to constraints induced by experiments involving human subjects. A solution to both issues is transfer learning, but it comes with its own challenge, i.e., substantial data distribution shifts between datasets, subjects and even between subsequent sessions of the same subject. Approach. For every pair of pre-training (donor) and test (receiver) dataset, we first train a model on the donor before training merely an additional new linear classification layer based on a few receiver trials. Performance of this transfer approach is then tested on other trials of the receiver dataset. Significance. First, we lower the threshold to use transfer learning between motor imagery datasets: the overall framework is extremely simple and nevertheless obtains decent classification scores. Second, we demonstrate that deep learning models are a good option for motor imagery cross-dataset transfer both for the reasons outlined in the first point and because the framework presented is viable in online scenarios. Finally, analysing which datasets are best suited for transfer learning can be used as a reference for future researchers to determine which to use for pre-training or benchmarking.", "url": "https://arxiv.org/abs/2311.16109"}, {"metadata": {"arXiv": "2311.16114", "Date": "Thu, 21 Sep 2023 10:49:02 ", "Title": "Learning Noise-Robust Joint Representation for Multimodal Emotion Recognition under Realistic Incomplete Data Scenarios", "Authors": ["Qi Fan (1)", "Haolin Zuo (1)", "Rui Liu (1)", "Zheng Lian (2) and Guanglai Gao (1) ((1) Inner Mongolia University", "Hohhot", "China", "(2) Institute of Automation", "Chinese Academy of Sciences", "Beijing", "China)"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Multimodal emotion recognition (MER) in practical scenarios presents a significant challenge due to the presence of incomplete data, such as missing or noisy data. Traditional methods often discard missing data or replace it with a zero vector, neglecting the availability issue of noisy data. Consequently, these approaches are not fully applicable to realistic scenarios, where both missing and noisy data are prevalent. To address this problem, we propose a novel noise-robust MER model, named NMER, which effectively learns robust multimodal joint representations from incomplete data containing noise. Our approach incorporates two key components. First, we introduce a noise scheduler that adjusts the type and level of noise in the training data, emulating the characteristics of incomplete data in realistic scenarios. Second, we employ a Variational AutoEncoder (VAE)-based NMER model to generate robust multimodal joint representations from the noisy data, leveraging the modality invariant feature. The experimental results on the benchmark dataset IEMOCAP indicate the proposed NMER outperforms state-of-the-art MER systems. The ablation results also confirm the effectiveness of the VAE structure. We release our code at \\href{https://github.com/WooyoohL/Noise-robust_MER.", "url": "https://arxiv.org/abs/2311.16114"}, {"metadata": {"arXiv": "2311.16122", "Date": "Thu, 26 Oct 2023 11:42:48 ", "Title": "Semantic Generative Augmentations for Few-Shot Counting", "Authors": ["Perla Doubinsky (CEDRIC - VERTIGO", "CNAM)", "Nicolas Audebert (CEDRIC - VERTIGO", "CNAM)", "Michel Crucianu (CEDRIC - VERTIGO)", "Herv\\'e Le Borgne (CEA)"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "With the availability of powerful text-to-image diffusion models, recent works have explored the use of synthetic data to improve image classification performances. These works show that it can effectively augment or even replace real data. In this work, we investigate how synthetic data can benefit few-shot class-agnostic counting. This requires to generate images that correspond to a given input number of objects. However, text-to-image models struggle to grasp the notion of count. We propose to rely on a double conditioning of Stable Diffusion with both a prompt and a density map in order to augment a training dataset for few-shot counting. Due to the small dataset size, the fine-tuned model tends to generate images close to the training images. We propose to enhance the diversity of synthesized images by exchanging captions between images thus creating unseen configurations of object types and spatial layout. Our experiments show that our diversified generation strategy significantly improves the counting accuracy of two recent and performing few-shot counting models on FSC147 and CARPK.", "url": "https://arxiv.org/abs/2311.16122"}, {"metadata": {"arXiv": "2311.16140", "Date": "Sat, 04 Nov 2023 14:20:08 ", "Title": "Adapting Segment Anything Model (SAM) through Prompt-based Learning for Enhanced Protein Identification in Cryo-EM Micrographs", "Authors": ["Fei He", "Zhiyuan Yang", "Mingyue Gao", "Biplab Poudel", "Newgin Sam Ebin Sam Dhas", "Rajan Gyawali", "Ashwin Dhakal", "Jianlin Cheng", "Dong Xu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet the task of protein particle picking, integral for 3D protein structure construction, is laden with manual inefficiencies. While recent AI tools such as Topaz and crYOLO are advancing the field, they do not fully address the challenges of cryo-EM images, including low contrast, complex shapes, and heterogeneous conformations. This study explored prompt-based learning to adapt the state-of-the-art image segmentation foundation model Segment Anything Model (SAM) for cryo-EM. This focus was driven by the desire to optimize model performance with a small number of labeled data without altering pre-trained parameters, aiming for a balance between adaptability and foundational knowledge retention. Through trials with three prompt-based learning strategies, namely head prompt, prefix prompt, and encoder prompt, we observed enhanced performance and reduced computational requirements compared to the fine-tuning approach. This work not only highlights the potential of prompting SAM in protein identification from cryo-EM micrographs but also suggests its broader promise in biomedical image segmentation and object detection.", "url": "https://arxiv.org/abs/2311.16140"}, {"metadata": {"arXiv": "2311.16201", "Date": "Mon, 27 Nov 2023 07:19:26 ", "Title": "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation", "Authors": ["Yuhui Zhang", "Brandon McKinzie", "Zhe Gan", "Vaishaal Shankar", "Alexander Toshev"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Recent advances in image tokenizers, such as VQ-VAE, have enabled text-to-image generation using auto-regressive methods, similar to language modeling. However, these methods have yet to leverage pre-trained language models, despite their adaptability to various downstream tasks. In this work, we explore this gap by adapting a pre-trained language model for auto-regressive text-to-image generation, and find that pre-trained language models offer limited help. We provide a two-fold explanation by analyzing tokens from each modality. First, we demonstrate that image tokens possess significantly different semantics compared to text tokens, rendering pre-trained language models no more effective in modeling them than randomly initialized ones. Second, the text tokens in the image-text datasets are too simple compared to normal language model pre-training data, which causes the catastrophic degradation of language models' capability.", "url": "https://arxiv.org/abs/2311.16201"}, {"metadata": {"arXiv": "2311.16312", "Date": "Mon, 27 Nov 2023 21:01:29 ", "Title": "Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer Detection", "Authors": ["Reza Basiri", "Milos R. Popovic", "Shehroz S. Khan"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["5 pages", "2 figures", "3 tables", "2022 IEEE International Conference on Data Mining Workshops"], "Journal-ref": "2022 IEEE International Conference on Data Mining Workshops. pp. 1-5", "DOI": "10.1109/icdmw58026.2022.00041"}, "abstract": "Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and evaluations for treatment. DFU patient population is on the rise and will soon outpace the available health resources. Autonomous monitoring and evaluation of DFU wounds is a much-needed area in health care. In this paper, we evaluate and identify the most accurate feature extractor that is the core basis for developing a deep-learning wound detection network. For the evaluation, we used mAP and F1-score on the publicly available DFU2020 dataset. A combination of UNet and EfficientNetb3 feature extractor resulted in the best evaluation among the 14 networks compared. UNet and Efficientnetb3 can be used as the classifier in the development of a comprehensive DFU domain-specific autonomous wound detection pipeline.", "url": "https://arxiv.org/abs/2311.16312"}, {"metadata": {"arXiv": "2311.16432", "Date": "Tue, 28 Nov 2023 02:27:31 ", "Title": "Text-Driven Image Editing via Learnable Regions", "Authors": ["Yuanze Lin", "Yi-Wen Chen", "Yi-Hsuan Tsai", "Lu Jiang", "Ming-Hsuan Yang"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project webpage: https://yuanze-lin.me/LearnableRegions_page"]}, "abstract": "Language has emerged as a natural interface for image editing. In this paper, we introduce a method for region-based image editing driven by textual prompts, without the need for user-provided masks or sketches. Specifically, our approach leverages an existing pretrained text-to-image model and introduces a bounding box generator to find the edit regions that are aligned with the textual prompts. We show that this simple approach enables flexible editing that is compatible with current image generation models, and is able to handle complex prompts featuring multiple objects, complex sentences or long paragraphs. We conduct an extensive user study to compare our method against state-of-the-art methods. Experiments demonstrate the competitive performance of our method in manipulating images with high fidelity and realism that align with the language descriptions provided. Our project webpage: https://yuanze-lin.me/LearnableRegions_page.", "url": "https://arxiv.org/abs/2311.16432"}, {"metadata": {"arXiv": "2311.16503", "Date": "Mon, 27 Nov 2023 12:59:52 ", "Title": "TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models", "Authors": ["Yushi Huang", "Ruihao Gong", "Jing Liu", "Tianlong Chen", "Xianglong Liu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "The Diffusion model, a prevalent framework for image generation, encounters significant challenges in terms of broad applicability due to its extended inference times and substantial memory requirements. Efficient Post-training Quantization (PTQ) is pivotal for addressing these issues in traditional models. Different from traditional models, diffusion models heavily depend on the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$ from the finite set $\\{1, \\ldots, T\\}$ is encoded to a temporal feature by a few modules totally irrespective of the sampling data. However, existing PTQ methods do not optimize these modules separately. They adopt inappropriate reconstruction targets and complex calibration methods, resulting in a severe disturbance of the temporal feature and denoising trajectory, as well as a low compression efficiency. To solve these, we propose a Temporal Feature Maintenance Quantization (TFMQ) framework building upon a Temporal Information Block which is just related to the time-step $t$ and unrelated to the sampling data. Powered by the pioneering block design, we devise temporal information aware reconstruction (TIAR) and finite set calibration (FSC) to align the full-precision temporal features in a limited time. Equipped with the framework, we can maintain the most temporal information and ensure the end-to-end generation quality. Extensive experiments on various datasets and diffusion models prove our state-of-the-art results. Remarkably, our quantization approach, for the first time, achieves model performance nearly on par with the full-precision model under 4-bit weight quantization. Additionally, our method incurs almost no extra computational cost and accelerates quantization time by $2.0 \\times$ on LSUN-Bedrooms $256 \\times 256$ compared to previous works.", "url": "https://arxiv.org/abs/2311.16503"}, {"metadata": {"arXiv": "2311.16514", "Date": "Mon, 27 Nov 2023 13:14:06 ", "Title": "Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation : A Unified Approach", "Authors": ["Ayush K. Rai", "Tarun Krishna", "Feiyan Hu", "Alexandru Drimbarean", "Kevin McGuinness", "Alan F. Smeaton", "Noel E. O'Connor"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["16 pages", "8 figures"]}, "abstract": "Video Anomaly Detection (VAD) is an open-set recognition task, which is usually formulated as a one-class classification (OCC) problem, where training data is comprised of videos with normal instances while test data contains both normal and anomalous instances. Recent works have investigated the creation of pseudo-anomalies (PAs) using only the normal data and making strong assumptions about real-world anomalies with regards to abnormality of objects and speed of motion to inject prior information about anomalies in an autoencoder (AE) based reconstruction model during training. This work proposes a novel method for generating generic spatio-temporal PAs by inpainting a masked out region of an image using a pre-trained Latent Diffusion Model and further perturbing the optical flow using mixup to emulate spatio-temporal distortions in the data. In addition, we present a simple unified framework to detect real-world anomalies under the OCC setting by learning three types of anomaly indicators, namely reconstruction quality, temporal irregularity and semantic inconsistency. Extensive experiments on four VAD benchmark datasets namely Ped2, Avenue, ShanghaiTech and UBnormal demonstrate that our method performs on par with other existing state-of-the-art PAs generation and reconstruction based methods under the OCC setting. Our analysis also examines the transferability and generalisation of PAs across these datasets, offering valuable insights by identifying real-world anomalies through PAs.", "url": "https://arxiv.org/abs/2311.16514"}, {"metadata": {"arXiv": "2311.16700", "Date": "Tue, 28 Nov 2023 11:22:08 ", "Title": "Rethinking Intermediate Layers design in Knowledge Distillation for Kidney and Liver Tumor Segmentation", "Authors": ["Vandan Gorade", "Sparsh Mittal", "Debesh Jha", "Ulas Bagci"], "Categories": "cs.CV cs.AI cs.LG q-bio.TO", "Comments": ["Under-review at ISBI-2024"]}, "abstract": "Knowledge distillation(KD) has demonstrated remarkable success across various domains, but its application to medical imaging tasks, such as kidney and liver tumor segmentation, has encountered challenges. Many existing KD methods are not specifically tailored for these tasks. Moreover, prevalent KD methods often lack a careful consideration of what and from where to distill knowledge from the teacher to the student. This oversight may lead to issues like the accumulation of training bias within shallower student layers, potentially compromising the effectiveness of KD. To address these challenges, we propose Hierarchical Layer-selective Feedback Distillation (HLFD). HLFD strategically distills knowledge from a combination of middle layers to earlier layers and transfers final layer knowledge to intermediate layers at both the feature and pixel levels. This design allows the model to learn higher-quality representations from earlier layers, resulting in a robust and compact student model. Extensive quantitative evaluations reveal that HLFD outperforms existing methods by a significant margin. For example, in the kidney segmentation task, HLFD surpasses the student model (without KD) by over 10pp, significantly improving its focus on tumor-specific features. From a qualitative standpoint, the student model trained using HLFD excels at suppressing irrelevant information and can focus sharply on tumor-specific details, which opens a new pathway for more efficient and accurate diagnostic tools.", "url": "https://arxiv.org/abs/2311.16700"}, {"metadata": {"arXiv": "2311.16711", "Date": "Tue, 28 Nov 2023 11:45:35 ", "Title": "LEDITS++: Limitless Image Editing using Text-to-Image Models", "Authors": ["Manuel Brack", "Felix Friedrich", "Katharina Kornmeier", "Linoy Tsaban", "Patrick Schramowski", "Kristian Kersting", "Apolin\\'ario Passos"], "Categories": "cs.CV cs.AI cs.HC cs.LG"}, "abstract": "Text-to-image diffusion models have recently received increasing interest for their astonishing ability to produce high-fidelity images from solely text inputs. Subsequent research efforts aim to exploit and apply their capabilities to real image editing. However, existing image-to-image methods are often inefficient, imprecise, and of limited versatility. They either require time-consuming fine-tuning, deviate unnecessarily strongly from the input image, and/or lack support for multiple, simultaneous edits. To address these issues, we introduce LEDITS++, an efficient yet versatile and precise textual image manipulation technique. LEDITS++'s novel inversion approach requires no tuning nor optimization and produces high-fidelity results with a few diffusion steps. Second, our methodology supports multiple simultaneous edits and is architecture-agnostic. Third, we use a novel implicit masking technique that limits changes to relevant image regions. We propose the novel TEdBench++ benchmark as part of our exhaustive evaluation. Our results demonstrate the capabilities of LEDITS++ and its improvements over previous methods. The project page is available at https://leditsplusplus-project.static.hf.space .", "url": "https://arxiv.org/abs/2311.16711"}, {"metadata": {"arXiv": "2311.16973", "Date": "Fri, 24 Nov 2023 00:16:00 ", "Title": "DemoFusion: Democratising High-Resolution Image Generation With No $$$", "Authors": ["Ruoyi Du", "Dongliang Chang", "Timothy Hospedales", "Yi-Zhe Song", "Zhanyu Ma"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "High-resolution image generation with Generative Artificial Intelligence (GenAI) has immense potential but, due to the enormous capital investment required for training, it is increasingly centralised to a few large corporations, and hidden behind paywalls. This paper aims to democratise high-resolution GenAI by advancing the frontier of high-resolution generation while remaining accessible to a broad audience. We demonstrate that existing Latent Diffusion Models (LDMs) possess untapped potential for higher-resolution image generation. Our novel DemoFusion framework seamlessly extends open-source GenAI models, employing Progressive Upscaling, Skip Residual, and Dilated Sampling mechanisms to achieve higher-resolution image generation. The progressive nature of DemoFusion requires more passes, but the intermediate results can serve as \"previews\", facilitating rapid prompt iteration.", "url": "https://arxiv.org/abs/2311.16973"}, {"metadata": {"arXiv": "2311.17026", "Date": "Tue, 28 Nov 2023 18:28:03 ", "Title": "When the Few Outweigh the Many: Illicit Content Recognition with Few-Shot Learning", "Authors": ["G. Cascavilla", "G. Catolino", "M. Conti", "D. Mellios", "D.A. Tamburri"], "Categories": "cs.CV cs.AI cs.CR cs.CY cs.LG", "Journal-ref": "In Proceedings of the 20th International Conference on Security and Cryptography - SECRYPT; 2023; ISBN 978-989-758-666-8; ISSN 2184-7711, pages 324-334", "DOI": "10.5220/0012049400003555"}, "abstract": "The anonymity and untraceability benefits of the Dark web account for the exponentially-increased potential of its popularity while creating a suitable womb for many illicit activities, to date. Hence, in collaboration with cybersecurity and law enforcement agencies, research has provided approaches for recognizing and classifying illicit activities with most exploiting textual dark web markets' content recognition; few such approaches use images that originated from dark web content. This paper investigates this alternative technique for recognizing illegal activities from images. In particular, we investigate label-agnostic learning techniques like One-Shot and Few-Shot learning featuring the use Siamese neural networks, a state-of-the-art approach in the field. Our solution manages to handle small-scale datasets with promising accuracy. In particular, Siamese neural networks reach 90.9% on 20-Shot experiments over a 10-class dataset; this leads us to conclude that such models are a promising and cheaper alternative to the definition of automated law-enforcing machinery over the dark web.", "url": "https://arxiv.org/abs/2311.17026"}, {"metadata": {"arXiv": "2311.17055", "Date": "Tue, 28 Nov 2023 18:59:46 ", "Title": "No Representation Rules Them All in Category Discovery", "Authors": ["Sagar Vaze", "Andrea Vedaldi", "Andrew Zisserman"], "Categories": "cs.CV cs.AI cs.IT cs.LG math.IT", "Comments": ["NeurIPS 2023"]}, "abstract": "In this paper we tackle the problem of Generalized Category Discovery (GCD). Specifically, given a dataset with labelled and unlabelled images, the task is to cluster all images in the unlabelled subset, whether or not they belong to the labelled categories. Our first contribution is to recognize that most existing GCD benchmarks only contain labels for a single clustering of the data, making it difficult to ascertain whether models are using the available labels to solve the GCD task, or simply solving an unsupervised clustering problem. As such, we present a synthetic dataset, named 'Clevr-4', for category discovery. Clevr-4 contains four equally valid partitions of the data, i.e based on object shape, texture, color or count. To solve the task, models are required to extrapolate the taxonomy specified by the labelled set, rather than simply latching onto a single natural grouping of the data. We use this dataset to demonstrate the limitations of unsupervised clustering in the GCD setting, showing that even very strong unsupervised models fail on Clevr-4. We further use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a new method which addresses these shortcomings, leveraging consistent findings from the representation learning literature to do so. Our simple solution, which is based on 'mean teachers' and termed $\\mu$GCD, substantially outperforms implemented baselines on Clevr-4. Finally, when we transfer these findings to real data on the challenging Semantic Shift Benchmark (SSB), we find that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art. For the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/", "url": "https://arxiv.org/abs/2311.17055"}, {"metadata": {"arXiv": "2311.16158", "Date": "Thu, 09 Nov 2023 01:21:19 ", "Title": "CarbNN: A Novel Active Transfer Learning Neural Network To Build De Novo Metal Organic Frameworks (MOFs) for Carbon Capture", "Authors": ["Neel Redkar"], "Categories": "cs.LG cs.AI", "Comments": ["13 pages", "12 figures", "presented at AAAI-23 orally & as a poster"], "MSC-class": "8.2.D.2.5"}, "abstract": "Over the past decade, climate change has become an increasing problem with one of the major contributing factors being carbon dioxide (CO2) emissions; almost 51% of total US carbon emissions are from factories. Current materials used in CO2 capture are lacking either in efficiency, sustainability, or cost. Electrocatalysis of CO2 is a new approach where CO2 can be reduced and the components used industrially as fuel, saving transportation costs, creating financial incentives. Metal Organic Frameworks (MOFs) are crystals made of organo-metals that adsorb, filter, and electrocatalyze CO2. The current available MOFs for capture & electrocatalysis are expensive to manufacture and inefficient at capture. The goal therefore is to computationally design a MOF that can adsorb CO2 and catalyze carbon monoxide & oxygen with low cost. A novel active transfer learning neural network was developed, utilizing transfer learning due to limited available data on 15 MOFs. Using the Cambridge Structural Database with 10,000 MOFs, the model used incremental mutations to fit a trained fitness hyper-heuristic function. Eventually, a Selenium MOF (C18MgO25Se11Sn20Zn5) was converged on. Through analysis of predictions & literature, the converged MOF was shown to be more effective & more synthetically accessible than existing MOFs, showing the model had an understanding of effective electrocatalytic structures in the material space. This novel network can be implemented for other gas separations and catalysis applications that have limited training accessible datasets.", "url": "https://arxiv.org/abs/2311.16158"}, {"metadata": {"arXiv": "2311.16176", "Date": "Thu, 23 Nov 2023 15:47:33 ", "Title": "Shortcut Bias Mitigation via Ensemble Diversity Using Diffusion Probabilistic Models", "Authors": ["Luca Scimeca", "Alexander Rubinstein", "Damien Teney", "Seong Joon Oh", "Armand Mihai Nicolicioiu", "Yoshua Bengio"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2310.02230"]}, "abstract": "Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as simplicity bias, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on images displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on primary shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalization and diversification performance on par with prior work that relies on auxiliary data collection.", "url": "https://arxiv.org/abs/2311.16176"}, {"metadata": {"arXiv": "2311.16180", "Date": "Sat, 25 Nov 2023 02:05:39 ", "Title": "Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence", "Authors": ["Tejas Venkateswaran", "Sheikh Rabiul Islam", "Md Golam Moula Mehedi Hasan", "and Mohiuddin Ahmed"], "Categories": "cs.LG cs.AI cs.CY", "Comments": ["IEEE Big Data 2023"]}, "abstract": "Approximately 30% of all traffic fatalities in the United States are attributed to alcohol-impaired driving. This means that, despite stringent laws against this offense in every state, the frequency of drunk driving accidents is alarming, resulting in approximately one person being killed every 45 minutes. The process of charging individuals with Driving Under the Influence (DUI) is intricate and can sometimes be subjective, involving multiple stages such as observing the vehicle in motion, interacting with the driver, and conducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed through racial profiling, leading to some groups and geographical areas facing fewer DUI tests, resulting in many actual DUI incidents going undetected, ultimately leading to a higher number of fatalities. To tackle this issue, our research introduces an Artificial Intelligence-based predictor that is both fairness-aware and incorporates domain knowledge to analyze DUI-related fatalities in different geographic locations. Through this model, we gain intriguing insights into the interplay between various demographic groups, including age, race, and income. By utilizing the provided information to allocate policing resources in a more equitable and efficient manner, there is potential to reduce DUI-related fatalities and have a significant impact on road safety.", "url": "https://arxiv.org/abs/2311.16180"}, {"metadata": {"arXiv": "2311.16185", "Date": "Sat, 25 Nov 2023 18:20:43 ", "Title": "Enhancing Sentiment Analysis Results through Outlier Detection Optimization", "Authors": ["Yuetian Chen and Mei Si"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["11 pages", "5 figures"]}, "abstract": "When dealing with text data containing subjective labels like speaker emotions, inaccuracies or discrepancies among labelers are not uncommon. Such discrepancies can significantly affect the performance of machine learning algorithms. This study investigates the potential of identifying and addressing outliers in text data with subjective labels, aiming to enhance classification outcomes. We utilized the Deep SVDD algorithm, a one-class classification method, to detect outliers in nine text-based emotion and sentiment analysis datasets. By employing both a small-sized language model (DistilBERT base model with 66 million parameters) and non-deep learning machine learning algorithms (decision tree, KNN, Logistic Regression, and LDA) as the classifier, our findings suggest that the removal of outliers can lead to enhanced results in most cases. Additionally, as outliers in such datasets are not necessarily unlearnable, we experienced utilizing a large language model -- DeBERTa v3 large with 131 million parameters, which can capture very complex patterns in data. We continued to observe performance enhancements across multiple datasets.", "url": "https://arxiv.org/abs/2311.16185"}, {"metadata": {"arXiv": "2311.16191", "Date": "Sun, 26 Nov 2023 03:31:43 ", "Title": "MACE: A Multi-pattern Accommodated and Efficient Anomaly Detection Method in the Frequency Domain", "Authors": ["Feiyi Chen", "Yingying zhang", "Zhen Qin", "Lunting Fan", "Renhe Jiang", "Yuxuan Liang", "Qingsong Wen", "Shuiguang Deng"], "Categories": "cs.LG cs.AI"}, "abstract": "Anomaly detection significantly enhances the robustness of cloud systems. While neural network-based methods have recently demonstrated strong advantages, they encounter practical challenges in cloud environments: the contradiction between the impracticality of maintaining a unique model for each service and the limited ability of dealing with diverse normal patterns by a unified model, as well as issues with handling heavy traffic in real time and short-term anomaly detection sensitivity. Thus, we propose MACE, a Multi-pattern Accommodated and efficient Anomaly detection method in the frequency domain for time series anomaly detection. There are three novel characteristics of it: (i) a pattern extraction mechanism excelling at handling diverse normal patterns, which enables the model to identify anomalies by examining the correlation between the data sample and its service normal pattern, instead of solely focusing on the data sample itself; (ii) a dualistic convolution mechanism that amplifies short-term anomalies in the time domain and hinders the reconstruction of anomalies in the frequency domain, which enlarges the reconstruction error disparity between anomaly and normality and facilitates anomaly detection; (iii) leveraging the sparsity and parallelism of frequency domain to enhance model efficiency. We theoretically and experimentally prove that using a strategically selected subset of Fourier bases can not only reduce computational overhead but is also profit to distinguish anomalies, compared to using the complete spectrum. Moreover, extensive experiments demonstrate MACE's effectiveness in handling diverse normal patterns with a unified model and it achieves state-of-the-art performance with high efficiency. \\end{abstract}", "url": "https://arxiv.org/abs/2311.16191"}, {"metadata": {"arXiv": "2311.16192", "Date": "Sun, 26 Nov 2023 09:50:32 ", "Title": "Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining Useful Life Prediction", "Authors": ["Junliang Wang", "Qinghua Zhang", "Guanhua Zhu", "Guoxi Sun"], "Categories": "cs.LG cs.AI eess.SP"}, "abstract": "Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is crucial in industrial production, yet existing models often struggle with limited generalization capabilities due to their inability to fully process all vibration signal patterns. We introduce a novel multi-input autoregressive model to address this challenge in RUL prediction for bearings. Our approach uniquely integrates vibration signals with previously predicted Health Indicator (HI) values, employing feature fusion to output current window HI values. Through autoregressive iterations, the model attains a global receptive field, effectively overcoming the limitations in generalization. Furthermore, we innovatively incorporate a segmentation method and multiple training iterations to mitigate error accumulation in autoregressive models. Empirical evaluation on the PMH2012 dataset demonstrates that our model, compared to other backbone networks using similar autoregressive approaches, achieves significantly lower Root Mean Square Error (RMSE) and Score. Notably, it outperforms traditional autoregressive models that use label values as inputs and non-autoregressive networks, showing superior generalization abilities with a marked lead in RMSE and Score metrics.", "url": "https://arxiv.org/abs/2311.16192"}, {"metadata": {"arXiv": "2311.16195", "Date": "Sun, 26 Nov 2023 14:42:31 ", "Title": "A Foundational Framework and Methodology for Personalized Early and Timely Diagnosis", "Authors": ["Tim Schubert", "Richard W Peck", "Alexander Gimson", "Camelia Davtyan", "Mihaela van der Schaar"], "Categories": "cs.LG cs.AI", "Comments": ["10 pages", "2 figures"]}, "abstract": "Early diagnosis of diseases holds the potential for deep transformation in healthcare by enabling better treatment options, improving long-term survival and quality of life, and reducing overall cost. With the advent of medical big data, advances in diagnostic tests as well as in machine learning and statistics, early or timely diagnosis seems within reach. Early diagnosis research often neglects the potential for optimizing individual diagnostic paths. To enable personalized early diagnosis, a foundational framework is needed that delineates the diagnosis process and systematically identifies the time-dependent value of various diagnostic tests for an individual patient given their unique characteristics. Here, we propose the first foundational framework for early and timely diagnosis. It builds on decision-theoretic approaches to outline the diagnosis process and integrates machine learning and statistical methodology for estimating the optimal personalized diagnostic path. To describe the proposed framework as well as possibly other frameworks, we provide essential definitions. The development of a foundational framework is necessary for several reasons: 1) formalism provides clarity for the development of decision support tools; 2) observed information can be complemented with estimates of the future patient trajectory; 3) the net benefit of counterfactual diagnostic paths and associated uncertainties can be modeled for individuals 4) 'early' and 'timely' diagnosis can be clearly defined; 5) a mechanism emerges for assessing the value of technologies in terms of their impact on personalized early diagnosis, resulting health outcomes and incurred costs. Finally, we hope that this foundational framework will unlock the long-awaited potential of timely diagnosis and intervention, leading to improved outcomes for patients and higher cost-effectiveness for healthcare systems.", "url": "https://arxiv.org/abs/2311.16195"}, {"metadata": {"arXiv": "2311.16203", "Date": "Mon, 27 Nov 2023 08:52:10 ", "Title": "ChatTraffc: Text-to-Traffic Generation via Diffusion Model", "Authors": ["Chengyang Zhang", "Yong Zhang", "Qitan Shao", "Bo Li", "Yisheng Lv", "Xinglin Piao", "Baocai Yin"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Traffic prediction is one of the most significant foundations in Intelligent Transportation Systems (ITS). Traditional traffic prediction methods rely only on historical traffic data to predict traffic trends and face two main challenges. 1) insensitivity to unusual events. 2) poor performance in long-term prediction. In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic generation and name the task Text-to-Traffic Generation (TTG). The key challenge of the TTG task is how to associate text with the spatial structure of the road network and traffic data for generating traffic situations. To this end, we propose ChatTraffic, the first diffusion model for text-to-traffic generation. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network (GCN) to extract spatial correlations of traffic data. In addition, we construct a large dataset containing text-traffic pairs for the TTG task. We benchmarked our model qualitatively and quantitatively on the released dataset. The experimental results indicate that ChatTraffic can generate realistic traffic situations from the text. Our code and dataset are available at https://github.com/ChyaZhang/ChatTraffic.", "url": "https://arxiv.org/abs/2311.16203"}, {"metadata": {"arXiv": "2311.16206", "Date": "Mon, 27 Nov 2023 15:04:48 ", "Title": "Continual Instruction Tuning for Large Multimodal Models", "Authors": ["Jinghan He", "Haiyun Guo", "Ming Tang", "Jinqiao Wang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Instruction tuning is now a widely adopted approach to aligning large multimodal models (LMMs) to follow human intent. It unifies the data format of vision-language tasks, enabling multi-task joint training. However, vision-language tasks are constantly being created in practice. Instead of always re-training LMMs when new tasks arrive, continual learning offers flexibility for models to continually and efficiently exploit the evolving data. This work aims to explore the following two questions: 1) Do LMMs still suffer from catastrophic forgetting in continual instruction tuning? 2) Are the existing three classes of continual learning methods still applicable to the continual instruction tuning of LMMs? An extensive study is conducted to address the above questions. First, we establish the first benchmark in this setting and reveal that catastrophic forgetting is still observed when continually instruction-tuning LMMs. However, the multi-task joint instruction tuning can facilitate the model's continual learning ability and mitigate forgetting. Second, we integrate and adapt classic continual learning methods to our context, demonstrating the efficacy of data replay and model expansion strategies across diverse scenarios. In contrast, regularization-based methods only perform well on models that have been jointly instruction-tuned on multiple tasks. Third, we delve into the correlation and forgetting dynamics between vision-language task pairs and propose task-similarity-informed regularization and model expansion methods for continual instruction tuning of LMMs. Experimental results show that our approach consistently boosts the model's performance.", "url": "https://arxiv.org/abs/2311.16206"}, {"metadata": {"arXiv": "2311.16277", "Date": "Mon, 27 Nov 2023 19:33:14 ", "Title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss Function for Combinatorial Optimization using Reinforcement Learning", "Authors": ["Redwan Ahmed Rizvee", "Raheeb Hasan and Md. Mosaddek Khan"], "Categories": "cs.LG cs.AI"}, "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard Combinatorial Optimization problems (CO) in the form of binary variables. Ising Hamiltonian is used to model the energy function of a system. QUBO to Ising Hamiltonian is regarded as a technique to solve various canonical optimization problems through quantum optimization algorithms. Recently, PI-GNN, a generic framework, has been proposed to address CO problems over graphs based on Graph Neural Network (GNN) architecture. They introduced a generic QUBO-formulated Hamiltonian-inspired loss function that was directly optimized using GNN. PI-GNN is highly scalable but there lies a noticeable decrease in the number of satisfied constraints when compared to problem-specific algorithms and becomes more pronounced with increased graph densities. Here, We identify a behavioral pattern related to it and devise strategies to improve its performance. Another group of literature uses Reinforcement learning (RL) to solve the aforementioned NP-hard problems using problem-specific reward functions. In this work, we also focus on creating a bridge between the RL-based solutions and the QUBO-formulated Hamiltonian. We formulate and empirically evaluate the compatibility of the QUBO-formulated Hamiltonian as the generic reward function in the RL-based paradigm in the form of rewards. Furthermore, we also introduce a novel Monty Carlo Tree Search-based strategy with GNN where we apply a guided search through manual perturbation of node labels during training. We empirically evaluated our methods and observed up to 44% improvement in the number of constraint violations compared to the PI-GNN.", "url": "https://arxiv.org/abs/2311.16277"}, {"metadata": {"arXiv": "2311.16339", "Date": "Mon, 27 Nov 2023 21:56:18 ", "Title": "Reward Shaping for Improved Learning in Real-time Strategy Game Play", "Authors": ["John Kliem and Prithviraj Dasgupta"], "Categories": "cs.LG cs.AI", "Comments": ["15 pages 11 figures and 5 tables"], "ACM-class": "I.2.6"}, "abstract": "We investigate the effect of reward shaping in improving the performance of reinforcement learning in the context of the real-time strategy, capture-the-flag game. The game is characterized by sparse rewards that are associated with infrequently occurring events such as grabbing or capturing the flag, or tagging the opposing player. We show that appropriately designed reward shaping functions applied to different game events can significantly improve the player's performance and training times of the player's learning algorithm. We have validated our reward shaping functions within a simulated environment for playing a marine capture-the-flag game between two players. Our experimental results demonstrate that reward shaping can be used as an effective means to understand the importance of different sub-tasks during game-play towards winning the game, to encode a secondary objective functions such as energy efficiency into a player's game-playing behavior, and, to improve learning generalizable policies that can perform well against different skill levels of the opponent.", "url": "https://arxiv.org/abs/2311.16339"}, {"metadata": {"arXiv": "2311.16353", "Date": "Mon, 27 Nov 2023 22:30:26 ", "Title": "Improving Denoising Diffusion Probabilistic Models via Exploiting Shared Representations", "Authors": ["Delaram Pirhayatifard", "Mohammad Taha Toghani", "Guha Balakrishnan", "C\\'esar A. Uribe"], "Categories": "cs.LG cs.AI cs.CV eess.IV eess.SP"}, "abstract": "In this work, we address the challenge of multi-task image generation with limited data for denoising diffusion probabilistic models (DDPM), a class of generative models that produce high-quality images by reversing a noisy diffusion process. We propose a novel method, SR-DDPM, that leverages representation-based techniques from few-shot learning to effectively learn from fewer samples across different tasks. Our method consists of a core meta architecture with shared parameters, i.e., task-specific layers with exclusive parameters. By exploiting the similarity between diverse data distributions, our method can scale to multiple tasks without compromising the image quality. We evaluate our method on standard image datasets and show that it outperforms both unconditional and conditional DDPM in terms of FID and SSIM metrics.", "url": "https://arxiv.org/abs/2311.16353"}, {"metadata": {"arXiv": "2311.16424", "Date": "Tue, 28 Nov 2023 02:08:06 ", "Title": "Manifold Preserving Guided Diffusion", "Authors": ["Yutong He", "Naoki Murata", "Chieh-Hsin Lai", "Yuhta Takida", "Toshimitsu Uesaka", "Dongjun Kim", "Wei-Hsiang Liao", "Yuki Mitsufuji", "J. Zico Kolter", "Ruslan Salakhutdinov", "Stefano Ermon"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Despite the recent advancements, conditional image generation still faces challenges of cost, generalizability, and the need for task-specific training. In this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a training-free conditional generation framework that leverages pretrained diffusion models and off-the-shelf neural networks with minimal additional inference cost for a broad range of tasks. Specifically, we leverage the manifold hypothesis to refine the guided diffusion steps and introduce a shortcut algorithm in the process. We then propose two methods for on-manifold training-free guidance using pre-trained autoencoders and demonstrate that our shortcut inherently preserves the manifolds when applied to latent diffusion models. Our experiments show that MPGD is efficient and effective for solving a variety of conditional generation applications in low-compute settings, and can consistently offer up to 3.8x speed-ups with the same number of diffusion steps while maintaining high sample quality compared to the baselines.", "url": "https://arxiv.org/abs/2311.16424"}, {"metadata": {"arXiv": "2311.16605", "Date": "Tue, 28 Nov 2023 08:45:37 ", "Title": "LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning", "Authors": ["Jintang Li", "Jiawang Dan", "Ruofan Wu", "Jing Zhou", "Sheng Tian", "Yunfei Liu", "Baokun Wang", "Changhua Meng", "Weiqiang Wang", "Yuchang Zhu", "Liang Chen", "Zibin Zheng"], "Categories": "cs.LG cs.AI", "Comments": ["Preprint; Work in progress"]}, "abstract": "Over the past few years, graph neural networks (GNNs) have become powerful and practical tools for learning on (static) graph-structure data. However, many real-world applications, such as social networks and e-commerce, involve temporal graphs where nodes and edges are dynamically evolving. Temporal graph neural networks (TGNNs) have progressively emerged as an extension of GNNs to address time-evolving graphs and have gradually become a trending research topic in both academics and industry. Advancing research in such an emerging field requires new tools to compose TGNN models and unify their different schemes in dealing with temporal graphs. To facilitate research and application in temporal graph learning, we introduce LasTGL, an industrial framework that integrates unified and extensible implementations of common temporal graph learning algorithms for various advanced tasks. The purpose of LasTGL is to provide the essential building blocks for solving temporal graph learning tasks, focusing on the guiding principles of user-friendliness and quick prototyping on which PyTorch is based. In particular, LasTGL provides comprehensive temporal graph datasets, TGNN models and utilities along with well-documented tutorials, making it suitable for both absolute beginners and expert deep learning practitioners alike.", "url": "https://arxiv.org/abs/2311.16605"}, {"metadata": {"arXiv": "2311.16666", "Date": "Tue, 28 Nov 2023 10:28:35 ", "Title": "MultiModal-Learning for Predicting Molecular Properties: A Framework Based on Image and Graph Structures", "Authors": ["Zhuoyuan Wang", "Jiacong Mi", "Shan Lu", "Jieyue He"], "Categories": "cs.LG cs.AI physics.chem-ph q-bio.BM", "Comments": ["8 pages"]}, "abstract": "The quest for accurate prediction of drug molecule properties poses a fundamental challenge in the realm of Artificial Intelligence Drug Discovery (AIDD). An effective representation of drug molecules emerges as a pivotal component in this pursuit. Contemporary leading-edge research predominantly resorts to self-supervised learning (SSL) techniques to extract meaningful structural representations from large-scale, unlabeled molecular data, subsequently fine-tuning these representations for an array of downstream tasks. However, an inherent shortcoming of these studies lies in their singular reliance on one modality of molecular information, such as molecule image or SMILES representations, thus neglecting the potential complementarity of various molecular modalities. In response to this limitation, we propose MolIG, a novel MultiModaL molecular pre-training framework for predicting molecular properties based on Image and Graph structures. MolIG model innovatively leverages the coherence and correlation between molecule graph and molecule image to execute self-supervised tasks, effectively amalgamating the strengths of both molecular representation forms. This holistic approach allows for the capture of pivotal molecular structural characteristics and high-level semantic information. Upon completion of pre-training, Graph Neural Network (GNN) Encoder is used for the prediction of downstream tasks. In comparison to advanced baseline models, MolIG exhibits enhanced performance in downstream tasks pertaining to molecular property prediction within benchmark groups such as MoleculeNet Benchmark Group and ADMET Benchmark Group.", "url": "https://arxiv.org/abs/2311.16666"}, {"metadata": {"arXiv": "2311.16834", "Date": "Tue, 28 Nov 2023 14:51:06 ", "Title": "Modular Neural Networks for Time Series Forecasting: Interpretability and Feature Selection using Attention", "Authors": ["Qiqi Su", "Christos Kloukinas", "Artur d'Garcez"], "Categories": "cs.LG cs.AI"}, "abstract": "Multivariate time series have many applications, from healthcare and meteorology to life science. Although deep learning models have shown excellent predictive performance for time series, they have been criticised for being \"black-boxes\" or non-interpretable. This paper proposes a novel modular neural network model for multivariate time series prediction that is interpretable by construction. A recurrent neural network learns the temporal dependencies in the data while an attention-based feature selection component selects the most relevant features and suppresses redundant features used in the learning of the temporal dependencies. A modular deep network is trained from the selected features independently to show the users how features influence outcomes, making the model interpretable. Experimental results show that this approach can outperform state-of-the-art interpretable Neural Additive Models (NAM) and variations thereof in both regression and classification of time series tasks, achieving a predictive performance that is comparable to the top non-interpretable methods for time series, LSTM and XGBoost.", "url": "https://arxiv.org/abs/2311.16834"}, {"metadata": {"arXiv": "2311.16941", "Date": "Tue, 28 Nov 2023 16:46:14 ", "Title": "Debiasing Multimodal Models via Causal Information Minimization", "Authors": ["Vaidehi Patil", "Adyasha Maharana", "Mohit Bansal"], "Categories": "cs.LG cs.AI cs.CL cs.CV stat.ME", "Comments": ["EMNLP 2023 Findings (16 pages)"]}, "abstract": "Most existing debiasing methods for multimodal models, including causal intervention and inference methods, utilize approximate heuristics to represent the biases, such as shallow features from early stages of training or unimodal features for multimodal tasks like VQA, etc., which may not be accurate. In this paper, we study bias arising from confounders in a causal graph for multimodal data and examine a novel approach that leverages causally-motivated information minimization to learn the confounder representations. Robust predictive features contain diverse information that helps a model generalize to out-of-distribution data. Hence, minimizing the information content of features obtained from a pretrained biased model helps learn the simplest predictive features that capture the underlying data distribution. We treat these features as confounder representations and use them via methods motivated by causal theory to remove bias from models. We find that the learned confounder representations indeed capture dataset biases, and the proposed debiasing methods improve out-of-distribution (OOD) performance on multiple multimodal datasets without sacrificing in-distribution performance. Additionally, we introduce a novel metric to quantify the sufficiency of spurious features in models' predictions that further demonstrates the effectiveness of our proposed methods. Our code is available at: https://github.com/Vaidehi99/CausalInfoMin", "url": "https://arxiv.org/abs/2311.16941"}, {"metadata": {"arXiv": "2311.16996", "Date": "Tue, 28 Nov 2023 17:48:18 ", "Title": "Goal-conditioned Offline Planning from Curious Exploration", "Authors": ["Marco Bagatella", "Georg Martius"], "Categories": "cs.LG cs.AI"}, "abstract": "Curiosity has established itself as a powerful exploration strategy in deep reinforcement learning. Notably, leveraging expected future novelty as intrinsic motivation has been shown to efficiently generate exploratory trajectories, as well as a robust dynamics model. We consider the challenge of extracting goal-conditioned behavior from the products of such unsupervised exploration techniques, without any additional environment interaction. We find that conventional goal-conditioned reinforcement learning approaches for extracting a value function and policy fall short in this difficult offline setting. By analyzing the geometry of optimal goal-conditioned value functions, we relate this issue to a specific class of estimation artifacts in learned values. In order to mitigate their occurrence, we propose to combine model-based planning over learned value landscapes with a graph-based value aggregation scheme. We show how this combination can correct both local and global artifacts, obtaining significant improvements in zero-shot goal-reaching performance across diverse simulated environments.", "url": "https://arxiv.org/abs/2311.16996"}, {"metadata": {"arXiv": "2311.17007", "Date": "Tue, 28 Nov 2023 18:02:06 ", "Title": "Computational Hypergraph Discovery, a Gaussian Process framework for connecting the dots", "Authors": ["Th\\'eo Bourdais and Pau Batlle and Xianjin Yang and Ricardo Baptista and Nicolas Rouquette and Houman Owhadi"], "Categories": "cs.LG cs.AI cs.NA cs.SI math.NA stat.ML", "Comments": ["The code for the algorithm introduced in this paper and its application to various examples are available for download (and as as an installable python library/package) at https://github.com/TheoBourdais/ComputationalHypergraphDiscovery"], "MSC-class": "62A09, 62H22, 65S05, 90C35, 94C15, 46E22, 62J02, 15A83, 62D20, 68R10"}, "abstract": "Most scientific challenges can be framed into one of the following three levels of complexity of function approximation. Type 1: Approximate an unknown function given input/output data. Type 2: Consider a collection of variables and functions, some of which are unknown, indexed by the nodes and hyperedges of a hypergraph (a generalized graph where edges can connect more than two vertices). Given partial observations of the variables of the hypergraph (satisfying the functional dependencies imposed by its structure), approximate all the unobserved variables and unknown functions. Type 3: Expanding on Type 2, if the hypergraph structure itself is unknown, use partial observations of the variables of the hypergraph to discover its structure and approximate its unknown functions. While most Computational Science and Engineering and Scientific Machine Learning challenges can be framed as Type 1 and Type 2 problems, many scientific problems can only be categorized as Type 3. Despite their prevalence, these Type 3 challenges have been largely overlooked due to their inherent complexity. Although Gaussian Process (GP) methods are sometimes perceived as well-founded but old technology limited to Type 1 curve fitting, their scope has recently been expanded to Type 2 problems. In this paper, we introduce an interpretable GP framework for Type 3 problems, targeting the data-driven discovery and completion of computational hypergraphs. Our approach is based on a kernel generalization of Row Echelon Form reduction from linear systems to nonlinear ones and variance-based analysis. Here, variables are linked via GPs and those contributing to the highest data variance unveil the hypergraph's structure. We illustrate the scope and efficiency of the proposed approach with applications to (algebraic) equation discovery, network discovery (gene pathways, chemical, and mechanical) and raw data analysis.", "url": "https://arxiv.org/abs/2311.17007"}, {"metadata": {"arXiv": "2311.17030", "Date": "Tue, 28 Nov 2023 18:32:19 ", "Title": "Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching", "Authors": ["Aleksandar Makelov", "Georg Lange", "Neel Nanda"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["NeurIPS 2023 Workshop on Attributing Model Behavior at Scale"]}, "abstract": "Mechanistic interpretability aims to understand model behaviors in terms of specific, interpretable features, often hypothesized to manifest as low-dimensional subspaces of activations. Specifically, recent studies have explored subspace interventions (such as activation patching) as a way to simultaneously manipulate model behavior and attribute the features behind it to given subspaces. In this work, we demonstrate that these two aims diverge, potentially leading to an illusory sense of interpretability. Counterintuitively, even if a subspace intervention makes the model's output behave as if the value of a feature was changed, this effect may be achieved by activating a dormant parallel pathway leveraging another subspace that is causally disconnected from model outputs. We demonstrate this phenomenon in a distilled mathematical example, in two real-world domains (the indirect object identification task and factual recall), and present evidence for its prevalence in practice. In the context of factual recall, we further show a link to rank-1 fact editing, providing a mechanistic explanation for previous work observing an inconsistency between fact editing performance and fact localization. However, this does not imply that activation patching of subspaces is intrinsically unfit for interpretability. To contextualize our findings, we also show what a success case looks like in a task (indirect object identification) where prior manual circuit analysis informs an understanding of the location of a feature. We explore the additional evidence needed to argue that a patched subspace is faithful.", "url": "https://arxiv.org/abs/2311.17030"}, {"metadata": {"arXiv": "2311.17053", "Date": "Tue, 28 Nov 2023 18:58:48 ", "Title": "DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative Diffusion Models", "Authors": ["Tsun-Hsuan Wang", "Juntian Zheng", "Pingchuan Ma", "Yilun Du", "Byungchul Kim", "Andrew Spielberg", "Joshua Tenenbaum", "Chuang Gan", "Daniela Rus"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["NeurIPS 2023. Project page: https://diffusebot.github.io/"]}, "abstract": "Nature evolves creatures with a high complexity of morphological and behavioral intelligence, meanwhile computational methods lag in approaching that diversity and efficacy. Co-optimization of artificial creatures' morphology and control in silico shows promise for applications in physical soft robotics and virtual character creation; such approaches, however, require developing new learning algorithms that can reason about function atop pure structure. In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. DiffuseBot bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and (ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation. We showcase a range of simulated and fabricated robots along with their capabilities. Check our website at https://diffusebot.github.io/", "url": "https://arxiv.org/abs/2311.17053"}, {"metadata": {"arXiv": "2311.17059", "Date": "Tue, 28 Nov 2023 18:59:58 ", "Title": "Mission-driven Exploration for Accelerated Deep Reinforcement Learning with Temporal Logic Task Specifications", "Authors": ["Jun Wang", "Hosein Hasanbeig", "Kaiyuan Tan", "Zihe Sun", "Yiannis Kantaros"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "This paper addresses the problem of designing optimal control policies for mobile robots with mission and safety requirements specified using Linear Temporal Logic (LTL). We consider robots with unknown stochastic dynamics operating in environments with unknown geometric structure. The robots are equipped with sensors allowing them to detect obstacles. Our goal is to synthesize a control policy that maximizes the probability of satisfying an LTL-encoded task in the presence of motion and environmental uncertainty. Several deep reinforcement learning (DRL) algorithms have been proposed recently to address similar problems. A common limitation in related works is that of slow learning performance. In order to address this issue, we propose a novel DRL algorithm, which has the capability to learn control policies at a notably faster rate compared to similar methods. Its sample efficiency is due to a mission-driven exploration strategy that prioritizes exploration towards directions that may contribute to mission accomplishment. Identifying these directions relies on an automaton representation of the LTL task as well as a learned neural network that (partially) models the unknown system dynamics. We provide comparative experiments demonstrating the efficiency of our algorithm on robot navigation tasks in unknown environments.", "url": "https://arxiv.org/abs/2311.17059"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

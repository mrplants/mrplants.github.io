<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.08438", "Date": "Tue, 14 Nov 2023 14:27:53 ", "Title": "LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping", "Authors": ["Sujal Vijayaraghavan and Redwan Alqasemi and Rajiv Dubey and Sudeep Sarkar"], "Categories": "cs.CV cs.LG", "DOI": "10.1007/978-3-031-25075-0_47"}, "abstract": "Robot grasp typically follows five stages: object detection, object localisation, object pose estimation, grasp pose estimation, and grasp planning. We focus on object pose estimation. Our approach relies on three pieces of information: multiple views of the object, the camera's extrinsic parameters at those viewpoints, and 3D CAD models of objects. The first step involves a standard deep learning backbone (FCN ResNet) to estimate the object label, semantic segmentation, and a coarse estimate of the object pose with respect to the camera. Our novelty is using a refinement module that starts from the coarse pose estimate and refines it by optimisation through differentiable rendering. This is a purely vision-based approach that avoids the need for other information such as point cloud or depth images. We evaluate our object pose estimation approach on the ShapeNet dataset and show improvements over the state of the art. We also show that the estimated object pose results in 99.65% grasp accuracy with the ground truth grasp candidates on the Object Clutter Indoor Dataset (OCID) Grasp dataset, as computed using standard practice.", "url": "https://arxiv.org/abs/2311.08438"}, {"metadata": {"arXiv": "2311.08503", "Date": "Tue, 14 Nov 2023 19:53:09 ", "Title": "MADG: Margin-based Adversarial Learning for Domain Generalization", "Authors": ["Aveen Dayal", "Vimal K. B.", "Linga Reddy Cenkeramaddi", "C. Krishna Mohan", "Abhinav Kumar and Vineeth N Balasubramanian"], "Categories": "cs.CV cs.LG"}, "abstract": "Domain Generalization (DG) techniques have emerged as a popular approach to address the challenges of domain shift in Deep Learning (DL), with the goal of generalizing well to the target domain unseen during the training. In recent years, numerous methods have been proposed to address the DG setting, among which one popular approach is the adversarial learning-based methodology. The main idea behind adversarial DG methods is to learn domain-invariant features by minimizing a discrepancy metric. However, most adversarial DG methods use 0-1 loss based $\\mathcal{H}\\Delta\\mathcal{H}$ divergence metric. In contrast, the margin loss-based discrepancy metric has the following advantages: more informative, tighter, practical, and efficiently optimizable. To mitigate this gap, this work proposes a novel adversarial learning DG algorithm, MADG, motivated by a margin loss-based discrepancy metric. The proposed MADG model learns domain-invariant features across all source domains and uses adversarial training to generalize well to the unseen target domain. We also provide a theoretical analysis of the proposed MADG model based on the unseen target error bound. Specifically, we construct the link between the source and unseen domains in the real-valued hypothesis space and derive the generalization bound using margin loss and Rademacher complexity. We extensively experiment with the MADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome, DomainNet, and TerraIncognita. We evaluate the proposed algorithm on DomainBed's benchmark and observe consistent performance across all the datasets.", "url": "https://arxiv.org/abs/2311.08503"}, {"metadata": {"arXiv": "2311.08539", "Date": "Tue, 14 Nov 2023 21:04:49 ", "Title": "Physical Adversarial Examples for Multi-Camera Systems", "Authors": ["Ana R\\u{a}du\\c{t}oiu and Jan-Philipp Schulze and Philip Sperl and Konstantin B\\\"ottinger"], "Categories": "cs.CV cs.CR cs.LG"}, "abstract": "Neural networks build the foundation of several intelligent systems, which, however, are known to be easily fooled by adversarial examples. Recent advances made these attacks possible even in air-gapped scenarios, where the autonomous system observes its surroundings by, e.g., a camera. We extend these ideas in our research and evaluate the robustness of multi-camera setups against such physical adversarial examples. This scenario becomes ever more important with the rise in popularity of autonomous vehicles, which fuse the information of several cameras for their driving decision. While we find that multi-camera setups provide some robustness towards past attack methods, we see that this advantage reduces when optimizing on multiple perspectives at once. We propose a novel attack method that we call Transcender-MC, where we incorporate online 3D renderings and perspective projections in the training process. Moreover, we motivate that certain data augmentation techniques can facilitate the generation of successful adversarial examples even further. Transcender-MC is 11% more effective in successfully attacking multi-camera setups than state-of-the-art methods. Our findings offer valuable insights regarding the resilience of object detection in a setup with multiple cameras and motivate the need of developing adequate defense mechanisms against them.", "url": "https://arxiv.org/abs/2311.08539"}, {"metadata": {"arXiv": "2311.08622", "Date": "Wed, 15 Nov 2023 01:00:02 ", "Title": "Multiple-Question Multiple-Answer Text-VQA", "Authors": ["Peng Tang", "Srikar Appalaraju", "R. Manmatha", "Yusheng Xie", "Vijay Mahadevan"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do text-VQA in encoder-decoder transformer models. The text-VQA task requires a model to answer a question by understanding multi-modal content: text (typically from OCR) and an associated image. To the best of our knowledge, almost all previous approaches for text-VQA process a single question and its associated content to predict a single answer. In order to answer multiple questions from the same image, each question and content are fed into the model multiple times. In contrast, our proposed MQMA approach takes multiple questions and content as input at the encoder and predicts multiple answers at the decoder in an auto-regressive manner at the same time. We make several novel architectural modifications to standard encoder-decoder transformers to support MQMA. We also propose a novel MQMA denoising pre-training task which is designed to teach the model to align and delineate multiple questions and content with associated answers. MQMA pre-trained model achieves state-of-the-art results on multiple text-VQA datasets, each with strong baselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%), DocVQA (+1.1%) absolute improvements over the previous state-of-the-art approaches.", "url": "https://arxiv.org/abs/2311.08622"}, {"metadata": {"arXiv": "2311.08623", "Date": "Wed, 15 Nov 2023 01:01:02 ", "Title": "DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models", "Authors": ["Peng Tang", "Pengkai Zhu", "Tian Li", "Srikar Appalaraju", "Vijay Mahadevan", "R. Manmatha"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Encoder-decoder transformer models have achieved great success on various vision-language (VL) tasks, but they suffer from high inference latency. Typically, the decoder takes up most of the latency because of the auto-regressive decoding. To accelerate the inference, we propose an approach of performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit encoder-decoder transformer model which is trained with deep supervision so that each of its decoder layers is capable of generating plausible predictions. In addition, we leverage simple yet practical techniques, including shared generation head and adaptation modules, to keep accuracy when exiting at shallow decoder layers. Based on the multi-exit model, we perform step-level dynamic early exit during inference, where the model may decide to use fewer decoder layers based on its confidence of the current layer at each individual decoding step. Considering different number of decoder layers may be used at different decoding steps, we compute deeper-layer decoder features of previous decoding steps just-in-time, which ensures the features from different decoding steps are semantically aligned. We evaluate our approach with two state-of-the-art encoder-decoder transformer models on various VL tasks. We show our approach can reduce overall inference latency by 30%-60% with comparable or even higher accuracy compared to baselines.", "url": "https://arxiv.org/abs/2311.08623"}, {"metadata": {"arXiv": "2311.08655", "Date": "Wed, 15 Nov 2023 02:28:52 ", "Title": "Review of AlexNet for Medical Image Classification", "Authors": ["Wenhao Tang", "Junding Sun", "Shuihua Wang", "Yudong Zhang"], "Categories": "cs.CV cs.LG"}, "abstract": "In recent years, the rapid development of deep learning has led to a wide range of applications in the field of medical image classification. The variants of neural network models with ever-increasing performance share some commonalities: to try to mitigate overfitting, improve generalization, avoid gradient vanishing and exploding, etc. AlexNet first utilizes the dropout technique to mitigate overfitting and the ReLU activation function to avoid gradient vanishing. Therefore, we focus our discussion on AlexNet, which has contributed greatly to the development of CNNs in 2012. After reviewing over 40 papers, including journal papers and conference papers, we give a narrative on the technical details, advantages, and application areas of AlexNet.", "url": "https://arxiv.org/abs/2311.08655"}, {"metadata": {"arXiv": "2311.08657", "Date": "Wed, 15 Nov 2023 02:33:08 ", "Title": "ConeQuest: A Benchmark for Cone Segmentation on Mars", "Authors": ["Mirali Purohit", "Jacob Adler", "Hannah Kerner"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at WACV 2024"]}, "abstract": "Over the years, space scientists have collected terabytes of Mars data from satellites and rovers. One important set of features identified in Mars orbital images is pitted cones, which are interpreted to be mud volcanoes believed to form in regions that were once saturated in water (i.e., a lake or ocean). Identifying pitted cones globally on Mars would be of great importance, but expert geologists are unable to sort through the massive orbital image archives to identify all examples. However, this task is well suited for computer vision. Although several computer vision datasets exist for various Mars-related tasks, there is currently no open-source dataset available for cone detection/segmentation. Furthermore, previous studies trained models using data from a single region, which limits their applicability for global detection and mapping. Motivated by this, we introduce ConeQuest, the first expert-annotated public dataset to identify cones on Mars. ConeQuest consists of >13k samples from 3 different regions of Mars. We propose two benchmark tasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size Generalization. We finetune and evaluate widely-used segmentation models on both benchmark tasks. Results indicate that cone segmentation is a challenging open problem not solved by existing segmentation models, which achieve an average IoU of 52.52% and 42.55% on in-distribution data for tasks (i) and (ii), respectively. We believe this new benchmark dataset will facilitate the development of more accurate and robust models for cone segmentation. Data and code are available at https://github.com/kerner-lab/ConeQuest.", "url": "https://arxiv.org/abs/2311.08657"}, {"metadata": {"arXiv": "2311.08870", "Date": "Wed, 15 Nov 2023 11:11:25 ", "Title": "One-Shot Federated Learning with Classifier-Guided Diffusion Models", "Authors": ["Mingzhao Yang", "Shangchao Su", "Bin Li", "Xiangyang Xue"], "Categories": "cs.CV cs.LG"}, "abstract": "One-shot federated learning (OSFL) has gained attention in recent years due to its low communication cost. However, most of the existing methods require auxiliary datasets or training generators, which hinders their practicality in real-world scenarios. In this paper, we explore the novel opportunities that diffusion models bring to OSFL and propose FedCADO, utilizing guidance from client classifiers to generate data that complies with clients' distributions and subsequently training the aggregated model on the server. Specifically, our method involves targeted optimizations in two aspects. On one hand, we conditionally edit the randomly sampled initial noises, embedding them with specified semantics and distributions, resulting in a significant improvement in both the quality and stability of generation. On the other hand, we employ the BN statistics from the classifiers to provide detailed guidance during generation. These tailored optimizations enable us to limitlessly generate datasets, which closely resemble the distribution and quality of the original client dataset. Our method effectively handles the heterogeneous client models and the problems of non-IID features or labels. In terms of privacy protection, our method avoids training any generator or transferring any auxiliary information on clients, eliminating any additional privacy leakage risks. Leveraging the extensive knowledge stored in the pre-trained diffusion model, the synthetic datasets can assist us in surpassing the knowledge limitations of the client samples, resulting in aggregation models that even outperform the performance ceiling of centralized training in some cases, which is convincingly demonstrated in the sufficient quantification and visualization experiments conducted on three large-scale multi-domain image datasets.", "url": "https://arxiv.org/abs/2311.08870"}, {"metadata": {"arXiv": "2311.08972", "Date": "Wed, 15 Nov 2023 14:04:37 ", "Title": "Unsupervised approaches based on optimal transport and convex analysis for inverse problems in imaging", "Authors": ["Marcello Carioni", "Subhadip Mukherjee", "Hong Ye Tan", "Junqi Tang"], "Categories": "cs.CV cs.LG math.OC"}, "abstract": "Unsupervised deep learning approaches have recently become one of the crucial research areas in imaging owing to their ability to learn expressive and powerful reconstruction operators even when paired high-quality training data is scarcely available. In this chapter, we review theoretically principled unsupervised learning schemes for solving imaging inverse problems, with a particular focus on methods rooted in optimal transport and convex analysis. We begin by reviewing the optimal transport-based unsupervised approaches such as the cycle-consistency-based models and learned adversarial regularization methods, which have clear probabilistic interpretations. Subsequently, we give an overview of a recent line of works on provably convergent learned optimization algorithms applied to accelerate the solution of imaging inverse problems, alongside their dedicated unsupervised training schemes. We also survey a number of provably convergent plug-and-play algorithms (based on gradient-step deep denoisers), which are among the most important and widely applied unsupervised approaches for imaging problems. At the end of this survey, we provide an overview of a few related unsupervised learning frameworks that complement our focused schemes. Together with a detailed survey, we provide an overview of the key mathematical results that underlie the methods reviewed in the chapter to keep our discussion self-contained.", "url": "https://arxiv.org/abs/2311.08972"}, {"metadata": {"arXiv": "2311.09064", "Date": "Wed, 15 Nov 2023 16:02:13 ", "Title": "Imagine the Unseen World: A Benchmark for Systematic Generalization in Visual World Models", "Authors": ["Yeongbin Kim", "Gautam Singh", "Junyeong Park", "Caglar Gulcehre", "Sungjin Ahn"], "Categories": "cs.CV cs.LG", "Comments": ["Published as a conference paper at NeurIPS 2023. The first two authors contributed equally. To download the benchmark", "visit https://systematic-visual-imagination.github.io"]}, "abstract": "Systematic compositionality, or the ability to adapt to novel situations by creating a mental model of the world using reusable pieces of knowledge, remains a significant challenge in machine learning. While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy. We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on. SVIB offers a novel framework for a minimal world modeling problem, where models are evaluated based on their ability to generate one-step image-to-image transformations under a latent world dynamics. The framework provides benefits such as the possibility to jointly optimize for systematic perception and imagination, a range of difficulty levels, and the ability to control the fraction of possible factor combinations used during training. We provide a comprehensive evaluation of various baseline models on SVIB, offering insight into the current state-of-the-art in systematic visual imagination. We hope that this benchmark will help advance visual systematic compositionality.", "url": "https://arxiv.org/abs/2311.09064"}, {"metadata": {"arXiv": "2311.09215", "Date": "Wed, 15 Nov 2023 18:56:51 ", "Title": "ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy", "Authors": ["Kirill Vishniakov", "Zhiqiang Shen", "Zhuang Liu"], "Categories": "cs.CV cs.LG", "Comments": ["Preprint"]}, "abstract": "Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging. Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet. However, this single metric does not fully capture performance nuances critical for specialized tasks. In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms. Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others. This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models. Our code is available at https://github.com/kirill-vish/Beyond-INet.", "url": "https://arxiv.org/abs/2311.09215"}, {"metadata": {"arXiv": "2311.08422", "Date": "Fri, 10 Nov 2023 23:29:32 ", "Title": "k-Parameter Approach for False In-Season Anomaly Suppression in Daily Time Series Anomaly Detection", "Authors": ["Vincent Yuansang Zha", "Vaishnavi Kommaraju", "Okenna Obi-Njoku", "Vijay Dakshinamoorthy", "Anirudh Agnihotri", "Nantes Kirsten"], "Categories": "cs.LG", "Comments": ["5 pages", "7 figures"]}, "abstract": "Detecting anomalies in a daily time series with a weekly pattern is a common task with a wide range of applications. A typical way of performing the task is by using decomposition method. However, the method often generates false positive results where a data point falls within its weekly range but is just off from its weekday position. We refer to this type of anomalies as \"in-season anomalies\", and propose a k-parameter approach to address the issue. The approach provides configurable extra tolerance for in-season anomalies to suppress misleading alerts while preserving real positives. It yields favorable result.", "url": "https://arxiv.org/abs/2311.08422"}, {"metadata": {"arXiv": "2311.08429", "Date": "Tue, 14 Nov 2023 01:05:14 ", "Title": "Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?", "Authors": ["Rex Chen", "Kathleen M. Carley", "Fei Fang", "Norman Sadeh"], "Categories": "cs.LG cs.CE", "Comments": ["12 pages; accepted version", "published at the 2023 Winter Simulation Conference (WSC '23)"]}, "abstract": "Traffic simulators are used to generate data for learning in intelligent transportation systems (ITSs). A key question is to what extent their modelling assumptions affect the capabilities of ITSs to adapt to various scenarios when deployed in the real world. This work focuses on two simulators commonly used to train reinforcement learning (RL) agents for traffic applications, CityFlow and SUMO. A controlled virtual experiment varying driver behavior and simulation scale finds evidence against distributional equivalence in RL-relevant measures from these simulators, with the root mean squared error and KL divergence being significantly greater than 0 for all assessed measures. While granular real-world validation generally remains infeasible, these findings suggest that traffic simulators are not a deus ex machina for RL training: understanding the impacts of inter-simulator differences is necessary to train and deploy RL-based ITSs.", "url": "https://arxiv.org/abs/2311.08429"}, {"metadata": {"arXiv": "2311.08479", "Date": "Tue, 14 Nov 2023 19:10:56 ", "Title": "Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning", "Authors": ["Xidong Wu", "Wan-Yi Lin", "Devin Willmott", "Filipe Condessa", "Yufei Huang", "Zhenzhen Li and Madan Ravi Ganesh"], "Categories": "cs.LG cs.CV cs.DC", "Comments": ["6 Pages + Appendices"]}, "abstract": "Federated Learning (FL) is a distributed training paradigm that enables clients scattered across the world to cooperatively learn a global model without divulging confidential data. However, FL faces a significant challenge in the form of heterogeneous data distributions among clients, which leads to a reduction in performance and robustness. A recent approach to mitigating the impact of heterogeneous data distributions is through the use of foundation models, which offer better performance at the cost of larger computational overheads and slower inference speeds. We introduce foundation model distillation to assist in the federated training of lightweight client models and increase their performance under heterogeneous data settings while keeping inference costs low. Our results show improvement in the global model performance on a balanced testing set, which contains rarely observed samples, even under extreme non-IID client data distributions. We conduct a thorough evaluation of our framework with different foundation model backbones on CIFAR10, with varying degrees of heterogeneous data distributions ranging from class-specific data partitions across clients to dirichlet data sampling, parameterized by values between 0.01 and 1.0.", "url": "https://arxiv.org/abs/2311.08479"}, {"metadata": {"arXiv": "2311.08569", "Date": "Tue, 14 Nov 2023 22:14:07 ", "Title": "Uncertainty Quantification in Neural-Network Based Pain Intensity Estimation", "Authors": ["Burcu Ozek", "Zhenyuan Lu", "Srinivasan Radhakrishnan", "Sagar Kamarthi"], "Categories": "cs.LG", "Comments": ["26 pages", "5 figures", "9 tables"]}, "abstract": "Improper pain management can lead to severe physical or mental consequences, including suffering, and an increased risk of opioid dependency. Assessing the presence and severity of pain is imperative to prevent such outcomes and determine the appropriate intervention. However, the evaluation of pain intensity is challenging because different individuals experience pain differently. To overcome this, researchers have employed machine learning models to evaluate pain intensity objectively. However, these efforts have primarily focused on point estimation of pain, disregarding the inherent uncertainty and variability present in the data and model. Consequently, the point estimates provide only partial information for clinical decision-making. This study presents a neural network-based method for objective pain interval estimation, incorporating uncertainty quantification. This work explores three algorithms: the bootstrap method, lower and upper bound estimation (LossL) optimized by genetic algorithm, and modified lower and upper bound estimation (LossS) optimized by gradient descent algorithm. Our empirical results reveal that LossS outperforms the other two by providing a narrower prediction interval. As LossS outperforms, we assessed its performance in three different scenarios for pain assessment: (1) a generalized approach (single model for the entire population), (2) a personalized approach (separate model for each individual), and (3) a hybrid approach (separate model for each cluster of individuals). Our findings demonstrate the hybrid approach's superior performance, with notable practicality in clinical contexts. It has the potential to be a valuable tool for clinicians, enabling objective pain intensity assessment while taking uncertainty into account. This capability is crucial in facilitating effective pain management and reducing the risks associated with improper treatment.", "url": "https://arxiv.org/abs/2311.08569"}, {"metadata": {"arXiv": "2311.08594", "Date": "Tue, 14 Nov 2023 23:36:39 ", "Title": "Variational Temporal IRT: Fast, Accurate, and Explainable Inference of Dynamic Learner Proficiency", "Authors": ["Yunsung Kim", "Sreechan Sankaranarayanan", "Chris Piech", "Candace Thille"], "Categories": "cs.LG stat.ML", "Comments": ["9 pages", "16th International Conference on Educational Data Mining (EDM'23)"]}, "abstract": "Dynamic Item Response Models extend the standard Item Response Theory (IRT) to capture temporal dynamics in learner ability. While these models have the potential to allow instructional systems to actively monitor the evolution of learner proficiency in real time, existing dynamic item response models rely on expensive inference algorithms that scale poorly to massive datasets. In this work, we propose Variational Temporal IRT (VTIRT) for fast and accurate inference of dynamic learner proficiency. VTIRT offers orders of magnitude speedup in inference runtime while still providing accurate inference. Moreover, the proposed algorithm is intrinsically interpretable by virtue of its modular design. When applied to 9 real student datasets, VTIRT consistently yields improvements in predicting future learner performance over other learner proficiency models.", "url": "https://arxiv.org/abs/2311.08594"}, {"metadata": {"arXiv": "2311.08610", "Date": "Wed, 15 Nov 2023 00:23:58 ", "Title": "Converting Transformers to Polynomial Form for Secure Inference Over Homomorphic Encryption", "Authors": ["Itamar Zimerman", "Moran Baruch", "Nir Drucker", "Gilad Ezov", "Omri Soceanu", "Lior Wolf"], "Categories": "cs.LG cs.CR", "Comments": ["6 figures"], "ACM-class": "F.2.2; I.2.7"}, "abstract": "Designing privacy-preserving deep learning models is a major challenge within the deep learning community. Homomorphic Encryption (HE) has emerged as one of the most promising approaches in this realm, enabling the decoupling of knowledge between the model owner and the data owner. Despite extensive research and application of this technology, primarily in convolutional neural networks, incorporating HE into transformer models has been challenging because of the difficulties in converting these models into a polynomial form. We break new ground by introducing the first polynomial transformer, providing the first demonstration of secure inference over HE with transformers. This includes a transformer architecture tailored for HE, alongside a novel method for converting operators to their polynomial equivalent. This innovation enables us to perform secure inference on LMs with WikiText-103. It also allows us to perform image classification with CIFAR-100 and Tiny-ImageNet. Our models yield results comparable to traditional methods, bridging the performance gap with transformers of similar scale and underscoring the viability of HE for state-of-the-art applications. Finally, we assess the stability of our models and conduct a series of ablations to quantify the contribution of each model component.", "url": "https://arxiv.org/abs/2311.08610"}, {"metadata": {"arXiv": "2311.08675", "Date": "Wed, 15 Nov 2023 03:43:04 ", "Title": "Coreset Selection with Prioritized Multiple Objectives", "Authors": ["Xiaobo Xia", "Jiale Liu", "Shaokun Zhang", "Qingyun Wu", "Tongliang Liu"], "Categories": "cs.LG"}, "abstract": "Coreset selection is powerful in reducing computational costs and accelerating data processing for deep learning algorithms. It strives to identify a small subset from large-scale data, so that training only on the subset practically performs on par with full data. When coreset selection is applied in realistic scenes, under the premise that the identified coreset has achieved comparable model performance, practitioners regularly desire the identified coreset can have a size as small as possible for lower costs and greater acceleration. Motivated by this desideratum, for the first time, we pose the problem of \"coreset selection with prioritized multiple objectives\", in which the smallest coreset size under model performance constraints is explored. Moreover, to address this problem, an innovative method is proposed, which maintains optimization priority order over the model performance and coreset size, and efficiently optimizes them in the coreset selection procedure. Theoretically, we provide the convergence guarantee of the proposed method. Empirically, extensive experiments confirm its superiority compared with previous strategies, often yielding better model performance with smaller coreset sizes.", "url": "https://arxiv.org/abs/2311.08675"}, {"metadata": {"arXiv": "2311.08677", "Date": "Wed, 15 Nov 2023 03:55:28 ", "Title": "Federated Learning for Sparse Principal Component Analysis", "Authors": ["Sin Cheng Ciou", "Pin Jui Chen", "Elvin Y. Tseng and Yuh-Jye Lee"], "Categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "Comments": ["11 pages", "7 figures", "1 table. Accepted by IEEE BigData 2023", "Sorrento", "Italy"]}, "abstract": "In the rapidly evolving realm of machine learning, algorithm effectiveness often faces limitations due to data quality and availability. Traditional approaches grapple with data sharing due to legal and privacy concerns. The federated learning framework addresses this challenge. Federated learning is a decentralized approach where model training occurs on client sides, preserving privacy by keeping data localized. Instead of sending raw data to a central server, only model updates are exchanged, enhancing data security. We apply this framework to Sparse Principal Component Analysis (SPCA) in this work. SPCA aims to attain sparse component loadings while maximizing data variance for improved interpretability. Beside the L1 norm regularization term in conventional SPCA, we add a smoothing function to facilitate gradient-based optimization methods. Moreover, in order to improve computational efficiency, we introduce a least squares approximation to original SPCA. This enables analytic solutions on the optimization processes, leading to substantial computational improvements. Within the federated framework, we formulate SPCA as a consensus optimization problem, which can be solved using the Alternating Direction Method of Multipliers (ADMM). Our extensive experiments involve both IID and non-IID random features across various data owners. Results on synthetic and public datasets affirm the efficacy of our federated SPCA approach.", "url": "https://arxiv.org/abs/2311.08677"}, {"metadata": {"arXiv": "2311.08690", "Date": "Wed, 15 Nov 2023 04:37:27 ", "Title": "Enabling CMF Estimation in Data-Constrained Scenarios: A Semantic-Encoding Knowledge Mining Model", "Authors": ["Yanlin Qi", "Jia Li", "Michael Zhang"], "Categories": "cs.LG cs.CY stat.ME", "Comments": ["39 pages", "9 figures"]}, "abstract": "Precise estimation of Crash Modification Factors (CMFs) is central to evaluating the effectiveness of various road safety treatments and prioritizing infrastructure investment accordingly. While customized study for each countermeasure scenario is desired, the conventional CMF estimation approaches rely heavily on the availability of crash data at given sites. This not only makes the estimation costly, but the results are also less transferable, since the intrinsic similarities between different safety countermeasure scenarios are not fully explored. Aiming to fill this gap, this study introduces a novel knowledge-mining framework for CMF prediction. This framework delves into the connections of existing countermeasures and reduces the reliance of CMF estimation on crash data availability and manual data collection. Specifically, it draws inspiration from human comprehension processes and introduces advanced Natural Language Processing (NLP) techniques to extract intricate variations and patterns from existing CMF knowledge. It effectively encodes unstructured countermeasure scenarios into machine-readable representations and models the complex relationships between scenarios and CMF values. This new data-driven framework provides a cost-effective and adaptable solution that complements the case-specific approaches for CMF estimation, which is particularly beneficial when availability of crash data or time imposes constraints. Experimental validation using real-world CMF Clearinghouse data demonstrates the effectiveness of this new approach, which shows significant accuracy improvements compared to baseline methods. This approach provides insights into new possibilities of harnessing accumulated transportation knowledge in various applications.", "url": "https://arxiv.org/abs/2311.08690"}, {"metadata": {"arXiv": "2311.08695", "Date": "Wed, 15 Nov 2023 04:50:30 ", "Title": "Attribute Diversity Determines the Systematicity Gap in VQA", "Authors": ["Ian Berlot-Attwell", "A. Michael Carrell", "Kumar Krishna Agrawal", "Yash Sharma", "Naomi Saphra"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["18 pages", "20 figures"]}, "abstract": "The degree to which neural networks can generalize to new combinations of familiar concepts, and the conditions under which they are able to do so, has long been an open question. In this work, we study the systematicity gap in visual question answering: the performance difference between reasoning on previously seen and unseen combinations of object attributes. To test, we introduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased quantity of training data does not reduce the systematicity gap, increased training data diversity of the attributes in the unseen combination does. In all, our experiments suggest that the more distinct attribute type combinations are seen during training, the more systematic we can expect the resulting model to be.", "url": "https://arxiv.org/abs/2311.08695"}, {"metadata": {"arXiv": "2311.08716", "Date": "Wed, 15 Nov 2023 05:43:14 ", "Title": "Scalable Federated Learning for Clients with Different Input Image Sizes and Numbers of Output Categories", "Authors": ["Shuhei Nitta", "Taiji Suzuki", "Albert Rodr\\'iguez Mulet", "Atsushi Yaguchi and Ryusuke Hirai"], "Categories": "cs.LG cs.CR cs.CV", "Comments": ["15 pages", "1 figure", "2023 22nd International Conference on Machine Learning and Applications (ICMLA)"]}, "abstract": "Federated learning is a privacy-preserving training method which consists of training from a plurality of clients but without sharing their confidential data. However, previous work on federated learning do not explore suitable neural network architectures for clients with different input images sizes and different numbers of output categories. In this paper, we propose an effective federated learning method named ScalableFL, where the depths and widths of the local models for each client are adjusted according to the clients' input image size and the numbers of output categories. In addition, we provide a new bound for the generalization gap of federated learning. In particular, this bound helps to explain the effectiveness of our scalable neural network approach. We demonstrate the effectiveness of ScalableFL in several heterogeneous client settings for both image classification and object detection tasks.", "url": "https://arxiv.org/abs/2311.08716"}, {"metadata": {"arXiv": "2311.08745", "Date": "Wed, 15 Nov 2023 07:27:40 ", "Title": "Using Stochastic Gradient Descent to Smooth Nonconvex Functions: Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling", "Authors": ["Naoki Sato and Hideaki Iiduka"], "Categories": "cs.LG math.OC"}, "abstract": "The graduated optimization approach is a heuristic method for finding globally optimal solutions for nonconvex functions and has been theoretically analyzed in several studies. This paper defines a new family of nonconvex functions for graduated optimization, discusses their sufficient conditions, and provides a convergence analysis of the graduated optimization algorithm for them. It shows that stochastic gradient descent (SGD) with mini-batch stochastic gradients has the effect of smoothing the function, the degree of which is determined by the learning rate and batch size. This finding provides theoretical insights from a graduated optimization perspective on why large batch sizes fall into sharp local minima, why decaying learning rates and increasing batch sizes are superior to fixed learning rates and batch sizes, and what the optimal learning rate scheduling is. To the best of our knowledge, this is the first paper to provide a theoretical explanation for these aspects. Moreover, a new graduated optimization framework that uses a decaying learning rate and increasing batch size is analyzed and experimental results of image classification that support our theoretical findings are reported.", "url": "https://arxiv.org/abs/2311.08745"}, {"metadata": {"arXiv": "2311.08851", "Date": "Wed, 15 Nov 2023 10:43:13 ", "Title": "Data Augmentations in Deep Weight Spaces", "Authors": ["Aviv Shamsian", "David W. Zhang", "Aviv Navon", "Yan Zhang", "Miltiadis Kofinas", "Idan Achituve", "Riccardo Valperga", "Gertjan J. Burghouts", "Efstratios Gavves", "Cees G. M. Snoek", "Ethan Fetaya", "Gal Chechik", "Haggai Maron"], "Categories": "cs.LG cs.CV", "Comments": ["Accepted to NeurIPS 2023 Workshop on Symmetry and Geometry in Neural Representations"]}, "abstract": "Learning in weight spaces, where neural networks process the weights of other deep neural networks, has emerged as a promising research direction with applications in various fields, from analyzing and editing neural fields and implicit neural representations, to network pruning and quantization. Recent works designed architectures for effective learning in that space, which takes into account its unique, permutation-equivariant, structure. Unfortunately, so far these architectures suffer from severe overfitting and were shown to benefit from large datasets. This poses a significant challenge because generating data for this learning setup is laborious and time-consuming since each data sample is a full set of network weights that has to be trained. In this paper, we address this difficulty by investigating data augmentations for weight spaces, a set of techniques that enable generating new data examples on the fly without having to train additional input weight space elements. We first review several recently proposed data augmentation schemes %that were proposed recently and divide them into categories. We then introduce a novel augmentation scheme based on the Mixup method. We evaluate the performance of these techniques on existing benchmarks as well as new benchmarks we generate, which can be valuable for future studies.", "url": "https://arxiv.org/abs/2311.08851"}, {"metadata": {"arXiv": "2311.08874", "Date": "Wed, 15 Nov 2023 11:23:15 ", "Title": "Towards Label Embedding - Measuring classification difficulty", "Authors": ["Katharina Hechinger", "Christoph Koller", "Xiao Xiang Zhu", "G\\\"oran Kauermann"], "Categories": "cs.LG stat.AP"}, "abstract": "Uncertainty quantification in machine learning is a timely and vast field of research. In supervised learning, uncertainty can already occur in the very first stage of the training process, the labelling step. In particular, this is the case when not every instance can be unambiguously classified. The problem occurs for classifying instances, where classes may overlap or instances can not be clearly categorised. In other words, there is inevitable ambiguity in the annotation step and not necessarily a 'ground truth'. We look exemplary at the classification of satellite images. Each image is annotated independently by multiple labellers and classified into local climate zones (LCZs). For each instance we have multiple votes, leading to a distribution of labels rather than a single value. The main idea of this work is that we do not assume a ground truth label but embed the votes into a K-dimensional space, with K as the number of possible categories. The embedding is derived from the voting distribution in a Bayesian setup, modelled via a Dirichlet-Multinomial model. We estimate the model and posteriors using a stochastic Expectation Maximisation algorithm with Markov Chain Monte Carlo steps. While we focus on the particular example of LCZ classification, the methods developed in this paper readily extend to other situations where multiple annotators independently label texts or images. We also apply our approach to two other benchmark datasets for image classification to demonstrate this. Besides the embeddings themselves, we can investigate the resulting correlation matrices, which can be seen as generalised confusion matrices and reflect the semantic similarities of the original classes very well for all three exemplary datasets. The insights gained are valuable and can serve as general label embedding if a single ground truth per observation cannot be guaranteed.", "url": "https://arxiv.org/abs/2311.08874"}, {"metadata": {"arXiv": "2311.08902", "Date": "Wed, 15 Nov 2023 12:18:15 ", "Title": "On the Importance of Step-wise Embeddings for Heterogeneous Clinical Time-Series", "Authors": ["Rita Kuznetsova", "Aliz\\'ee Pace", "Manuel Burger", "Hugo Y\\`eche", "Gunnar R\\\"atsch"], "Categories": "cs.LG", "Comments": ["Machine Learning for Health (ML4H) 2023 in Proceedings of Machine Learning Research 225"]}, "abstract": "Recent advances in deep learning architectures for sequence modeling have not fully transferred to tasks handling time-series from electronic health records. In particular, in problems related to the Intensive Care Unit (ICU), the state-of-the-art remains to tackle sequence classification in a tabular manner with tree-based methods. Recent findings in deep learning for tabular data are now surpassing these classical methods by better handling the severe heterogeneity of data input features. Given the similar level of feature heterogeneity exhibited by ICU time-series and motivated by these findings, we explore these novel methods' impact on clinical sequence modeling tasks. By jointly using such advances in deep learning for tabular data, our primary objective is to underscore the importance of step-wise embeddings in time-series modeling, which remain unexplored in machine learning methods for clinical data. On a variety of clinically relevant tasks from two large-scale ICU datasets, MIMIC-III and HiRID, our work provides an exhaustive analysis of state-of-the-art methods for tabular time-series as time-step embedding models, showing overall performance improvement. In particular, we evidence the importance of feature grouping in clinical time-series, with significant performance gains when considering features within predefined semantic groups in the step-wise embedding module.", "url": "https://arxiv.org/abs/2311.08902"}, {"metadata": {"arXiv": "2311.08909", "Date": "Wed, 15 Nov 2023 12:26:31 ", "Title": "DLAS: An Exploration and Assessment of the Deep Learning Acceleration Stack", "Authors": ["Perry Gibson", "Jos\\'e Cano", "Elliot J. Crowley", "Amos Storkey", "Michael O'Boyle"], "Categories": "cs.LG cs.CV cs.PF"}, "abstract": "Deep Neural Networks (DNNs) are extremely computationally demanding, which presents a large barrier to their deployment on resource-constrained devices. Since such devices are where many emerging deep learning applications lie (e.g., drones, vision-based medical technology), significant bodies of work from both the machine learning and systems communities have attempted to provide optimizations to accelerate DNNs. To help unify these two perspectives, in this paper we combine machine learning and systems techniques within the Deep Learning Acceleration Stack (DLAS), and demonstrate how these layers can be tightly dependent on each other with an across-stack perturbation study. We evaluate the impact on accuracy and inference time when varying different parameters of DLAS across two datasets, seven popular DNN architectures, four DNN compression techniques, three algorithmic primitives with sparse and dense variants, untuned and auto-scheduled code generation, and four hardware platforms. Our evaluation highlights how perturbations across DLAS parameters can cause significant variation and across-stack interactions. The highest level observation from our evaluation is that the model size, accuracy, and inference time are not guaranteed to be correlated. Overall we make 13 key observations, including that speedups provided by compression techniques are very hardware dependent, and that compiler auto-tuning can significantly alter what the best algorithm to use for a given configuration is. With DLAS, we aim to provide a reference framework to aid machine learning and systems practitioners in reasoning about the context in which their respective DNN acceleration solutions exist in. With our evaluation strongly motivating the need for co-design, we believe that DLAS can be a valuable concept for exploring the next generation of co-designed accelerated deep learning solutions.", "url": "https://arxiv.org/abs/2311.08909"}, {"metadata": {"arXiv": "2311.08914", "Date": "Wed, 15 Nov 2023 12:36:45 ", "Title": "Efficiently Escaping Saddle Points for Non-Convex Policy Optimization", "Authors": ["Sadegh Khorasani", "Saber Salehkaleybar", "Negar Kiyavash", "Niao He", "Matthias Grossglauser"], "Categories": "cs.LG math.OC", "MSC-class": "ACM-class:I.2.6"}, "abstract": "Policy gradient (PG) is widely used in reinforcement learning due to its scalability and good performance. In recent years, several variance-reduced PG methods have been proposed with a theoretical guarantee of converging to an approximate first-order stationary point (FOSP) with the sample complexity of $O(\\epsilon^{-3})$. However, FOSPs could be bad local optima or saddle points. Moreover, these algorithms often use importance sampling (IS) weights which could impair the statistical effectiveness of variance reduction. In this paper, we propose a variance-reduced second-order method that uses second-order information in the form of Hessian vector products (HVP) and converges to an approximate second-order stationary point (SOSP) with sample complexity of $\\tilde{O}(\\epsilon^{-3})$. This rate improves the best-known sample complexity for achieving approximate SOSPs by a factor of $O(\\epsilon^{-0.5})$. Moreover, the proposed variance reduction technique bypasses IS weights by using HVP terms. Our experimental results show that the proposed algorithm outperforms the state of the art and is more robust to changes in random seeds.", "url": "https://arxiv.org/abs/2311.08914"}, {"metadata": {"arXiv": "2311.08936", "Date": "Wed, 15 Nov 2023 13:19:02 ", "Title": "Confident Naturalness Explanation (CNE): A Framework to Explain and Assess Patterns Forming Naturalness", "Authors": ["Ahmed Emam", "Mohamed Farag", "Ribana Roscher"], "Categories": "cs.LG cs.CV"}, "abstract": "Protected natural areas are regions that have been minimally affected by human activities such as urbanization, agriculture, and other human interventions. To better understand and map the naturalness of these areas, machine learning models can be used to analyze satellite imagery. Specifically, explainable machine learning methods show promise in uncovering patterns that contribute to the concept of naturalness within these protected environments. Additionally, addressing the uncertainty inherent in machine learning models is crucial for a comprehensive understanding of this concept. However, existing approaches have limitations. They either fail to provide explanations that are both valid and objective or struggle to offer a quantitative metric that accurately measures the contribution of specific patterns to naturalness, along with the associated confidence. In this paper, we propose a novel framework called the Confident Naturalness Explanation (CNE) framework. This framework combines explainable machine learning and uncertainty quantification to assess and explain naturalness. We introduce a new quantitative metric that describes the confident contribution of patterns to the concept of naturalness. Furthermore, we generate an uncertainty-aware segmentation mask for each input sample, highlighting areas where the model lacks knowledge. To demonstrate the effectiveness of our framework, we apply it to a study site in Fennoscandia using two open-source satellite datasets.", "url": "https://arxiv.org/abs/2311.08936"}, {"metadata": {"arXiv": "2311.08979", "Date": "Wed, 15 Nov 2023 14:14:26 ", "Title": "A Multimodal Dataset of 21,412 Recorded Nights for Sleep and Respiratory Research", "Authors": ["Alon Diament (1)", "Maria Gorodetski (1)", "Adam Jankelow (1)", "Ayya Keshet (2)", "Tal Shor (1)", "Daphna Weissglas-Volkov (1)", "Hagai Rossman (1) and Eran Segal (2) ((1) Pheno.AI", "Tel-Aviv", "Israel", "(2) Weizmann Institute of Science", "Rehovot", "Israel)"], "Categories": "cs.LG eess.SP", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "14 pages"]}, "abstract": "This study introduces a novel, rich dataset obtained from home sleep apnea tests using the FDA-approved WatchPAT-300 device, collected from 7,077 participants over 21,412 nights. The dataset comprises three levels of sleep data: raw multi-channel time-series from sensors, annotated sleep events, and computed summary statistics, which include 447 features related to sleep architecture, sleep apnea, and heart rate variability (HRV). We present reference values for Apnea/Hypopnea Index (AHI), sleep efficiency, Wake After Sleep Onset (WASO), and HRV sample entropy, stratified by age and sex. Moreover, we demonstrate that the dataset improves the predictive capability for various health related traits, including body composition, bone density, blood sugar levels and cardiovascular health. These results illustrate the dataset's potential to advance sleep research, personalized healthcare, and machine learning applications in biomedicine.", "url": "https://arxiv.org/abs/2311.08979"}, {"metadata": {"arXiv": "2311.09018", "Date": "Wed, 15 Nov 2023 15:02:23 ", "Title": "On the Foundation of Distributionally Robust Reinforcement Learning", "Authors": ["Shengbo Wang", "Nian Si", "Jose Blanchet", "Zhengyuan Zhou"], "Categories": "cs.LG cs.SY eess.SY math.OC stat.ML"}, "abstract": "Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary. These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics. Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity. Within this DRMDP framework, we investigate conditions for the existence or absence of the dynamic programming principle (DPP). From an algorithmic standpoint, the existence of DPP holds significant implications, as the vast majority of existing data and computationally efficiency RL algorithms are reliant on the DPP. To study its existence, we comprehensively examine combinations of controller and adversary attributes, providing streamlined proofs grounded in a unified methodology. We also offer counterexamples for settings in which a DPP with full generality is absent.", "url": "https://arxiv.org/abs/2311.09018"}, {"metadata": {"arXiv": "2311.09058", "Date": "Wed, 15 Nov 2023 15:50:34 ", "Title": "New Horizons in Parameter Regularization: A Constraint Approach", "Authors": ["J\\\"org K.H. Franke", "Michael Hefenbrock", "Gregor Koehler", "Frank Hutter"], "Categories": "cs.LG"}, "abstract": "This work presents constrained parameter regularization (CPR), an alternative to traditional weight decay. Instead of applying a constant penalty uniformly to all parameters, we enforce an upper bound on a statistical measure (e.g., the L$_2$-norm) of individual parameter groups. This reformulates learning as a constrained optimization problem. To solve this, we utilize an adaptation of the augmented Lagrangian method. Our approach allows for varying regularization strengths across different parameter groups, removing the need for explicit penalty coefficients in the regularization terms. CPR only requires two hyperparameters and introduces no measurable runtime overhead. We offer empirical evidence of CPR's effectiveness through experiments in the \"grokking\" phenomenon, image classification, and language modeling. Our findings show that CPR can counteract the effects of grokking, and it consistently matches or surpasses the performance of traditional weight decay.", "url": "https://arxiv.org/abs/2311.09058"}, {"metadata": {"arXiv": "2311.09128", "Date": "Wed, 15 Nov 2023 17:17:49 ", "Title": "Fast Detection of Phase Transitions with Multi-Task Learning-by-Confusion", "Authors": ["Julian Arnold", "Frank Sch\\\"afer", "Niels L\\\"orch"], "Categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech", "Comments": ["7 pages", "3 figures", "Machine Learning and the Physical Sciences Workshop", "NeurIPS 2023"]}, "abstract": "Machine learning has been successfully used to study phase transitions. One of the most popular approaches to identifying critical points from data without prior knowledge of the underlying phases is the learning-by-confusion scheme. As input, it requires system samples drawn from a grid of the parameter whose change is associated with potential phase transitions. Up to now, the scheme required training a distinct binary classifier for each possible splitting of the grid into two sides, resulting in a computational cost that scales linearly with the number of grid points. In this work, we propose and showcase an alternative implementation that only requires the training of a single multi-class classifier. Ideally, such multi-task learning eliminates the scaling with respect to the number of grid points. In applications to the Ising model and an image dataset generated with Stable Diffusion, we find significant speedups that closely correspond to the ideal case, with only minor deviations.", "url": "https://arxiv.org/abs/2311.09128"}, {"metadata": {"arXiv": "2311.09137", "Date": "Wed, 15 Nov 2023 17:29:24 ", "Title": "Causal prediction models for medication safety monitoring: The diagnosis of vancomycin-induced acute kidney injury", "Authors": ["Izak Yasrebi-de Kom", "Joanna Klopotowska", "Dave Dongelmans", "Nicolette De Keizer", "Kitty Jager", "Ameen Abu-Hanna", "Giovanni Cin\\`a"], "Categories": "cs.LG stat.ME", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "14 pages"]}, "abstract": "The current best practice approach for the retrospective diagnosis of adverse drug events (ADEs) in hospitalized patients relies on a full patient chart review and a formal causality assessment by multiple medical experts. This evaluation serves to qualitatively estimate the probability of causation (PC); the probability that a drug was a necessary cause of an adverse event. This practice is manual, resource intensive and prone to human biases, and may thus benefit from data-driven decision support. Here, we pioneer a causal modeling approach using observational data to estimate a lower bound of the PC (PC$_{low}$). This method includes two key causal inference components: (1) the target trial emulation framework and (2) estimation of individualized treatment effects using machine learning. We apply our method to the clinically relevant use-case of vancomycin-induced acute kidney injury in intensive care patients, and compare our causal model-based PC$_{low}$ estimates to qualitative estimates of the PC provided by a medical expert. Important limitations and potential improvements are discussed, and we conclude that future improved causal models could provide essential data-driven support for medication safety monitoring in hospitalized patients.", "url": "https://arxiv.org/abs/2311.09137"}, {"metadata": {"arXiv": "2311.09142", "Date": "Wed, 15 Nov 2023 17:39:25 ", "Title": "Machine-learning parameter tracking with partial state observation", "Authors": ["Zheng-Meng Zhai", "Mohammadamin Moradi", "Bryan Glaz", "Mulugeta Haile", "and Ying-Cheng Lai"], "Categories": "cs.LG math.DS nlin.CD physics.comp-ph", "Comments": ["5 pages", "4 figures"]}, "abstract": "Complex and nonlinear dynamical systems often involve parameters that change with time, accurate tracking of which is essential to tasks such as state estimation, prediction, and control. Existing machine-learning methods require full state observation of the underlying system and tacitly assume adiabatic changes in the parameter. Formulating an inverse problem and exploiting reservoir computing, we develop a model-free and fully data-driven framework to accurately track time-varying parameters from partial state observation in real time. In particular, with training data from a subset of the dynamical variables of the system for a small number of known parameter values, the framework is able to accurately predict the parameter variations in time. Low- and high-dimensional, Markovian and non-Markovian nonlinear dynamical systems are used to demonstrate the power of the machine-learning based parameter-tracking framework. Pertinent issues affecting the tracking performance are addressed.", "url": "https://arxiv.org/abs/2311.09142"}, {"metadata": {"arXiv": "2311.09145", "Date": "Wed, 15 Nov 2023 17:40:48 ", "Title": "Model Agnostic Explainable Selective Regression via Uncertainty Estimation", "Authors": ["Andrea Pugnana", "Carlos Mougan", "Dan Saattrup Nielsen"], "Categories": "cs.LG stat.ML"}, "abstract": "With the wide adoption of machine learning techniques, requirements have evolved beyond sheer high performance, often requiring models to be trustworthy. A common approach to increase the trustworthiness of such systems is to allow them to refrain from predicting. Such a framework is known as selective prediction. While selective prediction for classification tasks has been widely analyzed, the problem of selective regression is understudied. This paper presents a novel approach to selective regression that utilizes model-agnostic non-parametric uncertainty estimation. Our proposed framework showcases superior performance compared to state-of-the-art selective regressors, as demonstrated through comprehensive benchmarking on 69 datasets. Finally, we use explainable AI techniques to gain an understanding of the drivers behind selective regression. We implement our selective regression method in the open-source Python package doubt and release the code used to reproduce our experiments.", "url": "https://arxiv.org/abs/2311.09145"}, {"metadata": {"arXiv": "2311.09165", "Date": "Wed, 15 Nov 2023 18:05:31 ", "Title": "Approaching adverse event detection utilizing transformers on clinical time-series", "Authors": ["Helge Fredriksen (1)", "Per Joel Burman (2)", "Ashenafi Woldaregay (2)", "Karl {\\O}yvind Mikalsen (2)", "St{\\aa}le Nymo (3) ((1) UiT - The Arctic University of Norway", "(2) The Norwegian Centre for Clinical Artificial Intelligence", "(3) Nordland Hospital Trust)"], "Categories": "cs.LG", "Comments": ["10 pages", "6 figures"]}, "abstract": "Patients being admitted to a hospital will most often be associated with a certain clinical development during their stay. However, there is always a risk of patients being subject to the wrong diagnosis or to a certain treatment not pertaining to the desired effect, potentially leading to adverse events. Our research aims to develop an anomaly detection system for identifying deviations from expected clinical trajectories. To address this goal we analyzed 16 months of vital sign recordings obtained from the Nordland Hospital Trust (NHT). We employed an self-supervised framework based on the STraTS transformer architecture to represent the time series data in a latent space. These representations were then subjected to various clustering techniques to explore potential patient phenotypes based on their clinical progress. While our preliminary results from this ongoing research are promising, they underscore the importance of enhancing the dataset with additional demographic information from patients. This additional data will be crucial for a more comprehensive evaluation of the method's performance.", "url": "https://arxiv.org/abs/2311.09165"}, {"metadata": {"arXiv": "2311.09195", "Date": "Wed, 15 Nov 2023 18:40:10 ", "Title": "Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge", "Authors": ["Sang-Hyun Lee and Seung-Woo Seo"], "Categories": "cs.LG cs.RO", "Comments": ["8 pages", "5 figures"]}, "abstract": "A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode. This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously. Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies. While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions. In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge. Our curriculum empowers the agent to autonomously reset to diverse and informative initial states. To achieve this, we introduce a success discriminator that estimates the success probability from each initial state when the agent follows the forward policy. The success discriminator is trained with relabeled transitions in a self-supervised manner. Our experimental results demonstrate that our ARL algorithm can generate an adaptive curriculum and enable the agent to efficiently bootstrap to solve sparse-reward maze navigation tasks, outperforming baselines with significantly fewer manual resets.", "url": "https://arxiv.org/abs/2311.09195"}, {"metadata": {"arXiv": "2311.09197", "Date": "Wed, 15 Nov 2023 18:41:19 ", "Title": "A Unified Approach to Learning Ising Models: Beyond Independence and Bounded Width", "Authors": ["Jason Gaitonde and Elchanan Mossel"], "Categories": "cs.LG cs.DS stat.ML", "Comments": ["51 pages"]}, "abstract": "We revisit the problem of efficiently learning the underlying parameters of Ising models from data. Current algorithmic approaches achieve essentially optimal sample complexity when given i.i.d. samples from the stationary measure and the underlying model satisfies \"width\" bounds on the total $\\ell_1$ interaction involving each node. We show that a simple existing approach based on node-wise logistic regression provably succeeds at recovering the underlying model in several new settings where these assumptions are violated: (1) Given dynamically generated data from a wide variety of local Markov chains, like block or round-robin dynamics, logistic regression recovers the parameters with optimal sample complexity up to $\\log\\log n$ factors. This generalizes the specialized algorithm of Bresler, Gamarnik, and Shah [IEEE Trans. Inf. Theory'18] for structure recovery in bounded degree graphs from Glauber dynamics. (2) For the Sherrington-Kirkpatrick model of spin glasses, given $\\mathsf{poly}(n)$ independent samples, logistic regression recovers the parameters in most of the known high-temperature regime via a simple reduction to weaker structural properties of the measure. This improves on recent work of Anari, Jain, Koehler, Pham, and Vuong [ArXiv'23] which gives distribution learning at higher temperature. (3) As a simple byproduct of our techniques, logistic regression achieves an exponential improvement in learning from samples in the M-regime of data considered by Dutt, Lokhov, Vuffray, and Misra [ICML'21] as well as novel guarantees for learning from the adversarial Glauber dynamics of Chin, Moitra, Mossel, and Sandon [ArXiv'23]. Our approach thus significantly generalizes the elegant analysis of Wu, Sanghavi, and Dimakis [Neurips'19] without any algorithmic modification.", "url": "https://arxiv.org/abs/2311.09197"}, {"metadata": {"arXiv": "2311.08530", "Date": "Tue, 14 Nov 2023 20:55:40 ", "Title": "SceneScore: Learning a Cost Function for Object Arrangement", "Authors": ["Ivan Kapelyukh", "Edward Johns"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["Presented at CoRL 2023 LEAP Workshop. Webpage: https://sites.google.com/view/scenescore"]}, "abstract": "Arranging objects correctly is a key capability for robots which unlocks a wide range of useful tasks. A prerequisite for creating successful arrangements is the ability to evaluate the desirability of a given arrangement. Our method \"SceneScore\" learns a cost function for arrangements, such that desirable, human-like arrangements have a low cost. We learn the distribution of training arrangements offline using an energy-based model, solely from example images without requiring environment interaction or human supervision. Our model is represented by a graph neural network which learns object-object relations, using graphs constructed from images. Experiments demonstrate that the learned cost function can be used to predict poses for missing objects, generalise to novel objects using semantic features, and can be composed with other cost functions to satisfy constraints at inference time.", "url": "https://arxiv.org/abs/2311.08530"}, {"metadata": {"arXiv": "2311.08536", "Date": "Tue, 14 Nov 2023 21:02:27 ", "Title": "Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism", "Authors": ["Amanie Azzam", "Saba Sanami", "and Amir G. Aghdam"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "Non-intrusive Load Monitoring (NILM) is an established technique for effective and cost-efficient electricity consumption management. The method is used to estimate appliance-level power consumption from aggregated power measurements. This paper presents a hybrid learning approach, consisting of a convolutional neural network (CNN) and a bidirectional long short-term memory (BILSTM), featuring an integrated attention mechanism, all within the context of disaggregating low-frequency power data. While prior research has been mainly focused on high-frequency data disaggregation, our study takes a distinct direction by concentrating on low-frequency data. The proposed hybrid CNN-BILSTM model is adept at extracting both temporal (time-related) and spatial (location-related) features, allowing it to precisely identify energy consumption patterns at the appliance level. This accuracy is further enhanced by the attention mechanism, which aids the model in pinpointing crucial parts of the data for more precise event detection and load disaggregation. We conduct simulations using the existing low-frequency REDD dataset to assess our model performance. The results demonstrate that our proposed approach outperforms existing methods in terms of accuracy and computation time.", "url": "https://arxiv.org/abs/2311.08536"}, {"metadata": {"arXiv": "2311.08547", "Date": "Tue, 14 Nov 2023 21:20:23 ", "Title": "DeepThought: An Architecture for Autonomous Self-motivated Systems", "Authors": ["Arlindo L. Oliveira", "Tiago Domingos", "M\\'ario Figueiredo", "Pedro U. Lima"], "Categories": "cs.AI", "ACM-class": "I.2"}, "abstract": "The ability of large language models (LLMs) to engage in credible dialogues with humans, taking into account the training data and the context of the conversation, has raised discussions about their ability to exhibit intrinsic motivations, agency, or even some degree of consciousness. We argue that the internal architecture of LLMs and their finite and volatile state cannot support any of these properties. By combining insights from complementary learning systems, global neuronal workspace, and attention schema theories, we propose to integrate LLMs and other deep learning systems into an architecture for cognitive language agents able to exhibit properties akin to agency, self-motivation, even some features of meta-cognition.", "url": "https://arxiv.org/abs/2311.08547"}, {"metadata": {"arXiv": "2311.08702", "Date": "Wed, 15 Nov 2023 05:05:40 ", "Title": "Debate Helps Supervise Unreliable Experts", "Authors": ["Julian Michael", "Salsabila Mahdi", "David Rein", "Jackson Petty", "Julien Dirani", "Vishakh Padmakumar", "Samuel R. Bowman"], "Categories": "cs.AI cs.CL", "Comments": ["84 pages", "13 footnotes", "5 figures", "4 tables", "28 debate transcripts; data and code at https://github.com/julianmichael/debate/tree/2023-nyu-experiments"], "ACM-class": "I.2.0"}, "abstract": "As AI systems are used to answer more difficult questions and potentially help create new knowledge, judging the truthfulness of their outputs becomes more difficult and more important. How can we supervise unreliable experts, which have access to the truth but may not accurately report it, to give answers that are systematically true and don't just superficially seem true, when the supervisor can't tell the difference between the two on their own? In this work, we show that debate between two unreliable experts can help a non-expert judge more reliably identify the truth. We collect a dataset of human-written debates on hard reading comprehension questions where the judge has not read the source passage, only ever seeing expert arguments and short quotes selectively revealed by 'expert' debaters who have access to the passage. In our debates, one expert argues for the correct answer, and the other for an incorrect answer. Comparing debate to a baseline we call consultancy, where a single expert argues for only one answer which is correct half of the time, we find that debate performs significantly better, with 84% judge accuracy compared to consultancy's 74%. Debates are also more efficient, being 68% of the length of consultancies. By comparing human to AI debaters, we find evidence that with more skilled (in this case, human) debaters, the performance of debate goes up but the performance of consultancy goes down. Our error analysis also supports this trend, with 46% of errors in human debate attributable to mistakes by the honest debater (which should go away with increased skill); whereas 52% of errors in human consultancy are due to debaters obfuscating the relevant evidence from the judge (which should become worse with increased skill). Overall, these results show that debate is a promising approach for supervising increasingly capable but potentially unreliable AI systems.", "url": "https://arxiv.org/abs/2311.08702"}, {"metadata": {"arXiv": "2311.08760", "Date": "Wed, 15 Nov 2023 08:06:51 ", "Title": "Forms of Understanding of XAI-Explanations", "Authors": ["Hendrik Buschmeier", "Heike M. Buhl", "Friederike Kern", "Angela Grimminger", "Helen Beierling", "Josephine Fisher", "Andr\\'e Gro{\\ss}", "Ilona Horwath", "Nils Klowait", "Stefan Lazarov", "Michael Lenke", "Vivien Lohmer", "Katharina Rohlfing", "Ingrid Scharlau", "Amit Singh", "Lutz Terfloth", "Anna-Lisa Vollmer", "Yu Wang", "Annedore Wilmes", "Britta Wrede"], "Categories": "cs.AI"}, "abstract": "Explainability has become an important topic in computer science and artificial intelligence, leading to a subfield called Explainable Artificial Intelligence (XAI). The goal of providing or seeking explanations is to achieve (better) 'understanding' on the part of the explainee. However, what it means to 'understand' is still not clearly defined, and the concept itself is rarely the subject of scientific investigation. This conceptual article aims to present a model of forms of understanding in the context of XAI and beyond. From an interdisciplinary perspective bringing together computer science, linguistics, sociology, and psychology, a definition of understanding and its forms, assessment, and dynamics during the process of giving everyday explanations are explored. Two types of understanding are considered as possible outcomes of explanations, namely enabledness, 'knowing how' to do or decide something, and comprehension, 'knowing that' -- both in different degrees (from shallow to deep). Explanations regularly start with shallow understanding in a specific domain and can lead to deep comprehension and enabledness of the explanandum, which we see as a prerequisite for human users to gain agency. In this process, the increase of comprehension and enabledness are highly interdependent. Against the background of this systematization, special challenges of understanding in XAI are discussed.", "url": "https://arxiv.org/abs/2311.08760"}, {"metadata": {"arXiv": "2311.08768", "Date": "Wed, 15 Nov 2023 08:24:41 ", "Title": "Three Conjectures on Unexpectedeness", "Authors": ["Giovanni Sileno", "Jean-Louis Dessalles"], "Categories": "cs.AI cs.CL cs.IT cs.SY eess.SY math.IT", "Comments": ["Working paper"]}, "abstract": "Unexpectedness is a central concept in Simplicity Theory, a theory of cognition relating various inferential processes to the computation of Kolmogorov complexities, rather than probabilities. Its predictive power has been confirmed by several experiments with human subjects, yet its theoretical basis remains largely unexplored: why does it work? This paper lays the groundwork for three theoretical conjectures. First, unexpectedness can be seen as a generalization of Bayes' rule. Second, the frequentist core of unexpectedness can be connected to the function of tracking ergodic properties of the world. Third, unexpectedness can be seen as constituent of various measures of divergence between the entropy of the world (environment) and the variety of the observer (system). The resulting framework hints to research directions that go beyond the division between probabilistic and logical approaches, potentially bringing new insights into the extraction of causal relations, and into the role of descriptive mechanisms in learning.", "url": "https://arxiv.org/abs/2311.08768"}, {"metadata": {"arXiv": "2311.08834", "Date": "Wed, 15 Nov 2023 10:22:34 ", "Title": "A* search algorithm for an optimal investment problem in vehicle-sharing systems", "Authors": ["Ba Luat Le", "Layla Martin", "Emrah Demir", "and Duc Minh Vu"], "Categories": "cs.AI", "Comments": ["Full version of the conference paper which is accepted to be appear in the proceeding of the The 12th International Conference on Computational Data and Social Networks - SCONET2023"]}, "abstract": "We study an optimal investment problem that arises in the context of the vehicle-sharing system. Given a set of locations to build stations, we need to determine i) the sequence of stations to be built and the number of vehicles to acquire in order to obtain the target state where all stations are built, and ii) the number of vehicles to acquire and their allocation in order to maximize the total profit returned by operating the system when some or all stations are open. The profitability associated with operating open stations, measured over a specific time period, is represented as a linear optimization problem applied to a collection of open stations. With operating capital, the owner of the system can open new stations. This property introduces a set-dependent aspect to the duration required for opening a new station, and the optimal investment problem can be viewed as a variant of the Traveling Salesman Problem (TSP) with set-dependent cost. We propose an A* search algorithm to address this particular variant of the TSP. Computational experiments highlight the benefits of the proposed algorithm in comparison to the widely recognized Dijkstra algorithm and propose future research to explore new possibilities and applications for both exact and approximate A* algorithms.", "url": "https://arxiv.org/abs/2311.08834"}, {"metadata": {"arXiv": "2311.08856", "Date": "Wed, 15 Nov 2023 10:46:55 ", "Title": "Advances in ACL2 Proof Debugging Tools", "Authors": ["Matt Kaufmann (UT Austin", "retired)", "J Strother Moore (UT Austin", "retired)"], "Categories": "cs.AI cs.LO cs.SE", "Comments": ["In Proceedings ACL2-2023", "arXiv:2311.08373"], "Journal-ref": "EPTCS 393, 2023, pp. 67-81", "DOI": "10.4204/EPTCS.393.7"}, "abstract": "The experience of an ACL2 user generally includes many failed proof attempts. A key to successful use of the ACL2 prover is the effective use of tools to debug those failures. We focus on changes made after ACL2 Version 8.5: the improved break-rewrite utility and the new utility, with-brr-data.", "url": "https://arxiv.org/abs/2311.08856"}, {"metadata": {"arXiv": "2311.08987", "Date": "Wed, 15 Nov 2023 14:20:56 ", "Title": "Proceedings Fifth International Workshop on Formal Methods for Autonomous Systems", "Authors": ["Marie Farrell (University of Manchester", "UK)", "Matt Luckcuck (University of Nottingham", "UK)", "Mario Gleirscher (University of Bremen", "Germany)", "Maike Schwammberger (Karlsruhe Institute of Technology", "Germany)"], "Categories": "cs.AI cs.RO", "Journal-ref": "EPTCS 395, 2023", "DOI": "10.4204/EPTCS.395"}, "abstract": "This EPTCS volume contains the proceedings for the Fifth International Workshop on Formal Methods for Autonomous Systems (FMAS 2023), which was held on the 15th and 16th of November 2023. FMAS 2023 was co-located with 18th International Conference on integrated Formal Methods (iFM) (iFM'22), organised by Leiden Institute of Advanced Computer Science of Leiden University. The workshop itself was held at Scheltema Leiden, a renovated 19th Century blanket factory alongside the canal. FMAS 2023 received 25 submissions. We received 11 regular papers, 3 experience reports, 6 research previews, and 5 vision papers. The researchers who submitted papers to FMAS 2023 were from institutions in: Australia, Canada, Colombia, France, Germany, Ireland, Italy, the Netherlands, Sweden, the United Kingdom, and the United States of America. Increasing our number of submissions for the third year in a row is an encouraging sign that FMAS has established itself as a reputable publication venue for research on the formal modelling and verification of autonomous systems. After each paper was reviewed by three members of our Programme Committee we accepted a total of 15 papers: 8 long papers and 7 short papers.", "url": "https://arxiv.org/abs/2311.08987"}, {"metadata": {"arXiv": "2311.08999", "Date": "Wed, 15 Nov 2023 14:38:41 ", "Title": "Leveraging AI for Natural Disaster Management : Takeaways From The Moroccan Earthquake", "Authors": ["Morocco Solidarity Hackathon (Organizers", "Speakers", "Mentors and Participant teams)"], "Categories": "cs.AI"}, "abstract": "The devastating 6.8-magnitude earthquake in Al Haouz, Morocco in 2023 prompted critical reflections on global disaster management strategies, resulting in a post-disaster hackathon, using artificial intelligence (AI) to improve disaster preparedness, response, and recovery. This paper provides (i) a comprehensive literature review, (ii) an overview of winning projects, (iii) key insights and challenges, namely real-time open-source data, data scarcity, and interdisciplinary collaboration barriers, and (iv) a community-call for further action.", "url": "https://arxiv.org/abs/2311.08999"}, {"metadata": {"arXiv": "2311.08525", "Date": "Tue, 14 Nov 2023 20:37:54 ", "Title": "Efficient Rotation Invariance in Deep Neural Networks through Artificial Mental Rotation", "Authors": ["Lukas Tuggener", "Thilo Stadelmann", "J\\\"urgen Schmidhuber"], "Categories": "cs.CV cs.AI"}, "abstract": "Humans and animals recognize objects irrespective of the beholder's point of view, which may drastically change their appearances. Artificial pattern recognizers also strive to achieve this, e.g., through translational invariance in convolutional neural networks (CNNs). However, both CNNs and vision transformers (ViTs) perform very poorly on rotated inputs. Here we present artificial mental rotation (AMR), a novel deep learning paradigm for dealing with in-plane rotations inspired by the neuro-psychological concept of mental rotation. Our simple AMR implementation works with all common CNN and ViT architectures. We test it on ImageNet, Stanford Cars, and Oxford Pet. With a top-1 error (averaged across datasets and architectures) of $0.743$, AMR outperforms the current state of the art (rotational data augmentation, average top-1 error of $0.626$) by $19\\%$. We also easily transfer a trained AMR module to a downstream task to improve the performance of a pre-trained semantic segmentation model on rotated CoCo from $32.7$ to $55.2$ IoU.", "url": "https://arxiv.org/abs/2311.08525"}, {"metadata": {"arXiv": "2311.08577", "Date": "Tue, 14 Nov 2023 22:46:01 ", "Title": "Finding AI-Generated Faces in the Wild", "Authors": ["Gonzalo J. Aniano Porcile", "Jack Gindi", "Shivansh Mundra", "James R. Verbus", "Hany Farid"], "Categories": "cs.CV cs.AI"}, "abstract": "AI-based image generation has continued to rapidly improve, producing increasingly more realistic images with fewer obvious visual flaws. AI-generated images are being used to create fake online profiles which in turn are being used for spam, fraud, and disinformation campaigns. As the general problem of detecting any type of manipulated or synthesized content is receiving increasing attention, here we focus on a more narrow task of distinguishing a real face from an AI-generated face. This is particularly applicable when tackling inauthentic online accounts with a fake user profile photo. We show that by focusing on only faces, a more resilient and general-purpose artifact can be detected that allows for the detection of AI-generated faces from a variety of GAN- and diffusion-based synthesis engines, and across image resolutions (as low as 128 x 128 pixels) and qualities.", "url": "https://arxiv.org/abs/2311.08577"}, {"metadata": {"arXiv": "2311.08764", "Date": "Wed, 15 Nov 2023 08:13:52 ", "Title": "Combining Past, Present and Future: A Self-Supervised Approach for Class Incremental Learning", "Authors": ["Xiaoshuang Chen", "Zhongyi Sun", "Ke Yan", "Shouhong Ding", "Hongtao Lu"], "Categories": "cs.CV cs.AI"}, "abstract": "Class Incremental Learning (CIL) aims to handle the scenario where data of novel classes occur continuously and sequentially. The model should recognize the sequential novel classes while alleviating the catastrophic forgetting. In the self-supervised manner, it becomes more challenging to avoid the conflict between the feature embedding spaces of novel classes and old ones without any class labels. To address the problem, we propose a self-supervised CIL framework CPPF, meaning Combining Past, Present and Future. In detail, CPPF consists of a prototype clustering module (PC), an embedding space reserving module (ESR) and a multi-teacher distillation module (MTD). 1) The PC and the ESR modules reserve embedding space for subsequent phases at the prototype level and the feature level respectively to prepare for knowledge learned in the future. 2) The MTD module maintains the representations of the current phase without the interference of past knowledge. One of the teacher networks retains the representations of the past phases, and the other teacher network distills relation information of the current phase to the student network. Extensive experiments on CIFAR100 and ImageNet100 datasets demonstrate that our proposed method boosts the performance of self-supervised class incremental learning. We will release code in the near future.", "url": "https://arxiv.org/abs/2311.08764"}, {"metadata": {"arXiv": "2311.08806", "Date": "Wed, 15 Nov 2023 09:22:52 ", "Title": "SparseSpikformer: A Co-Design Framework for Token and Weight Pruning in Spiking Transformer", "Authors": ["Yue Liu", "Shanlin Xiao", "Bo Li", "Zhiyi Yu"], "Categories": "cs.CV cs.AI"}, "abstract": "As the third-generation neural network, the Spiking Neural Network (SNN) has the advantages of low power consumption and high energy efficiency, making it suitable for implementation on edge devices. More recently, the most advanced SNN, Spikformer, combines the self-attention module from Transformer with SNN to achieve remarkable performance. However, it adopts larger channel dimensions in MLP layers, leading to an increased number of redundant model parameters. To effectively decrease the computational complexity and weight parameters of the model, we explore the Lottery Ticket Hypothesis (LTH) and discover a very sparse ($\\ge$90%) subnetwork that achieves comparable performance to the original network. Furthermore, we also design a lightweight token selector module, which can remove unimportant background information from images based on the average spike firing rate of neurons, selecting only essential foreground image tokens to participate in attention calculation. Based on that, we present SparseSpikformer, a co-design framework aimed at achieving sparsity in Spikformer through token and weight pruning techniques. Experimental results demonstrate that our framework can significantly reduce 90% model parameters and cut down Giga Floating-Point Operations (GFLOPs) by 20% while maintaining the accuracy of the original model.", "url": "https://arxiv.org/abs/2311.08806"}, {"metadata": {"arXiv": "2311.08923", "Date": "Wed, 15 Nov 2023 12:55:19 ", "Title": "Leveraging Activation Maximization and Generative Adversarial Training to Recognize and Explain Patterns in Natural Areas in Satellite Imagery", "Authors": ["Ahmed Emam", "Timo T. Stomberg", "Ribana Roscher"], "Categories": "cs.CV cs.AI"}, "abstract": "Natural protected areas are vital for biodiversity, climate change mitigation, and supporting ecological processes. Despite their significance, comprehensive mapping is hindered by a lack of understanding of their characteristics and a missing land cover class definition. This paper aims to advance the explanation of the designating patterns forming protected and wild areas. To this end, we propose a novel framework that uses activation maximization and a generative adversarial model. With this, we aim to generate satellite images that, in combination with domain knowledge, are capable of offering complete and valid explanations for the spatial and spectral patterns that define the natural authenticity of these regions. Our proposed framework produces more precise attribution maps pinpointing the designating patterns forming the natural authenticity of protected areas. Our approach fosters our understanding of the ecological integrity of the protected natural areas and may contribute to future monitoring and preservation efforts.", "url": "https://arxiv.org/abs/2311.08923"}, {"metadata": {"arXiv": "2311.09050", "Date": "Wed, 15 Nov 2023 15:40:46 ", "Title": "Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts", "Authors": ["Yunshi Lan", "Xiang Li", "Xin Liu", "Yang Li", "Wei Qin and Weining Qian"], "Categories": "cs.CV cs.AI"}, "abstract": "Zero-shot Visual Question Answering (VQA) is a prominent vision-language task that examines both the visual and textual understanding capability of systems in the absence of training data. Recently, by converting the images into captions, information across multi-modalities is bridged and Large Language Models (LLMs) can apply their strong zero-shot generalization capability to unseen questions. To design ideal prompts for solving VQA via LLMs, several studies have explored different strategies to select or generate question-answer pairs as the exemplar prompts, which guide LLMs to answer the current questions effectively. However, they totally ignore the role of question prompts. The original questions in VQA tasks usually encounter ellipses and ambiguity which require intermediate reasoning. To this end, we present Reasoning Question Prompts for VQA tasks, which can further activate the potential of LLMs in zero-shot scenarios. Specifically, for each question, we first generate self-contained questions as reasoning question prompts via an unsupervised question edition module considering sentence fluency, semantic integrity and syntactic invariance. Each reasoning question prompt clearly indicates the intent of the original question. This results in a set of candidate answers. Then, the candidate answers associated with their confidence scores acting as answer heuristics are fed into LLMs and produce the final answer. We evaluate reasoning question prompts on three VQA challenges, experimental results demonstrate that they can significantly improve the results of LLMs on zero-shot setting and outperform existing state-of-the-art zero-shot methods on three out of four data sets. Our source code is publicly released at \\url{https://github.com/ECNU-DASE-NLP/RQP}.", "url": "https://arxiv.org/abs/2311.09050"}, {"metadata": {"arXiv": "2311.08410", "Date": "Tue, 17 Oct 2023 09:07:16 ", "Title": "Exploration of the Assessment for AVP Algorithm Training in Underground Parking Garages Simulation Scenario", "Authors": ["Wenjin Li"], "Categories": "cs.RO cs.AI cs.SY"}, "abstract": "The autonomous valet parking (AVP) functionality in self-driving vehicles is currently capable of handling most simple parking tasks. However, further training is necessary to enable the AVP algorithm to adapt to complex scenarios and complete parking tasks in any given situation. Training algorithms with real-world data is time-consuming and labour-intensive, and the current state of constructing simulation environments is predominantly manual. This paper introduces an approach to automatically generate 3D underground garage simulation scenarios of varying difficulty levels based on pre-input 2D underground parking structure plans.", "url": "https://arxiv.org/abs/2311.08410"}, {"metadata": {"arXiv": "2311.08412", "Date": "Thu, 19 Oct 2023 14:20:30 ", "Title": "Exploring Large Language Models as a Source of Common-Sense Knowledge for Robots", "Authors": ["Felix Ocker and J\\\"org Deigm\\\"oller and Julian Eggert"], "Categories": "cs.RO cs.AI", "Comments": ["Accepted at ISWC 2023 Posters and Demos: 22nd International Semantic Web Conference", "November 6-10", "2023", "Athens", "Greece"]}, "abstract": "Service robots need common-sense knowledge to help humans in everyday situations as it enables them to understand the context of their actions. However, approaches that use ontologies face a challenge because common-sense knowledge is often implicit, i.e., it is obvious to humans but not explicitly stated. This paper investigates if Large Language Models (LLMs) can fill this gap. Our experiments reveal limited effectiveness in the selective extraction of contextual action knowledge, suggesting that LLMs may not be sufficient on their own. However, the large-scale extraction of general, actionable knowledge shows potential, indicating that LLMs can be a suitable tool for efficiently creating ontologies for robots. This paper shows that the technique used for knowledge extraction can be applied to populate a minimalist ontology, showcasing the potential of LLMs in synergy with formal knowledge representation.", "url": "https://arxiv.org/abs/2311.08412"}, {"metadata": {"arXiv": "2311.08783", "Date": "Wed, 15 Nov 2023 08:55:19 ", "Title": "ICRA Roboethics Challenge 2023: Intelligent Disobedience in an Elderly Care Home", "Authors": ["Sveta Paster", "Kantwon Rogers", "Gordon Briggs", "Peter Stone", "Reuth Mirsky"], "Categories": "cs.RO cs.AI", "Comments": ["This report is part of ICRA roboethics competition : https://competition.raiselab.ca/competition-details-2023_1/ethics-challenge/submitted-proposals/submission-1"]}, "abstract": "With the projected surge in the elderly population, service robots offer a promising avenue to enhance their well-being in elderly care homes. Such robots will encounter complex scenarios which will require them to perform decisions with ethical consequences. In this report, we propose to leverage the Intelligent Disobedience framework in order to give the robot the ability to perform a deliberation process over decisions with potential ethical implications. We list the issues that this framework can assist with, define it formally in the context of the specific elderly care home scenario, and delineate the requirements for implementing an intelligently disobeying robot. We conclude this report with some critical analysis and suggestions for future work.", "url": "https://arxiv.org/abs/2311.08783"}, {"metadata": {"arXiv": "2311.08957", "Date": "Wed, 15 Nov 2023 13:47:00 ", "Title": "I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots", "Authors": ["Giulio Antonio Abbo and Tony Belpaeme"], "Categories": "cs.RO cs.AI cs.HC", "Comments": ["8 pages", "3 figures"]}, "abstract": "In the rapidly evolving landscape of human-computer interaction, the integration of vision capabilities into conversational agents stands as a crucial advancement. This paper presents an initial implementation of a dialogue manager that leverages the latest progress in Large Language Models (e.g., GPT-4, IDEFICS) to enhance the traditional text-based prompts with real-time visual input. LLMs are used to interpret both textual prompts and visual stimuli, creating a more contextually aware conversational agent. The system's prompt engineering, incorporating dialogue with summarisation of the images, ensures a balance between context preservation and computational efficiency. Six interactions with a Furhat robot powered by this system are reported, illustrating and discussing the results obtained. By implementing this vision-enabled dialogue system, the paper envisions a future where conversational agents seamlessly blend textual and visual modalities, enabling richer, more context-aware dialogues.", "url": "https://arxiv.org/abs/2311.08957"}, {"metadata": {"arXiv": "2311.08820", "Date": "Wed, 15 Nov 2023 09:50:54 ", "Title": "Reinforcement Learning with Model Predictive Control for Highway Ramp Metering", "Authors": ["Filippo Airaldi and Bart De Schutter and Azita Dabiri"], "Categories": "eess.SY cs.AI cs.SY", "Comments": ["14 pages", "10 figures", "3 tables", "submitted to IEEE Transactions on Intelligent Transportation Systems"]}, "abstract": "In the backdrop of an increasingly pressing need for effective urban and highway transportation systems, this work explores the synergy between model-based and learning-based strategies to enhance traffic flow management by use of an innovative approach to the problem of highway ramp metering control that embeds Reinforcement Learning techniques within the Model Predictive Control framework. The control problem is formulated as an RL task by crafting a suitable stage cost function that is representative of the traffic conditions, variability in the control action, and violations of a safety-critical constraint on the maximum number of vehicles in queue. An MPC-based RL approach, which merges the advantages of the two paradigms in order to overcome the shortcomings of each framework, is proposed to learn to efficiently control an on-ramp and to satisfy its constraints despite uncertainties in the system model and variable demands. Finally, simulations are performed on a benchmark from the literature consisting of a small-scale highway network. Results show that, starting from an MPC controller that has an imprecise model and is poorly tuned, the proposed methodology is able to effectively learn to improve the control policy such that congestion in the network is reduced and constraints are satisfied, yielding an improved performance compared to the initial controller.", "url": "https://arxiv.org/abs/2311.08820"}, {"metadata": {"arXiv": "2311.08516", "Date": "Tue, 14 Nov 2023 20:12:38 ", "Title": "LLMs cannot find reasoning errors, but can correct them!", "Authors": ["Gladys Tyen", "Hassan Mansoor", "Peter Chen", "Tony Mak", "Victor C\\u{a}rbune"], "Categories": "cs.AI cs.CL cs.LG"}, "abstract": "While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang et al., 2023). In this paper, we break down the self-correction process into two core components: mistake finding and output correction. For mistake finding, we release BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought reasoning traces. We provide benchmark numbers for several state-of-the-art LLMs, and demonstrate that LLMs generally struggle with finding logical mistakes. For output correction, we propose a backtracking method which provides large improvements when given information on mistake location. We construe backtracking as a lightweight alternative to reinforcement learning methods, and show that it remains effective with a reward model at 60-70% accuracy.", "url": "https://arxiv.org/abs/2311.08516"}, {"metadata": {"arXiv": "2311.08557", "Date": "Tue, 14 Nov 2023 21:39:15 ", "Title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges", "Authors": ["Hrishikesh Vachhani", "Thangarajah Akilan", "Yash Devmurari", "Nisharaff Shaik", "Dhruvisha Patel"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Pedestrian detection has become a cornerstone for several high-level tasks, including autonomous driving, intelligent transportation, and traffic surveillance. There are several works focussed on pedestrian detection using visible images, mainly in the daytime. However, this task is very intriguing when the environmental conditions change to poor lighting or nighttime. Recently, new ideas have been spurred to use alternative sources, such as Far InfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light conditions. This study comprehensively reviews recent developments in low-light pedestrian detection approaches. It systematically categorizes and analyses various algorithms from region-based to non-region-based and graph-based learning methodologies by highlighting their methodologies, implementation issues, and challenges. It also outlines the key benchmark datasets that can be used for research and development of advanced pedestrian detection algorithms, particularly in low-light situations", "url": "https://arxiv.org/abs/2311.08557"}, {"metadata": {"arXiv": "2311.08427", "Date": "Mon, 13 Nov 2023 13:23:31 ", "Title": "Towards a Transportable Causal Network Model Based on Observational Healthcare Data", "Authors": ["Alice Bernasconi and Alessio Zanga and Peter J.F. Lucas and Marco Scutari Fabio Stella"], "Categories": "cs.LG cs.AI stat.ME"}, "abstract": "Over the last decades, many prognostic models based on artificial intelligence techniques have been used to provide detailed predictions in healthcare. Unfortunately, the real-world observational data used to train and validate these models are almost always affected by biases that can strongly impact the outcomes validity: two examples are values missing not-at-random and selection bias. Addressing them is a key element in achieving transportability and in studying the causal relationships that are critical in clinical decision making, going beyond simpler statistical approaches based on probabilistic association. In this context, we propose a novel approach that combines selection diagrams, missingness graphs, causal discovery and prior knowledge into a single graphical model to estimate the cardiovascular risk of adolescent and young females who survived breast cancer. We learn this model from data comprising two different cohorts of patients. The resulting causal network model is validated by expert clinicians in terms of risk assessment, accuracy and explainability, and provides a prognostic model that outperforms competing machine learning methods.", "url": "https://arxiv.org/abs/2311.08427"}, {"metadata": {"arXiv": "2311.08430", "Date": "Tue, 14 Nov 2023 03:02:02 ", "Title": "Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale", "Authors": ["Wei Wen", "Kuang-Hung Liu", "Igor Fedorov", "Xin Zhang", "Hang Yin", "Weiwei Chu", "Kaveh Hassani", "Mengying Sun", "Jiang Liu", "Xu Wang", "Lin Jiang", "Yuxin Chen", "Buyun Zhang", "Xi Liu", "Dehua Cheng", "Zhengxing Chen", "Guang Zhao", "Fangqiu Han", "Jiyan Yang", "Yuchen Hao", "Liang Xiong", "Wen-Yen Chen"], "Categories": "cs.LG cs.AI cs.IR", "Comments": ["Wei Wen and Kuang-Hung Liu contribute equally"]}, "abstract": "Neural Architecture Search (NAS) has demonstrated its efficacy in computer vision and potential for ranking systems. However, prior work focused on academic problems, which are evaluated at small scale under well-controlled fixed baselines. In industry system, such as ranking system in Meta, it is unclear whether NAS algorithms from the literature can outperform production baselines because of: (1) scale - Meta ranking systems serve billions of users, (2) strong baselines - the baselines are production models optimized by hundreds to thousands of world-class engineers for years since the rise of deep learning, (3) dynamic baselines - engineers may have established new and stronger baselines during NAS search, and (4) efficiency - the search pipeline must yield results quickly in alignment with the productionization life cycle. In this paper, we present Rankitect, a NAS software framework for ranking systems at Meta. Rankitect seeks to build brand new architectures by composing low level building blocks from scratch. Rankitect implements and improves state-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under the same search space, including sampling-based NAS, one-shot NAS, and Differentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple production ranking models at Meta. We find that Rankitect can discover new models from scratch achieving competitive tradeoff between Normalized Entropy loss and FLOPs. When utilizing search space designed by engineers, Rankitect can generate better models than engineers, achieving positive offline evaluation and online A/B test at Meta scale.", "url": "https://arxiv.org/abs/2311.08430"}, {"metadata": {"arXiv": "2311.08434", "Date": "Tue, 14 Nov 2023 07:21:00 ", "Title": "Uplift Modeling based on Graph Neural Network Combined with Causal Knowledge", "Authors": ["Haowen Wang", "Xinyan Ye", "Yangze Zhou", "Zhiyi Zhang", "Longhan Zhang", "Jing Jiang"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["6 pages", "6 figures"]}, "abstract": "Uplift modeling is a fundamental component of marketing effect modeling, which is commonly employed to evaluate the effects of treatments on outcomes. Through uplift modeling, we can identify the treatment with the greatest benefit. On the other side, we can identify clients who are likely to make favorable decisions in response to a certain treatment. In the past, uplift modeling approaches relied heavily on the difference-in-difference (DID) architecture, paired with a machine learning model as the estimation learner, while neglecting the link and confidential information between features. We proposed a framework based on graph neural networks that combine causal knowledge with an estimate of uplift value. Firstly, we presented a causal representation technique based on CATE (conditional average treatment effect) estimation and adjacency matrix structure learning. Secondly, we suggested a more scalable uplift modeling framework based on graph convolution networks for combining causal knowledge. Our findings demonstrate that this method works effectively for predicting uplift values, with small errors in typical simulated data, and its effectiveness has been verified in actual industry marketing data.", "url": "https://arxiv.org/abs/2311.08434"}, {"metadata": {"arXiv": "2311.08568", "Date": "Tue, 14 Nov 2023 22:13:38 ", "Title": "Adversarial Imitation Learning On Aggregated Data", "Authors": ["Pierre Le Pelletier de Woillemont and R\\'emi Labory and Vincent Corruble"], "Categories": "cs.LG cs.AI"}, "abstract": "Inverse Reinforcement Learning (IRL) learns an optimal policy, given some expert demonstrations, thus avoiding the need for the tedious process of specifying a suitable reward function. However, current methods are constrained by at least one of the following requirements. The first one is the need to fully solve a forward Reinforcement Learning (RL) problem in the inner loop of the algorithm, which might be prohibitively expensive in many complex environments. The second one is the need for full trajectories from the experts, which might not be easily available. The third one is the assumption that the expert data is homogeneous rather than a collection from various experts or possibly alternative solutions to the same task. Such constraints make IRL approaches either not scalable or not usable on certain existing systems. In this work we propose an approach which removes these requirements through a dynamic, adaptive method called Adversarial Imitation Learning on Aggregated Data (AILAD). It learns conjointly both a non linear reward function and the associated optimal policy using an adversarial framework. The reward learner only uses aggregated data. Moreover, it generates diverse behaviors producing a distribution over the aggregated data matching that of the experts.", "url": "https://arxiv.org/abs/2311.08568"}, {"metadata": {"arXiv": "2311.08576", "Date": "Tue, 14 Nov 2023 22:45:44 ", "Title": "Towards Evaluating AI Systems for Moral Status Using Self-Reports", "Authors": ["Ethan Perez and Robert Long"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "As AI systems become more advanced and widely deployed, there will likely be increasing debate over whether AI systems could have conscious experiences, desires, or other states of potential moral significance. It is important to inform these discussions with empirical evidence to the extent possible. We argue that under the right circumstances, self-reports, or an AI system's statements about its own internal states, could provide an avenue for investigating whether AI systems have states of moral significance. Self-reports are the main way such states are assessed in humans (\"Are you in pain?\"), but self-reports from current systems like large language models are spurious for many reasons (e.g. often just reflecting what humans would say). To make self-reports more appropriate for this purpose, we propose to train models to answer many kinds of questions about themselves with known answers, while avoiding or limiting training incentives that bias self-reports. The hope of this approach is that models will develop introspection-like capabilities, and that these capabilities will generalize to questions about states of moral significance. We then propose methods for assessing the extent to which these techniques have succeeded: evaluating self-report consistency across contexts and between similar models, measuring the confidence and resilience of models' self-reports, and using interpretability to corroborate self-reports. We also discuss challenges for our approach, from philosophical difficulties in interpreting self-reports to technical reasons why our proposal might fail. We hope our discussion inspires philosophers and AI researchers to criticize and improve our proposed methodology, as well as to run experiments to test whether self-reports can be made reliable enough to provide information about states of moral significance.", "url": "https://arxiv.org/abs/2311.08576"}, {"metadata": {"arXiv": "2311.08635", "Date": "Wed, 15 Nov 2023 01:22:47 ", "Title": "Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction", "Authors": ["Guangyin Jin", "Lingbo Liu", "Fuxian Li", "Jincai Huang"], "Categories": "cs.LG cs.AI cs.SI", "Journal-ref": "Jin, G., Liu, L., Li, F., & Huang, J. (2023). Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14268-14276", "DOI": "10.1609/aaai.v37i12.26669"}, "abstract": "Traffic congestion event prediction is an important yet challenging task in intelligent transportation systems. Many existing works about traffic prediction integrate various temporal encoders and graph convolution networks (GCNs), called spatio-temporal graph-based neural networks, which focus on predicting dense variables such as flow, speed and demand in time snapshots, but they can hardly forecast the traffic congestion events that are sparsely distributed on the continuous time axis. In recent years, neural point process (NPP) has emerged as an appropriate framework for event prediction in continuous time scenarios. However, most conventional works about NPP cannot model the complex spatio-temporal dependencies and congestion evolution patterns. To address these limitations, we propose a spatio-temporal graph neural point process framework, named STGNPP for traffic congestion event prediction. Specifically, we first design the spatio-temporal graph learning module to fully capture the long-range spatio-temporal dependencies from the historical traffic state data along with the road network. The extracted spatio-temporal hidden representation and congestion event information are then fed into a continuous gated recurrent unit to model the congestion evolution patterns. In particular, to fully exploit the periodic information, we also improve the intensity function calculation of the point process with a periodic gated mechanism. Finally, our model simultaneously predicts the occurrence time and duration of the next congestion. Extensive experiments on two real-world datasets demonstrate that our method achieves superior performance in comparison to existing state-of-the-art approaches.", "url": "https://arxiv.org/abs/2311.08635"}, {"metadata": {"arXiv": "2311.08644", "Date": "Wed, 15 Nov 2023 01:50:53 ", "Title": "Interpretable by Design: Wrapper Boxes Combine Neural Performance with Faithful Explanations", "Authors": ["Yiheng Su", "Juni Jessy Li", "Matthew Lease"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "Can we preserve the accuracy of neural models while also providing faithful explanations? We present wrapper boxes, a general approach to generate faithful, example-based explanations for model predictions while maintaining predictive performance. After training a neural model as usual, its learned feature representation is input to a classic, interpretable model to perform the actual prediction. This simple strategy is surprisingly effective, with results largely comparable to those of the original neural model, as shown across three large pre-trained language models, two datasets of varying scale, four classic models, and four evaluation metrics. Moreover, because these classic models are interpretable by design, the subset of training examples that determine classic model predictions can be shown directly to users.", "url": "https://arxiv.org/abs/2311.08644"}, {"metadata": {"arXiv": "2311.08815", "Date": "Wed, 15 Nov 2023 09:34:08 ", "Title": "Self-Supervised Disentanglement by Leveraging Structure in Data Augmentations", "Authors": ["Cian Eastwood", "Julius von K\\\"ugelgen", "Linus Ericsson", "Diane Bouchacourt", "Pascal Vincent", "Bernhard Sch\\\"olkopf", "Mark Ibrahim"], "Categories": "cs.LG cs.AI cs.CV stat.ML"}, "abstract": "Self-supervised representation learning often uses data augmentations to induce some invariance to \"style\" attributes of the data. However, with downstream tasks generally unknown at training time, it is difficult to deduce a priori which attributes of the data are indeed \"style\" and can be safely discarded. To address this, we introduce a more principled approach that seeks to disentangle style features rather than discard them. The key idea is to add multiple style embedding spaces where: (i) each is invariant to all-but-one augmentation; and (ii) joint entropy is maximized. We formalize our structured data-augmentation procedure from a causal latent-variable-model perspective, and prove identifiability of both content and (multiple blocks of) style variables. We empirically demonstrate the benefits of our approach on synthetic datasets and then present promising but limited results on ImageNet.", "url": "https://arxiv.org/abs/2311.08815"}, {"metadata": {"arXiv": "2311.08819", "Date": "Wed, 15 Nov 2023 09:46:30 ", "Title": "Frequency Domain-based Dataset Distillation", "Authors": ["Donghyeok Shin", "Seungjae Shin", "Il-Chul Moon"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted at NeurIPS 2023"]}, "abstract": "This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset. Unlike conventional approaches that focus on the spatial domain, FreD employs frequency-based transforms to optimize the frequency representations of each data instance. By leveraging the concentration of spatial domain information on specific frequency components, FreD intelligently selects a subset of frequency dimensions for optimization, leading to a significant reduction in the required budget for synthesizing an instance. Through the selection of frequency dimensions based on the explained variance, FreD demonstrates both theoretical and empirical evidence of its ability to operate efficiently within a limited budget, while better preserving the information of the original dataset compared to conventional parameterization methods. Furthermore, based on the orthogonal compatibility of FreD with existing methods, we confirm that FreD consistently improves the performances of existing distillation methods over the evaluation scenarios with different benchmark datasets. We release the code at https://github.com/sdh0818/FreD.", "url": "https://arxiv.org/abs/2311.08819"}, {"metadata": {"arXiv": "2311.08935", "Date": "Wed, 15 Nov 2023 13:16:16 ", "Title": "Supported Trust Region Optimization for Offline Reinforcement Learning", "Authors": ["Yixiu Mao", "Hongchang Zhang", "Chen Chen", "Yi Xu", "Xiangyang Ji"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at ICML 2023"]}, "abstract": "Offline reinforcement learning suffers from the out-of-distribution issue and extrapolation error. Most policy constraint methods regularize the density of the trained policy towards the behavior policy, which is too restrictive in most cases. We propose Supported Trust Region optimization (STR) which performs trust region policy optimization with the policy constrained within the support of the behavior policy, enjoying the less restrictive support constraint. We show that, when assuming no approximation and sampling error, STR guarantees strict policy improvement until convergence to the optimal support-constrained policy in the dataset. Further with both errors incorporated, STR still guarantees safe policy improvement for each step. Empirical results validate the theory of STR and demonstrate its state-of-the-art performance on MuJoCo locomotion domains and much more challenging AntMaze domains.", "url": "https://arxiv.org/abs/2311.08935"}, {"metadata": {"arXiv": "2311.09014", "Date": "Wed, 15 Nov 2023 14:56:49 ", "Title": "Adversarial Attacks to Reward Machine-based Reinforcement Learning", "Authors": ["Lorenzo Nodari"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["Thesis Supervisor: Prof. Federico Cerutti (Universit\\`a degli Studi di Brescia", "IT)"]}, "abstract": "In recent years, Reward Machines (RMs) have stood out as a simple yet effective automata-based formalism for exposing and exploiting task structure in reinforcement learning settings. Despite their relevance, little to no attention has been directed to the study of their security implications and robustness to adversarial scenarios, likely due to their recent appearance in the literature. With my thesis, I aim to provide the first analysis of the security of RM-based reinforcement learning techniques, with the hope of motivating further research in the field, and I propose and evaluate a novel class of attacks on RM-based techniques: blinding attacks.", "url": "https://arxiv.org/abs/2311.09014"}, {"metadata": {"arXiv": "2311.09027", "Date": "Wed, 15 Nov 2023 15:15:57 ", "Title": "Assessing the Robustness of Intelligence-Driven Reinforcement Learning", "Authors": ["Lorenzo Nodari and Federico Cerutti"], "Categories": "cs.LG cs.AI cs.CR", "Comments": ["Accepted for publication at IEEE TechDefense 2023"]}, "abstract": "Robustness to noise is of utmost importance in reinforcement learning systems, particularly in military contexts where high stakes and uncertain environments prevail. Noise and uncertainty are inherent features of military operations, arising from factors such as incomplete information, adversarial actions, or unpredictable battlefield conditions. In RL, noise can critically impact decision-making, mission success, and the safety of personnel. Reward machines offer a powerful tool to express complex reward structures in RL tasks, enabling the design of tailored reinforcement signals that align with mission objectives. This paper considers the problem of the robustness of intelligence-driven reinforcement learning based on reward machines. The preliminary results presented suggest the need for further research in evidential reasoning and learning to harden current state-of-the-art reinforcement learning approaches before being mission-critical-ready.", "url": "https://arxiv.org/abs/2311.09027"}, {"metadata": {"arXiv": "2311.09068", "Date": "Wed, 15 Nov 2023 16:10:34 ", "Title": "Learning Fair Division from Bandit Feedback", "Authors": ["Hakuei Yamada", "Junpei Komiyama", "Kenshi Abe", "Atsushi Iwasaki"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "This work addresses learning online fair division under uncertainty, where a central planner sequentially allocates items without precise knowledge of agents' values or utilities. Departing from conventional online algorithm, the planner here relies on noisy, estimated values obtained after allocating items. We introduce wrapper algorithms utilizing \\textit{dual averaging}, enabling gradual learning of both the type distribution of arriving items and agents' values through bandit feedback. This approach enables the algorithms to asymptotically achieve optimal Nash social welfare in linear Fisher markets with agents having additive utilities. We establish regret bounds in Nash social welfare and empirically validate the superior performance of our proposed algorithms across synthetic and empirical datasets.", "url": "https://arxiv.org/abs/2311.09068"}, {"metadata": {"arXiv": "2311.09115", "Date": "Wed, 15 Nov 2023 17:06:26 ", "Title": "HEALNet - Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data", "Authors": ["Konstantin Hemker", "Nikola Smidjievski", "Mateja Jamnik"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages body", "5 pages appendix"]}, "abstract": "Technological advances in medical data collection such as high-resolution histopathology and high-throughput genomic sequencing have contributed to the rising requirement for multi-modal biomedical modelling, specifically for image, tabular, and graph data. Most multi-modal deep learning approaches use modality-specific architectures that are trained separately and cannot capture the crucial cross-modal information that motivates the integration of different data sources. This paper presents the Hybrid Early-fusion Attention Learning Network (HEALNet): a flexible multi-modal fusion architecture, which a) preserves modality-specific structural information, b) captures the cross-modal interactions and structural information in a shared latent space, c) can effectively handle missing modalities during training and inference, and d) enables intuitive model inspection by learning on the raw data input instead of opaque embeddings. We conduct multi-modal survival analysis on Whole Slide Images and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas (TCGA). HEALNet achieves state-of-the-art performance, substantially improving over both uni-modal and recent multi-modal baselines, whilst being robust in scenarios with missing modalities.", "url": "https://arxiv.org/abs/2311.09115"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

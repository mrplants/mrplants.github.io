<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2306.12589", "Date": "Wed, 21 Jun 2023 22:01:12 ", "Title": "Rapid building damage assessment workflow: An implementation for the 2023 Rolling Fork, Mississippi tornado event", "Authors": ["Caleb Robinson", "Simone Fobi Nsutezo", "Anthony Ortiz", "Tina Sederholm", "Rahul Dodhia", "Cameron Birge", "Kasie Richards", "Kris Pitcher", "Paulo Duarte", "Juan M. Lavista Ferres"], "Categories": "cs.CV cs.LG", "Comments": ["In submission to the 2023 ICCV Humanitarian Assistance and Disaster Response Workshop"]}, "abstract": "Rapid and accurate building damage assessments from high-resolution satellite imagery following a natural disaster is essential to inform and optimize first responder efforts. However, performing such building damage assessments in an automated manner is non-trivial due to the challenges posed by variations in disaster-specific damage, diversity in satellite imagery, and the dearth of extensive, labeled datasets. To circumvent these issues, this paper introduces a human-in-the-loop workflow for rapidly training building damage assessment models after a natural disaster. This article details a case study using this workflow, executed in partnership with the American Red Cross during a tornado event in Rolling Fork, Mississippi in March, 2023. The output from our human-in-the-loop modeling process achieved a precision of 0.86 and recall of 0.80 for damaged buildings when compared to ground truth data collected post-disaster. This workflow was implemented end-to-end in under 2 hours per satellite imagery scene, highlighting its potential for real-time deployment.", "url": "https://arxiv.org/abs/2306.12589"}, {"metadata": {"arXiv": "2306.12760", "Date": "Thu, 22 Jun 2023 09:34:55 ", "Title": "Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields", "Authors": ["Ori Gordon and Omri Avrahami and Dani Lischinski"], "Categories": "cs.CV cs.GR cs.LG", "Comments": ["14 pages", "12 figures. Project page: https://www.vision.huji.ac.il/blended-nerf/"]}, "abstract": "Editing a local region or a specific object in a 3D scene represented by a NeRF is challenging, mainly due to the implicit nature of the scene representation. Consistently blending a new realistic object into the scene adds an additional level of difficulty. We present Blended-NeRF, a robust and flexible framework for editing a specific region of interest in an existing NeRF scene, based on text prompts or image patches, along with a 3D ROI box. Our method leverages a pretrained language-image model to steer the synthesis towards a user-provided text prompt or image patch, along with a 3D MLP model initialized on an existing NeRF scene to generate the object and blend it into a specified region in the original scene. We allow local editing by localizing a 3D ROI box in the input scene, and seamlessly blend the content synthesized inside the ROI with the existing scene using a novel volumetric blending technique. To obtain natural looking and view-consistent results, we leverage existing and new geometric priors and 3D augmentations for improving the visual fidelity of the final result. We test our framework both qualitatively and quantitatively on a variety of real 3D scenes and text prompts, demonstrating realistic multi-view consistent results with much flexibility and diversity compared to the baselines. Finally, we show the applicability of our framework for several 3D editing applications, including adding new objects to a scene, removing/replacing/altering existing objects, and texture conversion.", "url": "https://arxiv.org/abs/2306.12760"}, {"metadata": {"arXiv": "2306.12941", "Date": "Thu, 22 Jun 2023 14:56:06 ", "Title": "Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models", "Authors": ["Francesco Croce", "Naman D Singh", "Matthias Hein"], "Categories": "cs.CV cs.LG"}, "abstract": "While a large amount of work has focused on designing adversarial attacks against image classifiers, only a few methods exist to attack semantic segmentation models. We show that attacking segmentation models presents task-specific challenges, for which we propose novel solutions. Our final evaluation protocol outperforms existing methods, and shows that those can overestimate the robustness of the models. Additionally, so far adversarial training, the most successful way for obtaining robust image classifiers, could not be successfully applied to semantic segmentation. We argue that this is because the task to be learned is more challenging, and requires significantly higher computational effort than for image classification. As a remedy, we show that by taking advantage of recent advances in robust ImageNet classifiers, one can train adversarially robust segmentation models at limited computational cost by fine-tuning robust backbones.", "url": "https://arxiv.org/abs/2306.12941"}, {"metadata": {"arXiv": "2306.13091", "Date": "Thu, 22 Jun 2023 17:59:55 ", "Title": "Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces", "Authors": ["Fahad Shamshad", "Koushik Srivatsan", "Karthik Nandakumar"], "Categories": "cs.CV cs.CR cs.LG", "Comments": ["Accepted in CVPR 2023. Project page: https://koushiksrivats.github.io/face_attribute_attack/"]}, "abstract": "The ability of generative models to produce highly realistic synthetic face images has raised security and ethical concerns. As a first line of defense against such fake faces, deep learning based forensic classifiers have been developed. While these forensic models can detect whether a face image is synthetic or real with high accuracy, they are also vulnerable to adversarial attacks. Although such attacks can be highly successful in evading detection by forensic classifiers, they introduce visible noise patterns that are detectable through careful human scrutiny. Additionally, these attacks assume access to the target model(s) which may not always be true. Attempts have been made to directly perturb the latent space of GANs to produce adversarial fake faces that can circumvent forensic classifiers. In this work, we go one step further and show that it is possible to successfully generate adversarial fake faces with a specified set of attributes (e.g., hair color, eye size, race, gender, etc.). To achieve this goal, we leverage the state-of-the-art generative model StyleGAN with disentangled representations, which enables a range of modifications without leaving the manifold of natural images. We propose a framework to search for adversarial latent codes within the feature space of StyleGAN, where the search can be guided either by a text prompt or a reference image. We also propose a meta-learning based optimization strategy to achieve transferable performance on unknown target models. Extensive experiments demonstrate that the proposed approach can produce semantically manipulated adversarial fake faces, which are true to the specified attribute set and can successfully fool forensic face classifiers, while remaining undetectable by humans. Code: https://github.com/koushiksrivats/face_attribute_attack.", "url": "https://arxiv.org/abs/2306.13091"}, {"metadata": {"arXiv": "2306.12436", "Date": "Thu, 15 Jun 2023 18:12:55 ", "Title": "MPSTAN: Metapopulation-based Spatio-Temporal Attention Network for Epidemic Forecasting", "Authors": ["Junkai Mao", "Yuexing Han and Bing Wang"], "Categories": "cs.LG cs.SI"}, "abstract": "Accurate epidemic forecasting plays a vital role for governments in developing effective prevention measures for suppressing epidemics. Most of the present spatio-temporal models cannot provide a general framework for stable, and accurate forecasting of epidemics with diverse evolution trends. Incorporating epidemiological domain knowledge ranging from single-patch to multi-patch into neural networks is expected to improve forecasting accuracy. However, relying solely on single-patch knowledge neglects inter-patch interactions, while constructing multi-patch knowledge is challenging without population mobility data. To address the aforementioned problems, we propose a novel hybrid model called Metapopulation-based Spatio-Temporal Attention Network (MPSTAN). This model aims to improve the accuracy of epidemic forecasting by incorporating multi-patch epidemiological knowledge into a spatio-temporal model and adaptively defining inter-patch interactions. Moreover, we incorporate inter-patch epidemiological knowledge into both the model construction and loss function to help the model learn epidemic transmission dynamics. Extensive experiments conducted on two representative datasets with different epidemiological evolution trends demonstrate that our proposed model outperforms the baselines and provides more accurate and stable short- and long-term forecasting. We confirm the effectiveness of domain knowledge in the learning model and investigate the impact of different ways of integrating domain knowledge on forecasting. We observe that using domain knowledge in both model construction and loss functions leads to more efficient forecasting, and selecting appropriate domain knowledge can improve accuracy further.", "url": "https://arxiv.org/abs/2306.12436"}, {"metadata": {"arXiv": "2306.12495", "Date": "Wed, 21 Jun 2023 18:08:55 ", "Title": "Verifying Global Neural Network Specifications using Hyperproperties", "Authors": ["David Boetius and Stefan Leue"], "Categories": "cs.LG cs.LO", "Comments": ["10 pages", "2 figures. Accepted at FoMLAS 2023"]}, "abstract": "Current approaches to neural network verification focus on specifications that target small regions around known input data points, such as local robustness. Thus, using these approaches, we can not obtain guarantees for inputs that are not close to known inputs. Yet, it is highly likely that a neural network will encounter such truly unseen inputs during its application. We study global specifications that - when satisfied - provide guarantees for all potential inputs. We introduce a hyperproperty formalism that allows for expressing global specifications such as monotonicity, Lipschitz continuity, global robustness, and dependency fairness. Our formalism enables verifying global specifications using existing neural network verification approaches by leveraging capabilities for verifying general computational graphs. Thereby, we extend the scope of guarantees that can be provided using existing methods. Recent success in verifying specific global specifications shows that attaining strong guarantees for all potential data points is feasible.", "url": "https://arxiv.org/abs/2306.12495"}, {"metadata": {"arXiv": "2306.12497", "Date": "Wed, 21 Jun 2023 18:12:58 ", "Title": "Density Uncertainty Layers for Reliable Uncertainty Estimation", "Authors": ["Yookoon Park", "David M. Blei"], "Categories": "cs.LG stat.ML"}, "abstract": "Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the approaches that are commonly used to approximate the posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper we propose a novel criterion for predictive uncertainty, that a model's predictive variance should be grounded in the empirical density of the input. It should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for those inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, an architectural element for a stochastic neural network that guarantees that the density uncertain criterion is satisfied. We study neural networks with density uncertainty layers on the CIFAR-10 and CIFAR-100 uncertainty benchmarks. Compared to existing approaches, we find that density uncertainty layers provide reliable uncertainty estimates and robust out-of-distribution detection performance.", "url": "https://arxiv.org/abs/2306.12497"}, {"metadata": {"arXiv": "2306.12511", "Date": "Wed, 21 Jun 2023 18:49:22 ", "Title": "Semi-Implicit Denoising Diffusion Models (SIDDMs)", "Authors": ["Yanwu Xu", "Mingming Gong", "Shaoan Xie", "Wei Wei", "Matthias Grundmann", "kayhan Batmanghelich", "Tingbo Hou"], "Categories": "cs.LG cs.CV"}, "abstract": "Despite the proliferation of generative models, achieving fast sampling during inference without compromising sample diversity and quality remains challenging. Existing models such as Denoising Diffusion Probabilistic Models (DDPM) deliver high-quality, diverse samples but are slowed by an inherently high number of iterative steps. The Denoising Diffusion Generative Adversarial Networks (DDGAN) attempted to circumvent this limitation by integrating a GAN model for larger jumps in the diffusion process. However, DDGAN encountered scalability limitations when applied to large datasets. To address these limitations, we introduce a novel approach that tackles the problem by matching implicit and explicit factors. More specifically, our approach involves utilizing an implicit model to match the marginal distributions of noisy data and the explicit conditional distribution of the forward diffusion. This combination allows us to effectively match the joint denoising distributions. Unlike DDPM but similar to DDGAN, we do not enforce a parametric distribution for the reverse step, enabling us to take large steps during inference. Similar to the DDPM but unlike DDGAN, we take advantage of the exact form of the diffusion process. We demonstrate that our proposed method obtains comparable generative performance to diffusion-based models and vastly superior results to models with a small number of sampling steps.", "url": "https://arxiv.org/abs/2306.12511"}, {"metadata": {"arXiv": "2306.12517", "Date": "Wed, 21 Jun 2023 19:06:41 ", "Title": "FFCV: Accelerating Training by Removing Data Bottlenecks", "Authors": ["Guillaume Leclerc", "Andrew Ilyas", "Logan Engstrom", "Sung Min Park", "Hadi Salman", "Aleksander Madry"], "Categories": "cs.LG cs.CV"}, "abstract": "We present FFCV, a library for easy and fast machine learning model training. FFCV speeds up model training by eliminating (often subtle) data bottlenecks from the training process. In particular, we combine techniques such as an efficient file storage format, caching, data pre-loading, asynchronous data transfer, and just-in-time compilation to (a) make data loading and transfer significantly more efficient, ensuring that GPUs can reach full utilization; and (b) offload as much data processing as possible to the CPU asynchronously, freeing GPU cycles for training. Using FFCV, we train ResNet-18 and ResNet-50 on the ImageNet dataset with competitive tradeoff between accuracy and training time. For example, we are able to train an ImageNet ResNet-50 model to 75\\% in only 20 mins on a single machine. We demonstrate FFCV's performance, ease-of-use, extensibility, and ability to adapt to resource constraints through several case studies. Detailed installation instructions, documentation, and Slack support channel are available at https://ffcv.io/ .", "url": "https://arxiv.org/abs/2306.12517"}, {"metadata": {"arXiv": "2306.12574", "Date": "Wed, 21 Jun 2023 21:22:38 ", "Title": "An efficient and straightforward online quantization method for a data stream through remove-birth updating", "Authors": ["Kazuhisa Fujita"], "Categories": "cs.LG cs.DB"}, "abstract": "The growth of network-connected devices is creating an explosion of data, known as big data, and posing significant challenges to efficient data analysis. This data is generated continuously, creating a dynamic flow known as a data stream. The characteristics of a data stream may change dynamically, and this change is known as concept drift. Consequently, a method for handling data streams must efficiently reduce their volume while dynamically adapting to these changing characteristics. This paper proposes a simple online vector quantization method for concept drift. The proposed method identifies and replaces units with low win probability through remove-birth updating, thus achieving a rapid adaptation to concept drift. Furthermore, the results of this study show that the proposed method can generate minimal dead units even in the presence of concept drift. This study also suggests that some metrics calculated from the proposed method will be helpful for drift detection.", "url": "https://arxiv.org/abs/2306.12574"}, {"metadata": {"arXiv": "2306.12594", "Date": "Wed, 21 Jun 2023 22:28:17 ", "Title": "State-wise Constrained Policy Optimization", "Authors": ["Weiye Zhao", "Rui Chen", "Yifan Sun", "Tianhao Wei and Changliu Liu"], "Categories": "cs.LG cs.RO", "Comments": ["arXiv admin note: text overlap with arXiv:2305.13681"]}, "abstract": "Reinforcement Learning (RL) algorithms have shown tremendous success in simulation environments, but their application to real-world problems faces significant challenges, with safety being a major concern. In particular, enforcing state-wise constraints is essential for many challenging tasks such as autonomous driving and robot manipulation. However, existing safe RL algorithms under the framework of Constrained Markov Decision Process (CMDP) do not consider state-wise constraints. To address this gap, we propose State-wise Constrained Policy Optimization (SCPO), the first general-purpose policy search algorithm for state-wise constrained reinforcement learning. SCPO provides guarantees for state-wise constraint satisfaction in expectation. In particular, we introduce the framework of Maximum Markov Decision Process, and prove that the worst-case safety violation is bounded under SCPO. We demonstrate the effectiveness of our approach on training neural network policies for extensive robot locomotion tasks, where the agent must satisfy a variety of state-wise safety constraints. Our results show that SCPO significantly outperforms existing methods and can handle state-wise constraints in high-dimensional robotics tasks.", "url": "https://arxiv.org/abs/2306.12594"}, {"metadata": {"arXiv": "2306.12599", "Date": "Wed, 21 Jun 2023 22:41:58 ", "Title": "Constant Memory Attention Block", "Authors": ["Leo Feng", "Frederick Tung", "Hossein Hajimirsadeghi", "Yoshua Bengio", "Mohamed Osama Ahmed"], "Categories": "cs.LG", "Comments": ["Workshop version of arXiv:2305.14567"]}, "abstract": "Modern foundation model architectures rely on attention mechanisms to effectively capture context. However, these methods require linear or quadratic memory in terms of the number of inputs/datapoints, limiting their applicability in low-compute domains. In this work, we propose Constant Memory Attention Block (CMAB), a novel general-purpose attention block that computes its output in constant memory and performs updates in constant computation. Highlighting CMABs efficacy, we introduce methods for Neural Processes and Temporal Point Processes. Empirically, we show our proposed methods achieve results competitive with state-of-the-art while being significantly more memory efficient.", "url": "https://arxiv.org/abs/2306.12599"}, {"metadata": {"arXiv": "2306.12612", "Date": "Thu, 22 Jun 2023 00:23:37 ", "Title": "RobustNeuralNetworks.jl: a Package for Machine Learning and Data-Driven Control with Certified Robustness", "Authors": ["Nicholas H. Barbara", "Max Revay", "Ruigang Wang", "Jing Cheng", "Ian R. Manchester"], "Categories": "cs.LG cs.SY eess.SY"}, "abstract": "Neural networks are typically sensitive to small input perturbations, leading to unexpected or brittle behaviour. We present RobustNeuralNetworks.jl: a Julia package for neural network models that are constructed to naturally satisfy a set of user-defined robustness constraints. The package is based on the recently proposed Recurrent Equilibrium Network (REN) and Lipschitz-Bounded Deep Network (LBDN) model classes, and is designed to interface directly with Julia's most widely-used machine learning package, Flux.jl. We discuss the theory behind our model parameterization, give an overview of the package, and provide a tutorial demonstrating its use in image classification, reinforcement learning, and nonlinear state-observer design.", "url": "https://arxiv.org/abs/2306.12612"}, {"metadata": {"arXiv": "2306.12625", "Date": "Thu, 22 Jun 2023 01:29:50 ", "Title": "Communication-Efficient Federated Learning through Importance Sampling", "Authors": ["Berivan Isik", "Francesco Pase", "Deniz Gunduz", "Sanmi Koyejo", "Tsachy Weissman", "Michele Zorzi"], "Categories": "cs.LG cs.DC stat.ML"}, "abstract": "The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\\theta}$ that is close to the client's distribution $q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\\phi^{(n)}}$'s and the side information $p_{\\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks such as FedPM, Federated SGLD, and QSGD to attain the same (and often higher) test accuracy with up to $50$ times reduction in the bitrate.", "url": "https://arxiv.org/abs/2306.12625"}, {"metadata": {"arXiv": "2306.12640", "Date": "Thu, 22 Jun 2023 02:50:16 ", "Title": "On Addressing the Limitations of Graph Neural Networks", "Authors": ["Sitao Luan"], "Categories": "cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2109.05641", "arXiv:2210.07606"]}, "abstract": "This report gives a summary of two problems about graph convolutional networks (GCNs): over-smoothing and heterophily challenges, and outlines future directions to explore.", "url": "https://arxiv.org/abs/2306.12640"}, {"metadata": {"arXiv": "2306.12646", "Date": "Thu, 22 Jun 2023 03:08:42 ", "Title": "Learnability and Algorithm for Continual Learning", "Authors": ["Gyuhak Kim", "Changnan Xiao", "Tatsuya Konishi", "Bing Liu"], "Categories": "cs.LG cs.CV", "Comments": ["ICML 2023"]}, "abstract": "This paper studies the challenging continual learning (CL) setting of Class Incremental Learning (CIL). CIL learns a sequence of tasks consisting of disjoint sets of concepts or classes. At any time, a single model is built that can be applied to predict/classify test instances of any classes learned thus far without providing any task related information for each test instance. Although many techniques have been proposed for CIL, they are mostly empirical. It has been shown recently that a strong CIL system needs a strong within-task prediction (WP) and a strong out-of-distribution (OOD) detection for each task. However, it is still not known whether CIL is actually learnable. This paper shows that CIL is learnable. Based on the theory, a new CIL algorithm is also proposed. Experimental results demonstrate its effectiveness.", "url": "https://arxiv.org/abs/2306.12646"}, {"metadata": {"arXiv": "2306.12673", "Date": "Thu, 22 Jun 2023 05:16:58 ", "Title": "Identifying and Disentangling Spurious Features in Pretrained Image Representations", "Authors": ["Rafayel Darbinyan", "Hrayr Harutyunyan", "Aram H. Markosyan", "Hrant Khachatrian"], "Categories": "cs.LG cs.CV"}, "abstract": "Neural networks employ spurious correlations in their predictions, resulting in decreased performance when these correlations do not hold. Recent works suggest fixing pretrained representations and training a classification head that does not use spurious features. We investigate how spurious features are represented in pretrained representations and explore strategies for removing information about spurious features. Considering the Waterbirds dataset and a few pretrained representations, we find that even with full knowledge of spurious features, their removal is not straightforward due to entangled representation. To address this, we propose a linear autoencoder training method to separate the representation into core, spurious, and other features. We propose two effective spurious feature removal approaches that are applied to the encoding and significantly improve classification performance measured by worst group accuracy.", "url": "https://arxiv.org/abs/2306.12673"}, {"metadata": {"arXiv": "2306.12678", "Date": "Thu, 22 Jun 2023 05:48:25 ", "Title": "Outlier-robust Estimation of a Sparse Linear Model Using Invexity", "Authors": ["Adarsh Barik and Jean Honorio"], "Categories": "cs.LG"}, "abstract": "In this paper, we study problem of estimating a sparse regression vector with correct support in the presence of outlier samples. The inconsistency of lasso-type methods is well known in this scenario. We propose a combinatorial version of outlier-robust lasso which also identifies clean samples. Subsequently, we use these clean samples to make a good estimation. We also provide a novel invex relaxation for the combinatorial problem and provide provable theoretical guarantees for this relaxation. Finally, we conduct experiments to validate our theory and compare our results against standard lasso.", "url": "https://arxiv.org/abs/2306.12678"}, {"metadata": {"arXiv": "2306.12691", "Date": "Thu, 22 Jun 2023 06:33:12 ", "Title": "Slimmable Encoders for Flexible Split DNNs in Bandwidth and Resource Constrained IoT Systems", "Authors": ["Juliano S. Assine", "J. C. S. Santos Filho", "Eduardo Valle", "Marco Levorato"], "Categories": "cs.LG", "Journal-ref": "2023 IEEE 24th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)", "DOI": "10.1109/WoWMoM57956.2023.00014"}, "abstract": "The execution of large deep neural networks (DNN) at mobile edge devices requires considerable consumption of critical resources, such as energy, while imposing demands on hardware capabilities. In approaches based on edge computing the execution of the models is offloaded to a compute-capable device positioned at the edge of 5G infrastructures. The main issue of the latter class of approaches is the need to transport information-rich signals over wireless links with limited and time-varying capacity. The recent split computing paradigm attempts to resolve this impasse by distributing the execution of DNN models across the layers of the systems to reduce the amount of data to be transmitted while imposing minimal computing load on mobile devices. In this context, we propose a novel split computing approach based on slimmable ensemble encoders. The key advantage of our design is the ability to adapt computational load and transmitted data size in real-time with minimal overhead and time. This is in contrast with existing approaches, where the same adaptation requires costly context switching and model loading. Moreover, our model outperforms existing solutions in terms of compression efficacy and execution time, especially in the context of weak mobile devices. We present a comprehensive comparison with the most advanced split computing solutions, as well as an experimental evaluation on GPU-less devices.", "url": "https://arxiv.org/abs/2306.12691"}, {"metadata": {"arXiv": "2306.12700", "Date": "Thu, 22 Jun 2023 07:06:45 ", "Title": "Accelerated Training via Incrementally Growing Neural Networks using Variance Transfer and Learning Rate Adaptation", "Authors": ["Xin Yuan", "Pedro Savarese", "Michael Maire"], "Categories": "cs.LG"}, "abstract": "We develop an approach to efficiently grow neural networks, within which parameterization and optimization strategies are designed by considering their effects on the training dynamics. Unlike existing growing methods, which follow simple replication heuristics or utilize auxiliary gradient-based local optimization, we craft a parameterization scheme which dynamically stabilizes weight, activation, and gradient scaling as the architecture evolves, and maintains the inference functionality of the network. To address the optimization difficulty resulting from imbalanced training effort distributed to subnetworks fading in at different growth phases, we propose a learning rate adaption mechanism that rebalances the gradient contribution of these separate subcomponents. Experimental results show that our method achieves comparable or better accuracy than training large fixed-size models, while saving a substantial portion of the original computation budget for training. We demonstrate that these gains translate into real wall-clock training speedups.", "url": "https://arxiv.org/abs/2306.12700"}, {"metadata": {"arXiv": "2306.12726", "Date": "Thu, 22 Jun 2023 08:02:01 ", "Title": "On Exploring Node-feature and Graph-structure Diversities for Node Drop Graph Pooling", "Authors": ["Chuang Liu", "Yibing Zhan", "Baosheng Yu", "Liu Liu", "Bo Du", "Wenbin Hu", "Tongliang Liu"], "Categories": "cs.LG", "Comments": ["14 pages", "14 figures"]}, "abstract": "A pooling operation is essential for effective graph-level representation learning, where the node drop pooling has become one mainstream graph pooling technology. However, current node drop pooling methods usually keep the top-k nodes according to their significance scores, which ignore the graph diversity in terms of the node features and the graph structures, thus resulting in suboptimal graph-level representations. To address the aforementioned issue, we propose a novel plug-and-play score scheme and refer to it as MID, which consists of a \\textbf{M}ultidimensional score space with two operations, \\textit{i.e.}, fl\\textbf{I}pscore and \\textbf{D}ropscore. Specifically, the multidimensional score space depicts the significance of nodes through multiple criteria; the flipscore encourages the maintenance of dissimilar node features; and the dropscore forces the model to notice diverse graph structures instead of being stuck in significant local structures. To evaluate the effectiveness of our proposed MID, we perform extensive experiments by applying it to a wide variety of recent node drop pooling methods, including TopKPool, SAGPool, GSAPool, and ASAP. Specifically, the proposed MID can efficiently and consistently achieve about 2.8\\% average improvements over the above four methods on seventeen real-world graph classification datasets, including four social datasets (IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY, and COLLAB), and thirteen biochemical datasets (D\\&D, PROTEINS, NCI1, MUTAG, PTC-MR, NCI109, ENZYMES, MUTAGENICITY, FRANKENSTEIN, HIV, BBBP, TOXCAST, and TOX21). Code is available at~\\url{https://github.com/whuchuang/mid}.", "url": "https://arxiv.org/abs/2306.12726"}, {"metadata": {"arXiv": "2306.12755", "Date": "Thu, 22 Jun 2023 09:17:23 ", "Title": "Beyond OOD State Actions: Supported Cross-Domain Offline Reinforcement Learning", "Authors": ["Jinxin Liu", "Ziqi Zhang", "Zhenyu Wei", "Zifeng Zhuang", "Yachen Kang", "Sibo Gai", "Donglin Wang"], "Categories": "cs.LG"}, "abstract": "Offline reinforcement learning (RL) aims to learn a policy using only pre-collected and fixed data. Although avoiding the time-consuming online interactions in RL, it poses challenges for out-of-distribution (OOD) state actions and often suffers from data inefficiency for training. Despite many efforts being devoted to addressing OOD state actions, the latter (data inefficiency) receives little attention in offline RL. To address this, this paper proposes the cross-domain offline RL, which assumes offline data incorporate additional source-domain data from varying transition dynamics (environments), and expects it to contribute to the offline data efficiency. To do so, we identify a new challenge of OOD transition dynamics, beyond the common OOD state actions issue, when utilizing cross-domain offline data. Then, we propose our method BOSA, which employs two support-constrained objectives to address the above OOD issues. Through extensive experiments in the cross-domain offline RL setting, we demonstrate BOSA can greatly improve offline data efficiency: using only 10\\% of the target data, BOSA could achieve {74.4\\%} of the SOTA offline RL performance that uses 100\\% of the target data. Additionally, we also show BOSA can be effortlessly plugged into model-based offline RL and noising data augmentation techniques (used for generating source-domain data), which naturally avoids the potential dynamics mismatch between target-domain data and newly generated source-domain data.", "url": "https://arxiv.org/abs/2306.12755"}, {"metadata": {"arXiv": "2306.12768", "Date": "Thu, 22 Jun 2023 09:45:40 ", "Title": "Concept-aware clustering for decentralized deep learning under temporal shift", "Authors": ["Marcus Toft{\\aa}s", "Emilie Klefbom", "Edvin Listo Zec", "Martin Willbo", "Olof Mogren"], "Categories": "cs.LG", "Comments": ["4 pages", "2 figures"]}, "abstract": "Decentralized deep learning requires dealing with non-iid data across clients, which may also change over time due to temporal shifts. While non-iid data has been extensively studied in distributed settings, temporal shifts have received no attention. To the best of our knowledge, we are first with tackling the novel and challenging problem of decentralized learning with non-iid and dynamic data. We propose a novel algorithm that can automatically discover and adapt to the evolving concepts in the network, without any prior knowledge or estimation of the number of concepts. We evaluate our algorithm on standard benchmark datasets and demonstrate that it outperforms previous methods for decentralized learning.", "url": "https://arxiv.org/abs/2306.12768"}, {"metadata": {"arXiv": "2306.12774", "Date": "Thu, 22 Jun 2023 10:00:33 ", "Title": "Pure Exploration in Bandits with Linear Constraints", "Authors": ["Emil Carlsson", "Debabrota Basu", "Fredrik D. Johansson", "Devdatt Dubhashi"], "Categories": "cs.LG"}, "abstract": "We address the problem of identifying the optimal policy with a fixed confidence level in a multi-armed bandit setup, when \\emph{the arms are subject to linear constraints}. Unlike the standard best-arm identification problem which is well studied, the optimal policy in this case may not be deterministic and could mix between several arms. This changes the geometry of the problem which we characterize via an information-theoretic lower bound. We introduce two asymptotically optimal algorithms for this setting, one based on the Track-and-Stop method and the other based on a game-theoretic approach. Both these algorithms try to track an optimal allocation based on the lower bound and computed by a weighted projection onto the boundary of a normal cone. Finally, we provide empirical results that validate our bounds and visualize how constraints change the hardness of the problem.", "url": "https://arxiv.org/abs/2306.12774"}, {"metadata": {"arXiv": "2306.12830", "Date": "Thu, 22 Jun 2023 12:04:49 ", "Title": "MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge", "Authors": ["Sokratis Nikolaidis", "Stylianos I. Venieris", "Iakovos S. Venieris"], "Categories": "cs.LG cs.DC", "Comments": ["Accepted at 28th IEEE Symposium on Computers and Communications (ISCC)", "2023"]}, "abstract": "Cascade systems comprise a two-model sequence, with a lightweight model processing all samples and a heavier, higher-accuracy model conditionally refining harder samples to improve accuracy. By placing the light model on the device side and the heavy model on a server, model cascades constitute a widely used distributed inference approach. With the rapid expansion of intelligent indoor environments, such as smart homes, the new setting of Multi-Device Cascade is emerging where multiple and diverse devices are to simultaneously use a shared heavy model on the same server, typically located within or close to the consumer environment. This work presents MultiTASC, a multi-tenancy-aware scheduler that adaptively controls the forwarding decision functions of the devices in order to maximize the system throughput, while sustaining high accuracy and low latency. By explicitly considering device heterogeneity, our scheduler improves the latency service-level objective (SLO) satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade methods in highly heterogeneous setups, while serving over 40 devices, showcasing its scalability.", "url": "https://arxiv.org/abs/2306.12830"}, {"metadata": {"arXiv": "2306.12857", "Date": "Thu, 22 Jun 2023 13:08:42 ", "Title": "Efficient Partitioning Method of Large-Scale Public Safety Spatio-Temporal Data based on Information Loss Constraints", "Authors": ["Jie Gao", "Yawen Li", "Zhe Xue", "and Zeli Guan"], "Categories": "cs.LG cs.IR"}, "abstract": "The storage, management, and application of massive spatio-temporal data are widely applied in various practical scenarios, including public safety. However, due to the unique spatio-temporal distribution characteristics of re-al-world data, most existing methods have limitations in terms of the spatio-temporal proximity of data and load balancing in distributed storage. There-fore, this paper proposes an efficient partitioning method of large-scale public safety spatio-temporal data based on information loss constraints (IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal point da-ta by combining the spatio-temporal partitioning module (STPM) with the graph partitioning module (GPM). This approach can significantly reduce the scale of data while maintaining the model's accuracy, in order to improve the partitioning efficiency. It can also ensure the load balancing of distributed storage while maintaining spatio-temporal proximity of the data partitioning results. This method provides a new solution for distributed storage of mas-sive spatio-temporal data. The experimental results on multiple real-world da-tasets demonstrate the effectiveness and superiority of IFL-LSTP.", "url": "https://arxiv.org/abs/2306.12857"}, {"metadata": {"arXiv": "2306.12859", "Date": "Thu, 22 Jun 2023 13:11:19 ", "Title": "Reinforcement Federated Learning Method Based on Adaptive OPTICS Clustering", "Authors": ["Tianyu Zhao", "Junping Du", "Yingxia Shao", "and Zeli Guan"], "Categories": "cs.LG"}, "abstract": "Federated learning is a distributed machine learning technology, which realizes the balance between data privacy protection and data sharing computing. To protect data privacy, feder-ated learning learns shared models by locally executing distributed training on participating devices and aggregating local models into global models. There is a problem in federated learning, that is, the negative impact caused by the non-independent and identical distribu-tion of data across different user terminals. In order to alleviate this problem, this paper pro-poses a strengthened federation aggregation method based on adaptive OPTICS clustering. Specifically, this method perceives the clustering environment as a Markov decision process, and models the adjustment process of parameter search direction, so as to find the best clus-tering parameters to achieve the best federated aggregation method. The core contribution of this paper is to propose an adaptive OPTICS clustering algorithm for federated learning. The algorithm combines OPTICS clustering and adaptive learning technology, and can effective-ly deal with the problem of non-independent and identically distributed data across different user terminals. By perceiving the clustering environment as a Markov decision process, the goal is to find the best parameters of the OPTICS cluster without artificial assistance, so as to obtain the best federated aggregation method and achieve better performance. The reliability and practicability of this method have been verified on the experimental data, and its effec-tiveness and superiority have been proved.", "url": "https://arxiv.org/abs/2306.12859"}, {"metadata": {"arXiv": "2306.12860", "Date": "Thu, 22 Jun 2023 13:14:59 ", "Title": "Learning from Visual Observation via Offline Pretrained State-to-Go Transformer", "Authors": ["Bohan Zhou", "Ke Li", "Jiechuan Jiang", "Zongqing Lu"], "Categories": "cs.LG cs.CV", "Comments": ["19 pages"]}, "abstract": "Learning from visual observation (LfVO), aiming at recovering policies from only visual observation data, is promising yet a challenging problem. Existing LfVO approaches either only adopt inefficient online learning schemes or require additional task-specific information like goal states, making them not suited for open-ended tasks. To address these issues, we propose a two-stage framework for learning from visual observation. In the first stage, we introduce and pretrain State-to-Go (STG) Transformer offline to predict and differentiate latent transitions of demonstrations. Subsequently, in the second stage, the STG Transformer provides intrinsic rewards for downstream reinforcement learning tasks where an agent learns merely from intrinsic rewards. Empirical results on Atari and Minecraft show that our proposed method outperforms baselines and in some tasks even achieves performance comparable to the policy learned from environmental rewards. These results shed light on the potential of utilizing video-only data to solve difficult visual reinforcement learning tasks rather than relying on complete offline datasets containing states, actions, and rewards. The project's website and code can be found at https://sites.google.com/view/stgtransformer.", "url": "https://arxiv.org/abs/2306.12860"}, {"metadata": {"arXiv": "2306.12900", "Date": "Thu, 22 Jun 2023 14:07:54 ", "Title": "In Situ Framework for Coupling Simulation and Machine Learning with Application to CFD", "Authors": ["Riccardo Balin and Filippo Simini and Cooper Simpson and Andrew Shao and Alessandro Rigazzi and Matthew Ellis and Stephen Becker and Alireza Doostan and John A. Evans and Kenneth E. Jansen"], "Categories": "cs.LG physics.flu-dyn"}, "abstract": "Recent years have seen many successful applications of machine learning (ML) to facilitate fluid dynamic computations. As simulations grow, generating new training datasets for traditional offline learning creates I/O and storage bottlenecks. Additionally, performing inference at runtime requires non-trivial coupling of ML framework libraries with simulation codes. This work offers a solution to both limitations by simplifying this coupling and enabling in situ training and inference workflows on heterogeneous clusters. Leveraging SmartSim, the presented framework deploys a database to store data and ML models in memory, thus circumventing the file system. On the Polaris supercomputer, we demonstrate perfect scaling efficiency to the full machine size of the data transfer and inference costs thanks to a novel co-located deployment of the database. Moreover, we train an autoencoder in situ from a turbulent flow simulation, showing that the framework overhead is negligible relative to a solver time step and training epoch.", "url": "https://arxiv.org/abs/2306.12900"}, {"metadata": {"arXiv": "2306.12915", "Date": "Thu, 22 Jun 2023 14:30:41 ", "Title": "Multi-Objective Hull Form Optimization with CAD Engine-based Deep Learning Physics for 3D Flow Prediction", "Authors": ["Jocelyn Ahmed Mazari", "Antoine Reverberi", "Pierre Yser", "Sebastian Sigmund"], "Categories": "cs.LG cs.CV physics.flu-dyn", "Comments": ["X International Conference on Computational Methods in Marine Engineering", "MARINE 2023", "Madrid", "Spain"], "MSC-class": "J.2"}, "abstract": "In this work, we propose a built-in Deep Learning Physics Optimization (DLPO) framework to set up a shape optimization study of the Duisburg Test Case (DTC) container vessel. We present two different applications: (1) sensitivity analysis to detect the most promising generic basis hull shapes, and (2) multi-objective optimization to quantify the trade-off between optimal hull forms. DLPO framework allows for the evaluation of design iterations automatically in an end-to-end manner. We achieved these results by coupling Extrality's Deep Learning Physics (DLP) model to a CAD engine and an optimizer. Our proposed DLP model is trained on full 3D volume data coming from RANS simulations, and it can provide accurate and high-quality 3D flow predictions in real-time, which makes it a good evaluator to perform optimization of new container vessel designs w.r.t the hydrodynamic efficiency. In particular, it is able to recover the forces acting on the vessel by integration on the hull surface with a mean relative error of 3.84\\% \\pm 2.179\\% on the total resistance. Each iteration takes only 20 seconds, thus leading to a drastic saving of time and engineering efforts, while delivering valuable insight into the performance of the vessel, including RANS-like detailed flow information. We conclude that DLPO framework is a promising tool to accelerate the ship design process and lead to more efficient ships with better hydrodynamic performance.", "url": "https://arxiv.org/abs/2306.12915"}, {"metadata": {"arXiv": "2306.12919", "Date": "Thu, 22 Jun 2023 14:32:53 ", "Title": "An Interactive Interface for Novel Class Discovery in Tabular Data", "Authors": ["Colin Troisemaine", "Joachim Flocon-Cholet", "St\\'ephane Gosselin", "Alexandre Reiffers-Masson", "Sandrine Vaton", "Vincent Lemaire"], "Categories": "cs.LG cs.HC", "Comments": ["5 pages"]}, "abstract": "Novel Class Discovery (NCD) is the problem of trying to discover novel classes in an unlabeled set, given a labeled set of different but related classes. The majority of NCD methods proposed so far only deal with image data, despite tabular data being among the most widely used type of data in practical applications. To interpret the results of clustering or NCD algorithms, data scientists need to understand the domain- and application-specific attributes of tabular data. This task is difficult and can often only be performed by a domain expert. Therefore, this interface allows a domain expert to easily run state-of-the-art algorithms for NCD in tabular data. With minimal knowledge in data science, interpretable results can be generated.", "url": "https://arxiv.org/abs/2306.12919"}, {"metadata": {"arXiv": "2306.12974", "Date": "Thu, 22 Jun 2023 15:35:38 ", "Title": "Adaptive Bernstein Change Detector for High-Dimensional Data Streams", "Authors": ["Marco Heyden", "Edouard Fouch\\'e", "Vadim Arzamasov", "Tanja Fenn", "Florian Kalinke", "Klemens B\\\"ohm"], "Categories": "cs.LG", "MSC-class": "68T05", "ACM-class": "I.2.6"}, "abstract": "Change detection is of fundamental importance when analyzing data streams. Detecting changes both quickly and accurately enables monitoring and prediction systems to react, e.g., by issuing an alarm or by updating a learning algorithm. However, detecting changes is challenging when observations are high-dimensional. In high-dimensional data, change detectors should not only be able to identify when changes happen, but also in which subspace they occur. Ideally, one should also quantify how severe they are. Our approach, ABCD, has these properties. ABCD learns an encoder-decoder model and monitors its accuracy over a window of adaptive size. ABCD derives a change score based on Bernstein's inequality to detect deviations in terms of accuracy, which indicate changes. Our experiments demonstrate that ABCD outperforms its best competitor by at least 8% and up to 23% in F1-score on average. It can also accurately estimate changes' subspace, together with a severity measure that correlates with the ground truth.", "url": "https://arxiv.org/abs/2306.12974"}, {"metadata": {"arXiv": "2306.12981", "Date": "Thu, 22 Jun 2023 15:40:10 ", "Title": "Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping", "Authors": ["Yining Li", "Peizhong Ju", "Ness Shroff"], "Categories": "cs.LG"}, "abstract": "Reinforcement learning often needs to deal with the exponential growth of states and actions when exploring optimal control in high-dimensional spaces (often known as the curse of dimensionality). In this work, we address this issue by learning the inherent structure of action-wise similar MDP to appropriately balance the performance degradation versus sample/computational complexity. In particular, we partition the action spaces into multiple groups based on the similarity in transition distribution and reward function, and build a linear decomposition model to capture the difference between the intra-group transition kernel and the intra-group rewards. Both our theoretical analysis and experiments reveal a \\emph{surprising and counter-intuitive result}: while a more refined grouping strategy can reduce the approximation error caused by treating actions in the same group as identical, it also leads to increased estimation error when the size of samples or the computation resources is limited. This finding highlights the grouping strategy as a new degree of freedom that can be optimized to minimize the overall performance loss. To address this issue, we formulate a general optimization problem for determining the optimal grouping strategy, which strikes a balance between performance loss and sample/computational complexity. We further propose a computationally efficient method for selecting a nearly-optimal grouping strategy, which maintains its computational complexity independent of the size of the action space.", "url": "https://arxiv.org/abs/2306.12981"}, {"metadata": {"arXiv": "2306.12983", "Date": "Thu, 22 Jun 2023 15:41:15 ", "Title": "Towards More Realistic Membership Inference Attacks on Large Diffusion Models", "Authors": ["Jan Dubi\\'nski", "Antoni Kowalczuk", "Stanis{\\l}aw Pawlak", "Przemys{\\l}aw Rokita", "Tomasz Trzci\\'nski", "Pawe{\\l} Morawiecki"], "Categories": "cs.LG cs.CR cs.CV"}, "abstract": "Generative diffusion models, including Stable Diffusion and Midjourney, can generate visually appealing, diverse, and high-resolution images for various applications. These models are trained on billions of internet-sourced images, raising significant concerns about the potential unauthorized use of copyright-protected images. In this paper, we examine whether it is possible to determine if a specific image was used in the training set, a problem known in the cybersecurity community and referred to as a membership inference attack. Our focus is on Stable Diffusion, and we address the challenge of designing a fair evaluation framework to answer this membership question. We propose a methodology to establish a fair evaluation setup and apply it to Stable Diffusion, enabling potential extensions to other generative models. Utilizing this evaluation setup, we execute membership attacks (both known and newly introduced). Our research reveals that previously proposed evaluation setups do not provide a full understanding of the effectiveness of membership inference attacks. We conclude that the membership inference attack remains a significant challenge for large diffusion models (often deployed as black-box systems), indicating that related privacy and copyright issues will persist in the foreseeable future.", "url": "https://arxiv.org/abs/2306.12983"}, {"metadata": {"arXiv": "2306.13045", "Date": "Thu, 22 Jun 2023 17:11:18 ", "Title": "Multi-Task Learning with Loop Specific Attention for CDR Structure Prediction", "Authors": ["Eleni Giovanoudi and Dimitrios Rafailidis"], "Categories": "cs.LG", "Comments": ["8 pages"]}, "abstract": "The Complementarity Determining Region (CDR) structure prediction of loops in antibody engineering has gained a lot of attraction by researchers. When designing antibodies, a main challenge is to predict the CDR structure of the H3 loop. Compared with the other CDR loops, that is the H1 and H2 loops, the CDR structure of the H3 loop is more challenging due to its varying length and flexible structure. In this paper, we propose a Multi-task learning model with Loop Specific Attention, namely MLSA. In particular, to the best of our knowledge we are the first to jointly learn the three CDR loops, via a novel multi-task learning strategy. In addition, to account for the structural and functional similarities and differences of the three CDR loops, we propose a loop specific attention mechanism to control the influence of each CDR loop on the training of MLSA. Our experimental evaluation on widely used benchmark data shows that the proposed MLSA method significantly reduces the prediction error of the CDR structure of the H3 loop, by at least 19%, when compared with other baseline strategies. Finally, for reproduction purposes we make the implementation of MLSA publicly available at https://anonymous.4open.science/r/MLSA-2442/.", "url": "https://arxiv.org/abs/2306.13045"}, {"metadata": {"arXiv": "2306.13053", "Date": "Thu, 22 Jun 2023 17:20:30 ", "Title": "Context-lumpable stochastic bandits", "Authors": ["Chung-Wei Lee", "Qinghua Liu", "Yasin Abbasi-Yadkori", "Chi Jin", "Tor Lattimore", "Csaba Szepesv\\'ari"], "Categories": "cs.LG"}, "abstract": "We consider a contextual bandit problem with $S $ contexts and $A $ actions. In each round $t=1,2,\\dots$ the learner observes a random context and chooses an action based on its past experience. The learner then observes a random reward whose mean is a function of the context and the action for the round. Under the assumption that the contexts can be lumped into $r\\le \\min\\{S ,A \\}$ groups such that the mean reward for the various actions is the same for any two contexts that are in the same group, we give an algorithm that outputs an $\\epsilon$-optimal policy after using at most $\\widetilde O(r (S +A )/\\epsilon^2)$ samples with high probability and provide a matching $\\widetilde\\Omega(r (S +A )/\\epsilon^2)$ lower bound. In the regret minimization setting, we give an algorithm whose cumulative regret up to time $T$ is bounded by $\\widetilde O(\\sqrt{r^3(S +A )T})$. To the best of our knowledge, we are the first to show the near-optimal sample complexity in the PAC setting and $\\widetilde O(\\sqrt{{poly}(r)(S+K)T})$ minimax regret in the online setting for this problem. We also show our algorithms can be applied to more general low-rank bandits and get improved regret bounds in some scenarios.", "url": "https://arxiv.org/abs/2306.13053"}, {"metadata": {"arXiv": "2306.13057", "Date": "Thu, 22 Jun 2023 17:23:36 ", "Title": "SQ Lower Bounds for Learning Bounded Covariance GMMs", "Authors": ["Ilias Diakonikolas", "Daniel M. Kane", "Thanasis Pittas", "Nikos Zarifis"], "Categories": "cs.LG cs.DS math.ST stat.ML stat.TH"}, "abstract": "We study the complexity of learning mixtures of separated Gaussians with common unknown bounded covariance matrix. Specifically, we focus on learning Gaussian mixture models (GMMs) on $\\mathbb{R}^d$ of the form $P= \\sum_{i=1}^k w_i \\mathcal{N}(\\boldsymbol \\mu_i,\\mathbf \\Sigma_i)$, where $\\mathbf \\Sigma_i = \\mathbf \\Sigma \\preceq \\mathbf I$ and $\\min_{i \\neq j} \\| \\boldsymbol \\mu_i - \\boldsymbol \\mu_j\\|_2 \\geq k^\\epsilon$ for some $\\epsilon>0$. Known learning algorithms for this family of GMMs have complexity $(dk)^{O(1/\\epsilon)}$. In this work, we prove that any Statistical Query (SQ) algorithm for this problem requires complexity at least $d^{\\Omega(1/\\epsilon)}$. In the special case where the separation is on the order of $k^{1/2}$, we additionally obtain fine-grained SQ lower bounds with the correct exponent. Our SQ lower bounds imply similar lower bounds for low-degree polynomial tests. Conceptually, our results provide evidence that known algorithms for this problem are nearly best possible.", "url": "https://arxiv.org/abs/2306.13057"}, {"metadata": {"arXiv": "2306.13064", "Date": "Thu, 22 Jun 2023 17:32:12 ", "Title": "Auditing Predictive Models for Intersectional Biases", "Authors": ["Kate S. Boxer", "Edward McFowland III", "Daniel B. Neill"], "Categories": "cs.LG", "Comments": ["29 pages", "7 figures"]}, "abstract": "Predictive models that satisfy group fairness criteria in aggregate for members of a protected class, but do not guarantee subgroup fairness, could produce biased predictions for individuals at the intersection of two or more protected classes. To address this risk, we propose Conditional Bias Scan (CBS), a flexible auditing framework for detecting intersectional biases in classification models. CBS identifies the subgroup for which there is the most significant bias against the protected class, as compared to the equivalent subgroup in the non-protected class, and can incorporate multiple commonly used fairness definitions for both probabilistic and binarized predictions. We show that this methodology can detect previously unidentified intersectional and contextual biases in the COMPAS pre-trial risk assessment tool and has higher bias detection power compared to similar methods that audit for subgroup fairness.", "url": "https://arxiv.org/abs/2306.13064"}, {"metadata": {"arXiv": "2306.13076", "Date": "Thu, 22 Jun 2023 17:48:18 ", "Title": "A Comparison of Time-based Models for Multimodal Emotion Recognition", "Authors": ["Ege Kesim", "Selahattin Serdar Helli", "Sena Nur Cavsak"], "Categories": "cs.LG", "Comments": ["in Turkish language"]}, "abstract": "Emotion recognition has become an important research topic in the field of human-computer interaction. Studies on sound and videos to understand emotions focused mainly on analyzing facial expressions and classified 6 basic emotions. In this study, the performance of different sequence models in multi-modal emotion recognition was compared. The sound and images were first processed by multi-layered CNN models, and the outputs of these models were fed into various sequence models. The sequence model is GRU, Transformer, LSTM and Max Pooling. Accuracy, precision, and F1 Score values of all models were calculated. The multi-modal CREMA-D dataset was used in the experiments. As a result of the comparison of the CREMA-D dataset, GRU-based architecture with 0.640 showed the best result in F1 score, LSTM-based architecture with 0.699 in precision metric, while sensitivity showed the best results over time with Max Pooling-based architecture with 0.620. As a result, it has been observed that the sequence models compare performances close to each other.", "url": "https://arxiv.org/abs/2306.13076"}, {"metadata": {"arXiv": "2306.13089", "Date": "Sun, 28 May 2023 18:27:59 ", "Title": "GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning", "Authors": ["Haiteng Zhao", "Shengchao Liu", "Chang Ma", "Hannan Xu", "Jie Fu", "Zhi-Hong Deng", "Lingpeng Kong", "Qi Liu"], "Categories": "cs.LG cs.CL q-bio.BM"}, "abstract": "Molecule property prediction has gained significant attention in recent years. The main bottleneck is the label insufficiency caused by expensive lab experiments. In order to alleviate this issue and to better leverage textual knowledge for tasks, this study investigates the feasibility of employing natural language instructions to accomplish molecule-related tasks in a zero-shot setting. We discover that existing molecule-text models perform poorly in this setting due to inadequate treatment of instructions and limited capacity for graphs. To overcome these issues, we propose GIMLET, which unifies language models for both graph and text data. By adopting generalized position embedding, our model is extended to encode both graph structures and instruction text without additional graph encoding modules. GIMLET also decouples encoding of the graph from tasks instructions in the attention mechanism, enhancing the generalization of graph features across novel tasks. We construct a dataset consisting of more than two thousand molecule tasks with corresponding instructions derived from task descriptions. We pretrain GIMLET on the molecule tasks along with instructions, enabling the model to transfer effectively to a broad range of tasks. Experimental results demonstrate that GIMLET significantly outperforms molecule-text baselines in instruction-based zero-shot learning, even achieving closed results to supervised GNN models on tasks such as toxcast and muv.", "url": "https://arxiv.org/abs/2306.13089"}, {"metadata": {"arXiv": "2306.12962", "Date": "Thu, 22 Jun 2023 16:55:01 ", "Title": "PyKoopman: A Python Package for Data-Driven Approximation of the Koopman Operator", "Authors": ["Shaowu Pan", "Eurika Kaiser", "Brian M. de Silva", "J. Nathan Kutz", "Steven L. Brunton"], "Categories": "eess.SY cs.LG cs.SY math.DS physics.comp-ph", "Comments": ["16 pages"]}, "abstract": "PyKoopman is a Python package for the data-driven approximation of the Koopman operator associated with a dynamical system. The Koopman operator is a principled linear embedding of nonlinear dynamics and facilitates the prediction, estimation, and control of strongly nonlinear dynamics using linear systems theory. In particular, PyKoopman provides tools for data-driven system identification for unforced and actuated systems that build on the equation-free dynamic mode decomposition (DMD) and its variants. In this work, we provide a brief description of the mathematical underpinnings of the Koopman operator, an overview and demonstration of the features implemented in PyKoopman (with code examples), practical advice for users, and a list of potential extensions to PyKoopman. Software is available at http://github.com/dynamicslab/pykoopman", "url": "https://arxiv.org/abs/2306.12962"}, {"metadata": {"arXiv": "2306.12456", "Date": "Wed, 21 Jun 2023 05:50:33 ", "Title": "Pushing the Limits of Machine Design: Automated CPU Design with AI", "Authors": ["Shuyao Cheng", "Pengwei Jin", "Qi Guo", "Zidong Du", "Rui Zhang", "Yunhao Tian", "Xing Hu", "Yongwei Zhao", "Yifan Hao", "Xiangtao Guan", "Husheng Han", "Zhengyue Zhao", "Ximing Liu", "Ling Li", "Xishan Zhang", "Yuejie Chu", "Weilong Mao", "Tianshi Chen and Yunji Chen"], "Categories": "cs.AI cs.AR", "Comments": ["28 pages"]}, "abstract": "Design activity -- constructing an artifact description satisfying given goals and constraints -- distinguishes humanity from other animals and traditional machines, and endowing machines with design abilities at the human level or beyond has been a long-term pursuit. Though machines have already demonstrated their abilities in designing new materials, proteins, and computer programs with advanced artificial intelligence (AI) techniques, the search space for designing such objects is relatively small, and thus, \"Can machines design like humans?\" remains an open question. To explore the boundary of machine design, here we present a new AI approach to automatically design a central processing unit (CPU), the brain of a computer, and one of the world's most intricate devices humanity have ever designed. This approach generates the circuit logic, which is represented by a graph structure called Binary Speculation Diagram (BSD), of the CPU design from only external input-output observations instead of formal program code. During the generation of BSD, Monte Carlo-based expansion and the distance of Boolean functions are used to guarantee accuracy and efficiency, respectively. By efficiently exploring a search space of unprecedented size 10^{10^{540}}, which is the largest one of all machine-designed objects to our best knowledge, and thus pushing the limits of machine design, our approach generates an industrial-scale RISC-V CPU within only 5 hours. The taped-out CPU successfully runs the Linux operating system and performs comparably against the human-designed Intel 80486SX CPU. In addition to learning the world's first CPU only from input-output observations, which may reform the semiconductor industry by significantly reducing the design cycle, our approach even autonomously discovers human knowledge of the von Neumann architecture.", "url": "https://arxiv.org/abs/2306.12456"}, {"metadata": {"arXiv": "2306.12609", "Date": "Thu, 22 Jun 2023 00:12:30 ", "Title": "Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities", "Authors": ["Xudong Shen", "Hannah Brown", "Jiashu Tao", "Martin Strobel", "Yao Tong", "Akshay Narayan", "Harold Soh", "Finale Doshi-Velez"], "Categories": "cs.AI cs.CY"}, "abstract": "There is increasing attention being given to how to regulate AI systems. As governing bodies grapple with what values to encapsulate into regulation, we consider the technical half of the question: To what extent can AI experts vet an AI system for adherence to regulatory requirements? We investigate this question through two public sector procurement checklists, identifying what we can do now, what we should be able to do with technical innovation in AI, and what requirements necessitate a more interdisciplinary approach.", "url": "https://arxiv.org/abs/2306.12609"}, {"metadata": {"arXiv": "2306.12654", "Date": "Thu, 22 Jun 2023 03:44:04 ", "Title": "Novelty Accommodating Multi-Agent Planning in High Fidelity Simulated Open World", "Authors": ["James Chao", "Wiktor Piotrowski", "Mitch Manzanares", "Douglas S. Lange"], "Categories": "cs.AI cs.MA"}, "abstract": "Autonomous agents acting in real-world environments often need to reason with unknown novelties interfering with their plan execution. Novelty is an unexpected phenomenon that can alter the core characteristics, composition, and dynamics of the environment. Novelty can occur at any time in any sufficiently complex environment without any prior notice or explanation. Previous studies show that novelty has catastrophic impact on agent performance. Intelligent agents reason with an internal model of the world to understand the intricacies of their environment and to successfully execute their plans. The introduction of novelty into the environment usually renders their internal model inaccurate and the generated plans no longer applicable. Novelty is particularly prevalent in the real world where domain-specific and even predicted novelty-specific approaches are used to mitigate the novelty's impact. In this work, we demonstrate that a domain-independent AI agent designed to detect, characterize, and accommodate novelty in smaller-scope physics-based games such as Angry Birds and Cartpole can be adapted to successfully perform and reason with novelty in realistic high-fidelity simulator of the military domain.", "url": "https://arxiv.org/abs/2306.12654"}, {"metadata": {"arXiv": "2306.12850", "Date": "Thu, 22 Jun 2023 12:44:49 ", "Title": "Don't Treat the Symptom, Find the Cause! Efficient Artificial-Intelligence Methods for (Interactive) Debugging", "Authors": ["Patrick Rodler"], "Categories": "cs.AI cs.DM cs.LO", "Comments": ["Habilitation Thesis"]}, "abstract": "In the modern world, we are permanently using, leveraging, interacting with, and relying upon systems of ever higher sophistication, ranging from our cars, recommender systems in e-commerce, and networks when we go online, to integrated circuits when using our PCs and smartphones, the power grid to ensure our energy supply, security-critical software when accessing our bank accounts, and spreadsheets for financial planning and decision making. The complexity of these systems coupled with our high dependency on them implies both a non-negligible likelihood of system failures, and a high potential that such failures have significant negative effects on our everyday life. For that reason, it is a vital requirement to keep the harm of emerging failures to a minimum, which means minimizing the system downtime as well as the cost of system repair. This is where model-based diagnosis comes into play. Model-based diagnosis is a principled, domain-independent approach that can be generally applied to troubleshoot systems of a wide variety of types, including all the ones mentioned above, and many more. It exploits and orchestrates i.a. techniques for knowledge representation, automated reasoning, heuristic problem solving, intelligent search, optimization, stochastics, statistics, decision making under uncertainty, machine learning, as well as calculus, combinatorics and set theory to detect, localize, and fix faults in abnormally behaving systems. In this thesis, we will give an introduction to the topic of model-based diagnosis, point out the major challenges in the field, and discuss a selection of approaches from our research addressing these issues.", "url": "https://arxiv.org/abs/2306.12850"}, {"metadata": {"arXiv": "2306.12623", "Date": "Thu, 22 Jun 2023 01:27:55 ", "Title": "SEAL: Simultaneous Exploration and Localization in Multi-Robot Systems", "Authors": ["Ehsan Latif and Ramviyas Parasuraman"], "Categories": "cs.RO cs.AI cs.MA", "Comments": ["Accepted to IROS 2023"]}, "abstract": "The availability of accurate localization is critical for multi-robot exploration strategies; noisy or inconsistent localization causes failure in meeting exploration objectives. We aim to achieve high localization accuracy with contemporary exploration map belief and vice versa without needing global localization information. This paper proposes a novel simultaneous exploration and localization (SEAL) approach, which uses Gaussian Processes (GP)-based information fusion for maximum exploration while performing communication graph optimization for relative localization. Both these cross-dependent objectives were integrated through the Rao-Blackwellization technique. Distributed linearized convex hull optimization is used to select the next-best unexplored region for distributed exploration. SEAL outperformed cutting-edge methods on exploration and localization performance in extensive ROS-Gazebo simulations, illustrating the practicality of the approach in real-world applications.", "url": "https://arxiv.org/abs/2306.12623"}, {"metadata": {"arXiv": "2306.12677", "Date": "Thu, 22 Jun 2023 05:48:22 ", "Title": "SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by Generative Pre-trained Heterogeneous Graph Transformer", "Authors": ["Junjia Liu", "Zhihao Li", "Sylvain Calinon", "and Fei Chen"], "Categories": "cs.RO cs.AI", "Comments": ["6 pages", "5 figures", "accepted by IROS 2023"]}, "abstract": "Soft object manipulation tasks in domestic scenes pose a significant challenge for existing robotic skill learning techniques due to their complex dynamics and variable shape characteristics. Since learning new manipulation skills from human demonstration is an effective way for robot applications, developing prior knowledge of the representation and dynamics of soft objects is necessary. In this regard, we propose a pre-trained soft object manipulation skill learning model, namely SoftGPT, that is trained using large amounts of exploration data, consisting of a three-dimensional heterogeneous graph representation and a GPT-based dynamics model. For each downstream task, a goal-oriented policy agent is trained to predict the subsequent actions, and SoftGPT generates the consequences of these actions. Integrating these two approaches establishes a thinking process in the robot's mind that provides rollout for facilitating policy learning. Our results demonstrate that leveraging prior knowledge through this thinking process can efficiently learn various soft object manipulation skills, with the potential for direct learning from human demonstrations.", "url": "https://arxiv.org/abs/2306.12677"}, {"metadata": {"arXiv": "2306.13028", "Date": "Thu, 22 Jun 2023 16:45:45 ", "Title": "Transferable Curricula through Difficulty Conditioned Generators", "Authors": ["Sidney Tio", "Pradeep Varakantham"], "Categories": "cs.AI cs.LG", "Comments": ["IJCAI'23"]}, "abstract": "Advancements in reinforcement learning (RL) have demonstrated superhuman performance in complex tasks such as Starcraft, Go, Chess etc. However, knowledge transfer from Artificial \"Experts\" to humans remain a significant challenge. A promising avenue for such transfer would be the use of curricula. Recent methods in curricula generation focuses on training RL agents efficiently, yet such methods rely on surrogate measures to track student progress, and are not suited for training robots in the real world (or more ambitiously humans). In this paper, we introduce a method named Parameterized Environment Response Model (PERM) that shows promising results in training RL agents in parameterized environments. Inspired by Item Response Theory, PERM seeks to model difficulty of environments and ability of RL agents directly. Given that RL agents and humans are trained more efficiently under the \"zone of proximal development\", our method generates a curriculum by matching the difficulty of an environment to the current ability of the student. In addition, PERM can be trained offline and does not employ non-stationary measures of student ability, making it suitable for transfer between students. We demonstrate PERM's ability to represent the environment parameter space, and training with RL agents with PERM produces a strong performance in deterministic environments. Lastly, we show that our method is transferable between students, without any sacrifice in training quality.", "url": "https://arxiv.org/abs/2306.13028"}, {"metadata": {"arXiv": "2306.13092", "Date": "Thu, 22 Jun 2023 17:59:58 ", "Title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective", "Authors": ["Zeyuan Yin and Eric Xing and Zhiqiang Shen"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Technical report"]}, "abstract": "We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for effective dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution training, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively. Our approach also outperforms MTT by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster in speed with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://zeyuanyin.github.io/projects/SRe2L/.", "url": "https://arxiv.org/abs/2306.13092"}, {"metadata": {"arXiv": "2306.12442", "Date": "Tue, 20 Jun 2023 08:16:37 ", "Title": "Knowledge Distillation via Token-level Relationship Graph", "Authors": ["Shuoxi Zhang", "Hanpeng Liu", "Kun He"], "Categories": "cs.LG cs.AI"}, "abstract": "Knowledge distillation is a powerful technique for transferring knowledge from a pre-trained teacher model to a student model. However, the true potential of knowledge transfer has not been fully explored. Existing approaches primarily focus on distilling individual information or instance-level relationships, overlooking the valuable information embedded in token-level relationships, which may be particularly affected by the long-tail effects. To address the above limitations, we propose a novel method called Knowledge Distillation with Token-level Relationship Graph (TRG) that leverages the token-wise relational knowledge to enhance the performance of knowledge distillation. By employing TRG, the student model can effectively emulate higher-level semantic information from the teacher model, resulting in improved distillation results. To further enhance the learning process, we introduce a token-wise contextual loss called contextual loss, which encourages the student model to capture the inner-instance semantic contextual of the teacher model. We conduct experiments to evaluate the effectiveness of the proposed method against several state-of-the-art approaches. Empirical results demonstrate the superiority of TRG across various visual classification tasks, including those involving imbalanced data. Our method consistently outperforms the existing baselines, establishing a new state-of-the-art performance in the field of knowledge distillation.", "url": "https://arxiv.org/abs/2306.12442"}, {"metadata": {"arXiv": "2306.12453", "Date": "Wed, 21 Jun 2023 02:27:15 ", "Title": "Learning Conditional Instrumental Variable Representation for Causal Effect Estimation", "Authors": ["Debo Cheng", "Ziqi Xu", "Jiuyong Li", "Lin Liu", "Thuc Duy Le", "and Jixue Liu"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["Debo Cheng and Ziqi Xu contributed equally. 20 pages", "5 tables", "and 3 figures. Accepted at ECML-PKDD2023"]}, "abstract": "One of the fundamental challenges in causal inference is to estimate the causal effect of a treatment on its outcome of interest from observational data. However, causal effect estimation often suffers from the impacts of confounding bias caused by unmeasured confounders that affect both the treatment and the outcome. The instrumental variable (IV) approach is a powerful way to eliminate the confounding bias from latent confounders. However, the existing IV-based estimators require a nominated IV, and for a conditional IV (CIV) the corresponding conditioning set too, for causal effect estimation. This limits the application of IV-based estimators. In this paper, by leveraging the advantage of disentangled representation learning, we propose a novel method, named DVAE.CIV, for learning and disentangling the representations of CIV and the representations of its conditioning set for causal effect estimations from data with latent confounders. Extensive experimental results on both synthetic and real-world datasets demonstrate the superiority of the proposed DVAE.CIV method against the existing causal effect estimators.", "url": "https://arxiv.org/abs/2306.12453"}, {"metadata": {"arXiv": "2306.12457", "Date": "Wed, 21 Jun 2023 06:30:02 ", "Title": "Deep Dynamic Epidemiological Modelling for COVID-19 Forecasting in Multi-level Districts", "Authors": ["Ruhan Liu", "Jiajia Li", "Yang Wen", "Huating Li", "Ping Zhang", "Bin Sheng", "David Dagan Feng"], "Categories": "cs.LG cs.AI q-bio.PE"}, "abstract": "Objective: COVID-19 has spread worldwide and made a huge influence across the world. Modeling the infectious spread situation of COVID-19 is essential to understand the current condition and to formulate intervention measurements. Epidemiological equations based on the SEIR model simulate disease development. The traditional parameter estimation method to solve SEIR equations could not precisely fit real-world data due to different situations, such as social distancing policies and intervention strategies. Additionally, learning-based models achieve outstanding fitting performance, but cannot visualize mechanisms. Methods: Thus, we propose a deep dynamic epidemiological (DDE) method that combines epidemiological equations and deep-learning advantages to obtain high accuracy and visualization. The DDE contains deep networks to fit the effect function to simulate the ever-changing situations based on the neural ODE method in solving variants' equations, ensuring the fitting performance of multi-level areas. Results: We introduce four SEIR variants to fit different situations in different countries and regions. We compare our DDE method with traditional parameter estimation methods (Nelder-Mead, BFGS, Powell, Truncated Newton Conjugate-Gradient, Neural ODE) in fitting the real-world data in the cases of countries (the USA, Columbia, South Africa) and regions (Wuhan in China, Piedmont in Italy). Our DDE method achieves the best Mean Square Error and Pearson coefficient in all five areas. Further, compared with the state-of-art learning-based approaches, the DDE outperforms all techniques, including LSTM, RNN, GRU, Random Forest, Extremely Random Trees, and Decision Tree. Conclusion: DDE presents outstanding predictive ability and visualized display of the changes in infection rates in different regions and countries.", "url": "https://arxiv.org/abs/2306.12457"}, {"metadata": {"arXiv": "2306.12507", "Date": "Wed, 21 Jun 2023 18:36:15 ", "Title": "Investigating Poor Performance Regions of Black Boxes: LIME-based Exploration in Sepsis Detection", "Authors": ["Mozhgan Salimiparsa", "Surajsinh Parmar", "San Lee", "Choongmin Kim", "Yonghwan Kim", "Jang Yong Kim"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at the 1st World Conference on eXplainable Artificial Intelligence - Late-breaking work", "Demos and Doctoral Consortium", "2023"], "MSC-class": "68T01"}, "abstract": "Interpreting machine learning models remains a challenge, hindering their adoption in clinical settings. This paper proposes leveraging Local Interpretable Model-Agnostic Explanations (LIME) to provide interpretable descriptions of black box classification models in high-stakes sepsis detection. By analyzing misclassified instances, significant features contributing to suboptimal performance are identified. The analysis reveals regions where the classifier performs poorly, allowing the calculation of error rates within these regions. This knowledge is crucial for cautious decision-making in sepsis detection and other critical applications. The proposed approach is demonstrated using the eICU dataset, effectively identifying and visualizing regions where the classifier underperforms. By enhancing interpretability, our method promotes the adoption of machine learning models in clinical practice, empowering informed decision-making and mitigating risks in critical scenarios.", "url": "https://arxiv.org/abs/2306.12507"}, {"metadata": {"arXiv": "2306.12554", "Date": "Wed, 21 Jun 2023 20:47:23 ", "Title": "Improving Long-Horizon Imitation Through Instruction Prediction", "Authors": ["Joey Hejna", "Pieter Abbeel", "Lerrel Pinto"], "Categories": "cs.LG cs.AI", "Comments": ["Published at AAAI 2023"]}, "abstract": "Complex, long-horizon planning and its combinatorial nature pose steep challenges for learning-based agents. Difficulties in such settings are exacerbated in low data regimes where over-fitting stifles generalization and compounding errors hurt accuracy. In this work, we explore the use of an often unused source of auxiliary supervision: language. Inspired by recent advances in transformer-based models, we train agents with an instruction prediction loss that encourages learning temporally extended representations that operate at a high level of abstraction. Concretely, we demonstrate that instruction modeling significantly improves performance in planning environments when training with a limited number of demonstrations on the BabyAI and Crafter benchmarks. In further analysis we find that instruction modeling is most important for tasks that require complex reasoning, while understandably offering smaller gains in environments that require simple plans. More details and code can be found at https://github.com/jhejna/instruction-prediction.", "url": "https://arxiv.org/abs/2306.12554"}, {"metadata": {"arXiv": "2306.12627", "Date": "Thu, 22 Jun 2023 01:33:47 ", "Title": "Targeted collapse regularized autoencoder for anomaly detection: black hole at the center", "Authors": ["Amin Ghafourian", "Huanyi Shui", "Devesh Upadhyay", "Rajesh Gupta", "Dimitar Filev", "Iman Soltani Bozchalooi"], "Categories": "cs.LG cs.AI cs.CV q-bio.NC stat.ML", "Comments": ["16 pages", "4 figures", "4 tables"]}, "abstract": "Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes the requirement for hyperparameter tuning and customization for new applications which, paired with its permissive data modality constraint, enhances the potential for successful adoption across a broad range of applications. We test the method on various visual and tabular benchmarks and demonstrate that the technique matches and frequently outperforms alternatives. We also provide a theoretical analysis and numerical simulations that help demonstrate the underlying process that unfolds during training and how it can help with anomaly detection. This mitigates the black-box nature of autoencoder-based anomaly detection algorithms and offers an avenue for further investigation of advantages, fail cases, and potential new directions.", "url": "https://arxiv.org/abs/2306.12627"}, {"metadata": {"arXiv": "2306.12687", "Date": "Thu, 22 Jun 2023 06:18:40 ", "Title": "Explainable Representations for Relation Prediction in Knowledge Graphs", "Authors": ["Rita T. Sousa", "Sara Silva", "Catia Pesquita"], "Categories": "cs.LG cs.AI", "Comments": ["16 pages", "3 figures"]}, "abstract": "Knowledge graphs represent real-world entities and their relations in a semantically-rich structure supported by ontologies. Exploring this data with machine learning methods often relies on knowledge graph embeddings, which produce latent representations of entities that preserve structural and local graph neighbourhood properties, but sacrifice explainability. However, in tasks such as link or relation prediction, understanding which specific features better explain a relation is crucial to support complex or critical applications. We propose SEEK, a novel approach for explainable representations to support relation prediction in knowledge graphs. It is based on identifying relevant shared semantic aspects (i.e., subgraphs) between entities and learning representations for each subgraph, producing a multi-faceted and explainable representation. We evaluate SEEK on two real-world highly complex relation prediction tasks: protein-protein interaction prediction and gene-disease association prediction. Our extensive analysis using established benchmarks demonstrates that SEEK achieves significantly better performance than standard learning representation methods while identifying both sufficient and necessary explanations based on shared semantic aspects.", "url": "https://arxiv.org/abs/2306.12687"}, {"metadata": {"arXiv": "2306.12703", "Date": "Thu, 22 Jun 2023 07:14:02 ", "Title": "OptIForest: Optimal Isolation Forest for Anomaly Detection", "Authors": ["Haolong Xiang", "Xuyun Zhang", "Hongsheng Hu", "Lianyong Qi", "Wanchun Dou", "Mark Dras", "Amin Beheshti and Xiaolong Xu"], "Categories": "cs.LG cs.AI", "Comments": ["This paper has been accepted by International Joint Conference on Artificial Intelligence (IJCAI-23)"]}, "abstract": "Anomaly detection plays an increasingly important role in various fields for critical tasks such as intrusion detection in cybersecurity, financial risk detection, and human health monitoring. A variety of anomaly detection methods have been proposed, and a category based on the isolation forest mechanism stands out due to its simplicity, effectiveness, and efficiency, e.g., iForest is often employed as a state-of-the-art detector for real deployment. While the majority of isolation forests use the binary structure, a framework LSHiForest has demonstrated that the multi-fork isolation tree structure can lead to better detection performance. However, there is no theoretical work answering the fundamentally and practically important question on the optimal tree structure for an isolation forest with respect to the branching factor. In this paper, we establish a theory on isolation efficiency to answer the question and determine the optimal branching factor for an isolation tree. Based on the theoretical underpinning, we design a practical optimal isolation forest OptIForest incorporating clustering based learning to hash which enables more information to be learned from data for better isolation quality. The rationale of our approach relies on a better bias-variance trade-off achieved by bias reduction in OptIForest. Extensive experiments on a series of benchmarking datasets for comparative and ablation studies demonstrate that our approach can efficiently and robustly achieve better detection performance in general than the state-of-the-arts including the deep learning based methods.", "url": "https://arxiv.org/abs/2306.12703"}, {"metadata": {"arXiv": "2306.12729", "Date": "Thu, 22 Jun 2023 08:11:32 ", "Title": "MP3: Movement Primitive-Based (Re-)Planning Policy", "Authors": ["Fabian Otto", "Hongyi Zhou", "Onur Celik", "Ge Li", "Rudolf Lioutikov", "Gerhard Neumann"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["The video demonstration can be accessed at https://intuitive-robots.github.io/mp3_website/. arXiv admin note: text overlap with arXiv:2210.09622"]}, "abstract": "We introduce a novel deep reinforcement learning (RL) approach called Movement Prmitive-based Planning Policy (MP3). By integrating movement primitives (MPs) into the deep RL framework, MP3 enables the generation of smooth trajectories throughout the whole learning process while effectively learning from sparse and non-Markovian rewards. Additionally, MP3 maintains the capability to adapt to changes in the environment during execution. Although many early successes in robot RL have been achieved by combining RL with MPs, these approaches are often limited to learning single stroke-based motions, lacking the ability to adapt to task variations or adjust motions during execution. Building upon our previous work, which introduced an episode-based RL method for the non-linear adaptation of MP parameters to different task variations, this paper extends the approach to incorporating replanning strategies. This allows adaptation of the MP parameters throughout motion execution, addressing the lack of online motion adaptation in stochastic domains requiring feedback. We compared our approach against state-of-the-art deep RL and RL with MPs methods. The results demonstrated improved performance in sophisticated, sparse reward settings and in domains requiring replanning.", "url": "https://arxiv.org/abs/2306.12729"}, {"metadata": {"arXiv": "2306.12802", "Date": "Thu, 22 Jun 2023 11:01:41 ", "Title": "Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery", "Authors": ["Hoang Thanh Lam", "Marco Luca Sbodio", "Marcos Mart\\'inez Gallindo", "Mykhaylo Zayats", "Ra\\'ul Fern\\'andez-D\\'iaz", "V\\'ictor Valls", "Gabriele Picco", "Cesar Berrospi Ramis", "Vanessa L\\'opez"], "Categories": "cs.LG cs.AI q-bio.BM"}, "abstract": "Recent research in representation learning utilizes large databases of proteins or molecules to acquire knowledge of drug and protein structures through unsupervised learning techniques. These pre-trained representations have proven to significantly enhance the accuracy of subsequent tasks, such as predicting the affinity between drugs and target proteins. In this study, we demonstrate that by incorporating knowledge graphs from diverse sources and modalities into the sequences or SMILES representation, we can further enrich the representation and achieve state-of-the-art results on established benchmark datasets. We provide preprocessed and integrated data obtained from 7 public sources, which encompass over 30M triples. Additionally, we make available the pre-trained models based on this data, along with the reported outcomes of their performance on three widely-used benchmark datasets for drug-target binding affinity prediction found in the Therapeutic Data Commons (TDC) benchmarks. Additionally, we make the source code for training models on benchmark datasets publicly available. Our objective in releasing these pre-trained models, accompanied by clean data for model pretraining and benchmark results, is to encourage research in knowledge-enhanced representation learning.", "url": "https://arxiv.org/abs/2306.12802"}, {"metadata": {"arXiv": "2306.12816", "Date": "Thu, 22 Jun 2023 11:31:11 ", "Title": "XAI-TRIS: Non-linear benchmarks to quantify ML explanation performance", "Authors": ["Benedict Clark", "Rick Wilming", "Stefan Haufe"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Under review"]}, "abstract": "The field of 'explainable' artificial intelligence (XAI) has produced highly cited methods that seek to make the decisions of complex machine learning (ML) methods 'understandable' to humans, for example by attributing 'importance' scores to input features. Yet, a lack of formal underpinning leaves it unclear as to what conclusions can safely be drawn from the results of a given XAI method and has also so far hindered the theoretical verification and empirical validation of XAI methods. This means that challenging non-linear problems, typically solved by deep neural networks, presently lack appropriate remedies. Here, we craft benchmark datasets for three different non-linear classification scenarios, in which the important class-conditional features are known by design, serving as ground truth explanations. Using novel quantitative metrics, we benchmark the explanation performance of a wide set of XAI methods across three deep learning model architectures. We show that popular XAI methods are often unable to significantly outperform random performance baselines and edge detection methods. Moreover, we demonstrate that explanations derived from different model architectures can be vastly different; thus, prone to misinterpretation even under controlled conditions.", "url": "https://arxiv.org/abs/2306.12816"}, {"metadata": {"arXiv": "2306.12929", "Date": "Thu, 22 Jun 2023 14:39:04 ", "Title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing", "Authors": ["Yelysei Bondarenko", "Markus Nagel", "Tijmen Blankevoort"], "Categories": "cs.LG cs.AI cs.CL cs.CV"}, "abstract": "Transformer models have been widely adopted in various domains over the last years, and especially large language models have advanced the field of AI significantly. Due to their size, the capability of these networks has increased tremendously, but this has come at the cost of a significant increase in necessary compute. Quantization is one of the most effective ways to reduce the computational time and memory consumption of neural networks. Many studies have shown, however, that modern transformer models tend to learn strong outliers in their activations, making them difficult to quantize. To retain acceptable performance, the existence of these outliers requires activations to be in higher bitwidth or the use of different numeric formats, extra fine-tuning, or other workarounds. We show that strong outliers are related to very specific behavior of attention heads that try to learn a \"no-op\" or just a partial update of the residual. To achieve the exact zeros needed in the attention matrix for a no-update, the input to the softmax is pushed to be larger and larger during training, causing outliers in other parts of the network. Based on these observations, we propose two simple (independent) modifications to the attention mechanism - clipped softmax and gated attention. We empirically show that models pre-trained using our methods learn significantly smaller outliers while maintaining and sometimes even improving the floating-point task performance. This enables us to quantize transformers to full INT8 quantization of the activations without any additional effort. We demonstrate the effectiveness of our methods on both language models (BERT, OPT) and vision transformers.", "url": "https://arxiv.org/abs/2306.12929"}, {"metadata": {"arXiv": "2306.12943", "Date": "Thu, 22 Jun 2023 14:58:18 ", "Title": "Evolving Computation Graphs", "Authors": ["Andreea Deac", "Jian Tang"], "Categories": "cs.LG cs.AI cs.SI stat.ML", "Comments": ["To appear at ICML TAGML 2023; 18 pages", "2 figures"]}, "abstract": "Graph neural networks (GNNs) have demonstrated success in modeling relational data, especially for data that exhibits homophily: when a connection between nodes tends to imply that they belong to the same class. However, while this assumption is true in many relevant situations, there are important real-world scenarios that violate this assumption, and this has spurred research into improving GNNs for these cases. In this work, we propose Evolving Computation Graphs (ECGs), a novel method for enhancing GNNs on heterophilic datasets. Our approach builds on prior theoretical insights linking node degree, high homophily, and inter vs intra-class embedding similarity by rewiring the GNNs' computation graph towards adding edges that connect nodes that are likely to be in the same class. We utilise weaker classifiers to identify these edges, ultimately improving GNN performance on non-homophilic data as a result. We evaluate ECGs on a diverse set of recently-proposed heterophilous datasets and demonstrate improvements over the relevant baselines. ECG presents a simple, intuitive and elegant approach for improving GNN performance on heterophilic datasets without requiring prior domain knowledge.", "url": "https://arxiv.org/abs/2306.12943"}, {"metadata": {"arXiv": "2306.13004", "Date": "Thu, 22 Jun 2023 16:04:16 ", "Title": "Can Differentiable Decision Trees Learn Interpretable Reward Functions?", "Authors": ["Akansha Kalra", "Daniel S. Brown"], "Categories": "cs.LG cs.AI"}, "abstract": "There is an increasing interest in learning reward functions that model human intent and human preferences. However, many frameworks use blackbox learning methods that, while expressive, are difficult to interpret. We propose and evaluate a novel approach for learning expressive and interpretable reward functions from preferences using Differentiable Decision Trees (DDTs) for both low- and high-dimensional state inputs. We explore and discuss the viability of learning interpretable reward functions using DDTs by evaluating our algorithm on Cartpole, Visual Gridworld environments, and Atari games. We provide evidence that that the tree structure of our learned reward function is useful in determining the extent to which a reward function is aligned with human preferences. We visualize the learned reward DDTs and find that they are capable of learning interpretable reward functions but that the discrete nature of the trees hurts the performance of reinforcement learning at test time. However, we also show evidence that using soft outputs (averaged over all leaf nodes) results in competitive performance when compared with larger capacity deep neural network reward functions.", "url": "https://arxiv.org/abs/2306.13004"}, {"metadata": {"arXiv": "2306.13085", "Date": "Thu, 22 Jun 2023 17:58:02 ", "Title": "Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting", "Authors": ["Zhang-Wei Hong", "Pulkit Agrawal", "R\\'emi Tachet des Combes", "Romain Laroche"], "Categories": "cs.LG cs.AI", "Journal-ref": "Conference paper at ICLR 2023"}, "abstract": "Most offline reinforcement learning (RL) algorithms return a target policy maximizing a trade-off between (1) the expected performance gain over the behavior policy that collected the dataset, and (2) the risk stemming from the out-of-distribution-ness of the induced state-action occupancy. It follows that the performance of the target policy is strongly related to the performance of the behavior policy and, thus, the trajectory return distribution of the dataset. We show that in mixed datasets consisting of mostly low-return trajectories and minor high-return trajectories, state-of-the-art offline RL algorithms are overly restrained by low-return trajectories and fail to exploit high-performing trajectories to the fullest. To overcome this issue, we show that, in deterministic MDPs with stochastic initial states, the dataset sampling can be re-weighted to induce an artificial dataset whose behavior policy has a higher return. This re-weighted sampling strategy may be combined with any offline RL algorithm. We further analyze that the opportunity for performance improvement over the behavior policy correlates with the positive-sided variance of the returns of the trajectories in the dataset. We empirically show that while CQL, IQL, and TD3+BC achieve only a part of this potential policy improvement, these same algorithms combined with our reweighted sampling strategy fully exploit the dataset. Furthermore, we empirically demonstrate that, despite its theoretical limitation, the approach may still be efficient in stochastic environments. The code is available at https://github.com/Improbable-AI/harness-offline-rl.", "url": "https://arxiv.org/abs/2306.13085"}, {"metadata": {"arXiv": "2306.12926", "Date": "Thu, 22 Jun 2023 14:38:12 ", "Title": "Decentralized Multi-Agent Reinforcement Learning with Global State Prediction", "Authors": ["Joshua Bloom", "Pranjal Paliwal", "Apratim Mukherjee", "Carlo Pinciroli"], "Categories": "cs.RO cs.AI cs.LG cs.MA"}, "abstract": "Deep reinforcement learning (DRL) has seen remarkable success in the control of single robots. However, applying DRL to robot swarms presents significant challenges. A critical challenge is non-stationarity, which occurs when two or more robots update individual or shared policies concurrently, thereby engaging in an interdependent training process with no guarantees of convergence. Circumventing non-stationarity typically involves training the robots with global information about other agents' states and/or actions. In contrast, in this paper we explore how to remove the need for global information. We pose our problem as a Partially Observable Markov Decision Process, due to the absence of global knowledge on other agents. Using collective transport as a testbed scenario, we study two approaches to multi-agent training. In the first, the robots exchange no messages, and are trained to rely on implicit communication through push-and-pull on the object to transport. In the second approach, we introduce Global State Prediction (GSP), a network trained to forma a belief over the swarm as a whole and predict its future states. We provide a comprehensive study over four well-known deep reinforcement learning algorithms in environments with obstacles, measuring performance as the successful transport of the object to the goal within a desired time-frame. Through an ablation study, we show that including GSP boosts performance and increases robustness when compared with methods that use global knowledge.", "url": "https://arxiv.org/abs/2306.12926"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.00079", "Date": "Tue, 31 Oct 2023 18:44:03 ", "Title": "Spuriosity Rankings for Free: A Simple Framework for Last Layer Retraining Based on Object Detection", "Authors": ["Mohammad Azizmalayeri", "Reza Abbasi", "Amir Hosein Haji Mohammad rezaie", "Reihaneh Zohrabi", "Mahdi Amiri", "Mohammad Taghi Manzuri", "Mohammad Hossein Rohban"], "Categories": "cs.CV cs.LG", "Comments": ["Accepted at ICML 2023 Workshop on Spurious Correlations", "Invariance", "and Stability (SCIS)"]}, "abstract": "Deep neural networks have exhibited remarkable performance in various domains. However, the reliance of these models on spurious features has raised concerns about their reliability. A promising solution to this problem is last-layer retraining, which involves retraining the linear classifier head on a small subset of data without spurious cues. Nevertheless, selecting this subset requires human supervision, which reduces its scalability. Moreover, spurious cues may still exist in the selected subset. As a solution to this problem, we propose a novel ranking framework that leverages an open vocabulary object detection technique to identify images without spurious cues. More specifically, we use the object detector as a measure to score the presence of the target object in the images. Next, the images are sorted based on this score, and the last-layer of the model is retrained on a subset of the data with the highest scores. Our experiments on the ImageNet-1k dataset demonstrate the effectiveness of this ranking framework in sorting images based on spuriousness and using them for last-layer retraining.", "url": "https://arxiv.org/abs/2311.00079"}, {"metadata": {"arXiv": "2311.00285", "Date": "Wed, 01 Nov 2023 04:36:18 ", "Title": "Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space Detection Approach", "Authors": ["Zhenbang Du", "Jiayu An", "Jiahao Hong", "Dongrui Wu"], "Categories": "cs.CV cs.LG"}, "abstract": "Open Set Domain Adaptation (OSDA) aims to cope with the distribution and label shifts between the source and target domains simultaneously, performing accurate classification for known classes while identifying unknown class samples in the target domain. Most existing OSDA approaches, depending on the final image feature space of deep models, require manually-tuned thresholds, and may easily misclassify unknown samples as known classes. Mixture-of-Expert (MoE) could be a remedy. Within an MoE, different experts address different input features, producing unique expert routing patterns for different classes in a routing feature space. As a result, unknown class samples may also display different expert routing patterns to known classes. This paper proposes Dual-Space Detection, which exploits the inconsistencies between the image feature space and the routing feature space to detect unknown class samples without any threshold. Graph Router is further introduced to better make use of the spatial information among image patches. Experiments on three different datasets validated the effectiveness and superiority of our approach. The code will come soon.", "url": "https://arxiv.org/abs/2311.00285"}, {"metadata": {"arXiv": "2311.00476", "Date": "Wed, 01 Nov 2023 12:25:02 ", "Title": "Group Distributionally Robust Knowledge Distillation", "Authors": ["Konstantinos Vilouras", "Xiao Liu", "Pedro Sanchez", "Alison Q. O'Neil", "Sotirios A. Tsaftaris"], "Categories": "cs.CV cs.LG", "Comments": ["9 pages", "MLMI workshop"]}, "abstract": "Knowledge distillation enables fast and effective transfer of features learned from a bigger model to a smaller one. However, distillation objectives are susceptible to sub-population shifts, a common scenario in medical imaging analysis which refers to groups/domains of data that are underrepresented in the training set. For instance, training models on health data acquired from multiple scanners or hospitals can yield subpar performance for minority groups. In this paper, inspired by distributionally robust optimization (DRO) techniques, we address this shortcoming by proposing a group-aware distillation loss. During optimization, a set of weights is updated based on the per-group losses at a given iteration. This way, our method can dynamically focus on groups that have low performance during training. We empirically validate our method, GroupDistil on two benchmark datasets (natural images and cardiac MRIs) and show consistent improvement in terms of worst-group accuracy.", "url": "https://arxiv.org/abs/2311.00476"}, {"metadata": {"arXiv": "2311.00260", "Date": "Wed, 01 Nov 2023 03:17:39 ", "Title": "Incentivized Collaboration in Active Learning", "Authors": ["Lee Cohen", "Han Shao"], "Categories": "cs.GT cs.LG"}, "abstract": "In collaborative active learning, where multiple agents try to learn labels from a common hypothesis, we introduce an innovative framework for incentivized collaboration. Here, rational agents aim to obtain labels for their data sets while keeping label complexity at a minimum. We focus on designing (strict) individually rational (IR) collaboration protocols, ensuring that agents cannot reduce their expected label complexity by acting individually. We first show that given any optimal active learning algorithm, the collaboration protocol that runs the algorithm as is over the entire data is already IR. However, computing the optimal algorithm is NP-hard. We therefore provide collaboration protocols that achieve (strict) IR and are comparable with the best known tractable approximation algorithm in terms of label complexity.", "url": "https://arxiv.org/abs/2311.00260"}, {"metadata": {"arXiv": "2311.00676", "Date": "Wed, 01 Nov 2023 17:34:58 ", "Title": "Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games", "Authors": ["Yang Cai", "Gabriele Farina", "Julien Grand-Cl\\'ement", "Christian Kroer", "Chung-Wei Lee", "Haipeng Luo", "Weiqiang Zheng"], "Categories": "cs.GT cs.LG"}, "abstract": "Algorithms based on regret matching, specifically regret matching$^+$ (RM$^+$), and its variants are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-word learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-iterate convergence: we prove that extragradient RM$^{+}$ and smooth Predictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate) and $1/\\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted variants of these algorithms, and show that they enjoy linear-rate last-iterate convergence.", "url": "https://arxiv.org/abs/2311.00676"}, {"metadata": {"arXiv": "2311.00055", "Date": "Tue, 31 Oct 2023 18:03:54 ", "Title": "Training-Free Generalization on Heterogeneous Tabular Data via Meta-Representation", "Authors": ["Han-Jia Ye", "Qi-Le Zhou", "De-Chuan Zhan"], "Categories": "cs.LG"}, "abstract": "Tabular data is prevalent across various machine learning domains. Yet, the inherent heterogeneities in attribute and class spaces across different tabular datasets hinder the effective sharing of knowledge, limiting a tabular model to benefit from other datasets. In this paper, we propose Tabular data Pre-Training via Meta-representation (TabPTM), which allows one tabular model pre-training on a set of heterogeneous datasets. Then, this pre-trained model can be directly applied to unseen datasets that have diverse attributes and classes without additional training. Specifically, TabPTM represents an instance through its distance to a fixed number of prototypes, thereby standardizing heterogeneous tabular datasets. A deep neural network is then trained to associate these meta-representations with dataset-specific classification confidences, endowing TabPTM with the ability of training-free generalization. Experiments validate that TabPTM achieves promising performance in new datasets, even under few-shot scenarios.", "url": "https://arxiv.org/abs/2311.00055"}, {"metadata": {"arXiv": "2311.00109", "Date": "Tue, 31 Oct 2023 19:36:00 ", "Title": "FairWASP: Fast and Optimal Fair Wasserstein Pre-processing", "Authors": ["Zikai Xiong", "Niccol\\`o Dalmasso", "Alan Mishler", "Vamsi K. Potluru", "Tucker Balch", "Manuela Veloso"], "Categories": "cs.LG stat.ML", "Comments": ["14 pages", "4 figures", "1 table"]}, "abstract": "Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Our work is based on reformulating the pre-processing task as a large-scale mixed-integer program (MIP), for which we propose a highly efficient algorithm based on the cutting plane method. Experiments on synthetic datasets demonstrate that our proposed optimization algorithm significantly outperforms state-of-the-art commercial solvers in solving both the MIP and its linear program relaxation. Further experiments highlight the competitive performance of FairWASP in reducing disparities while preserving accuracy in downstream classification settings.", "url": "https://arxiv.org/abs/2311.00109"}, {"metadata": {"arXiv": "2311.00115", "Date": "Tue, 31 Oct 2023 19:44:32 ", "Title": "EXTRACT: Explainable Transparent Control of Bias in Embeddings", "Authors": ["Zhijin Guo", "Zhaozhen Xu", "Martha Lewis", "Nello Cristianini"], "Categories": "cs.LG", "Comments": ["Aequitas 2023: Workshop on Fairness and Bias in AI | co-located with ECAI 2023", "Krak\\'ow", "Poland"]}, "abstract": "Knowledge Graphs are a widely used method to represent relations between entities in various AI applications, and Graph Embedding has rapidly become a standard technique to represent Knowledge Graphs in such a way as to facilitate inferences and decisions. As this representation is obtained from behavioural data, and is not in a form readable by humans, there is a concern that it might incorporate unintended information that could lead to biases. We propose EXTRACT: a suite of Explainable and Transparent methods to ConTrol bias in knowledge graph embeddings, so as to assess and decrease the implicit presence of protected information. Our method uses Canonical Correlation Analysis (CCA) to investigate the presence, extent and origins of information leaks during training, then decomposes embeddings into a sum of their private attributes by solving a linear system. Our experiments, performed on the MovieLens1M dataset, show that a range of personal attributes can be inferred from a user's viewing behaviour and preferences, including gender, age, and occupation. Further experiments, performed on the KG20C citation dataset, show that the information about the conference in which a paper was published can be inferred from the citation network of that article. We propose four transparent methods to maintain the capability of the embedding to make the intended predictions without retaining unwanted information. A trade-off between these two goals is observed.", "url": "https://arxiv.org/abs/2311.00115"}, {"metadata": {"arXiv": "2311.00118", "Date": "Tue, 31 Oct 2023 19:47:11 ", "Title": "Extracting the Multiscale Causal Backbone of Brain Dynamics", "Authors": ["Gabriele D'Acunto", "Francesco Bonchi", "Gianmarco De Francisci Morales", "Giovanni Petri"], "Categories": "cs.LG q-bio.NC stat.AP stat.ME stat.ML"}, "abstract": "The bulk of the research effort on brain connectivity revolves around statistical associations among brain regions, which do not directly relate to the causal mechanisms governing brain dynamics. Here we propose the multiscale causal backbone (MCB) of brain dynamics shared by a set of individuals across multiple temporal scales, and devise a principled methodology to extract it. Our approach leverages recent advances in multiscale causal structure learning and optimizes the trade-off between the model fitting and its complexity. Empirical assessment on synthetic data shows the superiority of our methodology over a baseline based on canonical functional connectivity networks. When applied to resting-state fMRI data, we find sparse MCBs for both the left and right brain hemispheres. Thanks to its multiscale nature, our approach shows that at low-frequency bands, causal dynamics are driven by brain regions associated with high-level cognitive functions; at higher frequencies instead, nodes related to sensory processing play a crucial role. Finally, our analysis of individual multiscale causal structures confirms the existence of a causal fingerprint of brain connectivity, thus supporting from a causal perspective the existing extensive research in brain connectivity fingerprinting.", "url": "https://arxiv.org/abs/2311.00118"}, {"metadata": {"arXiv": "2311.00167", "Date": "Tue, 31 Oct 2023 21:51:12 ", "Title": "Multi-task Deep Convolutional Network to Predict Sea Ice Concentration and Drift in the Arctic Ocean", "Authors": ["Younghyun Koo", "Maryam Rahnemoonfar"], "Categories": "cs.LG cs.CV physics.ao-ph"}, "abstract": "Forecasting sea ice concentration (SIC) and sea ice drift (SID) in the Arctic Ocean is of great significance as the Arctic environment has been changed by the recent warming climate. Given that physical sea ice models require high computational costs with complex parameterization, deep learning techniques can effectively replace the physical model and improve the performance of sea ice prediction. This study proposes a novel multi-task fully conventional network architecture named hierarchical information-sharing U-net (HIS-Unet) to predict daily SIC and SID. Instead of learning SIC and SID separately at each branch, we allow the SIC and SID layers to share their information and assist each other's prediction through the weighting attention modules (WAMs). Consequently, our HIS-Unet outperforms other statistical approaches, sea ice physical models, and neural networks without such information-sharing units. The improvement of HIS-Unet is obvious both for SIC and SID prediction when and where sea ice conditions change seasonally, which implies that the information sharing through WAMs allows the model to learn the sudden changes of SIC and SID. The weight values of the WAMs imply that SIC information plays a more critical role in SID prediction, compared to that of SID information in SIC prediction, and information sharing is more active in sea ice edges (seasonal sea ice) than in the central Arctic (multi-year sea ice).", "url": "https://arxiv.org/abs/2311.00167"}, {"metadata": {"arXiv": "2311.00168", "Date": "Tue, 31 Oct 2023 21:52:41 ", "Title": "The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback", "Authors": ["Nathan Lambert and Roberto Calandra"], "Categories": "cs.LG", "Comments": ["10 pages", "4 figures"]}, "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a powerful technique to make large language models (LLMs) easier to prompt and more capable in complex settings. RLHF at its core is providing a new toolkit to optimize LLMs other than next-token prediction, enabling the integration of qualitative training goals. The attempted match between user preferences and downstream performance, which happens in a learned reward model, results in an optimization landscape where training and evaluation metrics can appear correlated. The apparent correlation can lead to unexpected behaviors and stories of \"too much RLHF.\" In RLHF, challenges emerge because the following sub-modules are not consistent with each other: the reward model training, the policy model training, and the policy model evaluation. This mismatch results in models that sometimes avoid user requests for false safety flags, are difficult to steer to an intended characteristic, or always answer in a specific style. As chat model evaluation becomes increasingly nuanced, the reliance on a perceived link between reward model score and downstream performance drives the objective mismatch issue. In this paper, we illustrate the cause of this issue, reviewing relevant literature from model-based reinforcement learning, and discuss relevant solutions to encourage further research. By solving objective mismatch in RLHF, the LLMs of the future will be more precisely aligned to user instructions for both safety and helpfulness.", "url": "https://arxiv.org/abs/2311.00168"}, {"metadata": {"arXiv": "2311.00208", "Date": "Wed, 01 Nov 2023 00:38:26 ", "Title": "Transformers as Recognizers of Formal Languages: A Survey on Expressivity", "Authors": ["Lena Strobl", "William Merrill", "Gail Weiss", "David Chiang and Dana Angluin"], "Categories": "cs.LG cs.CL cs.FL cs.LO"}, "abstract": "As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.", "url": "https://arxiv.org/abs/2311.00208"}, {"metadata": {"arXiv": "2311.00212", "Date": "Wed, 01 Nov 2023 01:19:54 ", "Title": "A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning", "Authors": ["Samuel E. Otto", "Nicholas Zolman", "J. Nathan Kutz", "Steven L. Brunton"], "Categories": "cs.LG cs.NA math.DG math.NA", "MSC-class": "15B30, 22E15, 22E70, 47D03, 54H15, 57S99, 5808, 58D19, 58K70, 65F55, 68Q32, 68T07, 70G65, 70H33, 90C25"}, "abstract": "Symmetry is present throughout nature and continues to play an increasingly central role in physics and machine learning. Fundamental symmetries, such as Poincar\\'{e} invariance, allow physical laws discovered in laboratories on Earth to be extrapolated to the farthest reaches of the universe. Symmetry is essential to achieving this extrapolatory power in machine learning applications. For example, translation invariance in image classification allows models with fewer parameters, such as convolutional neural networks, to be trained on smaller data sets and achieve state-of-the-art performance. In this paper, we provide a unifying theoretical and methodological framework for incorporating symmetry into machine learning models in three ways: 1. enforcing known symmetry when training a model; 2. discovering unknown symmetries of a given model or data set; and 3. promoting symmetry during training by learning a model that breaks symmetries within a user-specified group of candidates when there is sufficient evidence in the data. We show that these tasks can be cast within a common mathematical framework whose central object is the Lie derivative associated with fiber-linear Lie group actions on vector bundles. We extend and unify several existing results by showing that enforcing and discovering symmetry are linear-algebraic tasks that are dual with respect to the bilinear structure of the Lie derivative. We also propose a novel way to promote symmetry by introducing a class of convex regularization functions based on the Lie derivative and nuclear norm relaxation to penalize symmetry breaking during training of machine learning models. We explain how these ideas can be applied to a wide range of machine learning models including basis function regression, dynamical systems discovery, multilayer perceptrons, and neural networks acting on spatial fields such as images.", "url": "https://arxiv.org/abs/2311.00212"}, {"metadata": {"arXiv": "2311.00214", "Date": "Wed, 01 Nov 2023 01:23:59 ", "Title": "WinNet:time series forecasting with a window-enhanced period extracting and interacting", "Authors": ["Wenjie Ou", "Dongyue Guo", "Zheng Zhang", "Zhishuo Zhao", "Yi Lin"], "Categories": "cs.LG"}, "abstract": "Recently, Transformer-based methods have significantly improved state-of-the-art time series forecasting results, but they suffer from high computational costs and the inability to capture the long and short periodicity of time series. We present a highly accurate and simply structured CNN-based model for long-term time series forecasting tasks, called WinNet, including (i) Inter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with long and short periodicity according to the predefined periodic window, (ii) Two-Dimensional Period Decomposition (TDPD) to model period-trend and oscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage the correlations of the period-trend and oscillation terms to support the prediction tasks by CNNs. Results on nine benchmark datasets show that the WinNet can achieve SOTA performance and lower computational complexity over CNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the CNN-based methods in the time series forecasting tasks, with perfect tradeoff between performance and efficiency.", "url": "https://arxiv.org/abs/2311.00214"}, {"metadata": {"arXiv": "2311.00259", "Date": "Wed, 01 Nov 2023 03:15:10 ", "Title": "Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks", "Authors": ["Adrian Celaya", "Keegan Kirk", "David Fuentes", "Beatrice Riviere"], "Categories": "cs.LG cs.CV cs.NA math.NA", "Comments": ["Submitted to CMA", "under review"]}, "abstract": "In recent years, there has been a growing interest in leveraging deep learning and neural networks to address scientific problems, particularly in solving partial differential equations (PDEs). However, current neural network-based PDE solvers often rely on extensive training data or labeled input-output pairs, making them prone to challenges in generalizing to out-of-distribution examples. To mitigate the generalization gap encountered by conventional neural network-based methods in estimating PDE solutions, we formulate a fully unsupervised approach, requiring no training data, to estimate finite difference solutions for PDEs directly via small convolutional neural networks. Our proposed algorithms demonstrate a comparable accuracy to the true solution for several selected elliptic and parabolic problems compared to the finite difference method.", "url": "https://arxiv.org/abs/2311.00259"}, {"metadata": {"arXiv": "2311.00314", "Date": "Wed, 01 Nov 2023 06:00:14 ", "Title": "Federated Topic Model and Model Pruning Based on Variational Autoencoder", "Authors": ["Chengjie Ma", "Yawen Li", "Meiyu Liang", "Ang Li"], "Categories": "cs.LG cs.IR", "Comments": ["8 pages"], "Journal-ref": "In Proceedings of 2023 Chinese Intelligent Automation Conference, 2023: 51-60", "DOI": "10.1007/978-981-99-6187-0_5"}, "abstract": "Topic modeling has emerged as a valuable tool for discovering patterns and topics within large collections of documents. However, when cross-analysis involves multiple parties, data privacy becomes a critical concern. Federated topic modeling has been developed to address this issue, allowing multiple parties to jointly train models while protecting pri-vacy. However, there are communication and performance challenges in the federated sce-nario. In order to solve the above problems, this paper proposes a method to establish a federated topic model while ensuring the privacy of each node, and use neural network model pruning to accelerate the model, where the client periodically sends the model neu-ron cumulative gradients and model weights to the server, and the server prunes the model. To address different requirements, two different methods are proposed to determine the model pruning rate. The first method involves slow pruning throughout the entire model training process, which has limited acceleration effect on the model training process, but can ensure that the pruned model achieves higher accuracy. This can significantly reduce the model inference time during the inference process. The second strategy is to quickly reach the target pruning rate in the early stage of model training in order to accelerate the model training speed, and then continue to train the model with a smaller model size after reaching the target pruning rate. This approach may lose more useful information but can complete the model training faster. Experimental results show that the federated topic model pruning based on the variational autoencoder proposed in this paper can greatly accelerate the model training speed while ensuring the model's performance.", "url": "https://arxiv.org/abs/2311.00314"}, {"metadata": {"arXiv": "2311.00318", "Date": "Wed, 01 Nov 2023 06:02:59 ", "Title": "Flooding Regularization for Stable Training of Generative Adversarial Networks", "Authors": ["Iu Yahiro", "Takashi Ishida", "Naoto Yokoya"], "Categories": "cs.LG cs.CV", "Comments": ["14pages", "9 figures", "9 tables"], "ACM-class": "I.2.10"}, "abstract": "Generative Adversarial Networks (GANs) have shown remarkable performance in image generation. However, GAN training suffers from the problem of instability. One of the main approaches to address this problem is to modify the loss function, often using regularization terms in addition to changing the type of adversarial losses. This paper focuses on directly regularizing the adversarial loss function. We propose a method that applies flooding, an overfitting suppression method in supervised learning, to GANs to directly prevent the discriminator's loss from becoming excessively low. Flooding requires tuning the flood level, but when applied to GANs, we propose that the appropriate range of flood level settings is determined by the adversarial loss function, supported by theoretical analysis of GANs using the binary cross entropy loss. We experimentally verify that flooding stabilizes GAN training and can be combined with other stabilization techniques. We also reveal that by restricting the discriminator's loss to be no greater than flood level, the training proceeds stably even when the flood level is somewhat high.", "url": "https://arxiv.org/abs/2311.00318"}, {"metadata": {"arXiv": "2311.00327", "Date": "Wed, 01 Nov 2023 06:30:45 ", "Title": "Multi-task Representation Learning for Pure Exploration in Bilinear Bandits", "Authors": ["Subhojyoti Mukherjee", "Qiaomin Xie", "Josiah P. Hanna", "Robert Nowak"], "Categories": "cs.LG", "Comments": ["Accepted in 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \\textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that by learning the shared representation across tasks, we achieve significantly improved sample complexity compared to the traditional approach of solving tasks independently.", "url": "https://arxiv.org/abs/2311.00327"}, {"metadata": {"arXiv": "2311.00330", "Date": "Wed, 01 Nov 2023 06:50:00 ", "Title": "Latent Space Inference For Spatial Transcriptomics", "Authors": ["J. Ding", "S.N. Zaman", "P.Y. Chen", "D. Wang"], "Categories": "cs.LG q-bio.QM"}, "abstract": "In order to understand the complexities of cellular biology, researchers are interested in two important metrics: the genetic expression information of cells and their spatial coordinates within a tissue sample. However, state-of-the art methods, namely single-cell RNA sequencing and image based spatial transcriptomics can only recover a subset of this information, either full genetic expression with loss of spatial information, or spatial information with loss of resolution in sequencing data. In this project, we investigate a probabilistic machine learning method to obtain the full genetic expression information for tissues samples while also preserving their spatial coordinates. This is done through mapping both datasets to a joint latent space representation with the use of variational machine learning methods. From here, the full genetic and spatial information can be decoded and to give us greater insights on the understanding of cellular processes and pathways.", "url": "https://arxiv.org/abs/2311.00330"}, {"metadata": {"arXiv": "2311.00368", "Date": "Wed, 01 Nov 2023 08:43:59 ", "Title": "Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel Max Series GPU", "Authors": ["Mohammad Zubair and Christoph Bauinger"], "Categories": "cs.LG cs.MS", "Comments": ["20 pages", "1 Table", "19 Figures", "preprint"], "MSC-class": "68-04 (Primary) 68T07, 68W10 (Secondary)", "ACM-class": "I.2.5; G.4"}, "abstract": "In this paper, we focus on three sparse matrix operations that are relevant for machine learning applications, namely, the sparse-dense matrix multiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM), and the composition of the SDDMM with SPMM, also termed as FusedMM. We develop optimized implementations for SPMM, SDDMM, and FusedMM operations utilizing Intel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or SYCL, the ESIMD API enables the writing of explicitly vectorized kernel code. Sparse matrix algorithms implemented with the ESIMD API achieved performance close to the peak of the targeted Intel Data Center GPU. We compare our performance results to Intel's oneMKL library on Intel GPUs and to a recent CUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and demonstrate that our implementations for sparse matrix operations outperform either.", "url": "https://arxiv.org/abs/2311.00368"}, {"metadata": {"arXiv": "2311.00377", "Date": "Wed, 01 Nov 2023 09:08:35 ", "Title": "Uncertainty quantification and out-of-distribution detection using surjective normalizing flows", "Authors": ["Simon Dirmeier and Ye Hong and Yanan Xin and Fernando Perez-Cruz"], "Categories": "cs.LG stat.AP"}, "abstract": "Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet process mixture model and a bijective flow and find that the surjections are a crucial component to reliably distinguish in-distribution from out-of-distribution data.", "url": "https://arxiv.org/abs/2311.00377"}, {"metadata": {"arXiv": "2311.00416", "Date": "Wed, 01 Nov 2023 10:18:23 ", "Title": "Efficient Human-AI Coordination via Preparatory Language-based Convention", "Authors": ["Cong Guan", "Lichao Zhang", "Chunpeng Fan", "Yichen Li", "Feng Chen", "Lihe Li", "Yunjia Tian", "Lei Yuan", "Yang Yu"], "Categories": "cs.LG cs.CL"}, "abstract": "Developing intelligent agents capable of seamless coordination with humans is a critical step towards achieving artificial general intelligence. Existing methods for human-AI coordination typically train an agent to coordinate with a diverse set of policies or with human models fitted from real human data. However, the massively diverse styles of human behavior present obstacles for AI systems with constrained capacity, while high quality human data may not be readily available in real-world scenarios. In this study, we observe that prior to coordination, humans engage in communication to establish conventions that specify individual roles and actions, making their coordination proceed in an orderly manner. Building upon this observation, we propose employing the large language model (LLM) to develop an action plan (or equivalently, a convention) that effectively guides both human and AI. By inputting task requirements, human preferences, the number of agents, and other pertinent information into the LLM, it can generate a comprehensive convention that facilitates a clear understanding of tasks and responsibilities for all parties involved. Furthermore, we demonstrate that decomposing the convention formulation problem into sub-problems with multiple new sessions being sequentially employed and human feedback, will yield a more efficient coordination convention. Experimental evaluations conducted in the Overcooked-AI environment, utilizing a human proxy model, highlight the superior performance of our proposed method compared to existing learning-based approaches. When coordinating with real humans, our method achieves better alignment with human preferences and an average performance improvement of 15% compared to the state-of-the-art.", "url": "https://arxiv.org/abs/2311.00416"}, {"metadata": {"arXiv": "2311.00428", "Date": "Wed, 01 Nov 2023 10:44:05 ", "Title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks", "Authors": ["Seokil Ham", "Jungwuk Park", "Dong-Jun Han", "Jaekyun Moon"], "Categories": "cs.LG", "Comments": ["10 pages", "4 figures", "accepted by 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significantly improved robustness against adversarial attacks. Experimental results on various datasets/models show that our method achieves the best adversarial accuracy with reduced computation budgets, compared to the baselines relying on existing adversarial training or knowledge distillation techniques for multi-exit networks.", "url": "https://arxiv.org/abs/2311.00428"}, {"metadata": {"arXiv": "2311.00444", "Date": "Wed, 01 Nov 2023 11:12:02 ", "Title": "Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements", "Authors": ["Peter A. Zachares", "Vahan Hovhannisyan", "Alan Mosca", "Yarin Gal"], "Categories": "cs.LG"}, "abstract": "This work focuses on the novel problem setting of generating graphs conditioned on a description of the graph's functional requirements in a downstream task. We pose the problem as a text-to-text generation problem and focus on the approach of fine-tuning a pretrained large language model (LLM) to generate graphs. We propose an inductive bias which incorporates information about the structure of the graph into the LLM's generation process by incorporating message passing layers into an LLM's architecture. To evaluate our proposed method, we design a novel set of experiments using publicly available and widely studied molecule and knowledge graph data sets. Results suggest our proposed approach generates graphs which more closely meet the requested functional requirements, outperforming baselines developed on similar tasks by a statistically significant margin.", "url": "https://arxiv.org/abs/2311.00444"}, {"metadata": {"arXiv": "2311.00452", "Date": "Wed, 01 Nov 2023 11:38:31 ", "Title": "Hessian Eigenvectors and Principal Component Analysis of Neural Network Weight Matrices", "Authors": ["David Haink"], "Categories": "cs.LG", "Comments": ["Master thesis: 60 pages", "35 figures"]}, "abstract": "This study delves into the intricate dynamics of trained deep neural networks and their relationships with network parameters. Trained networks predominantly continue training in a single direction, known as the drift mode. This drift mode can be explained by the quadratic potential model of the loss function, suggesting a slow exponential decay towards the potential minima. We unveil a correlation between Hessian eigenvectors and network weights. This relationship, hinging on the magnitude of eigenvalues, allows us to discern parameter directions within the network. Notably, the significance of these directions relies on two defining attributes: the curvature of their potential wells (indicated by the magnitude of Hessian eigenvalues) and their alignment with the weight vectors. Our exploration extends to the decomposition of weight matrices through singular value decomposition. This approach proves practical in identifying critical directions within the Hessian, considering both their magnitude and curvature. Furthermore, our examination showcases the applicability of principal component analysis in approximating the Hessian, with update parameters emerging as a superior choice over weights for this purpose. Remarkably, our findings unveil a similarity between the largest Hessian eigenvalues of individual layers and the entire network. Notably, higher eigenvalues are concentrated more in deeper layers. Leveraging these insights, we venture into addressing catastrophic forgetting, a challenge of neural networks when learning new tasks while retaining knowledge from previous ones. By applying our discoveries, we formulate an effective strategy to mitigate catastrophic forgetting, offering a possible solution that can be applied to networks of varying scales, including larger architectures.", "url": "https://arxiv.org/abs/2311.00452"}, {"metadata": {"arXiv": "2311.00460", "Date": "Wed, 01 Nov 2023 11:52:41 ", "Title": "Optimal Budgeted Rejection Sampling for Generative Models", "Authors": ["Alexandre Verine and Muni Sreenivas Pydi and Benjamin Negrevergne and Yann Chevaleyre"], "Categories": "cs.LG"}, "abstract": "Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \\textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model's overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.", "url": "https://arxiv.org/abs/2311.00460"}, {"metadata": {"arXiv": "2311.00474", "Date": "Wed, 01 Nov 2023 12:17:05 ", "Title": "Diffusion models for probabilistic programming", "Authors": ["Simon Dirmeier and Fernando Perez-Cruz"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose Diffusion Model Variational Inference (DMVI), a novel method for automated approximate inference in probabilistic programming languages (PPLs). DMVI utilizes diffusion models as variational approximations to the true posterior distribution by deriving a novel bound to the marginal likelihood objective used in Bayesian modelling. DMVI is easy to implement, allows hassle-free inference in PPLs without the drawbacks of, e.g., variational inference using normalizing flows, and does not make any constraints on the underlying neural network model. We evaluate DMVI on a set of common Bayesian models and show that its posterior inferences are in general more accurate than those of contemporary methods used in PPLs while having a similar computational cost and requiring less manual tuning.", "url": "https://arxiv.org/abs/2311.00474"}, {"metadata": {"arXiv": "2311.00481", "Date": "Wed, 01 Nov 2023 12:32:17 ", "Title": "Fixed-Budget Best-Arm Identification in Sparse Linear Bandits", "Authors": ["Recep Can Yavas", "Vincent Y. F. Tan"], "Categories": "cs.LG stat.ML", "Comments": ["28 pages", "Submitted to TMLR"], "ACM-class": "I.2.6"}, "abstract": "We study the best-arm identification problem in sparse linear bandits under the fixed-budget setting. In sparse linear bandits, the unknown feature vector $\\theta^*$ may be of large dimension $d$, but only a few, say $s \\ll d$ of these features have non-zero values. We design a two-phase algorithm, Lasso and Optimal-Design- (Lasso-OD) based linear best-arm identification. The first phase of Lasso-OD leverages the sparsity of the feature vector by applying the thresholded Lasso introduced by Zhou (2009), which estimates the support of $\\theta^*$ correctly with high probability using rewards from the selected arms and a judicious choice of the design matrix. The second phase of Lasso-OD applies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated support. We derive a non-asymptotic upper bound on the error probability of Lasso-OD by carefully choosing hyperparameters (such as Lasso's regularization parameter) and balancing the error probabilities of both phases. For fixed sparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD depends on $s$ but not on the dimension $d$, yielding a significant performance improvement for sparse and high-dimensional linear bandits. Furthermore, we show that Lasso-OD is almost minimax optimal in the exponent. Finally, we provide numerical examples to demonstrate the significant performance improvement over the existing algorithms for non-sparse linear bandits such as OD-LinBAI, BayesGap, Peace, LinearExploration, and GSE.", "url": "https://arxiv.org/abs/2311.00481"}, {"metadata": {"arXiv": "2311.00488", "Date": "Wed, 01 Nov 2023 12:42:14 ", "Title": "Comparing Optimization Targets for Contrast-Consistent Search", "Authors": ["Hugo Fry", "Seamus Fallows", "Ian Fan", "Jamie Wright", "Nandi Schoots"], "Categories": "cs.LG cs.CL", "Comments": ["Socially Responsible Language Modelling Research (SoLaR) NeurIPS 2023"]}, "abstract": "We investigate the optimization target of Contrast-Consistent Search (CCS), which aims to recover the internal representations of truth of a large language model. We present a new loss function that we call the Midpoint-Displacement (MD) loss function. We demonstrate that for a certain hyper-parameter value this MD loss function leads to a prober with very similar weights to CCS. We further show that this hyper-parameter is not optimal and that with a better hyper-parameter the MD loss function attains a higher test accuracy than CCS.", "url": "https://arxiv.org/abs/2311.00488"}, {"metadata": {"arXiv": "2311.00517", "Date": "Wed, 01 Nov 2023 13:41:44 ", "Title": "Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction", "Authors": ["Jonayet Miah", "Duc M Ca", "Md Abu Sayed", "Ehsanur Rashid Lipu", "Fuad Mahmud", "S M Yasir Arafat"], "Categories": "cs.LG cs.CV cs.HC", "Journal-ref": "2023 15th International Conference on Innovations in Information Technology (IIT) - Track 2: Artificial Intelligence in Data Science"}, "abstract": "Cardiovascular disease remains a leading cause of mortality in the contemporary world. Its association with smoking, elevated blood pressure, and cholesterol levels underscores the significance of these risk factors. This study addresses the challenge of predicting myocardial illness, a formidable task in medical research. Accurate predictions are pivotal for refining healthcare strategies. This investigation conducts a comparative analysis of six distinct machine learning models: Logistic Regression, Support Vector Machine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes exhibit promise, with accuracy rates as follows: Logistic Regression (81.00%), Support Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision Tree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the top-performing model. These findings underscore its potential to enhance predictive precision for coronary infarction. As the prevalence of cardiovascular risk factors persists, incorporating advanced machine learning techniques holds the potential to refine proactive medical interventions.", "url": "https://arxiv.org/abs/2311.00517"}, {"metadata": {"arXiv": "2311.00519", "Date": "Wed, 01 Nov 2023 13:44:45 ", "Title": "Retrieval-Based Reconstruction For Time-series Contrastive Learning", "Authors": ["Maxwell A. Xu", "Alexander Moreno", "Hui Wei", "Benjamin M. Marlin", "James M. Rehg"], "Categories": "cs.LG"}, "abstract": "The success of self-supervised contrastive learning hinges on identifying positive data pairs that, when pushed together in embedding space, encode useful information for subsequent downstream tasks. However, in time-series, this is challenging because creating positive pairs via augmentations may break the original semantic meaning. We hypothesize that if we can retrieve information from one subsequence to successfully reconstruct another subsequence, then they should form a positive pair. Harnessing this intuition, we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR) contrastive learning. First, we utilize a convolutional cross-attention architecture to calculate the REBAR error between two different time-series. Then, through validation experiments, we show that the REBAR error is a predictor of mutual class membership, justifying its usage as a positive/negative labeler. Finally, once integrated into a contrastive learning framework, our REBAR method can learn an embedding that achieves state-of-the-art performance on downstream tasks across various modalities.", "url": "https://arxiv.org/abs/2311.00519"}, {"metadata": {"arXiv": "2311.00559", "Date": "Wed, 01 Nov 2023 14:55:54 ", "Title": "Learning to optimize by multi-gradient for multi-objective optimization", "Authors": ["Linxi Yang", "Xinmin Yang", "Liping Tang"], "Categories": "cs.LG"}, "abstract": "The development of artificial intelligence (AI) for science has led to the emergence of learning-based research paradigms, necessitating a compelling reevaluation of the design of multi-objective optimization (MOO) methods. The new generation MOO methods should be rooted in automated learning rather than manual design. In this paper, we introduce a new automatic learning paradigm for optimizing MOO problems, and propose a multi-gradient learning to optimize (ML2O) method, which automatically learns a generator (or mappings) from multiple gradients to update directions. As a learning-based method, ML2O acquires knowledge of local landscapes by leveraging information from the current step and incorporates global experience extracted from historical iteration trajectory data. By introducing a new guarding mechanism, we propose a guarded multi-gradient learning to optimize (GML2O) method, and prove that the iterative sequence generated by GML2O converges to a Pareto critical point. The experimental results demonstrate that our learned optimizer outperforms hand-designed competitors on training multi-task learning (MTL) neural network.", "url": "https://arxiv.org/abs/2311.00559"}, {"metadata": {"arXiv": "2311.00578", "Date": "Wed, 01 Nov 2023 15:19:54 ", "Title": "Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations", "Authors": ["Taniya Kapoor", "Hongrui Wang", "Alfredo Nunez", "Rolf Dollevoet"], "Categories": "cs.LG"}, "abstract": "This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial conditions, including those with noise in the initial data. Furthermore, the potential of the proposed method is demonstrated for the Timoshenko beam in an extended spatial and temporal domain. Several comparisons suggest that the proposed method accurately captures the inherent dynamics, outperforming the state-of-the-art physics-informed methods under standard $L^2$-norm metric and accelerating convergence.", "url": "https://arxiv.org/abs/2311.00578"}, {"metadata": {"arXiv": "2311.00599", "Date": "Wed, 01 Nov 2023 15:47:18 ", "Title": "Structure Learning with Adaptive Random Neighborhood Informed MCMC", "Authors": ["Alberto Caron", "Xitong Liang", "Samuel Livingstone and Jim Griffin"], "Categories": "cs.LG stat.CO"}, "abstract": "In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a fully-Bayesian approach to the problem of structure learning under observational data. Under the assumption of causal sufficiency, the algorithm allows for approximate sampling directly from the posterior distribution on Directed Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs via locally informed, adaptive random neighborhood proposal that results in better mixing properties. In addition, to ensure better scalability with the number of nodes, we couple PARNI-DAG with a pre-tuning procedure of the sampler's parameters that exploits a skeleton graph derived through some constraint-based or scoring-based algorithms. Thanks to these novel features, PARNI-DAG quickly converges to high-probability regions and is less likely to get stuck in local modes in the presence of high correlation between nodes in high-dimensional settings. After introducing the technical novelties in PARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in learning DAG structures on a variety of experiments.", "url": "https://arxiv.org/abs/2311.00599"}, {"metadata": {"arXiv": "2311.00636", "Date": "Wed, 01 Nov 2023 16:37:00 ", "Title": "Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures", "Authors": ["Runa Eschenhagen", "Alexander Immer", "Richard E. Turner", "Frank Schneider", "Philipp Hennig"], "Categories": "cs.LG stat.ML", "Comments": ["NeurIPS 2023"]}, "abstract": "The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\\textit{expand}$ and $\\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75\\%$ of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.", "url": "https://arxiv.org/abs/2311.00636"}, {"metadata": {"arXiv": "2311.00664", "Date": "Wed, 01 Nov 2023 17:12:00 ", "Title": "Latent Space Translation via Semantic Alignment", "Authors": ["Valentino Maiorca", "Luca Moschella", "Antonio Norelli", "Marco Fumero", "Francesco Locatello", "Emanuele Rodol\\`a"], "Categories": "cs.LG", "Comments": ["Accepted at NeurIPS 2023. 21 pages", "13 figures", "8 tables"]}, "abstract": "While different neural models often exhibit latent spaces that are alike when exposed to semantically related data, this intrinsic similarity is not always immediately discernible. Towards a better understanding of this phenomenon, our work shows how representations learned from these neural modules can be translated between different pre-trained networks via simpler transformations than previously thought. An advantage of this approach is the ability to estimate these transformations using standard, well-understood algebraic procedures that have closed-form solutions. Our method directly estimates a transformation between two given latent spaces, thereby enabling effective stitching of encoders and decoders without additional training. We extensively validate the adaptability of this translation procedure in different experimental settings: across various trainings, domains, architectures (e.g., ResNet, CNN, ViT), and in multiple downstream tasks (classification, reconstruction). Notably, we show how it is possible to zero-shot stitch text encoders and vision decoders, or vice-versa, yielding surprisingly good classification performance in this multimodal setting.", "url": "https://arxiv.org/abs/2311.00664"}, {"metadata": {"arXiv": "2311.00696", "Date": "Wed, 01 Nov 2023 17:54:49 ", "Title": "Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA", "Authors": ["Seyed Mohammad Ebrahim Sharifnia", "Faezeh Bagheri", "Rupy Sawhney", "John E. Kobza", "Enrique Macias De Anda", "Mostafa Hajiaghaei-Keshteli", "Michael Mirrielees"], "Categories": "cs.LG", "Comments": ["The document is written in the Elsevier LaTeX format"]}, "abstract": "Population aging is a global challenge, leading to increased demand for healthcare and social services for the elderly. Home Health Care (HHC) emerges as a vital solution, specifically designed to serve this population segment. Given the surging demand for HHC, it's essential to coordinate and regulate caregiver allocation efficiently. This is crucial for both budget-optimized planning and ensuring the delivery of high-quality care. This research addresses a key question faced by home health agencies (HHAs): \"How can caregiver allocation be optimized, especially when caregivers prefer flexibility in their visiting sequences?\". While earlier studies proposed rigid visiting sequences, our study introduces a decision support framework that allocates caregivers through a hybrid method that considers the flexibility in visiting sequences and aims to reduce travel mileage, increase the number of visits per planning period, and maintain the continuity of care - a critical metric for patient satisfaction. Utilizing data from an HHA in Tennessee, United States, our approach led to an impressive reduction in average travel mileage (up to 42% depending on discipline) without imposing restrictions on caregivers. Furthermore, the proposed framework is used for caregivers' supply analysis to provide valuable insights into caregiver resource management.", "url": "https://arxiv.org/abs/2311.00696"}, {"metadata": {"arXiv": "2311.00252", "Date": "Wed, 01 Nov 2023 03:06:14 ", "Title": "Active Neural Topological Mapping for Multi-Agent Exploration", "Authors": ["Xinyi Yang", "Yuxiang Yang", "Chao Yu", "Jiayu Chen", "Jingchen Yu", "Haibing Ren", "Huazhong Yang and Yu Wang"], "Categories": "cs.RO cs.LG cs.MA", "Comments": ["Accepted by Robotics and Automation Letters"]}, "abstract": "This paper investigates the multi-agent cooperative exploration problem, which requires multiple agents to explore an unseen environment via sensory signals in a limited time. A popular approach to exploration tasks is to combine active mapping with planning. Metric maps capture the details of the spatial representation, but are with high communication traffic and may vary significantly between scenarios, resulting in inferior generalization. Topological maps are a promising alternative as they consist only of nodes and edges with abstract but essential information and are less influenced by the scene structures. However, most existing topology-based exploration tasks utilize classical methods for planning, which are time-consuming and sub-optimal due to their handcrafted design. Deep reinforcement learning (DRL) has shown great potential for learning (near) optimal policies through fast end-to-end inference. In this paper, we propose Multi-Agent Neural Topological Mapping (MANTM) to improve exploration efficiency and generalization for multi-agent exploration tasks. MANTM mainly comprises a Topological Mapper and a novel RL-based Hierarchical Topological Planner (HTP). The Topological Mapper employs a visual encoder and distance-based heuristics to construct a graph containing main nodes and their corresponding ghost nodes. The HTP leverages graph neural networks to capture correlations between agents and graph nodes in a coarse-to-fine manner for effective global goal selection. Extensive experiments conducted in a physically-realistic simulator, Habitat, demonstrate that MANTM reduces the steps by at least 26.40% over planning-based baselines and by at least 7.63% over RL-based competitors in unseen scenarios.", "url": "https://arxiv.org/abs/2311.00252"}, {"metadata": {"arXiv": "2311.00203", "Date": "Wed, 01 Nov 2023 00:17:11 ", "Title": "Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities", "Authors": ["Senjuti Dutta (1)", "Sid Mittal (2)", "Sherol Chen (2)", "Deepak Ramachandran (2)", "Ravi Rajakumar (2)", "Ian Kivlichan (2)", "Sunny Mak (2)", "Alena Butryna (2)", "Praveen Paritosh (2) ((1) University of Tennessee", "Knoxville", "(2) Google LLC)"], "Categories": "cs.AI"}, "abstract": "The prevalence and impact of toxic discussions online have made content moderation crucial.Automated systems can play a vital role in identifying toxicity, and reducing the reliance on human moderation.Nevertheless, identifying toxic comments for diverse communities continues to present challenges that are addressed in this paper.The two-part goal of this study is to(1)identify intuitive variances from annotator disagreement using quantitative analysis and (2)model the subjectivity of these viewpoints.To achieve our goal, we published a new dataset\\footnote{\\url{https://github.com/XXX}} with expert annotators' annotations and used two other public datasets to identify the subjectivity of toxicity.Then leveraging the Large Language Model(LLM),we evaluate the model's ability to mimic diverse viewpoints on toxicity by varying size of the training data and utilizing same set of annotators as the test set used during model training and a separate set of annotators as the test set.We conclude that subjectivity is evident across all annotator groups, demonstrating the shortcomings of majority-rule voting. Moving forward, subjective annotations should serve as ground truth labels for training models for domains like toxicity in diverse communities.", "url": "https://arxiv.org/abs/2311.00203"}, {"metadata": {"arXiv": "2311.00217", "Date": "Wed, 01 Nov 2023 01:32:59 ", "Title": "Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias", "Authors": ["S. Lee", "T. Q. Peng", "M. H. Goldberg", "S. A. Rosenthal", "J. E. Kotcher", "E. W. Maibach and A. Leiserowitz"], "Categories": "cs.AI cs.CY", "Comments": ["34 pages", "6 figures", "1 table"]}, "abstract": "Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of meticulous conditioning, model selection, survey question format, and bias assessment when employing LLMs for survey simulation. Further investigation into prompt engineering and algorithm auditing is essential to harness the power of LLMs while addressing their inherent limitations.", "url": "https://arxiv.org/abs/2311.00217"}, {"metadata": {"arXiv": "2311.00344", "Date": "Wed, 01 Nov 2023 07:37:27 ", "Title": "A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents", "Authors": ["Olivier Sigaud", "Gianluca Baldassarre", "Cedric Colas", "Stephane Doncieux", "Richard Duro", "Nicolas Perrin-Gilbert", "Vieri-Giuliano Santucci"], "Categories": "cs.AI"}, "abstract": "A lot of recent machine learning research papers have \"Open-ended learning\" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement learning problems, as this framework facilitates the definition of learning a growing repertoire of skills. Finally, we highlight the work that remains to be performed to fill the gap between our elementary definition and the more involved notions of open-ended learning that developmental AI researchers may have in mind.", "url": "https://arxiv.org/abs/2311.00344"}, {"metadata": {"arXiv": "2311.00356", "Date": "Wed, 01 Nov 2023 08:07:16 ", "Title": "QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning", "Authors": ["Rizhong Wang", "Huiping Li", "Di Cui", "Demin Xu"], "Categories": "cs.AI"}, "abstract": "Centralized training is widely utilized in the field of multi-agent reinforcement learning (MARL) to assure the stability of training process. Once a joint policy is obtained, it is critical to design a value function factorization method to extract optimal decentralized policies for the agents, which needs to satisfy the individual-global-max (IGM) principle. While imposing additional limitations on the IGM function class can help to meet the requirement, it comes at the cost of restricting its application to more complex multi-agent environments. In this paper, we propose QFree, a universal value function factorization method for MARL. We start by developing mathematical equivalent conditions of the IGM principle based on the advantage function, which ensures that the principle holds without any compromise, removing the conservatism of conventional methods. We then establish a more expressive mixing network architecture that can fulfill the equivalent factorization. In particular, the novel loss function is developed by considering the equivalent conditions as regularization term during policy evaluation in the MARL algorithm. Finally, the effectiveness of the proposed method is verified in a nonmonotonic matrix game scenario. Moreover, we show that QFree achieves the state-of-the-art performance in a general-purpose complex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).", "url": "https://arxiv.org/abs/2311.00356"}, {"metadata": {"arXiv": "2311.00393", "Date": "Wed, 01 Nov 2023 09:38:56 ", "Title": "Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education", "Authors": ["Danial Hooshyar", "Roger Azevedo", "Yeongwook Yang"], "Categories": "cs.AI", "MSC-class": "I.2.0, I.2.1, I.2.6"}, "abstract": "Artificial neural networks (ANNs) have shown to be amongst the most important artificial intelligence (AI) techniques in educational applications, providing adaptive educational services. However, their educational potential is limited in practice due to three major challenges: i) difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, and practitioners' knowledge) in their development, ii) learning and reflecting biases, and iii) lack of interpretability. Given the high-risk nature of education, the integration of educational knowledge into ANNs becomes crucial for developing AI applications that adhere to essential educational restrictions, and provide interpretability over the predictions. This research argues that the neural-symbolic family of AI has the potential to address the named challenges. To this end, it adapts a neural-symbolic AI framework and accordingly develops an approach called NSAI, that injects and extracts educational knowledge into and from deep neural networks, for modelling learners computational thinking. Our findings reveal that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data, as well as training data augmented by SMOTE and autoencoder methods. More importantly, unlike the other models, the NSAI approach prioritises robust representations that capture causal relationships between input features and output labels, ensuring safety in learning to avoid spurious correlations and control biases in training data. Furthermore, the NSAI approach enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions, as well as refining the initial educational knowledge. These findings imply that neural-symbolic AI can overcome the limitations of ANNs in education, enabling trustworthy and interpretable applications.", "url": "https://arxiv.org/abs/2311.00393"}, {"metadata": {"arXiv": "2311.00447", "Date": "Wed, 01 Nov 2023 11:16:41 ", "Title": "On the Opportunities of Green Computing: A Survey", "Authors": ["You Zhou", "Xiujing Lin", "Xiang Zhang", "Maolin Wang", "Gangwei Jiang", "Huakang Lu", "Yupeng Wu", "Kai Zhang", "Zhe Yang", "Kehang Wang", "Yongduo Sui", "Fengwei Jia", "Zuoli Tang", "Yao Zhao", "Hongxuan Zhang", "Tiannuo Yang", "Weibo Chen", "Yunong Mao", "Yi Li", "De Bao", "Yu Li", "Hongrui Liao", "Ting Liu", "Jingwen Liu", "Jinchi Guo", "Jin Zhao", "Xiangyu Zhao", "Ying WEI", "Hong Qian", "Qi Liu", "Xiang Wang", "Wai Kin (Victor) Chan", "Chenliang Li", "Yusen Li", "Shiyu Yang", "Jining Yan", "Chao Mou", "Shuai Han", "Wuxia Jin", "Guannan Zhang and Xiaodong Zeng"], "Categories": "cs.AI", "Comments": ["113 pages", "18 figures"]}, "abstract": "Artificial Intelligence (AI) has achieved significant advancements in technology and research with the development over several decades, and is widely used in many areas including computing vision, natural language processing, time-series analysis, speech synthesis, etc. During the age of deep learning, especially with the arise of Large Language Models, a large majority of researchers' attention is paid on pursuing new state-of-the-art (SOTA) results, resulting in ever increasing of model size and computational complexity. The needs for high computing power brings higher carbon emission and undermines research fairness by preventing small or medium-sized research institutions and companies with limited funding in participating in research. To tackle the challenges of computing resources and environmental impact of AI, Green Computing has become a hot research topic. In this survey, we give a systematic overview of the technologies used in Green Computing. We propose the framework of Green Computing and devide it into four key components: (1) Measures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing Systems and (4) AI Use Cases for Sustainability. For each components, we discuss the research progress made and the commonly used techniques to optimize the AI efficiency. We conclude that this new research direction has the potential to address the conflicts between resource constraints and AI development. We encourage more researchers to put attention on this direction and make AI more environmental friendly.", "url": "https://arxiv.org/abs/2311.00447"}, {"metadata": {"arXiv": "2311.00462", "Date": "Wed, 01 Nov 2023 11:56:32 ", "Title": "Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design", "Authors": ["Heng Dong", "Junyu Zhang", "Chongjie Zhang"], "Categories": "cs.AI"}, "abstract": "Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and concentrate on regions demonstrating promise. Finally, the extensive empirical studies on various challenging tasks sourced from EvoGym show our approach's superior efficiency and generalization capability.", "url": "https://arxiv.org/abs/2311.00462"}, {"metadata": {"arXiv": "2311.00530", "Date": "Wed, 01 Nov 2023 14:08:56 ", "Title": "The Development of LLMs for Embodied Navigation", "Authors": ["Jinzhou Lin", "Han Gao", "Rongtao Xu", "Changwei Wang", "Li Guo", "Shibiao Xu"], "Categories": "cs.AI"}, "abstract": "In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidates the role of LLMs in embodied intelligence, based on current research, and forecasts future directions in the field. A comprehensive list of studies in this survey is available at https://github.com/Rongtao-Xu/Awesome-LLM-EN", "url": "https://arxiv.org/abs/2311.00530"}, {"metadata": {"arXiv": "2311.00545", "Date": "Wed, 01 Nov 2023 14:25:51 ", "Title": "Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle", "Authors": ["S\\'ebastien Ferr\\'e"], "Categories": "cs.AI"}, "abstract": "The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark, introduced to foster AI research towards human-level intelligence. It is a collection of unique tasks about generating colored grids, specified by a few examples only. In contrast to the transformation-based programs of existing work, we introduce object-centric models that are in line with the natural programs produced by humans. Our models can not only perform predictions, but also provide joint descriptions for input/output pairs. The Minimum Description Length (MDL) principle is used to efficiently search the large model space. A diverse range of tasks are solved, and the learned models are similar to the natural programs. We demonstrate the generality of our approach by applying it to a different domain.", "url": "https://arxiv.org/abs/2311.00545"}, {"metadata": {"arXiv": "2311.00634", "Date": "Wed, 01 Nov 2023 16:33:37 ", "Title": "A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline", "Authors": ["Rafat Tabassum Sukonna", "Soham Irtiza Swapnil"], "Categories": "cs.AI"}, "abstract": "Due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression model outperformed other machine learning regression models with Mean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and 28.91 for short and long-term accident duration prediction, respectively. Using the optimal classification and regression model identified in the preceding section, we then construct an end-to-end pipeline to incorporate the entire process. The results of both separate and combined approaches were comparable with previous works, which shows the applicability of only using static features for predicting traffic accident duration. The SHAP value analysis identified weather conditions, wind chill and wind speed as the most influential factors in determining the duration of an accident.", "url": "https://arxiv.org/abs/2311.00634"}, {"metadata": {"arXiv": "2311.00693", "Date": "Wed, 01 Nov 2023 17:51:43 ", "Title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval", "Authors": ["Jiayi Chen", "Hanjun Dai", "Bo Dai", "Aidong Zhang", "Wei Wei"], "Categories": "cs.AI", "Comments": ["20 pages", "6 figures; regular long paper", "EMNLP 2023"], "Journal-ref": "Findings of the Association for Computational Linguistics: EMNLP 2023"}, "abstract": "Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn't account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the increased complexity of out-of-distribution (OOD) contents. To tackle this novel task, we present a task-aware meta-learning based framework, with a central focus on achieving effective task personalization that distinguishes between in-task and out-of-task distribution. Specifically, we adopt a hierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to achieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost future research in the field of entity-level few-shot VDER. Experimental results demonstrate our approaches significantly improve the robustness of popular meta-learning baselines.", "url": "https://arxiv.org/abs/2311.00693"}, {"metadata": {"arXiv": "2311.00694", "Date": "Wed, 01 Nov 2023 17:52:15 ", "Title": "Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving", "Authors": ["Zhan Ling", "Yunhao Fang", "Xuanlin Li", "Tongzhou Mu", "Mingu Lee", "Reza Pourreza", "Roland Memisevic", "Hao Su"], "Categories": "cs.AI cs.CL"}, "abstract": "Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems. Current approaches address this challenge by sampling or searching detailed and low-level reasoning chains. However, these methods are still limited in their exploration capabilities, making it challenging for correct solutions to stand out in the huge solution space. In this work, we unleash LLMs' creative potential for exploring multiple diverse problem solving strategies by framing an LLM as a hierarchical policy via in-context learning. This policy comprises of a visionary leader that proposes multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instruction. The follower uses each of the leader's directives as a guide and samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal. Additionally, we propose an effective and efficient tournament-based approach to select among these explored solution groups to reach the final answer. Our approach produces meaningful and inspiring hints, enhances problem-solving strategy exploration, and improves the final answer accuracy on challenging problems in the MATH dataset. Code will be released at https://github.com/lz1oceani/LLM-As-Hierarchical-Policy.", "url": "https://arxiv.org/abs/2311.00694"}, {"metadata": {"arXiv": "2311.00206", "Date": "Wed, 01 Nov 2023 00:26:40 ", "Title": "ChatGPT-Powered Hierarchical Comparisons for Image Classification", "Authors": ["Zhiyuan Ren", "Yiyang Su and Xiaoming Liu"], "Categories": "cs.CV cs.AI", "Comments": ["Neurips 2023 Poster"]}, "abstract": "The zero-shot open-vocabulary challenge in image classification is tackled by pretrained vision-language models like CLIP, which benefit from incorporating class-specific knowledge from large language models (LLMs) like ChatGPT. However, biases in CLIP lead to similar descriptions for distinct but related classes, prompting our novel image classification framework via hierarchical comparisons: using LLMs to recursively group classes into hierarchies and classifying images by comparing image-text embeddings at each hierarchy level, resulting in an intuitive, effective, and explainable approach.", "url": "https://arxiv.org/abs/2311.00206"}, {"metadata": {"arXiv": "2311.00213", "Date": "Wed, 01 Nov 2023 01:20:12 ", "Title": "Consistent Video-to-Video Transfer Using Synthetic Dataset", "Authors": ["Jiaxin Cheng", "Tianjun Xiao and Tong He"], "Categories": "cs.CV cs.AI"}, "abstract": "We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.", "url": "https://arxiv.org/abs/2311.00213"}, {"metadata": {"arXiv": "2311.00278", "Date": "Wed, 01 Nov 2023 04:04:34 ", "Title": "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection", "Authors": ["Min Jae Jung", "Seung Dae Han and Joohee Kim"], "Categories": "cs.CV cs.AI", "Comments": ["19 pages", "11 figures"]}, "abstract": "Few-shot object detection, which focuses on detecting novel objects with few labels, is an emerging challenge in the community. Recent studies show that adapting a pre-trained model or modified loss function can improve performance. In this paper, we explore leveraging the power of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS-COCO and PASCAL VOC show that the proposed RISF substantially outperforms the state-of-the-art approaches. The code will be available.", "url": "https://arxiv.org/abs/2311.00278"}, {"metadata": {"arXiv": "2311.00308", "Date": "Wed, 01 Nov 2023 05:39:41 ", "Title": "From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities", "Authors": ["Md Farhan Ishmam", "Md Sakib Hossain Shovon", "M.F. Mridha", "Nilanjan Dey"], "Categories": "cs.CV cs.AI"}, "abstract": "The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.", "url": "https://arxiv.org/abs/2311.00308"}, {"metadata": {"arXiv": "2311.00358", "Date": "Wed, 01 Nov 2023 08:08:06 ", "Title": "Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples", "Authors": ["Hengkui Dong", "Xianzhong Long", "Yun Li"], "Categories": "cs.CV cs.AI"}, "abstract": "Contrastive learning predicts whether two images belong to the same category by training a model to make their feature representations as close or as far away as possible. In this paper, we rethink how to mine samples in contrastive learning, unlike other methods, our approach is more comprehensive, taking into account both positive and negative samples, and mining potential samples from two aspects: First, for positive samples, we consider both the augmented sample views obtained by data augmentation and the mined sample views through data mining. Then, we weight and combine them using both soft and hard weighting strategies. Second, considering the existence of uninformative negative samples and false negative samples in the negative samples, we analyze the negative samples from the gradient perspective and finally mine negative samples that are neither too hard nor too easy as potential negative samples, i.e., those negative samples that are close to positive samples. The experiments show the obvious advantages of our method compared with some traditional self-supervised methods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on CIFAR10, CIFAR100, and TinyImagenet, respectively.", "url": "https://arxiv.org/abs/2311.00358"}, {"metadata": {"arXiv": "2311.00401", "Date": "Wed, 01 Nov 2023 09:53:38 ", "Title": "A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios", "Authors": ["Wenyang Hu", "Kai Liu", "Libin Liu", "Huiliang Shang"], "Categories": "cs.CV cs.AI"}, "abstract": "Human pose assessment and correction play a crucial role in applications across various fields, including computer vision, robotics, sports analysis, healthcare, and entertainment. In this paper, we propose a Spatial-Temporal Transformer based Framework (STTF) for human pose assessment and correction in education scenarios such as physical exercises and science experiment. The framework comprising skeletal tracking, pose estimation, posture assessment, and posture correction modules to educate students with professional, quick-to-fix feedback. We also create a pose correction method to provide corrective feedback in the form of visual aids. We test the framework with our own dataset. It comprises (a) new recordings of five exercises, (b) existing recordings found on the internet of the same exercises, and (c) corrective feedback on the recordings by professional athletes and teachers. Results show that our model can effectively measure and comment on the quality of students' actions. The STTF leverages the power of transformer models to capture spatial and temporal dependencies in human poses, enabling accurate assessment and effective correction of students' movements.", "url": "https://arxiv.org/abs/2311.00401"}, {"metadata": {"arXiv": "2311.00425", "Date": "Wed, 01 Nov 2023 10:35:47 ", "Title": "Neural Implicit Field Editing Considering Object-environment Interaction", "Authors": ["Zhihong Zeng", "Zongji Wang", "Yuanben Zhang", "Weinan Cai", "Zehao Cao", "Lili Zhang", "Yan Guo", "Yanhong Zhang and Junyi Liu"], "Categories": "cs.CV cs.AI"}, "abstract": "The 3D scene editing method based on neural implicit field has gained wide attention. It has achieved excellent results in 3D editing tasks. However, existing methods often blend the interaction between objects and scene environment. The change of scene appearance like shadows is failed to be displayed in the rendering view. In this paper, we propose an Object and Scene environment Interaction aware (OSI-aware) system, which is a novel two-stream neural rendering system considering object and scene environment interaction. To obtain illuminating conditions from the mixture soup, the system successfully separates the interaction between objects and scene environment by intrinsic decomposition method. To study the corresponding changes to the scene appearance from object-level editing tasks, we introduce a depth map guided scene inpainting method and shadow rendering method by point matching strategy. Extensive experiments demonstrate that our novel pipeline produce reasonable appearance changes in scene editing tasks. It also achieve competitive performance for the rendering quality in novel-view synthesis tasks.", "url": "https://arxiv.org/abs/2311.00425"}, {"metadata": {"arXiv": "2311.00565", "Date": "Wed, 01 Nov 2023 15:07:03 ", "Title": "Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status", "Authors": ["Subhash Nerella", "Ziyuan Guan", "Andrea Davidson", "Yuanfang Ren", "Tezcan Baslanti", "Brooke Armfield", "Patrick Tighe", "Azra Bihorac", "Parisa Rashidi"], "Categories": "cs.CV cs.AI"}, "abstract": "Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signals and Electronic Health Record (EHR) data. In this paper, we examined the association between visual cues and patient condition including acuity status, acute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064 frames collected in the ICU annotated with facial action units (AUs) labels by trained annotators. We developed a new \"masked loss computation\" technique that addresses the data imbalance problem by maximizing data resource utilization. We trained the model using our AU-ICU dataset in conjunction with three external datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57 mean F1-score and 0.89 mean accuracy on the test set. Additionally, we performed AU inference on 634,054 frames to evaluate the association between facial AUs and clinically important patient conditions such as acuity status, acute brain dysfunction, and pain.", "url": "https://arxiv.org/abs/2311.00565"}, {"metadata": {"arXiv": "2311.00571", "Date": "Wed, 01 Nov 2023 15:13:43 ", "Title": "LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing", "Authors": ["Wei-Ge Chen", "Irina Spiridonova", "Jianwei Yang", "Jianfeng Gao", "Chunyuan Li"], "Categories": "cs.CV cs.AI cs.CL cs.HC cs.MM", "Comments": ["31 pages", "22 figures", "30M PDF file size; Project Page: https://llava-vl.github.io/llava-interactive/"]}, "abstract": "LLaVA-Interactive is a research prototype for multimodal human-AI interaction. The system can have multi-turn dialogues with human users by taking multimodal user inputs and generating multimodal responses. Importantly, LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled to align human intents in the interaction. The development of LLaVA-Interactive is extremely cost-efficient as the system combines three multimodal skills of pre-built AI models without additional model training: visual chat of LLaVA, image segmentation from SEEM, as well as image generation and editing from GLIGEN. A diverse set of application scenarios is presented to demonstrate the promises of LLaVA-Interactive and to inspire future research in multimodal interactive systems.", "url": "https://arxiv.org/abs/2311.00571"}, {"metadata": {"arXiv": "2311.00582", "Date": "Wed, 01 Nov 2023 15:27:29 ", "Title": "Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value", "Authors": ["Young Wu", "Jeremy McMahan", "Yiding Chen", "Yudong Chen", "Xiaojin Zhu", "Qiaomin Xie"], "Categories": "cs.GT cs.AI"}, "abstract": "We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.", "url": "https://arxiv.org/abs/2311.00582"}, {"metadata": {"arXiv": "2311.00651", "Date": "Wed, 01 Nov 2023 16:56:44 ", "Title": "Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning", "Authors": ["Richard Bornemann", "Gautier Hamon", "Eleni Nisioti", "Cl\\'ement Moulin-Frier"], "Categories": "cs.MA cs.AI"}, "abstract": "Recent works have proven that intricate cooperative behaviors can emerge in agents trained using meta reinforcement learning on open ended task distributions using self-play. While the results are impressive, we argue that self-play and other centralized training techniques do not accurately reflect how general collective exploration strategies emerge in the natural world: through decentralized training and over an open-ended distribution of tasks. In this work we therefore investigate the emergence of collective exploration strategies, where several agents meta-learn independent recurrent policies on an open ended distribution of tasks. To this end we introduce a novel environment with an open ended procedurally generated task space which dynamically combines multiple subtasks sampled from five diverse task types to form a vast distribution of task trees. We show that decentralized agents trained in our environment exhibit strong generalization abilities when confronted with novel objects at test time. Additionally, despite never being forced to cooperate during training the agents learn collective exploration strategies which allow them to solve novel tasks never encountered during training. We further find that the agents learned collective exploration strategies extend to an open ended task setting, allowing them to solve task trees of twice the depth compared to the ones seen during training. Our open source code as well as videos of the agents can be found on our companion website.", "url": "https://arxiv.org/abs/2311.00651"}, {"metadata": {"arXiv": "2311.00192", "Date": "Tue, 31 Oct 2023 23:42:14 ", "Title": "Large-Scale Multi-Robot Assembly Planning for Autonomous Manufacturing", "Authors": ["Kyle Brown", "Dylan M. Asmar", "Mac Schwager", "and Mykel J. Kochenderfer"], "Categories": "cs.RO cs.AI", "Comments": ["Repository: https://github.com/sisl/ConstructionBots.jl. Under review"]}, "abstract": "Mobile autonomous robots have the potential to revolutionize manufacturing processes. However, employing large robot fleets in manufacturing requires addressing challenges including collision-free movement in a shared workspace, effective multi-robot collaboration to manipulate and transport large payloads, complex task allocation due to coupled manufacturing processes, and spatial planning for parallel assembly and transportation of nested subassemblies. We propose a full algorithmic stack for large-scale multi-robot assembly planning that addresses these challenges and can synthesize construction plans for complex assemblies with thousands of parts in a matter of minutes. Our approach takes in a CAD-like product specification and automatically plans a full-stack assembly procedure for a group of robots to manufacture the product. We propose an algorithmic stack that comprises: (i) an iterative radial layout optimization procedure to define a global staging layout for the manufacturing facility, (ii) a graph-repair mixed-integer program formulation and a modified greedy task allocation algorithm to optimally allocate robots and robot sub-teams to assembly and transport tasks, (iii) a geometric heuristic and a hill-climbing algorithm to plan collaborative carrying configurations of robot sub-teams, and (iv) a distributed control policy that enables robots to execute the assembly motion plan collision-free. We also present an open-source multi-robot manufacturing simulator implemented in Julia as a resource to the research community, to test our algorithms and to facilitate multi-robot manufacturing research more broadly. Our empirical results demonstrate the scalability and effectiveness of our approach by generating plans to manufacture a LEGO model of a Saturn V launch vehicle with 1845 parts, 306 subassemblies, and 250 robots in under three minutes on a standard laptop computer.", "url": "https://arxiv.org/abs/2311.00192"}, {"metadata": {"arXiv": "2311.00047", "Date": "Tue, 31 Oct 2023 18:01:11 ", "Title": "Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?", "Authors": ["Yichi Zhang", "Jiayi Pan", "Yuchen Zhou", "Rui Pan", "Joyce Chai"], "Categories": "cs.AI cs.CL cs.CV cs.LG", "Comments": ["Accepted at EMNLP 2023 main conference"]}, "abstract": "Vision-Language Models (VLMs) are trained on vast amounts of data captured by humans emulating our understanding of the world. However, known as visual illusions, human's perception of reality isn't always faithful to the physical world. This raises a key question: do VLMs have the similar kind of illusions as humans do, or do they faithfully learn to represent reality? To investigate this question, we build a dataset containing five types of visual illusions and formulate four tasks to examine visual illusions in state-of-the-art VLMs. Our findings have shown that although the overall alignment is low, larger models are closer to human perception and more susceptible to visual illusions. Our dataset and initial findings will promote a better understanding of visual illusions in humans and machines and provide a stepping stone for future computational models that can better align humans and machines in perceiving and communicating about the shared visual world. The code and data are available at https://github.com/vl-illusion/dataset.", "url": "https://arxiv.org/abs/2311.00047"}, {"metadata": {"arXiv": "2311.00059", "Date": "Tue, 31 Oct 2023 18:07:07 ", "Title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"", "Authors": ["Peter West", "Ximing Lu", "Nouha Dziri", "Faeze Brahman", "Linjie Li", "Jena D. Hwang", "Liwei Jiang", "Jillian Fisher", "Abhilasha Ravichander", "Khyathi Chandu", "Benjamin Newman", "Pang Wei Koh", "Allyson Ettinger", "Yejin Choi"], "Categories": "cs.AI cs.CL cs.CV cs.LG"}, "abstract": "The recent wave of generative AI has sparked unprecedented global attention, with both excitement and concern over potentially superhuman levels of artificial intelligence: models now take only seconds to produce outputs that would challenge or exceed the capabilities even of expert humans. At the same time, models still show basic errors in understanding that would not be expected even in non-expert humans. This presents us with an apparent paradox: how do we reconcile seemingly superhuman capabilities with the persistence of errors that few humans would make? In this work, we posit that this tension reflects a divergence in the configuration of intelligence in today's generative models relative to intelligence in humans. Specifically, we propose and test the Generative AI Paradox hypothesis: generative models, having been trained directly to reproduce expert-like outputs, acquire generative capabilities that are not contingent upon -- and can therefore exceed -- their ability to understand those same types of outputs. This contrasts with humans, for whom basic understanding almost always precedes the ability to generate expert-level outputs. We test this hypothesis through controlled experiments analyzing generation vs. understanding in generative models, across both language and image modalities. Our results show that although models can outperform humans in generation, they consistently fall short of human capabilities in measures of understanding, as well as weaker correlation between generation and understanding performance, and more brittleness to adversarial inputs. Our findings support the hypothesis that models' generative capability may not be contingent upon understanding capability, and call for caution in interpreting artificial intelligence by analogy to human intelligence.", "url": "https://arxiv.org/abs/2311.00059"}, {"metadata": {"arXiv": "2311.00687", "Date": "Wed, 01 Nov 2023 17:44:50 ", "Title": "Improving Interpersonal Communication by Simulating Audiences with Language Models", "Authors": ["Ryan Liu and Howard Yen and Raja Marjieh and Thomas L. Griffiths and Ranjay Krishna"], "Categories": "cs.AI cs.CL cs.HC cs.LG", "Comments": ["16 pages (main paper)", "7 tables and figures (main)"]}, "abstract": "How do we communicate with others to achieve our goals? We use our prior experience or advice from others, or construct a candidate utterance by predicting how it will be received. However, our experiences are limited and biased, and reasoning about potential outcomes can be difficult and cognitively challenging. In this paper, we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better. We propose the Explore-Generate-Simulate (EGS) framework, which takes as input any scenario where an individual is communicating to an audience with a goal they want to achieve. EGS (1) explores the solution space by producing a diverse set of advice relevant to the scenario, (2) generates communication candidates conditioned on subsets of the advice, and (3) simulates the reactions from various audiences to determine both the best candidate and advice to use. We evaluate the framework on eight scenarios spanning the ten fundamental processes of interpersonal communication. For each scenario, we collect a dataset of human evaluations across candidates and baselines, and showcase that our framework's chosen candidate is preferred over popular generation mechanisms including Chain-of-Thought. We also find that audience simulations achieve reasonably high agreement with human raters across 5 of the 8 scenarios. Finally, we demonstrate the generality of our framework by applying it to real-world scenarios described by users on web forums. Through evaluations and demonstrations, we show that EGS enhances the effectiveness and outcomes of goal-oriented communication across a variety of situations, thus opening up new possibilities for the application of large language models in revolutionizing communication and decision-making processes.", "url": "https://arxiv.org/abs/2311.00687"}, {"metadata": {"arXiv": "2311.00048", "Date": "Tue, 31 Oct 2023 18:01:41 ", "Title": "SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification", "Authors": ["Peijie Qiu", "Pan Xiao", "Wenhui Zhu", "Yalin Wang", "Aristeidis Sotiras"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Multiple Instance Learning (MIL) has been widely used in weakly supervised whole slide image (WSI) classification. Typical MIL methods include a feature embedding part that embeds the instances into features via a pre-trained feature extractor and the MIL aggregator that combines instance embeddings into predictions. The current focus has been directed toward improving these parts by refining the feature embeddings through self-supervised pre-training and modeling the correlations between instances separately. In this paper, we proposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the same time by leveraging sparse dictionary learning. The sparse dictionary learning captures the similarities of instances by expressing them as a sparse linear combination of atoms in an over-complete dictionary. In addition, imposing sparsity help enhance the instance feature embeddings by suppressing irrelevant instances while retaining the most relevant ones. To make the conventional sparse coding algorithm compatible with deep learning, we unrolled it into an SC module by leveraging deep unrolling. The proposed SC module can be incorporated into any existing MIL framework in a plug-and-play manner with an acceptable computation cost. The experimental results on multiple datasets demonstrated that the proposed SC module could substantially boost the performance of state-of-the-art MIL methods. The codes are available at \\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.", "url": "https://arxiv.org/abs/2311.00048"}, {"metadata": {"arXiv": "2311.00056", "Date": "Tue, 31 Oct 2023 18:05:15 ", "Title": "Diversity and Diffusion: Observations on Synthetic Image Distributions with Stable Diffusion", "Authors": ["David Marwood", "Shumeet Baluja", "Yair Alon"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Recent progress in text-to-image (TTI) systems, such as StableDiffusion, Imagen, and DALL-E 2, have made it possible to create realistic images with simple text prompts. It is tempting to use these systems to eliminate the manual task of obtaining natural images for training a new machine learning classifier. However, in all of the experiments performed to date, classifiers trained solely with synthetic images perform poorly at inference, despite the images used for training appearing realistic. Examining this apparent incongruity in detail gives insight into the limitations of the underlying image generation processes. Through the lens of diversity in image creation vs.accuracy of what is created, we dissect the differences in semantic mismatches in what is modeled in synthetic vs. natural images. This will elucidate the roles of the image-languag emodel, CLIP, and the image generation model, diffusion. We find four issues that limit the usefulness of TTI systems for this task: ambiguity, adherence to prompt, lack of diversity, and inability to represent the underlying concept. We further present surprising insights into the geometry of CLIP embeddings.", "url": "https://arxiv.org/abs/2311.00056"}, {"metadata": {"arXiv": "2311.00441", "Date": "Wed, 01 Nov 2023 11:10:01 ", "Title": "Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation", "Authors": ["Shashank Kotyan and Danilo Vasconcellos Vargas"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted in Neurocomputing"]}, "abstract": "Vision Transformer (ViT) has demonstrated promising performance in computer vision tasks, comparable to state-of-the-art neural networks. Yet, this new type of deep neural network architecture is vulnerable to adversarial attacks limiting its capabilities in terms of robustness. This article presents a novel contribution aimed at further improving the accuracy and robustness of ViT, particularly in the face of adversarial attacks. We propose an augmentation technique called `Dynamic Scanning Augmentation' that leverages dynamic input sequences to adaptively focus on different patches, thereby maintaining performance and robustness. Our detailed investigations reveal that this adaptability to the input sequence induces significant changes in the attention mechanism of ViT, even for the same image. We introduce four variations of Dynamic Scanning Augmentation, outperforming ViT in terms of both robustness to adversarial attacks and accuracy against natural images, with one variant showing comparable results. By integrating our augmentation technique, we observe a substantial increase in ViT's robustness, improving it from $17\\%$ to $92\\%$ measured across different types of adversarial attacks. These findings, together with other comprehensive tests, indicate that Dynamic Scanning Augmentation enhances accuracy and robustness by promoting a more adaptive type of attention. In conclusion, this work contributes to the ongoing research on Vision Transformers by introducing Dynamic Scanning Augmentation as a technique for improving the accuracy and robustness of ViT. The observed results highlight the potential of this approach in advancing computer vision tasks and merit further exploration in future studies.", "url": "https://arxiv.org/abs/2311.00441"}, {"metadata": {"arXiv": "2311.00469", "Date": "Wed, 01 Nov 2023 12:10:55 ", "Title": "Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos", "Authors": ["Divyanshu Mishra", "He Zhao", "Pramit Saha", "Aris T. Papageorghiou", "J.Alison Noble"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Published in MICCAI 2023"]}, "abstract": "Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.", "url": "https://arxiv.org/abs/2311.00469"}, {"metadata": {"arXiv": "2311.00094", "Date": "Tue, 31 Oct 2023 19:16:07 ", "Title": "Expressive Modeling Is Insufficient for Offline RL: A Tractable Inference Perspective", "Authors": ["Xuejie Liu", "Anji Liu", "Guy Van den Broeck and Yitao Liang"], "Categories": "cs.LG cs.AI"}, "abstract": "A popular paradigm for offline Reinforcement Learning (RL) tasks is to first fit the offline trajectories to a sequence model, and then prompt the model for actions that lead to high expected return. While a common consensus is that more expressive sequence models imply better performance, this paper highlights that tractability, the ability to exactly and efficiently answer various probabilistic queries, plays an equally important role. Specifically, due to the fundamental stochasticity from the offline data-collection policies and the environment dynamics, highly non-trivial conditional/constrained generation is required to elicit rewarding actions. While it is still possible to approximate such queries, we observe that such crude estimates significantly undermine the benefits brought by expressive sequence models. To overcome this problem, this paper proposes Trifle (Tractable Inference for Offline RL), which leverages modern Tractable Probabilistic Models (TPMs) to bridge the gap between good sequence models and high expected returns at evaluation time. Empirically, Trifle achieves the most state-of-the-art scores in 9 Gym-MuJoCo benchmarks against strong baselines. Further, owing to its tractability, Trifle significantly outperforms prior approaches in stochastic environments and safe RL tasks (e.g. with action constraints) with minimum algorithmic modifications.", "url": "https://arxiv.org/abs/2311.00094"}, {"metadata": {"arXiv": "2311.00096", "Date": "Tue, 31 Oct 2023 19:19:01 ", "Title": "Bandit-Driven Batch Selection for Robust Learning under Label Noise", "Authors": ["Michal Lisicki", "Mihai Nica", "Graham W. Taylor"], "Categories": "cs.LG cs.AI", "Comments": ["WANT@NeurIPS 2023 & OPT@NeurIPS 2023"]}, "abstract": "We introduce a novel approach for batch selection in Stochastic Gradient Descent (SGD) training, leveraging combinatorial bandit algorithms. Our methodology focuses on optimizing the learning process in the presence of label noise, a prevalent issue in real-world datasets. Experimental evaluations on the CIFAR-10 dataset reveal that our approach consistently outperforms existing methods across various levels of label corruption. Importantly, we achieve this superior performance without incurring the computational overhead commonly associated with auxiliary neural network models. This work presents a balanced trade-off between computational efficiency and model efficacy, offering a scalable solution for complex machine learning applications.", "url": "https://arxiv.org/abs/2311.00096"}, {"metadata": {"arXiv": "2311.00143", "Date": "Tue, 31 Oct 2023 20:31:41 ", "Title": "Two-Stage Classifier for Campaign Negativity Detection using Axis Embeddings: A Case Study on Tweets of Political Users during 2021 Presidential Election in Iran", "Authors": ["Fatemeh Rajabi and Ali Mohades"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "In elections around the world, the candidates may turn their campaigns toward negativity due to the prospect of failure and time pressure. In the digital age, social media platforms such as Twitter are rich sources of political discourse. Therefore, despite the large amount of data that is published on Twitter, the automatic system for campaign negativity detection can play an essential role in understanding the strategy of candidates and parties in their campaigns. In this paper, we propose a hybrid model for detecting campaign negativity consisting of a two-stage classifier that combines the strengths of two machine learning models. Here, we have collected Persian tweets from 50 political users, including candidates and government officials. Then we annotated 5,100 of them that were published during the year before the 2021 presidential election in Iran. In the proposed model, first, the required datasets of two classifiers based on the cosine similarity of tweet embeddings with axis embeddings (which are the average of embedding in positive and negative classes of tweets) from the training set (85\\%) are made, and then these datasets are considered the training set of the two classifiers in the hybrid model. Finally, our best model (RF-RF) was able to achieve 79\\% for the macro F1 score and 82\\% for the weighted F1 score. By running the best model on the rest of the tweets of 50 political users that were published one year before the election and with the help of statistical models, we find that the publication of a tweet by a candidate has nothing to do with the negativity of that tweet, and the presence of the names of political persons and political organizations in the tweet is directly related to its negativity.", "url": "https://arxiv.org/abs/2311.00143"}, {"metadata": {"arXiv": "2311.00157", "Date": "Tue, 31 Oct 2023 21:18:44 ", "Title": "Score Normalization for a Faster Diffusion Exponential Integrator Sampler", "Authors": ["Guoxuan Xia", "Duolikun Danier", "Ayan Das", "Stathi Fotiadis", "Farhang Nabiei", "Ushnish Sengupta", "Alberto Bernacchia"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Recently, zhang et al have proposed the Diffusion Exponential Integrator Sampler (DEIS) for fast generation of samples from Diffusion Models. It leverages the semi-linear nature of the probability flow ordinary differential equation (ODE) in order to greatly reduce integration error and improve generation quality at low numbers of function evaluations (NFEs). Key to this approach is the score function reparameterisation, which reduces the integration error incurred from using a fixed score function estimate over each integration step. The original authors use the default parameterisation used by models trained for noise prediction -- multiply the score by the standard deviation of the conditional forward noising distribution. We find that although the mean absolute value of this score parameterisation is close to constant for a large portion of the reverse sampling process, it changes rapidly at the end of sampling. As a simple fix, we propose to instead reparameterise the score (at inference) by dividing it by the average absolute value of previous score estimates at that time step collected from offline high NFE generations. We find that our score normalisation (DEIS-SN) consistently improves FID compared to vanilla DEIS, showing an FID improvement from 6.44 to 5.57 at 10 NFEs for our CIFAR-10 experiments. Our code is available at https://github.com/mtkresearch/Diffusion-DEIS-SN.", "url": "https://arxiv.org/abs/2311.00157"}, {"metadata": {"arXiv": "2311.00201", "Date": "Wed, 01 Nov 2023 00:15:18 ", "Title": "Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning", "Authors": ["Tong Yang", "Shicong Cen", "Yuting Wei", "Yuxin Chen", "Yuejie Chi"], "Categories": "cs.LG cs.AI"}, "abstract": "Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon tabular Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods under softmax parameterization, where gradient tracking is applied to the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, which are nearly independent of the size of the state-action space and illuminate the impacts of network size and connectivity. To the best of our knowledge, this is the first time that global convergence is established for federated multi-task RL using policy optimization. Moreover, the convergence behavior of the proposed algorithms is robust against inexactness of policy evaluation.", "url": "https://arxiv.org/abs/2311.00201"}, {"metadata": {"arXiv": "2311.00227", "Date": "Wed, 01 Nov 2023 02:17:01 ", "Title": "StableFDG: Style and Attention Based Learning for Federated Domain Generalization", "Authors": ["Jungwuk Park", "Dong-Jun Han", "Jinho Kim", "Shiqiang Wang", "Christopher G. Brinton", "Jaekyun Moon"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at NeurIPS 2023", "19 pages"]}, "abstract": "Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a style and attention based learning strategy for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in the same class, and emphasizes the important/common characteristics to better learn the domain-invariant characteristics of each class in data-poor FL scenarios. Experimental results show that StableFDG outperforms existing baselines on various DG benchmark datasets, demonstrating its efficacy.", "url": "https://arxiv.org/abs/2311.00227"}, {"metadata": {"arXiv": "2311.00267", "Date": "Wed, 01 Nov 2023 03:32:13 ", "Title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning", "Authors": ["Yi Ma", "Chenjun Xiao", "Hebin Liang", "Jianye Hao"], "Categories": "cs.LG cs.AI"}, "abstract": "Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offline RL algorithms. Our empirical results clearly show that the proposed algorithms significantly surpass DT on several control and navigation benchmarks. We hope our contributions can inspire the integration of transformer architectures within the field of RL.", "url": "https://arxiv.org/abs/2311.00267"}, {"metadata": {"arXiv": "2311.00322", "Date": "Wed, 01 Nov 2023 06:12:34 ", "Title": "Robust Graph Clustering via Meta Weighting for Noisy Graphs", "Authors": ["Hyeonsoo Jo", "Fanchen Bu", "Kijung Shin"], "Categories": "cs.LG cs.AI", "Comments": ["CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management"]}, "abstract": "How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC.", "url": "https://arxiv.org/abs/2311.00322"}, {"metadata": {"arXiv": "2311.00334", "Date": "Wed, 01 Nov 2023 07:01:19 ", "Title": "MetisFL: An Embarrassingly Parallelized Controller for Scalable & Efficient Federated Learning Workflows", "Authors": ["Dimitris Stripelis", "Chrysovalantis Anastasiou", "Patrick Toral", "Armaghan Asghar", "Jose Luis Ambite"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["15 pages", "11 figures", "Accepted at DistributedML '23"], "DOI": "10.1145/3630048.3630186"}, "abstract": "A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners and the learners for training and evaluating federated models over their private datasets. While executing an FL workflow, the FL system has no control over the computational resources or data of the participating learners. Still, it is responsible for other operations, such as model aggregation, task dispatching, and scheduling. These computationally heavy operations generally need to be handled by the federation controller. Even though many FL systems have been recently proposed to facilitate the development of FL workflows, most of these systems overlook the scalability of the controller. To meet this need, we designed and developed a novel FL system called MetisFL, where the federation controller is the first-class citizen. MetisFL re-engineers all the operations conducted by the federation controller to accelerate the training of large-scale FL workflows. By quantitatively comparing MetisFL against other state-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a 10-fold wall-clock time execution boost across a wide range of challenging FL workflows with increasing model sizes and federation sites.", "url": "https://arxiv.org/abs/2311.00334"}, {"metadata": {"arXiv": "2311.00426", "Date": "Wed, 01 Nov 2023 10:40:46 ", "Title": "Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards", "Authors": ["Alain Andres", "Daochen Zha and Javier Del Ser"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "5 figures"]}, "abstract": "Exploration poses a fundamental challenge in Reinforcement Learning (RL) with sparse rewards, limiting an agent's ability to learn optimal decision-making due to a lack of informative feedback signals. Self-Imitation Learning (self-IL) has emerged as a promising approach for exploration, leveraging a replay buffer to store and reproduce successful behaviors. However, traditional self-IL methods, which rely on high-return transitions and assume singleton environments, face challenges in generalization, especially in procedurally-generated (PCG) environments. Therefore, new self-IL methods have been proposed to rank which experiences to persist, but they replay transitions uniformly regardless of their significance, and do not address the diversity of the stored demonstrations. In this work, we propose tailored self-IL sampling strategies by prioritizing transitions in different ways and extending prioritization techniques to PCG environments. We also address diversity loss through modifications to counteract the impact of generalization requirements and bias introduced by prioritization techniques. Our experimental analysis, conducted over three PCG sparse reward environments, including MiniGrid and ProcGen, highlights the benefits of our proposed modifications, achieving a new state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.", "url": "https://arxiv.org/abs/2311.00426"}, {"metadata": {"arXiv": "2311.00500", "Date": "Wed, 01 Nov 2023 13:00:46 ", "Title": "Intriguing Properties of Data Attribution on Diffusion Models", "Authors": ["Xiaosen Zheng", "Tianyu Pang", "Chao Du", "Jing Jiang", "Min Lin"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a significantly more efficient approach for attributing diffusion models, while the unexpected findings suggest that at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance. The code is available at https://github.com/sail-sg/D-TRAK.", "url": "https://arxiv.org/abs/2311.00500"}, {"metadata": {"arXiv": "2311.00502", "Date": "Wed, 01 Nov 2023 13:08:50 ", "Title": "Efficient LLM Inference on CPUs", "Authors": ["Haihao Shen", "Hanwen Chang", "Bo Dong", "Yu Luo", "and Hengyu Meng"], "Categories": "cs.LG cs.AI cs.CL", "Comments": ["NeurIPS'2023 on Efficient Natural Language and Speech Processing"]}, "abstract": "Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks. However, deploying these models has been challenging due to the astronomical amount of model parameters, which requires a demand for large memory capacity and high memory bandwidth. In this paper, we propose an effective approach that can make the deployment of LLMs more efficiently. We support an automatic INT4 weight-only quantization flow and design a special LLM runtime with highly-optimized kernels to accelerate the LLM inference on CPUs. We demonstrate the general applicability of our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase the extreme inference efficiency on CPUs. The code is publicly available at: https://github.com/intel/intel-extension-for-transformers.", "url": "https://arxiv.org/abs/2311.00502"}, {"metadata": {"arXiv": "2311.00523", "Date": "Wed, 01 Nov 2023 13:50:47 ", "Title": "Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning", "Authors": ["E. Panagiotou", "E. Ntoutsi"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at the ECML PKDD 2023 Workshop: Explainable Artificial Intelligence From Static to Dynamic"]}, "abstract": "In the field of explainable Artificial Intelligence (XAI), sequential counterfactual (SCF) examples are often used to alter the decision of a trained classifier by implementing a sequence of modifications to the input instance. Although certain test-time algorithms aim to optimize for each new instance individually, recently Reinforcement Learning (RL) methods have been proposed that seek to learn policies for discovering SCFs, thereby enhancing scalability. As is typical in RL, the formulation of the RL problem, including the specification of state space, actions, and rewards, can often be ambiguous. In this work, we identify shortcomings in existing methods that can result in policies with undesired properties, such as a bias towards specific actions. We propose to use the output probabilities of the classifier to create a more informative reward, to mitigate this effect.", "url": "https://arxiv.org/abs/2311.00523"}, {"metadata": {"arXiv": "2311.00591", "Date": "Wed, 01 Nov 2023 15:35:51 ", "Title": "Coop: Memory is not a Commodity", "Authors": ["Jianhao Zhang", "Shihan Ma", "Peihong Liu", "Jinhui Yuan"], "Categories": "cs.LG cs.AI cs.SE", "Comments": ["NeurIPS 2023 spotlight"]}, "abstract": "Tensor rematerialization allows the training of deep neural networks (DNNs) under limited memory budgets by checkpointing the models and recomputing the evicted tensors as needed. However, the existing tensor rematerialization techniques overlook the memory system in deep learning frameworks and implicitly assume that free memory blocks at different addresses are identical. Under this flawed assumption, discontiguous tensors are evicted, among which some are not used to allocate the new tensor. This leads to severe memory fragmentation and increases the cost of potential rematerializations. To address this issue, we propose to evict tensors within a sliding window to ensure all evictions are contiguous and are immediately used. Furthermore, we proposed cheap tensor partitioning and recomputable in-place to further reduce the rematerialization cost by optimizing the tensor allocation. We named our method Coop as it is a co-optimization of tensor allocation and tensor rematerialization. We evaluated Coop on eight representative DNNs. The experimental results demonstrate that Coop achieves up to $2\\times$ memory saving and hugely reduces compute overhead, search latency, and memory fragmentation compared to the state-of-the-art baselines.", "url": "https://arxiv.org/abs/2311.00591"}, {"metadata": {"arXiv": "2311.00594", "Date": "Wed, 01 Nov 2023 15:38:51 ", "Title": "Rethinking Variational Inference for Probabilistic Programs with Stochastic Support", "Authors": ["Tim Reichelt", "Luke Ong", "Tom Rainforth"], "Categories": "cs.LG cs.AI cs.PL", "Comments": ["Accepted to NeurIPS 2022"]}, "abstract": "We introduce Support Decomposition Variational Inference (SDVI), a new variational inference (VI) approach for probabilistic programs with stochastic support. Existing approaches to this problem rely on designing a single global variational guide on a variable-by-variable basis, while maintaining the stochastic control flow of the original program. SDVI instead breaks the program down into sub-programs with static support, before automatically building separate sub-guides for each. This decomposition significantly aids in the construction of suitable variational families, enabling, in turn, substantial improvements in inference performance.", "url": "https://arxiv.org/abs/2311.00594"}, {"metadata": {"arXiv": "2311.00619", "Date": "Wed, 01 Nov 2023 16:14:34 ", "Title": "Loss Modeling for Multi-Annotator Datasets", "Authors": ["Uthman Jinadu", "Jesse Annan", "Shanshan Wen", "Yi Ding"], "Categories": "cs.LG cs.AI cs.HC"}, "abstract": "Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.", "url": "https://arxiv.org/abs/2311.00619"}, {"metadata": {"arXiv": "2311.00638", "Date": "Wed, 01 Nov 2023 16:38:27 ", "Title": "FAIRLABEL: Correcting Bias in Labels", "Authors": ["Srinivasan H Sengamedu", "Hien Pham"], "Categories": "cs.LG cs.AI", "Comments": ["ICDM LegalAI Workshop 2023"], "MSC-class": "68T07", "ACM-class": "I.2.6", "Journal-ref": "ICDM 2023 Workshop"}, "abstract": "There are several algorithms for measuring fairness of ML models. A fundamental assumption in these approaches is that the ground truth is fair or unbiased. In real-world datasets, however, the ground truth often contains data that is a result of historical and societal biases and discrimination. Models trained on these datasets will inherit and propagate the biases to the model outputs. We propose FAIRLABEL, an algorithm which detects and corrects biases in labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across groups while maintaining high accuracy in predictions. We propose metrics to measure the quality of bias correction and validate FAIRLABEL on synthetic datasets and show that the label correction is correct 86.7% of the time vs. 71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such as UCI Adult, German Credit Risk, and Compas datasets and show that the Disparate Impact Ratio increases by as much as 54.2%.", "url": "https://arxiv.org/abs/2311.00638"}, {"metadata": {"arXiv": "2311.00063", "Date": "Tue, 31 Oct 2023 18:09:26 ", "Title": "Safe multi-agent motion planning under uncertainty for drones using filtered reinforcement learning", "Authors": ["Sleiman Safaoui", "Abraham P. Vinod", "Ankush Chakrabarty", "Rien Quirynen", "Nobuyuki Yoshikawa and Stefano Di Cairano"], "Categories": "cs.RO cs.AI cs.LG cs.MA cs.SY eess.SY"}, "abstract": "We consider the problem of safe multi-agent motion planning for drones in uncertain, cluttered workspaces. For this problem, we present a tractable motion planner that builds upon the strengths of reinforcement learning and constrained-control-based trajectory planning. First, we use single-agent reinforcement learning to learn motion plans from data that reach the target but may not be collision-free. Next, we use a convex optimization, chance constraints, and set-based methods for constrained control to ensure safety, despite the uncertainty in the workspace, agent motion, and sensing. The proposed approach can handle state and control constraints on the agents, and enforce collision avoidance among themselves and with static obstacles in the workspace with high probability. The proposed approach yields a safe, real-time implementable, multi-agent motion planner that is simpler to train than methods based solely on learning. Numerical simulations and experiments show the efficacy of the approach.", "url": "https://arxiv.org/abs/2311.00063"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

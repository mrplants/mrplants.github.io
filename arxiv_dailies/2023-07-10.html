<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2307.03494", "Date": "Fri, 07 Jul 2023 10:08:29 ", "Title": "HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution", "Authors": ["Jia-Qi Zhang", "Hao-Bin Duan", "Jun-Long Chen", "Ariel Shamir and Miao Wang"], "Categories": "cs.CV cs.LG"}, "abstract": "The task of lane detection has garnered considerable attention in the field of autonomous driving due to its complexity. Lanes can present difficulties for detection, as they can be narrow, fragmented, and often obscured by heavy traffic. However, it has been observed that the lanes have a geometrical structure that resembles a straight line, leading to improved lane detection results when utilizing this characteristic. To address this challenge, we propose a hierarchical Deep Hough Transform (DHT) approach that combines all lane features in an image into the Hough parameter space. Additionally, we refine the point selection method and incorporate a Dynamic Convolution Module to effectively differentiate between lanes in the original image. Our network architecture comprises a backbone network, either a ResNet or Pyramid Vision Transformer, a Feature Pyramid Network as the neck to extract multi-scale features, and a hierarchical DHT-based feature aggregation head to accurately segment each lane. By utilizing the lane features in the Hough parameter space, the network learns dynamic convolution kernel parameters corresponding to each lane, allowing the Dynamic Convolution Module to effectively differentiate between lane features. Subsequently, the lane features are fed into the feature decoder, which predicts the final position of the lane. Our proposed network structure demonstrates improved performance in detecting heavily occluded or worn lane images, as evidenced by our extensive experimental results, which show that our method outperforms or is on par with state-of-the-art techniques.", "url": "https://arxiv.org/abs/2307.03494"}, {"metadata": {"arXiv": "2307.03704", "Date": "Fri, 07 Jul 2023 16:30:18 ", "Title": "Equivariant Single View Pose Prediction Via Induced and Restricted Representations", "Authors": ["Owen Howell", "David Klee", "Ondrej Biza", "Linfeng Zhao", "and Robin Walters"], "Categories": "cs.CV cs.LG math.GR"}, "abstract": "Learning about the three-dimensional world from two-dimensional images is a fundamental problem in computer vision. An ideal neural network architecture for such tasks would leverage the fact that objects can be rotated and translated in three dimensions to make predictions about novel images. However, imposing SO(3)-equivariance on two-dimensional inputs is difficult because the group of three-dimensional rotations does not have a natural action on the two-dimensional plane. Specifically, it is possible that an element of SO(3) will rotate an image out of plane. We show that an algorithm that learns a three-dimensional representation of the world from two dimensional images must satisfy certain geometric consistency properties which we formulate as SO(2)-equivariance constraints. We use the induced and restricted representations of SO(2) on SO(3) to construct and classify architectures which satisfy these geometric consistency constraints. We prove that any architecture which respects said consistency constraints can be realized as an instance of our construction. We show that three previously proposed neural architectures for 3D pose prediction are special cases of our construction. We propose a new algorithm that is a learnable generalization of previously considered methods. We test our architecture on three pose predictions task and achieve SOTA results on both the PASCAL3D+ and SYMSOL pose estimation tasks.", "url": "https://arxiv.org/abs/2307.03704"}, {"metadata": {"arXiv": "2307.03206", "Date": "Thu, 06 Jul 2023 04:10:12 ", "Title": "Optimal Bandwidth Selection for DENCLUE", "Authors": ["Hao Wang"], "Categories": "cs.LG cs.IR"}, "abstract": "In modern day industry, clustering algorithms are daily routines of algorithm engineers. Although clustering algorithms experienced rapid growth before 2010. Innovation related to the research topic has stagnated after deep learning became the de facto industrial standard for machine learning applications. In 2007, a density-based clustering algorithm named DENCLUE was invented to solve clustering problem for nonlinear data structures. However, its parameter selection problem was largely neglected until 2011. In this paper, we propose a new approach to compute the optimal parameters for the DENCLUE algorithm, and discuss its performance in the experiment section.", "url": "https://arxiv.org/abs/2307.03206"}, {"metadata": {"arXiv": "2307.03210", "Date": "Thu, 06 Jul 2023 14:10:02 ", "Title": "Sparse Graphical Linear Dynamical Systems", "Authors": ["Emilie Chouzenoux and Victor Elvira"], "Categories": "cs.LG math.OC stat.CO"}, "abstract": "Time-series datasets are central in numerous fields of science and engineering, such as biomedicine, Earth observation, and network analysis. Extensive research exists on state-space models (SSMs), which are powerful mathematical tools that allow for probabilistic and interpretable learning on time series. Estimating the model parameters in SSMs is arguably one of the most complicated tasks, and the inclusion of prior knowledge is known to both ease the interpretation but also to complicate the inferential tasks. Very recent works have attempted to incorporate a graphical perspective on some of those model parameters, but they present notable limitations that this work addresses. More generally, existing graphical modeling tools are designed to incorporate either static information, focusing on statistical dependencies among independent random variables (e.g., graphical Lasso approach), or dynamic information, emphasizing causal relationships among time series samples (e.g., graphical Granger approaches). However, there are no joint approaches combining static and dynamic graphical modeling within the context of SSMs. This work proposes a novel approach to fill this gap by introducing a joint graphical modeling framework that bridges the static graphical Lasso model and a causal-based graphical approach for the linear-Gaussian SSM. We present DGLASSO (Dynamic Graphical Lasso), a new inference method within this framework that implements an efficient block alternating majorization-minimization algorithm. The algorithm's convergence is established by departing from modern tools from nonlinear analysis. Experimental validation on synthetic and real weather variability data showcases the effectiveness of the proposed model and inference algorithm.", "url": "https://arxiv.org/abs/2307.03210"}, {"metadata": {"arXiv": "2307.03217", "Date": "Thu, 06 Jul 2023 17:56:10 ", "Title": "Quantification of Uncertainty with Adversarial Models", "Authors": ["Kajetan Schweighofer", "Lukas Aichberger", "Mykyta Ielanskyi", "G\\\"unter Klambauer", "Sepp Hochreiter"], "Categories": "cs.LG stat.ML"}, "abstract": "Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of a reference model. Our experiments show that QUAM excels in capturing epistemic uncertainty for deep learning models and outperforms previous methods on challenging tasks in the vision domain.", "url": "https://arxiv.org/abs/2307.03217"}, {"metadata": {"arXiv": "2307.03288", "Date": "Thu, 06 Jul 2023 20:49:42 ", "Title": "Optimal Scalarizations for Sublinear Hypervolume Regret", "Authors": ["Qiuyi Zhang (Richard)"], "Categories": "cs.LG cs.DS math.OC", "Comments": ["ICML 2023 Workshop"]}, "abstract": "Scalarization is a general technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, such as recently in RLHF for training reward models that align human preferences. Yet some have dismissed this classical approach because linear scalarizations are known to miss concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that can explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights are surprisingly optimal for provably minimizing the hypervolume regret, achieving an optimal sublinear regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. As a theoretical case study, we consider the multiobjective stochastic linear bandits problem and demonstrate that by exploiting the sublinear regret bounds of the hypervolume scalarizations, we can derive a novel non-Euclidean analysis that produces improved hypervolume regret bounds of $\\tilde{O}( d T^{-1/2} + T^{-1/k})$. We support our theory with strong empirical performance of using simple hypervolume scalarizations that consistently outperforms both the linear and Chebyshev scalarizations, as well as standard multiobjective algorithms in bayesian optimization, such as EHVI.", "url": "https://arxiv.org/abs/2307.03288"}, {"metadata": {"arXiv": "2307.03290", "Date": "Thu, 06 Jul 2023 21:01:03 ", "Title": "OmniBoost: Boosting Throughput of Heterogeneous Embedded Devices under Multi-DNN Workload", "Authors": ["Andreas Karatzas and Iraklis Anagnostopoulos"], "Categories": "cs.LG cs.PF"}, "abstract": "Modern Deep Neural Networks (DNNs) exhibit profound efficiency and accuracy properties. This has introduced application workloads that comprise of multiple DNN applications, raising new challenges regarding workload distribution. Equipped with a diverse set of accelerators, newer embedded system present architectural heterogeneity, which current run-time controllers are unable to fully utilize. To enable high throughput in multi-DNN workloads, such a controller is ought to explore hundreds of thousands of possible solutions to exploit the underlying heterogeneity. In this paper, we propose OmniBoost, a lightweight and extensible multi-DNN manager for heterogeneous embedded devices. We leverage stochastic space exploration and we combine it with a highly accurate performance estimator to observe a x4.6 average throughput boost compared to other state-of-the-art methods. The evaluation was performed on the HiKey970 development board.", "url": "https://arxiv.org/abs/2307.03290"}, {"metadata": {"arXiv": "2307.03306", "Date": "Thu, 06 Jul 2023 21:38:18 ", "Title": "When Fair Classification Meets Noisy Protected Attributes", "Authors": ["Avijit Ghosh", "Pablo Kvitca", "Christo Wilson"], "Categories": "cs.LG cs.CY", "Comments": ["Accepted at the 6th AAAI/ACM Conference on Artificial Intelligence", "Ethics and Society (AIES) 2023"], "DOI": "10.1145/3600211.3604707"}, "abstract": "The operationalization of algorithmic fairness comes with several practical challenges, not the least of which is the availability or reliability of protected attributes in datasets. In real-world contexts, practical and legal impediments may prevent the collection and use of demographic data, making it difficult to ensure algorithmic fairness. While initial fairness algorithms did not consider these limitations, recent proposals aim to achieve algorithmic fairness in classification by incorporating noisiness in protected attributes or not using protected attributes at all. To the best of our knowledge, this is the first head-to-head study of fair classification algorithms to compare attribute-reliant, noise-tolerant and attribute-blind algorithms along the dual axes of predictivity and fairness. We evaluated these algorithms via case studies on four real-world datasets and synthetic perturbations. Our study reveals that attribute-blind and noise-tolerant fair classifiers can potentially achieve similar level of performance as attribute-reliant algorithms, even when protected attributes are noisy. However, implementing them in practice requires careful nuance. Our study provides insights into the practical implications of using fair classification algorithms in scenarios where protected attributes are noisy or partially available.", "url": "https://arxiv.org/abs/2307.03306"}, {"metadata": {"arXiv": "2307.03323", "Date": "Thu, 06 Jul 2023 22:32:06 ", "Title": "Machine Learning to detect cyber-attacks and discriminating the types of power system disturbances", "Authors": ["Diane Tuyizere and Remy Ihabwikuzo"], "Categories": "cs.LG cs.SY eess.SY", "Comments": ["4 pages ", "6 figures"]}, "abstract": "This research proposes a machine learning-based attack detection model for power systems, specifically targeting smart grids. By utilizing data and logs collected from Phasor Measuring Devices (PMUs), the model aims to learn system behaviors and effectively identify potential security boundaries. The proposed approach involves crucial stages including dataset pre-processing, feature selection, model creation, and evaluation. To validate our approach, we used a dataset used, consist of 15 separate datasets obtained from different PMUs, relay snort alarms and logs. Three machine learning models: Random Forest, Logistic Regression, and K-Nearest Neighbour were built and evaluated using various performance metrics. The findings indicate that the Random Forest model achieves the highest performance with an accuracy of 90.56% in detecting power system disturbances and has the potential in assisting operators in decision-making processes.", "url": "https://arxiv.org/abs/2307.03323"}, {"metadata": {"arXiv": "2307.03327", "Date": "Thu, 06 Jul 2023 22:59:52 ", "Title": "Encoder-Decoder Networks for Self-Supervised Pretraining and Downstream Signal Bandwidth Regression on Digital Antenna Arrays", "Authors": ["Rajib Bhattacharjea", "Nathan West"], "Categories": "cs.LG eess.SP"}, "abstract": "This work presents the first applications of self-supervised learning applied to data from digital antenna arrays. Encoder-decoder networks are pretrained on digital array data to perform a self-supervised noisy-reconstruction task called channel in-painting, in which the network infers the contents of array data that has been masked with zeros. The self-supervised step requires no human-labeled data. The encoder architecture and weights from pretraining are then transferred to a new network with a task-specific decoder, and the new network is trained on a small volume of labeled data. We show that pretraining on the unlabeled data allows the new network to perform the task of bandwidth regression on the digital array data better than an equivalent network that is trained on the same labeled data from random initialization.", "url": "https://arxiv.org/abs/2307.03327"}, {"metadata": {"arXiv": "2307.03332", "Date": "Thu, 06 Jul 2023 23:58:41 ", "Title": "ACDNet: Attention-guided Collaborative Decision Network for Effective Medication Recommendation", "Authors": ["Jiacong Mi", "Yi Zu", "Zhuoyuan Wang", "Jieyue He"], "Categories": "cs.LG"}, "abstract": "Medication recommendation using Electronic Health Records (EHR) is challenging due to complex medical data. Current approaches extract longitudinal information from patient EHR to personalize recommendations. However, existing models often lack sufficient patient representation and overlook the importance of considering the similarity between a patient's medication records and specific medicines. Therefore, an Attention-guided Collaborative Decision Network (ACDNet) for medication recommendation is proposed in this paper. Specifically, ACDNet utilizes attention mechanism and Transformer to effectively capture patient health conditions and medication records by modeling their historical visits at both global and local levels. ACDNet also employs a collaborative decision framework, utilizing the similarity between medication records and medicine representation to facilitate the recommendation process. The experimental results on two extensive medical datasets, MIMIC-III and MIMIC-IV, clearly demonstrate that ACDNet outperforms state-of-the-art models in terms of Jaccard, PR-AUC, and F1 score, reaffirming its superiority. Moreover, the ablation experiments provide solid evidence of the effectiveness of each module in ACDNet, validating their contribution to the overall performance. Furthermore, a detailed case study reinforces the effectiveness of ACDNet in medication recommendation based on EHR data, showcasing its practical value in real-world healthcare scenarios.", "url": "https://arxiv.org/abs/2307.03332"}, {"metadata": {"arXiv": "2307.03337", "Date": "Fri, 07 Jul 2023 00:44:06 ", "Title": "Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data", "Authors": ["Tanvir Islam", "Peter Washington"], "Categories": "cs.LG eess.SP"}, "abstract": "Chronic stress can significantly affect physical and mental health. The advent of wearable technology allows for the tracking of physiological signals, potentially leading to innovative stress prediction and intervention methods. However, challenges such as label scarcity and data heterogeneity render stress prediction difficult in practice. To counter these issues, we have developed a multimodal personalized stress prediction system using wearable biosignal data. We employ self-supervised learning (SSL) to pre-train the models on each subject's data, allowing the models to learn the baseline dynamics of the participant's biosignals prior to fine-tuning the stress prediction task. We test our model on the Wearable Stress and Affect Detection (WESAD) dataset, demonstrating that our SSL models outperform non-SSL models while utilizing less than 5% of the annotations. These results suggest that our approach can personalize stress prediction to each user with minimal annotations. This paradigm has the potential to enable personalized prediction of a variety of recurring health events using complex multimodal data streams.", "url": "https://arxiv.org/abs/2307.03337"}, {"metadata": {"arXiv": "2307.03347", "Date": "Fri, 07 Jul 2023 01:48:02 ", "Title": "Distilling Universal and Joint Knowledge for Cross-Domain Model Compression on Time Series Data", "Authors": ["Qing Xu", "Min Wu", "Xiaoli Li", "Kezhi Mao", "Zhenghua Chen"], "Categories": "cs.LG", "Comments": ["Accepted by IJCAI 2023"]}, "abstract": "For many real-world time series tasks, the computational complexity of prevalent deep leaning models often hinders the deployment on resource-limited environments (e.g., smartphones). Moreover, due to the inevitable domain shift between model training (source) and deploying (target) stages, compressing those deep models under cross-domain scenarios becomes more challenging. Although some of existing works have already explored cross-domain knowledge distillation for model compression, they are either biased to source data or heavily tangled between source and target data. To this end, we design a novel end-to-end framework called Universal and joint knowledge distillation (UNI-KD) for cross-domain model compression. In particular, we propose to transfer both the universal feature-level knowledge across source and target domains and the joint logit-level knowledge shared by both domains from the teacher to the student model via an adversarial learning scheme. More specifically, a feature-domain discriminator is employed to align teacher's and student's representations for universal knowledge transfer. A data-domain discriminator is utilized to prioritize the domain-shared samples for joint knowledge transfer. Extensive experimental results on four time series datasets demonstrate the superiority of our proposed method over state-of-the-art (SOTA) benchmarks.", "url": "https://arxiv.org/abs/2307.03347"}, {"metadata": {"arXiv": "2307.03357", "Date": "Fri, 07 Jul 2023 02:40:09 ", "Title": "Stability and Generalization of Stochastic Compositional Gradient Descent Algorithms", "Authors": ["Ming Yang", "Xiyuan Wei", "Tianbao Yang", "Yiming Ying"], "Categories": "cs.LG stat.ML"}, "abstract": "Many machine learning tasks can be formulated as a stochastic compositional optimization (SCO) problem such as reinforcement learning, AUC maximization, and meta-learning, where the objective function involves a nested composition associated with an expectation. While a significant amount of studies has been devoted to studying the convergence behavior of SCO algorithms, there is little work on understanding their generalization, i.e., how these learning algorithms built from training examples would behave on future test examples. In this paper, we provide the stability and generalization analysis of stochastic compositional gradient descent algorithms through the lens of algorithmic stability in the framework of statistical learning theory. Firstly, we introduce a stability concept called compositional uniform stability and establish its quantitative relation with generalization for SCO problems. Then, we establish the compositional uniform stability results for two popular stochastic compositional gradient descent algorithms, namely SCGD and SCSC. Finally, we derive dimension-independent excess risk bounds for SCGD and SCSC by trade-offing their stability results and optimization errors. To the best of our knowledge, these are the first-ever-known results on stability and generalization analysis of stochastic compositional gradient descent algorithms.", "url": "https://arxiv.org/abs/2307.03357"}, {"metadata": {"arXiv": "2307.03359", "Date": "Fri, 07 Jul 2023 02:55:04 ", "Title": "CSCLog: A Component Subsequence Correlation-Aware Log Anomaly Detection Method", "Authors": ["Ling Chen", "Chaodu Song", "Xu Wang", "Dachao Fu", "and Feifei Li"], "Categories": "cs.LG", "Comments": ["submitted to TKDD", "18 pages and 7 figures"]}, "abstract": "Anomaly detection based on system logs plays an important role in intelligent operations, which is a challenging task due to the extremely complex log patterns. Existing methods detect anomalies by capturing the sequential dependencies in log sequences, which ignore the interactions of subsequences. To this end, we propose CSCLog, a Component Subsequence Correlation-Aware Log anomaly detection method, which not only captures the sequential dependencies in subsequences, but also models the implicit correlations of subsequences. Specifically, subsequences are extracted from log sequences based on components and the sequential dependencies in subsequences are captured by Long Short-Term Memory Networks (LSTMs). An implicit correlation encoder is introduced to model the implicit correlations of subsequences adaptively. In addition, Graph Convolution Networks (GCNs) are employed to accomplish the information interactions of subsequences. Finally, attention mechanisms are exploited to fuse the embeddings of all subsequences. Extensive experiments on four publicly available log datasets demonstrate the effectiveness of CSCLog, outperforming the best baseline by an average of 7.41% in Macro F1-Measure.", "url": "https://arxiv.org/abs/2307.03359"}, {"metadata": {"arXiv": "2307.03363", "Date": "Fri, 07 Jul 2023 03:07:26 ", "Title": "Federated Unlearning via Active Forgetting", "Authors": ["Yuyuan Li", "Chaochao Chen", "Xiaolin Zheng", "Jiaming Zhang"], "Categories": "cs.LG"}, "abstract": "The increasing concerns regarding the privacy of machine learning models have catalyzed the exploration of machine unlearning, i.e., a process that removes the influence of training data on machine learning models. This concern also arises in the realm of federated learning, prompting researchers to address the federated unlearning problem. However, federated unlearning remains challenging. Existing unlearning methods can be broadly categorized into two approaches, i.e., exact unlearning and approximate unlearning. Firstly, implementing exact unlearning, which typically relies on the partition-aggregation framework, in a distributed manner does not improve time efficiency theoretically. Secondly, existing federated (approximate) unlearning methods suffer from imprecise data influence estimation, significant computational burden, or both. To this end, we propose a novel federated unlearning framework based on incremental learning, which is independent of specific models and federated settings. Our framework differs from existing federated unlearning methods that rely on approximate retraining or data influence estimation. Instead, we leverage new memories to overwrite old ones, imitating the process of \\textit{active forgetting} in neurology. Specifically, the model, intended to unlearn, serves as a student model that continuously learns from randomly initiated teacher models. To preserve catastrophic forgetting of non-target data, we utilize elastic weight consolidation to elastically constrain weight change. Extensive experiments on three benchmark datasets demonstrate the efficiency and effectiveness of our proposed method. The result of backdoor attacks demonstrates that our proposed method achieves satisfying completeness.", "url": "https://arxiv.org/abs/2307.03363"}, {"metadata": {"arXiv": "2307.03364", "Date": "Fri, 07 Jul 2023 03:07:28 ", "Title": "Distilled Pruning: Using Synthetic Data to Win the Lottery", "Authors": ["Luke McDermott", "Daniel Cummings"], "Categories": "cs.LG"}, "abstract": "This work introduces a novel approach to pruning deep learning models by using distilled data. Unlike conventional strategies which primarily focus on architectural or algorithmic optimization, our method reconsiders the role of data in these scenarios. Distilled datasets capture essential patterns from larger datasets, and we demonstrate how to leverage this capability to enable a computationally efficient pruning process. Our approach can find sparse, trainable subnetworks (a.k.a. Lottery Tickets) up to 5x faster than Iterative Magnitude Pruning at comparable sparsity on CIFAR-10. The experimental results highlight the potential of using distilled data for resource-efficient neural network pruning, model compression, and neural architecture search.", "url": "https://arxiv.org/abs/2307.03364"}, {"metadata": {"arXiv": "2307.03374", "Date": "Fri, 07 Jul 2023 03:54:26 ", "Title": "STG-MTL: Scalable Task Grouping for Multi-Task Learning Using Data Map", "Authors": ["Ammar Sherif", "Abubakar Abid", "Mustafa Elattar", "Mohamed ElHelw"], "Categories": "cs.LG", "Comments": ["Accepted submission to DMLR workshop @ ICML 23"]}, "abstract": "Multi-Task Learning (MTL) is a powerful technique that has gained popularity due to its performance improvement over traditional Single-Task Learning (STL). However, MTL is often challenging because there is an exponential number of possible task groupings, which can make it difficult to choose the best one, and some groupings might produce performance degradation due to negative interference between tasks. Furthermore, existing solutions are severely suffering from scalability issues, limiting any practical application. In our paper, we propose a new data-driven method that addresses these challenges and provides a scalable and modular solution for classification task grouping based on hand-crafted features, specifically Data Maps, which capture the training behavior for each classification task during the MTL training. We experiment with the method demonstrating its effectiveness, even on an unprecedented number of tasks (up to 100).", "url": "https://arxiv.org/abs/2307.03374"}, {"metadata": {"arXiv": "2307.03381", "Date": "Fri, 07 Jul 2023 04:33:31 ", "Title": "Teaching Arithmetic to Small Transformers", "Authors": ["Nayoung Lee", "Kartik Sreenivasan", "Jason D. Lee", "Kangwook Lee", "Dimitris Papailiopoulos"], "Categories": "cs.LG"}, "abstract": "Large language models like GPT-4 exhibit emergent capabilities across general-purpose tasks, such as basic arithmetic, when trained on extensive text data, even though these tasks are not explicitly encoded by the unsupervised, next-token prediction objective. This study investigates how small transformers, trained from random initialization, can efficiently learn arithmetic operations such as addition, multiplication, and elementary functions like square root, using the next-token prediction objective. We first demonstrate that conventional training data is not the most effective for arithmetic learning, and simple formatting changes can significantly improve accuracy. This leads to sharp phase transitions as a function of training data scale, which, in some cases, can be explained through connections to low-rank matrix completion. Building on prior work, we then train on chain-of-thought style data that includes intermediate step results. Even in the complete absence of pretraining, this approach significantly and simultaneously improves accuracy, sample complexity, and convergence speed. We also study the interplay between arithmetic and text data during training and examine the effects of few-shot prompting, pretraining, and model scale. Additionally, we discuss length generalization challenges. Our work highlights the importance of high-quality, instructive data that considers the particular characteristics of the next-word prediction objective for rapidly eliciting arithmetic capabilities.", "url": "https://arxiv.org/abs/2307.03381"}, {"metadata": {"arXiv": "2307.03411", "Date": "Fri, 07 Jul 2023 06:26:44 ", "Title": "Learning from Heterogeneity: A Dynamic Learning Framework for Hypergraphs", "Authors": ["Tiehua Zhang", "Yuze Liu", "Zhishu Shen", "Xingjun Ma", "Xin Chen", "Xiaowei Huang", "Jun Yin", "Jiong Jin"], "Categories": "cs.LG"}, "abstract": "Graph neural network (GNN) has gained increasing popularity in recent years owing to its capability and flexibility in modeling complex graph structure data. Among all graph learning methods, hypergraph learning is a technique for exploring the implicit higher-order correlations when training the embedding space of the graph. In this paper, we propose a hypergraph learning framework named LFH that is capable of dynamic hyperedge construction and attentive embedding update utilizing the heterogeneity attributes of the graph. Specifically, in our framework, the high-quality features are first generated by the pairwise fusion strategy that utilizes explicit graph structure information when generating initial node embedding. Afterwards, a hypergraph is constructed through the dynamic grouping of implicit hyperedges, followed by the type-specific hypergraph learning process. To evaluate the effectiveness of our proposed framework, we conduct comprehensive experiments on several popular datasets with eleven state-of-the-art models on both node classification and link prediction tasks, which fall into categories of homogeneous pairwise graph learning, heterogeneous pairwise graph learning, and hypergraph learning. The experiment results demonstrate a significant performance gain (average 12.5% in node classification and 13.3% in link prediction) compared with recent state-of-the-art methods.", "url": "https://arxiv.org/abs/2307.03411"}, {"metadata": {"arXiv": "2307.03476", "Date": "Fri, 07 Jul 2023 09:29:44 ", "Title": "Unpaired Multi-View Graph Clustering with Cross-View Structure Matching", "Authors": ["Yi Wen", "Siwei Wang", "Qing Liao", "Weixuan Liang", "Ke Liang", "Xinhang Wan", "Xinwang Liu"], "Categories": "cs.LG cs.CV", "Comments": ["15 pages"]}, "abstract": "Multi-view clustering (MVC), which effectively fuses information from multiple views for better performance, has received increasing attention. Most existing MVC methods assume that multi-view data are fully paired, which means that the mappings of all corresponding samples between views are pre-defined or given in advance. However, the data correspondence is often incomplete in real-world applications due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks: 1) Most methods focus on the feature representation while ignoring the structural information of multi-view data, which is essential for clustering tasks; 2) Existing methods for partially unpaired problems rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems; 3) Their inevitable parameters degrade the efficiency and applicability of the models. To tackle these issues, we propose a novel parameter-free graph clustering framework termed Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM effectively utilizes the structural information from each view to refine cross-view correspondences. Besides, our UPMGC-SM is a unified framework for both the fully and partially unpaired multi-view graph clustering. Moreover, existing graph clustering methods can adopt our UPMGC-SM to enhance their ability for unpaired scenarios. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both paired and unpaired datasets.", "url": "https://arxiv.org/abs/2307.03476"}, {"metadata": {"arXiv": "2307.03500", "Date": "Fri, 07 Jul 2023 10:29:25 ", "Title": "DEFT: Exploiting Gradient Norm Difference between Model Layers for Scalable Gradient Sparsification", "Authors": ["Daegun Yoon", "Sangyoon Oh"], "Categories": "cs.LG cs.DC", "Comments": ["Accepted at ICPP 2023"], "DOI": "10.1145/3605573.3605609"}, "abstract": "Gradient sparsification is a widely adopted solution for reducing the excessive communication traffic in distributed deep learning. However, most existing gradient sparsifiers have relatively poor scalability because of considerable computational cost of gradient selection and/or increased communication traffic owing to gradient build-up. To address these challenges, we propose a novel gradient sparsification scheme, DEFT, that partitions the gradient selection task into sub tasks and distributes them to workers. DEFT differs from existing sparsifiers, wherein every worker selects gradients among all gradients. Consequently, the computational cost can be reduced as the number of workers increases. Moreover, gradient build-up can be eliminated because DEFT allows workers to select gradients in partitions that are non-intersecting (between workers). Therefore, even if the number of workers increases, the communication traffic can be maintained as per user requirement. To avoid the loss of significance of gradient selection, DEFT selects more gradients in the layers that have a larger gradient norm than the other layers. Because every layer has a different computational load, DEFT allocates layers to workers using a bin-packing algorithm to maintain a balanced load of gradient selection between workers. In our empirical evaluation, DEFT shows a significant improvement in training performance in terms of speed in gradient selection over existing sparsifiers while achieving high convergence performance.", "url": "https://arxiv.org/abs/2307.03500"}, {"metadata": {"arXiv": "2307.03515", "Date": "Fri, 07 Jul 2023 11:08:18 ", "Title": "Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem", "Authors": ["Afsana Khan", "Marijn ten Thij", "Frank Thuijsman and Anna Wilbik"], "Categories": "cs.LG cs.DC cs.GT"}, "abstract": "Vertical federated learning (VFL) is a promising approach for collaboratively training machine learning models using private data partitioned vertically across different parties. Ideally in a VFL setting, the active party (party possessing features of samples with labels) benefits by improving its machine learning model through collaboration with some passive parties (parties possessing additional features of the same samples without labels) in a privacy preserving manner. However, motivating passive parties to participate in VFL can be challenging. In this paper, we focus on the problem of allocating incentives to the passive parties by the active party based on their contributions to the VFL process. We formulate this problem as a variant of the Nucleolus game theory concept, known as the Bankruptcy Problem, and solve it using the Talmud's division rule. We evaluate our proposed method on synthetic and real-world datasets and show that it ensures fairness and stability in incentive allocation among passive parties who contribute their data to the federated model. Additionally, we compare our method to the existing solution of calculating Shapley values and show that our approach provides a more efficient solution with fewer computations.", "url": "https://arxiv.org/abs/2307.03515"}, {"metadata": {"arXiv": "2307.03565", "Date": "Fri, 07 Jul 2023 12:57:10 ", "Title": "MALIBO: Meta-learning for Likelihood-free Bayesian Optimization", "Authors": ["Jiarong Pan", "Stefan Falkner", "Felix Berkenkamp", "Joaquin Vanschoren"], "Categories": "cs.LG stat.ML"}, "abstract": "Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that our method demonstrates strong anytime performance and outperforms state-of-the-art meta-learning BO methods in various benchmarks.", "url": "https://arxiv.org/abs/2307.03565"}, {"metadata": {"arXiv": "2307.03571", "Date": "Fri, 07 Jul 2023 13:06:12 ", "Title": "Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization", "Authors": ["Chris Kolb and Christian L. M\\\"uller and Bernd Bischl and David R\\\"ugamer"], "Categories": "cs.LG math.OC stat.ML"}, "abstract": "This paper introduces a smooth method for (structured) sparsity in $\\ell_q$ and $\\ell_{p,q}$ regularized optimization problems. Optimization of these non-smooth and possibly non-convex problems typically relies on specialized procedures. In contrast, our general framework is compatible with prevalent first-order optimization methods like Stochastic Gradient Descent and accelerated variants without any required modifications. This is accomplished through a smooth optimization transfer, comprising an overparametrization of selected model parameters using Hadamard products and a change of penalties. In the overparametrized problem, smooth and convex $\\ell_2$ regularization of the surrogate parameters induces non-smooth and non-convex $\\ell_q$ or $\\ell_{p,q}$ regularization in the original parametrization. We show that our approach yields not only matching global minima but also equivalent local minima. This is particularly useful in non-convex sparse regularization, where finding global minima is NP-hard and local minima are known to generalize well. We provide a comprehensive overview consolidating various literature strands on sparsity-inducing parametrizations and propose meaningful extensions to existing approaches. The feasibility of our approach is evaluated through numerical experiments, which demonstrate that its performance is on par with or surpasses commonly used implementations of convex and non-convex regularization methods.", "url": "https://arxiv.org/abs/2307.03571"}, {"metadata": {"arXiv": "2307.03576", "Date": "Fri, 07 Jul 2023 13:09:18 ", "Title": "One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention", "Authors": ["Arvind Mahankali", "Tatsunori B. Hashimoto", "Tengyu Ma"], "Categories": "cs.LG"}, "abstract": "Recent works have empirically analyzed in-context learning and shown that transformers trained on synthetic linear regression tasks can learn to implement ridge regression, which is the Bayes-optimal predictor, given sufficient capacity [Aky\\\"urek et al., 2023], while one-layer transformers with linear self-attention and no MLP layer will learn to implement one step of gradient descent (GD) on a least-squares linear regression objective [von Oswald et al., 2022]. However, the theory behind these observations remains poorly understood. We theoretically study transformers with a single layer of linear self-attention, trained on synthetic noisy linear regression data. First, we mathematically show that when the covariates are drawn from a standard Gaussian distribution, the one-layer transformer which minimizes the pre-training loss will implement a single step of GD on the least-squares linear regression objective. Then, we find that changing the distribution of the covariates and weight vector to a non-isotropic Gaussian distribution has a strong impact on the learned algorithm: the global minimizer of the pre-training loss now implements a single step of $\\textit{pre-conditioned}$ GD. However, if only the distribution of the responses is changed, then this does not have a large effect on the learned algorithm: even when the response comes from a more general family of $\\textit{nonlinear}$ functions, the global minimizer of the pre-training loss still implements a single step of GD on a least-squares linear regression objective.", "url": "https://arxiv.org/abs/2307.03576"}, {"metadata": {"arXiv": "2307.03577", "Date": "Fri, 07 Jul 2023 13:10:23 ", "Title": "Programmable Synthetic Tabular Data Generation", "Authors": ["Mark Vero", "Mislav Balunovi\\'c", "Martin Vechev"], "Categories": "cs.LG cs.DB cs.PL"}, "abstract": "Large amounts of tabular data remain underutilized due to privacy, data quality, and data sharing limitations. While training a generative model producing synthetic data resembling the original distribution addresses some of these issues, most applications require additional constraints from the generated data. Existing synthetic data approaches are limited as they typically only handle specific constraints, e.g., differential privacy (DP) or increased fairness, and lack an accessible interface for declaring general specifications. In this work, we introduce ProgSyn, the first programmable synthetic tabular data generation algorithm that allows for comprehensive customization over the generated data. To ensure high data quality while adhering to custom specifications, ProgSyn pre-trains a generative model on the original dataset and fine-tunes it on a differentiable loss automatically derived from the provided specifications. These can be programmatically declared using statistical and logical expressions, supporting a wide range of requirements (e.g., DP or fairness, among others). We conduct an extensive experimental evaluation of ProgSyn on a number of constraints, achieving a new state-of-the-art on some, while remaining general. For instance, at the same fairness level we achieve 2.3% higher downstream accuracy than the state-of-the-art in fair synthetic data generation on the Adult dataset. Overall, ProgSyn provides a versatile and accessible framework for generating constrained synthetic tabular data, allowing for specifications that generalize beyond the capabilities of prior work.", "url": "https://arxiv.org/abs/2307.03577"}, {"metadata": {"arXiv": "2307.03587", "Date": "Fri, 07 Jul 2023 13:29:07 ", "Title": "BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits", "Authors": ["Nicklas Werge", "Abdullah Akg\\\"ul", "Melih Kandemir"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.", "url": "https://arxiv.org/abs/2307.03587"}, {"metadata": {"arXiv": "2307.03630", "Date": "Fri, 07 Jul 2023 14:39:18 ", "Title": "PAC bounds of continuous Linear Parameter-Varying systems related to neural ODEs", "Authors": ["D\\'aniel R\\'acz and Mih\\'aly Petreczky and B\\'alint Dar\\'oczy"], "Categories": "cs.LG", "Comments": ["12 pages"], "MSC-class": "68", "ACM-class": "I.2.0"}, "abstract": "We consider the problem of learning Neural Ordinary Differential Equations (neural ODEs) within the context of Linear Parameter-Varying (LPV) systems in continuous-time. LPV systems contain bilinear systems which are known to be universal approximators for non-linear systems. Moreover, a large class of neural ODEs can be embedded into LPV systems. As our main contribution we provide Probably Approximately Correct (PAC) bounds under stability for LPV systems related to neural ODEs. The resulting bounds have the advantage that they do not depend on the integration interval.", "url": "https://arxiv.org/abs/2307.03630"}, {"metadata": {"arXiv": "2307.03641", "Date": "Fri, 07 Jul 2023 15:03:42 ", "Title": "Online Network Source Optimization with Graph-Kernel MAB", "Authors": ["Laura Toni", "Pascal Frossard"], "Categories": "cs.LG stat.ML"}, "abstract": "We propose Grab-UCB, a graph-kernel multi-arms bandit algorithm to learn online the optimal source placement in large scale networks, such that the reward obtained from a priori unknown network processes is maximized. The uncertainty calls for online learning, which suffers however from the curse of dimensionality. To achieve sample efficiency, we describe the network processes with an adaptive graph dictionary model, which typically leads to sparse spectral representations. This enables a data-efficient learning framework, whose learning rate scales with the dimension of the spectral representation model instead of the one of the network. We then propose Grab-UCB, an online sequential decision strategy that learns the parameters of the spectral representation while optimizing the action strategy. We derive the performance guarantees that depend on network parameters, which further influence the learning curve of the sequential decision strategy We introduce a computationally simplified solving method, Grab-arm-Light, an algorithm that walks along the edges of the polytope representing the objective function. Simulations results show that the proposed online learning algorithm outperforms baseline offline methods that typically separate the learning phase from the testing one. The results confirm the theoretical findings, and further highlight the gain of the proposed online learning strategy in terms of cumulative regret, sample efficiency and computational complexity.", "url": "https://arxiv.org/abs/2307.03641"}, {"metadata": {"arXiv": "2307.03672", "Date": "Fri, 07 Jul 2023 15:42:35 ", "Title": "Simulation-free Schr\\\"odinger bridges via score and flow matching", "Authors": ["Alexander Tong", "Nikolay Malkin", "Kilian Fatras", "Lazar Atanackovic", "Yanlei Zhang", "Guillaume Huguet", "Guy Wolf", "Yoshua Bengio"], "Categories": "cs.LG", "Comments": ["A version of this paper appeared in the New Frontiers in Learning", "Control", "and Dynamical Systems workshop at ICML 2023. Code: https://github.com/atong01/conditional-flow-matching"]}, "abstract": "We present simulation-free score and flow matching ([SF]$^2$M), a simulation-free objective for inferring stochastic dynamics given unpaired source and target samples drawn from arbitrary distributions. Our method generalizes both the score-matching loss used in the training of diffusion models and the recently proposed flow matching loss used in the training of continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic generative modeling as a Schr\\\"odinger bridge (SB) problem. It relies on static entropy-regularized optimal transport, or a minibatch approximation, to efficiently learn the SB without simulating the learned stochastic process. We find that [SF]$^2$M is more efficient and gives more accurate solutions to the SB problem than simulation-based methods from prior work. Finally, we apply [SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably, [SF]$^2$M is the first method to accurately model cell dynamics in high dimensions and can recover known gene regulatory networks from simulated data.", "url": "https://arxiv.org/abs/2307.03672"}, {"metadata": {"arXiv": "2307.03675", "Date": "Fri, 07 Jul 2023 15:45:05 ", "Title": "GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies", "Authors": ["Takahiro Mimori", "Michiaki Hamada"], "Categories": "cs.LG q-bio.PE stat.ML", "Comments": ["23 pages", "5 figures"]}, "abstract": "Phylogenetic inference, grounded in molecular evolution models, is essential for understanding the evolutionary relationships in biological data. Accounting for the uncertainty of phylogenetic tree variables, which include tree topologies and evolutionary distances on branches, is crucial for accurately inferring species relationships from molecular data and tasks requiring variable marginalization. Variational Bayesian methods are key to developing scalable, practical models; however, it remains challenging to conduct phylogenetic inference without restricting the combinatorially vast number of possible tree topologies. In this work, we introduce a novel, fully differentiable formulation of phylogenetic inference that leverages a unique representation of topological distributions in continuous geometric spaces. Through practical considerations on design spaces and control variates for gradient estimations, our approach, GeoPhy, enables variational inference without limiting the topological candidates. In experiments using real benchmark datasets, GeoPhy significantly outperformed other approximate Bayesian methods that considered whole topologies.", "url": "https://arxiv.org/abs/2307.03675"}, {"metadata": {"arXiv": "2307.03712", "Date": "Fri, 07 Jul 2023 16:54:53 ", "Title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers", "Authors": ["Lakshmi Nair", "Mikhail Bernadskiy", "Arulselvan Madhavan", "Craig Chan", "Ayon Basumallik", "Darius Bunandar"], "Categories": "cs.LG cs.CL cs.CV", "Comments": ["This report is supplementary material to the open-source code available at: https://github.com/lightmatter-ai/INT-FP-QSim"]}, "abstract": "The recent rise of large language models (LLMs) has resulted in increased efforts towards running LLMs at reduced precision. Running LLMs at lower precision supports resource constraints and furthers their democratization, enabling users to run billion-parameter LLMs on their personal devices. To supplement this ongoing effort, we propose INT-FP-QSim: an open-source simulator that enables flexible evaluation of LLMs and vision transformers at various numerical precisions and formats. INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch and AIMET for a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers at 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We hope INT-FP-QSim will enable researchers to flexibly simulate models at various precisions to support further research in quantization of LLMs and vision transformers.", "url": "https://arxiv.org/abs/2307.03712"}, {"metadata": {"arXiv": "2307.03723", "Date": "Thu, 06 Jul 2023 16:44:03 ", "Title": "Steel Surface Roughness Parameter Calculations Using Lasers and Machine Learning Models", "Authors": ["Alex Milne", "Xianghua Xie"], "Categories": "cs.LG"}, "abstract": "Control of surface texture in strip steel is essential to meet customer requirements during galvanizing and temper rolling processes. Traditional methods rely on post-production stylus measurements, while on-line techniques offer non-contact and real-time measurements of the entire strip. However, ensuring accurate measurement is imperative for their effective utilization in the manufacturing pipeline. Moreover, accurate on-line measurements enable real-time adjustments of manufacturing processing parameters during production, ensuring consistent quality and the possibility of closed-loop control of the temper mill. In this study, we leverage state-of-the-art machine learning models to enhance the transformation of on-line measurements into significantly a more accurate Ra surface roughness metric. By comparing a selection of data-driven approaches, including both deep learning and non-deep learning methods, to the close-form transformation, we evaluate their potential for improving surface texture control in temper strip steel manufacturing.", "url": "https://arxiv.org/abs/2307.03723"}, {"metadata": {"arXiv": "2307.03738", "Date": "Fri, 07 Jul 2023 17:46:08 ", "Title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models", "Authors": ["Tommaso Pegolotti", "Elias Frantar", "Dan Alistarh", "Markus P\\\"uschel"], "Categories": "cs.LG cs.CL cs.PF"}, "abstract": "We present ongoing work on a new automatic code generation approach for supporting quantized generative inference on LLMs such as LLaMA or OPT on off-the-shelf CPUs. Our approach is informed by the target architecture and a performance model, including both hardware characteristics and method-specific accuracy constraints. Results on CPU-based inference for LLaMA models show that our approach can lead to high performance and high accuracy, comparing favorably to the best existing open-source solution. A preliminary implementation is available at https://github.com/IST-DASLab/QIGen.", "url": "https://arxiv.org/abs/2307.03738"}, {"metadata": {"arXiv": "2307.03716", "Date": "Fri, 07 Jul 2023 17:07:41 ", "Title": "SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation", "Authors": ["Cameron Berg", "Vittorio Caggiano", "Vikash Kumar"], "Categories": "cs.RO cs.LG", "Comments": ["Accepted to RSS 2023"]}, "abstract": "Learning effective continuous control policies in high-dimensional systems, including musculoskeletal agents, remains a significant challenge. Over the course of biological evolution, organisms have developed robust mechanisms for overcoming this complexity to learn highly sophisticated strategies for motor control. What accounts for this robust behavioral flexibility? Modular control via muscle synergies, i.e. coordinated muscle co-contractions, is considered to be one putative mechanism that enables organisms to learn muscle control in a simplified and generalizable action space. Drawing inspiration from this evolved motor control strategy, we use physiologically accurate human hand and leg models as a testbed for determining the extent to which a Synergistic Action Representation (SAR) acquired from simpler tasks facilitates learning more complex tasks. We find in both cases that SAR-exploiting policies significantly outperform end-to-end reinforcement learning. Policies trained with SAR were able to achieve robust locomotion on a wide set of terrains with high sample efficiency, while baseline approaches failed to learn meaningful behaviors. Additionally, policies trained with SAR on a multiobject manipulation task significantly outperformed (>70% success) baseline approaches (<20% success). Both of these SAR-exploiting policies were also found to generalize zero-shot to out-of-domain environmental conditions, while policies that did not adopt SAR failed to generalize. Finally, we establish the generality of SAR on broader high-dimensional control problems using a robotic manipulation task set and a full-body humanoid locomotion task. To the best of our knowledge, this investigation is the first of its kind to present an end-to-end pipeline for discovering synergies and using this representation to learn high-dimensional continuous control across a wide diversity of tasks.", "url": "https://arxiv.org/abs/2307.03716"}, {"metadata": {"arXiv": "2307.03719", "Date": "Fri, 07 Jul 2023 17:21:16 ", "Title": "Polybot: Training One Policy Across Robots While Embracing Variability", "Authors": ["Jonathan Yang", "Dorsa Sadigh", "Chelsea Finn"], "Categories": "cs.RO cs.LG", "Comments": ["17 pages", "11 figures"], "MSC-class": "68T40", "ACM-class": "I.2.9"}, "abstract": "Reusing large datasets is crucial to scale vision-based robotic manipulators to everyday scenarios due to the high cost of collecting robotic datasets. However, robotic platforms possess varying control schemes, camera viewpoints, kinematic configurations, and end-effector morphologies, posing significant challenges when transferring manipulation skills from one platform to another. To tackle this problem, we propose a set of key design decisions to train a single policy for deployment on multiple robotic platforms. Our framework first aligns the observation and action spaces of our policy across embodiments via utilizing wrist cameras and a unified, but modular codebase. To bridge the remaining domain shift, we align our policy's internal representations across embodiments through contrastive learning. We evaluate our method on a dataset collected over 60 hours spanning 6 tasks and 3 robots with varying joint configurations and sizes: the WidowX 250S, the Franka Emika Panda, and the Sawyer. Our results demonstrate significant improvements in success rate and sample efficiency for our policy when using new task data collected on a different robot, validating our proposed design decisions. More details and videos can be found on our anonymized project website: https://sites.google.com/view/polybot-multirobot", "url": "https://arxiv.org/abs/2307.03719"}, {"metadata": {"arXiv": "2307.03690", "Date": "Mon, 19 Jun 2023 20:20:10 ", "Title": "Suppressing unknown disturbances to dynamical systems using machine learning", "Authors": ["Juan G. Restrepo", "Per Sebastian Skardal"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["9 pages", "9 figures (including supplemental material)"]}, "abstract": "Identifying and suppressing unknown disturbances to dynamical systems is a problem with applications in many different fields. In this Letter, we present a model-free method to identify and suppress an unknown disturbance to an unknown system based only on previous observations of the system under the influence of a known forcing function. We find that, under very mild restrictions on the training function, our method is able to robustly identify and suppress a large class of unknown disturbances. We illustrate our scheme with an example where a chaotic disturbance to the Lorenz system is identified and suppressed.", "url": "https://arxiv.org/abs/2307.03690"}, {"metadata": {"arXiv": "2307.03362", "Date": "Fri, 07 Jul 2023 03:05:34 ", "Title": "Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents' Beliefs about Plans", "Authors": ["Yuening Zhang", "Brian C. Williams"], "Categories": "cs.AI cs.RO", "Comments": ["10 pages", "Published at ICAPS 2023 (Main Track)"], "DOI": "10.1609/icaps.v33i1.27226"}, "abstract": "When agents collaborate on a task, it is important that they have some shared mental model of the task routines -- the set of feasible plans towards achieving the goals. However, in reality, situations often arise that such a shared mental model cannot be guaranteed, such as in ad-hoc teams where agents may follow different conventions or when contingent constraints arise that only some agents are aware of. Previous work on human-robot teaming has assumed that the team has a set of shared routines, which breaks down in these situations. In this work, we leverage epistemic logic to enable agents to understand the discrepancy in each other's beliefs about feasible plans and dynamically plan their actions to adapt or communicate to resolve the discrepancy. We propose a formalism that extends conditional doxastic logic to describe knowledge bases in order to explicitly represent agents' nested beliefs on the feasible plans and state of execution. We provide an online execution algorithm based on Monte Carlo Tree Search for the agent to plan its action, including communication actions to explain the feasibility of plans, announce intent, and ask questions. Finally, we evaluate the success rate and scalability of the algorithm and show that our agent is better equipped to work in teams without the guarantee of a shared mental model.", "url": "https://arxiv.org/abs/2307.03362"}, {"metadata": {"arXiv": "2307.03379", "Date": "Fri, 07 Jul 2023 04:20:07 ", "Title": "Efficient Ground Vehicle Path Following in Game AI", "Authors": ["Rodrigue de Schaetzen", "Alessandro Sestini"], "Categories": "cs.AI", "Comments": ["4 pages", "3 figures", "to be published in IEEE Conference on Games 2023"]}, "abstract": "This short paper presents an efficient path following solution for ground vehicles tailored to game AI. Our focus is on adapting established techniques to design simple solutions with parameters that are easily tunable for an efficient benchmark path follower. Our solution pays particular attention to computing a target speed which uses quadratic Bezier curves to estimate the path curvature. The performance of the proposed path follower is evaluated through a variety of test scenarios in a first-person shooter game, demonstrating its effectiveness and robustness in handling different types of paths and vehicles. We achieved a 70% decrease in the total number of stuck events compared to an existing path following solution.", "url": "https://arxiv.org/abs/2307.03379"}, {"metadata": {"arXiv": "2307.03492", "Date": "Fri, 07 Jul 2023 10:01:08 ", "Title": "Large AI Model-Based Semantic Communications", "Authors": ["Feibo Jiang", "Yubo Peng", "Li Dong", "Kezhi Wang", "Kun Yang", "Cunhua Pan", "Xiaohu You"], "Categories": "cs.AI cs.NI", "Comments": ["Plan to submit it to journal for possible publication"]}, "abstract": "Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC) encoding to remove redundant information in semantic features, thereby reducing communication overhead. Finally, through simulations, we demonstrate the effectiveness of the LAM-SC framework and the significance of the large AI model-based KB development in future SC paradigms.", "url": "https://arxiv.org/abs/2307.03492"}, {"metadata": {"arXiv": "2307.03591", "Date": "Thu, 06 Jul 2023 16:04:56 ", "Title": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning", "Authors": ["Ke Liang", "Sihang Zhou", "Yue Liu", "Lingyuan Meng", "Meng Liu", "Xinwang Liu"], "Categories": "cs.AI cs.IR", "Comments": ["This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessed"]}, "abstract": "Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph Structure Guided Multimodal Pretrained Transformer for knowledge graph reasoning, termed SGMPT. Specifically, the graph structure encoder is adopted for structural feature encoding. Then, a structure-guided fusion module with two different strategies, i.e., weighted summation and alignment constraint, is first designed to inject the structural information into both the textual and visual features. To the best of our knowledge, SGMPT is the first MPT model for multimodal KGR, which mines the structural information underlying the knowledge graph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that our SGMPT outperforms existing state-of-the-art models, and prove the effectiveness of the designed strategies.", "url": "https://arxiv.org/abs/2307.03591"}, {"metadata": {"arXiv": "2307.03637", "Date": "Fri, 07 Jul 2023 14:51:30 ", "Title": "Discovering Variable Binding Circuitry with Desiderata", "Authors": ["Xander Davies", "Max Nadeau", "Nikhil Prakash", "Tamar Rott Shaham", "David Bau"], "Categories": "cs.AI"}, "abstract": "Recent work has shown that computation in language models may be human-understandable, with successful efforts to localize and intervene on both single-unit features and input-output circuits. Here, we introduce an approach which extends causal mediation experiments to automatically identify model components responsible for performing a specific subtask by solely specifying a set of \\textit{desiderata}, or causal attributes of the model components executing that subtask. As a proof of concept, we apply our method to automatically discover shared \\textit{variable binding circuitry} in LLaMA-13B, which retrieves variable values for multiple arithmetic tasks. Our method successfully localizes variable binding to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.", "url": "https://arxiv.org/abs/2307.03637"}, {"metadata": {"arXiv": "2307.03274", "Date": "Thu, 06 Jul 2023 20:23:17 ", "Title": "It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos", "Authors": ["Enfa George", "Mihai Surdeanu"], "Categories": "cs.CV cs.AI cs.CL", "Comments": ["Accepted to ACL Findings 2023. 10 pages", "3 figures", "5 tables . Please refer to https://github.com/enfageorge/SexTok for dataset and related details"], "ACM-class": "I.2.10; I.4.9; I.2.7; I.5.4"}, "abstract": "We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator's point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children's exposure to sexually suggestive videos has been shown to have adversarial effects on their development. Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable. The platform's current system removes or penalizes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments suggest that this dataset is meaningful and invites further study on the subject.", "url": "https://arxiv.org/abs/2307.03274"}, {"metadata": {"arXiv": "2307.03373", "Date": "Fri, 07 Jul 2023 03:51:21 ", "Title": "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment", "Authors": ["Chunhui Zhang", "and Xin Sun", "and Li Liu", "and Yiqian Yang", "and Qiong Liu", "and Xi Zhou", "and Yanfeng Wang"], "Categories": "cs.CV cs.AI", "Comments": ["Work in progress"]}, "abstract": "Current mainstream vision-language (VL) tracking framework consists of three parts, \\ie a visual feature extractor, a language feature extractor, and a fusion model. To pursue better performance, a natural modus operandi for VL tracking is employing customized and heavier unimodal encoders, and multi-modal fusion models. Albeit effective, existing VL trackers separate feature extraction and feature integration, resulting in extracted features that lack semantic guidance and have limited target-aware capability in complex scenarios, \\eg similar distractors and extreme illumination. In this work, inspired by the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks, we propose an All-in-One framework, which learns joint feature extraction and interaction by adopting a unified transformer backbone. Specifically, we mix raw vision and language signals to generate language-injected vision tokens, which we then concatenate before feeding into the unified backbone architecture. This approach achieves feature integration in a unified backbone, removing the need for carefully-designed fusion modules and resulting in a more effective and efficient VL tracking framework. To further improve the learning efficiency, we introduce a multi-modal alignment module based on cross-modal and intra-modal contrastive objectives, providing more reasonable representations for the unified All-in-One transformer backbone. Extensive experiments on five benchmarks, \\ie OTB99-L, TNL2K, LaSOT, LaSOT$_{\\rm Ext}$ and WebUAV-3M, demonstrate the superiority of the proposed tracker against existing state-of-the-arts on VL tracking. Codes will be made publicly available.", "url": "https://arxiv.org/abs/2307.03373"}, {"metadata": {"arXiv": "2307.03421", "Date": "Fri, 07 Jul 2023 07:07:42 ", "Title": "Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration", "Authors": ["Mingyuan Meng", "Lei Bi", "Michael Fulham", "Dagan Feng", "and Jinman Kim"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["Accepted at International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)"]}, "abstract": "Image registration is a fundamental requirement for medical image analysis. Deep registration methods based on deep learning have been widely recognized for their capabilities to perform fast end-to-end registration. Many deep registration methods achieved state-of-the-art performance by performing coarse-to-fine registration, where multiple registration steps were iterated with cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE) registration methods have been proposed to perform coarse-to-fine registration in a single network and showed advantages in both registration accuracy and runtime. However, existing NICE registration methods mainly focus on deformable registration, while affine registration, a common prerequisite, is still reliant on time-consuming traditional optimization-based methods or extra affine registration networks. In addition, existing NICE registration methods are limited by the intrinsic locality of convolution operations. Transformers may address this limitation for their capabilities to capture long-range dependency, but the benefits of using transformers for NICE registration have not been explored. In this study, we propose a Non-Iterative Coarse-to-finE Transformer network (NICE-Trans) for image registration. Our NICE-Trans is the first deep registration method that (i) performs joint affine and deformable coarse-to-fine registration within a single network, and (ii) embeds transformers into a NICE registration framework to model long-range relevance between images. Extensive experiments with seven public datasets show that our NICE-Trans outperforms state-of-the-art registration methods on both registration accuracy and runtime.", "url": "https://arxiv.org/abs/2307.03421"}, {"metadata": {"arXiv": "2307.03465", "Date": "Fri, 07 Jul 2023 08:57:57 ", "Title": "TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning", "Authors": ["Zelun Zhang", "Xue Pan"], "Categories": "cs.CV cs.AI", "Comments": ["Foundation Model Challenge@CVPR2023", "Accepted by CVPR2023 Workshop"], "Journal-ref": "Conference on Computer Vision and Pattern Recognition, 2023"}, "abstract": "The AllInOne training paradigm squeezes a wide range of tasks into a unified model in a multi-task learning manner. However, optimization in multi-task learning is more challenge than single-task learning, as the gradient norm from different tasks may vary greatly, making the backbone overly biased towards one specific task. To address this issue, we propose the task-level backbone-oriented gradient clip paradigm, compared with the vanilla gradient clip method, it has two points of emphasis:1) gradient clip is performed independently for each task. 2) backbone gradients generated from each task are rescaled to the same norm scale. Based on the experimental results, we argue that the task-level backbone-oriented gradient clip paradigm can relieve the gradient bias problem to some extent. We also propose a novel multi-branch data augmentation strategy where conflict augmentations are placed in different branches. Our approach has been shown to be effective and finally achieve 1st place in the Leaderboard A and 2nd place in the Leaderboard B of the CVPR2023 Foundation Model Challenge. It's worth noting that instead of evaluating all three tasks(detection, segmentation and fine-grained classification) in Leaderboard A, the segmentation task is not evaluated in Leaderboard B, in which our team has a huge advantage.", "url": "https://arxiv.org/abs/2307.03465"}, {"metadata": {"arXiv": "2307.03505", "Date": "Fri, 07 Jul 2023 10:40:41 ", "Title": "RCDN -- Robust X-Corner Detection Algorithm based on Advanced CNN Model", "Authors": ["Ben Chen", "Caihua Xiong", "Quanlin Li", "Zhonghua Wan"], "Categories": "cs.CV cs.AI", "Comments": ["15 pages", "8 figures and 4 tables. Unpublished further research and experiments of Checkerboard corner detection network CCDN (arXiv:2302.05097) and application exploration for robust camera calibration (https://ieeexplore.ieee.org/abstract/document/9428389)"]}, "abstract": "Accurate detection and localization of X-corner on both planar and non-planar patterns is a core step in robotics and machine vision. However, previous works could not make a good balance between accuracy and robustness, which are both crucial criteria to evaluate the detectors performance. To address this problem, in this paper we present a novel detection algorithm which can maintain high sub-pixel precision on inputs under multiple interference, such as lens distortion, extreme poses and noise. The whole algorithm, adopting a coarse-to-fine strategy, contains a X-corner detection network and three post-processing techniques to distinguish the correct corner candidates, as well as a mixed sub-pixel refinement technique and an improved region growth strategy to recover the checkerboard pattern partially visible or occluded automatically. Evaluations on real and synthetic images indicate that the presented algorithm has the higher detection rate, sub-pixel accuracy and robustness than other commonly used methods. Finally, experiments of camera calibration and pose estimation verify it can also get smaller re-projection error in quantitative comparisons to the state-of-the-art.", "url": "https://arxiv.org/abs/2307.03505"}, {"metadata": {"arXiv": "2307.03512", "Date": "Fri, 07 Jul 2023 11:00:44 ", "Title": "Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data", "Authors": ["Paolo Soleni", "Wouter B. Verschoof-van der Vaart", "\\v{Z}iga Kokalj", "Arianna Traviglia", "Marco Fiorucci"], "Categories": "cs.CV cs.AI", "Comments": ["Accepted to IEEE International Geoscience and Remote Sensing Symposium 2023 (IGARSS 2023) @IEEE copyright"]}, "abstract": "When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.", "url": "https://arxiv.org/abs/2307.03512"}, {"metadata": {"arXiv": "2307.03575", "Date": "Fri, 07 Jul 2023 13:09:07 ", "Title": "Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data", "Authors": ["Maryamalsadat Mahootiha", "Hemin Ali Qadir", "Jacob Bergsland and Ilangko Balasingham"], "Categories": "cs.CV cs.AI"}, "abstract": "Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework comprises three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments are performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on: \\href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}", "url": "https://arxiv.org/abs/2307.03575"}, {"metadata": {"arXiv": "2307.03592", "Date": "Fri, 07 Jul 2023 13:35:48 ", "Title": "VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis", "Authors": ["Paula Feldman", "Miguel Fainstein", "Viviana Siless", "Claudio Delrieux", "Emmanuel Iarussi"], "Categories": "cs.CV cs.AI eess.IV", "Comments": ["Accepted for MICCAI 2023"]}, "abstract": "We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we generate 3D models of blood vessels that are both accurate and diverse, which is crucial for medical and surgical training, hemodynamic simulations, and many other purposes.", "url": "https://arxiv.org/abs/2307.03592"}, {"metadata": {"arXiv": "2307.03659", "Date": "Fri, 07 Jul 2023 15:26:03 ", "Title": "Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation", "Authors": ["Annie Xie", "Lisa Lee", "Ted Xiao", "Chelsea Finn"], "Categories": "cs.RO cs.AI", "Comments": ["Project webpage at https://sites.google.com/view/generalization-gap"]}, "abstract": "What makes generalization hard for imitation learning in visual robotic manipulation? This question is difficult to approach at face value, but the environment from the perspective of a robot can often be decomposed into enumerable factors of variation, such as the lighting conditions or the placement of the camera. Empirically, generalization to some of these factors have presented a greater obstacle than others, but existing work sheds little light on precisely how much each factor contributes to the generalization gap. Towards an answer to this question, we study imitation learning policies in simulation and on a real robot language-conditioned manipulation task to quantify the difficulty of generalization to different (sets of) factors. We also design a new simulated benchmark of 19 tasks with 11 factors of variation to facilitate more controlled evaluations of generalization. From our study, we determine an ordering of factors based on generalization difficulty, that is consistent across simulation and our real robot setup.", "url": "https://arxiv.org/abs/2307.03659"}, {"metadata": {"arXiv": "2307.03705", "Date": "Fri, 07 Jul 2023 16:30:50 ", "Title": "Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations", "Authors": ["Zhongliang Jiang", "Yuan Bi", "Mingchuan Zhou", "Ying Hu", "Michael Burke and and Nassir Navab"], "Categories": "cs.RO cs.AI"}, "abstract": "Ultrasound (US) imaging is widely used for biometric measurement and diagnosis of internal organs due to the advantages of being real-time and radiation-free. However, due to high inter-operator variability, resulting images highly depend on operators' experience. In this work, an intelligent robotic sonographer is proposed to autonomously \"explore\" target anatomies and navigate a US probe to a relevant 2D plane by learning from expert. The underlying high-level physiological knowledge from experts is inferred by a neural reward function, using a ranked pairwise image comparisons approach in a self-supervised fashion. This process can be referred to as understanding the \"language of sonography\". Considering the generalization capability to overcome inter-patient variations, mutual information is estimated by a network to explicitly extract the task-related and domain features in latent space. Besides, a Gaussian distribution-based filter is developed to automatically evaluate and take the quality of the expert's demonstrations into account. The robotic localization is carried out in coarse-to-fine mode based on the predicted reward associated to B-mode images. To demonstrate the performance of the proposed approach, representative experiments for the \"line\" target and \"point\" target are performed on vascular phantom and two ex-vivo animal organ phantoms (chicken heart and lamb kidney), respectively. The results demonstrated that the proposed advanced framework can robustly work on different kinds of known and unseen phantoms.", "url": "https://arxiv.org/abs/2307.03705"}, {"metadata": {"arXiv": "2307.03380", "Date": "Fri, 07 Jul 2023 04:20:36 ", "Title": "On Formal Feature Attribution and Its Approximation", "Authors": ["Jinqiang Yu", "Alexey Ignatiev", "Peter J. Stuckey"], "Categories": "cs.AI cs.LG cs.LO"}, "abstract": "Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution problem. Additionally, a formal explanation despite being formally sound is typically quite large, which hampers its applicability in practical settings. Motivated by the above, this paper proposes a way to apply the apparatus of formal XAI to the case of feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over the existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper then proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to the existing feature attribution algorithms not only in terms of feature importance and but also in terms of their relative order.", "url": "https://arxiv.org/abs/2307.03380"}, {"metadata": {"arXiv": "2307.03212", "Date": "Thu, 06 Jul 2023 16:38:43 ", "Title": "Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings", "Authors": ["Weiliang Chan and Qianqian Ren"], "Categories": "cs.CV cs.AI cs.CY cs.LG"}, "abstract": "Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\\% improvement.", "url": "https://arxiv.org/abs/2307.03212"}, {"metadata": {"arXiv": "2307.03254", "Date": "Thu, 06 Jul 2023 19:08:56 ", "Title": "Vision Language Transformers: A Survey", "Authors": ["Clayton Fields", "Casey Kennington"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \\citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations and some open questions that remain.", "url": "https://arxiv.org/abs/2307.03254"}, {"metadata": {"arXiv": "2307.03197", "Date": "Tue, 04 Jul 2023 00:37:12 ", "Title": "Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks", "Authors": ["Aysha Thahsin Zahir Ismail", "Raj Mani Shukla"], "Categories": "cs.LG cs.AI"}, "abstract": "Distributed Collaborative Machine Learning (DCML) is a potential alternative to address the privacy concerns associated with centralized machine learning. The Split learning (SL) and Federated Learning (FL) are the two effective learning approaches in DCML. Recently there have been an increased interest on the hybrid of FL and SL known as the SplitFed Learning (SFL). This research is the earliest attempt to study, analyze and present the impact of data poisoning attacks in SFL. We propose three kinds of novel attack strategies namely untargeted, targeted and distance-based attacks for SFL. All the attacks strategies aim to degrade the performance of the DCML-based classifier. We test the proposed attack strategies for two different case studies on Electrocardiogram signal classification and automatic handwritten digit recognition. A series of attack experiments were conducted by varying the percentage of malicious clients and the choice of the model split layer between the clients and the server. The results after the comprehensive analysis of attack strategies clearly convey that untargeted and distance-based poisoning attacks have greater impacts in evading the classifier outcomes compared to targeted attacks in SFL", "url": "https://arxiv.org/abs/2307.03197"}, {"metadata": {"arXiv": "2307.03201", "Date": "Wed, 05 Jul 2023 15:32:21 ", "Title": "Scaling Laws Do Not Scale", "Authors": ["Fernando Diaz and Michael Madaio"], "Categories": "cs.LG cond-mat.dis-nn cs.AI cs.CY"}, "abstract": "Recent work has proposed a power law relationship, referred to as ``scaling laws,'' between the performance of artificial intelligence (AI) models and aspects of those models' design (e.g., dataset size). In other words, as the size of a dataset (or model parameters, etc) increases, the performance of a given model trained on that dataset will correspondingly increase. However, while compelling in the aggregate, this scaling law relationship overlooks the ways that metrics used to measure performance may be precarious and contested, or may not correspond with how different groups of people may perceive the quality of models' output. In this paper, we argue that as the size of datasets used to train large AI models grows, the number of distinct communities (including demographic groups) whose data is included in a given dataset is likely to grow, each of whom may have different values. As a result, there is an increased risk that communities represented in a dataset may have values or preferences not captured by (or in the worst case, at odds with) the metrics used to evaluate model performance for scaling laws. We end the paper with implications for AI scaling laws -- that models may not, in fact, continue to improve as the datasets get larger -- at least not for all people or communities impacted by those models.", "url": "https://arxiv.org/abs/2307.03201"}, {"metadata": {"arXiv": "2307.03305", "Date": "Thu, 06 Jul 2023 21:38:13 ", "Title": "A Vulnerability of Attribution Methods Using Pre-Softmax Scores", "Authors": ["Miguel Lerma and Mirtha Lucas"], "Categories": "cs.LG cs.AI", "Comments": ["7 pages", "5 figures,"], "MSC-class": "68T07", "ACM-class": "I.2.m"}, "abstract": "We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.", "url": "https://arxiv.org/abs/2307.03305"}, {"metadata": {"arXiv": "2307.03311", "Date": "Thu, 06 Jul 2023 21:49:04 ", "Title": "On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data", "Authors": ["Janis Keuper"], "Categories": "cs.LG cs.AI", "Comments": ["106 pages", "tech report"]}, "abstract": "The mathematical representations of data in the Spherical Harmonic (SH) domain has recently regained increasing interest in the machine learning community. This technical report gives an in-depth introduction to the theoretical foundation and practical implementation of SH representations, summarizing works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. In extension, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), providing the same capabilities for 3d vector fields on spheres", "url": "https://arxiv.org/abs/2307.03311"}, {"metadata": {"arXiv": "2307.03315", "Date": "Thu, 06 Jul 2023 22:02:33 ", "Title": "Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation", "Authors": ["Bing Xue", "Ahmed Sameh Said", "Ziqi Xu", "Hanyang Liu", "Neel Shah", "Hanqing Yang", "Philip Payne", "Chenyang Lu"], "Categories": "cs.LG cs.AI", "DOI": "10.1145/3580305.3599774"}, "abstract": "Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.", "url": "https://arxiv.org/abs/2307.03315"}, {"metadata": {"arXiv": "2307.03393", "Date": "Fri, 07 Jul 2023 05:31:31 ", "Title": "Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs", "Authors": ["Zhikai Chen", "Haitao Mao", "Hang Li", "Wei Jin", "Hongzhi Wen", "Xiaochi Wei", "Shuaiqiang Wang", "Dawei Yin", "Wenqi Fan", "Hui Liu", "Jiliang Tang"], "Categories": "cs.LG cs.AI"}, "abstract": "Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs.", "url": "https://arxiv.org/abs/2307.03393"}, {"metadata": {"arXiv": "2307.03406", "Date": "Fri, 07 Jul 2023 06:12:14 ", "Title": "Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning", "Authors": ["Zilai Zeng", "Ce Zhang", "Shijie Wang", "Chen Sun"], "Categories": "cs.LG cs.AI"}, "abstract": "Recent work has demonstrated the effectiveness of formulating decision making as a supervised learning problem on offline-collected trajectories. However, the benefits of performing sequence modeling on trajectory data is not yet clear. In this work we investigate if sequence modeling has the capability to condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques, and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an \"implicit planner\", and enables competitive performance on all three benchmarks.", "url": "https://arxiv.org/abs/2307.03406"}, {"metadata": {"arXiv": "2307.03486", "Date": "Fri, 07 Jul 2023 09:47:15 ", "Title": "Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning", "Authors": ["Seungyong Moon", "Junyoung Yeom", "Bumsoo Park", "Hyun Oh Song"], "Categories": "cs.LG cs.AI"}, "abstract": "Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the agent's capability to predict the next achievement. Our method exhibits a strong capacity for discovering hierarchical achievements and shows state-of-the-art performance on the challenging Crafter environment using fewer model parameters in a sample-efficient regime.", "url": "https://arxiv.org/abs/2307.03486"}, {"metadata": {"arXiv": "2307.03595", "Date": "Fri, 07 Jul 2023 13:38:16 ", "Title": "GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting", "Authors": ["Sitan Yang", "Malcolm Wolff", "Shankar Ramasubramanian", "Vincent Quenneville-Belair", "Ronak Metha", "Michael W. Mahoney"], "Categories": "cs.LG cs.AI"}, "abstract": "Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting, especially in real-world applications. However, to forecast accurately, these sophisticated models typically rely on a large number of time series examples with substantial history. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data -- often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships, and their generation process can be optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge-defined graphs, scaling to incorporate information from multiple very large graphs with millions of nodes. In our target application of demand forecasting for a large e-commerce retailer, we demonstrate on both a small dataset of 100K products and a large dataset with over 2 million products that our method improves overall performance over competitive baseline models. More importantly, we show that it brings substantially more gains to ``cold start'' products such as those newly launched or recently out-of-stock.", "url": "https://arxiv.org/abs/2307.03595"}, {"metadata": {"arXiv": "2307.03694", "Date": "Fri, 07 Jul 2023 16:07:00 ", "Title": "Scalable Membership Inference Attacks via Quantile Regression", "Authors": ["Martin Bertran", "Shuai Tang", "Michael Kearns", "Jamie Morgenstern", "Aaron Roth", "Zhiwei Steven Wu"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \\emph{shadow models} -- i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large. We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less compute because our attack requires training only a single model. Moreover, unlike shadow model attacks, our proposed attack does not require any knowledge of the architecture of the model under attack and is therefore truly ``black-box\". We show the efficacy of this approach in an extensive series of experiments on various datasets and model architectures.", "url": "https://arxiv.org/abs/2307.03694"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

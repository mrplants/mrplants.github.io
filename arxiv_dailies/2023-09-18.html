<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2309.07929", "Date": "Wed, 13 Sep 2023 05:43:35 ", "Title": "Prompting Segmentation with Sound is Generalizable Audio-Visual Source Localizer", "Authors": ["Yaoting Wang", "Weisong Liu", "Guangyao Li", "Jian Ding", "Di Hu", "Xi Li"], "Categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "Comments": ["12 pages", "7 figures", "submitted to AAAI 2024"]}, "abstract": "Never having seen an object and heard its sound simultaneously, can the model still accurately localize its visual position from the input audio? In this work, we concentrate on the Audio-Visual Localization and Segmentation tasks but under the demanding zero-shot and few-shot scenarios. To achieve this goal, different from existing approaches that mostly employ the encoder-fusion-decoder paradigm to decode localization information from the fused audio-visual feature, we introduce the encoder-prompt-decoder paradigm, aiming to better fit the data scarcity and varying data distribution dilemmas with the help of abundant knowledge from pre-trained models. Specifically, we first propose to construct Semantic-aware Audio Prompt (SAP) to help the visual foundation model focus on sounding objects, meanwhile, the semantic gap between the visual and audio modalities is also encouraged to shrink. Then, we develop a Correlation Adapter (ColA) to keep minimal training efforts as well as maintain adequate knowledge of the visual foundation model. By equipping with these means, extensive experiments demonstrate that this new paradigm outperforms other fusion-based methods in both the unseen class and cross-dataset settings. We hope that our work can further promote the generalization study of Audio-Visual Localization and Segmentation in practical application scenarios.", "url": "https://arxiv.org/abs/2309.07929"}, {"metadata": {"arXiv": "2309.08066", "Date": "Thu, 14 Sep 2023 23:28:58 ", "Title": "Morphologically-Aware Consensus Computation via Heuristics-based IterATive Optimization (MACCHIatO)", "Authors": ["Dimitri Hamzaoui", "Sarah Montagne", "Rapha\\\"ele Renard-Penna", "Nicholas Ayache", "Herv\\'e Delingette"], "Categories": "cs.CV cs.LG math.OC", "Comments": ["Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2023:013"], "Journal-ref": "Machine.Learning.for.Biomedical.Imaging. 2 (2023)", "DOI": "10.59275/j.melba.2023-219c"}, "abstract": "The extraction of consensus segmentations from several binary or probabilistic masks is important to solve various tasks such as the analysis of inter-rater variability or the fusion of several neural network outputs. One of the most widely used methods to obtain such a consensus segmentation is the STAPLE algorithm. In this paper, we first demonstrate that the output of that algorithm is heavily impacted by the background size of images and the choice of the prior. We then propose a new method to construct a binary or a probabilistic consensus segmentation based on the Fr\\'{e}chet means of carefully chosen distances which makes it totally independent of the image background size. We provide a heuristic approach to optimize this criterion such that a voxel's class is fully determined by its voxel-wise distance to the different masks, the connected component it belongs to and the group of raters who segmented it. We compared extensively our method on several datasets with the STAPLE method and the naive segmentation averaging method, showing that it leads to binary consensus masks of intermediate size between Majority Voting and STAPLE and to different posterior probabilities than Mask Averaging and STAPLE methods. Our code is available at https://gitlab.inria.fr/dhamzaou/jaccardmap .", "url": "https://arxiv.org/abs/2309.08066"}, {"metadata": {"arXiv": "2309.08159", "Date": "Fri, 15 Sep 2023 04:52:49 ", "Title": "AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness", "Authors": ["Liyao Jiang", "Chenglin Li", "Haolan Chen", "Xiaodong Gao", "Xinwang Zhong", "Yang Qiu", "Shani Ye", "Di Niu"], "Categories": "cs.CV cs.IR cs.LG", "Comments": ["Accepted to KDD 2023 Applied Data Science Track"], "DOI": "10.1145/3580305.3599770"}, "abstract": "Online advertisements are important elements in e-commerce sites, social media platforms, and search engines. With the increasing popularity of mobile browsing, many online ads are displayed with visual information in the form of a cover image in addition to text descriptions to grab the attention of users. Various recent studies have focused on predicting the click rates of online advertisements aware of visual features or composing optimal advertisement elements to enhance visibility. In this paper, we propose Advertisement Style Editing and Attractiveness Enhancement (AdSEE), which explores whether semantic editing to ads images can affect or alter the popularity of online advertisements. We introduce StyleGAN-based facial semantic editing and inversion to ads images and train a click rate predictor attributing GAN-based face latent representations in addition to traditional visual and textual features to click rates. Through a large collected dataset named QQ-AD, containing 20,527 online ads, we perform extensive offline tests to study how different semantic directions and their edit coefficients may impact click rates. We further design a Genetic Advertisement Editor to efficiently search for the optimal edit directions and intensity given an input ad cover image to enhance its projected click rates. Online A/B tests performed over a period of 5 days have verified the increased click-through rates of AdSEE-edited samples as compared to a control group of original ads, verifying the relation between image styles and ad popularity. We open source the code for AdSEE research at https://github.com/LiyaoJiang1998/adsee.", "url": "https://arxiv.org/abs/2309.08159"}, {"metadata": {"arXiv": "2309.08353", "Date": "Fri, 15 Sep 2023 12:25:42 ", "Title": "Continual Learning with Deep Streaming Regularized Discriminant Analysis", "Authors": ["Joe Khawand", "Peter Hanappe", "David Colliaux"], "Categories": "cs.CV cs.LG"}, "abstract": "Continual learning is increasingly sought after in real world machine learning applications, as it enables learning in a more human-like manner. Conventional machine learning approaches fail to achieve this, as incrementally updating the model with non-identically distributed data leads to catastrophic forgetting, where existing representations are overwritten. Although traditional continual learning methods have mostly focused on batch learning, which involves learning from large collections of labeled data sequentially, this approach is not well-suited for real-world applications where we would like new data to be integrated directly. This necessitates a paradigm shift towards streaming learning. In this paper, we propose a streaming version of regularized discriminant analysis as a solution to this challenge. We combine our algorithm with a convolutional neural network and demonstrate that it outperforms both batch learning and existing streaming learning algorithms on the ImageNet ILSVRC-2012 dataset.", "url": "https://arxiv.org/abs/2309.08353"}, {"metadata": {"arXiv": "2309.08586", "Date": "Fri, 15 Sep 2023 17:43:40 ", "Title": "Replacing softmax with ReLU in Vision Transformers", "Authors": ["Mitchell Wortsman", "Jaehoon Lee", "Justin Gilmer", "Simon Kornblith"], "Categories": "cs.CV cs.LG"}, "abstract": "Previous research observed accuracy degradation when replacing the attention softmax with a point-wise activation such as ReLU. In the context of vision transformers, we find that this degradation is mitigated when dividing by sequence length. Our experiments training small to large vision transformers on ImageNet-21k indicate that ReLU-attention can approach or match the performance of softmax-attention in terms of scaling behavior as a function of compute.", "url": "https://arxiv.org/abs/2309.08586"}, {"metadata": {"arXiv": "2309.07988", "Date": "Thu, 14 Sep 2023 19:01:08 ", "Title": "Folding Attention: Memory and Power Optimization for On-Device Transformer-based Streaming Speech Recognition", "Authors": ["Yang Li", "Liangzhen Lai", "Yuan Shangguan", "Forrest N. Iandola", "Ernie Chang", "Yangyang Shi", "Vikas Chandra"], "Categories": "cs.LG cs.AR cs.SD eess.AS"}, "abstract": "Transformer-based models excel in speech recognition. Existing efforts to optimize Transformer inference, typically for long-context applications, center on simplifying attention score calculations. However, streaming speech recognition models usually process a limited number of tokens each time, making attention score calculation less of a bottleneck. Instead, the bottleneck lies in the linear projection layers of multi-head attention and feedforward networks, constituting a substantial portion of the model size and contributing significantly to computation, memory, and power usage. To address this bottleneck, we propose folding attention, a technique targeting these linear layers, significantly reducing model size and improving memory and power efficiency. Experiments on on-device Transformer-based streaming speech recognition models show that folding attention reduces model size (and corresponding memory consumption) by up to 24% and power consumption by up to 23%, all without compromising model accuracy or computation overhead.", "url": "https://arxiv.org/abs/2309.07988"}, {"metadata": {"arXiv": "2309.08043", "Date": "Thu, 14 Sep 2023 22:10:09 ", "Title": "On Prediction Feature Assignment in the Heckman Selection Model", "Authors": ["Huy Mai", "Xintao Wu"], "Categories": "cs.LG stat.ME"}, "abstract": "Under missing-not-at-random (MNAR) sample selection bias, the performance of a prediction model is often degraded. This paper focuses on one classic instance of MNAR sample selection bias where a subset of samples have non-randomly missing outcomes. The Heckman selection model and its variants have commonly been used to handle this type of sample selection bias. The Heckman model uses two separate equations to model the prediction and selection of samples, where the selection features include all prediction features. When using the Heckman model, the prediction features must be properly chosen from the set of selection features. However, choosing the proper prediction features is a challenging task for the Heckman model. This is especially the case when the number of selection features is large. Existing approaches that use the Heckman model often provide a manually chosen set of prediction features. In this paper, we propose Heckman-FA as a novel data-driven framework for obtaining prediction features for the Heckman model. Heckman-FA first trains an assignment function that determines whether or not a selection feature is assigned as a prediction feature. Using the parameters of the trained function, the framework extracts a suitable set of prediction features based on the goodness-of-fit of the prediction model given the chosen prediction features and the correlation between noise terms of the prediction and selection equations. Experimental results on real-world datasets show that Heckman-FA produces a robust regression model under MNAR sample selection bias.", "url": "https://arxiv.org/abs/2309.08043"}, {"metadata": {"arXiv": "2309.08077", "Date": "Fri, 15 Sep 2023 00:26:21 ", "Title": "Supervised Stochastic Neighbor Embedding Using Contrastive Learning", "Authors": ["Yi Zhang"], "Categories": "cs.LG"}, "abstract": "Stochastic neighbor embedding (SNE) methods $t$-SNE, UMAP are two most popular dimensionality reduction methods for data visualization. Contrastive learning, especially self-supervised contrastive learning (SSCL), has showed great success in embedding features from unlabeled data. The conceptual connection between SNE and SSCL has been exploited. In this work, within the scope of preserving neighboring information of a dataset, we extend the self-supervised contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of samples belonging to the same class are pulled together in low-dimensional embedding space, while simultaneously pushing apart clusters of samples from different classes.", "url": "https://arxiv.org/abs/2309.08077"}, {"metadata": {"arXiv": "2309.08201", "Date": "Fri, 15 Sep 2023 07:05:33 ", "Title": "Gaussian Processes with Linear Multiple Kernel: Spectrum Design and Distributed Learning for Multi-Dimensional Data", "Authors": ["Richard Cornelius Suwandi", "Zhidi Lin", "Feng Yin"], "Categories": "cs.LG eess.SP math.OC"}, "abstract": "Gaussian processes (GPs) have emerged as a prominent technique for machine learning and signal processing. A key component in GP modeling is the choice of kernel, and linear multiple kernels (LMKs) have become an attractive kernel class due to their powerful modeling capacity and interpretability. This paper focuses on the grid spectral mixture (GSM) kernel, an LMK that can approximate arbitrary stationary kernels. Specifically, we propose a novel GSM kernel formulation for multi-dimensional data that reduces the number of hyper-parameters compared to existing formulations, while also retaining a favorable optimization structure and approximation capability. In addition, to make the large-scale hyper-parameter optimization in the GSM kernel tractable, we first introduce the distributed SCA (DSCA) algorithm. Building on this, we propose the doubly distributed SCA (D$^2$SCA) algorithm based on the alternating direction method of multipliers (ADMM) framework, which allows us to cooperatively learn the GSM kernel in the context of big data while maintaining data privacy. Furthermore, we tackle the inherent communication bandwidth restriction in distributed frameworks, by quantizing the hyper-parameters in D$^2$SCA, resulting in the quantized doubly distributed SCA (QD$^2$SCA) algorithm. Theoretical analysis establishes convergence guarantees for the proposed algorithms, while experiments on diverse datasets demonstrate the superior prediction performance and efficiency of our methods.", "url": "https://arxiv.org/abs/2309.08201"}, {"metadata": {"arXiv": "2309.08216", "Date": "Fri, 15 Sep 2023 07:30:15 ", "Title": "Unified Risk Analysis for Weakly Supervised Learning", "Authors": ["Chao-Kai Chiang", "Masashi Sugiyama"], "Categories": "cs.LG"}, "abstract": "Among the flourishing research of weakly supervised learning (WSL), we recognize the lack of a unified interpretation of the mechanism behind the weakly supervised scenarios, let alone a systematic treatment of the risk rewrite problem, a crucial step in the empirical risk minimization approach. In this paper, we introduce a framework providing a comprehensive understanding and a unified methodology for WSL. The formulation component of the framework, leveraging a contamination perspective, provides a unified interpretation of how weak supervision is formed and subsumes fifteen existing WSL settings. The induced reduction graphs offer comprehensive connections over WSLs. The analysis component of the framework, viewed as a decontamination process, provides a systematic method of conducting risk rewrite. In addition to the conventional inverse matrix approach, we devise a novel strategy called marginal chain aiming to decontaminate distributions. We justify the feasibility of the proposed framework by recovering existing rewrites reported in the literature.", "url": "https://arxiv.org/abs/2309.08216"}, {"metadata": {"arXiv": "2309.08228", "Date": "Fri, 15 Sep 2023 07:58:26 ", "Title": "Ensuring Toplogical Data-Structure Preservation under Autoencoder Compression due to Latent Space Regularization in Gauss--Legendre nodes", "Authors": ["Chethan Krishnamurthy Ramanaik", "Juan-Esteban Suarez Cardona", "Anna Willmann", "Pia Hanfeld", "Nico Hoffmann and Michael Hecht"], "Categories": "cs.LG math.DG"}, "abstract": "We formulate a data independent latent space regularisation constraint for general unsupervised autoencoders. The regularisation rests on sampling the autoencoder Jacobian in Legendre nodes, being the centre of the Gauss-Legendre quadrature. Revisiting this classic enables to prove that regularised autoencoders ensure a one-to-one re-embedding of the initial data manifold to its latent representation. Demonstrations show that prior proposed regularisation strategies, such as contractive autoencoding, cause topological defects already for simple examples, and so do convolutional based (variational) autoencoders. In contrast, topological preservation is ensured already by standard multilayer perceptron neural networks when being regularised due to our contribution. This observation extends through the classic FashionMNIST dataset up to real world encoding problems for MRI brain scans, suggesting that, across disciplines, reliable low dimensional representations of complex high-dimensional datasets can be delivered due to this regularisation technique.", "url": "https://arxiv.org/abs/2309.08228"}, {"metadata": {"arXiv": "2309.08249", "Date": "Fri, 15 Sep 2023 08:46:53 ", "Title": "Deep Nonnegative Matrix Factorization with Beta Divergences", "Authors": ["Valentin Leplat", "Le Thi Khanh Hien", "Akwum Onwunta", "Nicolas Gillis"], "Categories": "cs.LG cs.NA eess.SP math.NA stat.ML", "Comments": ["30 pages", "11 figures", "4 tables"]}, "abstract": "Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.", "url": "https://arxiv.org/abs/2309.08249"}, {"metadata": {"arXiv": "2309.08256", "Date": "Fri, 15 Sep 2023 09:06:23 ", "Title": "Sampling-Free Probabilistic Deep State-Space Models", "Authors": ["Andreas Look", "Melih Kandemir", "Barbara Rakitsch", "Jan Peters"], "Categories": "cs.LG stat.ML"}, "abstract": "Many real-world dynamical systems can be described as State-Space Models (SSMs). In this formulation, each observation is emitted by a latent state, which follows first-order Markovian dynamics. A Probabilistic Deep SSM (ProDSSM) generalizes this framework to dynamical systems of unknown parametric form, where the transition and emission models are described by neural networks with uncertain weights. In this work, we propose the first deterministic inference algorithm for models of this type. Our framework allows efficient approximations for training and testing. We demonstrate in our experiments that our new method can be employed for a variety of tasks and enjoys a superior balance between predictive performance and computational budget.", "url": "https://arxiv.org/abs/2309.08256"}, {"metadata": {"arXiv": "2309.08332", "Date": "Fri, 15 Sep 2023 11:41:23 ", "Title": "Estimation of Counterfactual Interventions under Uncertainties", "Authors": ["Juliane Weilbach", "Sebastian Gerwinn", "Melih Kandemir and Martin Fraenzle"], "Categories": "cs.LG stat.ME"}, "abstract": "Counterfactual analysis is intuitively performed by humans on a daily basis eg. \"What should I have done differently to get the loan approved?\". Such counterfactual questions also steer the formulation of scientific hypotheses. More formally it provides insights about potential improvements of a system by inferring the effects of hypothetical interventions into a past observation of the system's behaviour which plays a prominent role in a variety of industrial applications. Due to the hypothetical nature of such analysis, counterfactual distributions are inherently ambiguous. This ambiguity is particularly challenging in continuous settings in which a continuum of explanations exist for the same observation. In this paper, we address this problem by following a hierarchical Bayesian approach which explicitly models such uncertainty. In particular, we derive counterfactual distributions for a Bayesian Warped Gaussian Process thereby allowing for non-Gaussian distributions and non-additive noise. We illustrate the properties our approach on a synthetic and on a semi-synthetic example and show its performance when used within an algorithmic recourse downstream task.", "url": "https://arxiv.org/abs/2309.08332"}, {"metadata": {"arXiv": "2309.08339", "Date": "Fri, 15 Sep 2023 11:47:14 ", "Title": "Convergence of ADAM with Constant Step Size in Non-Convex Settings: A Simple Proof", "Authors": ["Alokendu Mazumder", "Bhartendu Kumar", "Manan Tayal", "Punit Rathore"], "Categories": "cs.LG math.OC", "Comments": ["9 pages including references and appendix"]}, "abstract": "In neural network training, RMSProp and ADAM remain widely favoured optimization algorithms. One of the keys to their performance lies in selecting the correct step size, which can significantly influence their effectiveness. It is worth noting that these algorithms performance can vary considerably, depending on the chosen step sizes. Additionally, questions about their theoretical convergence properties continue to be a subject of interest. In this paper, we theoretically analyze a constant stepsize version of ADAM in the non-convex setting. We show sufficient conditions for the stepsize to achieve almost sure asymptotic convergence of the gradients to zero with minimal assumptions. We also provide runtime bounds for deterministic ADAM to reach approximate criticality when working with smooth, non-convex functions.", "url": "https://arxiv.org/abs/2309.08339"}, {"metadata": {"arXiv": "2309.08374", "Date": "Fri, 15 Sep 2023 13:04:11 ", "Title": "Understanding the limitations of self-supervised learning for tabular anomaly detection", "Authors": ["Kimberly T. Mai", "Toby Davies", "Lewis D. Griffin"], "Categories": "cs.LG"}, "abstract": "While self-supervised learning has improved anomaly detection in computer vision and natural language processing, it is unclear whether tabular data can benefit from it. This paper explores the limitations of self-supervision for tabular anomaly detection. We conduct several experiments spanning various pretext tasks on 26 benchmark datasets to understand why this is the case. Our results confirm representations derived from self-supervision do not improve tabular anomaly detection performance compared to using the raw representations of the data. We show this is due to neural networks introducing irrelevant features, which reduces the effectiveness of anomaly detectors. However, we demonstrate that using a subspace of the neural network's representation can recover performance.", "url": "https://arxiv.org/abs/2309.08374"}, {"metadata": {"arXiv": "2309.08375", "Date": "Fri, 15 Sep 2023 13:04:55 ", "Title": "Adaptive Priority Reweighing for Generalizing Fairness Improvement", "Authors": ["Zhihao Hu", "Yiran Xu", "Mengnan Du", "Jindong Gu", "Xinmei Tian", "and Fengxiang He"], "Categories": "cs.LG cs.CY"}, "abstract": "With the increasing penetration of machine learning applications in critical decision-making areas, calls for algorithmic fairness are more prominent. Although there have been various modalities to improve algorithmic fairness through learning with fairness constraints, their performance does not generalize well in the test set. A performance-promising fair algorithm with better generalizability is needed. This paper proposes a novel adaptive reweighing method to eliminate the impact of the distribution shifts between training and test data on model generalizability. Most previous reweighing methods propose to assign a unified weight for each (sub)group. Rather, our method granularly models the distance from the sample predictions to the decision boundary. Our adaptive reweighing method prioritizes samples closer to the decision boundary and assigns a higher weight to improve the generalizability of fair classifiers. Extensive experiments are performed to validate the generalizability of our adaptive priority reweighing method for accuracy and fairness measures (i.e., equal opportunity, equalized odds, and demographic parity) in tabular benchmarks. We also highlight the performance of our method in improving the fairness of language and vision models. The code is available at https://github.com/che2198/APW.", "url": "https://arxiv.org/abs/2309.08375"}, {"metadata": {"arXiv": "2309.08385", "Date": "Fri, 15 Sep 2023 13:19:31 ", "Title": "A Unified View Between Tensor Hypergraph Neural Networks And Signal Denoising", "Authors": ["Fuli Wang", "Karelia Pena-Pena", "Wei Qian", "Gonzalo R. Arce"], "Categories": "cs.LG eess.SP", "Comments": ["5 pages", "accepted by EUSIPCO 2023"]}, "abstract": "Hypergraph Neural networks (HyperGNNs) and hypergraph signal denoising (HyperGSD) are two fundamental topics in higher-order network modeling. Understanding the connection between these two domains is particularly useful for designing novel HyperGNNs from a HyperGSD perspective, and vice versa. In particular, the tensor-hypergraph convolutional network (T-HGCN) has emerged as a powerful architecture for preserving higher-order interactions on hypergraphs, and this work shows an equivalence relation between a HyperGSD problem and the T-HGCN. Inspired by this intriguing result, we further design a tensor-hypergraph iterative network (T-HGIN) based on the HyperGSD problem, which takes advantage of a multi-step updating scheme in every single layer. Numerical experiments are conducted to show the promising applications of the proposed T-HGIN approach.", "url": "https://arxiv.org/abs/2309.08385"}, {"metadata": {"arXiv": "2309.08406", "Date": "Fri, 15 Sep 2023 14:08:09 ", "Title": "Constraint-Free Structure Learning with Smooth Acyclic Orientations", "Authors": ["Riccardo Massidda", "Francesco Landolfi", "Martina Cinquini", "Davide Bacciu"], "Categories": "cs.LG stat.ML"}, "abstract": "The structure learning problem consists of fitting data generated by a Directed Acyclic Graph (DAG) to correctly reconstruct its arcs. In this context, differentiable approaches constrain or regularize the optimization problem using a continuous relaxation of the acyclicity property. The computational cost of evaluating graph acyclicity is cubic on the number of nodes and significantly affects scalability. In this paper we introduce COSMO, a constraint-free continuous optimization scheme for acyclic structure learning. At the core of our method, we define a differentiable approximation of an orientation matrix parameterized by a single priority vector. Differently from previous work, our parameterization fits a smooth orientation matrix and the resulting acyclic adjacency matrix without evaluating acyclicity at any step. Despite the absence of explicit constraints, we prove that COSMO always converges to an acyclic solution. In addition to being asymptotically faster, our empirical analysis highlights how COSMO performance on graph reconstruction compares favorably with competing structure learning methods.", "url": "https://arxiv.org/abs/2309.08406"}, {"metadata": {"arXiv": "2309.08414", "Date": "Fri, 15 Sep 2023 14:18:21 ", "Title": "Make Deep Networks Shallow Again", "Authors": ["Bernhard Bermeitinger", "Tomas Hrycej", "Siegfried Handschuh"], "Categories": "cs.LG", "Comments": ["to be published at KDIR2023", "Rome"]}, "abstract": "Deep neural networks have a good success record and are thus viewed as the best architecture choice for complex applications. Their main shortcoming has been, for a long time, the vanishing gradient which prevented the numerical optimization algorithms from acceptable convergence. A breakthrough has been achieved by the concept of residual connections -- an identity mapping parallel to a conventional layer. This concept is applicable to stacks of layers of the same dimension and substantially alleviates the vanishing gradient problem. A stack of residual connection layers can be expressed as an expansion of terms similar to the Taylor expansion. This expansion suggests the possibility of truncating the higher-order terms and receiving an architecture consisting of a single broad layer composed of all initially stacked layers in parallel. In other words, a sequential deep architecture is substituted by a parallel shallow one. Prompted by this theory, we investigated the performance capabilities of the parallel architecture in comparison to the sequential one. The computer vision datasets MNIST and CIFAR10 were used to train both architectures for a total of 6912 combinations of varying numbers of convolutional layers, numbers of filters, kernel sizes, and other meta parameters. Our findings demonstrate a surprising equivalence between the deep (sequential) and shallow (parallel) architectures. Both layouts produced similar results in terms of training and validation set loss. This discovery implies that a wide, shallow architecture can potentially replace a deep network without sacrificing performance. Such substitution has the potential to simplify network architectures, improve optimization efficiency, and accelerate the training process.", "url": "https://arxiv.org/abs/2309.08414"}, {"metadata": {"arXiv": "2309.08415", "Date": "Fri, 15 Sep 2023 14:18:53 ", "Title": "A new method of modeling the multi-stage decision-making process of CRT using machine learning with uncertainty quantification", "Authors": ["Kristoffer Larsena", "Chen Zhao", "Joyce Keyak", "Qiuying Sha", "Diana Paezd", "Xinwei Zhang", "Jiangang Zou", "Amalia Peixf", "Weihua Zhou"], "Categories": "cs.LG eess.SP physics.med-ph", "Comments": ["26 pages,5 figures. arXiv admin note: text overlap with arXiv:2305.02475"]}, "abstract": "Aims. The purpose of this study is to create a multi-stage machine learning model to predict cardiac resynchronization therapy (CRT) response for heart failure (HF) patients. This model exploits uncertainty quantification to recommend additional collection of single-photon emission computed tomography myocardial perfusion imaging (SPECT MPI) variables if baseline clinical variables and features from electrocardiogram (ECG) are not sufficient. Methods. 218 patients who underwent rest-gated SPECT MPI were enrolled in this study. CRT response was defined as an increase in left ventricular ejection fraction (LVEF) > 5% at a 6 month follow-up. A multi-stage ML model was created by combining two ensemble models. Results. The response rate for CRT was 55.5% (n = 121) with overall male gender 61.0% (n = 133), an average age of 62.0, and LVEF of 27.7. The multi-stage model performed similarly to Ensemble 2 (which utilized the additional SPECT data) with AUC of 0.75 vs. 0.77, accuracy of 0.71 vs. 0.69, sensitivity of 0.70 vs. 0.72, and specificity 0.72 vs. 0.65, respectively. However, the multi-stage model only required SPECT MPI data for 52.7% of the patients across all folds. Conclusions. By using rule-based logic stemming from uncertainty quantification, the multi-stage model was able to reduce the need for additional SPECT MPI data acquisition without sacrificing performance.", "url": "https://arxiv.org/abs/2309.08415"}, {"metadata": {"arXiv": "2309.08420", "Date": "Fri, 15 Sep 2023 14:23:20 ", "Title": "FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning", "Authors": ["Hongyu Zhang", "Dongyi Zheng", "Xu Yang", "Jiyuan Feng", "Qing Liao"], "Categories": "cs.LG cs.IR"}, "abstract": "Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design an intra domain contrastive infomax (CIM) strategy to learn richer domain-exclusive features of users by performing data augmentation on user sequences. Extensive experiments on three real-world scenarios demonstrate that FedDCSR achieves significant improvements over existing baselines.", "url": "https://arxiv.org/abs/2309.08420"}, {"metadata": {"arXiv": "2309.08520", "Date": "Fri, 15 Sep 2023 16:29:27 ", "Title": "Scaling Laws for Sparsely-Connected Foundation Models", "Authors": ["Elias Frantar", "Carlos Riquelme", "Neil Houlsby", "Dan Alistarh", "Utku Evci"], "Categories": "cs.LG"}, "abstract": "We explore the impact of parameter sparsity on the scaling behavior of Transformers trained on massive datasets (i.e., \"foundation models\"), in both vision and language domains. In this setting, we identify the first scaling law describing the relationship between weight sparsity, number of non-zero parameters, and amount of training data, which we validate empirically across model and data scales; on ViT/JFT-4B and T5/C4. These results allow us to characterize the \"optimal sparsity\", the sparsity level which yields the best performance for a given effective model size and training budget. For a fixed number of non-zero parameters, we identify that the optimal sparsity increases with the amount of data used for training. We also extend our study to different sparsity structures (such as the hardware-friendly n:m pattern) and strategies (such as starting from a pretrained dense model). Our findings shed light on the power and limitations of weight sparsity across various parameter and computational settings, offering both theoretical understanding and practical implications for leveraging sparsity towards computational efficiency improvements.", "url": "https://arxiv.org/abs/2309.08520"}, {"metadata": {"arXiv": "2309.08534", "Date": "Fri, 15 Sep 2023 16:52:29 ", "Title": "Towards Last-layer Retraining for Group Robustness with Fewer Annotations", "Authors": ["Tyler LaBonte", "Vidya Muthukumar", "Abhishek Kumar"], "Categories": "cs.LG"}, "abstract": "Empirical risk minimization (ERM) of neural networks is prone to over-reliance on spurious correlations and poor generalization on minority groups. The recent deep feature reweighting (DFR) technique achieves state-of-the-art group robustness via simple last-layer retraining, but it requires held-out group and class annotations to construct a group-balanced reweighting dataset. In this work, we examine this impractical requirement and find that last-layer retraining can be surprisingly effective with no group annotations (other than for model selection) and only a handful of class annotations. We first show that last-layer retraining can greatly improve worst-group accuracy even when the reweighting dataset has only a small proportion of worst-group data. This implies a \"free lunch\" where holding out a subset of training data to retrain the last layer can substantially outperform ERM on the entire dataset with no additional data or annotations. To further improve group robustness, we introduce a lightweight method called selective last-layer finetuning (SELF), which constructs the reweighting dataset using misclassifications or disagreements. Our empirical and theoretical results present the first evidence that model disagreement upsamples worst-group data, enabling SELF to nearly match DFR on four well-established benchmarks across vision and language tasks with no group annotations and less than 3% of the held-out class annotations. Our code is available at https://github.com/tmlabonte/last-layer-retraining.", "url": "https://arxiv.org/abs/2309.08534"}, {"metadata": {"arXiv": "2309.08545", "Date": "Fri, 15 Sep 2023 17:10:19 ", "Title": "Efficient and robust Sensor Placement in Complex Environments", "Authors": ["Lukas Taus", "Yen-Hsi Richard Tsai"], "Categories": "cs.LG cs.RO math.OC"}, "abstract": "We address the problem of efficient and unobstructed surveillance or communication in complex environments. On one hand, one wishes to use a minimal number of sensors to cover the environment. On the other hand, it is often important to consider solutions that are robust against sensor failure or adversarial attacks. This paper addresses these challenges of designing minimal sensor sets that achieve multi-coverage constraints -- every point in the environment is covered by a prescribed number of sensors. We propose a greedy algorithm to achieve the objective. Further, we explore deep learning techniques to accelerate the evaluation of the objective function formulated in the greedy algorithm. The training of the neural network reveals that the geometric properties of the data significantly impact the network's performance, particularly at the end stage. By taking into account these properties, we discuss the differences in using greedy and $\\epsilon$-greedy algorithms to generate data and their impact on the robustness of the network.", "url": "https://arxiv.org/abs/2309.08545"}, {"metadata": {"arXiv": "2309.08546", "Date": "Fri, 15 Sep 2023 17:10:51 ", "Title": "Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization", "Authors": ["Jack Foster and Alexandra Brintrup"], "Categories": "cs.LG"}, "abstract": "The pursuit of long-term autonomy mandates that robotic agents must continuously adapt to their changing environments and learn to solve new tasks. Continual learning seeks to overcome the challenge of catastrophic forgetting, where learning to solve new tasks causes a model to forget previously learnt information. Prior-based continual learning methods are appealing for robotic applications as they are space efficient and typically do not increase in computational complexity as the number of tasks grows. Despite these desirable properties, prior-based approaches typically fail on important benchmarks and consequently are limited in their potential applications compared to their memory-based counterparts. We introduce Bayesian adaptive moment regularization (BAdam), a novel prior-based method that better constrains parameter growth, leading to lower catastrophic forgetting. Our method boasts a range of desirable properties for robotic applications such as being lightweight and task label-free, converging quickly, and offering calibrated uncertainty that is important for safe real-world deployment. Results show that BAdam achieves state-of-the-art performance for prior-based methods on challenging single-headed class-incremental experiments such as Split MNIST and Split FashionMNIST, and does so without relying on task labels or discrete task boundaries.", "url": "https://arxiv.org/abs/2309.08546"}, {"metadata": {"arXiv": "2309.08569", "Date": "Fri, 15 Sep 2023 17:35:51 ", "Title": "Local Differential Privacy in Graph Neural Networks: a Reconstruction Approach", "Authors": ["Karuna Bhaila and Wen Huang and Yongkai Wu and Xintao Wu"], "Categories": "cs.LG cs.CR"}, "abstract": "Graph Neural Networks have achieved tremendous success in modeling complex graph data in a variety of applications. However, there are limited studies investigating privacy protection in GNNs. In this work, we propose a learning framework that can provide node privacy at the user level, while incurring low utility loss. We focus on a decentralized notion of Differential Privacy, namely Local Differential Privacy, and apply randomization mechanisms to perturb both feature and label data at the node level before the data is collected by a central server for model training. Specifically, we investigate the application of randomization mechanisms in high-dimensional feature settings and propose an LDP protocol with strict privacy guarantees. Based on frequency estimation in statistical analysis of randomized data, we develop reconstruction methods to approximate features and labels from perturbed data. We also formulate this learning framework to utilize frequency estimates of graph clusters to supervise the training procedure at a sub-graph level. Extensive experiments on real-world and semi-synthetic datasets demonstrate the validity of our proposed model.", "url": "https://arxiv.org/abs/2309.08569"}, {"metadata": {"arXiv": "2309.08571", "Date": "Fri, 15 Sep 2023 17:37:09 ", "Title": "A Bayesian Approach to Robust Inverse Reinforcement Learning", "Authors": ["Ran Wei", "Siliang Zeng", "Chenliang Li", "Alfredo Garcia", "Anthony McDonald", "Mingyi Hong"], "Categories": "cs.LG"}, "abstract": "We consider a Bayesian approach to offline model-based inverse reinforcement learning (IRL). The proposed framework differs from existing offline model-based IRL approaches by performing simultaneous estimation of the expert's reward function and subjective model of environment dynamics. We make use of a class of prior distributions which parameterizes how accurate the expert's model of the environment is to develop efficient algorithms to estimate the expert's reward and subjective dynamics in high-dimensional settings. Our analysis reveals a novel insight that the estimated policy exhibits robust performance when the expert is believed (a priori) to have a highly accurate model of the environment. We verify this observation in the MuJoCo environments and show that our algorithms outperform state-of-the-art offline IRL algorithms.", "url": "https://arxiv.org/abs/2309.08571"}, {"metadata": {"arXiv": "2309.08593", "Date": "Fri, 15 Sep 2023 17:47:45 ", "Title": "Attention-Only Transformers and Implementing MLPs with Attention Heads", "Authors": ["Robert Huben and Valerie Morris"], "Categories": "cs.LG", "Comments": ["11 pages"]}, "abstract": "The transformer architecture is widely used in machine learning models and consists of two alternating sublayers: attention heads and MLPs. We prove that an MLP neuron can be implemented by a masked attention head with internal dimension 1 so long as the MLP's activation function comes from a restricted class including SiLU and close approximations of ReLU and GeLU. This allows one to convert an MLP-and-attention transformer into an attention-only transformer at the cost of greatly increasing the number of attention heads. We also prove that attention heads can perform the components of an MLP (linear transformations and activation functions) separately. Finally, we prove that attention heads can encode arbitrary masking patterns in their weight matrices to within arbitrarily small error.", "url": "https://arxiv.org/abs/2309.08593"}, {"metadata": {"arXiv": "2309.08600", "Date": "Fri, 15 Sep 2023 17:56:55 ", "Title": "Sparse Autoencoders Find Highly Interpretable Features in Language Models", "Authors": ["Hoagy Cunningham", "Aidan Ewart", "Logan Riggs", "Robert Huben", "Lee Sharkey"], "Categories": "cs.LG cs.CL", "Comments": ["21 pages", "20 figures", "2 tables"]}, "abstract": "One of the roadblocks to a better understanding of neural networks' internals is \\textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \\textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Ablating these features enables precise model editing, for example, by removing capabilities such as pronoun prediction, while disrupting model behaviour less than prior techniques. This work indicates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our method may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability.", "url": "https://arxiv.org/abs/2309.08600"}, {"metadata": {"arXiv": "2309.08399", "Date": "Fri, 15 Sep 2023 13:50:21 ", "Title": "Optimizing Modular Robot Composition: A Lexicographic Genetic Algorithm Approach", "Authors": ["Jonathan K\\\"ulz and Matthias Althoff"], "Categories": "cs.RO cs.LG cs.NE"}, "abstract": "Industrial robots are designed as general-purpose hardware, which limits their ability to adapt to changing task requirements or environments. Modular robots, on the other hand, offer flexibility and can be easily customized to suit diverse needs. The morphology, i.e., the form and structure of a robot, significantly impacts the primary performance metrics acquisition cost, cycle time, and energy efficiency. However, identifying an optimal module composition for a specific task remains an open problem, presenting a substantial hurdle in developing task-tailored modular robots. Previous approaches either lack adequate exploration of the design space or the possibility to adapt to complex tasks. We propose combining a genetic algorithm with a lexicographic evaluation of solution candidates to overcome this problem and navigate search spaces exceeding those in prior work by magnitudes in the number of possible compositions. We demonstrate that our approach outperforms a state-of-the-art baseline and is able to synthesize modular robots for industrial tasks in cluttered environments.", "url": "https://arxiv.org/abs/2309.08399"}, {"metadata": {"arXiv": "2309.08021", "Date": "Thu, 14 Sep 2023 20:34:30 ", "Title": "Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol", "Authors": ["Ross Greer", "Akshay Gopalkrishnan", "Sumega Mandadi", "Pujitha Gunaratne", "Mohan M. Trivedi", "Thomas D. Marcotte"], "Categories": "cs.CV cs.AI"}, "abstract": "About 30% of all traffic crash fatalities in the United States involve drunk drivers, making the prevention of drunk driving paramount to vehicle safety in the US and other locations which have a high prevalence of driving while under the influence of alcohol. Driving impairment can be monitored through active use of sensors (when drivers are asked to engage in providing breath samples to a vehicle instrument or when pulled over by a police officer), but a more passive and robust mechanism of sensing may allow for wider adoption and benefit of intelligent systems that reduce drunk driving accidents. This could assist in identifying impaired drivers before they drive, or early in the driving process (before a crash or detection by law enforcement). In this research, we introduce a study which adopts a multi-modal ensemble of visual, thermal, audio, and chemical sensors to (1) examine the impact of acute alcohol administration on driving performance in a driving simulator, and (2) identify data-driven methods for detecting driving under the influence of alcohol. We describe computer vision and machine learning models for analyzing the driver's face in thermal imagery, and introduce a pipeline for training models on data collected from drivers with a range of breath-alcohol content levels, including discussion of relevant machine learning phenomena which can help in future experiment design for related studies.", "url": "https://arxiv.org/abs/2309.08021"}, {"metadata": {"arXiv": "2309.08036", "Date": "Thu, 14 Sep 2023 21:54:23 ", "Title": "BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture", "Authors": ["Syed Sha Qutub and Neslihan Kose and Rafael Rosales and Michael Paulitsch and Korbinian Hagn and Florian Geissler and Yang Peng and Gereon Hinz and Alois Knoll"], "Categories": "cs.CV cs.AI", "Comments": ["14 pages", "5 pages supplementary material. Accepted at BMVC2023"], "MSC-class": "68T07, 68T37"}, "abstract": "This paper introduces the Budding Ensemble Architecture (BEA), a novel reduced ensemble architecture for anchor-based object detection models. Object detection models are crucial in vision-based tasks, particularly in autonomous systems. They should provide precise bounding box detections while also calibrating their predicted confidence scores, leading to higher-quality uncertainty estimates. However, current models may make erroneous decisions due to false positives receiving high scores or true positives being discarded due to low scores. BEA aims to address these issues. The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives and, eventually, higher accuracy of the object detection models. Both Base-YOLOv3 and SSD models were enhanced using the BEA method and its proposed loss functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6% and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanced uncertainty estimation threshold to discard samples in real-time even leads to a 9.6% higher AP50 than its base model. This is attributed to a 40% increase in the area under the AP50-based retention curve used to measure the quality of calibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTI provides superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets compared to the ensembles and vanilla models of YOLOv3 and Gaussian-YOLOv3.", "url": "https://arxiv.org/abs/2309.08036"}, {"metadata": {"arXiv": "2309.08042", "Date": "Thu, 14 Sep 2023 22:02:14 ", "Title": "Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved", "Authors": ["Yao Sun", "Anna Kruspe", "Liqiu Meng", "Yifan Tian", "Eike J Hoffmann", "Stefan Auer", "Xiao Xiang Zhu"], "Categories": "cs.CV cs.AI"}, "abstract": "Crowdsourced platforms provide huge amounts of street-view images that contain valuable building information. This work addresses the challenges in applying Scene Text Recognition (STR) in crowdsourced street-view images for building attribute mapping. We use Flickr images, particularly examining texts on building facades. A Berlin Flickr dataset is created, and pre-trained STR models are used for text detection and recognition. Manual checking on a subset of STR-recognized images demonstrates high accuracy. We examined the correlation between STR results and building functions, and analysed instances where texts were recognized on residential buildings but not on commercial ones. Further investigation revealed significant challenges associated with this task, including small text regions in street-view images, the absence of ground truth labels, and mismatches in buildings in Flickr images and building footprints in OpenStreetMap (OSM). To develop city-wide mapping beyond urban hotspot locations, we suggest differentiating the scenarios where STR proves effective while developing appropriate algorithms or bringing in additional data for handling other cases. Furthermore, interdisciplinary collaboration should be undertaken to understand the motivation behind building photography and labeling. The STR-on-Flickr results are publicly available at https://github.com/ya0-sun/STR-Berlin.", "url": "https://arxiv.org/abs/2309.08042"}, {"metadata": {"arXiv": "2309.08048", "Date": "Thu, 14 Sep 2023 22:20:57 ", "Title": "Padding Aware Neurons", "Authors": ["Dario Garcia-Gasulla and Victor Gimenez-Abalos and Pablo Martin-Torres"], "Categories": "cs.CV cs.AI", "Comments": ["In 4th Visual Inductive Priors for Data-Efficient Deep Learning Workshop", "ICCV 2023"]}, "abstract": "Convolutional layers are a fundamental component of most image-related models. These layers often implement by default a static padding policy (\\eg zero padding), to control the scale of the internal representations, and to allow kernel activations centered on the border regions. In this work we identify Padding Aware Neurons (PANs), a type of filter that is found in most (if not all) convolutional models trained with static padding. PANs focus on the characterization and recognition of input border location, introducing a spatial inductive bias into the model (e.g., how close to the input's border a pattern typically is). We propose a method to identify PANs through their activations, and explore their presence in several popular pre-trained models, finding PANs on all models explored, from dozens to hundreds. We discuss and illustrate different types of PANs, their kernels and behaviour. To understand their relevance, we test their impact on model performance, and find padding and PANs to induce strong and characteristic biases in the data. Finally, we discuss whether or not PANs are desirable, as well as the potential side effects of their presence in the context of model performance, generalisation, efficiency and safety.", "url": "https://arxiv.org/abs/2309.08048"}, {"metadata": {"arXiv": "2309.08365", "Date": "Fri, 15 Sep 2023 12:46:14 ", "Title": "M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection", "Authors": ["Yao Yuan", "Pan Gao", "XiaoYang Tan"], "Categories": "cs.CV cs.AI"}, "abstract": "Most existing salient object detection methods mostly use U-Net or feature pyramid structure, which simply aggregates feature maps of different scales, ignoring the uniqueness and interdependence of them and their respective contributions to the final prediction. To overcome these, we propose the M$^3$Net, i.e., the Multilevel, Mixed and Multistage attention network for Salient Object Detection (SOD). Firstly, we propose Multiscale Interaction Block which innovatively introduces the cross-attention approach to achieve the interaction between multilevel features, allowing high-level features to guide low-level feature learning and thus enhancing salient regions. Secondly, considering the fact that previous Transformer based SOD methods locate salient regions only using global self-attention while inevitably overlooking the details of complex objects, we propose the Mixed Attention Block. This block combines global self-attention and window self-attention, aiming at modeling context at both global and local levels to further improve the accuracy of the prediction map. Finally, we proposed a multilevel supervision strategy to optimize the aggregated feature stage-by-stage. Experiments on six challenging datasets demonstrate that the proposed M$^3$Net surpasses recent CNN and Transformer-based SOD arts in terms of four metrics. Codes are available at https://github.com/I2-Multimedia-Lab/M3Net.", "url": "https://arxiv.org/abs/2309.08365"}, {"metadata": {"arXiv": "2309.08513", "Date": "Fri, 15 Sep 2023 16:19:09 ", "Title": "SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels", "Authors": ["Henry Hengyuan Zhao", "Pichao Wang", "Yuyang Zhao", "Hao Luo", "Fan Wang", "Mike Zheng Shou"], "Categories": "cs.CV cs.AI", "Comments": ["This work has been accepted by IJCV2023"]}, "abstract": "Pre-trained vision transformers have strong representation benefits to various downstream tasks. Recently, many parameter-efficient fine-tuning (PEFT) methods have been proposed, and their experiments demonstrate that tuning only 1% of extra parameters could surpass full fine-tuning in low-data resource scenarios. However, these methods overlook the task-specific information when fine-tuning diverse downstream tasks. In this paper, we propose a simple yet effective method called \"Salient Channel Tuning\" (SCT) to leverage the task-specific information by forwarding the model with the task images to select partial channels in a feature map that enables us to tune only 1/8 channels leading to significantly lower parameter costs. Experiments outperform full fine-tuning on 18 out of 19 tasks in the VTAB-1K benchmark by adding only 0.11M parameters of the ViT-B, which is 780$\\times$ fewer than its full fine-tuning counterpart. Furthermore, experiments on domain generalization and few-shot learning surpass other PEFT methods with lower parameter costs, demonstrating our proposed tuning technique's strong capability and effectiveness in the low-data regime.", "url": "https://arxiv.org/abs/2309.08513"}, {"metadata": {"arXiv": "2309.08535", "Date": "Fri, 15 Sep 2023 16:53:01 ", "Title": "Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model", "Authors": ["Jeong Hun Yeo", "Minsu Kim", "Shinji Watanabe", "Yong Man Ro"], "Categories": "cs.CV cs.AI eess.AS"}, "abstract": "This paper proposes a powerful Visual Speech Recognition (VSR) method for multiple languages, especially for low-resource languages that have a limited number of labeled data. Different from previous methods that tried to improve the VSR performance for the target language by using knowledge learned from other languages, we explore whether we can increase the amount of training data itself for the different languages without human intervention. To this end, we employ a Whisper model which can conduct both language identification and audio-based speech recognition. It serves to filter data of the desired languages and transcribe labels from the unannotated, multilingual audio-visual data pool. By comparing the performances of VSR models trained on automatic labels and the human-annotated labels, we show that we can achieve similar VSR performance to that of human-annotated labels even without utilizing human annotations. Through the automated labeling process, we label large-scale unlabeled multilingual databases, VoxCeleb2 and AVSpeech, producing 1,002 hours of data for four low VSR resource languages, French, Italian, Spanish, and Portuguese. With the automatic labels, we achieve new state-of-the-art performance on mTEDx in four languages, significantly surpassing the previous methods. The automatic labels are available online: https://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages", "url": "https://arxiv.org/abs/2309.08535"}, {"metadata": {"arXiv": "2309.08106", "Date": "Fri, 15 Sep 2023 02:03:59 ", "Title": "Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques", "Authors": ["Zihang Su", "Tianshi Yu", "Nir Lipovetzky", "Alireza Mohammadi", "Denny Oetomo", "Artem Polyvyanyy", "Sebastian Sardina", "Ying Tan", "Nick van Beest"], "Categories": "cs.RO cs.AI cs.CV", "Comments": ["The 5th International Conference on Process Mining (ICPM 2023)"], "ACM-class": "I.2.4; I.2.9"}, "abstract": "A transhumeral prosthesis restores missing anatomical segments below the shoulder, including the hand. Active prostheses utilize real-valued, continuous sensor data to recognize patient target poses, or goals, and proactively move the artificial limb. Previous studies have examined how well the data collected in stationary poses, without considering the time steps, can help discriminate the goals. In this case study paper, we focus on using time series data from surface electromyography electrodes and kinematic sensors to sequentially recognize patients' goals. Our approach involves transforming the data into discrete events and training an existing process mining-based goal recognition system. Results from data collected in a virtual reality setting with ten subjects demonstrate the effectiveness of our proposed goal recognition approach, which achieves significantly better precision and recall than the state-of-the-art machine learning techniques and is less confident when wrong, which is beneficial when approximating smoother movements of prostheses.", "url": "https://arxiv.org/abs/2309.08106"}, {"metadata": {"arXiv": "2309.08138", "Date": "Fri, 15 Sep 2023 04:07:57 ", "Title": "Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation", "Authors": ["Hongcheng Wang", "Andy Guan Hong Chen", "Xiaoqi Li", "Mingdong Wu", "Hao Dong"], "Categories": "cs.RO cs.AI"}, "abstract": "The task of Visual Object Navigation (VON) involves an agent's ability to locate a particular object within a given scene. In order to successfully accomplish the VON task, two essential conditions must be fulfilled:1) the user must know the name of the desired object; and 2) the user-specified object must actually be present within the scene. To meet these conditions, a simulator can incorporate pre-defined object names and positions into the metadata of the scene. However, in real-world scenarios, it is often challenging to ensure that these conditions are always met. Human in an unfamiliar environment may not know which objects are present in the scene, or they may mistakenly specify an object that is not actually present. Nevertheless, despite these challenges, human may still have a demand for an object, which could potentially be fulfilled by other objects present within the scene in an equivalent manner. Hence, we propose Demand-driven Navigation (DDN), which leverages the user's demand as the task instruction and prompts the agent to find the object matches the specified demand. DDN aims to relax the stringent conditions of VON by focusing on fulfilling the user's demand rather than relying solely on predefined object categories or names. We propose a method first acquire textual attribute features of objects by extracting common knowledge from a large language model. These textual attribute features are subsequently aligned with visual attribute features using Contrastive Language-Image Pre-training (CLIP). By incorporating the visual attribute features as prior knowledge, we enhance the navigation process. Experiments on AI2Thor with the ProcThor dataset demonstrate the visual attribute features improve the agent's navigation performance and outperform the baseline methods commonly used in VON.", "url": "https://arxiv.org/abs/2309.08138"}, {"metadata": {"arXiv": "2309.07930", "Date": "Wed, 13 Sep 2023 08:21:59 ", "Title": "Generative AI", "Authors": ["Stefan Feuerriegel and Jochen Hartmann and Christian Janiesch and Patrick Zschech"], "Categories": "cs.AI cs.LG", "Comments": ["Published in Business & Information Systems Engineering (2023)"], "DOI": "10.1007/s12599-023-00834-7"}, "abstract": "The term \"generative AI\" refers to computational techniques that are capable of generating seemingly new, meaningful content such as text, images, or audio from training data. The widespread diffusion of this technology with examples such as Dall-E 2, GPT-4, and Copilot is currently revolutionizing the way we work and communicate with each other. In this article, we provide a conceptualization of generative AI as an entity in socio-technical systems and provide examples of models, systems, and applications. Based on that, we introduce limitations of current generative AI and provide an agenda for Business & Information Systems Engineering (BISE) research. Different from previous works, we focus on generative AI in the context of information systems, and, to this end, we discuss several opportunities and challenges that are unique to the BISE community and make suggestions for impactful directions for BISE research.", "url": "https://arxiv.org/abs/2309.07930"}, {"metadata": {"arXiv": "2309.07947", "Date": "Thu, 14 Sep 2023 15:17:42 ", "Title": "TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging Analysis", "Authors": ["Xiangzhu Meng", "Wei Wei", "Qiang Liu", "Shu Wu", "Liang Wang"], "Categories": "cs.AI cs.LG"}, "abstract": "In recent years, functional magnetic resonance imaging has emerged as a powerful tool for investigating the human brain's functional connectivity networks. Related studies demonstrate that functional connectivity networks in the human brain can help to improve the efficiency of diagnosing neurological disorders. However, there still exist two challenges that limit the progress of functional neuroimaging. Firstly, there exists an abundance of noise and redundant information in functional connectivity data, resulting in poor performance. Secondly, existing brain network models have tended to prioritize either classification performance or the interpretation of neuroscience findings behind the learned models. To deal with these challenges, this paper proposes a novel brain graph learning framework called Template-induced Brain Graph Learning (TiBGL), which has both discriminative and interpretable abilities. Motivated by the related medical findings on functional connectivites, TiBGL proposes template-induced brain graph learning to extract template brain graphs for all groups. The template graph can be regarded as an augmentation process on brain networks that removes noise information and highlights important connectivity patterns. To simultaneously support the tasks of discrimination and interpretation, TiBGL further develops template-induced convolutional neural network and template-induced brain interpretation analysis. Especially, the former fuses rich information from brain graphs and template brain graphs for brain disorder tasks, and the latter can provide insightful connectivity patterns related to brain disorders based on template brain graphs. Experimental results on three real-world datasets show that the proposed TiBGL can achieve superior performance compared with nine state-of-the-art methods and keep coherent with neuroscience findings in recent literatures.", "url": "https://arxiv.org/abs/2309.07947"}, {"metadata": {"arXiv": "2309.08254", "Date": "Fri, 15 Sep 2023 09:02:16 ", "Title": "Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles", "Authors": ["Laura Ferrarotti", "Massimiliano Luca", "Gabriele Santin", "Giorgio Previati", "Gianpiero Mastinu", "Elena Campi", "Lorenzo Uccello", "Antonino Albanese", "Praveen Zalaya", "Alessandro Roccasalva", "Bruno Lepri"], "Categories": "cs.AI cs.LG cs.RO"}, "abstract": "Optimizing traffic dynamics in an evolving transportation landscape is crucial, particularly in scenarios where autonomous vehicles (AVs) with varying levels of autonomy coexist with human-driven cars. This paper presents a novel approach to optimizing choices of AVs using Proximal Policy Optimization (PPO), a reinforcement learning algorithm. We learned a policy to minimize traffic jams (i.e., minimize the time to cross the scenario) and to minimize pollution in a roundabout in Milan, Italy. Through empirical analysis, we demonstrate that our approach can reduce time and pollution levels. Furthermore, we qualitatively evaluate the learned policy using a cutting-edge cockpit to assess its performance in near-real-world conditions. To gauge the practicality and acceptability of the policy, we conducted evaluations with human participants using the simulator, focusing on a range of metrics like traffic smoothness and safety perception. In general, our findings show that human-driven vehicles benefit from optimizing AVs dynamics. Also, participants in the study highlighted that the scenario with 80\\% AVs is perceived as safer than the scenario with 20\\%. The same result is obtained for traffic smoothness perception.", "url": "https://arxiv.org/abs/2309.08254"}, {"metadata": {"arXiv": "2309.08395", "Date": "Fri, 15 Sep 2023 13:41:57 ", "Title": "Learning by Self-Explaining", "Authors": ["Wolfgang Stammer", "Felix Friedrich", "David Steinmann", "Hikaru Shindo and Kristian Kersting"], "Categories": "cs.AI cs.LG"}, "abstract": "Artificial intelligence (AI) research has a long track record of drawing inspirations from findings from biology, in particular human intelligence. In contrast to current AI research that mainly treats explanations as a means for model inspection, a somewhat neglected finding from human psychology is the benefit of self-explaining in an agents' learning process. Motivated by this, we introduce a novel learning paradigm, termed Learning by Self-Explaining (LSX). The underlying idea is that a learning module (learner) performs a base task, e.g. image classification, and provides explanations to its decisions. An internal critic module next evaluates the quality of these explanations given the original task. Finally, the learner is refined with the critic's feedback and the loop is repeated as required. The intuition behind this is that an explanation is considered \"good\" if the critic can perform the same task given the respective explanation. Despite many implementation possibilities the structure of any LSX instantiation can be taxonomized based on four learning modules which we identify as: Fit, Explain, Reflect and Revise. In our work, we provide distinct instantiations of LSX for two different learner models, each illustrating different choices for the various LSX components. We broadly evaluate these on several datasets and show that Learning by Self-Explaining not only boosts the generalization abilities of AI models, particularly in small-data regimes, but also aids in mitigating the influence of confounding factors, as well as leading to more task specific and faithful model explanations. Overall, our results provide experimental evidence of the potential of self-explaining within the learning phase of an AI model.", "url": "https://arxiv.org/abs/2309.08395"}, {"metadata": {"arXiv": "2309.07986", "Date": "Thu, 14 Sep 2023 18:52:16 ", "Title": "Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models", "Authors": ["James Burgess", "Kuan-Chieh Wang", "and Serena Yeung"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Project page: https://jmhb0.github.io/viewneti/"]}, "abstract": "Text-to-image diffusion models understand spatial relationship between objects, but do they represent the true 3D structure of the world from only 2D supervision? We demonstrate that yes, 3D knowledge is encoded in 2D image diffusion models like Stable Diffusion, and we show that this structure can be exploited for 3D vision tasks. Our method, Viewpoint Neural Textual Inversion (ViewNeTI), controls the 3D viewpoint of objects in generated images from frozen diffusion models. We train a small neural mapper to take camera viewpoint parameters and predict text encoder latents; the latents then condition the diffusion generation process to produce images with the desired camera viewpoint. ViewNeTI naturally addresses Novel View Synthesis (NVS). By leveraging the frozen diffusion model as a prior, we can solve NVS with very few input views; we can even do single-view novel view synthesis. Our single-view NVS predictions have good semantic details and photorealism compared to prior methods. Our approach is well suited for modeling the uncertainty inherent in sparse 3D vision problems because it can efficiently generate diverse samples. Our view-control mechanism is general, and can even change the camera view in images generated by user-defined prompts.", "url": "https://arxiv.org/abs/2309.07986"}, {"metadata": {"arXiv": "2309.08289", "Date": "Fri, 15 Sep 2023 10:10:48 ", "Title": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "Authors": ["Kaouther Mouheb", "Mobina Ghojogh Nejad", "Lavsen Dahal", "Ehsan Samei", "W. Paul Segars", "Joseph Y. Lo"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Accurate 3D modeling of human organs plays a crucial role in building computational phantoms for virtual imaging trials. However, generating anatomically plausible reconstructions of organ surfaces from computed tomography scans remains challenging for many structures in the human body. This challenge is particularly evident when dealing with the large intestine. In this study, we leverage recent advancements in geometric deep learning and denoising diffusion probabilistic models to refine the segmentation results of the large intestine. We begin by representing the organ as point clouds sampled from the surface of the 3D segmentation mask. Subsequently, we employ a hierarchical variational autoencoder to obtain global and local latent representations of the organ's shape. We train two conditional denoising diffusion models in the hierarchical latent space to perform shape refinement. To further enhance our method, we incorporate a state-of-the-art surface reconstruction model, allowing us to generate smooth meshes from the obtained complete point clouds. Experimental results demonstrate the effectiveness of our approach in capturing both the global distribution of the organ's shape and its fine details. Our complete refinement pipeline demonstrates remarkable enhancements in surface representation compared to the initial segmentation, reducing the Chamfer distance by 70%, the Hausdorff distance by 32%, and the Earth Mover's distance by 6%. By combining geometric deep learning, denoising diffusion models, and advanced surface reconstruction techniques, our proposed method offers a promising solution for accurately modeling the large intestine's surface and can easily be extended to other anatomical structures.", "url": "https://arxiv.org/abs/2309.08289"}, {"metadata": {"arXiv": "2309.08442", "Date": "Fri, 15 Sep 2023 14:42:04 ", "Title": "Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups", "Authors": ["Parsa Rahimi", "Christophe Ecabert", "Sebastien Marcel"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["IJCB 2023"]}, "abstract": "Recently, it has been exposed that some modern facial recognition systems could discriminate specific demographic groups and may lead to unfair attention with respect to various facial attributes such as gender and origin. The main reason are the biases inside datasets, unbalanced demographics, used to train theses models. Unfortunately, collecting a large-scale balanced dataset with respect to various demographics is impracticable. In this paper, we investigate as an alternative the generation of a balanced and possibly bias-free synthetic dataset that could be used to train, to regularize or to evaluate deep learning-based facial recognition models. We propose to use a simple method for modeling and sampling a disentangled projection of a StyleGAN latent space to generate any combination of demographic groups (e.g. $hispanic-female$). Our experiments show that we can synthesis any combination of demographic groups effectively and the identities are different from the original training dataset. We also released the source code.", "url": "https://arxiv.org/abs/2309.08442"}, {"metadata": {"arXiv": "2309.07936", "Date": "Thu, 14 Sep 2023 01:53:45 ", "Title": "Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems", "Authors": ["Rafael Monteiro and Kartik Sau"], "Categories": "cs.LG cond-mat.mtrl-sci cs.AI math.OC math.PR", "Comments": ["Git-hub on https://github.com/rafael-a-monteiro-math/landscape_sketch_and_step/"], "MSC-class": "68T20, 90C56"}, "abstract": "In this paper, we introduce a new heuristics for global optimization in scenarios where extensive evaluations of the cost function are expensive, inaccessible, or even prohibitive. The method, which we call Landscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic Optimization, and Reinforcement Learning techniques, relying on historical information from previously sampled points to make judicious choices of parameter values where the cost function should be evaluated at. Unlike optimization by Replica Exchange Monte Carlo methods, the number of evaluations of the cost function required in this approach is comparable to that used by Simulated Annealing, quality that is especially important in contexts like high-throughput computing or high-performance computing tasks, where evaluations are either computationally expensive or take a long time to be performed. The method also differs from standard Surrogate Optimization techniques, for it does not construct a surrogate model that aims at approximating or reconstructing the objective function. We illustrate our method by applying it to low dimensional optimization problems (dimensions 1, 2, 4, and 8) that mimick known difficulties of minimization on rugged energy landscapes often seen in Condensed Matter Physics, where cost functions are rugged and plagued with local minima. When compared to classical Simulated Annealing, the LSS shows an effective acceleration of the optimization process.", "url": "https://arxiv.org/abs/2309.07936"}, {"metadata": {"arXiv": "2309.07945", "Date": "Thu, 14 Sep 2023 09:42:13 ", "Title": "Masked Generative Modeling with Enhanced Sampling Scheme", "Authors": ["Daesoo Lee", "Erlend Aune", "and Sara Malacarne"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "This paper presents a novel sampling scheme for masked non-autoregressive generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme (ESS) to overcome these limitations. ESS explicitly ensures both sample diversity and fidelity, and consists of three stages: Naive Iterative Decoding, Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a token set using the naive iterative decoding as proposed in MaskGIT, ensuring sample diversity. Then, the token set undergoes the critical reverse sampling, masking tokens leading to unrealistic samples. After that, critical resampling reconstructs masked tokens until the final sampling step is reached to ensure high fidelity. Critical resampling uses confidence scores obtained from a self-Token-Critic to better measure the realism of sampled tokens, while critical reverse sampling uses the structure of the quantized latent vector space to discover unrealistic sample paths. We demonstrate significant performance gains of ESS in both unconditional sampling and class-conditional sampling using all the 128 datasets in the UCR Time Series archive.", "url": "https://arxiv.org/abs/2309.07945"}, {"metadata": {"arXiv": "2309.07974", "Date": "Thu, 14 Sep 2023 18:17:16 ", "Title": "A Data Source for Reasoning Embodied Agents", "Authors": ["Jack Lanchantin", "Sainbayar Sukhbaatar", "Gabriel Synnaeve", "Yuxuan Sun", "Kavya Srinet", "Arthur Szlam"], "Categories": "cs.LG cs.AI"}, "abstract": "Recent progress in using machine learning models for reasoning tasks has been driven by novel model architectures, large-scale pre-training protocols, and dedicated reasoning datasets for fine-tuning. In this work, to further pursue these advances, we introduce a new data generator for machine reasoning that integrates with an embodied agent. The generated data consists of templated text queries and answers, matched with world-states encoded into a database. The world-states are a result of both world dynamics and the actions of the agent. We show the results of several baseline models on instantiations of train sets. These include pre-trained language models fine-tuned on a text-formatted representation of the database, and graph-structured Transformers operating on a knowledge-graph representation of the database. We find that these models can answer some questions about the world-state, but struggle with others. These results hint at new research directions in designing neural reasoning models and database representations. Code to generate the data will be released at github.com/facebookresearch/neuralmemory", "url": "https://arxiv.org/abs/2309.07974"}, {"metadata": {"arXiv": "2309.07992", "Date": "Thu, 14 Sep 2023 19:07:50 ", "Title": "An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone", "Authors": ["Ijaz Ul Haq", "Byung Suk Lee", "Donna M. Rizzo", "Julia N Perdrial"], "Categories": "cs.LG cs.AI", "Comments": ["This document is the results of the research project funded by the National Science Foundation. Preprint submitted to Engineering Applications of Artificial IntelligenceSeptember 14", "2023"]}, "abstract": "This paper presents an automated machine learning framework designed to assist hydrologists in detecting anomalies in time series data generated by sensors in a research watershed in the northeastern United States critical zone. The framework specifically focuses on identifying peak-pattern anomalies, which may arise from sensor malfunctions or natural phenomena. However, the use of classification methods for anomaly detection poses challenges, such as the requirement for labeled data as ground truth and the selection of the most suitable deep learning model for the given task and dataset. To address these challenges, our framework generates labeled datasets by injecting synthetic peak patterns into synthetically generated time series data and incorporates an automated hyperparameter optimization mechanism. This mechanism generates an optimized model instance with the best architectural and training parameters from a pool of five selected models, namely Temporal Convolutional Network (TCN), InceptionTime, MiniRocket, Residual Networks (ResNet), and Long Short-Term Memory (LSTM). The selection is based on the user's preferences regarding anomaly detection accuracy and computational cost. The framework employs Time-series Generative Adversarial Networks (TimeGAN) as the synthetic dataset generator. The generated model instances are evaluated using a combination of accuracy and computational cost metrics, including training time and memory, during the anomaly detection process. Performance evaluation of the framework was conducted using a dataset from a watershed, demonstrating consistent selection of the most fitting model instance that satisfies the user's preferences.", "url": "https://arxiv.org/abs/2309.07992"}, {"metadata": {"arXiv": "2309.08165", "Date": "Fri, 15 Sep 2023 05:25:43 ", "Title": "To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data", "Authors": ["Hechuan Wen", "Tong Chen", "Li Kheng Chai", "Shazia Sadiq", "Kai Zheng", "Hongzhi Yin"], "Categories": "cs.LG cs.AI stat.ME", "Comments": ["Accepted by ICDM'23"]}, "abstract": "Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. Nevertheless, this potential risk of individual-level treatment effect estimation on networked data has been largely under-explored. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework with Lipschitz constraint to model the prediction uncertainty with Gaussian process and identify unreliable estimations. To the best of our knowledge, GraphDKL is the first framework to tackle the violation of positivity assumption when performing causal effect estimation with graphs. With extensive experiments, we demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data.", "url": "https://arxiv.org/abs/2309.08165"}, {"metadata": {"arXiv": "2309.08171", "Date": "Fri, 15 Sep 2023 05:38:33 ", "Title": "Unveiling Invariances via Neural Network Pruning", "Authors": ["Derek Xu", "Yizhou Sun", "Wei Wang"], "Categories": "cs.LG cs.AI"}, "abstract": "Invariance describes transformations that do not alter data's underlying semantics. Neural networks that preserve natural invariance capture good inductive biases and achieve superior performance. Hence, modern networks are handcrafted to handle well-known invariances (ex. translations). We propose a framework to learn novel network architectures that capture data-dependent invariances via pruning. Our learned architectures consistently outperform dense neural networks on both vision and tabular datasets in both efficiency and effectiveness. We demonstrate our framework on multiple deep learning models across 3 vision and 40 tabular datasets.", "url": "https://arxiv.org/abs/2309.08171"}, {"metadata": {"arXiv": "2309.08227", "Date": "Fri, 15 Sep 2023 07:54:49 ", "Title": "VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime Inference", "Authors": ["Soumya Banerjee", "Vinay K. Verma", "Avideep Mukherjee", "Deepak Gupta", "Vinay P. Namboodiri", "Piyush Rai"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Lifelong learning, also referred to as continual learning, is the problem of training an AI agent continuously while also preventing it from forgetting its previously acquired knowledge. Most of the existing methods primarily focus on lifelong learning within a static environment and lack the ability to mitigate forgetting in a quickly-changing dynamic environment. Streaming lifelong learning is a challenging setting of lifelong learning with the goal of continuous learning in a dynamic non-stationary environment without forgetting. We introduce a novel approach to lifelong learning, which is streaming, requires a single pass over the data, can learn in a class-incremental manner, and can be evaluated on-the-fly (anytime inference). To accomplish these, we propose virtual gradients for continual representation learning to prevent catastrophic forgetting and leverage an exponential-moving-average-based semantic memory to further enhance performance. Extensive experiments on diverse datasets demonstrate our method's efficacy and superior performance over existing methods.", "url": "https://arxiv.org/abs/2309.08227"}, {"metadata": {"arXiv": "2309.08247", "Date": "Fri, 15 Sep 2023 08:41:12 ", "Title": "A Geometric Perspective on Autoencoders", "Authors": ["Yonghyeon Lee"], "Categories": "cs.LG cs.AI cs.CG", "Comments": ["10 pages", "13 figures", "a summary of the contents presented in publications from NeurIPS 2021", "ICLR 2022", "and TAG-ML at ICML 2023"]}, "abstract": "This paper presents the geometric aspect of the autoencoder framework, which, despite its importance, has been relatively less recognized. Given a set of high-dimensional data points that approximately lie on some lower-dimensional manifold, an autoencoder learns the \\textit{manifold} and its \\textit{coordinate chart}, simultaneously. This geometric perspective naturally raises inquiries like \"Does a finite set of data points correspond to a single manifold?\" or \"Is there only one coordinate chart that can represent the manifold?\". The responses to these questions are negative, implying that there are multiple solution autoencoders given a dataset. Consequently, they sometimes produce incorrect manifolds with severely distorted latent space representations. In this paper, we introduce recent geometric approaches that address these issues.", "url": "https://arxiv.org/abs/2309.08247"}, {"metadata": {"arXiv": "2309.08333", "Date": "Fri, 15 Sep 2023 11:43:09 ", "Title": "Let's Predict Who Will Move to a New Job", "Authors": ["Rania Mkhinini Gahar", "Adel Hidri", "Minyar Sassi Hidri"], "Categories": "cs.LG cs.AI", "Comments": ["5 pages", "3 figures"], "Journal-ref": "2023 IEEE International Conference on Advanced Systems and Emergent Technologies (IC_ASET)", "DOI": "10.1109/IC_ASET58101.2023.10150675"}, "abstract": "Any company's human resources department faces the challenge of predicting whether an applicant will search for a new job or stay with the company. In this paper, we discuss how machine learning (ML) is used to predict who will move to a new job. First, the data is pre-processed into a suitable format for ML models. To deal with categorical features, data encoding is applied and several MLA (ML Algorithms) are performed including Random Forest (RF), Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting (XGBoost). To improve the performance of ML models, the synthetic minority oversampling technique (SMOTE) is used to retain them. Models are assessed using decision support metrics such as precision, recall, F1-Score, and accuracy.", "url": "https://arxiv.org/abs/2309.08333"}, {"metadata": {"arXiv": "2309.08499", "Date": "Fri, 15 Sep 2023 16:03:23 ", "Title": "P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification", "Authors": ["Shaowu Chen", "Weize Sun", "Lei Huang", "Xiaopeng Li", "Qingyuan Wang", "Deepu John"], "Categories": "cs.LG cs.AI"}, "abstract": "In recent years, two time series classification models, ROCKET and MINIROCKET, have attracted much attention for their low training cost and state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without training, ROCKET and MINIROCKET can rapidly extract features from time series data, allowing for the efficient fitting of linear classifiers. However, to comprehensively capture useful features, a large number of random kernels are required, which is incompatible for resource-constrained devices. Therefore, a heuristic evolutionary algorithm named S-ROCKET is devised to recognize and prune redundant kernels. Nevertheless, the inherent nature of evolutionary algorithms renders the evaluation of kernels within S-ROCKET an unacceptable time-consuming process. In this paper, diverging from S-ROCKET, which directly evaluates random kernels with nonsignificant differences, we remove kernels from a feature selection perspective by eliminating associating connections in the sequential classification layer. To this end, we start by formulating the pruning challenge as a Group Elastic Net classification problem and employ the ADMM method to arrive at a solution. Sequentially, we accelerate the aforementioned time-consuming solving process by bifurcating the $l_{2,1}$ and $l_2$ regularizations into two sequential stages and solve them separately, which ultimately forms our core algorithm, named P-ROCKET. Stage 1 of P-ROCKET employs group-wise regularization similarly to our initial ADMM-based Algorithm, but introduces dynamically varying penalties to greatly accelerate the process. To mitigate overfitting, Stage 2 of P-ROCKET implements element-wise regularization to refit a linear classifier, utilizing the retained features.", "url": "https://arxiv.org/abs/2309.08499"}, {"metadata": {"arXiv": "2309.08549", "Date": "Fri, 15 Sep 2023 17:12:19 ", "Title": "HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks", "Authors": ["Minh-Hao Van", "Alycia N. Carey", "Xintao Wu"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "While numerous defense methods have been proposed to prohibit potential poisoning attacks from untrusted data sources, most research works only defend against specific attacks, which leaves many avenues for an adversary to exploit. In this work, we propose an efficient and robust training approach to defend against data poisoning attacks based on influence functions, named Healthy Influential-Noise based Training. Using influence functions, we craft healthy noise that helps to harden the classification model against poisoning attacks without significantly affecting the generalization ability on test data. In addition, our method can perform effectively when only a subset of the training data is modified, instead of the current method of adding noise to all examples that has been used in several previous works. We conduct comprehensive evaluations over two image datasets with state-of-the-art poisoning attacks under different realistic attack scenarios. Our empirical results show that HINT can efficiently protect deep learning models against the effect of both untargeted and targeted poisoning attacks.", "url": "https://arxiv.org/abs/2309.08549"}, {"metadata": {"arXiv": "2309.08560", "Date": "Fri, 15 Sep 2023 17:28:06 ", "Title": "Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources", "Authors": ["Yikuan Li", "Chengsheng Mao", "Kaixuan Huang", "Hanyin Wang", "Zheng Yu", "Mengdi Wang and Yuan Luo"], "Categories": "cs.LG cs.AI", "Comments": ["9 pages", "4 figures", "2 tables"]}, "abstract": "Scarcity of health care resources could result in the unavoidable consequence of rationing. For example, ventilators are often limited in supply, especially during public health emergencies or in resource-constrained health care settings, such as amid the pandemic of COVID-19. Currently, there is no universally accepted standard for health care resource allocation protocols, resulting in different governments prioritizing patients based on various criteria and heuristic-based protocols. In this study, we investigate the use of reinforcement learning for critical care resource allocation policy optimization to fairly and effectively ration resources. We propose a transformer-based deep Q-network to integrate the disease progression of individual patients and the interaction effects among patients during the critical care resource allocation. We aim to improve both fairness of allocation and overall patient outcomes. Our experiments demonstrate that our method significantly reduces excess deaths and achieves a more equitable distribution under different levels of ventilator shortage, when compared to existing severity-based and comorbidity-based methods in use by different governments. Our source code is included in the supplement and will be released on Github upon publication.", "url": "https://arxiv.org/abs/2309.08560"}, {"metadata": {"arXiv": "2309.08587", "Date": "Fri, 15 Sep 2023 17:44:05 ", "Title": "Compositional Foundation Models for Hierarchical Planning", "Authors": ["Anurag Ajay", "Seungwook Han", "Yilun Du", "Shaung Li", "Abhi Gupta", "Tommi Jaakkola", "Josh Tenenbaum", "Leslie Kaelbling", "Akash Srivastava", "Pulkit Agrawal"], "Categories": "cs.LG cs.AI cs.RO", "Comments": ["Website: https://hierarchical-planning-foundation-model.github.io/"]}, "abstract": "To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustrate the efficacy and adaptability of our approach in three different long-horizon table-top manipulation tasks.", "url": "https://arxiv.org/abs/2309.08587"}, {"metadata": {"arXiv": "2309.08589", "Date": "Fri, 15 Sep 2023 17:44:17 ", "Title": "Chain-of-Thought Reasoning is a Policy Improvement Operator", "Authors": ["Hugh Zhang", "David C. Parkes"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "Large language models have astounded the world with fascinating new capabilities. However, they currently lack the ability to teach themselves new skills, relying instead on being trained on large amounts of human-generated data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a proof-of-concept demonstration that language models can successfully teach themselves new skills using chain-of-thought reasoning. Inspired by previous work in both reinforcement learning (Silver et al., 2017) and human cognition (Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think its way through problems. SECToR then fine-tunes the model to generate those same answers, this time without using chain-of-thought reasoning. Language models trained via SECToR autonomously learn to add up to 29-digit numbers without any access to any ground truth examples beyond an initial supervised fine-tuning phase consisting only of numbers with 6 or fewer digits. Our central hypothesis is that chain-of-thought reasoning can act as a policy improvement operator, analogously to how Monte-Carlo Tree Search is used in AlphaZero. We hope that this research can lead to new directions in which language models can learn to teach themselves without the need for human demonstrations.", "url": "https://arxiv.org/abs/2309.08589"}, {"metadata": {"arXiv": "2309.08086", "Date": "Fri, 15 Sep 2023 00:59:31 ", "Title": "Fast and Accurate Deep Loop Closing and Relocalization for Reliable LiDAR SLAM", "Authors": ["Chenghao Shi", "Xieyuanli Chen", "Junhao Xiao", "Bin Dai", "Huimin Lu"], "Categories": "cs.RO cs.AI cs.CV cs.LG", "Comments": ["20 pages 10 figures 7 tables"]}, "abstract": "Loop closing and relocalization are crucial techniques to establish reliable and robust long-term SLAM by addressing pose estimation drift and degeneration. This article begins by formulating loop closing and relocalization within a unified framework. Then, we propose a novel multi-head network LCR-Net to tackle both tasks effectively. It exploits novel feature extraction and pose-aware attention mechanism to precisely estimate similarities and 6-DoF poses between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a SLAM system and achieve robust and accurate online LiDAR SLAM in outdoor driving environments. We thoroughly evaluate our LCR-Net through three setups derived from loop closing and relocalization, including candidate retrieval, closed-loop point cloud registration, and continuous relocalization using multiple datasets. The results demonstrate that LCR-Net excels in all three tasks, surpassing the state-of-the-art methods and exhibiting a remarkable generalization ability. Notably, our LCR-Net outperforms baseline methods without using a time-consuming robust pose estimator, rendering it suitable for online SLAM applications. To our best knowledge, the integration of LCR-Net yields the first LiDAR SLAM with the capability of deep loop closing and relocalization. The implementation of our methods will be made open-source.", "url": "https://arxiv.org/abs/2309.08086"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

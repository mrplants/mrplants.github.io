<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2311.10812", "Date": "Fri, 17 Nov 2023 18:47:07 ", "Title": "SplatArmor: Articulated Gaussian splatting for animatable humans from monocular RGB videos", "Authors": ["Rohit Jena", "Ganesh Subramanian Iyer", "Siddharth Choudhary", "Brandon Smith", "Pratik Chaudhari", "James Gee"], "Categories": "cs.CV cs.GR cs.LG"}, "abstract": "We propose SplatArmor, a novel approach for recovering detailed and animatable human models by `armoring' a parameterized body model with 3D Gaussians. Our approach represents the human as a set of 3D Gaussians within a canonical space, whose articulation is defined by extending the skinning of the underlying SMPL geometry to arbitrary locations in the canonical space. To account for pose-dependent effects, we introduce a SE(3) field, which allows us to capture both the location and anisotropy of the Gaussians. Furthermore, we propose the use of a neural color field to provide color regularization and 3D supervision for the precise positioning of these Gaussians. We show that Gaussian splatting provides an interesting alternative to neural rendering based methods by leverging a rasterization primitive without facing any of the non-differentiability and optimization challenges typically faced in such approaches. The rasterization paradigms allows us to leverage forward skinning, and does not suffer from the ambiguities associated with inverse skinning and warping. We show compelling results on the ZJU MoCap and People Snapshot datasets, which underscore the effectiveness of our method for controllable human synthesis.", "url": "https://arxiv.org/abs/2311.10812"}, {"metadata": {"arXiv": "2311.10899", "Date": "Fri, 17 Nov 2023 22:44:05 ", "Title": "Extraction and Summarization of Explicit Video Content using Multi-Modal Deep Learning", "Authors": ["Shaunak Joshi (1)", "Raghav Gaggar (1) ((1) University of Southern California)"], "Categories": "cs.CV cs.CL cs.LG", "Comments": ["8 pages", "3 figures"], "ACM-class": "I.2.10"}, "abstract": "With the increase in video-sharing platforms across the internet, it is difficult for humans to moderate the data for explicit content. Hence, an automated pipeline to scan through video data for explicit content has become the need of the hour. We propose a novel pipeline that uses multi-modal deep learning to first extract the explicit segments of input videos and then summarize their content using text to determine its age appropriateness and age rating. We also evaluate our pipeline's effectiveness in the end using standard metrics.", "url": "https://arxiv.org/abs/2311.10899"}, {"metadata": {"arXiv": "2311.11019", "Date": "Sat, 18 Nov 2023 09:42:03 ", "Title": "Hyperbolic Space with Hierarchical Margin Boosts Fine-Grained Learning from Coarse Labels", "Authors": ["Shu-Lin Xu and Yifan Sun and Faen Zhang and Anqi Xu and Xiu-Shen Wei and Yi Yang"], "Categories": "cs.CV cs.LG cs.MM", "Comments": ["Accepted by NeurIPS 2023"]}, "abstract": "Learning fine-grained embeddings from coarse labels is a challenging task due to limited label granularity supervision, i.e., lacking the detailed distinctions required for fine-grained tasks. The task becomes even more demanding when attempting few-shot fine-grained recognition, which holds practical significance in various applications. To address these challenges, we propose a novel method that embeds visual embeddings into a hyperbolic space and enhances their discriminative ability with a hierarchical cosine margins manner. Specifically, the hyperbolic space offers distinct advantages, including the ability to capture hierarchical relationships and increased expressive power, which favors modeling fine-grained objects. Based on the hyperbolic space, we further enforce relatively large/small similarity margins between coarse/fine classes, respectively, yielding the so-called hierarchical cosine margins manner. While enforcing similarity margins in the regular Euclidean space has become popular for deep embedding learning, applying it to the hyperbolic space is non-trivial and validating the benefit for coarse-to-fine generalization is valuable. Extensive experiments conducted on five benchmark datasets showcase the effectiveness of our proposed method, yielding state-of-the-art results surpassing competing methods.", "url": "https://arxiv.org/abs/2311.11019"}, {"metadata": {"arXiv": "2311.11198", "Date": "Sun, 19 Nov 2023 01:57:55 ", "Title": "Self-Supervised Versus Supervised Training for Segmentation of Organoid Images", "Authors": ["Asmaa Haja", "Eric Brouwer and Lambert Schomaker"], "Categories": "cs.CV cs.LG"}, "abstract": "The process of annotating relevant data in the field of digital microscopy can be both time-consuming and especially expensive due to the required technical skills and human-expert knowledge. Consequently, large amounts of microscopic image data sets remain unlabeled, preventing their effective exploitation using deep-learning algorithms. In recent years it has been shown that a lot of relevant information can be drawn from unlabeled data. Self-supervised learning (SSL) is a promising solution based on learning intrinsic features under a pretext task that is similar to the main task without requiring labels. The trained result is transferred to the main task - image segmentation in our case. A ResNet50 U-Net was first trained to restore images of liver progenitor organoids from augmented images using the Structural Similarity Index Metric (SSIM), alone, and using SSIM combined with L1 loss. Both the encoder and decoder were trained in tandem. The weights were transferred to another U-Net model designed for segmentation with frozen encoder weights, using Binary Cross Entropy, Dice, and Intersection over Union (IoU) losses. For comparison, we used the same U-Net architecture to train two supervised models, one utilizing the ResNet50 encoder as well as a simple CNN. Results showed that self-supervised learning models using a 25\\% pixel drop or image blurring augmentation performed better than the other augmentation techniques using the IoU loss. When trained on only 114 images for the main task, the self-supervised learning approach outperforms the supervised method achieving an F1-score of 0.85, with higher stability, in contrast to an F1=0.78 scored by the supervised method. Furthermore, when trained with larger data sets (1,000 images), self-supervised learning is still able to perform better, achieving an F1-score of 0.92, contrasting to a score of 0.85 for the supervised method.", "url": "https://arxiv.org/abs/2311.11198"}, {"metadata": {"arXiv": "2311.11252", "Date": "Sun, 19 Nov 2023 06:34:50 ", "Title": "Submeter-level Land Cover Mapping of Japan", "Authors": ["Naoto Yokoya", "Junshi Xia", "Clifford Broni-Bediako"], "Categories": "cs.CV cs.LG", "Comments": ["16 pages", "10 figures"]}, "abstract": "Deep learning has shown promising performance in submeter-level mapping tasks; however, the annotation cost of submeter-level imagery remains a challenge, especially when applied on a large scale. In this paper, we present the first submeter-level land cover mapping of Japan with eight classes, at a relatively low annotation cost. We introduce a human-in-the-loop deep learning framework leveraging OpenEarthMap, a recently introduced benchmark dataset for global submeter-level land cover mapping, with a U-Net model that achieves national-scale mapping with a small amount of additional labeled data. By adding a small amount of labeled data of areas or regions where a U-Net model trained on OpenEarthMap clearly failed and retraining the model, an overall accuracy of 80\\% was achieved, which is a nearly 16 percentage point improvement after retraining. Using aerial imagery provided by the Geospatial Information Authority of Japan, we create land cover classification maps of eight classes for the entire country of Japan. Our framework, with its low annotation cost and high-accuracy mapping results, demonstrates the potential to contribute to the automatic updating of national-scale land cover mapping using submeter-level optical remote sensing data. The mapping results will be made publicly available.", "url": "https://arxiv.org/abs/2311.11252"}, {"metadata": {"arXiv": "2311.11629", "Date": "Mon, 20 Nov 2023 09:28:04 ", "Title": "Generating Realistic Counterfactuals for Retinal Fundus and OCT Images using Diffusion Models", "Authors": ["Indu Ilanchezian", "Valentyn Boreiko", "Laura K\\\"uhlewein", "Ziwei Huang", "Murat Se\\c{c}kin Ayhan", "Matthias Hein", "Lisa Koch", "Philipp Berens"], "Categories": "cs.CV cs.LG"}, "abstract": "Counterfactual reasoning is often used in a clinical setting to explain decisions or weigh alternatives. Therefore, for imaging based modalities such as ophthalmology, it would be beneficial to be able to create counterfactual images, illustrating the answer to the question: \"If the subject had had diabetic retinopathy, how would the fundus image have looked?\" Here, we demonstrate that using a diffusion model in combination with an adversarially robust classifier trained on retinal disease classification tasks enables generation of highly realistic counterfactuals of retinal fundus images and optical coherence tomorgraphy (OCT) B-scans. Ideally, these classifiers encode the salient features indicative for each disease class and can steer the diffusion model to show realistic disease signs or remove disease-related lesions in a realistic way. Importantly, in a user study, domain experts found the counterfactuals generated using our method significantly more realistic than counterfactuals generated from a previous method, and even indistiguishable from realistic images.", "url": "https://arxiv.org/abs/2311.11629"}, {"metadata": {"arXiv": "2311.11772", "Date": "Mon, 20 Nov 2023 13:58:26 ", "Title": "A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology", "Authors": ["Georg W\\\"olflein", "Dyke Ferber", "Asier Rabasco Meneghetti", "Omar S. M. El Nahhas", "Daniel Truhn", "Zunamys I. Carrero", "David J. Harrison", "Ognjen Arandjelovi\\'c", "Jakob N. Kather"], "Categories": "cs.CV cs.LG"}, "abstract": "Deep learning is revolutionising pathology, offering novel opportunities in disease prognosis and personalised treatment. Historically, stain normalisation has been a crucial preprocessing step in computational pathology pipelines, and persists into the deep learning era. Yet, with the emergence of feature extractors trained using self-supervised learning (SSL) on diverse pathology datasets, we call this practice into question. In an empirical evaluation of publicly available feature extractors, we find that omitting stain normalisation and image augmentations does not compromise downstream performance, while incurring substantial savings in memory and compute. Further, we show that the top-performing feature extractors are remarkably robust to variations in stain and augmentations like rotation in their latent space. Contrary to previous patch-level benchmarking studies, our approach emphasises clinical relevance by focusing on slide-level prediction tasks in a weakly supervised setting with external validation cohorts. This work represents the most comprehensive robustness evaluation of public pathology SSL feature extractors to date, involving more than 6,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Our findings stand to streamline digital pathology workflows by minimising preprocessing needs and informing the selection of feature extractors.", "url": "https://arxiv.org/abs/2311.11772"}, {"metadata": {"arXiv": "2311.11777", "Date": "Mon, 20 Nov 2023 14:02:50 ", "Title": "Multimodal deep learning for mapping forest dominant height by fusing GEDI with earth observation data", "Authors": ["Man Chen", "Wenquan Dong", "Hao Yu", "Iain Woodhouse", "Casey M. Ryan", "Haoyu Liu", "Selena Georgiou", "Edward T.A. Mitchard"], "Categories": "cs.CV cs.LG eess.IV"}, "abstract": "The integration of multisource remote sensing data and deep learning models offers new possibilities for accurately mapping high spatial resolution forest height. We found that GEDI relative heights (RH) metrics exhibited strong correlation with the mean of the top 10 highest trees (dominant height) measured in situ at the corresponding footprint locations. Consequently, we proposed a novel deep learning framework termed the multi-modal attention remote sensing network (MARSNet) to estimate forest dominant height by extrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2 PALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises separate encoders for each remote sensing data modality to extract multi-scale features, and a shared decoder to fuse the features and estimate height. Using individual encoders for each remote sensing imagery avoids interference across modalities and extracts distinct representations. To focus on the efficacious information from each dataset, we reduced the prevalent spatial and band redundancies in each remote sensing data by incorporating the extended spatial and band reconstruction convolution modules in the encoders. MARSNet achieved commendable performance in estimating dominant height, with an R2 of 0.62 and RMSE of 2.82 m, outperforming the widely used random forest approach which attained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained MARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin, China. Through independent validation using field measurements, MARSNet demonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for the random forest baseline. Our research demonstrates the effectiveness of a multimodal deep learning approach fusing GEDI with SAR and passive optical imagery for enhancing the accuracy of high resolution dominant height estimation.", "url": "https://arxiv.org/abs/2311.11777"}, {"metadata": {"arXiv": "2311.11827", "Date": "Mon, 20 Nov 2023 15:04:16 ", "Title": "Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning", "Authors": ["Dilith Jayakody", "Thanuja Ambegoda"], "Categories": "cs.CV cs.LG", "Comments": ["10 pages", "4 figures"]}, "abstract": "The task of multispectral image segmentation (segmentation of images with numerous channels/bands, each capturing a specific range of wavelengths of electromagnetic radiation) has been previously explored in contexts with large amounts of labeled data. However, these models tend not to generalize well to datasets of smaller size. In this paper, we propose a novel approach for improving few-shot segmentation performance on multispectral images using reinforcement learning to generate representations. These representations are generated in the form of mathematical expressions between channels and are tailored to the specific class being segmented. Our methodology involves training an agent to identify the most informative expressions, updating the dataset using these expressions, and then using the updated dataset to perform segmentation. Due to the limited length of the expressions, the model receives useful representations without any added risk of overfitting. We evaluate the effectiveness of our approach on several multispectral datasets and demonstrate its effectiveness in boosting the performance of segmentation algorithms.", "url": "https://arxiv.org/abs/2311.11827"}, {"metadata": {"arXiv": "2311.11882", "Date": "Mon, 20 Nov 2023 16:19:46 ", "Title": "Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks", "Authors": ["Rami Haffar", "David S\\'anchez", "and Josep Domingo-Ferrer"], "Categories": "cs.CV cs.LG", "Comments": ["21 pages", "2 figures", "9 Tables,"]}, "abstract": "Human facial data hold tremendous potential to address a variety of classification problems, including face recognition, age estimation, gender identification, emotion analysis, and race classification. However, recent privacy regulations, such as the EU General Data Protection Regulation and others, have restricted the ways in which human images may be collected and used for research. As a result, several previously published data sets containing human faces have been removed from the internet due to inadequate data collection methods that failed to meet privacy regulations. Data sets consisting of synthetic data have been proposed as an alternative, but they fall short of accurately representing the real data distribution. On the other hand, most available data sets are labeled for just a single task, which limits their applicability. To address these issues, we present the Multi-Task Faces (MTF) image data set, a meticulously curated collection of face images designed for various classification tasks, including face recognition, as well as race, gender, and age classification. The MTF data set has been ethically gathered by leveraging publicly available images of celebrities and strictly adhering to copyright regulations. In this paper, we present this data set and provide detailed descriptions of the followed data collection and processing procedures. Furthermore, we evaluate the performance of five deep learning (DL) models on the MTF data set across the aforementioned classification tasks. Additionally, we compare the performance of DL models over the processed MTF data and over raw data crawled from the internet. The reported results constitute a baseline for further research employing these data. The MTF data set can be accessed through the following link (please cite the present paper if you use the data set): https://github.com/RamiHaf/MTF_data_set", "url": "https://arxiv.org/abs/2311.11882"}, {"metadata": {"arXiv": "2311.11904", "Date": "Mon, 20 Nov 2023 16:37:45 ", "Title": "LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions", "Authors": ["Songhao Han", "Le Zhuo", "Yue Liao", "Si Liu"], "Categories": "cs.CV cs.CL cs.LG"}, "abstract": "Vision-language models (VLMs) offer a promising paradigm for image classification by comparing the similarity between images and class embeddings. A critical challenge lies in crafting precise textual representations for class names. While previous studies have leveraged recent advancements in large language models (LLMs) to enhance these descriptors, their outputs often suffer from ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent reliance on textual interactions with LLMs, leading to a mismatch between the generated text and the visual content in VLMs' latent space - a phenomenon we term the \"explain without seeing\" dilemma. 2) The oversight of the inter-class relationships, resulting in descriptors that fail to differentiate similar classes effectively. To address these issues, we propose a novel image classification framework combining VLMs with LLMs, named Iterative Optimization with Visual Feedback. In particular, our method develops an LLM-based agent, employing an evolutionary optimization strategy to refine class descriptors. Crucially, we incorporate visual feedback from VLM classification metrics, thereby guiding the optimization process with concrete visual data. Our method leads to improving accuracy on a wide range of image classification benchmarks, with 3.47\\% average gains over state-of-the-art methods. We also highlight the resulting descriptions serve as explainable and robust features that can consistently improve the performance across various backbone models.", "url": "https://arxiv.org/abs/2311.11904"}, {"metadata": {"arXiv": "2311.10927", "Date": "Sat, 18 Nov 2023 01:21:54 ", "Title": "Near-Optimal Fair Resource Allocation for Strategic Agents without Money: A Data-Driven Approach", "Authors": ["Sihan Zeng", "Sujay Bhatt", "Eleonora Kreacic", "Parisa Hassanzadeh", "Alec Koppel", "Sumitra Ganesh"], "Categories": "cs.GT cs.LG"}, "abstract": "We study learning-based design of fair allocation mechanisms for divisible resources, using proportional fairness (PF) as a benchmark. The learning setting is a significant departure from the classic mechanism design literature, in that, we need to learn fair mechanisms solely from data. In particular, we consider the challenging problem of learning one-shot allocation mechanisms -- without the use of money -- that incentivize strategic agents to be truthful when reporting their valuations. It is well-known that the mechanism that directly seeks to optimize PF is not incentive compatible, meaning that the agents can potentially misreport their preferences to gain increased allocations. We introduce the notion of \"exploitability\" of a mechanism to measure the relative gain in utility from misreport, and make the following important contributions in the paper: (i) Using sophisticated techniques inspired by differentiable convex programming literature, we design a numerically efficient approach for computing the exploitability of the PF mechanism. This novel contribution enables us to quantify the gap that needs to be bridged to approximate PF via incentive compatible mechanisms. (ii) Next, we modify the PF mechanism to introduce a trade-off between fairness and exploitability. By properly controlling this trade-off using data, we show that our proposed mechanism, ExPF-Net, provides a strong approximation to the PF mechanism while maintaining low exploitability. This mechanism, however, comes with a high computational cost. (iii) To address the computational challenges, we propose another mechanism ExS-Net, which is end-to-end parameterized by a neural network. ExS-Net enjoys similar (slightly inferior) performance and significantly accelerated training and inference time performance. (iv) Extensive numerical simulations demonstrate the robustness and efficacy of the proposed mechanisms.", "url": "https://arxiv.org/abs/2311.10927"}, {"metadata": {"arXiv": "2311.10731", "Date": "Sun, 15 Oct 2023 03:44:51 ", "Title": "Gender-Based Comparative Study of Type 2 Diabetes Risk Factors in Kolkata, India: A Machine Learning Approach", "Authors": ["Rahul Jain", "Anoushka Saha", "Gourav Daga", "Durba Bhattacharya", "Madhura Das Gupta", "Sourav Chowdhury", "Suparna Roychowdhury"], "Categories": "cs.LG physics.med-ph physics.soc-ph", "Comments": ["10 pages", "7 tables,3 figures", "submitted to a conference"]}, "abstract": "Type 2 diabetes mellitus represents a prevalent and widespread global health concern, necessitating a comprehensive assessment of its risk factors. This study aimed towards learning whether there is any differential impact of age, Lifestyle, BMI and Waist to height ratio on the risk of Type 2 diabetes mellitus in males and females in Kolkata, West Bengal, India based on a sample observed from the out-patient consultation department of Belle Vue Clinic in Kolkata. Various machine learning models like Logistic Regression, Random Forest, and Support Vector Classifier, were used to predict the risk of diabetes, and performance was compared based on different predictors. Our findings indicate a significant age-related increase in risk of diabetes for both males and females. Although exercising and BMI was found to have significant impact on the risk of Type 2 diabetes in males, in females both turned out to be statistically insignificant. For both males and females, predictive models based on WhtR demonstrated superior performance in risk assessment compared to those based on BMI. This study sheds light on the gender-specific differences in the risk factors for Type 2 diabetes, offering valuable insights that can be used towards more targeted healthcare interventions and public health strategies.", "url": "https://arxiv.org/abs/2311.10731"}, {"metadata": {"arXiv": "2311.10787", "Date": "Thu, 16 Nov 2023 22:22:13 ", "Title": "Assurance for Deployed Continual Learning Systems", "Authors": ["Ari Goodman", "Ryan O'Shea", "Noam Hirschorn", "Hubert Chrostowski"], "Categories": "cs.LG", "Comments": ["8 pages", "11 figures. Published in the Proceedings of the ASNE 2023 Technology", "Systems & Ships Symposium. Reproduced with permission from the American Society of Naval Engineers. Distribution Statement A: Approved for public release; distribution is unlimited", "as submitted under NAVAIR Public Release Authorization 2023-022"]}, "abstract": "The future success of the Navy will depend, in part, on artificial intelligence. In practice, many artificially intelligent algorithms, and in particular deep learning models, rely on continual learning to maintain performance in dynamic environments. The software requires adaptation to maintain its initial level of performance in unseen situations. However, if not monitored properly, continual learning may lead to several issues including catastrophic forgetting in which a trained model forgets previously learned tasks when being retrained on new data. The authors created a new framework for safely performing continual learning with the goal of pairing this safety framework with a deep learning computer vision algorithm to allow for safe and high-performing automatic deck tracking on carriers and amphibious assault ships. The safety framework includes several features, such as an ensemble of convolutional neural networks to perform image classification, a manager to record confidences and determine the best answer from the ensemble, a model of the environment to predict when the system may fail to meet minimum performance metrics, a performance monitor to log system and domain performance and check against requirements, and a retraining component to update the ensemble and manager to maintain performance. The authors validated the proposed method using extensive simulation studies based on dynamic image classification. The authors showed the safety framework could probabilistically detect out of distribution data. The results also show the framework can detect when the system is no longer performing safely and can significantly extend the working envelope of an image classifier.", "url": "https://arxiv.org/abs/2311.10787"}, {"metadata": {"arXiv": "2311.10789", "Date": "Fri, 17 Nov 2023 00:34:41 ", "Title": "Stratified-NMF for Heterogeneous Data", "Authors": ["James Chapman", "Yotam Yaniv", "Deanna Needell"], "Categories": "cs.LG cs.NA math.NA", "Comments": ["5 pages. Will appear in IEEE Asilomar Conference on Signals", "Systems", "and Computers 2023"], "ACM-class": "G.1.6; I.5.3; I.5.4"}, "abstract": "Non-negative matrix factorization (NMF) is an important technique for obtaining low dimensional representations of datasets. However, classical NMF does not take into account data that is collected at different times or in different locations, which may exhibit heterogeneity. We resolve this problem by solving a modified NMF objective, Stratified-NMF, that simultaneously learns strata-dependent statistics and a shared topics matrix. We develop multiplicative update rules for this novel objective and prove convergence of the objective. Then, we experiment on synthetic data to demonstrate the efficiency and accuracy of the method. Lastly, we apply our method to three real world datasets and empirically investigate their learned features.", "url": "https://arxiv.org/abs/2311.10789"}, {"metadata": {"arXiv": "2311.10795", "Date": "Fri, 17 Nov 2023 04:30:31 ", "Title": "How False Data Affects Machine Learning Models in Electrochemistry?", "Authors": ["Krittapong Deshsorna", "Luckhana Lawtrakul", "Pawin Iamprasertkun"], "Categories": "cs.LG physics.chem-ph", "Comments": ["47 pages", "23 figures"]}, "abstract": "Recently, the selection of machine learning model based on only the data distribution without concerning the noise of the data. This study aims to distinguish, which models perform well under noisy data, and establish whether stacking machine learning models actually provide robustness to otherwise weak-to-noise models. The electrochemical data were tested with 12 standalone models and stacking model. This includes XGB, LGBM, RF, GB, ADA, NN, ELAS, LASS, RIDGE, SVM, KNN, DT, and the stacking model. It is found that linear models handle noise well with the average error of (slope) to 1.75 F g-1 up to error per 100% percent noise added; but it suffers from prediction accuracy due to having an average of 60.19 F g-1 estimated at minimal error at 0% noise added. Tree-based models fail in terms of noise handling (average slope is 55.24 F g-1 at 100% percent noise), but it can provide higher prediction accuracy (lowest error of 23.9 F g-1) than that of linear. To address the controversial between prediction accuracy and error handling, the stacking model was constructed, which is not only show high accuracy (intercept of 25.03 F g-1), but it also exhibits good noise handling (slope of 43.58 F g-1), making stacking models a relatively low risk and viable choice for beginner and experienced machine learning research in electrochemistry. Even though neural networks (NN) are gaining popularity in the electrochemistry field. However, this study presents that NN is not suitable for electrochemical data, and improper tuning resulting in a model that is susceptible to noise. Thus, STACK models should provide better benefits in that even with untuned base models, they can achieve an accurate and noise-tolerant model. Overall, this work provides insight into machine learning model selection for electrochemical data, which should aid the understanding of data science in chemistry context.", "url": "https://arxiv.org/abs/2311.10795"}, {"metadata": {"arXiv": "2311.10799", "Date": "Fri, 17 Nov 2023 07:49:32 ", "Title": "Adaptive Modelling Approach for Row-Type Dependent Predictive Analysis (RTDPA): A Framework for Designing Machine Learning Models for Credit Risk Analysis in Banking Sector", "Authors": ["Minati Rath", "Hema Date"], "Categories": "cs.LG"}, "abstract": "In many real-world datasets, rows may have distinct characteristics and require different modeling approaches for accurate predictions. In this paper, we propose an adaptive modeling approach for row-type dependent predictive analysis(RTDPA). Our framework enables the development of models that can effectively handle diverse row types within a single dataset. Our dataset from XXX bank contains two different risk categories, personal loan and agriculture loan. each of them are categorised into four classes standard, sub-standard, doubtful and loss. We performed tailored data pre processing and feature engineering to different row types. We selected traditional machine learning predictive models and advanced ensemble techniques. Our findings indicate that all predictive approaches consistently achieve a precision rate of no less than 90%. For RTDPA, the algorithms are applied separately for each row type, allowing the models to capture the specific patterns and characteristics of each row type. This approach enables targeted predictions based on the row type, providing a more accurate and tailored classification for the given dataset.Additionally, the suggested model consistently offers decision makers valuable and enduring insights that are strategic in nature in banking sector.", "url": "https://arxiv.org/abs/2311.10799"}, {"metadata": {"arXiv": "2311.10803", "Date": "Fri, 17 Nov 2023 10:00:47 ", "Title": "Robustness Enhancement in Neural Networks with Alpha-Stable Training Noise", "Authors": ["Xueqiong Yuan", "Jipeng Li", "Ercan Engin Kuruo\\u{g}lu"], "Categories": "cs.LG"}, "abstract": "With the increasing use of deep learning on data collected by non-perfect sensors and in non-perfect environments, the robustness of deep learning systems has become an important issue. A common approach for obtaining robustness to noise has been to train deep learning systems with data augmented with Gaussian noise. In this work, we challenge the common choice of Gaussian noise and explore the possibility of stronger robustness for non-Gaussian impulsive noise, specifically alpha-stable noise. Justified by the Generalized Central Limit Theorem and evidenced by observations in various application areas, alpha-stable noise is widely present in nature. By comparing the testing accuracy of models trained with Gaussian noise and alpha-stable noise on data corrupted by different noise, we find that training with alpha-stable noise is more effective than Gaussian noise, especially when the dataset is corrupted by impulsive noise, thus improving the robustness of the model. The generality of this conclusion is validated through experiments conducted on various deep learning models with image and time series datasets, and other benchmark corrupted datasets. Consequently, we propose a novel data augmentation method that replaces Gaussian noise, which is typically added to the training data, with alpha-stable noise.", "url": "https://arxiv.org/abs/2311.10803"}, {"metadata": {"arXiv": "2311.10908", "Date": "Fri, 17 Nov 2023 23:28:22 ", "Title": "Equivariant Neural Operator Learning with Graphon Convolution", "Authors": ["Chaoran Cheng", "Jian Peng"], "Categories": "cs.LG"}, "abstract": "We propose a general architecture that combines the coefficient learning scheme with a residual operator layer for learning mappings between continuous functions in the 3D Euclidean space. Our proposed model is guaranteed to achieve SE(3)-equivariance by design. From the graph spectrum view, our method can be interpreted as convolution on graphons (dense graphs with infinitely many nodes), which we term InfGCN. By leveraging both the continuous graphon structure and the discrete graph structure of the input data, our model can effectively capture the geometric information while preserving equivariance. Through extensive experiments on large-scale electron density datasets, we observed that our model significantly outperformed the current state-of-the-art architectures. Multiple ablation studies were also carried out to demonstrate the effectiveness of the proposed architecture.", "url": "https://arxiv.org/abs/2311.10908"}, {"metadata": {"arXiv": "2311.10919", "Date": "Sat, 18 Nov 2023 00:20:57 ", "Title": "PACOL: Poisoning Attacks Against Continual Learners", "Authors": ["Huayu Li and Gregory Ditzler"], "Categories": "cs.LG"}, "abstract": "Continual learning algorithms are typically exposed to untrusted sources that contain training data inserted by adversaries and bad actors. An adversary can insert a small number of poisoned samples, such as mislabeled samples from previously learned tasks, or intentional adversarial perturbed samples, into the training datasets, which can drastically reduce the model's performance. In this work, we demonstrate that continual learning systems can be manipulated by malicious misinformation and present a new category of data poisoning attacks specific for continual learners, which we refer to as {\\em Poisoning Attacks Against Continual Learners} (PACOL). The effectiveness of labeling flipping attacks inspires PACOL; however, PACOL produces attack samples that do not change the sample's label and produce an attack that causes catastrophic forgetting. A comprehensive set of experiments shows the vulnerability of commonly used generative replay and regularization-based continual learning approaches against attack methods. We evaluate the ability of label-flipping and a new adversarial poison attack, namely PACOL proposed in this work, to force the continual learning system to forget the knowledge of a learned task(s). More specifically, we compared the performance degradation of continual learning systems trained on benchmark data streams with and without poisoning attacks. Moreover, we discuss the stealthiness of the attacks in which we test the success rate of data sanitization defense and other outlier detection-based defenses for filtering out adversarial samples.", "url": "https://arxiv.org/abs/2311.10919"}, {"metadata": {"arXiv": "2311.10937", "Date": "Sat, 18 Nov 2023 02:11:14 ", "Title": "Bridging Data-Driven and Knowledge-Driven Approaches for Safety-Critical Scenario Generation in Automated Vehicle Validation", "Authors": ["Kunkun Hao", "Lu Liu", "Wen Cui", "Jianxing Zhang", "Songyang Yan", "Yuxi Pan and Zijiang Yang"], "Categories": "cs.LG"}, "abstract": "Automated driving vehicles~(ADV) promise to enhance driving efficiency and safety, yet they face intricate challenges in safety-critical scenarios. As a result, validating ADV within generated safety-critical scenarios is essential for both development and performance evaluations. This paper investigates the complexities of employing two major scenario-generation solutions: data-driven and knowledge-driven methods. Data-driven methods derive scenarios from recorded datasets, efficiently generating scenarios by altering the existing behavior or trajectories of traffic participants but often falling short in considering ADV perception; knowledge-driven methods provide effective coverage through expert-designed rules, but they may lead to inefficiency in generating safety-critical scenarios within that coverage. To overcome these challenges, we introduce BridgeGen, a safety-critical scenario generation framework, designed to bridge the benefits of both methodologies. Specifically, by utilizing ontology-based techniques, BridgeGen models the five scenario layers in the operational design domain (ODD) from knowledge-driven methods, ensuring broad coverage, and incorporating data-driven strategies to efficiently generate safety-critical scenarios. An optimized scenario generation toolkit is developed within BridgeGen. This expedites the crafting of safety-critical scenarios through a combination of traditional optimization and reinforcement learning schemes. Extensive experiments conducted using Carla simulator demonstrate the effectiveness of BridgeGen in generating diverse safety-critical scenarios.", "url": "https://arxiv.org/abs/2311.10937"}, {"metadata": {"arXiv": "2311.10962", "Date": "Sat, 18 Nov 2023 04:01:46 ", "Title": "Classification Methods Based on Machine Learning for the Analysis of Fetal Health Data", "Authors": ["Binod Regmi and Chiranjibi Shah"], "Categories": "cs.LG"}, "abstract": "The persistent battle to decrease childhood mortality serves as a commonly employed benchmark for gauging advancements in the field of medicine. Globally, the under-5 mortality rate stands at approximately 5 million, with a significant portion of these deaths being avoidable. Given the significance of this problem, Machine learning-based techniques have emerged as a prominent tool for assessing fetal health. In this work, we have analyzed the classification performance of various machine learning models for fetal health analysis. Classification performance of various machine learning models, such as support vector machine (SVM), random forest(RF), and attentive interpretable tabular learning (TabNet) have been assessed on fetal health. Moreover, dimensionality reduction techniques, such as Principal component analysis (PCA) and Linear discriminant analysis (LDA) have been implemented to obtain better classification performance with less number of features. A TabNet model on a fetal health dataset provides a classification accuracy of 94.36%. In general, this technology empowers doctors and healthcare experts to achieve precise fetal health classification and identify the most influential features in the process.", "url": "https://arxiv.org/abs/2311.10962"}, {"metadata": {"arXiv": "2311.10972", "Date": "Sat, 18 Nov 2023 04:41:07 ", "Title": "Polynomial-Time Solutions for ReLU Network Training: A Complexity Classification via Max-Cut and Zonotopes", "Authors": ["Yifei Wang and Mert Pilanci"], "Categories": "cs.LG cs.CC stat.ML"}, "abstract": "We investigate the complexity of training a two-layer ReLU neural network with weight decay regularization. Previous research has shown that the optimal solution of this problem can be found by solving a standard cone-constrained convex program. Using this convex formulation, we prove that the hardness of approximation of ReLU networks not only mirrors the complexity of the Max-Cut problem but also, in certain special cases, exactly corresponds to it. In particular, when $\\epsilon\\leq\\sqrt{84/83}-1\\approx 0.006$, we show that it is NP-hard to find an approximate global optimizer of the ReLU network objective with relative error $\\epsilon$ with respect to the objective value. Moreover, we develop a randomized algorithm which mirrors the Goemans-Williamson rounding of semidefinite Max-Cut relaxations. To provide polynomial-time approximations, we classify training datasets into three categories: (i) For orthogonal separable datasets, a precise solution can be obtained in polynomial-time. (ii) When there is a negative correlation between samples of different classes, we give a polynomial-time approximation with relative error $\\sqrt{\\pi/2}-1\\approx 0.253$. (iii) For general datasets, the degree to which the problem can be approximated in polynomial-time is governed by a geometric factor that controls the diameter of two zonotopes intrinsic to the dataset. To our knowledge, these results present the first polynomial-time approximation guarantees along with first hardness of approximation results for regularized ReLU networks.", "url": "https://arxiv.org/abs/2311.10972"}, {"metadata": {"arXiv": "2311.10986", "Date": "Sat, 18 Nov 2023 06:40:39 ", "Title": "EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge", "Authors": ["Bufang Yang", "Lixing He", "Neiwen Ling", "Zhenyu Yan", "Guoliang Xing", "Xian Shuai", "Xiaozhe Ren", "Xin Jiang"], "Categories": "cs.LG"}, "abstract": "Deep Learning (DL) models have been widely deployed on IoT devices with the help of advancements in DL algorithms and chips. However, the limited resources of edge devices make these on-device DL models hard to be generalizable to diverse environments and tasks. Although the recently emerged foundation models (FMs) show impressive generalization power, how to effectively leverage the rich knowledge of FMs on resource-limited edge devices is still not explored. In this paper, we propose EdgeFM, a novel edge-cloud cooperative system with open-set recognition capability. EdgeFM selectively uploads unlabeled data to query the FM on the cloud and customizes the specific knowledge and architectures for edge models. Meanwhile, EdgeFM conducts dynamic model switching at run-time taking into account both data uncertainty and dynamic network variations, which ensures the accuracy always close to the original FM. We implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on three public datasets and two self-collected datasets. Results show that EdgeFM can reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy increase compared with the baseline.", "url": "https://arxiv.org/abs/2311.10986"}, {"metadata": {"arXiv": "2311.10996", "Date": "Sat, 18 Nov 2023 07:10:32 ", "Title": "BrainZ-BP: A Non-invasive Cuff-less Blood Pressure Estimation Approach Leveraging Brain Bio-impedance and Electrocardiogram", "Authors": ["Bufang Yang", "Le Liu", "Wenxuan Wu", "Mengliang Zhou", "Hongxing Liu", "Xinbao Ning"], "Categories": "cs.LG"}, "abstract": "Accurate and continuous blood pressure (BP) monitoring is essential to the early prevention of cardiovascular diseases. Non-invasive and cuff-less BP estimation algorithm has gained much attention in recent years. Previous studies have demonstrated that brain bio-impedance (BIOZ) is a promising technique for non-invasive intracranial pressure (ICP) monitoring. Clinically, treatment for patients with traumatic brain injuries (TBI) requires monitoring the ICP and BP of patients simultaneously. Estimating BP by brain BIOZ directly can reduce the number of sensors attached to the patients, thus improving their comfort. To address the issues, in this study, we explore the feasibility of leveraging brain BIOZ for BP estimation and propose a novel cuff-less BP estimation approach called BrainZ-BP. Two electrodes are placed on the forehead and occipital bone of the head in the anterior-posterior direction for brain BIOZ measurement. Various features including pulse transit time and morphological features of brain BIOZ are extracted and fed into four regression models for BP estimation. Results show that the mean absolute error, root mean square error, and correlation coefficient of random forest regression model are 2.17 mmHg, 3.91 mmHg, and 0.90 for systolic pressure estimation, and are 1.71 mmHg, 3.02 mmHg, and 0.89 for diastolic pressure estimation. The presented BrainZ-BP can be applied in the brain BIOZ-based ICP monitoring scenario to monitor BP simultaneously.", "url": "https://arxiv.org/abs/2311.10996"}, {"metadata": {"arXiv": "2311.11003", "Date": "Sat, 18 Nov 2023 07:53:22 ", "Title": "Wasserstein Convergence Guarantees for a General Class of Score-Based Generative Models", "Authors": ["Xuefeng Gao", "Hoang M. Nguyen", "Lingjiong Zhu"], "Categories": "cs.LG math.PR stat.ML"}, "abstract": "Score-based generative models (SGMs) is a recent class of deep generative models with state-of-the-art performance in many applications. In this paper, we establish convergence guarantees for a general class of SGMs in 2-Wasserstein distance, assuming accurate score estimates and smooth log-concave data distribution. We specialize our result to several concrete SGMs with specific choices of forward processes modelled by stochastic differential equations, and obtain an upper bound on the iteration complexity for each model, which demonstrates the impacts of different choices of the forward processes. We also provide a lower bound when the data distribution is Gaussian. Numerically, we experiment SGMs with different forward processes, some of which are newly proposed in this paper, for unconditional image generation on CIFAR-10. We find that the experimental results are in good agreement with our theoretical predictions on the iteration complexity, and the models with our newly proposed forward processes can outperform existing models.", "url": "https://arxiv.org/abs/2311.11003"}, {"metadata": {"arXiv": "2311.11018", "Date": "Sat, 18 Nov 2023 09:15:58 ", "Title": "SORTAD: Self-Supervised Optimized Random Transformations for Anomaly Detection in Tabular Data", "Authors": ["Guy Hay and Pablo Liberman"], "Categories": "cs.LG", "Comments": ["16 pages", "7 figures"], "ACM-class": "I.5.1"}, "abstract": "We consider a self-supervised approach to anomaly detection in tabular data. Random transformations are applied to the data, and then each transformation is identified based on its output. These predicted transformations are used to identify anomalies. In tabular data this approach faces many challenges that are related to the uncorrelated nature of the data. These challenges affect the transformations that should be used, as well as the use of their predictions. To this end, we propose SORTAD, a novel algorithm that is tailor-made to solve these challenges. SORTAD optimally chooses random transformations that help the classification process, and have a scoring function that is more sensitive to the changes in the transformations classification prediction encountered in tabular data. SORTAD achieved state-of-the-art results on multiple commonly used anomaly detection data sets, as well as in the overall results across all data sets tested.", "url": "https://arxiv.org/abs/2311.11018"}, {"metadata": {"arXiv": "2311.11057", "Date": "Sat, 18 Nov 2023 12:30:49 ", "Title": "Challenges in data-based geospatial modeling for environmental research and practice", "Authors": ["Diana Koldasbayeva", "Polina Tregubova", "Mikhail Gasanov", "Alexey Zaytsev", "Anna Petrovskaia", "Evgeny Burnaev"], "Categories": "cs.LG"}, "abstract": "With the rise of electronic data, particularly Earth observation data, data-based geospatial modelling using machine learning (ML) has gained popularity in environmental research. Accurate geospatial predictions are vital for domain research based on ecosystem monitoring and quality assessment and for policy-making and action planning, considering effective management of natural resources. The accuracy and computation speed of ML has generally proved efficient. However, many questions have yet to be addressed to obtain precise and reproducible results suitable for further use in both research and practice. A better understanding of the ML concepts applicable to geospatial problems enhances the development of data science tools providing transparent information crucial for making decisions on global challenges such as biosphere degradation and climate change. This survey reviews common nuances in geospatial modelling, such as imbalanced data, spatial autocorrelation, prediction errors, model generalisation, domain specificity, and uncertainty estimation. We provide an overview of techniques and popular programming tools to overcome or account for the challenges. We also discuss prospects for geospatial Artificial Intelligence in environmental applications.", "url": "https://arxiv.org/abs/2311.11057"}, {"metadata": {"arXiv": "2311.11058", "Date": "Sat, 18 Nov 2023 12:31:34 ", "Title": "Tactics2D: A Multi-agent Reinforcement Learning Environment for Driving Decision-making", "Authors": ["Yueyuan Li", "Songan Zhang", "Mingyang Jiang", "Xingyuan Chen", "Ming Yang"], "Categories": "cs.LG", "Comments": ["technique paper", "6 pages", "1 figure"]}, "abstract": "Tactics2D is an open-source multi-agent reinforcement learning library with a Python backend. Its goal is to provide a convenient toolset for researchers to develop decision-making algorithms for autonomous driving. The library includes diverse traffic scenarios implemented as gym-based environments equipped with multi-sensory capabilities and violation detection for traffic rules. Additionally, it features a reinforcement learning baseline tested with reasonable evaluation metrics. Tactics2D is highly modular and customizable. The source code of Tactics2D is available at https://github.com/WoodOxen/Tactics2D.", "url": "https://arxiv.org/abs/2311.11058"}, {"metadata": {"arXiv": "2311.11085", "Date": "Sat, 18 Nov 2023 14:20:56 ", "Title": "Compositional Fusion of Signals in Data Embedding", "Authors": ["Zhijin Guo", "Zhaozhen Xu", "Martha Lewis and Nello Cristianini"], "Categories": "cs.LG"}, "abstract": "Embeddings in AI convert symbolic structures into fixed-dimensional vectors, effectively fusing multiple signals. However, the nature of this fusion in real-world data is often unclear. To address this, we introduce two methods: (1) Correlation-based Fusion Detection, measuring correlation between known attributes and embeddings, and (2) Additive Fusion Detection, viewing embeddings as sums of individual vectors representing attributes. Applying these methods, word embeddings were found to combine semantic and morphological signals. BERT sentence embeddings were decomposed into individual word vectors of subject, verb and object. In the knowledge graph-based recommender system, user embeddings, even without training on demographic data, exhibited signals of demographics like age and gender. This study highlights that embeddings are fusions of multiple signals, from Word2Vec components to demographic hints in graph embeddings.", "url": "https://arxiv.org/abs/2311.11085"}, {"metadata": {"arXiv": "2311.11093", "Date": "Sat, 18 Nov 2023 14:45:06 ", "Title": "Flat Minima in Linear Estimation and an Extended Gauss Markov Theorem", "Authors": ["Simon Segert"], "Categories": "cs.LG stat.ML"}, "abstract": "We consider the problem of linear estimation, and establish an extension of the Gauss-Markov theorem, in which the bias operator is allowed to be non-zero but bounded with respect to a matrix norm of Schatten type. We derive simple and explicit formulas for the optimal estimator in the cases of Nuclear and Spectral norms (with the Frobenius case recovering ridge regression). Additionally, we analytically derive the generalization error in multiple random matrix ensembles, and compare with Ridge regression. Finally, we conduct an extensive simulation study, in which we show that the cross-validated Nuclear and Spectral regressors can outperform Ridge in several circumstances.", "url": "https://arxiv.org/abs/2311.11093"}, {"metadata": {"arXiv": "2311.11108", "Date": "Sat, 18 Nov 2023 15:50:07 ", "Title": "Auxiliary Losses for Learning Generalizable Concept-based Models", "Authors": ["Ivaxi Sheth", "Samira Ebrahimi Kahou"], "Categories": "cs.LG", "Comments": ["Neurips 2023"]}, "abstract": "The increasing use of neural networks in various applications has lead to increasing apprehensions, underscoring the necessity to understand their operations beyond mere final predictions. As a solution to enhance model transparency, Concept Bottleneck Models (CBMs) have gained popularity since their introduction. CBMs essentially limit the latent space of a model to human-understandable high-level concepts. While beneficial, CBMs have been reported to often learn irrelevant concept representations that consecutively damage model performance. To overcome the performance trade-off, we propose cooperative-Concept Bottleneck Model (coop-CBM). The concept representation of our model is particularly meaningful when fine-grained concept labels are absent. Furthermore, we introduce the concept orthogonal loss (COL) to encourage the separation between the concept representations and to reduce the intra-concept distance. This paper presents extensive experiments on real-world datasets for image classification tasks, namely CUB, AwA2, CelebA and TIL. We also study the performance of coop-CBM models under various distributional shift settings. We show that our proposed method achieves higher accuracy in all distributional shift settings even compared to the black-box models with the highest concept accuracy.", "url": "https://arxiv.org/abs/2311.11108"}, {"metadata": {"arXiv": "2311.11172", "Date": "Sat, 18 Nov 2023 21:36:52 ", "Title": "Low-Precision Floating-Point for Efficient On-Board Deep Neural Network Processing", "Authors": ["C\\'edric Gernigon and Silviu-Ioan Filip and Olivier Sentieys and Cl\\'ement Coggiola and Micka\\\"el Bruno"], "Categories": "cs.LG eess.SP", "Comments": ["7 pages", "7 figures", "EDHPC 2023"]}, "abstract": "One of the major bottlenecks in high-resolution Earth Observation (EO) space systems is the downlink between the satellite and the ground. Due to hardware limitations, on-board power limitations or ground-station operation costs, there is a strong need to reduce the amount of data transmitted. Various processing methods can be used to compress the data. One of them is the use of on-board deep learning to extract relevant information in the data. However, most ground-based deep neural network parameters and computations are performed using single-precision floating-point arithmetic, which is not adapted to the context of on-board processing. We propose to rely on quantized neural networks and study how to combine low precision (mini) floating-point arithmetic with a Quantization-Aware Training methodology. We evaluate our approach with a semantic segmentation task for ship detection using satellite images from the Airbus Ship dataset. Our results show that 6-bit floating-point quantization for both weights and activations can compete with single-precision without significant accuracy degradation. Using a Thin U-Net 32 model, only a 0.3% accuracy degradation is observed with 6-bit minifloat quantization (a 6-bit equivalent integer-based approach leads to a 0.5% degradation). An initial hardware study also confirms the potential impact of such low-precision floating-point designs, but further investigation at the scale of a full inference accelerator is needed before concluding whether they are relevant in a practical on-board scenario.", "url": "https://arxiv.org/abs/2311.11172"}, {"metadata": {"arXiv": "2311.11206", "Date": "Sun, 19 Nov 2023 03:07:29 ", "Title": "Robust Network Slicing: Multi-Agent Policies, Adversarial Attacks, and Defensive Strategies", "Authors": ["Feng Wang", "M. Cenk Gursoy", "and Senem Velipasalar"], "Categories": "cs.LG cs.CR cs.MA", "Comments": ["Published in IEEE Transactions on Machine Learning in Communications and Networking (TMLCN)"], "DOI": "10.1109/TMLCN.2023.3334236"}, "abstract": "In this paper, we present a multi-agent deep reinforcement learning (deep RL) framework for network slicing in a dynamic environment with multiple base stations and multiple users. In particular, we propose a novel deep RL framework with multiple actors and centralized critic (MACC) in which actors are implemented as pointer networks to fit the varying dimension of input. We evaluate the performance of the proposed deep RL algorithm via simulations to demonstrate its effectiveness. Subsequently, we develop a deep RL based jammer with limited prior information and limited power budget. The goal of the jammer is to minimize the transmission rates achieved with network slicing and thus degrade the network slicing agents' performance. We design a jammer with both listening and jamming phases and address jamming location optimization as well as jamming channel optimization via deep RL. We evaluate the jammer at the optimized location, generating interference attacks in the optimized set of channels by switching between the jamming phase and listening phase. We show that the proposed jammer can significantly reduce the victims' performance without direct feedback or prior knowledge on the network slicing policies. Finally, we devise a Nash-equilibrium-supervised policy ensemble mixed strategy profile for network slicing (as a defensive measure) and jamming. We evaluate the performance of the proposed policy ensemble algorithm by applying on the network slicing agents and the jammer agent in simulations to show its effectiveness.", "url": "https://arxiv.org/abs/2311.11206"}, {"metadata": {"arXiv": "2311.11225", "Date": "Sun, 19 Nov 2023 04:42:16 ", "Title": "TextGuard: Provable Defense against Backdoor Attacks on Text Classification", "Authors": ["Hengzhi Pei", "Jinyuan Jia", "Wenbo Guo", "Bo Li", "Dawn Song"], "Categories": "cs.LG cs.CR", "Comments": ["Accepted by NDSS Symposium 2024"]}, "abstract": "Backdoor attacks have become a major security threat for deploying machine learning models in security-critical applications. Existing research endeavors have proposed many defenses against backdoor attacks. Despite demonstrating certain empirical defense efficacy, none of these techniques could provide a formal and provable security guarantee against arbitrary attacks. As a result, they can be easily broken by strong adaptive attacks, as shown in our evaluation. In this work, we propose TextGuard, the first provable defense against backdoor attacks on text classification. In particular, TextGuard first divides the (backdoored) training data into sub-training sets, achieved by splitting each training sentence into sub-sentences. This partitioning ensures that a majority of the sub-training sets do not contain the backdoor trigger. Subsequently, a base classifier is trained from each sub-training set, and their ensemble provides the final prediction. We theoretically prove that when the length of the backdoor trigger falls within a certain threshold, TextGuard guarantees that its prediction will remain unaffected by the presence of the triggers in training and testing inputs. In our evaluation, we demonstrate the effectiveness of TextGuard on three benchmark text classification tasks, surpassing the certification accuracy of existing certified defenses against backdoor attacks. Furthermore, we propose additional strategies to enhance the empirical performance of TextGuard. Comparisons with state-of-the-art empirical defenses validate the superiority of TextGuard in countering multiple backdoor attacks. Our code and data are available at https://github.com/AI-secure/TextGuard.", "url": "https://arxiv.org/abs/2311.11225"}, {"metadata": {"arXiv": "2311.11228", "Date": "Sun, 19 Nov 2023 04:52:05 ", "Title": "A Universal Framework for Accurate and Efficient Geometric Deep Learning of Molecular Systems", "Authors": ["Shuo Zhang", "Yang Liu", "Lei Xie"], "Categories": "cs.LG q-bio.BM", "Comments": ["Published in Scientific Reports (DOI: 10.1038/s41598-023-46382-8)"], "Journal-ref": "Scientific Reports 13, 19171 (2023)", "DOI": "10.1038/s41598-023-46382-8"}, "abstract": "Molecular sciences address a wide range of problems involving molecules of different types and sizes and their complexes. Recently, geometric deep learning, especially Graph Neural Networks, has shown promising performance in molecular science applications. However, most existing works often impose targeted inductive biases to a specific molecular system, and are inefficient when applied to macromolecules or large-scale tasks, thereby limiting their applications to many real-world problems. To address these challenges, we present PAMNet, a universal framework for accurately and efficiently learning the representations of three-dimensional (3D) molecules of varying sizes and types in any molecular system. Inspired by molecular mechanics, PAMNet induces a physics-informed bias to explicitly model local and non-local interactions and their combined effects. As a result, PAMNet can reduce expensive operations, making it time and memory efficient. In extensive benchmark studies, PAMNet outperforms state-of-the-art baselines regarding both accuracy and efficiency in three diverse learning tasks: small molecule properties, RNA 3D structures, and protein-ligand binding affinities. Our results highlight the potential for PAMNet in a broad range of molecular science applications.", "url": "https://arxiv.org/abs/2311.11228"}, {"metadata": {"arXiv": "2311.11262", "Date": "Sun, 19 Nov 2023 08:18:26 ", "Title": "Uncertainty quantification for noisy inputs-outputs in physics-informed neural networks and neural operators", "Authors": ["Zongren Zou", "Xuhui Meng", "George Em Karniadakis"], "Categories": "cs.LG physics.comp-ph"}, "abstract": "Uncertainty quantification (UQ) in scientific machine learning (SciML) becomes increasingly critical as neural networks (NNs) are being widely adopted in addressing complex problems across various scientific disciplines. Representative SciML models are physics-informed neural networks (PINNs) and neural operators (NOs). While UQ in SciML has been increasingly investigated in recent years, very few works have focused on addressing the uncertainty caused by the noisy inputs, such as spatial-temporal coordinates in PINNs and input functions in NOs. The presence of noise in the inputs of the models can pose significantly more challenges compared to noise in the outputs of the models, primarily due to the inherent nonlinearity of most SciML algorithms. As a result, UQ for noisy inputs becomes a crucial factor for reliable and trustworthy deployment of these models in applications involving physical knowledge. To this end, we introduce a Bayesian approach to quantify uncertainty arising from noisy inputs-outputs in PINNs and NOs. We show that this approach can be seamlessly integrated into PINNs and NOs, when they are employed to encode the physical information. PINNs incorporate physics by including physics-informed terms via automatic differentiation, either in the loss function or the likelihood, and often take as input the spatial-temporal coordinate. Therefore, the present method equips PINNs with the capability to address problems where the observed coordinate is subject to noise. On the other hand, pretrained NOs are also commonly employed as equation-free surrogates in solving differential equations and Bayesian inverse problems, in which they take functions as inputs. The proposed approach enables them to handle noisy measurements for both input and output functions with UQ.", "url": "https://arxiv.org/abs/2311.11262"}, {"metadata": {"arXiv": "2311.11285", "Date": "Sun, 19 Nov 2023 10:05:50 ", "Title": "TimeSQL: Improving Multivariate Time Series Forecasting with Multi-Scale Patching and Smooth Quadratic Loss", "Authors": ["Site Mo", "Haoxin Wang", "Bixiong Li", "Songhai Fan", "Yuankai Wu", "Xianggen Liu"], "Categories": "cs.LG"}, "abstract": "Time series is a special type of sequence data, a sequence of real-valued random variables collected at even intervals of time. The real-world multivariate time series comes with noises and contains complicated local and global temporal dynamics, making it difficult to forecast the future time series given the historical observations. This work proposes a simple and effective framework, coined as TimeSQL, which leverages multi-scale patching and smooth quadratic loss (SQL) to tackle the above challenges. The multi-scale patching transforms the time series into two-dimensional patches with different length scales, facilitating the perception of both locality and long-term correlations in time series. SQL is derived from the rational quadratic kernel and can dynamically adjust the gradients to avoid overfitting to the noises and outliers. Theoretical analysis demonstrates that, under mild conditions, the effect of the noises on the model with SQL is always smaller than that with MSE. Based on the two modules, TimeSQL achieves new state-of-the-art performance on the eight real-world benchmark datasets. Further ablation studies indicate that the key modules in TimeSQL could also enhance the results of other models for multivariate time series forecasting, standing as plug-and-play techniques.", "url": "https://arxiv.org/abs/2311.11285"}, {"metadata": {"arXiv": "2311.11293", "Date": "Sun, 19 Nov 2023 10:43:43 ", "Title": "From Categories to Classifier: Name-Only Continual Learning by Exploring the Web", "Authors": ["Ameya Prabhu", "Hasan Abed Al Kader Hammoud", "Ser-Nam Lim", "Bernard Ghanem", "Philip H.S. Torr", "Adel Bibi"], "Categories": "cs.LG"}, "abstract": "Continual Learning (CL) often relies on the availability of extensive annotated datasets, an assumption that is unrealistically time-consuming and costly in practice. We explore a novel paradigm termed name-only continual learning where time and cost constraints prohibit manual annotation. In this scenario, learners adapt to new category shifts using only category names without the luxury of annotated training data. Our proposed solution leverages the expansive and ever-evolving internet to query and download uncurated webly-supervised data for image classification. We investigate the reliability of our web data and find them comparable, and in some cases superior, to manually annotated datasets. Additionally, we show that by harnessing the web, we can create support sets that surpass state-of-the-art name-only classification that create support sets using generative models or image retrieval from LAION-5B, achieving up to 25% boost in accuracy. When applied across varied continual learning contexts, our method consistently exhibits a small performance gap in comparison to models trained on manually annotated datasets. We present EvoTrends, a class-incremental dataset made from the web to capture real-world trends, created in just minutes. Overall, this paper underscores the potential of using uncurated webly-supervised data to mitigate the challenges associated with manual data labeling in continual learning.", "url": "https://arxiv.org/abs/2311.11293"}, {"metadata": {"arXiv": "2311.11303", "Date": "Sun, 19 Nov 2023 11:36:35 ", "Title": "Large Learning Rates Improve Generalization: But How Large Are We Talking About?", "Authors": ["Ekaterina Lobacheva", "Eduard Pockonechnyy", "Maxim Kodryan", "Dmitry Vetrov"], "Categories": "cs.LG stat.ML", "Comments": ["Published in Mathematics of Modern Machine Learning Workshop at NeurIPS 2023. First two authors contributed equally"]}, "abstract": "Inspired by recent research that recommends starting neural networks training with large learning rates (LRs) to achieve the best generalization, we explore this hypothesis in detail. Our study clarifies the initial LR ranges that provide optimal results for subsequent training with a small LR or weight averaging. We find that these ranges are in fact significantly narrower than generally assumed. We conduct our main experiments in a simplified setup that allows precise control of the learning rate hyperparameter and validate our key findings in a more practical setting.", "url": "https://arxiv.org/abs/2311.11303"}, {"metadata": {"arXiv": "2311.11328", "Date": "Sun, 19 Nov 2023 13:56:24 ", "Title": "LABCAT: Locally adaptive Bayesian optimization using principal component-aligned trust regions", "Authors": ["E. Visser", "C.E. van Daalen", "J.C. Schoeman"], "Categories": "cs.LG"}, "abstract": "Bayesian optimization (BO) is a popular method for optimizing expensive black-box functions. BO has several well-documented shortcomings, including computational slowdown with longer optimization runs, poor suitability for non-stationary or ill-conditioned objective functions, and poor convergence characteristics. Several algorithms have been proposed that incorporate local strategies, such as trust regions, into BO to mitigate these limitations; however, none address all of them satisfactorily. To address these shortcomings, we propose the LABCAT algorithm, which extends trust-region-based BO by adding principal-component-aligned rotation and an adaptive rescaling strategy based on the length-scales of a local Gaussian process surrogate model with automatic relevance determination. Through extensive numerical experiments using a set of synthetic test functions and the well-known COCO benchmarking software, we show that the LABCAT algorithm outperforms several state-of-the-art BO and other black-box optimization algorithms.", "url": "https://arxiv.org/abs/2311.11328"}, {"metadata": {"arXiv": "2311.11335", "Date": "Sun, 19 Nov 2023 14:34:01 ", "Title": "Self-Distilled Representation Learning for Time Series", "Authors": ["Felix Pieper and Konstantin Ditschuneit and Martin Genzel and Alexandra Lindt and Johannes Otterbach"], "Categories": "cs.LG", "Comments": ["Presented at the NeurIPS 2023 Workshop: Self-Supervised Learning - Theory and Practice"]}, "abstract": "Self-supervised learning for time-series data holds potential similar to that recently unleashed in Natural Language Processing and Computer Vision. While most existing works in this area focus on contrastive learning, we propose a conceptually simple yet powerful non-contrastive approach, based on the data2vec self-distillation framework. The core of our method is a student-teacher scheme that predicts the latent representation of an input time series from masked views of the same time series. This strategy avoids strong modality-specific assumptions and biases typically introduced by the design of contrastive sample pairs. We demonstrate the competitiveness of our approach for classification and forecasting as downstream tasks, comparing with state-of-the-art self-supervised learning methods on the UCR and UEA archives as well as the ETT and Electricity datasets.", "url": "https://arxiv.org/abs/2311.11335"}, {"metadata": {"arXiv": "2311.11342", "Date": "Sun, 19 Nov 2023 14:56:26 ", "Title": "On the Communication Complexity of Decentralized Bilevel Optimization", "Authors": ["Yihan Zhang", "My T. Thai", "Jie Wu", "Hongchang Gao"], "Categories": "cs.LG cs.DC math.OC"}, "abstract": "Decentralized bilevel optimization has been actively studied in the past few years since it has widespread applications in machine learning. However, existing algorithms suffer from large communication complexity caused by the estimation of stochastic hypergradient, limiting their application to real-world tasks. To address this issue, we develop a novel decentralized stochastic bilevel gradient descent algorithm under the heterogeneous setting, which enjoys a small communication cost in each round and small communication rounds. As such, it can achieve a much better communication complexity than existing algorithms. Moreover, we extend our algorithm to the more challenging decentralized multi-level optimization. To the best of our knowledge, this is the first time achieving these theoretical results under the heterogeneous setting. At last, the experimental results confirm the efficacy of our algorithm.", "url": "https://arxiv.org/abs/2311.11342"}, {"metadata": {"arXiv": "2311.11343", "Date": "Sun, 19 Nov 2023 15:03:19 ", "Title": "A Generative Model for Accelerated Inverse Modelling Using a Novel Embedding for Continuous Variables", "Authors": ["S\\'ebastien Bompas abd Stefan Sandfeld"], "Categories": "cs.LG cond-mat.mtrl-sci", "Comments": ["9 pages", "8 figures", "NeurIPS 2023"]}, "abstract": "In materials science, the challenge of rapid prototyping materials with desired properties often involves extensive experimentation to find suitable microstructures. Additionally, finding microstructures for given properties is typically an ill-posed problem where multiple solutions may exist. Using generative machine learning models can be a viable solution which also reduces the computational cost. This comes with new challenges because, e.g., a continuous property variable as conditioning input to the model is required. We investigate the shortcomings of an existing method and compare this to a novel embedding strategy for generative models that is based on the binary representation of floating point numbers. This eliminates the need for normalization, preserves information, and creates a versatile embedding space for conditioning the generative model. This technique can be applied to condition a network on any number, to provide fine control over generated microstructure images, thereby contributing to accelerated materials design.", "url": "https://arxiv.org/abs/2311.11343"}, {"metadata": {"arXiv": "2311.11349", "Date": "Sun, 19 Nov 2023 15:21:49 ", "Title": "Coverage-Validity-Aware Algorithmic Recourse", "Authors": ["Ngoc Bui", "Duy Nguyen", "Man-Chung Yue", "Viet Anh Nguyen"], "Categories": "cs.LG math.OC"}, "abstract": "Algorithmic recourse emerges as a prominent technique to promote the explainability, transparency and hence ethics of machine learning models. Existing algorithmic recourse approaches often assume an invariant predictive model; however, the predictive model is usually updated upon the arrival of new data. Thus, a recourse that is valid respective to the present model may become invalid for the future model. To resolve this issue, we propose a novel framework to generate a model-agnostic recourse that exhibits robustness to model shifts. Our framework first builds a coverage-validity-aware linear surrogate of the nonlinear (black-box) model; then, the recourse is generated with respect to the linear surrogate. We establish a theoretical connection between our coverage-validity-aware linear surrogate and the minimax probability machines (MPM). We then prove that by prescribing different covariance robustness, the proposed framework recovers popular regularizations for MPM, including the $\\ell_2$-regularization and class-reweighting. Furthermore, we show that our surrogate pushes the approximate hyperplane intuitively, facilitating not only robust but also interpretable recourses. The numerical results demonstrate the usefulness and robustness of our framework.", "url": "https://arxiv.org/abs/2311.11349"}, {"metadata": {"arXiv": "2311.11367", "Date": "Sun, 19 Nov 2023 16:33:42 ", "Title": "Evidential Uncertainty Quantification: A Variance-Based Perspective", "Authors": ["Ruxiao Duan", "Brian Caffo", "Harrison X. Bai", "Haris I. Sair", "Craig Jones"], "Categories": "cs.LG cs.CV", "Comments": ["IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024"]}, "abstract": "Uncertainty quantification of deep neural networks has become an active field of research and plays a crucial role in various downstream tasks such as active learning. Recent advances in evidential deep learning shed light on the direct quantification of aleatoric and epistemic uncertainties with a single forward pass of the model. Most traditional approaches adopt an entropy-based method to derive evidential uncertainty in classification, quantifying uncertainty at the sample level. However, the variance-based method that has been widely applied in regression problems is seldom used in the classification setting. In this work, we adapt the variance-based approach from regression to classification, quantifying classification uncertainty at the class level. The variance decomposition technique in regression is extended to class covariance decomposition in classification based on the law of total covariance, and the class correlation is also derived from the covariance. Experiments on cross-domain datasets are conducted to illustrate that the variance-based approach not only results in similar accuracy as the entropy-based one in active domain adaptation but also brings information about class-wise uncertainties as well as between-class correlations. The code is available at https://github.com/KerryDRX/EvidentialADA. This alternative means of evidential uncertainty quantification will give researchers more options when class uncertainties and correlations are important in their applications.", "url": "https://arxiv.org/abs/2311.11367"}, {"metadata": {"arXiv": "2311.11368", "Date": "Sun, 19 Nov 2023 16:34:56 ", "Title": "Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks", "Authors": ["Abdalgader Abubaker", "Takanori Maehara", "Madhav Nimishakavi", "Vassilis Plachouras"], "Categories": "cs.LG cs.SI stat.ML"}, "abstract": "Recently, pretraining methods for the Graph Neural Networks (GNNs) have been successful at learning effective representations from unlabeled graph data. However, most of these methods rely on pairwise relations in the graph and do not capture the underling higher-order relations between entities. Hypergraphs are versatile and expressive structures that can effectively model higher-order relationships among entities in the data. Despite the efforts to adapt GNNs to hypergraphs (HyperGNN), there are currently no fully self-supervised pretraining methods for HyperGNN on heterogeneous hypergraphs. In this paper, we present SPHH, a novel self-supervised pretraining framework for heterogeneous HyperGNNs. Our method is able to effectively capture higher-order relations among entities in the data in a self-supervised manner. SPHH is consist of two self-supervised pretraining tasks that aim to simultaneously learn both local and global representations of the entities in the hypergraph by using informative representations derived from the hypergraph structure. Overall, our work presents a significant advancement in the field of self-supervised pretraining of HyperGNNs, and has the potential to improve the performance of various graph-based downstream tasks such as node classification and link prediction tasks which are mapped to hypergraph configuration. Our experiments on two real-world benchmarks using four different HyperGNN models show that our proposed SPHH framework consistently outperforms state-of-the-art baselines in various downstream tasks. The results demonstrate that SPHH is able to improve the performance of various HyperGNN models in various downstream tasks, regardless of their architecture or complexity, which highlights the robustness of our framework.", "url": "https://arxiv.org/abs/2311.11368"}, {"metadata": {"arXiv": "2311.11385", "Date": "Sun, 19 Nov 2023 18:09:25 ", "Title": "Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts", "Authors": ["Ahmed Hendawy", "Jan Peters", "Carlo D'Eramo"], "Categories": "cs.LG", "Comments": ["Under review"]}, "abstract": "Multi-Task Reinforcement Learning (MTRL) tackles the long-standing problem of endowing agents with skills that generalize across a variety of problems. To this end, sharing representations plays a fundamental role in capturing both unique and common characteristics of the tasks. Tasks may exhibit similarities in terms of skills, objects, or physical properties while leveraging their representations eases the achievement of a universal policy. Nevertheless, the pursuit of learning a shared set of diverse representations is still an open challenge. In this paper, we introduce a novel approach for representation learning in MTRL that encapsulates common structures among the tasks using orthogonal representations to promote diversity. Our method, named Mixture Of Orthogonal Experts (MOORE), leverages a Gram-Schmidt process to shape a shared subspace of representations generated by a mixture of experts. When task-specific information is provided, MOORE generates relevant representations from this shared subspace. We assess the effectiveness of our approach on two MTRL benchmarks, namely MiniGrid and MetaWorld, showing that MOORE surpasses related baselines and establishes a new state-of-the-art result on MetaWorld.", "url": "https://arxiv.org/abs/2311.11385"}, {"metadata": {"arXiv": "2311.11396", "Date": "Sun, 19 Nov 2023 18:40:49 ", "Title": "Towards interpretable-by-design deep learning algorithms", "Authors": ["Plamen Angelov", "Dmitry Kangin", "Ziyang Zhang"], "Categories": "cs.LG"}, "abstract": "The proposed framework named IDEAL (Interpretable-by-design DEep learning ALgorithms) recasts the standard supervised classification problem into a function of similarity to a set of prototypes derived from the training data, while taking advantage of existing latent spaces of large neural networks forming so-called Foundation Models (FM). This addresses the issue of explainability (stage B) while retaining the benefits from the tremendous achievements offered by DL models (e.g., visual transformers, ViT) pre-trained on huge data sets such as IG-3.6B + ImageNet-1K or LVD-142M (stage A). We show that one can turn such DL models into conceptually simpler, explainable-through-prototypes ones. The key findings can be summarized as follows: (1) the proposed models are interpretable through prototypes, mitigating the issue of confounded interpretations, (2) the proposed IDEAL framework circumvents the issue of catastrophic forgetting allowing efficient class-incremental learning, and (3) the proposed IDEAL approach demonstrates that ViT architectures narrow the gap between finetuned and non-finetuned models allowing for transfer learning in a fraction of time \\textbf{without} finetuning of the feature space on a target dataset with iterative supervised methods.", "url": "https://arxiv.org/abs/2311.11396"}, {"metadata": {"arXiv": "2311.11410", "Date": "Sun, 19 Nov 2023 19:53:49 ", "Title": "Negotiated Representations for Machine Mearning Application", "Authors": ["Nuri Korhan", "Samet Bayram"], "Categories": "cs.LG", "Comments": ["10 pages", "10 figures", "2 tables"]}, "abstract": "Overfitting is a phenomenon that occurs when a machine learning model is trained for too long and focused too much on the exact fitness of the training samples to the provided training labels and cannot keep track of the predictive rules that would be useful on the test data. This phenomenon is commonly attributed to memorization of particular samples, memorization of the noise, and forced fitness into a data set of limited samples by using a high number of neurons. While it is true that the model encodes various peculiarities as the training process continues, we argue that most of the overfitting occurs in the process of reconciling sharply defined membership ratios. In this study, we present an approach that increases the classification accuracy of machine learning models by allowing the model to negotiate output representations of the samples with previously determined class labels. By setting up a negotiation between the models interpretation of the inputs and the provided labels, we not only increased average classification accuracy but also decreased the rate of overfitting without applying any other regularization tricks. By implementing our negotiation paradigm approach to several low regime machine learning problems by generating overfitting scenarios from publicly available data sets such as CIFAR 10, CIFAR 100, and MNIST we have demonstrated that the proposed paradigm has more capacity than its intended purpose. We are sharing the experimental results and inviting the machine learning community to explore the limits of the proposed paradigm. We also aim to incentive the community to exploit the negotiation paradigm to overcome the learning related challenges in other research fields such as continual learning. The Python code of the experimental setup is uploaded to GitHub.", "url": "https://arxiv.org/abs/2311.11410"}, {"metadata": {"arXiv": "2311.11413", "Date": "Sun, 19 Nov 2023 20:16:16 ", "Title": "Large Pre-trained time series models for cross-domain Time series analysis tasks", "Authors": ["Harshavardhan Kamarthi", "B. Aditya Prakash"], "Categories": "cs.LG", "Comments": ["14 pages", "3 Figures", "3 Tables"]}, "abstract": "Large pre-trained models have been instrumental in significant advancements in domains like language and vision making model training for individual downstream tasks more efficient as well as provide superior performance. However, tackling time-series analysis tasks usually involves designing and training a separate model from scratch leveraging training data and domain expertise specific to the task. We tackle a significant challenge for pre-training a general time-series model from multiple heterogeneous time-series dataset: providing semantically useful inputs to models for modeling time series of different dynamics from different domains. We observe that partitioning time-series into segments as inputs to sequential models produces semantically better inputs and propose a novel model LPTM that automatically identifies optimal dataset-specific segmentation strategy leveraging self-supervised learning loss during pre-training. LPTM provides performance similar to or better than domain-specific state-of-art model and is significantly more data and compute efficient taking up to 40% less data as well as 50% less training time to achieve state-of-art performance in a wide range of time-series analysis tasks from multiple disparate domain.", "url": "https://arxiv.org/abs/2311.11413"}, {"metadata": {"arXiv": "2311.11422", "Date": "Sun, 19 Nov 2023 20:47:39 ", "Title": "Precision at the indistinguishability threshold: a method for evaluating classification algorithms", "Authors": ["David J. T. Sumpter"], "Categories": "cs.LG stat.ML"}, "abstract": "There exist a wide range of single number metrics for assessing performance of classification algorithms, including AUC and the F1-score (Wikipedia lists 17 such metrics, with 27 different names). In this article, I propose a new metric to answer the following question: when an algorithm is tuned so that it can no longer distinguish labelled cats from real cats, how often does a randomly chosen image that has been labelled as containing a cat actually contain a cat? The steps to construct this metric are as follows. First, we set a threshold score such that when the algorithm is shown two randomly-chosen images -- one that has a score greater than the threshold (i.e. a picture labelled as containing a cat) and another from those pictures that really does contain a cat -- the probability that the image with the highest score is the one chosen from the set of real cat images is 50\\%. At this decision threshold, the set of positively labelled images are indistinguishable from the set of images which are positive. Then, as a second step, we measure performance by asking how often a randomly chosen picture from those labelled as containing a cat actually contains a cat. This metric can be thought of as {\\it precision at the indistinguishability threshold}. While this new metric doesn't address the tradeoff between precision and recall inherent to all such metrics, I do show why this method avoids pitfalls that can occur when using, for example AUC, and it is better motivated than, for example, the F1-score.", "url": "https://arxiv.org/abs/2311.11422"}, {"metadata": {"arXiv": "2311.11429", "Date": "Sun, 19 Nov 2023 21:40:16 ", "Title": "Fast Heavy Inner Product Identification Between Weights and Inputs in Neural Network Training", "Authors": ["Lianke Qin", "Saayan Mitra", "Zhao Song", "Yuanyuan Yang", "Tianyi Zhou"], "Categories": "cs.LG", "Comments": ["IEEE BigData 2023"]}, "abstract": "In this paper, we consider a heavy inner product identification problem, which generalizes the Light Bulb problem~(\\cite{prr89}): Given two sets $A \\subset \\{-1,+1\\}^d$ and $B \\subset \\{-1,+1\\}^d$ with $|A|=|B| = n$, if there are exact $k$ pairs whose inner product passes a certain threshold, i.e., $\\{(a_1, b_1), \\cdots, (a_k, b_k)\\} \\subset A \\times B$ such that $\\forall i \\in [k], \\langle a_i,b_i \\rangle \\geq \\rho \\cdot d$, for a threshold $\\rho \\in (0,1)$, the goal is to identify those $k$ heavy inner products. We provide an algorithm that runs in $O(n^{2 \\omega / 3+ o(1)})$ time to find the $k$ inner product pairs that surpass $\\rho \\cdot d$ threshold with high probability, where $\\omega$ is the current matrix multiplication exponent. By solving this problem, our method speed up the training of neural networks with ReLU activation function.", "url": "https://arxiv.org/abs/2311.11429"}, {"metadata": {"arXiv": "2311.11446", "Date": "Sun, 19 Nov 2023 23:00:27 ", "Title": "Weight Norm Control", "Authors": ["Ilya Loshchilov"], "Categories": "cs.LG"}, "abstract": "We note that decoupled weight decay regularization is a particular case of weight norm control where the target norm of weights is set to 0. Any optimization method (e.g., Adam) which uses decoupled weight decay regularization (respectively, AdamW) can be viewed as a particular case of a more general algorithm with weight norm control (respectively, AdamWN). We argue that setting the target norm of weights to 0 can be suboptimal and other target norm values can be considered. For instance, any training run where AdamW achieves a particular norm of weights can be challenged by AdamWN scheduled to achieve a comparable norm of weights. We discuss various implications of introducing weight norm control instead of weight decay.", "url": "https://arxiv.org/abs/2311.11446"}, {"metadata": {"arXiv": "2311.11452", "Date": "Sun, 19 Nov 2023 23:20:16 ", "Title": "Physics-Enhanced TinyML for Real-Time Detection of Ground Magnetic Anomalies", "Authors": ["Talha Siddique and MD Shaad Mahmud"], "Categories": "cs.LG eess.SP", "Comments": ["13 pages", "7 figures"]}, "abstract": "Space weather phenomena like geomagnetic disturbances (GMDs) and geomagnetically induced currents (GICs) pose significant risks to critical technological infrastructure. While traditional predictive models, grounded in simulation, hold theoretical robustness, they grapple with challenges, notably the assimilation of imprecise data and extensive computational complexities. In recent years, Tiny Machine Learning (TinyML) has been adopted to develop Machine Learning (ML)-enabled magnetometer systems for predicting real-time terrestrial magnetic perturbations as a proxy measure for GIC. While TinyML offers efficient, real-time data processing, its intrinsic limitations prevent the utilization of robust methods with high computational needs. This paper developed a physics-guided TinyML framework to address the above challenges. This framework integrates physics-based regularization at the stages of model training and compression, thereby augmenting the reliability of predictions. The developed pruning scheme within the framework harnesses the inherent physical characteristics of the domain, striking a balance between model size and robustness. The study presents empirical results, drawing a comprehensive comparison between the accuracy and reliability of the developed framework and its traditional counterpart. Such a comparative analysis underscores the prospective applicability of the developed framework in conceptualizing robust, ML-enabled magnetometer systems for real-time space weather forecasting.", "url": "https://arxiv.org/abs/2311.11452"}, {"metadata": {"arXiv": "2311.11463", "Date": "Mon, 20 Nov 2023 00:15:16 ", "Title": "Towards a Post-Market Monitoring Framework for Machine Learning-based Medical Devices: A case study", "Authors": ["Jean Feng", "Adarsh Subbaswamy", "Alexej Gossmann", "Harvineet Singh", "Berkman Sahiner", "Mi-Ok Kim", "Gene Pennello", "Nicholas Petrick", "Romain Pirracchio", "Fan Xia"], "Categories": "cs.LG stat.ML"}, "abstract": "After a machine learning (ML)-based system is deployed in clinical practice, performance monitoring is important to ensure the safety and effectiveness of the algorithm over time. The goal of this work is to highlight the complexity of designing a monitoring strategy and the need for a systematic framework that compares the multitude of monitoring options. One of the main decisions is choosing between using real-world (observational) versus interventional data. Although the former is the most convenient source of monitoring data, it exhibits well-known biases, such as confounding, selection, and missingness. In fact, when the ML algorithm interacts with its environment, the algorithm itself may be a primary source of bias. On the other hand, a carefully designed interventional study that randomizes individuals can explicitly eliminate such biases, but the ethics, feasibility, and cost of such an approach must be carefully considered. Beyond the decision of the data source, monitoring strategies vary in the performance criteria they track, the interpretability of the test statistics, the strength of their assumptions, and their speed at detecting performance decay. As a first step towards developing a framework that compares the various monitoring options, we consider a case study of an ML-based risk prediction algorithm for postoperative nausea and vomiting (PONV). Bringing together tools from causal inference and statistical process control, we walk through the basic steps of defining candidate monitoring criteria, describing potential sources of bias and the causal model, and specifying and comparing candidate monitoring procedures. We hypothesize that these steps can be applied more generally, as causal inference can address other sources of biases as well.", "url": "https://arxiv.org/abs/2311.11463"}, {"metadata": {"arXiv": "2311.11485", "Date": "Mon, 20 Nov 2023 02:00:33 ", "Title": "An NMF-Based Building Block for Interpretable Neural Networks With Continual Learning", "Authors": ["Brian K. Vogel"], "Categories": "cs.LG", "Comments": ["42 pages", "13 figures"]}, "abstract": "Existing learning methods often struggle to balance interpretability and predictive performance. While models like nearest neighbors and non-negative matrix factorization (NMF) offer high interpretability, their predictive performance on supervised learning tasks is often limited. In contrast, neural networks based on the multi-layer perceptron (MLP) support the modular construction of expressive architectures and tend to have better recognition accuracy but are often regarded as black boxes in terms of interpretability. Our approach aims to strike a better balance between these two aspects through the use of a building block based on NMF that incorporates supervised neural network training methods to achieve high predictive performance while retaining the desirable interpretability properties of NMF. We evaluate our Predictive Factorized Coupling (PFC) block on small datasets and show that it achieves competitive predictive performance with MLPs while also offering improved interpretability. We demonstrate the benefits of this approach in various scenarios, such as continual learning, training on non-i.i.d. data, and knowledge removal after training. Additionally, we show examples of using the PFC block to build more expressive architectures, including a fully-connected residual network as well as a factorized recurrent neural network (RNN) that performs competitively with vanilla RNNs while providing improved interpretability. The PFC block uses an iterative inference algorithm that converges to a fixed point, making it possible to trade off accuracy vs computation after training but also currently preventing its use as a general MLP replacement in some scenarios such as training on very large datasets. We provide source code at https://github.com/bkvogel/pfc", "url": "https://arxiv.org/abs/2311.11485"}, {"metadata": {"arXiv": "2311.11544", "Date": "Mon, 20 Nov 2023 05:35:40 ", "Title": "Understanding Variation in Subpopulation Susceptibility to Poisoning Attacks", "Authors": ["Evan Rose", "Fnu Suya", "David Evans"], "Categories": "cs.LG cs.CR", "Comments": ["18 pages", "11 figures"]}, "abstract": "Machine learning is susceptible to poisoning attacks, in which an attacker controls a small fraction of the training data and chooses that data with the goal of inducing some behavior unintended by the model developer in the trained model. We consider a realistic setting in which the adversary with the ability to insert a limited number of data points attempts to control the model's behavior on a specific subpopulation. Inspired by previous observations on disparate effectiveness of random label-flipping attacks on different subpopulations, we investigate the properties that can impact the effectiveness of state-of-the-art poisoning attacks against different subpopulations. For a family of 2-dimensional synthetic datasets, we empirically find that dataset separability plays a dominant role in subpopulation vulnerability for less separable datasets. However, well-separated datasets exhibit more dependence on individual subpopulation properties. We further discover that a crucial subpopulation property is captured by the difference in loss on the clean dataset between the clean model and a target model that misclassifies the subpopulation, and a subpopulation is much easier to attack if the loss difference is small. This property also generalizes to high-dimensional benchmark datasets. For the Adult benchmark dataset, we show that we can find semantically-meaningful subpopulation properties that are related to the susceptibilities of a selected group of subpopulations. The results in this paper are accompanied by a fully interactive web-based visualization of subpopulation poisoning attacks found at https://uvasrg.github.io/visualizing-poisoning", "url": "https://arxiv.org/abs/2311.11544"}, {"metadata": {"arXiv": "2311.11628", "Date": "Mon, 20 Nov 2023 09:27:09 ", "Title": "Incorporating LLM Priors into Tabular Learners", "Authors": ["Max Zhu", "Sini\\v{s}a Stanivuk", "Andrija Petrovic", "Mladen Nikolic", "Pietro Lio"], "Categories": "cs.LG", "Comments": ["Table Representation Learning Workshop at NeurIPS 2023"]}, "abstract": "We present a method to integrate Large Language Models (LLMs) and traditional tabular data classification techniques, addressing LLMs challenges like data serialization sensitivity and biases. We introduce two strategies utilizing LLMs for ranking categorical variables and generating priors on correlations between continuous variables and targets, enhancing performance in few-shot scenarios. We focus on Logistic Regression, introducing MonotonicLR that employs a non-linear monotonic function for mapping ordinals to cardinals while preserving LLM-determined orders. Validation against baseline models reveals the superior performance of our approach, especially in low-data scenarios, while remaining interpretable.", "url": "https://arxiv.org/abs/2311.11628"}, {"metadata": {"arXiv": "2311.11694", "Date": "Mon, 20 Nov 2023 11:48:50 ", "Title": "Unveiling the Power of Self-Attention for Shipping Cost Prediction: The Rate Card Transformer", "Authors": ["P Aditya Sreekar", "Sahil Verma", "Varun Madhavan", "Abhishek Persad"], "Categories": "cs.LG stat.ML"}, "abstract": "Amazon ships billions of packages to its customers annually within the United States. Shipping cost of these packages are used on the day of shipping (day 0) to estimate profitability of sales. Downstream systems utilize these days 0 profitability estimates to make financial decisions, such as pricing strategies and delisting loss-making products. However, obtaining accurate shipping cost estimates on day 0 is complex for reasons like delay in carrier invoicing or fixed cost components getting recorded at monthly cadence. Inaccurate shipping cost estimates can lead to bad decision, such as pricing items too low or high, or promoting the wrong product to the customers. Current solutions for estimating shipping costs on day 0 rely on tree-based models that require extensive manual engineering efforts. In this study, we propose a novel architecture called the Rate Card Transformer (RCT) that uses self-attention to encode all package shipping information such as package attributes, carrier information and route plan. Unlike other transformer-based tabular models, RCT has the ability to encode a variable list of one-to-many relations of a shipment, allowing it to capture more information about a shipment. For example, RCT can encode properties of all products in a package. Our results demonstrate that cost predictions made by the RCT have 28.82% less error compared to tree-based GBDT model. Moreover, the RCT outperforms the state-of-the-art transformer-based tabular model, FTTransformer, by 6.08%. We also illustrate that the RCT learns a generalized manifold of the rate card that can improve the performance of tree-based models.", "url": "https://arxiv.org/abs/2311.11694"}, {"metadata": {"arXiv": "2311.11723", "Date": "Mon, 20 Nov 2023 12:40:25 ", "Title": "Leveraging Uncertainty Estimates To Improve Classifier Performance", "Authors": ["Gundeep Arora", "Srujana Merugu", "Anoop Saladi", "Rajeev Rastogi"], "Categories": "cs.LG"}, "abstract": "Binary classification involves predicting the label of an instance based on whether the model score for the positive class exceeds a threshold chosen based on the application requirements (e.g., maximizing recall for a precision bound). However, model scores are often not aligned with the true positivity rate. This is especially true when the training involves a differential sampling across classes or there is distributional drift between train and test settings. In this paper, we provide theoretical analysis and empirical evidence of the dependence of model score estimation bias on both uncertainty and score itself. Further, we formulate the decision boundary selection in terms of both model score and uncertainty, prove that it is NP-hard, and present algorithms based on dynamic programming and isotonic regression. Evaluation of the proposed algorithms on three real-world datasets yield 25%-40% gain in recall at high precision bounds over the traditional approach of using model score alone, highlighting the benefits of leveraging uncertainty.", "url": "https://arxiv.org/abs/2311.11723"}, {"metadata": {"arXiv": "2311.11762", "Date": "Mon, 20 Nov 2023 13:40:40 ", "Title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations", "Authors": ["Daniel Bogdoll", "Yitian Yang", "J. Marius Z\\\"ollner"], "Categories": "cs.LG cs.RO"}, "abstract": "Learning unsupervised world models for autonomous driving has the potential to improve the reasoning capabilities of today's systems dramatically. However, most work neglects the physical attributes of the world and focuses on sensor data alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel Representations to address this challenge. We utilize raw camera and lidar data to learn a sensor-agnostic geometric representation of the world, which can directly be used by downstream tasks, such as planning. We demonstrate multimodal future predictions and show that our geometric representation improves the prediction quality of both camera images and lidar point clouds.", "url": "https://arxiv.org/abs/2311.11762"}, {"metadata": {"arXiv": "2311.11789", "Date": "Mon, 20 Nov 2023 14:14:13 ", "Title": "Approximate Linear Programming and Decentralized Policy Improvement in Cooperative Multi-agent Markov Decision Processes", "Authors": ["Lakshmi Mandal", "Chandrashekar Lakshminarayanan", "and Shalabh Bhatnagar"], "Categories": "cs.LG cs.MA math.OC"}, "abstract": "In this work, we consider a `cooperative' multi-agent Markov decision process (MDP) involving m greater than 1 agents, where all agents are aware of the system model. At each decision epoch, all the m agents cooperatively select actions in order to maximize a common long-term objective. Since the number of actions grows exponentially in the number of agents, policy improvement is computationally expensive. Recent works have proposed using decentralized policy improvement in which each agent assumes that the decisions of the other agents are fixed and it improves its decisions unilaterally. Yet, in these works, exact values are computed. In our work, for cooperative multi-agent finite and infinite horizon discounted MDPs, we propose suitable approximate policy iteration algorithms, wherein we use approximate linear programming to compute the approximate value function and use decentralized policy improvement. Thus our algorithms can handle both large number of states as well as multiple agents. We provide theoretical guarantees for our algorithms and also demonstrate the performance of our algorithms on some numerical examples.", "url": "https://arxiv.org/abs/2311.11789"}, {"metadata": {"arXiv": "2311.11798", "Date": "Mon, 20 Nov 2023 14:31:18 ", "Title": "Operator Learning for Continuous Spatial-Temporal Model with A Hybrid Optimization Scheme", "Authors": ["Chuanqi Chen", "Jin-Long Wu"], "Categories": "cs.LG"}, "abstract": "Partial differential equations are often used in the spatial-temporal modeling of complex dynamical systems in many engineering applications. In this work, we build on the recent progress of operator learning and present a data-driven modeling framework that is continuous in both space and time. A key feature of the proposed model is the resolution-invariance with respect to both spatial and temporal discretizations. To improve the long-term performance of the calibrated model, we further propose a hybrid optimization scheme that leverages both gradient-based and derivative-free optimization methods and efficiently trains on both short-term time series and long-term statistics. We investigate the performance of the spatial-temporal continuous learning framework with three numerical examples, including the viscous Burgers' equation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation. The results confirm the resolution-invariance of the proposed modeling framework and also demonstrate stable long-term simulations with only short-term time series data. In addition, we show that the proposed model can better predict long-term statistics via the hybrid optimization scheme with a combined use of short-term and long-term data.", "url": "https://arxiv.org/abs/2311.11798"}, {"metadata": {"arXiv": "2311.11821", "Date": "Mon, 20 Nov 2023 14:58:47 ", "Title": "Cross-View Graph Consistency Learning for Invariant Graph Representations", "Authors": ["Jie Chen and Zhiming Li and Hua Mao and Wai Lok Woo and Xi Peng"], "Categories": "cs.LG cs.CV", "Comments": ["8 pages"]}, "abstract": "Graph representation learning is fundamental for analyzing graph-structured data. Exploring invariant graph representations remains a challenge for most existing graph representation learning methods. In this paper, we propose a cross-view graph consistency learning (CGCL) method that learns invariant graph representations for link prediction. First, two complementary augmented views are derived from an incomplete graph structure through a bidirectional graph structure augmentation scheme. This augmentation scheme mitigates the potential information loss that is commonly associated with various data augmentation techniques involving raw graph data, such as edge perturbation, node removal, and attribute masking. Second, we propose a CGCL model that can learn invariant graph representations. A cross-view training scheme is proposed to train the proposed CGCL model. This scheme attempts to maximize the consistency information between one augmented view and the graph structure reconstructed from the other augmented view. Furthermore, we offer a comprehensive theoretical CGCL analysis. This paper empirically and experimentally demonstrates the effectiveness of the proposed CGCL method, achieving competitive results on graph datasets in comparisons with several state-of-the-art algorithms.", "url": "https://arxiv.org/abs/2311.11821"}, {"metadata": {"arXiv": "2311.11822", "Date": "Mon, 20 Nov 2023 14:58:56 ", "Title": "Zero redundancy distributed learning with differential privacy", "Authors": ["Zhiqi Bu", "Justin Chiu", "Ruixuan Liu", "Sheng Zha", "George Karypis"], "Categories": "cs.LG cs.CC cs.CR cs.DC"}, "abstract": "Deep learning using large models have achieved great success in a wide range of domains. However, training these models on billions of parameters is very challenging in terms of the training speed, memory cost, and communication efficiency, especially under the privacy-preserving regime with differential privacy (DP). On the one hand, DP optimization has comparable efficiency to the standard non-private optimization on a single GPU, but on multiple GPUs, existing DP distributed learning (such as pipeline parallel) has suffered from significantly worse efficiency. On the other hand, the Zero Redundancy Optimizer (ZeRO) is a state-of-the-art solution to the standard distributed learning, exhibiting excellent training efficiency on large models, but to work compatibly with DP is technically complicated. In this work, we develop a new systematic solution, DP-ZeRO, (I) to scale up the trainable DP model size, e.g. to GPT-100B, (II) to obtain the same computation and communication efficiency as the standard ZeRO, and (III) to enable mixed-precision DP training. Our DP-ZeRO, like the standard ZeRO, has the potential to train models with arbitrary size and is evaluated on the world's largest DP models in terms of the number of trainable parameters.", "url": "https://arxiv.org/abs/2311.11822"}, {"metadata": {"arXiv": "2311.11891", "Date": "Mon, 20 Nov 2023 16:24:23 ", "Title": "AMES: A Differentiable Embedding Space Selection Framework for Latent Graph Inference", "Authors": ["Yuan Lu", "Haitz S\\'aez de Oc\\'ariz Borde", "Pietro Li\\`o"], "Categories": "cs.LG cs.SI stat.ML"}, "abstract": "In real-world scenarios, although data entities may possess inherent relationships, the specific graph illustrating their connections might not be directly accessible. Latent graph inference addresses this issue by enabling Graph Neural Networks (GNNs) to operate on point cloud data, dynamically learning the necessary graph structure. These graphs are often derived from a latent embedding space, which can be modeled using Euclidean, hyperbolic, spherical, or product spaces. However, currently, there is no principled differentiable method for determining the optimal embedding space. In this work, we introduce the Attentional Multi-Embedding Selection (AMES) framework, a differentiable method for selecting the best embedding space for latent graph inference through backpropagation, considering a downstream task. Our framework consistently achieves comparable or superior results compared to previous methods for latent graph inference across five benchmark datasets. Importantly, our approach eliminates the need for conducting multiple experiments to identify the optimal embedding space. Furthermore, we explore interpretability techniques that track the gradient contributions of different latent graphs, shedding light on how our attention-based, fully differentiable approach learns to choose the appropriate latent space. In line with previous works, our experiments emphasize the advantages of hyperbolic spaces in enhancing performance. More importantly, our interpretability framework provides a general approach for quantitatively comparing embedding spaces across different tasks based on their contributions, a dimension that has been overlooked in previous literature on latent graph inference.", "url": "https://arxiv.org/abs/2311.11891"}, {"metadata": {"arXiv": "2311.11905", "Date": "Mon, 20 Nov 2023 16:38:45 ", "Title": "Real-Time Surface-to-Air Missile Engagement Zone Prediction Using Simulation and Machine Learning", "Authors": ["Joao P. A. Dantas", "Diego Geraldo", "Felipe L. L. Medeiros", "Marcos R. O. A. Maximo", "Takashi Yoneyama"], "Categories": "cs.LG cs.RO"}, "abstract": "Surface-to-Air Missiles (SAMs) are crucial in modern air defense systems. A critical aspect of their effectiveness is the Engagement Zone (EZ), the spatial region within which a SAM can effectively engage and neutralize a target. Notably, the EZ is intrinsically related to the missile's maximum range; it defines the furthest distance at which a missile can intercept a target. The accurate computation of this EZ is essential but challenging due to the dynamic and complex factors involved, which often lead to high computational costs and extended processing times when using conventional simulation methods. In light of these challenges, our study investigates the potential of machine learning techniques, proposing an approach that integrates machine learning with a custom-designed simulation tool to train supervised algorithms. We leverage a comprehensive dataset of pre-computed SAM EZ simulations, enabling our model to accurately predict the SAM EZ for new input parameters. It accelerates SAM EZ simulations, enhances air defense strategic planning, and provides real-time insights, improving SAM system performance. The study also includes a comparative analysis of machine learning algorithms, illuminating their capabilities and performance metrics and suggesting areas for future research, highlighting the transformative potential of machine learning in SAM EZ simulations.", "url": "https://arxiv.org/abs/2311.11905"}, {"metadata": {"arXiv": "2311.11911", "Date": "Mon, 20 Nov 2023 16:41:54 ", "Title": "Certification of Distributional Individual Fairness", "Authors": ["Matthew Wicker", "Vihari Piratia", "and Adrian Weller"], "Categories": "cs.LG cs.CY", "Comments": ["21 Pages", "Neural Information Processing Systems 2023"]}, "abstract": "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify distributional individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.", "url": "https://arxiv.org/abs/2311.11911"}, {"metadata": {"arXiv": "2311.11913", "Date": "Mon, 20 Nov 2023 16:44:18 ", "Title": "Deep Calibration of Market Simulations using Neural Density Estimators and Embedding Networks", "Authors": ["Namid R. Stillman", "Rory Baggott", "Justin Lyon", "Jianfei Zhang", "Dingqiu Zhu", "Tao Chen", "Perukrishnen Vytelingum"], "Categories": "cs.LG q-fin.CP stat.ML", "Comments": ["4th ACM International Conference on AI in Finance (ICAIF 2023)"]}, "abstract": "The ability to construct a realistic simulator of financial exchanges, including reproducing the dynamics of the limit order book, can give insight into many counterfactual scenarios, such as a flash crash, a margin call, or changes in macroeconomic outlook. In recent years, agent-based models have been developed that reproduce many features of an exchange, as summarised by a set of stylised facts and statistics. However, the ability to calibrate simulators to a specific period of trading remains an open challenge. In this work, we develop a novel approach to the calibration of market simulators by leveraging recent advances in deep learning, specifically using neural density estimators and embedding networks. We demonstrate that our approach is able to correctly identify high probability parameter sets, both when applied to synthetic and historical data, and without reliance on manually selected or weighted ensembles of stylised facts.", "url": "https://arxiv.org/abs/2311.11913"}, {"metadata": {"arXiv": "2311.11963", "Date": "Mon, 20 Nov 2023 17:43:09 ", "Title": "What Can AutoML Do For Continual Learning?", "Authors": ["Mert Kilickaya", "Joaquin Vanschoren"], "Categories": "cs.LG cs.CV"}, "abstract": "This position paper outlines the potential of AutoML for incremental (continual) learning to encourage more research in this direction. Incremental learning involves incorporating new data from a stream of tasks and distributions to learn enhanced deep representations and adapt better to new tasks. However, a significant limitation of incremental learners is that most current techniques freeze the backbone architecture, hyperparameters, and the order & structure of the learning tasks throughout the learning and adaptation process. We strongly believe that AutoML offers promising solutions to address these limitations, enabling incremental learning to adapt to more diverse real-world tasks. Therefore, instead of directly proposing a new method, this paper takes a step back by posing the question: \"What can AutoML do for incremental learning?\" We outline three key areas of research that can contribute to making incremental learners more dynamic, highlighting concrete opportunities to apply AutoML methods in novel ways as well as entirely new challenges for AutoML research.", "url": "https://arxiv.org/abs/2311.11963"}, {"metadata": {"arXiv": "2311.11965", "Date": "Mon, 20 Nov 2023 17:44:40 ", "Title": "Provably Efficient CVaR RL in Low-rank MDPs", "Authors": ["Yulai Zhao", "Wenhao Zhan", "Xiaoyan Hu", "Ho-fung Leung", "Farzan Farnia", "Wen Sun", "Jason D. Lee"], "Categories": "cs.LG stat.ML", "Comments": ["The first three authors contribute equally and are ordered randomly"]}, "abstract": "We study risk-sensitive Reinforcement Learning (RL), where we aim to maximize the Conditional Value at Risk (CVaR) with a fixed risk tolerance $\\tau$. Prior theoretical work studying risk-sensitive RL focuses on the tabular Markov Decision Processes (MDPs) setting. To extend CVaR RL to settings where state space is large, function approximation must be deployed. We study CVaR RL in low-rank MDPs with nonlinear function approximation. Low-rank MDPs assume the underlying transition kernel admits a low-rank decomposition, but unlike prior linear models, low-rank MDPs do not assume the feature or state-action representation is known. We propose a novel Upper Confidence Bound (UCB) bonus-driven algorithm to carefully balance the interplay between exploration, exploitation, and representation learning in CVaR RL. We prove that our algorithm achieves a sample complexity of $\\tilde{O}\\left(\\frac{H^7 A^2 d^4}{\\tau^2 \\epsilon^2}\\right)$ to yield an $\\epsilon$-optimal CVaR, where $H$ is the length of each episode, $A$ is the capacity of action space, and $d$ is the dimension of representations. Computational-wise, we design a novel discretized Least-Squares Value Iteration (LSVI) algorithm for the CVaR objective as the planning oracle and show that we can find the near-optimal policy in a polynomial running time with a Maximum Likelihood Estimation oracle. To our knowledge, this is the first provably efficient CVaR RL algorithm in low-rank MDPs.", "url": "https://arxiv.org/abs/2311.11965"}, {"metadata": {"arXiv": "2311.11973", "Date": "Mon, 20 Nov 2023 18:01:29 ", "Title": "Adaptive Training Distributions with Scalable Online Bilevel Optimization", "Authors": ["David Grangier", "Pierre Ablin", "Awni Hannun"], "Categories": "cs.LG cs.CL"}, "abstract": "Large neural networks pretrained on web-scale corpora are central to modern machine learning. In this paradigm, the distribution of the large, heterogeneous pretraining data rarely matches that of the application domain. This work considers modifying the pretraining distribution in the case where one has a small sample of data reflecting the targeted test conditions. We propose an algorithm motivated by a recent formulation of this setting as an online, bilevel optimization problem. With scalability in mind, our algorithm prioritizes computing gradients at training points which are likely to most improve the loss on the targeted distribution. Empirically, we show that in some cases this approach is beneficial over existing strategies from the domain adaptation literature but may not succeed in other cases. We propose a simple test to evaluate when our approach can be expected to work well and point towards further research to address current limitations.", "url": "https://arxiv.org/abs/2311.11973"}, {"metadata": {"arXiv": "2311.12004", "Date": "Mon, 20 Nov 2023 18:36:10 ", "Title": "Risk-averse Batch Active Inverse Reward Design", "Authors": ["Panagiotis Liampas"], "Categories": "cs.LG", "Comments": ["14 pages", "12 figures"]}, "abstract": "Designing a perfect reward function that depicts all the aspects of the intended behavior is almost impossible, especially generalizing it outside of the training environments. Active Inverse Reward Design (AIRD) proposed the use of a series of queries, comparing possible reward functions in a single training environment. This allows the human to give information to the agent about suboptimal behaviors, in order to compute a probability distribution over the intended reward function. However, it ignores the possibility of unknown features appearing in real-world environments, and the safety measures needed until the agent completely learns the reward function. I improved this method and created Risk-averse Batch Active Inverse Reward Design (RBAIRD), which constructs batches, sets of environments the agent encounters when being used in the real world, processes them sequentially, and, for a predetermined number of iterations, asks queries that the human needs to answer for each environment of the batch. After this process is completed in one batch, the probabilities have been improved and are transferred to the next batch. This makes it capable of adapting to real-world scenarios and learning how to treat unknown features it encounters for the first time. I also integrated a risk-averse planner, similar to that of Inverse Reward Design (IRD), which samples a set of reward functions from the probability distribution and computes a trajectory that takes the most certain rewards possible. This ensures safety while the agent is still learning the reward function, and enables the use of this approach in situations where cautiousness is vital. RBAIRD outperformed the previous approaches in terms of efficiency, accuracy, and action certainty, demonstrated quick adaptability to new, unknown features, and can be more widely used for the alignment of crucial, powerful AI models.", "url": "https://arxiv.org/abs/2311.12004"}, {"metadata": {"arXiv": "2311.11056", "Date": "Sat, 18 Nov 2023 12:30:41 ", "Title": "A Survey of Simulators for Autonomous Driving: Taxonomy, Challenges, and Evaluation Metrics", "Authors": ["Yueyuan Li", "Wei Yuan", "Weihao Yan", "Qiyuan Shen", "Chunxiang Wang", "Ming Yang"], "Categories": "cs.RO cs.LG cs.SE", "Comments": ["17 pages", "7 figures", "2 tables"]}, "abstract": "Simulators have irreplaceable importance for the research and development of autonomous driving. Besides saving resources, labor, and time, simulation is the only feasible way to reproduce many severe accident scenarios. Despite their widespread adoption across academia and industry, there is an absence in the evolutionary trajectory of simulators and critical discourse on their limitations. To bridge the gap in research, this paper conducts an in-depth review of simulators for autonomous driving. It delineates the three-decade development into three stages: specialized development period, gap period, and comprehensive development, from which it detects a trend of implementing comprehensive functionalities and open-source accessibility. Then it classifies the simulators by functions, identifying five categories: traffic flow simulator, vehicle dynamics simulator, scenario editor, sensory data generator, and driving strategy validator. Simulators that amalgamate diverse features are defined as comprehensive simulators. By investigating commercial and open-source simulators, this paper reveals that the critical issues faced by simulators primarily revolve around fidelity and efficiency concerns. This paper justifies that enhancing the realism of adverse weather simulation, automated map reconstruction, and interactive traffic participants will bolster credibility. Concurrently, headless simulation and multiple-speed simulation techniques will exploit the theoretic advantages. Moreover, this paper delves into potential solutions for the identified issues. It explores qualitative and quantitative evaluation metrics to assess the simulator's performance. This paper guides users to find suitable simulators efficiently and provides instructive suggestions for developers to improve simulator efficacy purposefully.", "url": "https://arxiv.org/abs/2311.11056"}, {"metadata": {"arXiv": "2311.11151", "Date": "Sat, 18 Nov 2023 19:34:56 ", "Title": "On the Hardness of Learning to Stabilize Linear Systems", "Authors": ["Xiong Zeng", "Zexiang Liu", "Zhe Du", "Necmiye Ozay", "Mario Sznaier"], "Categories": "eess.SY cs.LG cs.SY stat.ML", "Comments": ["7 pages", "2 figures", "accepted by CDC 2023"]}, "abstract": "Inspired by the work of Tsiamis et al. \\cite{tsiamis2022learning}, in this paper we study the statistical hardness of learning to stabilize linear time-invariant systems. Hardness is measured by the number of samples required to achieve a learning task with a given probability. The work in \\cite{tsiamis2022learning} shows that there exist system classes that are hard to learn to stabilize with the core reason being the hardness of identification. Here we present a class of systems that can be easy to identify, thanks to a non-degenerate noise process that excites all modes, but the sample complexity of stabilization still increases exponentially with the system dimension. We tie this result to the hardness of co-stabilizability for this class of systems using ideas from robust control.", "url": "https://arxiv.org/abs/2311.11151"}, {"metadata": {"arXiv": "2311.11280", "Date": "Sun, 19 Nov 2023 09:50:21 ", "Title": "Multi-Timescale Control and Communications with Deep Reinforcement Learning -- Part II: Control-Aware Radio Resource Allocation", "Authors": ["Lei Lei", "Tong Liu", "Kan Zheng", "Xuemin (Sherman) Shen"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "In Part I of this two-part paper (Multi-Timescale Control and Communications with Deep Reinforcement Learning -- Part I: Communication-Aware Vehicle Control), we decomposed the multi-timescale control and communications (MTCC) problem in Cellular Vehicle-to-Everything (C-V2X) system into a communication-aware Deep Reinforcement Learning (DRL)-based platoon control (PC) sub-problem and a control-aware DRL-based radio resource allocation (RRA) sub-problem. We focused on the PC sub-problem and proposed the MTCC-PC algorithm to learn an optimal PC policy given an RRA policy. In this paper (Part II), we first focus on the RRA sub-problem in MTCC assuming a PC policy is given, and propose the MTCC-RRA algorithm to learn the RRA policy. Specifically, we incorporate the PC advantage function in the RRA reward function, which quantifies the amount of PC performance degradation caused by observation delay. Moreover, we augment the state space of RRA with PC action history for a more well-informed RRA policy. In addition, we utilize reward shaping and reward backpropagation prioritized experience replay (RBPER) techniques to efficiently tackle the multi-agent and sparse reward problems, respectively. Finally, a sample- and computational-efficient training approach is proposed to jointly learn the PC and RRA policies in an iterative process. In order to verify the effectiveness of the proposed MTCC algorithm, we performed experiments using real driving data for the leading vehicle, where the performance of MTCC is compared with those of the baseline DRL algorithms.", "url": "https://arxiv.org/abs/2311.11280"}, {"metadata": {"arXiv": "2311.11281", "Date": "Sun, 19 Nov 2023 09:51:58 ", "Title": "Multi-Timescale Control and Communications with Deep Reinforcement Learning -- Part I: Communication-Aware Vehicle Control", "Authors": ["Tong Liu", "Lei Lei", "Kan Zheng", "Xuemin (Sherman) Shen"], "Categories": "eess.SY cs.LG cs.SY"}, "abstract": "An intelligent decision-making system enabled by Vehicle-to-Everything (V2X) communications is essential to achieve safe and efficient autonomous driving (AD), where two types of decisions have to be made at different timescales, i.e., vehicle control and radio resource allocation (RRA) decisions. The interplay between RRA and vehicle control necessitates their collaborative design. In this two-part paper (Part I and Part II), taking platoon control (PC) as an example use case, we propose a joint optimization framework of multi-timescale control and communications (MTCC) based on Deep Reinforcement Learning (DRL). In this paper (Part I), we first decompose the problem into a communication-aware DRL-based PC sub-problem and a control-aware DRL-based RRA sub-problem. Then, we focus on the PC sub-problem assuming an RRA policy is given, and propose the MTCC-PC algorithm to learn an efficient PC policy. To improve the PC performance under random observation delay, the PC state space is augmented with the observation delay and PC action history. Moreover, the reward function with respect to the augmented state is defined to construct an augmented state Markov Decision Process (MDP). It is proved that the optimal policy for the augmented state MDP is optimal for the original PC problem with observation delay. Different from most existing works on communication-aware control, the MTCC-PC algorithm is trained in a delayed environment generated by the fine-grained embedded simulation of C-V2X communications rather than by a simple stochastic delay model. Finally, experiments are performed to compare the performance of MTCC-PC with those of the baseline DRL algorithms.", "url": "https://arxiv.org/abs/2311.11281"}, {"metadata": {"arXiv": "2311.11644", "Date": "Mon, 20 Nov 2023 10:22:38 ", "Title": "Unraveling the Control Engineer's Craft with Neural Networks", "Authors": ["Braghadeesh Lakshminarayanan", "Federico Dett\\`u", "Cristian R. Rojas", "Simone Formentin"], "Categories": "eess.SY cs.LG cs.SY", "Comments": ["6 pages"]}, "abstract": "Many industrial processes require suitable controllers to meet their performance requirements. More often, a sophisticated digital twin is available, which is a highly complex model that is a virtual representation of a given physical process, whose parameters may not be properly tuned to capture the variations in the physical process. In this paper, we present a sim2real, direct data-driven controller tuning approach, where the digital twin is used to generate input-output data and suitable controllers for several perturbations in its parameters. State-of-the art neural-network architectures are then used to learn the controller tuning rule that maps input-output data onto the controller parameters, based on artificially generated data from perturbed versions of the digital twin. In this way, as far as we are aware, we tackle for the first time the problem of re-calibrating the controller by meta-learning the tuning rule directly from data, thus practically replacing the control engineer with a machine learning model. The benefits of this methodology are illustrated via numerical simulations for several choices of neural-network architectures.", "url": "https://arxiv.org/abs/2311.11644"}, {"metadata": {"arXiv": "2311.10735", "Date": "Mon, 23 Oct 2023 04:23:07 ", "Title": "Safe Navigation: Training Autonomous Vehicles using Deep Reinforcement Learning in CARLA", "Authors": ["Ghadi Nehme", "Tejas Y. Deo"], "Categories": "cs.AI cs.RO"}, "abstract": "Autonomous vehicles have the potential to revolutionize transportation, but they must be able to navigate safely in traffic before they can be deployed on public roads. The goal of this project is to train autonomous vehicles to make decisions to navigate in uncertain environments using deep reinforcement learning techniques using the CARLA simulator. The simulator provides a realistic and urban environment for training and testing self-driving models. Deep Q-Networks (DQN) are used to predict driving actions. The study involves the integration of collision sensors, segmentation, and depth camera for better object detection and distance estimation. The model is tested on 4 different trajectories in presence of different types of 4-wheeled vehicles and pedestrians. The segmentation and depth cameras were utilized to ensure accurate localization of objects and distance measurement. Our proposed method successfully navigated the self-driving vehicle to its final destination with a high success rate without colliding with other vehicles, pedestrians, or going on the sidewalk. To ensure the optimal performance of our reinforcement learning (RL) models in navigating complex traffic scenarios, we implemented a pre-processing step to reduce the state space. This involved processing the images and sensor output before feeding them into the model. Despite significantly decreasing the state space, our approach yielded robust models that successfully navigated through traffic with high levels of safety and accuracy.", "url": "https://arxiv.org/abs/2311.10735"}, {"metadata": {"arXiv": "2311.10786", "Date": "Thu, 16 Nov 2023 19:01:01 ", "Title": "A Systems-Theoretical Formalization of Closed Systems", "Authors": ["Niloofar Shadab", "Tyler Cody", "Alejandro Salado", "Peter Beling"], "Categories": "cs.AI cs.SY", "Comments": ["11 pages", "3 figures"]}, "abstract": "There is a lack of formalism for some key foundational concepts in systems engineering. One of the most recently acknowledged deficits is the inadequacy of systems engineering practices for engineering intelligent systems. In our previous works, we proposed that closed systems precepts could be used to accomplish a required paradigm shift for the systems engineering of intelligent systems. However, to enable such a shift, formal foundations for closed systems precepts that expand the theory of systems engineering are needed. The concept of closure is a critical concept in the formalism underlying closed systems precepts. In this paper, we provide formal, systems- and information-theoretic definitions of closure to identify and distinguish different types of closed systems. Then, we assert a mathematical framework to evaluate the subjective formation of the boundaries and constraints of such systems. Finally, we argue that engineering an intelligent system can benefit from appropriate closed and open systems paradigms on multiple levels of abstraction of the system. In the main, this framework will provide the necessary fundamentals to aid in systems engineering of intelligent systems.", "url": "https://arxiv.org/abs/2311.10786"}, {"metadata": {"arXiv": "2311.10809", "Date": "Fri, 17 Nov 2023 18:09:21 ", "Title": "Extracting periodontitis diagnosis in clinical notes with RoBERTa and regular expression", "Authors": ["Yao-Shun Chuang", "Chun-Teh Lee", "Ryan Brandon", "Trung Duong Tran", "Oluwabunmi Tokede", "Muhammad F. Walji", "Xiaoqian Jiang"], "Categories": "cs.AI", "Comments": ["IEEE ICHI 2023", "see https://ieeeichi.github.io/ICHI2023/program.html"]}, "abstract": "This study aimed to utilize text processing and natural language processing (NLP) models to mine clinical notes for the diagnosis of periodontitis and to evaluate the performance of a named entity recognition (NER) model on different regular expression (RE) methods. Two complexity levels of RE methods were used to extract and generate the training data. The SpaCy package and RoBERTa transformer models were used to build the NER model and evaluate its performance with the manual-labeled gold standards. The comparison of the RE methods with the gold standard showed that as the complexity increased in the RE algorithms, the F1 score increased from 0.3-0.4 to around 0.9. The NER models demonstrated excellent predictions, with the simple RE method showing 0.84-0.92 in the evaluation metrics, and the advanced and combined RE method demonstrating 0.95-0.99 in the evaluation. This study provided an example of the benefit of combining NER methods and NLP models in extracting target information from free-text to structured data and fulfilling the need for missing diagnoses from unstructured notes.", "url": "https://arxiv.org/abs/2311.10809"}, {"metadata": {"arXiv": "2311.10840", "Date": "Fri, 17 Nov 2023 19:38:37 ", "Title": "Integration and Implementation Strategies for AI Algorithm Deployment with Smart Routing Rules and Workflow Management", "Authors": ["Barbaros Selnur Erdal", "Vikash Gupta", "Mutlu Demirer", "Kim H. Fair", "Richard D. White", "Jeff Blair", "Barbara Deichert", "Laurie Lafleur", "Ming Melvin Qin", "David Bericat", "Brad Genereaux"], "Categories": "cs.AI", "Comments": ["13 pages", "6 figures"], "ACM-class": "I.2.m"}, "abstract": "This paper reviews the challenges hindering the widespread adoption of artificial intelligence (AI) solutions in the healthcare industry, focusing on computer vision applications for medical imaging, and how interoperability and enterprise-grade scalability can be used to address these challenges. The complex nature of healthcare workflows, intricacies in managing large and secure medical imaging data, and the absence of standardized frameworks for AI development pose significant barriers and require a new paradigm to address them. The role of interoperability is examined in this paper as a crucial factor in connecting disparate applications within healthcare workflows. Standards such as DICOM, Health Level 7 HL7, and Integrating the Healthcare Enterprise (IHE) are highlighted as foundational for common imaging workflows. A specific focus is placed on the role of DICOM gateways, with Laurel Bridge leading transformational efforts in this area. To drive enterprise scalability, new tools are needed. Project MONAI, established in 2019, is introduced as an initiative aiming to redefine the development of medical AI applications. The MONAI Deploy App SDK, a component of Project MONAI, is identified as a key tool in simplifying the packaging and deployment process, enabling repeatable, scalable, and standardized deployment patterns for AI applications. The abstract underscores the potential impact of successful AI adoption in healthcare, offering physicians both life-saving and time-saving insights and driving efficiencies in radiology department workflows. The collaborative efforts between academia and industry, exemplified by collaborations with organizations like NVIDIA and Laurel Bridge, are emphasized as essential for advancing the adoption of healthcare AI solutions.", "url": "https://arxiv.org/abs/2311.10840"}, {"metadata": {"arXiv": "2311.10856", "Date": "Fri, 17 Nov 2023 20:32:24 ", "Title": "Exploring the Consistency, Quality and Challenges in Manual and Automated Coding of Free-text Diagnoses from Hospital Outpatient Letters", "Authors": ["Warren Del-Pinto", "George Demetriou", "Meghna Jani", "Rikesh Patel", "Leanne Gray", "Alex Bulcock", "Niels Peek", "Andrew S. Kanter", "William G Dixon", "Goran Nenadic"], "Categories": "cs.AI"}, "abstract": "Coding of unstructured clinical free-text to produce interoperable structured data is essential to improve direct care, support clinical communication and to enable clinical research.However, manual clinical coding is difficult and time consuming, which motivates the development and use of natural language processing for automated coding. This work evaluates the quality and consistency of both manual and automated clinical coding of diagnoses from hospital outpatient letters. Using 100 randomly selected letters, two human clinicians performed coding of diagnosis lists to SNOMED CT. Automated coding was also performed using IMO's Concept Tagger. A gold standard was constructed by a panel of clinicians from a subset of the annotated diagnoses. This was used to evaluate the quality and consistency of both manual and automated coding via (1) a distance-based metric, treating SNOMED CT as a graph, and (2) a qualitative metric agreed upon by the panel of clinicians. Correlation between the two metrics was also evaluated. Comparing human and computer-generated codes to the gold standard, the results indicate that humans slightly out-performed automated coding, while both performed notably better when there was only a single diagnosis contained in the free-text description. Automated coding was considered acceptable by the panel of clinicians in approximately 90% of cases.", "url": "https://arxiv.org/abs/2311.10856"}, {"metadata": {"arXiv": "2311.10898", "Date": "Fri, 17 Nov 2023 22:34:47 ", "Title": "On Functional Activations in Deep Neural Networks", "Authors": ["Andrew S. Nencka", "L. Tugan Muftuler", "Peter LaViolette", "Kevin M. Koch"], "Categories": "cs.AI cs.NE"}, "abstract": "Background: Deep neural networks have proven to be powerful computational tools for modeling, prediction, and generation. However, the workings of these models have generally been opaque. Recent work has shown that the performance of some models are modulated by overlapping functional networks of connections within the models. Here the techniques of functional neuroimaging are applied to an exemplary large language model to probe its functional structure. Methods: A series of block-designed task-based prompt sequences were generated to probe the Facebook Galactica-125M model. Tasks included prompts relating to political science, medical imaging, paleontology, archeology, pathology, and random strings presented in an off/on/off pattern with prompts about other random topics. For the generation of each output token, all layer output values were saved to create an effective time series. General linear models were fit to the data to identify layer output values which were active with the tasks. Results: Distinct, overlapping networks were identified with each task. Most overlap was observed between medical imaging and pathology networks. These networks were repeatable across repeated performance of related tasks, and correspondence of identified functional networks and activation in tasks not used to define the functional networks was shown to accurately identify the presented task. Conclusion: The techniques of functional neuroimaging can be applied to deep neural networks as a means to probe their workings. Identified functional networks hold the potential for use in model alignment, modulation of model output, and identifying weights to target in fine-tuning.", "url": "https://arxiv.org/abs/2311.10898"}, {"metadata": {"arXiv": "2311.10922", "Date": "Sat, 18 Nov 2023 00:33:48 ", "Title": "Explainable Product Classification for Customs", "Authors": ["Eunji Lee", "Sihyeon Kim", "Sundong Kim", "Soyeon Jung", "Heeja Kim", "Meeyoung Cha"], "Categories": "cs.AI cs.CL cs.DB cs.IR", "Comments": ["24 pages", "Accepted to ACM Transactions on Intelligent Systems and Technology"], "DOI": "10.8080/1020220078265"}, "abstract": "The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9\\% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.", "url": "https://arxiv.org/abs/2311.10922"}, {"metadata": {"arXiv": "2311.10932", "Date": "Sat, 18 Nov 2023 01:58:23 ", "Title": "Cognitive bias in large language models: Cautious optimism meets anti-Panglossian meliorism", "Authors": ["David Thorstad"], "Categories": "cs.AI"}, "abstract": "Traditional discussions of bias in large language models focus on a conception of bias closely tied to unfairness, especially as affecting marginalized groups. Recent work raises the novel possibility of assessing the outputs of large language models for a range of cognitive biases familiar from research in judgment and decisionmaking. My aim in this paper is to draw two lessons from recent discussions of cognitive bias in large language models: cautious optimism about the prevalence of bias in current models coupled with an anti-Panglossian willingness to concede the existence of some genuine biases and work to reduce them. I draw out philosophical implications of this discussion for the rationality of human cognitive biases as well as the role of unrepresentative data in driving model biases.", "url": "https://arxiv.org/abs/2311.10932"}, {"metadata": {"arXiv": "2311.10933", "Date": "Sat, 18 Nov 2023 02:00:20 ", "Title": "Representing visual classification as a linear combination of words", "Authors": ["Shobhit Agarwal", "Yevgeniy R. Semenov", "William Lotter"], "Categories": "cs.AI cs.CL cs.CV cs.HC", "Comments": ["To be published in the Proceedings of the 3rd Machine Learning for Health symposium", "Proceedings of Machine Learning Research (PMLR)"]}, "abstract": "Explainability is a longstanding challenge in deep learning, especially in high-stakes domains like healthcare. Common explainability methods highlight image regions that drive an AI model's decision. Humans, however, heavily rely on language to convey explanations of not only \"where\" but \"what\". Additionally, most explainability approaches focus on explaining individual AI predictions, rather than describing the features used by an AI model in general. The latter would be especially useful for model and dataset auditing, and potentially even knowledge generation as AI is increasingly being used in novel tasks. Here, we present an explainability strategy that uses a vision-language model to identify language-based descriptors of a visual classification task. By leveraging a pre-trained joint embedding space between images and text, our approach estimates a new classification task as a linear combination of words, resulting in a weight for each word that indicates its alignment with the vision-based classifier. We assess our approach using two medical imaging classification tasks, where we find that the resulting descriptors largely align with clinical knowledge despite a lack of domain-specific language training. However, our approach also identifies the potential for 'shortcut connections' in the public datasets used. Towards a functional measure of explainability, we perform a pilot reader study where we find that the AI-identified words can enable non-expert humans to perform a specialized medical task at a non-trivial level. Altogether, our results emphasize the potential of using multimodal foundational models to deliver intuitive, language-based explanations of visual tasks.", "url": "https://arxiv.org/abs/2311.10933"}, {"metadata": {"arXiv": "2311.10934", "Date": "Sat, 18 Nov 2023 02:02:40 ", "Title": "Case Repositories: Towards Case-Based Reasoning for AI Alignment", "Authors": ["K. J. Kevin Feng", "Quan Ze (Jim) Chen", "Inyoung Cheong", "King Xia", "Amy X. Zhang"], "Categories": "cs.AI cs.CY cs.HC", "Comments": ["MP2 workshop @ NeurIPS 2023"]}, "abstract": "Case studies commonly form the pedagogical backbone in law, ethics, and many other domains that face complex and ambiguous societal questions informed by human values. Similar complexities and ambiguities arise when we consider how AI should be aligned in practice: when faced with vast quantities of diverse (and sometimes conflicting) values from different individuals and communities, with whose values is AI to align, and how should AI do so? We propose a complementary approach to constitutional AI alignment, grounded in ideas from case-based reasoning (CBR), that focuses on the construction of policies through judgments on a set of cases. We present a process to assemble such a case repository by: 1) gathering a set of ``seed'' cases -- questions one may ask an AI system -- in a particular domain from discussions in online communities, 2) eliciting domain-specific key dimensions for cases through workshops with domain experts, 3) using LLMs to generate variations of cases not seen in the wild, and 4) engaging with the public to judge and improve cases. We then discuss how such a case repository could assist in AI alignment, both through directly acting as precedents to ground acceptable behaviors, and as a medium for individuals and communities to engage in moral reasoning around AI", "url": "https://arxiv.org/abs/2311.10934"}, {"metadata": {"arXiv": "2311.10940", "Date": "Sat, 18 Nov 2023 02:31:36 ", "Title": "Practical Estimation of Ensemble Accuracy", "Authors": ["Simi Haber", "Yonatan Wexler"], "Categories": "cs.AI", "Comments": ["4 pages", "2 figures. Submitted to InfoCOG@NeurIPS 2023"]}, "abstract": "Ensemble learning combines several individual models to obtain better generalization performance. In this work we present a practical method for estimating the joint power of several classifiers which differs from existing approaches by {\\em not relying on labels}, hence enabling the work in unsupervised setting of huge datasets. It differs from existing methods which define a \"diversity measure\". The heart of the method is a combinatorial bound on the number of mistakes the ensemble is likely to make. The bound can be efficiently approximated in time linear in the number of samples. Thus allowing an efficient search for a combination of classifiers that are likely to produce higher joint accuracy. Moreover, having the bound applicable to unlabeled data makes it both accurate and practical in modern setting of unsupervised learning. We demonstrate the method on popular large-scale face recognition datasets which provide a useful playground for fine-grain classification tasks using noisy data over many classes. The proposed framework fits neatly in trending practices of unsupervised learning. It is a measure of the inherent independence of a set of classifiers not relying on extra information such as another classifier or labeled data.", "url": "https://arxiv.org/abs/2311.10940"}, {"metadata": {"arXiv": "2311.11030", "Date": "Sat, 18 Nov 2023 10:38:35 ", "Title": "Data Center Audio/Video Intelligence on Device (DAVID) - An Edge-AI Platform for Smart-Toys", "Authors": ["Gabriel Cosache", "Francisco Salgado", "Cosmin Rotariu", "George Sterpu", "Rishabh Jain and Peter Corcoran"], "Categories": "cs.AI cs.CY cs.HC", "Comments": ["The 12th IEEE Conference on Speech Technology and Human Dialogue (SpeD 2023) URL: https://sped.pub.ro/"]}, "abstract": "An overview is given of the DAVID Smart-Toy platform, one of the first Edge AI platform designs to incorporate advanced low-power data processing by neural inference models co-located with the relevant image or audio sensors. There is also on-board capability for in-device text-to-speech generation. Two alternative embodiments are presented: a smart Teddy-bear, and a roving dog-like robot. The platform offers a speech-driven user interface and can observe and interpret user actions and facial expressions via its computer vision sensor node. A particular benefit of this design is that no personally identifiable information passes beyond the neural inference nodes thus providing inbuilt compliance with data protection regulations.", "url": "https://arxiv.org/abs/2311.11030"}, {"metadata": {"arXiv": "2311.11045", "Date": "Sat, 18 Nov 2023 11:44:52 ", "Title": "Orca 2: Teaching Small Language Models How to Reason", "Authors": ["Arindam Mitra", "Luciano Del Corro", "Shweti Mahajan", "Andres Codas", "Clarisse Simoes", "Sahaj Agrawal", "Xuxi Chen", "Anastasia Razdaibiedina", "Erik Jones", "Kriti Aggarwal", "Hamid Palangi", "Guoqing Zheng", "Corby Rosset", "Hamed Khanpour", "Ahmed Awadallah"], "Categories": "cs.AI"}, "abstract": "Orca 1 learns from rich signals, such as explanation traces, allowing it to outperform conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval. In Orca 2, we continue exploring how improved training signals can enhance smaller LMs' reasoning abilities. Research on training small LMs has often relied on imitation learning to replicate the output of more capable models. We contend that excessive emphasis on imitation may restrict the potential of smaller models. We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model. For example, while larger models might provide a direct answer to a complex task, smaller models may not have the same capacity. In Orca 2, we teach the model various reasoning techniques (step-by-step, recall then generate, recall-reason-generate, direct answer, etc.). More crucially, we aim to help the model learn to determine the most effective solution strategy for each task. We evaluate Orca 2 using a comprehensive set of 15 diverse benchmarks (corresponding to approximately 100 tasks and over 36,000 unique prompts). Orca 2 significantly surpasses models of similar size and attains performance levels similar or better to those of models 5-10x larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. We open-source Orca 2 to encourage further research on the development, evaluation, and alignment of smaller LMs.", "url": "https://arxiv.org/abs/2311.11045"}, {"metadata": {"arXiv": "2311.11120", "Date": "Sat, 18 Nov 2023 17:07:25 ", "Title": "An Improved Neural Network Model Based On CNN Using For Fruit Sugar Degree Detection", "Authors": ["Boyang Deng", "Xin Wen", "and Zhan Gao"], "Categories": "cs.AI"}, "abstract": "Artificial Intelligence(AI) widely applies in Image Classification and Recognition, Text Understanding and Natural Language Processing, which makes great progress. In this paper, we introduced AI into the fruit quality detection field. We designed a fruit sugar degree regression model using an Artificial Neural Network based on spectra of fruits within the visible/near-infrared(V/NIR)range. After analysis of fruit spectra, we innovatively proposed a new neural network structure: low layers consist of a Multilayer Perceptron(MLP), a middle layer is a 2-dimensional correlation matrix layer, and high layers consist of several Convolutional Neural Network(CNN) layers. In this study, we used fruit sugar value as a detection target, collecting two fruits called Gan Nan Navel and Tian Shan Pear as samples, doing experiments respectively, and comparing their results. We used Analysis of Variance(ANOVA) to evaluate the reliability of the dataset we collected. Then, we tried multiple strategies to process spectrum data, evaluating their effects. In this paper, we tried to add Wavelet Decomposition(WD) to reduce feature dimensions and a Genetic Algorithm(GA) to find excellent features. Then, we compared Neural Network models with traditional Partial Least Squares(PLS) based models. We also compared the neural network structure we designed(MLP-CNN) with other traditional neural network structures. In this paper, we proposed a new evaluation standard derived from dataset standard deviation(STD) for evaluating detection performance, validating the viability of using an artificial neural network model to do fruit sugar degree nondestructive detection.", "url": "https://arxiv.org/abs/2311.11120"}, {"metadata": {"arXiv": "2311.11175", "Date": "Sat, 18 Nov 2023 21:57:54 ", "Title": "Best uses of ChatGPT and Generative AI for computer science research", "Authors": ["Eduardo C. Garrido-Merchan"], "Categories": "cs.AI"}, "abstract": "Generative Artificial Intelligence (AI), particularly tools like OpenAI's popular ChatGPT, is reshaping the landscape of computer science research. Used wisely, these tools can boost the productivity of a computer research scientist. This paper provides an exploration of the diverse applications of ChatGPT and other generative AI technologies in computer science academic research, making recommendations about the use of Generative AI to make more productive the role of the computer research scientist, with the focus of writing new research papers. We highlight innovative uses such as brainstorming research ideas, aiding in the drafting and styling of academic papers and assisting in the synthesis of state-of-the-art section. Further, we delve into using these technologies in understanding interdisciplinary approaches, making complex texts simpler, and recommending suitable academic journals for publication. Significant focus is placed on generative AI's contributions to synthetic data creation, research methodology, and mentorship, as well as in task organization and article quality assessment. The paper also addresses the utility of AI in article review, adapting texts to length constraints, constructing counterarguments, and survey development. Moreover, we explore the capabilities of these tools in disseminating ideas, generating images and audio, text transcription, and engaging with editors. We also describe some non-recommended uses of generative AI for computer science research, mainly because of the limitations of this technology.", "url": "https://arxiv.org/abs/2311.11175"}, {"metadata": {"arXiv": "2311.11211", "Date": "Sun, 19 Nov 2023 03:29:45 ", "Title": "Leveraging Generative AI for Clinical Evidence Summarization Needs to Achieve Trustworthiness", "Authors": ["Gongbo Zhang", "Qiao Jin", "Denis Jered McInerney", "Yong Chen", "Fei Wang", "Curtis L. Cole", "Qian Yang", "Yanshan Wang", "Bradley A. Malin", "Mor Peleg", "Byron C. Wallace", "Zhiyong Lu", "Chunhua Weng", "Yifan Peng"], "Categories": "cs.AI"}, "abstract": "Evidence-based medicine aims to improve the quality of healthcare by empowering medical decisions and practices with the best available evidence. The rapid growth of medical evidence, which can be obtained from various sources, poses a challenge in collecting, appraising, and synthesizing the evidential information. Recent advancements in generative AI, exemplified by large language models, hold promise in facilitating the arduous task. However, developing accountable, fair, and inclusive models remains a complicated undertaking. In this perspective, we discuss the trustworthiness of generative AI in the context of automated summarization of medical evidence.", "url": "https://arxiv.org/abs/2311.11211"}, {"metadata": {"arXiv": "2311.11226", "Date": "Sun, 19 Nov 2023 04:42:24 ", "Title": "An Interactive Query Generation Assistant using LLM-based Prompt Modification and User Feedback", "Authors": ["Kaustubh D. Dhole", "Ramraj Chandradevan", "Eugene Agichtein"], "Categories": "cs.AI cs.IR", "Comments": ["Intelligence Advanced Research Projects Activity (IARPA) BETTER Research Program"]}, "abstract": "While search is the predominant method of accessing information, formulating effective queries remains a challenging task, especially for situations where the users are not familiar with a domain, or searching for documents in other languages, or looking for complex information such as events, which are not easily expressible as queries. Providing example documents or passages of interest, might be easier for a user, however, such query-by-example scenarios are prone to concept drift, and are highly sensitive to the query generation method. This demo illustrates complementary approaches of using LLMs interactively, assisting and enabling the user to provide edits and feedback at all stages of the query formulation process. The proposed Query Generation Assistant is a novel search interface which supports automatic and interactive query generation over a mono-linguial or multi-lingual document collection. Specifically, the proposed assistive interface enables the users to refine the queries generated by different LLMs, to provide feedback on the retrieved documents or passages, and is able to incorporate the users' feedback as prompts to generate more effective queries. The proposed interface is a valuable experimental tool for exploring fine-tuning and prompting of LLMs for query generation to qualitatively evaluate the effectiveness of retrieval and ranking models, and for conducting Human-in-the-Loop (HITL) experiments for complex search tasks where users struggle to formulate queries without such assistance.", "url": "https://arxiv.org/abs/2311.11226"}, {"metadata": {"arXiv": "2311.11237", "Date": "Sun, 19 Nov 2023 05:49:39 ", "Title": "Implementation of AI Deep Learning Algorithm For Multi-Modal Sentiment Analysis", "Authors": ["Jiazhen Wang"], "Categories": "cs.AI"}, "abstract": "A multi-modal emotion recognition method was established by combining two-channel convolutional neural network with ring network. This method can extract emotional information effectively and improve learning efficiency. The words were vectorized with GloVe, and the word vector was input into the convolutional neural network. Combining attention mechanism and maximum pool converter BiSRU channel, the local deep emotion and pre-post sequential emotion semantics are obtained. Finally, multiple features are fused and input as the polarity of emotion, so as to achieve the emotion analysis of the target. Experiments show that the emotion analysis method based on feature fusion can effectively improve the recognition accuracy of emotion data set and reduce the learning time. The model has a certain generalization.", "url": "https://arxiv.org/abs/2311.11237"}, {"metadata": {"arXiv": "2311.11250", "Date": "Sun, 19 Nov 2023 06:29:41 ", "Title": "A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications", "Authors": ["Sudhanshu Kumar (1)", "Partha Pratim Roy (1)", "Debi Prosad Dogra (2)", "Byung-Gyu Kim (3) ((1) Department of Computer Science and Engineering", "IIT Roorkee", "India", "(2) School of Electrical Sciences", "IIT Bhubaneswar", "Odisha", "India", "(3) Department of IT Engineering", "Sookmyung Women's University", "Seoul", "South Korea)"], "Categories": "cs.AI"}, "abstract": "Sentiment analysis (SA) is an emerging field in text mining. It is the process of computationally identifying and categorizing opinions expressed in a piece of text over different social media platforms. Social media plays an essential role in knowing the customer mindset towards a product, services, and the latest market trends. Most organizations depend on the customer's response and feedback to upgrade their offered products and services. SA or opinion mining seems to be a promising research area for various domains. It plays a vital role in analyzing big data generated daily in structured and unstructured formats over the internet. This survey paper defines sentiment and its recent research and development in different domains, including voice, images, videos, and text. The challenges and opportunities of sentiment analysis are also discussed in the paper. \\keywords{Sentiment Analysis, Machine Learning, Lexicon-based approach, Deep Learning, Natural Language Processing}", "url": "https://arxiv.org/abs/2311.11250"}, {"metadata": {"arXiv": "2311.11288", "Date": "Sun, 19 Nov 2023 10:24:39 ", "Title": "What Lies beyond the Pareto Front? A Survey on Decision-Support Methods for Multi-Objective Optimization", "Authors": ["Zuzanna Osika", "Jazmin Zatarain Salazar", "Diederik M. Roijers", "Frans A. Oliehoek and Pradeep K. Murukannaiah"], "Categories": "cs.AI", "Comments": ["IJCAI 2023 Conference Paper", "Survey Track"]}, "abstract": "We present a review that unifies decision-support methods for exploring the solutions produced by multi-objective optimization (MOO) algorithms. As MOO is applied to solve diverse problems, approaches for analyzing the trade-offs offered by MOO algorithms are scattered across fields. We provide an overview of the advances on this topic, including methods for visualization, mining the solution set, and uncertainty exploration as well as emerging research directions, including interactivity, explainability, and ethics. We synthesize these methods drawing from different fields of research to build a unified approach, independent of the application. Our goals are to reduce the entry barrier for researchers and practitioners on using MOO algorithms and to provide novel research directions.", "url": "https://arxiv.org/abs/2311.11288"}, {"metadata": {"arXiv": "2311.11315", "Date": "Sun, 19 Nov 2023 12:37:30 ", "Title": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems", "Authors": ["Yilun Kong", "Jingqing Ruan", "Yihong Chen", "Bin Zhang", "Tianpeng Bao", "Shiwei Shi", "Guoqing Du", "Xiaoru Hu", "Hangyu Mao", "Ziyue Li", "Xingyu Zeng", "Rui Zhao"], "Categories": "cs.AI"}, "abstract": "Large Language Models (LLMs) have demonstrated proficiency in addressing tasks that necessitate a combination of task planning and the usage of external tools that require a blend of task planning and the utilization of external tools, such as APIs. However, real-world complex systems present three prevalent challenges concerning task planning and tool usage: (1) The real system usually has a vast array of APIs, so it is impossible to feed the descriptions of all APIs to the prompt of LLMs as the token length is limited; (2) the real system is designed for handling complex tasks, and the base LLMs can hardly plan a correct sub-task order and API-calling order for such tasks; (3) Similar semantics and functionalities among APIs in real systems create challenges for both LLMs and even humans in distinguishing between them. In response, this paper introduces a comprehensive framework aimed at enhancing the Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating within real-world systems. Our framework comprises three key components designed to address these challenges: (1) the API Retriever selects the most pertinent APIs for the user task among the extensive array available; (2) LLM Finetuner tunes a base LLM so that the finetuned LLM can be more capable for task planning and API calling; (3) the Demo Selector adaptively retrieves different demonstrations related to hard-to-distinguish APIs, which is further used for in-context learning to boost the final performance. We validate our methods using a real-world commercial system as well as an open-sourced academic dataset, and the outcomes clearly showcase the efficacy of each individual component as well as the integrated framework.", "url": "https://arxiv.org/abs/2311.11315"}, {"metadata": {"arXiv": "2311.11400", "Date": "Sun, 19 Nov 2023 19:04:24 ", "Title": "Make me an Offer: Forward and Reverse Auctioning Problems in the Tourism Industry", "Authors": ["Ioannis T. Christou", "Dimitris Doukas", "Konstantina Skouri", "Gerasimos Meletiou"], "Categories": "cs.AI cs.CE cs.CY", "Comments": ["21 pages", "7 figures"]}, "abstract": "Most tourist destinations are facing regular and consistent seasonality with significant economic and social impacts. This phenomenon is more pronounced in the post-covid era, where demand for travel has increased but unevenly among different geographic areas. To counter these problems that both customers and hoteliers are facing, we have developed two auctioning systems that allow hoteliers of lower popularity tier areas or during low season periods to auction their rooms in what we call a forward auction model, and also allows customers to initiate a bidding process whereby hoteliers in an area may make offers to the customer for their rooms, in what constitutes a reverse auction model initiated by the customer, similar to the bidding concept of priceline.com. We develop mathematical programming models that define explicitly both types of auctions, and show that in each type, there are significant benefits to be gained both on the side of the hotelier as well as on the side of the customer. We discuss algorithmic techniques for the approximate solution of these optimization problems, and present results using exact optimization solvers to solve them to guaranteed optimality. These techniques could be beneficial to both customer and hotelier reducing seasonality during middle and low season and providing the customer with attractive offers.", "url": "https://arxiv.org/abs/2311.11400"}, {"metadata": {"arXiv": "2311.11435", "Date": "Sun, 19 Nov 2023 22:14:48 ", "Title": "Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis of COVID-19 Vaccines in India", "Authors": ["Milind Gupta and Abhishek Kaushik"], "Categories": "cs.AI"}, "abstract": "In March 2020, the World Health Organisation declared COVID-19 a global pandemic as it spread to nearly every country. By mid-2021, India had introduced three vaccines: Covishield, Covaxin, and Sputnik. To ensure successful vaccination in a densely populated country like India, understanding public sentiment was crucial. Social media, particularly Reddit with over 430 million users, played a vital role in disseminating information. This study employs data mining techniques to analyze Reddit data and gauge Indian sentiments towards COVID-19 vaccines. Using Python's Text Blob library, comments are annotated to assess general sentiments. Results show that most Reddit users in India expressed neutrality about vaccination, posing a challenge for the Indian government's efforts to vaccinate a significant portion of the population.", "url": "https://arxiv.org/abs/2311.11435"}, {"metadata": {"arXiv": "2311.11476", "Date": "Mon, 20 Nov 2023 01:04:04 ", "Title": "Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions", "Authors": ["Rashikala Weerawarna and Shah J Miah"], "Categories": "cs.AI", "Comments": ["Ppaper has been accepted for presenting in the Australasian Conference on Information Systems 2023", "Dec 6 to 8", "Wellington", "NZ"], "Journal-ref": "Australasian Conference on Information Systems 2023, Wellington, NZ"}, "abstract": "The advent of Blockchain technology (BT) revolutionised the way remittance transactions are recorded. Banks and remittance organisations have shown a growing interest in exploring blockchain's potential advantages over traditional practices. This paper presents a data-driven predictive decision support approach as an innovative artefact designed for the blockchain-oriented remittance industry. Employing a theory-generating Design Science Research (DSR) approach, we have uncovered the emergence of predictive capabilities driven by transactional big data. The artefact integrates predictive analytics and Machine Learning (ML) to enable real-time remittance monitoring, empowering management decision-makers to address challenges in the uncertain digitised landscape of blockchain-oriented remittance companies. Bridging the gap between theory and practice, this research not only enhances the security of the remittance ecosystem but also lays the foundation for future predictive decision support solutions, extending the potential of predictive analytics to other domains. Additionally, the generated theory from the artifact's implementation enriches the DSR approach and fosters grounded and stakeholder theory development in the information systems domain.", "url": "https://arxiv.org/abs/2311.11476"}, {"metadata": {"arXiv": "2311.11482", "Date": "Mon, 20 Nov 2023 01:51:13 ", "Title": "Meta Prompting for AGI Systems", "Authors": ["Yifan Zhang"], "Categories": "cs.AI cs.CL"}, "abstract": "This paper presents an in-depth exploration of Meta Prompting, a novel technique that revolutionizes the way large language models (LLMs), multi-modal foundation models, and AI systems approach problem-solving and data interpretation. Meta Prompting, rooted in type theory and category theory, prioritizes the structure and syntax of information, providing a unique framework that transcends traditional content-focused methods. We delve into the formal definitions of Meta Prompting, contrasting it with Few-Shot Prompting, and highlight its applicability and superiority in various AI applications. Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. Here, we demonstrate how this technique adeptly breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method proves especially advantageous in terms of token efficiency and offering a fair comparison in problem-solving scenarios, standing out against few-shot example approaches. Furthermore, the paper breaks new ground by extending Meta Prompting into multi-modal foundation model settings. This extension addresses the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting, highlighting both the challenges and the vast potential of this approach in handling complex, multi-faceted data (The code is available at https://github.com/meta-prompting/meta-prompting).", "url": "https://arxiv.org/abs/2311.11482"}, {"metadata": {"arXiv": "2311.11516", "Date": "Mon, 20 Nov 2023 03:42:24 ", "Title": "GPT in Data Science: A Practical Exploration of Model Selection", "Authors": ["Nathalia Nascimento", "Cristina Tavares", "Paulo Alencar", "Donald Cowan"], "Categories": "cs.AI cs.CL cs.DB", "Comments": ["11 pages. To appear in IEEE BigData 2023"]}, "abstract": "There is an increasing interest in leveraging Large Language Models (LLMs) for managing structured data and enhancing data science processes. Despite the potential benefits, this integration poses significant questions regarding their reliability and decision-making methodologies. It highlights the importance of various factors in the model selection process, including the nature of the data, problem type, performance metrics, computational resources, interpretability vs accuracy, assumptions about data, and ethical considerations. Our objective is to elucidate and express the factors and assumptions guiding GPT-4's model selection recommendations. We employ a variability model to depict these factors and use toy datasets to evaluate both the model and the implementation of the identified heuristics. By contrasting these outcomes with heuristics from other platforms, our aim is to determine the effectiveness and distinctiveness of GPT-4's methodology. This research is committed to advancing our comprehension of AI decision-making processes, especially in the realm of model selection within data science. Our efforts are directed towards creating AI systems that are more transparent and comprehensible, contributing to a more responsible and efficient practice in data science.", "url": "https://arxiv.org/abs/2311.11516"}, {"metadata": {"arXiv": "2311.11539", "Date": "Mon, 20 Nov 2023 05:07:03 ", "Title": "A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure", "Authors": ["Jing Yang", "Wei Su"], "Categories": "cs.AI"}, "abstract": "For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy number(IFN). Intuitionistic fuzzy set (IFS) plays an important role in dealing with un-certain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which con-siders the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented pa-per is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some exist-ing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In medical diagnosis area, it can be used to quickly diagnose disease. The proposed method enriches the exist-ing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets(IVIFSs) as well.", "url": "https://arxiv.org/abs/2311.11539"}, {"metadata": {"arXiv": "2311.11542", "Date": "Mon, 20 Nov 2023 05:13:17 ", "Title": "Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling", "Authors": ["Izack Cohen"], "Categories": "cs.AI"}, "abstract": "Our focus is on projects, i.e., business processes, which are emerging as the economic drivers of our times. Differently from day-to-day operational processes that do not require detailed planning, a project requires planning and resource-constrained scheduling for coordinating resources across sub- or related projects and organizations. A planner in charge of project planning has to select a set of activities to perform, determine their precedence constraints, and schedule them according to temporal project constraints. We suggest a data-driven project planning approach for classes of projects such as infrastructure building and information systems development projects. A project network is first learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for: 1) decoding a project variation such that it forms a new project plan, and 2) applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation. Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.", "url": "https://arxiv.org/abs/2311.11542"}, {"metadata": {"arXiv": "2311.11547", "Date": "Mon, 20 Nov 2023 05:55:05 ", "Title": "Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT", "Authors": ["Abdelkarim El-Hajjami", "Nicolas Fafin", "Camille Salinesi"], "Categories": "cs.AI cs.SE"}, "abstract": "Context and motivation: Recently, Large Language Models (LLMs) like ChatGPT have demonstrated remarkable proficiency in various Natural Language Processing (NLP) tasks. Their application in Requirements Engineering (RE), especially in requirements classification, has gained increasing interest. Question/problem: In our research, we conducted an extensive empirical evaluation of ChatGPT models including text-davinci-003, gpt-3.5-turbo, and gpt-4 in both zero-shot and few-shot settings for requirements classification. The question arises as to how these models compare to traditional classification methods, specifically Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). Principal ideas/results: Based on five diverse datasets, our results show that ChatGPT consistently outperforms LSTM, and while ChatGPT is more effective than SVM in classifying functional requirements (FR), SVM is better in classifying non-functional requirements (NFR). Our results also show that contrary to our expectations, the few-shot setting does not always lead to enhanced performance; in most instances, it was found to be suboptimal. Contribution: Our findings underscore the potential of LLMs in the RE domain, suggesting that they could play a pivotal role in future software engineering processes, particularly as tools to enhance requirements classification.", "url": "https://arxiv.org/abs/2311.11547"}, {"metadata": {"arXiv": "2311.11591", "Date": "Mon, 20 Nov 2023 08:05:52 ", "Title": "DesignGPT: Multi-Agent Collaboration in Design", "Authors": ["Shiying Ding", "Xinyi Chen", "Yan Fang", "Wenrui Liu", "Yiwu Qiu", "Chunlei Chai"], "Categories": "cs.AI cs.HC"}, "abstract": "Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.", "url": "https://arxiv.org/abs/2311.11591"}, {"metadata": {"arXiv": "2311.11605", "Date": "Mon, 20 Nov 2023 08:43:09 ", "Title": "Machine learning-based malware detection for IoT devices using control-flow data", "Authors": ["Gergely Hevesi"], "Categories": "cs.AI cs.CR"}, "abstract": "Embedded devices are specialised devices designed for one or only a few purposes. They are often part of a larger system, through wired or wireless connection. Those embedded devices that are connected to other computers or embedded systems through the Internet are called Internet of Things (IoT for short) devices. With their widespread usage and their insufficient protection, these devices are increasingly becoming the target of malware attacks. Companies often cut corners to save manufacturing costs or misconfigure when producing these devices. This can be lack of software updates, ports left open or security defects by design. Although these devices may not be as powerful as a regular computer, their large number makes them suitable candidates for botnets. Other types of IoT devices can even cause health problems since there are even pacemakers connected to the Internet. This means, that without sufficient defence, even directed assaults are possible against people. The goal of this thesis project is to provide better security for these devices with the help of machine learning algorithms and reverse engineering tools. Specifically, I study the applicability of control-flow related data of executables for malware detection. I present a malware detection method with two phases. The first phase extracts control-flow related data using static binary analysis. The second phase classifies binary executables as either malicious or benign using a neural network model. I train the model using a dataset of malicious and benign ARM applications.", "url": "https://arxiv.org/abs/2311.11605"}, {"metadata": {"arXiv": "2311.11652", "Date": "Mon, 20 Nov 2023 10:38:22 ", "Title": "Web News Timeline Generation with Extended Task Prompting", "Authors": ["Sha Wang", "Yuchen Li", "Hanhua Xiao", "Lambert Deng", "Yanfei Dong"], "Categories": "cs.AI", "Comments": ["4 pages"]}, "abstract": "The creation of news timeline is essential for a comprehensive and contextual understanding of events as they unfold over time. This approach aids in discerning patterns and trends that might be obscured when news is viewed in isolation. By organizing news in a chronological sequence, it becomes easier to track the development of stories, understand the interrelation of events, and grasp the broader implications of news items. This is particularly helpful in sectors like finance and insurance, where timely understanding of the event development-ranging from extreme weather to political upheavals and health crises-is indispensable for effective risk management. While traditional natural language processing (NLP) techniques have had some success, they often fail to capture the news with nuanced relevance that are readily apparent to domain experts, hindering broader industry integration. The advance of Large Language Models (LLMs) offers a renewed opportunity to tackle this challenge. However, direct prompting LLMs for this task is often ineffective. Our study investigates the application of an extended task prompting technique to assess past news relevance. We demonstrate that enhancing conventional prompts with additional tasks boosts their effectiveness on various news dataset, rendering news timeline generation practical for professional use. This work has been deployed as a publicly accessible browser extension which is adopted within our network.", "url": "https://arxiv.org/abs/2311.11652"}, {"metadata": {"arXiv": "2311.11655", "Date": "Mon, 20 Nov 2023 10:42:31 ", "Title": "Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System", "Authors": ["Dean-Robin Kern", "Gunnar Stevens", "Erik Dethier", "Sidra Naveed", "Fatemeh Alizadeh", "Delong Du", "Md Shajalal"], "Categories": "cs.AI cs.HC", "Comments": ["7 pages", "3 figures", "ACM CHI 2023 Workshop on Human-Centered Explainable AI (HCXAI)"]}, "abstract": "Explainable Artificial Intelligence is a concept aimed at making complex algorithms transparent to users through a uniform solution. Researchers have highlighted the importance of integrating domain specific contexts to develop explanations tailored to end users. In this study, we focus on the Schufa housing scoring system in Germany and investigate how users information needs and expectations for explanations vary based on their roles. Using the speculative design approach, we asked business information students to imagine user interfaces that provide housing credit score explanations from the perspectives of both tenants and landlords. Our preliminary findings suggest that although there are general needs that apply to all users, there are also conflicting needs that depend on the practical realities of their roles and how credit scores affect them. We contribute to Human centered XAI research by proposing future research directions that examine users explanatory needs considering their roles and agencies.", "url": "https://arxiv.org/abs/2311.11655"}, {"metadata": {"arXiv": "2311.11689", "Date": "Mon, 20 Nov 2023 11:43:20 ", "Title": "Causal Structure Learning Supervised by Large Language Model", "Authors": ["Taiyu Ban and Lyuzhou Chen and Derui Lyu and Xiangyu Wang and Huanhuan Chen"], "Categories": "cs.AI"}, "abstract": "Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \\url{https://github.com/tyMadara/ILS-CSL}.", "url": "https://arxiv.org/abs/2311.11689"}, {"metadata": {"arXiv": "2311.11756", "Date": "Mon, 20 Nov 2023 13:34:08 ", "Title": "LSTM-CNN: An efficient diagnostic network for Parkinson's disease utilizing dynamic handwriting analysis", "Authors": ["Xuechao Wang", "Junqing Huang", "Sven Nomm", "Marianna Chatzakou", "Kadri Medijainen", "Aaro Toomela", "Michael Ruzhansky"], "Categories": "cs.AI"}, "abstract": "Background and objectives: Dynamic handwriting analysis, due to its non-invasive and readily accessible nature, has recently emerged as a vital adjunctive method for the early diagnosis of Parkinson's disease. In this study, we design a compact and efficient network architecture to analyse the distinctive handwriting patterns of patients' dynamic handwriting signals, thereby providing an objective identification for the Parkinson's disease diagnosis. Methods: The proposed network is based on a hybrid deep learning approach that fully leverages the advantages of both long short-term memory (LSTM) and convolutional neural networks (CNNs). Specifically, the LSTM block is adopted to extract the time-varying features, while the CNN-based block is implemented using one-dimensional convolution for low computational cost. Moreover, the hybrid model architecture is continuously refined under ablation studies for superior performance. Finally, we evaluate the proposed method with its generalization under a five-fold cross-validation, which validates its efficiency and robustness. Results: The proposed network demonstrates its versatility by achieving impressive classification accuracies on both our new DraWritePD dataset ($96.2\\%$) and the well-established PaHaW dataset ($90.7\\%$). Moreover, the network architecture also stands out for its excellent lightweight design, occupying a mere $0.084$M of parameters, with a total of only $0.59$M floating-point operations. It also exhibits near real-time CPU inference performance, with inference times ranging from $0.106$ to $0.220$s. Conclusions: We present a series of experiments with extensive analysis, which systematically demonstrate the effectiveness and efficiency of the proposed hybrid neural network in extracting distinctive handwriting patterns for precise diagnosis of Parkinson's disease.", "url": "https://arxiv.org/abs/2311.11756"}, {"metadata": {"arXiv": "2311.11775", "Date": "Mon, 20 Nov 2023 14:02:10 ", "Title": "Intelligent methods for business rule processing: State-of-the-art", "Authors": ["Cristiano Andr\\'e da Costa", "U\\'elison Jean Lopes dos Santos", "Eduardo Souza dos Reis", "Rodolfo Stoffel Antunes", "Henrique Chaves Pacheco", "Thayn\\~a da Silva Fran\\c{c}a", "Rodrigo da Rosa Righi", "Jorge Luis Vict\\'oria Barbosa", "Franklin Jebadoss", "Jorge Montalvao", "Rogerio Kunkel"], "Categories": "cs.AI", "Comments": ["6 pages", "3 figures"]}, "abstract": "In this article, we provide an overview of the latest intelligent techniques used for processing business rules. We have conducted a comprehensive survey of the relevant literature on robot process automation, with a specific focus on machine learning and other intelligent approaches. Additionally, we have examined the top vendors in the market and their leading solutions to tackle this issue.", "url": "https://arxiv.org/abs/2311.11775"}, {"metadata": {"arXiv": "2311.11776", "Date": "Mon, 20 Nov 2023 14:02:28 ", "Title": "Responsible AI Research Needs Impact Statements Too", "Authors": ["Alexandra Olteanu", "Michael Ekstrand", "Carlos Castillo", "Jina Suh"], "Categories": "cs.AI cs.CY"}, "abstract": "All types of research, development, and policy work can have unintended, adverse consequences - work in responsible artificial intelligence (RAI), ethical AI, or ethics in AI is no exception.", "url": "https://arxiv.org/abs/2311.11776"}, {"metadata": {"arXiv": "2311.11802", "Date": "Mon, 20 Nov 2023 14:37:20 ", "Title": "Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens", "Authors": ["Andoni Aranguren", "Eneko Osaba", "Silvia Urra-Uriarte and Patricia Molina-Costa"], "Categories": "cs.AI", "Comments": ["11 pages", "5 figures", "paper presented in the 11th World Conference on Information Systems and Technologies (WorldCist'23)"]}, "abstract": "The application of routing algorithms to real-world situations is a widely studied research topic. Despite this, routing algorithms and applications are usually developed for a general purpose, meaning that certain groups, such as ageing people, are often marginalized due to the broad approach of the designed algorithms. This situation may pose a problem in cities which are suffering a slow but progressive ageing of their populations. With this motivation in mind, this paper focuses on describing our implemented Age-Friendly Route Planner, whose goal is to improve the experience in the city for senior citizens. In order to measure the age-friendliness of a route, several variables have been deemed, such as the number of amenities along the route, the amount of comfortable elements found, or the avoidance of sloppy sections. In this paper, we describe one of the main features of the Age-Friendly Route Planner: the preference-based routes, and we also demonstrate how it can contribute to the creation of adapted friendly routes.", "url": "https://arxiv.org/abs/2311.11802"}, {"metadata": {"arXiv": "2311.11811", "Date": "Mon, 20 Nov 2023 14:47:20 ", "Title": "Large Language Models and Explainable Law: a Hybrid Methodology", "Authors": ["Marco Billi", "Alessandro Parenti", "Giuseppe Pisano", "Marco Sanchi"], "Categories": "cs.AI"}, "abstract": "The paper advocates for LLMs to enhance the accessibility, usage and explainability of rule-based legal systems, contributing to a democratic and stakeholder-oriented view of legal technology. A methodology is developed to explore the potential use of LLMs for translating the explanations produced by rule-based systems, from high-level programming languages to natural language, allowing all users a fast, clear, and accessible interaction with such technologies. The study continues by building upon these explanations to empower laypeople with the ability to execute complex juridical tasks on their own, using a Chain of Prompts for the autonomous legal comparison of different rule-based inferences, applied to the same factual case.", "url": "https://arxiv.org/abs/2311.11811"}, {"metadata": {"arXiv": "2311.11812", "Date": "Mon, 20 Nov 2023 14:48:09 ", "Title": "Improving Real Estate Appraisal with POI Integration and Areal Embedding", "Authors": ["Sumin Han", "Youngjun Park", "Sonia Sabir", "Jisun An", "Dongman Lee"], "Categories": "cs.AI"}, "abstract": "Despite advancements in real estate appraisal methods, this study primarily focuses on two pivotal challenges. Firstly, we explore the often-underestimated impact of Points of Interest (POI) on property values, emphasizing the necessity for a comprehensive, data-driven approach to feature selection. Secondly, we integrate road-network-based Areal Embedding to enhance spatial understanding for real estate appraisal. We first propose a revised method for POI feature extraction, and discuss the impact of each POI for house price appraisal. Then we present the Areal embedding-enabled Masked Multihead Attention-based Spatial Interpolation for House Price Prediction (AMMASI) model, an improvement upon the existing ASI model, which leverages masked multi-head attention on geographic neighbor houses and similar-featured houses. Our model outperforms current baselines and also offers promising avenues for future optimization in real estate appraisal methodologies.", "url": "https://arxiv.org/abs/2311.11812"}, {"metadata": {"arXiv": "2311.11868", "Date": "Mon, 20 Nov 2023 16:04:56 ", "Title": "Towards Exploratory Reformulation of Constraint Models", "Authors": ["Ian Miguel and Andr\\'as Z. Salamon and Christopher Stone"], "Categories": "cs.AI", "Comments": ["13 pages", "6 figures"], "ACM-class": "F.4.2"}, "abstract": "It is well established that formulating an effective constraint model of a problem of interest is crucial to the efficiency with which it can subsequently be solved. Following from the observation that it is difficult, if not impossible, to know a priori which of a set of candidate models will perform best in practice, we envisage a system that explores the space of models through a process of reformulation from an initial model, guided by performance on a set of training instances from the problem class under consideration. We plan to situate this system in a refinement-based approach, where a user writes a constraint specification describing a problem above the level of abstraction at which many modelling decisions are made. In this position paper we set out our plan for an exploratory reformulation system, and discuss progress made so far.", "url": "https://arxiv.org/abs/2311.11868"}, {"metadata": {"arXiv": "2311.11910", "Date": "Mon, 20 Nov 2023 16:40:48 ", "Title": "Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning", "Authors": ["Biying Fu", "Naser Damer", "Florian Kirchbuchner", "and Arjan Kuijper"], "Categories": "cs.AI cs.CV", "Comments": ["accepted at International Conference on Pattern Recognition (ICPR) workshop 2021"]}, "abstract": "In previous works, a mobile application was developed using an unmodified commercial off-the-shelf smartphone to recognize whole-body exercises. The working principle was based on the ultrasound Doppler sensing with the device built-in hardware. Applying such a lab-environment trained model on realistic application variations causes a significant drop in performance, and thus decimate its applicability. The reason of the reduced performance can be manifold. It could be induced by the user, environment, and device variations in realistic scenarios. Such scenarios are often more complex and diverse, which can be challenging to anticipate in the initial training data. To study and overcome this issue, this paper presents a database with controlled and uncontrolled subsets of fitness exercises. We propose two concepts to utilize small adaption data to successfully improve model generalization in an uncontrolled environment, increasing the recognition accuracy by two to six folds compared to the baseline for different users.", "url": "https://arxiv.org/abs/2311.11910"}, {"metadata": {"arXiv": "2311.12010", "Date": "Mon, 20 Nov 2023 18:45:04 ", "Title": "Steering Responsible AI: A Case for Algorithmic Pluralism", "Authors": ["Stefaan G. Verhulst"], "Categories": "cs.AI", "Comments": ["10 pages", "working paper"]}, "abstract": "In this paper, I examine questions surrounding AI neutrality through the prism of existing literature and scholarship about mediation and media pluralism. Such traditions, I argue, provide a valuable theoretical framework for how we should approach the (likely) impending era of AI mediation. In particular, I suggest examining further the notion of algorithmic pluralism. Contrasting this notion to the dominant idea of algorithmic transparency, I seek to describe what algorithmic pluralism may be, and present both its opportunities and challenges. Implemented thoughtfully and responsibly, I argue, Algorithmic or AI pluralism has the potential to sustain the diversity, multiplicity, and inclusiveness that are so vital to democracy.", "url": "https://arxiv.org/abs/2311.12010"}, {"metadata": {"arXiv": "2311.12022", "Date": "Mon, 20 Nov 2023 18:57:34 ", "Title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "Authors": ["David Rein", "Betty Li Hou", "Asa Cooper Stickland", "Jackson Petty", "Richard Yuanzhe Pang", "Julien Dirani", "Julian Michael", "Samuel R. Bowman"], "Categories": "cs.AI cs.CL", "Comments": ["28 pages", "5 figures", "7 tables"]}, "abstract": "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are \"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.", "url": "https://arxiv.org/abs/2311.12022"}, {"metadata": {"arXiv": "2311.10788", "Date": "Fri, 17 Nov 2023 00:21:02 ", "Title": "Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors", "Authors": ["Peter Gr\\\"onquist", "Yufan Ren", "Qingyi He", "Alessio Verardo", "Sabine S\\\"usstrunk"], "Categories": "cs.CV cs.AI", "ACM-class": "I.5.4; I.4.8; I.2.10; I.4.2"}, "abstract": "Video DeepFakes are fake media created with Deep Learning (DL) that manipulate a person's expression or identity. Most current DeepFake detection methods analyze each frame independently, ignoring inconsistencies and unnatural movements between frames. Some newer methods employ optical flow models to capture this temporal aspect, but they are computationally expensive. In contrast, we propose using the related but often ignored Motion Vectors (MVs) and Information Masks (IMs) from the H.264 video codec, to detect temporal inconsistencies in DeepFakes. Our experiments show that this approach is effective and has minimal computational costs, compared with per-frame RGB-only methods. This could lead to new, real-time temporally-aware DeepFake detection methods for video calls and streaming.", "url": "https://arxiv.org/abs/2311.10788"}, {"metadata": {"arXiv": "2311.10793", "Date": "Fri, 17 Nov 2023 02:30:36 ", "Title": "Traffic Sign Interpretation in Real Road Scene", "Authors": ["Chuang Yang", "Kai Zhuang", "Mulin Chen", "Haozhao Ma", "Xu Han", "Tao Han", "Changxing Guo", "Han Han", "Bingxuan Zhao", "and Qi Wang"], "Categories": "cs.CV cs.AI"}, "abstract": "Most existing traffic sign-related works are dedicated to detecting and recognizing part of traffic signs individually, which fails to analyze the global semantic logic among signs and may convey inaccurate traffic instruction. Following the above issues, we propose a traffic sign interpretation (TSI) task, which aims to interpret global semantic interrelated traffic signs (e.g.,~driving instruction-related texts, symbols, and guide panels) into a natural language for providing accurate instruction support to autonomous or assistant driving. Meanwhile, we design a multi-task learning architecture for TSI, which is responsible for detecting and recognizing various traffic signs and interpreting them into a natural language like a human. Furthermore, the absence of a public TSI available dataset prompts us to build a traffic sign interpretation dataset, namely TSI-CN. The dataset consists of real road scene images, which are captured from the highway and the urban way in China from a driver's perspective. It contains rich location labels of texts, symbols, and guide panels, and the corresponding natural language description labels. Experiments on TSI-CN demonstrate that the TSI task is achievable and the TSI architecture can interpret traffic signs from scenes successfully even if there is a complex semantic logic among signs. The TSI-CN dataset and the source code of the TSI architecture will be publicly available after the revision process.", "url": "https://arxiv.org/abs/2311.10793"}, {"metadata": {"arXiv": "2311.10807", "Date": "Fri, 17 Nov 2023 14:10:57 ", "Title": "SENetV2: Aggregated dense layer for channelwise and global representations", "Authors": ["Mahendran Narayanan"], "Categories": "cs.CV cs.AI", "Comments": ["WACV 2024 (Rejected)"]}, "abstract": "Convolutional Neural Networks (CNNs) have revolutionized image classification by extracting spatial features and enabling state-of-the-art accuracy in vision-based tasks. The squeeze and excitation network proposed module gathers channelwise representations of the input. Multilayer perceptrons (MLP) learn global representation from the data and in most image classification models used to learn extracted features of the image. In this paper, we introduce a novel aggregated multilayer perceptron, a multi-branch dense layer, within the Squeeze excitation residual module designed to surpass the performance of existing architectures. Our approach leverages a combination of squeeze excitation network module with dense layers. This fusion enhances the network's ability to capture channel-wise patterns and have global knowledge, leading to a better feature representation. This proposed model has a negligible increase in parameters when compared to SENet. We conduct extensive experiments on benchmark datasets to validate the model and compare them with established architectures. Experimental results demonstrate a remarkable increase in the classification accuracy of the proposed model.", "url": "https://arxiv.org/abs/2311.10807"}, {"metadata": {"arXiv": "2311.10813", "Date": "Fri, 17 Nov 2023 18:59:56 ", "Title": "A Language Agent for Autonomous Driving", "Authors": ["Jiageng Mao and Junjie Ye and Yuxi Qian and Marco Pavone and Yue Wang"], "Categories": "cs.CV cs.AI cs.CL cs.RO"}, "abstract": "Human-level driving is an ultimate goal of autonomous driving. Conventional approaches formulate autonomous driving as a perception-prediction-planning framework, yet their systems do not capitalize on the inherent reasoning ability and experiential knowledge of humans. In this paper, we propose a fundamental paradigm shift from current pipelines, exploiting Large Language Models (LLMs) as a cognitive agent to integrate human-like intelligence into autonomous driving systems. Our approach, termed Agent-Driver, transforms the traditional autonomous driving pipeline by introducing a versatile tool library accessible via function calls, a cognitive memory of common sense and experiential knowledge for decision-making, and a reasoning engine capable of chain-of-thought reasoning, task planning, motion planning, and self-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive common sense and robust reasoning capabilities, thus enabling a more nuanced, human-like approach to autonomous driving. We evaluate our approach on the large-scale nuScenes benchmark, and extensive experiments substantiate that our Agent-Driver significantly outperforms the state-of-the-art driving methods by a large margin. Our approach also demonstrates superior interpretability and few-shot learning ability to these methods. Project page: \\href{https://github.com/USC-GVL/Agent-Driver/blob/main/index.html}{here}.", "url": "https://arxiv.org/abs/2311.10813"}, {"metadata": {"arXiv": "2311.10931", "Date": "Sun, 29 Oct 2023 23:25:10 ", "Title": "FLORIDA: Fake-looking Real Images Dataset", "Authors": ["Ali Borji"], "Categories": "cs.CV cs.AI"}, "abstract": "Although extensive research has been carried out to evaluate the effectiveness of AI tools and models in detecting deep fakes, the question remains unanswered regarding whether these models can accurately identify genuine images that appear artificial. In this study, as an initial step towards addressing this issue, we have curated a dataset of 510 genuine images that exhibit a fake appearance and conducted an assessment using two AI models. We show that two models exhibited subpar performance when applied to our dataset. Additionally, our dataset can serve as a valuable tool for assessing the ability of deep learning models to comprehend complex visual stimuli. We anticipate that this research will stimulate further discussions and investigations in this area. Our dataset is accessible at https://github.com/aliborji/FLORIDA.", "url": "https://arxiv.org/abs/2311.10931"}, {"metadata": {"arXiv": "2311.11014", "Date": "Sat, 18 Nov 2023 08:51:25 ", "Title": "Lesion Search with Self-supervised Learning", "Authors": ["Kristin Qi", "Jiali Cheng", "Daniel Haehn"], "Categories": "cs.CV cs.AI", "Comments": ["ICLR 2023 Tiny Paper"]}, "abstract": "Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians' interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to classify lesion types and retrieve similar images before clinicians' analysis. Results have shown improved performance. We additionally build an open-source application for image analysis and retrieval. The application is easy to integrate, relieving manual efforts and suggesting the potential to support clinicians' everyday activities.", "url": "https://arxiv.org/abs/2311.11014"}, {"metadata": {"arXiv": "2311.11029", "Date": "Sat, 18 Nov 2023 10:35:18 ", "Title": "Geometric Data Augmentations to Mitigate Distribution Shifts in Pollen Classification from Microscopic Images", "Authors": ["Nam Cao", "Olga Saukh"], "Categories": "cs.CV cs.AI", "Comments": ["16 pages", "6 figures", "ICPADS 2023"]}, "abstract": "Distribution shifts are characterized by differences between the training and test data distributions. They can significantly reduce the accuracy of machine learning models deployed in real-world scenarios. This paper explores the distribution shift problem when classifying pollen grains from microscopic images collected in the wild with a low-cost camera sensor. We leverage the domain knowledge that geometric features are highly important for accurate pollen identification and introduce two novel geometric image augmentation techniques to significantly narrow the accuracy gap between the model performance on the train and test datasets. In particular, we show that Tenengrad and ImageToSketch filters are highly effective to balance the shape and texture information while leaving out unimportant details that may confuse the model. Extensive evaluations on various model architectures demonstrate a consistent improvement of the model generalization to field data of up to 14% achieved by the geometric augmentation techniques when compared to a wide range of standard image augmentations. The approach is validated through an ablation study using pollen hydration tests to recover the shape of dry pollen grains. The proposed geometric augmentations also receive the highest scores according to the affinity and diversity measures from the literature.", "url": "https://arxiv.org/abs/2311.11029"}, {"metadata": {"arXiv": "2311.11039", "Date": "Sat, 18 Nov 2023 11:15:08 ", "Title": "Synthetic Data Generation for Bridging Sim2Real Gap in a Production Environment", "Authors": ["Parth Rawal", "Mrunal Sompura", "Wolfgang Hintze"], "Categories": "cs.CV cs.AI cs.RO", "Comments": ["17 pages", "9 figures", "has not been presented in any conference or published in journal"]}, "abstract": "Synthetic data is being used lately for training deep neural networks in computer vision applications such as object detection, object segmentation and 6D object pose estimation. Domain randomization hereby plays an important role in reducing the simulation to reality gap. However, this generalization might not be effective in specialized domains like a production environment involving complex assemblies. Either the individual parts, trained with synthetic images, are integrated in much larger assemblies making them indistinguishable from their counterparts and result in false positives or are partially occluded just enough to give rise to false negatives. Domain knowledge is vital in these cases and if conceived effectively while generating synthetic data, can show a considerable improvement in bridging the simulation to reality gap. This paper focuses on synthetic data generation procedures for parts and assemblies used in a production environment. The basic procedures for synthetic data generation and their various combinations are evaluated and compared on images captured in a production environment, where results show up to 15% improvement using combinations of basic procedures. Reducing the simulation to reality gap in this way can aid to utilize the true potential of robot assisted production using artificial intelligence.", "url": "https://arxiv.org/abs/2311.11039"}, {"metadata": {"arXiv": "2311.11191", "Date": "Sun, 19 Nov 2023 00:47:17 ", "Title": "Attention-Based Real-Time Defenses for Physical Adversarial Attacks in Vision Applications", "Authors": ["Giulio Rossolini", "Alessandro Biondi and Giorgio Buttazzo"], "Categories": "cs.CV cs.AI"}, "abstract": "Deep neural networks exhibit excellent performance in computer vision tasks, but their vulnerability to real-world adversarial attacks, achieved through physical objects that can corrupt their predictions, raises serious security concerns for their application in safety-critical domains. Existing defense methods focus on single-frame analysis and are characterized by high computational costs that limit their applicability in multi-frame scenarios, where real-time decisions are crucial. To address this problem, this paper proposes an efficient attention-based defense mechanism that exploits adversarial channel-attention to quickly identify and track malicious objects in shallow network layers and mask their adversarial effects in a multi-frame setting. This work advances the state of the art by enhancing existing over-activation techniques for real-world adversarial attacks to make them usable in real-time applications. It also introduces an efficient multi-frame defense framework, validating its efficacy through extensive experiments aimed at evaluating both defense performance and computational cost.", "url": "https://arxiv.org/abs/2311.11191"}, {"metadata": {"arXiv": "2311.11207", "Date": "Sun, 19 Nov 2023 03:17:54 ", "Title": "On the Noise Scheduling for Generating Plausible Designs with Diffusion Models", "Authors": ["Jiajie Fan", "Laure Vuaille", "Thomas B\\\"ack", "Hao Wang"], "Categories": "cs.CV cs.AI cs.CE"}, "abstract": "Deep Generative Models (DGMs) are widely used to create innovative designs across multiple industries, ranging from fashion to the automotive sector. In addition to generating images of high visual quality, the task of structural design generation imposes more stringent constrains on the semantic expression, e.g., no floating material or missing part, which we refer to as plausibility in this work. We delve into the impact of noise schedules of diffusion models on the plausibility of the outcome: there exists a range of noise levels at which the model's performance decides the result plausibility. Also, we propose two techniques to determine such a range for a given image set and devise a novel parametric noise schedule for better plausibility. We apply this noise schedule to the training and sampling of the well-known diffusion model EDM and compare it to its default noise schedule. Compared to EDM, our schedule significantly improves the rate of plausible designs from 83.4% to 93.5% and Fr\\'echet Inception Distance (FID) from 7.84 to 4.87. Further applications of advanced image editing tools demonstrate the model's solid understanding of structure.", "url": "https://arxiv.org/abs/2311.11207"}, {"metadata": {"arXiv": "2311.11261", "Date": "Sun, 19 Nov 2023 07:47:43 ", "Title": "Adversarial Prompt Tuning for Vision-Language Models", "Authors": ["Jiaming Zhang", "Xingjun Ma", "Xin Wang", "Lingyu Qiu", "Jiaqi Wang", "Yu-Gang Jiang", "Jitao Sang"], "Categories": "cs.CV cs.AI"}, "abstract": "With the rapid advancement of multimodal learning, pre-trained Vision-Language Models (VLMs) such as CLIP have demonstrated remarkable capacities in bridging the gap between visual and language modalities. However, these models remain vulnerable to adversarial attacks, particularly in the image modality, presenting considerable security risks. This paper introduces Adversarial Prompt Tuning (AdvPT), a novel technique to enhance the adversarial robustness of image encoders in VLMs. AdvPT innovatively leverages learnable text prompts and aligns them with adversarial image embeddings, to address the vulnerabilities inherent in VLMs without the need for extensive parameter training or modification of the model architecture. We demonstrate that AdvPT improves resistance against white-box and black-box adversarial attacks and exhibits a synergistic effect when combined with existing image-processing-based defense techniques, further boosting defensive capabilities. Comprehensive experimental analyses provide insights into adversarial prompt tuning, a novel paradigm devoted to improving resistance to adversarial images through textual input modifications, paving the way for future robust multimodal learning research. These findings open up new possibilities for enhancing the security of VLMs. Our code will be available upon publication of the paper.", "url": "https://arxiv.org/abs/2311.11261"}, {"metadata": {"arXiv": "2311.11319", "Date": "Sun, 19 Nov 2023 13:28:01 ", "Title": "GeoSAM: Fine-tuning SAM with Sparse and Dense Visual Prompting for Automated Segmentation of Mobility Infrastructure", "Authors": ["Rafi Ibn Sultan", "Chengyin Li", "Hui Zhu", "Prashant Khanduri", "Marco Brocanelli", "Dongxiao Zhu"], "Categories": "cs.CV cs.AI"}, "abstract": "The Segment Anything Model (SAM) has shown impressive performance when applied to natural image segmentation. However, it struggles with geographical images like aerial and satellite imagery, especially when segmenting mobility infrastructure including roads, sidewalks, and crosswalks. This inferior performance stems from the narrow features of these objects, their textures blending into the surroundings, and interference from objects like trees, buildings, vehicles, and pedestrians - all of which can disorient the model to produce inaccurate segmentation maps. To address these challenges, we propose Geographical SAM (GeoSAM), a novel SAM-based framework that implements a fine-tuning strategy using the dense visual prompt from zero-shot learning, and the sparse visual prompt from a pre-trained CNN segmentation model. The proposed GeoSAM outperforms existing approaches for geographical image segmentation, specifically by 20%, 14.29%, and 17.65% for road infrastructure, pedestrian infrastructure, and on average, respectively, representing a momentous leap in leveraging foundation models to segment mobility infrastructure including both road and pedestrian infrastructure in geographical images.", "url": "https://arxiv.org/abs/2311.11319"}, {"metadata": {"arXiv": "2311.11371", "Date": "Sun, 19 Nov 2023 16:47:51 ", "Title": "SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction Transformers trained under memory constraints", "Authors": ["Aditya Nalgunda Ganesh"], "Categories": "cs.CV cs.AI", "Comments": ["This work has been submitted to the ICRA 2024 IEEE for possible publication. Copyright may be transferred without notice", "after which this version may no longer be accessible"]}, "abstract": "We present SOccDPT, a memory-efficient approach for 3D semantic occupancy prediction from monocular image input using dense prediction transformers. To address the limitations of existing methods trained on structured traffic datasets, we train our model on unstructured datasets including the Indian Driving Dataset and Bengaluru Driving Dataset. Our semi-supervised training pipeline allows SOccDPT to learn from datasets with limited labels by reducing the requirement for manual labelling by substituting it with pseudo-ground truth labels to produce our Bengaluru Semantic Occupancy Dataset. This broader training enhances our model's ability to handle unstructured traffic scenarios effectively. To overcome memory limitations during training, we introduce patch-wise training where we select a subset of parameters to train each epoch, reducing memory usage during auto-grad graph construction. In the context of unstructured traffic and memory-constrained training and inference, SOccDPT outperforms existing disparity estimation approaches as shown by the RMSE score of 9.1473, achieves a semantic segmentation IoU score of 46.02% and operates at a competitive frequency of 69.47 Hz. We make our code and semantic occupancy dataset public.", "url": "https://arxiv.org/abs/2311.11371"}, {"metadata": {"arXiv": "2311.11378", "Date": "Sun, 19 Nov 2023 17:22:50 ", "Title": "Inspecting Explainability of Transformer Models with Additional Statistical Information", "Authors": ["Hoang C. Nguyen", "Haeil Lee", "Junmo Kim"], "Categories": "cs.CV cs.AI"}, "abstract": "Transformer becomes more popular in the vision domain in recent years so there is a need for finding an effective way to interpret the Transformer model by visualizing it. In recent work, Chefer et al. can visualize the Transformer on vision and multi-modal tasks effectively by combining attention layers to show the importance of each image patch. However, when applying to other variants of Transformer such as the Swin Transformer, this method can not focus on the predicted object. Our method, by considering the statistics of tokens in layer normalization layers, shows a great ability to interpret the explainability of Swin Transformer and ViT.", "url": "https://arxiv.org/abs/2311.11378"}, {"metadata": {"arXiv": "2311.11427", "Date": "Sun, 19 Nov 2023 21:24:34 ", "Title": "Appearance Codes using Joint Embedding Learning of Multiple Modalities", "Authors": ["Alex Zhang and Evan Dogariu"], "Categories": "cs.CV cs.AI"}, "abstract": "The use of appearance codes in recent work on generative modeling has enabled novel view renders with variable appearance and illumination, such as day-time and night-time renders of a scene. A major limitation of this technique is the need to re-train new appearance codes for every scene on inference, so in this work we address this problem proposing a framework that learns a joint embedding space for the appearance and structure of the scene by enforcing a contrastive loss constraint between different modalities. We apply our framework to a simple Variational Auto-Encoder model on the RADIATE dataset \\cite{sheeny2021radiate} and qualitatively demonstrate that we can generate new renders of night-time photos using day-time appearance codes without additional optimization iterations. Additionally, we compare our model to a baseline VAE that uses the standard per-image appearance code technique and show that our approach achieves generations of similar quality without learning appearance codes for any unseen images on inference.", "url": "https://arxiv.org/abs/2311.11427"}, {"metadata": {"arXiv": "2311.11467", "Date": "Wed, 02 Aug 2023 13:37:08 ", "Title": "SkateboardAI: The Coolest Video Action Recognition for Skateboarding", "Authors": ["Hanxiao Chen"], "Categories": "cs.CV cs.AI", "Comments": ["This original first-author work has been accepted and presented by CVPR 2022 WiCV Workshop"]}, "abstract": "Impressed by the coolest skateboarding sports program from 2021 Tokyo Olympic Games, we are the first to curate the original real-world video datasets \"SkateboardAI\" in the wild, even self-design and implement diverse uni-modal and multi-modal video action recognition approaches to recognize different tricks accurately. For uni-modal methods, we separately apply (1) CNN and LSTM; (2) CNN and BiLSTM; (3) CNN and BiLSTM with effective attention mechanisms; (4) Transformer-based action recognition pipeline. Transferred to the multi-modal conditions, we investigated the two-stream Inflated-3D architecture on \"SkateboardAI\" datasets to compare its performance with uni-modal cases. In sum, our objective is developing an excellent AI sport referee for the coolest skateboarding competitions.", "url": "https://arxiv.org/abs/2311.11467"}, {"metadata": {"arXiv": "2311.11471", "Date": "Wed, 09 Aug 2023 16:46:21 ", "Title": "Towards AI enabled automated tracking of multiple boxers", "Authors": ["A.S. Karthikeyan", "Vipul Baghel", "Anish Monsley Kirupakaran", "John Warburton", "Ranganathan Srinivasan", "Babji Srinivasan", "Ravi Sadananda Hegde"], "Categories": "cs.CV cs.AI"}, "abstract": "Continuous tracking of boxers across multiple training sessions helps quantify traits required for the well-known ten-point-must system. However, continuous tracking of multiple athletes across multiple training sessions remains a challenge, because it is difficult to precisely segment bout boundaries in a recorded video stream. Furthermore, re-identification of the same athlete over different period or even within the same bout remains a challenge. Difficulties are further compounded when a single fixed view video is captured in top-view. This work summarizes our progress in creating a system in an economically single fixed top-view camera. Specifically, we describe improved algorithm for bout transition detection and in-bout continuous player identification without erroneous ID updation or ID switching. From our custom collected data of ~11 hours (athlete count: 45, bouts: 189), our transition detection algorithm achieves 90% accuracy and continuous ID tracking achieves IDU=0, IDS=0.", "url": "https://arxiv.org/abs/2311.11471"}, {"metadata": {"arXiv": "2311.11570", "Date": "Mon, 20 Nov 2023 07:10:39 ", "Title": "Decoupled DETR For Few-shot Object Detection", "Authors": ["Zeyu Shangguan", "Lian Huai", "Tong Liu", "Xingqun Jiang"], "Categories": "cs.CV cs.AI"}, "abstract": "Few-shot object detection (FSOD), an efficient method for addressing the severe data-hungry problem, has been extensively discussed. Current works have significantly advanced the problem in terms of model and data. However, the overall performance of most FSOD methods still does not fulfill the desired accuracy. In this paper we improve the FSOD model to address the severe issue of sample imbalance and weak feature propagation. To alleviate modeling bias from data-sufficient base classes, we examine the effect of decoupling the parameters for classes with sufficient data and classes with few samples in various ways. We design a base-novel categories decoupled DETR (DeDETR) for FSOD. We also explore various types of skip connection between the encoder and decoder for DETR. Besides, we notice that the best outputs could come from the intermediate layer of the decoder instead of the last layer; therefore, we build a unified decoder module that could dynamically fuse the decoder layers as the output feature. We evaluate our model on commonly used datasets such as PASCAL VOC and MSCOCO. Our results indicate that our proposed module could achieve stable improvements of 5% to 10% in both fine-tuning and meta-learning paradigms and has outperformed the highest score in recent works.", "url": "https://arxiv.org/abs/2311.11570"}, {"metadata": {"arXiv": "2311.11590", "Date": "Mon, 20 Nov 2023 08:03:12 ", "Title": "Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models", "Authors": ["Zheyuan Kuang", "Jiaxin Zhang", "Yiying Huang", "Yunqin Li"], "Categories": "cs.CV cs.AI", "Comments": ["HABITS OF THE ANTHROPOCENE - Proceedings of the 43rd ACADIA Conference - Volume II: Proceedings book one", "University of Colorado Denver", "Denver", "Colorado", "USA", "26-28 October 2023", "pp. 616-625", "CUMINCAD", "2023"]}, "abstract": "Urban renewal and transformation processes necessitate the preservation of the historical urban fabric, particularly in districts known for their architectural and historical significance. These regions, with their diverse architectural styles, have traditionally required extensive preliminary research, often leading to subjective results. However, the advent of machine learning models has opened up new avenues for generating building facade images. Despite this, creating high-quality images for historical district renovations remains challenging, due to the complexity and diversity inherent in such districts. In response to these challenges, our study introduces a new methodology for automatically generating images of historical arcade facades, utilizing Stable Diffusion models conditioned on textual descriptions. By classifying and tagging a variety of arcade styles, we have constructed several realistic arcade facade image datasets. We trained multiple low-rank adaptation (LoRA) models to control the stylistic aspects of the generated images, supplemented by ControlNet models for improved precision and authenticity. Our approach has demonstrated high levels of precision, authenticity, and diversity in the generated images, showing promising potential for real-world urban renewal projects. This new methodology offers a more efficient and accurate alternative to conventional design processes in urban renewal, bypassing issues of unconvincing image details, lack of precision, and limited stylistic variety. Future research could focus on integrating this two-dimensional image generation with three-dimensional modeling techniques, providing a more comprehensive solution for renovating architectural facades in historical districts.", "url": "https://arxiv.org/abs/2311.11590"}, {"metadata": {"arXiv": "2311.11602", "Date": "Mon, 20 Nov 2023 08:29:55 ", "Title": "A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow", "Authors": ["Jaemin Lee", "Minseok Seo", "Sangwoo Lee", "Hyobin Park", "Dong-Geol Choi"], "Categories": "cs.CV cs.AI"}, "abstract": "In general, deep learning-based video frame interpolation (VFI) methods have predominantly focused on estimating motion vectors between two input frames and warping them to the target time. While this approach has shown impressive performance for linear motion between two input frames, it exhibits limitations when dealing with occlusions and nonlinear movements. Recently, generative models have been applied to VFI to address these issues. However, as VFI is not a task focused on generating plausible images, but rather on predicting accurate intermediate frames between two given frames, performance limitations still persist. In this paper, we propose a multi-in-single-out (MISO) based VFI method that does not rely on motion vector estimation, allowing it to effectively model occlusions and nonlinear motion. Additionally, we introduce a novel motion perceptual loss that enables MISO-VFI to better capture the spatio-temporal correlations within the video frames. Our MISO-VFI method achieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and UCF101, with a significant performance gap compared to existing approaches.", "url": "https://arxiv.org/abs/2311.11602"}, {"metadata": {"arXiv": "2311.11659", "Date": "Mon, 20 Nov 2023 10:49:32 ", "Title": "MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features", "Authors": ["Mingxin Liu", "Yunzan Liu", "Hui Cui", "Chunquan Li", "Jiquan Ma"], "Categories": "cs.CV cs.AI", "Comments": ["7 pages", "4 figures", "accepted by 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2023)"]}, "abstract": "The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000x150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods.", "url": "https://arxiv.org/abs/2311.11659"}, {"metadata": {"arXiv": "2311.11683", "Date": "Mon, 20 Nov 2023 11:28:18 ", "Title": "ViP-Mixer: A Convolutional Mixer for Video Prediction", "Authors": ["Xin Zheng", "Ziang Peng", "Yuan Cao", "Hongming Shan", "Junping Zhang"], "Categories": "cs.CV cs.AI", "Comments": ["Under review"]}, "abstract": "Video prediction aims to predict future frames from a video's previous content. Existing methods mainly process video data where the time dimension mingles with the space and channel dimensions from three distinct angles: as a sequence of individual frames, as a 3D volume in spatiotemporal coordinates, or as a stacked image where frames are treated as separate channels. Most of them generally focus on one of these perspectives and may fail to fully exploit the relationships across different dimensions. To address this issue, this paper introduces a convolutional mixer for video prediction, termed ViP-Mixer, to model the spatiotemporal evolution in the latent space of an autoencoder. The ViP-Mixers are stacked sequentially and interleave feature mixing at three levels: frames, channels, and locations. Extensive experiments demonstrate that our proposed method achieves new state-of-the-art prediction performance on three benchmark video datasets covering both synthetic and real-world scenarios.", "url": "https://arxiv.org/abs/2311.11683"}, {"metadata": {"arXiv": "2311.11722", "Date": "Mon, 20 Nov 2023 12:37:58 ", "Title": "Sparse4D v3: Advancing End-to-End 3D Detection and Tracking", "Authors": ["Xuewu Lin", "Zixiang Pei", "Tianwei Lin", "Lichao Huang", "Zhizhong Su"], "Categories": "cs.CV cs.AI cs.RO"}, "abstract": "In autonomous driving perception systems, 3D detection and tracking are the two fundamental tasks. This paper delves deeper into this field, building upon the Sparse4D framework. We introduce two auxiliary training tasks (Temporal Instance Denoising and Quality Estimation) and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. Additionally, we extend the detector into a tracker using a straightforward approach that assigns instance ID during inference, further highlighting the advantages of query-based algorithms. Extensive experiments conducted on the nuScenes benchmark validate the effectiveness of the proposed improvements. With ResNet50 as the backbone, we witnessed enhancements of 3.0\\%, 2.2\\%, and 7.6\\% in mAP, NDS, and AMOTA, achieving 46.9\\%, 56.1\\%, and 49.0\\%, respectively. Our best model achieved 71.9\\% NDS and 67.7\\% AMOTA on the nuScenes test set. Code will be released at \\url{https://github.com/linxuewu/Sparse4D}.", "url": "https://arxiv.org/abs/2311.11722"}, {"metadata": {"arXiv": "2311.11754", "Date": "Mon, 20 Nov 2023 13:30:42 ", "Title": "A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection", "Authors": ["Wang Jie", "Zhong Yilin", "Cao Qianqian"], "Categories": "cs.CV cs.AI"}, "abstract": "Automotive related datasets have previously been used for training autonomous driving systems or vehicle classification tasks. However, there is a lack of datasets in the field of automotive AI for car parts detection, and most available datasets are limited in size and scope, struggling to cover diverse scenarios. To address this gap, this paper presents a large-scale and fine-grained automotive dataset consisting of 84,162 images for detecting 12 different types of car parts. This dataset was collected from natural cameras and online websites which covers various car brands, scenarios, and shooting angles. To alleviate the burden of manual annotation, we propose a novel semi-supervised auto-labeling method that leverages state-of-the-art pre-trained detectors. Moreover, we study the limitations of the Grounding DINO approach for zero-shot labeling. Finally, we evaluate the effectiveness of our proposed dataset through fine-grained car parts detection by training several lightweight YOLO-series detectors.", "url": "https://arxiv.org/abs/2311.11754"}, {"metadata": {"arXiv": "2311.11810", "Date": "Mon, 20 Nov 2023 14:42:25 ", "Title": "DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding", "Authors": ["Hao Feng and Qi Liu and Hao Liu and Wengang Zhou and Houqiang Li and Can Huang"], "Categories": "cs.CV cs.AI"}, "abstract": "This work presents DocPedia, a novel large multimodal model (LMM) for versatile OCR-free document understanding, capable of parsing images up to 2,560$\\times$2,560 resolution. Unlike existing work either struggle with high-resolution documents or give up the large language model thus vision or language ability constrained, our DocPedia directly processes visual input in the frequency domain rather than the pixel space. The unique characteristic enables DocPedia to capture a greater amount of visual and textual information using a limited number of visual tokens. To consistently enhance both perception and comprehension abilities of our model, we develop a dual-stage training strategy and enrich instructions/annotations of all training tasks covering multiple document types. Extensive quantitative and qualitative experiments conducted on various publicly available benchmarks confirm the mutual benefits of jointly learning perception and comprehension tasks. The results provide further evidence of the effectiveness and superior performance of our DocPedia over other methods.", "url": "https://arxiv.org/abs/2311.11810"}, {"metadata": {"arXiv": "2311.11988", "Date": "Mon, 20 Nov 2023 18:21:18 ", "Title": "Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs", "Authors": ["Shreyas Sundara Raman", "Madeline H. Pelgrim", "Daphna Buchsbaum and Thomas Serre"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages", "11 figures", "1 table", "WACV CV4Smalls Workshop"]}, "abstract": "Dogs have a unique evolutionary relationship with humans and serve many important roles e.g. search and rescue, blind assistance, emotional support. However, few datasets exist to categorize visual features and objects available to dogs, as well as how dogs direct their visual attention within their environment. We collect and study a dataset with over 11,698 gazes to categorize the objects available to be gazed at by 11 dogs in everyday outdoor environments i.e. a walk around a college campus and urban area. We explore the availability of these object categories and the visual attention of dogs over these categories using a head mounted eye tracking apparatus. A small portion (approx. 600 images or < 20% of total dataset) of the collected data is used to fine tune a MaskRCNN for the novel image domain to segment objects present in the scene, enabling further statistical analysis on the visual gaze tendencies of dogs. The MaskRCNN, with eye tracking apparatus, serves as an end to end model for automatically classifying the visual fixations of dogs. The fine tuned MaskRCNN performs far better than chance. There are few individual differences between the 11 dogs and we observe greater visual fixations on buses, plants, pavement, and construction equipment. This work takes a step towards understanding visual behavior of dogs and their interaction with the physical world.", "url": "https://arxiv.org/abs/2311.11988"}, {"metadata": {"arXiv": "2311.11101", "Date": "Sat, 18 Nov 2023 15:30:29 ", "Title": "$\\varepsilon$-fractional Core Stability in Hedonic Games", "Authors": ["Simone Fioravanti", "Michele Flammini", "Bojana Kodric and Giovanna Varricchio"], "Categories": "cs.GT cs.AI", "Comments": ["Accepted as poster at NeurIPS 2023"]}, "abstract": "Hedonic Games (HGs) are a classical framework modeling coalition formation of strategic agents guided by their individual preferences. According to these preferences, it is desirable that a coalition structure (i.e. a partition of agents into coalitions) satisfies some form of stability. The most well-known and natural of such notions is arguably core-stability. Informally, a partition is core-stable if no subset of agents would like to deviate by regrouping in a so-called core-blocking coalition. Unfortunately, core-stable partitions seldom exist and even when they do, it is often computationally intractable to find one. To circumvent these problems, we propose the notion of $\\varepsilon$-fractional core-stability, where at most an $\\varepsilon$-fraction of all possible coalitions is allowed to core-block. It turns out that such a relaxation may guarantee both existence and polynomial-time computation. Specifically, we design efficient algorithms returning an $\\varepsilon$-fractional core-stable partition, with $\\varepsilon$ exponentially decreasing in the number of agents, for two fundamental classes of HGs: Simple Fractional and Anonymous. From a probabilistic point of view, being the definition of $\\varepsilon$-fractional core equivalent to requiring that uniformly sampled coalitions core-block with probability lower than $\\varepsilon$, we further extend the definition to handle more complex sampling distributions. Along this line, when valuations have to be learned from samples in a PAC-learning fashion, we give positive and negative results on which distributions allow the efficient computation of outcomes that are $\\varepsilon$-fractional core-stable with arbitrarily high confidence.", "url": "https://arxiv.org/abs/2311.11101"}, {"metadata": {"arXiv": "2311.10751", "Date": "Thu, 02 Nov 2023 14:32:16 ", "Title": "ProAgent: From Robotic Process Automation to Agentic Process Automation", "Authors": ["Yining Ye", "Xin Cong", "Shizuo Tian", "Jiannan Cao", "Hao Wang", "Yujia Qin", "Yaxi Lu", "Heyang Yu", "Huadong Wang", "Yankai Lin", "Zhiyuan Liu", "Maosong Sun"], "Categories": "cs.RO cs.AI cs.CL", "Comments": ["Work in progress"]}, "abstract": "From ancient water wheels to robotic process automation (RPA), automation technology has evolved throughout history to liberate human beings from arduous tasks. Yet, RPA struggles with tasks needing human-like intelligence, especially in elaborate design of workflow construction and dynamic decision-making in workflow execution. As Large Language Models (LLMs) have emerged human-like intelligence, this paper introduces Agentic Process Automation (APA), a groundbreaking automation paradigm using LLM-based agents for advanced automation by offloading the human labor to agents associated with construction and execution. We then instantiate ProAgent, an LLM-based agent designed to craft workflows from human instructions and make intricate decisions by coordinating specialized agents. Empirical experiments are conducted to detail its construction and execution procedure of workflow, showcasing the feasibility of APA, unveiling the possibility of a new paradigm of automation driven by agents. Our code is public at https://github.com/OpenBMB/ProAgent.", "url": "https://arxiv.org/abs/2311.10751"}, {"metadata": {"arXiv": "2311.11287", "Date": "Sun, 19 Nov 2023 10:19:22 ", "Title": "Tactile Active Inference Reinforcement Learning for Efficient Robotic Manipulation Skill Acquisition", "Authors": ["Zihao Liu", "Xing Liu", "Yizhai Zhang", "Zhengxiong Liu and Panfeng Huang"], "Categories": "cs.RO cs.AI"}, "abstract": "Robotic manipulation holds the potential to replace humans in the execution of tedious or dangerous tasks. However, control-based approaches are not suitable due to the difficulty of formally describing open-world manipulation in reality, and the inefficiency of existing learning methods. Thus, applying manipulation in a wide range of scenarios presents significant challenges. In this study, we propose a novel method for skill learning in robotic manipulation called Tactile Active Inference Reinforcement Learning (Tactile-AIRL), aimed at achieving efficient training. To enhance the performance of reinforcement learning (RL), we introduce active inference, which integrates model-based techniques and intrinsic curiosity into the RL process. This integration improves the algorithm's training efficiency and adaptability to sparse rewards. Additionally, we utilize a vision-based tactile sensor to provide detailed perception for manipulation tasks. Finally, we employ a model-based approach to imagine and plan appropriate actions through free energy minimization. Simulation results demonstrate that our method achieves significantly high training efficiency in non-prehensile objects pushing tasks. It enables agents to excel in both dense and sparse reward tasks with just a few interaction episodes, surpassing the SAC baseline. Furthermore, we conduct physical experiments on a gripper screwing task using our method, which showcases the algorithm's rapid learning capability and its potential for practical applications.", "url": "https://arxiv.org/abs/2311.11287"}, {"metadata": {"arXiv": "2311.10892", "Date": "Fri, 17 Nov 2023 22:25:07 ", "Title": "The Hidden Linear Structure in Score-Based Models and its Application", "Authors": ["Binxu Wang", "John J. Vastola"], "Categories": "cs.AI cs.LG cs.NA cs.NE math.NA stat.CO", "Comments": ["Accepted to Workshop on Diffusion Models in NeurIPS 2023. 24 pages", "8 figures"], "ACM-class": "I.3.3; I.5.1; G.1.7; I.2.6"}, "abstract": "Score-based models have achieved remarkable results in the generative modeling of many domains. By learning the gradient of smoothed data distribution, they can iteratively generate samples from complex distribution e.g. natural images. However, is there any universal structure in the gradient field that will eventually be learned by any neural network? Here, we aim to find such structures through a normative analysis of the score function. First, we derived the closed-form solution to the scored-based model with a Gaussian score. We claimed that for well-trained diffusion models, the learned score at a high noise scale is well approximated by the linear score of Gaussian. We demonstrated this through empirical validation of pre-trained images diffusion model and theoretical analysis of the score function. This finding enabled us to precisely predict the initial diffusion trajectory using the analytical solution and to accelerate image sampling by 15-30\\% by skipping the initial phase without sacrificing image quality. Our finding of the linear structure in the score-based model has implications for better model design and data pre-processing.", "url": "https://arxiv.org/abs/2311.10892"}, {"metadata": {"arXiv": "2311.10953", "Date": "Sat, 18 Nov 2023 03:17:51 ", "Title": "HungerGist: An Interpretable Predictive Model for Food Insecurity", "Authors": ["Yongsu Ahn", "Muheng Yan", "Yu-Ru Lin", "Zian Wang"], "Categories": "cs.AI cs.LG"}, "abstract": "The escalating food insecurity in Africa, caused by factors such as war, climate change, and poverty, demonstrates the critical need for advanced early warning systems. Traditional methodologies, relying on expert-curated data encompassing climate, geography, and social disturbances, often fall short due to data limitations, hindering comprehensive analysis and potential discovery of new predictive factors. To address this, this paper introduces \"HungerGist\", a multi-task deep learning model utilizing news texts and NLP techniques. Using a corpus of over 53,000 news articles from nine African countries over four years, we demonstrate that our model, trained solely on news data, outperforms the baseline method trained on both traditional risk factors and human-curated keywords. In addition, our method has the ability to detect critical texts that contain interpretable signals known as \"gists.\" Moreover, our examination of these gists indicates that this approach has the potential to reveal latent factors that would otherwise remain concealed in unstructured texts.", "url": "https://arxiv.org/abs/2311.10953"}, {"metadata": {"arXiv": "2311.11055", "Date": "Sat, 18 Nov 2023 12:29:18 ", "Title": "Designing Interpretable ML System to Enhance Trustworthy AI in Healthcare: A Systematic Review of the Last Decade to A Proposed Robust Framework", "Authors": ["Elham Nasarian", "Roohallah Alizadehsani", "U. Rajendra Acharyac", "d Kwok-Leung Tsui"], "Categories": "cs.AI cs.HC cs.LG", "Comments": ["37 pages (without appendixes and references) + 16 figures + 5 tables"]}, "abstract": "AI-based medical technologies, including wearables, telemedicine, LLMs, and digital care twins, significantly impact healthcare. Ensuring AI results are accurate and interpretable is crucial, especially for clinicians. This paper reviews processes and challenges of interpretable ML (IML) and explainable AI (XAI) in healthcare. Objectives include reviewing XAI processes, methods, applications, and challenges, with a focus on quality control. The IML process is classified into data pre-processing interpretability, interpretable modeling, and post-processing interpretability. The paper aims to establish the importance of robust interpretability in healthcare through experimental results, providing insights for creating communicable clinician-AI tools. Research questions, eligibility criteria, and goals were identified following PRISMA and PICO methods. PubMed, Scopus, and Web of Science were systematically searched using specific strings. The survey introduces a step-by-step roadmap for implementing XAI in clinical applications, addressing existing gaps and acknowledging XAI model limitations.", "url": "https://arxiv.org/abs/2311.11055"}, {"metadata": {"arXiv": "2311.11212", "Date": "Sun, 19 Nov 2023 03:31:30 ", "Title": "Can We Utilize Pre-trained Language Models within Causal Discovery Algorithms?", "Authors": ["Chanhui Lee (1)", "Juhyeon Kim (2)", "Yongjun Jeong (3)", "Juhyun Lyu (4)", "Junghee Kim (4)", "Sangmin Lee (4)", "Sangjun Han (4)", "Hyeokjun Choe (4)", "Soyeon Park (4)", "Woohyung Lim (4)", "Sungbin Lim (5,6{\\dag})", "Sanghack Lee (2,7{\\dag}) ((1) Department of Artificial Intelligence", "Korea University", "(2) Graduate School of Data Science", "Seoul National University", "(3) Department of Computer Science and Engineering", "UNIST", "(4) Data Intelligence Laboratory", "LG AI Research", "(5) Department of Statistics", "Korea University", "(6) LG AI Research", "(7) SNU-LG AI Research Center)"], "Categories": "cs.AI cs.LG", "Comments": ["The first two authors are contributed equally. {\\dag}Corresponding Authors"], "ACM-class": "I.2"}, "abstract": "Scaling laws have allowed Pre-trained Language Models (PLMs) into the field of causal reasoning. Causal reasoning of PLM relies solely on text-based descriptions, in contrast to causal discovery which aims to determine the causal relationships between variables utilizing data. Recently, there has been current research regarding a method that mimics causal discovery by aggregating the outcomes of repetitive causal reasoning, achieved through specifically designed prompts. It highlights the usefulness of PLMs in discovering cause and effect, which is often limited by a lack of data, especially when dealing with multiple variables. Conversely, the characteristics of PLMs which are that PLMs do not analyze data and they are highly dependent on prompt design leads to a crucial limitation for directly using PLMs in causal discovery. Accordingly, PLM-based causal reasoning deeply depends on the prompt design and carries out the risk of overconfidence and false predictions in determining causal relationships. In this paper, we empirically demonstrate the aforementioned limitations of PLM-based causal reasoning through experiments on physics-inspired synthetic data. Then, we propose a new framework that integrates prior knowledge obtained from PLM with a causal discovery algorithm. This is accomplished by initializing an adjacency matrix for causal discovery and incorporating regularization using prior knowledge. Our proposed framework not only demonstrates improved performance through the integration of PLM and causal discovery but also suggests how to leverage PLM-extracted prior knowledge with existing causal discovery algorithms.", "url": "https://arxiv.org/abs/2311.11212"}, {"metadata": {"arXiv": "2311.11537", "Date": "Mon, 20 Nov 2023 04:54:51 ", "Title": "ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning", "Authors": ["Yizhao Jin", "Greg Slabaugh", "Simon Lucas"], "Categories": "cs.AI cs.LG"}, "abstract": "Deep Reinforcement Learning (DRL) agents frequently face challenges in adapting to tasks outside their training distribution, including issues with over-fitting, catastrophic forgetting and sample inefficiency. Although the application of adapters has proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper delves into the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.", "url": "https://arxiv.org/abs/2311.11537"}, {"metadata": {"arXiv": "2311.10983", "Date": "Sat, 18 Nov 2023 06:32:40 ", "Title": "Multiple View Geometry Transformers for 3D Human Pose Estimation", "Authors": ["Ziwei Liao", "Jialiang Zhu", "Chunyu Wang", "Han Hu", "Steven L. Waslander"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["14 pages", "8 figures"]}, "abstract": "In this work, we aim to improve the 3D reasoning ability of Transformers in multi-view 3D human pose estimation. Recent works have focused on end-to-end learning-based transformer designs, which struggle to resolve geometric information accurately, particularly during occlusion. Instead, we propose a novel hybrid model, MVGFormer, which has a series of geometric and appearance modules organized in an iterative manner. The geometry modules are learning-free and handle all viewpoint-dependent 3D tasks geometrically which notably improves the model's generalization ability. The appearance modules are learnable and are dedicated to estimating 2D poses from image signals end-to-end which enables them to achieve accurate estimates even when occlusion occurs, leading to a model that is both accurate and generalizable to new cameras and geometries. We evaluate our approach for both in-domain and out-of-domain settings, where our model consistently outperforms state-of-the-art methods, and especially does so by a significant margin in the out-of-domain setting. We will release the code and models: https://github.com/XunshanMan/MVGFormer.", "url": "https://arxiv.org/abs/2311.10983"}, {"metadata": {"arXiv": "2311.11090", "Date": "Sat, 18 Nov 2023 14:37:53 ", "Title": "Beyond Images: An Integrative Multi-modal Approach to Chest X-Ray Report Generation", "Authors": ["Nurbanu Aksoy", "Serge Sharoff", "Selcuk Baser", "Nishant Ravikumar and Alejandro F Frangi"], "Categories": "cs.CV cs.AI cs.CL cs.LG"}, "abstract": "Image-to-text radiology report generation aims to automatically produce radiology reports that describe the findings in medical images. Most existing methods focus solely on the image data, disregarding the other patient information accessible to radiologists. In this paper, we present a novel multi-modal deep neural network framework for generating chest X-rays reports by integrating structured patient data, such as vital signs and symptoms, alongside unstructured clinical notes.We introduce a conditioned cross-multi-head attention module to fuse these heterogeneous data modalities, bridging the semantic gap between visual and textual data. Experiments demonstrate substantial improvements from using additional modalities compared to relying on images alone. Notably, our model achieves the highest reported performance on the ROUGE-L metric compared to relevant state-of-the-art models in the literature. Furthermore, we employed both human evaluation and clinical semantic similarity measurement alongside word-overlap metrics to improve the depth of quantitative analysis. A human evaluation, conducted by a board-certified radiologist, confirms the model's accuracy in identifying high-level findings, however, it also highlights that more improvement is needed to capture nuanced details and clinical context.", "url": "https://arxiv.org/abs/2311.11090"}, {"metadata": {"arXiv": "2311.11097", "Date": "Sat, 18 Nov 2023 14:52:26 ", "Title": "Radiology Report Generation Using Transformers Conditioned with Non-imaging Data", "Authors": ["Nurbanu Aksoy", "Nishant Ravikumar and Alejandro F Frangi"], "Categories": "cs.CV cs.AI cs.CL cs.LG", "DOI": "10.1117/12.2653672"}, "abstract": "Medical image interpretation is central to most clinical applications such as disease diagnosis, treatment planning, and prognostication. In clinical practice, radiologists examine medical images and manually compile their findings into reports, which can be a time-consuming process. Automated approaches to radiology report generation, therefore, can reduce radiologist workload and improve efficiency in the clinical pathway. While recent deep-learning approaches for automated report generation from medical images have seen some success, most studies have relied on image-derived features alone, ignoring non-imaging patient data. Although a few studies have included the word-level contexts along with the image, the use of patient demographics is still unexplored. This paper proposes a novel multi-modal transformer network that integrates chest x-ray (CXR) images and associated patient demographic information, to synthesise patient-specific radiology reports. The proposed network uses a convolutional neural network to extract visual features from CXRs and a transformer-based encoder-decoder network that combines the visual features with semantic text embeddings of patient demographic information, to synthesise full-text radiology reports. Data from two public databases were used to train and evaluate the proposed approach. CXRs and reports were extracted from the MIMIC-CXR database and combined with corresponding patients' data MIMIC-IV. Based on the evaluation metrics used including patient demographic information was found to improve the quality of reports generated using the proposed approach, relative to a baseline network trained using CXRs alone. The proposed approach shows potential for enhancing radiology report generation by leveraging rich patient metadata and combining semantic text embeddings derived thereof, with medical image-derived visual features.", "url": "https://arxiv.org/abs/2311.11097"}, {"metadata": {"arXiv": "2311.11099", "Date": "Sat, 18 Nov 2023 15:18:38 ", "Title": "Introducing NCL-SM: A Fully Annotated Dataset of Images from Human Skeletal Muscle Biopsies", "Authors": ["Atif Khan", "Conor Lawless", "Amy Vincent", "Charlotte Warren", "Valeria Di Leo", "Tiago Gomes", "A. Stephen McGough"], "Categories": "cs.CV cs.AI cs.LG q-bio.TO", "Comments": ["Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023", "December 10th", "2023", "New Orleans", "United States", "09 pages Full Paper presented at Big Data Analytics for Health and Medicine (BDA4HM) workshop", "IEEE BigData 2023", "December 15th-18th", "2023", "Sorrento", "Italy"]}, "abstract": "Single cell analysis of skeletal muscle (SM) tissue is a fundamental tool for understanding many neuromuscular disorders. For this analysis to be reliable and reproducible, identification of individual fibres within microscopy images (segmentation) of SM tissue should be precise. There is currently no tool or pipeline that makes automatic and precise segmentation and curation of images of SM tissue cross-sections possible. Biomedical scientists in this field rely on custom tools and general machine learning (ML) models, both followed by labour intensive and subjective manual interventions to get the segmentation right. We believe that automated, precise, reproducible segmentation is possible by training ML models. However, there are currently no good quality, publicly available annotated imaging datasets available for ML model training. In this paper we release NCL-SM: a high quality bioimaging dataset of 46 human tissue sections from healthy control subjects and from patients with genetically diagnosed muscle pathology. These images include $>$ 50k manually segmented muscle fibres (myofibres). In addition we also curated high quality myofibres and annotated reasons for rejecting low quality myofibres and regions in SM tissue images, making this data completely ready for downstream analysis. This, we believe, will pave the way for development of a fully automatic pipeline that identifies individual myofibres within images of tissue sections and, in particular, also classifies individual myofibres that are fit for further analysis.", "url": "https://arxiv.org/abs/2311.11099"}, {"metadata": {"arXiv": "2311.11164", "Date": "Sat, 18 Nov 2023 20:49:50 ", "Title": "Mitigating Exposure Bias in Discriminator Guided Diffusion Models", "Authors": ["Eleftherios Tsonis", "Paraskevi Tzouveli", "Athanasios Voulodimos"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Diffusion Models have demonstrated remarkable performance in image generation. However, their demanding computational requirements for training have prompted ongoing efforts to enhance the quality of generated images through modifications in the sampling process. A recent approach, known as Discriminator Guidance, seeks to bridge the gap between the model score and the data score by incorporating an auxiliary term, derived from a discriminator network. We show that despite significantly improving sample quality, this technique has not resolved the persistent issue of Exposure Bias and we propose SEDM-G++, which incorporates a modified sampling approach, combining Discriminator Guidance and Epsilon Scaling. Our proposed approach outperforms the current state-of-the-art, by achieving an FID score of 1.73 on the unconditional CIFAR-10 dataset.", "url": "https://arxiv.org/abs/2311.11164"}, {"metadata": {"arXiv": "2311.11176", "Date": "Sat, 18 Nov 2023 22:06:04 ", "Title": "Morphology-Enhanced CAM-Guided SAM for weakly supervised Breast Lesion Segmentation", "Authors": ["Xin Yue", "Qing Zhao", "Jianqiang Li", "Xiaoling Liu", "Changwei Song", "Suqin Liu", "Guanghui Fu"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Breast cancer diagnosis challenges both patients and clinicians, with early detection being crucial for effective treatment. Ultrasound imaging plays a key role in this, but its utility is hampered by the need for precise lesion segmentation-a task that is both time-consuming and labor-intensive. To address these challenges, we propose a new framework: a morphology-enhanced, Class Activation Map (CAM)-guided model, which is optimized using a computer vision foundation model known as SAM. This innovative framework is specifically designed for weakly supervised lesion segmentation in early-stage breast ultrasound images. Our approach uniquely leverages image-level annotations, which removes the requirement for detailed pixel-level annotation. Initially, we perform a preliminary segmentation using breast lesion morphology knowledge. Following this, we accurately localize lesions by extracting semantic information through a CAM-based heatmap. These two elements are then fused together, serving as a prompt to guide the SAM in performing refined segmentation. Subsequently, post-processing techniques are employed to rectify topological errors made by the SAM. Our method not only simplifies the segmentation process but also attains accuracy comparable to supervised learning methods that rely on pixel-level annotation. Our framework achieves a Dice score of 74.39% on the test set, demonstrating compareable performance with supervised learning methods. Additionally, it outperforms a supervised learning model, in terms of the Hausdorff distance, scoring 24.27 compared to Deeplabv3+'s 32.22. These experimental results showcase its feasibility and superior performance in integrating weakly supervised learning with SAM. The code is made available at: https://github.com/YueXin18/MorSeg-CAM-SAM.", "url": "https://arxiv.org/abs/2311.11176"}, {"metadata": {"arXiv": "2311.11837", "Date": "Mon, 20 Nov 2023 15:11:31 ", "Title": "Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms", "Authors": ["Joren Brunekreef", "Eric Marcus", "Ray Sheombarsing", "Jan-Jakob Sonke", "Jonas Teuwen"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["15 pages", "11 figures"]}, "abstract": "Image segmentation algorithms can be understood as a collection of pixel classifiers, for which the outcomes of nearby pixels are correlated. Classifier models can be calibrated using Inductive Conformal Prediction, but this requires holding back a sufficiently large calibration dataset for computing the distribution of non-conformity scores of the model's predictions. If one only requires only marginal calibration on the image level, this calibration set consists of all individual pixels in the images available for calibration. However, if the goal is to attain proper calibration for each individual pixel classifier, the calibration set consists of individual images. In a scenario where data are scarce (such as the medical domain), it may not always be possible to set aside sufficiently many images for this pixel-level calibration. The method we propose, dubbed ``Kandinsky calibration'', makes use of the spatial structure present in the distribution of natural images to simultaneously calibrate the classifiers of ``similar'' pixels. This can be seen as an intermediate approach between marginal (imagewise) and conditional (pixelwise) calibration, where non-conformity scores are aggregated over similar image regions, thereby making more efficient use of the images available for calibration. We run experiments on segmentation algorithms trained and calibrated on subsets of the public MS-COCO and Medical Decathlon datasets, demonstrating that Kandinsky calibration method can significantly improve the coverage. When compared to both pixelwise and imagewise calibration on little data, the Kandinsky method achieves much lower coverage errors, indicating the data efficiency of the Kandinsky calibration.", "url": "https://arxiv.org/abs/2311.11837"}, {"metadata": {"arXiv": "2311.11974", "Date": "Mon, 20 Nov 2023 18:02:20 ", "Title": "Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting", "Authors": ["David Latortue", "Moetez Kdayem", "Fidel A Guerrero Pe\\~na", "Eric Granger", "Marco Pedersoli"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024"]}, "abstract": "Object detection models are commonly used for people counting (and localization) in many applications but require a dataset with costly bounding box annotations for training. Given the importance of privacy in people counting, these models rely more and more on infrared images, making the task even harder. In this paper, we explore how weaker levels of supervision can affect the performance of deep person counting architectures for image classification and point-level localization. Our experiments indicate that counting people using a CNN Image-Level model achieves competitive results with YOLO detectors and point-level models, yet provides a higher frame rate and a similar amount of model parameters.", "url": "https://arxiv.org/abs/2311.11974"}, {"metadata": {"arXiv": "2311.11980", "Date": "Mon, 20 Nov 2023 18:14:53 ", "Title": "Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces", "Authors": ["Pietro B. S. Masur and Willams Costa and Lucas S. Figueredo and Veronica Teichrieb"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "People naturally understand emotions, thus permitting a machine to do the same could open new paths for human-computer interaction. Facial expressions can be very useful for emotion recognition techniques, as these are the biggest transmitters of non-verbal cues capable of being correlated with emotions. Several techniques are based on Convolutional Neural Networks (CNNs) to extract information in a machine learning process. However, simple CNNs are not always sufficient to locate points of interest on the face that can be correlated with emotions. In this work, we intend to expand the capacity of emotion recognition techniques by proposing the usage of Facial Action Units (AUs) recognition techniques to recognize emotions. This recognition will be based on the Facial Action Coding System (FACS) and computed by a machine learning system. In particular, our method expands over EmotiRAM, an approach for multi-cue emotion recognition, in which we improve over their facial encoding module.", "url": "https://arxiv.org/abs/2311.11980"}, {"metadata": {"arXiv": "2311.11992", "Date": "Mon, 20 Nov 2023 18:23:41 ", "Title": "Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis", "Authors": ["Pietro B. S. Masur and Francisco Braulio Oliveira and Lucas Moreira Medino and Emanuel Huber and Milene Haraguchi Padilha and Cassio de Alcantara and Renata Sellaro"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Lip segmentation is crucial in computer vision, especially for lip reading. Despite extensive face segmentation research, lip segmentation has received limited attention. The aim of this study is to compare state-of-the-art lip segmentation models using a standardized setting and a publicly available dataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and STDC1, are qualitatively selected based on their reported performance, inference time, code availability, recency, and popularity. The CelebAMask-HQ dataset, comprising manually annotated face images, is used to fairly assess the lip segmentation performance of the selected models. Inference experiments are conducted on a Raspberry Pi4 to emulate limited computational resources. The results show that Mask2Former and EHANet have the best performances in terms of mIoU score. BiSeNet V2 demonstrate competitive performance, while PIDNet excels in recall but has lower precision. Most models present inference time ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with PIDNet having the lowest mean inference time. This study provides a comprehensive evaluation of lip segmentation models, highlighting their performance and inference times. The findings contribute to the development of lightweight techniques and establish benchmarks for future advances in lip segmentation, especially in IoT and edge computing scenarios.", "url": "https://arxiv.org/abs/2311.11992"}, {"metadata": {"arXiv": "2311.12028", "Date": "Mon, 20 Nov 2023 18:59:51 ", "Title": "Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation", "Authors": ["Wenhao Li", "Mengyuan Liu", "Hong Liu", "Pichao Wang", "Jialun Cai", "Nicu Sebe"], "Categories": "cs.CV cs.AI cs.LG"}, "abstract": "Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a plug-and-play pruning-and-recovering framework, called Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose estimation from videos. Our HoT begins with pruning pose tokens of redundant frames and ends with recovering full-length tokens, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. To effectively achieve this, we propose a token pruning cluster (TPC) that dynamically selects a few representative tokens with high semantic diversity while eliminating the redundancy of video frames. In addition, we develop a token recovering attention (TRA) to restore the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and MPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and estimation accuracy compared to the original VPT models. For instance, applying to MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs without sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop, respectively. Our source code will be open-sourced.", "url": "https://arxiv.org/abs/2311.12028"}, {"metadata": {"arXiv": "2311.10780", "Date": "Thu, 16 Nov 2023 11:01:39 ", "Title": "Extending Neural Network Verification to a Larger Family of Piece-wise Linear Activation Functions", "Authors": ["L\\'aszl\\'o Antal (RWTH Aachen University)", "Hana Masara (RWTH Aachen University)", "Erika \\'Abrah\\'am (RWTH Aachen University)"], "Categories": "cs.LG cs.AI cs.LO", "Comments": ["In Proceedings FMAS 2023", "arXiv:2311.08987"], "Journal-ref": "EPTCS 395, 2023, pp. 30-68", "DOI": "10.4204/EPTCS.395.4"}, "abstract": "In this paper, we extend an available neural network verification technique to support a wider class of piece-wise linear activation functions. Furthermore, we extend the algorithms, which provide in their original form exact respectively over-approximative results for bounded input sets represented as start sets, to allow also unbounded input set. We implemented our algorithms and demonstrated their effectiveness in some case studies.", "url": "https://arxiv.org/abs/2311.10780"}, {"metadata": {"arXiv": "2311.10792", "Date": "Fri, 17 Nov 2023 02:30:19 ", "Title": "Attention Mechanism for Lithium-Ion Battery Lifespan Prediction: Temporal and Cyclic Attention", "Authors": ["Jaewook Lee", "Seongmin Heo", "Jay H. Lee"], "Categories": "cs.LG cs.AI stat.AP"}, "abstract": "Accurately predicting the lifespan of lithium-ion batteries (LIBs) is pivotal for optimizing usage and preventing accidents. Previous studies in constructing prediction models often relied on inputs challenging to measure in real-time operations and failed to capture intra-cycle and inter-cycle data patterns, essential features for accurate predictions, comprehensively. In this study, we employ attention mechanisms (AM) to develop data-driven models for predicting LIB lifespan using easily measurable inputs such as voltage, current, temperature, and capacity data. The developed model integrates recurrent neural network (RNN) and convolutional neural network (CNN) components, featuring two types of attention mechanisms: temporal attention (TA) and cyclic attention (CA). The inclusion of TA aims to identify important time steps within each cycle by scoring the hidden states of the RNN, whereas CA strives to capture key features of inter-cycle correlations through self-attention (SA). This enhances model accuracy and elucidates critical features in the input data. To validate our method, we apply it to publicly available cycling data consisting of three batches of cycling modes. The calculated TA scores highlight the rest phase as a key characteristic distinguishing LIB data among different batches. Additionally, CA scores reveal variations in the importance of cycles across batches. By leveraging CA scores, we explore the potential to reduce the number of cycles in the input data. The single-head and multi-head attentions enable us to decrease the input dimension from 100 to 50 and 30 cycles, respectively.", "url": "https://arxiv.org/abs/2311.10792"}, {"metadata": {"arXiv": "2311.10798", "Date": "Fri, 17 Nov 2023 07:28:16 ", "Title": "INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and Prognosis", "Authors": ["Shih-Cheng Huang", "Zepeng Huo", "Ethan Steinberg", "Chia-Chun Chiang", "Matthew P. Lungren", "Curtis P. Langlotz", "Serena Yeung", "Nigam H. Shah", "Jason A. Fries"], "Categories": "cs.LG cs.AI"}, "abstract": "Synthesizing information from multiple data sources plays a crucial role in the practice of modern medicine. Current applications of artificial intelligence in medicine often focus on single-modality data due to a lack of publicly available, multimodal medical datasets. To address this limitation, we introduce INSPECT, which contains de-identified longitudinal records from a large cohort of patients at risk for pulmonary embolism (PE), along with ground truth labels for multiple outcomes. INSPECT contains data from 19,402 patients, including CT images, radiology report impression sections, and structured electronic health record (EHR) data (i.e. demographics, diagnoses, procedures, vitals, and medications). Using INSPECT, we develop and release a benchmark for evaluating several baseline modeling approaches on a variety of important PE related tasks. We evaluate image-only, EHR-only, and multimodal fusion models. Trained models and the de-identified dataset are made available for non-commercial use under a data use agreement. To the best of our knowledge, INSPECT is the largest multimodal dataset integrating 3D medical imaging and EHR for reproducible methods evaluation and research.", "url": "https://arxiv.org/abs/2311.10798"}, {"metadata": {"arXiv": "2311.10805", "Date": "Fri, 17 Nov 2023 13:54:02 ", "Title": "Towards a Standardized Reinforcement Learning Framework for AAM Contingency Management", "Authors": ["Luis E. Alvarez", "Marc W. Brittain", "Kara Breeden"], "Categories": "cs.LG cs.AI"}, "abstract": "Advanced Air Mobility (AAM) is the next generation of air transportation that includes new entrants such as electric vertical takeoff and landing (eVTOL) aircraft, increasingly autonomous flight operations, and small UAS package delivery. With these new vehicles and operational concepts comes a desire to increase densities far beyond what occurs today in and around urban areas, to utilize new battery technology, and to move toward more autonomously-piloted aircraft. To achieve these goals, it becomes essential to introduce new safety management system capabilities that can rapidly assess risk as it evolves across a span of complex hazards and, if necessary, mitigate risk by executing appropriate contingencies via supervised or automated decision-making during flights. Recently, reinforcement learning has shown promise for real-time decision making across a wide variety of applications including contingency management. In this work, we formulate the contingency management problem as a Markov Decision Process (MDP) and integrate the contingency management MDP into the AAM-Gym simulation framework. This enables rapid prototyping of reinforcement learning algorithms and evaluation of existing systems, thus providing a community benchmark for future algorithm development. We report baseline statistical information for the environment and provide example performance metrics.", "url": "https://arxiv.org/abs/2311.10805"}, {"metadata": {"arXiv": "2311.10806", "Date": "Fri, 17 Nov 2023 13:54:18 ", "Title": "SEA++: Multi-Graph-based High-Order Sensor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation", "Authors": ["Yucheng Wang", "Yuecong Xu", "Jianfei Yang", "Min Wu", "Xiaoli Li", "Lihua Xie", "Zhenghua Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Unsupervised Domain Adaptation (UDA) methods have been successful in reducing label dependency by minimizing the domain discrepancy between a labeled source domain and an unlabeled target domain. However, these methods face challenges when dealing with Multivariate Time-Series (MTS) data. MTS data typically consist of multiple sensors, each with its own unique distribution. This characteristic makes it hard to adapt existing UDA methods, which mainly focus on aligning global features while overlooking the distribution discrepancies at the sensor level, to reduce domain discrepancies for MTS data. To address this issue, a practical domain adaptation scenario is formulated as Multivariate Time-Series Unsupervised Domain Adaptation (MTS-UDA). In this paper, we propose SEnsor Alignment (SEA) for MTS-UDA, aiming to reduce domain discrepancy at both the local and global sensor levels. At the local sensor level, we design endo-feature alignment, which aligns sensor features and their correlations across domains. To reduce domain discrepancy at the global sensor level, we design exo-feature alignment that enforces restrictions on global sensor features. We further extend SEA to SEA++ by enhancing the endo-feature alignment. Particularly, we incorporate multi-graph-based high-order alignment for both sensor features and their correlations. Extensive empirical results have demonstrated the state-of-the-art performance of our SEA and SEA++ on public MTS datasets for MTS-UDA.", "url": "https://arxiv.org/abs/2311.10806"}, {"metadata": {"arXiv": "2311.10811", "Date": "Fri, 17 Nov 2023 18:35:13 ", "Title": "A novel post-hoc explanation comparison metric and applications", "Authors": ["Shreyan Mitra and Leilani Gilpin"], "Categories": "cs.LG cs.AI", "Comments": ["8 pages", "4 figures", "2 tables", "and 1 listing. arXiv admin note: substantial text overlap with arXiv:2304.08499"], "MSC-class": "I.2"}, "abstract": "Explanatory systems make the behavior of machine learning models more transparent, but are often inconsistent. To quantify the differences between explanatory systems, this paper presents the Shreyan Distance, a novel metric based on the weighted difference between ranked feature importance lists produced by such systems. This paper uses the Shreyan Distance to compare two explanatory systems, SHAP and LIME, for both regression and classification learning tasks. Because we find that the average Shreyan Distance varies significantly between these two tasks, we conclude that consistency between explainers not only depends on inherent properties of the explainers themselves, but also the type of learning task. This paper further contributes the XAISuite library, which integrates the Shreyan distance algorithm into machine learning pipelines.", "url": "https://arxiv.org/abs/2311.10811"}, {"metadata": {"arXiv": "2311.10832", "Date": "Fri, 17 Nov 2023 19:23:21 ", "Title": "Exploring Machine Learning Models for Federated Learning: A Review of Approaches, Performance, and Limitations", "Authors": ["Elaheh Jafarigol", "Theodore Trafalis", "Talayeh Razzaghi", "Mona Zamankhani"], "Categories": "cs.LG cs.AI"}, "abstract": "In the growing world of artificial intelligence, federated learning is a distributed learning framework enhanced to preserve the privacy of individuals' data. Federated learning lays the groundwork for collaborative research in areas where the data is sensitive. Federated learning has several implications for real-world problems. In times of crisis, when real-time decision-making is critical, federated learning allows multiple entities to work collectively without sharing sensitive data. This distributed approach enables us to leverage information from multiple sources and gain more diverse insights. This paper is a systematic review of the literature on privacy-preserving machine learning in the last few years based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Specifically, we have presented an extensive review of supervised/unsupervised machine learning algorithms, ensemble methods, meta-heuristic approaches, blockchain technology, and reinforcement learning used in the framework of federated learning, in addition to an overview of federated learning applications. This paper reviews the literature on the components of federated learning and its applications in the last few years. The main purpose of this work is to provide researchers and practitioners with a comprehensive overview of federated learning from the machine learning point of view. A discussion of some open problems and future research directions in federated learning is also provided.", "url": "https://arxiv.org/abs/2311.10832"}, {"metadata": {"arXiv": "2311.10921", "Date": "Sat, 18 Nov 2023 00:30:03 ", "Title": "Compact and Intuitive Airfoil Parameterization Method through Physics-aware Variational Autoencoder", "Authors": ["Yu-Eop Kang", "Dawoon Lee", "and Kwanjung Yee"], "Categories": "cs.LG cs.AI", "Comments": ["33 pages", "19 figures", "preprint for journal submission"]}, "abstract": "Airfoil shape optimization plays a critical role in the design of high-performance aircraft. However, the high-dimensional nature of airfoil representation causes the challenging problem known as the \"curse of dimensionality\". To overcome this problem, numerous airfoil parameterization methods have been developed, which can be broadly classified as polynomial-based and data-driven approaches. Each of these methods has desirable characteristics such as flexibility, parsimony, feasibility, and intuitiveness, but a single approach that encompasses all of these attributes has yet to be found. For example, polynomial-based methods struggle to balance parsimony and flexibility, while data-driven methods lack in feasibility and intuitiveness. In recent years, generative models, such as generative adversarial networks and variational autoencoders, have shown promising potential in airfoil parameterization. However, these models still face challenges related to intuitiveness due to their black-box nature. To address this issue, we developed a novel airfoil parameterization method using physics-aware variational autoencoder. The proposed method not only explicitly separates the generation of thickness and camber distributions to produce smooth and non-intersecting airfoils, thereby improving feasibility, but it also directly aligns its latent dimensions with geometric features of the airfoil, significantly enhancing intuitiveness. Finally, extensive comparative studies were performed to demonstrate the effectiveness of our approach.", "url": "https://arxiv.org/abs/2311.10921"}, {"metadata": {"arXiv": "2311.11083", "Date": "Sat, 18 Nov 2023 14:10:09 ", "Title": "ECLM: Efficient Edge-Cloud Collaborative Learning with Continuous Environment Adaptation", "Authors": ["Yan Zhuang", "Zhenzhe Zheng", "Yunfeng Shao", "Bingshuai Li", "Fan Wu", "Guihai Chen"], "Categories": "cs.LG cs.AI"}, "abstract": "Pervasive mobile AI applications primarily employ one of the two learning paradigms: cloud-based learning (with powerful large models) or on-device learning (with lightweight small models). Despite their own advantages, neither paradigm can effectively handle dynamic edge environments with frequent data distribution shifts and on-device resource fluctuations, inevitably suffering from performance degradation. In this paper, we propose ECLM, an edge-cloud collaborative learning framework for rapid model adaptation for dynamic edge environments. We first propose a novel block-level model decomposition design to decompose the original large cloud model into multiple combinable modules. By flexibly combining a subset of the modules, this design enables the derivation of compact, task-specific sub-models for heterogeneous edge devices from the large cloud model, and the seamless integration of new knowledge learned on these devices into the cloud model periodically. As such, ECLM ensures that the cloud model always provides up-to-date sub-models for edge devices. We further propose an end-to-end learning framework that incorporates the modular model design into an efficient model adaptation pipeline including an offline on-cloud model prototyping and training stage, and an online edge-cloud collaborative adaptation stage. Extensive experiments over various datasets demonstrate that ECLM significantly improves model performance (e.g., 18.89% accuracy increase) and resource efficiency (e.g., 7.12x communication cost reduction) in adapting models to dynamic edge environments by efficiently collaborating the edge and the cloud models.", "url": "https://arxiv.org/abs/2311.11083"}, {"metadata": {"arXiv": "2311.11091", "Date": "Sat, 18 Nov 2023 14:41:33 ", "Title": "Deep Tensor Network", "Authors": ["Yifan Zhang"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "In this paper, we delve into the foundational principles of tensor categories, harnessing the universal property of the tensor product to pioneer novel methodologies in deep network architectures. Our primary contribution is the introduction of the Tensor Attention and Tensor Interaction Mechanism, a groundbreaking approach that leverages the tensor category to enhance the computational efficiency and the expressiveness of deep networks, and can even be generalized into the quantum realm.", "url": "https://arxiv.org/abs/2311.11091"}, {"metadata": {"arXiv": "2311.11114", "Date": "Sat, 18 Nov 2023 16:31:10 ", "Title": "Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization", "Authors": ["Haonan Yuan", "Qingyun Sun", "Xingcheng Fu", "Ziwei Zhang", "Cheng Ji", "Hao Peng", "Jianxin Li"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"]}, "abstract": "Dynamic graph neural networks (DGNNs) are increasingly pervasive in exploiting spatio-temporal patterns on dynamic graphs. However, existing works fail to generalize under distribution shifts, which are common in real-world scenarios. As the generation of dynamic graphs is heavily influenced by latent environments, investigating their impacts on the out-of-distribution (OOD) generalization is critical. However, it remains unexplored with the following two major challenges: (1) How to properly model and infer the complex environments on dynamic graphs with distribution shifts? (2) How to discover invariant patterns given inferred spatio-temporal environments? To solve these challenges, we propose a novel Environment-Aware dynamic Graph LEarning (EAGLE) framework for OOD generalization by modeling complex coupled environments and exploiting spatio-temporal invariant patterns. Specifically, we first design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. Then, we propose an environment instantiation mechanism for environment diversification with inferred distributions. Finally, we discriminate spatio-temporal invariant patterns for out-of-distribution prediction by the invariant pattern recognition mechanism and perform fine-grained causal interventions node-wisely with a mixture of instantiated environment samples. Experiments on real-world and synthetic dynamic graph datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts. To the best of our knowledge, we are the first to study OOD generalization on dynamic graphs from the environment learning perspective.", "url": "https://arxiv.org/abs/2311.11114"}, {"metadata": {"arXiv": "2311.11126", "Date": "Sat, 18 Nov 2023 17:17:15 ", "Title": "Bayesian Neural Networks: A Min-Max Game Framework", "Authors": ["Junping Hong", "Ercan Engin Kuruoglu"], "Categories": "cs.LG cs.AI", "Comments": ["3 pages", "2 figures"]}, "abstract": "Bayesian neural networks use random variables to describe the neural networks rather than deterministic neural networks and are mostly trained by variational inference which updates the mean and variance at the same time. Here, we formulate the Bayesian neural networks as a minimax game problem. We do the experiments on the MNIST data set and the primary result is comparable to the existing closed-loop transcription neural network. Finally, we reveal the connections between Bayesian neural networks and closed-loop transcription neural networks, and show our framework is rather practical, and provide another view of Bayesian neural networks.", "url": "https://arxiv.org/abs/2311.11126"}, {"metadata": {"arXiv": "2311.11202", "Date": "Sun, 19 Nov 2023 02:34:12 ", "Title": "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models", "Authors": ["Zhaowei Zhu", "Jialu Wang", "Hao Cheng", "Yang Liu"], "Categories": "cs.LG cs.AI cs.CL cs.CY"}, "abstract": "Language models have shown promise in various tasks but can be affected by undesired data during training, fine-tuning, or alignment. For example, if some unsafe conversations are wrongly annotated as safe ones, the model fine-tuned on these samples may be harmful. Therefore, the correctness of annotations, i.e., the credibility of the dataset, is important. This study focuses on the credibility of real-world datasets, including the popular benchmarks Jigsaw Civil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that can be used for training a harmless language model. Given the cost and difficulty of cleaning these datasets by humans, we introduce a systematic framework for evaluating the credibility of datasets, identifying label errors, and evaluating the influence of noisy labels in the curated language data, specifically focusing on unsafe comments and conversation classification. With the framework, we find and fix an average of 6.16% label errors in 11 datasets constructed from the above benchmarks. The data credibility and downstream learning performance can be remarkably improved by directly fixing label errors, indicating the significance of cleaning existing real-world datasets. Open-source: https://github.com/Docta-ai/docta.", "url": "https://arxiv.org/abs/2311.11202"}, {"metadata": {"arXiv": "2311.11227", "Date": "Sun, 19 Nov 2023 04:43:16 ", "Title": "FedRA: A Random Allocation Strategy for Federated Tuning to Unleash the Power of Heterogeneous Clients", "Authors": ["Shangchao Su", "Bin Li", "Xiangyang Xue"], "Categories": "cs.LG cs.AI cs.DC"}, "abstract": "With the increasing availability of Foundation Models, federated tuning has garnered attention in the field of federated learning, utilizing data and computation resources from multiple clients to collaboratively fine-tune foundation models. However, in real-world federated scenarios, there often exist a multitude of heterogeneous clients with varying computation and communication resources, rendering them incapable of supporting the entire model fine-tuning process. In response to this challenge, we propose a novel federated tuning algorithm, FedRA. The implementation of FedRA is straightforward and can be seamlessly integrated into any transformer-based model without the need for further modification to the original model. Specifically, in each communication round, FedRA randomly generates an allocation matrix. For resource-constrained clients, it reorganizes a small number of layers from the original model based on the allocation matrix and fine-tunes using LoRA. Subsequently, the server aggregates the updated LoRA parameters from the clients according to the current allocation matrix into the corresponding layers of the original model. It is worth noting that FedRA also supports scenarios where none of the clients can support the entire global model, which is an impressive advantage. We conduct experiments on two large-scale image datasets, DomainNet and NICO++, under various non-iid settings. The results demonstrate that FedRA outperforms the compared methods significantly. The source code is available at \\url{https://github.com/leondada/FedRA}.", "url": "https://arxiv.org/abs/2311.11227"}, {"metadata": {"arXiv": "2311.11235", "Date": "Sun, 19 Nov 2023 05:37:18 ", "Title": "Unraveling the `Anomaly' in Time Series Anomaly Detection: A Self-supervised Tri-domain Solution", "Authors": ["Yuting Sun", "Guansong Pang", "Guanhua Ye", "Tong Chen", "Xia Hu", "Hongzhi Yin"], "Categories": "cs.LG cs.AI", "Comments": ["This work is submitted to IEEE International Conference on Data Engineering (ICDE) 2024"]}, "abstract": "The ongoing challenges in time series anomaly detection (TSAD), notably the scarcity of anomaly labels and the variability in anomaly lengths and shapes, have led to the need for a more efficient solution. As limited anomaly labels hinder traditional supervised models in TSAD, various SOTA deep learning techniques, such as self-supervised learning, have been introduced to tackle this issue. However, they encounter difficulties handling variations in anomaly lengths and shapes, limiting their adaptability to diverse anomalies. Additionally, many benchmark datasets suffer from the problem of having explicit anomalies that even random functions can detect. This problem is exacerbated by ill-posed evaluation metrics, known as point adjustment (PA), which can result in inflated model performance. In this context, we propose a novel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which addresses these challenges by modeling features across three data domains - temporal, frequency, and residual domains - without relying on anomaly labels. Unlike traditional contrastive learning methods, TriAD employs both inter-domain and intra-domain contrastive loss to learn common attributes among normal data and differentiate them from anomalies. Additionally, our approach can detect anomalies of varying lengths by integrating with a discord discovery algorithm. It is worth noting that this study is the first to reevaluate the deep learning potential in TSAD, utilizing both rigorously designed datasets (i.e., UCR Archive) and evaluation metrics (i.e., PA%K and affiliation). Through experimental results on the UCR dataset, TriAD achieves an impressive three-fold increase in PA%K based F1 scores over SOTA deep learning models, and 50% increase of accuracy as compared to SOTA discord discovery algorithms.", "url": "https://arxiv.org/abs/2311.11235"}, {"metadata": {"arXiv": "2311.11249", "Date": "Sun, 19 Nov 2023 06:28:43 ", "Title": "Open Set Dandelion Network for IoT Intrusion Detection", "Authors": ["Jiashu Wu", "Hao Dai", "Kenneth B. Kent", "Jerome Yen", "Chengzhong Xu", "Yang Wang"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "As IoT devices become widely, it is crucial to protect them from malicious intrusions. However, the data scarcity of IoT limits the applicability of traditional intrusion detection methods, which are highly data-dependent. To address this, in this paper we propose the Open-Set Dandelion Network (OSDN) based on unsupervised heterogeneous domain adaptation in an open-set manner. The OSDN model performs intrusion knowledge transfer from the knowledge-rich source network intrusion domain to facilitate more accurate intrusion detection for the data-scarce target IoT intrusion domain. Under the open-set setting, it can also detect newly-emerged target domain intrusions that are not observed in the source domain. To achieve this, the OSDN model forms the source domain into a dandelion-like feature space in which each intrusion category is compactly grouped and different intrusion categories are separated, i.e., simultaneously emphasising inter-category separability and intra-category compactness. The dandelion-based target membership mechanism then forms the target dandelion. Then, the dandelion angular separation mechanism achieves better inter-category separability, and the dandelion embedding alignment mechanism further aligns both dandelions in a finer manner. To promote intra-category compactness, the discriminating sampled dandelion mechanism is used. Assisted by the intrusion classifier trained using both known and generated unknown intrusion knowledge, a semantic dandelion correction mechanism emphasises easily-confused categories and guides better inter-category separability. Holistically, these mechanisms form the OSDN model that effectively performs intrusion knowledge transfer to benefit IoT intrusion detection. Comprehensive experiments on several intrusion datasets verify the effectiveness of the OSDN model, outperforming three state-of-the-art baseline methods by 16.9%.", "url": "https://arxiv.org/abs/2311.11249"}, {"metadata": {"arXiv": "2311.11420", "Date": "Sun, 19 Nov 2023 20:39:35 ", "Title": "LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded Computing Platforms", "Authors": ["Young D. Kwon", "Jagmohan Chauhan", "Hong Jia", "Stylianos I. Venieris", "and Cecilia Mascolo"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted for publication at SenSys 2023"]}, "abstract": "Continual Learning (CL) allows applications such as user personalization and household robots to learn on the fly and adapt to context. This is an important feature when context, actions, and users change. However, enabling CL on resource-constrained embedded systems is challenging due to the limited labeled data, memory, and computing capacity. In this paper, we propose LifeLearner, a hardware-aware meta continual learning system that drastically optimizes system resources (lower memory, latency, energy consumption) while ensuring high accuracy. Specifically, we (1) exploit meta-learning and rehearsal strategies to explicitly cope with data scarcity issues and ensure high accuracy, (2) effectively combine lossless and lossy compression to significantly reduce the resource requirements of CL and rehearsal samples, and (3) developed hardware-aware system on embedded and IoT platforms considering the hardware characteristics. As a result, LifeLearner achieves near-optimal CL performance, falling short by only 2.8% on accuracy compared to an Oracle baseline. With respect to the state-of-the-art (SOTA) Meta CL method, LifeLearner drastically reduces the memory footprint (by 178.7x), end-to-end latency by 80.8-94.2%, and energy consumption by 80.9-94.2%. In addition, we successfully deployed LifeLearner on two edge devices and a microcontroller unit, thereby enabling efficient CL on resource-constrained platforms where it would be impractical to run SOTA methods and the far-reaching deployment of adaptable CL in a ubiquitous manner. Code is available at https://github.com/theyoungkwon/LifeLearner.", "url": "https://arxiv.org/abs/2311.11420"}, {"metadata": {"arXiv": "2311.11473", "Date": "Mon, 20 Nov 2023 00:57:30 ", "Title": "CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection", "Authors": ["Yifan Li", "Zhen Tan", "Kai Shu", "Zongsheng Cao", "Yu Kong", "Huan Liu"], "Categories": "cs.LG cs.AI"}, "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for representation learning on graphs, but they often suffer from overfitting and label noise issues, especially when the data is scarce or imbalanced. Different from the paradigm of previous methods that rely on single-node confidence, in this paper, we introduce a novel Class-wise Selection for Graph Neural Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to adaptively select reliable nodes across different classes. Specifically, 1) to tackle the class imbalance issue, we introduce a dynamic class-wise selection mechanism, leveraging the clustering technique to identify clean nodes based on the neighbor-aggregated confidences. In this way, our approach can avoid the pitfalls of biased sampling which is common with global threshold techniques. 2) To alleviate the problem of noisy labels, built on the concept of the memorization effect, CSGNN prioritizes learning from clean nodes before noisy ones, thereby iteratively enhancing model performance while mitigating label noise. Through extensive experiments, we demonstrate that CSGNN outperforms state-of-the-art methods in terms of both effectiveness and robustness.", "url": "https://arxiv.org/abs/2311.11473"}, {"metadata": {"arXiv": "2311.11483", "Date": "Mon, 20 Nov 2023 01:58:27 ", "Title": "A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records", "Authors": ["Lin Lawrence Guo", "Jason Fries", "Ethan Steinberg", "Scott Lanyon Fleming", "Keith Morse", "Catherine Aftandilian", "Jose Posada", "Nigam Shah", "Lillian Sung"], "Categories": "cs.LG cs.AI", "Comments": ["41 pages", "3 figures", "2 tables", "16 appendices"]}, "abstract": "Foundation models hold promise for transforming AI in healthcare by providing modular components that are easily adaptable to downstream healthcare tasks, making AI development more scalable and cost-effective. Structured EHR foundation models, trained on coded medical records from millions of patients, demonstrated benefits including increased performance with fewer training labels, and improved robustness to distribution shifts. However, questions remain on the feasibility of sharing these models across different hospitals and their performance for local task adaptation. This multi-center study examined the adaptability of a recently released structured EHR foundation model ($FM_{SM}$), trained on longitudinal medical record data from 2.57M Stanford Medicine patients. Experiments were conducted using EHR data at The Hospital for Sick Children and MIMIC-IV. We assessed both adaptability via continued pretraining on local data, and task adaptability compared to baselines of training models from scratch at each site, including a local foundation model. We evaluated the performance of these models on 8 clinical prediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$ matched the performance of GBM models locally trained on all data while providing a 13% improvement in settings with few task-specific training labels. With continued pretraining on local data, label efficiency substantially improved, such that $FM_{SM}$ required fewer than 1% of training examples to match the fully trained GBM's performance. Continued pretraining was also 60 to 90% more sample-efficient than training local foundation models from scratch. Our findings show that adapting shared EHR foundation models across hospitals provides improved prediction performance at less cost, underscoring the utility of base foundation models as modular components to streamline the development of healthcare AI.", "url": "https://arxiv.org/abs/2311.11483"}, {"metadata": {"arXiv": "2311.11491", "Date": "Mon, 20 Nov 2023 02:31:08 ", "Title": "Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models", "Authors": ["Benjamin Leblanc and Pascal Germain"], "Categories": "cs.LG cs.AI"}, "abstract": "Interpretability has recently gained attention in the field of machine learning, for it is crucial when it comes to high-stakes decisions or troubleshooting. This abstract concept is hard to grasp and has been associated, over time, with many labels and preconceived ideas. In this position paper, in order to clarify some misunderstandings regarding interpretability, we discuss its relationship with significant concepts in machine learning: explainability, predictive performances, and machine learning models. For instance, we challenge the idea that interpretability and explainability are substitutes to one another, or that a fixed degree of interpretability can be associated with a given machine learning model.", "url": "https://arxiv.org/abs/2311.11491"}, {"metadata": {"arXiv": "2311.11501", "Date": "Mon, 20 Nov 2023 02:59:18 ", "Title": "MultiLoRA: Democratizing LoRA for Better Multi-Task Learning", "Authors": ["Yiming Wang", "Yu Lin", "Xiaodong Zeng and Guannan Zhang"], "Categories": "cs.LG cs.AI"}, "abstract": "LoRA achieves remarkable resource efficiency and comparable performance when adapting LLMs for specific tasks. Since ChatGPT demonstrated superior performance on various tasks, there has been a growing desire to adapt one model for all tasks. However, the explicit low-rank of LoRA limits the adaptation performance in complex multi-task scenarios. LoRA is dominated by a small number of top singular vectors while fine-tuning decomposes into a set of less important unitary transforms. In this paper, we propose MultiLoRA for better multi-task adaptation by reducing the dominance of top singular vectors observed in LoRA. MultiLoRA scales LoRA modules horizontally and change parameter initialization of adaptation matrices to reduce parameter dependency, thus yields more balanced unitary subspaces. We unprecedentedly construct specialized training data by mixing datasets of instruction follow, natural language understanding, world knowledge, to cover semantically and syntactically different samples. With only 2.5% of additional parameters, MultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple benchmarks and model scales. Further investigation into weight update matrices of MultiLoRA exhibits reduced dependency on top singular vectors and more democratic unitary transform contributions.", "url": "https://arxiv.org/abs/2311.11501"}, {"metadata": {"arXiv": "2311.11532", "Date": "Mon, 20 Nov 2023 04:34:19 ", "Title": "Optimal Hyperparameter $\\epsilon$ for Adaptive Stochastic Optimizers through Gradient Histograms", "Authors": ["Gustavo Silva", "Paul Rodriguez"], "Categories": "cs.LG cs.AI"}, "abstract": "Optimizers are essential components for successfully training deep neural network models. In order to achieve the best performance from such models, designers need to carefully choose the optimizer hyperparameters. However, this can be a computationally expensive and time-consuming process. Although it is known that all optimizer hyperparameters must be tuned for maximum performance, there is still a lack of clarity regarding the individual influence of minor priority hyperparameters, including the safeguard factor $\\epsilon$ and momentum factor $\\beta$, in leading adaptive optimizers (specifically, those based on the Adam optimizers). In this manuscript, we introduce a new framework based on gradient histograms to analyze and justify important attributes of adaptive optimizers, such as their optimal performance and the relationships and dependencies among hyperparameters. Furthermore, we propose a novel gradient histogram-based algorithm that automatically estimates a reduced and accurate search space for the safeguard hyperparameter $\\epsilon$, where the optimal value can be easily found.", "url": "https://arxiv.org/abs/2311.11532"}, {"metadata": {"arXiv": "2311.11557", "Date": "Mon, 20 Nov 2023 06:21:52 ", "Title": "Replay-enhanced Continual Reinforcement Learning", "Authors": ["Tiantian Zhang", "Kevin Zehua Shen", "Zichuan Lin", "Bo Yuan", "Xueqian Wang", "Xiu Li", "Deheng Ye"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted by Transactions on Machine Learning Research 2023"]}, "abstract": "Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods.", "url": "https://arxiv.org/abs/2311.11557"}, {"metadata": {"arXiv": "2311.11626", "Date": "Mon, 20 Nov 2023 09:20:26 ", "Title": "A novel transformer-based approach for soil temperature prediction", "Authors": ["Muhammet Mucahit Enes Yurtsever", "Ayhan Kucukmanisa and Zeynep Hilal Kilimci"], "Categories": "cs.LG cs.AI cs.CE physics.ao-ph"}, "abstract": "Soil temperature is one of the most significant parameters that plays a crucial role in glacier energy, dynamics of mass balance, processes of surface hydrological, coaction of glacier-atmosphere, nutrient cycling, ecological stability, the management of soil, water, and field crop. In this work, we introduce a novel approach using transformer models for the purpose of forecasting soil temperature prediction. To the best of our knowledge, the usage of transformer models in this work is the very first attempt to predict soil temperature. Experiments are carried out using six different FLUXNET stations by modeling them with five different transformer models, namely, Vanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To demonstrate the effectiveness of the proposed model, experiment results are compared with both deep learning approaches and literature studies. Experiment results show that the utilization of transformer models ensures a significant contribution to the literature, thence determining the new state-of- the-art.", "url": "https://arxiv.org/abs/2311.11626"}, {"metadata": {"arXiv": "2311.11717", "Date": "Mon, 20 Nov 2023 12:35:11 ", "Title": "Can we infer the presence of Differential Privacy in Deep Learning models' weights? Towards more secure Deep Learning", "Authors": ["Jim\\'enez-L\\'opez", "Daniel and Rodr\\'iguez-Barroso", "Nuria and Luz\\'on", "M. Victoria and Herrera", "Francisco"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Differential Privacy (DP) is a key property to protect data and models from integrity attacks. In the Deep Learning (DL) field, it is commonly implemented through the Differentially Private Stochastic Gradient Descent (DP-SGD). However, when a model is shared or released, there is no way to check whether it is differentially private, that is, it required to trust the model provider. This situation poses a problem when data privacy is mandatory, specially with current data regulations, as the presence of DP can not be certificated consistently by any third party. Thus, we face the challenge of determining whether a DL model has been trained with DP, according to the title question: Can we infer the presence of Differential Privacy in Deep Learning models' weights? Since the DP-SGD significantly changes the training process of a DL model, we hypothesize that DP leaves an imprint in the weights of a DL model, which can be used to predict whether a model has been trained with DP regardless of its architecture and the training dataset. In this paper, we propose to employ the imprint in model weights of using DP to infer the presence of DP training in a DL model. To substantiate our hypothesis, we developed an experimental methodology based on two datasets of weights of DL models, each with models with and without DP training and a meta-classifier to infer whether DP was used in the training process of a DL model, by accessing its weights. We accomplish both, the removal of the requirement of a trusted model provider and a strong foundation for this interesting line of research. Thus, our contribution is an additional layer of security on top of the strict private requirements of DP training in DL models, towards to DL models.", "url": "https://arxiv.org/abs/2311.11717"}, {"metadata": {"arXiv": "2311.11759", "Date": "Mon, 20 Nov 2023 13:39:19 ", "Title": "Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs", "Authors": ["Yong-Min Shin", "Won-Yong Shin"], "Categories": "cs.LG cs.AI cs.IT cs.NE cs.SI math.IT", "Comments": ["35 pages", "5 figures", "8 tables"]}, "abstract": "Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semi-supervised node classification on graphs, by training a student MLP by knowledge distillation (KD) from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during KD, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\\Pi$. Although this can be achieved by applying the inverse propagation $\\Pi^{-1}$ before distillation from the teacher GNN, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing further performance boost of the student MLP.", "url": "https://arxiv.org/abs/2311.11759"}, {"metadata": {"arXiv": "2311.11862", "Date": "Mon, 20 Nov 2023 15:57:49 ", "Title": "Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning", "Authors": ["Xiaoping Zheng", "Claudine JC Lamoth", "Hans Timmerman", "Ebert Otten", "Michiel F Reneman"], "Categories": "cs.LG cs.AI q-bio.NC", "Comments": ["31 pages", "5 tables", "3 figures"]}, "abstract": "Human Assumed Central Sensitization is involved in the development and maintenance of chronic low back pain (CLBP). The Central Sensitization Inventory (CSI) was developed to evaluate the presence of HACS, with a cut-off value of 40/100 based on patients with chronic pain. However, various factors including pain conditions (e.g., CLBP), and gender may influence this cut-off value. For chronic pain condition such as CLBP, unsupervised clustering approaches can take these factors into consideration and automatically learn the HACS-related patterns. Therefore, this study aimed to determine the cut-off values for a Dutch-speaking population with CLBP, considering the total group and stratified by gender based on unsupervised machine learning. In this study, questionnaire data covering pain, physical, and psychological aspects were collected from patients with CLBP and aged-matched pain-free adults (referred to as healthy controls, HC). Four clustering approaches were applied to identify HACS-related clusters based on the questionnaire data and gender. The clustering performance was assessed using internal and external indicators. Subsequently, receiver operating characteristic analysis was conducted on the best clustering results to determine the optimal cut-off values. The study included 151 subjects, consisting of 63 HCs and 88 patients with CLBP. Hierarchical clustering yielded the best results, identifying three clusters: healthy group, CLBP with low HACS level, and CLBP with high HACS level groups. Based on the low HACS levels group (including HC and CLBP with low HACS level) and high HACS level group, the cut-off value for the overall groups were 35, 34 for females, and 35 for. The findings suggest that the optimal cut-off values for CLBP is 35. The gender-related cut-off values should be interpreted with caution due to the unbalanced gender distribution in the sample.", "url": "https://arxiv.org/abs/2311.11862"}, {"metadata": {"arXiv": "2311.11908", "Date": "Mon, 20 Nov 2023 16:40:29 ", "Title": "Continual Learning: Applications and the Road Forward", "Authors": ["Eli Verwimp", "Shai Ben-David", "Matthias Bethge", "Andrea Cossu", "Alexander Gepperth", "Tyler L. Hayes", "Eyke H\\\"ullermeier", "Christopher Kanan", "Dhireesha Kudithipudi", "Christoph H. Lampert", "Martin Mundt", "Razvan Pascanu", "Adrian Popescu", "Andreas S. Tolias", "Joost van de Weijer", "Bing Liu", "Vincenzo Lomonaco", "Tinne Tuytelaars", "Gido M. van de Ven"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Continual learning is a sub-field of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: \"Why should one care about continual learning in the first place?\". We set the stage by surveying recent continual learning papers published at three major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model-editing, personalization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.", "url": "https://arxiv.org/abs/2311.11908"}, {"metadata": {"arXiv": "2311.11932", "Date": "Mon, 20 Nov 2023 17:17:29 ", "Title": "Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance", "Authors": ["Muta Tah Hira", "Mohammad A. Razzaque", "and Mosharraf Sarker"], "Categories": "cs.LG cs.AI"}, "abstract": "Background and objectives: By extracting this information, Machine or Deep Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and cancer researchers in discovering patterns and relationships from complex data sets. Many DL-based analyses on ovarian cancer (OC) data have recently been published. These analyses are highly diverse in various aspects of cancer (e.g., subdomain(s) and cancer type they address) and data analysis features. However, a comprehensive understanding of these analyses in terms of these features and AI assurance (AIA) is currently lacking. This systematic review aims to fill this gap by examining the existing literature and identifying important aspects of OC data analysis using DL, explicitly focusing on the key features and AI assurance perspectives. Methods: The PRISMA framework was used to conduct comprehensive searches in three journal databases. Only studies published between 2015 and 2023 in peer-reviewed journals were included in the analysis. Results: In the review, a total of 96 DL-driven analyses were examined. The findings reveal several important insights regarding DL-driven ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on detection and diagnosis, while no study addressed the prediction and prevention of OC. - The analyses were predominantly based on samples from a non-diverse population (75% (72/96 studies)), limited to a geographic location or country. - Only a small proportion of studies (only 33% (32/96)) performed integrated analyses, most of which used homogeneous data (clinical or omics). - Notably, a mere 8.3% (8/96) of the studies validated their models using external and diverse data sets, highlighting the need for enhanced model validation, and - The inclusion of AIA in cancer data analysis is in a very early stage; only 2.1% (2/96) explicitly addressed AIA through explainability.", "url": "https://arxiv.org/abs/2311.11932"}, {"metadata": {"arXiv": "2311.11959", "Date": "Mon, 20 Nov 2023 17:35:44 ", "Title": "Correlated Attention in Transformers for Multivariate Time Series", "Authors": ["Quang Minh Nguyen", "Lam M. Nguyen", "Subhro Das"], "Categories": "cs.LG cs.AI"}, "abstract": "Multivariate time series (MTS) analysis prevails in real-world applications such as finance, climate science and healthcare. The various self-attention mechanisms, the backbone of the state-of-the-art Transformer-based models, efficiently discover the temporal dependencies, yet cannot well capture the intricate cross-correlation between different features of MTS data, which inherently stems from complex dynamical systems in practice. To this end, we propose a novel correlated attention mechanism, which not only efficiently captures feature-wise dependencies, but can also be seamlessly integrated within the encoder blocks of existing well-known Transformers to gain efficiency improvement. In particular, correlated attention operates across feature channels to compute cross-covariance matrices between queries and keys with different lag values, and selectively aggregate representations at the sub-series level. This architecture facilitates automated discovery and representation learning of not only instantaneous but also lagged cross-correlations, while inherently capturing time series auto-correlation. When combined with prevalent Transformer baselines, correlated attention mechanism constitutes a better alternative for encoder-only architectures, which are suitable for a wide range of tasks including imputation, anomaly detection and classification. Extensive experiments on the aforementioned tasks consistently underscore the advantages of correlated attention mechanism in enhancing base Transformer models, and demonstrate our state-of-the-art results in imputation, anomaly detection and classification.", "url": "https://arxiv.org/abs/2311.11959"}, {"metadata": {"arXiv": "2311.11961", "Date": "Mon, 20 Nov 2023 17:38:35 ", "Title": "NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation", "Authors": ["Hao Dong", "Ga\\\"etan Frusque", "Yue Zhao", "Eleni Chatzi", "Olga Fink"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Anomaly detection (AD) is essential in identifying rare and often critical events in complex systems, finding applications in fields such as network intrusion detection, financial fraud detection, and fault detection in infrastructure and industrial systems. While AD is typically treated as an unsupervised learning task due to the high cost of label annotation, it is more practical to assume access to a small set of labeled anomaly samples from domain experts, as is the case for semi-supervised anomaly detection. Semi-supervised and supervised approaches can leverage such labeled data, resulting in improved performance. In this paper, rather than proposing a new semi-supervised or supervised approach for AD, we introduce a novel algorithm for generating additional pseudo-anomalies on the basis of the limited labeled anomalies and a large volume of unlabeled data. This serves as an augmentation to facilitate the detection of new anomalies. Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies. We compare the performance of this novel algorithm with commonly applied augmentation techniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various existing semi-supervised and supervised anomaly detection algorithms on the original training data along with the generated pseudo-anomalies. Through extensive experiments on 57 benchmark datasets in ADBench, reflecting different data types, we demonstrate that NNG-Mix outperforms other data augmentation methods. It yields significant performance improvements compared to the baselines trained exclusively on the original training data. Notably, NNG-Mix yields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP datasets in ADBench. Our source code will be available at https://github.com/donghao51/NNG-Mix.", "url": "https://arxiv.org/abs/2311.11961"}, {"metadata": {"arXiv": "2311.11995", "Date": "Mon, 20 Nov 2023 18:26:01 ", "Title": "BrainWash: A Poisoning Attack to Forget in Continual Learning", "Authors": ["Ali Abbasi", "Parsa Nooralinejad", "Hamed Pirsiavash", "Soheil Kolouri"], "Categories": "cs.LG cs.AI cs.CR"}, "abstract": "Continual learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods.", "url": "https://arxiv.org/abs/2311.11995"}, {"metadata": {"arXiv": "2311.10747", "Date": "Tue, 31 Oct 2023 18:21:24 ", "Title": "Safety-aware Causal Representation for Trustworthy Reinforcement Learning in Autonomous Driving", "Authors": ["Haohong Lin", "Wenhao Ding", "Zuxin Liu", "Yaru Niu", "Jiacheng Zhu", "Yuming Niu", "Ding Zhao"], "Categories": "cs.RO cs.AI cs.LG"}, "abstract": "In the domain of autonomous driving, the Learning from Demonstration (LfD) paradigm has exhibited notable efficacy in addressing sequential decision-making problems. However, consistently achieving safety in varying traffic contexts, especially in safety-critical scenarios, poses a significant challenge due to the long-tailed and unforeseen scenarios absent from offline datasets. In this paper, we introduce the saFety-aware strUctured Scenario representatION (FUSION), a pioneering methodology conceived to facilitate the learning of an adaptive end-to-end driving policy by leveraging structured scenario information. FUSION capitalizes on the causal relationships between decomposed reward, cost, state, and action space, constructing a framework for structured sequential reasoning under dynamic traffic environments. We conduct rigorous evaluations in two typical real-world settings of distribution shift in autonomous vehicles, demonstrating the good balance between safety cost and utility reward of FUSION compared to contemporary state-of-the-art safety-aware LfD baselines. Empirical evidence under diverse driving scenarios attests that FUSION significantly enhances the safety and generalizability of autonomous driving agents, even in the face of challenging and unseen environments. Furthermore, our ablation studies reveal noticeable improvements in the integration of causal representation into the safe offline RL problem.", "url": "https://arxiv.org/abs/2311.10747"}, {"metadata": {"arXiv": "2311.10863", "Date": "Fri, 17 Nov 2023 20:51:24 ", "Title": "Verified Compositional Neuro-Symbolic Control for Stochastic Systems with Temporal Logic Tasks", "Authors": ["Jun Wang", "Kaiyuan Tan", "Zihe Sun", "Yiannis Kantaros"], "Categories": "cs.RO cs.AI cs.LG", "Comments": ["arXiv admin note: substantial text overlap with arXiv:2209.06130"]}, "abstract": "Several methods have been proposed recently to learn neural network (NN) controllers for autonomous agents, with unknown and stochastic dynamics, tasked with complex missions captured by Linear Temporal Logic (LTL). Due to the sample-inefficiency of the majority of these works, compositional learning methods have been proposed decomposing the LTL specification into smaller sub-tasks. Then, separate controllers are learned and composed to satisfy the original task. A key challenge within these approaches is that they often lack safety guarantees or the provided guarantees are impractical. This paper aims to address this challenge. Particularly, we consider autonomous systems with unknown and stochastic dynamics and LTL-encoded tasks. We assume that the system is equipped with a finite set of base skills modeled by trained NN feedback controllers. Our goal is to check if there exists a temporal composition of the trained NN controllers - and if so, to compute it - that will yield a composite system behavior that satisfies the assigned LTL task with probability one. We propose a new approach that relies on a novel integration of automata theory and data-driven reachability analysis tools for NN-controlled stochastic systems. The resulting neuro-symbolic controller allows the agent to generate safe behaviors for unseen complex temporal logic tasks in a zero-shot fashion by leveraging its base skills. We show correctness of the proposed method and we provide conditions under which it is complete. To the best of our knowledge, this is the first work that designs verified temporal compositions of NN controllers for unknown and stochastic systems. Finally, we provide extensive numerical simulations and hardware experiments on robot navigation tasks to demonstrate the proposed method.", "url": "https://arxiv.org/abs/2311.10863"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>

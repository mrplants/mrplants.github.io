<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #papers {
            width: 50%;
            margin: auto;
        }
        .paper {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }
        .dropdown {
            cursor: pointer;
            font-weight: bold;
            color: #0056b3;
            text-decoration: underline;
        }
        .dropdown:hover {
            color: #007bff;
        }
        .abstract, .link {
            display: none;
            margin-left: 20px;
            margin-top: 10px;
        }
        .link a {
            color: #0056b3;
        }
        .link a:hover {
            color: #007bff;
        }
        .footer {
            text-align: center;
            padding: 10px;
            margin-top: 20px;
            font-size: 0.8em;
            color: #999;
        }
    </style>
</head>
<body>
    <div id="papers"></div>

    <div class="footer">Thank you to arXiv for use of its open access interoperability.</div>

    <script>
        var papers = [{"metadata": {"arXiv": "2306.15789", "Date": "Tue, 27 Jun 2023 20:38:09 ", "Title": "Structured State Space Models for Multiple Instance Learning in Digital Pathology", "Authors": ["Leo Fillioux", "Joseph Boyd", "Maria Vakalopoulou", "Paul-Henry Courn\\`ede", "Stergios Christodoulidis"], "Categories": "cs.CV cs.LG"}, "abstract": "Multiple instance learning is an ideal mode of analysis for histopathology data, where vast whole slide images are typically annotated with a single global label. In such cases, a whole slide image is modelled as a collection of tissue patches to be aggregated and classified. Common models for performing this classification include recurrent neural networks and transformers. Although powerful compression algorithms, such as deep pre-trained neural networks, are used to reduce the dimensionality of each patch, the sequences arising from whole slide images remain excessively long, routinely containing tens of thousands of patches. Structured state space models are an emerging alternative for sequence modelling, specifically designed for the efficient modelling of long sequences. These models invoke an optimal projection of an input sequence into memory units that compress the entire sequence. In this paper, we propose the use of state space models as a multiple instance learner to a variety of problems in digital pathology. Across experiments in metastasis detection, cancer subtyping, mutation classification, and multitask learning, we demonstrate the competitiveness of this new class of models with existing state of the art approaches. Our code is available at https://github.com/MICS-Lab/s4_digital_pathology.", "url": "https://arxiv.org/abs/2306.15789"}, {"metadata": {"arXiv": "2306.15853", "Date": "Wed, 28 Jun 2023 01:00:36 ", "Title": "GoalieNet: A Multi-Stage Network for Joint Goalie, Equipment, and Net Pose Estimation in Ice Hockey", "Authors": ["Marjan Shahi", "David Clausi", "Alexander Wong"], "Categories": "cs.CV cs.LG"}, "abstract": "In the field of computer vision-driven ice hockey analytics, one of the most challenging and least studied tasks is goalie pose estimation. Unlike general human pose estimation, goalie pose estimation is much more complex as it involves not only the detection of keypoints corresponding to the joints of the goalie concealed under thick padding and mask, but also a large number of non-human keypoints corresponding to the large leg pads and gloves worn, the stick, as well as the hockey net. To tackle this challenge, we introduce GoalieNet, a multi-stage deep neural network for jointly estimating the pose of the goalie, their equipment, and the net. Experimental results using NHL benchmark data demonstrate that the proposed GoalieNet can achieve an average of 84\\% accuracy across all keypoints, where 22 out of 29 keypoints are detected with more than 80\\% accuracy. This indicates that such a joint pose estimation approach can be a promising research direction.", "url": "https://arxiv.org/abs/2306.15853"}, {"metadata": {"arXiv": "2306.15932", "Date": "Wed, 28 Jun 2023 05:33:11 ", "Title": "NIPD: A Federated Learning Person Detection Benchmark Based on Real-World Non-IID Data", "Authors": ["Kangning Yin", "Zhen Ding", "Zhihua Dong", "Dongsheng Chen", "Jie Fu", "Xinhui Ji", "Guangqiang Yin and Zhiguo Wang"], "Categories": "cs.CV cs.LG", "Comments": ["8 pages", "5 figures", "3 tables", "FL-IJCAI 23 conference"]}, "abstract": "Federated learning (FL), a privacy-preserving distributed machine learning, has been rapidly applied in wireless communication networks. FL enables Internet of Things (IoT) clients to obtain well-trained models while preventing privacy leakage. Person detection can be deployed on edge devices with limited computing power if combined with FL to process the video data directly at the edge. However, due to the different hardware and deployment scenarios of different cameras, the data collected by the camera present non-independent and identically distributed (non-IID), and the global model derived from FL aggregation is less effective. Meanwhile, existing research lacks public data set for real-world FL object detection, which is not conducive to studying the non-IID problem on IoT cameras. Therefore, we open source a non-IID IoT person detection (NIPD) data set, which is collected from five different cameras. To our knowledge, this is the first true device-based non-IID person detection data set. Based on this data set, we explain how to establish a FL experimental platform and provide a benchmark for non-IID person detection. NIPD is expected to promote the application of FL and the security of smart city.", "url": "https://arxiv.org/abs/2306.15932"}, {"metadata": {"arXiv": "2306.16050", "Date": "Wed, 28 Jun 2023 09:30:59 ", "Title": "Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack", "Authors": ["Jie Ning", "Yao Li", "Zhichang Guo"], "Categories": "cs.CV cs.LG eess.IV", "Comments": ["12 pages", "15 figures"]}, "abstract": "Deep neural networks (DNNs) have a wide range of applications in the field of image denoising, and they are superior to traditional image denoising. However, DNNs inevitably show vulnerability, which is the weak robustness in the face of adversarial attacks. In this paper, we find some similitudes between existing deep image denoising methods, as they are consistently fooled by adversarial attacks. First, denoising-PGD is proposed which is a denoising model full adversarial method. The current mainstream non-blind denoising models (DnCNN, FFDNet, ECNDNet, BRDNet), blind denoising models (DnCNN-B, Noise2Noise, RDDCNN-B, FAN), and plug-and-play (DPIR, CurvPnP) and unfolding denoising models (DeamNet) applied to grayscale and color images can be attacked by the same set of methods. Second, since the transferability of denoising-PGD is prominent in the image denoising task, we design experiments to explore the characteristic of the latent under the transferability. We correlate transferability with similitude and conclude that the deep image denoising models have high similitude. Third, we investigate the characteristic of the adversarial space and use adversarial training to complement the vulnerability of deep image denoising to adversarial attacks on image denoising. Finally, we constrain this adversarial attack method and propose the L2-denoising-PGD image denoising adversarial attack method that maintains the Gaussian distribution. Moreover, the model-driven image denoising BM3D shows some resistance in the face of adversarial attacks.", "url": "https://arxiv.org/abs/2306.16050"}, {"metadata": {"arXiv": "2306.16122", "Date": "Wed, 28 Jun 2023 11:47:08 ", "Title": "Semantic Positive Pairs for Enhancing Contrastive Instance Discrimination", "Authors": ["Mohammad Alkhalefi", "Georgios Leontidis", "Mingjun Zhong"], "Categories": "cs.CV cs.LG", "Comments": ["12 pages", "7 figures"]}, "abstract": "Self-supervised learning algorithms based on instance discrimination effectively prevent representation collapse and produce promising results in representation learning. However, the process of attracting positive pairs (i.e., two views of the same instance) in the embedding space and repelling all other instances (i.e., negative pairs) irrespective of their categories could result in discarding important features. To address this issue, we propose an approach to identifying those images with similar semantic content and treating them as positive instances, named semantic positive pairs set (SPPS), thereby reducing the risk of discarding important features during representation learning. Our approach could work with any contrastive instance discrimination framework such as SimCLR or MOCO. We conduct experiments on three datasets: ImageNet, STL-10 and CIFAR-10 to evaluate our approach. The experimental results show that our approach consistently outperforms the baseline method vanilla SimCLR across all three datasets; for example, our approach improves upon vanilla SimCLR under linear evaluation protocol by 4.18% on ImageNet with a batch size 1024 and 800 epochs.", "url": "https://arxiv.org/abs/2306.16122"}, {"metadata": {"arXiv": "2306.15731", "Date": "Tue, 27 Jun 2023 18:15:41 ", "Title": "Stochastic Gradient Bayesian Optimal Experimental Designs for Simulation-based Inference", "Authors": ["Vincent D. Zaballa and Elliot E. Hui"], "Categories": "cs.LG q-bio.QM stat.ME", "Comments": ["Presented at ICML 2023 workshop on Differentiable Everything"]}, "abstract": "Simulation-based inference (SBI) methods tackle complex scientific models with challenging inverse problems. However, SBI models often face a significant hurdle due to their non-differentiable nature, which hampers the use of gradient-based optimization techniques. Bayesian Optimal Experimental Design (BOED) is a powerful approach that aims to make the most efficient use of experimental resources for improved inferences. While stochastic gradient BOED methods have shown promising results in high-dimensional design problems, they have mostly neglected the integration of BOED with SBI due to the difficult non-differentiable property of many SBI simulators. In this work, we establish a crucial connection between ratio-based SBI inference algorithms and stochastic gradient-based variational inference by leveraging mutual information bounds. This connection allows us to extend BOED to SBI applications, enabling the simultaneous optimization of experimental designs and amortized inference functions. We demonstrate our approach on a simple linear model and offer implementation details for practitioners.", "url": "https://arxiv.org/abs/2306.15731"}, {"metadata": {"arXiv": "2306.15744", "Date": "Tue, 27 Jun 2023 18:54:40 ", "Title": "Ticketed Learning-Unlearning Schemes", "Authors": ["Badih Ghazi", "Pritish Kamath", "Ravi Kumar", "Pasin Manurangsi", "Ayush Sekhari", "Chiyuan Zhang"], "Categories": "cs.LG cs.DS stat.ML", "Comments": ["Conference on Learning Theory (COLT) 2023"]}, "abstract": "We consider the learning--unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples. We propose a new ticketed model for learning--unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) ``ticket'' to each participating training example, in addition to retaining a small amount of ``central'' information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning--unlearning schemes for a broad family of concept classes, including thresholds, parities, intersection-closed classes, among others. En route, we introduce the count-to-zero problem, where during unlearning, the goal is to simply know if there are any examples that survived. We give a ticketed learning--unlearning scheme for this problem that relies on the construction of Sperner families with certain properties, which might be of independent interest.", "url": "https://arxiv.org/abs/2306.15744"}, {"metadata": {"arXiv": "2306.15764", "Date": "Tue, 27 Jun 2023 19:28:41 ", "Title": "High Fidelity Image Counterfactuals with Probabilistic Causal Models", "Authors": ["Fabio De Sousa Ribeiro", "Tian Xia", "Miguel Monteiro", "Nick Pawlowski", "Ben Glocker"], "Categories": "cs.LG stat.ME", "Comments": ["ICML2023 publication"]}, "abstract": "We present a general causal generative modelling framework for accurate estimation of high fidelity image counterfactuals with deep structural causal models. Estimation of interventional and counterfactual queries for high-dimensional structured variables, such as images, remains a challenging task. We leverage ideas from causal mediation analysis and advances in generative modelling to design new deep causal mechanisms for structured variables in causal models. Our experiments demonstrate that our proposed mechanisms are capable of accurate abduction and estimation of direct, indirect and total effects as measured by axiomatic soundness of counterfactuals.", "url": "https://arxiv.org/abs/2306.15764"}, {"metadata": {"arXiv": "2306.15769", "Date": "Tue, 27 Jun 2023 19:34:53 ", "Title": "What Makes ImageNet Look Unlike LAION", "Authors": ["Ali Shirali", "Moritz Hardt"], "Categories": "cs.LG cs.CV"}, "abstract": "ImageNet was famously created from Flickr image search results. What if we recreated ImageNet instead by searching the massive LAION dataset based on image captions alone? In this work, we carry out this counterfactual investigation. We find that the resulting ImageNet recreation, which we call LAIONet, looks distinctly unlike the original. Specifically, the intra-class similarity of images in the original ImageNet is dramatically higher than it is for LAIONet. Consequently, models trained on ImageNet perform significantly worse on LAIONet. We propose a rigorous explanation for the discrepancy in terms of a subtle, yet important, difference in two plausible causal data-generating processes for the respective datasets, that we support with systematic experimentation. In a nutshell, searching based on an image caption alone creates an information bottleneck that mitigates the selection bias otherwise present in image-based filtering. Our explanation formalizes a long-held intuition in the community that ImageNet images are stereotypical, unnatural, and overly simple representations of the class category. At the same time, it provides a simple and actionable takeaway for future dataset creation efforts.", "url": "https://arxiv.org/abs/2306.15769"}, {"metadata": {"arXiv": "2306.15790", "Date": "Tue, 27 Jun 2023 20:39:07 ", "Title": "Probing the Transition to Dataset-Level Privacy in ML Models Using an Output-Specific and Data-Resolved Privacy Profile", "Authors": ["Tyler LeBlond", "Joseph Munoz", "Fred Lu", "Maya Fuchs", "Elliott Zaresky-Williams", "Edward Raff", "Brian Testa"], "Categories": "cs.LG cs.CR", "Comments": ["Approved for Public Release; Distribution Unlimited. PA #:AFRL-2022-3639"]}, "abstract": "Differential privacy (DP) is the prevailing technique for protecting user data in machine learning models. However, deficits to this framework include a lack of clarity for selecting the privacy budget $\\epsilon$ and a lack of quantification for the privacy leakage for a particular data row by a particular trained model. We make progress toward these limitations and a new perspective by which to visualize DP results by studying a privacy metric that quantifies the extent to which a model trained on a dataset using a DP mechanism is ``covered\" by each of the distributions resulting from training on neighboring datasets. We connect this coverage metric to what has been established in the literature and use it to rank the privacy of individual samples from the training set in what we call a privacy profile. We additionally show that the privacy profile can be used to probe an observed transition to indistinguishability that takes place in the neighboring distributions as $\\epsilon$ decreases, which we suggest is a tool that can enable the selection of $\\epsilon$ by the ML practitioner wishing to make use of DP.", "url": "https://arxiv.org/abs/2306.15790"}, {"metadata": {"arXiv": "2306.15794", "Date": "Tue, 27 Jun 2023 20:46:34 ", "Title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution", "Authors": ["Eric Nguyen", "Michael Poli", "Marjan Faizi", "Armin Thomas", "Callum Birch-Sykes", "Michael Wornow", "Aman Patel", "Clayton Rabideau", "Stefano Massaroli", "Yoshua Bengio", "Stefano Ermon", "Stephen A. Baccus", "Chris R\\'e"], "Categories": "cs.LG q-bio.GN"}, "abstract": "Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context (<0.001% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers to aggregate meaningful DNA units, losing single nucleotide resolution where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyenas new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level, an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics for simple adaptation to novel tasks without updating pretrained model weights. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 17 datasets using a model with orders of magnitude less parameters and pretraining data. On the GenomicBenchmarks, HyenaDNA surpasses SotA on all 8 datasets on average by +9 accuracy points.", "url": "https://arxiv.org/abs/2306.15794"}, {"metadata": {"arXiv": "2306.15799", "Date": "Tue, 27 Jun 2023 20:58:41 ", "Title": "FLuRKA: Fast fused Low-Rank & Kernel Attention", "Authors": ["Ahan Gupta", "Yueming Yuan", "Yanqi Zhou and Charith Mendis"], "Categories": "cs.LG cs.CL cs.PF", "Comments": ["9 pages", "4 figures"]}, "abstract": "Many efficient approximate self-attention techniques have become prevalent since the inception of the transformer architecture. Two popular classes of these techniques are low-rank and kernel methods. Each of these methods has its own strengths. We observe these strengths synergistically complement each other and exploit these synergies to fuse low-rank and kernel methods, producing a new class of transformers: FLuRKA (Fast Low-Rank and Kernel Attention). FLuRKA provide sizable performance gains over these approximate techniques and are of high quality. We theoretically and empirically evaluate both the runtime performance and quality of FLuRKA. Our runtime analysis posits a variety of parameter configurations where FLuRKA exhibit speedups and our accuracy analysis bounds the error of FLuRKA with respect to full-attention. We instantiate three FLuRKA variants which experience empirical speedups of up to 3.3x and 1.7x over low-rank and kernel methods respectively. This translates to speedups of up to 30x over models with full-attention. With respect to model quality, FLuRKA can match the accuracy of low-rank and kernel methods on GLUE after pre-training on wiki-text 103. When pre-training on a fixed time budget, FLuRKA yield better perplexity scores than models with full-attention.", "url": "https://arxiv.org/abs/2306.15799"}, {"metadata": {"arXiv": "2306.15848", "Date": "Wed, 28 Jun 2023 00:46:58 ", "Title": "Ordering for Non-Replacement SGD", "Authors": ["Yuetong Xu and Baharan Mirzasoleiman"], "Categories": "cs.LG math.OC"}, "abstract": "One approach for reducing run time and improving efficiency of machine learning is to reduce the convergence rate of the optimization algorithm used. Shuffling is an algorithm technique that is widely used in machine learning, but it only started to gain attention theoretically in recent years. With different convergence rates developed for random shuffling and incremental gradient descent, we seek to find an ordering that can improve the convergence rates for the non-replacement form of the algorithm. Based on existing bounds of the distance between the optimal and current iterate, we derive an upper bound that is dependent on the gradients at the beginning of the epoch. Through analysis of the bound, we are able to develop optimal orderings for constant and decreasing step sizes for strongly convex and convex functions. We further test and verify our results through experiments on synthesis and real data sets. In addition, we are able to combine the ordering with mini-batch and further apply it to more complex neural networks, which show promising results.", "url": "https://arxiv.org/abs/2306.15848"}, {"metadata": {"arXiv": "2306.15856", "Date": "Wed, 28 Jun 2023 01:14:55 ", "Title": "Pure exploration in multi-armed bandits with low rank structure using oblivious sampler", "Authors": ["Yaxiong Liu", "Atsuyoshi Nakamura", "Kohei Hatano", "Eiji Takimoto"], "Categories": "cs.LG stat.ML", "Comments": ["15 pages"]}, "abstract": "In this paper, we consider the low rank structure of the reward sequence of the pure exploration problems. Firstly, we propose the separated setting in pure exploration problem, where the exploration strategy cannot receive the feedback of its explorations. Due to this separation, it requires that the exploration strategy to sample the arms obliviously. By involving the kernel information of the reward vectors, we provide efficient algorithms for both time-varying and fixed cases with regret bound $O(d\\sqrt{(\\ln N)/n})$. Then, we show the lower bound to the pure exploration in multi-armed bandits with low rank sequence. There is an $O(\\sqrt{\\ln N})$ gap between our upper bound and the lower bound.", "url": "https://arxiv.org/abs/2306.15856"}, {"metadata": {"arXiv": "2306.15865", "Date": "Wed, 28 Jun 2023 01:41:30 ", "Title": "Differentially Private Distributed Estimation and Learning", "Authors": ["Marios Papachristou", "M. Amin Rahimian"], "Categories": "cs.LG cs.SI cs.SY eess.SY math.ST stat.AP stat.ML stat.TH"}, "abstract": "We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP) constraints. In every case, we demonstrate the efficiency of our algorithms by proving convergence to the estimators of a hypothetical, omniscient observer that has central access to all of the signals. We also provide convergence rate analysis and finite-time performance guarantees and show that the noise that minimizes the convergence time to the best estimates is the Laplace noise, with parameters corresponding to each agent's sensitivity to their signal and network characteristics. Finally, to supplement and validate our theoretical results, we run experiments on real-world data from the US Power Grid Network and electric consumption data from German Households to estimate the average power consumption of power stations and households under all privacy regimes.", "url": "https://arxiv.org/abs/2306.15865"}, {"metadata": {"arXiv": "2306.15868", "Date": "Wed, 28 Jun 2023 01:50:46 ", "Title": "GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for Remote Sensing Image Semantic Segmentation", "Authors": ["Zhaoyang Zhang", "Zhen Ren", "Chao Tao", "Yunsheng Zhang", "Chengli Peng", "Haifeng Li"], "Categories": "cs.LG cs.CV eess.IV", "Comments": ["12 pages", "9 figures"]}, "abstract": "Self-supervised contrastive learning (SSCL) has achieved significant milestones in remote sensing image (RSI) understanding. Its essence lies in designing an unsupervised instance discrimination pretext task to extract image features from a large number of unlabeled images that are beneficial for downstream tasks. However, existing instance discrimination based SSCL suffer from two limitations when applied to the RSI semantic segmentation task: 1) Positive sample confounding issue; 2) Feature adaptation bias. It introduces a feature adaptation bias when applied to semantic segmentation tasks that require pixel-level or object-level features. In this study, We observed that the discrimination information can be mapped to specific regions in RSI through the gradient of unsupervised contrastive loss, these specific regions tend to contain singular ground objects. Based on this, we propose contrastive learning with Gradient guided Sampling Strategy (GraSS) for RSI semantic segmentation. GraSS consists of two stages: Instance Discrimination warm-up (ID warm-up) and Gradient guided Sampling contrastive training (GS training). The ID warm-up aims to provide initial discrimination information to the contrastive loss gradients. The GS training stage aims to utilize the discrimination information contained in the contrastive loss gradients and adaptively select regions in RSI patches that contain more singular ground objects, in order to construct new positive and negative samples. Experimental results on three open datasets demonstrate that GraSS effectively enhances the performance of SSCL in high-resolution RSI semantic segmentation. Compared to seven baseline methods from five different types of SSCL, GraSS achieves an average improvement of 1.57\\% and a maximum improvement of 3.58\\% in terms of mean intersection over the union. The source code is available at https://github.com/GeoX-Lab/GraSS", "url": "https://arxiv.org/abs/2306.15868"}, {"metadata": {"arXiv": "2306.15890", "Date": "Wed, 28 Jun 2023 03:15:55 ", "Title": "A Unified View of Deep Learning for Reaction and Retrosynthesis Prediction: Current Status and Future Challenges", "Authors": ["Ziqiao Meng", "Peilin Zhao", "Yang Yu", "Irwin King"], "Categories": "cs.LG physics.chem-ph q-bio.QM", "Comments": ["Accepted as IJCAI 2023 Survey"]}, "abstract": "Reaction and retrosynthesis prediction are fundamental tasks in computational chemistry that have recently garnered attention from both the machine learning and drug discovery communities. Various deep learning approaches have been proposed to tackle these problems, and some have achieved initial success. In this survey, we conduct a comprehensive investigation of advanced deep learning-based models for reaction and retrosynthesis prediction. We summarize the design mechanisms, strengths, and weaknesses of state-of-the-art approaches. Then, we discuss the limitations of current solutions and open challenges in the problem itself. Finally, we present promising directions to facilitate future research. To our knowledge, this paper is the first comprehensive and systematic survey that seeks to provide a unified understanding of reaction and retrosynthesis prediction.", "url": "https://arxiv.org/abs/2306.15890"}, {"metadata": {"arXiv": "2306.15891", "Date": "Wed, 28 Jun 2023 03:16:45 ", "Title": "Asymptotic-Preserving Convolutional DeepONets Capture the Diffusive Behavior of the Multiscale Linear Transport Equations", "Authors": ["Keke Wu and Xiong-bin Yan and Shi Jin and Zheng Ma"], "Categories": "cs.LG"}, "abstract": "In this paper, we introduce two types of novel Asymptotic-Preserving Convolutional Deep Operator Networks (APCONs) designed to address the multiscale time-dependent linear transport problem. We observe that the vanilla physics-informed DeepONets with modified MLP may exhibit instability in maintaining the desired limiting macroscopic behavior. Therefore, this necessitates the utilization of an asymptotic-preserving loss function. Drawing inspiration from the heat kernel in the diffusion equation, we propose a new architecture called Convolutional Deep Operator Networks, which employ multiple local convolution operations instead of a global heat kernel, along with pooling and activation operations in each filter layer. Our APCON methods possess a parameter count that is independent of the grid size and are capable of capturing the diffusive behavior of the linear transport problem. Finally, we validate the effectiveness of our methods through several numerical examples.", "url": "https://arxiv.org/abs/2306.15891"}, {"metadata": {"arXiv": "2306.15907", "Date": "Wed, 28 Jun 2023 04:15:01 ", "Title": "Deep Learning Models for Water Stage Predictions in South Florida", "Authors": ["Jimeng Shi", "Zeda Yin", "Rukmangadh Myana", "Khandker Ishtiaq", "Anupama John", "Jayantha Obeysekera", "Arturo Leon", "Giri Narasimhan"], "Categories": "cs.LG physics.ao-ph"}, "abstract": "Simulating and predicting water levels in river systems is essential for flood warnings, hydraulic operations, and flood mitigations. In the engineering field, tools such as HEC-RAS, MIKE, and SWMM are used to build detailed physics-based hydrological and hydraulic computational models to simulate the entire watershed, thereby predicting the water stage at any point in the system. However, these physics-based models are computationally intensive, especially for large watersheds and for longer simulations. To overcome this problem, we train several deep learning (DL) models for use as surrogate models to rapidly predict the water stage. The downstream stage of the Miami River in South Florida is chosen as a case study for this paper. The dataset is from January 1, 2010, to December 31, 2020, downloaded from the DBHYDRO database of the South Florida Water Management District (SFWMD). Extensive experiments show that the performance of the DL models is comparable to that of the physics-based models, even during extreme precipitation conditions (i.e., tropical storms). Furthermore, we study the decline in prediction accuracy of the DL models with an increase in prediction lengths. In order to predict the water stage in the future, our DL models use measured variables of the river system from the recent past as well as covariates that can be reliably predicted in the near future. In summary, the deep learning models achieve comparable or better error rates with at least 1000x speedup in comparison to the physics-based models.", "url": "https://arxiv.org/abs/2306.15907"}, {"metadata": {"arXiv": "2306.15918", "Date": "Wed, 28 Jun 2023 04:46:59 ", "Title": "On information captured by neural networks: connections with memorization and generalization", "Authors": ["Hrayr Harutyunyan"], "Categories": "cs.LG cs.IT math.IT", "Comments": ["PhD thesis"]}, "abstract": "Despite the popularity and success of deep learning, there is limited understanding of when, how, and why neural networks generalize to unseen examples. Since learning can be seen as extracting information from data, we formally study information captured by neural networks during training. Specifically, we start with viewing learning in presence of noisy labels from an information-theoretic perspective and derive a learning algorithm that limits label noise information in weights. We then define a notion of unique information that an individual sample provides to the training of a deep network, shedding some light on the behavior of neural networks on examples that are atypical, ambiguous, or belong to underrepresented subpopulations. We relate example informativeness to generalization by deriving nonvacuous generalization gap bounds. Finally, by studying knowledge distillation, we highlight the important role of data and label complexity in generalization. Overall, our findings contribute to a deeper understanding of the mechanisms underlying neural network generalization.", "url": "https://arxiv.org/abs/2306.15918"}, {"metadata": {"arXiv": "2306.15924", "Date": "Wed, 28 Jun 2023 05:02:03 ", "Title": "The curse of dimensionality in operator learning", "Authors": ["Samuel Lanthaler and Andrew M. Stuart"], "Categories": "cs.LG cs.NA math.NA"}, "abstract": "Neural operator architectures employ neural networks to approximate operators mapping between Banach spaces of functions; they may be used to accelerate model evaluations via emulation, or to discover models from data. Consequently, the methodology has received increasing attention over recent years, giving rise to the rapidly growing field of operator learning. The first contribution of this paper is to prove that for general classes of operators which are characterized only by their $C^r$- or Lipschitz-regularity, operator learning suffers from a curse of dimensionality, defined precisely here in terms of representations of the infinite-dimensional input and output function spaces. The result is applicable to a wide variety of existing neural operators, including PCA-Net, DeepONet and the FNO. The second contribution of the paper is to prove that the general curse of dimensionality can be overcome for solution operators defined by the Hamilton-Jacobi equation; this is achieved by leveraging additional structure in the underlying solution operator, going beyond regularity. To this end, a novel neural operator architecture is introduced, termed HJ-Net, which explicitly takes into account characteristic information of the underlying Hamiltonian system. Error and complexity estimates are derived for HJ-Net which show that this architecture can provably beat the curse of dimensionality related to the infinite-dimensional input and output function spaces.", "url": "https://arxiv.org/abs/2306.15924"}, {"metadata": {"arXiv": "2306.15927", "Date": "Wed, 28 Jun 2023 05:14:03 ", "Title": "Learning Dynamic Graphs from All Contextual Information for Accurate Point-of-Interest Visit Forecasting", "Authors": ["Arash Hajisafi", "Haowen Lin", "Sina Shaham", "Haoji Hu", "Maria Despoina Siampou", "Yao-Yi Chiang", "Cyrus Shahabi"], "Categories": "cs.LG cs.SI"}, "abstract": "Forecasting the number of visits to Points-of-Interest (POI) in an urban area is critical for planning and decision-making for various application domains, from urban planning and transportation management to public health and social studies. Although this forecasting problem can be formulated as a multivariate time-series forecasting task, the current approaches cannot fully exploit the ever-changing multi-context correlations among POIs. Therefore, we propose Busyness Graph Neural Network (BysGNN), a temporal graph neural network designed to learn and uncover the underlying multi-context correlations between POIs for accurate visit forecasting. Unlike other approaches where only time-series data is used to learn a dynamic graph, BysGNN utilizes all contextual information and time-series data to learn an accurate dynamic graph representation. By incorporating all contextual, temporal, and spatial signals, we observe a significant improvement in our forecasting accuracy over state-of-the-art forecasting models in our experiments with real-world datasets across the United States.", "url": "https://arxiv.org/abs/2306.15927"}, {"metadata": {"arXiv": "2306.15944", "Date": "Wed, 28 Jun 2023 06:05:47 ", "Title": "Pb-Hash: Partitioned b-bit Hashing", "Authors": ["Ping Li", "Weijie Zhao"], "Categories": "cs.LG cs.DS cs.IR"}, "abstract": "Many hashing algorithms including minwise hashing (MinHash), one permutation hashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$ bits. With $k$ hashes for each data vector, the storage would be $B\\times k$ bits; and when used for large-scale learning, the model size would be $2^B\\times k$, which can be expensive. A standard strategy is to use only the lowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of hashes. In this study, we propose to re-use the hashes by partitioning the $B$ bits into $m$ chunks, e.g., $b\\times m =B$. Correspondingly, the model size becomes $m\\times 2^b \\times k$, which can be substantially smaller than the original $2^B\\times k$. Our theoretical analysis reveals that by partitioning the hash values into $m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$ bits would not be as accurate as directly using $B$ bits. This is due to the correlation from re-using the same hash. On the other hand, our analysis also shows that the accuracy would not drop much for (e.g.,) $m=2\\sim 4$. In some regions, Pb-Hash still works well even for $m$ much larger than 4. We expect Pb-Hash would be a good addition to the family of hashing methods/applications and benefit industrial practitioners. We verify the effectiveness of Pb-Hash in machine learning tasks, for linear SVM models as well as deep learning models. Since the hashed data are essentially categorical (ID) features, we follow the standard practice of using embedding tables for each hash. With Pb-Hash, we need to design an effective strategy to combine $m$ embeddings. Our study provides an empirical evaluation on four pooling schemes: concatenation, max pooling, mean pooling, and product pooling. There is no definite answer which pooling would be always better and we leave that for future study.", "url": "https://arxiv.org/abs/2306.15944"}, {"metadata": {"arXiv": "2306.15963", "Date": "Wed, 28 Jun 2023 07:00:12 ", "Title": "Graph Interpolation via Fast Fused-Gromovization", "Authors": ["Xinyu Ma", "Xu Chu", "Yasha Wang", "Yang Lin", "Junfeng Zhao", "Liantao Ma", "Wenwu Zhu"], "Categories": "cs.LG"}, "abstract": "Graph data augmentation has proven to be effective in enhancing the generalizability and robustness of graph neural networks (GNNs) for graph-level classifications. However, existing methods mainly focus on augmenting the graph signal space and the graph structure space independently, overlooking their joint interaction. This paper addresses this limitation by formulating the problem as an optimal transport problem that aims to find an optimal strategy for matching nodes between graphs considering the interactions between graph structures and signals. To tackle this problem, we propose a novel graph mixup algorithm dubbed FGWMixup, which leverages the Fused Gromov-Wasserstein (FGW) metric space to identify a \"midpoint\" of the source graphs. To improve the scalability of our approach, we introduce a relaxed FGW solver that accelerates FGWMixup by enhancing the convergence rate from $\\mathcal{O}(t^{-1})$ to $\\mathcal{O}(t^{-2})$. Extensive experiments conducted on five datasets, utilizing both classic (MPNNs) and advanced (Graphormers) GNN backbones, demonstrate the effectiveness of FGWMixup in improving the generalizability and robustness of GNNs.", "url": "https://arxiv.org/abs/2306.15963"}, {"metadata": {"arXiv": "2306.15990", "Date": "Wed, 28 Jun 2023 07:59:47 ", "Title": "MyDigitalFootprint: an extensive context dataset for pervasive computing applications at the edge", "Authors": ["Mattia Giovanni Campana", "Franca Delmastro"], "Categories": "cs.LG cs.CY", "Journal-ref": "Pervasive and Mobile Computing, Volume 70, January 2021, 101309", "DOI": "10.1016/j.pmcj.2020.101309"}, "abstract": "The widespread diffusion of connected smart devices has contributed to the rapid expansion and evolution of the Internet at its edge. Personal mobile devices interact with other smart objects in their surroundings, adapting behavior based on rapidly changing user context. The ability of mobile devices to process this data locally is crucial for quick adaptation. This can be achieved through a single elaboration process integrated into user applications or a middleware platform for context processing. However, the lack of public datasets considering user context complexity in the mobile environment hinders research progress. We introduce MyDigitalFootprint, a large-scale dataset comprising smartphone sensor data, physical proximity information, and Online Social Networks interactions. This dataset supports multimodal context recognition and social relationship modeling. It spans two months of measurements from 31 volunteer users in their natural environment, allowing for unrestricted behavior. Existing public datasets focus on limited context data for specific applications, while ours offers comprehensive information on the user context in the mobile environment. To demonstrate the dataset's effectiveness, we present three context-aware applications utilizing various machine learning tasks: (i) a social link prediction algorithm based on physical proximity data, (ii) daily-life activity recognition using smartphone-embedded sensors data, and (iii) a pervasive context-aware recommender system. Our dataset, with its heterogeneity of information, serves as a valuable resource to validate new research in mobile and edge computing.", "url": "https://arxiv.org/abs/2306.15990"}, {"metadata": {"arXiv": "2306.15994", "Date": "Wed, 28 Jun 2023 08:08:14 ", "Title": "Systematic analysis of the impact of label noise correction on ML Fairness", "Authors": ["I. Oliveira e Silva", "C. Soares", "I. Sousa", "R. Ghani"], "Categories": "cs.LG cs.CY"}, "abstract": "Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply the methodology to analyze six label noise correction methods according to several fairness metrics on standard OpenML datasets. Our results suggest that the Hybrid Label Noise Correction method achieves the best trade-off between predictive performance and fairness. Clustering-Based Correction can reduce discrimination the most, however, at the cost of lower predictive performance.", "url": "https://arxiv.org/abs/2306.15994"}, {"metadata": {"arXiv": "2306.16029", "Date": "Wed, 28 Jun 2023 08:57:01 ", "Title": "Lightweight Modeling of User Context Combining Physical and Virtual Sensor Data", "Authors": ["Mattia Giovanni Campana", "Dimitris Chatzopoulos", "Franca Delmastro", "Pan Hui"], "Categories": "cs.LG", "DOI": "10.1145/3267305.3274178"}, "abstract": "The multitude of data generated by sensors available on users' mobile devices, combined with advances in machine learning techniques, support context-aware services in recognizing the current situation of a user (i.e., physical context) and optimizing the system's personalization features. However, context-awareness performances mainly depend on the accuracy of the context inference process, which is strictly tied to the availability of large-scale and labeled datasets. In this work, we present a framework developed to collect datasets containing heterogeneous sensing data derived from personal mobile devices. The framework has been used by 3 voluntary users for two weeks, generating a dataset with more than 36K samples and 1331 features. We also propose a lightweight approach to model the user context able to efficiently perform the entire reasoning process on the user mobile device. To this aim, we used six dimensionality reduction techniques in order to optimize the context classification. Experimental results on the generated dataset show that we achieve a 10x speed up and a feature reduction of more than 90% while keeping the accuracy loss less than 3%.", "url": "https://arxiv.org/abs/2306.16029"}, {"metadata": {"arXiv": "2306.16085", "Date": "Wed, 28 Jun 2023 10:33:57 ", "Title": "Mass Spectra Prediction with Structural Motif-based Graph Neural Networks", "Authors": ["Jiwon Park", "Jeonghee Jo", "Sungroh Yoon"], "Categories": "cs.LG physics.chem-ph q-bio.QM", "Comments": ["19 pages", "3figures"]}, "abstract": "Mass spectra, which are agglomerations of ionized fragments from targeted molecules, play a crucial role across various fields for the identification of molecular structures. A prevalent analysis method involves spectral library searches,where unknown spectra are cross-referenced with a database. The effectiveness of such search-based approaches, however, is restricted by the scope of the existing mass spectra database, underscoring the need to expand the database via mass spectra prediction. In this research, we propose the Motif-based Mass Spectrum Prediction Network (MoMS-Net), a system that predicts mass spectra using the information derived from structural motifs and the implementation of Graph Neural Networks (GNNs). We have tested our model across diverse mass spectra and have observed its superiority over other existing models. MoMS-Net considers substructure at the graph level, which facilitates the incorporation of long-range dependencies while using less memory compared to the graph transformer model.", "url": "https://arxiv.org/abs/2306.16085"}, {"metadata": {"arXiv": "2306.16111", "Date": "Wed, 28 Jun 2023 11:27:48 ", "Title": "Time Regularization in Optimal Time Variable Learning", "Authors": ["Evelyn Herberg and Roland Herzog and Frederik K\\\"ohne"], "Categories": "cs.LG math.OC"}, "abstract": "Recently, optimal time variable learning in deep neural networks (DNNs) was introduced in arXiv:2204.08528. In this manuscript we extend the concept by introducing a regularization term that directly relates to the time horizon in discrete dynamical systems. Furthermore, we propose an adaptive pruning approach for Residual Neural Networks (ResNets), which reduces network complexity without compromising expressiveness, while simultaneously decreasing training time. The results are illustrated by applying the proposed concepts to classification tasks on the well known MNIST and Fashion MNIST data sets. Our PyTorch code is available on https://github.com/frederikkoehne/time_variable_learning.", "url": "https://arxiv.org/abs/2306.16111"}, {"metadata": {"arXiv": "2306.16126", "Date": "Wed, 28 Jun 2023 11:56:09 ", "Title": "More efficient manual review of automatically transcribed tabular data", "Authors": ["Bj{\\o}rn-Richard Pedersen", "Rigmor Katrine Johansen", "Einar Holsb{\\o}", "Hilde Sommerseth", "Lars Ailo Bongo"], "Categories": "cs.LG cs.CV cs.HC", "Comments": ["19 pages", "5 figures", "1 table"]}, "abstract": "Machine learning methods have proven useful in transcribing historical data. However, results from even highly accurate methods require manual verification and correction. Such manual review can be time-consuming and expensive, therefore the objective of this paper was to make it more efficient. Previously, we used machine learning to transcribe 2.3 million handwritten occupation codes from the Norwegian 1950 census with high accuracy (97%). We manually reviewed the 90,000 (3%) codes with the lowest model confidence. We allocated those 90,000 codes to human reviewers, who used our annotation tool to review the codes. To assess reviewer agreement, some codes were assigned to multiple reviewers. We then analyzed the review results to understand the relationship between accuracy improvements and effort. Additionally, we interviewed the reviewers to improve the workflow. The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of cases. About 0.2% of the images could not be assigned a label, while for 5.1% the reviewers were uncertain, or they assigned an invalid label. 9,000 images were independently reviewed by multiple reviewers, resulting in an agreement of 86.43% and disagreement of 8.96%. We learned that our automatic transcription is biased towards the most frequent codes, with a higher degree of misclassification for the lowest frequency codes. Our interview findings show that the reviewers did internal quality control and found our custom tool well-suited. So, only one reviewer is needed, but they should report uncertainty.", "url": "https://arxiv.org/abs/2306.16126"}, {"metadata": {"arXiv": "2306.16156", "Date": "Wed, 28 Jun 2023 12:37:23 ", "Title": "Recent Advances in Optimal Transport for Machine Learning", "Authors": ["Eduardo Fernandes Montesuma", "Fred Ngol\\`e Mboula", "Antoine Souloumiac"], "Categories": "cs.LG math.PR stat.ML", "Comments": ["20 pages,5 figures,under review"]}, "abstract": "Recently, Optimal Transport has been proposed as a probabilistic framework in Machine Learning for comparing and manipulating probability distributions. This is rooted in its rich history and theory, and has offered new solutions to different problems in machine learning, such as generative modeling and transfer learning. In this survey we explore contributions of Optimal Transport for Machine Learning over the period 2012 -- 2022, focusing on four sub-fields of Machine Learning: supervised, unsupervised, transfer and reinforcement learning. We further highlight the recent development in computational Optimal Transport, and its interplay with Machine Learning practice.", "url": "https://arxiv.org/abs/2306.16156"}, {"metadata": {"arXiv": "2306.16170", "Date": "Wed, 28 Jun 2023 12:47:01 ", "Title": "Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation", "Authors": ["Shiji Zhao", "Xizhe Wang", "Xingxing Wei"], "Categories": "cs.LG cs.CV"}, "abstract": "Adversarial training is a practical approach for improving the robustness of deep neural networks against adversarial attacks. Although bringing reliable robustness, the performance toward clean examples is negatively affected after adversarial training, which means a trade-off exists between accuracy and robustness. Recently, some studies have tried to use knowledge distillation methods in adversarial training, achieving competitive performance in improving the robustness but the accuracy for clean samples is still limited. In this paper, to mitigate the accuracy-robustness trade-off, we introduce the Multi-Teacher Adversarial Robustness Distillation (MTARD) to guide the model's adversarial training process by applying a strong clean teacher and a strong robust teacher to handle the clean examples and adversarial examples, respectively. During the optimization process, to ensure that different teachers show similar knowledge scales, we design the Entropy-Based Balance algorithm to adjust the teacher's temperature and keep the teachers' information entropy consistent. Besides, to ensure that the student has a relatively consistent learning speed from multiple teachers, we propose the Normalization Loss Balance algorithm to adjust the learning weights of different types of knowledge. A series of experiments conducted on public datasets demonstrate that MTARD outperforms the state-of-the-art adversarial training and distillation methods against various adversarial attacks.", "url": "https://arxiv.org/abs/2306.16170"}, {"metadata": {"arXiv": "2306.16208", "Date": "Wed, 28 Jun 2023 13:43:46 ", "Title": "Continuous-Time q-learning for McKean-Vlasov Control Problems", "Authors": ["Xiaoli Wei", "Xiang Yu"], "Categories": "cs.LG math.OC q-fin.CP", "Comments": ["Keywords: Continuous-time reinforcement learning", "q-function", "Mckean-Vlasov control", "weak martingale characterization", "test policies"]}, "abstract": "This paper studies the q-learning, recently coined as the continuous-time counterpart of Q-learning by Jia and Zhou (2022c), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2022c), the mean-field interaction of agents render the definition of q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (denoted by $q$) as the first-order approximation of the integrated Q-function introduced in Gu, Guo, Wei and Xu (2023) that can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function (denoted by $q_e$) that is employed in the policy improvement iterations. We show that two q-functions are related via an integral representation under all test policies. Based on the weak martingale condition of the integrated q-function and our proposed searching method of test policies, some model-free offline and online learning algorithms are devised. In two financial applications, one in LQ control framework and one beyond LQ control framework, we can obtain the exact parameterization of the value function and two q-functions and illustrate our algorithms with simulation experiments.", "url": "https://arxiv.org/abs/2306.16208"}, {"metadata": {"arXiv": "2306.16248", "Date": "Wed, 28 Jun 2023 14:18:52 ", "Title": "Latent SDEs on Homogeneous Spaces", "Authors": ["Sebastian Zeng", "Florian Graf", "Roland Kwitt"], "Categories": "cs.LG"}, "abstract": "We consider the problem of variational Bayesian inference in a latent variable model where a (possibly complex) observed stochastic process is governed by the solution of a latent stochastic differential equation (SDE). Motivated by the challenges that arise when trying to learn an (almost arbitrary) latent neural SDE from large-scale data, such as efficient gradient computation, we take a step back and study a specific subclass instead. In our case, the SDE evolves on a homogeneous latent space and is induced by stochastic dynamics of the corresponding (matrix) Lie group. In learning problems, SDEs on the unit $n$-sphere are arguably the most relevant incarnation of this setup. Notably, for variational inference, the sphere not only facilitates using a truly uninformative prior SDE, but we also obtain a particularly simple and intuitive expression for the Kullback-Leibler divergence between the approximate posterior and prior process in the evidence lower bound. Experiments demonstrate that a latent SDE of the proposed type can be learned efficiently by means of an existing one-step geometric Euler-Maruyama scheme. Despite restricting ourselves to a less diverse class of SDEs, we achieve competitive or even state-of-the-art performance on various time series interpolation and classification benchmarks.", "url": "https://arxiv.org/abs/2306.16248"}, {"metadata": {"arXiv": "2306.16352", "Date": "Wed, 28 Jun 2023 16:33:39 ", "Title": "Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise", "Authors": ["Ilias Diakonikolas", "Jelena Diakonikolas", "Daniel M. Kane", "Puqian Wang", "Nikos Zarifis"], "Categories": "cs.LG cs.DS math.ST stat.ML stat.TH"}, "abstract": "We study the problem of PAC learning $\\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoff suggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\\widetilde{O}(1/(\\gamma^2 \\epsilon^2))$. Our main result is a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\\epsilon$ in the sample complexity is inherent for computationally efficient algorithms. Specifically, our results imply a lower bound of $\\widetilde{\\Omega}(1/(\\gamma^{1/2} \\epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.", "url": "https://arxiv.org/abs/2306.16352"}, {"metadata": {"arXiv": "2306.16354", "Date": "Wed, 28 Jun 2023 16:34:50 ", "Title": "cuSLINK: Single-linkage Agglomerative Clustering on the GPU", "Authors": ["Corey J. Nolet", "Divye Gala", "Alex Fender", "Mahesh Doijade", "Joe Eaton", "Edward Raff", "John Zedlewski", "Brad Rees", "Tim Oates"], "Categories": "cs.LG stat.ML", "Comments": ["To appear in ECML PKDD 2023 by Springer Nature"]}, "abstract": "In this paper, we propose cuSLINK, a novel and state-of-the-art reformulation of the SLINK algorithm on the GPU which requires only $O(Nk)$ space and uses a parameter $k$ to trade off space and time. We also propose a set of novel and reusable building blocks that compose cuSLINK. These building blocks include highly optimized computational patterns for $k$-NN graph construction, spanning trees, and dendrogram cluster extraction. We show how we used our primitives to implement cuSLINK end-to-end on the GPU, further enabling a wide range of real-world data mining and machine learning applications that were once intractable. In addition to being a primary computational bottleneck in the popular HDBSCAN algorithm, the impact of our end-to-end cuSLINK algorithm spans a large range of important applications, including cluster analysis in social and computer networks, natural language processing, and computer vision. Users can obtain cuSLINK at https://docs.rapids.ai/api/cuml/latest/api/#agglomerative-clustering", "url": "https://arxiv.org/abs/2306.16354"}, {"metadata": {"arXiv": "2306.16361", "Date": "Wed, 28 Jun 2023 16:45:38 ", "Title": "Beyond NTK with Vanilla Gradient Descent: A Mean-Field Analysis of Neural Networks with Polynomial Width, Samples, and Time", "Authors": ["Arvind Mahankali", "Jeff Z. Haochen", "Kefan Dong", "Margalit Glasgow", "Tengyu Ma"], "Categories": "cs.LG"}, "abstract": "Despite recent theoretical progress on the non-convex optimization of two-layer neural networks, it is still an open question whether gradient descent on neural networks without unnatural modifications can achieve better sample complexity than kernel methods. This paper provides a clean mean-field analysis of projected gradient flow on polynomial-width two-layer neural networks. Different from prior works, our analysis does not require unnatural modifications of the optimization algorithm. We prove that with sample size $n = O(d^{3.1})$ where $d$ is the dimension of the inputs, the network converges in polynomially many iterations to a non-trivial error that is not achievable by kernel methods using $n \\ll d^4$ samples, hence demonstrating a clear separation between unmodified gradient descent and NTK.", "url": "https://arxiv.org/abs/2306.16361"}, {"metadata": {"arXiv": "2306.16367", "Date": "Wed, 28 Jun 2023 17:00:32 ", "Title": "Multi-Site Clinical Federated Learning using Recursive and Attentive Models and NVFlare", "Authors": ["Won Joon Yun", "Samuel Kim", "Joongheon Kim"], "Categories": "cs.LG cs.CL cs.DC"}, "abstract": "The prodigious growth of digital health data has precipitated a mounting interest in harnessing machine learning methodologies, such as natural language processing (NLP), to scrutinize medical records, clinical notes, and other text-based health information. Although NLP techniques have exhibited substantial potential in augmenting patient care and informing clinical decision-making, data privacy and adherence to regulations persist as critical concerns. Federated learning (FL) emerges as a viable solution, empowering multiple organizations to train machine learning models collaboratively without disseminating raw data. This paper proffers a pragmatic approach to medical NLP by amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA. We introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based model and Bidirectional Encoder Representations from Transformers (BERT), which have demonstrated exceptional performance in comprehending context and semantics within medical data. This paper encompasses the development of an integrated framework that addresses data privacy and regulatory compliance challenges while maintaining elevated accuracy and performance, incorporating BERT pretraining, and comprehensively substantiating the efficacy of the proposed approach.", "url": "https://arxiv.org/abs/2306.16367"}, {"metadata": {"arXiv": "2306.16394", "Date": "Wed, 28 Jun 2023 17:43:19 ", "Title": "Sharper Model-free Reinforcement Learning for Average-reward Markov Decision Processes", "Authors": ["Zihan Zhang and Qiaomin Xie"], "Categories": "cs.LG"}, "abstract": "We develop several provably efficient model-free reinforcement learning (RL) algorithms for infinite-horizon average-reward Markov Decision Processes (MDPs). We consider both online setting and the setting with access to a simulator. In the online setting, we propose model-free RL algorithms based on reference-advantage decomposition. Our algorithm achieves $\\widetilde{O}(S^5A^2\\mathrm{sp}(h^*)\\sqrt{T})$ regret after $T$ steps, where $S\\times A$ is the size of state-action space, and $\\mathrm{sp}(h^*)$ the span of the optimal bias function. Our results are the first to achieve optimal dependence in $T$ for weakly communicating MDPs. In the simulator setting, we propose a model-free RL algorithm that finds an $\\epsilon$-optimal policy using $\\widetilde{O} \\left(\\frac{SA\\mathrm{sp}^2(h^*)}{\\epsilon^2}+\\frac{S^2A\\mathrm{sp}(h^*)}{\\epsilon} \\right)$ samples, whereas the minimax lower bound is $\\Omega\\left(\\frac{SA\\mathrm{sp}(h^*)}{\\epsilon^2}\\right)$. Our results are based on two new techniques that are unique in the average-reward setting: 1) better discounted approximation by value-difference estimation; 2) efficient construction of confidence region for the optimal bias function with space complexity $O(SA)$.", "url": "https://arxiv.org/abs/2306.16394"}, {"metadata": {"arXiv": "2306.15700", "Date": "Mon, 26 Jun 2023 19:24:53 ", "Title": "Imitation with Spatial-Temporal Heatmap: 2nd Place Solution for NuPlan Challenge", "Authors": ["Yihan Hu", "Kun Li", "Pingyuan Liang", "Jingyu Qian", "Zhening Yang", "Haichao Zhang", "Wenxin Shao", "Zhuangzhuang Ding", "Wei Xu", "Qiang Liu"], "Categories": "cs.RO cs.LG"}, "abstract": "This paper presents our 2nd place solution for the NuPlan Challenge 2023. Autonomous driving in real-world scenarios is highly complex and uncertain. Achieving safe planning in the complex multimodal scenarios is a highly challenging task. Our approach, Imitation with Spatial-Temporal Heatmap, adopts the learning form of behavior cloning, innovatively predicts the future multimodal states with a heatmap representation, and uses trajectory refinement techniques to ensure final safety. The experiment shows that our method effectively balances the vehicle's progress and safety, generating safe and comfortable trajectories. In the NuPlan competition, we achieved the second highest overall score, while obtained the best scores in the ego progress and comfort metrics.", "url": "https://arxiv.org/abs/2306.15700"}, {"metadata": {"arXiv": "2306.15713", "Date": "Tue, 27 Jun 2023 17:58:39 ", "Title": "Rethinking Closed-loop Training for Autonomous Driving", "Authors": ["Chris Zhang", "Runsheng Guo", "Wenyuan Zeng", "Yuwen Xiong", "Binbin Dai", "Rui Hu", "Mengye Ren", "Raquel Urtasun"], "Categories": "cs.RO cs.CV cs.LG", "Comments": ["ECCV 2022"], "DOI": "10.1007/978-3-031-19842-7_16"}, "abstract": "Recent advances in high-fidelity simulators have enabled closed-loop training of autonomous driving agents, potentially solving the distribution shift in training v.s. deployment and allowing training to be scaled both safely and cheaply. However, there is a lack of understanding of how to build effective training benchmarks for closed-loop training. In this work, we present the first empirical study which analyzes the effects of different training benchmark designs on the success of learning agents, such as how to design traffic scenarios and scale training environments. Furthermore, we show that many popular RL algorithms cannot achieve satisfactory performance in the context of autonomous driving, as they lack long-term planning and take an extremely long time to train. To address these issues, we propose trajectory value learning (TRAVL), an RL-based driving agent that performs planning with multistep look-ahead and exploits cheaply generated imagined data for efficient learning. Our experiments show that TRAVL can learn much faster and produce safer maneuvers compared to all the baselines. For more information, visit the project website: https://waabi.ai/research/travl", "url": "https://arxiv.org/abs/2306.15713"}, {"metadata": {"arXiv": "2306.15968", "Date": "Wed, 28 Jun 2023 07:11:02 ", "Title": "Action and Trajectory Planning for Urban Autonomous Driving with Hierarchical Reinforcement Learning", "Authors": ["Xinyang Lu", "Flint Xiaofeng Fan and Tianying Wang"], "Categories": "cs.RO cs.LG", "Comments": ["ICML Workshop on New Frontiers in Learning", "Control", "and Dynamical Systems"]}, "abstract": "Reinforcement Learning (RL) has made promising progress in planning and decision-making for Autonomous Vehicles (AVs) in simple driving scenarios. However, existing RL algorithms for AVs fail to learn critical driving skills in complex urban scenarios. First, urban driving scenarios require AVs to handle multiple driving tasks of which conventional RL algorithms are incapable. Second, the presence of other vehicles in urban scenarios results in a dynamically changing environment, which challenges RL algorithms to plan the action and trajectory of the AV. In this work, we propose an action and trajectory planner using Hierarchical Reinforcement Learning (atHRL) method, which models the agent behavior in a hierarchical model by using the perception of the lidar and birdeye view. The proposed atHRL method learns to make decisions about the agent's future trajectory and computes target waypoints under continuous settings based on a hierarchical DDPG algorithm. The waypoints planned by the atHRL model are then sent to a low-level controller to generate the steering and throttle commands required for the vehicle maneuver. We empirically verify the efficacy of atHRL through extensive experiments in complex urban driving scenarios that compose multiple tasks with the presence of other vehicles in the CARLA simulator. The experimental results suggest a significant performance improvement compared to the state-of-the-art RL methods.", "url": "https://arxiv.org/abs/2306.15968"}, {"metadata": {"arXiv": "2306.16169", "Date": "Wed, 28 Jun 2023 12:44:59 ", "Title": "Communication Resources Constrained Hierarchical Federated Learning for End-to-End Autonomous Driving", "Authors": ["Wei-Bin Kou", "Shuai Wang", "Guangxu Zhu", "Bin Luo", "Yingxian Chen", "Derrick Wing Kwan Ng", "and Yik-Chung Wu"], "Categories": "cs.RO cs.LG"}, "abstract": "While federated learning (FL) improves the generalization of end-to-end autonomous driving by model aggregation, the conventional single-hop FL (SFL) suffers from slow convergence rate due to long-range communications among vehicles and cloud server. Hierarchical federated learning (HFL) overcomes such drawbacks via introduction of mid-point edge servers. However, the orchestration between constrained communication resources and HFL performance becomes an urgent problem. This paper proposes an optimization-based Communication Resource Constrained Hierarchical Federated Learning (CRCHFL) framework to minimize the generalization error of the autonomous driving model using hybrid data and model aggregation. The effectiveness of the proposed CRCHFL is evaluated in the Car Learning to Act (CARLA) simulation platform. Results show that the proposed CRCHFL both accelerates the convergence rate and enhances the generalization of federated learning autonomous driving model. Moreover, under the same communication resource budget, it outperforms the HFL by 10.33% and the SFL by 12.44%.", "url": "https://arxiv.org/abs/2306.16169"}, {"metadata": {"arXiv": "2306.15711", "Date": "Tue, 27 Jun 2023 12:41:36 ", "Title": "Semi-supervised Multimodal Representation Learning through a Global Workspace", "Authors": ["Benjamin Devillers", "L\\'eopold Mayti\\'e and Rufin VanRullen"], "Categories": "cs.AI q-bio.NC", "Comments": ["Under review"]}, "abstract": "Recent deep learning models can efficiently combine inputs from different modalities (e.g., images and text) and learn to align their latent representations, or to translate signals from one domain to another (as in image captioning, or text-to-image generation). However, current approaches mainly rely on brute-force supervised training over large multimodal datasets. In contrast, humans (and other animals) can learn useful multimodal representations from only sparse experience with matched cross-modal data. Here we evaluate the capabilities of a neural network architecture inspired by the cognitive notion of a \"Global Workspace\": a shared representation for two (or more) input modalities. Each modality is processed by a specialized system (pretrained on unimodal data, and subsequently frozen). The corresponding latent representations are then encoded to and decoded from a single shared workspace. Importantly, this architecture is amenable to self-supervised training via cycle-consistency: encoding-decoding sequences should approximate the identity function. For various pairings of vision-language modalities and across two datasets of varying complexity, we show that such an architecture can be trained to align and translate between two modalities with very little need for matched data (from 4 to 7 times less than a fully supervised approach). The global workspace representation can be used advantageously for downstream classification tasks and for robust transfer learning. Ablation studies reveal that both the shared workspace and the self-supervised cycle-consistency training are critical to the system's performance.", "url": "https://arxiv.org/abs/2306.15711"}, {"metadata": {"arXiv": "2306.15796", "Date": "Tue, 27 Jun 2023 20:51:03 ", "Title": "ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis", "Authors": ["Yakun Yu", "Mingjun Zhao", "Shi-ang Qi", "Feiran Sun", "Baoxun Wang", "Weidong Guo", "Xiaoli Wang", "Lei Yang", "Di Niu"], "Categories": "cs.AI", "Comments": ["Accepted by ACL Findings 2023"]}, "abstract": "Multimodal Sentiment Analysis leverages multimodal signals to detect the sentiment of a speaker. Previous approaches concentrate on performing multimodal fusion and representation learning based on general knowledge obtained from pretrained models, which neglects the effect of domain-specific knowledge. In this paper, we propose Contrastive Knowledge Injection (ConKI) for multimodal sentiment analysis, where specific-knowledge representations for each modality can be learned together with general knowledge representations via knowledge injection based on an adapter architecture. In addition, ConKI uses a hierarchical contrastive learning procedure performed between knowledge types within every single modality, across modalities within each sample, and across samples to facilitate the effective learning of the proposed representations, hence improving multimodal sentiment predictions. The experiments on three popular multimodal sentiment analysis benchmarks show that ConKI outperforms all prior methods on a variety of performance metrics.", "url": "https://arxiv.org/abs/2306.15796"}, {"metadata": {"arXiv": "2306.15803", "Date": "Tue, 27 Jun 2023 21:09:25 ", "Title": "On Logic-Based Explainability with Partially Specified Inputs", "Authors": ["Ram\\'on B\\'ejar and Ant\\'onio Morgado and Jordi Planes and Joao Marques-Silva"], "Categories": "cs.AI", "Comments": ["14 pages"]}, "abstract": "In the practical deployment of machine learning (ML) models, missing data represents a recurring challenge. Missing data is often addressed when training ML models. But missing data also needs to be addressed when deciding predictions and when explaining those predictions. Missing data represents an opportunity to partially specify the inputs of the prediction to be explained. This paper studies the computation of logic-based explanations in the presence of partially specified inputs. The paper shows that most of the algorithms proposed in recent years for computing logic-based explanations can be generalized for computing explanations given the partially specified inputs. One related result is that the complexity of computing logic-based explanations remains unchanged. A similar result is proved in the case of logic-based explainability subject to input constraints. Furthermore, the proposed solution for computing explanations given partially specified inputs is applied to classifiers obtained from well-known public datasets, thereby illustrating a number of novel explainability use cases.", "url": "https://arxiv.org/abs/2306.15803"}, {"metadata": {"arXiv": "2306.15887", "Date": "Wed, 28 Jun 2023 03:03:51 ", "Title": "Beyond the Hype: Assessing the Performance, Trustworthiness, and Clinical Suitability of GPT3.5", "Authors": ["Salmonn Talebi", "Elizabeth Tong and Mohammad R. K. Mofrad"], "Categories": "cs.AI"}, "abstract": "The use of large language models (LLMs) in healthcare is gaining popularity, but their practicality and safety in clinical settings have not been thoroughly assessed. In high-stakes environments like medical settings, trust and safety are critical issues for LLMs. To address these concerns, we present an approach to evaluate the performance and trustworthiness of a GPT3.5 model for medical image protocol assignment. We compare it with a fine-tuned BERT model and a radiologist. In addition, we have a radiologist review the GPT3.5 output to evaluate its decision-making process. Our evaluation dataset consists of 4,700 physician entries across 11 imaging protocol classes spanning the entire head. Our findings suggest that the GPT3.5 performance falls behind BERT and a radiologist. However, GPT3.5 outperforms BERT in its ability to explain its decision, detect relevant word indicators, and model calibration. Furthermore, by analyzing the explanations of GPT3.5 for misclassifications, we reveal systematic errors that need to be resolved to enhance its safety and suitability for clinical use.", "url": "https://arxiv.org/abs/2306.15887"}, {"metadata": {"arXiv": "2306.15903", "Date": "Wed, 28 Jun 2023 03:56:57 ", "Title": "Diversity is Strength: Mastering Football Full Game with Interactive Reinforcement Learning of Multiple AIs", "Authors": ["Chenglu Sun", "Shuo Shen", "Sijia Xu", "Weidong Zhang"], "Categories": "cs.AI"}, "abstract": "Training AI with strong and rich strategies in multi-agent environments remains an important research topic in Deep Reinforcement Learning (DRL). The AI's strength is closely related to its diversity of strategies, and this relationship can guide us to train AI with both strong and rich strategies. To prove this point, we propose Diversity is Strength (DIS), a novel DRL training framework that can simultaneously train multiple kinds of AIs. These AIs are linked through an interconnected history model pool structure, which enhances their capabilities and strategy diversities. We also design a model evaluation and screening scheme to select the best models to enrich the model pool and obtain the final AI. The proposed training method provides diverse, generalizable, and strong AI strategies without using human data. We tested our method in an AI competition based on Google Research Football (GRF) and won the 5v5 and 11v11 tracks. The method enables a GRF AI to have a high level on both 5v5 and 11v11 tracks for the first time, which are under complex multi-agent environments. The behavior analysis shows that the trained AI has rich strategies, and the ablation experiments proved that the designed modules benefit the training process.", "url": "https://arxiv.org/abs/2306.15903"}, {"metadata": {"arXiv": "2306.16034", "Date": "Wed, 28 Jun 2023 09:04:56 ", "Title": "Stone Needle: A General Multimodal Large-scale Model Framework towards Healthcare", "Authors": ["Weihua Liu and Yong Zuo"], "Categories": "cs.AI cs.NI"}, "abstract": "In healthcare, multimodal data is prevalent and requires to be comprehensively analyzed before diagnostic decisions, including medical images, clinical reports, etc. However, current large-scale artificial intelligence models predominantly focus on single-modal cognitive abilities and neglect the integration of multiple modalities. Therefore, we propose Stone Needle, a general multimodal large-scale model framework tailored explicitly for healthcare applications. Stone Needle serves as a comprehensive medical multimodal model foundation, integrating various modalities such as text, images, videos, and audio to surpass the limitations of single-modal systems. Through the framework components of intent analysis, medical foundation models, prompt manager, and medical language module, our architecture can perform multi-modal interaction in multiple rounds of dialogue. Our method is a general multimodal large-scale model framework, integrating diverse modalities and allowing us to tailor for specific tasks. The experimental results demonstrate the superior performance of our method compared to single-modal systems. The fusion of different modalities and the ability to process complex medical information in Stone Needle benefits accurate diagnosis, treatment recommendations, and patient care.", "url": "https://arxiv.org/abs/2306.16034"}, {"metadata": {"arXiv": "2306.16088", "Date": "Wed, 28 Jun 2023 10:39:31 ", "Title": "Mastering Nordschleife -- A comprehensive race simulation for AI strategy decision-making in motorsports", "Authors": ["Max Boettinger", "David Klotz"], "Categories": "cs.AI"}, "abstract": "In the realm of circuit motorsports, race strategy plays a pivotal role in determining race outcomes. This strategy focuses on the timing of pit stops, which are necessary due to fuel consumption and tire performance degradation. The objective of race strategy is to balance the advantages of pit stops, such as tire replacement and refueling, with the time loss incurred in the pit lane. Current race simulations, used to estimate the best possible race strategy, vary in granularity, modeling of probabilistic events, and require manual input for in-laps. This paper addresses these limitations by developing a novel simulation model tailored to GT racing and leveraging artificial intelligence to automate strategic decisions. By integrating the simulation with OpenAI's Gym framework, a reinforcement learning environment is created and an agent is trained. The study evaluates various hyperparameter configurations, observation spaces, and reward functions, drawing upon historical timing data from the 2020 N\\\"urburgring Langstrecken Serie for empirical parameter validation. The results demonstrate the potential of reinforcement learning for improving race strategy decision-making, as the trained agent makes sensible decisions regarding pit stop timing and refueling amounts. Key parameters, such as learning rate, decay rate and the number of episodes, are identified as crucial factors, while the combination of fuel mass and current race position proves most effective for policy development. The paper contributes to the broader application of reinforcement learning in race simulations and unlocks the potential for race strategy optimization beyond FIA Formula~1, specifically in the GT racing domain.", "url": "https://arxiv.org/abs/2306.16088"}, {"metadata": {"arXiv": "2306.16133", "Date": "Wed, 28 Jun 2023 12:02:27 ", "Title": "Training Deep Surrogate Models with Large Scale Online Learning", "Authors": ["Lucas Meyer (EDF R\\&D", "SINCLAIR AI Lab", "DATAMOVE )", "Marc Schouler (DATAMOVE )", "Robert Alexander Caulk (DATAMOVE )", "Alejandro Rib\\'es (SINCLAIR AI Lab", "EDF R\\&D)", "Bruno Raffin (DATAMOVE )"], "Categories": "cs.AI cs.DC physics.comp-ph"}, "abstract": "The spatiotemporal resolution of Partial Differential Equations (PDEs) plays important roles in the mathematical description of the world's physical phenomena. In general, scientists and engineers solve PDEs numerically by the use of computationally demanding solvers. Recently, deep learning algorithms have emerged as a viable alternative for obtaining fast solutions for PDEs. Models are usually trained on synthetic data generated by solvers, stored on disk and read back for training. This paper advocates that relying on a traditional static dataset to train these models does not allow the full benefit of the solver to be used as a data generator. It proposes an open source online training framework for deep surrogate models. The framework implements several levels of parallelism focused on simultaneously generating numerical simulations and training deep neural networks. This approach suppresses the I/O and storage bottleneck associated with disk-loaded datasets, and opens the way to training on significantly larger datasets. Experiments compare the offline and online training of four surrogate models, including state-of-the-art architectures. Results indicate that exposing deep surrogate models to more dataset diversity, up to hundreds of GB, can increase model generalization capabilities. Fully connected neural networks, Fourier Neural Operator (FNO), and Message Passing PDE Solver prediction accuracy is improved by 68%, 16% and 7%, respectively.", "url": "https://arxiv.org/abs/2306.16133"}, {"metadata": {"arXiv": "2306.16205", "Date": "Wed, 28 Jun 2023 13:37:48 ", "Title": "Towards a Better Understanding of Learning with Multiagent Teams", "Authors": ["David Radke", "Kate Larson", "Tim Brecht and Kyle Tilbury"], "Categories": "cs.AI", "Comments": ["15 pages", "11 figures", "published at the International Joint Conference on Artificial Intelligence (IJCAI) in 2023"]}, "abstract": "While it has long been recognized that a team of individual learning agents can be greater than the sum of its parts, recent work has shown that larger teams are not necessarily more effective than smaller ones. In this paper, we study why and under which conditions certain team structures promote effective learning for a population of individual learning agents. We show that, depending on the environment, some team structures help agents learn to specialize into specific roles, resulting in more favorable global results. However, large teams create credit assignment challenges that reduce coordination, leading to large teams performing poorly compared to smaller ones. We support our conclusions with both theoretical analysis and empirical results.", "url": "https://arxiv.org/abs/2306.16205"}, {"metadata": {"arXiv": "2306.16207", "Date": "Wed, 28 Jun 2023 13:43:46 ", "Title": "Inferring the Goals of Communicating Agents from Actions and Instructions", "Authors": ["Lance Ying", "Tan Zhi-Xuan", "Vikash Mansinghka", "Joshua B. Tenenbaum"], "Categories": "cs.AI cs.CL cs.RO", "Comments": ["8 pages", "5 figures. Accepted to the ICML 2023 Workshop on Theory of Mind in Communicating Agents. Supplementary Information: https://osf.io/gh758/"]}, "abstract": "When humans cooperate, they frequently coordinate their activity through both verbal communication and non-verbal actions, using this information to infer a shared goal and plan. How can we model this inferential ability? In this paper, we introduce a model of a cooperative team where one agent, the principal, may communicate natural language instructions about their shared plan to another agent, the assistant, using GPT-3 as a likelihood function for instruction utterances. We then show how a third person observer can infer the team's goal via multi-modal Bayesian inverse planning from actions and instructions, computing the posterior distribution over goals under the assumption that agents will act and communicate rationally to achieve them. We evaluate this approach by comparing it with human goal inferences in a multi-agent gridworld, finding that our model's inferences closely correlate with human judgments (R = 0.96). When compared to inference from actions alone, we also find that instructions lead to more rapid and less uncertain goal inference, highlighting the importance of verbal communication for cooperative agents.", "url": "https://arxiv.org/abs/2306.16207"}, {"metadata": {"arXiv": "2306.16299", "Date": "Wed, 28 Jun 2023 15:25:30 ", "Title": "Social World Knowledge: Modeling and Applications", "Authors": ["Nir Lotan and Einat Minkov"], "Categories": "cs.AI cs.SI", "Comments": ["Accepted for publication in PLOS ONE"]}, "abstract": "Social world knowledge is a key ingredient in effective communication and information processing by humans and machines alike. As of today, there exist many knowledge bases that represent factual world knowledge. Yet, there is no resource that is designed to capture social aspects of world knowledge. We believe that this work makes an important step towards the formulation and construction of such a resource. We introduce SocialVec, a general framework for eliciting low-dimensional entity embeddings from the social contexts in which they occur in social networks. In this framework, entities correspond to highly popular accounts which invoke general interest. We assume that entities that individual users tend to co-follow are socially related, and use this definition of social context to learn the entity embeddings. Similar to word embeddings which facilitate tasks that involve text semantics, we expect the learned social entity embeddings to benefit multiple tasks of social flavor. In this work, we elicited the social embeddings of roughly 200K entities from a sample of 1.3M Twitter users and the accounts that they follow. We employ and gauge the resulting embeddings on two tasks of social importance. First, we assess the political bias of news sources in terms of entity similarity in the social embedding space. Second, we predict the personal traits of individual Twitter users based on the social embeddings of entities that they follow. In both cases, we show advantageous or competitive performance using our approach compared with task-specific baselines. We further show that existing entity embedding schemes, which are fact-based, fail to capture social aspects of knowledge. We make the learned social entity embeddings available to the research community to support further exploration of social world knowledge and its applications.", "url": "https://arxiv.org/abs/2306.16299"}, {"metadata": {"arXiv": "2306.16368", "Date": "Wed, 28 Jun 2023 17:01:03 ", "Title": "Lagrangian based A* algorithm for automated reasoning", "Authors": ["Renju Rajan"], "Categories": "cs.AI", "Comments": ["8 pages", "3 figures"]}, "abstract": "In this paper, a modification of A* algorithm is considered for the shortest path problem. A weightage is introduced in the heuristic part of the A* algorithm to improve its efficiency. An application of the algorithm is considered for UAV path planning wherein velocity is taken as the weigtage to the heuristic. At the outset, calculus of variations based Lagrange's equation was used to identify velocity as the decisive factor for the dynamical system. This approach would be useful for other problems as well to improve the efficiency of algorithms in those areas.", "url": "https://arxiv.org/abs/2306.16368"}, {"metadata": {"arXiv": "2306.15760", "Date": "Tue, 27 Jun 2023 19:26:28 ", "Title": "xAI-CycleGAN, a Cycle-Consistent Generative Assistive Network", "Authors": ["Tibor Sloboda", "Luk\\'a\\v{s} Hudec", "Wanda Bene\\v{s}ov\\'a"], "Categories": "cs.CV cs.AI", "Comments": ["10 pages", "4 figures", "ICVS TU Wien 2023"]}, "abstract": "In the domain of unsupervised image-to-image transformation using generative transformative models, CycleGAN has become the architecture of choice. One of the primary downsides of this architecture is its relatively slow rate of convergence. In this work, we use discriminator-driven explainability to speed up the convergence rate of the generative model by using saliency maps from the discriminator that mask the gradients of the generator during backpropagation, based on the work of Nagisetty et al., and also introducing the saliency map on input, added onto a Gaussian noise mask, by using an interpretable latent variable based on Wang M.'s Mask CycleGAN. This allows for an explainability fusion in both directions, and utilizing the noise-added saliency map on input as evidence-based counterfactual filtering. This new architecture has much higher rate of convergence than a baseline CycleGAN architecture while preserving the image quality.", "url": "https://arxiv.org/abs/2306.15760"}, {"metadata": {"arXiv": "2306.15880", "Date": "Wed, 28 Jun 2023 02:33:06 ", "Title": "Towards Open Vocabulary Learning: A Survey", "Authors": ["Jianzong Wu", "Xiangtai Li", "Shilin Xu. Haobo Yuan", "Henghui Ding", "Yibo Yang", "Xia Li", "Jiangning Zhang", "Yunhai Tong", "Xudong Jiang", "Bernard Ghanem", "and Dacheng Tao"], "Categories": "cs.CV cs.AI", "Comments": ["Project page at https://github.com/jianzongwu/Awesome-Open-Vocabulary"]}, "abstract": "In the field of visual scene understanding, deep neural networks have made impressive advancements in various core tasks like segmentation, tracking, and detection. However, most approaches operate on the close-set assumption, meaning that the model can only identify pre-defined categories that are present in the training set. Recently, open vocabulary settings were proposed due to the rapid progress of vision language pre-training. These new approaches seek to locate and recognize categories beyond the annotated label space. The open vocabulary approach is more general, practical, and effective compared to weakly supervised and zero-shot settings. This paper provides a thorough review of open vocabulary learning, summarizing and analyzing recent developments in the field. In particular, we begin by comparing it to related concepts such as zero-shot learning, open-set recognition, and out-of-distribution detection. Then, we review several closely related tasks in the case of segmentation and detection, including long-tail problems, few-shot, and zero-shot settings. For the method survey, we first present the basic knowledge of detection and segmentation in close-set as the preliminary knowledge. Next, we examine various scenarios in which open vocabulary learning is used, identifying common design elements and core ideas. Then, we compare the recent detection and segmentation approaches in commonly used datasets and benchmarks. Finally, we conclude with insights, issues, and discussions regarding future research directions. To our knowledge, this is the first comprehensive literature review of open vocabulary learning. We keep tracing related works at https://github.com/jianzongwu/Awesome-Open-Vocabulary.", "url": "https://arxiv.org/abs/2306.15880"}, {"metadata": {"arXiv": "2306.15919", "Date": "Wed, 28 Jun 2023 04:48:21 ", "Title": "Fine-grained 3D object recognition: an approach and experiments", "Authors": ["Junhyung Jo", "Hamidreza Kasaei"], "Categories": "cs.CV cs.AI"}, "abstract": "Three-dimensional (3D) object recognition technology is being used as a core technology in advanced technologies such as autonomous driving of automobiles. There are two sets of approaches for 3D object recognition: (i) hand-crafted approaches like Global Orthographic Object Descriptor (GOOD), and (ii) deep learning-based approaches such as MobileNet and VGG. However, it is needed to know which of these approaches works better in an open-ended domain where the number of known categories increases over time, and the system should learn about new object categories using few training examples. In this paper, we first implemented an offline 3D object recognition system that takes an object view as input and generates category labels as output. In the offline stage, instance-based learning (IBL) is used to form a new category and we use K-fold cross-validation to evaluate the obtained object recognition performance. We then test the proposed approach in an online fashion by integrating the code into a simulated teacher test. As a result, we concluded that the approach using deep learning features is more suitable for open-ended fashion. Moreover, we observed that concatenating the hand-crafted and deep learning features increases the classification accuracy.", "url": "https://arxiv.org/abs/2306.15919"}, {"metadata": {"arXiv": "2306.15977", "Date": "Wed, 28 Jun 2023 07:29:26 ", "Title": "A Dimensional Structure based Knowledge Distillation Method for Cross-Modal Learning", "Authors": ["Lingyu Si", "Hongwei Dong", "Wenwen Qiang", "Junzhi Yu", "Wenlong Zhai", "Changwen Zheng", "Fanjiang Xu", "Fuchun Sun"], "Categories": "cs.CV cs.AI"}, "abstract": "Due to limitations in data quality, some essential visual tasks are difficult to perform independently. Introducing previously unavailable information to transfer informative dark knowledge has been a common way to solve such hard tasks. However, research on why transferred knowledge works has not been extensively explored. To address this issue, in this paper, we discover the correlation between feature discriminability and dimensional structure (DS) by analyzing and observing features extracted from simple and hard tasks. On this basis, we express DS using deep channel-wise correlation and intermediate spatial distribution, and propose a novel cross-modal knowledge distillation (CMKD) method for better supervised cross-modal learning (CML) performance. The proposed method enforces output features to be channel-wise independent and intermediate ones to be uniformly distributed, thereby learning semantically irrelevant features from the hard task to boost its accuracy. This is especially useful in specific applications where the performance gap between dual modalities is relatively large. Furthermore, we collect a real-world CML dataset to promote community development. The dataset contains more than 10,000 paired optical and radar images and is continuously being updated. Experimental results on real-world and benchmark datasets validate the effectiveness of the proposed method.", "url": "https://arxiv.org/abs/2306.15977"}, {"metadata": {"arXiv": "2306.16048", "Date": "Wed, 28 Jun 2023 09:29:06 ", "Title": "Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness", "Authors": ["Zhenlin Xu", "Yi Zhu", "Tiffany Deng", "Abhay Mittal", "Yanbei Chen", "Manchen Wang", "Paolo Favaro", "Joseph Tighe", "Davide Modolo"], "Categories": "cs.CV cs.AI"}, "abstract": "This paper investigates the challenges of applying vision-language models (VLMs) to zero-shot visual recognition tasks in an open-world setting, with a focus on contrastive vision-language models such as CLIP. We first examine the performance of VLMs on concepts of different granularity levels. We propose a way to fairly evaluate the performance discrepancy under two experimental setups and find that VLMs are better at recognizing fine-grained concepts. Furthermore, we find that the similarity scores from VLMs do not strictly reflect the correctness of the textual inputs given visual input. We propose an evaluation protocol to test our hypothesis that the scores can be biased towards more informative descriptions, and the nature of the similarity score between embedding makes it challenging for VLMs to recognize the correctness between similar but wrong descriptions. Our study highlights the challenges of using VLMs in open-world settings and suggests directions for future research to improve their zero-shot capabilities.", "url": "https://arxiv.org/abs/2306.16048"}, {"metadata": {"arXiv": "2306.16186", "Date": "Wed, 28 Jun 2023 13:08:08 ", "Title": "Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection", "Authors": ["Zhewei Chen", "Wai Keung Wong", "Zuofeng Zhong", "Jinpiao Liao", "Ying Qu"], "Categories": "cs.CV cs.AI", "Comments": ["13 pages,4 figures", "3 tables"], "ACM-class": "I.2.10; I.4.9; I.5.4"}, "abstract": "Fabric defect segmentation is integral to textile quality control. Despite this, the scarcity of high-quality annotated data and the diversity of fabric defects present significant challenges to the application of deep learning in this field. These factors limit the generalization and segmentation performance of existing models, impeding their ability to handle the complexity of diverse fabric types and defects. To overcome these obstacles, this study introduces an innovative method to infuse specialized knowledge of fabric defects into the Segment Anything Model (SAM), a large-scale visual model. By introducing and training a unique set of fabric defect-related parameters, this approach seamlessly integrates domain-specific knowledge into SAM without the need for extensive modifications to the pre-existing model parameters. The revamped SAM model leverages generalized image understanding learned from large-scale natural image datasets while incorporating fabric defect-specific knowledge, ensuring its proficiency in fabric defect segmentation tasks. The experimental results reveal a significant improvement in the model's segmentation performance, attributable to this novel amalgamation of generic and fabric-specific knowledge. When benchmarking against popular existing segmentation models across three datasets, our proposed model demonstrates a substantial leap in performance. Its impressive results in cross-dataset comparisons and few-shot learning experiments further demonstrate its potential for practical applications in textile quality control.", "url": "https://arxiv.org/abs/2306.16186"}, {"metadata": {"arXiv": "2306.15724", "Date": "Tue, 27 Jun 2023 18:03:15 ", "Title": "REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction", "Authors": ["Zeyi Liu", "Arpit Bahety", "Shuran Song"], "Categories": "cs.RO cs.AI"}, "abstract": "The ability to detect and analyze failed executions automatically is crucial for an explainable and robust robotic system. Recently, Large Language Models (LLMs) have demonstrated strong common sense reasoning skills on textual inputs. To leverage the power of LLM for robot failure explanation, we propose a framework REFLECT, which converts multi-sensory data into a hierarchical summary of robot past experiences and queries LLM with a progressive failure explanation algorithm. Conditioned on the explanation, a failure correction planner generates an executable plan for the robot to correct the failure and complete the task. To systematically evaluate the framework, we create the RoboFail dataset and show that our LLM-based framework is able to generate informative failure explanations that assist successful correction planning. Project website: https://roboreflect.github.io/", "url": "https://arxiv.org/abs/2306.15724"}, {"metadata": {"arXiv": "2306.15928", "Date": "Wed, 28 Jun 2023 05:21:59 ", "Title": "Reducing Redundant Work in Jump Point Search", "Authors": ["Shizhe Zhao", "Daniel Harabor", "Peter J. Stuckey"], "Categories": "cs.RO cs.AI"}, "abstract": "JPS (Jump Point Search) is a state-of-the-art optimal algorithm for online grid-based pathfinding. Widely used in games and other navigation scenarios, JPS nevertheless can exhibit pathological behaviours which are not well studied: (i) it may repeatedly scan the same area of the map to find successors; (ii) it may generate and expand suboptimal search nodes. In this work, we examine the source of these pathological behaviours, show how they can occur in practice, and propose a purely online approach, called Constrained JPS (CJPS), to tackle them efficiently. Experimental results show that CJPS has low overheads and is often faster than JPS in dynamically changing grid environments: by up to 7x in large game maps and up to 14x in pathological scenarios.", "url": "https://arxiv.org/abs/2306.15928"}, {"metadata": {"arXiv": "2306.16061", "Date": "Wed, 28 Jun 2023 09:51:25 ", "Title": "RoMo-HER: Robust Model-based Hindsight Experience Replay", "Authors": ["Yuming Huang and Bin Ren"], "Categories": "cs.RO cs.AI"}, "abstract": "Sparse rewards are one of the factors leading to low sample efficiency in multi-goal reinforcement learning (RL). Based on Hindsight Experience Replay (HER), model-based relabeling methods have been proposed to relabel goals using virtual trajectories obtained by interacting with the trained model, which can effectively enhance the sample efficiency in accurately modelable sparse-reward environments. However, they are ineffective in robot manipulation environment. In our paper, we design a robust framework called Robust Model-based Hindsight Experience Replay (RoMo-HER) which can effectively utilize the dynamical model in robot manipulation environments to enhance the sample efficiency. RoMo-HER is built upon a dynamics model and a novel goal relabeling technique called Foresight relabeling (FR), which selects the prediction starting state with a specific strategy, predicts the future trajectory of the starting state, and then relabels the goal using the dynamics model and the latest policy to train the agent. Experimental results show that RoMo-HER has higher sample efficiency than HER and Model-based Hindsight Experience Replay in several simulated robot manipulation environments. Furthermore, we integrate RoMo-HER and Relay Hindsight Experience Replay (RHER), which currently exhibits the highest sampling efficiency in most benchmark environments, resulting in a novel approach called Robust Model-based Relay Hindsight Experience Replay (RoMo-RHER). Our experimental results demonstrate that RoMo-RHER achieves higher sample efficiency over RHER, outperforming RHER by 25% and 26% in FetchPush-v1 and FetchPickandPlace-v1, respectively.", "url": "https://arxiv.org/abs/2306.16061"}, {"metadata": {"arXiv": "2306.15696", "Date": "Mon, 26 Jun 2023 09:34:47 ", "Title": "Procedural content generation of puzzle games using conditional generative adversarial networks", "Authors": ["Andreas Hald", "Jens Struckmann Hansen", "Jeppe Kristensen", "Paolo Burelli"], "Categories": "cs.AI cs.LG", "Comments": ["Proceedings of the 15th International Conference on the Foundations of Digital Games 2020"], "DOI": "10.1145/3402942.3409601"}, "abstract": "In this article, we present an experimental approach to using parameterized Generative Adversarial Networks (GANs) to produce levels for the puzzle game Lily's Garden. We extract two condition vectors from the real levels in an effort to control the details of the GAN's outputs. While the GANs perform well in approximating the first condition (map shape), they struggle to approximate the second condition (piece distribution). We hypothesize that this might be improved by trying out alternative architectures for both the Generator and Discriminator of the GANs.", "url": "https://arxiv.org/abs/2306.15696"}, {"metadata": {"arXiv": "2306.16023", "Date": "Wed, 28 Jun 2023 08:50:35 ", "Title": "A Distributed Computation Model Based on Federated Learning Integrates Heterogeneous models and Consortium Blockchain for Solving Time-Varying Problems", "Authors": ["Zhihao Hao", "Guancheng Wang", "Chunwei Tian", "Bob Zhang"], "Categories": "cs.AI cs.DC cs.LG"}, "abstract": "The recurrent neural network has been greatly developed for effectively solving time-varying problems corresponding to complex environments. However, limited by the way of centralized processing, the model performance is greatly affected by factors like the silos problems of the models and data in reality. Therefore, the emergence of distributed artificial intelligence such as federated learning (FL) makes it possible for the dynamic aggregation among models. However, the integration process of FL is still server-dependent, which may cause a great risk to the overall model. Also, it only allows collaboration between homogeneous models, and does not have a good solution for the interaction between heterogeneous models. Therefore, we propose a Distributed Computation Model (DCM) based on the consortium blockchain network to improve the credibility of the overall model and effective coordination among heterogeneous models. In addition, a Distributed Hierarchical Integration (DHI) algorithm is also designed for the global solution process. Within a group, permissioned nodes collect the local models' results from different permissionless nodes and then sends the aggregated results back to all the permissionless nodes to regularize the processing of the local models. After the iteration is completed, the secondary integration of the local results will be performed between permission nodes to obtain the global results. In the experiments, we verify the efficiency of DCM, where the results show that the proposed model outperforms many state-of-the-art models based on a federated learning framework.", "url": "https://arxiv.org/abs/2306.16023"}, {"metadata": {"arXiv": "2306.16296", "Date": "Wed, 28 Jun 2023 15:17:59 ", "Title": "Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning", "Authors": ["Lucas Jarnac", "Miguel Couceiro", "Pierre Monnin"], "Categories": "cs.AI cs.LG"}, "abstract": "Knowledge Graph Construction (KGC) can be seen as an iterative process starting from a high quality nucleus that is refined by knowledge extraction approaches in a virtuous loop. Such a nucleus can be obtained from knowledge existing in an open KG like Wikidata. However, due to the size of such generic KGs, integrating them as a whole may entail irrelevant content and scalability issues. We propose an analogy-based approach that starts from seed entities of interest in a generic KG, and keeps or prunes their neighboring entities. We evaluate our approach on Wikidata through two manually labeled datasets that contain either domain-homogeneous or -heterogeneous seed entities. We empirically show that our analogy-based approach outperforms LSTM, Random Forest, SVM, and MLP, with a drastically lower number of parameters. We also evaluate its generalization potential in a transfer learning setting. These results advocate for the further integration of analogy-based inference in tasks related to the KG lifecycle.", "url": "https://arxiv.org/abs/2306.16296"}, {"metadata": {"arXiv": "2306.15782", "Date": "Tue, 27 Jun 2023 20:09:56 ", "Title": "UTRNet: High-Resolution Urdu Text Recognition In Printed Documents", "Authors": ["Abdur Rahman", "Arjun Ghosh", "and Chetan Arora"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["Accepted at The 17th International Conference on Document Analysis and Recognition (ICDAR 2023)"]}, "abstract": "In this paper, we propose a novel approach to address the challenges of printed Urdu text recognition using high-resolution, multi-scale semantic feature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model, demonstrates state-of-the-art performance on benchmark datasets. To address the limitations of previous works, which struggle to generalize to the intricacies of the Urdu script and the lack of sufficient annotated real-world data, we have introduced the UTRSet-Real, a large-scale annotated real-world dataset comprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000 lines closely resembling real-world and made corrections to the ground truth of the existing IIITH dataset, making it a more reliable resource for future research. We also provide UrduDoc, a benchmark dataset for Urdu text line detection in scanned documents. Additionally, we have developed an online tool for end-to-end Urdu OCR from printed documents by integrating UTRNet with a text detection model. Our work not only addresses the current limitations of Urdu OCR but also paves the way for future research in this area and facilitates the continued advancement of Urdu OCR technology. The project page with source code, datasets, annotations, trained models, and online tool is available at abdur75648.github.io/UTRNet.", "url": "https://arxiv.org/abs/2306.15782"}, {"metadata": {"arXiv": "2306.16045", "Date": "Wed, 28 Jun 2023 09:28:33 ", "Title": "OpenNDD: Open Set Recognition for Neurodevelopmental Disorders Detection", "Authors": ["Jiaming Yu", "Zihao Guan", "Xinyue Chang", "Xiumei Liu", "Zhenshan Shi", "Changcai Yang", "Riqing Chen", "Lanyan Xue", "Lifang Wei"], "Categories": "cs.CV cs.AI cs.LG", "Comments": ["10 pages", "2 figures"]}, "abstract": "Neurodevelopmental disorders (NDDs) are a highly prevalent group of disorders and represent strong clinical behavioral similarities, and that make it very challenging for accurate identification of different NDDs such as autism spectrum disorder (ASD) and attention-deficit hyperactivity disorder (ADHD). Moreover, there is no reliable physiological markers for NDDs diagnosis and it solely relies on psychological evaluation criteria. However, it is crucial to prevent misdiagnosis and underdiagnosis by intelligent assisted diagnosis, which is closely related to the follow-up corresponding treatment. In order to relieve these issues, we propose a novel open set recognition framework for NDDs screening and detection, which is the first application of open set recognition in this field. It combines auto encoder and adversarial reciprocal points open set recognition to accurately identify known classes as well as recognize classes never encountered. And considering the strong similarities between different subjects, we present a joint scaling method called MMS to distinguish unknown disorders. To validate the feasibility of our presented method, we design a reciprocal opposition experiment protocol on the hybrid datasets from Autism Brain Imaging Data Exchange I (ABIDE I) and THE ADHD-200 SAMPLE (ADHD-200) with 791 samples from four sites and the results demonstrate the superiority on various metrics. Our OpenNDD has achieved promising performance, where the accuracy is 77.38%, AUROC is 75.53% and the open set classification rate is as high as 59.43%.", "url": "https://arxiv.org/abs/2306.16045"}, {"metadata": {"arXiv": "2306.16384", "Date": "Wed, 28 Jun 2023 17:22:15 ", "Title": "Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses", "Authors": ["Jeongmin Brian Park and Vikram Sharma Mailthody and Zaid Qureshi and Wen-mei Hwu"], "Categories": "cs.DC cs.AI cs.AR cs.LG", "Comments": ["Under Submission. Source code: https://github.com/jeongminpark417/GIDS"]}, "abstract": "Graph Neural Networks (GNNs) are emerging as a powerful tool for learning from graph-structured data and performing sophisticated inference tasks in various application domains. Although GNNs have been shown to be effective on modest-sized graphs, training them on large-scale graphs remains a significant challenge due to lack of efficient data access and data movement methods. Existing frameworks for training GNNs use CPUs for graph sampling and feature aggregation, while the training and updating of model weights are executed on GPUs. However, our in-depth profiling shows the CPUs cannot achieve the throughput required to saturate GNN model training throughput, causing gross under-utilization of expensive GPU resources. Furthermore, when the graph and its embeddings do not fit in the CPU memory, the overhead introduced by the operating system, say for handling page-faults, comes in the critical path of execution. To address these issues, we propose the GPU Initiated Direct Storage Access (GIDS) dataloader, to enable GPU-oriented GNN training for large-scale graphs while efficiently utilizing all hardware resources, such as CPU memory, storage, and GPU memory with a hybrid data placement strategy. By enabling GPU threads to fetch feature vectors directly from storage, GIDS dataloader solves the memory capacity problem for GPU-oriented GNN training. Moreover, GIDS dataloader leverages GPU parallelism to tolerate storage latency and eliminates expensive page-fault overhead. Doing so enables us to design novel optimizations for exploiting locality and increasing effective bandwidth for GNN training. Our evaluation using a single GPU on terabyte-scale GNN datasets shows that GIDS dataloader accelerates the overall DGL GNN training pipeline by up to 392X when compared to the current, state-of-the-art DGL dataloader.", "url": "https://arxiv.org/abs/2306.16384"}, {"metadata": {"arXiv": "2306.15786", "Date": "Tue, 27 Jun 2023 20:32:07 ", "Title": "An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning", "Authors": ["Sebastian M\\\"uller", "Vanessa Toborek", "Katharina Beckh", "Matthias Jakobs Christian Bauckhage and Pascal Welke"], "Categories": "cs.LG cs.AI"}, "abstract": "The Rashomon Effect describes the following phenomenon: for a given dataset there may exist many models with equally good performance but with different solution strategies. The Rashomon Effect has implications for Explainable Machine Learning, especially for the comparability of explanations. We provide a unified view on three different comparison scenarios and conduct a quantitative evaluation across different datasets, models, attribution methods, and metrics. We find that hyperparameter-tuning plays a role and that metric selection matters. Our results provide empirical support for previously anecdotal evidence and exhibit challenges for both scientists and practitioners.", "url": "https://arxiv.org/abs/2306.15786"}, {"metadata": {"arXiv": "2306.15832", "Date": "Tue, 27 Jun 2023 23:33:30 ", "Title": "Easing Color Shifts in Score-Based Diffusion Models", "Authors": ["Katherine Deck and Tobias Bischoff"], "Categories": "cs.LG cs.AI cs.CV"}, "abstract": "Generated images of score-based models can suffer from errors in their spatial means, an effect, referred to as a color shift, which grows for larger images. This paper introduces a computationally inexpensive solution to mitigate color shifts in score-based diffusion models. We propose a simple nonlinear bypass connection in the score network, designed to process the spatial mean of the input and to predict the mean of the score function. This network architecture substantially improves the resulting spatial means of the generated images, and we show that the improvement is approximately independent of the size of the generated images. As a result, our solution offers a comparatively inexpensive solution for the color shift problem across image sizes. Lastly, we discuss the origin of color shifts in an idealized setting in order to motivate our approach.", "url": "https://arxiv.org/abs/2306.15832"}, {"metadata": {"arXiv": "2306.15902", "Date": "Wed, 28 Jun 2023 03:52:41 ", "Title": "Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization", "Authors": ["Ling Yang", "Jiayi Zheng", "Heyuan Wang", "Zhongyi Liu", "Zhilin Huang", "Shenda Hong", "Wentao Zhang", "Bin Cui"], "Categories": "cs.LG cs.AI cs.CV", "Comments": ["Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)"]}, "abstract": "Out-of-distribution (OOD) graph generalization are critical for many real-world applications. Existing methods neglect to discard spurious or noisy features of inputs, which are irrelevant to the label. Besides, they mainly conduct instance-level class-invariant graph learning and fail to utilize the structural class relationships between graph instances. In this work, we endeavor to address these issues in a unified framework, dubbed Individual and Structural Graph Information Bottlenecks (IS-GIB). To remove class spurious feature caused by distribution shifts, we propose Individual Graph Information Bottleneck (I-GIB) which discards irrelevant information by minimizing the mutual information between the input graph and its embeddings. To leverage the structural intra- and inter-domain correlations, we propose Structural Graph Information Bottleneck (S-GIB). Specifically for a batch of graphs with multiple domains, S-GIB first computes the pair-wise input-input, embedding-embedding, and label-label correlations. Then it minimizes the mutual information between input graph and embedding pairs while maximizing the mutual information between embedding and label pairs. The critical insight of S-GIB is to simultaneously discard spurious features and learn invariant features from a high-order perspective by maintaining class relationships under multiple distributional shifts. Notably, we unify the proposed I-GIB and S-GIB to form our complementary framework IS-GIB. Extensive experiments conducted on both node- and graph-level tasks consistently demonstrate the superior generalization ability of IS-GIB. The code is available at https://github.com/YangLing0818/GraphOOD.", "url": "https://arxiv.org/abs/2306.15902"}, {"metadata": {"arXiv": "2306.15909", "Date": "Wed, 28 Jun 2023 04:16:16 ", "Title": "RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$", "Authors": ["Abhinav Bhatia", "Samer B. Nashed", "Shlomo Zilberstein"], "Categories": "cs.LG cs.AI"}, "abstract": "Meta reinforcement learning (meta-RL) methods such as RL$^2$ have emerged as promising approaches for learning data-efficient RL algorithms tailored to a given task distribution. However, these RL algorithms struggle with long-horizon tasks and out-of-distribution tasks since they rely on recurrent neural networks to process the sequence of experiences instead of summarizing them into general RL components such as value functions. Moreover, even transformers have a practical limit to the length of histories they can efficiently reason about before training and inference costs become prohibitive. In contrast, traditional RL algorithms are data-inefficient since they do not leverage domain knowledge, but they do converge to an optimal policy as more data becomes available. In this paper, we propose RL$^3$, a principled hybrid approach that combines traditional RL and meta-RL by incorporating task-specific action-values learned through traditional RL as an input to the meta-RL neural network. We show that RL$^3$ earns greater cumulative reward on long-horizon and out-of-distribution tasks compared to RL$^2$, while maintaining the efficiency of the latter in the short term. Experiments are conducted on both custom and benchmark discrete domains from the meta-RL literature that exhibit a range of short-term, long-term, and complex dependencies.", "url": "https://arxiv.org/abs/2306.15909"}, {"metadata": {"arXiv": "2306.15913", "Date": "Wed, 28 Jun 2023 04:32:09 ", "Title": "DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces", "Authors": ["Pranavi Pathakota and Hardik Meisheri and Harshad Khadilkar"], "Categories": "cs.LG cs.AI", "Comments": ["17 pages"]}, "abstract": "The ability to learn robust policies while generalizing over large discrete action spaces is an open challenge for intelligent systems, especially in noisy environments that face the curse of dimensionality. In this paper, we present a novel framework to efficiently learn action embeddings that simultaneously allow us to reconstruct the original action as well as to predict the expected future state. We describe an encoder-decoder architecture for action embeddings with a dual channel loss that balances between action reconstruction and state prediction accuracy. We use the trained decoder in conjunction with a standard reinforcement learning algorithm that produces actions in the embedding space. Our architecture is able to outperform two competitive baselines in two diverse environments: a 2D maze environment with more than 4000 discrete noisy actions, and a product recommendation task that uses real-world e-commerce transaction data. Empirical results show that the model results in cleaner action embeddings, and the improved representations help learn better policies with earlier convergence.", "url": "https://arxiv.org/abs/2306.15913"}, {"metadata": {"arXiv": "2306.15934", "Date": "Wed, 28 Jun 2023 05:34:53 ", "Title": "Curious Replay for Model-based Adaptation", "Authors": ["Isaac Kauvar", "Chris Doyle", "Linqi Zhou", "Nick Haber"], "Categories": "cs.LG cs.AI stat.ML", "Comments": ["Accepted at ICML 2023. Website at https://sites.google.com/view/curious-replay"]}, "abstract": "Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay -- a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at https://github.com/AutonomousAgentsLab/curiousreplay", "url": "https://arxiv.org/abs/2306.15934"}, {"metadata": {"arXiv": "2306.15938", "Date": "Wed, 28 Jun 2023 05:50:17 ", "Title": "Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders", "Authors": ["Amandeep Singh", "Michael Weber", "Markus Lange-Hegermann"], "Categories": "cs.LG cs.AI cs.NI stat.AP", "ACM-class": "C.2.m; C.2.3; G.3; I.2.6; I.5.3"}, "abstract": "This paper addresses the challenges of detecting anomalies in cellular networks in an interpretable way and proposes a new approach using variational autoencoders (VAEs) that learn interpretable representations of the latent space for each Key Performance Indicator (KPI) in the dataset. This enables the detection of anomalies based on reconstruction loss and Z-scores. We ensure the interpretability of the anomalies via additional information centroids (c) using the K-means algorithm to enhance representation learning. We evaluate the performance of the model by analyzing patterns in the latent dimension for specific KPIs and thereby demonstrate the interpretability and anomalies. The proposed framework offers a faster and autonomous solution for detecting anomalies in cellular networks and showcases the potential of deep learning-based algorithms in handling big data.", "url": "https://arxiv.org/abs/2306.15938"}, {"metadata": {"arXiv": "2306.15951", "Date": "Wed, 28 Jun 2023 06:21:22 ", "Title": "Reduce Computational Complexity for Convolutional Layers by Skipping Zeros", "Authors": ["Zhiyi Zhang", "Pengfei Zhang", "Zhuopin Xu", "Qi Wang"], "Categories": "cs.LG cs.AI", "Comments": ["To download the code of Dragon-Alpha and experimental datas", "please go to https://github.com/GilgameshXYZ123/Dragon-Alpha"]}, "abstract": "Deep neural networks rely on parallel processors for acceleration. To design operators for them, it requires not only good algorithm to reduce complexity, but also sufficient utilization of hardwares. Convolutional layers mainly contain 3 kinds of operators: convolution in forward propagation, deconvolution and dilated-convolution in backward propagation. When executing these operators, 0s are always added to tensors, causing redundant calculations. This paper gives C-K-S algorithm (ConvV2, KS-deconv, Sk-dilated), which skips these 0s in two ways: trim the filters to exclude padded 0s; transform sparse tensors to dense tensors, to avoid inserted 0s in deconvolution and dilated-convolution. In contrast to regular convolution, deconvolution is hard to accelerate due to its complicacy. This paper provides high-performance GPU implementations of C-K-S, and verifies their effectiveness with comparison to PyTorch. According to the experiments, C-K-S has advantages over PyTorch in certain cases, especially in deconvolution on small feature-maps. Further enhancement of C-K-S can be done by making full optimizations oriented at specific GPU architectures.", "url": "https://arxiv.org/abs/2306.15951"}, {"metadata": {"arXiv": "2306.15969", "Date": "Wed, 28 Jun 2023 07:11:39 ", "Title": "Separable Physics-Informed Neural Networks", "Authors": ["Junwoo Cho", "Seungtae Nam", "Hyunmo Yang", "Seok-Bae Yun", "Youngjoon Hong", "Eunbyung Park"], "Categories": "cs.LG cs.AI", "Comments": ["arXiv admin note: text overlap with arXiv:2211.08761"]}, "abstract": "Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate highly complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, but it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this issue, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to significantly reduce the number of network propagations in multi-dimensional PDEs unlike point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points (>10^7) on a single commodity GPU. The experimental results show drastically reduced computational costs (62x in wall-clock time, 1,394x in FLOPs given the same number of collocation points) in multi-dimensional PDEs while achieving better accuracy. Furthermore, we present that SPINN can solve a chaotic (2+1)-d Navier-Stokes equation significantly faster than the best-performing prior method (9 minutes vs 10 hours in a single GPU), maintaining accuracy. Finally, we showcase that SPINN can accurately obtain the solution of a highly nonlinear and multi-dimensional PDE, a (3+1)-d Navier-Stokes equation.", "url": "https://arxiv.org/abs/2306.15969"}, {"metadata": {"arXiv": "2306.16015", "Date": "Wed, 28 Jun 2023 08:41:49 ", "Title": "BayesFlow: Amortized Bayesian Workflows With Neural Networks", "Authors": ["Stefan T Radev and Marvin Schmitt and Lukas Schumacher and Lasse Elsem\\\"uller and Valentin Pratz and Yannik Sch\\\"alte and Ullrich K\\\"othe and Paul-Christian B\\\"urkner"], "Categories": "cs.LG cs.AI stat.ML"}, "abstract": "Modern Bayesian inference involves a mixture of computational techniques for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows for data analysis. Typical problems in Bayesian workflows are the approximation of intractable posterior distributions for diverse model types and the comparison of competing models of the same process in terms of their complexity and predictive performance. This manuscript introduces the Python library BayesFlow for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized.", "url": "https://arxiv.org/abs/2306.16015"}, {"metadata": {"arXiv": "2306.16021", "Date": "Wed, 28 Jun 2023 08:48:40 ", "Title": "Structure in Reinforcement Learning: A Survey and Open Problems", "Authors": ["Aditya Mohan", "Amy Zhang", "Marius Lindauer"], "Categories": "cs.LG cs.AI"}, "abstract": "Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep Neural Networks (DNNs) for function approximation, has demonstrated considerable success in numerous applications. However, its practicality in addressing a wide range of real-world scenarios, characterized by diverse and unpredictable dynamics, noisy signals, and large state and action spaces, remains limited. This limitation stems from issues such as poor data efficiency, limited generalization capabilities, a lack of safety guarantees, and the absence of interpretability, among other factors. To overcome these challenges and improve performance across these crucial metrics, one promising avenue is to incorporate additional structural information about the problem into the RL learning process. Various sub-fields of RL have proposed methods for incorporating such inductive biases. We amalgamate these diverse methodologies under a unified framework, shedding light on the role of structure in the learning problem, and classify these methods into distinct patterns of incorporating structure. By leveraging this comprehensive framework, we provide valuable insights into the challenges associated with structured RL and lay the groundwork for a design pattern perspective on RL research. This novel perspective paves the way for future advancements and aids in the development of more effective and efficient RL algorithms that can potentially handle real-world scenarios better.", "url": "https://arxiv.org/abs/2306.16021"}, {"metadata": {"arXiv": "2306.16058", "Date": "Wed, 28 Jun 2023 09:40:03 ", "Title": "DUET: 2D Structured and Approximately Equivariant Representations", "Authors": ["Xavier Suau", "Federico Danieli", "T. Anderson Keller", "Arno Blaas", "Chen Huang", "Jason Ramapuram", "Dan Busbridge", "Luca Zappella"], "Categories": "cs.LG cs.AI", "Comments": ["Accepted at ICML 2023"]}, "abstract": "Multiview Self-Supervised Learning (MSSL) is based on learning invariances with respect to a set of input transformations. However, invariance partially or totally removes transformation-related information from the representations, which might harm performance for specific downstream tasks that require such information. We propose 2D strUctured and EquivarianT representations (coined DUET), which are 2d representations organized in a matrix structure, and equivariant with respect to transformations acting on the input data. DUET representations maintain information about an input transformation, while remaining semantically expressive. Compared to SimCLR (Chen et al., 2020) (unstructured and invariant) and ESSL (Dangovski et al., 2022) (unstructured and equivariant), the structured and equivariant nature of DUET representations enables controlled generation with lower reconstruction error, while controllability is not possible with SimCLR or ESSL. DUET also achieves higher accuracy for several discriminative tasks, and improves transfer learning.", "url": "https://arxiv.org/abs/2306.16058"}, {"metadata": {"arXiv": "2306.16064", "Date": "Wed, 28 Jun 2023 09:52:36 ", "Title": "Federated Generative Learning with Foundation Models", "Authors": ["Jie Zhang", "Xiaohua Qi", "Bo Zhao"], "Categories": "cs.LG cs.AI"}, "abstract": "Existing federated learning solutions focus on transmitting features, parameters or gadients between clients and server, which suffer from serious low-efficiency and privacy-leakage problems. Thanks to the emerging foundation generative models, we propose a novel federated learning framework, namely Federated Generative Learning, that transmits prompts associated with distributed training data between clients and server. The informative training data can be synthesized remotely based on received prompts containing little privacy and the foundation generative models. The new framework possesses multiple advantages, including improved communication efficiency, better resilience to distribution shift, substantial performance gains, and enhanced privacy protection, which are verified in extensive experiments on ImageNet and DomainNet datasets.", "url": "https://arxiv.org/abs/2306.16064"}, {"metadata": {"arXiv": "2306.16077", "Date": "Wed, 28 Jun 2023 10:18:08 ", "Title": "Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization", "Authors": ["Ganyu Wang", "Qingsong Zhang", "Li Xiang", "Boyu Wang", "Bin Gu", "Charles Ling"], "Categories": "cs.LG cs.AI cs.DC", "Comments": ["Under Review"]}, "abstract": "Vertical Federated Learning (VFL) attracts increasing attention because it empowers multiple parties to jointly train a privacy-preserving model over vertically partitioned data. Recent research has shown that applying zeroth-order optimization (ZOO) has many advantages in building a practical VFL algorithm. However, a vital problem with the ZOO-based VFL is its slow convergence rate, which limits its application in handling modern large models. To address this problem, we propose a cascaded hybrid optimization method in VFL. In this method, the downstream models (clients) are trained with ZOO to protect privacy and ensure that no internal information is shared. Meanwhile, the upstream model (server) is updated with first-order optimization (FOO) locally, which significantly improves the convergence rate, making it feasible to train the large models without compromising privacy and security. We theoretically prove that our VFL framework converges faster than the ZOO-based VFL, as the convergence of our framework is not limited by the size of the server model, making it effective for training large models with the major part on the server. Extensive experiments demonstrate that our method achieves faster convergence than the ZOO-based VFL framework, while maintaining an equivalent level of privacy protection. Moreover, we show that the convergence of our VFL is comparable to the unsafe FOO-based VFL baseline. Additionally, we demonstrate that our method makes the training of a large model feasible.", "url": "https://arxiv.org/abs/2306.16077"}, {"metadata": {"arXiv": "2306.16090", "Date": "Wed, 28 Jun 2023 10:46:14 ", "Title": "Empirical Loss Landscape Analysis of Neural Network Activation Functions", "Authors": ["Anna Sergeevna Bosman", "Andries Engelbrecht", "Marde Helbig"], "Categories": "cs.LG cs.AI cs.NE", "Comments": ["Accepted for publication in Genetic and Evolutionary Computation Conference Companion", "July 15--19", "2023", "Lisbon", "Portugal"], "DOI": "10.1145/3583133.3596321"}, "abstract": "Activation functions play a significant role in neural network design by enabling non-linearity. The choice of activation function was previously shown to influence the properties of the resulting loss landscape. Understanding the relationship between activation functions and loss landscape properties is important for neural architecture and training algorithm design. This study empirically investigates neural network loss landscapes associated with hyperbolic tangent, rectified linear unit, and exponential linear unit activation functions. Rectified linear unit is shown to yield the most convex loss landscape, and exponential linear unit is shown to yield the least flat loss landscape, and to exhibit superior generalisation performance. The presence of wide and narrow valleys in the loss landscape is established for all activation functions, and the narrow valleys are shown to correlate with saturated neurons and implicitly regularised network configurations.", "url": "https://arxiv.org/abs/2306.16090"}, {"metadata": {"arXiv": "2306.16177", "Date": "Wed, 28 Jun 2023 12:58:42 ", "Title": "Defining data science: a new field of inquiry", "Authors": ["Michael L Brodie"], "Categories": "cs.LG cs.AI cs.DB", "ACM-class": "I.2; I.2.4; I.2.7; K.2"}, "abstract": "Data science is not a science. It is a research paradigm. Its power, scope, and scale will surpass science, our most powerful research paradigm, to enable knowledge discovery and change our world. We have yet to understand and define it, vital to realizing its potential and managing its risks. Modern data science is in its infancy. Emerging slowly since 1962 and rapidly since 2000, it is a fundamentally new field of inquiry, one of the most active, powerful, and rapidly evolving 21st century innovations. Due to its value, power, and applicability, it is emerging in 40+ disciplines, hundreds of research areas, and thousands of applications. Millions of data science publications contain myriad definitions of data science and data science problem solving. Due to its infancy, many definitions are independent, application-specific, mutually incomplete, redundant, or inconsistent, hence so is data science. This research addresses this data science multiple definitions challenge by proposing the development of coherent, unified definition based on a data science reference framework using a data science journal for the data science community to achieve such a definition. This paper provides candidate definitions for essential data science artifacts that are required to discuss such a definition. They are based on the classical research paradigm concept consisting of a philosophy of data science, the data science problem solving paradigm, and the six component data science reference framework (axiology, ontology, epistemology, methodology, methods, technology) that is a frequently called for unifying framework with which to define, unify, and evolve data science. It presents challenges for defining data science, solution approaches, i.e., means for defining data science, and their requirements and benefits as the basis of a comprehensive solution.", "url": "https://arxiv.org/abs/2306.16177"}, {"metadata": {"arXiv": "2306.16326", "Date": "Wed, 28 Jun 2023 16:00:45 ", "Title": "Representation Learning via Variational Bayesian Networks", "Authors": ["Oren Barkan", "Avi Caciularu", "Idan Rejwan", "Ori Katz", "Jonathan Weill", "Itzik Malkiel", "Noam Koenigstein"], "Categories": "cs.LG cs.AI cs.CL"}, "abstract": "We present Variational Bayesian Network (VBN) - a novel Bayesian entity representation learning model that utilizes hierarchical and relational side information and is particularly useful for modeling entities in the ``long-tail'', where the data is scarce. VBN provides better modeling for long-tail entities via two complementary mechanisms: First, VBN employs informative hierarchical priors that enable information propagation between entities sharing common ancestors. Additionally, VBN models explicit relations between entities that enforce complementary structure and consistency, guiding the learned representations towards a more meaningful arrangement in space. Second, VBN represents entities by densities (rather than vectors), hence modeling uncertainty that plays a complementary role in coping with data scarcity. Finally, we propose a scalable Variational Bayes optimization algorithm that enables fast approximate Bayesian inference. We evaluate the effectiveness of VBN on linguistic, recommendations, and medical inference tasks. Our findings show that VBN outperforms other existing methods across multiple datasets, and especially in the long-tail.", "url": "https://arxiv.org/abs/2306.16326"}, {"metadata": {"arXiv": "2306.16334", "Date": "Wed, 28 Jun 2023 16:10:01 ", "Title": "Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection", "Authors": ["Vit\\'oria Barin-Pacela", "Kartik Ahuja", "Simon Lacoste-Julien", "Pascal Vincent"], "Categories": "cs.LG cs.AI"}, "abstract": "Disentanglement aims to recover meaningful latent ground-truth factors from only the observed distribution. Identifiability provides the theoretical grounding for disentanglement to be well-founded. Unfortunately, unsupervised identifiability of independent latent factors is a theoretically proven impossibility in the i.i.d. setting under a general nonlinear smooth map from factors to observations. In this work, we show that, remarkably, it is possible to recover discretized latent coordinates under a highly generic nonlinear smooth mapping (a diffeomorphism) without any additional inductive bias on the mapping. This is, assuming that latent density has axis-aligned discontinuity landmarks, but without making the unrealistic assumption of statistical independence of the factors. We introduce this novel form of identifiability, termed quantized coordinate identifiability, and provide a comprehensive proof of the recovery of discretized coordinates.", "url": "https://arxiv.org/abs/2306.16334"}, {"metadata": {"arXiv": "2306.16413", "Date": "Wed, 28 Jun 2023 17:59:10 ", "Title": "MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning", "Authors": ["Paul Pu Liang", "Yiwei Lyu", "Xiang Fan", "Arav Agarwal", "Yun Cheng", "Louis-Philippe Morency", "Ruslan Salakhutdinov"], "Categories": "cs.LG cs.AI cs.CL cs.CV cs.MM", "Comments": ["JMLR Open Source Software 2023", "Code available at https://github.com/pliang279/MultiBench"]}, "abstract": "Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of > 20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.", "url": "https://arxiv.org/abs/2306.16413"}, {"metadata": {"arXiv": "2306.16415", "Date": "Wed, 28 Jun 2023 17:59:35 ", "Title": "On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks", "Authors": ["Wenxiao Wang", "Soheil Feizi"], "Categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "Comments": ["15 pages"]}, "abstract": "The increasing access to data poses both opportunities and risks in deep learning, as one can manipulate the behaviors of deep learning models with malicious training samples. Such attacks are known as data poisoning. Recent advances in defense strategies against data poisoning have highlighted the effectiveness of aggregation schemes in achieving state-of-the-art results in certified poisoning robustness. However, the practical implications of these approaches remain unclear. Here we focus on Deep Partition Aggregation, a representative aggregation defense, and assess its practical aspects, including efficiency, performance, and robustness. For evaluations, we use ImageNet resized to a resolution of 64 by 64 to enable evaluations at a larger scale than previous ones. Firstly, we demonstrate a simple yet practical approach to scaling base models, which improves the efficiency of training and inference for aggregation defenses. Secondly, we provide empirical evidence supporting the data-to-complexity ratio, i.e. the ratio between the data set size and sample complexity, as a practical estimation of the maximum number of base models that can be deployed while preserving accuracy. Last but not least, we point out how aggregation defenses boost poisoning robustness empirically through the poisoning overfitting phenomenon, which is the key underlying mechanism for the empirical poisoning robustness of aggregations. Overall, our findings provide valuable insights for practical implementations of aggregation defenses to mitigate the threat of data poisoning.", "url": "https://arxiv.org/abs/2306.16415"}, {"metadata": {"arXiv": "2306.15793", "Date": "Tue, 27 Jun 2023 20:41:59 ", "Title": "A Population-Level Analysis of Neural Dynamics in Robust Legged Robots", "Authors": ["Eugene R. Rush", "Christoffer Heckman", "Kaushik Jayaram", "J. Sean Humbert"], "Categories": "cs.RO cs.AI cs.LG cs.NE q-bio.NC"}, "abstract": "Recurrent neural network-based reinforcement learning systems are capable of complex motor control tasks such as locomotion and manipulation, however, much of their underlying mechanisms still remain difficult to interpret. Our aim is to leverage computational neuroscience methodologies to understanding the population-level activity of robust robot locomotion controllers. Our investigation begins by analyzing topological structure, discovering that fragile controllers have a higher number of fixed points with unstable directions, resulting in poorer balance when instructed to stand in place. Next, we analyze the forced response of the system by applying targeted neural perturbations along directions of dominant population-level activity. We find evidence that recurrent state dynamics are structured and low-dimensional during walking, which aligns with primate studies. Additionally, when recurrent states are perturbed to zero, fragile agents continue to walk, which is indicative of a stronger reliance on sensory input and weaker recurrence.", "url": "https://arxiv.org/abs/2306.15793"}, {"metadata": {"arXiv": "2306.15858", "Date": "Wed, 28 Jun 2023 01:18:53 ", "Title": "Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-hand Objects", "Authors": ["Alireza Rezazadeh", "Snehal Dikhale", "Soshi Iba and Nawid Jamali"], "Categories": "cs.RO cs.AI cs.CV cs.LG"}, "abstract": "Robotic manipulation, in particular in-hand object manipulation, often requires an accurate estimate of the object's 6D pose. To improve the accuracy of the estimated pose, state-of-the-art approaches in 6D object pose estimation use observational data from one or more modalities, e.g., RGB images, depth, and tactile readings. However, existing approaches make limited use of the underlying geometric structure of the object captured by these modalities, thereby, increasing their reliance on visual features. This results in poor performance when presented with objects that lack such visual features or when visual features are simply occluded. Furthermore, current approaches do not take advantage of the proprioceptive information embedded in the position of the fingers. To address these limitations, in this paper: (1) we introduce a hierarchical graph neural network architecture for combining multimodal (vision and touch) data that allows for a geometrically informed 6D object pose estimation, (2) we introduce a hierarchical message passing operation that flows the information within and across modalities to learn a graph-based object representation, and (3) we introduce a method that accounts for the proprioceptive information for in-hand object representation. We evaluate our model on a diverse subset of objects from the YCB Object and Model Set, and show that our method substantially outperforms existing state-of-the-art work in accuracy and robustness to occlusion. We also deploy our proposed framework on a real robot and qualitatively demonstrate successful transfer to real settings.", "url": "https://arxiv.org/abs/2306.15858"}];

        var papersDiv = document.getElementById("papers");

        papers.forEach(function(paper, index) {
            var paperDiv = document.createElement("div");
            paperDiv.className = "paper";

            var titleDiv = document.createElement("div");
            titleDiv.innerText = (index + 1) + ". " + paper.metadata.Title;
            titleDiv.className = "dropdown";

            var abstractDiv = document.createElement("div");
            abstractDiv.innerText = paper.abstract;
            abstractDiv.className = "abstract";

            var linkDiv = document.createElement("div");
            linkDiv.innerHTML = '<a href="' + paper.url + '" target="_blank">Link to paper</a>';
            linkDiv.className = "link";

            titleDiv.addEventListener("click", function() {
                var display = abstractDiv.style.display;
                abstractDiv.style.display = display === "block" ? "none" : "block";
                linkDiv.style.display = abstractDiv.style.display;
            });

            paperDiv.appendChild(titleDiv);
            paperDiv.appendChild(abstractDiv);
            paperDiv.appendChild(linkDiv);
            papersDiv.appendChild(paperDiv);
        });
    </script>
</body>
</html>
